"Authors","Author full names","Author(s) ID","Titles","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","DOI","Cited by","Link","Abstract","Indexed Keywords","Author Keywords","Document Type","Publication Stage","Open Access","Source","EID"
"Abduljawad M.; Alsalmani A.","Abduljawad, Mohamed (58067643600); Alsalmani, Abdullah (57554356500)","58067643600; 57554356500","Towards Creating Exotic Remote Sensing Datasets using Image Generating AI","2022","2022 International Conference on Electrical and Computing Technologies and Applications, ICECTA 2022","","","","84","88","4","10.1109/ICECTA57148.2022.9990245","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146372111&doi=10.1109%2fICECTA57148.2022.9990245&partnerID=40&md5=c9b7a7d99817a1936107810c1d9a8225","Over the past few years, neural networks have been used more often to solve long lasting challenges. Remote sensing and data classification were some of the fields that have widely depended on this continuously developing technology. In this context, remote sensing data related to places with harsh conditions have been missing, especially the ones related to SAR imagery. Such conditions include deserts, glaciers, and icebergs, where lots of people have lost their lives in, due to the lack of efficient methods of searching and finding these people in such critical timing. Training AI models on similar scenarios to fasten the process can be beneficial, but the lack of data is an obstacle in the way of development such models. In this paper, we propose using image generating AI systems to generate remote sensing datasets that are difficult to collect using normal imagery, thus creating more efficient image classification systems that can be used in scenarios such as locating missing people. Several AI models are discussed in this paper: Dall-E 2, Stable Diffusion and Midjourney, where they are found to vary a lot in terms of the generated images, that could be because of the architecture of the model, and the data they trained on. The overall performance of the AI models is promising. Dall-E 2 performed the best in our tests, followed by Stable Diffusion, and finally Midjourney. This research could open the door to using such models in generating lots of datasets, which might solve crucial problems.  © 2022 IEEE.","Arid regions; Classification (of information); Diffusion; Generative adversarial networks; Radar imaging; Sea ice; Synthetic aperture radar; Condition; Data classification; Dataset; Diffusion model; Long lasting; Neural-networks; Remote data; Remote sensing classification; Remote sensing data; Remote-sensing; Remote sensing","Datasets; Diffusion Models; Generative Adversarial Networks; Remote Sensing","Conference paper","Final","","Scopus","2-s2.0-85146372111"
"Zhu Y.; Liu C.","Zhu, Yongli (55723795200); Liu, Chengxi (55210007500)","55723795200; 55210007500","Iceberg Detection by CNN Based on Incidence-Angle Confusion","2020","Advances in Intelligent Systems and Computing","944","","","44","56","12","10.1007/978-3-030-17798-0_6","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065492551&doi=10.1007%2f978-3-030-17798-0_6&partnerID=40&md5=7a33b2647f92a8126d35a2da0f8e738b","In this paper, an image object identification problem for the Kaggle Iceberg Classifier Challenge was tackled by deep neural network. Basic convolutional neural network (CNN) was implemented and tested firstly. Then, deeper networks including VGG16 and ResNet50 are adopted to improve the accuracy. The deep learning-based methods are also compared with the conventional machine learning method i.e. SVM (support Vector Machine). Three feature augmentation approaches are utilized and compared, i.e. incidence angle confusion of satellite radar signals, multi-band composition and data augmentation of the original image data. Tentative results by GAN (Generative Adversarial Network) and Capsule Network are also presented. Results demonstrate the applicability and superiority of CNN over the conventional method (SVM) on the given dataset. © 2020, Springer Nature Switzerland AG.","Deep neural networks; Neural networks; Object detection; Sea ice; Support vector machines; Adversarial networks; Capsule; Conventional machines; Conventional methods; Convolutional neural network; Iceberg; Learning-based methods; SVM(support vector machine); Computer vision","Capsule; GAN; Iceberg; Object detection; SVM","Conference paper","Final","","Scopus","2-s2.0-85065492551"
"Zhao C.; Dong X.; Yan Y.; Su N.; Huang B.","Zhao, Chunhui (7403563984); Dong, Xiaoyu (57212387140); Yan, Yiming (55243504600); Su, Nan (57203308751); Huang, Bowen (57222247635)","7403563984; 57212387140; 55243504600; 57203308751; 57222247635","A Distribution Controllable Simulation Method of Remote Sensing Sea-Ice Images","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323550","3063","3065","2","10.1109/IGARSS39084.2020.9323550","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101991430&doi=10.1109%2fIGARSS39084.2020.9323550&partnerID=40&md5=98e7c83166c301e62d44006cdd50f9a3","In the case of sailing out in the sea-ice areas, it is instructive for route planning to research the distribution characters of ice in the target sea. Existing deep learning methods have shown their strength on sea-ice images processing like image classification. Due to the complex environment around sea-ice area, capturing large quantities of images is not easy. Besides, it's often hard to guarantee the abundance of sea-ice distribution of each different scene class, which causes unsatisfactory classification results. Therefore, it is of considerable practical value to research on sea-ice images simulation. In this paper, a distribution controllable simulation method is proposed based on generative adversarial networks for remote sensing sea-ice images. This research can help settle the problem of small sea-ice samples, as well as can provide a practical method for optical image simulation and similar type problems. © 2020 IEEE.","Deep learning; Geology; Geometrical optics; Ice problems; Image classification; Learning systems; Sea ice; Adversarial networks; Classification results; Complex environments; Distribution character; Images processing; Images simulations; Practical method; Sea ice distribution; Remote sensing","generative adversarial networks; image simulation; remote sensing sea-ice","Conference paper","Final","","Scopus","2-s2.0-85101991430"
"Wang X.; Zhao Y.; Yang S.; Wang Y.; Shangguan D.","Wang, Xingdong (55577953500); Zhao, Yue (57821017600); Yang, Shuhui (57226787386); Wang, Yuhua (57226259594); Shangguan, Donghui (57431323200)","55577953500; 57821017600; 57226787386; 57226259594; 57431323200","CGAN Based Improved ASI Retrieval Algorithm for Antarctic Sea Ice Concentration","2022","Frontiers in Marine Science","9","","844359","","","","10.3389/fmars.2022.844359","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135078765&doi=10.3389%2ffmars.2022.844359&partnerID=40&md5=5acaea310bf8b8ee58c2053b7db8de5d","Sea ice change is closely related to the change of global atmosphere and ocean circulation, which plays an important role in the study of global climate change. Sea ice concentration is one of the important parameters to study the temporal and spatial change of sea ice. Accurately retrieving sea ice concentration is the innovation of this paper. At present, the high-resolution microwave-detected sea ice concentration product was provided by the University of Bremen, which was derived by the Arctic Radiation and Turbulence Interaction Study (ARTSIST) Sea Ice (ASI) algorithm based on the Advanced Microwave Scanning Radiometer for Earth Observing System (AMSR-E) 89-GHz brightness temperature data. The AMSR-E/AMSR-2 89-GHz brightness temperature data has higher spatial resolution, but it is often affected by cloud and water vapor, which affects the recognition and subsequent use of ground feature. Although the weather filters can remove some errors in the edge regions of the sea water and the sea ice, the errors of the sea ice concentration in other regions cannot be removed. The generative model of Conditional Generative Adversarial Network (CGAN) increases the utilization of image feature information through skip connection, which improves the removal of the influence of cloud and water vapor. The discriminative model can retain the image feature information and realize the non-linear mapping from the image to the image. The loss function can reduce the pixel-level loss, which can remove the influence of cloud and water vapor. Therefore, this paper proposed an improved ASI algorithm based on CGAN. Firstly, the relatively stable relationship between the 89-GHz brightness temperature data which is not disturbed or less affected by the external environment and the 36-GHz brightness temperature data was determined, and the 89-GHz brightness temperature data with large interference was screened. Secondly, based on the 36-GHz brightness temperature data with high reliability, the 89-GHz brightness temperature data with large interference was corrected through CGAN. Finally, the ASI algorithm was used to retrieve sea ice concentration. Compared with sea ice concentration retrieved by the ASI algorithm, the results showed that the improved ASI algorithm based on CGAN was feasible. Compared with sea ice distribution obtained from the Landsat 8 OLI-L1T data, the improved ASI algorithm based on CGAN significantly improves the inversion accuracy of sea ice concentration. The improved ASI algorithm based on CGAN makes use of the reliable 36-GHz brightness temperature data, which greatly reduces the error caused by cloud and water vapor, and the method effectively corrects sea ice concentration of the pixels affected by the external environment. Therefore, the improved ASI algorithm based on CGAN realizes high spatial resolution and significantly improves the inversion accuracy of sea ice concentration. Copyright © 2022 Wang, Zhao, Yang, Wang and Shangguan.","","AMSR-2; Antarctic; CGAN; data correction; sea ice concentration","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85135078765"
"Ghosh A.; Kulharia V.; Namboodiri V.; Torr P.H.S.; Dokania P.K.","Ghosh, Arnab (57207030871); Kulharia, Viveka (57195957444); Namboodiri, Vinay (8724086000); Torr, Philip H.S. (56821543600); Dokania, Puneet K. (56336168600)","57207030871; 57195957444; 8724086000; 56821543600; 56336168600","Multi-agent Diverse Generative Adversarial Networks","2018","Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition","","","8578986","8513","8521","8","10.1109/CVPR.2018.00888","138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062669337&doi=10.1109%2fCVPR.2018.00888&partnerID=40&md5=b11bb456a1ea3262378312caba2cbf35","We propose MAD-GAN, an intuitive generalization to the Generative Adversarial Networks (GANs) and its conditional variants to address the well known problem of mode collapse. First, MAD-GAN is a multi-agent GAN architecture incorporating multiple generators and one discriminator. Second, to enforce that different generators capture diverse high probability modes, the discriminator of MAD-GAN is designed such that along with finding the real and fake samples, it is also required to identify the generator that generated the given fake sample. Intuitively, to succeed in this task, the discriminator must learn to push different generators towards different identifiable modes. We perform extensive experiments on synthetic and real datasets and compare MAD-GAN with different variants of GAN. We show high quality diverse sample generations for challenging tasks such as image-to-image translation and face generation. In addition, we also show that MAD-GAN is able to disentangle different modalities when trained using highly challenging diverse-class dataset (e.g. dataset with images of forests, icebergs, and bedrooms). In the end, we show its efficacy on the unsupervised feature representation task. © 2018 IEEE.","Computer vision; Sea ice; Adversarial networks; Face generation; Feature representation; High probability; High quality; Image translation; Real data sets; Sample generations; Multi agent systems","","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85062669337"
"Sasaki H.; Willcocks C.G.; Breckon T.P.","Sasaki, Hiroshi (57219732822); Willcocks, Chris G. (55179413600); Breckon, Toby P. (8661055600)","57219732822; 55179413600; 8661055600","Data augmentation via mixed class interpolation using cycle-consistent generative adversarial networks applied to cross-domain imagery","2020","Proceedings - International Conference on Pattern Recognition","","","9413023","1059","1066","7","10.1109/ICPR48806.2021.9413023","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110497161&doi=10.1109%2fICPR48806.2021.9413023&partnerID=40&md5=dda7da1456ad4062eca45ac97d7c0172","Machine learning driven object detection and classification within non-visible imagery has an important role in many fields such as night vision, all-weather surveillance and aviation security. However, such applications often suffer due to the limited quantity and variety of non-visible spectral domain imagery, in contrast to the high data availability of visible-band imagery that readily enables contemporary deep learning driven detection and classification approaches. To address this problem, this paper proposes and evaluates a novel data augmentation approach that leverages the more readily available visible-band imagery via a generative domain transfer model. The model can synthesise large volumes of non-visible domain imagery by image-to-image (I2I) translation from the visible image domain. Furthermore, we show that the generation of interpolated mixed class (non-visible domain) image examples via our novel Conditional CycleGAN Mixup Augmentation (C2GMA) methodology can lead to a significant improvement in the quality of non-visible domain classification tasks that otherwise suffer due to limited data availability. Focusing on classification within the Synthetic Aperture Radar (SAR) domain, our approach is evaluated on a variation of the Statoil/C-CORE Iceberg Classifier Challenge dataset and achieves 75.4% accuracy, demonstrating a significant improvement when compared against traditional data augmentation strategies (Rotation, Mixup, and MixCycleGAN). © 2020 IEEE","Classification (of information); Deep learning; Object detection; Sea ice; Synthetic aperture radar; Adversarial networks; All-weather surveillance; Aviation Security; Classification approach; Classification tasks; Data augmentation; Data availability; Spectral domains; Image enhancement","","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85110497161"
"Tao Y.; Muller J.-P.","Tao, Yu (56539197700); Muller, Jan-Peter (7404871794)","56539197700; 7404871794","Super-resolution restoration of MISR images using the UCL MAGiGAN system","2019","Remote Sensing","11","1","52","","","","10.3390/rs11010052","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059950995&doi=10.3390%2frs11010052&partnerID=40&md5=a20a39691361ba100c7146d05da7ba55","High spatial resolution Earth observation imagery is considered desirable for many scientific and commercial applications. Given repeat multi-angle imagery, an imaging instrument with a specified spatial resolution, we can use image processing and deep learning techniques to enhance the spatial resolution. In this paper, we introduce the University College London (UCL) MAGiGAN super-resolution restoration (SRR) system based on multi-angle feature restoration and deep SRR networks. We explore the application of MAGiGAN SRR to a set of 9 MISR red band images (275 m) to produce up to a factor of 3.75 times resolution enhancement. We show SRR results over four different test sites containing different types of image content including urban and rural targets, sea ice and a cloud field. Different image metrics are introduced to assess the overall SRR performance, and these are employed to compare the SRR results with the original MISR input images and higher resolution Landsat images, where available. Significant resolution improvement over various types of image content is demonstrated and the potential of SRR for different scientific application is discussed. © 2019 by the authors.","Deep learning; Image reconstruction; Image resolution; Optical resolving power; Restoration; Sea ice; Urban growth; Adversarial networks; Feature matching; Gotcha; MISR; Super-resolution restoration; Image enhancement","Deep learning; Feature matching; GAN; Generative adversarial network; Gotcha; GPT; MISR; SRR; Super-resolution restoration","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85059950995"
