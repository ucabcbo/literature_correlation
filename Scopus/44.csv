"Authors","Author full names","Author(s) ID","Titles","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","DOI","Cited by","Link","Abstract","Indexed Keywords","Author Keywords","Document Type","Publication Stage","Open Access","Source","EID"
"Shen M.; Zhang F.; Wu C.Y.","Shen, M. (57973676600); Zhang, F. (56434720200); Wu, C.Y. (57216969621)","57973676600; 56434720200; 57216969621","FLOOD INUNDATION EXTRACTION BASED ON DECISION-LEVEL DATA FUSION: A CASE IN PERU","2022","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","10","3/W1-2022","","133","140","7","10.5194/isprs-annals-X-3-W1-2022-133-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142365793&doi=10.5194%2fisprs-annals-X-3-W1-2022-133-2022&partnerID=40&md5=04e415a6b0a66eaf7368dec1b48995af","Every year, millions of people affected and huge property losses by floods were recorded in many parts of the world. Accurately flood inundated areas extraction is essential for disaster reduction. Existed studies have used multi-spectral (MS) data and synthetic-aperture radar (SAR) data or the fusion data to extract flood inundated areas. However, most data fusion methods think less about regional difference and the complementarities between different models. This study explores a new decision-level data fusion method, which pays more attention to the complementarities between models. First, we construct models trained by diverse bands of Sentinel- 1/2 and water indices. Then, divide the whole study area into three parts, cloud-free & non-water area, cloud-free & flood area and cloud area, and select the models suitable for the three areas. Third, combine water extents extracted by selected models with decision tree to obtain water extents before and after disaster. Finally, subtract the water extent before disaster from the water extent after disaster to get flood inundated areas. The experiments in Peru indicated that our method increases the Intersection over Union (IoU) of water extraction to 0.69. Moreover, our method successfully reduces the impact of cloud and shadow owing to the fusion of different features.  © Copyright: ","Data fusion; Data mining; Decision trees; Deep learning; Disasters; Flood control; Floods; Synthetic aperture radar; Data fusion methods; Decision levels; Decision-level data fusion; Deep learning; Disaster reduction; Flood inundation extraction; Multi-spectral data; Property loss; Radar data; Regional differences; Extraction","decision-level data fusion; deep learning; Flood; flood inundation extraction","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85142365793"
"Kurekin A.; Loveday B.; Clements O.; Quartly G.; Miller P.; Wiafe G.; Agyekum K.A.","Kurekin, Andrey (55960488500); Loveday, Benjamin (55835319400); Clements, Oliver (56505464200); Quartly, Graham (7003341226); Miller, Peter (7404427354); Wiafe, George (6506274991); Agyekum, Kwame Adu (25926364000)","55960488500; 55835319400; 56505464200; 7003341226; 7404427354; 6506274991; 25926364000","Use of sentinel-1 and sentinel-2 for monitoring illegal fishing off Ghana","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8519539","6875","6878","3","10.1109/IGARSS.2018.8519539","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064266484&doi=10.1109%2fIGARSS.2018.8519539&partnerID=40&md5=d6386d41248821234b17a6b954c5df52","An efficient and inexpensive service has been developed for the monitoring of fishing vessels in West Africa using Earth Observation (EO) data. The service makes use of fast-delivery data from the Synthetic Aperture Radar (SAR) instrument on Sentinel-1 and the Multi Spectral Imager (MSI) on Sentinel-2, detecting objects that differ markedly from their immediate background using a constant false alarm rate (CFAR) test. The selected objects are then discounted from further analysis if they fall within the bespoke land mask or can be shown from time series analysis to be static (signals associated with jetties, oil platforms and ""ghost objects"" arising from very bright land targets). Detections are matched to, and verified by, AIS data, which provides location and dimensions of ships that are legally in the region. Both matched and un-matched data are then displayed on a web portal for use by the Gulf of Guinea (GoG) state authorities. © 2018 IEEE.","Automation; Crime; Fisheries; Geology; Object detection; Portals; Remote sensing; Service vessels; Spectroscopy; Synthetic aperture radar; Time series analysis; Tracking radar; Automatic identification system; Constant false alarm rate; Detecting objects; Earth observation data; Gulf of Guinea; Multi spectral imager; Oil platforms; Vessel detection; Fishing vessels","Automatic identification system; Illegal fishing; Synthetic Aperture Radar; Vessel detection","Conference paper","Final","","Scopus","2-s2.0-85064266484"
"Gupta R.; Sharma L.K.","Gupta, Rajit (57206767551); Sharma, Laxmi Kant (36807307800)","57206767551; 36807307800","Mixed tropical forests canopy height mapping from spaceborne LiDAR GEDI and multisensor imagery using machine learning models","2022","Remote Sensing Applications: Society and Environment","27","","100817","","","","10.1016/j.rsase.2022.100817","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135700380&doi=10.1016%2fj.rsase.2022.100817&partnerID=40&md5=ce67fcf5ffa21380a40ffbd99f650172","Spatial mapping of forests canopy height (Hcanopy) provides an opportunity to assess above-ground biomass, net primary productivity, carbon dioxide (CO2) sequestration, biodiversity conservation and forest fire risks. This study incorporated a continuous coverage of multi-spectral optical and synthetic aperture radar (SAR) along with sparsely global ecosystem dynamics investigation (GEDI) spaceborne Light Detection and Ranging (LiDAR) data in the machine learning (ML) models for mapping Hcanopy in the mixed tropical forests of Shoolpaneshwar wildlife sanctuary (SWLS), Gujarat, India. We trained seven ML models, including quantile random forest (QRF), support vector machine (SVM), Bayesian regularization for feed-forward neural networks (BRNN), conditional inference random forest (Cforest), Extreme gradient boosting (Xgbtree), multivariate adaptive regression splines (MARS), and k-nearest neighbors (KNN) using GEDI_02A extracted Hcanopy as training data. We used predictors which were extracted from LiDAR (GEDI metrics), multispectral optical (Landsat -8, Sentinel-2), and SAR (ALOS-2/PALSAR-2, Sentinel-1). A 10-fold cross-validation (CV) resampling was used to avoid overfitting or underfitting. The comparison of the models performances shows that the BRNN model has the highest satisfactory accuracy metrics, such as root mean square error (RMSE) of 4.686 m, R-squared (R2) of 0.49 and mean absolute error (MAE) of 3.66 m. Low training samples of tall canopies (>25 m), presence of mixed vegetation, geometric and structural variability and sloppy terrain of SWLS possibly restricted models from performing well. Field validation shows an R2 of 0.55, satisfactory for mixed tropical forests using spaceborne LiDAR. The present work provides insights into using spaceborne LiDAR GEDI data with optical and SAR data for Hcanopy mapping through ML models, which help to manage SWLS and further implications of forest Hcanopy mapping over large spatial scales. © 2022 Elsevier B.V.","","Canopy height; GEDI; Machine learning; Optical; SAR; Tropical mixed forests","Article","Final","","Scopus","2-s2.0-85135700380"
"Agrawal S.; Khairnar G.B.","Agrawal, S. (55535780800); Khairnar, G.B. (57215668083)","55535780800; 57215668083","A comparative assessment of remote sensing imaging techniques: Optical, sar and lidar","2019","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","5/W3","","1","6","5","10.5194/isprs-archives-XLII-5-W3-1-2019","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081610630&doi=10.5194%2fisprs-archives-XLII-5-W3-1-2019&partnerID=40&md5=fb27defdebcc0e16b5c775219a49a915","Remote sensing is a popular technique that is using in the mapping and monitoring of earth features. Early remote sensing was predominantly passive, i.e. it depends upon the sun for energy. Till the last decade, optical imaging is mainly used in remote sensing works. Over the time, significant innovations and improvements have been made in the active remote sensing which resulted in the form of sophisticated imaging techniques like Synthetic Aperture RADAR (SAR) and Light Detection And Ranging (LiDAR). These advancements promoted the use of multi-sensor and multi-source data in remote sensing projects. This highlights the need to review these imaging techniques. Therefore, this review work is carried out. In this review, different imaging techniques are discussed and compared. Optical, SAR and LiDAR techniques are first summarized and then they are compared on the basis of technical specification and working. Finally, an in-depth assessment is made on the applicability of these imaging techniques in different fields. © Authors 2019.","Applications; Imaging techniques; Optical radar; Radar imaging; Synthetic aperture radar; Comparative assessment; Depth assessment; Light detection and ranging; Multi-spectral; Multisource data; Optical imaging; Remote sensing imaging; Technical specifications; Remote sensing","Application; Light detection and ranging; Multispectral; Remote sensing; Synthetic aperture radar","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85081610630"
"Paz-Delgado M.V.; Payo A.; Gómez-Pazo A.; Beck A.-L.; Savastano S.","Paz-Delgado, Maria Victoria (57394796400); Payo, Andrés (24802308800); Gómez-Pazo, Alejandro (57204973434); Beck, Anne-Laure (57669451200); Savastano, Salvatore (57668120600)","57394796400; 24802308800; 57204973434; 57669451200; 57668120600","Shoreline Change from Optical and Sar Satellite Imagery at Macro-Tidal Estuarine, Cliffed Open-Coast and Gravel Pock-ET-Beach Environments","2022","Journal of Marine Science and Engineering","10","5","561","","","","10.3390/jmse10050561","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129467785&doi=10.3390%2fjmse10050561&partnerID=40&md5=0a9a07c54503c47d8d25202f7fa86a9e","Coasts are continually changing and remote sensing from satellite has the potential to both map and monitor coastal change at multiple scales. This study aims to assess the application of shorelines extracted from Multi-Spectral Imagery (MSI) and Synthetic Aperture Radar (SAR) from publicly available satellite imagery to map and capture sub-annual to inter-annual shoreline variability. This is assessed at three macro-tidal study sites along the coastline of England, United Kingdom (UK): estuarine, soft cliff environment, and gravel pocket-beach. We have assessed the accuracy of MSI-derived lines against ground truth datum tideline data and found that the satellite derived lines have the tendency to be lower (seaward) on the Digital Elevation Model than the datum-tideline. We have also compared the metric of change derived from SAR lines differentiating between ascending and descending orbits. The spatial and temporal characteristics extracted from SAR lines via Principal Component Analysis suggested that beach rotation is captured within the SAR dataset for descending orbits but not for the ascending ones in our study area. The present study contributes to our understanding of a poorly known aspect of using coastlines derived from publicly available MSI and SAR satellite missions. It outlines a quantitative approach to assess their mapping accuracy with a new non-foreshore method. This allows the assessment of variability on the metrics of change using the Open Digital Shoreline Analysis System (ODSAS) method and to extract complex spatial and temporal information using Principal Component Analysis (PCA) that is transferable to coastline evolution assessments worldwide. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","","coastal change; Earth observation; England; erosion; monitoring; PCA","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85129467785"
"Lapini A.; Fontanelli G.; Pettinato S.; Santi E.; Paloscia S.; Tapete D.; Cigna F.","Lapini, Alessandro (36681330000); Fontanelli, Giacomo (36816017700); Pettinato, Simone (22235499100); Santi, Emanuele (14031975000); Paloscia, Simonetta (7006059266); Tapete, Deodato (55221777800); Cigna, Francesca (36720533600)","36681330000; 36816017700; 22235499100; 14031975000; 7006059266; 55221777800; 36720533600","Application of Deep Learning to Optical and SAR Images for the Classification of Agricultural Areas in Italy","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323190","4163","4166","3","10.1109/IGARSS39084.2020.9323190","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101994936&doi=10.1109%2fIGARSS39084.2020.9323190&partnerID=40&md5=685bdd470ffa343783a12006c906a89c","Modern agriculture is facing new challenges about food production for a growing population in a sustainable manner. Crop mapping at local and regional scale could provide valuable information in support of agricultural policy. This paper describes a field mapping investigation in a populated area in Tuscany (Italy). Satellite images from Sentinel-1 C-band and COSMO-SkyMed X-band SAR and Sentinel-2 optical sensors are input of classifiers based on deep learning and convolutional neural networks. Results pinpointed that the use of optical images allowed the best overall classification accuracy (99.7%), nevertheless X-band SAR imagery, providing an accuracy of 94.6%, could be a good substitute of optical indices in case of lack of cloud-free multispectral data. © 2020 IEEE.","Agricultural robots; Agriculture; Convolutional neural networks; Geology; Geometrical optics; Image classification; Mapping; Radar imaging; Remote sensing; Synthetic aperture radar; Agricultural areas; Agricultural policies; Classification accuracy; Food production; Modern agricultures; Multi-spectral data; Optical indices; Satellite images; Deep learning","Agriculture; convolutional neural networks (CNNs); crop classification; deep learning (DL)","Conference paper","Final","","Scopus","2-s2.0-85101994936"
"Corradino C.; Bilotta G.; Cappello A.; Fortuna L.; Del Negro C.","Corradino, Claudia (57038823100); Bilotta, Giuseppe (25224951800); Cappello, Annalisa (45761022000); Fortuna, Luigi (7006124439); Del Negro, Ciro (7003335619)","57038823100; 25224951800; 45761022000; 7006124439; 7003335619","Combining radar and optical satellite imagery with machine learning to map lava flows at mount etna and fogo island","2021","Energies","14","1","197","","","","10.3390/en14010197","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106260868&doi=10.3390%2fen14010197&partnerID=40&md5=b17abb9b1bffdafeda129f46aacd9988","Lava flow mapping has direct relevance to volcanic hazards once an eruption has begun. Satellite remote sensing techniques are increasingly used to map newly erupted lava, thanks to their capability to survey large areas with frequent revisit time and accurate spatial resolution. Visible and infrared satellite data are routinely used to detect the distributions of volcanic deposits and monitor thermal features, even if clouds are a serious obstacle for optical sensors, since they cannot be penetrated by optical radiation. On the other hand, radar satellite data have been playing an important role in surface change detection and image classification, being able to operate in all weather conditions, although their use is hampered by the special imaging geometry, the complicated scattering process, and the presence of speckle noise. Thus, optical and radar data are complementary data sources that can be used to map lava flows effectively, in addition to alleviating cloud obstruction and improving change detection performance. Here, we propose a machine learning approach based on the Google Earth Engine (GEE) platform to analyze simultaneously the images acquired by the synthetic aperture radar (SAR) sensor, on board of Sentinel-1 mission, and by optical and multispectral sensors of Landsat-8 missions and Multi-Spectral Imager (MSI), on board of Sentinel-2 mission. Machine learning classifiers, including K-means algorithm (K-means) and support vector machine (SVM), are used to map lava flows automatically from a combination of optical and SAR images. We describe the operation of this approach by using a retrospective analysis of two recent lava flow-forming eruptions at Mount Etna (Italy) and Fogo Island (Cape Verde). We found that combining both radar and optical imagery improved the accuracy and reliability of lava flow mapping. The results highlight the need to fully exploit the extraordinary potential of complementary satellite sensors to provide time-critical hazard information during volcanic eruptions. © 2021 by the authors. Li-censee MDPI, Basel, Switzerland.","Hazards; Image enhancement; K-means clustering; Learning systems; Mapping; Remote sensing; Satellite imagery; Space-based radar; Spectroscopy; Support vector machines; Synthetic aperture radar; Turing machines; Volcanoes; Infrared satellites; Machine learning approaches; Multi spectral imager; Multispectral sensors; Optical satellite imagery; Radar satellite data; Retrospective analysis; Satellite remote sensing; Radar imaging","Lava flow mapping; Machine learning classifier; Optical data; Synthetic aperture radar; Volcano remote sensing","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85106260868"
"Foroughnia F.; Alfieri S.M.; Menenti M.; Lindenbergh R.","Foroughnia, Fatemeh (57207776022); Alfieri, Silvia Maria (55800560800); Menenti, Massimo (7006145109); Lindenbergh, Roderik (7801611878)","57207776022; 55800560800; 7006145109; 7801611878","Evaluation of SAR and Optical Data for Flood Delineation Using Supervised and Unsupervised Classification","2022","Remote Sensing","14","15","3718","","","","10.3390/rs14153718","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137075477&doi=10.3390%2frs14153718&partnerID=40&md5=bd9689ae069a5a08c77984609f20dea7","Precise and accurate delineation of flooding areas with synthetic aperture radar (SAR) and multi-spectral (MS) data is challenging because flooded areas are inherently heterogeneous as emergent vegetation (EV) and turbid water (TW) are common. We addressed these challenges by developing and applying a new stepwise sequence of unsupervised and supervised classification methods using both SAR and MS data. The MS and SAR signatures of land and water targets in the study area were evaluated prior to the classification to identify the land and water classes that could be delineated. The delineation based on a simple thresholding method provided a satisfactory estimate of the total flooded area but did not perform well on heterogeneous surface water. To deal with the heterogeneity and fragmentation of water patches, a new unsupervised classification approach based on a combination of thresholding and segmentation (CThS) was developed. Since sandy areas and emergent vegetation could not be classified by the SAR-based unsupervised methods, supervised random forest (RF) classification was applied to a time series of SAR and co-event MS data, both combined and separated. The new stepwise approach was tested for determining the flood extent of two events in Italy. The results showed that all the classification methods applied to MS data outperformed the ones applied to SAR data. Although the supervised RF classification may lead to better accuracies, the CThS (unsupervised) method achieved precision and accuracy comparable to the RF, making it more appropriate for rapid flood mapping due to its ease of implementation. © 2022 by the authors.","Classification (of information); Decision trees; Floods; Supervised learning; Surface waters; Vegetation mapping; Emergent vegetation; Flood mapping; Flooded areas; Multi-spectral data; Optical-; Otsu thresholding; Radar data; Random forests; Supervised classification; Unsupervised classification; Synthetic aperture radar","flood mapping; optical; Otsu thresholding; random forest; SAR; supervised classification; unsupervised classification","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85137075477"
"Martinez K.P.; Burgos D.F.M.; Blanco A.C.; Salmo S.G., Iii","Martinez, K.P. (57209336726); Burgos, D.F.M. (57209340874); Blanco, A.C. (25222367300); Salmo, S.G. (36097541900)","57209336726; 57209340874; 25222367300; 36097541900","Multi-sensor approach to leaf area index estimation using statistical machine learning models: A case on mangrove forests","2021","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","3","","109","115","6","10.5194/isprs-annals-V-3-2021-109-2021","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113154106&doi=10.5194%2fisprs-annals-V-3-2021-109-2021&partnerID=40&md5=607255f3896ad36227445e8967372bc5","Leaf Area Index (LAI) is a quantity that characterizes canopy foliage content. As leaf surfaces are the primary sites of energy, mass exchange, and fundamental production of terrestrial ecosystem, many important processes are directly proportional to LAI. With this, LAI can be considered as an important parameter of plant growth. Multispectral optical images have been widely utilized for mangrove-related studies, such as LAI estimation. In Sentinel-2, for example, LAI can be estimated using a biophysical processor in SNAP or using various machine learning algorithms. However, multispectral optical images have disadvantages due to its weather-dependence and limited canopy penetration. In this study, a multi-sensor approach was implemented by using free multi-spectral optical images (Sentinel-2 ) and synthetic aperture radar (SAR) images (Sentinel-1) to perform Leaf Area Index (LAI) estimation. The use of SAR images can compensate for the abovementioned disadvantages and it then can pave the way for regular mapping and assessment of LAI, despite any weather conditions and cloud cover. In this study, generation of LAI models that explores linear, non-linear and decision trees modelling algorithms to incorporate Sentinel-1 derivatives and Sentinel-2 LAI were executed. The Random Forest model have exhibited the most robust model having the lowest RMSE of 0.2845. This result poses a concrete relationship of a biophysical entity derived from optical parameters to RADAR derivatives to which opens the opportunity of integrating both systems to compensate each disadvantages and produce a more efficient quantification of LAI.  © Author(s) 2021.","Decision trees; Geometrical optics; Machine learning; Plants (botany); Radar imaging; Synthetic aperture radar; Canopy penetration; Leaf Area Index; Optical parameter; Random forest modeling; Robust modeling; Statistical machine learning; Synthetic aperture radar (SAR) images; Terrestrial ecosystems; Learning algorithms","Leaf Area Index; Machine Learning; Random Forest; Sentinel-1 SAR; Sentinel-2","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85113154106"
"Pelich R.; La T.V.; Chini M.; Matgen P.","Pelich, Ramona (56155778100); La, Tran Vu (57999758800); Chini, Marco (35847445700); Matgen, Patrick (8051813300)","56155778100; 57999758800; 35847445700; 8051813300","Retrieval and multi-temporal characterization of oil spills from multi-sensor earth observation imagery","2022","2022 IEEE International Workshop on Metrology for the Sea; Learning to Measure Sea Health Parameters, MetroSea 2022 - Proceedings","","","","388","392","4","10.1109/MetroSea55331.2022.9950927","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143683248&doi=10.1109%2fMetroSea55331.2022.9950927&partnerID=40&md5=b8306890a3d69dbe22d06a9ea7c54c60","In this study we propose an image classification method that allows to delineate oil spills from multi-sensor earth observation (EO) data, i.e. Synthetic Aperture Radar (SAR) and multi-spectral imagery. By making use of the SAR intensity and an index derived from multi-spectral data, we perform a multiscale-based bimodal distribution classification, represented in our case by the oil spill and sea clutter, respectively. The proposed method is applied to a sequence of images acquired with a daily frequency allowing to characterise the temporal and spatial of evolution of the oil spill. In addition, we address the surface wind and currents corresponding to each satellite image in order to investigate their impact on the oil spill evolution. The experimental results are focused on two different oil spill events: one in the waters around Mauritius after a Japanese bulk carrier, MV Wakashio, ran aground on a coral reef, and one in the Persian golf which is the largest offshore oil development area.  © 2022 IEEE.","Geology; Observatories; Offshore oil well production; Oil spills; Radar imaging; Remote sensing; Classification methods; Earth observation data; Earth observations; Images classification; Multi sensor; Multi-spectral; Multi-spectral data; Multi-temporal; Multispectral imagery; Synthetic aperture radar; Synthetic aperture radar","multi-spectral; multi-temporal; oil spill; Synthetic Aperture Radar (SAR)","Conference paper","Final","","Scopus","2-s2.0-85143683248"
"Zhu Y.Y.; He Y.F.; Li H.Y.; Lv Z.P.; Xu G.C.","Zhu, Y.Y. (57740863700); He, Y.F. (57755798600); Li, H.Y. (57250587200); Lv, Z.P. (57741181700); Xu, G.C. (57212081807)","57740863700; 57755798600; 57250587200; 57741181700; 57212081807","LAND SUBSIDENCE MONITORING AND ANALYSIS IN FUZHOU BASED ON INSAR AND MULTISPECTRAL REMOTE SENSING TECHNOLOGY","2022","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","43","B3-2022","","373","379","6","10.5194/isprs-archives-XLIII-B3-2022-373-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131945144&doi=10.5194%2fisprs-archives-XLIII-B3-2022-373-2022&partnerID=40&md5=ad5edadeead30620de2dae199748e10a","Interferometric Synthetic Aperture Radar (InSAR) technology has millimeter level measurement accuracy and has great advantages in urban land subsidence monitoring. Meanwhile, multispectral remote sensing technique can also provide a large amount of urban features changes information for analyzing the causes of land subsidence. In this study, SAR and multispectral images are both used to monitor and analyze land subsidence in Fuzhou of China. 115 scenes Sentinel-1 SAR images from May 2017 to May 2021 are used based on the Persistent Scatterers Interferometric (PSI) method to evaluate the land subsidence in Fuzhou, while Sentinel-2 multispectral images are used to evaluate several remote sensing indexes. During SAR data processing, Generic Atmospheric Correction Online Service for InSAR (GACOS) data is used to remove atmospheric errors for higher accuracy land subsidence. In order to analyze the relationship between the land subsidence and land cover changes in urban areas, the Soil-Adjusted Vegetation Index (SAVI), Normalized Difference Built-up Index (NDBI) and Modified Normalized Difference Water Index (MNDWI) of the main subsidence areas are obtained based on Sentinel-2 multispectral images from 2016 to 2021. In the end, it is found that the land subsidence in some areas exceeded 12 mm/year in Fuzhou. The time series of four areas with severe subsidence were analyzed, and the cumulative subsidence reached about 60 mm. Besides, the spatial distribution and temporal changes of vegetation, buildings and water bodies in these areas were obtained based on the multispectral data, it is found there is very less relationship between the land subsidence and the urban features. It is concluded that that the main causes of the land subsidence are the changes of land internal components such as groundwater and others.  © Authors 2022","Data handling; Groundwater; Image analysis; Interferometry; Radar imaging; Radar measurement; Remote sensing; Subsidence; Time series; Time series analysis; Vegetation; Fuzhou; Interferometric synthetic aperture radars; Land subsidence; Multi-spectral; Multispectral images; Multispectral remote sensing; SAR Images; Subsidence monitoring; Times series; Urban features; Synthetic aperture radar","Fuzhou; InSAR; Land Subsidence; Multispectral; Time series","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85131945144"
"","","","2020 IEEE International Geoscience and Remote Sensing Symposium, IGARSS 2020 - Proceedings","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","","","1757","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102005077&partnerID=40&md5=3d07c744803b5fd8557d27a94dd92d63","The proceedings contain 1634 papers. The topics discussed include: continuing education units (CEUS) for NASA's global learning and observations to benefit the environment (globe) worldwide program; multi-spectral image classification with quantum neural network; demonstration of the federated satellite systems concept for future earth observation satellite missions; monitoring the 2019 agricultural drought in the state of San Luis Potosi, Mexico; studies of internal waves in the Strait of Georgia based on remote sensing images; human body recognition method using diffraction signal in NLOS scenario for millimeter wave radar; do deep learning models generalize to overhead imagery from novel geographic domains? the XGD benchmark problem; physically informed neural networks for the simulation and data-assimilation of geophysical dynamics; cloud detection using Gabor filters and attention-based convolutional neural network for remote sensing images; and a new algorithm for estimating surface roughness using interferometric synthetic aperture radar (INSAR) data.","","","Conference review","Final","","Scopus","2-s2.0-85102005077"
"Wendleder A.; Friedl P.; Mayer C.","Wendleder, Anna (36012163600); Friedl, Peter (57201649903); Mayer, Christoph (7202232610)","36012163600; 57201649903; 7202232610","Impacts of climate and supraglacial lakes on the surface velocity of Baltoro Glacier from 1992 to 2017","2018","Remote Sensing","10","11","1681","","","","10.3390/rs10111681","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057116476&doi=10.3390%2frs10111681&partnerID=40&md5=4b66147f6efe8f4cee17ffbde351ad71","The Baltoro Glacier is one of the largest glaciers in the Karakoram mountain range. Long-term monitoring of glacier dynamics provides key information on glacier evolution in a changing climate, which is essential for regional water resource and natural hazard management. On large glaciers, detailed field based mass balance is not feasible. Ice dynamic variations quantify changes in mass transport and possibly the influence of environmental parameters on the evolution of the glacier. Although velocity variations of Baltoro Glacier during winter and summer are linked to seasonally enhanced basal sliding, little is known about differences in timing and magnitude of (intra-)seasonal velocity variations and their determining mechanisms. We present time series of annual, seasonal, and intra-seasonal glacier surface velocities by means of intensity offset tracking applied on multi-mission Synthetic Aperture Radar (SAR) data for a period of 25 years from 1992 to 2017. Supraglacial lakes forming on the downstream glacier surface in summer were mapped from 1991 to 2017 based on the Normalized Difference Water Index (NDWI), calculated from multi-spectral Landsat and ASTER (Advanced Spaceborne Thermal Emission and Reflection Radiometer) imagery. Additionally, precipitation data of the Tropical Rainfall Measurement Mission (TRMM) and temperature data of ERA-Interim were used to derive the Standardized Precipitation Index (SPI) and Standardized Temperature Index (STI) from 1998 to 2017. Linking surface velocities to the SPI confirmed a strong correlation between heavy precipitation events in winter and the magnitude and the timing of glacier acceleration in summer. Downstream extensions of summer acceleration that have been found since 2015 may be explained by additional water draining from an increased number of supraglacial lakes through crevasses that have been formed in consequence of higher initial velocities, evoked by strong winter precipitation. The warmer melt seasons observed in the years 2015 to 2017 additionally affects the formation of a supraglacial lake, so stronger summer acceleration events in recent years may be indirectly related to global warming. © 2018 by the authors.","Global warming; Information management; Lakes; Rain gages; Space-based radar; Synthetic aperture radar; Velocity; Glacier dynamics; Karakorum; LANDSAT; NDWI; Speckle tracking; Precipitation (meteorology)","Glacier dynamic; Glacier velocity; Intensity and speckle tracking; Karakorum; Landsat data; NDWI; SAR; Supraglacial lake","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85057116476"
"Verma A.; Gupta K.","Verma, Ayushi (57661726200); Gupta, Kunal (56007336300)","57661726200; 56007336300","Classification of Hyperspectral Image for Property Analysis","2019","Proceedings of the 2nd International Conference on Intelligent Computing and Control Systems, ICICCS 2018","","","8663049","1","4","3","10.1109/ICCONS.2018.8663049","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063798053&doi=10.1109%2fICCONS.2018.8663049&partnerID=40&md5=f3c9e410e682dc28d598cac3f4ebcf39","For the detection of the sea ice SAR algorithm has been utilized in order to avoid any damage to ship. This will identify whether there is any obstruction in the way of ice or not so that ship does not strike with ice. The desired results are obtained when SAR algorithm is connected on RADARl imagery data. They also studied the algorithm for the segmentation of ice known as pixel based segmentation which helps to differentiate ice based on its properties. Large number of methods has been utilized for multi temporal segmentation from the MODIS data which is known as TempoSeg strategy for multiyear sea ice. Synthetic Aperture Radar utilized the RADARSATl imagery data in order to detect the ice of sea at different regions of the seas. With the help of Rl imagery data better outcomes are provided by the automated algorithm. In present work, the automated SAR algorithm is required to execute in order to detect sea ice. © 2018 IEEE.","Control systems; Damage detection; Image classification; Intelligent computing; Sea ice; Ships; Spectroscopy; Synthetic aperture radar; Automated algorithms; HyperSpectral; Image properties; Multi-spectral; Multi-temporal; Number of methods; Pixel-based segmentation; Property analysis; Radar imaging","Hyperspectral; Image property; multi-spectral; SAR","Conference paper","Final","","Scopus","2-s2.0-85063798053"
"Paloscia S.; Fontanelli G.; Lapini A.; Santi E.; Pettinato S.; Notarnicola C.; Chiarito E.; Cuozzo G.; Tapete D.; Cigna F.","Paloscia, Simonetta (7006059266); Fontanelli, Giacomo (36816017700); Lapini, Alessandro (36681330000); Santi, Emanuele (14031975000); Pettinato, Simone (22235499100); Notarnicola, Claudia (56213274700); Chiarito, Eugenia (57217203743); Cuozzo, Giovanni (8258624600); Tapete, Deodato (55221777800); Cigna, Francesca (36720533600)","7006059266; 36816017700; 36681330000; 14031975000; 22235499100; 56213274700; 57217203743; 8258624600; 55221777800; 36720533600","SAR multi-frequency observations of vegetation in agricultural and mountain areas","2020","2020 33rd General Assembly and Scientific Symposium of the International Union of Radio Science, URSI GASS 2020","","","9232372","","","","10.23919/URSIGASS49373.2020.9232372","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096844032&doi=10.23919%2fURSIGASS49373.2020.9232372&partnerID=40&md5=1a97cbbc85d23cc1ad00c607cd7df82e","In this paper, the potential of space-borne Synthetic Aperture Radar (SAR) sensors combined with optical ones has been exploited by analyzing datasets collected on two vegetated areas in Italy, by using COSMO-SkyMed X-band and Sentinel-1 C-band SAR, PRISMA hyperspectral and Sentinel-2 multispectral imagery, combined with field measurements acquired with spectroradiometers. On the mountain area in Alto Adige, a biomass estimation approach was developed by combining Sentinel-1 SAR and spectroradiometer hyperspectral data. On Val d'Elsa area in Tuscany, COSMO-SkyMed StripMap HIMAGE and Sentinel-1 Interferometric Wide swath mode SAR data have been integrated with Sentinel-2 imagery for improving the classification of agricultural crops. Convolutional Neural Networks (CNN) have been used for the classification of agricultural areas using these three sensors. © 2020 URSI.","Agricultural robots; Convolutional neural networks; Crops; Image enhancement; Radar imaging; Radiometers; Agricultural areas; Agricultural crops; Biomass estimation; Field measurement; Hyperspectral Data; Multi-spectral imagery; Spectro-radiometers; Wide swath modes; Synthetic aperture radar","","Conference paper","Final","","Scopus","2-s2.0-85096844032"
"Li M.; Zhang L.; Dong J.; Tang M.; Shi X.; Liao M.; Xu Q.","Li, Menghua (57188731273); Zhang, Lu (57202469300); Dong, Jie (57192691342); Tang, Minggao (12754057200); Shi, Xuguo (55577794600); Liao, Mingsheng (7202371636); Xu, Qiang (56506033600)","57188731273; 57202469300; 57192691342; 12754057200; 55577794600; 7202371636; 56506033600","Characterization of pre- and post-failure displacements of the Huangnibazi landslide in Li County with multi-source satellite observations","2019","Engineering Geology","257","","105140","","","","10.1016/j.enggeo.2019.05.017","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065813022&doi=10.1016%2fj.enggeo.2019.05.017&partnerID=40&md5=55cc84c67abd6d30fc3ffdd4d185aa42","The Huangnibazi landslide in Li County of southwest China, began to slide rapidly since 8 August 2017. It received little attention before the failure event. The fast motion of the slope posed great threats to the safety of nearby villages and the national highway G317 at the foot of the mountain. In this study, Synthetic Aperture Radar (SAR)datasets collected by C-band Sentinel-1 and X-band TerraSAR-X (TSX), as well as optical images acquired by Sentinel-2 Multi-Spectral Instrument (MSI)over the landslide site were analyzed to characterize the evolution of the slope before and after the failure event. Firstly, the surface change of the sliding area was qualitatively evaluated using the Sentinel-2 true-color images and pseudo-colored TerraSAR-X amplitude images. Next, the slow movement of the slope before the failure event was detected by interferometry using both TerraSAR-X and Sentinel-1 data stacks. The maximum displacement rate estimated was larger than −45 mm/year along the radar line of sight (LOS)direction. Finally, the large post-failure displacements of the landslide were successfully retrieved with meter-level accuracy from TerraSAR-X observations using adaptive amplitude offset tracking method. The maximum displacement decreased from about 30 m in 11 days in August 2017 to 1–2 m in 22 days in January 2018 in both LOS and azimuth directions. According to the recent measurements of surface displacement, the landslide body is becoming stabilized gradually, which suggests that the risk of catastrophic collapse of the slope has been largely reduced. © 2019 Elsevier B.V.","China; Geometrical optics; Landslides; Satellites; Azimuth direction; Maximum displacement; Offset tracking; Post-failure displacement; Pre-failure displacement; Satellite observations; Surface changes; Surface displacement; displacement; failure analysis; landslide; satellite imagery; Sentinel; slope failure; synthetic aperture radar; time series analysis; tracking; Synthetic aperture radar","Adaptive pixel offset tracking; Huangnibazi landslide; Post-failure displacement; Pre-failure displacement; Time-series InSAR","Article","Final","","Scopus","2-s2.0-85065813022"
"Wang W.; Ma Q.; Huang J.; Feng Q.; Zhao Y.; Guo H.; Chen B.; Li C.; Zhang Y.","Wang, Weitao (57381560200); Ma, Qin (35332370300); Huang, Jianxi (8206714700); Feng, Quanlong (56417016300); Zhao, Yuanyuan (57202720366); Guo, Hao (55331600800); Chen, Boan (57363506300); Li, Chenxi (57344716800); Zhang, Yuxin (57205355915)","57381560200; 35332370300; 8206714700; 56417016300; 57202720366; 55331600800; 57363506300; 57344716800; 57205355915","Remote Sensing Monitoring of Grasslands Based on Adaptive Feature Fusion with Multi-Source Data","2022","Remote Sensing","14","3","750","","","","10.3390/rs14030750","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124225337&doi=10.3390%2frs14030750&partnerID=40&md5=2453bad577bb697d2c75e821d3a550fd","Grasslands, as an important part of terrestrial ecosystems, are facing serious threats of land degradation. Therefore, the remote monitoring of grasslands is an important tool to control degradation and protect grasslands. However, the existing methods are often disturbed by clouds and fog, which makes it difficult to achieve all-weather and all-time grassland remote sensing mon-itoring. Synthetic aperture radar (SAR) data can penetrate clouds, which is helpful for solving this problem. In this study, we verified the advantages of the fusion of multi-spectral (MS) and SAR data for improving classification accuracy, especially for cloud-covered areas. We also proposed an adaptive feature fusion method (the SK-like method) based on an attention mechanism, and tested two types of patch construction strategies, single-size and multi-size patches. Experiments have shown that the proposed SK-like method with single-size patches obtains the best results, with 93.12% accuracy and a 0.91 average f1-score, which is a 1.02% accuracy improvement and a 0.01 average f1-score improvement compared with the commonly used feature concatenation method. Our results show that the all-weather, all-time remote sensing monitoring of grassland is possible through the fusion of MS and SAR data with suitable feature fusion methods, which will effectively enhance the regulatory capability of grassland resources. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Convolution; Convolutional neural networks; Deep neural networks; Remote sensing; Adaptive feature fusion; Adaptive features; Convolutional neural network; Deep learning; Features fusions; Grassland remote sensing monitoring; Multi-spectral; Multi-spectral and synthetic aperture radar data; Radar data; Remote sensing monitoring; Synthetic aperture radar","Adaptive feature fusion; Convolutional neural network; Deep learning; Grassland remote sensing monitoring; Multi-spectral and synthetic aperture radar data","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85124225337"
"Ashiotis G.; Oldfield J.; Chrysostomou C.; Christoudias T.; Nicolaou M.A.","Ashiotis, Giannis (56582313900); Oldfield, James (57211991046); Chrysostomou, Charalambos (26023118300); Christoudias, Theodoros (35232773600); Nicolaou, Mihalis A. (36622278100)","56582313900; 57211991046; 26023118300; 35232773600; 36622278100","Shared-Space Autoencoders with Randomized Skip Connections for Building Footprint Detection with Missing Views","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12667 LNCS","","","536","549","13","10.1007/978-3-030-68787-8_39","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104388153&doi=10.1007%2f978-3-030-68787-8_39&partnerID=40&md5=a87a73728567ded7468610181449b77e","Recently, a vast amount of satellite data has become available, going beyond standard optical (EO) data to other forms such as synthetic aperture radars (SAR). While more robust, SAR data are often more difficult to interpret, can be of lower resolution, and require intense pre-processing compared to EO data. On the other hand, while more interpretable, EO data often fail under unfavourable lighting, weather, or cloud-cover conditions. To leverage the advantages of both domains, we present a novel autoencoder-based architecture that is able to both (i) fuse multi-spectral optical and radar data in a common shared-space, and (ii) perform image segmentation for building footprint detection under the assumption that one of the data modalities is missing–resembling a situation often encountered under real-world settings. To do so, a novel randomized skip-connection architecture that utilizes autoencoder weight-sharing is designed. We compare the proposed method to baseline approaches relying on network fine-tuning, and established architectures such as UNet. Qualitative and quantitative results show the merits of the proposed method, that outperforms all compared techniques for the task-at-hand. © 2021, Springer Nature Switzerland AG.","Electrooptical devices; Image segmentation; Learning systems; Network architecture; Pattern recognition; Synthetic aperture radar; Synthetic apertures; Building footprint; Lower resolution; Multi-spectral; Pre-processing; Quantitative result; Real world setting; Satellite data; Shared spaces; Space-based radar","Footprint detection; Missing views; Shared-space","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85104388153"
"Mngadi M.; Odindi J.; Peerbhay K.; Mutanga O.","Mngadi, Mthembeni (57189305085); Odindi, John (36521256000); Peerbhay, Kabir (55617877700); Mutanga, Onisimo (55912148400)","57189305085; 36521256000; 55617877700; 55912148400","Examining the effectiveness of Sentinel-1 and 2 imagery for commercial forest species mapping","2021","Geocarto International","36","1","","1","12","11","10.1080/10106049.2019.1585483","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067581795&doi=10.1080%2f10106049.2019.1585483&partnerID=40&md5=54c83dc8500ed3185266c332440679ab","The successful launch and operation of the Sentinel satellite platform has provided access to freely available remotely sensed data useful for commercial forest species discrimination. Sentinel–1 (S1) with a synthetic aperture radar (SAR) sensor and Sentinel–2 (S2) multi-spectral sensor with additional and strategically positioned bands offer great potential for providing reliable information for discriminating and mapping commercial forest species. In this study, we sought to determine the value of S1 and S2 data characteristics in discriminating and mapping commercial forest species. Using linear discriminant analysis (LDA) algorithm, S2 multi-spectral imagery showed an overall classification accuracy of 84% (kappa = 0.81), with bands such as the red-edge (703.9–740.2 nm), narrow near infrared (835.1–864.8 nm), and short wave infrared (1613.7–2202.4 nm) particularly influential in discriminating individual forest species stands. When Sentinel 2’s spectral wavebands were fused with Sentinel 1’s (SAR) VV and VH polarimetric modes, overall classification accuracies improved to 87% (kappa = 0.83) and 88% (kappa = 0.85), respectively. These findings demonstrate the value of combining Sentinel’s multispectral and SAR structural information characteristics in improving commercial forest species discrimination. These, in addition to the sensors free availability, higher spatial resolution and larger swath width, offer unprecedented opportunities for improved local and large scale commercial forest species discrimination and mapping. © 2019 Informa UK Limited, trading as Taylor & Francis Group.","algorithm; commercial species; discriminant analysis; forest; mapping; remote sensing; satellite imagery; Sentinel; synthetic aperture radar","forest species discrimination; linear discriminant analysis; Sentinel-2; Synthetic aperture radar","Article","Final","","Scopus","2-s2.0-85067581795"
"Schmitt M.; Hughes L.H.; Qiu C.; Zhu X.X.","Schmitt, M. (7401931279); Hughes, L.H. (57201113391); Qiu, C. (57194601941); Zhu, X.X. (55696622200)","7401931279; 57201113391; 57194601941; 55696622200","SEN12MS &ndash; A CURATED DATASET of GEOREFERENCED MULTI-SPECTRAL SENTINEL-1/2 IMAGERY for DEEP LEARNING and DATA FUSION","2019","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","4","2/W7","","153","160","7","10.5194/isprs-annals-IV-2-W7-153-2019","84","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084684118&doi=10.5194%2fisprs-annals-IV-2-W7-153-2019&partnerID=40&md5=a594132c1ed18fcccd585a917a8d3bba","The availability of curated large-scale training data is a crucial factor for the development of well-generalizing deep learning methods for the extraction of geoinformation from multi-sensor remote sensing imagery. While quite some datasets have already been published by the community, most of them suffer from rather strong limitations, e.g. regarding spatial coverage, diversity or simply number of available samples. Exploiting the freely available data acquired by the Sentinel satellites of the Copernicus program implemented by the European Space Agency, as well as the cloud computing facilities of Google Earth Engine, we provide a dataset consisting of 180,662 triplets of dual-pol synthetic aperture radar (SAR) image patches, multi-spectral Sentinel-2 image patches, and MODIS land cover maps. With all patches being fully georeferenced at a 10 m ground sampling distance and covering all inhabited continents during all meteorological seasons, we expect the dataset to support the community in developing sophisticated deep learning-based approaches for common tasks such as scene classification or semantic segmentation for land cover mapping. © 2019 ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences. All rights reserved.","Classification (of information); Data fusion; Earth (planet); Learning systems; Remote sensing; Semantics; Space optics; Space-based radar; Synthetic aperture radar; European Space Agency; Ground sampling distances; Land cover mapping; Learning-based approach; Remote sensing imagery; Scene classification; Semantic segmentation; Synthetic aperture radar (SAR) images; Deep learning","Data Fusion; Dataset; Deep Learning; Machine Learning; Multi-Spectral Imagery; Optical Remote Sensing; Remote Sensing; Sentinel-1; Sentinel-2; Synthetic Aperture Radar (SAR)","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85084684118"
"Ayhan B.; Kwan C.","Ayhan, Bulent (14037070200); Kwan, Chiman (7201421216)","14037070200; 7201421216","New Results in Change Detection Using Optical and Multispectral Images","2019","2019 IEEE 10th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2019","","","8992937","0316","0321","5","10.1109/UEMCON47517.2019.8992937","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074212916&doi=10.1109%2fUEMCON47517.2019.8992937&partnerID=40&md5=59ce821534c2fa1076d96639c936cf38","Optical and multispectral images have been widely used in change detection applications. Although there are many existing algorithms in the literature, it is still difficult to perform accurate change detection due to illumination and other changes between the pre-event and post-event images. In this paper, we present a new change detection algorithm that has great potential in detecting changes in optical, multispectral, and even SAR images. Here, we focus on change detection using optical and multispectral images. Comparison with existing algorithms show that the proposed approach is promising. © 2019 IEEE.","Geometrical optics; Image registration; Synthetic aperture radar; Ubiquitous computing; Change detection; Change detection algorithms; Multi-spectral; Multispectral images; New results; Optical image; SAR Images; Satellite images; Mobile telecommunication systems","Change detection; image registration; multispectral; optical images; satellite images","Conference paper","Final","","Scopus","2-s2.0-85074212916"
"Mityagina M.; Lavrova O.","Mityagina, Marina (6603023317); Lavrova, Olga (7004606595)","6603023317; 7004606595","Satellite Survey of Offshore Oil Seep Sites in the Caspian Sea","2022","Remote Sensing","14","3","525","","","","10.3390/rs14030525","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123616563&doi=10.3390%2frs14030525&partnerID=40&md5=e0bad0e3a24a53685b5203dbed50cb8f","This paper presents the results of a long-term survey of the Caspian Sea using satellite SAR and multispectral sensors. The primary environmental problem of the Caspian Sea is oil pollution which is determined by its natural properties, mainly by the presence of big oil and gas deposits beneath the seabed. Our research focuses on natural oil slicks (NOS), i.e., oil showings on the sea surface due to natural hydrocarbon emission from seabed seeps. The spatial and temporal variability of NOS in the Caspian Sea and the possibilities of their reliable detection using satellite data are examined. NOS frequency and detectability in satellite images depending on sensor type, season and geographical region are assessed. It is shown that both parameters vary significantly, and largely depend on sensor type and season, with season being most pronounced in visible (VIS) data. The locations of two offshore seep sites at the Iranian and Turkmenian shelves are accurately estimated. Statistics on individual sizes of NOS are drawn. The release rates of crude oil from the seabed to the sea surface are compared. Detailed maps of NOS are put together, and areas exposed to high risk of sea surface oil pollution are determined. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Hydrocarbons; Marine pollution; Offshore oil well production; Radar imaging; Remote sensing; Satellite imagery; Surveys; Synthetic aperture radar; Tracking radar; Hydrocarbon seeps; Multi-spectral data; Natural hydrocarbon seep; Natural hydrocarbons; Natural oil; Natural oil slick; Oil pollution; Oils slick; Satellite monitoring; Satellite remote sensing; Sea surfaces; Surface films; The caspian sea; Surface waters","Multispectral data; Natural hydrocarbon seeps; Natural oil slicks; Oil pollution; Radar imagery; Satellite monitoring; Satellite remote sensing; Sea surface; Surface films; The Caspian Sea","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85123616563"
"Chen Y.","Chen, Yucai (57214821938)","57214821938","Multi-sensor remote sensing image coastline extraction method based on fuzzy clustering","2019","Journal of Geomatics","44","5","","16","19","3","10.14188/j.2095-6045.2019114","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079214439&doi=10.14188%2fj.2095-6045.2019114&partnerID=40&md5=7b76feffeb8ca6154da7237dec802113","In this paper, the coastline of shantou, guang-dong, which is 217 km long, was selected for research, and images of Landsat 8 and Sentinel-1A were used for coastline extraction. The main purpose is to improve the quality of land/water segmentation results by combining the advantages of Landsat 8 and Sentinel-1A SAR images. Firstly, Landsat 8 images were used to obtain the initial land/water segmentation results through the edge extraction method based on the LoG operator. This result was used as the training data set to define the fuzzy parameters of coastline extraction using Landsat 8 images. Then, Sentinel-1A images were used to conduct fuzzy clustering extraction of coastline using the obtained fuzzy parameters. Finally, the experimental results were compared with the artificial coastline drawing, and the accuracy was evaluated by calculating the vertical distance between the reference coastline and the coastline extracted by this method. © 2019 Wuhan University. All rights reserved.","coastal zone; fuzzy mathematics; Landsat; remote sensing; satellite data; satellite imagery; Sentinel; synthetic aperture radar","Coastline; Fuzzy clustering; Landsat 8; Multi-spectral image; Sar","Article","Final","","Scopus","2-s2.0-85079214439"
"Krzepek K.; Schmidt J.; Iwaszczuk D.","Krzepek, Katrin (57885927500); Schmidt, Jakob (57885700600); Iwaszczuk, Dorota (38662679700)","57885927500; 57885700600; 38662679700","Fusion of SAR and Multi-spectral Time Series for Determination of Water Table Depth and Lake Area in Peatlands","2022","PFG - Journal of Photogrammetry, Remote Sensing and Geoinformation Science","90","6","","561","575","14","10.1007/s41064-022-00216-w","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137774021&doi=10.1007%2fs41064-022-00216-w&partnerID=40&md5=a5160fe7c1e83d1bc6900b9d8608ddad","Peatlands as natural carbon sinks have a major impact on the climate balance and should therefore be monitored and protected. The hydrology of the peatland serves as an indicator of the carbon storage capacity. Hence, we investigate the question how suitable different remote sensing data are for monitoring the size of open water surface and the water table depth (WTD) of a peatland ecosystem. Furthermore, we examine the potential of combining remote sensing data for this purpose. We use C-band synthetic aperture radar (SAR) data from Sentinel-1 and multi-spectral data from Sentinel-2. The radar backscatter σ, the normalized difference water index (NDWI) and the modified normalized difference water index (MNDWI) are calculated and used for consideration of the WTD and the lake size. For the measurement of the lake size, we implement and investigate the methods: random forest, adaptive thresholding and an analysis according to the Dempster–Shafer theory. Correlations between WTD and the remote sensing data σ as well as NDWI are investigated. When looking at the individual data sets the results of our case study show that the VH polarized σ data produces the clearest delineation of the peatland lake. However the adaptive thresholding of the weighted fusion image of σ-VH, σ-VV and MNDWI, and the random forest algorithm with all three data sets as input proves to be the most suitable for determining the lake area. The correlation coefficients between σ/NDWI and WTD vary greatly and lie in ranges of low to moderate correlation. © 2022, The Author(s).","lake water; peatland; remote sensing; Sentinel; synthetic aperture radar; time series analysis; water depth; water table","Fusion; NDWI; Peatland; SAR; Water area; Water table depth","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85137774021"
"Cherif E.; Hell M.; Brandmeier M.","Cherif, Eya (57931056300); Hell, Maximilian (57561515600); Brandmeier, Melanie (36639182600)","57931056300; 57561515600; 36639182600","DeepForest: Novel Deep Learning Models for Land Use and Land Cover Classification Using Multi-Temporal and -Modal Sentinel Data of the Amazon Basin","2022","Remote Sensing","14","19","5000","","","","10.3390/rs14195000","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140030738&doi=10.3390%2frs14195000&partnerID=40&md5=6c08d4aa866e5729415f9d0b9d765498","Land use and land cover (LULC) mapping is a powerful tool for monitoring large areas. For the Amazon rainforest, automated mapping is of critical importance, as land cover is changing rapidly due to forest degradation and deforestation. Several research groups have addressed this challenge by conducting local surveys and producing maps using freely available remote sensing data. However, automating the process of large-scale land cover mapping remains one of the biggest challenges in the remote sensing community. One issue when using supervised learning is the scarcity of labeled training data. One way to address this problem is to make use of already available maps produced with (semi-) automated classifiers. This is also known as weakly supervised learning. The present study aims to develop novel methods for automated LULC classification in the cloud-prone Amazon basin (Brazil) based on the labels from the MapBiomas project, which include twelve classes. We investigate different fusion techniques for multi-spectral Sentinel-2 data and synthetic aperture radar Sentinel-1 time-series from 2018. The newly designed deep learning architectures—DeepForest-1 and DeepForest-2—utilize spatiotemporal characteristics, as well as multi-scale representations of the data. In several data scenarios, the models are compared to state-of-the-art (SotA) models, such as U-Net and DeepLab. The proposed networks reach an overall accuracy of up to 75.0%, similar to the SotA models. However, the novel approaches outperform the SotA models with respect to underrepresented classes. Forest, savanna and crop were mapped best, with F1 scores up to 85.0% when combining multi-modal data, compared to 81.6% reached by DeepLab. Furthermore, in a qualitative analysis, we highlight that the classifiers sometimes outperform the inaccurate labels. © 2022 by the authors.","Automation; Data fusion; Deep learning; Deforestation; Land use; Mapping; Modal analysis; Remote sensing; Space-based radar; Supervised learning; Tropics; Amazon rain forest; Deep learning; Land-use and land-cover classifications; Multi-modal; Multi-modal and multi-temporal data; Multi-temporal data; Sentinel-1; Sentinel-2; Tropic; Weak supervision; Synthetic aperture radar","Amazon rainforest; data fusion; deep learning; land use and land cover classification; multi-modal and multi-temporal data; Sentinel-1; Sentinel-2; tropics; weak supervision","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85140030738"
"Zhang M.; Chen F.; Liang D.; Tian B.; Yang A.","Zhang, Meimei (56746586200); Chen, Fang (57441279900); Liang, Dong (57212943980); Tian, Bangsen (34882193500); Yang, Aqiang (57212121230)","56746586200; 57441279900; 57212943980; 34882193500; 57212121230","Use of sentinel-1 grd sar images to delineate flood extent in Pakistan","2020","Sustainability (Switzerland)","12","14","5784","1","19","18","10.3390/su12145784","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095588497&doi=10.3390%2fsu12145784&partnerID=40&md5=c7abafa3e0fae6d3df9c3409a73dbdd3","Floods are some of the most serious and devastating natural hazards on earth, bringing huge threats to lives, properties, and living environments. Rapid delineation of the spatial extent of flooding is of great importance for the dynamic monitoring of flood evolution and corresponding emergency strategies. Some of the current flood mapping methods mainly process single date images characterized by simple flood situations and homogenous backgrounds. Although other methods show good performance for images with harsh conditions for floods, they must be trained—many times based on pre-classified samples—or undergo complicated parameter tuning processes, which require computation efforts. The widely used change detection methods utilize multi-temporal Synthetic Aperture Radar (SAR) images for the detection of flood area, but the results are largely influenced by the quality of defined reference images. Furthermore, these methods were mostly applied for some river basin floods, which are not effective for the large scale, semi-arid regions with complex flood conditions, and various land cover types. All of these extremely limited the use of these methods for the timely and accurate extraction of the spatial distribution pattern of floods in other typical and broad areas. Based on the above considerations, this paper presents a new method for rapidly determining the extent of flooding in large, semi-arid areas with challenging environmental conditions, based on multi-temporal Sentinel-1 Synthetic Aperture Radar (SAR) data. First, a preprocessing scheme is applied to perform geometric correction and to estimate the intensity of the imagery. Second, an automatic thresholding procedure is used to generate an initial land and water classification through the integration of the probability density distribution. A fuzzy logic-based approach, combining SAR backscattering information and other auxiliary data, is then used to refine the initial classified image. The fuzzy logic-based refinement removes areas that look similar to water in the SAR images, significantly enhancing the flood mapping accuracy. Finally, a post-processing step consisting of morphological operations and extraction improves the homogeneity of the extracted flood segments, discards isolated pixels, and gives the final flood map. This method can automatically detect the extent of floods at little computational cost. As Sentinel-1 data are publicly available and have a fast repeat cycle, the procedure can provide near real time results for rapid emergency response following flash floods. The accuracy of the proposed method is assessed at three test sites in Pakistan, which covered diverse landscapes and suffered large scale serious flooding after a long and severe drought in 2015. In comparison with the more recent studies from Ohki et al., 2020, and Shahabi et al., 2020, our results indicate the best spatial agreement with GF-2 panchromatic multi-spectral (PMS) water classification, with an encouraging overall accuracy ranging from 91.1% to 96.6%, and Kappa coefficients ranging from 0.893 to 0.954. Especially for the areas with fragmented floods, heterogeneous backgrounds, and the areas where samples are highly unbalanced in the SAR images, our method combines the global statistics and local relationships of backscattering properties, terrain, and other auxiliary information, enabling to effectively preserve the detailed structures and also remove the noise. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Pakistan; automation; backscatter; correspondence analysis; data processing; detection method; flood; image classification; natural hazard; performance assessment; river basin; satellite imagery; Sentinel; spatial distribution; strategic approach; synthetic aperture radar","Floods; Fuzzy logic; Pakistan; Probability density function; Sentinel-1","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85095588497"
"Huang B.; Li Z.; Yang C.; Sun F.; Song Y.","Huang, Binghui (57216946822); Li, Zhi (57208551292); Yang, Chao (57195032153); Sun, Fuchun (57204699218); Song, Yixu (15124457200)","57216946822; 57208551292; 57195032153; 57204699218; 15124457200","Single satellite optical imagery dehazing using SAR image prior based on conditional generative adversarial networks","2020","Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020","","","9093471","1795","1802","7","10.1109/WACV45572.2020.9093471","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085521974&doi=10.1109%2fWACV45572.2020.9093471&partnerID=40&md5=4ebab6919c32b079b180d91c1193b85f","Satellite image dehazing aims at precisely retrieving the real situations of the obscured parts from the hazy remote sensing (RS) images, which is a challenging task since the hazy regions contain both ground features and haze components. Many approaches of removing haze focus on processing multi-spectral or RGB images, whereas few of them utilize multi-sensor data. The multi-sensor data fusion is significant to provide auxiliary information since RGB images are sensitive to atmospheric conditions. In this paper, a dataset called SateHaze1k is established and composed of 1200 pairs clear Synthetic Aperture Radar (SAR), hazy RGB, and corresponding ground truth images, which are divided into three degrees of the haze, i.e. thin, moderate, and thick fog. Moreover, we propose a novel fusion dehazing method to directly restore the haze-free RS images by using an end-to-end conditional generative adversarial network(cGAN). The proposed network combines the information of both RGB and SAR images to eliminate the image blurring. Besides, the dilated residual blocks of the generator can also sufficiently improve the dehazing effects. Our experiments demonstrate that the proposed method, which fuses the information of different sensors applied to the cloudy conditions, can achieve more precise results than other baseline models. © 2020 IEEE.","Computer vision; Demulsification; Image fusion; Remote sensing; Satellite imagery; Sensor data fusion; Space-based radar; Synthetic aperture radar; Adversarial networks; Atmospheric conditions; Auxiliary information; Cloudy conditions; Multi-sensor data; Multisensor data fusion; Remote sensing images; Satellite optical imagery; Radar imaging","","Conference paper","Final","","Scopus","2-s2.0-85085521974"
"Numbisi F.N.; Van Coillie F.; De Wulf R.","Numbisi, F.N. (57204567584); Van Coillie, F. (7801421591); De Wulf, R. (6603347989)","57204567584; 7801421591; 6603347989","Multi-date sentinel1 SAR image textures discriminate perennial agroforests in a tropical forest-savannah transition landscape","2018","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","1","","339","346","7","10.5194/isprs-archives-XLII-1-339-2018","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056187206&doi=10.5194%2fisprs-archives-XLII-1-339-2018&partnerID=40&md5=c34cd222cf3d053c74f69a656ed08d19","Synthetic Aperture Radar (SAR) provides consistent information on target land features; especially in tropical conditions that restrain penetration of optical imaging sensors. Because radar response signal is influenced by geometric and di-electrical properties of surface features', the different land cover may appear similar in radar images. For discriminating perennial cocoa agroforestry land cover, we compare a multi-spectral optical image from RapidEye, acquired in the dry season, and multi-seasonal C-band SAR of Sentinel 1: A final set of 10 (out of 50) images that represent six dry and four wet seasons from 2015 to 2017. We ran eight RF models for different input band combinations; multi-spectral reflectance, vegetation indices, co-(VV) and cross-(VH) polarised SAR intensity and Grey Level Co-occurrence Matrix (GLCM) texture measures. Following a pixel-based image analysis, we evaluated accuracy metrics and uncertainty Shannon entropy. The model comprising co- and cross-polarised texture bands had the highest accuracy of 88.07% (95% CI: 85.52 - 90.31) and kappa of 85.37; and the low class uncertainty for perennial agroforests and transition forests. The optical image had low classification uncertainty for the entire image; but, it performed better in discriminating non-vegetated areas. The measured uncertainty provides reliable validation for comparing class discrimination from different image resolution. The GLCM texture measures that are crucial in delineating vegetation cover differed for the season and polarization of SAR image. Given the high accuracies of mapping, our approach has value for landscape monitoring; and, an improved valuation of agroforestry contribution to REDD+ strategies in the Congo basin sub-region. © Authors 2018. CC BY 4.0 License.","Decision trees; Forestry; Geometrical optics; Image resolution; Image texture; Mapping; Synthetic aperture radar; Tropics; Uncertainty analysis; Vegetation; Agroforestry; Congo basins; Random forest algorithm; REDD+ Strategy; Sentinel-1; Radar imaging","Congo Basin Rainforest; GLCM textures; Perennial Agroforestry Mapping; Random Forest Algorithm; REDD+ Strategy; Sentinel1 SAR","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85056187206"
"Mukherjee S.; Hazra S.","Mukherjee, Samadrita (57198769167); Hazra, Sugata (57197882363)","57198769167; 57197882363","Assessment of agricultural drought using multi-temporal synthetic aperture radar (SAR) and multispectral data – A case study on part of Odisha State, India","2022","Advances in Space Research","70","12","","3859","3869","10","10.1016/j.asr.2022.04.064","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132853708&doi=10.1016%2fj.asr.2022.04.064&partnerID=40&md5=1f0d17cd3901de24f554ac9bc613e41a","Drought is primarily considered as a natural hazard which is a resultant phenomenon of less rainfall. When an agricultural area constantly received low rainfall during the sowing and growing season of crop, the soil moisture of the cropland goes down and the crop began to wilt, the situation is known as agricultural drought. Present study, used the multi-temporal Sentinel 1 SAR and Landsat optical data to assess the agricultural drought in the part of Odisha state. Initially, to establish the methodology, correlation between NDVI and SAR backscattering has been carried out for the demarcated agricultural landscape of MODIS images derived landcover map of 2019. The drought assessment has been carried out for the month of Jun-July of 2020 and 2021 which is the kharif crop growing season. Thereafter, the backscattering vale range has been identified as a threshold value to delineate the agricultural drought affected areas from other SAR images of various vintages. The study area was more affected by the drought in 2020 compared to 2021. In this study, it is observed that although the area is drought affected, received less rainfall, but due to location in coastal region this area is mostly under cloud cover, therefore, it is very difficult assess the agricultural drought using optical remote sensing data. SAR data is also sensitive to soil moisture condition; therefore, it can be potentially to be used for drought assessment for the coastal agricultural area. © 2022 COSPAR","Backscattering; Crops; Cultivation; Optical remote sensing; Radar imaging; Rain; Soil moisture; Space-based radar; Synthetic aperture radar; Agricultural areas; Agricultural drought; Case-studies; Growing season; Multi-spectral data; Multi-temporal; Natural hazard; NDVI; Radar data; Remote-sensing; Drought","Agricultural drought; NDVI; Remote Sensing; SAR","Article","Final","","Scopus","2-s2.0-85132853708"
"Kurekin A.A.; Miller P.I.; Avillanosa A.L.; Sumeldan J.D.C.","Kurekin, Andrey A. (55960488500); Miller, Peter I. (7404427354); Avillanosa, Arlene L. (55932184200); Sumeldan, Joel D. C. (57224526746)","55960488500; 7404427354; 55932184200; 57224526746","Monitoring of Coastal Aquaculture Sites in the Philippines through Automated Time Series Analysis of Sentinel-1 SAR Images","2022","Remote Sensing","14","12","2862","","","","10.3390/rs14122862","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132765823&doi=10.3390%2frs14122862&partnerID=40&md5=7122ccaea446f9cb7cd41d58b85cbe3a","With the unprecedented expansion of aquaculture around the world, there is a critical need to monitor its progress. In Palawan, Philippines, coastal aquaculture is gaining momentum towards increasing fish production, a pressure that presents a challenge to the sustainability of these areas. In this paper, we explore the application of Earth observation methods to map coastal aquaculture development in Palawan and evaluate the extent of its change. The European Space Agency Sentinel-1 synthetic aperture radar and Sentinel-2 multispectral instrument sensor data were applied in fully automatic mode to build maps of Palawan coastal aquaculture. The maps were validated using Google Earth high-resolution optical images and in situ observations in Malampaya Sound, and demonstrated a successful detection rate of 72%, while the false alarm rate was less than 7.5%. Objects only 5 m across, four times smaller than the spatial resolution of the Sentinel-1 sensors, were successfully detected using the developed methodology, thus exceeding the capabilities of other published methods that are limited to detecting large groups of aquaculture structures. The maps revealed aquaculture structures in high quantities in Malampaya Sound, Taytay Bay, and other locations in the coastal waters of Palawan, Philippines. A significant change of aquaculture spatial distribution was identified by comparing aquaculture maps generated with an interval of three years. This new automated methodology was validated as robust for mapping aquaculture objects in Palawan, Philippines, and can be applied to aquaculture studies in other regions worldwide. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Aquaculture; Fish; Geometrical optics; Mapping; Object detection; Observatories; Offshore oil well production; Radar imaging; Space-based radar; Time series analysis; Aquaculture mapping; Aquaculture structure; Box filters; Coastal aquaculture; Earth observations; Fish cages; Land mask; Multi-spectral; Objects detection; Offshore aquaculture; Palawan; Static objects; Synthetic aperture radar","aquaculture mapping; aquaculture structure; box filter; coastal aquaculture; Earth observation; fish cage; land mask; multispectral; object detection; offshore aquaculture; Palawan; static objects; synthetic aperture radar","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85132765823"
"Sivasankar T.; Ghosh S.; Joshi M.","Sivasankar, Thota (57202915146); Ghosh, Swakangkha (57221271924); Joshi, Mayank (57204554559)","57202915146; 57221271924; 57204554559","Exploitation of optical and SAR amplitude imagery for landslide identification: a case study from Sikkim, Northeast India","2021","Environmental Monitoring and Assessment","193","7","386","","","","10.1007/s10661-021-09119-6","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107288938&doi=10.1007%2fs10661-021-09119-6&partnerID=40&md5=6fd53acb1d4a677d9cf83246bca77919","Detection and mapping of landslides is one of the most important techniques used for reducing the impact of natural disasters especially in the Himalaya, owing to its high amount of tectonic deformation, seismicity, and unfavorable climatic conditions. Moreover, the northeastern part of the Himalaya, severely affected by landslides every monsoon, is poorly studied. The information on the inventories is inhomogeneous and lacking. In this context, satellite-based earth observation data, which has significantly advanced in the last decade and often serves as a potential source for data collection, monitoring, and damage assessment for disasters in a short time span, has been implemented. Keeping in mind the above framework, this study aims to exploit the potentials of Sentinel-1 synthetic aperture radar (SAR) and Sentinel-2 optical imagery for identifying new landslides in vegetated and hilly areas of the northeastern part of India. In order to assess the potentials of our data and methodology, a landslide event which occurred on 13 August 2016 13:30 h (IST) in North Sikkim, India, triggered due to rainfall has been explored in detail. The landslide also resulted in the formation of a lake, 2.2 km in length and 290 m in width. Difficulty in procurement of cloud-free datasets immediately after the event led us to the use of Sentinel-1 SAR backscatter data, to assess its potential for this purpose. It is observed that the potential of SAR amplitude imagery is limited to different aspects as per the sensor look direction during the mode of acquisition. Furthermore, the present study also incorporates a change detection algorithm to evaluate the performance of the Sudden Landslide Identification Product (SLIP) model to identify new landslides using Sentinel-2 multispectral imagery. Overall, the results exhibit that integrated usage of both optical and SAR amplitude imagery may provide a plethora of information for identification and mapping of new landslides for damage assessment and early warning. All the above results combined together suggest this method for rapid identification of landslides in the Himalayan terrain with special emphasis on the northeastern part of the Himalaya. The automation of this method for future operational usage is also suggested. © 2021, The Author(s), under exclusive licence to Springer Nature Switzerland AG.","Environmental Monitoring; India; Landslides; Radar; Sikkim; Himalayas; India; Sikkim; Damage detection; Disasters; Landslides; Mapping; Synthetic aperture radar; rain; Change detection algorithms; Climatic conditions; Damage assessments; Landslide identification; Multi-spectral imagery; Rapid identification; Satellite based Earth observation; Tectonic deformations; algorithm; geological mapping; landslide; multispectral image; radar imagery; rainfall; Sentinel; synthetic aperture radar; trigger mechanism; Article; automation; detection algorithm; environmental exploitation; environmental monitoring; fluorescence imaging; information processing; landslide; multispectral imaging; natural disaster; satellite imagery; Sikkim; synthetic aperture radar; vegetation; India; telecommunication; Radar imaging","Himalaya; Landslide; Look direction; Sudden Landslide Identification Product; Synthetic aperture radar","Article","Final","","Scopus","2-s2.0-85107288938"
"Quan Y.; Tong Y.; Feng W.; Dauphin G.; Huang W.; Xing M.","Quan, Yinghui (35181982300); Tong, Yingping (57220011021); Feng, Wei (57089587500); Dauphin, Gabriel (8283331300); Huang, Wenjiang (9040267000); Xing, Mengdao (7005922869)","35181982300; 57220011021; 57089587500; 8283331300; 9040267000; 7005922869","A novel image fusion method of multi-spectral and sar images for land cover classification","2020","Remote Sensing","12","22","3801","1","25","24","10.3390/rs12223801","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096495742&doi=10.3390%2frs12223801&partnerID=40&md5=eb9553b2876ca8c695ecba924939a302","The fusion of multi-spectral and synthetic aperture radar (SAR) images could retain the advantages of each data, hence benefiting accurate land cover classification. However, some current image fusion methods face the challenge of producing unexpected noise. To overcome the aforementioned problem, this paper proposes a novel fusion method based on weighted median filter and Gram–Schmidt transform. In the proposed method, Sentinel-2A images and GF-3 images are respectively subjected to different preprocessing processes. Since weighted median filter does not strongly blur edges while filtering, it is applied to Sentinel-2A images for reducing noise. The processed Sentinel images are then transformed by Gram–Schmidt with GF-3 images. Two popular methods, principal component analysis method and traditional Gram–Schmidt transform, are used as the comparison methods in the experiment. In addition, random forest, a powerful ensemble model, is adopted as the land cover classifier due to its fast training speed and excellent classification performance. The overall accuracy, Kappa coefficient and classification map of the random forest are used as the evaluation criteria of the fusion method. Experiments conducted on five datasets demonstrate the superiority of the proposed method in both objective metrics and visual impressions. The experimental results indicate that the proposed method can improve the overall accuracy by up to 5% compared to using the original Sentinel-2A and has the potential to improve the satellite-based land cover classification accuracy. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Decision trees; Image classification; Median filters; Radar imaging; Random forests; Synthetic aperture radar; Classification performance; Comparison methods; Evaluation criteria; Image fusion methods; Land cover classification; Principal component analysis method; Synthetic aperture radar (SAR) images; Weighted median filter; Image fusion","Image fusion; Land cover classification; Multi-spectral; Random forest; Remote sensing","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85096495742"
"Gao S.; Castellazzi P.; Vervoort R.W.; Doody T.M.","Gao, Sicong (57212062932); Castellazzi, Pascal (41660929500); Vervoort, R. Willem (7004868259); Doody, Tanya M. (15032360100)","57212062932; 41660929500; 7004868259; 15032360100","Fine scale mapping of fractional tree canopy cover to support river basin management","2021","Hydrological Processes","35","4","e14156","","","","10.1002/hyp.14156","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104963150&doi=10.1002%2fhyp.14156&partnerID=40&md5=a1338c021d8b960ef1577f82297de304","Management of water, regionally, nationally and globally will continue to be a priority and complex undertaking. In riverine systems, biotic components like flora and fauna play critical roles in filtering water so it is available for human use and consumption. Preservation of ecosystems and associated ecosystem functions is therefore vital. In highly regulated large river basins, natural ecosystems are often supported through provision of environmental flows. Flow delivery, however, should be underpinned by rigorous monitoring to identify and prioritise biotic water requirements. Currently, large-scale monitoring solutions are scaled from remote sensing data via measurement of field evapotranspiration for woody tree vegetation species. However, as there is generally a mismatch between field data collection area and remote sensing pixel size, new methods are required to proportion tree evapotranspiration based on tree fractional canopy area per pixel. We present a novel method to derive tree fractional canopy cover (FTCC) at 20 m resolution in semi-arid and arid floodplain areas. The method employs LiDAR as a canopy area field measurement proxy (10 m resolution). We used Sentinel-1 and Sentinel-2 (radar and multispectral imagery) in a Random Forest analysis, undertaken to develop a predictive FTCC model trained using LiDAR for two regions in the Murray–Darling Basin. A predictor model combining the results of both regions was able to explain between 71%–85% of FTCC variation when compared to LiDAR FTCC when output in 10% increments. Development of this method underpins the advancement of woody vegetation monitoring to inform environmental flow management in the Murray–Darling Basin. The method and fine scale outputs will also be of value to other catchment management concerns such as altered catchment water yields related to bushfires and as such has application to water management worldwide. © 2021 John Wiley & Sons Ltd.","Australia; Murray-Darling Basin; Catchments; Decision trees; Ecosystems; Evapotranspiration; Forestry; Pixels; Predictive analytics; Remote sensing; Runoff; Vegetation; Water management; Watersheds; Catchment management; Ecosystem functions; Field data collection; Field evapotranspiration; Large-scale monitoring; Multi-spectral imagery; Remote sensing data; River basin management; catchment; evapotranspiration; lidar; model test; pixel; prediction; radar; remote sensing; resource assessment; satellite imagery; Sentinel; spectral resolution; synthetic aperture radar; vegetation cover; water management; water quality; Optical radar","catchment water management; evapotranspiration; LiDAR; Murray–Darling basin; radar; SAR; sentinel; vegetation","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85104963150"
"Gargiulo M.; Dell'Aglio D.A.G.; Iodice A.; Riccio D.; Ruello G.","Gargiulo, Massimiliano (57200856555); Dell'Aglio, Domenico A. G. (57202729372); Iodice, Antonio (7003793925); Riccio, Daniele (7006577607); Ruello, Giuseppe (6603038881)","57200856555; 57202729372; 7003793925; 7006577607; 6603038881","Semantic segmentation using deep learning: A case of study in albufera park, Valencia","2019","2019 IEEE International Workshop on Metrology for Agriculture and Forestry, MetroAgriFor 2019 - Proceedings","","","8909243","134","138","4","10.1109/MetroAgriFor.2019.8909243","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076368259&doi=10.1109%2fMetroAgriFor.2019.8909243&partnerID=40&md5=90d5a703cf7d7207a2dfcfd5480195e2","In this work, we explore the potential of using Sentinel-1 (S1) dual-polarization Synthetic Aperture Radar (SAR) data to obtain semantic maps that may complement those provided by the Level-2A (L2A) product of Sentinel-2 (S2). Specifically, we consider the use of the Interferometric Wide swath mode (IW) Sentinel-1 (S1) data collected along ascending/descending orbit, for wetlands and rice growing monitoring over the Natural Park of Albufera, Valencia. For this purpose, supervised Deep Learning (DL) approaches have been proposed to classify the pixels of the interested area. The advantages and disadvantages of different input stacks have been analysed, and the results have been assessed in terms of Accuracy, F1-score, Precision, and Recall. The results demonstrate that dual polarimetric Sentinel-1 SAR data can be effectively integrated in land cover maps produced by Sentinel-2 multispectral data. This approach is particularly helpful for rapid vegetation dynamics in tropical weather countries. © 2019 IEEE.","Forestry; Semantics; Synthetic aperture radar; Timber; Dual-polarizations; Land cover maps; Multi-spectral data; Semantic segmentation; Sentinel-1; Sentinel-2; Vegetation dynamics; Wide swath modes; Deep learning","deep learning; semantic segmentation; Sentinel-1; Sentinel-2; U-Net","Conference paper","Final","","Scopus","2-s2.0-85076368259"
"Pangali Sharma T.P.; Zhang J.; Koju U.A.; Zhang S.; Bai Y.; Suwal M.K.","Pangali Sharma, Til Prasad (57204979912); Zhang, Jiahua (55720362700); Koju, Upama Ashish (56449396000); Zhang, Sha (57194048928); Bai, Yun (57194052987); Suwal, Madan Krishna (56433510400)","57204979912; 55720362700; 56449396000; 57194048928; 57194052987; 56433510400","Review of flood disaster studies in Nepal: A remote sensing perspective","2019","International Journal of Disaster Risk Reduction","34","","","18","27","9","10.1016/j.ijdrr.2018.11.022","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058237524&doi=10.1016%2fj.ijdrr.2018.11.022&partnerID=40&md5=b73dc01b10eee94e3e91bb68a9e101e5","Research on flood disaster generate ideas and provoke the best solution for disaster management. This work primarily focuses research on monsoon flood due to its frequency and severity in the southern flood plain of Nepal. Here we review the previous studies on flood disaster at the regional and national level and compare with the global context. This facilitates exploring the data and methods that are mostly unexplored, and areas that have not lightened in the field of flood studies in Nepal. Our scope of literature review limited the literature that are accessed through internet. The findings are revised and compared with different contexts. Multi-criteria weighted arithmetic mean have been used to find the spatial severity of flood disaster in 2017. We found several studies carried out on flood in Nepal. They are mostly based on field-based data, except few that have used current state-of-art, remote sensing method, using satellite images. Since the multi-spectral optical satellite imageries have a high cloud effect, it is not very useful in real time flood mapping; and very limited Synthetic-Aperture Radar (SAR) image, has been used in Nepal. In Global context, Support Vector Machine and Random Forest method are used in flood risk assessment; VNG flood V1.0 software has been used in flood forecasting, and Probabilistic Change Detection and Thresholding have widely been used in flood research, which can also be adopted in Nepalese context. © 2018 Elsevier Ltd","","Disaster management; Monsoon flood; Multi-criteria method; Nepal; Remote sensing","Review","Final","","Scopus","2-s2.0-85058237524"
"Meroni M.; d'Andrimont R.; Vrieling A.; Fasbender D.; Lemoine G.; Rembold F.; Seguini L.; Verhegghen A.","Meroni, Michele (7006862860); d'Andrimont, Raphaël (52663095400); Vrieling, Anton (23089590700); Fasbender, Dominique (24314742800); Lemoine, Guido (7006844017); Rembold, Felix (6602085685); Seguini, Lorenzo (55365619400); Verhegghen, Astrid (52664629200)","7006862860; 52663095400; 23089590700; 24314742800; 7006844017; 6602085685; 55365619400; 52664629200","Comparing land surface phenology of major European crops as derived from SAR and multispectral data of Sentinel-1 and -2","2021","Remote Sensing of Environment","253","","112232","","","","10.1016/j.rse.2020.112232","38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097639924&doi=10.1016%2fj.rse.2020.112232&partnerID=40&md5=1a813208b78951b222a6a37f0edf364c","The frequent acquisitions of fine spatial resolution imagery (10 m) offered by recent multispectral satellite missions, including Sentinel-2, can resolve single agricultural fields and thus provide crop-specific phenology metrics, a crucial information for crop monitoring. However, effective phenology retrieval may still be hampered by significant cloud cover. Synthetic aperture radar (SAR) observations are not restricted by weather conditions, and Sentinel-1 thus ensures more frequent observations of the land surface. However, these data have not been systematically exploited for phenology retrieval so far. In this study, we extracted crop-specific land surface phenology (LSP) from Sentinel-1 and Sentinel-2 of major European crops (common and durum wheat, barley, maize, oats, rape and turnip rape, sugar beet, sunflower, and dry pulses) using ground-truth information from the “Copernicus module” of the Land Use/Cover Area frame statistical Survey (LUCAS) of 2018. We consistently used a single model-fit approach to retrieve LSP metrics on temporal profiles of CR (Cross Ratio, the ratio of the backscattering coefficient VH/VV from Sentinel-1) and NDVI (Normalized Difference Vegetation Index from Sentinel-2). Our analysis revealed that LSP retrievals from Sentinel-1 are comparable to those of Sentinel-2, particularly for winter crops. The start of season (SOS) timings, as derived from Sentinel-1 and -2, are significantly correlated (average r of 0.78 for winter and 0.46 for summer crops). The correlation is lower for end of season retrievals (EOS, r of 0.62 and 0.34). Agreement between LSP derived from Sentinel-1 and -2 varies among crop types, ranging from r = 0.89 and mean absolute error MAE = 10 days (SOS of dry pulses) to r = 0.15 and MAE = 53 days (EOS of sugar beet). Observed deviations revealed that Sentinel-1 and -2 LSP retrievals can be complementary; for example for winter crops we found that SAR detected the start of the spring growth while multispectral data is sensitive to the vegetative growth before and during winter. To test if our results correspond reasonably to in-situ data, we compared average crop-specific LSP for Germany to average phenology from ground phenological observations of 2018 gathered from the German Meteorological Service (DWD). Our study demonstrated that both Sentinel-1 and -2 can provide relevant and at times complementary LSP information at field- and crop-level. © 2020 The Author(s)","Germany; Beta vulgaris subsp. vulgaris; Brassica rapa; Helianthus; Hordeum; Triticum turgidum subsp. durum; Agricultural robots; Backscattering; Biology; Land use; Radar imaging; Satellite imagery; Search engines; Sugar beets; Surface measurement; Synthetic aperture radar; Backscattering coefficients; Land surface phenology; Mean absolute error; Multi-spectral data; Normalized difference vegetation index; Phenological observations; Spatial resolution imagery; Start of seasons (SOS); backscatter; data acquisition; error analysis; image resolution; phenology; satellite data; satellite imagery; Sentinel; spatial resolution; synthetic aperture radar; Crops","Agriculture; Crop phenology; DWD ground phenological observations; Europe; Land surface phenology; LUCAS survey; Satellite image time series; Sentinel-1; Sentinel-2","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85097639924"
"Guo J.; Bai Q.; Guo W.; Bu Z.; Zhang W.","Guo, Jiao (56161174200); Bai, Qingyuan (57290603300); Guo, Wenchuan (55856377700); Bu, Zhendong (57417370700); Zhang, Weitao (25937043500)","56161174200; 57290603300; 55856377700; 57417370700; 25937043500","Soil moisture content estimation in winter wheat planting area for multi-source sensing data using CNNR","2022","Computers and Electronics in Agriculture","193","","106670","","","","10.1016/j.compag.2021.106670","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123050568&doi=10.1016%2fj.compag.2021.106670&partnerID=40&md5=95b2e5c879b68d57504fc713ffc6f152","Rapid and accurate estimation of soil moisture content (SMC) is an important part of precision agriculture, and it is also one of the key problems to be solved in field real-time monitoring and precision irrigation. Most of the existing studies are limited to SMC monitoring of bare soil, which can be obtained by optical remote sensing (e.g., multispectral, hyperspectral) or Synthetic Aperture Radar (SAR). However, for the soil covered by vegetation, such as farmland, there are some theoretical defects with only one of the measuring methods. Meanwhile, in order to break through the limitations of low spatial and temporal resolutions of satellite remote sensing, it is of great significance to study SMC retrieval based on multi-source remote sensing data for the near earth UAV remote sensing systems. Based on this, this paper, taking the winter wheat planting area in Guanzhong plain of China as the research area, combines the advantages of ultra-wideband (UWB) radar, and multispectral remote sensing data, to reduce the influences of vegetation coverage on the estimation accuracy. A one-dimensional regression convolution neural network model is constructed to realize the quantitative prediction and estimation of SMC in farmland. The carried out experiments show that the proposed CNNR model has a better performance than traditional SVR and GRNN models and the R2, RMSE and RPD are 0.7453, 0.0140 cm3/cm3 and 1.9246, respectively. After introducing NDVI, MSAVI and DVI vegetation indices generated from multispectral images, the accuracy of the three models increased significantly. Among the three models, the constructed CNNR model has the best performance, and its R2, RMSE and RPD reach 0.9168, 0.0089 cm3/cm3, and 3.0201. Furthermore, after adding different levels of Gaussian noise to the original radar echoes, the CNNR model constructed in this paper still has the highest prediction accuracy and the strongest noise robustness. © 2022 Elsevier B.V.","China; Convolution; Farms; Gaussian noise (electronic); Moisture determination; Neural networks; Radar imaging; Remote sensing; Search engines; Soil moisture; Soil surveys; Space-based radar; Synthetic aperture radar; Ultra-wideband (UWB); Vegetation; White noise; Convolutional neural network; Convolutional neural network regression; Multi-Sources; Multi-spectral; Performance; Planting areas; Remote sensing data; Soil moisture content; Ultra wideband radars; Winter wheat; accuracy assessment; moisture content; multispectral image; NDVI; remote sensing; satellite data; seasonal variation; soil moisture; Crops","Convolutional neural network regression; Multispectral; Soil moisture content; Ultra wideband radar","Article","Final","","Scopus","2-s2.0-85123050568"
"Kulkarni S.C.; Rege P.P.","Kulkarni, Samadhan C. (57204893706); Rege, Priti P. (6701858789)","57204893706; 6701858789","Application of Taguchi method to improve land use land cover classification using PCA-DWT-based SAR-multispectral image fusion","2021","Journal of Applied Remote Sensing","15","1","014509","","","","10.1117/1.JRS.15.014509","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103662238&doi=10.1117%2f1.JRS.15.014509&partnerID=40&md5=79649ae2d1087aff8efd3a9755abb7a0","The fusion of multispectral and synthetic aperture radar (SAR) images is of vital importance in many remote sensing applications. Spectral distortion and trade-off between the spatial and spectral quality of the fused image are significant issues in SAR-multispectral image fusion. Our study attempts to improve the performance of SAR-multispectral image fusion concerning these two issues. The primary objective of our study is to optimize the performance of hybrid fusion approach based on principal component analysis and discrete wavelet transform (PCA-DWT) using Taguchi orthogonal array. The fused data are evaluated using visual analysis and standard quality metrics. The results are compared with recent hybrid fusion approaches applied to the SAR-multispectral image fusion. The utility of the fused data is evaluated based on the remote sensing application, namely, land use land cover classification. The classification results are compared to a standard thematic map available on the Bhuvan geoportal to check classification accuracy. A comparative analysis with recent hybrid approaches conclusively demonstrates that the proposed optimization in the PCA-DWT based fusion is superior to conventional hybrid methods. © 2021 Society of Photo-Optical Instrumentation Engineers (SPIE).","Discrete wavelet transforms; Economic and social effects; Image classification; Image enhancement; Image fusion; Land use; Maps; Quality control; Remote sensing; Signal reconstruction; Synthetic aperture radar; Taguchi methods; Classification accuracy; Classification results; Comparative analysis; Land use/ land covers; Multi-spectral image fusions; Remote sensing applications; Synthetic aperture radar (SAR) images; Taguchi orthogonal arrays; Radar imaging","land use land cover classification; multispectral imagery; principal component analysis; synthetic aperture radar imagery; Taguchi orthogonal array; wavelet transform","Article","Final","","Scopus","2-s2.0-85103662238"
"Asam S.; Gessner U.; González R.A.; Wenzl M.; Kriese J.; Kuenzer C.","Asam, Sarah (55783123600); Gessner, Ursula (24467994800); González, Roger Almengor (57220564995); Wenzl, Martina (57776030200); Kriese, Jennifer (57387140100); Kuenzer, Claudia (55927784300)","55783123600; 24467994800; 57220564995; 57776030200; 57387140100; 55927784300","Mapping Crop Types of Germany by Combining Temporal Statistical Metrics of Sentinel-1 and Sentinel-2 Time Series with LPIS Data","2022","Remote Sensing","14","13","2981","","","","10.3390/rs14132981","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133302397&doi=10.3390%2frs14132981&partnerID=40&md5=8c50cc1637a4a752c9de100fb8a22a4c","Nationwide and consistent information on agricultural land use forms an important basis for sustainable land management maintaining food security, (agro)biodiversity, and soil fertility, especially as German agriculture has shown high vulnerability to climate change. Sentinel-1 and Sentinel-2 satellite data of the Copernicus program offer time series with temporal, spatial, radiometric, and spectral characteristics that have great potential for mapping and monitoring agricultural crops. This paper presents an approach which synergistically uses these multispectral and Synthetic Aperture Radar (SAR) time series for the classification of 17 crop classes at 10 m spatial resolution for Germany in the year 2018. Input data for the Random Forest (RF) classification are monthly statistics of Sentinel-1 and Sentinel-2 time series. This approach reduces the amount of input data and pre-processing steps while retaining phenological information, which is crucial for crop type discrimination. For training and validation, Land Parcel Identification System (LPIS) data were available covering 15 of the 16 German Federal States. An overall map accuracy of 75.5% was achieved, with class-specific F1-scores above 80% for winter wheat, maize, sugar beet, and rapeseed. By combining optical and SAR data, overall accuracies could be increased by 6% and 9%, respectively, compared to single sensor approaches. While no increase in overall accuracy could be achieved by stratifying the classification in natural landscape regions, the class-wise accuracies for all but the cereal classes could be improved, on average, by 7%. In comparison to census data, the crop areas could be approximated well with, on average, only 1% of deviation in class-specific acreages. Using this streamlined approach, similar accuracies for the most widespread crop types as well as for smaller permanent crop classes were reached as in other Germany-wide crop type studies, indicating its potential for repeated nationwide crop type mapping. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Biodiversity; Classification (of information); Climate change; Crops; Data handling; Decision trees; Food supply; Input output programs; Land use; Population statistics; Synthetic aperture radar; Crop class; IACS; Land parcel identification systems; Multi-spectral data; Radar data; Random forest classification; Sentinel-1; Spectral statistics; Temporal statistic; Times series; Time series","agriculture; IACS; multispectral data; radar data; random forest classification; spectral statistics; temporal statistics","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85133302397"
"Upadhyay P.; Czerkawski M.; Davison C.; Cardona J.; Macdonald M.; Andonovic I.; Michie C.; Atkinson R.; Papadopoulou N.; Nikas K.; Tachtatzis C.","Upadhyay, Priti (57474842000); Czerkawski, Mikolaj (57218294325); Davison, Christopher (57193000486); Cardona, Javier (56727904800); Macdonald, Malcolm (7401502084); Andonovic, Ivan (35461300200); Michie, Craig (7006306265); Atkinson, Robert (50660892000); Papadopoulou, Nikela (57144238000); Nikas, Konstantinos (57189018285); Tachtatzis, Christos (26029612300)","57474842000; 57218294325; 57193000486; 56727904800; 7401502084; 35461300200; 7006306265; 50660892000; 57144238000; 57189018285; 26029612300","A Flexible Multi-Temporal and Multi-Modal Framework for Sentinel-1 and Sentinel-2 Analysis Ready Data","2022","Remote Sensing","14","5","1120","","","","10.3390/rs14051120","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125672739&doi=10.3390%2frs14051120&partnerID=40&md5=f99f800cf8e8b32f94b1f3e6fae2cc4b","The rich, complementary data provided by Sentinel-1 and Sentinel-2 satellite constellations host considerable potential to transform Earth observation (EO) applications. However, a substantial amount of effort and infrastructure is still required for the generation of analysis-ready data (ARD) from the low-level products provided by the European Space Agency (ESA). Here, a flexible Python framework able to generate a range of consistent ARD aligned with the ESA-recommended processing pipeline is detailed. Sentinel-1 Synthetic Aperture Radar (SAR) data are radiometrically calibrated, speckle-filtered and terrain-corrected, and Sentinel-2 multi-spectral data resampled in order to harmonise the spatial resolution between the two streams and to allow stacking with multiple scene classification masks. The global coverage and flexibility of the framework allows users to define a specific region of interest (ROI) and time window to create geo-referenced Sentinel-1 and Sentinel-2 images, or a combination of both with closest temporal alignment. The framework can be applied to any location and is user-centric and versatile in generating multi-modal and multi-temporal ARD. Finally, the framework handles automatically the inherent challenges in processing Sentinel data, such as boundary regions with missing values within Sentinel-1 and the filtering of Sentinel-2 scenes based on ROI cloud coverage. © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https:// creativecommons.org/licenses/by/ 4.0/).","Data handling; Modal analysis; Pipeline processing systems; Python; Synthetic aperture radar; Analyse-ready data; Complementary data; European Space Agency; Multi-modal; Multi-temporal; Region-of-interest; Regions of interest; Satellite constellations; Sentinel-1; Sentinel-2; Image segmentation","Analysis-ready data; Multi-modal; Multi-temporal; Sentinel-1; Sentinel-2","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85125672739"
"Brinkhoff J.; Vardanega J.; Robson A.J.","Brinkhoff, James (57497574700); Vardanega, Justin (57216674643); Robson, Andrew J. (55780256400)","57497574700; 57216674643; 55780256400","Land cover classification of nine perennial crops using sentinel-1 and -2 data","2020","Remote Sensing","12","1","96","","","","10.3390/rs12010096","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080907751&doi=10.3390%2frs12010096&partnerID=40&md5=38f7a8cef7479b2740cfc69dfc358484","Land cover mapping of intensive cropping areas facilitates an enhanced regional response to biosecurity threats and to natural disasters such as drought and flooding. Such maps also provide information for natural resource planning and analysis of the temporal and spatial trends in crop distribution and gross production. In this work, 10 meter resolution land cover maps were generated over a 6200 km2 area of the Riverina region in New SouthWales (NSW), Australia, with a focus on locating the most important perennial crops in the region. The maps discriminated between 12 classes, including nine perennial crop classes. A satellite image time series (SITS) of freely available Sentinel-1 synthetic aperture radar (SAR) and Sentinel-2 multispectral imagery was used. A segmentation technique grouped spectrally similar adjacent pixels together, to enable object-based image analysis (OBIA). K-means unsupervised clustering was used to filter training points and classify some map areas, which improved supervised classification of the remaining areas. The support vector machine (SVM) supervised classifier with radial basis function (RBF) kernel gave the best results among several algorithms trialled. The accuracies of maps generated using several combinations of the multispectral and radar bands were compared to assess the relative value of each combination. An object-based post classification refinement step was developed, enabling optimization of the tradeoff between producers' accuracy and users' accuracy. Accuracy was assessed against randomly sampled segments, and the final map achieved an overall count-based accuracy of 84.8% and area-weighted accuracy of 90.9%. Producers' accuracies for the perennial crop classes ranged from 78 to 100%, and users' accuracies ranged from 63 to 100%. This work develops methods to generate detailed and large-scale maps that accurately discriminate between many perennial crops and can be updated frequently. © 2019 by the authors.","Crops; Disasters; Image segmentation; K-means clustering; Radial basis function networks; Satellite imagery; Support vector machines; Synthetic aperture radar; Land cover classification; Multi-spectral imagery; Object based image analysis (OBIA); Radial Basis Function(RBF); Segmentation techniques; Supervised classification; Supervised classifiers; Unsupervised clustering; Radar imaging","Crop type classification; Land cover mapping; Machine learning; Remote sensing; Satellite image time series; Sentinel-1; Sentinel-2","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85080907751"
"Lu Y.; Liu J.; Ding J.; Shi J.; Chen J.; Ye X.","Lu, Yingcheng (55443757500); Liu, Jianqiang (57203899343); Ding, Jing (55463424400); Shi, Jing (57191676169); Chen, Junying (57212554950); Ye, Xiaomin (57212564001)","55443757500; 57203899343; 55463424400; 57191676169; 57212554950; 57212564001","Optical remote identification of spilled oils from the SANCHI oil tanker collision in the East China Sea; [中国东海""桑吉""轮溢油污染类型的光学遥感识别]","2019","Kexue Tongbao/Chinese Science Bulletin","64","31","","3213","3222","9","10.1360/N972019-00094","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077080688&doi=10.1360%2fN972019-00094&partnerID=40&md5=553a8705ab37a85024c4f0222c87ccdd","Remote sensing of marine oil spills is an important application of satellite observation data. During the oil weathering process, marine spilled crude oils undergo chemical and physical changes (e.g. spreading, drifting, mixing, emulsification, evaporation, dissolution, and Photo-oxidation) to form different pollution types with various visual features. These visual features include the following: Light sheen, silver sheen, rainbow sheen, streamers, brown oil slick, and black oil, and they represent different oil amounts per unit area. Notably, different treatment methods, such as booms, skimmers, chemical dispersants, and in situ burning, can be used specifically to reduce the damage of various types of oil spill to the marine environment. Therefore, the detection, classification, and quantification of the various types can facilitate the monitoring and assessment of marine oil spills. Synthetic aperture radar (SAR) and multi/hyper spectral optical sensors onboard satellites or aircraft provide timely observation data for remote sensing of marine spilled oils based on distinctly different detection principles. Although SAR is an effective detection method which can penetrate clouds and rain, the identification and estimation of the various spilled oils are difficult. Optical remote sensing has been used for several decades and it has the capability to identify various spilled oils (i.e. oil slicks, water-in-oil (WO) or oil-in-water (OW) emulsions) and to estimate oil slick thickness or oil emulsions concentrations according to their spectral reflectance and other characteristics. Integration of the use of SAR and optical remote sensing imageries will undoubtedly improve the identification and estimation of various marine spilled oils in the future. Here we present the results of a case study of the SANCHI oil tanker collision on January 2018 in the East Sea of China, which we use to evaluate how the advantages of SAR and optical sensors for remotely identifying different marine spilled oils can be combined. SAR imageries of different polarization modes over the East Sea from 7 to 14 January 2018 were collected from the GF-3 satellite (China) for detecting spilled oils. In these different SAR imageries, the modulation of the spilled oils of surface roughness reduces Bragg backscattering, resulting in darker look-alike oils than the surrounding water. Optical data (cloud-free or less cloud) over the same area on 18 January 2018 were obtained from a multi-spectral instrument (MSI) onboard the Sentinel-2 (European Space Agency, ESA) in order to identify various spilled oils. Laboratory-based measurements of the spectral reflectance of oil slicks, oil emulsions, and crude oil were used to simulate the spectral features of various spilled oils in MSI imagery under weak sunglint reflectance. The high spatial resolution of MSI images (spatial resolution of 10 m) reduces the mixing effect of clouds, and spilled oils could be identified through the gaps in the clouds. These look-alike spilled oils derived from the SAR imagery can be verified using MSI optical images. Moreover, based on the laboratory-derived spectral features of various spilled oils and the decision tree method, these different spilled oils (i.e. oil slicks, WO and OW emulsions) produced by the SANCHI oil tanker collision can be identified using MSI spectral reflectance. The results have been verified against each other, and they indicate that the various spilled oils can be identified using passive optical remote sensing. We conclude that the integrated application of multi-source remote sensing (especially optical remote sensing) can provide an important method for the detection, identification, and estimation of marine spilled oils in the near future. © 2019, Science Press. All right reserved.","Aircraft accidents; Aircraft detection; Crude oil; Decision trees; Emulsification; Emulsions; Geometrical optics; Image enhancement; Image resolution; Marine pollution; Marine radar; Mixing; Oil booms; Oil spills; Oil tankers; Optical sensors; Ostwald ripening; Radar imaging; Reflection; Satellites; Space optics; Space-based radar; Surface roughness; Synthetic aperture radar; Weathering; Integrated applications; Marine oil spills; Optical remote sensing; SANCHI; Spectral feature; Remote sensing","Integrated application; Marine oil spill; Optical remote sensing; SANCHI; Spectral features","Article","Final","","Scopus","2-s2.0-85077080688"
"Kulkarni S.C.; Rege P.P.","Kulkarni, Samadhan C. (57204893706); Rege, Priti P. (6701858789)","57204893706; 6701858789","Fusion of RISAT-1 SAR Image and Resourcesat-2 Multispectral Images Using Wavelet Transform","2019","2019 6th International Conference on Signal Processing and Integrated Networks, SPIN 2019","","","8711589","45","52","7","10.1109/SPIN.2019.8711589","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066897202&doi=10.1109%2fSPIN.2019.8711589&partnerID=40&md5=7825390435348ef36f892396b737c46c","This paper presents a pixel level wavelet-based approach to fuse synthetic aperture radar (SAR) imagery with multispectral (MS) imagery. Image fusion combines information from two or more images to generate a new image, which is rich in information. Due to complementary nature of SAR and multispectral imagery, fusion of these images is of significant interest in the field of remote sensing. The primary objective of this work is to enhance spatial information in multispectral images by injecting structural information derived from SAR image. Due to negative correlation between SAR and multispectral data, conventional component substitution methods face the problem of spectral distortion in the fused image. Wavelet based fusion approaches overcome this problem due to excellent localization in spatial and frequency domain. Here, different wavelet-based fusion rules are applied for fusion of SAR and multispectral images. Fusion rules applied to fuse approximate sub-bands and detail sub-bands of these images consider spectral dis-similarity between them. Results are evaluated visually, as well as using standard quality metrics and are compared with component substitution fusion techniques namely, principal component analysis and generalized IHS transform. Trade-off between spectral and spatial quality of fused image has been observed while fusing SAR and multispectral images. © 2019 IEEE.","Economic and social effects; Frequency domain analysis; Image compression; Image enhancement; Image fusion; Principal component analysis; Quality control; Remote sensing; Synthetic aperture radar; Wavelet transforms; Component substitution; Conventional components; Multi-spectral imagery; SAR imagery; Spatial and frequency domain; Structural information; Synthetic Aperture Radar Imagery; Wavelet-based fusion approach; Radar imaging","Image Fusion; Multispectral Imagery; Remote Sensing; SAR Imagery; Wavelet Transform","Conference paper","Final","","Scopus","2-s2.0-85066897202"
"Seaton D.; Dube T.","Seaton, Dylan (57218364463); Dube, Timothy (55629520500)","57218364463; 55629520500","A new modified spatial approach for monitoring non-perennial river water availability using remote sensing in the tankwa karoo, western cape, south africa","2021","Water SA","47","3","","338","346","8","10.17159/wsa/2021.v47.i3.11862","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112094050&doi=10.17159%2fwsa%2f2021.v47.i3.11862&partnerID=40&md5=4357624b933b21958a664ba8558e5042","Non-perennial rivers (N-PRs) make up two thirds of all rivers in South Africa, yet many are ungauged. Traditionally, it has been assumed that when a flow is recorded, there is water throughout that river. These assumptions have led to incorrect estimations of available water resources. This work thus aimed at developing a new spatially explicit framework, for monitoring river water availability in a N-PR system. The Tankwa River in South Africa was used for testing this approach. The length of the river reach with water was determined using the Sentinel-1 and Sentinel-2 data derived indices. Image thresholding was applied to Sentinel-1, and the normalised difference water index (NDWI) to Sentinel-2. Sentinel-2 yielded an overall accuracy (OA) of 85%, whereas Sentinel-1 yielded an OA of 38%. The analysed reach of the Tankwa River had an actual length of 9 244 m. Based on the performance of Sentinel-2 data, further analysis was undertaken using Sentinel images acquired during the months of February, May and July of 2016. The results indicated that the lengths of the reaches of inundated Tankwa River were 2 809 m, 3 202 m and 2 890 m, respectively. Overall, the findings of this study show that an estimated length of a river inundated by water can be determined using new-generation Sentinel data and these results provide new insights on the dynamics of N-PRs – a previously challenging task with broadband multispectral satellite datasets. © The Author(s).","South Africa; Remote sensing; Available water; Image thresholding; Multi-spectral; Overall accuracies; River water; South Africa; Spatially explicit; Western Cape , South Africa; accuracy assessment; performance assessment; remote sensing; river system; river water; satellite data; Sentinel; water availability; Rivers","non-perennial rivers; remote sensing; semi-arid environments; Sentinel-1 and-2 data; South Africa; synthetic aperture radar (SAR); water resource management","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85112094050"
"Saini O.; Bhardwaj A.; Chatterjee R.S.","Saini, Ojasvi (57215434308); Bhardwaj, Ashutosh (55202293600); Chatterjee, R.S. (57211317449)","57215434308; 55202293600; 57211317449","Detection of water body using very high-resolution UAV SAR and sentinel-2 images","2020","Lecture Notes in Civil Engineering","51","","","53","65","12","10.1007/978-3-030-37393-1_7","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080881393&doi=10.1007%2f978-3-030-37393-1_7&partnerID=40&md5=0b45c23b8a9e71fe7e24eca8e959ff43","The extent of water body has far-reaching effects on agriculture, flood control, and ecological studies. Synthetic Aperture Radar (SAR) imaging technique can be operated in all weather, day and night circumstances. Due to the numerous advantages of SAR imaging technique over other conventional image acquisition practices, it has been used for the detection of the waterbody. Subsets of quad-pol, georeferenced (L-band) SAR imagery of UAV platform (provided by JPL, NASA) of Mondah, Gabon region and optical imagery by Sentinel-2 of the same region is used for the extraction of the water body. After preprocessing of UAV SAR image, Yamaguchi Decomposition was carried out and volume scattering image array (T33) has been used for the extraction of the waterbody. T33 array element of the coherency matrix represents volume back-scattering responses from the area of acquisition. Since the surface of the water body (either smooth or rough water surface) shows negligible volume back-scattering, water bodies can be easily delineated using thresholding and then applying the SVM classification method. The area covered by water reflects most of the radiations falling in the Green color frequency range and strongly absorbs Near-Infrared part of the electromagnetic spectrum. Taking advantage of this unique behavior of water surface while interacting with the electromagnetic spectrum, Normalized Difference Water Index (NDWI) is used for the extraction of waterbody from Sentinel-2 optical image. Finally, the SVM classified outcomes for extracted water area from both the images were compared. The harmonizing information from the, (UAV SAR and Sentinel-2 multi-spectral) images have been used for the quick and precise recognition of waterbody. © Springer Nature Switzerland AG 2020.","Agricultural robots; Aircraft detection; Backscattering; Extraction; Flood control; Geometrical optics; Imaging techniques; Infrared devices; NASA; Support vector machines; Surface waters; Synthetic aperture radar; Unmanned aerial vehicles (UAV); Electromagnetic spectra; NDWI; Normalized difference water index; Sentinel-2; SVM classification; Very high resolution; Waterbodies; Yamaguchi decompositions; Radar imaging","NDWI; Sentinel-2; SVM; UAV SAR; VHR; Waterbody","Book chapter","Final","","Scopus","2-s2.0-85080881393"
"Oukali S.; Lazri M.; Labadi K.; Brucker J.M.; Ameur S.","Oukali, Salim (57209478030); Lazri, Mourad (55598469400); Labadi, Karim (23005007800); Brucker, Jean Michel (55599190600); Ameur, Soltane (8629285200)","57209478030; 55598469400; 23005007800; 55599190600; 8629285200","Development of a hybrid classification technique based on deep learning applied to MSG / SEVIRI multispectral data","2019","Journal of Atmospheric and Solar-Terrestrial Physics","193","","105062","","","","10.1016/j.jastp.2019.105062","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067869633&doi=10.1016%2fj.jastp.2019.105062&partnerID=40&md5=d90e3b4bd860fe5e178beb621f87f341","The approach developed in this paper for the classification of precipitation intensities is based on deep learning of neural network. Multispectral data from the MSG satellite (Meteosat Second Generation) providing information about the cloud's physical and optical characteristics are exploited and used as inputs to a deep neural network model. The model is a combination of CNN (Convolutional Neural Network) and DMLP (Deep Multi-Layer Peceptron) which is learned and validated by comparison with the corresponding Radar data during the rainy seasons 2006/2007 and 2010/2011 respectively. The CNN extracts spatial characteristics from MSG multi-spectral images. Then, the set of spatial and multi-spectral information are used as inputs for the DMLP. The results show an improvement compared to the three other classifiers (Random Forest, Support Vector Machine and Artificial Neural Network). The CNN-DMLP method was also compared to the technique combining the three classifiers (SAR). The results indicate a percentage correct (PC) of 97% and a probability of detection (POD) of 90% for CNN-DMLP method compared to 94% and 87% for of the SAR technique, respectively. In terms of bias, the CNN-DMLP method gives 1.08 compared 1.10 for SAR technique. © 2019 Elsevier Ltd","Classification (of information); Decision trees; Deep learning; Neural networks; Space-based radar; Spectroscopy; Synthetic aperture radar; Convolutional neural network; Hybrid classification; Meteosat second generations; MSG satellites; Optical characteristics; Precipitation intensity; Probability of detection; Spatial characteristics; Deep neural networks","Classification; CNN; Deep learning; MLP; MSG satellite","Article","Final","","Scopus","2-s2.0-85067869633"
"Tong Y.; Quan Y.; Feng W.; Xing M.","Tong, Yingping (57220011021); Quan, Yinghui (35181982300); Feng, Wei (57089587500); Xing, Mengdao (7005922869)","57220011021; 35181982300; 57089587500; 7005922869","Multi-source remote sensing image fusion method based on spatial-spectrum information collaboration and Gram-Schmidt transform; [基于空谱信息协同与Gram-Schmidt变换的多源遥感图像融合方法]","2022","Xi Tong Gong Cheng Yu Dian Zi Ji Shu/Systems Engineering and Electronics","44","7","","2074","2083","9","10.12305/j.issn.1001-506X.2022.07.02","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132523965&doi=10.12305%2fj.issn.1001-506X.2022.07.02&partnerID=40&md5=29eab6b032f2e79b467f873c1fd9733b","The fusion of multispectral and synthetic aperture radar (SAR) images can retain the advantages of each data and improve the accuracy of land cover classification. However, some current image fusion methods cannot fully utilize the spectral information and texture details of the original data. In order to overcome these problems, a fusion method based on space-spectrum information collaboration and Gram-Schmidt transform is proposed. In the proposed method, Sentinel-2A images and GaoFen-3 (GF-3) images are preprocessed by different methods. Since the gray co-occurrence matrix can effectively extract the texture information of the image, it is applied to the Sentinel-2A image to extract the structural features, and the multispectral image coordinated by the space-spectrum information is fused with GF-3 image by the Gram-Schmidt transform. Principal component analysis (PCA) and the traditional Gram-Schmidt transform are used as the comparison methods in this experiment. In order to determine the effectiveness of the fusion algorithm, this paper uses five evaluation indicators including average gradient, spatial frequency, mean, standard deviation and correlation coefficient to measure the quality of the fusion image. In addition, due to its excellent training speed and excellent classification performance, random forest is used for land cover classification. The classification accuracy of random forest, Kappa coefficient and classification result graph are used as the evaluation criteria of the fusion method. Experimental results show that, compared with the original Sentinel-2A alone, the proposed fusion method can improve the overall accuracy by up to 5%, and has the potential to improve the accuracy of land cover classification in remote sensing satellite images. © 2022, Editorial Office of Systems Engineering and Electronics. All right reserved.","Classification (of information); Decision trees; Image classification; Image enhancement; Image fusion; Principal component analysis; Quality control; Synthetic aperture radar; Textures; Fusion methods; Gram-Schmidt transform; Image fusion methods; Information collaborations; Land cover classification; Multi-spectral; Random forests; Remote-sensing; Space spectrum; Spectrum information; Remote sensing","Classification; Image fusion; Multispectral; Remote sensing","Article","Final","","Scopus","2-s2.0-85132523965"
"Solórzano J.V.; Mas J.F.; Gao Y.; Gallardo-Cruz J.A.","Solórzano, Jonathan V. (57191527096); Mas, Jean François (55993660100); Gao, Yan (55731329000); Gallardo-Cruz, José Alberto (26029823700)","57191527096; 55993660100; 55731329000; 26029823700","Land use land cover classification with U-net: Advantages of combining sentinel-1 and sentinel-2 imagery","2021","Remote Sensing","13","18","3600","","","","10.3390/rs13183600","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114688043&doi=10.3390%2frs13183600&partnerID=40&md5=aaba8e2361ff1e3f8023976390b7dade","The U-net is nowadays among the most popular deep learning algorithms for land use/land cover (LULC) mapping; nevertheless, it has rarely been used with synthetic aperture radar (SAR) and multispectral (MS) imagery. On the other hand, the discrimination between plantations and forests in LULC maps has been emphasized, especially for tropical areas, due to their differences in biodiversity and ecosystem services provision. In this study, we trained a U-net using different imagery inputs from Sentinel-1 and Sentinel-2 satellites, MS, SAR and a combination of both (MS + SAR); while a random forests algorithm (RF) with the MS + SAR input was also trained to evaluate the difference in algorithm selection. The classification system included ten classes, including old-growth and secondary forests, as well as old-growth and young plantations. The most accurate results were obtained with the MS + SAR U-net, where the highest overall accuracy (0.76) and average F1-score (0.58) were achieved. Although MS + SAR and MS U-nets gave similar results for almost all of the classes, for old-growth plantations and secondary forest, the addition of the SAR band caused an F1-score increment of 0.08–0.11 (0.62 vs. 0.54 and 0.45 vs. 0.34, respectively). Consecutively, in comparison with the MS + SAR RF, the MS + SAR U-net obtained higher F1-scores for almost all the classes. Our results show that using the U-net with a combined input of SAR and MS images enabled a higher F1-score and accuracy for a detailed LULC map, in comparison with other evaluated methods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Biodiversity; Decision trees; Deep learning; Ecosystems; Image classification; Land use; Learning algorithms; Synthetic aperture radar; Tropics; Algorithm selection; Classification system; Ecosystem services; Land use/ land covers; Land use/land cover; Multi-spectral imagery; Old-growth plantation; Overall accuracies; Radar imaging","Convolutional neural networks; Deep learning; LULC mapping; Multispectral and synthetic aperture radar (SAR) imagery; Tropical landscape mosaic","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85114688043"
"Agrawal R.; Mohite J.D.; Sawant S.A.; Pandit A.; Pappula S.","Agrawal, R. (36701055900); Mohite, J.D. (56515235000); Sawant, S.A. (56421604400); Pandit, A. (56539386000); Pappula, S. (6505567619)","36701055900; 56515235000; 56421604400; 56539386000; 6505567619","ESTIMATION OF NDVI FOR CLOUDY PIXELS USING MACHINE LEARNING","2022","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","43","B3-2022","","813","818","5","10.5194/isprs-archives-XLIII-B3-2022-813-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131935892&doi=10.5194%2fisprs-archives-XLIII-B3-2022-813-2022&partnerID=40&md5=991929515e4a3ed3c01533acc62e683e","The Normalized Difference Vegetation Index (NDVI) is a useful index for vegetation monitoring. However, due to cloud cover the observations of NDVI are discrete and vary in the intensity. Therefore, there is a need to estimate the NDVI during cloud cover using alternative sources of satellite observations. The main objective of this study is to estimate NDVI during cloudy conditions using moderate resolution multi-spectral and synthetic aperture radar (SAR) observations. Two approaches were identified: 1) pixel replacement and 2) machine learning based regression analysis to estimate cloud free NDVI. Moderate Resolution Imaging Spectroradiometer (MODIS) 8-day NDVI composite, Sentinel-1 SAR and cloud masked Sentinel-2 multi-spectral observations were collected for entire cropping season. The satellite observations were selected only for agricultural areas by applying the agriculture, non-agriculture land use land cover mask. Machine learning algorithms such as Linear Regression (LR), Random Forest Regression (RFR), and Support Vector Regression (SVR) were used for NDVI estimation. Regression analysis was performed using Sentinel-2 NDVI as an independent variable and VV, VH, Cross Ratio (i.e., VV/VH), and MODIS NDVI as dependent variables. NDVI of the cloudy pixel was estimated using the trained regression models over the agriculture areas. A regression model was trained and applied to each Sentinel-2 tile that covers an area of 100 km × 100 km. The RFR and SVR showed the highest R2 of 0.73 and a RMSE of 0.12. A visual comparison of time series graphs showed good alignment between actual (Sentinel-2) and predicted NDVI and usual crop growth trend.  © Authors 2022","Agriculture; Decision trees; Land use; Learning algorithms; Machine learning; Pixels; Radar imaging; Regression analysis; Remote sensing; Vegetation; Cloud cover; Cloud free normalized difference vegetation index; Cloudy pixels; Machine-learning; Moderate-resolution imaging spectroradiometers; Multi-spectral; Normalized difference vegetation index; Random forests; Remote-sensing; Satellite observations; Synthetic aperture radar","Cloud Free NDVI; Machine Learning; Multi-spectral; Remote Sensing; SAR","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85131935892"
"Yuzugullu O.; Lorenz F.; Fröhlich P.; Liebisch F.","Yuzugullu, Onur (48161792800); Lorenz, Frank (57225812573); Fröhlich, Peter (57225395020); Liebisch, Frank (6505641135)","48161792800; 57225812573; 57225395020; 6505641135","Understanding fields by remote sensing: Soil zoning and property mapping","2020","Remote Sensing","12","7","1116","","","","10.3390/rs12071116","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084264499&doi=10.3390%2frs12071116&partnerID=40&md5=dfc853f6ca681295e7863eded416f141","Precision agriculture aims to optimize field management to increase agronomic yield, reduce environmental impact, and potentially foster soil carbon sequestration. In 2015, the Copernicus mission, with Sentinel-1 and -2, opened a new era by providing freely available high spatial and temporal resolution satellite data. Since then, many studies have been conducted to understand, monitor and improve agricultural systems. This paper presents results from the SolumScire project, focusing on the prediction of the spatial distribution of soil zones and topsoil properties, such as pH, soil organic matter (SOM) and clay content in agricultural fields through random forest algorithms. For this purpose, samples from 120 fields were investigated. The zoning and soil property prediction has an accuracy greater than 90%. This is supported by a high agreement of the derived zones with farmer's observations. The trained models revealed a prediction accuracy of 94%, 89% and 96% for pH, SOM and clay content, respectively. The obtained models for soil properties can support precision field management, the improvement of soil sampling and fertilization strategies, and eventually the management of soil properties such as SOM. © 2020, by the authors.","Agricultural robots; Agriculture; Decision trees; Environmental impact; Forecasting; Remote sensing; Soils; Zoning; Agricultural fields; Agricultural system; Field management; Prediction accuracy; Random forest algorithm; Soil carbon sequestration; Soil organic matters; Spatial and temporal resolutions; Soil surveys","Copernicus mission; Machine learning; Multi-spectral imagery; PH; Precision agriculture; Random forest; Sentinel; Soil clay content; Soil organic matter; Soil property prediction; Synthetic aperture radar imagery","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85084264499"
"Amisse C.; Jijon-Palma M.E.; Centeno J.A.S.","Amisse, C. (57219194048); Jijon-Palma, M.E. (57204977729); Centeno, J.A.S. (12752460700)","57219194048; 57204977729; 12752460700","Mapping Extension and Magnitude of Changes Induced by Cyclone Idai with Multi-Temporal Landsat and Sar Images","2020","2020 IEEE Latin American GRSS and ISPRS Remote Sensing Conference, LAGIRS 2020 - Proceedings","","","9165657","574","578","4","10.1109/LAGIRS48042.2020.9165657","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091678345&doi=10.1109%2fLAGIRS48042.2020.9165657&partnerID=40&md5=b6068f38982d51f33208f60572d3cf1a","In this paper it is described a study case of a rapid assessment of change detections for post-cyclone Idai vegetated damage and flood extension estimation by fusion of multi-temporal Landsat and sentinel-1 SAR images. For automated change detection, after disasters, many algorithms have been proposed. To visualize the changes induced by cyclone we tested and compared two automated change detection techniques namely: Principal Components Analysis (PCA), Normalized Difference Vegetation Index (NDVI) and image segmentation. With the image segmentation of multispectral and SAR images, it was possible to visualize the extension of the wet area. For this specific application, PCA was identified as the optimal change detection indicator than NDVI. This study suggested that image segmentation, principal components analysis, and normalized difference vegetation index can be used for change detection of surface water due to flood and disasters especially in prone countries like Mozambique.  © 2020 IEEE.","Damage detection; Disasters; Floods; Image analysis; Image segmentation; Remote sensing; Space-based radar; Storms; Surface waters; Synthetic aperture radar; Vegetation; Change detection; Multi-spectral; Multi-temporal; Normalized difference vegetation index; Principal components analysis; Rapid assessment; SAR Images; Sentinel-1; Radar imaging","Change Detection; Cyclone IDAI; Landsat; Mozambique; SAR","Conference paper","Final","","Scopus","2-s2.0-85091678345"
"Demarez V.; Helen F.; Marais-Sicre C.; Baup F.","Demarez, Valérie (6601953572); Helen, Florian (57195039477); Marais-Sicre, Claire (36659511900); Baup, Frédéric (16678672300)","6601953572; 57195039477; 36659511900; 16678672300","In-season mapping of irrigated crops using Landsat 8 and Sentinel-1 time series","2019","Remote Sensing","11","2","118","","","","10.3390/rs11020118","50","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060670633&doi=10.3390%2frs11020118&partnerID=40&md5=12fe26f6dd9a6de35d48dcbf54183496","Numerous studies have reported the use of multi-spectral and multi-temporal remote sensing images to map irrigated crops. Such maps are useful for water management. The recent availability of optical and radar image time series such as the Sentinel data offers new opportunities to map land cover with high spatial and temporal resolutions. Early identification of irrigated crops is of major importance for irrigation scheduling, but the cloud coverage might significantly reduce the number of available optical images, making crop identification difficult. SAR image time series such as those provided by Sentinel-1 offer the possibility of improving early crop mapping. This paper studies the impact of the Sentinel-1 images when used jointly with optical imagery (Landsat8) and a digital elevation model of the Shuttle Radar Topography Mission (SRTM). The study site is located in a temperate zone (southwest France) with irrigated maize crops. The classifier used is the Random Forest. The combined use of the different data (radar, optical, and SRTM) improves the early classifications of the irrigated crops (k = 0.89) compared to classifications obtained using each type of data separately (k = 0.84). The use of the DEM is significant for the early stages but becomes useless once crops have reached their full development. In conclusion, compared to a ""full optical"" approach, the ""combined"" method is more robust over time as radar images permit cloudy conditions to be overcome. © 2019 by the authors.","Crops; Decision trees; Geometrical optics; Image enhancement; Radar imaging; Remote sensing; Space-based radar; Surveying; Synthetic aperture radar; Time series; Tracking radar; Water management; Crop mapping; Irrigated crops; LANDSAT; Random forests; Satellite images; Sentinel-2; Mapping","Irrigated crops; Landsat-8; Random Forest; Satellite image time series; Seasonal crop mapping; Sentinel-2","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85060670633"
"Lee J.; Kim W.; Im J.; Kwon C.; Kim S.","Lee, Jaese (57216949164); Kim, Woohyeok (57223918651); Im, Jungho (9036557400); Kwon, Chunguen (57211242867); Kim, Sungyong (53866721300)","57216949164; 57223918651; 9036557400; 57211242867; 53866721300","Detection of Forest Fire Damage from Sentinel-1 SAR Data through the Synergistic Use of Principal Component Analysis and K-means Clustering; [Sentinel-1 SAR K-means Clustering]","2021","Korean Journal of Remote Sensing","37","5","","1373","1387","14","10.7780/kjrs.2021.37.5.3.4","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120415643&doi=10.7780%2fkjrs.2021.37.5.3.4&partnerID=40&md5=933632b0f37cfd1fd89e748a1852d206","Forest fire poses a significant threat to the environment and society, affecting carbon cycle and surface energy balance, and resulting in socioeconomic losses. Widely used multi-spectral satellite image-based approaches for burned area detection have a problem in that they do not work under cloudy conditions. Therefore, in this study, Sentinel-1 Synthetic Aperture Radar (SAR) data from Europe Space Agency, which can be collected in all weather conditions, were used to identify forest fire damaged area based on a series of processes including Principal Component Analysis (PCA) and K-means clustering. Four forest fire cases, which occurred in Gangneung·Donghae and Goseong·Sokcho in Gangwon-do of South Korea and two areas in North Korea on April 4, 2019, were examined. The estimated burned areas were evaluated using fire reference data provided by the National Institute of Forest Science (NIFOS) for two forest fire cases in South Korea, and differenced normalized burn ratio (dNBR) for all four cases. The average accuracy using the NIFOS reference data was 86% for the Gangneung·Donghae and Goseong·Sokcho fires. Evaluation using dNBR showed an average accuracy of 84% for all four forest fire cases. It was also confirmed that the stronger the burned intensity, the higher detection the accuracy, and vice versa. Given the advantage of SAR remote sensing, the proposed statistical processing and K-means clustering-based approach can be used to quickly identify forest fire damaged area across the Korean Peninsula, where a cloud cover rate is high and small-scale forest fires frequently occur. © 2020 National Chengchi University. All rights reserved.","","DNBR; Forest fire damaged area; K-means clustering; PCA; SAR","Article","Final","","Scopus","2-s2.0-85120415643"
"Petrushevsky N.; Manzoni M.; Monti-Guarnieri A.","Petrushevsky, Naomi (57275053800); Manzoni, Marco (57202783363); Monti-Guarnieri, Andrea (57217210945)","57275053800; 57202783363; 57217210945","Fast urban land cover mapping exploiting sentinel-1 and sentinel-2 data","2022","Remote Sensing","14","1","36","","","","10.3390/rs14010036","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121739600&doi=10.3390%2frs14010036&partnerID=40&md5=23a061da418d9ff241eae9f985bed2c4","The rapid change and expansion of human settlements raise the need for precise remote-sensing monitoring tools. While some Land Cover (LC) maps are publicly available, the knowledge of the up-to-date urban extent for a specific instance in time is often missing. The lack of a relevant urban mask, especially in developing countries, increases the burden on Earth Observation (EO) data users or requires them to rely on time-consuming manual classification. This paper explores fast and effective exploitation of Sentinel-1 (S1) and Sentinel-2 (S2) data for the generation of urban LC, which can be frequently updated. The method is based on an Object-Based Image Analysis (OBIA), where one Multi-Spectral (MS) image is used to define clusters of similar pixels through super-pixel segmentation. A short stack (<2 months) of Synthetic Aperture Radar (SAR) data is then employed to classify the clusters, exploiting the unique characteristics of the radio backscatter from human-made targets. The repeated illumination and acquisition geometry allows defining robust features based on amplitude, coherence, and polarimetry. Data from ascending and descending orbits are combined to overcome distortions and decrease sensitivity to the orientation of structures. Finally, an unsupervised Machine Learning (ML) model is used to separate the signature of urban targets in a mixed environment. The method was validated in two sites in Portugal, with diverse types of LC and complex topography. Comparative analysis was performed with two state-of-the-art high-resolution solutions, which require long sensing periods, indicating significant agreement between the methods (averaged accuracy of around 90%). © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Data fusion; Developing countries; Image segmentation; Machine learning; Orbits; Photomapping; Radar imaging; Remote sensing; Topography; Data users; Earth observation data; Human settlements; Land cover maps; Monitoring tools; Multi-spectral; Remote sensing monitoring; Sentinel-1; Urban classification; Urban land cover mappings; Synthetic aperture radar","Data fusion; Machine-learning; Multi-spectral; Synthetic aperture radar; Urban classification","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85121739600"
"Fu B.; Xie S.; He H.; Zuo P.; Sun J.; Liu L.; Huang L.; Fan D.; Gao E.","Fu, Bolin (57218665909); Xie, Shuyu (57222315790); He, Hongchang (57216353044); Zuo, Pingping (57223162393); Sun, Jun (57243603800); Liu, Lilong (55839579500); Huang, Liangke (55839763400); Fan, Donglin (57216356487); Gao, Ertao (57209529103)","57218665909; 57222315790; 57216353044; 57223162393; 57243603800; 55839579500; 55839763400; 57216356487; 57209529103","Synergy of multi-temporal polarimetric SAR and optical image satellite for mapping of marsh vegetation using object-based random forest algorithm","2021","Ecological Indicators","131","","108173","","","","10.1016/j.ecolind.2021.108173","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114124942&doi=10.1016%2fj.ecolind.2021.108173&partnerID=40&md5=1f83f20791b362c30ec27ffb43d809a0","The accurate classification of marsh vegetation is an important prerequisite for wetland management and protection. In this study, the Honghe National Nature Reserve was used as the research area. The VV and VH polarized backscattering coefficients of Sentinel-1B, the polarimetric decomposition parameters of Sentinel-1B, and Sentinel-2A multi-spectral images from June and September were selected to construct 18 multi-dimensional data sets. A highly correlated variable elimination algorithm, a recursive feature elimination variable selection algorithm (RFE-RF), and an optimized random forest algorithm (RF) were used to construct a marsh vegetation identification model. In this study, we searched for an RF model to achieve the accurate classification of marsh vegetation and find the best feature for identifying various types of vegetation. Additionally, the applicability of different optimized RF models to the task of the identification of wetland vegetation and the stability of the identification of marsh vegetation using different classification models were quantitatively analyzed. The results show the following: (1) RFE-RF variable selection and RF parameter optimization can reduce the data dimensionality, improve the accuracy and stability of the wetland vegetation classification model, and achieve a training accuracy of up to 85.39%. (2) The RF model integrating multi-spectral data, backscattering coefficients, and polarimetric decomposition parameters for June and September can obtain the highest overall accuracy (91.16%), and the model has the strongest applicability. (3) The importance of multi-spectral variables in wetland vegetation classification is higher than that of backscattering coefficients and polarimetric decomposition parameters. The visible bands and vegetation index are the most important variables, while the cross-polarized backscattering coefficient (Mean_VH), polarimetric decomposition eigenvalue (Mean_l1, Mean_l2), and calculated eigenvalues of the matrix (Mean_lambda) are the backscattering coefficient features and polarimetric decomposition parameters with the highest contributions. (4) The modified normalized difference water index in June (MNDWI_ Jun), blue band in September (Mean_B_Sep), location feature pixel coordinates (Y_Max_Pxl), and ratio vegetation index in September (RVI_Sep) have the highest contribution to the identification and classification of deep-water marsh vegetation, shallow-water marsh vegetation, forest, and shrubs, respectively. (5) The identification of forest is the strongest, and the classification accuracy for shrubs and deep-water marsh vegetation is greatly affected by the combination of time phase and data sources. © 2021","China; Heilongjiang; Honghe Nature Reserve; Decision trees; Eigenvalues and eigenfunctions; Geometrical optics; Image segmentation; Mapping; Parameter estimation; Remote sensing; Spectroscopy; Synthetic aperture radar; Wetlands; Algorithm model; Backscattering coefficients; Marsh vegetation; Marsh vegetation classification; Multi-scale inheritance segmentation; Polarimetric decomposition; Polarimetric decomposition parameter; Random forest algorithm; Variables selections; Wetland vegetation; algorithm; eigenvalue; forest; image classification; mapping method; marsh; Sentinel; synthetic aperture radar; vegetation classification; vegetation index; vegetation mapping; wetland management; Backscattering","Backscattering coefficient; Marsh vegetation classification; Multi-scale inheritance segmentation; Polarimetric decomposition parameters; Random forest algorithm; Variable selection","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85114124942"
"Konapala G.; Kumar S.V.; Khalique Ahmad S.","Konapala, Goutam (57190068026); Kumar, Sujay V. (56122626400); Khalique Ahmad, Shahryar (57233503900)","57190068026; 56122626400; 57233503900","Exploring Sentinel-1 and Sentinel-2 diversity for flood inundation mapping using deep learning","2021","ISPRS Journal of Photogrammetry and Remote Sensing","180","","","163","173","10","10.1016/j.isprsjprs.2021.08.016","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113612780&doi=10.1016%2fj.isprsjprs.2021.08.016&partnerID=40&md5=3f0aaa92da8e0341c28c9cb132f4ab37","Identification of flood water extent from satellite images has historically relied on either synthetic aperture radar (SAR) or multi-spectral (MS) imagery. MS sensors are limited to cloud free conditions, whereas SAR imagery is plagued by noise-like speckle. Prior studies that use combinations of MS and SAR data to overcome individual limitations of these sensors have not fully examined sensitivity of flood mapping performance to different combinations of SAR and MS derived spectral indices or band transformations in color space. This study explores the use of diverse bands of Sentinel 2 (S2) through well-established water indices and Sentinel 1 (S1) derived SAR imagery along with their combinations to assess their capability for generating accurate flood inundation maps. The robustness in performance of S-1 and S-2 band combinations was evaluated using 446 hand labeled flood inundation images spanning across 11 flood events from Sen1Floods11 dataset which are highly diverse in terms of land cover as well as location. A modified K-fold cross validation approach is used to evaluate the performance of 32 combinations of S1 and S2 bands using a fully connected deep convolutional neural network known as U-Net. Our results indicated that usage of elevation information has improved the capability of S1 imagery to produce more accurate flood inundation maps. Compared to a median F1 score of 0.62 when using only S1 bands, the combined use of S1 and elevation information led to an improved median F1 score of 0.73. Water extraction indices based on S2 bands have a statistically significant superior performance in comparison to S1. Among all the band combinations, HSV (Hue, Saturation, Value) transformation of S2 bands provides a median F1 score of 0.9, outperforming the commonly used water spectral indices owing to HSV's transformation's superior contrast distinguishing abilities. Additionally, U-Net algorithm was able to learn the relationship between raw S2 based water extraction indices and their corresponding raw S2 bands, but not of HSV owing to relatively complex computation involved in the latter. Results of the paper establishes important benchmarks for the extension of S1 and S2 data-based flood inundation mapping efforts over large spatial extents. © 2021 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Deep neural networks; Extraction; Floods; Image enhancement; Image segmentation; Photomapping; Radar imaging; Remote sensing; Satellite imagery; Synthetic aperture radar; Deep learning; F1 scores; Flood inundation mappings; Inundation maps; Multispectral; Performance; Segmentation; Sentinel-1; Spectral indices; Synthetic Aperture Radar Imagery; flood control; machine learning; mapping method; satellite imagery; Sentinel; synthetic aperture radar; Flood control","Deep learning; Flood inundation mapping; Hydrology; Segmentation","Article","Final","","Scopus","2-s2.0-85113612780"
"Farhana Ahmad S.S.; Hazrina Idris N.","Farhana Ahmad, Siti Sarah (57697972300); Hazrina Idris, Nurul (57210910980)","57697972300; 57210910980","Oil Spill Impacts on Mangrove Forest from Satellite Remote Sensing","2021","International Conference on Space Science and Communication, IconSpace","2021-November","","","60","64","4","10.1109/IconSpace53224.2021.9768774","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130245326&doi=10.1109%2fIconSpace53224.2021.9768774&partnerID=40&md5=eecd9a8417146f8d29fd52ab407fb8c4","The mangrove forest has been continuously threatened by oil spills occurring on the sea surfaces. The oil spills pose and cause severe and long-term effect havoc on mangrove forests that sustain them. Previous research has found that satellite remote sensing technologies are one of the most effective techniques to detect oil spills and assess the health of mangrove forests in contaminated areas. This study utilized the Synthetic-Aperture Radar (SAR) images from dualpolarized Sentinel-1 and Multi-Spectral Instrument (MSI) from Sentinel-2 to study the impact of oil spills on Mangrove Forest in Pantai Cermin, Negeri Sembilan. The Random Forest classification was used to detect the oil spill areas, while vegetation indices were used to assess the impact of oil pollution on mangrove forests in the early stages. Analysis from Sentinel1 imagery shows that the oil spill could be accurately detected using the Random Forest classifer with accuracy of 76%. Spectral indices: the normalized difference vegetation index (NDVI) was explored and evaluated to study the health of mangrove forest after the oil spills event. It is found that the oil spills have caused physical suffocation as well as toxicological effects to the mangrove forests. © 2021 IEEE.","Decision trees; Forestry; Oil spills; Synthetic aperture radar; Vegetation; Contaminated areas; Long-term effects; Mangrove forest; Remote sensing technology; Remote-sensing; Satellite remote sensing; Sea surfaces; Sentinel 2; Sentinel-1; Synthetic aperture radar images; Remote sensing","oil spill; remote sensing; sentinel 1; sentinel 2","Conference paper","Final","","Scopus","2-s2.0-85130245326"
"De Luca G.; M. N. Silva J.; Di Fazio S.; Modica G.","De Luca, Giandomenico (57209178035); M. N. Silva, João (57411604800); Di Fazio, Salvatore (24586867400); Modica, Giuseppe (42962067500)","57209178035; 57411604800; 24586867400; 42962067500","Integrated use of Sentinel-1 and Sentinel-2 data and open-source machine learning algorithms for land cover mapping in a Mediterranean region","2022","European Journal of Remote Sensing","55","1","","52","70","18","10.1080/22797254.2021.2018667","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122808100&doi=10.1080%2f22797254.2021.2018667&partnerID=40&md5=f5690d36434317965708030c30187d5d","This paper aims to develop a supervised classification integrating synthetic aperture radar (SAR) Sentinel-1 (S1) and optical Sentinel-2 (S2) data for land use/land cover (LULC) mapping in a heterogeneous Mediterranean forest area. The time-series of each SAR and optical bands, three optical indices (normalized difference vegetation index, NDVI; normalized burn ratio, NBR; normalized difference red-edge index, NDRE), and two SAR indices (radar vegetation index, RVI; radar forest degradation index, RFDI), constituted the dataset. The coherence information from SAR interferometry (InSAR) analysis and three optical biophysical variables (leaf area index, LAI; fraction of green vegetation cover, fCOVER; fraction of absorbed photosynthetically active radiation, fAPAR) of the single final month of the time-series were added to exploit their correlation with the canopy structure and improve the classification. The random forests (RF) algorithm was used to train and classify the final dataset, and an exhaustive grid search analysis was applied to set the optimal hyperparameters. The overall accuracy reached an F-scoreM of 90.33% and the integration of SAR improved it by 2.53% compared to that obtained using only optical data. The whole process was performed using freely available data and open-source software and libraries (SNAP, Google Earth Engine, Scikit-Learn) executed in Python-script language. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Mediterranean Region; Classification (of information); Decision trees; Engines; Forestry; Interferometry; Land use; Learning algorithms; Machine learning; Mapping; Open source software; Time series analysis; Vegetation; Biophysical indicators; Google earth engine; Google earths; Interferometric coherence; Multi-spectral; Sentinel-1; Synthetic aperture radar; Synthetic aperture radar and multispectral time-series analyse; Synthetic aperture radar interferometry; Synthetic aperture radar interferometry (inSAR); accuracy assessment; algorithm; biophysics; land cover; mapping; photosynthetically active radiation; radar interferometry; satellite data; Sentinel; software; supervised classification; synthetic aperture radar; time series analysis; Synthetic aperture radar","biophysical indicators; Google Earth Engine (GEE); interferometric coherence; SAR and multispectral time-series analysis; SAR interferometry (inSAR); Synthetic aperture radar (SAR)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85122808100"
"Prashant P.; Michael A.","Prashant, P. (57734618500); Michael, A. (57219653115)","57734618500; 57219653115","Application of geospatial technology for high-resolution mapping and monitoring of crop patterns in support of crop insurance for the rain-fed regions of India","2020","Proceedings of SPIE - The International Society for Optical Engineering","11528","","1152804","","","","10.1117/12.2572393","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094571246&doi=10.1117%2f12.2572393&partnerID=40&md5=7f258df144c45f7a561dc360bb44c021","Spectral reflectance and backscattering's of remotely-sensed data presents significant details of different objects on the Earth's surface in numerous applications of space technology. In this study, satellite datasets such as Sentinel-1 i.e. synthetic aperture radar (SAR) and Sentinel-2 satellite datasets i.e. multispectral data is used in order to effectively classify crop patterns of rainfed regions of India. The study areas have been selected in Jhansi district of Uttar Pradesh, Buldhana district of Maharashtra and Ballari district of Karnataka. These three (3) selected districts contains rainfed and irrigated agricultural lands. In the initial stage baseline map of cropland has been prepared by the following concepts; a baseline map is a map including the total cropland area i.e. Rabi and Kharif and non-cropped area's i.e. man-made (infrastructures + urban), permanent water, permanent vegetation (forest), and other land cover's depending on the area (for instance wetlands, etc.). This is generated by using annual temporal descriptors (TD). In the next, Sentinel-2 MSI high-resolution satellite data has been further used for crop pattern map derived by applying the supervised classification following the machine learning algorithms (MLA) techniques. The accuracy level of crop pattern map of Ballari district is 84.04%, Jhansi district is 89.3%, and of Buldhana district is 83.09%. The total crop land area in Ballari district is 0.582 million ha, with the total crop types covered area is cotton 32%, groundnut 23%, maize 29%, pearl millet 10% and paddy 6%. The total cropland area in Jhansi district is 0.507 million ha, with the total crop types covered area is black gram 65%, paddy 10%, groundnut 17%, and peppermint 8%. The total cropland area in Buldhana district is 0.686 million ha, with the total crop types covered area is cotton 24%, maize 7%, pigeon pea 16%, sorghum 25% and soybean 28%, respectively.  © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Agricultural robots; Classification (of information); Cotton; Earth (planet); Ecosystems; Hydrology; Learning algorithms; Remote sensing; Satellites; Space optics; Space-based radar; Supervised learning; Synthetic aperture radar; Geospatial technology; High resolution satellite data; High-resolution mapping; Multi-spectral data; Remotely sensed data; Space technologies; Spectral reflectances; Supervised classification; Crops","Crop pattern; Rainfed; Sentinel 2 optical; Sentinel1-SAR","Conference paper","Final","","Scopus","2-s2.0-85094571246"
"Peng J.; Su Y.; Xue X.; Song D.; Xue X.","Peng, Jinxi (56039598000); Su, Yuanqi (14036527100); Xue, Xiaorong (12781780100); Song, Donghong (57211081243); Xue, Xiaoyong (57211082928)","56039598000; 14036527100; 12781780100; 57211081243; 57211082928","A parallel segmentation after classification algorithm of multi-spectral image of k-means of deep learning and panchromatic based on wavelet","2019","Proceedings of SPIE - The International Society for Optical Engineering","11179","","111791P","","","","10.1117/12.2539657","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072615408&doi=10.1117%2f12.2539657&partnerID=40&md5=6858c0ec8c482aa6db8cd094be7a513c","[Purpose]To take the advantages of a variety of remote sensing data, the application of remote sensing image classification is a very important choice.Remote sensing image classification is large in computing capacity and time-consuming, and with the development of modern remote sensing technology, the amount of various remote sensing data obtained is getting larger and larger,the issue of how to fuse remote sensing image quickly and accurately and of getting useful information is becoming more and more urgent especially in some remote sensing applications such as disaster monitoring, prevention and relief, etc.In this paper, in order to fuse remote sensing image quickly and accurately, a parallel classification algorithm of multi-spectral image and panchromatic image based on wavelet transform is proposed.[Methods]In the method, based on parallel computing, the low-frequency components of wavelet decomposition are fused with the classification rule based on the feature matching, and the high-frequency components of wavelet decomposition are fused with the classification rule based on the sub-region variance. Then the low-frequency components and the high-frequency components after classification are processed with the inverse wavelet transform, and the fused image is obtained. According to the statistical characteristics of SAR images and the semantics of fuzzy neural networks analysis, an efficient image segmentation method based on Deep Learning Semantic analysis and wavelet transform is proposed to achieve precision of classification.[ Results] The experiment results show that the proposed method can get better classification results and faster computing speed for multi-spectral image and panchromatic image. Originality. In the proposed classification algorithm of multi-spectral image and panchromatic image, wavelet transform and different proper classification rules for low-frequency components and high frequency components of wavelet decomposition are used. To get a high speed, parallel computing is also taken in some complex parts of the proposed classification algorithm. Thus, better classification results and faster computing speed are obtained. [Conclusions] Practical value. The experiments have proved that the proposed algorithm can quickly get good classification results for remote sensing images, and it is useful in remote sensing applications in some aspects such as disaster monitoring, prevention and relief, Hybrid parallel Computing method for tasks and data (Pixels) etc. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Classification (of information); Deep learning; Disaster prevention; Electric arcs; Emergency services; Fuzzy neural networks; Image compression; Image segmentation; Inverse problems; K-means clustering; Parallel processing systems; Remote sensing; Semantics; Spectroscopy; Synthetic aperture radar; Wavelet decomposition; Wavelet transforms; Data clustering; High frequency components; Inverse wavelet transforms; Multispectral images; Panchromatic images; Remote sensing applications; Remote sensing image classification; Statistical characteristics; Image classification","Data clustering; Image classification; Multi-spectral image; Panchromatic image; Parallel computing; Remote sensing; Wavelet transform","Conference paper","Final","","Scopus","2-s2.0-85072615408"
"Elmoussaoui E.; Moumni A.; Lahrouni A.","Elmoussaoui, E. (57398208600); Moumni, A. (57214067375); Lahrouni, A. (6506465558)","57398208600; 57214067375; 6506465558","CARTOGRAPHY of MOROCCAN ARGAN TREE USING COMBINED OPTICAL and SAR IMAGERY INTEGRATED with DIGITAL ELEVATION MODEL","2021","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","46","4/W5-2021","","211","217","6","10.5194/isprs-Archives-XLVI-4-W5-2021-211-2021","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122316178&doi=10.5194%2fisprs-Archives-XLVI-4-W5-2021-211-2021&partnerID=40&md5=fff2054e45348b7c5f95aed275891783","Forest tree species mapping became easier due to the global availability of high spatio-Temporal resolution images acquired from multiple sensors. Such data can lead to better forest resources management. Machine-learning pixel based analysis was performed to multi-spectral Sentinel-2 and Synthetic Aperture Radar Sentinel-1 time series integrated with Digital Elevation Model acquired over Argan forest of Essaouira province, Morocco. The argan tree constitutes a fundamental resource for the populations of this arid area of Morocco. This research aims to use the potential of the combination of multi-sensor data to detect, map and identify argan tree from other forest species using three Machine Learning algorithms: Support Vector Machine (SVM), Maximum Likelihood (ML) and Artificial Neural Networks (ANN). The exploited datasets included Sentinel-1 (S1), Sentinel-2 (S2) time series, Shuttle Radar Topographic Missing Digital Elevation Model (DEM) layer and Ground truth data. We tested several sets of scenarios, including single S1 derived features, single S2 time series and combined S1 and S2 derived layers with DEM scene acquisition. The best results (overall accuracy OA and Kappa coefficient K) obtained from time series of optical data (NDVI): OA Combining double low line 86.87%, K Combining double low line 0.84, from time series of SAR data (VV+VH/VV): OA Combining double low line 45.90%, K Combining double low line 0.36, from the combination of optical and SAR time series (NDVI+VH+DEM): OA Combining double low line 93.01%, K Combining double low line 0.914, and from the fusion of optical time series and DEM layer (NDVI+DEM): OA Combining double low line 93.25%, K Combining double low line 0.91. These results indicate that single-sensor (S2) integrated with the DEM layer led us to obtain the highest classification results.  © Author(s) 2021. CC BY 4.0 License.","Digital instruments; Forestry; Geomorphology; Information management; Learning algorithms; Mapping; Maps; Maximum likelihood; Neural networks; Radar imaging; Remote sensing; Support vector machines; Surveying; Synthetic aperture radar; Time series; Time series analysis; Argan tree (arganium spinosa (L) skeel) mapping; Digital elevation model; Images classification; Morocco.; Optical and synthetic aperture radar  data; Optical-; Radar data; Sentinel-1; Times series; Tree species; Image classification","Argan tree (Argania spinosa (L.) Skeels) mapping; image Classification; Morocco.; Optical and Synthetic Aperture Radar (SAR) data","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85122316178"
"Zhang S.; Zhang Y.; Chou Y.; Wang Z.; Shi Y.; Sun Z.","Zhang, Shuchun (8321575700); Zhang, Yun (56097923300); Chou, Yonabin (57226379460); Wang, Ziheng (57221806189); Shi, Yifu (57226378587); Sun, Zhenyu (57226385910)","8321575700; 56097923300; 57226379460; 57221806189; 57226378587; 57226385910","Analysis of the Multispectral and SAR Image","2021","2021 IEEE 6th International Conference on Computer and Communication Systems, ICCCS 2021","","","9449213","312","315","3","10.1109/ICCCS52626.2021.9449213","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113318904&doi=10.1109%2fICCCS52626.2021.9449213&partnerID=40&md5=3f27d037003422d427bbed8acb67490c","The SAR image and the multispectral image are both used for dynamic monitoring, mineral resources investigation, urban and rural monitoring and evaluation, traffic network exploration, forest resources investigation, desertification monitoring, and so on. The multi-spectral and SAR image fusion to improve the classify quality is discussed in this paper, compared the common fusion algorithms of the SAR image and multi spectral images, that is standard color transform (Brovey) method, phase recovery (Gram-Schmidt) method and color space transform (HSV) method, principal component transformation super resolution (PCA) method and Bias method (Pansharp), by which the fused image is more relative with the multi-spectral and SAR. © 2021 IEEE.","Color; Image enhancement; Image fusion; Mineral exploration; Mineral resources; Spectroscopy; Synthetic aperture radar; Color space transform; Desertification monitoring; Dynamic monitoring; Fusion algorithms; Monitoring and evaluations; Multispectral images; Principal component transformations; Traffic networks; Radar imaging","image fusion; multi spectral; SAR","Conference paper","Final","","Scopus","2-s2.0-85113318904"
"Tziolas N.; Tsakiridis N.; Ben-Dor E.; Theocharis J.; Zalidis G.","Tziolas, Nikolaos (57190677799); Tsakiridis, Nikolaos (57189582972); Ben-Dor, Eyal (7003384607); Theocharis, John (7003978405); Zalidis, George (6701355494)","57190677799; 57189582972; 7003384607; 7003978405; 6701355494","Employing a multi-input deep convolutional neural network to derive soil clay content from a synergy of multi-temporal optical and radar imagery data","2020","Remote Sensing","12","9","1389","","","","10.3390/RS12091389","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085257255&doi=10.3390%2fRS12091389&partnerID=40&md5=96dcc24c44815be46f1ad324136dd55a","Earth observation (EO) has an immense potential as being an enabling tool formapping spatial characteristics of the topsoil layer. Recently, deep learning based algorithms and cloud computing infrastructure have become available with a great potential to revolutionize the processing of EO data. This paper aims to present a novel EO-based soil monitoring approach leveraging open-access Copernicus Sentinel data and Google Earth Engine platform. Building on key results from existing data mining approaches to extract bare soil reflectance values the current study delivers valuable insights on the synergistic use of open access optical and radar images. The proposed framework is driven by the need to eliminate the influence of ambient factors and evaluate the efficiency of a convolutional neural network (CNN) to effectively combine the complimentary information contained in the pool of both optical and radar spectral information and those form auxiliary geographical coordinates mainly for soil. We developed and calibrated our multi-input CNN model based on soil samples (calibration = 80% and validation 20%) of the LUCAS database and then applied this approach to predict soil clay content. A promising prediction performance (R2 = 0.60, ratio of performance to the interquartile range (RPIQ) = 2.02, n = 6136) was achieved by the inclusion of both types (synthetic aperture radar (SAR) and laboratory visible near infrared-short wave infrared (VNIR-SWIR) multispectral) of observations using the CNN model, demonstrating an improvement of more than 5.5% in RMSE using the multi-year median optical composite and current state-of-the-art non linear machine learning methods such as random forest (RF; R2 = 0.55, RPIQ = 1.91, n = 6136) and artificial neural network (ANN; R2 = 0.44, RPIQ = 1.71, n = 6136). Moreover, we examined post-hoc techniques to interpret the CNN model and thus acquire an understanding of the relationships between spectral information and the soil target identified by the model. Looking to the future, the proposed approach can be adopted on the forthcoming hyperspectral orbital sensors to expand the current capabilities of the EO component by estimating more soil attributes with higher predictive performance. © 2020 by the authors.","Convolution; Convolutional neural networks; Data handling; Data mining; Decision trees; Deep learning; Deep neural networks; Infrared devices; Infrared radiation; Learning systems; Orbits; Reflection; Soils; Synthetic aperture radar; Tracking radar; Cloud computing infrastructures; Geographical coordinates; Inter quartile ranges; Learning-based algorithms; Prediction performance; Predictive performance; Spatial characteristics; Visible near-infrared; Radar imaging","Copernicus data; Deep learning; Earth observation; Hyper and multi spectral remote sensing; SAR data; Soil texture mapping; Spectral signatures","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85085257255"
"Kulkarni S.C.; Rege P.P.; Parishwad O.","Kulkarni, Samadhan C. (57204893706); Rege, Priti P. (6701858789); Parishwad, Omkar (56015522800)","57204893706; 6701858789; 56015522800","Hybrid fusion approach for synthetic aperture radar and multispectral imagery for improvement in land use land cover classification","2019","Journal of Applied Remote Sensing","13","3","034516","","","","10.1117/1.JRS.13.034516","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072517280&doi=10.1117%2f1.JRS.13.034516&partnerID=40&md5=a245234cafc0cdcb1ba564f108be4e3a","Multisensor image fusion has gained tremendous significance due to various satellites operating in different parts of the electromagnetic spectrum. We present a hybrid fusion approach to integrate information from synthetic aperture radar (SAR) and multispectral (MS) imagery to improve land use land cover (LULC) classification. The major concern in SAR and optical fusion is the spectral distortion in the fused image, which is significantly less in pansharpening algorithms. The primary objective of our work is to inject unique spatial information from the SAR image into MS images, deriving enhanced data. The proposed approach is based on the integration of principal component analysis and wavelet decomposition to reduce spectral distortion in the fused image. Fused images are evaluated visually and statistically. Results are compared with conventional fusion approaches. In order to explore the effectiveness of the proposed technique, LULC classification is performed on the fused and original data. The LULC classification results are analytically compared with the standard thematic map to derive classification accuracy. A comparative analysis with other approaches conclusively proves that the proposed hybrid approach is superior to conventional approaches. © 2019 Society of Photo-Optical Instrumentation Engineers (SPIE).","Classification (of information); Image analysis; Image classification; Image enhancement; Image fusion; Land use; Maps; Principal component analysis; Remote sensing; Synthetic aperture radar; Tracking radar; Wavelet decomposition; Wavelet transforms; Classification accuracy; Classification results; Conventional approach; Electromagnetic spectra; Land use/ land covers; Multi-spectral imagery; Multisensor image fusion; Synthetic Aperture Radar Imagery; Radar imaging","image fusion; land use land cover classification; multispectral imagery; principal component analysis; synthetic aperture radar imagery; wavelet transform","Article","Final","","Scopus","2-s2.0-85072517280"
"Zahriban Hesari M.; Buono A.; Nunziata F.; Aulicino G.; Migliaccio M.","Zahriban Hesari, Mozhgan (57216963907); Buono, Andrea (57188716157); Nunziata, Ferdinando (35613962200); Aulicino, Giuseppe (55857208900); Migliaccio, Maurizio (23012466600)","57216963907; 57188716157; 35613962200; 55857208900; 23012466600","Multi-Polarisation C-Band SAR Imagery to Estimate the Recent Dynamics of the d’Iberville Glacier","2022","Remote Sensing","14","22","5758","","","","10.3390/rs14225758","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144421612&doi=10.3390%2frs14225758&partnerID=40&md5=d1c6bd58f62b181f0f2d8d6a98aa146b","To monitor polar regions is of paramount importance for climatological studies. Climate change due to anthropogenic activities is inducing global warming that, for example, has resulted in glacier melting. This has had a significant impact on sea levels and ocean circulation. In this study, the temporal trend of the marine-terminated d’Iberville glacier (Ellesmere Island, Canada) is analysed using C-band synthetic aperture radar satellite imagery collected by the Radarsat-2 and Sentinel-1 missions. The data set consists of a time series of 10 synthetic aperture radar data collected from 2010 to 2022 in dual-polarimetric imaging mode, where a horizontally polarised electromagnetic wave was transmitted. An automatic approach based on a global threshold constant false alarm rate method is applied to the single- and dual-polarisation features, namely the HH-polarised normalised radar cross-section and a combination of the HH- and HV-polarised scattering amplitudes, with the aim of extracting the ice front of the glacier and, therefore, estimating its behaviour over time. Independent collocated satellite optical imagery from the Sentinel-2 multi-spectral instrument is also considered, where available, to support the experimental outcomes. The experimental results show that (1) the HH-polarised normalised radar cross-section achieved better performance with respect to the dual-polarised feature, especially under the most challenging case of a sea-ice infested sea surface; (2) when the HH-polarised normalised radar cross-section was considered, the ice front extraction methodology provided a satisfactory accuracy, i.e., a root mean square error spanning from about 1.1 pixels to 3.4 pixels, depending on the sea-surface conditions; and (3) the d’Iberville glacier exhibited, during the study period, a significant retreat whose average surface velocity was 160 m per year, resulting in a net ice area loss of 2.2 km2 (0.18 km2 per year). These outcomes demonstrate that the d’Iberville glacier is behaving as most of the marine-terminated glaciers in the study area while experiencing a larger ice loss. © 2022 by the authors.","Electromagnetic waves; Extraction; Global warming; Mean square error; Pixels; Polarization; Radar cross section; Radar imaging; Satellite imagery; Sea ice; Sea level; Space-based radar; Surface waters; Anthropogenic activity; C-band SAR; C-bands; Canada; D’iberville glacier; Ice front extraction; Multi-polarization; Normalized radar cross section; Polar Regions; SAR imagery; Synthetic aperture radar","C-band SAR; Canada; d’Iberville glacier; ice front extraction; polarisation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85144421612"
"Philipp M.B.; Levick S.R.","Philipp, Marius B. (57215008212); Levick, Shaun R. (23060739900)","57215008212; 23060739900","Exploring the potential of C-band SAR in contributing to burn severity mapping in tropical savanna","2020","Remote Sensing","12","1","49","","","","10.3390/RS12010049","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079664992&doi=10.3390%2fRS12010049&partnerID=40&md5=df297bd28d4c6f0f993fb3a2afb8d226","The ability to map burn severity and to understand how it varies as a function of time of year and return frequency is an important tool for landscape management and carbon accounting in tropical savannas. Different indices based on optical satellite imagery are typically used for mapping fire scars and for estimating burn severity. However, cloud cover is a major limitation for analyses using optical data over tropical landscapes. To address this pitfall, we explored the suitability of C-band Synthetic Aperture Radar (SAR) data for detecting vegetation response to fire, using experimental fires in northern Australia. Pre-and post-fire results from Sentinel-1 C-band backscatter intensity data were compared to those of optical satellite imagery and were corroborated against structural changes on the ground that we documented through terrestrial laser scanning (TLS). Sentinel-1 C-band backscatter (VH) proved sensitive to the structural changes imparted by fire and was correlated with the Normalised Burn Ratio (NBR) derived from Sentinel-2 optical data. Our results suggest that C-band SAR holds potential to inform the mapping of burn severity in savannas, but further research is required over larger spatial scales and across a broader spectrum of fire regime conditions before automated products can be developed. Combining both Sentinel-1 SAR and Sentinel-2 multi-spectral data will likely yield the best results for mapping burn severity under a range of weather conditions. © 2019 by the authors.","Backscattering; Fires; Optical radar; Photomapping; Radar imaging; Satellite imagery; Surveying instruments; Synthetic aperture radar; Tropics; Burn Severity; Landscape management; Multi-spectral data; Optical satellite imagery; Sentinel-1; Sentinel-2; Terrestrial laser scanning; Terrestrial lidars; Space-based radar","Burn severity; Sentinel-1; Sentinel-2; Terrestrial LiDAR","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85079664992"
"Bhattarai R.; Rahimzadeh-Bajgiran P.; Weiskittel A.; Meneghini A.; MacLean D.A.","Bhattarai, Rajeev (57217729994); Rahimzadeh-Bajgiran, Parinaz (23470540100); Weiskittel, Aaron (13806825800); Meneghini, Aaron (57220836180); MacLean, David A. (7202649883)","57217729994; 23470540100; 13806825800; 57220836180; 7202649883","Spruce budworm tree host species distribution and abundance mapping using multi-temporal Sentinel-1 and Sentinel-2 satellite imagery","2021","ISPRS Journal of Photogrammetry and Remote Sensing","172","","","28","40","12","10.1016/j.isprsjprs.2020.11.023","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097713407&doi=10.1016%2fj.isprsjprs.2020.11.023&partnerID=40&md5=353f2a963d527b6d873516edd9ac2ca2","Spruce budworm (Choristoneura fumiferana; SBW) is the most destructive forest pest of northeastern Canada and United States. SBW occurrence as well as the extent and severity of its damage are highly dependent on the characteristics of the forests and the availability of host species namely, spruce (Picea sp.) and balsam fir (Abies balsamea (L.) Mill.). Remote sensing satellite imagery represents a valuable data source for seamless regional-scale mapping of forest composition. This study developed and evaluated new models to map the distribution and abundance of SBW host species at 20 m spatial resolution using Sentinel-1 synthetic aperture radar (SAR) and Sentinel-2 multispectral imagery in combination with several site variables for a total of 191 variables in northern New Brunswick, Canada using the Random Forest (RF) algorithm. We found Sentinel-2 multi-temporal single spectral bands and numerous spectral vegetation indices (SVIs) yielded the classification of SBW host species with an overall accuracy (OA) of 72.6% and kappa coefficient (K) of 0.65. Incorporating Sentinel-1 SAR data with Sentinel-2 variables coupled with elevation, only marginally improved the performance of the model (OA: 73.0% and K: 0.66). The use of Sentinel-1 SAR data with elevation resulted in a reasonable OA of 57.5% and K of 0.47. These spatially explicit up-to-date SBW host species maps are essential for identifying susceptible forests, monitoring SBW defoliation, and minimizing forest losses from insect impacts at landscape scale in the current SBW outbreak in the region. © 2020 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Canada; New Brunswick; Abies balsamea; Choristoneura fumiferana; Hexapoda; Decision trees; Forestry; Radar imaging; Remote sensing; Satellite imagery; Space-based radar; Synthetic aperture radar; Choristoneura fumiferana; Forest compositions; Multi-spectral imagery; Overall accuracies; Remote sensing satellites; Spatially explicit; Species distributions; Spectral vegetation indices; abundance; accuracy assessment; classification; host plant; moth; pest damage; remote sensing; satellite data; satellite imagery; Sentinel; synthetic aperture radar; Population distribution","Choristoneura fumiferana; Random forest; Sentinel-2; Synthetic aperture radar; Tree species","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85097713407"
"Avian M.; Bauer C.; Schlögl M.; Widhalm B.; Gutjahr K.-H.; Paster M.; Hauer C.; Frießenbichler M.; Neureiter A.; Weyss G.; Flödl P.; Seier G.; Sulzer W.","Avian, Michael (8578597300); Bauer, Christian (57196863939); Schlögl, Matthias (40561707800); Widhalm, Barbara (6506176864); Gutjahr, Karl-Heinz (21934060300); Paster, Michael (57216908698); Hauer, Christoph (15845712000); Frießenbichler, Melina (57216909695); Neureiter, Anton (56037832900); Weyss, Gernot (36740612600); Flödl, Peter (56346766500); Seier, Gernot (55544865300); Sulzer, Wolfgang (27067971400)","8578597300; 57196863939; 40561707800; 6506176864; 21934060300; 57216908698; 15845712000; 57216909695; 56037832900; 36740612600; 56346766500; 55544865300; 27067971400","The status of earth observation techniques in monitoring high mountain environments at the example of pasterze glacier, austria: Data, methods, accuracies, processes, and scales","2020","Remote Sensing","12","8","1251","","","","10.3390/RS12081251","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085260899&doi=10.3390%2fRS12081251&partnerID=40&md5=ff7196697e8d2f7ddc0ae4ae192f9738","Earth observation offers a variety of techniques for monitoring and characterizing geomorphic processes in high mountain environments. Terrestrial laserscanning and unmanned aerial vehicles provide very high resolution data with high accuracy. Automatic cameras have become a valuable source of information-mostly in a qualitative manner-in recent years. The availability of satellite data with very high revisiting time has gained momentum through the European Space Agency's Sentinel missions, offering new application potential for Earth observation. This paper reviews the status of recent techniques such as terrestrial laserscanning, remote sensed imagery, and synthetic aperture radar in monitoring high mountain environments with a particular focus on the impact of new platforms such as Sentinel-1 and-2 as well as unmanned aerial vehicles. The study area comprises the high mountain glacial environment at the Pasterze Glacier, Austria. The area is characterized by a highly dynamic geomorphological evolution and by being subject to intensive scientific research as well as long-term monitoring. We primarily evaluate landform classification and process characterization for: (i) the proglacial lake; (ii) icebergs; (iii) the glacier river; (iv) valley-bottom processes; (v) slope processes; and (vi) rock wall processes. We focus on assessing the potential of every single method both in spatial and temporal resolution in characterizing different geomorphic processes. Examples of the individual techniques are evaluated qualitatively and quantitatively in the context of: (i) morphometric analysis; (ii) applicability in high alpine regions; and (iii) comparability of the methods among themselves. The final frame of this article includes considerations on scale dependent process detectability and characterization potentials of these Earth observation methods, along with strengths and limitations in applying these methods in high alpine regions. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Antennas; Earth (planet); Observatories; Patient monitoring; Remote sensing; Sea ice; Space applications; Space-based radar; Synthetic aperture radar; Unmanned aerial vehicles (UAV); Earth observation techniques; Geomorphological evolution; Landform classification; Process characterization; Remote sensed imagery; Spatial and temporal resolutions; Terrestrial laser scanning; Very high resolution datum; Landforms","Cryosphere; Glacier lake evolution; Glacier river; Laserscanning; Multi-spectral satellite data; Rock fall; Slope processes; Synthetic aperture radar; UAV-structure from motion","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85085260899"
"Notti D.; Giordan D.; Caló F.; Pepe A.; Zucca F.; Galve J.P.","Notti, Davide (30767762500); Giordan, Daniele (12785078600); Caló, Fabiana (16052312800); Pepe, Antonio (7003776958); Zucca, Francesco (6603173217); Galve, Jorge Pedro (16309409900)","30767762500; 12785078600; 16052312800; 7003776958; 6603173217; 16309409900","Potential and limitations of open satellite data for flood mapping","2018","Remote Sensing","10","11","1673","","","","10.3390/rs10111673","88","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057088214&doi=10.3390%2frs10111673&partnerID=40&md5=fe6cc58cfdf707802e1d950db6c555d1","Satellite remote sensing is a powerful tool to map flooded areas. In recent years, the availability of free satellite data significantly increased in terms of type and frequency, allowing the production of flood maps at low cost around the world. In this work, we propose a semi-automatic method for flood mapping, based only on free satellite images and open-source software. The proposed methods are suitable to be applied by the community involved in flood hazard management, not necessarily experts in remote sensing processing. As case studies, we selected three flood events that recently occurred in Spain and Italy. Multispectral satellite data acquired by MODIS, Proba-V, Landsat, and Sentinel-2 and synthetic aperture radar (SAR) data collected by Sentinel-1 were used to detect flooded areas using different methodologies (e.g., Modified Normalized Difference Water Index, SAR backscattering variation, and supervised classification). Then, we improved and manually refined the automatic mapping using free ancillary data such as the digital elevation model-based water depth model and available ground truth data. We calculated flood detection performance (flood ratio) for the different datasets by comparing with flood maps made by official river authorities. The results show that it is necessary to consider different factors when selecting the best satellite data. Among these factors, the time of the satellite pass with respect to the flood peak is the most important. With co-flood multispectral images, more than 90% of the flooded area was detected in the 2015 Ebro flood (Spain) case study. With post-flood multispectral data, the flood ratio showed values under 50% a few weeks after the 2016 flood in Po and Tanaro plains (Italy), but it remained useful to map the inundated pattern. The SAR could detect flooding only at the co-flood stage, and the flood ratio showed values below 5% only a few days after the 2016 Po River inundation. Another result of the research was the creation of geomorphology-based inundation maps that matched up to 95% with official flood maps. © 2018 by the authors.","Flood control; Geomorphology; Mapping; Open source software; Open systems; Remote sensing; Satellites; Space-based radar; Synthetic aperture radar; Ebro basin; Flood mapping; Multi-spectral; Multispectral satellite data; Normalized difference water index; Satellite data; Satellite remote sensing; Supervised classification; Floods","Ebro basin; Flood mapping; Free satellite data; Multispectral; Po basin; SAR","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85057088214"
"Prabhakar K.R.; Nukala V.H.; Gubbi J.; Pal A.; Balamuralidhar P.","Prabhakar, K Ram (57189591594); Nukala, Veera Harikrishna (57323973300); Gubbi, Jayavardhana (23090806600); Pal, Arpan (57203638167); Balamuralidhar, P. (16201684400)","57189591594; 57323973300; 23090806600; 57203638167; 16201684400","FEW-Shot Cross-Sensor Domain Adaptation Between SAR and Multispectral Data","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","763","766","3","10.1109/IGARSS46834.2022.9884302","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140397163&doi=10.1109%2fIGARSS46834.2022.9884302&partnerID=40&md5=01307951f2b0e1c1b8d3a77d48b00f9f","In this paper, we present a novel few-shot cross-sensor domain adaptation technique between SAR and multispectral data for LULC classification. Cross-sensor, such as SAR and multispectral, domain adaptation is a long standing challenge in remote sensing. Due to scarcity of large annotated dataset for every domain, it is desirable to have a method that enables cross-domain training with limited supervisory signal in that domain. We address this problem in this paper with a novel few-shot domain adaptation technique. We leverage large corpus of annotated multispectral dataset to improve performance for SAR based LULC classification. We propose a novel Feature Domain Alignment (FDA) loss function to align higher dimension features between multispectral and SAR domain. We validate our approach in publicly available DFC2020 dataset and achieve 78% overall LULC classification accuracy using only 5% annotated SAR samples. © 2022 IEEE.","Large dataset; Remote sensing; Synthetic aperture radar; Adaptation techniques; Annotated datasets; Cross-domain; Domain adaptation; Large corpora; Multi-spectral; Multi-spectral data; Remote-sensing; SAR data; Sensor domains; Classification (of information)","CNN; Domain adaptation; Multispectral; SAR","Conference paper","Final","","Scopus","2-s2.0-85140397163"
"Calota I.; Faur D.; Datcu M.","Calota, Iulia (57221233198); Faur, Daniela (15041980400); Datcu, Mihai (7004523124)","57221233198; 15041980400; 7004523124","BAG-OF-WORDS FOR TRANSFER LEARNING","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","808","811","3","10.1109/IGARSS47720.2021.9554776","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129955410&doi=10.1109%2fIGARSS47720.2021.9554776&partnerID=40&md5=f7e06ded05d2972a0dc249b58354f257","Although the number of labeled dataseis in Earth Observation (EO) is increasing, there is still a major gap between the Deep Learning (DL) classifiers designed in this field versus the models in Computer Vision. This gap is produced mainly by the number of datasets available, but also by the diversity of data. In EO, there are different sensors acquiring images, from multispectral (MS) or hyperspectral data, to SAR imagery. In this paper, we want to demonstrate how to reduce the divergence created by the diversity of data. We trained several DL architectures on Bag-of-Words from large-scale MS and SAR datasets, and then we used transfer learning on smaller ones and evaluated the results. With this method, we demonstrate that a DL architecture can be trained with any type of large-scale data, transformed into Bag-of-Words, and the trained model can be used further on other types of data, without regard on the number of channels. © 2021 IEEE","Data transfer; Deep learning; Information retrieval; Synthetic aperture radar; Bag of words; Deep learning; Earth observations; Hyperspectral Data; Learning architectures; Learning classifiers; Multi-spectral data; SAR data; SAR imagery; Transfer learning; Large dataset","Bag-of-Words; Deep Learning; multispectral data; SAR data; Transfer Learning","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85129955410"
"Li P.; Li D.; Li Z.; Wang H.","Li, Peng (57209542263); Li, Dahui (57216740968); Li, Zhenhong (57898397300); Wang, Houjie (14059171200)","57209542263; 57216740968; 57898397300; 14059171200","Wetland Classification Through Integration of GF-3 SAR and Sentinel-2B Multispectral Data over the Yellow River Delta; [黄河三角洲地区GF-3雷达数据与Sentinel-2多光谱数据湿地协同分类研究]","2019","Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University","44","11","","1641","1649","8","10.13203/j.whugis20180258","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076702410&doi=10.13203%2fj.whugis20180258&partnerID=40&md5=94dc5de5e091e93a59703bd1ea5488d8","It is of great significance to monitor dynamic change of wetland over the Yellow River Delta for rational utilization, development and protection of wetland resources. Both Gaofen-3 (GF-3) SAR data and Sentinel-2B multispectral data were used to analyze the spectral, index, polarization scatter and texture feature information of seven types of ground objects over the Yellow River Delta wetland, and then supervised classification was implemented with maximum likelihood (ML), decision tree (DT) and support vector machine (SVM) classifier. The performances of both the joint and the individual classifications with GF-3 and Sentinel-2B data were also evaluated. The results of three algorithms show that the overall accuracy of the joint classification can reach 90.4%, 95.4%, 95.7%, significantly higher than that of the individual classifications, showing the promising potential of GF-3 SAR and Sentinel-2B multi-spectral images in joint wetland classification. © 2019, Editorial Board of Geomatics and Information Science of Wuhan University. All right reserved.","China; Shandong; Yellow River Delta; Classification (of information); Decision trees; Maximum likelihood estimation; Rivers; Spectroscopy; Supervised learning; Textures; Trees (mathematics); Wetlands; GF-3; Multi-spectral data; Multispectral images; Overall accuracies; Supervised classification; Wetland classification; Wetland resources; Yellow River delta; image classification; maximum likelihood analysis; Sentinel; supervised classification; support vector machine; synthetic aperture radar; wetland; Support vector machines","GF-3; Sentinel-2B; Supervised classification; The Yellow River Delta; Wetland classification","Article","Final","","Scopus","2-s2.0-85076702410"
"Lin Y.; Zhang H.; Li G.; Wan L.; Wang F.; Ma P.; Lin H.","Lin, Yinyi (57205063110); Zhang, Hongsheng (55349777400); Li, Gang (55790666100); Wan, Luoma (57203950658); Wang, Feng (56459216100); Ma, Peifeng (56411541500); Lin, Hui (36071585400)","57205063110; 55349777400; 55790666100; 57203950658; 56459216100; 56411541500; 36071585400","Improving urban impervious surface extraction by synergizing hyperspectral and polarimetric radar data using sparse representation","2022","Egyptian Journal of Remote Sensing and Space Science","25","4","","1045","1056","11","10.1016/j.ejrs.2022.11.004","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143493502&doi=10.1016%2fj.ejrs.2022.11.004&partnerID=40&md5=b7201c6362327fe784ba1c2b5c6a4ad3","Accurate extraction of urban impervious surface (UIS) is essential for urban planning and environmental monitoring. However, multispectral remote sensing data for UIS extraction suffers from the inter-class spectral confusions, e.g. UIS and bare soil, and intra-class variations of sub-class UIS. Hyperspectral and full/dual-polarization synthetic aperture radar (full/dual PolSAR) data provide opportunities for reducing such confusions and have potential for fine UIS mapping, i.e., roads, buildings, and grounds. In this study, we first investigated the hyperspectral data (Gaofen-5) capability to reduce the intra/inter-class misclassification in comparison with multispectral data (Landsat-8). Then, we explored contributions of synergistically using full and dual PolSAR (ALOS-2 and Sentinel-1) with hyperspectral and multispectral data using optical-SAR sparse representation classification (OSSRC). Results showed that both the hyperspectral and the SAR polarization features helped better delineation between UIS and bare soil, and sub-class UIS (roads and buildings). The relative contribution of PolSAR was higher in multispectral data than in hyperspectral data, with full PolSAR contributed significantly. The combined hyperspectral and full PolSAR data using OSSRC delivered the best result, with an overall accuracy higher than 90%. The results indicate the promising capability of synergizing hyperspectral and full/dual PolSAR data for improving UIS extraction from advanced satellite data. © 2022","Data mining; Extraction; Optical remote sensing; Gaofen-5; HyperSpectral; Hyperspectral Data; Impervious surface; Multi-spectral data; PolSAR; Radar data; Sparse representation; Surface extraction; Urban impervious surfaces; environmental monitoring; image analysis; image resolution; Landsat; remote sensing; satellite data; satellite imagery; synthetic aperture radar; urban planning; Synthetic aperture radar","Gaofen-5; Hyperspectral; Impervious surface; PolSAR","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85143493502"
"Mouret F.; Albughdadi M.; Duthoit S.; Kouamé D.; Rieu G.; Tourneret J.-Y.","Mouret, Florian (57195994598); Albughdadi, Mohanad (56426491400); Duthoit, Sylvie (23099622300); Kouamé, Denis (6603829832); Rieu, Guillaume (57200598942); Tourneret, Jean-Yves (7003857060)","57195994598; 56426491400; 23099622300; 6603829832; 57200598942; 7003857060","Reconstruction of Sentinel-2 derived time series using robust Gaussian mixture models — Application to the detection of anomalous crop development","2022","Computers and Electronics in Agriculture","198","","106983","","","","10.1016/j.compag.2022.106983","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129796783&doi=10.1016%2fj.compag.2022.106983&partnerID=40&md5=5ff66c5d67dce90aa8f0e3f5ad019b22","Missing data is a recurrent problem in remote sensing, mainly due to cloud coverage for multispectral images and acquisition problems. This can be a critical issue for crop monitoring, especially for applications relying on machine learning techniques, which generally assume that the feature matrix does not have missing values. This paper proposes a Gaussian Mixture Model (GMM) for the reconstruction of parcel-level features extracted from multispectral images. A robust version of the GMM is also investigated, since datasets can be contaminated by inaccurate samples or features (e.g., wrong crop type reported, inaccurate boundaries, undetected clouds, etc). Additional features extracted from Synthetic Aperture Radar (SAR) images using Sentinel-1 data are also used to provide complementary information and improve the imputations. The robust GMM investigated in this work assigns reduced weights to the outliers during the estimation of the GMM parameters, which improves the final reconstruction. These weights are computed at each step of an Expectation–Maximization (EM) algorithm by using outlier scores provided by the isolation forest (IF) algorithm. Experimental validation is conducted on rapeseed and wheat parcels located in the Beauce region (France). Overall, we show that the GMM imputation method outperforms other reconstruction strategies. A mean absolute error (MAE) of 0.013 (resp. 0.019) is obtained for the imputation of the median Normalized Difference Index (NDVI) of the rapeseed (resp. wheat) parcels. Other indicators (e.g., Normalized Difference Water Index) and statistics (for instance the interquartile range, which captures heterogeneity among the parcel indicator) are reconstructed at the same time with good accuracy. In a dataset contaminated by irrelevant samples, using the robust GMM is recommended since the standard GMM imputation can lead to inaccurate imputed values. An application to the monitoring of anomalous crop development in the presence of missing data is finally considered. In this application, using the proposed method leads to the best detection results, especially when SAR data are used jointly with multispectral images. Exploiting the information contained in cloudy multispectral images instead of removing these images is beneficial for this application. © 2022 Elsevier B.V.","Beauce [Centre]; Anomaly detection; Crops; Data mining; Forestry; Image enhancement; Learning systems; Oilseeds; Radar imaging; Remote sensing; Statistics; Synthetic aperture radar; Anomaly detection; Crop monitoring; Data imputation; Expectation Maximization; Gaussian Mixture Model; Heterogeneity; Isolation forest; Missing data; Multi-spectral; Robust gaussian mixture model; Sentinel-1; Sentinel-2; Synthetic aperture radar; Vigor; algorithm; data set; detection method; heterogeneity; machine learning; Sentinel; synthetic aperture radar; Gaussian distribution","Anomaly detection; Crop monitoring; Data imputation; Expectation–Maximization; Heterogeneity; Isolation Forest; Missing data; Multispectral; Robust Gaussian Mixture Model; Sentinel-1; Sentinel-2; Synthetic Aperture Radar (SAR); Vigor","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85129796783"
"He G.; Dong Z.; Guan J.; Feng P.; Jin S.; Zhang X.","He, Guangjun (56485034500); Dong, Zhe (58073020300); Guan, Jian (57202816841); Feng, Pengming (56517583500); Jin, Shichao (58072519700); Zhang, Xueliang (48762261800)","56485034500; 58073020300; 57202816841; 56517583500; 58072519700; 48762261800","SAR and Multi-Spectral Data Fusion for Local Climate Zone Classification with Multi-Branch Convolutional Neural Network","2023","Remote Sensing","15","2","434","","","","10.3390/rs15020434","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146602149&doi=10.3390%2frs15020434&partnerID=40&md5=b74c624bc0b45a01170f8ce9a892d8b0","The local climate zone (LCZ) scheme is of great value for urban heat island (UHI) effect studies by providing a standard classification framework to describe the local physical structure at a global scale. In recent years, with the rapid development of satellite imaging techniques, both multi-spectral (MS) and synthetic aperture radar (SAR) data have been widely used in LCZ classification tasks. However, the fusion of MS and SAR data still faces the challenges of the different imaging mechanisms and the feature heterogeneity. In this study, to fully exploit and utilize the features of SAR and MS data, a data-grouping method was firstly proposed to divide multi-source data into several band groups according to the spectral characteristics of different bands. Then, a novel network architecture, namely Multi-source data Fusion Network for Local Climate Zone (MsF-LCZ-Net), was introduced to achieve high-precision LCZ classification, which contains a multi-branch CNN for multi-modal feature extraction and fusion, followed by a classifier for LCZ prediction. In the proposed multi-branch structure, a split–fusion-aggregate strategy was adopted to capture multi-level information and enhance the feature representation. In addition, a self channel attention (SCA) block was introduced to establish long-range spatial and inter-channel dependencies, which made the network pay more attention to informative features. Experiments were conducted on the So2Sat LCZ42 dataset, and the results show the superiority of our proposed method when compared with state-of-the-art methods. Moreover, the LCZ maps of three main cities in China were generated and analyzed to demonstrate the effectiveness of our proposed method. © 2023 by the authors.","Convolutional neural networks; Network architecture; Radar imaging; Synthetic aperture radar; Convolutional neural network; Local climate; Local climate zone; Multi-branch CNN; Multi-spectral; Multi-spectral data; Multisource data; Radar data; Urban Heat Island Effects; Zone classifications; Data fusion","data fusion; local climate zone; multi-branch CNN; multi-spectral; SAR","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85146602149"
"Dancheva A.; Nedkov R.; Borisova D.; Spasova T.; Georgiev N.","Dancheva, Adlin (57204632209); Nedkov, Roumen (57204958301); Borisova, Denitsa (8642458900); Spasova, Temenuzhka (57211430744); Georgiev, Nikolay (57211428499)","57204632209; 57204958301; 8642458900; 57211430744; 57211428499","Using optical and radar images to study the thermal pollution from the waste disposal site around Vidin area","2019","Proceedings of SPIE - The International Society for Optical Engineering","11149","","1114928","","","","10.1117/12.2538116","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078142138&doi=10.1117%2f12.2538116&partnerID=40&md5=c4444384c58a5e195d188e9b7a6c0cb7","One of the main issues that concerns mankind today is the problem of domestic waste and how it affects climate change, air pollution and the environment. In the present work the heat pollution from the waste disposal site is tracked at various time points. The waste disposal site near Vidin was selected for the purpose of the research. Optical satellite data from the Sentinel 2 multi-spectral instrument (MSI) and synthetic-aperture radar (SAR) data from the Sentinel 1 platform of the Copernicus program of the European Space Agency were used. The Landsat 5-7 (ETM) and Landsat 8 (OLI/TIRS) sensors were used to calculate the surface thermal pollution of the waste disposal sites. Orthogonalization of satellite imagery was made to trace the dynamics of the main components of the Earth's surface-vegetation, moisture and soil. On this basis, a correlation is made to trace the link between the different components of the Earth's surface at different time points. Climate data on average air temperature, evapotranspiration, radiation and rainfall was used and a comparative analysis of surface temperature from landfill and climatic data was made. © 2019 SPIE.","Agriculture; Atmospheric temperature; Climate change; Ecosystems; Geometrical optics; Hydrology; Land fill; Radar imaging; Remote sensing; Satellite imagery; Space optics; Space-based radar; Surface properties; Synthetic aperture radar; Average air temperature; Comparative analysis; European Space Agency; Optical image; Optical satellites; Orthogonalization; Surface temperatures; Waste disposal sites; Thermal pollution","Optical images; SAR; Surface temperature; Thermal pollution; Waste disposal site","Conference paper","Final","","Scopus","2-s2.0-85078142138"
"Bai Y.; Sun G.; Ge Y.; Zhang Y.; Li Y.","Bai, Yunkun (57213195421); Sun, Guangmin (8431278000); Ge, Yi (57213197892); Zhang, Yuanzhi (57200534631); Li, Yu (57214959189)","57213195421; 8431278000; 57213197892; 57200534631; 57214959189","Mapping urban impervious surfaces by fusing optical and SAR data at decision level","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898039","6336","6339","3","10.1109/IGARSS.2019.8898039","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077675994&doi=10.1109%2fIGARSS.2019.8898039&partnerID=40&md5=58e431a78929ddd60a8ebb045122b4af","The extraction of urban impervious surface information plays a key role in the studies of urbanization and its related environmental issues. Optical and SAR remote sensing provides complementary information to improve the accuracy of impervious mapping. However, the fusing of information acquired by different sensors is challenging. Optical and SAR features have distinct characteristics, and require different classification strategy and classification types. In this study, a strategy of fusing multi-spectral optical and polarimetric SAR data at decision-level is proposed. Features are extracted from optical and SAR data, then staked auto-encoder is applied to achieve the land use and land cover classification separately. D-S evidence theory is used to fuse the classification result and the imperious surface map is derived. The experiment was conducted in a highly complex urban area of Hong Kong and the results proves the soundness of the method. © 2019 IEEE.","Geology; Land use; Mapping; Remote sensing; Classification results; Decision level fusion; Impervious surface; Land use and land cover; Land-use and land cover classifications; Multi-spectrum; Polarimetric SAR data; Urban impervious surfaces; Synthetic aperture radar","decision-level fusion; impervious surface; land use and land cover; multi-spectrum; synthetic aperture radar","Conference paper","Final","","Scopus","2-s2.0-85077675994"
"Hafner S.; Ban Y.; Nascetti A.","Hafner, Sebastian (57310203000); Ban, Yifang (7202222338); Nascetti, Andrea (36816311000)","57310203000; 7202222338; 36816311000","EXPLORING THE FUSION OF SENTINEL-1 SAR AND SENTINEL-2 MSI DATA FOR BUILT-UP AREA MAPPING USING DEEP LEARNING","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","4720","4723","3","10.1109/IGARSS47720.2021.9553448","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126039388&doi=10.1109%2fIGARSS47720.2021.9553448&partnerID=40&md5=6a170670b07c783059ce1dc66b09c027","This research explores the potential of combining Sentinel-1 C-band Synthetic Aperture Radar (SAR) and Sentinel-2 MultiSpectral Instrument (MSI) data for Built-Up Area (BUA) mapping using deep learning. A lightweight U-Net model is trained using openly available building footprint reference data in North America and tested in four cities across three additional continents. The best test performance in terms of F1 score was achieved by the joint use of SAR and multi-spectral data (0.676), followed by multi-spectral (0.611) and SAR data (0.601). The developed fusion approach is particularly promising to distinguish BUA in low-density residential neighborhoods. Furthermore, our fusion approach compares favorably to the state-of-the-art in BUA mapping in the selected cities. However, associated with the diverse characteristics of human settlements around the world, considerable differences in accuracy among the test cities were observed. This indicates the need for more sophisticated fusion techniques to improve CNN model generalization and for adding more diverse training data. © 2021 IEEE.","","Built-up area mapping; Data fusion; Deep learning; Sentinel-1; Sentinel-2","Conference paper","Final","","Scopus","2-s2.0-85126039388"
"Park S.-E.; Jung Y.T.; Kim H.-C.","Park, Sang-Eun (8409996700); Jung, Yoon Taek (57205162914); Kim, Hyun-Cheol (55739545700)","8409996700; 57205162914; 55739545700","Monitoring permafrost changes in central Yakutia using optical and polarimetric SAR data","2022","Remote Sensing of Environment","274","","112989","","","","10.1016/j.rse.2022.112989","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127166822&doi=10.1016%2fj.rse.2022.112989&partnerID=40&md5=274935586bd119f557d95e2499f9876f","The changes in the permafrost environment have been of interest as a sensitive indicator of changes in global climate conditions. Since changes in the soil and ecosystem of the permafrost active layer are spatially and temporally complex depending on many environmental factors, it is not easy to grasp climate-induced changes occurring in coupled atmospheric-ecological-geocryological systems. To understand the changes in the permafrost active layer, spatially detailed monitoring methods such as multi-spectral optical and Synthetic Aperture Radar (SAR) remote sensing technologies have been extensively applied to the permafrost observation. Optical and SAR systems observe different permafrost features due to significant differences in electromagnetic wave frequencies and imaging mechanisms. Therefore, most studies used optical and SAR data separately according to the purpose and characteristics of each study. The objective of this study is to explore the possibility of combined interpretation of optical and SAR data for identifying and understanding spatiotemporal details of the short- and long-term changes occurring in the permafrost active layer. Multi-spectral optical images acquired during the thawing period and L-band polarimetric SAR images acquired during the freezing period are used in this study in order to examine ecological characteristics and cryogenic processes, respectively. The result of analyzing the relationship between information obtained from optical and SAR sensors revealed that there was a significant correlation between winter changes in scattering properties observed in SAR data and summer land cover changes observed in optical data. The scattering characteristics of winter soil were found to be particularly related to the ecosystem changes in areas that can be explained by the thermokarst development process. Additional data from independent sources, such as elevation data, meteorological data, and long-term optical data, consistently supported the relationship between the winter SAR observations and the thermokarst-related ecosystem changes. The experimental results also elucidated that polarimetric scattering mechanism indicators representing the signal depolarization and surface roughness properties played an important role in deriving information related to the permafrost process from the winter SAR data. © 2022 Elsevier Inc.","Russian Federation; Sakha; Climate change; Ecosystems; Image enhancement; Optical correlation; Permafrost; Polarimeters; Radar imaging; Remote sensing; Surface roughness; Active Layer; ALOS PALSAR; Ecosystem changes; LANDSAT; Multi-spectral; Optical data; Optical-; Polarimetric synthetic aperture radars; Radar data; Thermokarst; environmental factor; Landsat; permafrost; polarization; remote sensing; synthetic aperture radar; thermokarst; Synthetic aperture radar","ALOS PALSAR; Landsat; Permafrost; Polarimetric SAR; Synthetic Aperture Radar; Thermokarst","Article","Final","","Scopus","2-s2.0-85127166822"
"Duke O.P.; Alabi T.; Neeti N.; Adewopo J.","Duke, Ojo Patrick (57855012000); Alabi, Tunrayo (36719970800); Neeti, Neeti (23985592800); Adewopo, Julius (37119923200)","57855012000; 36719970800; 23985592800; 37119923200","Comparison of UAV and SAR performance for Crop type classification using machine learning algorithms: a case study of humid forest ecology experimental research site of West Africa","2022","International Journal of Remote Sensing","43","11","","4259","4286","27","10.1080/01431161.2022.2109444","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136516019&doi=10.1080%2f01431161.2022.2109444&partnerID=40&md5=9dfd196045b0f9397d9ef507900f5696","Food insecurity is one of the major challenges facing African countries; therefore, timely and accurate information on agricultural production is essential to feed the growing population on the continent. A synergistic approach comprising a high-resolution multispectral UAV optical dataset and synthetic aperture radar (SAR) can help understand spectral features of target objects, especially with crop type identification. We conducted this work on the experimental plots using high spatial resolution multispectral UAV data (12 cm, re-sampled to 50 cm) in combination with the Sentinel 1C Synthetic Aperture Radar (SAR) dataset. We generated 11 agronomically relevent vegetation indices from the UAV multispectral image. Multiple combinations of the UAV datasets were analysed to assess the impact of canopy height model (CHM) on classification accuracy and to determine the optimum dataset (including spatial resolution) for the land cover classification. We also appraise the impact of variable spatial resolution on classification accuracy. A combination of VH and VV polarizations of Sentinel-1 SAR data was also analysed to classify the crop types while comparing its accuracy with the UAV-derived models. Our results show that model accuracy is improved- for all the data combination pairs, when CHM is added to the modelling. We also observed a decreasing trend in classification accuracy with respect to increasing spatial resolution. Generally, the support vector machine (SVM) classifier produced an overall accuracy of 94.78% and 81.72% for UAV and SAR datasets, respectively. In comparison, the random forest (RF) achieved an accuracy of 93.84% and 92.58%, for UAV and SAR datasets, respectively. The outputs from ground-based validation corroborate the results from model-based classification coupled with acceptable simple models’ agreement ratio (SMAR), exceeding 90% in some cases. The combined techniques can be useful in precision agriculture over small and large agricultural fields to support food security assessment and planning. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Nigeria; Classification (of information); Crops; Decision trees; Ecology; Food supply; Image resolution; Precision agriculture; Random forests; Synthetic aperture radar; Unmanned aerial vehicles (UAV); Canopy Height Models; Classification accuracy; IITA; Multi-spectral; Nigeria; Precision Agriculture; Radar datasets; Random forests; Spatial resolution; Support vectors machine; algorithm; classification; comparative study; crop; forest ecosystem; machine learning; precision agriculture; support vector machine; synthetic aperture radar; unmanned vehicle; Support vector machines","IITA; Nigeria; precision agriculture; random forest; SAR; Support vector machine; UAV","Article","Final","","Scopus","2-s2.0-85136516019"
"Wu R.; Liu G.; Zhang R.; Wang X.; Li Y.; Zhang B.; Cai J.; Xiang W.","Wu, Renzhe (57220766039); Liu, Guoxiang (22035722100); Zhang, Rui (57219019691); Wang, Xiaowen (55790720900); Li, Yong (55414749300); Zhang, Bo (57199725987); Cai, Jialun (57210947398); Xiang, Wei (57220767310)","57220766039; 22035722100; 57219019691; 55790720900; 55414749300; 57199725987; 57210947398; 57220767310","A deep learning method for mapping glacial lakes from the combined use of synthetic-aperture radar and optical satellite images","2020","Remote Sensing","12","24","4020","1","18","17","10.3390/rs12244020","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097579945&doi=10.3390%2frs12244020&partnerID=40&md5=4c80d5941e1c25207988f3f2acab26b8","Glacial lakes (GLs), a vital link between the hydrosphere and the cryosphere, participate in the local hydrological process, and their interannual dynamic evolution is an objective reflection and an indicator of regional climate change. The complex terrain and climatic conditions in mountainous areas where GLs are located make it difficult to employ conventional remote sensing observation means to obtain stable, accurate, and comprehensive observation data. In view of this situation, this study presents an algorithm with a high generalization ability established by optimizing and improving a deep learning (DL) semantic segmentation network model for extracting GL contours from combined synthetic-aperture radar (SAR) amplitude and multispectral imagery data. The aim is to use the high penetrability and all-weather advantages of SAR to reduce the effects of cloud cover as well as to integrate the multiscale and detail-oriented advantages of multispectral data to facilitate accurate, quantitative extraction of GL contours. The accuracy and reliability of the model and algorithm were examined by employing them to extract the contours of GLs in a large region of south-eastern Tibet from Landsat 8 optical remote sensing images and Sentinel-1A amplitude images. In this study, the contours of a total 8262 GLs in south-eastern Tibet were extracted. These GLs were distributed predominantly at altitudes of 4000–5500 m. Only 17.4% of these GLs were greater than 0.1 km2 in size, while a large number of small GLs made up the majority. Through analysis and validation, the proposed method was found highly capable of distinguishing rivers and lakes and able to effectively reduce the misidentification and extraction of rivers. With the DL model based on combined optical and SAR images, the intersection-over-union (IoU) score increased by 0.0212 (to 0.6207) on the validation set and by 0.038 (to 0.6397) on the prediction set. These validation data sufficiently demonstrate the efficacy of the model and algorithm. The technical means employed in this study as well as the results and data obtained can provide a reference for research and application expansion in related fields. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Climate change; Data mining; Deep learning; Extraction; Glacial geology; Image enhancement; Lakes; Learning systems; Remote sensing; Semantics; Space-based radar; Synthetic aperture radar; Generalization ability; Multi-spectral imagery; Optical remote sensing; Optical satellite images; Quantitative extraction; Regional climate changes; Research and application; Semantic segmentation; Radar imaging","Deep learning; Glacial lake extraction; High accuracy; Images of different sources","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85097579945"
"Bresciani M.; Ghirardi N.; Fornaro G.; Zamparelli V.; de Santi F.; de Carolis G.; Tapete D.; Palandri M.; Giardino C.","Bresciani, Mariano (25026685500); Ghirardi, Nicola (57207986526); Fornaro, Gianfranco (7005348278); Zamparelli, Virginia (36505512000); de Santi, Francesca (39161255200); de Carolis, Giacomo (7003329743); Tapete, Deodato (55221777800); Palandri, Monica (36011994500); Giardino, Claudia (7007069808)","25026685500; 57207986526; 7005348278; 36505512000; 39161255200; 7003329743; 55221777800; 36011994500; 7007069808","COMBINED USE OF OPTICAL AND SAR IMAGES FOR MAPPING COASTAL EROSION RISK","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","7549","7552","3","10.1109/IGARSS47720.2021.9554000","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129826356&doi=10.1109%2fIGARSS47720.2021.9554000&partnerID=40&md5=fc436d5e52d24a6e59ece73426b7022a","This study demonstrates the use of a novel satellite remote sensing approach to map coastal erosion vulnerability in the Italian site of Piscinas (Sardinia). We focused on the land/water transitional ecosystem, to identify potential coastal erosion phenomena. For this analysis, a synergistic approach between multi-spectral satellite data (Sentinel-2) and SAR imagery (COSMO-SkyMed and Sentinel-1B) was exploited. Two vulnerability maps were created: one long-term (2016-2018) and one short-term (wind event). The results confirm how the coastal vulnerability of this site seems to be linked to episodic events, consequently, the dune system of Piscinas might be considered safe from coastal erosion processes. ©2021 IEEE","Coastal zones; Erosion; Geometrical optics; Remote sensing; Satellite imagery; Synthetic aperture radar; Coastal erosion; Erosion risk; Multi-spectral; Optical image; Remote sensing approaches; Remote-sensing; SAR Images; Sardinia; Satellite remote sensing; Vulnerability maps; Radar imaging","Coastal zones; Optical images; Radar images; Remote sensing; Vulnerability maps","Conference paper","Final","","Scopus","2-s2.0-85129826356"
"Garcia-Pineda O.; Staples G.; Jones C.E.; Hu C.; Holt B.; Kourafalou V.; Graettinger G.; DiPinto L.; Ramirez E.; Streett D.; Cho J.; Swayze G.A.; Sun S.; Garcia D.; Haces-Garcia F.","Garcia-Pineda, Oscar (26666719300); Staples, Gordon (7004227448); Jones, Cathleen E. (55474246200); Hu, Chuanmin (57195673046); Holt, Benjamin (35594051500); Kourafalou, Villy (6603155473); Graettinger, George (55440133200); DiPinto, Lisa (6602770565); Ramirez, Ellen (56926200800); Streett, Davida (56149480200); Cho, Jay (57190810251); Swayze, Gregg A. (6602804600); Sun, Shaojie (55611510700); Garcia, Diana (57213360866); Haces-Garcia, Francisco (57211600690)","26666719300; 7004227448; 55474246200; 57195673046; 35594051500; 6603155473; 55440133200; 6602770565; 56926200800; 56149480200; 57190810251; 6602804600; 55611510700; 57213360866; 57211600690","Classification of oil spill by thicknesses using multiple remote sensors","2020","Remote Sensing of Environment","236","","111421","","","","10.1016/j.rse.2019.111421","54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074604636&doi=10.1016%2fj.rse.2019.111421&partnerID=40&md5=34d7198a4f921a08ff31720722c9ebe5","Satellite Synthetic Aperture Radar (SAR) is an operational tool for monitoring and assessment of oil spills. Satellite SAR has primarily been used to detect the presence/absence of oil, yet its ability to discriminate oil emulsions within a detected oil slick has not been fully exploited. Additionally, one of the challenges in the past has been the ability to deliver strategic information derived from satellite remote sensing in a timely fashion to responders in the field. This study presents methods for the rapid classification of oil types and estimated thicknesses, from which information about thick oil and oil emulsions (i.e., “actionable” oil) can be delivered in an operational timeframe to responders in the field. Experiments carried out at the OHMSETT test facility in New Jersey demonstrate that under specific viewing conditions, a single polarization satellite SAR image can record a signal variance between thick stable emulsions and non-emulsified oil. During a series of field campaigns in the Gulf of Mexico with in situ measurements of oil thickness, multiple satellite data were obtained including fully polarimetric C-band SAR imagery from RADARSAT-2 and multispectral imagery from ASTER and WorldView-2. One campaign included the airborne polarimetric UAVSAR L-band sensor. An oil/emulsion thickness classification product was generated based on RADARSAT-2 polarimetric imagery using entropy and the damping ratio derivations. Herein, we present the classification methods to generate oil thickness products from SAR, validated by sea-truth observations, the multispectral imagery, and the UAVSAR data. We tested the ability to deliver these products with minimum latency to responding vessels via NOAA. During field operations in the Gulf of Mexico, a satellite SAR-based product of oil delineation by relative thickness was delivered to a responding vessel 42 min after the RADARSAT-2 data acquisition. This proof-of-concept test using satellite SAR and multispectral imagery to detect emulsions and deliver a derived information product to a vessel in near-real-time points directly to methods for satellite-based assets to be used in the near future for oil spill tactical response operations. © 2019 Elsevier Inc.","Classification (of information); Data acquisition; Emulsification; Emulsions; Oil spills; Ostwald ripening; Polarimeters; Radar imaging; Remote sensing; Satellite imagery; Synthetic aperture radar; Classification methods; Monitoring and assessment; Multi-spectral imagery; Oil emulsions; Oil thickness; Proof-of-concept tests; Remote sensing imagery; Satellite remote sensing; Space-based radar","Oil emulsions; Oil spills; Oil thickness; Remote sensing imagery; SAR","Article","Final","","Scopus","2-s2.0-85074604636"
"Saha S.; Zhao S.; Shahzad M.; Zhu X.X.","Saha, Sudipan (57205200597); Zhao, Shan (57731138900); Shahzad, Muhammad (15048845800); Zhu, Xiao Xiang (55696622200)","57205200597; 57731138900; 15048845800; 55696622200","Mitigating Distribution Shift for Multi-Sensor Classification","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","1201","1204","3","10.1109/IGARSS46834.2022.9883596","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140365584&doi=10.1109%2fIGARSS46834.2022.9883596&partnerID=40&md5=dded380cd1e9dd66518cc2978314558c","Distribution shift may pose significant challenges in Earth observation, especially when dealing with significantly differ-ent sensors like multispectral optical and Synthetic Aperture Radar (SAR). Deep learning models trained for optical image classification generally do not generalize well for SAR images. This is due to very marked differences between them. Though there is a considerable amount of works on domain adaptation, only few deal with such strong differences. Towards this, we propose a co-teaching based domain adaptation method using dual classifier head, a Multi-layer Perceptron (MLP) classi-fier and a Graph Neural Network (GNN) classifier. The two classifier heads teach each other in an iterative manner, thus gradually adapting both of them for target classification. We experimentally demonstrate the efficacy of the proposed approach on Sentinel 2 (optical) as source and Sentinel 1 (SAR) images as target-both product of Copernicus program of European Space Agency. © 2022 IEEE.","Deep learning; Geometrical optics; Graph neural networks; Iterative methods; Radar imaging; Space-based radar; Co-teaching; Domain adaptation; Earth observations; Graph neural networks; Learning models; Multi sensor; Multi-spectral; Optical-; Synthetic aper-ture radar; Synthetic aperture radar images; Synthetic aperture radar","Co-teaching; Domain adaptation; Graph Neural Network; Multi-sensor; Optical; Synthetic Aper-ture Radar","Conference paper","Final","","Scopus","2-s2.0-85140365584"
"Zhang X.; Yue Y.; Han L.; Li F.; Yuan X.; Fan M.; Zhang Y.","Zhang, Xiuwei (24780164800); Yue, Yuanzeng (57221861693); Han, Lin (57225865018); Li, Fei (56587080000); Yuan, Xiuzhong (57224682203); Fan, Minhao (57211749460); Zhang, Yanning (57223020446)","24780164800; 57221861693; 57225865018; 56587080000; 57224682203; 57211749460; 57223020446","River ice monitoring and change detection with multi-spectral and SAR images: application over yellow river","2021","Multimedia Tools and Applications","80","19","","28989","29004","15","10.1007/s11042-021-11054-0","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108161213&doi=10.1007%2fs11042-021-11054-0&partnerID=40&md5=56f59002582654d8182ed14b7aa69621","Spatially detailed characterization of the distribution amount and timing of river ice are important for identifying and predicting potential ice hazards. In this paper, we present an asynchronous river ice extraction and change detection method using multi-temporal SAR image and multi-spectral image. River channel information is a strong prior knowledge for ice detection and analysis. Therefore a river channel extraction algorithm on multi-spectral image based on sparse reconstruction is proposed and adopted in our method. The extracted river channel is used as prior information to effectively eliminate most interference regions on the shore. Then an adaptive threshold segmentation method is adopted to accurately detect river ice regions in SAR image. Fuzzy C-means clustering is used to segment river ice using the infrared bands of multi-spectral image, considering temperature can provide significant information to discriminate ice, water and shore. Finally, change analysis is done based on the ice extractions results of two kinds of images. The proposed method is applied on the Yellow River ice monitoring and experiments demonstrated that this straightforward approach works well with both SAR image and multi-spectral image. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Extraction; Ice; Image segmentation; Rivers; Spectroscopy; Synthetic aperture radar; Adaptive threshold segmentation; Change detection; Extraction algorithms; Fuzzy C means clustering; Multi-temporal SAR images; Multispectral images; Prior information; Sparse reconstruction; Radar imaging","Change detection; Ice extraction; Multi-temporal data; Yellow River","Article","Final","","Scopus","2-s2.0-85108161213"
"Ataee M.S.; Maghsoudi Y.; Latifi H.; Fadaie F.","Ataee, Mohammad Sadegh (57210388668); Maghsoudi, Yasser (36659425300); Latifi, Hooman (15073733900); Fadaie, Farhad (55945666200)","57210388668; 36659425300; 15073733900; 55945666200","Improving estimation accuracy of growing stock by multi-frequency SAR and multi-spectral data over Iran's heterogeneously-structured broadleaf Hyrcanian forests","2019","Forests","10","8","641","","","","10.3390/f10080641","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070547834&doi=10.3390%2ff10080641&partnerID=40&md5=8ec9c898c12377a4496244bcc1fdb154","Via providing various ecosystem services, the old-growth Hyrcanian forests play a crucial role in the environment and anthropogenic aspects of Iran and beyond. The amount of growing stock volume (GSV) is a forest biophysical parameter with great importance in issues like economy, environmental protection, and adaptation to climate change. Thus, accurate and unbiased estimation of GSV is also crucial to be pursued across the Hyrcanian. Our goal was to investigate the potential of ALOS-2 and Sentinel-1's polarimetric features in combination with Sentinel-2 multi-spectral features for the GSV estimation in a portion of heterogeneously-structured and mountainous Hyrcanian forests. We used five different kernels by the support vector regression (nu-SVR) for the GSV estimation. Because each kernel differently models the parameters, we separately selected features for each kernel by a binary genetic algorithm (GA). We simultaneously optimized R2 and RMSE in a suggested GA fitness function. We calculated R2, RMSE to evaluate the models. We additionally calculated the standard deviation of validation metrics to estimate the model's stability. Also for models over-fitting or under-fitting analysis, we used mean difference (MD) index. The results suggested the use of polynomial kernel as the final model. Despite multiple methodical challenges raised from the composition and structure of the study site, we conclude that the combined use of polarimetric features (both dual and full) with spectral bands and indices can improve the GSV estimation over mixed broadleaf forests. This was partially supported by the use of proposed evaluation criterion within the GA, which helped to avoid the curse of dimensionality for the applied SVR and lowest over estimation or under estimation. © 2019 by the authors.","Ecosystems; Estimation; Evaluation; Forestry; Forests; Iran; Models; Optimization; Iran; Climate change; Ecosystems; Forestry; Genetic algorithms; Optimization; Polarimeters; Adaptation to climate changes; Binary genetic algorithm; Curse of dimensionality; Multi-spectral; Nu SVR; Polarimetery; Support vector regression (SVR); Uneven-aged; accuracy assessment; ALOS; broad-leaved forest; estimation method; mountain region; multispectral image; optimization; Sentinel; synthetic aperture radar; Frequency estimation","GSV; Multi-spectral; Nu SVR; Optimization; Polarimetery; Uneven-aged mountainous","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85070547834"
"Li D.","Li, Dezheng (57408408400)","57408408400","Research on mathematical optimization algorithm for image processing problem","2021","ACM International Conference Proceeding Series","","","3501497","483","486","3","10.1145/3501409.3501497","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122652729&doi=10.1145%2f3501409.3501497&partnerID=40&md5=34f20f9467d2b41142c1be638e85e9a7","Since the film camera came into being, image has become one of the most important ways for people to record scene information. Especially with the rapid development of digital imaging technology and electronic communication in recent years, image has become one of the most important ways of human cognition of the world. Thanks to the development of science and technology, there are more and more kinds of imaging equipment, such as NUCLEAR magnetic resonance imaging equipment in medical imaging system, synthetic aperture radar widely used in the military field, multi-spectral scanner for remote sensing imaging carried on aircraft or satellites, etc. The images acquired by these new imaging devices are increasingly being studied by scholars. This thesis mainly studies how to design a reasonable mathematical optimization model and an efficient solving algorithm to solve related problems when digital camera image is affected by noise, blur, low resolution, scratch and ink. This paper focuses on three important problems in image processing, which are image denoising and blur removal, image super-resolution and image repair. Therefore, the study of these three image problems has very important practical application value. In particular, these three image problems have the same characteristics. They can be regarded as inverse problems, can be solved by mathematical optimization model, and can be regarded as image restoration problems. © 2021 ACM.","Digital devices; Image denoising; Image reconstruction; Inverse problems; Magnetic resonance imaging; Medical imaging; Military applications; Military photography; Optical resolving power; Optimization; Radar imaging; Remote sensing; Synthetic aperture radar; Algorithms optimizations; Image problem; Image processing problems; Image repair; Image super resolutions; Images processing; Imaging equipment; Mathematical optimization model; Mathematical optimizations; Optimization algorithms; Photographic films","Algorithm optimization; image processing; image repair; image super-resolution","Conference paper","Final","","Scopus","2-s2.0-85122652729"
"Liao C.; Wang J.; Xie Q.; Baz A.A.; Huang X.; Shang J.; He Y.","Liao, Chunhua (50461691800); Wang, Jinfei (57203323201); Xie, Qinghua (52063844200); Baz, Ayman Al (57215780799); Huang, Xiaodong (56733799000); Shang, Jiali (10144065500); He, Yongjun (57215423675)","50461691800; 57203323201; 52063844200; 57215780799; 56733799000; 10144065500; 57215423675","Synergistic use of multi-temporal RADARSAT-2 and VENμS data for crop classification based on 1D convolutional neural network","2020","Remote Sensing","12","5","832","","","","10.3390/rs12050832","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081935163&doi=10.3390%2frs12050832&partnerID=40&md5=b63bca07082bd7d0c40bb0b3f2c97426","Annual crop inventory information is important for many agriculture applications and government statistics. The synergistic use of multi-temporal polarimetric synthetic aperture radar (SAR) and available multispectral remote sensing data can reduce the temporal gaps and provide the spectral and polarimetric information of the crops, which is effective for crop classification in areas with frequent cloud interference. The main objectives of this study are to develop a deep learning model to map agricultural areas using multi-temporal full polarimetric SAR and multi-spectral remote sensing data, and to evaluate the influence of different input features on the performance of deep learning methods in crop classification. In this study, a one-dimensional convolutional neural network (Conv1D) was proposed and tested on multi-temporal RADARSAT-2 and VENμS data for crop classification. Compared with the Multi-Layer Perceptron (MLP), Recurrent Neural Network (RNN) and non-deep learning methods including XGBoost, Random Forest (RF), and Support Vector Machina (SVM), the Conv1D performed the best when the multi-temporal RADARSAT-2 data (Pauli decomposition or coherency matrix) and VENμS multispectral data were fused by the Minimum Noise Fraction (MNF) transformation. The Pauli decomposition and coherency matrix gave similar overall accuracy (OA) for Conv1D when fused with the VENμS data by the MNF transformation (OA = 96.65 ± 1.03% and 96.72 ± 0.77%). The MNF transformation improved the OA and F-score for most classes when Conv1D was used. The results reveal that the coherency matrix has a great potential in crop classification and the MNF transformation of multi-temporal RADARSAT-2 and VENμS data can enhance the performance of Conv1D. © 2020 by the authors.","Convolution; Convolutional neural networks; Crops; Data fusion; Decision trees; Deep learning; Deep neural networks; Learning systems; Linear transformations; Matrix algebra; Metadata; Multilayer neural networks; Polarimeters; Random forests; Recurrent neural networks; Remote sensing; Support vector machines; Synthetic aperture radar; Agriculture applications; Crop classification; Minimum noise fraction; Multispectral remote sensing; Polarimetric informations; Polarimetric synthetic aperture radars; Radarsat-2; Recurrent neural network (RNN); Classification (of information)","Convolutional neural network; Crop classification; Data fusion; Deep learning; RADARSAT-2; VENμS","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85081935163"
"Wei Z.; Jia K.; Liu P.; Jia X.; Xie Y.; Jiang Z.","Wei, Zhihao (57193134437); Jia, Kebin (8659887500); Liu, Pengyu (14056447600); Jia, Xiaowei (56589359200); Xie, Yiqun (57195229262); Jiang, Zhe (54938812700)","57193134437; 8659887500; 14056447600; 56589359200; 57195229262; 54938812700","Large-scale river mapping using contrastive learning and multi-source satellite imagery","2021","Remote Sensing","13","15","2893","","","","10.3390/rs13152893","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111608764&doi=10.3390%2frs13152893&partnerID=40&md5=aa341685da681a166e06a665a0dad420","River system is critical for the future sustainability of our planet but is always under the pressure of food, water and energy demands. Recent advances in machine learning bring a great potential for automatic river mapping using satellite imagery. Surface river mapping can provide accurate and timely water extent information that is highly valuable for solid policy and management decisions. However, accurate large-scale river mapping remains challenging given limited labels, spatial heterogeneity and noise in satellite imagery (e.g., clouds and aerosols). In this paper, we propose a new multi-source data-driven method for large-scale river mapping by combining multispectral imagery and synthetic aperture radar data. In particular, we build a multi-source data segmentation model, which uses contrastive learning to extract the common information between multiple data sources while also preserving distinct knowledge from each data source. Moreover, we create the first large-scale multi-source river imagery dataset based on Sentinel-1 and Sentinel-2 satellite data, along with 1013 handmade accurate river segmentation mask (which will be released to the public). In this dataset, our method has been shown to produce superior performance (F1score is 91.53%) over multiple state-of-the-art segmentation algorithms. We also demonstrate the effectiveness of the proposed contrastive learning model in mapping river extent when we have limited and noisy data. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Large dataset; Learning systems; Mapping; Radar imaging; Rivers; Space-based radar; Synthetic aperture radar; Management decisions; Multi-source satellite imagery; Multi-spectral imagery; Multiple data sources; Segmentation algorithms; Segmentation masks; Spatial heterogeneity; Water and energies; Satellite imagery","Contrastive learning; Multi-source data; River segmentation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85111608764"
"Saran S.; Sterk G.; Aggarwal S.P.; Dadhwal V.K.","Saran, Sameer (7003795359); Sterk, Geert (7003742891); Aggarwal, S.P. (13204366700); Dadhwal, V.K. (7004389152)","7003795359; 7003742891; 13204366700; 7004389152","Coupling Remote Sensing and GIS with KINEROS2 Model for Spatially Distributed Runoff Modeling in a Himalayan Watershed","2021","Journal of the Indian Society of Remote Sensing","49","5","","1121","1139","18","10.1007/s12524-020-01295-1","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100138993&doi=10.1007%2fs12524-020-01295-1&partnerID=40&md5=9c9c61dfab7fdcf100440c5cbbc62a5d","Excessive runoff and high soil erosion rate are the critical problems in the Himalayan terrain, mainly due to rugged topography and high intensity rains. Accurate quantification of runoff and erosion is thus of paramount importance for taking appropriate measures to sustain the soil productivity in the Himalayan watersheds. Distributed, process-based hydrological and erosion models are ideal for this purpose. However, model parameterization in the rugged, inaccessible and thus generally a data scarce Himalayan watershed is a major challenge. The present study primarily investigates the applicability of kinematic runoff and erosion model (KINEROS2) model in a Himalayan watershed besides exploring the potential of satellite remote sensing and GIS in spatially distributed runoff modeling. The KINEROS2 model, is an event-based, distributed, water and erosion process model. It discretizes the watershed into a mosaic of planes and channels based on topography. The runoff is estimated for each plane which eventually flows to adjacent channel and is then routed to estimate the total runoff at the watershed outlet. Remote sensing is primarily used for model parameterization, i.e., characterizing the individual planes and channels. Optimized digital elevation model and fine-scale land-use/land-cover information are generated using high-resolution panchromatic and multi-spectral optical and microwave satellite imagery. The resulting data on near-surface soil moisture from radar imagery (ENVISAT ASAR) calibrated the initial soil moisture in the model, whose performance is evaluated using root mean square error and Nash–Sutcliffe that reveals that KINEROS2 model works quite well in a small Himalayan watershed. The sensitivity analysis indicates that saturated soil hydraulic conductivity is the most sensitive parameter influencing the runoff compared to Manning’s coefficient and initial soil moisture. The model output is also used for validating the remote sensing and geographical information system (GIS) based hydrologic response units delineated in a previous research study. The study highlights that the coupling of remote sensing and GIS with process models, such as KINEROS2, can provide valuable information in planning sustainable watershed management practices in the Himalayan watersheds. © 2021, Indian Society of Remote Sensing.","Himalayas; digital elevation model; Envisat; GIS; hydrological modeling; numerical model; parameterization; remote sensing; runoff; satellite imagery; soil erosion; soil moisture; spatial distribution; synthetic aperture radar; watershed","Himalaya; Hydrologic response units; Hydrological modeling; KINEROS2 model; Remote sensing","Article","Final","","Scopus","2-s2.0-85100138993"
"Becker A.; Russo S.; Puliti S.; Lang N.; Schindler K.; Wegner J.D.","Becker, Alexander (57361934600); Russo, Stefania (57190281838); Puliti, Stefano (56784209400); Lang, Nico (57197768856); Schindler, Konrad (58018355200); Wegner, Jan Dirk (58017481700)","57361934600; 57190281838; 56784209400; 57197768856; 58018355200; 58017481700","Country-wide retrieval of forest structure from optical and SAR satellite imagery with deep ensembles","2023","ISPRS Journal of Photogrammetry and Remote Sensing","195","","","269","286","17","10.1016/j.isprsjprs.2022.11.011","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144062328&doi=10.1016%2fj.isprsjprs.2022.11.011&partnerID=40&md5=e9bd013c66e4170878293874908d51d2","Monitoring and managing Earth's forests in an informed manner is an important requirement for addressing challenges like biodiversity loss and climate change. While traditional in situ or aerial campaigns for forest assessments provide accurate data for analysis at regional level, scaling them to entire countries and beyond with high temporal resolution is hardly possible. In this work, we propose a method based on deep ensembles that densely estimates forest structure variables at country-scale with 10-m resolution, using freely available satellite imagery as input. Our method jointly transforms Sentinel-2 optical images and Sentinel-1 synthetic-aperture radar images into maps of five different forest structure variables: 95th height percentile, mean height, density, Gini coefficient, and fractional cover. We train and test our model on reference data from 41 airborne laser scanning missions across Norway and demonstrate that it is able to generalize to unseen test regions, achieving normalized mean absolute errors between 11% and 15%, depending on the variable. Our work is also the first to propose a variant of so-called Bayesian deep learning to densely predict multiple forest structure variables with well-calibrated uncertainty estimates from satellite imagery. The uncertainty information increases the trustworthiness of the model and its suitability for downstream tasks that require reliable confidence estimates as a basis for decision making. We present an extensive set of experiments to validate the accuracy of the predicted maps as well as the quality of the predicted uncertainties. To demonstrate scalability, we provide Norway-wide maps for the five forest structure variables. © 2022 The Author(s)","Norway; Antennas; Biodiversity; Climate change; Decision making; Deep learning; Earth (planet); Forestry; Geometrical optics; Radar imaging; Satellite imagery; Space-based radar; Uncertainty analysis; Bayesian; Bayesian deep learning; Biodiversity loss; Country-scale; Forest structure; Multi-spectral; Optical-; Regional levels; Sentinel; Structure variables; Bayesian analysis; biodiversity; calibration; climate change; error analysis; forest cover; machine learning; model validation; satellite imagery; Sentinel; synthetic aperture radar; Synthetic aperture radar","Bayesian deep learning; Country-scale; Forest structure; Multispectral; SAR; Sentinel","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85144062328"
"Rastogi A.; Doegar A.","Rastogi, Aishwarya (57210701909); Doegar, Amit (39361254600)","57210701909; 39361254600","Object-based and rule-based classification of synthetic aperture radar images","2019","International Journal of Innovative Technology and Exploring Engineering","8","10","","2458","2463","5","10.35940/ijitee.J9534.0881019","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071237526&doi=10.35940%2fijitee.J9534.0881019&partnerID=40&md5=2d17b812f79cd9b9ecb1a6cb86f23eaf","Since thousands of years, the land is the basic and very important requirement for humans to survive and grow. The surface area of the earth provided by nature contains many different geographical locations divided into oceans, mountains, rivers, barren land, fertile land, ice caps and many more. The huge land masses and water bodies need to be observed and analyzed for optimum utilization of resources. Remote sensing is the best possible way to observe the earth's surface from a distance through different satellites and sensors. But most of the satellite images are not clear up to the extent to classify different terrain features accurately. Hence classification of image is needed to observe different terrain features in original images. In this study, the aim is to propose a branch of natural computation for SAR image classification into different terrain features with better information retrieval and accuracy measures as compared to traditional methods for satellite image classification. The object-based analysis has been used to extract spectral reflectance of five texture measures namely urban, rocky, vegetation, water and barren to generate training set. Minimum distance to mean classifier has been used with one of the Nature Inspired computation technique i.e. bacterial foraging optimization algorithm for the satellite image classification, to extract the more accurate information about land area of Alwar district, Rajasthan, India. In the proposed study a high-quality thematic map has been generated with the 7-band multi-spectral, medium-resolution satellite images. This approach provides the greater speed and accuracy in its computation with 97.43% overall accuracy (OA) and 0.96 Kappa co-efficient. © BEIESP.","","Bacterial Foraging Optimization Algorithm (BFOA); Land use land cover (LULC); Object-based image analysis (OBIA); Synthetic Aperture Radar (SAR) Image","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85071237526"
"Ebel P.; Schmitt M.; Zhu X.X.","Ebel, Patrick (57409415200); Schmitt, Michael (7401931279); Zhu, Xiao Xiang (55696622200)","57409415200; 7401931279; 55696622200","INTERNAL LEARNING FOR SEQUENCE-TO-SEQUENCE CLOUD REMOVAL VIA SYNTHETIC APERTURE RADAR PRIOR INFORMATION","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","2691","2694","3","10.1109/IGARSS47720.2021.9554268","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126275713&doi=10.1109%2fIGARSS47720.2021.9554268&partnerID=40&md5=951a4adea52293e8357ea690d73a0e20","Many observations acquired via optical satellites are polluted by cloud coverage, impeding a continuous and on-demand monitoring of the Earth. Recent advances in the field of cloud removal consider multi-temporal data to reconstruct pixels covered by clouds at a time point of interest. Yet, the limitation of preceding work is that information gets integrated over time, removing any temporal resolution from the de-clouded end products. In this work we consider a sequence-to-sequence approach, translating cloudy time series to a series of cloud-free multi-spectral images without the need of any external cloud-free data set. Our network is guided by synthetic aperture radar (SAR) information providing a strong prior for the reconstruction of cloud-covered information. We analyze the proposed method by visual inspection of predictions and in terms of error metrics to highlight its benefits. Finally, an ablation study is conducted in which the our network is compared against a baseline model and the effectiveness of the proposed SAR prior is demonstrated. © 2021 IEEE","Deep learning; Radar imaging; Remote sensing; Spectroscopy; Synthetic aperture radar; Time series; Cloud coverage; Cloud removal; Continuous demand; Deep learning; Internal learning; On demands; Optical imagery; Optical satellites; Prior information; Times series; Data fusion","cloud removal; data fusion; deep learning; optical imagery; synthetic aperture radar; time series","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85126275713"
"Sun S.; Hu C.","Sun, Shaojie (55611510700); Hu, Chuanmin (57195673046)","55611510700; 57195673046","The Challenges of Interpreting Oil-Water Spatial and Spectral Contrasts for the Estimation of Oil Thickness: Examples From Satellite and Airborne Measurements of the Deepwater Horizon Oil Spill","2019","IEEE Transactions on Geoscience and Remote Sensing","57","5","8529276","2643","2658","15","10.1109/TGRS.2018.2876091","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056325600&doi=10.1109%2fTGRS.2018.2876091&partnerID=40&md5=6faab18b1b377daa8608efd1e85a5b2b","Optical remote sensing is one of the most commonly used techniques to detect oil in the surface ocean. This is because oil has optical properties that are different from water to modulate oil-water spatial and spectral contrasts. However, understanding these contrasts is challenging because of variable results from laboratory and field experiments as well as from different observing conditions and spatial/spectral resolutions of remote sensing imagery. Here, through reviewing published oil-water spectral contrasts and analyzing remotely sensed spectra collected by several satellite and airborne sensors (MERIS, MODIS, MISR, Landsat, and AVIRIS) from the Deepwater Horizon oil spill, we provide the interpretation of the spatial/spectral contrasts of various oil slicks and discuss the challenges in such interpretations. In addition to oil thickness, several other factors also affect oil-water spatial/spectral contrasts, including sun glint strength, oil emulsification state, optical properties of oil covered water, and spatial/spectral resolutions of remote sensing imagery. In the absence of high spatial- and spectral-resolution imagery, a multistep scheme may be used to classify oil type (emulsion and non-emulsion) and to estimate relative oil thickness for each type based on the known optical properties of oil, yet such a scheme requires further research to improve and validate. © 1980-2012 IEEE.","Emulsification; Hyperspectral imaging; Image enhancement; Infrared spectrometers; Oil spills; Optical properties; Optical resolving power; Optical sensors; Radiometers; Space-based radar; Sun; Surface waves; Synthetic aperture radar; AVIRIS; HyperSpectral; LANDSAT; MERIS; MISR; MODIS; Multi-spectral; oil thickness; Oils; Optical imaging; Optical remote sensing; Optical surface waves; abundance estimation; airborne sensing; detection method; estimation method; image resolution; Landsat; MISR; MODIS; multispectral image; oil spill; optical property; remote sensing; satellite imagery; satellite sensor; spatial analysis; Remote sensing","AVIRIS; emulsification; hyperspectral; Landsat; MERIS; MISR; MODIS; multispectral; oil spill; oil thickness; optical remote sensing; resolution","Article","Final","","Scopus","2-s2.0-85056325600"
"Soldal I.H.; Dierking W.; Korosov A.; Marino A.","Soldal, Ingri Halland (57208164449); Dierking, Wolfgang (55903760300); Korosov, Anton (6505884703); Marino, Armando (34881857900)","57208164449; 55903760300; 6505884703; 34881857900","Automatic detection of small icebergs in fast ice using satellite Wide-Swath SAR images","2019","Remote Sensing","11","7","806","","","","10.3390/rs11070806","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063990860&doi=10.3390%2frs11070806&partnerID=40&md5=fa240b22d09161c2ca86894621f5422f","Automatic detection of icebergs in satellite images is regarded a useful tool to provide information necessary for safety in Arctic shipping or operations over large ocean areas in near-real time. In this work, we investigated the feasibility of automatic iceberg detection in Sentinel-1 Extra Wide Swath (EWS) SAR images which follow the preferred image mode in operational ice charting. As test region, we selected the Barents Sea where the size of many icebergs is on the order of the spatial resolution of the EWS-mode. We tested a new approach for a detection scheme. It is based on a combination of a filter for enhancing the contrast between icebergs and background, subsequent blob detection, and final application of a Constant False Alarm Rate (CFAR) algorithm. The filter relies mainly on the HV-polarized intensity which often reveals a larger difference between icebergs and sea ice or open water. The blob detector identifies locations of potential icebergs and thus shortens computation time. The final detection is performed on the identified blobs using the CFAR algorithm. About 2000 icebergs captured in fast ice were visually identified in Sentinel-2 Multi Spectral Imager (MSI) data and exploited for an assessment of the detection scheme performance using confusion matrices. For our performance tests, we used four Sentinel-1 EWS images. For judging the effect of spatial resolution, we carried out an additional test with one Sentinel-1 InterferometricWide Swath (IWS) mode image. Our results show that only 8-22 percent of the icebergs could be detected in the EWS images, and over 90 percent of all detections were false alarms. In IWS mode, the number of correctly identified icebergs increased to 38 percent. However, we obtained a larger number of false alarms in the IWS image than in the corresponding EWS image. We identified two problems for iceberg detection: 1) with the given frequency-polarization combination, not all icebergs are strong scatterers at HV-polarization, and (2) icebergs and deformation structures present on fast ice can often not be distinguished since both may reveal equally strong responses at HV-polarization. © 2019 by the authors.","Alarm systems; Data visualization; Errors; Geometrical optics; Ice problems; Image resolution; Polarization; Sea ice; Small satellites; Space-based radar; Spectroscopy; Synthetic aperture radar; CFAR; Constant false alarm rate algorithms; Deformation structure; iDPolRAD; Multi spectral imager; Number of false alarms; Operational ice charting; Optical image; Radar imaging","CFAR; Iceberg detection; iDPolRAD; Optical images; SAR","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85063990860"
"Zhang H.; Shen H.; Yuan Q.; Guan X.","Zhang, Hai (57192694132); Shen, Huanfeng (8359721100); Yuan, Qiangqiang (36635300800); Guan, Xiaobin (57191221261)","57192694132; 8359721100; 36635300800; 57191221261","Multispectral and SAR Image Fusion Based on Laplacian Pyramid and Sparse Representation","2022","Remote Sensing","14","4","870","","","","10.3390/rs14040870","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124700963&doi=10.3390%2frs14040870&partnerID=40&md5=b2620e2f3e8610763ac6ded42a6b016b","Complementary information from multi-sensors can be combined to improve the availabil-ity and reliability of stand-alone data. Typically, multispectral (MS) images contain plentiful spectral information of the Earth’s surface that is beneficial for identifying land cover types, while synthetic aperture radar (SAR) images can provide abundant information on the texture and structure of target objects. Therefore, this paper presents a fusion framework to integrate the information from MS and SAR images based on the Laplacian pyramid (LP) and sparse representation (SR) theory. LP is performed to decompose both the multispectral and SAR images into high-frequency components and low-frequency components, so that different processing strategies can be applied to multi-scale information. Low-frequency components are merged based on SR theory, whereas high-frequency components are combined based on a certain activity-level measurement, identifying salient features. Finally, LP reconstruction is performed to obtain the integrated image. We conduct experiments on several datasets to verify the effectiveness of the proposed method. Both visual interpretation and statistical analyses demonstrate that the proposed method strikes a satisfactory balance between spectral information preservation and the enhancement of spatial and textual characteristics. In addition, a further discussion regarding the adjustability property of the proposed method shows its flexibility for further application scenarios. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Image fusion; Laplace transforms; Radar imaging; Textures; Image quality assessment; Laplacian Pyramid; Laplacian pyramid representation; Multi sensor images; Multi-sensor image fusion; Multi-spectral; Sensor image fusion; Sparse representation; Spectral information; Synthetic aperture radar images; Synthetic aperture radar","Image quality assessment; Laplacian pyramid; Multi-sensor image fusion; Sparse representation; Synthetic aperture radar","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85124700963"
"Gao H.; Wang C.; Wang G.; Zhu J.; Tang Y.; Shen P.; Zhu Z.","Gao, Han (57190812153); Wang, Changcheng (24400348400); Wang, Guanya (57203937232); Zhu, Jianjun (6602928296); Tang, Yuqi (53865526100); Shen, Peng (57199323441); Zhu, Ziwei (57202502807)","57190812153; 24400348400; 57203937232; 6602928296; 53865526100; 57199323441; 57202502807","A crop classification method integrating GF-3 PolSAR and sentinel-2A optical data in the Dongting lake basin","2018","Sensors (Switzerland)","18","9","3139","","","","10.3390/s18093139","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053691254&doi=10.3390%2fs18093139&partnerID=40&md5=9b4385f8b8bb3c6ddd8e423eeac84120","With the increasing of satellite sensors, more available multi-source data can be used for large-scale high-precision crop classification. Both polarimetric synthetic aperture radar (PolSAR) and multi-spectral optical data have been widely used for classification. However, it is difficult to combine the covariance matrix of PolSAR data with the spectral bands of optical data. Using Hoekman’s method, this study solves the above problems by transforming the covariance matrix to an intensity vector that includes multiple intensity values on different polarization basis. In order to reduce the features redundancy, the principal component analysis (PCA) algorithm is adopted to select some useful polarimetric and optical features. In this study, the PolSAR data acquired by satellite Gaofen-3 (GF-3) on 19 July 2017 and the optical data acquired by Sentinel-2A on 17 July 2017 over the Dongting lake basin are selected for the validation experiment. The results show that the full feature integration method proposed in this study achieves an overall classification accuracy of 85.27%, higher than that of the single dataset method or some other feature integration modes. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Covariance matrix; Crops; Data integration; Lakes; Polarimeters; Principal component analysis; Space-based radar; Synthetic aperture radar; Crop classification; Dongting Lake; GF-3; Optical data; PolSAR data; Sentinel-2A; Classification (of information)","Crop classification; Data integration; Dongting lake basin; GF-3; Optical data; PolSAR data; Sentinel-2A","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85053691254"
"Shahateet K.; Seehaus T.; Navarro F.; Sommer C.; Braun M.","Shahateet, Kaian (57240722200); Seehaus, Thorsten (56724058100); Navarro, Francisco (7102666825); Sommer, Christian (57205459494); Braun, Matthias (55482393700)","57240722200; 56724058100; 7102666825; 57205459494; 55482393700","Geodetic mass balance of the south shetland islands ice caps, antarctica, from differencing tanDEM-X DEMs","2021","Remote Sensing","13","17","3408","","","","10.3390/rs13173408","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114046476&doi=10.3390%2frs13173408&partnerID=40&md5=5ae77123894d6b781130f115db707bac","Although the glaciers in the Antarctic periphery currently modestly contribute to sea level rise, their contribution is projected to increase substantially until the end of the 21st century. The South Shetland Islands (SSI), located to the north of the Antarctic Peninsula, are lacking a geodetic mass balance calculation for the entire archipelago. We estimated its geodetic mass balance over a 3–4-year period within 2013–2017. Our estimation is based on remotely sensed multispectral and interferometric SAR data covering 96% of the glacierized areas of the islands considered in our study and 73% of the total glacierized area of the SSI archipelago (Elephant, Clarence, and Smith Islands were excluded due to data limitations). Our results show a close to balance, slightly negative aver-age specific mass balance for the whole area of −0.106 ± 0.007 m w.e. a−1, representing a mass change of −238 ± 12 Mt a−1. These results are consistent with a wider scale geodetic mass balance estimation and with glaciological mass balance measurements at SSI locations for the same study period. They are also consistent with the cooling trend observed in the region between 1998 and the mid-2010s. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Sea level; Synthetic aperture radar; Antarctic Peninsula; Cooling trends; Data limitations; Interferometric SAR; Mass-balance calculations; Mass-balance estimation; Multi-spectral; South Shetland Islands; Geodesy","Antarctic Peninsula; Antarctic periphery; Glacier; Ice loss; Remote sensing; SAR","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85114046476"
"Calota I.; Faur D.; Datcu M.","Calota, Iulia (57221233198); Faur, Daniela (15041980400); Datcu, Mihai (7004523124)","57221233198; 15041980400; 7004523124","Estimating NDVI from SAR Images Using DNN","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","5232","5235","3","10.1109/IGARSS46834.2022.9884313","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140382425&doi=10.1109%2fIGARSS46834.2022.9884313&partnerID=40&md5=83f0b06ec610b15ec4ac285987fa5ffb","The Normalized Difference Vegetation Index (NDVI) is an important factor to be considered in vegetation tracking and analysis, which can be easily derived from multispectral (MS) images. However, the limitation imposed by the atmospheric conditions makes the calculation of this index difficult. Because of the clouds, only a limited number of multispectral bands can capture the land appropriately. Furthermore, the multispectral sensors are dependent on the sunlight, which makes the acquisition of data more limited. These limitations do not hinder other types of Earth Observation (EO) data, like the scenes captured by the Synthetic Aperture Radar (SAR). However, SAR images cannot be used in NDVI calculation. In this article, we propose a deep learning (DL) based method for NDVI estimation from SAR data. Using a database with corresponding MS and SAR patches, we calculate the NDVI for each sample, then use a convolutional neural network (CNN) for predicting the NDVI of SAR images. This simple method leads to a precision of 70% in NDVI estimation from SAR images. © 2022 IEEE.","Convolution; Convolutional neural networks; Deep learning; Radar imaging; Remote sensing; Vegetation; Atmospheric conditions; Convolutional neural network; Earth observation data; Learning-based methods; Multi-spectral; Multispectral images; Multispectral sensors; Normalized difference vegetation index; Synthetic aperture radar images; Vegetation index calculations; Synthetic aperture radar","Convolutional Neural Networks; Multispectral images; Normalized Difference Vegetation Index; Synthetic Aperture Radar","Conference paper","Final","","Scopus","2-s2.0-85140382425"
"Saha S.K.","Saha, Sudip Kumar (55961507700)","55961507700","Remote Sensing and Geographic Information System Applications in Hydrocarbon Exploration: A Review","2022","Journal of the Indian Society of Remote Sensing","50","8","","1457","1475","18","10.1007/s12524-022-01540-9","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127964553&doi=10.1007%2fs12524-022-01540-9&partnerID=40&md5=64071dd32116a322e4268424e4ae34ea","Hydrocarbon exploration requires integration and updating of multi-source geo-scientific data for gathering knowledge of subsurface oil and gas bearing geological traps. Multi-spectral aerospace remote sensing (RS) data is an important spatial geo-scientific information source for hydrocarbon exploration, when combine with data of ground based geophysical, geochemical and well log data, using geographic information system (GIS). This paper presents a review on current status as well as future prospects of satellite RS and GIS applications in hydrocarbon exploration. In recent years, satellite RS and GIS techniques successfully used for basin wide assessment of hydrocarbon favourable areas by integration and analysis of multi-spectral RS derived geological inputs on sedimentary basin, lithology, geomorphology, terrain, geological structure, tectonic information etc. RS and digital elevation model derived geomorphic anomalies in the forms of anomalous drainage pattern and surface lineament linked with subsurface structural features are widely used in onshore hydrocarbon prospecting. Commonly, in hydrocarbon reservoirs, a well-known phenomenon called seepage (both macro and micro) is associated with oil and gas leak from subsurface accumulations to the surface. Long-term hydrocarbon seepages locally alter surface geochemical and microbial processes. Recently, hyperspectral RS successfully used in onshore hydrocarbon exploration by detection of micro-seepage based on identification and mapping of altered clay minerals, bleaching of red beds and geo-botanical effects of vegetation stress. Hyperspectral satellite derived indices viz. Hydrocarbon index, vegetation indices, and spectral angle mapper and spectral unmixing classification techniques are used in micro-seepage detection. Number of studies showed the potential utility of satellite microwave synthetic aperture radar (SAR) data for offshore petroleum exploration by identification of sea surface oil slicks produced from sea floor hydrocarbon seeps. Use of satellite altimetry remote sensing technique also attempted for offshore hydrocarbon exploration by free air gravity anomalies derived geological details from satellite estimated geoid anomalies. Limited studies also highlighted potential applications of thermal and UAV (unmanned aerial vehicle) RS in hydrocarbon exploration. GIS aided both data and knowledge driven geospatial modelling were applied for identification of favourable potential hydrocarbon areas integration of RS derived geological and vegetation anomalies and ground geophysical, geochemical and well data. Although recent and past multi-spectral RS and GIS techniques are successfully used for petroleum exploration, in depth research studies needed in the use of hyperspectral, polarimetric microwave SAR, altimetry, thermal satellite data, UAV RS, and GIS aided spatial modeling for efficiently exploring petroleum resources. © 2022, Indian Society of Remote Sensing.","bleaching; digital elevation model; geoid; GIS; hydrocarbon exploration; image classification; lineament; mapping method; remote sensing; satellite altimetry; synthetic aperture radar","Hydrocarbon; Hyperspectral; Integrated spatial analysis; Microseepage; Radar; Spatial modeling","Review","Final","","Scopus","2-s2.0-85127964553"
"Aybar C.; Ysuhuaylas L.; Loja J.; Gonzales K.; Herrera F.; Bautista L.; Yali R.; Flores A.; Diaz L.; Cuenca N.; Espinoza W.; Prudencio F.; Llactayo V.; Montero D.; Sudmanns M.; Tiede D.; Mateo-García G.; Gómez-Chova L.","Aybar, Cesar (57210561007); Ysuhuaylas, Luis (58028914500); Loja, Jhomira (58028813900); Gonzales, Karen (58028914600); Herrera, Fernando (58029017000); Bautista, Lesly (58028967700); Yali, Roy (57391736700); Flores, Angie (57206421006); Diaz, Lissette (58029060400); Cuenca, Nicole (58028967800); Espinoza, Wendy (58028865700); Prudencio, Fernando (57310187700); Llactayo, Valeria (58028814100); Montero, David (57872964500); Sudmanns, Martin (56671340300); Tiede, Dirk (21935206500); Mateo-García, Gonzalo (57192947904); Gómez-Chova, Luis (6603354695)","57210561007; 58028914500; 58028813900; 58028914600; 58029017000; 58028967700; 57391736700; 57206421006; 58029060400; 58028967800; 58028865700; 57310187700; 58028814100; 57872964500; 56671340300; 21935206500; 57192947904; 6603354695","CloudSEN12, a global dataset for semantic understanding of cloud and cloud shadow in Sentinel-2","2022","Scientific Data","9","1","782","","","","10.1038/s41597-022-01878-2","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144636643&doi=10.1038%2fs41597-022-01878-2&partnerID=40&md5=7666a0dd6a2c6796243ee8f1aff46238","Accurately characterizing clouds and their shadows is a long-standing problem in the Earth Observation community. Recent works showcase the necessity to improve cloud detection methods for imagery acquired by the Sentinel-2 satellites. However, the lack of consensus and transparency in existing reference datasets hampers the benchmarking of current cloud detection methods. Exploiting the analysis-ready data offered by the Copernicus program, we created CloudSEN12, a new multi-temporal global dataset to foster research in cloud and cloud shadow detection. CloudSEN12 has 49,400 image patches, including (1) Sentinel-2 level-1C and level-2A multi-spectral data, (2) Sentinel-1 synthetic aperture radar data, (3) auxiliary remote sensing products, (4) different hand-crafted annotations to label the presence of thick and thin clouds and cloud shadows, and (5) the results from eight state-of-the-art cloud detection algorithms. At present, CloudSEN12 exceeds all previous efforts in terms of annotation richness, scene variability, geographic distribution, metadata complexity, quality control, and number of samples. © 2022, The Author(s).","Algorithms; Radar; Satellite Imagery; Semantics; Telemetry; algorithm; satellite imagery; semantics; telecommunication; telemetry","","Data paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85144636643"
"Hopkinson C.; Fuoco B.; Grant T.; Bayley S.E.; Brisco B.; Macdonald R.","Hopkinson, Chris (7006813492); Fuoco, Brendon (57221126693); Grant, Travis (57221119665); Bayley, Suzanne E. (57207529010); Brisco, Brian (7003505161); Macdonald, Ryan (36116992400)","7006813492; 57221126693; 57221119665; 57207529010; 7003505161; 36116992400","Wetland hydroperiod change along the upper columbia river floodplain, canada, 1984 to 2019","2020","Remote Sensing","12","24","4084","1","20","19","10.3390/rs12244084","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098289604&doi=10.3390%2frs12244084&partnerID=40&md5=0929c8c76c5f4551c6922a7996005906","Increasing air temperatures and changing hydrological conditions in the mountainous Kootenay Region of British Columbia, Canada are expected to affect floodplain wetland extent and function along the Columbia River. The objective of this study was to determine the seasonally inundated hydroperiod for a floodplain section (28.66 km2) of the Upper Columbia River wetlands complex using time series satellite image observations and binary open water mask extraction. A mid pixel resolution (30 m) optical satellite image time series of 61 clear sky scenes from the Landsat Thematic Mapper (TM) and Operational Land Imager (OLI) sensors were used to map temporal variations in floodplain open water wetland extent during the April to October hydrologically active season from 1984 to 2019 (35 years). The hydroperiod from the first 31 scenes (T1: 18 years) was compared to the second 30 (T2: 16 years) to identify changes in the permanent and seasonal open water bodies. The seasonal variation in open water extent and duration was similar across the two time periods but the permanent water body extent diminished by ~16% (or ~3.5% of the floodplain). A simple linear model (r2 = 0.87) was established to predict floodplain open water extent as a function of river discharge downstream of the case study area. Four years of Landsat Multi-Spectral Scanner (MSS) data from 1992 to 1995 (12 scenes) were examined to evaluate the feasibility of extending the hydroperiod record back to 1972 using lower resolution (60 m) archive data. While the MSS hydroperiod produced a similar pattern of open water area to duration to the TM/OLI hydroperiod, small open water features were omitted or expanded due to the lower resolution. While MSS could potentially extend the TM/OLI hydroperiod record, this was not performed as the loss of features like the river channel diminished its value for change detection purposes. Radarsat 2 scenes from 2015 to 2019 were examined to evaluate the feasibility of continued mountain valley hydroperiod monitoring using higher spatial and temporal resolution sensors like the Radarsat Constellation Mission (RCM). From the available horizontal transmit/receive (HH) single polarization sample set (8 scenes), the hydroperiod pattern of open water extent to duration was similar to the longer Landsat time series and possessed greater feature detail, but it was significantly reduced in seasonal inundation area due to the systematic omission of open water areas containing emergent vegetation. However, accepting that differences exist in sensor-based hydroperiod attributes, the higher temporal resolution of RCM will be suited to mountain floodplain inundation monitoring and open water hydroperiod analysis. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Banks (bodies of water); Floods; Function evaluation; Satellites; Space-based radar; Time series; Wetlands; British Columbia , Canada; Constellation missions; Floodplain inundation; Hydrological condition; Landsat Thematic Mapper; Operational land imager; Optical satellite images; Spatial and temporal resolutions; Rivers","Climate change; Columbia River; Floodplain wetlands; Hydroperiod; Landsat; Lidar; Synthetic aperture radar (SAR); Time series; Water mask","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85098289604"
"Zhai P.; Li S.; He Z.; Deng Y.; Hu Y.","Zhai, Pengfei (57216490182); Li, Shihua (57203292649); He, Ze (57200859080); Deng, Yuchuan (57222244695); Hu, Yueming (56701099200)","57216490182; 57203292649; 57200859080; 57222244695; 56701099200","COLLABORATIVE MAPPING RICE PLANTING AREAS USING MULTISOURCE REMOTE SENSING DATA","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","5969","5972","3","10.1109/IGARSS47720.2021.9553245","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120781251&doi=10.1109%2fIGARSS47720.2021.9553245&partnerID=40&md5=d220dbd26a6ed90004255f7c273f5586","Recent satellite missions have provided a variety of high spatial resolution, multi-spectral, and high-frequency revisit remote sensing datasets. The collaborative use of optical and synthetic aperture radar (SAR) imagery in remote sensing applications attracts considerable attention. The purpose of this paper is to investigate the contribution of both data to the rice planting area mapping. In particular, the red-edge band was introduced to construct a red-edge vegetation index based on Sentinel-2 data. C-band quad-pol Radarsat-2 data was also used. We finally used the random forest algorithm, collaborating with optical and radar data to map rice planting area. We found that the red-edge band and red-edge vegetation index can improve the classification accuracy compared to the classifier using NIR (near-infrared) band and NDVI (Normalized Difference Vegetation Index). The result shows that the jointly use of optical and radar data is feasible to map rice planting area. The overall accuracy, recall and F-measure are 0.9441, 0.9598 and 0.9680, respectively. © 2021 IEEE.","","Radarsat-2; Random forest; Red edge; Rice mapping; SAR; Sentinel-2","Conference paper","Final","","Scopus","2-s2.0-85120781251"
"Wangchuk S.; Bolch T.; Zawadzki J.","Wangchuk, Sonam (57224611372); Bolch, Tobias (55901447400); Zawadzki, Jarosław (7006144222)","57224611372; 55901447400; 7006144222","Towards automated mapping and monitoring of potentially dangerous glacial lakes in Bhutan Himalaya using Sentinel-1 Synthetic Aperture Radar data","2019","International Journal of Remote Sensing","40","12","","4642","4667","25","10.1080/01431161.2019.1569789","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061607625&doi=10.1080%2f01431161.2019.1569789&partnerID=40&md5=3dc50077981585429fda8ff3416fcbb4","The majority of glacial lakes around the world are located in remote and hardly accessible regions. The use of remote sensing data is therefore of high importance to identify and assess their potential hazards. However, the persistence of cloud cover, particularly in high mountain areas such as the Himalayas, limits the temporal resolution of optical satellite data with which we can monitor potentially dangerous glacial lakes (PDGLs). The ability of Synthetic Aperture Radar (SAR) satellites to collect data, irrespective of weather and at day or night, facilitates monitoring of PDGLs by without compromising temporal resolution. In this study, we present a semi-automated approach, based on a radar signal intensity threshold between water and non-water feature classes followed by post-processing including elevations, slopes, vegetation and size thresholds, to delineate glacial lakes in Sentinel-1 SAR images in Bhutan Himalaya. We show the capability of our method to be used for delineating and monitoring glacial lakes in Bhutan Himalaya by comparing our results to 10 m resolution Sentinel-2 multispectral data, field survey data, meteorological data, and a time series of monthly images from January to December 2016 of two lakes. Sentinel-1 SAR data can, moreover, be used for detecting lake surface area changes and open water area variations, at temporal resolution of six days, providing substantial advantages over optical satellite data to continuously monitor PDGLs. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Bhutan; Himalayas; Automation; Glacial geology; Lakes; Meteorology; Radar imaging; Remote sensing; Space-based radar; Weather satellites; Automated approach; Automated mapping; Meteorological data; Multi-spectral data; Optical satellites; Potential hazards; Remote sensing data; Temporal resolution; geological mapping; glacial lake; image resolution; mapping; monitoring; multispectral image; satellite data; Sentinel; synthetic aperture radar; temporal analysis; Synthetic aperture radar","","Article","Final","","Scopus","2-s2.0-85061607625"
"Sapucci G.R.; Negri R.G.","Sapucci, Gabriela Ribeiro (57214862380); Negri, Rogério Galante (54409218100)","57214862380; 54409218100","Hierarchical clustering and stochastic distance for indirect semi-supervised remote sensing image classification","2019","SN Applied Sciences","1","3","272","","","","10.1007/s42452-019-0278-x","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100713422&doi=10.1007%2fs42452-019-0278-x&partnerID=40&md5=ddb57d71f7f855b48935bcfad5fdca2b","Usually, image classification methods have supervised or unsupervised learning paradigms. While unsupervised methods do not need training data, the meanings behind the classified elements are not explicitly know. Conversely, supervised methods are able to provide classification results with an intrinsic meaning, since a labeled dataset is available for training, which may be a limitation in some cases. The semi-supervised learning paradigm, which simultaneously exploits both labeled and unlabeled data, may be an alternative to this dilemma. This work proposes a semi-supervised classification framework through the combination of the Hierarchical Divisive Algorithm and stochastic distance concepts, where the former is adopted to automatically determine clusters in the data and the latter is used to label such clusters in a supervised way. In order to verify the potential of the proposed framework, two case studies about land use and land cover classification were carried out in an Amazonian area using synthetic aperture radar and multispectral data acquired by ALOS PALSAR and LANDSAT-5 TM sensors. Supervised methods based on statistical concepts were also included in these studies as baselines. The results show that when very small training sets are available, the proposed method provides results up to 14.6% and 3.8% more accurate than the baselines with respect to the classification of TM and PALSAR images, respectively. © 2019, Springer Nature Switzerland AG.","Classification (of information); Hierarchical clustering; Land use; Remote sensing; Semi-supervised learning; Stochastic systems; Synthetic aperture radar; Classification methods; Classification results; Labeled and unlabeled data; Land-use and land cover classifications; Multi-spectral data; Remote sensing image classification; Semi-supervised classification; Statistical concepts; Image classification","Clustering; Image classification; Indirect model; Remote sensing; Semi-supervised; Stochastic distance","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85100713422"
"Petrushevsky N.; Manzoni M.; Guarnieri A.M.","Petrushevsky, N. (57275053800); Manzoni, M. (57202783363); Guarnieri, A.M. (57217210945)","57275053800; 57202783363; 57217210945","High-resolution urban mapping by fusion of sar and optical data","2021","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","43","B3-2021","","273","278","5","10.5194/isprs-archives-XLIII-B3-2021-273-2021","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115830901&doi=10.5194%2fisprs-archives-XLIII-B3-2021-273-2021&partnerID=40&md5=e1c8e564863c74bb23e4dbbd2efd6292","Mapping the exact extent of urban areas is a critical prerequisite in many remote sensing applications, such as hazard evaluation and change detection. The usage of Synthetical Aperture Radar (SAR) data has gained popularity due to the unique characteristics of the backscattered radio signal from human-made targets. The Sentinel-1 (S1) constellation, with a global revisit time of 6-12 days in Interferometric Wide Swath (IW) mode and free and open access to the data, allows the development of new applications to monitor urban sites. However, S1 is rarely considered when fine resolution is required due to the large pixel size and the need for spatial averaging to obtain robust estimators. We propose a method to improve Sentinel-1 urban classification performance by exploiting one Multi-Spectral (MS) image acquired by Sentinel-2 (S2). MS data is used for tracing the precise natural boundaries in a scene through superpixels segmentation. A machine learning approach is then applied to interpret the thematic context of each segment from short temporal stacks of coregistered SAR data. We use a short sensing period (around two months), so rapid changes can be traces. The proposed fusion of S1 and S2 data was tested in the area of Milan (Italy), with a total accuracy of about 90%. The ability to follow high-resolution details in a mixed environment is demonstrated, opening the possibility of efficiently tracing the human footprint. © 2021 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives. All rights reserved.","Image enhancement; Machine learning; Mapping; Pixels; Radar imaging; Remote sensing; Urban growth; High resolution; Land cover classification; Machine-learning; Optical data; Optical-; Radar data; SAR data; Segmentation; Sentinel-1; Urban mapping; Synthetic aperture radar","Land Cover Classification; Machine Learning; Optical; Segmentation; Synthetic Aperture Radar","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85115830901"
"Jain P.; Schoen-Phelan B.; Ross R.","Jain, Pallavi (57199743268); Schoen-Phelan, Bianca (57213267321); Ross, Robert (8843354800)","57199743268; 57213267321; 8843354800","MULTI-MODAL SELF-SUPERVISED REPRESENTATION LEARNING FOR EARTH OBSERVATION","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","3241","3244","3","10.1109/IGARSS47720.2021.9553741","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126055646&doi=10.1109%2fIGARSS47720.2021.9553741&partnerID=40&md5=5ee4d7f023d020ce050fce6fd5025bc1","Self-Supervised learning (SSL) has reduced the performance gap between supervised and unsupervised learning, due to its ability to learn invariant representations. This is a boon to the domains like Earth Observation (EO), where labelled data availability is scarce but unlabelled data is freely available. While Transfer Learning from generic RGB pre-trained models is still common-place in EO, we argue that, it is essential to have good EO domain specific pre-trained model in order to use with downstream tasks with limited labelled data. Hence, we explored the applicability of SSL with multi-modal satellite imagery for downstream tasks. For this we utilised the state-of-art SSL architectures i.e. BYOL and SimSiam to train on EO data. Also to obtain better invariant representations, we considered multi-spectral (MS) images and synthetic aperture radar (SAR) images as separate augmented views of an image to maximise their similarity. Our work shows that by learning single channel representations through non-contrastive learning, our approach can outperform ImageNet pre-trained models significantly on a scene classification task. We further explored the usefulness of a momentum encoder by comparing the two architectures i.e. BYOL and SimSiam but did not identify a significant improvement in performance between the models. © 2021 IEEE","","Satellite images; Self-supervised learning; Unsupervised learning","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85126055646"
"Ziemann A.; Pitts T.","Ziemann, Amanda (36134071500); Pitts, Travis (57221774710)","36134071500; 57221774710","Exploring feature augmentation as a method for improving panchromatic remote sensing change detection","2020","Proceedings of the IEEE Southwest Symposium on Image Analysis and Interpretation","2020-March","","9094619","82","85","3","10.1109/SSIAI49293.2020.9094619","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085482320&doi=10.1109%2fSSIAI49293.2020.9094619&partnerID=40&md5=40e11ccfc06a156236df19d20b593cde","Change detection seeks to identify temporal changes in material composition within a remotely sensed scene by comparing the pixels of two images collected at different points in time. Anomalous change detection (ACD), in particular, emphasizes changes that are different from how other pixels might have changed. This will suppress broader but potentially uninteresting changes, e.g., seasonal or pervasive changes like snow or shadowing. ACD algorithms are typically applied to physics-based imagery such as multispectral data or synthetic aperture radar data, making use of the finer signal discrimination enabled by the multi-band nature of the imagery. Here we are interested in panchromatic imagery, which, while typically at much higher spatial resolution, comes at the cost of less signal information per pixel (only one value, a measure of brightness). This lack of signal information makes it challenging to apply traditional change detection techniques. This research explores augmenting panchromatic imagery with multiple derived texture feature layers, such as variance or entropy, to create a pseudo multi-band image. The resulting multi-band feature-augmented panchromatic images can then be exploited using traditional ACD approaches. Experiments are shown using real panchromatic imagery collected from spaceborne platforms. © 2020 IEEE.","Pixels; Remote sensing; Synthetic aperture radar; Textures; Change detection; Material compositions; Multi-band images; Multi-spectral data; Panchromatic images; Signal discrimination; Signal information; Spatial resolution; Image analysis","anomalous change detection; feature augmentation; panchromatic; Remote sensing","Conference paper","Final","","Scopus","2-s2.0-85085482320"
"Zaina F.; Tapete D.","Zaina, Federico (57204923677); Tapete, Deodato (55221777800)","57204923677; 55221777800","Satellite-Based Methodology for Purposes of Rescue Archaeology of Cultural Heritage Threatened by Dam Construction","2022","Remote Sensing","14","4","1009","","","","10.3390/rs14041009","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125006842&doi=10.3390%2frs14041009&partnerID=40&md5=29dee570e1bfc6a75d138e8530953df6","The destruction of cultural heritage caused by dams represents a major issue especially in an age of climate change and narrowly focused development policies. To counteract this phe-nomenon, archaeologists and cultural heritage experts have relied upon rescue archaeology practices generally limited to fieldwork methodologies, while remote sensing of satellite imagery re-mains under-considered. To bridge this gap, we build on a multidisciplinary collaboration ex-ploring the potential of Synthetic Aperture Radar (SAR) and open access multispectral satellite imagery, for quantifying the archaeological evidence located within a prospective reservoir area before dam construction. Based on previous research by Marchetti (2020) claiming the necessity for ad hoc protocols to document and monitor the impact of dams on cultural heritage, we selected two complementary situations: the planned dam of Halabiyeh in Syria and the under construction Grand Ethiopian Renaissance Dam (GERD) in Ethiopia. These case studies were analyzed with state-of-the-art methodologies to develop a feasible workflow that may contribute to fostering the use of satellite imagery in operational contexts such as those represented by these particular cases, and be replicated by archaeologists in other areas. The workflow is designed to be integrated to ground-truthing methodologies into two dedicated protocols named Pre-Construction Archaeological Risk Assessment (PCARA) and Pre-Flooding Rescue Archaeological Program (PFRAP) which could eventually become a standard procedure for rescue archaeology in dams areas. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Bridges; Climate change; History; Radar imaging; Remote sensing; Reservoirs (water); Risk assessment; Satellite imagery; Synthetic aperture radar; COSMO-skymed; Cultural heritages; Dam construction; Development policies; Multi-disciplinary collaborations; Multi-spectral; Remote-sensing; Risks assessments; Sentinel-2; Work-flows; Dams","Archaeology; COSMO-SkyMed; Cultural heritage; Dams; Multispectral; Risk assessment; SAR; Satellite imagery; Sentinel-2","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85125006842"
"Li X.; Yang Y.; Yang B.; Yin F.","Li, Xin (56996899300); Yang, Yuhui (57201199785); Yang, Bo (57188670239); Yin, Feng (57216821180)","56996899300; 57201199785; 57188670239; 57216821180","A Multi-source Remote Sensing Image Matching Method Using Directional Phase Feature; [利用方向相位特征进行多源遥感影像匹配]","2020","Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University","45","4","","488","494","6","10.13203/j.whugis20180445","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084792457&doi=10.13203%2fj.whugis20180445&partnerID=40&md5=cf955090b59cdb6f0d246eb1cb17b446","A multi-source remote sensing image matching method using directional phase feature is proposed to solve the problem of matching multi-source remote sensing images with nonlinear radiometric differences. Firstly, feature points of reference image are extracted uniformly. And then phase congruency energy images in multiple directions are calculated using Log-Gabor filters. Dense character descriptions of feature points of the reference image are built. Finally, correspondences are obtained by sliding matching window and Taylor series expansion is used to fit to the sub pixel accuracy. Experiments on three groups of real heterogeneous remote sensing images show that the proposed method can achieve stable and reliable matching results on optical, infrared, multi-spectral and SAR (synthetic aperture radar)images. © 2020, Editorial Board of Geomatics and Information Science of Wuhan University. All right reserved.","Gabor filters; Image matching; Image registration; Radar imaging; Synthetic aperture radar; Log-gabor filter; Matching methods; Phase congruency; Reference image; Remote sensing images; SAR(synthetic aperture radar); Subpixel accuracy; Taylor series expansions; image analysis; imaging method; infrared imagery; multispectral image; nonlinearity; pattern recognition; pixel; radar imagery; remote sensing; synthetic aperture radar; Remote sensing","Directional phase congruency; Feature points; Image matching; Multi-source remote sensing image","Article","Final","","Scopus","2-s2.0-85084792457"
"Alami Machichi M.; El Mansouri L.; Imani Y.; Bourja O.; Hadria R.; Lahlou O.; Benmansour S.; Zennayi Y.; Bourzeix F.","Alami Machichi, Mouad (58029162000); El Mansouri, Loubna (57219924427); Imani, Yasmina (6508271701); Bourja, Omar (56607357700); Hadria, Rachid (6507578688); Lahlou, Ouiam (6507735462); Benmansour, Samir (57745828900); Zennayi, Yahya (57190219995); Bourzeix, François (37561013300)","58029162000; 57219924427; 6508271701; 56607357700; 6507578688; 6507735462; 57745828900; 57190219995; 37561013300","CerealNet: A Hybrid Deep Learning Architecture for Cereal Crop Mapping Using Sentinel-2 Time-Series","2022","Informatics","9","4","96","","","","10.3390/informatics9040096","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144662479&doi=10.3390%2finformatics9040096&partnerID=40&md5=388ea34c8bce46d258223e8168e52361","Remote sensing-based crop mapping has continued to grow in economic importance over the last two decades. Given the ever-increasing rate of population growth and the implications of multiplying global food production, the necessity for timely, accurate, and reliable agricultural data is of the utmost importance. When it comes to ensuring high accuracy in crop maps, spectral similarities between crops represent serious limiting factors. Crops that display similar spectral responses are notorious for being nearly impossible to discriminate using classical multi-spectral imagery analysis. Chief among these crops are soft wheat, durum wheat, oats, and barley. In this paper, we propose a unique multi-input deep learning approach for cereal crop mapping, called “CerealNet”. Two time-series used as input, from the Sentinel-2 bands and NDVI (Normalized Difference Vegetation Index), were fed into separate branches of the LSTM-Conv1D (Long Short-Term Memory Convolutional Neural Networks) model to extract the temporal and spectral features necessary for the pixel-based crop mapping. The approach was evaluated using ground-truth data collected in the Gharb region (northwest of Morocco). We noted a categorical accuracy and an F1-score of 95% and 94%, respectively, with minimal confusion between the four cereal classes. CerealNet proved insensitive to sample size, as the least-represented crop, oats, had the highest F1-score. This model was compared with several state-of-the-art crop mapping classifiers and was found to outperform them. The modularity of CerealNet could possibly allow for injecting additional data such as Synthetic Aperture Radar (SAR) bands, especially when optical imagery is not available. © 2022 by the authors.","","CerealNet; CNN; crop mapping; deep learning; LSTM; spectral similarity; time-series","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85144662479"
"Judah A.; Hu B.","Judah, Aaron (56104693300); Hu, Baoxin (7402044943)","56104693300; 7402044943","An Advanced Data Fusion Method to Improve Wetland Classification Using Multi-Source Remotely Sensed Data","2022","Sensors","22","22","8942","","","","10.3390/s22228942","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142730746&doi=10.3390%2fs22228942&partnerID=40&md5=5eda228f7684968503c62645cf8ec0e3","The goal of this research was to improve wetland classification by fully exploiting multi-source remotely sensed data. Three distinct classifiers were designed to distinguish individual or compound wetland categories using random forest (RF) classification. They were determined, in part, to best use the available remotely sensed features in order to maximize that information and to maximize classification accuracy. The results from these classifiers were integrated according to Dempster–Shafer theory (D–S theory). The developed method was tested on data collected from a study area in Northern Alberta, Canada. The data utilized were Landsat-8 and Sentinel-2 (multi-spectral), Sentinel-1 (synthetic aperture radar—SAR), and digital elevation model (DEM). Classification of fen, bog, marsh, swamps, and upland resulted in an overall accuracy of 0.93 using the proposed methodology, an improvement of 5% when compared to a traditional classification method based on the aggregated features from these data sources. It was noted that, with the traditional method, some pixels were misclassified with a high level of confidence (>85%). Such misclassification was significantly reduced (by ~10%) by the proposed method. Results also showed that some features important in separating compound wetland classes were not considered important using the traditional method based on the RF feature selection mechanism. When used in the proposed method, these features increased the classification accuracy, which demonstrated that the proposed method provided an effective means to fully employ available data to improve wetland classification. © 2022 by the authors.","Canada; Information Storage and Retrieval; Radar; Wetlands; Classification (of information); Data fusion; Decision trees; Landsat; Random forests; Remote sensing; Surveying; Synthetic aperture radar; Classification accuracy; Data fusion methods; Dempster-Shafer theory; Ensemble-classifier; Multi-Sources; Random forest classification; Random forests; Remotely sensed data; Study areas; Wetland classification; Canada; information retrieval; telecommunication; wetland; Wetlands","data fusion; Dempster–Shafer theory; ensemble classifier; multi-source; random forest; wetlands","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85142730746"
"Dubucq D.","Dubucq, D. (12798848100)","12798848100","Huge Oil Spill in the Desert: Fake News or Reality? the Remote Sensing Perspective","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8899028","9780","9783","3","10.1109/IGARSS.2019.8899028","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077697713&doi=10.1109%2fIGARSS.2019.8899028&partnerID=40&md5=d41f8b1264135749ee6c268fe5a6dc4d","Being able to detect surface hydrocarbons is of prime importance for plant, processing facilities and wells monitoring as well as for exploration purposes. In this case study, production oil was said to be wasted in the desert, in Northern Africa, in the vicinity of a production area. If a dark spot can be seen on the satellite images, how can we state for sure that it is hydrocarbon, or water? How can we answer that question, as a partner, or a government agency with no access or no easy access to the site? Hyperspectral data are not available. How far can we go with open-access multispectral, thermal and SAR images to answer the question and provide a tool to monitor the facility over time. © 2019 IEEE.","Geology; Hydrocarbon refining; Hydrocarbons; Monitoring; Oil spills; Petroleum industry; Petroleum prospecting; Synthetic aperture radar; Government agencies; Hyperspectral Data; Multi-spectral; Processing facilities; Production area; SAR Images; Satellite images; Thermal infrared; Remote sensing","monitoring; multispectral; Oil spill; thermal infrared","Conference paper","Final","","Scopus","2-s2.0-85077697713"
"Bartsch A.; Widhalm B.; Leibman M.; Ermokhina K.; Kumpula T.; Skarin A.; Wilcox E.J.; Jones B.M.; Frost G.V.; Höfler A.; Pointner G.","Bartsch, Annett (8709691100); Widhalm, Barbara (6506176864); Leibman, Marina (6602909851); Ermokhina, Ksenia (55453883200); Kumpula, Timo (57222997904); Skarin, Anna (24171972900); Wilcox, Evan J. (57198863740); Jones, Benjamin M. (16636910800); Frost, Gerald V. (54395292900); Höfler, Angelika (57192269268); Pointner, Georg (57194632496)","8709691100; 6506176864; 6602909851; 55453883200; 57222997904; 24171972900; 57198863740; 16636910800; 54395292900; 57192269268; 57194632496","Feasibility of tundra vegetation height retrieval from Sentinel-1 and Sentinel-2 data","2020","Remote Sensing of Environment","237","","111515","","","","10.1016/j.rse.2019.111515","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076042309&doi=10.1016%2fj.rse.2019.111515&partnerID=40&md5=179f8cf80216b767e382a5d82d6612a7","The quantification of vegetation height for the circumpolar Arctic tundra biome is of interest for a wide range of applications, including biomass and habitat studies as well as permafrost modelling in the context of climate change. To date, only indices from multispectral data have been used in these environments to address biomass and vegetation changes over time. The retrieval of vegetation height itself has not been attempted so far over larger areas. Synthetic Aperture Radar (SAR) holds promise for canopy modeling over large extents, but the high variability of near-surface soil moisture during the snow-free season is a major challenge for application of SAR in tundra for such a purpose. We hypothesized that tundra vegetation height can be derived from multispectral indices as well as from C-band SAR data acquired in winter (close to zero liquid water content). To test our hypothesis, we used C-band SAR data from Sentinel-1 and multi-spectral data from Sentinel-2. Results show that vegetation height can be derived with an RMSE of 44 cm from Normalized Difference Vegetation Index (NDVI) and 54 cm from Tasseled Cap Wetness index (TC). Retrieval from C-band SAR shows similar performance, but C-VV is more suitable than C-HH to derive vegetation height (RMSEs of 48 and 56 cm respectively). An exponential relationship with in situ height was evident for all tested parameters (NDVI, TC, C-VV and C-HH) suggesting that the C-band SAR and multi-spectral approaches possess similar capabilities including tundra biomass retrieval. Errors might occur in specific settings as a result of high surface roughness, high photosynthetic activity in wetlands or high snow density. We therefore introduce a method for combined use of Sentinel-1 and Sentinel-2 to address the ambiguities related to Arctic wetlands and barren rockfields. Snow-related deviations occur within tundra fire scars in permafrost areas in the case of C-VV use. The impact decreases with age of the fire scar, following permafrost and vegetation recovery. The evaluation of masked C-VV retrievals across different regions, tundra types and sources (in situ and circumpolar vegetation community classification from satellite data) suggests pan-Arctic applicability to map current conditions for heights up to 160 cm. The presented methodology will allow for new applications and provide advanced insight into changing environmental conditions in the Arctic. © 2019 The Authors","Arctic; Biomass; Climate change; Forestry; Permafrost; Radar; Snow; Soil moisture; Surface roughness; Synthetic aperture radar; Wetlands; Environmental conditions; Multispectral indices; Normalized difference vegetation index; Optical; Photosynthetic activity; Shrubs; Tasseled cap wetness; Tundra; biomass; climate change; environmental conditions; feasibility study; NDVI; permafrost; satellite data; Sentinel; shrub; soil moisture; soil-vegetation interaction; synthetic aperture radar; tundra; vegetation type; Vegetation","Optical; Radar; Shrubs; Tundra; Vegetation","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85076042309"
"Bartsch A.; Pointner G.; Ingeman-Nielsen T.; Lu W.","Bartsch, Annett (8709691100); Pointner, Georg (57194632496); Ingeman-Nielsen, Thomas (14068804900); Lu, Wenjun (55861171800)","8709691100; 57194632496; 14068804900; 55861171800","Towards circumpolar mapping of arctic settlements and infrastructure based on sentinel-1 and sentinel-2","2020","Remote Sensing","12","15","2368","","","","10.3390/RS12152368","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089689584&doi=10.3390%2fRS12152368&partnerID=40&md5=a2161703fedbc180bd50f80e104f04ee","Infrastructure expands rapidly in the Arctic due to industrial development. At the same time, climate change impacts are pronounced in the Arctic. Ground temperatures are, for example, increasing as well as coastal erosion. A consistent account of the current human footprint is needed in order to evaluate the impact on the environments as well as risk for infrastructure. Identification of roads and settlements with satellite data is challenging due to the size of single features and low density of clusters. Spatial resolution and spectral characteristics of satellite data are the main issues regarding their separation. The Copernicus Sentinel-1 and-2 missions recently provided good spatial coverage and at the same time comparably high pixel spacing starting with 10 m for modes available across the entire Arctic. The purpose of this study was to assess the capabilities of both, Sentinel-1 C-band Synthetic Aperture Radar (SAR) and the Sentinel-2 multispectral information for Arctic focused mapping. Settings differ across the Arctic (historic settlements versus industrial, locations on bedrock versus tundra landscapes) and reference data are scarce and inconsistent. The type of features and data scarcity demand specific classification approaches. The machine learning approaches Gradient Boosting Machines (GBM) and deep learning (DL)-based semantic segmentation have been tested. Records for the Alaskan North Slope, Western Greenland, and Svalbard in addition to high-resolution satellite data have been used for validation and calibration. Deep learning is superior to GBM with respect to users accuracy. GBM therefore requires comprehensive postprocessing. SAR provides added value in case of GBM. VV is of benefit for road identification and HH for detection of buildings. Unfortunately, the Sentinel-1 acquisition strategy is varying across the Arctic. The majority is covered in VV+VH only. DL is of benefit for road and building detection but misses large proportions of other human-impacted areas, such as gravel pads which are typical for gas and oil fields. A combination of results from both GBM (Sentinel-1 and-2 combined) and DL (Sentinel-2; Sentinel-1 optional) is therefore suggested for circumpolar mapping. © 2020 by the authors.","Adaptive boosting; Climate change; Deep learning; Mapping; Oil fields; Roads and streets; Satellites; Semantics; Space-based radar; Synthetic aperture radar; Acquisition strategies; Classification approach; High resolution satellite data; Impact on the environment; Industrial development; Machine learning approaches; Semantic segmentation; Spectral characteristics; Classification (of information)","Arctic; Infrastructure; Machine learning; Multi-spectral; SAR; Settlements","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85089689584"
"Wang L.; Xu X.; Yu Y.; Yang R.; Gui R.; Xu Z.; Pu F.","Wang, Lei (57211488504); Xu, Xin (56294598500); Yu, Yue (57214104632); Yang, Rui (57208294306); Gui, Rong (57211231417); Xu, Zhaozhuo (57171068000); Pu, Fangling (13408173100)","57211488504; 56294598500; 57214104632; 57208294306; 57211231417; 57171068000; 13408173100","SAR-to-optical image translation using supervised cycle-consistent adversarial networks","2019","IEEE Access","7","","8825802","129136","129149","13","10.1109/ACCESS.2019.2939649","70","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078034428&doi=10.1109%2fACCESS.2019.2939649&partnerID=40&md5=a6086960f8b2c0f3cb16077d491dcb0b","Optical remote sensing (RS) data suffer from the limitation of bad weather and cloud contamination, whereas synthetic aperture radar (SAR) can work under all weather conditions and overcome this disadvantage of optical RS data. However, due to the imaging mechanism of SAR and the speckle noise, untrained people are difficult to recognize the land cover types visually from SAR images. Inspired by the excellent image-to-image translation performance of Generative Adversarial Networks (GANs), a supervised Cycle-Consistent Adversarial Network (S-CycleGAN) was proposed to generate large optical images from the SAR images. When the optical RS data are unavailable or partly unavailable, the generated optical images can be alternative data that aid in land cover visual recognition for untrained people. The main steps of SAR-to-optical image translation were as follows. First, the large SAR image was split to small patches. Then S-CycleGAN was used to translate the SAR patches to optical image patches. Finally, the optical image patches were stitched to generate the large optical image. A paired SAR-optical image dataset which covered 32 Chinese cities was published to evaluate the proposed method. The dataset was generated from Sentinel-1 (SEN-1) SAR images and Sentinel-2 (SEN-2) multi-spectral images. S-CycleGAN was applied to two experiments, which were SAR-to-optical image translation and cloud removal, and the results showed that S-CycleGAN could keep both the land cover and structure information well, and its performance was superior to some famous image-to-image translation models. © 2013 IEEE.","Flow visualization; Geometrical optics; Remote sensing; Spectroscopy; Synthetic aperture radar; Adversarial networks; Cloud contamination; Cloud removal; Multispectral images; Optical image; Optical remote sensing; Sentinel; Structure information; Radar imaging","cloud removal; GAN; SAR-to-optical image translation; Sentinel; visualization","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85078034428"
"Ma C.; Li X.; McCabe M.F.","Ma, Chunfeng (55574615500); Li, Xin (55718307400); McCabe, Matthew F. (7202748891)","55574615500; 55718307400; 7202748891","Retrieval of high-resolution soil moisture through combination of Sentinel-1 and Sentinel-2 data","2020","Remote Sensing","12","14","2303","","","","10.3390/rs12142303","30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088626234&doi=10.3390%2frs12142303&partnerID=40&md5=1758469c950352976a9bcbdc2fa2d87d","Estimating soil moisture based on synthetic aperture radar (SAR) data remains challenging due to the influences of vegetation and surface roughness. Here we present an algorithm that simultaneously retrieves soil moisture, surface roughness and vegetation water content by jointly using high-resolution Sentinel-1 SAR and Sentinel-2 multispectral imagery, with an application directed towards the provision of information at the precision agricultural scale. Sentinel-2-derived vegetation water indices are investigated and used to quantify the backscatter resulting from the vegetation canopy. The proposed algorithm then inverts the water cloud model to simultaneously estimate soil moisture and surface roughness by minimizing a cost function constructed by model simulations and SAR observations. To examine the performance of VV- and VH-polarized backscatters on soil moisture retrievals, three retrieval schemes are explored: a single channel algorithm using VV (SCA-VV) and VH (SCA-VH) polarizations and a dual channel algorithm using both VV and VH polarizations (DCA-VVVH). An evaluation of the approach using a combination of a cosmic-ray soil moisture observing system (COSMOS) and Soil Climate Analysis Network measurements over Nebraska shows that the SCA-VV scheme yields good agreement at both the COSMOS footprint and single-site scales. The features of the algorithms that have the most impact on the retrieval accuracy include the vegetation water content estimation scheme, parameters of the water cloud model and the specification of initial ranges of soil moisture and roughness, all of which are comprehensively analyzed and discussed. Through careful consideration and selection of these factors, we demonstrate that the proposed SCA-VV approach can provide reasonable soil moisture retrievals, with RMSE ranging from 0.039 to 0.078 m3/m3 and R2 ranging from 0.472 to 0.665, highlighting the utility of SAR for application at the precision agricultural scale. © 2020 by the authors.","Agricultural robots; Agriculture; Backscattering; Cloud computing; Cosmic ray measurement; Cosmology; Cost functions; Polarization; Soil moisture; Surface roughness; Synthetic aperture radar; Vegetation; Water content; Estimation schemes; Multi-spectral imagery; Network measurement; Retrieval accuracy; Single-channel algorithms; Soil moisture retrievals; Vegetation water content; Water cloud models; Soil surveys","Microwave remote sensing; Precision agriculture; Soil moisture; Synthetic aperture radar","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85088626234"
"Hariharan K.; Rajaan N.R.; Chelliah P.P.R.; Deepika M.","Hariharan, K. (56370672300); Rajaan, N.R. (35072920000); Chelliah, Peter Pethuru Raj (55579667900); Deepika, Malini (55155476000)","56370672300; 35072920000; 55579667900; 55155476000","The Enriched Feature Enhancement Technique for Satellite Image Based on Transforms Using PCNN","2021","Wireless Personal Communications","117","4","","2729","2744","15","10.1007/s11277-020-07044-4","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078604715&doi=10.1007%2fs11277-020-07044-4&partnerID=40&md5=b54b5f4c5e6dc16111c8fbfcbbf7fa90","The features of the satellite images can be improved by fusing or combining two images with complementary property. By fusing these two images the spatial property of the resultant image is improved. Satellite images are one of the agents that give the features of the earth’s surface. Processing these satellite images will provide more geographical information hidden in the images. This research paper have an detailed insight study of two types of the satellite images one is Panchromatic (PAN) and other Multispectral (MS). The PAN image with high spatial resolution and MS image with spectral resolution are fused to get better resultant output. For fusion process Nonsubsampled Contour let Transform is used to decompose the images into low and high frequency values. Pulse Coupled Neural Network is used to motivate the low frequency pixel and Morphological filter is applied to the edge detected image for finding the features in the images. This is an real time transformations which will give better results in SAR image processing, video processing, stereo based reconstruction of depth and width of the features present in the image. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Neural networks; Satellites; Stereo image processing; Synthetic aperture radar; Video signal processing; Contourlet transform; Feature enhancement techniques; Geographical information; High spatial resolution; Low and high frequencies; Multi-spectral; Panchromatic (PAN); Pulse coupled neural network; Image enhancement","Multispectral (MS); Panchromatic (PAN); Pulse Coupled Neural Network (PCNN); Subsampled contourlet transform (SCT)","Article","Final","","Scopus","2-s2.0-85078604715"
"Zhang Y.; Thenkabail P.S.; Wang P.","Zhang, YuYing (57205423318); Thenkabail, Prasad S. (57203279842); Wang, Peng (57195321846)","57205423318; 57203279842; 57195321846","A bibliometric profile of the Remote Sensing Open Access Journal published by MDPI between 2009 and 2018","2019","Remote Sensing","11","1","91","","","","10.3390/rs11010091","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059935709&doi=10.3390%2frs11010091&partnerID=40&md5=c520ebefcb3419e05cf052f5948378d1","Remote Sensing Open Access Journal (RS OAJ) is an international leading journal in the field of remote sensing science and technology. It was first published in the year 2009 and is currently celebrating tenth year of publications. In this research, a bibliometric analysis of RS OAJ was conducted based on 5588 articles published during the 10-year (2009-2018) time-period. The bibliometric analysis includes a comprehensive set of indicators such as dynamics and trends of publications, journal impact factor, total cites, eigenfactor score, normalized eigenfactor, CiteScore, h-index, h-classic publications, most productive countries (or territories) and institutions, co-authorship collaboration about countries (territories), research themes, citation impact of co-occurrences keywords, intellectual structure, and knowledge commutation. We found that publications of RS OAJ presented an exponential growth in the past ten years. From 2010 to 2017 (for which complete years data were available), the h-index of RS OAJ is 67. From 2009-2018, RS OAJ includes publications from 129 countries (or territories) and 3826 institutions. The leading nations contributing articles, based on 2009-2018 data, and listed based on ranking were: China, United States, Germany, Italy, France, Spain, Canada, England, Australia, Netherlands, Japan, Switzerland and Austria. The leading institutions, also for the same period and listed based on ranking were: Chinese Academy of Sciences, Wuhan University, University of Chinese Academy of Sciences, Beijing Normal University, The university of Maryland, National Aeronautics and Space Administration, National Oceanic and Atmospheric Administration, China University of Geosciences, United States Geological Survey, German Aerospace Centre, University of Twente, and California Institute of Technology. For the year 2017, RS OAJ had an impressive journal impact factor of 3.4060, a CiteScore of 4.03, eigenfactor score of 0.0342, and normalized eigenfactor score of 3.99. In addition, based on 2009-2018, data co-word analysis determined that ""remote sensing"", ""MODIS"", ""Landsat"", ""LiDAR"" and ""NDVI"" are the high-frequency of author keywords co-occurrence in RS OAJ. The main themes of RS OAJ are multi-spectral and hyperspectral remote sensing, LiDAR scanning and forestry remote sensing monitoring, MODIS and LAI data applications, Remote sensing applications and Synthetic Aperture Radar (SAR). Through author keywords citation impact analysis, we find the most influential keyword is Unmanned Aerial Vehicle (UAV), followed, forestry, Normalized Difference Vegetation Index (NDVI), terrestrial laser scanning, airborne laser scanning, forestry inventory, urban heat island, monitoring, agriculture, and laser scanning. By analyzing the intellectual structure of RS OAJ, we identify the main reference publications and find that the themes are about Random Forests, MODIS vegetation indices and image analysis, etc. RS OAJ ranks first in cited journals and third in citing, this indicates that RS OAJ has the internal knowledge flow. Our results will bring more benefits to scholars, researchers and graduate students, who hopes to get a quick overview of the RS OAJ. And this article will also be the starting point for communication between scholars and practitioners. Finally, this paper proposed a nuanced h-index (nh-index) to measure productivity and intellectual contribution of authors by considering h-index based on whether the one is first, second, third, or nth author. This nuanced approach to determining h-index of authors is powerful indicator of an academician's productivity and intellectual contribution. © 2019 by the authors.","Antennas; Decision trees; Forestry; Indexing (of information); Laser applications; NASA; Optical radar; Productivity; Publishing; Radiometers; Scanning; Space optics; Space-based radar; Students; Synthetic aperture radar; Timber; Unmanned aerial vehicles (UAV); Vegetation; Bibliometric; California Institute of Technology; Citation impact; Hyperspectral remote sensing; National Oceanic and Atmospheric Administration; Normalized difference vegetation index; Scientific journals; United states geological surveys; Remote sensing","Bibliometric; Citation impact; Remote sensing; Research theme; Scientific journals evaluation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85059935709"
"Xi Z.; Xu H.; Xing Y.; Gong W.; Chen G.; Yang S.","Xi, Zhilong (57415894800); Xu, Huadong (55493773900); Xing, Yanqiu (26656347100); Gong, Weishu (55968257300); Chen, Guizhen (57416022500); Yang, Shuhang (57416158500)","57415894800; 55493773900; 26656347100; 55968257300; 57416022500; 57416158500","Forest Canopy Height Mapping by Synergizing ICESat-2, Sentinel-1, Sentinel-2 and Topographic Information Based on Machine Learning Methods","2022","Remote Sensing","14","2","364","","","","10.3390/rs14020364","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122988635&doi=10.3390%2frs14020364&partnerID=40&md5=892c942229504db6f0125b815ec16872","Spaceborne LiDAR has been widely used to obtain forest canopy heights over large areas, but it is still a challenge to obtain spatio-continuous forest canopy heights with this technology. In order to make up for this deficiency and take advantage of the complementary for multi-source remote sensing data in forest canopy height mapping, a new method to estimate forest canopy height was proposed by synergizing the spaceborne LiDAR (ICESat-2) data, Synthetic Aperture Radar (SAR) data, multi-spectral images, and topographic data considering forest types. In this study, National Geographical Condition Monitoring (NGCM) data was used to extract the distributions of coniferous forest (CF), broadleaf forest (BF), and mixed forest (MF) in Hua’ nan forest area in Heilongjiang Province, China. Accordingly, the forest canopy height estimation models for whole forest (all forests together without distinguishing types, WF), CF, BF, and MF were established, respectively, by Radom Forest (RF) and Gradient Boosting Decision Tree (GBDT). The accuracy for established models and the forest canopy height obtained based on estimation models were validated consequently. The results showed that the forest canopy height estimation models considering forest types had better performance than the model grouping all types of forest together. Compared with GBDT, RF with optimal variables had better performance in forest canopy height estimation with Pearson’s correlation coefficient (R) and the root-mean-squared error (RMSE) values for CF, BF, and MF of 0.72, 0.59, 0.62, and 3.15, 3.37, 3.26 m, respectively. It has been validated that a synergy of ICESat-2 with other remote sensing data can make a crucial contribution to spatio-continuous forest canopy height mapping, especially for areas covered by different types of forest. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Adaptive boosting; Condition monitoring; Forestry; Machine learning; Mean square error; Optical radar; Photomapping; Remote sensing; Spectroscopy; Synthetic aperture radar; Canopy heights; Coniferous forests; Forest canopies; Forest canopy height; Forest type; Height mapping; ICESat-2; Sentinel-1; Sentinel-2; Topographic information; Decision trees","Forest canopy height; Forest type; ICESat-2; Machine learning; Sentinel-1; Sentinel-2; Topographic information","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85122988635"
"Li H.; Zhu F.; Zheng X.; Liu M.; Chen G.","Li, Haoyang (57848525400); Zhu, Fangjie (57738383900); Zheng, Xiaoyu (57737378700); Liu, Mengxi (57208160778); Chen, Guangzhao (57193994470)","57848525400; 57738383900; 57737378700; 57208160778; 57193994470","MSCDUNet: A Deep Learning Framework for Built-Up Area Change Detection Integrating Multispectral, SAR, and VHR Data","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","5163","5176","13","10.1109/JSTARS.2022.3181155","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131798039&doi=10.1109%2fJSTARS.2022.3181155&partnerID=40&md5=45cf5796084b53df2664eb4af6d0f62e","Built-up area change detection (CD) plays an important role in city management, which always uses very high spatial resolution (VHR) remote sensing data to extract refined spatial information. Recently, many CD models based on deep learning with VHR data have been proposed. However, due to the complex background information and natural landscape changes, VHR with optical RGB features is hard to extract changes exactly. To this end, we tend to explore the abundant channel information of multispectral and SAR data as a supplement to the refined spatial features of VHR images. We propose a new deep learning framework called multisource CD UNet++ (MSCDUNet), integrating multispectral, SAR, and VHR data for built-up area CD. First, we label and reform two new built-up area CD datasets containing multispectral, SAR, and VHR data: multisource built-up change (MSBC) and multisource OSCD (MSOSCD) datasets. Second, a feature selection method based on random forest is introduced to choose effective features from multispectral and SAR images. Finally, a multilevel heterogeneous feature fusion module is embedded in MSCDUNet to combine multifeatures for CD. Experiments are conducted on both the MSOSCD and the MSBC datasets. Compared to other CD methods based on VHR images, our proposal achieves the highest accuracy on both datasets and proves the effectiveness of multispectral, SAR, and VHR data fusion for CD. The dataset in the article will be available for download from the following link.1  © 2008-2012 IEEE.","Data integration; Data mining; Decision trees; Deep learning; Radar imaging; Remote sensing; Synthetic aperture radar; Area-changes; Benchmark datasets; Build-up; Built-up areas; Change detection; Deep learning; Multi-spectral data; Multispectral data fusion; Very high resolution; Very high-resolution; detection method; machine learning; multispectral image; remote sensing; satellite data; spatial resolution; synthetic aperture radar; Data fusion","Benchmark dataset; built-up; change detection (CD); deep learning (DL); multispectral data fusion; very high resolution (VHR)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85131798039"
"Jing H.; Feng Y.; Zhang W.; Zhang Y.; Wang S.; Fu K.; Chen K.","Jing, Hao (57213194651); Feng, Yingchao (57210817570); Zhang, Wenkai (57194594257); Zhang, Yue (56971657300); Wang, Siyue (57204970785); Fu, Kun (7202283802); Chen, Kaiqiang (57200269572)","57213194651; 57210817570; 57194594257; 56971657300; 57204970785; 7202283802; 57200269572","Effective Classification of Local Climate Zones Based on Multi-Source Remote Sensing Data","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898475","2666","2669","3","10.1109/IGARSS.2019.8898475","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077722438&doi=10.1109%2fIGARSS.2019.8898475&partnerID=40&md5=259ad332b3f1d0b9203517848b587f22","The local climate zone (LCZ) classification divides the urban areas into 17 categories, which are composed of 10 manmade structures and 7 natural landscapes. Though originally designed for temperature study, LCZ classification can be used for studies on economy and population. In this paper, we achieve a LCZ classification with convolutional neural networks based on the multi-source remote sensing data, including the polarimetric synthetic aperture radar (PolSAR) data and the corresponding multi-spectral imagery (MSI). Through experiments we attempt to reveal the contributions of the SAR data and the MSI to the classification performance. Furthermore, we emphasize the crucial importance of the preprocessing on the training data to derive a balanced dataset. We are ranked second in the Tianchi competition rankings when we submit our results. © 2019 IEEE.","Convolution; Convolutional neural networks; Geology; Spectroscopy; Synthetic aperture radar; Classification performance; Local climate; Man-made structures; Multi modality; Multi-spectral imagery; Natural landscapes; Polarimetric synthetic aperture radars; Remote sensing data; Remote sensing","convolutional neural networks; local climate zone (LCZ) classification; Multi-modality; multispectral imagery; SAR","Conference paper","Final","","Scopus","2-s2.0-85077722438"
"Fu Z.; Qi J.; Zhang D.; Wang J.; Zhang W.; Han X.","Fu, Zhengbo (57206674533); Qi, Jianwei (55821319700); Zhang, Dandan (57206663630); Wang, Jie (57206675662); Zhang, Wei (57206658072); Han, Xu (57206658269)","57206674533; 55821319700; 57206663630; 57206675662; 57206658072; 57206658269","Comparative Analysis of the Fusion Methods Based on GF-3 Radar and GF-1 Multispectral Data","2018","5th International Workshop on Earth Observation and Remote Sensing Applications, EORSA 2018 - Proceedings","","","8598556","","","","10.1109/EORSA.2018.8598556","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061824193&doi=10.1109%2fEORSA.2018.8598556&partnerID=40&md5=72644bdbfb65be2dfb12d6b3d435b055","To make better use of the advantages of radar and promote the application of image fusion based on radar data, the author uses different fusion methods based on GF-3 SAR and GF-1 MSS, and evaluates the fusion results by analyzing mean, variance, information entropy, average gradient, spectral distortion and correlation coefficient. The results show that HSV and GS transforms have the best performances in overall. PC is recognized as the third, while it is still remarkable that it has the best ability of spectral retention. And the specialty in NIR band makes PC more conducive for extraction of vegetation. Brovey and Multiplicative transforms are not effective in comparison. © 2018 IEEE.","Fusion reactions; Observatories; Radar imaging; Remote sensing; Synthetic aperture radar; Comparative analysis; Correlation coefficient; GF-3; Information entropy; Multi-spectral data; Multiplicative transforms; Multispectral images; Spectral distortions; Image fusion","fusion; GF-3; multispectral image; remote sensing; SAR","Conference paper","Final","","Scopus","2-s2.0-85061824193"
"Akhtar N.; Choubey N.S.; Ragavendran U.","Akhtar, Nadeem (57225360343); Choubey, Nitin S. (36163000600); Ragavendran, U. (57198451783)","57225360343; 36163000600; 57198451783","Investigation of non-natural information from remote sensing images: A case study approach","2019","EAI/Springer Innovations in Communication and Computing","","","","165","199","34","10.1007/978-3-030-02674-5_12","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070326126&doi=10.1007%2f978-3-030-02674-5_12&partnerID=40&md5=cc20fde85a5148f30ea30a9f7c43c1f9","The frequent changes in natural and non-natural information on the earth can be imaged using remote sensing (RS) techniques. Non-natural information changes are more frequent than natural changes on the planet; thus, they have a drastic impact on geographical information systems (GIS). Revolutions in satellite imaging technology have improved the interpretation of non-natural information (e.g., roads, buildings, bridges, dams) for GIS updates in a shorter period of time compared with ground surveying. The interpretation of road information is particularly vital for navigation. High-resolution RS images provide a good interpretation of road information; however, different interferences (e.g., building rooftops, parking lots, shadows from buildings, trees, vehicles) appear as noise, which reduces the efficiency of the extraction. In this chapter, different types of RS images are investigated, including panchromatic, aerial, multispectral, synthetic-aperture radar, and light detection and ranging. © Springer Nature Switzerland AG 2019.","Antennas; Geographic information systems; Imaging techniques; Optical radar; Roads and streets; Synthetic aperture radar; Tracking radar; Case study approach; High-resolution RS images; Light detection and ranging; Multi-spectral; Parking lots; Remote sensing images; Remote sensing techniques; Satellite imaging; Remote sensing","Artificial Intelligent and Information Systems; Image Computing and Navigation Systems; Remote Sensing; Road Detection","Book chapter","Final","","Scopus","2-s2.0-85070326126"
"Zhang D.; Gade M.; Zhang J.","Zhang, Di (57220961814); Gade, Martin (7004090435); Zhang, Jianwei (57834225000)","57220961814; 7004090435; 57834225000","SOFNet: SAR-Optical Fusion Network for Land Cover Classification","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","2409","2412","3","10.1109/IGARSS47720.2021.9554070","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129799056&doi=10.1109%2fIGARSS47720.2021.9554070&partnerID=40&md5=bab54dcb4572a80eab2063fa7aab166f","The objective of this research is to realize automatic land cover classification from synthetic aperture radar (SAR) and multispectral remote sensing imagery. We develop a SAR-optical fusion network (SOFNet) with the symmetric cross entropy (SCE) loss to utilize both the SAR and optical information in a novel deep neural network. The proposed framework has been trained on the public SEN12MS dataset and tested on the 2020 IEEE-GRSS Data Fusion Contest (DFC2020) dataset. Experimental results show that our approach takes full advantage of multimodal information and outperforms the state-of-the-art convolutional architectures. © 2021 IEEE","Convolutional neural networks; Data fusion; Deep neural networks; Radar imaging; Remote sensing; Cross entropy; Deep learning; Entropy loss; Land cover classification; Multi-modal fusion; Multi-spectral; Multispectral remote sensing imagery; Optical-; Radar remote sensing; Symmetrics; Synthetic aperture radar","deep learning; land cover classification; multimodal fusion; multispectral; SAR","Conference paper","Final","","Scopus","2-s2.0-85129799056"
"Carcereri D.; Rizzoli P.; Ienco D.; Bueso-Bello J.-L.; Gonzalez C.; Puliti S.; Brurzone L.","Carcereri, Daniel (57214083599); Rizzoli, Paola (36816379500); Ienco, Dino (25027558600); Bueso-Bello, Jose-Luis (55574699800); Gonzalez, Carolina (56306945700); Puliti, Stefano (56784209400); Brurzone, Lorenzo (57964644300)","57214083599; 36816379500; 25027558600; 55574699800; 56306945700; 56784209400; 57964644300","Large Scale Forest Parameter Estimation Through a Deep Learning-Based Fusion of Sentinel-2 and Tandem-X Data","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","5773","5776","3","10.1109/IGARSS46834.2022.9884872","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141882817&doi=10.1109%2fIGARSS46834.2022.9884872&partnerID=40&md5=b4a2aa2cabba2c1343e3f57533fb2035","The estimation of forest parameters, such as canopy height model (CHM) and above ground biomass (AGB), is of ut-most importance for forest monitoring, carbon-cycle modelling, disturbance analysis, resource inventorying and natural disaster prevention. In this work, we profit from the most recent advancements in deep learning research to propose a convolutional neural network (CNN) architecture for frequent forest parameter estimation at large scale. Our technique consists of a fully convolutional, multi-modal framework, which works on a single set of complementary multi-spectral and interferometric SAR data, acquired by ESA's Sentinel-2 and DLR's TanDEM-X missions, respectively. The regression performance of our framework has been tested over four tropical forest test sites in Gabon, Africa. The estimation of CHM shows promising early results when compared to state-of-the-art methods and has the advantage of requiring only a single input image pair instead of a longer time-series, as commonly done for state-of-the-art model-based techniques. © 2022 IEEE.","Convolution; Convolutional neural networks; Deep learning; Disaster prevention; Forestry; Remote sensing; Synthetic aperture radar; Canopy Height Models; Deep learning; Forest height; Forest monitoring; Forest parameters; Large-scales; Parameters estimation; Sensor fusion; Sentinel-2; TanDEM-X; Parameter estimation","deep learning; forest height; forest monitoring; sensor fusion; Sentinel-2; TanDEM-X","Conference paper","Final","","Scopus","2-s2.0-85141882817"
"Montanaro A.; Valsesia D.; Fracastoro G.; Magli E.","Montanaro, Antonio (57245937400); Valsesia, Diego (55968886600); Fracastoro, Giulia (56344146600); Magli, Enrico (7003771643)","57245937400; 55968886600; 56344146600; 7003771643","Semi-Supervised Learning for Joint SAR and Multispectral Land Cover Classification","2022","IEEE Geoscience and Remote Sensing Letters","19","","2506305","","","","10.1109/LGRS.2022.3195259","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135764301&doi=10.1109%2fLGRS.2022.3195259&partnerID=40&md5=43d1b9df985e86d151b038549347ac94","Semisupervised learning techniques are gaining popularity due to their capability of building models that are effective, even when scarce amounts of labeled data are available. In this letter, we present a framework and specific tasks for self-supervised pretraining of multichannel models, such as the fusion of multispectral and synthetic aperture radar (SAR) images. We show that the proposed self-supervised approach is highly effective at learning features that correlate with the labels for land cover classification. This is enabled by an explicit design of pretraining tasks which promotes bridging the gaps between sensing modalities and exploiting the spectral characteristics of the input. In a semisupervised setting, when limited labels are available, using the proposed self-supervised pretraining, followed by supervised fine-tuning for land cover classification with SAR and multispectral data, outperforms conventional approaches such as purely supervised learning, initialization from training on ImageNet, and other recent self-supervised approaches.  © 2004-2012 IEEE.","Classification (of information); Image classification; Iron; Radar imaging; Remote sensing; Supervised learning; Features extraction; Land cover classification; Multi-spectral; Multispectral images; Pre-training; Remote-sensing; Self-supervised learning; Semi-supervised learning; Semi-supervised learning techniques; Task analysis; image analysis; land classification; land cover; numerical model; spectral analysis; supervised learning; synthetic aperture radar; Synthetic aperture radar","Land cover classification; Multispectral images; Self-supervised learning (SSL); Semisupervised learning; Synthetic aperture radar (SAR)","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85135764301"
"Gawlikowski J.; Schmitt M.; Kruspe A.; Zhu X.X.","Gawlikowski, Jakob (57222241665); Schmitt, Michael (7401931279); Kruspe, Anna (54971261400); Zhu, Xiao Xiang (55696622200)","57222241665; 7401931279; 54971261400; 55696622200","On the Fusion Strategies of Sentinel-1 and Sentinel-2 Data for Local Climate Zone Classification","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324234","2081","2084","3","10.1109/IGARSS39084.2020.9324234","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090327381&doi=10.1109%2fIGARSS39084.2020.9324234&partnerID=40&md5=6525395c9271e39a1bb4f0b60d16b841","Local Climate Zone (LCZ) classification is the most commonly used scheme to analyze how local urban morphology affects the climate of local areas. Classification methods are often based on remote sensing data or on a fusion of several data sources. In this study, the effects of different fusion strategies of optical and synthetic aperture radar (SAR) data on the accuracy of LCZ classifications are investigated. The data processing is implemented with a convolutional neural network (CNN), where until a fusion layer, separate data sources are processed separately on branches. Strategies of splitting the data into branches and the effects of different fusion stages are compared, together with approaches based on sums of independent classifiers. For our setting, the stage of fusion does not seem to have a big influence on the accuracy. The results of this study contribute to a better understanding of cooperative usage of multispectral and SAR data. © 2020 IEEE.","Convolutional neural networks; Data handling; Geology; Multilayer neural networks; Remote sensing; Synthetic aperture radar; Classification methods; Fusion layers; Fusion strategies; Independent classifiers; Multi-spectral; Remote sensing data; Urban morphology; Zone classifications; Classification (of information)","Data Fusion; Fusion Network; Local Climate Zone Classification","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85090327381"
"Tapete D.; Cigna F.","Tapete, D. (55221777800); Cigna, F. (36720533600)","55221777800; 36720533600","Mapping impact of urbanization in Shahat-Cyrene (Libya) using a big SAR data approach of change detection with COSMO-SkyMed time series","2020","IOP Conference Series: Earth and Environmental Science","509","1","012056","","","","10.1088/1755-1315/509/1/012056","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088513516&doi=10.1088%2f1755-1315%2f509%2f1%2f012056&partnerID=40&md5=abc829b3c6d7a2a2996ebdb3aeac9db3","Uncontrolled and unregulated urbanization around the modern town of Shahat, Libya, has been reported by several studies as a pressing issue for the conservation of archaeological heritage in the cultural landscape south of Cyrene UNESCO World Heritage Site (WHS). In this paper, we implemented a big Synthetic Aperture Radar (SAR) data analysis approach on a selection of more than 180 StripMap images that the Italian Space Agency (ASI)'s COSMO-SkyMed constellation has consistently collected at 3-m resolution over Cyrene since 2011, as part of its background acquisition scenario. We prove the accuracy of the method to map the spatial and temporal spread of new building and road blocks using COSMO-SkyMed SAR data, and its complementarity with the mapping based on the full archive of cloud-free Copernicus Sentinel-2 multi-spectral imagery at 10-m resolution (2015-2017). Owing to the higher spatial resolution and half-month frequency of observation of COSMO-SkyMed, we better delineated the new urban features and estimated more precisely when these were developed across the landscape. © 2020 Published under licence by IOP Publishing Ltd.","Photomapping; Radar imaging; Spectroscopy; Urban growth; Analysis approach; Change detection; Cultural landscape; Italian Space Agency; Multi-spectral imagery; Spatial resolution; UNESCO world heritages; Urban features; Synthetic aperture radar","","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85088513516"
"Aswatha S.M.; Saini V.; Mukherjee J.; Biswas P.K.; Aikat S.; Misra A.","Aswatha, Shashaank M. (55001806100); Saini, Vishnu (57221091911); Mukherjee, Jayanta (57212348061); Biswas, Prabir K. (7202443668); Aikat, Subhas (57195366142); Misra, Arundhati (15840289400)","55001806100; 57221091911; 57212348061; 7202443668; 57195366142; 15840289400","Unsupervised Detection of Surface Mine Sites using Sentinel Multi-spectral Imagery and Dual-polarimetric SAR Data","2018","ACM International Conference Proceeding Series","","","3293405","","","","10.1145/3293353.3293405","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098175053&doi=10.1145%2f3293353.3293405&partnerID=40&md5=eb79c81e6fff7452acafefc6e7e745d9","Detecting surface mine activities has been one of the major challenges of remote sensing community to monitor ecological balance in the vicinity of mine area. Towards addressing this issue, we propose an unsupervised mine-site detection technique using multi-modal remotely sensed data from Sentinel missions. We use Sentinel-1's dual polarized SAR data, and Sentinel-2's multi-spectral data for this purpose. An initial set of seed pixels is sampled using spectral slopes based rules on multi-spectral images, which are tailored to capture mining area pixels that exhibit common characteristics. Then, we generate features using multi-spectral image indices and dual polarized SAR data Stokes' parameters. These features over locations sampled by slope based rules are used to train a one-class support vector machine to detect the land anomalies (mine activities). As observed from the experiments, multi-spectral features are efficient in separating mine region and built-up region from the rest of the land surface, and SAR image features discriminate built-up region from the rest of the image. We fuse both of these imagery features to encash their advantage in segregating mine sites in the considered study area. We demonstrate the efficiency of the proposed technique in detecting active coal mines over two study sites, Asansol region (in West bengal, India) and Jharia region (in Jharkhand, India), both of which exhibit common geographical characteristics. The average detection accuracy in our results is found to be around 94.8%. © 2018 ACM.","Coal industry; Coal mines; Computer vision; Image segmentation; Mining; Pixels; Remote sensing; Spectroscopy; Support vector machines; Synthetic aperture radar; Initial set of seeds; Multi-spectral data; Multi-spectral imagery; Multispectral images; One-class support vector machine; Polarimetric SAR data; Remotely sensed data; Unsupervised detection; Radar imaging","multi-modal analysis; Multi-spectral imagery; spectral slopes; surface mining area detection; synthetic aperture radar","Conference paper","Final","","Scopus","2-s2.0-85098175053"
"Kurekin A.A.; Loveday B.R.; Clements O.; Quartly G.D.; Miller P.I.; Wiafe G.; Agyekum K.A.","Kurekin, Andrey A. (55960488500); Loveday, Benjamin R. (55835319400); Clements, Oliver (56505464200); Quartly, Graham D. (7003341226); Miller, Peter I. (7404427354); Wiafe, George (6506274991); Agyekum, Kwame Adu (25926364000)","55960488500; 55835319400; 56505464200; 7003341226; 7404427354; 6506274991; 25926364000","Operational monitoring of illegal fishing in Ghana through exploitation of satellite earth observation and AIS data","2019","Remote Sensing","11","3","293","","","","10.3390/rs11030293","46","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061350523&doi=10.3390%2frs11030293&partnerID=40&md5=a20dc0d4f7f14d22a433cc419135e3ea","Over the last decade,West African coastal countries, including Ghana, have experienced extensive economic damage due to illegal, unreported and unregulated (IUU) fishing activity, estimated at about USD 100 million in losses each year. Illegal, unreported and unregulated fishing poses an enormous threat to the conservation and management of the dwindling fish stocks, causing multiple adverse consequences for fisheries, coastal and marine ecosystems and for the people who depend on these resources. The Integrated System for Surveillance of Illegal, Unlicensed and Unreported Fishing (INSURE) is an efficient and inexpensive system that has been developed for the monitoring of IUU fishing in Ghanaian waters. It makes use of fast-delivery Earth observation data from the synthetic aperture radar instrument on Sentinel-1 and the Multi Spectral Imager on Sentinel-2, detecting objects that differ markedly from their immediate background using a constant false alarm rate test. Detections are matched to, and verified by, Automatic Identification System (AIS) data, which provide the location and dimensions of ships that are legally operating in the region. Matched and unmatched data are then displayed on a web portal for use by coastal management authorities in Ghana. The system has a detection success rate of 91% for AIS-registered vessels, and a fast throughput, processing and delivering information within 2 h of acquiring the satellite overpass. However, over the 17-month analysis period, 75% of SAR detections have no equivalent in the AIS record, suggesting significant unregulated marine activity, including vessels potentially involved in IUU. The INSURE system demonstrated its efficiency in Ghana's exclusive economic zone and it can be extended to the neighbouring states in the Gulf of Guinea, or other geographical regions that need to improve fisheries surveillance. © 2019 by the authors.","Automation; Crime; Ecosystems; Errors; Fisheries; Fishing vessels; Geographical regions; Image resolution; Object detection; Observatories; Portals; Spectroscopy; Synthetic aperture radar; Automatic identification system; Constant false alarm rate; Earth observations; Unreported and unregulated fishing (IUU); Vessel detection; Space-based radar","Automatic identification system (AIS); Constant false alarm rate (CFAR); Earth observation; Synthetic aperture radar (SAR); Unreported and unregulated fishing (IUU); Vessel detection","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85061350523"
"Dhanaraj M.; Sharma M.; Sarkar T.; Karnam S.; Chachlakis D.G.; Ptucha R.; Markopoulos P.P.; Saber E.","Dhanaraj, Mayur (57204102452); Sharma, Manish (57217742732); Sarkar, Tiyasa (57216953921); Karnam, Srivallabha (57216953193); Chachlakis, Dimitris G. (57190342440); Ptucha, Raymond (6505949286); Markopoulos, Panos P. (57220417543); Saber, Eli (56889316900)","57204102452; 57217742732; 57216953921; 57216953193; 57190342440; 6505949286; 57220417543; 56889316900","Vehicle detection from multi-modal aerial imagery using YOLOv3 with mid-level fusion","2020","Proceedings of SPIE - The International Society for Optical Engineering","11395","","1139506","","","","10.1117/12.2558115","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085525395&doi=10.1117%2f12.2558115&partnerID=40&md5=e791e56591f3a1ad78e33f655c3f2b32","Target detection is an important problem in remote-sensing with crucial applications in law-enforcement, military and security surveillance, search-and-rescue operations, and air traffic control, among others. Owing to the recently increased availability of computational resources, deep-learning based methods have demonstrated state-of-the-art performance in target detection from unimodal aerial imagery. In addition, owing to the availability of remote-sensing data from various imaging modalities, such as RGB, infrared, hyper-spectral, multi-spectral, synthetic aperture radar, and lidar, researchers have focused on leveraging the complementary information offered by these various modalities. Over the past few years, deep-learning methods have demonstrated enhanced performance using multi-modal data. In this work, we propose a method for vehicle detection from multi-modal aerial imagery, by means of a modified YOLOv3 deep neural network that conducts mid-level fusion. To the best of our knowledge, the proposed mid-level fusion architecture is the first of its kind to be used for vehicle detection from multi-modal aerial imagery using a hierarchical object detection network. Our experimental studies corroborate the advantages of the proposed method. © 2020 SPIE.","Aerial photography; Air traffic control; Antennas; Big data; Deep neural networks; Law enforcement; Learning systems; Military applications; Modal analysis; Object detection; Object recognition; Optical radar; Remote sensing; Synthetic aperture radar; Vehicles; Computational resources; Detection networks; Hierarchical objects; Learning-based methods; Remote sensing data; Search and rescue operations; Security surveillance; State-of-the-art performance; Deep learning","Aerial imagery; Fusion; Multi-modal sensing; Vehicle detection; YOLOv3","Conference paper","Final","","Scopus","2-s2.0-85085525395"
"Normand J.C.L.; Heggy E.","Normand, Jonathan C.L. (56769204400); Heggy, Essam (6602810646)","56769204400; 6602810646","Mapping Transient Soil Moisture Post Rainstorm Events in Hyper-Arid Karst Environments Using Multi-Sensor Observations","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","6319","6322","3","10.1109/IGARSS47720.2021.9554442","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130042767&doi=10.1109%2fIGARSS47720.2021.9554442&partnerID=40&md5=2f7cc950c42a42a3c04031a2c357b6c3","In hyper-arid areas, soil moisture controls surface dust emissivity, surface run-offs during flash floods, aquifers recharge, and soil induration, as well as the biological diversity of these extreme environments. Of particular interest is assessing the soil moisture spatial distribution after a rare rainstorm event in fractured karstic environments. Therefore, we use three different remote sensing methods to map the soil moisture change as well as the volumetric water content following a storm event in the hyper-arid, unvegetated, and karstic Qatar Peninsula: (1) C-band SENTINEL1 SAR backscatter intensity difference as well as its interferometric coherence, (2) Principal Component Analysis SENTINEL2-multispectral moisture index, and (3) L-band SMAP Level3 radiometer. Our results suggest that transient soil moisture spatial patterns with volumetric water content higher than 0.12 cm3/cm3 can persist longer than 48 hours following a major storm event with 50-100 mm precipitation in depressions. The above is a crucial step for assessing the origins and temporal evolution of soil moisture in Hyper-arid areas. © 2021 IEEE","Aquifers; Arid regions; Biology; Groundwater resources; Hydrogeology; Interferometry; Principal component analysis; Remote sensing; Storms; Synthetic aperture radar; Arid area; Interferometric coherence; Karstic; Moisture variability; Multi-spectral; Principal-component analysis; SAR intensity; Soil moisture variability; Storm events; Volumetric water content; Soil moisture","Interferometric coherence; Multispectral; Principal Component Analysis; SAR Intensity; Soil Moisture Variability","Conference paper","Final","","Scopus","2-s2.0-85130042767"
"Mengen D.; Montzka C.; Jagdhuber T.; Fluhrer A.; Brogi C.; Baum S.; Schüttemeyer D.; Bayat B.; Bogena H.; Coccia A.; Masalias G.; Trinkel V.; Jakobi J.; Jonard F.; Ma Y.; Mattia F.; Palmisano D.; Rascher U.; Satalino G.; Schumacher M.; Koyama C.; Schmidt M.; Vereecken H.","Mengen, David (57219465937); Montzka, Carsten (23390484800); Jagdhuber, Thomas (26027889100); Fluhrer, Anke (57208248475); Brogi, Cosimo (57203414847); Baum, Stephani (57194601314); Schüttemeyer, Dirk (14046142700); Bayat, Bagher (57191264690); Bogena, Heye (55908049900); Coccia, Alex (52463398500); Masalias, Gerard (57221995998); Trinkel, Verena (57222255792); Jakobi, Jannis (57203895517); Jonard, François (17345777800); Ma, Yueling (57222240722); Mattia, Francesco (35567712500); Palmisano, Davide (57208221852); Rascher, Uwe (6602181439); Satalino, Giuseppe (58089020400); Schumacher, Maike (56381980800); Koyama, Christian (35778186500); Schmidt, Marius (57217845942); Vereecken, Harry (7004082452)","57219465937; 23390484800; 26027889100; 57208248475; 57203414847; 57194601314; 14046142700; 57191264690; 55908049900; 52463398500; 57221995998; 57222255792; 57203895517; 17345777800; 57222240722; 35567712500; 57208221852; 6602181439; 58089020400; 56381980800; 35778186500; 57217845942; 7004082452","The sarsense campaign: Air‐ and space‐borne c‐ and l‐band sar for the analysis of soil and plant parameters in agriculture","2021","Remote Sensing","13","4","825","1","28","27","10.3390/rs13040825","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102029582&doi=10.3390%2frs13040825&partnerID=40&md5=260ae71e999641cf1dfd04b77ef29458","With the upcoming L‐band Synthetic Aperture Radar (SAR) satellite mission Radar Ob-serving System for Europe L‐band SAR (ROSE‐L) and its integration into existing C‐band satellite missions such as Sentinel‐1, multi‐frequency SAR observations with high temporal and spatial resolution will become available. The SARSense campaign was conducted between June and August 2019 to investigate the potential for estimating soil and plant parameters at the agricultural test site in Selhausen (Germany). It included C‐ and L‐band air‐ and space‐borne observations accompanied by extensive in situ soil and plant sampling as well as unmanned aerial system (UAS) based multi-spectral and thermal infrared measurements. In this regard, we introduce a new publicly available SAR data set and present the first analysis of C‐ and L‐band co‐ and cross‐polarized backscattering signals regarding their sensitivity to soil and plant parameters. Results indicate that a multi‐fre-quency approach is relevant to disentangle soil and plant contributions to the SAR signal and to identify specific scattering mechanisms associated with the characteristics of different crop type, especially for root crops and cereals. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Agricultural robots; Antennas; Crops; Soils; Synthetic aperture radar; Analysis of soils; Backscattering signals; Plant parameters; Satellite mission; Scattering mechanisms; Temporal and spatial; Thermal infrared; Unmanned aerial systems; Space-based radar","Airborne campaign; C‐band; L‐band; Plant parameters; ROSE‐L; SAR; Soil moisture","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85102029582"
"Jafarzadeh H.; Mahdianpari M.; Gill E.; Mohammadimanesh F.; Homayouni S.","Jafarzadeh, Hamid (57214856530); Mahdianpari, Masoud (57190371939); Gill, Eric (7101827634); Mohammadimanesh, Fariba (56541784200); Homayouni, Saeid (24070293900)","57214856530; 57190371939; 7101827634; 56541784200; 24070293900","Bagging and boosting ensemble classifiers for classification of multispectral, hyperspectral and polSAR data: A comparative evaluation","2021","Remote Sensing","13","21","4405","","","","10.3390/rs13214405","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118743757&doi=10.3390%2frs13214405&partnerID=40&md5=274eebf657945e2bb06cdc6d7f082ea6","In recent years, several powerful machine learning (ML) algorithms have been developed for image classification, especially those based on ensemble learning (EL). In particular, Extreme Gradient Boosting (XGBoost) and Light Gradient Boosting Machine (LightGBM) methods have attracted researchers’ attention in data science due to their superior results compared to other commonly used ML algorithms. Despite their popularity within the computer science community, they have not yet been well examined in detail in the field of Earth Observation (EO) for satellite image classification. As such, this study investigates the capability of different EL algorithms, generally known as bagging and boosting algorithms, including Adaptive Boosting (AdaBoost), Gradient Boosting Machine (GBM), XGBoost, LightGBM, and Random Forest (RF), for the classification of Remote Sensing (RS) data. In particular, different classification scenarios were designed to compare the performance of these algorithms on three different types of RS data, namely high-resolution multispectral, hyperspectral, and Polarimetric Synthetic Aperture Radar (PolSAR) data. Moreover, the Decision Tree (DT) single classifier, as a base classifier, is considered to evaluate the classification’s accuracy. The experimental results demonstrated that the RF and XGBoost methods for the multispectral image, the LightGBM and XGBoost methods for hyperspectral data, and the XGBoost and RF algorithms for PolSAR data produced higher classification accuracies compared to other ML techniques. This demonstrates the great capability of the XGBoost method for the classification of different types of RS data. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Adaptive boosting; Decision trees; Image classification; Machine learning; Remote sensing; Synthetic aperture radar; Bagging; Boosting; Ensemble-classifier; Gradient boosting; HyperSpectral; Light gradients; Machine learning algorithms; Multi-spectral; Polarimetric synthetic aperture radars; Remote sensing data; Classification (of information)","Bagging; Boosting; Classification; Ensemble classifier; Hyperspectral; Multispectral; PolSAR","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85118743757"
"Chen Y.; Ma L.; Yu D.; Feng K.; Wang X.; Song J.","Chen, Yang (55877254700); Ma, Lixia (56754435600); Yu, Dongsheng (7404666383); Feng, Kaiyue (57391889800); Wang, Xin (57272441900); Song, Jie (57391505700)","55877254700; 56754435600; 7404666383; 57391889800; 57272441900; 57391505700","Improving leaf area index retrieval using multi-sensor images and stacking learning in subtropical forests of China","2022","Remote Sensing","14","1","148","","","","10.3390/rs14010148","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122012893&doi=10.3390%2frs14010148&partnerID=40&md5=ed22937702d23b4ab68c8e6e2771ae1e","The leaf area index (LAI) is a key indicator of the status of forest ecosystems that is important for understanding global carbon and water cycles as well as terrestrial surface energy balances and the impacts of climate change. Machine learning (ML) methods offer promising ways of generating spatially explicit LAI data covering large regions based on optical images. However, there have been few efforts to analyze the LAI in heterogeneous subtropical forests with complex terrain by fusing high-resolution multi-sensor data from the Sentinel-1 Synthetic Aperture Radar (SAR), Sentinel-2 Multi Spectral Instrument (MSI), and Advanced Land Observing Satellite-1 digital elevation model (DEM). Here, forest LAI mapping was performed by integrating the MSI, SAR, and DEM data using a stacking learning (SL) approach that incorporates distinct predictions from a set of optimized individual ML algorithms. The method’s performance was evaluated by comparison to field forest LAI measurements acquired in Xingguo and Gandong of subtropical China. The results showed that the addition of the SAR and DEM images using the SL model compared to the inputs of only optical images reduced the mean absolute error (MAE) and root mean square error (RMSE) by 26% and 18%, respectively, in Xingguo, and by 12% and 8%, respectively, in Gandong. Furthermore, the combination of all images had the best prediction performance. SL was found to be more robust and accurate than conventional individual ML models, while the MAE and RMSE were decreased by 71% and 64%, respectively, in Xingguo, and by 68% and 59%, respectively, in Gandong. Therefore, the SL model using the three-source data combination produced satisfied prediction accuracy with the coefficients of determination (R2 ), MAE, and RMSE of 0.96, 0.17, and 0.28, respectively, in Xingguo and 0.94, 0.30, and 0.47, respectively, in Gandong. This study revealed the potential of the SL algorithm for retrieving the forest LAI using multi-sensor data in areas with complex terrain. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Climate change; Ecosystems; Forecasting; Forestry; Geometrical optics; Image enhancement; Learning systems; Mean square error; Surveying; Tropics; Complex terrains; Leaf Area Index; Mean absolute error; Multi-sensor data; Multi-sensor imagery; Optical image; Root mean square errors; Stacking learning; Stackings; Subtropical forests; Synthetic aperture radar","Leaf area index; Multi-sensors imagery; Stacking learning; Subtropical forest","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85122012893"
"Robberg T.; Schmitt M.","Robberg, Thomas (57937805500); Schmitt, Michael (7401931279)","57937805500; 7401931279","Estimating NDVI from Sentinel-1 Sar Data Using Deep Learning","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","1412","1415","3","10.1109/IGARSS46834.2022.9883707","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140375688&doi=10.1109%2fIGARSS46834.2022.9883707&partnerID=40&md5=9c6224d4974682a76c19198f5bf6c3fd","Monitoring vegetation is of great importance for many applications, for example agriculture or forestry. Commonly, the normalized difference vegetation index (NDVI) of spaceborn sensor is utilized for this task. However, as the NDVI is derived from multispectral optical data, cloud coverage prevents the acquisition of useful values. This results in data and monitoring gaps. Generally, this can be avoided using cloud penetrating radar sensors but the different sensing method and different image characteristics hamper the easy usage of the data. Therefore, in this paper a method is presented to allow global cloud-independent vegetation monitoring by estimating the NDVI from radar data using a deep learning model. The used U-Net architecture is trained on a newly created dataset called SEN12TP of globally distributed radar and optical imagery with a small difference in acquisition time. The resulting performance is evaluated and different input modalities are compared. Additionally, the ability of this approach to densify NDVI time series is demonstrated. © 2022 IEEE.","Deep learning; Geology; Learning systems; Radar imaging; Remote sensing; Synthetic aperture radar; Time series; Vegetation; Cloud coverage; Data clouds; Multi-spectral; Normalized difference vegetation index; Optical data; Pixel-wise regression; SAR data; Sentinel-1; Times series; Vegetation monitoring; Forestry","normalized difference vegetation index; pixel-wise regression; synthetic aperture radar; time series; vegetation monitoring","Conference paper","Final","","Scopus","2-s2.0-85140375688"
"Bernabe S.; Garcia C.; Fernandez-Beltran R.; Paoletti M.E.; Haut J.M.; Plaza J.; Plaza A.","Bernabe, S. (36550217200); Garcia, C. (55328676100); Fernandez-Beltran, R. (55838551300); Paoletti, M.E. (57027389000); Haut, J.M. (57215636081); Plaza, J. (57195716301); Plaza, A. (7006613644)","36550217200; 55328676100; 55838551300; 57027389000; 57215636081; 57195716301; 7006613644","Open Multi-Processing Acceleration for Unsupervised Land Cover Categorization Using Probabilistic Latent Semantic Analysis","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898507","9835","9838","3","10.1109/IGARSS.2019.8898507","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077688486&doi=10.1109%2fIGARSS.2019.8898507&partnerID=40&md5=c444cbf2b97528e554f8fe7d0cf8ea00","The probabilistic Latent Semantic Analysis (pLSA) model has recently shown a great potential to uncover highly descriptive semantic features from limited amounts of remote sensing data. Nonetheless, the high computational cost of this algorithm often constraints its operational application for land cover categorization tasks. In this scenario, this paper presents an Open Multi-Processing (OpenMP) implementation of the pLSA algorithm for unsupervised Synthetic Aperture Radar (SAR) and Multi-Spectral Imaging (MSI) image categorization. The experimental results suggest that multi-core systems are an important architecture for the efficient processing of both SAR and MSI datasets. Specifically, the proposed approach is able to cover a real scenario exhibiting good results in both accuracy and performance terms. © 2019 IEEE.","Application programming interfaces (API); Geology; Remote sensing; Spectroscopy; Synthetic aperture radar; Descriptive semantics; Image Categorization; Land cover; Multi-core processor; Multi-processing; Multispectral imaging; Operational applications; Probabilistic latent semantic analysis; Semantics","land cover categorization; multi-core processors; Open Multi-Processing (OpenMP); probabilistic Latent Semantic Analysis (pLSA)","Conference paper","Final","","Scopus","2-s2.0-85077688486"
"Fremout T.; Cobián-De Vinatea J.; Thomas E.; Huaman-Zambrano W.; Salazar-Villegas M.; Limache-de la Fuente D.; Bernardino P.N.; Atkinson R.; Csaplovics E.; Muys B.","Fremout, Tobias (57215905647); Cobián-De Vinatea, Jorge (57652287300); Thomas, Evert (23471373100); Huaman-Zambrano, Wilson (57653949900); Salazar-Villegas, Mike (57652842400); Limache-de la Fuente, Daniela (57654508500); Bernardino, Paulo N. (57216255590); Atkinson, Rachel (35087917700); Csaplovics, Elmar (55939496300); Muys, Bart (6701686533)","57215905647; 57652287300; 23471373100; 57653949900; 57652842400; 57654508500; 57216255590; 35087917700; 55939496300; 6701686533","Site-specific scaling of remote sensing-based estimates of woody cover and aboveground biomass for mapping long-term tropical dry forest degradation status","2022","Remote Sensing of Environment","276","","113040","","","","10.1016/j.rse.2022.113040","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129120089&doi=10.1016%2fj.rse.2022.113040&partnerID=40&md5=9346ddf17f901cd1abfe14c55e8a949f","Remote sensing-based approaches are important for evaluating ecosystem degradation and the efficient planning of ecosystem restoration efforts. However, the large majority of remote sensing-based degradation assessments are trend-based, implying that they can only detect degradation that occurred after medium or high-resolution satellite imagery became available. This makes them less suitable to map long-term degradation in ecosystems that have been under high human pressure since before. The main goal of this study was to develop a robust operational approach to map forest degradation status in heterogeneous landscapes with a long-standing degradation history to inform the planning of restoration interventions. We hereby use the tropical dry forests of Lambayeque, Peru, as a case study. Instead of using a trend-based assessment, we evaluated forest degradation status by comparing current woody cover (WC) and aboveground biomass (AGB) estimates obtained from remote sensing imagery with benchmark values consisting of the 95th percentile WC and AGB values inside environmentally homogenous land capability classes. Using boosted regression tree models and a combination of optical (Sentinel-2) and synthetic aperture radar (Sentinel-1) data of different seasons, we mapped WC and AGB, using training data obtained through very high-resolution imagery and field measurements. Further, we aimed at assessing (i) whether the inclusion of Sentinel-1 data improves mapping accuracy in comparison to using only Sentinel-2 data, and (ii) whether the use of multi-seasonal data improves accuracy in comparison to single-season data. Models combining multi-seasonal Sentinel-1 and Sentinel-2 data resulted in the most accurate WC predictions (mean absolute error (MAE): 16%; MAE normalized by dividing by the inter-quartile range of training data: 26%) and AGB predictions (MAE: 28.6 t/ha; normalized MAE: 65%), but differences in predictive accuracy with single season models or models using only Sentinel-2 data were small. The most accurate models estimated an average WC of 41% and an average AGB of 23.4 t/ha. Average WC and AGB reduction due to degradation was 35% and 36%, respectively, indicating that these forests are highly degraded. The site-specific scaling of WC and AGB allows to efficiently estimate forest degradation status irrespective of the time when this degradation occurred, and to express degradation status against site-specific benchmarks. On the condition that there are still some areas that are sufficiently undegraded to be used as a benchmark, the approach can be used to prioritize forest restoration actions and inform targets for restoration in heterogeneous landscapes suffering the impacts of undocumented long-term degradation. © 2022 Elsevier Inc.","Lambayeque; Peru; Biomass; Conservation; Ecosystems; Forestry; Image reconstruction; Mapping; Radar imaging; Restoration; Satellite imagery; Space-based radar; Synthetic aperture radar; Tropics; Aboveground biomass; Canopy cover; Forest degradation; Land capability; Land capability class; Long-term forest degradation; Multi-spectral; Sentinel-1; Sentinel-2; Woody cover; aboveground biomass; dry forest; multispectral image; remote sensing; satellite imagery; seasonal variation; Sentinel; synthetic aperture radar; vegetation cover; woody plant; Remote sensing","Aboveground biomass; Canopy cover; Land capability classes; Long-term forest degradation; Multispectral; Radar; Sentinel-1; Sentinel-2; Woody cover","Article","Final","","Scopus","2-s2.0-85129120089"
"Wang J.; Feng Y.; Wang R.; Tong X.; Chen S.; Lei Z.; Li P.; Xi M.","Wang, Jiafeng (55618928500); Feng, Yongjiu (23004403900); Wang, Rong (57208563524); Tong, Xiaohua (55500134600); Chen, Shurui (57204520847); Lei, Zhenkun (57204519809); Li, Pengshuo (57273571100); Xi, Mengrong (57641466700)","55618928500; 23004403900; 57208563524; 55500134600; 57204520847; 57204519809; 57273571100; 57641466700","Evaluation of typhoon-induced inundation losses associated with LULC using multi-temporal SAR and optical images","2022","Geomatics, Natural Hazards and Risk","13","1","","2227","2251","24","10.1080/19475705.2022.2112624","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136502229&doi=10.1080%2f19475705.2022.2112624&partnerID=40&md5=a3e8e60c4084a43c3ef0ce4ef9effb0e","We utilized a two-branch end-to-end network (MultiSenCNN) for land use and land cover (LULC) classification and flood event mapping using multispectral (MS), panchromatic (Pan) and synthetic aperture radar (SAR) images, where flooding was induced by typhoon Lekima in August 2019. Flood damages were assessed by considering both the LULC and flood maps. We defined three strategies to compare the MS + SAR and MS + Pan images to demonstrate the ability of the MultiSenCNN algorithm for LULC classification. The three strategies yielded an average overall accuracy of ∼98% and an average Kappa of ∼0.98 for LULC classification. The overall accuracy of the fused MS + SAR images is slightly higher than the MS + Pan images when using the same model training samples. The flood mapping shows an overall accuracy of 97.22% and a Kappa of 0.94, with a flood inundation area of 101 km2 that mainly inundated cropland and urban areas. Compared to other LULC types, the flooded cropland has caused more loss of ecosystem service values during typhoon Lekima, accounting for 81.19% of the total. Using SAR mages can well monitor the start/end states of flood events and the inundated areas, providing the flood status information to rescuers and governments for making timely decisions. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Damage detection; Deep learning; Ecosystems; Flood control; Floods; Geometrical optics; Hurricanes; Image classification; Land use; Mapping; Radar imaging; Deep learning; Flood event; Flood mapping; Inundation assessment; Land use and land cover; Land-use and land-cover classifications; Multi-spectral; Multi-temporal; Overall accuracies; Synthetic aperture radar images; Synthetic aperture radar","deep learning; flood mapping; inundation assessment; LULC classification; synthetic aperture radar","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85136502229"
"Grohnfeldt C.; Schmitt M.; Zhu X.","Grohnfeldt, Claas (55946211600); Schmitt, Michael (7401931279); Zhu, Xiaoxiang (55696622200)","55946211600; 7401931279; 55696622200","A conditional generative adversarial network to fuse SAR and multispectral optical data for cloud removal from Sentinel-2 images","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8519215","1726","1729","3","10.1109/IGARSS.2018.8519215","76","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056354296&doi=10.1109%2fIGARSS.2018.8519215&partnerID=40&md5=86a96bdfdcfcff984120e3d9c682d5d1","In this paper, we present the first conditional generative adversarial network (cGAN) architecture that is specifically designed to fuse synthetic aperture radar (SAR) and optical multi-spectral (MS) image data to generate cloud- and hazefree MS optical data from a cloud-corrupted MS input and an auxiliary SAR image. Experiments on Sentinel-2 MS and Sentinel-1 SAR data confirm that our extended SAR-OptcGAN model utilizes the auxiliary SAR information to better reconstruct MS images than an equivalent model which uses the same architecture but only single-sensor MS data as input. © 2018 IEEE.","Data fusion; Deep learning; Geology; Network architecture; Remote sensing; Synthetic aperture radar; Adversarial networks; Cloudremoval; Equivalent model; Multi-spectral; Optical data; Optical remote sensing; Sentinel-1; Single sensor; Radar imaging","Cloudremoval; Data fusion; Deep learning; Generative adversarial network (GAN); Optical remote sensing; SAR","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85056354296"
"Ahmed U.I.; Velasco A.; Rabus B.","Ahmed, Usman Iqbal (57217787833); Velasco, Arturo (57678840800); Rabus, Bernhard (6701849102)","57217787833; 57678840800; 6701849102","SEMANTIC SEGMENTATION OF LAND USE/LAND COVER (LU/LC) TYPES USING F-CNNS ON MULTI-SENSOR (RADAR-IR-OPTICAL) IMAGE DATA","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","4700","4703","3","10.1109/IGARSS47720.2021.9554051","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129814620&doi=10.1109%2fIGARSS47720.2021.9554051&partnerID=40&md5=b8dc1f95871cc72be7c4f907f4846f7d","Land Use/Land Cover (LU/LC) segmentation is a widely studied topic in the field of remote sensing. Past focus has been on independent studies either on color (RGB) and the Normalized Vegetation Index (NDVI) or on Polarimetric Synthetic Aperture Radar (PolSAR) data. In this paper we explore the fusion potential of RGB images with additional SAR and Near Infra-red (NIR) images for enhanced LU/LC segmentation through Fully-Convolutional Neural Networks (F-CNNs). F-CNNs have been extensively studied for semantic segmentation problems with U-Net and SegNet being two well-known F-CNN architectures. Both these architectures were used as references for this study. High resolution RGB, SAR and NIR images were acquired through Google Earth (GE), German Aerospace Center (DLR) and The Planet Laboratories, respectively. IR was converted to NDVI for its higher potential of segmentation of vegetations areas. Four multi-sensor configurations as input channels to the networks were studied after precise co-registration of these images, and the results were compared to individual channels for both architectures. Simon Fraser University (SFU), Burnaby Campus and its surrounding area was selected for this study due its diverse land types. The area was divided into 5 classes i.e. Roads, Buildings, Forest, Water and No class (unclassified). An overall, best accuracy of ~86% was achieved for a five-channel configuration (R+G+B+SAR+NDVI). We show that the inclusion of SAR and IR channels to RGB based network can significantly improve the performance of LU/LC segmentation. © 2021 IEEE","Convolutional neural networks; Earth (planet); Image enhancement; Image fusion; Infrared devices; Land use; Network architecture; Radar imaging; Remote sensing; Semantics; Space optics; Synthetic aperture radar; Vegetation; Convolutional neural network; Fully-convolutional neural network; Land use/land cover; LAND USE/LAND COVER segmentation; Multi sensor; Multi-sensor fusion; Multi-spectral; SAR/multi-spectral fusion; Semantic segmentation; Vegetation index; Semantic Segmentation","F-CNNs; LU/LC Segmentation; Multi-Sensor Fusion; SAR/Multi-Spectral Fusion; Semantic Segmentation","Conference paper","Final","","Scopus","2-s2.0-85129814620"
"Wang S.-T.; Cui K.; Kong D.-M.; Liu S.-Y.; Wu X.","Wang, Shu-Tao (55714642300); Cui, Kai (57216916554); Kong, De-Ming (55513769000); Liu, Shi-Yu (57209286687); Wu, Xing (57210164510)","55714642300; 57216916554; 55513769000; 57209286687; 57210164510","Application of densely connected network in SAR and multispectral image fusion; [密集连接网络在SAR与多光谱影像融合中的应用]","2021","Guangxue Jingmi Gongcheng/Optics and Precision Engineering","29","5","","1145","1153","8","10.37188/OPE.20212905.1145","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108662401&doi=10.37188%2fOPE.20212905.1145&partnerID=40&md5=f7290d3cd617b5a8743151c6fa0cc1a7","To overcome the shortcomings of single satellite sensor imaging, a fusion algorithm for synthetic aperture radar (SAR) and multispectral images based on densely connected networks is proposed herein. Firstly, the SAR and multispectral images are preprocessed separately, and the bicubic interpolation method is used to resample the same spatial resolution. Then, the densely connected network is used to extract the feature maps of the image separately, and the fusion strategy with the largest regional energy is used to combine the depth features. The fused image is input to a pre-trained decoder for reconstruction to obtain the final fused image. The experiment uses Sentinel-1 SAR images, Landsat-8 images, and Gaofen-1 satellite images for verification and draws comparisons with methods based on component substitution, those based on multiscale decomposition, and those based on deep learning. Experimental results indicate that the accuracy of the fusion algorithm based on densely connected networks in terms of the multiscale structural similarity index is as high as 0.9307, and it is better than other fusion algorithms in terms of other evaluation indexes. Detailed information of SAR images and multispectral images are well preserved.","Deep learning; Image fusion; Image processing; Space-based radar; Synthetic aperture radar; Bicubic interpolation; Component substitution; Densely connected networks; Multi-scale Decomposition; Multi-spectral image fusions; Multispectral images; Spatial resolution; Structural similarity indices; Radar imaging","Densely connected network; Image fusion; Multispectral; Synthetic aperture radar","Article","Final","","Scopus","2-s2.0-85108662401"
"Feng P.; Lin Y.; Guan J.; Dong Y.; He G.; Xia Z.; Shi H.","Feng, Pengming (56517583500); Lin, Youtian (57213189392); Guan, Jian (57202816841); Dong, Yan (57213199231); He, Guangjun (56485034500); Xia, Zhenghuan (55608556100); Shi, Huifeng (57208867317)","56517583500; 57213189392; 57202816841; 57213199231; 56485034500; 55608556100; 57208867317","Embranchment Cnn Based Local Climate Zone Classification Using Sar and Multispectral Remote Sensing Data","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898703","6344","6347","3","10.1109/IGARSS.2019.8898703","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077714119&doi=10.1109%2fIGARSS.2019.8898703&partnerID=40&md5=3331661f18f823c4dbc33b9dd3a95614","In this study, a Local Climate Zone (LCZ) classification framework is established using a Densenet based embranchment Convolutional Neural Network (CNN). Both synthetic aperture radar (SAR) and multispectral data are employed for feature fusion, specifically, considering about the difference in imaging mechanism between SAR and multispectral data, features from both resources are extracted in different branches separately according to the physical properties of each band. Significant accuracy improvement can be achieved when evaluate the proposed method by Sentinel-1 and Sentinel-2 dataset, and the comparison results show the superiority of the proposed embranchment CNN framework over the conventional methods. © 2019 IEEE.","Convolutional neural networks; Geology; Synthetic aperture radar; Accuracy Improvement; Classification framework; Conventional methods; Embranchment CNN; Multi-spectral data; Multi-spectrum; Multispectral remote sensing; Zone classifications; Remote sensing","Embranchment CNN; Local Climate Zone Classification; Multi-spectrum; SAR","Conference paper","Final","","Scopus","2-s2.0-85077714119"
"Zhao Q.; Pan J.; Devlin A.; Xu Q.; Tang M.; Li Z.; Zamparelli V.; Falabella F.; Mastro P.; Pepe A.","Zhao, Qing (55743346000); Pan, Jiayi (7404098942); Devlin, Adam (57190407454); Xu, Qing (55560135200); Tang, Maochuan (57219318827); Li, Zhengjie (57242952500); Zamparelli, Virginia (36505512000); Falabella, Francesco (57209105919); Mastro, Pietro (57200604308); Pepe, Antonio (7003776958)","55743346000; 7404098942; 57190407454; 55560135200; 57219318827; 57242952500; 36505512000; 57209105919; 57200604308; 7003776958","Integrated analysis of the combined risk of ground subsidence, sea level rise, and natural hazards in coastal and delta river regions","2021","Remote Sensing","13","17","3431","","","","10.3390/rs13173431","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114108101&doi=10.3390%2frs13173431&partnerID=40&md5=b633eaa24d3731f4ac17cabead9947bc","Non‐climate‐related anthropogenic processes and frequently encountered natural hazards exacerbate the risk in coastal zones and megacities and amplify local vulnerability. Coastal risk is amplified by the combination of sea level rise (SLR) resulting from climate change, associated tidal evolution, and the local sinking of land resulting from anthropogenic and natural hazards. In this framework, the authors of this investigation have actively contributed to the joint European Space Agency (ESA) and the Chinese Ministry of Science and Technology (MOST) Dragon IV initiative through a project (ID. 32294) that was explicitly designed to address the issue of monitoring coastal and delta river regions through Earth Observation (EO) technologies. The project’s primary goals were to provide a complete characterization of the changes in target scenes over time and provide estimates of future regional sea level changes to derive submerged coastal areas and wave fields. Suggestions are also provided for implementing coastal protection measures in order to adapt and mitigate the multifactor coastal vulnerability. In order to achieve these tasks, well‐established remote sensing technologies based on the joint exploitation of multi‐spectral information gathered at different spectral wavelengths, the exploitation of advanced Differential Interferometric Synthetic Aperture Radar (DInSAR) techniques for the retrieval of ground deformations, the realization of geophysical analyses, and the use of satellite altimeters and tide gauge data have effectively been employed. The achieved results, which mainly focus on selected sensitive regions including the city of Shanghai, the Pearl River Delta in China, and the coastal city of Saint Petersburg in Europe, provide essential assets for planning present and future scientific activities devoted to monitoring such fragile environments. These analyses are crucial for assessing the factors that will amplify the vulnerability of low‐elevation coastal zones. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Climate change; Hazards; Remote sensing; Risk assessment; Rivers; Sea level; Shore protection; Space applications; Space-based radar; Synthetic aperture radar; Tide gages; Anthropogenic process; Differential interferometric synthetic aperture radars; European Space Agency; Geophysical analysis; Ministry of science and technologies; Regional sea level changes; Remote sensing technology; Spectral information; Coastal zones","Delta regions; Flooding risk; Ground subsidence; Sea level rise (SLR)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85114108101"
"Bacha A.S.; Van Der Werff H.; Shafique M.; Khan H.","Bacha, Alam Sher (57192203389); Van Der Werff, Harald (14069318600); Shafique, Muhammad (36609198000); Khan, Hawas (57204936004)","57192203389; 14069318600; 36609198000; 57204936004","Transferability of object-based image analysis approaches for landslide detection in the Himalaya Mountains of northern Pakistan","2020","International Journal of Remote Sensing","41","9","","3390","3410","20","10.1080/01431161.2019.1701725","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077251845&doi=10.1080%2f01431161.2019.1701725&partnerID=40&md5=9782cf5ef1445b630049d646fa8cb328","A landslide inventory is indispensable for determination of landslide susceptibility, hazard, risk assessment and disaster mitigation strategies. These inventories were traditionally developed using manual digitization of remote sensing images and aerial photographs, and pixel-based image classification. Recently, Object-Based Image Analysis (OBIA) supersedes visual interpretation and pixel-based methods. OBIA utilizes spectral, textural, contextual, morphological and topographical information in remote sensing images. However, OBIA-based landslide detection methods are often designed for speciﬁc areas and remote sensing dataset. The aim of this study is to evaluate the transferability of three published OBIA landslide detection methods for semi-automated landslide detection in the Himalaya mountainous region of northern Pakistan. A SPOT-6 multi-spectral image with Advanced Land Observing Satellite (ALOS) Phased Array type L-band Synthetic Aperture Radar (PALSAR) Digital Elevation Model (DEM) derivatives, i.e. slope, aspect, hill-shade, relief, elevation and stream network are used for landslide detection using eCognition developer software. The three published methods scale parameters for image segmentation and parameter thresholds are evaluated first. It is observed that the aforementioned methods are not directly applicable to our study area and remote sensing datasets. Therefore, an alternate (proposed) method is developed for semi-automated landslide detection. Accuracy assessment of the selected methods and proposed method is assessed by Precision, Recall and F1 measures. Using the proposed method, a total of 357 landslides are detected with 91.46% Precision, 93.31% Recall and 92.38% F1 measure accuracy. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Himalayas; Pakistan; Antennas; Automation; Image segmentation; Landslides; Object detection; Pixels; Risk assessment; Spectroscopy; Surveying; Synthetic aperture radar; Advanced land observing satellites; Digital elevation model; Landslide susceptibility; Object based image analysis; Object based image analysis (OBIA); Phased array type l-band synthetic aperture radars; Remote sensing images; Topographical information; aerial photograph; ALOS; digital elevation model; image analysis; image classification; landslide; PALSAR; pixel; remote sensing; Remote sensing","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85077251845"
"Aswatha S.M.; Mukherjee J.; Biswas P.K.; Aikat S.","Aswatha, Shashaank Mattur (55001806100); Mukherjee, Jayanta (57212348061); Biswas, Prabir K. (7202443668); Aikat, Subhas (57195366142)","55001806100; 57212348061; 7202443668; 57195366142","Unsupervised classification of land cover using multi-modal data from multi-spectral and hybrid-polarimetric SAR imageries","2020","International Journal of Remote Sensing","41","14","","5277","5304","27","10.1080/01431161.2020.1731771","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083510485&doi=10.1080%2f01431161.2020.1731771&partnerID=40&md5=dcbdbcc35b2c0ba35fc65c37c73543c7","Current research investigations using remotely sensed images are offered with a plethora of sources to explore land cover/land use applicability. Some of the recent advances have shown the advantage of fusing different data sources in land-cover analysis. Though intuitively combined processing of multi-modal imagery should provide better classification of land cover, there are not many work towards this direction and a theoretical framework is not laid out properly. In this work, we are providing such a framework where scattering and spectral properties (from synthetic aperture radar and multi-spectral images, respectively) of ground materials are used to distinguish land-cover classes with higher precision. Different kinds of information that are represented by these two modes of imageries are semantically bridged to infer more distinguishable land-cover classes in an unsupervised framework. The proposed technique is implemented in two phases, i.e., (1) sampling of seed pixels from imageries, and (2) training of representative features and prediction of classes using random forest classifier. Experimental results also show the effectiveness of this fusion of multi-modal image characteristics in classifying the underlying land cover. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.","Decision trees; Modal analysis; Radar imaging; Spectroscopy; Synthetic aperture radar; Combined processing; Land cover analysis; Multispectral images; Random forest classifier; Remotely sensed images; Spectral properties; Theoretical framework; Unsupervised classification; image classification; land cover; multispectral image; precision; satellite data; satellite imagery; spectral resolution; synthetic aperture radar; Image classification","","Article","Final","","Scopus","2-s2.0-85083510485"
"Chaudhuri U.; Bose R.; Banerjee B.; Bhattacharya A.; Datcu M.","Chaudhuri, Ushasi (57213946643); Bose, Rupak (57226749299); Banerjee, Biplab (55568183500); Bhattacharya, Avik (57208699587); Datcu, Mihai (7004523124)","57213946643; 57226749299; 55568183500; 57208699587; 7004523124","Zero-Shot Cross-Modal Retrieval for Remote Sensing Images With Minimal Supervision","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","4708615","","","","10.1109/TGRS.2022.3196307","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135734518&doi=10.1109%2fTGRS.2022.3196307&partnerID=40&md5=1892807e8d4d0eaf8f483d508e063d66","The performance of a deep-learning-based model primarily relies on the diversity and size of the training dataset. However, obtaining such a large amount of labeled data for practical remote sensing (RS) applications is expensive and labor-intensive. Training protocols have been previously proposed for few-shot learning (FSL) and zero-shot learning (ZSL). However, FSL is not compatible with handling unobserved class data at the inference phase, while ZSL requires many training samples of the seen classes. In this work, we propose a novel training protocol for image retrieval and name it as label-deficit zero-shot learning (LDZSL). We use this novel LDZSL training protocol for the challenging task of cross-sensor data retrieval in RS. This protocol uses very few labeled data samples of the seen classes during training and interprets unobserved class data samples at the inference phase. This strategy is critical as some data modalities are hard to annotate without domain experts. This work proposes a novel bilevel Siamese network to perform the LDZSL cross-sensor retrieval of multispectral and synthetic aperture radar (SAR) images. We use the available georeferenced SAR and multispectral data to domain align the embedding features of the two modalities. We experimentally demonstrate the proposed model's efficacy using the So2Sat dataset compared with the existing state-of-the-art models of the ZSL framework trained under a reduced training set. We also show the generalizability of the proposed model using a sketch-based image retrieval task. Experimental results on the Earth on the Canvas dataset exhibit comparative performance over the literature.  © 1980-2012 IEEE.","Data handling; Deep learning; Image retrieval; Radar imaging; Remote sensing; Synthetic aperture radar; Zero-shot learning; Cross-modal; Cross-modal retrieval; Data sample; Few-shot learning; Labeled data; Multi-spectral; Remote sensing images; Remote-sensing; Task analysis; Training data; experimental study; performance assessment; remote sensing; sampling; satellite imagery; training; Semantics","Cross-modal retrieval (CMR); few-shot learning (FSL); multispectral; remote sensing (RS); synthetic aperture radar (SAR); zero-shot learning (ZSL)","Article","Final","","Scopus","2-s2.0-85135734518"
"Agersborg J.A.; Luppino L.T.; Anfinsen S.N.; Jepsen J.U.","Agersborg, Jørgen A. (56431139100); Luppino, Luigi T. (57194513229); Anfinsen, Stian Normann (6504079727); Jepsen, Jane Uhd (7004975079)","56431139100; 57194513229; 6504079727; 7004975079","Toward Targeted Change Detection with Heterogeneous Remote Sensing Images for Forest Mortality Mapping; [  Vers une détection ciblée de changements à l’aide d’images de télédétection hétérogènes pour la cartographie de la mortalité sylvestre]","2022","Canadian Journal of Remote Sensing","48","6","","826","848","22","10.1080/07038992.2022.2135497","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140222198&doi=10.1080%2f07038992.2022.2135497&partnerID=40&md5=8277361f04851f334e2aa56cc68d0846","Several generic methods have recently been developed for change detection in heterogeneous remote sensing data, such as images from synthetic aperture radar (SAR) and multispectral radiometers. However, these are not well-suited to detect weak signatures of certain disturbances of ecological systems. To resolve this problem we propose a new approach based on image-to-image translation and one-class classification (OCC). We aim to map forest mortality caused by an outbreak of geometrid moths in a sparsely forested forest-tundra ecotone using multisource satellite images. The images preceding and following the event are collected by Landsat-5 and RADARSAT-2, respectively. Using a recent deep learning method for change-aware image translation, we compute difference images in both satellites’ respective domains. These differences are stacked with the original pre- and post-event images and passed to an OCC trained on a small sample from the targeted change class. The classifier produces a credible map of the complex pattern of forest mortality. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Change detection; Deep learning; Ecology; Forestry; Learning systems; Radar imaging; Remote sensing; Change detection; Ecological systems; Forest-tundra ecotone; Generic method; Image translation; Multi-spectral; New approaches; One-class Classification; Remote sensing data; Remote sensing images; Synthetic aperture radar","","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85140222198"
"Rodríguez-Veiga P.; Barbosa-Herrera A.P.; Barreto-Silva J.S.; Bispo P.C.; Cabrera E.; Capachero C.; Galindo G.; Gou Y.; Moreno L.M.; Louis V.; Lozano P.; Pacheco-Pascagaza A.M.; Pachon-Cendales I.P.; Phillips-Bernal J.F.; Roberts J.; Salinas N.R.; Vergara L.; Zuluaga A.C.; Balzter H.","Rodríguez-Veiga, P. (25961216600); Barbosa-Herrera, A.P. (57189941340); Barreto-Silva, J.S. (55270305100); Bispo, P.C. (36154348200); Cabrera, E. (55608807800); Capachero, C. (57209109768); Galindo, G. (56715432400); Gou, Y. (53163901400); Moreno, L.M. (57209100204); Louis, V. (57194393650); Lozano, P. (57195535133); Pacheco-Pascagaza, A.M. (57208222024); Pachon-Cendales, I.P. (57209101363); Phillips-Bernal, J.F. (55320577400); Roberts, J. (57209634397); Salinas, N.R. (57209107753); Vergara, L. (57209101430); Zuluaga, A.C. (57209108827); Balzter, H. (6603839405)","25961216600; 57189941340; 55270305100; 36154348200; 55608807800; 57209109768; 56715432400; 53163901400; 57209100204; 57194393650; 57195535133; 57208222024; 57209101363; 55320577400; 57209634397; 57209107753; 57209101430; 57209108827; 6603839405","Mapping the spatial distribution of Colombia’s forest aboveground biomass using SAR and optical data","2019","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","3/W7","","57","60","3","10.5194/isprs-archives-XLII-3-W7-57-2019","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066474208&doi=10.5194%2fisprs-archives-XLII-3-W7-57-2019&partnerID=40&md5=f53d9ff2e769f705a98ad0702f374b88","An assessment on the amount and spatial distribution of forest aboveground biomass (AGB) for the forests in Colombia was generated using in-situ national forest inventory data (IDEAM, 2018), in combination with multispectral optical data and synthetic aperture radar (SAR) satellite imagery. ALOS-2 PALSAR-2 gamma-0 backscatter annual mosaics (2015-2017) provided by JAXA were normalised and corrected using previous ALOS PALSAR annual mosaics (2007-2010) as reference. A multi-temporal Landsat 7 & 8 composite over the whole of Colombia was used for the year 2016 ± 1. The national forest inventory in-situ plots used to train our model consisted of 5-subplots each and were collected during the period 2015-2017 in the main biomes of the country. A sample of permanent 1ha plots (PPMs) were also measured. Nationally developed allometries (Alvarez et al, 2012) were used to estimate AGB. A non-parametric random forests (RF) algorithm was used within a k-fold framework to retrieve AGB at 30m spatial resolution for the whole of Colombia. The algorithm was trained using forest inventory plots and validated at plot (0.35 ha) and PPM level (1 ha). The accuracy assessment found coefficients of determination (R2) of 0.68 and 0.61, and relative root mean square errors (Rel. RMSE) of 49% and 34% at plot and at PPM level, respectively. The results showed that the average AGB for the country was 118.1 t ha-1 (45.6 t ha-1 for Caribe, 75.4 t ha-1 Andes, 122.5 t ha-1 Pacifico, 32.7 t ha-1 Orinoquia, and 200.5 t ha-1 for the Amazonia, regionally), and that the total carbon stocks for the country were 6.7 Pg C for the period 2015-2017. © Authors 2019. CC BY 4.0 License.","Biomass; Carbon; Decision trees; Learning algorithms; Learning systems; Mean square error; Radar imaging; Satellite imagery; Spatial distribution; Synthetic aperture radar; Aboveground biomass; Accuracy assessment; Forest inventory; Multi-spectral; National forest inventories; Non-parametric; Root mean square errors; Spatial resolution; Space-based radar","Biomass; Carbon; Forest inventory; Machine-learning; Multispectral; SAR","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85066474208"
"Datta U.","Datta, U. (7007098861)","7007098861","Multimodal change monitoring using multitemporal satellite images","2021","Proceedings of SPIE - The International Society for Optical Engineering","11862","","118620M","","","","10.1117/12.2600099","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118562976&doi=10.1117%2f12.2600099&partnerID=40&md5=b8701ca19db314f013b32048a2075cc9","The main objective of this study is to monitor the land infrastructure growth over a period of time using multimodality of remote sensing satellite images. In this project unsupervised change detection analysis using ITPCA (Iterated Principal Component Analysis) is presented to indicate the continuous change occurring over a long period of time. The change monitoring is pixel based and multitemporal. Co-registration is an important criteria in pixel based multitemporal image analysis. The minimization of co-registration error is addressed considering 8-neighborhood pixels. Comparison of results of ITPCA analysis with LRT (likelihood ratio test) and GLRT (generalized likelihood ratio test) methods used for SAR and MS (Multispectral) images respectively in earlier publications are also presented in this paper. The datasets of Sentinel-2 around 0-3 days of the acquisition of Sentinel-1 are used for multimodal image fusion. SAR and MS both have inherent advantages and disadvantages. SAR images have the advantage of being insensitive to atmospheric and light conditions, but it suffers the presence of speckle phenomenon. In case of multispectral, challenge is to get quite a large number of datasets without cloud coverage in region of interest for multivariate distribution modelling.  © 2021 SPIE.","Image analysis; Image fusion; Image segmentation; Large dataset; Pixels; Radar imaging; Remote sensing; Synthetic aperture radar; Change detection; Coregistration; Generalized Likelihood Ratio Test; Iterated principal component analyse; Likelihood ratio tests; Multi-modal; Multi-spectral; Principal-component analysis; SAR; SAR Images; Principal component analysis","Change detection; GLRT; ITPCA; LRT; Multimodal; Multispectral; SAR","Conference paper","Final","","Scopus","2-s2.0-85118562976"
"Park N.-W.; Park M.-G.; Kwak G.-H.; Hong S.","Park, No-Wook (7202111787); Park, Min-Gyu (57215432360); Kwak, Geun-Ho (57206203736); Hong, Sungwook (55817600100)","7202111787; 57215432360; 57206203736; 55817600100","Deep Learning-Based Virtual Optical Image Generation and Its Application to Early Crop Mapping","2023","Applied Sciences (Switzerland)","13","3","1766","","","","10.3390/app13031766","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147917899&doi=10.3390%2fapp13031766&partnerID=40&md5=665bb799b92337d2b903139947863e3e","This paper investigates the potential of cloud-free virtual optical imagery generated using synthetic-aperture radar (SAR) images and conditional generative adversarial networks (CGANs) for early crop mapping, which requires cloud-free optical imagery at the optimal date for classification. A two-stage CGAN approach, including representation and generation stages, is presented to generate virtual Sentinel-2 spectral bands using all available information from Sentinel-1 SAR and Sentinel-2 optical images. The dual-polarization-based radar vegetation index and all available multi-spectral bands of Sentinel-2 imagery are particularly considered for feature extraction in the representation stage. A crop classification experiment using Sentinel-1 and -2 images in Illinois, USA, demonstrated that the use of all available scattering and spectral features achieved the best prediction performance for all spectral bands, including visible, near-infrared, red-edge, and shortwave infrared bands, compared with the cases that only used dual-polarization backscattering coefficients and partial input spectral bands. Early crop mapping with an image time series, including the virtual Sentinel-2 image, yielded satisfactory classification accuracy comparable to the case of using an actual time-series image set, regardless of the different combinations of spectral bands. Therefore, the generation of virtual optical images using the proposed model can be effectively applied to early crop mapping when the availability of cloud-free optical images is limited. © 2023 by the authors.","","crop classification; deep learning; generative adversarial networks; virtual image","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85147917899"
"Bartsch A.; Pointner G.; Nitze I.; Efimova A.; Jakober D.; Ley S.; Högström E.; Grosse G.; Schweitzer P.","Bartsch, Annett (8709691100); Pointner, Georg (57194632496); Nitze, Ingmar (56224472600); Efimova, Aleksandra (57351162000); Jakober, Dan (57350584400); Ley, Sarah (57219172566); Högström, Elin (56372298800); Grosse, Guido (7101977707); Schweitzer, Peter (7102806020)","8709691100; 57194632496; 56224472600; 57351162000; 57350584400; 57219172566; 56372298800; 7101977707; 7102806020","Expanding infrastructure and growing anthropogenic impacts along Arctic coasts","2021","Environmental Research Letters","16","11","115013","","","","10.1088/1748-9326/ac3176","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119686313&doi=10.1088%2f1748-9326%2fac3176&partnerID=40&md5=9574d2dc91df81b720a70044f074ad49","The accelerating climatic changes and new infrastructure development across the Arctic require more robust risk and environmental assessment, but thus far there is no consistent record of human impact. We provide a first panarctic satellite-based record of expanding infrastructure and anthropogenic impacts along all permafrost affected coasts (100 km buffer, ≈6.2 Mio km2), named the Sentinel-1/2 derived Arctic Coastal Human Impact (SACHI) dataset. The completeness and thematic content goes beyond traditional satellite based approaches as well as other publicly accessible data sources. Three classes are considered: linear transport infrastructure (roads and railways), buildings, and other impacted area. C-band synthetic aperture radar and multi-spectral information (2016-2020) is exploited within a machine learning framework (gradient boosting machines and deep learning) and combined for retrieval with 10 m nominal resolution. In total, an area of 1243 km2 constitutes human-built infrastructure as of 2016-2020. Depending on region, SACHI contains 8%-48% more information (human presence) than in OpenStreetMap. 221 (78%) more settlements are identified than in a recently published dataset for this region. 47% is not covered in a global night-time light dataset from 2016. At least 15% (180 km2) correspond to new or increased detectable human impact since 2000 according to a Landsat-based normalized difference vegetation index trend comparison within the analysis extent. Most of the expanded presence occurred in Russia, but also some in Canada and US. 31% and 5% of impacted area associated predominantly with oil/gas and mining industry respectively has appeared after 2000. 55% of the identified human impacted area will be shifting to above 0 °C ground temperature at two meter depth by 2050 if current permafrost warming trends continue at the pace of the last two decades, highlighting the critical importance to better understand how much and where Arctic infrastructure may become threatened by permafrost thaw.  © 2021 The Author(s).","Arctic; Adaptive boosting; Deep learning; Permafrost; Risk assessment; Synthetic aperture radar; Anthropogenic impacts; Arctic; Climatic changes; Human impact; Infrastructure; New infrastructure development; Remote-sensing; Sentinel; Sentinel-1; Settlement; anthropogenic effect; climate change; data set; infrastructure; permafrost; Remote sensing","Arctic; Infrastructure; Machine learning; Permafrost; Remote sensing; Sentinel; Settlements","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85119686313"
"Aswatha S.M.; Mahapatra R.; Mukhopadhyay J.; Biswas P.K.; Aikat S.; Misra A.","Aswatha, Shashaank M. (55001806100); Mahapatra, Rajeswari (57213190605); Mukhopadhyay, J. (57212348061); Biswas, P.K. (7202443668); Aikat, S. (57195366142); Misra, A. (15840289400)","55001806100; 57213190605; 57212348061; 7202443668; 57195366142; 15840289400","Unsupervised Categorization of Forest-Cover Using Multi-Spectral and Hybrid Polarimetric Sar Images","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898870","2603","2606","3","10.1109/IGARSS.2019.8898870","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077691022&doi=10.1109%2fIGARSS.2019.8898870&partnerID=40&md5=57d9058f2e76dc5a954c09cf8f27f192","In this paper, we propose to distinguish forest-cover in an unsupervised fashion by a combination of passive multi-spectral imagery and active hybrid polarized SAR data. At first, multi-spectral imagery (MSI) is used to separate general vegetation region (e.g., forest, mature grassland, and pre-harvest agricultural fields) from the imaged scene using spectral slopes based rules and support vector machine technique. Then, hybrid polarimetric SAR image of the same region (acquired with a common time stamp) is clustered into three scatter classes, namely, surface, volume, and dihedral, using Stokes parameters based m - δ decomposition. Forest cover is extracted by bi-labeled pixels of the study site that correspond to vegetation (in MSI) and volume scatter (in SAR), which forms a community level classification of forest region. Further, using Wishart derived mean-shift clustering technique, we segregate possible categories of forest clusters within the mapped forest region to obtain a sub-community level classification. Discernible spectral and scattering characteristics of remotely sensed images are explored in our work for identifying forest regions and their possible categories. The proposed method is automated by freeing the manual supervision in selecting seed pixels for training any machine learning technique. © 2019 IEEE.","Agricultural robots; Forestry; Geology; Learning systems; Pixels; Polarimeters; Remote sensing; Spectroscopy; Support vector machines; Synthetic aperture radar; Vegetation; Forest classification; Mean shift; Multispectral images; Polarimetric SAR; Unsupervised classification; Radar imaging","Forest classification; hybrid polarimetric SAR image; multi-spectral image; unsupervised classification; Wishart mean-shift","Conference paper","Final","","Scopus","2-s2.0-85077691022"
"Guerman A.D.; Ivanov D.S.; Roldugin D.S.; Tkachev S.S.; Okhitina A.S.","Guerman, A.D. (6508339570); Ivanov, D.S. (57201991357); Roldugin, D.S. (55037526400); Tkachev, S.S. (25823962200); Okhitina, A.S. (57212134263)","6508339570; 57201991357; 55037526400; 25823962200; 57212134263","Infante maritime surveillance satellite","2020","Advances in the Astronautical Sciences","173","","AAS 20-269","617","623","6","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111857275&partnerID=40&md5=510d17e3528b9689cb6e7181243f8d7c","The INFANTE small satellite mission is currently designed for the Portuguese home waters coverage. It is equipped with the synthetic aperture radar and multispectral camera. Orbit maintenance is required due to the restrictions imposed by the bus and payload. Namely, the radar operation requires relatively narrow range of orbit altitudes so the orbit should be maintained quite close to the nominal operational one. Orbital and angular motion combined simulation results are provided along with the corresponding maintenance maneuvers. © 2020, Univelt Inc., All rights reserved.","Orbits; Space-based radar; Synthetic aperture radar; Angular motions; Combined simulation; Maritime surveillance; Multi-spectral cameras; Orbit altitude; Orbit maintenance; Small satellite mission; Small satellites","","Conference paper","Final","","Scopus","2-s2.0-85111857275"
"Shah E.; Jayaprasad P.; James M.E.","Shah, Esha (57210882835); Jayaprasad, P. (6506108165); James, M.E. (55233401000)","57210882835; 6506108165; 55233401000","Image Fusion of SAR and Optical Images for Identifying Antarctic Ice Features","2019","Journal of the Indian Society of Remote Sensing","47","12","","2113","2127","14","10.1007/s12524-019-01040-3","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074560479&doi=10.1007%2fs12524-019-01040-3&partnerID=40&md5=975c9c3df3b1430973c863e3690bc89f","Remote sensing data plays an important role in extracting thematic information from various sensors having different spectral, spatial and temporal resolutions. The present study aims at fusion of Radar Imaging Satellite-1 Fine Resolution Stripmap-1 and ResourceSAT-2 Linear Imaging Self Scanning Scanner-4 (LISS-4) images over Indian Antarctic Research Station Maitri and its surroundings to generate a better product which contains the characteristics of both the spectral information from LISS-4 and the spatial details of SAR. Different pixel-based fusion techniques such as Brovey Transform, Principal Component Analysis (PCA), Intensity Hue Saturation and Wavelet Principal Component Analysis (W-PCA) have been used in the present study. These image fusion techniques have been applied for the whole scene as well as for individual surface features like melt ponds, crevasses, freshwater lake, blue ice, oasis and lake ice for better discrimination of features. Quality assessment is performed by evaluating the performance of these algorithms using visual, spatial (High Pass Correlation Coefficient and Entropy) and spectral (Root Mean Square Error, Correlation Coefficient, ERGAS and Universal Quality Index) parameters. It is found that the identification of certain features such as crevasses, blue ice, melt ponds and lake ice has been improved with fused images compared to the original multi-spectral and SAR images. PCA and W-PCA fusion techniques offer better performance as compared to the rest of the techniques. © 2019, Indian Society of Remote Sensing.","Antarctica; East Antarctica; Maitri; algorithm; ice; image; image analysis; LISS; optical method; principal component analysis; spatial analysis; synthetic aperture radar; wavelet analysis","Antarctic ice features; Feature extraction; Image fusion; Image merging; ResourceSAT-2 LISS-4; RISAT-1 FRS-1; SAR","Article","Final","","Scopus","2-s2.0-85074560479"
"Hamidi E.; Peter B.G.; Munoz D.F.; Moftakhari H.; Moradkhani H.","Hamidi, Ebrahim (58088349200); Peter, Brad G. (57191077814); Munoz, David F. (57211500703); Moftakhari, Hamed (55909919300); Moradkhani, Hamid (6506246184)","58088349200; 57191077814; 57211500703; 55909919300; 6506246184","Fast Flood Extent Monitoring with SAR Change Detection Using Google Earth Engine","2023","IEEE Transactions on Geoscience and Remote Sensing","","","","1","1","0","10.1109/TGRS.2023.3240097","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147298963&doi=10.1109%2fTGRS.2023.3240097&partnerID=40&md5=bc7afe95f9a6b65ce949867dc841b9a6","Flooding is one of the most frequent and disastrous natural hazards triggered by extreme precipitation, high river runoff, hurricane storm surges, and compounding effects of various flood drivers. This study introduces a new multi-source remote sensing approach that leverages both multi-spectral optical imagery and the weather- and illumination-independent characteristics of Synthetic Aperture Radar (SAR) data to streamline, automate, and map geographically reliable flood inundation extents. Utilizing the near real-time and cloud computing capabilities of Google Earth Engine (GEE), this process facilitates data acquisition and enables large-scale flood monitoring in an expeditious manner. Two major hurricanes along the U.S. Gulf Coast were evaluated: (1) the 2021 Hurricane Ida to the south of New Orleans, Louisiana and (2) the 2017 Hurricane Harvey to the east of Houston, Texas. We devised a change detection and thresholding framework using multi-temporal SAR imagery and validated the results with flood extent maps derived from Landsat 8 and Sentinel-2 optical imagery. We demonstrate that constant threshold values for flood extraction from SAR change detection indices are not ubiquitously suitable for all geographies, thus we outline a heuristic that can be used to select thresholds suitable for specific sites through a fully automated sensitivity analysis. The results indicated high agreement between the SAR and optical imagery (77&#x2013;80%), with SAR providing the benefit of under-cloud detection. Furthermore, our results contribute to scaling the SAR approach to produce rapid and accurate information for decision-makers and emergency responders during time-sensitive flood events. IEEE","Change detection; Data acquisition; Decision making; Flood control; Hurricanes; Optical remote sensing; Radar imaging; Sensitivity analysis; Space-based radar; Synthetic aperture radar; Change detection; Change detection and thresholding; Flood extent monitoring; Google earth engine; Google earths; Multi-source remote sensing data; Multi-Sources; Optical imagery; Remote sensing data; Thresholding; Floods","Change Detection and Thresholding; Flood Extent Monitoring; Google Earth Engine; Hurricanes; Multi-Source Remote Sensing Data","Article","Article in press","","Scopus","2-s2.0-85147298963"
"Yu Z.; Wang T.; Zhang X.; Zhang J.; Ren P.","Yu, Zhiqiang (7404345818); Wang, Tingwei (57201195180); Zhang, Xi (24469469100); Zhang, Jie (55963073000); Ren, Peng (25960361900)","7404345818; 57201195180; 24469469100; 55963073000; 25960361900","Locality preserving fusion of multi-source images for sea-ice classification","2019","Acta Oceanologica Sinica","38","7","","129","136","7","10.1007/s13131-019-1464-2","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068752284&doi=10.1007%2fs13131-019-1464-2&partnerID=40&md5=229ee1cf6b587873e39072f64efe3496","We present a novel sea-ice classification framework based on locality preserving fusion of multi-source images information. The locality preserving fusion arises from two-fold, i.e., the local characterization in both spatial and feature domains. We commence by simultaneously learning a projection matrix, which preserves spatial localities, and a similarity matrix, which encodes feature similarities. We map the pixels of multi-source images by the projection matrix to a set fusion vectors that preserve spatial localities of the image. On the other hand, by applying the Laplacian eigen-decomposition to the similarity matrix, we obtain another set of fusion vectors that preserve the feature local similarities. We concatenate the fusion vectors for both spatial and feature locality preservation and obtain the fusion image. Finally, we classify the fusion image pixels by a novel sliding ensemble strategy, which enhances the locality preservation in classification. Our locality preserving fusion framework is effective in classifying multi-source sea-ice images (e.g., multi-spectral and synthetic aperture radar (SAR) images) because it not only comprehensively captures the spatial neighboring relationships but also intrinsically characterizes the feature associations between different types of sea-ices. Experimental evaluations validate the effectiveness of our framework. © 2019, Chinese Society for Oceanography and Springer-Verlag GmbH Germany, part of Springer Nature.","","ensemble classification; multi-source image fusion; sea-ice classification","Article","Final","","Scopus","2-s2.0-85068752284"
"Ioannidou M.; Koukos A.; Sitokonstantinou V.; Papoutsis I.; Kontoes C.","Ioannidou, Maria (57381943300); Koukos, Alkiviadis (57215426034); Sitokonstantinou, Vasileios (57202645115); Papoutsis, Ioannis (56763995400); Kontoes, Charalampos (35618936400)","57381943300; 57215426034; 57202645115; 56763995400; 35618936400","Assessing the Added Value of Sentinel-1 PolSAR Data for Crop Classification","2022","Remote Sensing","14","22","5739","","","","10.3390/rs14225739","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142677999&doi=10.3390%2frs14225739&partnerID=40&md5=177002b5424f64b1eb08afa9eb243001","Crop classification is an important remote sensing task with many applications, e.g., food security monitoring, ecosystem service mapping, climate change impact assessment, etc. This work focuses on mapping 10 crop types at the field level in an agricultural region located in the Spanish province of Navarre. For this, multi-temporal Synthetic Aperture Radar Polarimetric (PolSAR) Sentinel-1 imagery and multi-spectral Sentinel-2 data were jointly used. We applied the Cloude–Pottier polarimetric decomposition on PolSAR data to compute 23 polarimetric indicators and extracted vegetation indices from Sentinel-2 time-series to generate a big feature space of 818 features. In order to assess the relevance of the different features for the crop mapping task, we run a number of scenarios using a Support Vector Machines (SVM) classifier. The model that was trained using only the polarimetric data demonstrates a very promising performance, achieving an overall accuracy over 82%. A genetic algorithm was also implemented as a feature selection method for deriving an optimal feature subset. To showcase the positive effect of using polarimetric data over areas suffering from cloud coverage, we contaminated the original Sentinel-2 time-series with simulated cloud masks. By incorporating the genetic algorithm, we derived a high informative feature subset of 120 optical and polarimetric features, as the corresponding classification model increased the overall accuracy by 5% compared to the model trained only with Sentinel-2 features. The feature importance analysis indicated that apart from the Sentinel-2 spectral bands and vegetation indices, several polarimetric parameters, such as Shannon entropy, second eigenvalue and normalised Shannon entropy are of high value in identifying crops. In summary, the findings of our study highlight the significant contribution of Sentinel-1 PolSAR data in crop classification in areas with frequent cloud coverage and the effectiveness of the genetic algorithm in discovering the most informative features. © 2022 by the authors.","Classification (of information); Climate change; Crops; Ecosystems; Eigenvalues and eigenfunctions; Feature Selection; Food supply; Optical remote sensing; Polarimeters; Space-based radar; Support vector machines; Synthetic aperture radar; Time series; Vegetation mapping; Cloud cover; Common agricultural policy; Crop classification; Crop type mappings; Features selection; Polarimetric data; Radar polarimetry; Sentinel-1; Times series; Vegetation index; Genetic algorithms","cloud cover; common agricultural policy; crop type mapping; feature selection; genetic algorithm; radar polarimetry; time series","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85142677999"
"Wu K.; Gu L.; Jiang M.","Wu, Kunpeng (57295001700); Gu, Lingjia (15834718400); Jiang, Mingda (57295437600)","57295001700; 15834718400; 57295437600","Research on fusion of SAR image and multispectral image using texture feature information","2021","Proceedings of SPIE - The International Society for Optical Engineering","11829","","1182916","","","","10.1117/12.2592925","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116960462&doi=10.1117%2f12.2592925&partnerID=40&md5=3a0be947723402dbeafc6fd8ba86a391","Remote sensing images have the characteristics of multiple data sources and complex data. How to integrate remote sensing image information more efficiently has always been the focus of research. In this paper, Changchun City, Jilin Province, China was selected as the experimental area, Sentinel-1 and Sentinel-2 images were used as experimental data, and a fusion method of SAR image and multispectral image using texture feature information was proposed. First, perform HIS transformation on the multi-spectral image to obtain the intensity image. After that, wavelet transform was used to extract the high-frequency and low-frequency detail components of the intensity image. At the same time, the principal component analysis method and the deep learning network VGG-19 were used to extract the texture features of the SAR image. The SAR texture image was used to enhance the high-frequency detail component of the intensity image, and combined with the original low-frequency detail component to perform inverse wavelet transform, then a new intensity image was obtained. Finally, the modulated intensity image was used to replace the original intensity image, and the inverse transformation (I-HIS) was performed to obtain an enhanced image fused from the multispectral image and the SAR image. Compared with the original image, the detailed features and boundary distinction were significantly improved. The fusion image was input into the support vector machine for feature classification, and the comprehensive classification accuracy reached 94.74%, which was 3.5% higher than the classification accuracy of the unfused image. © 2021 SPIE.","Classification (of information); Deep learning; Image compression; Image enhancement; Image fusion; Image texture; Principal component analysis; Radar imaging; Remote sensing; Spectroscopy; Support vector machines; Synthetic aperture radar; Textures; Wavelet transforms; Classification accuracy; Deep learning algorithm; Feature information; High frequency HF; Intensity images; Lower frequencies; Multispectral images; Remote sensing images; SAR Images; Texture features; Learning algorithms","Deep learning algorithm; Image fusion; Multispectral image; SAR image","Conference paper","Final","","Scopus","2-s2.0-85116960462"
"Srivastava H.; Saini K.; Pant T.","Srivastava, Harsh (56081845000); Saini, Kirti (57679155100); Pant, Triloki (26423113300)","56081845000; 57679155100; 26423113300","A Time Series Approach for Wheat Crop Harvest Detection using Multispectral Data","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","6777","6780","3","10.1109/IGARSS47720.2021.9554017","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129817150&doi=10.1109%2fIGARSS47720.2021.9554017&partnerID=40&md5=9314cdc979d1bcd625f2ac8a69d10082","—In this paper, a time series approach for the detection of winter wheat harvest is proposed. The use of satellites to monitor crops and predict crop yield and estimated harvest dates is gathering attention now a days. The present study undertakes the task of finding and predicting the accurate time for the harvesting of wheat crops based on the change in the spectral signature of the field during observation and the growth timeline of the crop. For this purpose, Sentinel-2 multispectral time series data is used for which a timely ground observation is done. High emphasis is given to the selection of the optimal set of bands among 13 available bands, and after a rigorous pattern observation, Red, Blue, and NIR bands are found to be the optimal band set. Although Red and Blue bands together are able to identify various crop growth stages, using the NIR band in the band set is an added advantage because it is used to generate NDVI time series with Red band. The only contrast between Red and Blue bands for this specific study is that Red band is more aggressive towards changes in the state of the crop. The selected band set is used for the observation of the field to detect an accurate harvest period. The proposed approach is validated using Sentinel-1 SAR coherence time series and found to be accurate. ©2021 IEEE","Harvesting; Infrared devices; Observatories; Remote sensing; Synthetic aperture radar; Time series; Crop harvest detection; Crop yield; Multi-spectral; Multi-spectral data; NDVI; Remote-sensing; Spectral signature; Times series; Wheat harvest; Winter wheat; Crops","Crop harvest detection; NDVI; Remote sensing; Time series","Conference paper","Final","","Scopus","2-s2.0-85129817150"
"Alvarez-Mozos J.; Villanueva J.; Arias M.; Gonzalez-Audicana M.","Alvarez-Mozos, J. (35587500600); Villanueva, J. (57680052900); Arias, M. (57211135010); Gonzalez-Audicana, M. (8248673500)","35587500600; 57680052900; 57211135010; 8248673500","CORRELATION BETWEEN NDVI AND SENTINEL-1 DERIVED FEATURES FOR MAIZE","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","6773","6776","3","10.1109/IGARSS47720.2021.9554099","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125667786&doi=10.1109%2fIGARSS47720.2021.9554099&partnerID=40&md5=5e13cca813b3004fcfa02bf1c9518a64","Operational agricultural applications of remote sensing, such as crop monitoring or irrigation scheduling, often rely on the Normalized Difference Vegetation Index (NDVI) obtained from multispectral observations. Yet, cloud cover limits its availability, so the possibility to estimate it from SAR data is appealing, as it would enable a complementary monitoring of crops. The objective of this article is to evaluate the correlation of NDVI with several SAR features obtained from Sentinel-1 data over maize. Eighteen maize fields, located in the province of Navarre (Spain), were analyzed in two agricultural campaigns. Nine SAR features were evaluated, including: the backscattering coefficients in VH and VV polarizations, their ratio, product, sum and difference, as well as the Radar Vegetation Index (RVI), the Vertical Dual DePolarization Index (VDDPI) and the Normalized Difference Polarization Index (NDPI). The correlations obtained in linear and dB units were compared, as well as the influence of temporal smoothing. The highest correlation was obtained with VH backscatter expressed in dB. © 2021 IEEE","Crops; Depolarization; Geology; Remote sensing; Synthetic aperture radar; Vegetation; Cloud cover; Crop monitoring; Derived features; Irrigation scheduling; Maize; Multi-spectral; Normalized difference vegetation index; Remote-sensing; SAR data; Sentinel-1; Backscattering","backscatter; maize; NDVI; Sentinel-1","Conference paper","Final","","Scopus","2-s2.0-85125667786"
"Yi W.; Zeng Y.; Yuan Z.","Yi, Wei (57206484579); Zeng, Yong (36624647900); Yuan, Zheng (57206482317)","57206484579; 36624647900; 57206482317","Fusion of GF-3 SAR and Optical Images Based on the Nonsubsampled Contourlet Transform; [基于NSCT变换的高分三号SAR与光学图像融合]","2018","Guangxue Xuebao/Acta Optica Sinica","38","11","1110002","","","","10.3788/AOS201838.1110002","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061739023&doi=10.3788%2fAOS201838.1110002&partnerID=40&md5=7796f0c583e8aba96a36e8f36bedaafa","Among the existing synthetic-aperture radar (SAR) satellites, the GF-3 offers the most kinds of imaging modes. The fusion of the GF-3 SAR images with the multi-spectral images can improve the visual quality of the SAR images. We show how to use the nonsubsampled contourlet transform (NSCT) for simulating high-resolution images such that both the details of the SAR image and the spectral information of the multi-spectral image can be retained. This method ensures that the fusion of SAR and multi-spectral images is not limited by a specific algorithm. To verify the effectiveness of the proposed idea, two types of resolutions are used as the experimental data: the GF-3 satellite SAR images with resolutions of 3 m and 5 m, respectively, and the GF-1 satellite multi-spectral images with a resolution of 16 m. We perform comparative experiments with different fusion algorithms. The results show the effectiveness of the proposed approach. The traditional method that directly fuses the SAR and multi-spectral images can keep the details of the SAR image. However, the noise is obvious and some information of the multi-spectral image remains. The NSCT average images and the average NSCT images can retain the spectral information. The spectral information of NSCT average images is closer to the multi-spectral images than the average NSCT images. © 2018, Chinese Lasers Press. All right reserved.","Geometrical optics; Image enhancement; Image fusion; Image processing; Optical data processing; Satellites; Space-based radar; Spectroscopy; Synthetic aperture radar; Comparative experiments; Evaluation index; High resolution image; Multispectral images; Non subsampled contourlet transform (NSCT); Non-sub-sampled contourlet transforms; Optical image; Spectral information; Radar imaging","Evaluation index; GF-3 satellite; Image processing; Nonsubsampled contourlet transform; Synthetic-aperture radar and optical image","Article","Final","","Scopus","2-s2.0-85061739023"
"Park K.-A.; Park J.-J.; Jang J.-C.; Lee J.-H.; Oh S.; Lee M.","Park, Kyung-Ae (55090872100); Park, Jae-Jin (57190621407); Jang, Jae-Cheol (57206970543); Lee, Ji-Hyun (57268979600); Oh, Sangwoo (56399724500); Lee, Moonjin (7409116066)","55090872100; 57190621407; 57206970543; 57268979600; 56399724500; 7409116066","Multi-spectral ship detection using optical, hyperspectral, and microwave SAR remote sensing data in coastal regions","2018","Sustainability (Switzerland)","10","11","4064","","","","10.3390/su10114064","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055988491&doi=10.3390%2fsu10114064&partnerID=40&md5=eb8e5eb23f05482474c5dfe8b9b1e9e6","The necessity of efficient monitoring of ships in coastal regions has been increasing over time. Multi-satellite observations make it possible to effectively monitor vessels. This study presents the results of ship detection methodology, applied to optical, hyperspectral, and microwave satellite images in the seas around the Korean Peninsula. Spectral matching algorithms are used to detect ships using hyperspectral images with hundreds of spectral channels and investigate the similarity between the spectra and in-situ measurements. In the case of SAR (Synthetic Aperture Radar) images, the Constant False Alarm Rate (CFAR) algorithm is used to discriminate the vessels from the backscattering coefficients of Sentinel-1B SAR and ALOS-2 PALSAR2 images. Validation results exhibited that the locations of the satellite-detected vessels showed good agreement with real-time location data within the Sentinel-1B coverage in the Korean coastal region. This study presented the probability of detection values of optical and SAR-based ship detection and discussed potential causes of the errors. This study also suggested a possibility for real-time operational use of vessel detection from multi-satellite images based on optical, hyperspectral, and SAR remote sensing, particularly in the inaccessible coastal regions off North Korea, for comprehensive coastal management and sustainability. © 2018 by the authors.","North Korea; coastal zone management; detection method; remote sensing; satellite data; satellite imagery; ship design; sustainability; synthetic aperture radar","Coastal region; Hyperspectral; Optical remote sensing; SAR; Ship detection; Sustainability","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85055988491"
"Datta U.","Datta, U. (7007098861)","7007098861","Infrastructure monitoring using SAR and multispectral multitemporal images","2020","Proceedings of SPIE - The International Society for Optical Engineering","11533","","115330B","","","","10.1117/12.2573894","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093980993&doi=10.1117%2f12.2573894&partnerID=40&md5=c7ebf8404446e509bdc8feda61148b3e","The main objective of this study is to investigate suitable approaches to monitor the land infrastructure growth over a period of time using multimodality of remote sensing satellite images. Bi-temporal change detection method is unable to indicate the continuous change occurring over a long period of time and thus to achieve this purpose, synthetic aperture radar (SAR) and multispectral satellite images of same geographical region over a period of 2015 to 2018 are obtained and analyzed. SAR data from Sentinel-1 and multispectral image data from Sentinel-2 and Landsat-8 are used. Statistical composite hypothesis technique is used for estimating pixel-based change detection. The well-established likelihood ratio test (LRT) statistic is used for determining the pixel-wise change in a series of complex covariance matrices of multilooked polarimetric SAR data. In case of multispectral images, the approach used is to estimate a statistical model from series of multispectral image data over a long period of time, assuming there is no considerable change during that time period and then compare it with the multispectral image data obtained at a later time. The generalized likelihood ratio test (GLRT) is used to detect the target (changed pixel) from probabilistic estimated model of the corresponding background clutter (non-changed pixels). To minimize error due to co-registration, 8- neighborhood pixels around the pixel under test are also considered. There are different challenges in both the cases. SAR images have the advantage of being insensitive to atmospheric and light conditions, but it suffers the presence of speckle phenomenon. In case of multispectral, challenge is to get quite large number of datasets without cloud coverage in region of interest for multivariate distribution modelling. Due to imperfect modelling there will be high probability of false alarm. Co-registration is also an important criterion in multitemporal image analysis. © SPIE. Downloading of the abstract is permitted for personal use only.","Covariance matrix; Image analysis; Image segmentation; Large dataset; Pixels; Remote sensing; Space-based radar; Synthetic aperture radar; Generalized likelihood-ratio tests; Infrastructure monitoring; Likelihood ratio tests; Multi-spectral image data; Multispectral satellite image; Multitemporal image analysis; Multivariate distributions; Remote sensing satellites; Radar imaging","Co-registration; Covariance matrices; GLRT; LRT; Multispectral; Multitemporal; SAR","Conference paper","Final","","Scopus","2-s2.0-85093980993"
"Desrues M.; Malet J.-P.; Brenguier O.; Point J.; Stumpf A.; Lorier L.","Desrues, Mathilde (57194949094); Malet, Jean-Philippe (7004001508); Brenguier, Ombeline (56919651200); Point, Julien (57201210692); Stumpf, André (37103096800); Lorier, Lione (56040164600)","57194949094; 7004001508; 56919651200; 57201210692; 37103096800; 56040164600","TSM-tracing surface motion: A generic toolbox for analyzing ground-based image time series of slope deformation","2019","Remote Sensing","11","19","2189","","","","10.3390/rs11192189","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073420773&doi=10.3390%2frs11192189&partnerID=40&md5=4ac06f029387b125dd72c8a3ec0b7599","Passive sensors such as multi-spectral (e.g., Single Lens Reflex, SLR) cameras are increasingly being used for geohazards monitoring (landslides, cliffs affected by rock falls, ice glaciers, and volcano flanks) because of their low cost compared to expensive terrestrial laser scanner (TLS) or radar imaging (GB-InSAR) systems. Indeed, due to the large consumer market, sensor resolution and quality (e.g., gain, dynamic range, and geometry) are increasing rapidly. For gravitational processes, such as landslides, recent research has focused on the development and implementation of image correlation techniques to estimate the spatial shift between at least a pair of images by maximizing a cross-correlation function. A generic and fully automated pipeline is proposed for the processing of long image time series acquired for several site configurations. The system associates modules for (1) the selection of the image sequences, (2) the registration of the image stacks and the correction of the camera movements, and (3) the calculation of the terrain motion using change detection approaches. The system is based on the open-source photogrammetric library MicMac and tailored for the processing of monoscopic images. A sensitivity analysis is conducted to design and test the image processing for two use cases respectively the Chambon landslide (Isère, France) characterized by slow motion (< 10 cm day-1), and the Pas de l'Ours landslide (Hautes-Alpes, France) characterized by moderate motion (> 50 cm day-1). Four categories of parameters are tested: the image modality, the image matching parameters, the size of the stable area used in the co-registration stage, and the strategy used to combine the images in the time series. The application of the pipeline on the two use cases provides information about the kinematics and the spatial behavior of the landslides. © 2019 by the authors.","Cameras; Costs; Geometrical optics; Image matching; Landforms; Landslides; Open systems; Optical data processing; Pipeline processing systems; Pipelines; Rock bursts; Sensitivity analysis; Surveying instruments; Synthetic aperture radar; Time series; Cross-correlation function; Image correlation techniques; Image time-series; Matching parameters; Optical image; Single lens reflexes; Slope deformation; Terrestrial laser scanners; Image analysis","Ground-based optical images; Image matching; Image time series; Landslide; Terrain motion monitoring","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85073420773"
"Tapete D.; Cigna F.; Paloscia S.; Santi E.; Pettinato S.; Fontanelli G.; Chiarito E.; Notarnicola C.; Cuozzo G.; Jacob A.; De Gregorio L.; Rossi M.","Tapete, Deodato (55221777800); Cigna, Francesca (36720533600); Paloscia, Simonetta (7006059266); Santi, Emanuele (14031975000); Pettinato, Simone (22235499100); Fontanelli, Giacomo (36816017700); Chiarito, Eugenia (57217203743); Notarnicola, Claudia (56213274700); Cuozzo, Giovanni (8258624600); Jacob, Alexander (8248107800); De Gregorio, Ludovica (56422006900); Rossi, Mattia (57196234553)","55221777800; 36720533600; 7006059266; 14031975000; 22235499100; 36816017700; 57217203743; 56213274700; 8258624600; 8248107800; 56422006900; 57196234553","Development of Algorithms for the Estimation of Hydrological Parameters Combining Cosmo-Skymed and Sentinel Time Series with in Situ Measurements","2020","2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium, M2GARSS 2020 - Proceedings","","","9105313","53","56","3","10.1109/M2GARSS47143.2020.9105313","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086730511&doi=10.1109%2fM2GARSS47143.2020.9105313&partnerID=40&md5=4598cd66d3964a6dd5e2c5ed0b75f5a5","The collaborative research project 'ALGORITHMS' (20192021) between the Italian Space Agency (ASI) and the Institute of Applied Physics of the National Research Council of Italy (IFAC-CNR) aims to develop innovative algorithms to estimate the main hydrological parameters (e.g. soil moisture content, vegetation properties, snow water equivalent). The proposed algorithms combine Synthetic Aperture Radar (SAR), multispectral and hyperspectral satellite data with in-situ measurements. First results are presented based on retrieval analyses and surveys over the test sites in northern and central Italy, using exceptionally long, consistent and multi-polarized C- and X-band SAR time series from the Copernicus Sentinel-1 and ASI's COSMO-SkyMed missions, as well as Copernicus Sentinel2 high resolution multi-spectral imagery. © 2020 IEEE.","Geology; Remote sensing; Snow; Soil moisture; Soil testing; Space optics; Space-based radar; Spectroscopy; Synthetic aperture radar; Time series; Time series analysis; Collaborative research projects; High resolution multi-spectral imagery; Hydrological parameters; Hyperspectral satellite; Innovative algorithms; National Research Council; Snow water equivalent; Vegetation properties; Parameter estimation","Artificial Neural Networks; COSMO-SkyMed; sensitivity analysis; Sentinels; snow water equivalent; Soil moisture content","Conference paper","Final","","Scopus","2-s2.0-85086730511"
"Radhika K.; Murali Mohan Babu Y.; Shahina S.K.M.","Radhika, K. (57193256948); Murali Mohan Babu, Y. (57188737305); Shahina, S.K.M. (57207827189)","57193256948; 57188737305; 57207827189","Classification of RISAT MRS data with BM3D algorithm","2019","International Journal of Innovative Technology and Exploring Engineering","8","5","","104","106","2","","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062967786&partnerID=40&md5=df141bfec1b194da9765a8c91b689d02","In this Paper, It has been proposed a de-speckling method on Indian Synthetic-aperture radar (SAR) image with block matching 3D transformation and has been used for classification method. This block-matching 3D algorithm clearly explained how to generate de-speckling of SAR image for classification. In this technique has been tested on RISAT-1 SAR image data set and practical results exhibit that this technique is the better in terms of de speckling quality image factors. The despeckled image has been fused with LANSAT-8 optical image. The resultant multi spectral and good resolution image has been classified using supervised classification. © BEIESP.","","Block matching 3D algorithm; De-speckling; Synthetic-aperture radar","Article","Final","","Scopus","2-s2.0-85062967786"
"Collings B.; Ford M.; Dickson M.","Collings, Benedict (57930909300); Ford, Murray (12792686300); Dickson, Mark (11838868100)","57930909300; 12792686300; 11838868100","A Methodology for National Scale Coastal Landcover Mapping in New Zealand","2022","Remote Sensing","14","19","4827","","","","10.3390/rs14194827","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140031370&doi=10.3390%2frs14194827&partnerID=40&md5=f2e487d4ed61b4194df2aacdf51fa8fa","Satellite earth observation data has become fundamental in efforts to map coastal change at large geographic scales. Research has generally focussed on extracting the instantaneous waterline position from time-series of satellite images to interpret long-term trends. The use of this proxy can, however, be uncertain because the waterline is sensitive to marine conditions and beach gradient. In addition, the technique disregards potentially useful data stored in surrounding pixels. In this paper, we describe a pixel-based technique to analyse coastal change. A hybrid rule-based and machine learning methodology was developed using a combination of Sentinel multispectral and Synthetic Aperture Radar composite imagery. The approach was then used to provide the first national-scale pixel-based landcover classification for the open coast of New Zealand. Nine landcover types were identified including vegetation, rock, and sedimentary classes that are common on beaches (dark sand, light sand, and gravel). Accuracy was assessed at national scale (overall accuracy: 86%) and was greater than 90% when normalised for class area. Using a combination of optical and Synthetic Aperture Radar data improved overall accuracy by 14% and enhanced the separation of coastal sedimentary classes. Comparison against a previous classification approach of sandy coasts indicated improvements of 30% in accuracy. The outputs and code are freely available and open-source providing a new framework for per-pixel coastal landcover mapping for all regions where public earth observation data is available. © 2022 by the authors.","Beaches; Pixels; Radar imaging; Sedimentary rocks; Sedimentology; Space-based radar; Synthetic aperture radar; Change detection; Coastal change; Earth observation data; Google earth engine; Google earths; Land cover mapping; Multi-spectral; New zealand; Pixel-based techniques; Sentinel; Mapping","change detection; classification; coastal change; google earth engine; mapping; multispectral; pixel-based techniques; sentinel; synthetic aperture radar","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85140031370"
"Bhugeloo A.; Peerbhay K.; Ramdhani S.; Sershen","Bhugeloo, Astika (57205185436); Peerbhay, Kabir (55617877700); Ramdhani, Syd (25653179500); Sershen (22956600900)","57205185436; 55617877700; 25653179500; 22956600900","Assessing the Trade-Offs of SPOT7 Imagery for Monitoring Natural Forest Canopy Intactness","2018","Forests","9","12","781","","","","10.3390/f9120781","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058997991&doi=10.3390%2ff9120781&partnerID=40&md5=5a1ce8286ebbccbef61e19db7657fded","Natural and human-induced disturbances influence the biodiversity and functionality of forest ecosystems. Regular, repeated assessments of canopy intactness are essential to map site-specific forest disturbance and recovery patterns, an essential requirement for forest monitoring and management. However, accessibility to images required for this practice, uncertainty around the levels of accuracy achieved with images of different resolution, and the affordability of the practice challenges its application in many developing regions. This study aimed to compare the accuracy of forest gap detection (in subtropical forests) achieved with lower-resolution (SPOT7 5 m) and higher-resolution (SPOT7 1.5 m) pan-sharpened imagery. Additionally, the Normalised Difference Vegetation Index (NDVI) and Synthetic Aperture Radar (SAR) were compared in terms of their ability to increase the accuracy of this detection when used in conjunction with both high and low resolution imagery. Results indicate that the SPOT7 1.5 m imagery produced an overall accuracy of 77.78% and a κ coefficient of 0.66 compared with the 69.44% accuracy and the 0.59 κ coefficient achieved with the SPOT7 5 m imagery. Computing image texture analysis within the Random Forest classifier (RF) framework increased classification accuracies to 75.00% for the SPOT 5 m and 86.11% for the SPOT7 1.5 m imagery, validating the usefulness of texture analysis. Variable importance was used to identify wavebands and texture-derived variables that were the most effective in discriminating canopy gaps from intact canopy. In this regard, near infrared, NDVI, SAR, contrast, mean, entropy and second moment were the most important. Collectively the results indicate that the approach adopted in this study, i.e., the use of SPOT7 1.5 m imagery in conjunction with image texture analysis and variable importance, can be used to accurately discriminate between canopy gaps and intact canopy, making it a cost-effective spatial approach for monitoring and managing natural forests. © 2018 by the authors.","Accuracy; Biodiversity; Cost Effectiveness; Ecosystems; Forestry; Image Analysis; Resolution; Spotting; Biodiversity; Cost effectiveness; Decision trees; Economic and social effects; Ecosystems; Forestry; Image texture; Infrared devices; Radar imaging; Synthetic aperture radar; Classification accuracy; Image texture analysis; Multi-spectral imagery; Normalised difference vegetation index; Random forest classifier; Random forests; Tropical forest; Variable importances; forest canopy; imagery; machine learning; monitoring; multispectral image; NDVI; SPOT; synthetic aperture radar; Image analysis","Multispectral imagery; Random forest; Sub-tropical forests; Synthetic aperture radar; Variable importance","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85058997991"
"Spasova T.; Nedkov R.; Dancheva A.; Stoyanov A.; Ivanova I.; Georgiev N.","Spasova, Temenuzhka (57211430744); Nedkov, Roumen (57204958301); Dancheva, Adlin (57204632209); Stoyanov, Andrey (24765749200); Ivanova, Iva (57198062540); Georgiev, Nikolay (57211428499)","57211430744; 57204958301; 57204632209; 24765749200; 57198062540; 57211428499","Seasonal assessment of the dynamics of sea ice based on aerospace data on Livingston Island, New Shetland Islands in Antarctica and Longyearbyen in the Arctic","2020","Proceedings of SPIE - The International Society for Optical Engineering","11524","","115240J","","","","10.1117/12.2570829","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091226958&doi=10.1117%2f12.2570829&partnerID=40&md5=d6c23f6ceeea9afec269d713e00cd3e8","Sea ice plays a major role in our planet's climate. It' acts as a reflector of solar energy, mainly in spring and summer. Sea ice covered with fresh snow can reflect 75-90% of solar energy, the open sea reflects just 5-15%. Sea ice acts as an insulator in autumn and winter. This insulating effect limits the amount of both heat and moisture the ocean loses to the atmosphere. The declining sea ice disrupts the climate, societies and fauna of Polar areas, but encourages the econcmic and industrial development. The relevance of this study is related to current trends in the use of remote sensing in solving problems of a different nature in environmental monitoring. The sea ice was analyzed and mapped according to the European Space Agency data (ESA), acquired by sensors of Sentinel-1 SAR (Synthetic Aperture Radar), Sentinel-2MSI (Multi Spectral Instrument), Sentinel-3 and GIS. The subject of the study is to demonstrate the dynamics, during the summer season from 2015 to 2019, around the coastline of Livingston Island, New Shetland Islands in Antarctica and Longyearbyen in the Arctic. Changes in environmental objects are indicated by radar images through different processing approaches. The results clearly show that sea ice melting can be best recorded by using SAR data through the C-band. The results obtained are data in the form of thematic maps showing the spatial reflectance of sea ice and its dynamics over time.  © 2020 SPIE.","Dynamics; Insulator contamination; Maps; Reflection; Sea ice; Solar energy; Space optics; Synthetic aperture radar; Environmental Monitoring; Environmental objects; European Space Agency; Industrial development; Processing approach; SAR(synthetic aperture radar); Sea ice melting; Shetland islands; Remote sensing","Optical data; SAR data; Sea ice; Sentinel 2-MSI; Sentinel-1 SAR","Conference paper","Final","","Scopus","2-s2.0-85091226958"
"Ziemann A.; Ren C.X.; Theiler J.","Ziemann, Amanda (36134071500); Ren, Christopher X. (57004276700); Theiler, James (7004449154)","36134071500; 57004276700; 7004449154","Multi-sensor anomalous change detection at scale","2019","Proceedings of SPIE - The International Society for Optical Engineering","10986","","1098615","","","","10.1117/12.2519167","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072572728&doi=10.1117%2f12.2519167&partnerID=40&md5=459401fa1727a77d859903a93041ef0e","Combining multiple satellite remote sensing sources provides a far richer, more frequent view of the earth than that of any single source; the challenge is in distilling these petabytes of heterogeneous sensor imagery into meaningful characterizations of the imaged areas. To meet this challenge requires effective algorithms for combining heterogeneous data to identify subtle but important changes among the intrinsic data variation. The major obstacle to using heterogeneous satellite data to monitor anomalous changes across time is this: subtle but real changes on the ground can be overwhelmed by artifacts that are simply due to the change in modality. Here, we implement a joint-distribution framework for anomalous change detection that can effectively ""normalize"" for these changes in modality, and does not require any phenomenological resampling of the pixel signal. This flexibility enables the use of satellite imagery from different sensor platforms and modalities. We use multi-year construction of the Los Angeles Stadium at Hollywood Park (in Inglewood, CA) as our testbed, and exploit synthetic aperture radar (SAR) imagery from Sentinel-1 and multispectral imagery from both Sentinel-2 and Landsat 8. We explore results for anomalous change detection between Sentinel-2 and Landsat 8 over time, and also show results for anomalous change detection between Sentinel-1 SAR imagery and Sentinel-2 multispectral imagery. © 2019 SPIE.","Remote sensing; Satellite imagery; Space-based radar; Spectroscopy; Synthetic aperture radar; Change detection; Effective algorithms; Heterogeneous sensors; Multi sensor; Multi-modal; Multi-spectral imagery; Multiple satellites; Synthetic Aperture Radar Imagery; Radar imaging","Anomalous change detection; Change detection; Multi-modal; Multi-sensor; Multispectral imagery; Synthetic aperture radar","Conference paper","Final","","Scopus","2-s2.0-85072572728"
"Harrington E.M.; Shaposhnikova M.; Neish C.D.; Tornabene L.L.; Osinski G.R.; Choe B.-H.; Zanetti M.","Harrington, Elise M. (57203940726); Shaposhnikova, Maria (57208887078); Neish, Catherine D. (14050508100); Tornabene, Livio L. (6506431379); Osinski, Gordon R. (6603659506); Choe, Byung-Hun (57200605479); Zanetti, Michael (48462253900)","57203940726; 57208887078; 14050508100; 6506431379; 6603659506; 57200605479; 48462253900","A Polarimetric SAR and Multispectral Remote Sensing Approach for Mapping Salt Diapirs: Axel Heiberg Island, NU, Canada","2019","Canadian Journal of Remote Sensing","45","1","","54","72","18","10.1080/07038992.2019.1610656","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066014157&doi=10.1080%2f07038992.2019.1610656&partnerID=40&md5=e4141f61f9619188d6f8fd0530168f25","Remote sensing has revolutionized resource exploration by enabling quick surveillance of large areas. Quad-polarimetric synthetic aperture radar (SAR) is useful for assessing surface roughness, but few studies have applied it for geological mapping. Located in the Canadian Arctic, Axel Heiberg Island is a suitable site for exploring remote predictive geologic mapping techniques that combine quad-polarimetric SAR and multispectral datasets. The island has extensive rock exposure, with little interference from vegetation and snow in late summer. Axel Heiberg Island has the second highest concentration of salt diapirs globally. As a result, it also hosts extensive secondary salt deposits that have been weathered and precipitated away from their source. Because diapirs frequently provide structural traps for petroleum reservoirs, it is important to distinguish between diapiric and non-diapiric salt during early exploration. This study maps diapirs and secondary salts using multispectral data and characterizes them in polarimetric SAR. Diapirs appear rough in C-Band and L-Band radar, whereas the secondary salts appear smooth at both (cm–dm) scales. Field observations confirm salt diapirs are rough at the millimeter–meter scales, whereas secondary salts precipitate on smoother surfaces. These results show that radar can help differentiate between diapiric and secondary salt exposures, which will assist in future resource exploration. ©, Copyright © CASI.","Geological surveys; Mapping; Petroleum prospecting; Petroleum reservoir engineering; Petroleum reservoirs; Polarimeters; Remote sensing; Salt tectonics; Salts; Surface roughness; Field observations; Geologic mapping; Geological mapping; Multi-spectral data; Multispectral datasets; Multispectral remote sensing; Polarimetric SAR; Polarimetric synthetic aperture radars; Synthetic aperture radar","","Article","Final","","Scopus","2-s2.0-85066014157"
"Oliveira E.R.; Disperati L.; Alves F.L.","Oliveira, Eduardo R. (56673588600); Disperati, Leonardo (6506418489); Alves, Fátima L. (36130953500)","56673588600; 6506418489; 36130953500","MINDED-FBA: An Automatic Remote Sensing Tool for the Estimation of Flooded and Burned Areas","2023","Remote Sensing","15","3","724","","","","10.3390/rs15030724","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147904570&doi=10.3390%2frs15030724&partnerID=40&md5=d94ebed5e5f038655275d86bc11d4579","This paper presents the MINDED-FBA, a remote-sensing-based tool for the determination of both flooded and burned areas. The tool, freely distributed as a QGIS plugin, consists of an adaptation and development of the previously published Multi Index Image Differencing methods (MINDED and MINDED-BA). The MINDED-FBA allows the integration and combination of a wider diversity of satellite sensor datasets, now including the synthetic aperture radar (SAR), in addition to optical multispectral data. The performance of the tool is evaluated for six case studies located in Portugal, Australia, Pakistan, Italy, and the USA. The case studies were chosen for representing a wide range of conditions, such as type of hazardous event (i.e., flooding or fire), scale of application (i.e., local or regional), site specificities (e.g., climatic conditions, morphology), and available satellite data (optical multispectral and SAR). The results are compared in respect to reference delineation datasets (mostly from the Copernicus EMS). The application of the MINDED-FBA tool with SAR data is particularly effective to delineate flooding, while optical multispectral data resulted in the best performances for burned areas. Nonetheless, the combination of both types of remote sensing data (data fusion approach) also provides high correlations with the available reference datasets. The MINDED-FBA tool could represent a new near-real-time solution, capable of supporting emergency response measures. © 2023 by the authors.","Data fusion; Floods; Image classification; Optical remote sensing; Radar imaging; Automatic threshold selection; Burned areas; Flooded areas; Image differencing; Multi-spectral data; Non-supervised classification; Optical-; Performance; Plug-ins; QGIS plugin; Synthetic aperture radar","automatic threshold selection; data fusion; fire; floods; image differencing; non-supervised classification; QGIS plugin","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85147904570"
"Mohite J.D.; Sawant S.A.; Rana S.; Pappula S.","Mohite, J.D. (56515235000); Sawant, S.A. (56421604400); Rana, S. (35173731600); Pappula, S. (6505567619)","56515235000; 56421604400; 35173731600; 6505567619","Wheat area mapping and phenology detection using synthetic aperture radar and multi-spectral remote sensing observations","2019","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","3/W6","","123","127","4","10.5194/isprs-archives-XLII-3-W6-123-2019","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071109909&doi=10.5194%2fisprs-archives-XLII-3-W6-123-2019&partnerID=40&md5=62c67ba8f8737eab8bbbef51a0370bd7","In season crop area mapping is of significant importance for multiple reasons such as monitoring if crop health and residue burning areas, etc. Wheat is one of the important cereal crop cultivated all across the India, with Punjab-Haryana being the prime contributors to the total production. In this study we propose a method for early season Wheat area mapping using the combined use of temporal Sentinel-1 and 2 observations. Further, we propose a method to estimate the crop phenology parameter viz. sowing date using the early time series of Normalized Difference Vegetation Index (NDVI). Few districts from Haryana and Punjab have been selected. The Wheat sowing starts in month of Oct.-Nov. Considering the sowing window, images available during Oct.-Dec. 2017 have been chosen for early season Wheat area mapping. The field data for Wheat, other crops, forest, water and settlements classes is gathered using human participatory sensing and Google Earth Engine (GEE) platform and used for data analysis. We have assessed the performance of random forest classifier using 1. NDVI derived from Sentinel-2, 2. VV and VH backscatter obtained from Sentinel-1 and 3. Both NDVI and VV-VH backscatter. Results show the maximum classification accuracy of 88.31 % when using combination of NDVI, VV and VH. However, accuracy drops to 87.19 % and 79.16 % while using NDVI and VV-VH respectively. Further, to estimate the sowing date we have considered the NDVI time-series during Oct.-Dec. for Wheat pixels. A method based on NDVI compositing is used with gradual increase of 0.1-0.15 at every 12 days for subsequent two images. We have found a good agreement between the estimated sowing dates and actual sowing dates. © Authors 2019. CC BY 4.0 License.","Backscattering; Biology; Classification (of information); Crops; Decision trees; Engines; Radar imaging; Remote sensing; Synthetic aperture radar; Time series; Tracking radar; Area mapping; Google earths; Random forests; Sentinel-1; Sentinel-2; Photomapping","Classification; Google Earth Engine; Random Forest; Sentinel-1; Sentinel-2; Wheat area mapping","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85071109909"
"Ziemann A.; Theiler J.","Ziemann, Amanda (36134071500); Theiler, James (7004449154)","36134071500; 7004449154","Change detection across satellite images collected by different sensors","2021","Optics InfoBase Conference Papers","","","","","","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119520079&partnerID=40&md5=85c4c34a956de977f7027e7afea1410c","A joint-distribution based machine learning framework is used to identify anomalous changes in image pairs captured by different sensor designs and even different imaging modalities (e.g., multispectral to synthetic aperture radar). © 2021 The Author (s).","Change detection; Image pairs; Imaging modality; Joint distributions; Multi-spectral; Satellite images; Sensor designs; Synthetic aperture radar","","Conference paper","Final","","Scopus","2-s2.0-85119520079"
"Reinisch E.C.; Ziemann A.; Flynn E.B.; Theiler J.","Reinisch, Elena C. (57190175245); Ziemann, Amanda (36134071500); Flynn, Eric B. (24278782800); Theiler, James (7004449154)","57190175245; 36134071500; 24278782800; 7004449154","Combining multispectral imagery and synthetic aperture radar for detecting deforestation","2020","Proceedings of SPIE - The International Society for Optical Engineering","11392","","1139209","","","","10.1117/12.2558201","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088165607&doi=10.1117%2f12.2558201&partnerID=40&md5=9ff85099971ab6ad8ec7dd6dfb8a0018","Forest destruction is a main contributor to carbon emissions and loss of biodiversity, making it a matter of global importance. Due to the large global footprint and often inaccessibility of forested areas, remote sensing is one of the most valuable techniques for monitoring deforestation. Spectral imaging is typically favored for material classification of forested areas and identification of broad swaths of deforestation. However, spectral data can fall short in detecting more subtle destruction beneath the forest canopy. Radar remote sensing can help fill this gap, as it has the ability to penetrate through tree canopies such that pixels capture backscatter information from both the canopy and material beneath it. Synthetic aperture radar in particular can capture this information at fine spatial resolution, and techniques such as polarimetry and interferometry can be used to measure biomass and detect deforestation. In this study, we compare synthetic aperture radar data with multispectral data to improve characterization and identification of source signatures captured within a pixel, with specific consideration to detecting areas where thinning is happening beneath the forest canopy. We focus on identifying different types of forest thinning in the Valles Caldera, located in the Jemez Mountains of northern New Mexico. We apply anomalous change detection to a combination of data products derived from multispectral imagery and synthetic aperture radar to determine which combinations are most effective at identifying anomalous features of interest in thinning regions. We find that comparing phase change measured by synthetic aperture radar interferometry to differenced vegetation indices highlights anomalous relationships in the thinning region. When comparing multispectral reflectance to backscatter intensity measured by synthetic aperture radar, the most successful temporal comparisons contained synthetic aperture radar data during the thinning period. This suggests that synthetic aperture radar enhances detection of thinning practices via remote sensing, especially in regards to changes taking place beneath the tree canopy. These results were improved even further by segmenting the images according to vegetation coverage prior to applying anomalous change detection techniques. © 2020 SPIE.","Backscattering; Biodiversity; Deforestation; Image enhancement; Interferometry; Pixels; Radar measurement; Remote sensing; Spectroscopy; Synthetic aperture radar; Tracking radar; Vegetation; Backscatter information; Backscatter intensity; Identification of sources; Material classification; Multi-spectral imagery; Radar remote sensing; Synthetic aperture radar interferometry; Vegetation coverage; Radar imaging","Anomalous change detection; Deforestation; Multispectral imagery; Synthetic aperture radar","Conference paper","Final","","Scopus","2-s2.0-85088165607"
"Hong D.; Yokoya N.; Xia G.-S.; Chanussot J.; Zhu X.X.","Hong, Danfeng (56108179600); Yokoya, Naoto (36440631200); Xia, Gui-Song (12781686200); Chanussot, Jocelyn (6602159365); Zhu, Xiao Xiang (55696622200)","56108179600; 36440631200; 12781686200; 6602159365; 55696622200","X-ModalNet: A semi-supervised deep cross-modal network for classification of remote sensing data","2020","ISPRS Journal of Photogrammetry and Remote Sensing","167","","","12","23","11","10.1016/j.isprsjprs.2020.06.014","110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087733258&doi=10.1016%2fj.isprsjprs.2020.06.014&partnerID=40&md5=39f27c7d8dbb2af527b079d74c5375fe","This paper addresses the problem of semi-supervised transfer learning with limited cross-modality data in remote sensing. A large amount of multi-modal earth observation images, such as multispectral imagery (MSI) or synthetic aperture radar (SAR) data, are openly available on a global scale, enabling parsing global urban scenes through remote sensing imagery. However, their ability in identifying materials (pixel-wise classification) remains limited, due to the noisy collection environment and poor discriminative information as well as limited number of well-annotated training images. To this end, we propose a novel cross-modal deep-learning framework, called X-ModalNet, with three well-designed modules: self-adversarial module, interactive learning module, and label propagation module, by learning to transfer more discriminative information from a small-scale hyperspectral image (HSI) into the classification task using a large-scale MSI or SAR data. Significantly, X-ModalNet generalizes well, owing to propagating labels on an updatable graph constructed by high-level features on the top of the network, yielding semi-supervised cross-modality learning. We evaluate X-ModalNet on two multi-modal remote sensing datasets (HSI-MSI and HSI-SAR) and achieve a significant improvement in comparison with several state-of-the-art methods. © 2020","Classification (of information); Deep learning; Semi-supervised learning; Spectroscopy; Synthetic aperture radar; Transfer learning; Classification tasks; Earth observation images; Interactive learning; Learning frameworks; Multi-spectral imagery; Remote sensing data; Remote sensing imagery; State-of-the-art methods; image classification; multispectral image; numerical method; pixel; satellite data; satellite imagery; synthetic aperture radar; Remote sensing","Adversarial; Cross-modality; Deep learning; Deep neural network; Fusion; Hyperspectral; Label propagation; Multispectral; Mutual learning; Remote sensing; Semi-supervised; Synthetic aperture radar","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85087733258"
"Liu X.; Samat A.; Li E.; Wang W.; Abuduwaili J.","Liu, Ximing (57897660500); Samat, Alim (57226635372); Li, Erzhu (55368587800); Wang, Wei (57783830000); Abuduwaili, Jilili (24376100700)","57897660500; 57226635372; 55368587800; 57783830000; 24376100700","Self-Trained Deep Forest with Limited Samples for Urban Impervious Surface Area Extraction in Arid Area Using Multispectral and PolSAR Imageries","2022","Sensors","22","18","6844","","","","10.3390/s22186844","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138391093&doi=10.3390%2fs22186844&partnerID=40&md5=0f8f9d4e9cb8bea2565586093155d6b8","Impervious surface area (ISA) has been recognized as a significant indicator for evaluating levels of urbanization and the quality of urban ecological environments. ISA extraction methods based on supervised classification usually rely on a large number of manually labeled samples, the production of which is a time-consuming and labor-intensive task. Furthermore, in arid areas, man-made objects are easily confused with bare land due to similar spectral responses. To tackle these issues, a self-trained deep-forest (STDF)-based ISA extraction method is proposed which exploits the complementary information contained in multispectral and polarimetric synthetic aperture radar (PolSAR) images using limited numbers of samples. In detail, this method consists of three major steps. First, multi-features, including spectral, spatial and polarimetric features, are extracted from Sentinel-2 multispectral and Chinese GaoFen-3 (GF-3) PolSAR images; secondly, a deep forest (DF) model is trained in a self-training manner using a limited number of samples for ISA extraction; finally, ISAs (in this case, in three major cities located in Central Asia) are extracted and comparatively evaluated. The experimental results from the study areas of Bishkek, Tashkent and Nursultan demonstrate the effectiveness of the proposed method, with an overall accuracy (OA) above 95% and a Kappa coefficient above 0.90. © 2022 by the authors.","Cities; Environmental Monitoring; Forests; Humans; Radar; Urbanization; Arid regions; Forestry; Image processing; Polarimeters; Synthetic aperture radar; Arid area; Deep forest; Extraction method; Gaofen-3; Impervious surface area; Multi-spectral; Polarimetric synthetic aperture radars; Self-training; Sentinel-2; Synthetic aperture radar images; city; environmental monitoring; forest; human; procedures; telecommunication; urbanization; Extraction","deep forest; GaoFen-3; impervious surface area; PolSAR; self-training; Sentinel-2","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85138391093"
"Rasid N.; Prashnani M.; Goswami J.; Raju P.L.N.","Rasid, N. (57210600046); Prashnani, M. (56031853100); Goswami, J. (35268563800); Raju, P.L.N. (56448256400)","57210600046; 56031853100; 35268563800; 56448256400","Crop damage assessment in flood inundated area of Morigaon district of Assam","2019","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","3/W6","","489","491","2","10.5194/isprs-archives-XLII-3-W6-489-2019","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071099024&doi=10.5194%2fisprs-archives-XLII-3-W6-489-2019&partnerID=40&md5=00e9df3c930975760be732b5a0bfe300","Cropping System Analysis is essential for studying the sustainability of Agriculture. Remote sensing technology provide continuous and synoptic observations of crop area over large extent and substantial contribution in monitoring, evaluating and forecasting of crop and its damage assessment both in cloud and cloud-free environment. Geo-stationary satellites like Synthetic Aperture Radar (SAR) can penetrate through clouds hence it help in assessment of crop even in hazy atmospheric circumstances like fog, smog, light rain, mist etc. The present study reviews cropping pattern and crop rotation of of Morigaon District of Assam. Landsat OLI- 8 multi-spectral data, sentinel 2 multi-spectral and sentinel- 1 SAR data was collected during crop year 2015, 2016 and 2017. The microwave SAR data was used for the classification of crop area for Kharif season due to unavailability of optical cloud free data and also helps in estimation of flood water propagation and its extent and its significant loss to agriculture crop. The result of the pilot study shows that integration of SAR data and GIS environment can be exploited in an efficient way to assess the crop damage area due to flood. Block-wise flood inundation statistics have been derived. This study can be extended to other states/ districts as data collected by satellite can be standardized, the data are reliably objective. © Authors 2019. CC BY 4.0 License.","Damage detection; Flood control; Floods; Remote sensing; Space-based radar; Sustainable development; Synthetic aperture radar; Crop intensity; Crop rotation; Cropping patterns; Cropping systems; NDVI threshold; Crops","Crop Intensity; Crop Rotation; Cropping Pattern; Cropping system; Cropping system indices; NDVI threshold","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85071099024"
"Ghorbanian A.; Ahmadi S.A.; Amani M.; Mohammadzadeh A.; Jamali S.","Ghorbanian, Arsalan (57204481038); Ahmadi, Seyed Ali (57194457319); Amani, Meisam (56684747900); Mohammadzadeh, Ali (16070064500); Jamali, Sadegh (55783340000)","57204481038; 57194457319; 56684747900; 16070064500; 55783340000","Application of Artificial Neural Networks for Mangrove Mapping Using Multi-Temporal and Multi-Source Remote Sensing Imagery","2022","Water (Switzerland)","14","2","244","","","","10.3390/w14020244","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123204215&doi=10.3390%2fw14020244&partnerID=40&md5=772712c7d6cee0eb7e59707eb43fd0ff","Mangroves, as unique coastal wetlands with numerous benefits, are endangered mainly due to the coupled effects of anthropogenic activities and climate change. Therefore, acquiring reliable and up-to-date information about these ecosystems is vital for their conservation and sustainable blue carbon development. In this regard, the joint use of remote sensing data and machine learning algorithms can assist in producing accurate mangrove ecosystem maps. This study investigated the potential of artificial neural networks (ANNs) with different topologies and specifications for mangrove classification in Iran. To this end, multi-temporal synthetic aperture radar (SAR) and multi-spectral remote sensing data from Sentinel-1 and Sentinel-2 were processed in the Google Earth Engine (GEE) cloud computing platform. Afterward, the ANN topologies and specifications considering the number of layers and neurons, learning algorithm, type of activation function, and learning rate were examined for mangrove ecosystem mapping. The results indicated that an ANN model with four hidden layers, 36 neurons in each layer, adaptive moment estimation (Adam) learning algorithm, rectified linear unit (Relu) activation function, and the learning rate of 0.001 produced the most accurate mangrove ecosystem map (F-score = 0.97). Further analysis revealed that although ANN models were subjected to accuracy decline when a limited number of training samples were used, they still resulted in satisfactory results. Additionally, it was observed that ANN models had a high resistance when training samples included wrong labels, and only the ANN model with the Adam learning algorithm produced an accurate mangrove ecosystem map when no data standardization was performed. Moreover, further investigations showed the higher potential of multi-temporal and multi-source remote sensing data compared to single-source and mono-temporal (e.g., single season) for accurate mangrove ecosystem mapping. Overall, the high potential of the proposed method, along with utilizing open-access satellite images and big-geo data processing platforms (i.e., GEE, Google Colab, and scikit-learn), made the proposed approach efficient and applicable over other study areas for all interested users. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Iran; Chemical activation; Climate change; Data handling; Ecosystems; Engines; Mapping; Neural networks; Remote sensing; Sampling; Specifications; Synthetic aperture radar; Topology; Artificial neural network; Google earth engine; Google earths; Mangrove; Mangrove ecosystems; Multi-Sources; Multi-temporal; Remote-sensing; Sentinel-1; Sentinel-2; algorithm; artificial neural network; data processing; mapping method; remote sensing; satellite imagery; synthetic aperture radar; Learning algorithms","Artificial neural networks (ANNs); Google Earth Engine (GEE); Mangrove; Multi-source; Multi-temporal; Remote sensing; Sentinel-1; Sentinel-2","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85123204215"
"Zhao Y.; Jiang M.","Zhao, Yi (57209397198); Jiang, Mi (32367691100)","57209397198; 32367691100","Integration of SAR polarimetric parameters and multi-spectral data for object-based land cover classification; [极化SAR参数优化与光学波谱相结合的面向对象土地覆盖分类]","2019","Cehui Xuebao/Acta Geodaetica et Cartographica Sinica","48","5","","609","617","8","10.11947/j.AGCS.2019.20170746","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067623564&doi=10.11947%2fj.AGCS.2019.20170746&partnerID=40&md5=ca3f8e4f8d6ab8faf959e5e906dc3947","An object-based approach is proposed for land cover classification using optimal polarimetric parameters. The ability to identify targets is effectively enhanced by the integration of SAR and optical images. The innovation of presented method can be summarized in the following two main points: ① estimating polarimetric parameters (H-A-α decomposition) through optical image as a driver; ② a multi-resolution segmentation based on optical image only is deployed to refine classification results. The proposed method is verified by using Sentinel-1/2 datasets over Bakersfield area, California.The results are compared against those from pixel-based SVM classification using the ground truth from the National Land Cover Database (NLCD). A detailed accuracy assessment complied for seven classes of surfaces shows that the proposed method outperforms the conventional approach by around 10%, with an overall accuracy of 92.6% over regions with rich texture. © 2019, Surveying and Mapping Press. All right reserved.","Bakersfield; California; United States; Data fusion; Geometrical optics; Image enhancement; Image segmentation; Polarimeters; Radar imaging; Synthetic aperture radar; Textures; Accuracy assessment; Classification results; Conventional approach; Land cover classification; Multi-spectral; Object based; Polarimetric; Polarimetric parameters; accuracy assessment; data acquisition; detection method; image analysis; image classification; multispectral image; numerical method; pixel; satellite data; segmentation; synthetic aperture radar; Classification (of information)","Data fusion; Land-cover classification; Multispectral; Object-based; Polarimetric; Synthetic aperture radar(SAR)","Article","Final","","Scopus","2-s2.0-85067623564"
"Varade D.; Dikshit O.; Manickam S.","Varade, Divyesh (56448781000); Dikshit, Onkar (6602092727); Manickam, Surendar (56654960500)","56448781000; 6602092727; 56654960500","Dry/wet snow mapping based on the synergistic use of dual polarimetric SAR and multispectral data","2019","Journal of Mountain Science","16","6","","1435","1451","16","10.1007/s11629-019-5373-3","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067355647&doi=10.1007%2fs11629-019-5373-3&partnerID=40&md5=753c65b0c179255325fcadb3d9f77d39","We propose a multi-sensor multi-spectral and bi-temporal dual-polarimetric Synthetic Aperture Radar (SAR) data integration scheme for dry/wet snow mapping using Sentinel-2 and Sentinel-1 data which are freely available to the research community. The integration is carried out by incorporating the information retrieved from ratio images of the conventional method for wet snow mapping and the multispectral data in two different frameworks. Firstly, a simple differencing scheme is employed for dry/wet snow mapping, where the snow cover area is derived using the Normalized Differenced Snow Index (NDSI). In the second framework, the ratio images are stacked with the multispectral bands and this stack is used for supervised and unsupervised classification using support vector machines for dry/wet snow mapping. We also investigate the potential of a state of the art backscatter model for the identification of dry/wet snow using Sentinel-1 data. The results are validated using a reference map derived from RADARSAT-2 full polarimetric SAR data. A good agreement was observed between the results and the reference data with an overall accuracy greater than 0.78 for the different blending techniques examined. For all the proposed frameworks, the wet snow was better identified. The coefficient of determination between the snow wetness derived from the backscatter model and the reference based on RADARSAT-2 data was observed to be 0.58 with a significantly higher root mean square error of 1.03% by volume. © 2019, Science Press, Institute of Mountain Hazards and Environment, CAS and Springer-Verlag GmbH Germany, part of Springer Nature.","image classification; mapping; multispectral image; Sentinel; snow; synergism; synthetic aperture radar","Classification; Normalized Differenced Snow Index; Polarimetric synthetic-aperture radar; Ratio method; Snow mapping","Article","Final","","Scopus","2-s2.0-85067355647"
"Verma A.K.; Nandan R.; Verma A.","Verma, Arun Kumar (7401937964); Nandan, Ranbir (57202058847); Verma, Aditi (57203489538)","7401937964; 57202058847; 57203489538","Spaceborne synthetic aperture radar (SAR) sensors in low Earth orbit (LEO) for real-time detection and monitoring of floods","2019","Defence S and T Technical Bulletin","12","1","","39","50","11","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072771355&partnerID=40&md5=8f515f59cd439a5fc38836aaa6b8c6f4","Earth observation system (EOS) consists of optical or microwave sensors on spaceborne systems in the low Earth orbit (LEO) and provides crucial information for effective flood disaster management by supporting decision makers or emergency response organisations in their activities during the time critical crisis response phase of natural disasters. It is well known that the applications of satellite images of multi-spectral sensors in optical spectrum is not suitable for detection and monitoring of floods during rainy seasons with clouds in the sky due to non-penetrating capability of signals restricting its applications during clear sky condition. The other limitation of multi-spectral sensors in optical spectrum is its acquisition of satellite imageries during day time only. Synthetic aperture radar (SAR) is the preferred tool for flood detection and mapping from space due to continuous observation of earth surface from the polar orbit, where SAR sensors provides its own source of illumination and is characterised by near all-weather / day-night imaging capability independent of atmospheric conditions in the microwave spectrum. Open water surface areas during flooding period in rivers behave like flat water surface for radar bands in the microwave spectrum and act as specular reflector responsible for scattering of radar signals incident from spaceborne SAR sensors resulting into dark pixels in the radar image in contrast to non-flooding areas of the Earth surface. Change detection techniques using multi-temporal SAR images based on the behaviour of backscattered signals for threshold value for detecting the flood between nonflooding and flooding periods provide information related to the status of water surface of river systems. Recently, radar sensors have received interest in the development of spaceborne bi-static and multi-static SAR sensors due its potential to reduce the revisit (repeat orbit) time for monitoring the changes on the Earth surface depending upon the repeat orbit and SAR payloads on the satellites. Spaceborne SAR payloads can be placed in the orbit into fully active or semi-active configuration based on both transmit and receive capability of signals. In this paper, the concept of the bi-static and multi- static space-borne SAR sensors is described for the development of real time space-borne SAR surveillance system for monitoring of various characteristics of river basins and detection of floods using threshold / change detection techniques. Furthermore, the concept for the development of constellation of multi-static SAR satellite imaging receivers in LEO and geostationary radar illuminating system is described for real time detection and monitoring of floods. © 2019, Science and Technology Research Institute for Defence.","","Bi-static and multi-static SAR sensors; Detection and monitoring of floods; Radar backscattering coefficient; Rain drop size distribution (RDSD); Spaceborne synthetic aperture radar (SAR)","Article","Final","","Scopus","2-s2.0-85072771355"
"Jimenez-Sierra D.A.; Benítez-Restrepo H.D.; Arce G.R.; Florez-Ospina J.F.","Jimenez-Sierra, David Alejandro (57218846750); Benítez-Restrepo, Hernán Darío (22949882900); Arce, Gonzalo R. (7006653894); Florez-Ospina, Juan F. (56031557500)","57218846750; 22949882900; 7006653894; 56031557500","BLUE NOISE SAMPLING AND NYSTRÖM EXTENSION FOR GRAPH BASED CHANGE DETECTION","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","2895","2898","3","10.1109/IGARSS47720.2021.9555107","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129884845&doi=10.1109%2fIGARSS47720.2021.9555107&partnerID=40&md5=ce61826b0ae09cff965d70efcdb2ab65","In this paper, we address the problem of sampling on graphs for change detection in large multi-spectral (MS) and synthetic aperture radar (SAR) images by proposing a graphbased data-driven framework. The main steps of the proposed approach are: (i) the segmentation of regions that enclose the change; (ii) the use of smoothness prior for learning a graph of the regions; (iii) the integration of blue-noise sampling (BN) in the change detection scheme. We validate our approach in 14 real cases of remote sensing according to quantitative analyses. The results confirm that using a structured sampling such as BN outperforms recent state-of-the-art methods in change detection for multimodal data.  © 2021 IEEE.","Data fusion; Radar imaging; Remote sensing; Synthetic aperture radar; Blue noise; Change detection; Data driven; Detection scheme; Graph-based; Multi-spectral; Nystrom extension; Remote sensing images; Smoothness; Synthetic aperture radar images; Graphic methods","Blue-noise; change detection; data fusion; graph; remote sensing images; sampling; smoothness","Conference paper","Final","","Scopus","2-s2.0-85129884845"
"Zhang M.; Chen F.; Tian B.; Liang D.; Yang A.","Zhang, Meimei (56746586200); Chen, Fang (57441279900); Tian, Bangsen (34882193500); Liang, Dong (57212943980); Yang, Aqiang (57212121230)","56746586200; 57441279900; 34882193500; 57212943980; 57212121230","High-frequency glacial lake mapping using time series of sentinel-1A/1B sar imagery: An assessment for the southeastern tibetan plateau","2020","International Journal of Environmental Research and Public Health","17","3","1072","","","","10.3390/ijerph17031072","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079244485&doi=10.3390%2fijerph17031072&partnerID=40&md5=33d3bbddb899708121969be98ed347eb","Glacial lakes are an important component of the cryosphere in the Tibetan Plateau. In response to climate warming, they threaten the downstream lives, ecological environment, and public infrastructures through outburst floods within a short time. Although most of the efforts have been made toward extracting glacial lake outlines and detect their changes with remotely sensed images, the temporal frequency and spatial resolution of glacial lake datasets are generally not fine enough to reflect the detailed processes of glacial lake dynamics, especially for potentially dangerous glacial lakes with high-frequency variability. By using full time-series Sentinel-1A/1B imagery over a year, this study presents a new systematic method to extract the glacial lake outlines that have a fast variability in the southeastern Tibetan Plateau with a time interval of six days. Our approach was based on a level-set segmentation, combined with a median pixel composition of synthetic aperture radar (SAR) backscattering coefficients stacked as a regularization term, to robustly estimate the lake extent across the observed time range. The mapping results were validated against manually digitized lake outlines derived from Gaofen-2 panchromatic multi-spectral (GF-2 PMS) imagery, with an overall accuracy and kappa coefficient of 96.54% and 0.95, respectively. In comparison with results from classical supervised support vector machine (SVM) and unsupervised Iterative Self-Organizing Data Analysis Technique Algorithm (ISODATA) methods, the proposed method proved to be much more robust and effective at detecting glacial lakes with irregular boundaries that have similar backscattering as the surroundings. This study also demonstrated the feasibility of time-series Sentinel-1A/1B SAR data in the continuous monitoring of glacial lake outline dynamics. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Climate Change; Environmental Monitoring; Geographic Mapping; Ice Cover; Lakes; Radar; Remote Sensing Technology; Tibet; China; Qinghai-Xizang Plateau; glacial lake; model validation; numerical model; satellite data; satellite imagery; Sentinel; support vector machine; synthetic aperture radar; time series analysis; article; data analysis; feasibility study; human; human experiment; imagery; kappa statistics; lake; support vector machine; telecommunication; time series analysis; climate change; environmental monitoring; geographic mapping; ice cover; lake; procedures; remote sensing; telecommunication; Tibet","Glacial lake mapping; Median composite; Sentinel-1; Tibetan Plateau; Time series","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85079244485"
"Jain P.; Schoen-Phelan B.; Ross R.","Jain, Pallavi (57199743268); Schoen-Phelan, Bianca (57213267321); Ross, Robert (8843354800)","57199743268; 57213267321; 8843354800","Self-Supervised Learning for Invariant Representations From Multi-Spectral and SAR Images","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","7797","7808","11","10.1109/JSTARS.2022.3204888","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137928319&doi=10.1109%2fJSTARS.2022.3204888&partnerID=40&md5=0afaa43c71bf17927030aec7dc0525b9","Self-supervised learning (SSL) has become the new state of the art in several domain classification and segmentation tasks. One popular category of SSL are distillation networks, such as Bootstrap Your Own Latent (BYOL). This work proposes RS-BYOL, which builds on BYOL in the remote sensing (RS) domain where data are nontrivially different from natural RGB images. Since multispectral (MS) and synthetic aperture radar (SAR) sensors provide varied spectral and spatial resolution information, we utilize them as an implicit augmentation to learn invariant feature embeddings. In order to learn RS-based invariant features with SSL, we trained RS-BYOL in two ways, i.e., single channel feature learning and three channel feature learning. This work explores the usefulness of single channel feature learning from random 10 MS bands of 10-20 m resolution and VV-VH of SAR bands compared to the common notion of using three or more bands. In our linear probing evaluation, these single channel features reached a 0.92 F1 score on the EuroSAT classification task and 59.6 mIoU on the IEEE Data Fusion Contest segmentation task for certain single bands. We also compare our results with ImageNet weights and show that the RS-based SSL model outperforms the supervised ImageNet-based model. We further explore the usefulness of multimodal data compared to single modality data, and it is shown that utilizing MS and SAR data allows better invariant representations to be learnt than utilizing only MS data.  © 2008-2012 IEEE.","Data fusion; Distillation; Image segmentation; Modal analysis; Optical remote sensing; Radar imaging; Supervised learning; Learn+; Multi-spectral; Optical imaging; Optical synthetic aperture radar; Optical-synthetic aperture radar fusion; Remote-sensing; Representation learning; Satellite images; Self-supervised learning; Task analysis; classification; image processing; multispectral image; remote sensing; segmentation; supervised learning; synthetic aperture radar; Synthetic aperture radar","Optical-synthetic aperture radar (SAR) fusion; satellite images; self-supervised learning (SSL); unsupervised learning","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85137928319"
"DeMets S.A.; Ziemann A.; Manore C.; Russell C.","DeMets, Sydney A. (57216946482); Ziemann, Amanda (36134071500); Manore, Carrie (37102427300); Russell, Curtis (8927397600)","57216946482; 36134071500; 37102427300; 8927397600","Improving mosquito population models over the greater toronto area using MSI and SAR data","2021","Proceedings of SPIE - The International Society for Optical Engineering","11727","","117271I","","","","10.1117/12.2587714","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108716050&doi=10.1117%2f12.2587714&partnerID=40&md5=d4a2a8667008b4788cbff0ef9daae6da","As West Nile Virus (WNV) and St. Louis Encephalitis (SLE) become more prevalent across North America, there is an increased risk of fatal neuroinvasive cases. In order for public health officials to prepare for these cases and potentially intervene, the ability to forecast mosquito borne disease outbreaks is paramount. In practice, however, such vector borne diseases are notoriously difficult to predict due to their seemingly sporadic spatial and temporal outbreak patterns. Recent research has demonstrated that mosquito abundance is causally related to WNV/SLE prevalence, providing a practical starting point for developing mosquito-borne disease forecasting systems. When focusing on building mosquito population models, understanding the reproduction environment of Culex mosquitos (WNV and SLE’s primary vectors) is key: they rely on warmth, water, and vegetation to reproduce. Previous work has shown that global-coverage multispectral imagery (MSI) (i.e., Landsat 8, Sentinel-2) is a valuable resource for characterizing vegetation health as a predictor of mosquito population, but it is limited in that it may not provide the spatial resolution necessary to distinguish between, e.g., a well-fertilized lawn (poor Culex habitat) and a stand of trees (good Culex habitat). The backscatter information collected by synthetic aperture radar (SAR) imagery provides opportunity to distinguish between broader categories of vegetation type, potentially helping to fill this gap. This research uses publicly available global-coverage MSI and SAR imagery (Landsat 8, Sentinel-2, and Sentinel-1) to explore if vegetation type, in tandem with vegetation health, improves our ability to forecast mosquito populations. Vegetation characterization is done over the Greater Toronto Area from 2014 to 2017, and we derive weekly time series from MSI, spectral indices, and SAR for this time period. We then quantify the strength of vegetation health and type as a predictor of Culex abundance. © 2021 SPIE.","Cell proliferation; Ecosystems; Forecasting; Health; Hyperspectral imaging; Image enhancement; Population statistics; Space-based radar; Spectroscopy; Synthetic aperture radar; Vegetation; Viruses; Backscatter information; Greater Toronto Area; Mosquito populations; Mosquito-borne disease; Multi-spectral imagery; Spatial resolution; Synthetic Aperture Radar Imagery; Vector-borne disease; Radar imaging","Multispectral imagery; NDVI; Random forest; Synthetic aperture radar","Conference paper","Final","","Scopus","2-s2.0-85108716050"
"Upreti M.; Kumar D.","Upreti, Manjari (57226442590); Kumar, Deepak (57203026436)","57226442590; 57203026436","Investigating capability of open archive multispectral and SAR datasets for Wheat crop monitoring and acreage estimation studies","2021","Earth Science Informatics","14","4","","2017","2035","18","10.1007/s12145-021-00656-9","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111610797&doi=10.1007%2fs12145-021-00656-9&partnerID=40&md5=d3278a9993e2e277731fcc47a92d2cbf","There is a necessity for new methods and technology for several agricultural applications and decision support systems. Technological development at the global, national, and regional level has shown a path for the application of spaceborne remote sensing for agriculture purposes. Remote sensing technology eases to detect areas within the plots for a reliable data supply to analyze the data. Spaceborne synthetic aperture radar (SAR) data are capable to provide a reliable data supply throughout the year. The global repetition rate is up to 12 days. The datasets acquired from the Sentinel-1 platform facilitates a ground resolution of 20 × 20 m and these sufficient for the synchronization of spaceborne multispectral and radar datasets for enhanced agricultural cropland monitoring applications and decision support systems. Sentinel-1 data is a C-band radar data sets in dual-polarizations. The signal intensity changes over according to humidity in the soil or vegetation cover and the surface structure. The variations in signal information being recovered at the sensor end help in the informed decision making. Besides, SAR datasets are capable to provide information on the phenological stage of agricultural cropland along with crop-type differentiation for specific use cases. The synchronous utilization of spaceborne multispectral and radar datasets for enhanced agricultural cropland monitoring applications and decision support systems can be transformed into informative map products for several processes. The same technology can be beneficial for monitoring crop conditions during any disaster and early warning systems for proper management of available resources. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","biomonitoring; data set; decision support system; estimation method; remote sensing; Sentinel; spectral analysis; synthetic aperture radar; vegetation cover; wheat","Agriculture; Data fusion; Estimation; Monitoring; Multi-spectral; SAR","Article","Final","","Scopus","2-s2.0-85111610797"
"Prabhakar K.R.; Nukala V.H.; Gubbi J.; Pal A.; Balamuralidhar P.","Prabhakar, K Ram (57189591594); Nukala, Veera Harikrishna (57323973300); Gubbi, Jayavardhana (23090806600); Pal, Arpan (57203638167); Balamuralidhar, P. (16201684400)","57189591594; 57323973300; 23090806600; 57203638167; 16201684400","Improving SAR and Optical Image Fusion for Lulc Classification with Domain Knowledge","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","711","714","3","10.1109/IGARSS46834.2022.9884283","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140404254&doi=10.1109%2fIGARSS46834.2022.9884283&partnerID=40&md5=4f0ab8ef3488ddc56ca96afd52478a3e","Fusing SAR and multi-spectral images to generate a precise land cover map in a weakly supervised setting is a challenging yet essential problem. The inaccurate, noisy, and inexact ground truth labels pose difficulty training any machine learning models. In this paper, we make a fundamental and pivotal contribution towards improving the ground truth label quality using domain knowledge. We present a simple yet effective mechanism to refine the low-resolution noisy ground truth labels. The proposed approach is trained and tested on a publicly available DFC2020 dataset. Through experiments, we show the effectiveness of our method by training a deep learning model on the refined labels that outperform even the models trained with clean ground truth. © 2022 IEEE.","Deep learning; Domain Knowledge; Geometrical optics; Image classification; Image enhancement; Image fusion; Learning systems; Radar imaging; Remote sensing; Spectroscopy; Domain knowledge; Essential problems; Ground truth; Land cover maps; Machine learning models; Multi-spectral; Multispectral images; Optical image; SAR Images; Simple++; Synthetic aperture radar","CNN; image fusion; multispectral; SAR","Conference paper","Final","","Scopus","2-s2.0-85140404254"
"Normandin C.; Paillou P.; Lopez S.; Marais E.; Scipal K.","Normandin, Cassandra (57195467498); Paillou, Philippe (7003915889); Lopez, Sylvia (8356713900); Marais, Eugene (7003708355); Scipal, Klaus (6505822925)","57195467498; 7003915889; 8356713900; 7003708355; 6505822925","Monitoring the Dynamics of Ephemeral Rivers from Space: An Example of the Kuiseb River in Namibia","2022","Water (Switzerland)","14","19","3142","","","","10.3390/w14193142","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139982367&doi=10.3390%2fw14193142&partnerID=40&md5=1548e64d58bbf8b8ca0ebf959a6ae06c","Ephemeral rivers are characterized by brief episodic flood events, which recharge subterraean alluvial aquifers that sustain humans, riparian vegetation, and wildlife in the hyper-arid Namib Desert. Yet we only have a poor understanding of the dynamics and feedback mechanisms in these hydrological systems as arid and semi-arid zones are typically poorly equipped with reliable in situ monitoring stations to provide necessary information. The main objective of our study is to show the potential of satellite data to monitor the dynamics of ephemeral rivers, such as the Kuiseb located in Namibia, since remotesensing offers the advantage of adapted spatial and temporal resolutions. For this study, multi-spectral imagery (Sentinel-2), Synthetic Aperture Radar (SAR, Sentinel-1), and SAR interferometry (Sentinel-1) data were used to produce Normalized Difference Vegetation Index (NDVI) maps, backscattering maps (as σ0), and interferograms, respectively. These parameters provide information on the hydrologic and vegetation dynamics of the river. Strong variations in NDVI, σ0, and interferograms are observed during March–April 2017 and June–July 2018 in a tributary of the Kuiseb in the central Namib Desert. In those years, rain events caused the reactivation of the tributary. However, during a major flood in 2021, when no rain occured, no variations in NDVI were detected in this tributary, unlike the σ0 and interferogram anomalies after the flood. Thus, these variations cannot be explained by rains, which were non-existent during this period, but seem to be linked to the dynamics of the aquifer of the Kuiseb River, wherein floods recharge the alluvial aquifers and the rising water table levels produce a signal that is measurable by satellite radar sensors. All these results present a preliminary work that might be used by water resource managers to automate the processing and methods used to create an ephemeral river monitoring tool. © 2022 by the authors.","Kuiseb River; Namib Desert; Namibia; Namibia; Nigeria; Rivers; Aquifers; Arid regions; Backscattering; Dynamics; Floods; Hydrogeology; Radar imaging; Rain; Remote sensing; Rivers; Satellites; Space-based radar; Spectroscopy; Synthetic aperture radar; Vegetation; Alluvial aquifers; Ephemeral river; Fluvial aquifer hydrology; Fluvials; Groundwater monitoring; Interferograms; Multispectral imagery; Namibia; Normalized difference vegetation index; Radar backscattering; NDVI; Interferometry","fluvial aquifer hydrology; groundwater monitoring; interferometry; multispectral imagery; radar backscattering","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85139982367"
"Meena S.R.; Bhuyan K.; Chauhan A.; Singh R.P.","Meena, Sansar Raj (57205598140); Bhuyan, Kushanav (57225033871); Chauhan, Akshansha (57200583116); Singh, Ramesh P. (57202327051)","57205598140; 57225033871; 57200583116; 57202327051","Changes in the flood plains and water quality along the Himalayan rivers after the Chamoli disaster of 7 February 2021","2021","International Journal of Remote Sensing","42","18","","6984","7001","17","10.1080/01431161.2021.1944696","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113230665&doi=10.1080%2f01431161.2021.1944696&partnerID=40&md5=c85a404bad525996c1da79c9ae6c9145","The Himalayan regions are vulnerable to all kinds of natural hazards. On 7 February 2021, a deadly disaster occurred near the Tapovan, in Uttarakhand, Himalayas. During the event, large volume of debris along with broken glacial fragments flooded the Rishi Ganga River and washed away the nearby hydropower plants (Rishi Ganga and Tapovan), which was revealed from detailed analysis of multi spectral and bi-temporal satellite data. We present the impact of the Chamoli disaster on the flood plains and water quality of Himalayan rivers, Rishi Ganga near Tapovan, Alaknanda near Srinagar and Ganga near Haridwar and Bijnor. We used four locations along four sections of Himalayan rivers and have analysed various indices, modified normalized difference water index, normalized difference chlorophyll index, and normalized difference turbidity index, to study the changes in water quality and flood plains. On comparison of the spectral and backscattering coefficients derived from Sentinel-2 optical and Sentinel-1 synthetic aperture radar data, changes in the water quality and flood plains of the rivers were found. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Himalayas; India; Uttarakhand; Backscattering; Disasters; Hydroelectric power plants; Rivers; Synthetic aperture radar; Water quality; Backscattering coefficients; Chlorophyll Index; Himalayan rivers; Hydropower plants; Natural hazard; Normalized difference water index; Normalized differences; Satellite data; comparative study; flooding; floodplain; remote sensing; satellite data; Sentinel; synthetic aperture radar; water quality; Floods","","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85113230665"
"Lin Y.N.; Park E.; Wang Y.; Quek Y.P.; Lim J.; Alcantara E.; Loc H.H.","Lin, Yunung Nina (36470589700); Park, Edward (56088790300); Wang, Yu (37029136700); Quek, Yu Pin (57224958418); Lim, Jana (57218370399); Alcantara, Enner (23491677700); Loc, Ho Huu (57189027363)","36470589700; 56088790300; 37029136700; 57224958418; 57218370399; 23491677700; 57189027363","The 2020 Hpakant Jade Mine Disaster, Myanmar: A multi-sensor investigation for slope failure","2021","ISPRS Journal of Photogrammetry and Remote Sensing","177","","","291","305","14","10.1016/j.isprsjprs.2021.05.015","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108718103&doi=10.1016%2fj.isprsjprs.2021.05.015&partnerID=40&md5=cff57bfd0fc7d4d16fd473db8b032702","A quarry failure along the slopes of the Wai Khar open-pit jade mine in Hpakant, Myanmar has led to the deaths of at least 172 jade miners on 2 July 2020. This paper conducts a systematic investigation of the incident by integrating data from multiple sensors, including high-resolution optical imagery, Sentinel-1 synthetic aperture radar (SAR) images, unmanned aerial system (UAS) footage, SRTM and ALOS digital elevation models (DEMs), soil moisture product from multi-spectral Landsat-8 satellite and precipitation records from the Climate Hazards Group InfraRed Precipitation with Station data (CHIRPS). Optical imagery, UAS footage and DEMs allow us to build a comprehensive mapping of tailing areas and quarry scarps from 2010 and reconstruct the 2D pit geometry prior to failure. Deformation signals from multi-temporal SAR interferometry (MTInSAR), soil moisture variations and precipitation trends further allow us to identify possible failure causes. To evaluate the quality of deformation obtained from different distributed-scatterer phase estimators, we develop an empirical mapping function based on areal fraction values to facilitate the comparison of temporal coherence values that are differently formulated in each phase estimator. The comparison shows that phase linking algorithm outperforms the small baseline subset method in terms of signal recovery and phase reliability. Our investigation points out that the mining site is under aggressive mining cycles that are exacerbated by frequent, uncontrolled landslides. Seepage failure, which involves the expulsion of water from rapidly compacting tailings, may be a critical factor in the 2020 incident. Instead of extreme weather, the failure had occurred under normal to drier conditions. This means that the sliding planes were already in a critical state, which is evident from the accelerated deformation around the collapse area since the beginning of 2020. Based on these findings, we provide recommendations to improve mining site regulations and management practices for safer open-pit mining in Myanmar and probably in similar contexts outside Myanmar. © 2021 The Author(s)","Myanmar; Antennas; Climate models; Deformation; Earth (planet); Erosion; Failure (mechanical); Landslides; Mapping; Remote sensing; Signal reconstruction; Silicate minerals; Slope protection; Soil moisture; Time series; Unmanned aerial vehicles (UAV); Weathering; Digital elevation model; InSAR time-series; Jade mine in myanmar; Myanmars; Open-pit mine; Phase estimators; Phase linking; Seepage failure; Slope failure; Unmanned aerial systems; algorithm; ALOS; digital elevation model; disaster; landslide; mapping method; mortality; open pit mine; satellite imagery; sensor; Sentinel; Shuttle Radar Topography Mission; slope failure; synthetic aperture radar; unmanned vehicle; Seepage","InSAR time-series; Jade mine in Myanmar; Open-pit mine; Phase linking; Seepage failure; Slope failure","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85108718103"
"Sim S.; Kim W.; Lee J.; Kang Y.; Im J.; Kwon C.; Kim S.","Sim, Seongmun (57111518400); Kim, Woohyeok (57223918651); Lee, Jaese (57216949164); Kang, Yoojin (57205735462); Im, Jungho (9036557400); Kwon, Chunguen (57211242867); Kim, Sungyong (53866721300)","57111518400; 57223918651; 57216949164; 57205735462; 9036557400; 57211242867; 53866721300","Wildfire severity mapping using sentinel satellite data based on machine learning approaches","2020","Korean Journal of Remote Sensing","36","5-3","","1109","1123","14","10.7780/kjrs.2020.36.5.3.9","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106511439&doi=10.7780%2fkjrs.2020.36.5.3.9&partnerID=40&md5=06ec9666c08e8cdeb280202986fb3caf","In South Korea with forest as a major land cover class (over 60% of the country), many wildfires occur every year. Wildfires weaken the shear strength of the soil, forming a layer of soil that is vulnerable to landslides. It is important to identify the severity of a wildfire as well as the burned area to sustainably manage the forest. Although satellite remote sensing has been widely used to map wildfire severity, it is often difficult to determine the severity using only the temporal change of satellite-derived indices such as Normalized Difference Vegetation Index (NDVI) and Normalized Burn Ratio (NBR). In this study, we proposed an approach for determining wildfire severity based on machine learning through the synergistic use of Sentinel-1A Synthetic Aperture Radar-C data and Sentinel-2A Multi Spectral Instrument data. Three wildfire cases-Samcheok in May 2017, Gangreung · Donghae in April 2019, and Gosung · Sokcho in April 2019-were used for developing wildfire severity mapping models with three machine learning algorithms (i.e., Random Forest, Logistic Regression, and Support Vector Machine). The results showed that the random forest model yielded the best performance, resulting in an overall accuracy of 82.3%. The cross-site validation to examine the spatiotemporal transferability of the machine learning models showed that the models were highly sensitive to temporal differences between the training and validation sites, especially in the early growing season. This implies that a more robust model with high spatiotemporal transferability can be developed when more wildfire cases with different seasons and areas are added in the future. © 2020 Korean Society of Remote Sensing. All right reserved.","","Machine learning; Sentinel-1; Sentinel-2; Wildfire; Wildfire-damaged area","Article","Final","","Scopus","2-s2.0-85106511439"
"Chen X.; Cui Y.; Wen C.; Zheng M.; Gao Y.; Li J.","Chen, Xi (57219219985); Cui, Yaokui (35344501200); Wen, Changjun (57222239512); Zheng, Mingxuan (57222248400); Gao, Yuan (57222242049); Li, Jing (55872205000)","57219219985; 35344501200; 57222239512; 57222248400; 57222242049; 55872205000","Flood Mapping with SAR and Multi-Spectral Remote Sensing Images Based on Weighted Evidential Fusion","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324158","2519","2522","3","10.1109/IGARSS39084.2020.9324158","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101986809&doi=10.1109%2fIGARSS39084.2020.9324158&partnerID=40&md5=c2296f5e5e35d045c949e4e54f762393","Synthetic Aperture Radar (SAR) and Multi-spectral (MS) remote sensing images are commonly used for flood mapping. SAR images can provide valid backscattering measurements of inundated areas through cloud cover, while MS data is able to monitor the spectral changes of ground surface, but usually affected by clouds. The complementary characteristics of the two data indicate the potential of their combining application for flood monitoring in emergency. This paper proposes a novel weighted evidential fusion method to take full advantages of the SAR and MS data for change detection during the flood. First, pre-processing and classification are performed with the SAR and MS data, independently. Second, a modified PCR6 rule for evidential fusion is proposed, which introduces the confusion matrixes to calculate the weight of evidences so that the conflicting degree in the fusion process can be reduced. Then, the flood inundating, standing and receding patterns are identified, which can be used to describe the flooding process in details. Practically, the proposed method is applied to flood mapping of the Typhoon Rumbia in 2018, in Shouguang City, China. The experiments show that the proposed fusion scheme efficiently use both of the SAR and MS data, and improve the flood mapping accuracy. © 2020 IEEE.","Floods; Geology; Photomapping; Radar imaging; Synthetic aperture radar; Backscattering measurement; Change detection; Complementary characteristics; Confusion matrix; Evidential fusions; Flood monitoring; Remote sensing images; Weight of evidences; Remote sensing","change detection; evidential fusion; flood monitoring; multi-spectral; remote sensing; SAR","Conference paper","Final","","Scopus","2-s2.0-85101986809"
"Zhao T.; Shi J.; Lv L.; Xu H.; Chen D.; Cui Q.; Jackson T.J.; Yan G.; Jia L.; Chen L.; Zhao K.; Zheng X.; Zhao L.; Zheng C.; Ji D.; Xiong C.; Wang T.; Li R.; Pan J.; Wen J.; Yu C.; Zheng Y.; Jiang L.; Chai L.; Lu H.; Yao P.; Ma J.; Lv H.; Wu J.; Zhao W.; Yang N.; Guo P.; Li Y.; Hu L.; Geng D.; Zhang Z.","Zhao, Tianjie (34882458900); Shi, Jiancheng (7404495164); Lv, Liqing (57214363759); Xu, Hongxin (57214365813); Chen, Deqing (55494027200); Cui, Qian (55416785500); Jackson, Thomas J. (57217436324); Yan, Guangjian (7202089880); Jia, Li (15834571900); Chen, Liangfu (8437626600); Zhao, Kai (55768842800); Zheng, Xingming (36197682900); Zhao, Limin (55493565400); Zheng, Chaolei (55937815500); Ji, Dabin (36815873200); Xiong, Chuan (8118973000); Wang, Tianxing (55576700800); Li, Rui (57738535700); Pan, Jinmei (55459081200); Wen, Jianguang (8284949000); Yu, Chao (24802843700); Zheng, Yaomin (54418336700); Jiang, Lingmei (7403476075); Chai, Linna (34881403600); Lu, Hui (55729812300); Yao, Panpan (54993245900); Ma, Jianwei (56199692000); Lv, Haishen (57214365117); Wu, Jianjun (56840894700); Zhao, Wei (57043789200); Yang, Na (57191271863); Guo, Peng (57212579032); Li, Yuxia (57004263900); Hu, Lu (57202960293); Geng, Deyuan (57208168007); Zhang, Ziqian (57208602831)","34882458900; 7404495164; 57214363759; 57214365813; 55494027200; 55416785500; 57217436324; 7202089880; 15834571900; 8437626600; 55768842800; 36197682900; 55493565400; 55937815500; 36815873200; 8118973000; 55576700800; 57738535700; 55459081200; 8284949000; 24802843700; 54418336700; 7403476075; 34881403600; 55729812300; 54993245900; 56199692000; 57214365117; 56840894700; 57043789200; 57191271863; 57212579032; 57004263900; 57202960293; 57208168007; 57208602831","Soil moisture experiment in the Luan River supporting new satellite mission opportunities","2020","Remote Sensing of Environment","240","","111680","","","","10.1016/j.rse.2020.111680","83","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078694659&doi=10.1016%2fj.rse.2020.111680&partnerID=40&md5=2249c2c13aa832a39537e99c6165c0a2","The Soil Moisture Experiment in the Luan River (SMELR) was conducted from 2017 to 2018 in the semi-arid Luan River watershed located in the North of China. One of the objectives of SMELR is to serve as an assessment tool and demonstration for a new Terrestrial Water Resources Satellite (TWRS) concept with one-dimensional synthetic aperture microwave techniques, for which soil moisture retrieval under variable satellite observing configurations (mainly in terms of incidence angels) is the greatest challenge. This proposed mission is targeted to provide continuity for the current satellite L-band microwave observations, and further improve the accuracy and spatial resolution of soil moisture mapping through the synergistic use of active, passive and optical remote sensing data. Multi-resolution, multi-angle and multi-spectral airborne data were obtained four times over a 70 km by 12 km area in the Shandian River basin, and one time over a 165 km by 5 km area that includes the Xiaoluan River basin. The near surface soil moisture (0 cm–5 cm) was measured extensively on the ground in fifty 1 km by 2 km quadrats (targeted to compare with the airborne radiometer), and two hundred and fifty 200 m by 200 m quadrats corresponding to radar observations. Two networks were established for continuous measurement of the soil moisture and temperature profile (3 cm, 5 cm, 10 cm, 20 cm, 50 cm) and precipitation in the Shandian and Xiaoluan River basin, respectively. Supporting ground measurements also included ground temperature, vegetation water content, surface roughness, continuous measurement of microwave emission and backscatter at a pasture site, reflectance of various land cover types, evapotranspiration and aerosol observations. Preliminary results within the experimental area indicate that (1) the near surface soil moisture spatial variability at a 200 m scale was up to ~0.1 cm3/cm3 at an intermediate value of ~0.35 cm3/cm3. (2) The difference of soil and vegetation temperature in grass and croplands reach its maximum of 11 K around solar noon time, and the soil temperature gradient is largest at around 15 P.M. (3) Both the airborne and ground measurements cover a wide range of conditions. The L-band active and passive observations exhibit a large variation of ~30 dB and ~80 K, respectively, corresponding to soil moisture range from 0.1 cm3/cm3 to 0.5 cm3/cm3. The sensitivity of both active and passive data to soil moisture is compared at corresponding spatial resolutions and show high information complementarity for better accuracy and resolution soil moisture retrieval. © 2020","China; Luan River; Remote sensing; Rivers; Satellites; Soil moisture; Surface roughness; Synthetic apertures; Temperature; Vegetation; Watersheds; Airborne experiments; Continuous measurements; L-band active and passive; Optical remote sensing data; Soil moisture retrievals; Soil temperature gradient; Vegetation temperature; Vegetation water content; accuracy assessment; airborne survey; backscatter; experimental study; ground-based measurement; radiometer; satellite altimetry; satellite data; satellite mission; soil moisture; soil temperature; spatial resolution; synthetic aperture radar; water resource; watershed; Soil surveys","Airborne experiment; L-band active and passive; Luan River; Soil moisture; Terrestrial Water Resources Satellite","Article","Final","","Scopus","2-s2.0-85078694659"
"Liu K.; Li Y.","Liu, Kaixuan (57210150004); Li, Yufeng (56006987500)","57210150004; 56006987500","SAR and multispectral image fusion algorithm based on sparse representation and NSST","2019","AIP Conference Proceedings","2122","","020059","","","","10.1063/1.5116498","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069658842&doi=10.1063%2f1.5116498&partnerID=40&md5=b9aca26ac747684a3c7c1817019b315d","Aiming at the problem of spectral distortion and texture detail loss in synthetic aperture radar (SAR) image and multi-spectral (MS) image fusion, an image fusion algorithm combining sparse representation (SR) and non-subsampled Shearlet transform (NSST) is proposed. The algorithm uses the multi-scale, multi-directional and translation-invariant characteristics of NSST to transform and decompose the luminance components of SAR images and multi-spectral images. Then, the low-frequency sub-band is represented by SR, and the fusion is performed by an energy-adaptive method. The high-frequency sub-band is fused with the correlation coefficient as the saliency index, and finally the fused image is obtained by inverse transformation. The simulation experiments show that the proposed algorithm effectively preserves the subject information and feature information of the source image, so that the contrast of the fused image is significantly improved, the image outline is clear, and the overall sharpness. The spectral resolution and spatial resolution are closer to the fused reference image. © 2019 Author(s).","","","Conference paper","Final","","Scopus","2-s2.0-85069658842"
"Dumitru C.O.; Schwarz G.; Pulak-Siwiec A.; Kulawik B.; Lorenzo J.; Datcu M.","Dumitru, Corneliu Octavian (16047147700); Schwarz, Gottfried (7201633911); Pulak-Siwiec, Anna (57213198559); Kulawik, Bartosz (57213185858); Lorenzo, Jose (57213189517); Datcu, Mihai (7004523124)","16047147700; 7201633911; 57213198559; 57213185858; 57213189517; 7004523124","Earth Observation Data Mining: A Use Case for Forest Monitoring","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8899135","5359","5362","3","10.1109/IGARSS.2019.8899135","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077701812&doi=10.1109%2fIGARSS.2019.8899135&partnerID=40&md5=a8ce431d4910bbf17aaab54b3877f1a5","The increased number of free and open satellite images has led to new applications of these data. Among them is the systematic classification of land cover/use types based on patterns of settlements or agriculture recorded by satellite imagers, in particular, the identification and quantification of temporal changes. In this paper, we will present guidelines and practical examples of how to obtain reliable image patch classification results based on data mining techniques for detecting possible changes that can appear within a data set. Here, we will focus on a scenario, namely forest monitoring using Earth observation Synthetic Aperture Radar data acquired by Sentinel-1, and multispectral data acquired by Sentinel-2. © 2019 IEEE.","Agricultural robots; Classification (of information); Forestry; Geology; Observatories; Remote sensing; Space-based radar; Synthetic aperture radar; Classification results; Copernicus data; Earth observation data; Earth observations; Forest monitoring; Multi-spectral data; New applications; Satellite images; Data mining","Copernicus data; Data mining; Earth observation; forest monitoring","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85077701812"
"Fagir J.; Frioud M.; Henke D.","Fagir, Julian (57194593493); Frioud, Max (6602510079); Henke, Daniel (36011653700)","57194593493; 6602510079; 36011653700","Change detection between high-resolution airborne sar and multispectral data with dempster-shafer theory","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-January","","8900637","1526","1529","3","10.1109/IGARSS.2019.8900637","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113858783&doi=10.1109%2fIGARSS.2019.8900637&partnerID=40&md5=3a0a3f82fe6f1c0909a130fdbef3c4d7","Change detection from multi-sensoral SAR-MS datasets is useful for improving the performance by adding data from another modality or for increasing the number of available times. Few methods with two modalities have been investigated though, and often only for lowresolution data. Here, we approach change detection of decimeterresolution data from an airborne platform. Geometric differences are mitigated by generating a point cloud from optical images, focusing the SAR on it and projecting this into camera view. A joint segmentation of the two datasets is followed by a change detection based on Iterated Conditional Modes (ICM) and Dempster-Shafer theory (DS) to mark changes. An experiment with moving cars is conducted to confirm the method's applicability. © 2019 IEEE.","Geometrical optics; Probabilistic logics; Remote sensing; Synthetic aperture radar; Airborne platforms; Change detection; Dempster-Shafer theory; Geometric difference; High resolution; Iterated conditional modes; Joint segmentation; Multi-spectral data; Aircraft detection","Heterogeneous change detection; Multi-sensor; Oblique; SAR","Conference paper","Final","","Scopus","2-s2.0-85113858783"
"Yuan Y.; Meng X.; Sun W.; Yang G.; Wang L.; Peng J.; Wang Y.","Yuan, Yi (57874623700); Meng, Xiangchao (56158755000); Sun, Weiwei (55726567900); Yang, Gang (57192178476); Wang, Lihua (57221651796); Peng, Jiangtao (24833160700); Wang, Yumiao (57874832700)","57874623700; 56158755000; 55726567900; 57192178476; 57221651796; 24833160700; 57874832700","Multi-Resolution Collaborative Fusion of SAR, Multispectral and Hyperspectral Images for Coastal Wetlands Mapping","2022","Remote Sensing","14","14","3492","","","","10.3390/rs14143492","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137272381&doi=10.3390%2frs14143492&partnerID=40&md5=af4929a341e9f100543bba2531bcd73e","The hyperspectral, multispectral, and synthetic aperture radar (SAR) remote sensing images provide complementary advantages in high spectral resolution, high spatial resolution, and geometric and polarimetric properties, generally. How to effectively integrate cross-modal information to obtain a high spatial resolution hyperspectral image with the characteristics of the SAR is promising. However, due to divergent imaging mechanisms of modalities, existing SAR and optical image fusion techniques generally remain limited due to the spectral or spatial distortions, especially for complex surface features such as coastal wetlands. This paper provides, for the first time, an efficient multi-resolution collaborative fusion method for multispectral, hyperspectral, and SAR images. We improve generic multi-resolution analysis with spectral-spatial weighted modulation and spectral compensation to achieve minimal spectral loss. The backscattering gradients of SAR are guided to fuse, which is calculated from saliency gradients with edge preserving. The experiments were performed on ZiYuan-1 02D (ZY-1 02D) and GaoFen-5B (AHSI) hyperspectral, Sentinel-2 and GaoFen-5B (VIMI) multispectral, and Sentinel-1 SAR images in the challenging coastal wetlands. Specifically, the fusion results were comprehensively tested and verified on the qualitative, quantitative, and classification metrics. The experimental results show the competitive performance of the proposed method. © 2022 by the authors.","Geometrical optics; Hyperspectral imaging; Image fusion; Image resolution; Optical remote sensing; Photomapping; Radar imaging; Space-based radar; Spectral resolution; Spectroscopy; Wetlands; Coastal wetlands; Gaofen-5; High spatial resolution; HyperSpectral; Multi-spectral; Pixel level; Remote-sensing; Synthetic aperture radar images; Synthetic aperture radar remote sensing images; Ziyuan-1 02d; Synthetic aperture radar","classification; coastal wetlands; data fusion; GaoFen-5; hyperspectral; pixel-level; remote sensing; synthetic aperture radar; ZY-1 02D","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85137272381"
"John A.; Fuentes H.R.; Gann D.","John, Anupama (57190944729); Fuentes, Hector R. (7004147160); Gann, Daniel (56432446100)","57190944729; 7004147160; 56432446100","Application of single-polarimetric RADARSAT-2 images with WorldView 2 images in estimating water stages in the everglades","2016","World Environmental and Water Resources Congress 2016: Professional Development, Innovative Technology, International Perspectives, and History and Heritage - Papers from Sessions of the Proceedings of the 2016 World Environmental and Water Resources Congress","","","","50","58","8","10.1061/9780784479841.006","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984614687&doi=10.1061%2f9780784479841.006&partnerID=40&md5=47e4068a680016cff9d69b7615b3b3f7","Understanding the dynamics of hydrological regimes and their effects on Everglades ecosystems requires high resolution, spatially explicit time series data such as water depth and flow across those ecosystems. This study investigated the relationship between radar backscatter from RSAT2 a satellite based synthetic aperture radar (SAR) system, NDVI calculated from WorldView 2 (WV2) multi-spectral data, and water stages for different vegetation types using EDEN water level gages. Linear regression models for backscatter with ground condition were developed for five different vegetation classes: Cladium jamaicense, dense Cladium, sparse Cladium, graminoid prairie, and wet prairie. In all the cases considered, additive models, that is, those for backscatter as a function of both water depth and NDVI (Graminoid Prairie, R2=0.92; dense Cladium, R2=0.62; and sparse Cladium, R2=0.69), explained the variation of backscatter with ground conditions better than individual models. Hence, SAR backscatter data in combination with spatially explicit vegetation data could allow for estimation of continuous water levels at high spatial resolutions. © 2016 ASCE.","Backscattering; Ecosystems; Environmental technology; Radar imaging; Regression analysis; Synthetic aperture radar; Vegetation; Water levels; Cladium jamaicense; High spatial resolution; Hydrological regime; Individual models; Linear regression models; Multi-spectral data; RADARSAT-2 images; Spatially explicit; Water resources","","Conference paper","Final","","Scopus","2-s2.0-84984614687"
"Salentinig A.; Gamba P.","Salentinig, Andreas (56422257700); Gamba, Paolo (7007165803)","56422257700; 7007165803","Combining SAR-Based and Multispectral-Based Extractions to Map Urban Areas at Multiple Spatial Resolutions","2015","IEEE Geoscience and Remote Sensing Magazine","3","3","7284788","100","112","12","10.1109/MGRS.2015.2430874","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943798991&doi=10.1109%2fMGRS.2015.2430874&partnerID=40&md5=7a68cea1f03c8f3b4ce8e7231b82a6a2","Urban remote sensing and data fusion are intimately connected, and this paper discusses recent developments in urban extent extraction using remotely sensed data with data sets or algorithms working at the global level. To achieve the results presented in this paper, several data fusion techniques at the raw data level, the feature level, and the decision level are designed and exploited. Specifically, multi-resolution data fusion techniques to exploit SAR data acquired in different modes, as well as fusion of information extracted from SAR and multispectral data are considered and evaluated. © 2013 IEEE.","Data fusion; Data fusion technique; Decision levels; Multi-spectral; Multi-spectral data; Multiresolution data; Remotely sensed data; Spatial resolution; Urban remote sensing; algorithm; data interpretation; geological mapping; multispectral image; remote sensing; satellite data; spatial resolution; synthetic aperture radar; urban agriculture; Remote sensing","","Article","Final","","Scopus","2-s2.0-84943798991"
"Kennedy H.L.","Kennedy, Hugh L. (24076402700)","24076402700","Isotropic Estimators of Local Background Statistics for Target Detection in Imagery","2018","IEEE Geoscience and Remote Sensing Letters","15","7","","1075","1079","4","10.1109/LGRS.2018.2821120","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045762567&doi=10.1109%2fLGRS.2018.2821120&partnerID=40&md5=c690f84c0e8dd143125a9429aadb0678","Square windows are usually used to estimate the parameters of local background statistics for the constant false alarm rate detection of anomalies/targets in multispectral and synthetic-aperture radar imagery. It is shown that more isotropic windows offer improved detection performance in Monte Carlo simulations. Separable and nonseparable realizations are discussed and a novel recursive realization is presented. © 2018 IEEE.","Clutter (information theory); Detectors; IIR filters; Impulse response; Intelligent systems; Manganese; Monte Carlo methods; Object detection; Object recognition; Synthetic aperture radar; Constant false alarm rate detections; Detection performance; Image filtering; Infinite impulse response; Microsoft windows; Multi-spectral; Nonseparable; Synthetic Aperture Radar Imagery; anomaly; filter; isotropy; Monte Carlo analysis; radar imagery; synthetic aperture radar; Tracking radar","Image filtering; infinite impulse response (IIR) filters; object detection","Article","Final","","Scopus","2-s2.0-85045762567"
"Suresh G.; Hovenbitzer M.","Suresh, Gopika (57212919806); Hovenbitzer, Michael (57190428258)","57212919806; 57190428258","Quantification of forest extent in Germany by combining multi-temporal stacks of Sentinel-1 and Sentinel-2 images","2018","Proceedings of SPIE - The International Society for Optical Engineering","10773","","107730N","","","","10.1117/12.2326013","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052675759&doi=10.1117%2f12.2326013&partnerID=40&md5=c2dbd2dbbc31879dfe27a97c23843f2f","Information regarding the extents of forests and forest biomass is crucial for the quantification of the terrestrial carbon budget. While field surveys are time consuming and expensive, remote sensing techniques offer an efficient and fast alternative. The Copernicus programme provides large amounts of Synthetic Aperture Radar (SAR) and multi-spectral data that can be used for this purpose. This study presents two methods for forest cover classification, one using a multitemporal dataset of SAR images from one orbit, and the other combining SAR images acquired in both ascending and descending orbits and almost cloud-free (<10%) multi-spectral images. The SAR-LC classification system, a rule-based decision tree which is designed to classify land cover types using radar backscatter is used to extract forest cover extent from the 2016 dataset. For the second method, Sentinel-1 images from 2017 in both ascending and descending orbits are combined with 10 m resampled almost cloud free Sentinel-2 images to form one multi-temporal dataset with 88 bands. This is then segmented into objects before forest extent is classified using a rule-based classification. The SAR-LC thresholds were optimised to include the ReNDVI values from the Sentinel-2 images for this purpose. While the final objective of this study is to produce forest cover maps for the whole of Germany, this paper will only focus on the forests around the region of Frankfurt. The challenges, limitations and accuracy of each method is reported and discussed. © 2018 SPIE.","Budget control; Classification (of information); Decision trees; Forestry; Remote sensing; Spectroscopy; Synthetic aperture radar; Copernicus; Forest; Rule-based classification; Sentinel-1; Sentinel-2; Radar imaging","Copernicus; Forest; Rule-Based Classification; SAR; Sentinel-1; Sentinel-2","Conference paper","Final","","Scopus","2-s2.0-85052675759"
"Santoro M.; Wegmüller U.; Lamarche C.; Bontemps S.; Defourny P.; Arino O.","Santoro, Maurizio (7201820022); Wegmüller, Urs (7005064554); Lamarche, Céline (56181338400); Bontemps, Sophie (24281070000); Defourny, Pierre (6603669676); Arino, Olivier (7006963419)","7201820022; 7005064554; 56181338400; 24281070000; 6603669676; 7006963419","Strengths and weaknesses of multi-year Envisat ASAR backscatter measurements to map permanent open water bodies at global scale","2015","Remote Sensing of Environment","171","","","185","201","16","10.1016/j.rse.2015.10.031","53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946542137&doi=10.1016%2fj.rse.2015.10.031&partnerID=40&md5=44f6814afd98dec0c446ca3bcae50ae3","The mapping of water bodies at global scale has been undertaken primarily using multi-spectral optical Earth Observation data. Limitations of optical data associatedwith non-uniform and temporally variable spectral signatures suggested investigating alternative approaches towards a more consistent and reliable detection of water bodies. Multi-year (2005-2012) observations of SAR backscattered intensities at moderate resolution from the Envisat Advanced Synthetic Aperture Radar (ASAR) instrument were used in this study to generate an indicator of open permanent water bodies (SAR-WBI) for the year 2010 time frame and for all land surfaces excluding Antarctica and the Greenland ice sheet. A first map of potential water bodies with a spatial resolution of 150 m was obtained with a global detection algorithm based on a set of thresholds applied to multi-temporal metrics of the SAR backscatter (temporal variability, TV, and minimum backscatter, MB). Local refinements were then used to reduce systematic commission and omission errors (4.6% of the total area mapped) due to the similarity of TV and MB over open water bodies and other land surface types primarily in cold and arid environments. The refinement rules are here explained by means of a detailed signature analysis of the SAR backscatter in such environments. The accuracy of the SAR-WBIwas 80%when compared against 2078 manually interpreted footprints with a size of 150 × 150 m2. Omission errors were primarily observed along coast- and shorelines whereas commission errors were associated with (i) ephemeral water bodies, (ii) seasonally inundated areas, and (iii) an incorrect choice of the local refinement. © 2015 Elsevier Inc.","Antarctica; Arctic; Greenland; Greenland Ice Sheet; Backscattering; Errors; Photomapping; Surface measurement; Systematic errors; C-bands; ENVISAT ASAR; Land cover; SAR; Waterbodies; algorithm; backscatter; Envisat; ephemeral lake; error analysis; global change; land cover; map generalization; observational method; spectral analysis; synthetic aperture radar; temporal variation; Synthetic aperture radar","Backscatter; C-band; Envisat ASAR; Land cover; SAR; Water body","Article","Final","","Scopus","2-s2.0-84946542137"
"Verma A.K.; Nandan R.; Verma A.","Verma, Arun Kumar (7401937964); Nandan, Ranbir (57202058847); Verma, Aditi (57203489538)","7401937964; 57202058847; 57203489538","Space-borne synthetic aperture radar (SAR) sensors in low earth orbit for real-time detection, monitoring of floods and disaster management","2018","Proceedings - 39th Asian Conference on Remote Sensing: Remote Sensing Enabling Prosperity, ACRS 2018","3","","","1520","1529","9","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071903249&partnerID=40&md5=b3b6fdb9b6732748c47032c177d3c2ca","Earth Observation System (EOS) consists of optical or microwave sensors on space-borne system in theLower Earth Orbit (LEO) and provides crucial information for effective flood disaster management by supportingdecision makers or emergency response organization in their activities during time critical crisis response phase ofnatural disaster. It is well known that the applications of satellite images of multi-spectral sensors in optical spectrum isnot suitable for detection and monitoring of flood during rainy season and clouds in the sky due to non-penetratingcapability of signals restricting its applications during clear sky condition. The other limitation of multi-spectral sensorsin optical spectrum is its acquisition of satellite imageries during day time only. Synthetic Aperture Radar (SAR)Sensor is the preferred tool for flood detection and mapping from space due to continuous observation of earth surfacefrom the polar orbit, where SAR sensors provides its own source of illumination and characterized by near all-weather/day-night imaging capability independent of atmospheric conditions in the microwave spectrum. Open water surfaceareas during flooding period in rivers behave like flat water surface for radar bands in microwave spectrum and acts asspecular reflector responsible for scattering of radar signals incident from space borne SAR sensors resulting into darkpixels in the radar image in contrast to non-flooding area of earth surface. The change detection techniques using multitemporal SAR images based on the behavior of back-scattered signals for threshold value for detecting the floodbetween non-flooding and flooding period, and provide information related the status of water surface of river system.Recently, radar sensors have received interest in the development of space-borne bi-static and multi-static SAR sensorsdue its potential to reduce the revisit (repeat orbit) time for monitoring the changes on the earth surface depending uponthe repeat orbit and SAR payloads on satellite. Space-borne SAR payloads can be placed in the orbit into fully active orsemi-active configuration based on both transmits and receives capability of signals.In this paper, the concept of the bi-static and multi-static space-borne SAR sensors has been described for developmentof real time space-borne SAR surveillance system for monitoring of various characteristics of river basins and detectionof flood using threshold/change detection techniques. Further, the concept for the development of constellation ofmulti-static SAR satellite imaging receiver in low earth orbit and geostationary radar illuminating system have beendescribed for real time surveillance of flood detection and management of flood detection, monitoring and disastermanagement. © 2018 Proceedings - 39th Asian Conference on Remote Sensing: Remote Sensing Enabling Prosperity, ACRS 2018. All rights reserved.","Backscattering; Communication satellites; Disaster prevention; Earth (planet); Emergency services; Floods; Geostationary satellites; Information management; Microwave sensors; Microwave spectroscopy; Monitoring; Multistatic radars; Orbits; Radar imaging; Remote sensing; Rivers; Signal detection; Space optics; Surface scattering; Synthetic aperture radar; Disaster management; Earth observation systems; Flood disaster management; Multi-static; Multi-temporal SAR images; Radar backscattering coefficient; Space-borne; Space-borne SAR sensors; Space-based radar","Bi-Static and Multi-Static SAR Sensors; Detection and Monitoring of Flood; Disaster Management; Radar Backscattering Coefficient; Space-borne Synthetic Aperture Radar (SAR","Conference paper","Final","","Scopus","2-s2.0-85071903249"
"Verma A.K.; Nandan R.; Verma A.","Verma, Arun Kumar (7401937964); Nandan, Ranbir (57202058847); Verma, Aditi (57203489538)","7401937964; 57202058847; 57203489538","Space-borne-synthetic aperture radar (SAR) system for real time survilliances of earth surface for detection and management of flood disaster in Indian sub-continent","2017","38th Asian Conference on Remote Sensing - Space Applications: Touching Human Lives, ACRS 2017","2017-October","","","","","","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047004262&partnerID=40&md5=7844923121bc586876720a128f09cc7e","Earth Observation System consisting of remote sensing satellite in optical and microwave spectrum provides the information of different environmental and earth surface parameters by mapping and monitoring the earth surface for natural disasters such as earth quake, landslides, foods and forest fire apart from natural resource management. The remote sensing satellite images of multi-spectral sensors in the optical spectrum are affected by weather conditions due to clouds and rains as well as climatic conditions, restricting its application during clear sky conditions apart from limiting its image acquisition during the day time only. The development in the space borne synthetic aperture radar (SAR) technology and imaging techniques to reduce the repeat pass period using multi-SAR systems in orbits makes its suitable for real time monitoring and mapping of earth surface for the flood and water resource management due inherent cloud and rain penetrating capability as well as backscattering properties of radar signals in different frequency band. The recent development of space-borne SAR systems in bi-static and multi-static configuration by different space agencies ensures the availability of multi-sensor SAR in different microwave radar bands for the development of space-based flood disaster management system. The inherent characteristics to generate high contrast in SAR image between surfaces such as soil and water is due to very low backscattering coefficient of radar signals from water bodies acting as a mirror reflecting surface and earth surface gives higher backscattering coefficient due to surface roughness consisting of soil characteristics and vegetation, which increases the radar reflectivity of the surface. Major rivers in India like Indus, Ganga and Brahmaputra are snow-fed as well as monsoon rainfall dependent, while the other river basins are purely rainfall dependent. A large variability in the characteristics of rainfall has been observed over the basin in different seasons and months. The southwest (SW) monsoon, which brings about 80% of the total precipitation over the country, is critical for the availability of freshwater for drinking and irrigation. Flooding in rivers are caused due to excessive rainfall and discharge of water in the river basins leading to the overflow of the water submerging the landmass depending upon its terrain profile, river bed characteristics, raindrop size distribution and rainfall characteristics. In this paper, the concept of the bi-static and multi-static space-borne SAR sensors has been described for development of real time space-borne surveillance system for Indian Sub-continent as Disaster Management System (DMS), which can be used for flood detection and flood disaster management. The concept of geostationary radar illuminator and constellation of multi-SAR-satellites in LEO has been described. © 2017 Asian Association on Remote Sensing. All rights reserved.","Atmospheric thermodynamics; Backscattering; Communication satellites; Deforestation; Disaster prevention; Disasters; Electric discharges; Floods; Geostationary satellites; Information management; Mapping; Microwave sensors; Microwave spectroscopy; Multistatic radars; Orbits; Radar astronomy; Radar imaging; Rain; Real time systems; Remote sensing; Resource allocation; Rivers; Space applications; Space optics; Surface roughness; Synthetic aperture radar; Tracking radar; Water management; Watersheds; Flood detections; Geostationary radar illuminator; Low earth orbit(LEO); Radar backscattering coefficient; Remote sensing satellites; SAR system; Space-based radar","Bi-static; Flood detection techniques; Geostationary radar illuminator; Low Earth Orbit (LEO); Micro-SAR receiver; Multi-static SAR system; Radar backscattering coefficient; Remote sensing satellite","Conference paper","Final","","Scopus","2-s2.0-85047004262"
"Liu M.; Dai Y.; Zhang J.; Zhang X.; Meng J.; Xie Q.","Liu, Meijie (57221054798); Dai, Yongshou (56048616800); Zhang, Jie (55963073000); Zhang, Xi (24469469100); Meng, Junmin (14028537000); Xie, Qinchuan (55840156400)","57221054798; 56048616800; 55963073000; 24469469100; 14028537000; 55840156400","PCA-based sea-ice image fusion of optical data by HIS transform and SAR data by wavelet transform","2015","Acta Oceanologica Sinica","34","3","","59","67","8","10.1007/s13131-015-0634-7","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924975294&doi=10.1007%2fs13131-015-0634-7&partnerID=40&md5=482e22e8ff8c96af7c516f6766761b10","Sea ice as a disaster has recently attracted a great deal of attention in China. Its monitoring has become a routine task for the maritime sector. Remote sensing, which depends mainly on SAR and optical sensors, has become the primary means for sea-ice research. Optical images contain abundant sea-ice multi-spectral information, whereas SAR images contain rich sea-ice texture information. If the characteristic advantages of SAR and optical images could be combined for sea-ice study, the ability of sea-ice monitoring would be improved. In this study, in accordance with the characteristics of sea-ice SAR and optical images, the transformation and fusion methods for these images were chosen. Also, a fusion method of optical and SAR images was proposed in order to improve sea-ice identification. Texture information can play an important role in sea-ice classification. Haar wavelet transformation was found to be suitable for the sea-ice SAR images, and the texture information of the sea-ice SAR image from Advanced Synthetic Aperture Radar (ASAR) loaded on ENVISAT was documented. The results of our studies showed that, the optical images in the hue-intensity-saturation (HIS) space could reflect the spectral characteristics of the sea-ice types more efficiently than in the red-green-blue (RGB) space, and the optical image from the China-Brazil Earth Resources Satellite (CBERS-02B) was transferred from the RGB space to the HIS space. The principal component analysis (PCA) method could potentially contain the maximum information of the sea-ice images by fusing the HIS and texture images. The fusion image was obtained by a PCA method, which included the advantages of both the sea-ice SAR image and the optical image. To validate the fusion method, three methods were used to evaluate the fused image, i.e., objective, subjective, and comprehensive evaluations. It was concluded that the fusion method proposed could improve the ability of image interpretation and sea-ice identification. © 2015, The Chinese Society of Oceanography and Springer-Verlag Berlin Heidelberg.","","HIS transform; optical remote sensing image; PCA method; SAR remote sensing image; sea ice; wavelet transform","Article","Final","","Scopus","2-s2.0-84924975294"
"Pohl C.; Loong C.K.; Van Genderen J.","Pohl, Christine (7102763531); Loong, Chong Khai (57188878635); Van Genderen, John (7003791000)","7102763531; 57188878635; 7003791000","Multisensor approach to oil palm plantation monitoring using data fusion and GIS","2015","ACRS 2015 - 36th Asian Conference on Remote Sensing: Fostering Resilient Growth in Asia, Proceedings","","","","","","","","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964048175&partnerID=40&md5=932e9c71334cc2fc286507e9763efe49","Oil palm is recognized as the golden crop. It produces the highest oil yield among oil seed crops. Malaysia, as the world's second largest producer of palm oil, has 16 % of its lands planted with oil palms. To cope with the ever-increasing global demand on edible oil, additional areas of oil palm are forecasted to increase globally by 12 to 19 million hectares by 2050. Multisensor remote sensing plays an important role by providing relevant, timely and accurate information that can be developed into a plantation monitoring system to optimize production and sustainability. The use of synthetic aperture radar (SAR), a form of microwave remote sensing, in combination with visible and infrared (VIR) data has several distinct advantages, the biggest benefits being daylight and weather independent. SAR produces 'cloud-free' images. However, SAR image are difficult to interpret. Using optical remote sensing provides important physical parameters of the plantation using multispectral data acquisition. Both types of data are complementary and need to be exploited simultaneously to obtain a holistic view on the plantation. Using interferometric SAR a topographical surface and height profiles of oil palm plantations can be derived. The information is crucial in the effort of mapping the oil palms age profile in the country. With this monitored, a replanting program could be effectively installed to maximize national production. VIR remote sensing delivers information on the plants' health and stress along with other biophysical parameters. Therefore the study aims to discover a set of parameters for oil palm plantation monitoring, which are retrievable from multisensor remote sensing data. The parameters are validated through the collection of ground. It is anticipated to derive all relevant information for the oil palm industry to implement a sustainable plantation management. The workflow on the parameter extraction and information derivation is designed and optimized.","Crops; Data acquisition; Data fusion; Image fusion; Monitoring; Oil shale; Parameter extraction; Radar; Radar imaging; Remote sensing; Synthetic aperture radar; Biophysical parameters; Interferometric SAR; Microwave remote sensing; Multi-spectral data; Multisensor remote sensing; Oil palm plantations; Optical remote sensing; Plantation managements; Palm oil","Image fusion; Palm oil; Radar; Remote sensing","Conference paper","Final","","Scopus","2-s2.0-84964048175"
"Wei C.","Wei, Chunzhu (57669890800)","57669890800","Detecting and analysing ""urban villages"" in the Pearl River delta using multisource remote sensing data","2015","CEUR Workshop Proceedings","1598","","","","","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977578415&partnerID=40&md5=cfc9edb1af2294d2b95580c899c5d3ee","'Urban villages' is the Chinese version of informal settlement. It is a unique phenomenon that comprises mainly low-rise and congested, often illegal buildings surrounded by new constructions and high-rise buildings. Due to a lack of an unambiguous definition allowing for a spatial delineation of such areas, this article investigates a joint use of high-resolution optical and SAR satellite data through building extraction and 3D reconstruction of urban villages in Shenzhen, China. First, potential urban village footprints are extracted through a combined image fusion analysis of multispectral GaoFen-1 (GF-1) and high resolution TerraSAR-X radar (SAR) imagery. Then, building height estimation is performed on the basis of interferometry principles using interferometric X-band SAR (InSAR) from the Tandem-X mission. It can be demonstrated that urban villages and surrounding urban areas are clearly distinguishable through particular combinations of optical data, SAR data and height information. In particular, a rigid analysis identified three types of information as most suitable: 1) Normalized Difference Vegetation Index (NDVI), 2) contextual parameters such as edge and line density from GF-1 multi-spectral imagery, and 3) textural parameters such as Grey-Level Co-occurrence Matrix (GLCM) variables from TerraSAR-X imagery. The additional height information from InSAR clearly improves the detecting of taller buildings surrounding the urban villages. In conclusion, the fusion of SAR and optical imagery can effectively reveal the footprint characteristics of urban villages. It is an effective means to reduce the effects of layover, shadow and dominant scattering at building location. The 3D building reconstruction model based on urban village footprint maps can reduce the continuous alteration of layover and shadow areas from high-rise buildings in the dense urban area.","Buildings; Image fusion; Interferometry; Maintenance; Remote sensing; Rural areas; Satellites; Spectroscopy; Synthetic aperture radar; Tall buildings; Three dimensional computer graphics; 3-d building reconstruction; Building extraction; Grey-level co-occurrence matrixes; Informal settlements; Multi-spectral imagery; Multisource remote sensing data; Normalized difference vegetation index; Spatial delineation; Radar imaging","","Conference paper","Final","","Scopus","2-s2.0-84977578415"
"Tai J.; Pan B.; Zhao S.; Zhao Y.","Tai, Jianhao (57194470574); Pan, Bin (57206682357); Zhao, Shanshan (57220796676); Zhao, Yuan (57194463764)","57194470574; 57206682357; 57220796676; 57194463764","SAR and Multispectral Remote Sensing Image Fusion Method Using Shearlet Transform","2017","Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University","42","4","","468","474","6","10.13203/j.whugis20150768","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020263870&doi=10.13203%2fj.whugis20150768&partnerID=40&md5=ed5ae8f12c7bb106b53a4abc5c549939","In terms of conventional methods for SAR image and multispectral image fusion can't integrate and reserve good spectral information and spatial resolution at the same time, a new fusion method based on the difference of imaging mechanism of SAR and multispectral images is proposed in this paper. Firstly, the original image is decomposed by Shearlet transform, and the high frequency and low frequency components are obtained respectively. The two components contain different detailed information of the image. Shearlet transform decomposes the image into multi-scale and multi-directional sub-band coefficients, which contain different image features. In addition, Shearlet inverse transform has good image reconstruction capability. And then, according to that the low frequency coefficient and the high frequency coefficient represent different meanings, we design the different fusion rule for them. The fusion rules of low frequency coefficients based on region energy and the high frequency coefficient based on improved pulse coupled neural network are designed. Finally, an information-rich image is obtained by inversing Shearlet transform. Therefore, the fusion results are richer and contain more spatial detail information and spectral information. In order to verify the effectiveness of the proposed method, a test is carried out with data from TerraSAR-X and Landsat5-TM, and the result shows that the proposed method is effective in improving the spatial resolution and keeping more spectral information. Compared with the methods of wavelet transform, contourlet transform, and NSCT transform, this method has a significant improvement in spatial information and spectral information. Cross entropy has a margin of improvement of nearly 100%. The correlation coefficient is higher than 25% increase, and the spectral distortion is better than 40% increase. © 2017, Research and Development Office of Wuhan University. All right reserved.","Image enhancement; Image fusion; Image reconstruction; Image resolution; Inverse problems; Inverse transforms; Neural networks; Remote sensing; Spectroscopy; Synthetic aperture radar; Wavelet transforms; Imaging properties; Multi-source images; Multispectral images; PCNN; Shearlet transforms; imaging method; multispectral image; radar imagery; remote sensing; spatial resolution; synthetic aperture radar; transform; Radar imaging","Difference of imaging property; Multi-spectral images; Multisource image fusion; PCNN; SAR; Shearlet transform","Article","Final","","Scopus","2-s2.0-85020263870"
"Stankova N.; Nedkov R.; Ivanova I.; Avetisyan D.","Stankova, Nataliya (57188725615); Nedkov, Roumen (57204958301); Ivanova, Iva (57198062540); Avetisyan, Daniela (57188731292)","57188725615; 57204958301; 57198062540; 57188731292","Integration of multispectral and SAR data for monitoring forest ecosystems recovery after fire","2017","Proceedings of SPIE - The International Society for Optical Engineering","10444","","104441J","","","","10.1117/12.2277313","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029676329&doi=10.1117%2f12.2277313&partnerID=40&md5=2b027dcdda40d85e16151b32b813f47d","The aim of this study is assessing the impacts and monitoring the condition and recovery processes of forest ecosystems after fire based on remote aerospace methods and data. To achieve this goal, satellite imagery in microwave and optical range of the spectrum were used. A hybrid model for assessing the instantaneous condition of forest ecosystems after fire that uses parallel data from optical and Synthetic Aperture Radar (SAR) was developed. Based on the three Tasseled Cap components (Brightness-BR, Greenness-GR and Wetness-W), a vector describing the current condition of the forest ecosystems was obtained and used as input data from the optical range. Results obtained by implementation of the proposed approach show that the integrated composite images of VIC and SAR represent the degree of recovery. © 2017 SPIE.","Ecology; Fires; Forestry; Radar; Radar imaging; Recovery; Remote sensing; Satellite imagery; Synthetic aperture radar; After fires; Composite images; Degree of recovery; Forest ecosystem; Multi-spectral; Optical range; Parallel data; Recovery process; Ecosystems","Recovery after fire; Remote sensing; Synthetic aperture radar (SAR); Vector of instantaneous condition (VIC)","Conference paper","Final","","Scopus","2-s2.0-85029676329"
"Soldin R.J.","Soldin, Ryan J. (57208862226)","57208862226","SAR Target Recognition with Deep Learning","2018","Proceedings - Applied Imagery Pattern Recognition Workshop","2018-October","","8707419","","","","10.1109/AIPR.2018.8707419","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065970234&doi=10.1109%2fAIPR.2018.8707419&partnerID=40&md5=eb67b3b07d0a30bb3b59a722ad5abc45","The automated detection and classification of objects in imagery is an important topic for many applications in remote sensing. These can include the counting of cars and ships and the tracking of military vehicles for the defense and intelligence industry. Synthetic aperture radar (SAR) provides day/night and all-weather imaging capabilities. SAR is a powerful data source for Deep Learning (DL) algorithms to provide automatic target recognition (ATR) capabilities. DL classification was shown to be extremely effective on multi-spectral satellite imagery during the IARPA Functional Map of the World (fMoW). In our work we look to extend these techniques to SAR. We start by applying ResNet-18 to the Moving and Stationary Target Acquisition and Recognition (MSTAR) dataset. The MSTAR program, sponsored by DARPA and AFRL, consists of SAR collections of military style targets using an aerial X-band radar with one-foot resolution. We achieved an overall classification accuracy of 99% on 10 different classes of targets, confirming previously published results. We then extend this classifier to investigate an emerging target and the effects of limited training data on system performance. © 2018 IEEE.","Antennas; Artificial intelligence; Automatic target recognition; Classification (of information); Deep learning; Image understanding; Learning systems; Military vehicles; Neural networks; Object detection; Radar imaging; Remote sensing; Satellite imagery; Synthetic aperture radar; Automated detection and classification; Classification accuracy; Defense and intelligences; Imaging capabilities; Limited training data; recognition; Stationary targets; Target recognition; Radar target recognition","AI; artificial intelligence; ATR; classification; CNN; deep learning; image understanding; machine learning; neural networks; recognition; synthetic aperture radar; target recognition","Conference paper","Final","","Scopus","2-s2.0-85065970234"
"Baque R.; Ruault Du Plessis O.; Castet N.; Fromage P.; Martinot-Lagarde J.; Nouvel J.-F.; Oriot H.; Angelliaume S.; Brigui F.; Cantalloube H.; Chanteclerc M.; Dubois-Fernandez P.; Dupuis X.; Martineau P.","Baque, Remi (36069113000); Ruault Du Plessis, Olivier (23492206700); Castet, Nicolas (57201852505); Fromage, Patrick (15064087200); Martinot-Lagarde, Joseph (52464045300); Nouvel, Jean-Francois (6602299637); Oriot, Helene (6603289678); Angelliaume, Sebastien (23017892200); Brigui, Frederic (35075788700); Cantalloube, Hubert (6602747764); Chanteclerc, Martine (6505728352); Dubois-Fernandez, Pascale (6603435799); Dupuis, Xavier (8366163700); Martineau, Philippe (7007044874)","36069113000; 23492206700; 57201852505; 15064087200; 52464045300; 6602299637; 6603289678; 23017892200; 35075788700; 6602747764; 6505728352; 6603435799; 8366163700; 7007044874","SETHI/RAMSES-NG: New performances of the flexible multi-spectral airborne remote sensing research platform","2017","European Microwave Week 2017: ""A Prime Year for a Prime Event"", EuMW 2017 - Conference Proceedings; 14th European Microwave Conference, EURAD 2017","2018-January","","","191","194","3","10.23919/EURAD.2017.8249179","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046288262&doi=10.23919%2fEURAD.2017.8249179&partnerID=40&md5=3ca00757e76ea935016c84abed81f176","SETHI is an airborne SAR/GMTI system developed by the French Aerospace Lab. ONERA, and integrating various sensors. In 2016 ONERA invested in upgrade and improvement of all SETHI components. The microwave ones cover from VHF-UHF to X Band, full polarimetric and very high resolution, along track and cross track interferometry and very high precision multi-baseline capacity for interferometry and tomography applications. The optronic sensors offer very high spatial resolution visible images and fine spectral scene analysis in VNIR and SWIR bands. This paper presents the upgrade and new performances of this flexible platform and the qualification campaign results with various sensor configurations. © 2017 European Microwave Association.","Interferometry; Microwaves; Synthetic aperture radar; Airborne remote sensing; Flexible platforms; Moving target detection; Optronic; Sensor configurations; Tomography applications; Very high resolution; Very high spatial resolutions; Remote sensing","Moving target detection and tracking; Optronic; Remote sensing; SAR; Very High Resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85046288262"
"Gokaraju B.; Turlapaty A.C.; Doss D.A.; King R.L.; Younan N.H.","Gokaraju, Balakrishna (26666734900); Turlapaty, Anish C. (35312809900); Doss, Daniel A. (57188933720); King, Roger L. (24565319100); Younan, Nicolas H. (7004671182)","26666734900; 35312809900; 57188933720; 24565319100; 7004671182","Change detection analysis of tornado disaster using conditional copulas and Data Fusion for cost-effective disaster management","2016","2015 IEEE Applied Imagery Pattern Recognition Workshop, AIPR 2015","","","7444537","","","","10.1109/AIPR.2015.7444537","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966552702&doi=10.1109%2fAIPR.2015.7444537&partnerID=40&md5=df148397bbaf59dec87a543a00149a9e","The up-to-date results are presented from an ongoing study of the Data Fusion of multi-temporal and multi-sensor satellite datasets for near real time damage and debris assessment after a tornado disaster event. The space-borne sensor datasets comprising of: (i) C-band SAR dataset from RADARSAT-2; (ii) Multi-Spectral (MS) optical dataset including NIR from RapidEye; (iii) MS and panchromatic dataset of Advanced Linear Imaging (ALI), are studied for multi-sensor data fusion. A combined approach of multi-polarized radiometric and textural feature extraction, and statistical learning based feature classification is devised for fine tuning of the complex and generalized change detection model. We also investigated the use of multi-variate conditional copula as a classifier technique, by formulating the change and no-change as a binary-class classification problem in this study. The classification results from the above technique are used for assessment of damage and debris cover after the tornado disaster event. The performance of the above approach yields a very significant Kappa accuracy up to 75%. A 10-fold cross validation strategy is used for quantitative analysis of the performance of the classification model. This study will be further extended for modelling the effect of incidence angle discrepancies or climatic condition variances, which will address the heterogeneity factor in terms of local statistics of the dataset. © 2015 IEEE.","Artificial intelligence; Cost effectiveness; Damage detection; Data fusion; Debris; Disaster prevention; Disasters; Feature extraction; Learning systems; Pattern recognition; Signal detection; Space-based radar; Synthetic aperture radar; Tornadoes; 10-fold cross-validation; Change detection; Change detection analysis; Classification results; Conditional copula; Disaster management; Feature classification; Multisensor data fusion; Sensor data fusion","change detection; conditional Copula; data fusion; disaster management; machine learning","Conference paper","Final","","Scopus","2-s2.0-84966552702"
"Di Iorio A.; Biliouris D.; Guzinski R.; Hansen L.B.; Bagni M.","Di Iorio, A. (24528196400); Biliouris, D. (57199351088); Guzinski, R. (48861565700); Hansen, L.B. (23012240100); Bagni, M. (57213700676)","24528196400; 57199351088; 48861565700; 23012240100; 57213700676","Innovation technologies and applications for coastal archaeological sites FP7-ITACA","2015","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","40","7W3","","1367","1373","6","10.5194/isprsarchives-XL-7-W3-1367-2015","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930390413&doi=10.5194%2fisprsarchives-XL-7-W3-1367-2015&partnerID=40&md5=24fe9ea2a9ed29c08f136a335d7e115e","Innovation Technologies and Applications for Coastal Archaeological sites project (ITACA) aims to develop and test a management system for underwater archaeological sites in coastal regions. The discovering and monitoring service will use innovative satellite remote sensing techniques combined with image processing algorithms. The project will develop a set of applications integrated in a system pursuing the following objectives: • Search and location of ancient ship wrecks; • Monitoring of ship wrecks, ruins and historical artefacts that are now submerged; • Integration of resulting search and monitoring data with on-site data into a management tool for underwater sites; • Demonstration of the system's suitability for a service. High resolution synthetic aperture radar (TerraSAR-X, Cosmo-SkyMed) and multispectral satellite data (WorldView) will be combined to derive the relative bathymetry of the bottom of the sea up to the depth of 50 meters. The resulting data fusion will be processed using shape detection algorithms specific for archaeological items. The new algorithms, the physical modelling and the computational capabilities will be integrated into the Web-GIS, together with data recorded from surface (2D and 3D modelling) and from underwater surveys. Additional specific archaeological layers will be included into the WebGIS to facilitate the object identification through shape detection techniques and mapping. The system will be verified and validated through an extensive onground (sea) campaign carried out with both cutting edge technologies (side-scan sonar, multi beam echo sounder) and traditional means (professional scuba divers) in two test sites in Italy and Greece. The project is leaded by Planetek Hellas E.P.E. and include ALMA Sistemi sas for the ""shape detection"" and dissemination tasks, DHI-GRAS and Kell Srl for multispectral and SAR bathymetry. The complete consortium is composed by eleven partners and the project Kick-Off has been held in January 2014. The present contribution aims to present the project research achievements and finding at the mid-term review.","3D modeling; Architecture; Bathymetry; Data fusion; Object detection; Remote sensing; Search engines; Ships; Space-based radar; Synthetic aperture radar; Three dimensional computer graphics; Underwater acoustics; Computational capability; High resolution synthetic aperture radar; Image processing algorithm; Multi-spectral; Multispectral satellite data; Shape detection; Shape detection algorithms; Underwater archaeology; Information management","Multispectral; Remote sensing; SAR; Shape detection; Underwater archaeology","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-84930390413"
"Byrd K.B.; Ballanti L.; Thomas N.; Nguyen D.; Holmquist J.R.; Simard M.; Windham-Myers L.","Byrd, Kristin B. (8206445700); Ballanti, Laurel (57189710598); Thomas, Nathan (56229764300); Nguyen, Dung (57191916274); Holmquist, James R. (56109185600); Simard, Marc (26428503000); Windham-Myers, Lisamarie (9133578200)","8206445700; 57189710598; 56229764300; 57191916274; 56109185600; 26428503000; 9133578200","A remote sensing-based model of tidal marsh aboveground carbon stocks for the conterminous United States","2018","ISPRS Journal of Photogrammetry and Remote Sensing","139","","","255","271","16","10.1016/j.isprsjprs.2018.03.019","63","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044580018&doi=10.1016%2fj.isprsjprs.2018.03.019&partnerID=40&md5=36f9a1cc1a1ab8ddbcc0e984bf7926c6","Remote sensing based maps of tidal marshes, both of their extents and carbon stocks, have the potential to play a key role in conducting greenhouse gas inventories and implementing climate mitigation policies. Our objective was to generate a single remote sensing model of tidal marsh aboveground biomass and carbon that represents nationally diverse tidal marshes within the conterminous United States (CONUS). We developed the first calibration-grade, national-scale dataset of aboveground tidal marsh biomass, species composition, and aboveground plant carbon content (%C) from six CONUS regions: Cape Cod, MA, Chesapeake Bay, MD, Everglades, FL, Mississippi Delta, LA, San Francisco Bay, CA, and Puget Sound, WA. Using the random forest machine learning algorithm, we tested whether imagery from multiple sensors, Sentinel-1 C-band synthetic aperture radar, Landsat, and the National Agriculture Imagery Program (NAIP), can improve model performance. The final model, driven by six Landsat vegetation indices and with the soil adjusted vegetation index as the most important (n = 409, RMSE = 310 g/m2, 10.3% normalized RMSE), successfully predicted biomass for a range of marsh plant functional types defined by height, leaf angle and growth form. Model results were improved by scaling field-measured biomass calibration data by NAIP-derived 30 m fraction green vegetation. With a mean plant carbon content of 44.1% (n = 1384, 95% C.I. = 43.99%–44.37%), we generated regional 30 m aboveground carbon density maps for estuarine and palustrine emergent tidal marshes as indicated by a modified NOAA Coastal Change Analysis Program map. We applied a multivariate delta method to calculate uncertainties in regional carbon densities and stocks that considered standard error in map area, mean biomass and mean %C. Louisiana palustrine emergent marshes had the highest C density (2.67 ± 0.004 Mg/ha) of all regions, while San Francisco Bay brackish/saline marshes had the highest C density of all estuarine emergent marshes (2.03 ± 0.004 Mg/ha). Estimated C stocks for predefined jurisdictional areas ranged from 1023 ± 39 Mg in the Nisqually National Wildlife Refuge in Washington to 507,761 ± 14,822 Mg in the Terrebonne and St. Mary Parishes in Louisiana. This modeling and data synthesis effort will allow for aboveground C stocks in tidal marshes to be included in the coastal wetland section of the U.S. National Greenhouse Gas Inventory. With the increased availability of free post-processed satellite data, we provide a tractable means of modeling tidal marsh aboveground biomass and carbon at the global extent as well. © 2018","United States; Biomass; Calibration; Carbon; Decision trees; Forestry; Greenhouse gases; Image enhancement; Learning algorithms; Learning systems; Remote sensing; Software testing; Space-based radar; Synthetic aperture radar; Vegetation; Wetlands; Above-ground carbons; C-bands; Greenhouse gas inventory; Multi-spectral imagery; Plant functional type; Tidal marshes; aboveground biomass; algorithm; calibration; functional group; intertidal environment; Landsat; machine learning; marsh; model; multispectral image; NOAA satellite; remote sensing; stock assessment; synthetic aperture radar; vegetation index; C (programming language)","Aboveground carbon stocks; C-band synthetic aperture radar; Multispectral imagery; National greenhouse gas inventory; Plant functional type; Tidal marsh biomass","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85044580018"
"Zakeri H.; Liu W.; Yamazaki F.","Zakeri, Homa (57194007097); Liu, Wen (57210953131); Yamazaki, Fumio (35857807800)","57194007097; 57210953131; 35857807800","Land-cover classification of Tehran using L- and C-band synthetic aperture radar imagery","2016","37th Asian Conference on Remote Sensing, ACRS 2016","1","","","619","628","9","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018313191&partnerID=40&md5=73c6a39152d2fcf815b86f6dd95e9c97","Monitoring land-cover of urban areas is a main issue in several fields such as urban planning and seismic risk assessment. Detecting built-up and bare land areas in arid or semi-arid regions is quiet difficult by using multi-spectral optical images because of similarity of the spectral characteristics of grounds and building materials. On the contrary, synthetic aperture radar (SAR) images have possibility to overcome this issue because the backscatter depends on the material and geometry of different surface objects. The use of L- and C-band SAR images may have possibility to provide more information of the same objects in urban areas. In this paper, dual polarized data from ALOS-2 PALSAR-2 (HH, HV) with 6.2-m resolution and Sentinel-1 C-SAR (VV, VH) with 13.9-m resolution were used for an unsupervised classification analysis of land-cover in Tehran city, Iran, which has been growing very fast recently. Although the result of classification from the SAR images was better than that from optical images, some noise still remained in the result. Hence texture information was added to improve the classification. The result, which showed less noise by combining the texture measures with the backscattering intensity, was then compared with the visual inspection result of a high-resolution optical image and a reasonable level of accuracy was confirmed.","Backscattering; C (programming language); Classification (of information); Geometrical optics; Image classification; Radar; Remote sensing; Risk assessment; Synthetic aperture radar; Tracking radar; Urban planning; Land cover; SAR imagery; Tehran; Texture measures; Unsupervised classification; Radar imaging","Land-cover; SAR imagery; Tehran; Texture measures; Unsupervised classification","Conference paper","Final","","Scopus","2-s2.0-85018313191"
"Zhang Y.; Guindon B.; Raymond D.; Hong G.","Zhang, Ying (57393797800); Guindon, Bert (7003949233); Raymond, Don (7103274563); Hong, Gang (54410564300)","57393797800; 7003949233; 7103274563; 54410564300","Effective delineation of urban flooded areas based on aerial ortho-photo imagery","2016","Proceedings of SPIE - The International Society for Optical Engineering","10008","","100080M","","","","10.1117/12.2241128","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010843500&doi=10.1117%2f12.2241128&partnerID=40&md5=bc598366c948e9f4275f68e3f89a917d","The combination of rapid global urban growth and climate change has resulted in increased occurrence of major urban flood events across the globe. The distribution of flooded area is one of the key information layers for applications of emergency planning and response management. While SAR systems and technologies have been widely used for flood area delineation, radar images suffer from range ambiguities arising from corner reflection effects and shadowing in dense urban settings. A new mapping framework is proposed for the extraction and quantification of flood extent based on aerial optical multi-spectral imagery and ancillary data. This involves first mapping of flood areas directly visible to the sensor. Subsequently, the complete area of submergence is estimated from this initial mapping and inference techniques based on baseline data such as land cover and GIS information such as available digital elevation models. The methodology has been tested and proven effective using aerial photography for the case of the 2013 flood in Calgary, Canada. © 2016 SPIE.","Aerial photography; Climate change; Floods; Geographic information systems; Mapping; Photomapping; Radar imaging; Radar reflection; Remote sensing; Spectroscopy; Synthetic aperture radar; Urban planning; Aerial photos; Flooded areas; Land cover; Spatial analysis; Urban flooding; Urban remote sensing; Urban growth","Aerial photos; Flooded area mapping; Land cover; Spatial analysis; Urban flooding; Urban remote sensing","Conference paper","Final","","Scopus","2-s2.0-85010843500"
"Sukawattanavijit C.; Chen J.","Sukawattanavijit, Chanika (55349184000); Chen, Jie (55909160300)","55349184000; 55909160300","Fusion of RADARSAT-2 imagery with LANDSAT-8 multispectral data for improving land cover classification performance using SVM","2015","Proceedings of the 2015 IEEE 5th Asia-Pacific Conference on Synthetic Aperture Radar, APSAR 2015","","","7306273","567","572","5","10.1109/APSAR.2015.7306273","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957645277&doi=10.1109%2fAPSAR.2015.7306273&partnerID=40&md5=6cb45bb348abe8fb999d71d17e6323ef","Study of the land cover classification using multi-source data are very important for eco-environment monitoring, land use planning and climatic change detection. In this study, the utility of multi-source RADARSAT-2 and LANDSAT-8 multi-spectral images for improving land cover classification performance using Support Vector Machine (SVM) classifier. HH polarized C band RADARSAT-2 images were fused with the three band (6, 5, and 4) LANDSAT-8 multispectral image for land cover classification. Wavelet-based fusion (WT) techniques are implemented in the data fusion process. The Radial Basic Function (RBF) kernel function were used for SVM classifier in order to classify land cover types in the study area. The results of the SVM classification were compared with those using standard method Maximum Likelihood (ML) classifier, and it demonstrates a higher accuracy. Finally, it was indicated by the study that the fusion of SAR and optical images can significantly improve the classification accuracy with respect to use single dataset, and the SVM classifier could clearly outperform the standard method the ML classifier. © 2015 IEEE.","Data fusion; Geometrical optics; Image classification; Image fusion; Land use; Maximum likelihood; Radar; Space-based radar; Spectroscopy; Support vector machines; Synthetic aperture radar; Wavelet analysis; Classification accuracy; Land cover classification; LANDSAT; Maximum likelihood classifiers; Multi-spectral data; Multispectral images; Radarsat-2; Radial basic function; Classification (of information)","image fusion; land cover classification; LANDSAT-8; RADARSAT-2; Support Vector Machine (SVM)","Conference paper","Final","","Scopus","2-s2.0-84957645277"
"Abdikan S.; Bilgin G.; Sanli F.B.; Uslu E.; Ustuner M.","Abdikan, Saygin (55515101500); Bilgin, Gokhan (8362224100); Sanli, Fusun Balik (23098475900); Uslu, Erkan (25652333200); Ustuner, Mustafa (56246446800)","55515101500; 8362224100; 23098475900; 25652333200; 56246446800","Enhancing land use classification with fusing dual-polarized TerraSAR-X and multispectral RapidEye data","2015","Journal of Applied Remote Sensing","9","1","15125","","","","10.1117/1.JRS.9.096054","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929206896&doi=10.1117%2f1.JRS.9.096054&partnerID=40&md5=abec4cab5c9f901ec84144f6220cb1b2","The contribution of dual-polarized synthetic aperture radar (SAR) to optical data for the accuracy of land use classification is investigated. For this purpose, different image fusion algorithms are implemented to achieve spatially improved images while preserving the spectral information. To compare the performance of the fusion techniques, both the microwave X-band dual-polarized TerraSAR-X data and the multispectral (MS) optical image RapidEye data are used. Our test site, Gediz Basin, covers both agricultural fields and artificial structures. Before the classification phase, four data fusion approaches: (1) adjustable SAR-MS fusion, (2) Ehlers fusion, (3) high-pass filtering, and (4) Bayesian data fusion are applied. The quality of the fused images was evaluated with statistical analyses. In this respect, several methods are performed for quality assessments. Then the classification performances of the fused images are also investigated using the support vector machines as a kernel-based method, the random forests as an ensemble learning method, the fundamental k-nearest neighbor, and the maximum likelihood classifier methods comparatively. Experiments provide promising results for the fusion of dual polarimetric SAR data and optical data in land use/cover mapping. © 2015 The Authors. Published by SPIE.","Classification (of information); Decision trees; Geometrical optics; High pass filters; Image enhancement; Land use; Maximum likelihood; Nearest neighbor search; Satellites; Support vector machines; Synthetic aperture radar; Bayesian data fusions; Classification performance; Image fusion algorithms; Landuse classifications; Maximum likelihood classifiers; Multi-spectral; Rapideye; TerraSAR-X; Image fusion","Classification; Image fusion; Multispectral; RapidEye image; Synthetic aperture radar; TerraSAR-X image","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-84929206896"
"Laghezza F.; Scotti F.; Onori D.; Bogoni A.","Laghezza, Francesco (36185516000); Scotti, Filippo (37111400100); Onori, Daniel (56106034700); Bogoni, Antonella (7004301749)","36185516000; 37111400100; 56106034700; 7004301749","ISAR imaging of non-cooperative targets via dual band photonics-based radar system","2016","Proceedings International Radar Symposium","2016-June","","7497319","","","","10.1109/IRS.2016.7497319","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982791117&doi=10.1109%2fIRS.2016.7497319&partnerID=40&md5=13a00cf146032e62a6e97942eacf74aa","We present results of ISAR imaging derived from a field trial detecting different non-cooperative targets with a photonics-based dual band radar operating in S and X band. Images of the targets have been extracted from collected data demonstrating the capability of the system to operate as an imaging radar. The innovative features of the photonic system as the frequency flexibility and the coherent distribution to decentralized peripherals open the way to multi-spectral/static imaging. © 2016 IEEE.","Inverse synthetic aperture radar; Photonics; Radar; Radar systems; Synthetic aperture radar; Dual Band; Field trial; Frequency flexibility; ISAR Imaging; Microwave Photonics; Multi-spectral; Non-cooperative target; Photonic systems; Radar imaging","Dual-Band; Inverse Synthetic Aperture Radar; Microwave photonics; Radar System","Conference paper","Final","","Scopus","2-s2.0-84982791117"
"Parkes S.; McClements C.; McLaren D.; Florit A.F.; Villafranca A.G.","Parkes, Steve (7005187836); McClements, Chris (6508235564); McLaren, David (36816060900); Florit, Albert Ferrer (16645308700); Villafranca, Alberto Gonzalez (23020220400)","7005187836; 6508235564; 36816060900; 16645308700; 23020220400","Spacefibre: The standard and the multi-lane layer","2016","European Space Agency, (Special Publication) ESA SP","SP-736","","","","","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994319051&partnerID=40&md5=b32b19738666ebfba4401c1331ae00b5","SpaceFibre is a new standard for spacecraft on-board data-handling networks, initially designed to deliver multi-Gbit/s data rates for synthetic aperture radar and high-resolution, multi-spectral imaging instruments, The addition of quality of service (QoS) and fault detection, isolation and recovery (FDIR) capabilities to SpaceFibre has resulted in a unified network technology. SpaceFibre provides high bandwidth, low latency, fault isolation and recovery suitable for space applications, and novel QoS that combines priority, bandwidth reservation and scheduling and which provides babbling node protection. SpaceFibre is backwards compatible with the widely used SpaceWire standard at the network level allowing simple interconnection of existing SpaceWire equipment to a SpaceFibre link or network. Developed by STAR-Dundee and the University of Dundee for the European Space Agency (ESA) SpaceFibre is able to operate over fibre-optic and electrical cable. A single lane of SpaceFibre comprises four signals (TX+/- and RX+/-) and supports data rates of 2 Gbits/s (2.5 Gbits/s data signalling rate) with data rates up to 5 Gbits/s already planned. Several lanes can operate together to provide a multilane link. Multi-laning increases the data-rate to well over 20 Gbits/s. This paper details the current state of SpaceFibre which is now in the process of formal standardisation by the European Cooperation for Space Standardization (ECSS). The multi-lane layer of SpaceFibre is then described.","Bandwidth; Computer system recovery; Data handling; Fault detection; International cooperation; Quality of service; Space applications; Space flight; Spectroscopy; Standardization; Synthetic aperture radar; Bandwidth reservation; Electrical cables; European cooperation for space standardizations; European Space Agency; Isolation and recoveries; Multispectral imaging; Network technologies; Onboard data handling; Space-based radar","","Conference paper","Final","","Scopus","2-s2.0-84994319051"
"Aimaiti Y.; Kasimu A.; Jing G.","Aimaiti, Yusupujiang (57189073747); Kasimu, Alimujiang (21742772100); Jing, Guo (57220485672)","57189073747; 21742772100; 57220485672","Urban landscape extraction and analysis based on optical and microwave ALOS satellite data","2016","Earth Science Informatics","9","4","","425","435","10","10.1007/s12145-016-0264-4","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965071500&doi=10.1007%2fs12145-016-0264-4&partnerID=40&md5=87697cf76a3b50217c72173656a1a7b9","Accurate mapping of urban land cover from satellite data provides essential input to urban landscape analysis, modelling and urban ecosystem studies. Additionally, analysis of urban landscape metrics will provide a positive step towards comprehensive understanding of the features of urban landscape structure and further planning. In the present study, multi-spectral Advanced Land Observing Satellite (ALOS)/Advanced Visible and Near Infrared Radiometer type 2 (AVNIR-2) images and ALOS/Phased Array type L-band Synthetic Aperture Radar (PALSAR) dual-polarized (FBD) microwave images were used to extract urban land cover information by applying the decision tree method, and additional Advanced Space borne Thermal Emission and Reflection Radiometer Global Digital Elevation Model (ASTER/GDEM) was used to reduce the effects of mountains in Synthetic Aperture Radar (SAR) images due to high backscattering from urban construction land. A set of landscape metrics, such as landscape diversity, edge density and landscape shape indices with supplementary ecological meanings, were chosen to quantitatively analysis urban landscape patterns in arid environments. The overall accuracy assessment result was 91.50%, and the experimental results demonstrate that synergetic use of optical and SAR ALOS data has the potential and advantages for Arid Urban Region mapping, while the decision tree method showed intuitive simplicity and computational efficiency. The quantitative analysis results of landscape metrics showed that distribution of landscape types in Urumqi city were inhomogeneous, the urban landscape dominated by a few classes. Urbanization in this region has resulted in dramatic increases in patch density (PD), edge density (ED) and landscape shape complexity. © 2016, Springer-Verlag Berlin Heidelberg.","China; Urumqi; Xinjiang Uygur; ALOS; arid environment; ASTER; AVNIR; land cover; landscape structure; PALSAR; satellite data; urban ecosystem; urban planning; urbanization","Alos/Avnir-2; Alos/Palsar; Landscape metrics; Urban extraction; Urumqi city","Article","Final","","Scopus","2-s2.0-84965071500"
"Xu J.; Yu X.; Pei W.; Hu D.; Zhang L.","Xu, Jindong (35176864300); Yu, Xianchuan (12785792300); Pei, Wenjing (55195859000); Hu, Dan (36161111200); Zhang, Libao (35325855000)","35176864300; 12785792300; 55195859000; 36161111200; 35325855000","A remote sensing image fusion method based on feedback sparse component analysis","2015","Computers and Geosciences","85","","","115","123","8","10.1016/j.cageo.2015.09.022","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999715889&doi=10.1016%2fj.cageo.2015.09.022&partnerID=40&md5=2a52e0ce0fc78a25e3a0010faee0c081","We propose a new remote sensing image (RSI) fusion technique based on sparse blind source separation theory. Our method employs feedback sparse component analysis (FSCA), which can extract the original image in a step-by-step manner and is robust against noise. For RSIs from the China–Brazil Earth Resources Satellite, FSCA can separate useful surface feature information from redundant information and noise. The FSCA algorithm is therefore used to develop two RSI fusion schemes: one focuses on fusing high-resolution and multi-spectral images, while the other fuses synthetic aperture radar bands. The experimental results show that the proposed method can preserve spectral and spatial details of the source images. For certain evaluation indexes, our method performs better than classical fusion methods. © 2015 Elsevier Ltd","Blind source separation; Image analysis; Remote sensing; Spectroscopy; Synthetic aperture radar; Earth resources satellites; Evaluation index; Fusion techniques; High resolution; Multispectral images; Remote sensing images; Sparse component analysis; Surface feature; Image fusion","Blind source separation; Image fusion; Multi-spectral image; Remote sensing; Sparse component analysis; Synthetic aperture radar","Article","Final","","Scopus","2-s2.0-84999715889"
"Bechtel B.; See L.; Mills G.; Foley M.","Bechtel, Benjamin (37088140000); See, Linda (7006538249); Mills, Gerald (8907716700); Foley, Micheal (7102557235)","37088140000; 7006538249; 8907716700; 7102557235","Classification of local climate zones using SAR and multispectral data in an arid environment","2016","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","9","7","7442773","3097","3105","8","10.1109/JSTARS.2016.2531420","72","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963959027&doi=10.1109%2fJSTARS.2016.2531420&partnerID=40&md5=a656a8db21c7b3bc8ac3c29f54303531","There is an urgent need for more detailed spatial information on cities globally that has been acquired using a standard method to facilitate comparison and the transfer of scientific and practical knowledge between places. As part of the world urban database and access portal tools (WUDAPT) initiative, a simple workflow has been developed to perform this task. Using freely available satellite imagery (Landsat) and software (SAGA), WUDAPT characterizes settlements using the local climate zone (LCZ) scheme, which decomposes the city into distinctive neighborhoods (> 1km2 based on typical properties (e.g., green proportion and built fraction). In this paper, the methodology is extended to examine the effect of adding synthetic aperture radar (SAR) data, which is now freely available from Sentinel 1, for generating LCZs. Using the city of Khartoum as a case study, the results show that combining multispectral and SAR data improves the overall performance of several classifiers, with random forest (RF) performing the best overall. © 2008-2012 IEEE.","Khartoum [Khartoum (STT)]; Khartoum [Sudan]; Sudan; Decision trees; Radar imaging; Satellite imagery; Synthetic aperture radar; Arid environments; Local climate; Multi-spectral; Multi-spectral data; Portal tools; Random forests; Spatial informations; Typical properties; arid region; climate classification; image classification; Landsat; multispectral image; performance assessment; regional climate; remote sensing; satellite imagery; Sentinel; synthetic aperture radar; urban area; Space-based radar","Multisensor systems; remote sensing; satellite applications; synthetic aperture radar; urban areas","Article","Final","","Scopus","2-s2.0-84963959027"
"Schuster C.; Schmidt T.; Conrad C.; Kleinschmit B.; Förster M.","Schuster, Christian (57213135964); Schmidt, Tobias (57199319746); Conrad, Christopher (7102811204); Kleinschmit, Birgit (14321990600); Förster, Michael (55533645800)","57213135964; 57199319746; 7102811204; 14321990600; 55533645800","Grassland habitat mapping by intra-annual time series analysis -Comparison of RapidEye and TerraSAR-X satellite data","2015","International Journal of Applied Earth Observation and Geoinformation","34","1","","25","34","9","10.1016/j.jag.2014.06.004","119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907965453&doi=10.1016%2fj.jag.2014.06.004&partnerID=40&md5=135cd8cf5e58dc18a420cb1fb8e2d7ed","Remote sensing concepts are needed to monitor open landscape habitats for environmental change and biodiversity loss. However, existing operational approaches are limited to the monitoring of European dryheaths only. They need to be extended to further habitats. Thus far, reported studies lack the exploitation of intra-annual time series of high spatial resolution data to take advantage of the vegetations' phenolog-ical differences. In this study, we investigated the usefulness of such data to classify grassland habitats ina nature reserve area in northeastern Germany. Intra-annual time series of 21 observations were used,acquired by a multi-spectral (RapidEye) and a synthetic aperture radar (TerraSAR-X) satellite system, to differentiate seven grassland classes using a Support Vector Machine classifier. The classification accuracy was evaluated and compared with respect to the sensor type - multi-spectral or radar - and the numberof acquisitions needed. Our results showed that very dense time series allowed for very high accuracy classifications (>90%) of small scale vegetation types. The classification for TerraSAR-X obtained similar accuracy as compared to RapidEye although distinctly more acquisitions were needed. This study intro-duces a new approach to enable the monitoring of small-scale grassland habitats and gives an estimate of the amount of data required for operational surveys. © 2014 Elsevier B.V.","Germany; grassland; habitat; mapping; multispectral image; nature reserve; satellite data; TerraSAR-X; time series analysis","Feature selection; Natura 2000; RapidEye; Semi-natural grassland habitats; TerraSAR-X; Time series","Article","Final","","Scopus","2-s2.0-84907965453"
"Barbieux K.; Charitsi A.; Merminod B.","Barbieux, Kévin (57190170746); Charitsi, Antigoni (57201321657); Merminod, Bertrand (6603170065)","57190170746; 57201321657; 6603170065","Icy lakes extraction and water-ice classification using Landsat 8 OLI multispectral data","2018","International Journal of Remote Sensing","39","11","","3646","3678","32","10.1080/01431161.2018.1447165","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044279392&doi=10.1080%2f01431161.2018.1447165&partnerID=40&md5=55412e1fb8ab2c5985e672074ca56f29","We present an algorithm discriminating ice from open water on icy lakes using multispectral data from Landsat 8. Lakes are first extracted from the images using a new radiometric index coined ILI (Icy Lakes Index) which uses the stability of the reflectance of water and ice in the shortwave infrared bands. Quantitative comparisons to state-of-the-art indexes such as the Modified Normalised Difference Water Index (MNDWI) or the Water Ratio Index (WRI) show the ILI separates mixed ice/water bodies from land better than the current indexes, consistently achieving kappa coefficients (κ) above 0.93 with manually labelled reference data. Additionally, these results suggest that the ILI has a very high optimal threshold stability, compared to other indexes. In the delineated lake area, we perform a supervised classification with a decision tree using radiometric properties, but also texture properties such as the local standard deviations and average gradients in each band. A key feature of this classification is the Water-Ice Classification Index (WICI), also texture-based, which discriminates shallow water from ice efficiently. We prove the robustness of our classification algorithm by comparing its results to manually digitised reference data, but also to concurrent Sentinel-1 Synthetic Aperture Radar (SAR) data in the case of Lake Ladoga. In both cases, the comparison leads to κ ranging from 0.84 to 0.97. © 2018 Informa UK Limited, trading as Taylor & Francis Group.","Lake Ladoga; Russian Federation; Classification (of information); Decision trees; Extraction; Ice; Inspection; Lakes; Radiometry; Space-based radar; Synthetic aperture radar; Classification algorithm; Local standard deviation; Multi-spectral data; Quantitative comparison; Radiometric indices; Short wave infrared; Supervised classification; Texture properties; algorithm; glacial lake; Landsat; multispectral image; open water; supervised classification; synthetic aperture radar; Data mining","","Article","Final","","Scopus","2-s2.0-85044279392"
"Verhegghen A.; Eva H.; Ceccherini G.; Achard F.; Gond V.; Gourlet-Fleury S.; Cerutti P.O.","Verhegghen, Astrid (52664629200); Eva, Hugh (6603680187); Ceccherini, Guido (55820856400); Achard, Frederic (7004609951); Gond, Valery (6603641900); Gourlet-Fleury, Sylvie (6508332597); Cerutti, Paolo Omar (25225195300)","52664629200; 6603680187; 55820856400; 7004609951; 6603641900; 6508332597; 25225195300","The potential of sentinel satellites for burnt area mapping and monitoring in the Congo Basin forests","2016","Remote Sensing","8","12","986","","","","10.3390/rs8120986","115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019769220&doi=10.3390%2frs8120986&partnerID=40&md5=c1d84011d553128f00c55aab2c264656","In this study, the recently launched Sentinel-2 (S2) optical satellite and the active radar Sentinel-1 (S1) satellite supported by active fire data from the MODIS sensor were used to detect and monitor forest fires in the Congo Basin. In the context of a very strong El Niño event, an unprecedented outbreak of fires was observed during the first months of 2016 in open forests formations in the north of the Republic of Congo. The anomalies of the recent fires and meteorological situation compared to historical data show the severity of the drought. Burnt areas mapped by the S1 SAR and S2 Multi Spectral Instrument (MSI) sensors highlight that the fires occurred mainly in Marantaceae forests, characterized by open tree canopy cover and an extensive tall herbaceous layer. The maps show that the origin of the fires correlates with accessibility to the forest, suggesting an anthropogenic origin. The combined use of the two independent and fundamentally different satellite systems of S2 and S1 captured an extent of 36,000 ha of burnt areas, with each sensor compensating for the weakness (cloud perturbations for S2, and sensitivity to ground moisture for S1) of the other. © 2016 by the authors.","Deforestation; Forestry; Satellites; Space-based radar; Synthetic aperture radar; Burnt areas; Republic of Congo; Sentinel-1; Sentinel-2; Tropical rain forest; Fires","Burnt areas; Fires; Logging roads; Republic of Congo; Sentinel-1; Sentinel-2; Tropical rainforests","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85019769220"
"Bigdeli B.; Pahlavani P.","Bigdeli, Behnaz (35098378600); Pahlavani, Parham (15042866900)","35098378600; 15042866900","Quad-polarized synthetic aperture radar and multispectral data classification using classification and regression tree and support vector machine-based data fusion system","2017","Journal of Applied Remote Sensing","11","1","016007","","","","10.1117/1.JRS.11.016007","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009450715&doi=10.1117%2f1.JRS.11.016007&partnerID=40&md5=f4a1f92b759e95c991683b29d1512bfc","Interpretation of synthetic aperture radar (SAR) data processing is difficult because the geometry and spectral range of SAR are different from optical imagery. Consequently, SAR imaging can be a complementary data to multispectral (MS) optical remote sensing techniques because it does not depend on solar illumination and weather conditions. This study presents a multisensor fusion of SAR and MS data based on the use of classification and regression tree (CART) and support vector machine (SVM) through a decision fusion system. First, different feature extraction strategies were applied on SAR and MS data to produce more spectral and textural information. To overcome the redundancy and correlation between features, an intrinsic dimension estimation method based on noise-whitened Harsanyi, Farrand, and Chang determines the proper dimension of the features. Then, principal component analysis and independent component analysis were utilized on stacked feature space of two data. Afterward, SVM and CART classified each reduced feature space. Finally, a fusion strategy was utilized to fuse the classification results. To show the effectiveness of the proposed methodology, single classification on each data was compared to the obtained results. A coregistered Radarsat-2 and WorldView-2 data set from San Francisco, USA, was available to examine the effectiveness of the proposed method. The results show that combinations of SAR data with optical sensor based on the proposed methodology improve the classification results for most of the classes. The proposed fusion method provided approximately 93.24% and 95.44% for two different areas of the data. © 2017 Society of Photo-Optical Instrumentation Engineers (SPIE).","Data fusion; Data handling; Forestry; Independent component analysis; Principal component analysis; Radar imaging; Regression analysis; Remote sensing; Space-based radar; Support vector machines; Synthetic aperture radar; Trees (mathematics); Classification and regression tree; Classification results; Correlation between features; Intrinsic dimension estimation; Multi-spectral; Optical remote sensing; Sensor fusion; Textural information; Classification (of information)","classification and regression tree; multispectral; sensor fusion; support vector machine; synthetic aperture radar","Article","Final","","Scopus","2-s2.0-85009450715"
"Baque R.; Du Plessis O.R.; Castet N.; Fromage P.; Martinot-Lagarde J.; Nouvel J.-F.; Oriot H.; Angelliaume S.; Brigui F.; Cantalloube H.; Chanteclerc M.; Dubois-Fernandez P.; Dupuis X.; Martineau P.","Baque, Rémi (36069113000); Du Plessis, Olivier Ruault (23492206700); Castet, Nicolas (57201852505); Fromage, Patrick (15064087200); Martinot-Lagarde, Joseph (52464045300); Nouvel, Jean-François (6602299637); Oriot, Hélène (6603289678); Angelliaume, Sébastien (23017892200); Brigui, Frédéric (35075788700); Cantalloube, Hubert (6602747764); Chanteclerc, Martine (6505728352); Dubois-Fernandez, Pascale (6603435799); Dupuis, Xavier (8366163700); Martineau, Philippe (7007044874)","36069113000; 23492206700; 57201852505; 15064087200; 52464045300; 6602299637; 6603289678; 23017892200; 35075788700; 6602747764; 6505728352; 6603435799; 8366163700; 7007044874","SETHI / RAMSES-NG new performances of the flexible multi-spectral airborne remote sensing research platform","2017","IET Conference Publications","2017","CP728","","","","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048667581&partnerID=40&md5=5db09449d2b7810d994d9ed9fc4c2a2f","SETHI is an airborne SAR/GMTI system developed by the French Aerospace Lab. ONERA, and integrating various sensors. In 2016 ONERA invested in upgrade and improvement of all SETHI components. The microwave ones cover from VHF-UHF to X Band, full polarimetric and very high resolution, along track and cross track interferometry and very high precision multi-baseline capacity for interferometry and tomography applications. The optronic sensors offer very high spatial resolution visible images and fine spectral scene analysis in VNIR and SWIR bands. This paper presents the upgrade and new performances of this flexible platform and the qualification campaign results with various sensor configurations. © 2017 Institution of Engineering and Technology. All rights reserved.","Interferometry; Radar systems; Surface discharges; Synthetic aperture radar; Airborne remote sensing; Flexible platforms; Moving target detection; Optronic; Sensor configurations; Tomography applications; Very high resolution; Very high spatial resolutions; Remote sensing","Moving target detection; Optronic; Remote sensing; SAR; Tracking; Very High Resolution","Conference paper","Final","","Scopus","2-s2.0-85048667581"
"Liu G.; Li L.; Gong H.; Jin Q.; Li X.; Song R.; Chen Y.; Chen Y.; He C.; Huang Y.; Yao Y.","Liu, Guang (48461511700); Li, Lei (57756339800); Gong, Hui (57220602239); Jin, Qingwen (57192237377); Li, Xinwu (57208284748); Song, Rui (55760765100); Chen, Yun (57193090033); Chen, Yu (56200332700); He, Chengxin (7402285036); Huang, Yuqing (25622974300); Yao, Yuefeng (37115053700)","48461511700; 57756339800; 57220602239; 57192237377; 57208284748; 55760765100; 57193090033; 56200332700; 7402285036; 25622974300; 37115053700","Multisource remote sensing imagery fusion scheme based on bidimensional empirical mode decomposition (BEMD) and its application to the extraction of bamboo forest","2017","Remote Sensing","9","1","19","","","","10.3390/rs9010019","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010637355&doi=10.3390%2frs9010019&partnerID=40&md5=6022a6e7480c7dcadd375b003c11a7eb","Most bamboo forests grow in humid climates in low-latitude tropical or subtropical monsoon areas, and they are generally located in hilly areas. Bamboo trunks are very straight and smooth, which means that bamboo forests have low structural diversity. These features are beneficial to synthetic aperture radar (SAR) microwave penetration and they provide special information in SAR imagery. However, some factors (e.g., foreshortening) can compromise the interpretation of SAR imagery. The fusion of SAR and optical imagery is considered an effective method with which to obtain information on ground objects. However, most relevant research has been based on two types of remote sensing image. This paper proposes a new fusion scheme, which combines three types of image simultaneously, based on two fusion methods: bidimensional empirical mode decomposition (BEMD) and the Gram-Schmidt transform. The fusion of panchromatic and multispectral images based on the Gram-Schmidt transform can enhance spatial resolution while retaining multispectral information. BEMD is an adaptive decomposition method that has been applied widely in the analysis of nonlinear signals and to the nonstable signal of SAR. The fusion of SAR imagery with fused panchromatic and multispectral imagery using BEMD is based on the frequency information of the images. It was established that the proposed fusion scheme is an effective remote sensing image interpretation method, and that the value of entropy and the spatial frequency of the fused images were improved in comparison with other techniques such as the discrete wavelet, à-trous, and non-subsampled contourlet transform methods. Compared with the original image, information entropy of the fusion image based on BEMD improves about 0.13-0.38. Compared with the other three methods it improves about 0.06-0.12. The average gradient of BEMD is 4%-6% greater than for other methods. BEMD maintains spatial frequency 3.2-4.0 higher than other methods. The experimental results showed the proposed fusion scheme could improve the accuracy of bamboo forest classification. Accuracy increased by 12.1%, and inaccuracy was reduced by 11.0%. © 2016 by the authors; licensee MDPI, Basel, Switzerland.","Bamboo; Decay; Forests; Image Analysis; Remote Sensing; Adaptive optics; Bamboo; Extraction; Forestry; Image enhancement; Image fusion; Image reconstruction; Remote sensing; Synthetic aperture radar; Textures; Adaptive decomposition; BEMD; Bi dimensional empirical mode decomposition (BEMD); Gram-Schmidt transform; Multi-spectral imagery; Multisources; Non-sub-sampled contourlet transforms; Remote sensing image interpretations; Radar imaging","Bamboo extraction; BEMD; Extraction; Multisource remote sensing; Texture","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85010637355"
"Choe B.-H.; Tornabene L.L.; Osinski G.R.; Newman J.D.","Choe, Byung-Hun (57200605479); Tornabene, Livio L. (6506431379); Osinski, Gordon R. (6603659506); Newman, Jennifer D. (57206913567)","57200605479; 6506431379; 6603659506; 57206913567","Remote Predictive Mapping of the Tunnunik Impact Structure in the Canadian Arctic using Multispectral and Polarimetric SAR Data Fusion","2018","Canadian Journal of Remote Sensing","44","5","","513","531","18","10.1080/07038992.2018.1544846","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060731925&doi=10.1080%2f07038992.2018.1544846&partnerID=40&md5=b8bb862acfb1fb10814a3f2107bcb7b8","The 28-km diameter Tunnunik impact structure in northern Victoria Island, Arctic Canada, was mapped using ASTER, Landsat 8, RADARSAT-2 polarimetric synthetic aperture radar (SAR), and Quickbird data. Multispectral analysis was accomplished through band ratios, MNF transform, and spectral matching algorithms, from which 4 distinct spectral units were defined. Polarimetric SAR decompositions also showed different scattering mechanisms for these 4 units indicating different surface roughness properties. These multispectral and polarimetric SAR observations were combined with detailed surface textures and morphological features as visible in very high-resolution Quickbird imagery (61 cm/pixel). Remote sensing parameters and their thresholds for characterizing each unit were implemented into a decision-tree algorithm and a remote predictive geological map was produced. Subsequent field and follow-up laboratory investigations enabled the ground-truthing of these predictions. The geological units were defined as follows: (i) (smooth) fluvioglacial deposits, (ii) (moderately rough) chert-bearing dolostone, (iii) (rough) dolostone, and (iv) (rough) dolostone covered by silicified surfaces. The rough surfaces characterized by multiple scattering in the polarimetric SAR decomposition correspond to the occurrences of weathered carbonate rocks, which are relatively resistant to weathering and form blocky surfaces. This shows that SAR-derived surface roughness properties can greatly contribute to defining geological units by combining with lithological mapping. © 2019, Copyright © CASI.","Data fusion; Data mining; Decision trees; Forestry; Lithology; Mapping; Polarimeters; Radar imaging; Remote sensing; Surface roughness; Surface scattering; Textures; Trees (mathematics); Weathering; Decision-tree algorithm; Laboratory investigations; Morphological features; Multi-spectral analysis; Polarimetric SAR data; Polarimetric synthetic aperture radars; Scattering mechanisms; Spectral matching algorithms; Synthetic aperture radar","","Article","Final","","Scopus","2-s2.0-85060731925"
"Imperatore P.; Azar R.; Calo F.; Stroppiana D.; Brivio P.A.; Lanari R.; Pepe A.","Imperatore, Pasquale (24314931400); Azar, Ramin (55796260500); Calo, Fabiana (16052312800); Stroppiana, Daniela (12760994800); Brivio, Pietro Alessandro (7003737933); Lanari, Riccardo (7003896636); Pepe, Antonio (7003776958)","24314931400; 55796260500; 16052312800; 12760994800; 7003737933; 7003896636; 7003776958","Effect of the Vegetation Fire on Backscattering: An Investigation Based on Sentinel-1 Observations","2017","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","10","10","7972961","4478","4492","14","10.1109/JSTARS.2017.2717039","43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023180866&doi=10.1109%2fJSTARS.2017.2717039&partnerID=40&md5=f0e1daf595425735dceeede57daaedb9","This paper aims at investigating the potential of Sentinel-1 C-band synthetic aperture radar (SAR) observations for detecting fire scars in vegetated areas at regional scale. A comprehensive analysis of the backscattering coefficients is carried out. The experimental analysis is conducted by analyzing the scenario of the Sardinia Island, which is one of the Italian regions most affected by fire events over the summer season. The detection capability of fire scars in such an environment is demonstrated by exploiting information extracted from dual-polarized SAR data. Our results reveal a significant decrease of the VH response over the fire-disturbed forests, thus, highlighting the effectiveness of such cross-polarized observations. In order to prove the validity of the proposed approach for the detection of fire scars in the vegetation layer, the results of the conducted experiments have been suitably compared with burned areas identified by using an existing fuzzy-based algorithm, which has been applied to multispectral Landsat-8 operational land imager data. This investigation opens the way to systematic methods for monitoring fire scars in heterogeneous environments, and in particular in fire-prone Mediterranean ecosystems. © 2008-2012 IEEE.","Italy; Sardinia; Backscattering; Fires; Radar; Space-based radar; Vegetation; Backscattering coefficients; Comprehensive analysis; Experimental analysis; Heterogeneous environments; Mediterranean ecosystem; Multi-spectral; Operational land imager; Sentinel-1; algorithm; fire; Landsat; Sentinel; synthetic aperture radar; vegetation dynamics; Synthetic aperture radar","Burned vegetation; electromagnetic backscattering; Landsat-8 operational land imager (OLI); multispectral; Sentinel-1 (S1); synthetic aperture radar (SAR)","Article","Final","","Scopus","2-s2.0-85023180866"
"Huang G.; Sun Y.; Zhao Z.","Huang, Guoman (35233640500); Sun, Yue (57202049009); Zhao, Zheng (55726185500)","35233640500; 57202049009; 55726185500","The feasibility evaluation of land use change detection using Gaofen-3 data","2018","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","3","","587","593","6","10.5194/isprs-archives-XLII-3-587-2018","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046936919&doi=10.5194%2fisprs-archives-XLII-3-587-2018&partnerID=40&md5=945d4f88d0695ed6097ec01ee26e5c0e","GaoFen-3(GF-3) satellite, is the first C band and multi-polarimetric Synthetic Aperture Radar (SAR) satellite in China. In order to explore the feasibility of GF-3 satellite in remote sensing interpretation and land-use remote sensing change detection, taking Guangzhou, China as a study area, the full polarimetric image of GF-3 satellite with 8 m resolution of two temporal as the data source. Firstly, the image is pre-processed by orthorectification, image registration and mosaic, and the land-use remote sensing digital orthophoto map (DOM) in 2017 is made according to the each county. Then the classification analysis and judgment of ground objects on the image are carried out by means of ArcGIS combining with the auxiliary data and using artificial visual interpretation, to determine the area of changes and the category of change objects. According to the unified change information extraction principle to extract change areas. Finally, the change detection results are compared with 3 m resolution TerraSAR-X data and 2 m resolution multi-spectral image, and the accuracy is evaluated. Experimental results show that the accuracy of the GF-3 data is over 75% in detecting the change of ground objects, and the detection capability of new filling soil is better than that of TerraSAR-X data, verify the detection and monitoring capability of GF-3 data to the change information extraction, also, it shows that GF-3 can provide effective data support for the remote sensing detection of land resources. © Authors 2018.","Artificial intelligence; Data mining; Image registration; Information retrieval; Land use; Object detection; Polarimeters; Quality control; Satellites; Space-based radar; Spectroscopy; Synthetic aperture radar; Change detection; Gaofen-3; High resolution; Polarimetric SAR; Quality evaluation; Remote sensing","Change Detection; Gaofen-3; High-resolution; Land Use; Polarimetric SAR; Quality Evaluation","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85046936919"
"Reigber A.; Krogager E.; Keller M.; Jäger M.; Hajnsek I.; Horn R.","Reigber, Andreas (7003334243); Krogager, Ernst (6603452841); Keller, Martin (55576352500); Jäger, Marc (56693942100); Hajnsek, Irena (57204342098); Horn, Ralf (56210101500)","7003334243; 6603452841; 55576352500; 56693942100; 57204342098; 56210101500","The DALO-ARCTIC campaign: Multi-spectral SAR imaging of ice features in Greenland","2016","Proceedings of the European Conference on Synthetic Aperture Radar, EUSAR","","","7559298","","","","","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001115467&partnerID=40&md5=d71892d1f2f3a6417e8bc39f5ce4b73a","In May 2015, the Danish Defence Acquisition and Logistics Organization (DALO) together with the German Aerospace Center (DLR) conducted the joint DALO-ARCTIC airborne SAR campaign with the F-SAR sensor over several testsites in Greenland. Principal goal of this campaign was to demonstrate the capabilities of SAR for security applications in arctic environments, as well as to investigate various advanced methods for extracting ice and snow parameters from SAR data. During this campaign, the ability of F-SAR to simultaneously record fully-polarimetric SAR data in several frequency bands was used for the first time on a large scale. Due to the significantly varying penetration depth of the different bands into ice and snow, it is of particular interest to understand and analyse what can be seen in each band and what are the dominating scattering processes. This paper will discuss this based on examples of polarimetric multi-band imaging of ice and snow layers from data acquired during the DALO-ARCTIC campaign. In this way, the huge potential of multi-spectral SAR imaging for the analysis of ice bodies will be demonstrated. © VDE VERLAG GMBH · Berlin · Offenbach.","Frequency bands; Ice; Polarimeters; Radar; Snow; Synthetic aperture radar; Airborne SAR; Arctic environments; Defence acquisitions; Fully polarimetric SAR; German aerospace centers; Multi-spectral; Scattering process; Security application; Radar imaging","","Conference paper","Final","","Scopus","2-s2.0-85001115467"
"Yang H.; Zhao C.; Yang G.; Li Z.; Chen E.; Yuan L.; Yang X.; Xu X.","Yang, Hao (56957326900); Zhao, Chunjiang (55724676300); Yang, Guijun (55501651300); Li, Zengyuan (8719489000); Chen, Erxue (8719488800); Yuan, Lin (56957543200); Yang, Xiaodong (56336392100); Xu, Xingang (14032384000)","56957326900; 55724676300; 55501651300; 8719489000; 8719488800; 56957543200; 56336392100; 14032384000","Agricultural crop harvest progress monitoring by fully polarimetric synthetic aperture radar imagery","2015","Journal of Applied Remote Sensing","9","1","096076","","","","10.1117/1.JRS.9.096076","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924785743&doi=10.1117%2f1.JRS.9.096076&partnerID=40&md5=e108c567436df09edc988242ccec93f0","Dynamic mapping and monitoring of crop harvest on a large spatial scale will provide critical information for the formulation of optimal harvesting strategies. This study evaluates the feasibility of C-band polarimetric synthetic aperture radar (PolSAR) for monitoring the harvesting progress of oilseed rape (Brassica napus L.) fields. Five multitemporal, quad-pol Radarsat-2 images and one optical ZY-1 02C image were acquired over a farmland area in China during the 2013 growing season. Typical polarimetric signatures were obtained relying on polarimetric decomposition methods. Temporal evolutions of these signatures of harvested fields were compared with the ones of unharvested fields in the context of the entire growing cycle. Significant sensitivity was observed between the specific polarimetric parameters and the harvest status of oilseed rape fields. Based on this sensitivity, a new method that integrates two polarimetric features was devised to detect the harvest status of oilseed rape fields using a single image. The validation results are encouraging even for the harvested fields covered with high residues. This research demonstrates the capability of PolSAR remote sensing in crop harvest monitoring, which is a step toward more complex applications of PolSAR data in precision agriculture. © 2015 Society of Photo-Optical Instrumentation Engineers.","Crops; Harvesting; Oilseeds; Polarimeters; Remote sensing; Synthetic aperture radar; Time series; Tracking radar; Brassica Napus L; Complex applications; Multi-spectral data; Polarimetric decomposition; Polarimetric features; Polarimetric parameters; Polarimetric synthetic aperture radars; Radarsat-2; Radar imaging","Brassica napus L; polarimetric decomposition; Radarsat-2; remote sensing; time series; ZY-1 02C multispectral data","Article","Final","","Scopus","2-s2.0-84924785743"
"Sridhara Murthi K.R.; Rao M.K.","Sridhara Murthi, K.R. (8627886200); Rao, Mukund Kadursrinivas (56732282300)","8627886200; 56732282300","In emerging eo newspace global markets - Challenges for Indian remote sensing systems","2018","Proceedings of the International Astronautical Congress, IAC","2018-October","","","","","","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065333674&partnerID=40&md5=862c2c5743781c1bf0f13dc4283d18d4","Indian Remote Sensing (IRS) satellites have been providing various types of IRS images wide-field and high repeat multi-spectral images; moderate resolution multi-spectral data; high resolution panchromatic and multi-spectral image products; panchromatic stereo images; Synthetic Aperture Radar (SAR) data; ocean colour images, scatterometer data and many others. The data are received at Indian station and also at polar receiving stations data is processed and disseminated from the processing centre at Hyderabad. Within India, IRS images are priced low and are widely used; across the world the use of IRS images are through cooperative arrangements. The average turnaround for moderate- or high-resolution images is 7-10 days. A Remote Sensing Data Policy (RSDP) defines the scheme for IRS data dissemination to users in India. Globally EO business in NewSpace era have not only been commercial but have gone e-image portals bringing high efficiency using advanced image processing and internet technologies. Spurred by US DigitalGlobe and WorldView, French SPOT, European Sentinel, other commercial systems like Rapideye, Planet etc, global EO is now focussed on high-demand geospatial markets and providing high resolution panchromatic/multi-spectral images with very high cadence/frequency of global coverage AND real-time image availability. The trend is for IMAGES ANYTIME ANYWHERE with real-time geo-rectification, seaming, organising and making available images as they stream or within 24-48 hours of image acquisition. Google offers online Landsat image archive from 1980 onwards for immediate access. These global developments in EO imaging and dissemination can be â€œdisrupting to IRS"" even as Indian EO is making significant shifts by continued space segment deployments strengthening of ground segment and online Bhuvan geoportal - all for â€œeasier access"" by users. The characters of NewSpace EO developments have not been fully addressed in the IRS environment and fragmented nature of value generation is becoming glaringly apparent. In a highly subsidised environment and lack of competitive business models, IRS could easily slip-down to an â€œaverage national endeavour"" and loose impact in the global NewSpace environment. We assess markets of traditionally strong national programmes - like IRS that will need re-definition to be able to compete and be relevant in the NewSpace era. The paper assesses the evolutionary trends and market opportunities for IRS, maintaining â€œleadership"" in EO, need for win-win relation between government and Indian industry, deregulation of IRS data access for energising industry and even licensing private Indian EO systems. This paper presents a strategic analysis of NewSpace implications for IRS. Copyright © 2018 by the International Astronautical Federation.","Deregulation; International trade; Iridium; Meteorological instruments; Radar imaging; Real time systems; Remote sensing; Space optics; Space-based radar; Spectroscopy; Synthetic aperture radar; Competitive business; Cooperative arrangements; High resolution image; Indian EO future; Market opportunities; Multispectral images; NewSpace impact; Remote sensing system; Stereo image processing","Indian EO future; IRS; IRS Markets; NewSpace impact","Conference paper","Final","","Scopus","2-s2.0-85065333674"
"Iervolino P.; Guida R.; Ayesh-Meagher A.","Iervolino, Pasquale (55305269200); Guida, Raffaella (22234096000); Ayesh-Meagher, Amelia (57203095635)","55305269200; 22234096000; 57203095635","Land classification using a novel multispectral and SAR data fusion in Doha area","2018","Proceedings of the European Conference on Synthetic Aperture Radar, EUSAR","2018-June","","","512","516","4","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050508709&partnerID=40&md5=0fdd1916a94346a41ce2812bea593e8f","A new algorithm for land classification is presented in this paper and is based on the fusion of Multispectral, Panchromatic and Synthetic Aperture Radar (SAR) images. The novel approach relies on Generalized Intensity-Hue-Saturation (G-HIS) transform and the Wavelet Transform (WT). The fused image is derived by modulating the SAR texture with the high features details of the Panchromatic WT and by injecting this product at the place of G-HIS high feature details. Finally, a classification is performed on the fused product by using a Maximum Likelihood (ML) classifier. The algorithm has been tested on data acquired by Sentinel-1 (SAR) and Landsat-8 (Multispectral and Panchromatic) over the area of Greater Doha in Qatar in 2017. Results show an increment of 3% in the overall accuracy for the fused product compared to the Multispectral dataset. © VDE VERLAG GMBH Â Berlin Â Offenbach.","Data fusion; Maximum likelihood; Radar imaging; Wavelet transforms; Fused images; Intensity hue saturations; LANDSAT; Maximum likelihood classifiers; Multi-spectral; Overall accuracies; Sentinel-1; Synthetic aperture radar (SAR) images; Synthetic aperture radar","","Conference paper","Final","","Scopus","2-s2.0-85050508709"
"Havivi S.; Schvartzman I.; Maman S.; Marinoni A.; Gamba P.; Rotman S.R.; Blumberg D.G.","Havivi, S. (57190382855); Schvartzman, I. (56829437100); Maman, S. (37111154200); Marinoni, A. (23018988200); Gamba, P. (7007165803); Rotman, S.R. (7005613682); Blumberg, D.G. (26642986200)","57190382855; 56829437100; 37111154200; 23018988200; 7007165803; 7005613682; 26642986200","Utilizing SAR and multispectral integrated data for emergency response","2016","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","41","","","493","496","3","10.5194/isprsarchives-XLI-B7-493-2016","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979561908&doi=10.5194%2fisprsarchives-XLI-B7-493-2016&partnerID=40&md5=f0c7384e3bcc91caac8a9cf6342c2d2c","Satellite images are used widely in the risk cycle to understand the exposure, refine hazard maps and quickly provide an assessment after a natural or man-made disaster. Though there are different types of satellite images (e.g. optical, radar) these have not been combined for risk assessments. The characteristics of different remote sensing data type may be extremely valuable for monitoring and evaluating the impacts of disaster events, to extract additional information thus making it available for emergency situations. To base this approach, two different change detection methods, for two different sensor's data were used: Coherence Change Detection (CCD) for SAR data and Covariance Equalization (CE) for multispectral imagery. The CCD provides an identification of the stability of an area, and shows where changes have occurred. CCD shows subtle changes with an accuracy of several millimetres to centimetres. The CE method overcomes the atmospheric effects differences between two multispectral images, taken at different times. Therefore, areas that had undergone a major change can be detected. To achieve our goals, we focused on the urban areas affected by the tsunami event in Sendai, Japan that occurred on March 11, 2011 which affected the surrounding area, coastline and inland. High resolution TerraSAR-X (TSX) and Landsat 7 images, covering the research area, were acquired for the period before and after the event. All pre-processed and processed according to each sensor. Both results, of the optical and SAR algorithms, were combined by resampling the spatial resolution of the Multispectral data to the SAR resolution. This was applied by spatial linear interpolation. A score representing the damage level in both products was assigned. The results of both algorithms, high level of damage is shown in the areas closer to the sea and shoreline. Our approach, combining SAR and multispectral images, leads to more reliable information and provides a complete scene for the emergency response following an event.","Coherent light; Data fusion; Disasters; Emergency services; Equalizers; Hazards; Remote sensing; Risk assessment; Signal detection; Space-based radar; Synthetic aperture radar; Atmospheric effects; Change detection; Covariance equalization; Linear Interpolation; Multi-spectral imagery; Multidimensional data; Multispectral images; Natural hazard; Radar imaging","Change detection; Coherence; Covariance equalization; Multi-dimensional data fusion; Natural hazards","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84979561908"
"Parkes S.; McClements C.; McLaren D.; Florit A.F.; Villafranca A.G.","Parkes, Steve (7005187836); McClements, Chris (6508235564); McLaren, David (36816060900); Florit, Albert Ferrer (16645308700); Villafranca, Alberto Gonzalez (23020220400)","7005187836; 6508235564; 36816060900; 16645308700; 23020220400","SpaceFibre: A multi-Gigabit/s interconnect for spacecraft onboard data handling","2015","IEEE Aerospace Conference Proceedings","2015-June","","7119317","","","","10.1109/AERO.2015.7119317","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940707411&doi=10.1109%2fAERO.2015.7119317&partnerID=40&md5=7829b977732b5e4ee1904d9556e6df59","SpaceFibre is a spacecraft onboard data link and network technology being developed by University of Dundee for the European Space Agency (ESA), which runs over both copper and fibre optic cables. Initially targeted at very high data rate payloads such as Synthetic Aperture Radar (SAR) and multi-spectral imaging instruments, SpaceFibre is capable of fulfilling a wider set of spacecraft onboard communications applications because of its inbuilt QoS and FDIR capabilities and its backwards compatibility with the ubiquitous SpaceWire technology. SpaceFibre operates at 2.5 Gbits/s providing 12 times the throughput of a SpaceWire link with current flight qualified technology and allowing data from multiple SpaceWire devices to be concentrated over a single SpaceFibre link. This substantially reduces cable harness mass and simplifies redundancy strategies. The innovative QoS mechanism in SpaceFibre provides concurrent bandwidth reservation, priority and scheduled QoS. This simplifies spacecraft system engineering through integrated quality of service (QoS), which reduces system engineering costs and streamlines integration and test. Novel integrated FDIR support provides galvanic isolation, transparent recovery from transient errors, error containment in virtual channels and frames, and 'Babbling Idiot' protection. SpaceFibre enhances onboard network robustness through its inherent FDIR and graceful degradation techniques incorporated in the network hardware. This simplifies system FDIR software, reducing development and system validation time and cost. SpaceFibre includes low latency event signalling and time distribution with broadcast messages. This enables a single network to be used for several functions including: transporting very high data rate payload data, carrying SpaceWire traffic, deterministic delivery of command/control information, time distribution and event signalling. SpaceFibre is backwards compatible with existing SpaceWire equipment at the packet level allowing simple interconnection of SpaceWire devices into a SpaceFibre network and enabling that equipment to take advantage of the QoS and FDIR capabilities of SpaceFibre. © 2015 IEEE.","Cables; Cost engineering; Cost reduction; Data handling; Networks (circuits); Quality of service; Space flight; Spacecraft; Spectroscopy; Synthetic aperture radar; Systems engineering; FDIR; Next generation interconnect; Onboard data handling; Spacefibre; SpaceWire; Space-based radar","FDIR; Network; Next generation interconnect; Quality of service; Spacecraft onboard data-handling; Spacefibre; Spacewire","Conference paper","Final","","Scopus","2-s2.0-84940707411"
"Chen B.; Gong H.; Li X.; Lei K.; Gao M.; Zhou C.; Ke Y.","Chen, Beibei (55818653400); Gong, Huili (35240287700); Li, Xiaojuan (55718181400); Lei, Kunchao (43361409600); Gao, Mingliang (55585533800); Zhou, Chaofan (56384686300); Ke, Yinghai (35784422100)","55818653400; 35240287700; 55718181400; 43361409600; 55585533800; 56384686300; 35784422100","Spatial–temporal evolution patterns of land subsidence with different situation of space utilization","2015","Natural Hazards","77","3","","1765","1783","18","10.1007/s11069-015-1674-1","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930374850&doi=10.1007%2fs11069-015-1674-1&partnerID=40&md5=216a01678ac64a00015aa96f627febbb","Long-term over-exploitation of underground water, static and dynamic load is increasing year by year, which influenced the occurrence and development of regional land subsidence in Beijing, China. We used Envisat advanced synthetic aperture radar data acquired from 2003 to 2009 and PSI (persistent scatterers for SAR interferometry) and small baseline technology to estimate regional land subsidence information in Beijing, China. In different situation of space utilization, we chose five typical settlement areas according to classified information of land-use, multi-spectral remote sensing images and geological data. We analyzed the time-series evolution characteristics of uneven subsidence by GIS spatial analysis. The comparative analysis results suggest that for five typical settlement areas, the complex situations of space utilization affect the trend of uneven subsidence, the simpler space utilization situation (relatively fewer transport lines, construction), the smaller settlement differences and the smaller trend of the uneven subsidence. © 2015, Springer Science+Business Media Dordrecht.","Beijing [China]; China; Envisat; remote sensing; space use; spatial analysis; subsidence; synthetic aperture radar; temporal evolution","Evolution pattern; GIS; InSAR; Land subsidence","Article","Final","","Scopus","2-s2.0-84930374850"
"Zakeri H.; Yamazaki F.; Liu W.","Zakeri, Homa (57194007097); Yamazaki, Fumio (35857807800); Liu, Wen (57210953131)","57194007097; 35857807800; 57210953131","Texture analysis and land cover classification of tehran using polarimetric synthetic aperture radar imagery","2017","Applied Sciences (Switzerland)","7","5","452","","","","10.3390/app7050452","37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019222212&doi=10.3390%2fapp7050452&partnerID=40&md5=04881953cabf4e1cdaa61c23ca2edc42","Land cover classification of built-up and bare land areas in arid or semi-arid regions from multi-spectral optical images is not simple, due to the similarity of the spectral characteristics of the ground and building materials. However, synthetic aperture radar (SAR) images could overcome this issue because of the backscattering dependency on the material and the geometry of different surface objects. Therefore, in this paper, dual-polarized data from ALOS-2 PALSAR-2 (HH, HV) and Sentinel-1 C-SAR (VV, VH) were used to classify the land cover of Tehran city, Iran, which has grown rapidly in recent years. In addition, texture analysis was adopted to improve the land cover classification accuracy. In total, eight texture measures were calculated from SAR data. Then, principal component analysis was applied, and the first three components were selected for combination with the backscattering polarized images. Additionally, two supervised classification algorithms, support vector machine and maximum likelihood, were used to detect bare land, vegetation, and three different built-up classes. The results indicate that land cover classification obtained from backscatter values has better performance than that obtained from optical images. Furthermore, the layer stacking of texture features and backscatter values significantly increases the overall accuracy. © 2017 by the authors.","","Land cover; Maximum likelihood; Supervised classification; Support vector machine; Synthetic aperture radar (SAR) imagery; Tehran; Texture measures","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85019222212"
"Delgado Blasco J.M.; Verstraeten G.; Hanssen R.F.","Delgado Blasco, José Manuel (57192664765); Verstraeten, Gert (6603775264); Hanssen, Ramon F. (7004324889)","57192664765; 6603775264; 7004324889","Detecting modern desert to urban transitions from space in the surroundings of the Giza World Heritage site and Greater Cairo","2017","Journal of Cultural Heritage","23","","","71","78","7","10.1016/j.culher.2016.10.014","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007273757&doi=10.1016%2fj.culher.2016.10.014&partnerID=40&md5=78d66c0e46e0ed5606f64a8173ea1727","During the last decades, Greater Cairo, Egypt, is increasing in population and in built-up extension. Some of the new buildings are informal, constructed in absence of government planning processes, and threaten the Heritage Cultural Site of the Giza Pyramids. In addition, the fertile land of the Nile floodplain is being urbanized despite the government's building prohibition since the 1990s. Therefore, constant monitoring of construction activity is crucial in the rapidly changing environment of this area. Here, we present a data fusion approach that overcomes the limitations of single medium resolution sensor approaches, and also identifies areas in transition from desert to urban. We use multi-temporal multi-sensor supervised land use classification and include a new land use class for detecting undefined disturbances. Synthetic aperture radar (SAR) data is combined with multi-spectral data for creating the land use land cover (LULC) maps using artificial neural networks (ANN). Specifically, ERS SAR data is combined with Landsat 5TM for 1998 and Envisat ASAR IMS with Landsat 7 ETM+ for 2004 and 2010. With this data fusion approach, it is measured an increase of 73% of Greater Cairo built-up extent from 1998 to 2010. Finally, we show the relationship between the aforementioned disturbances and the new built-up areas, detecting 26% of the total new built-up areas constructed from 1998 to 2010 where undefined disturbances were identified in previous land use maps. © 2016 Elsevier Masson SAS","","Data fusion; Giza; Greater Cairo; Land use classification; Landsat; SAR; Urban expansion","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85007273757"
"Baqué R.; Du Plessis O.R.; Dreuillet P.; Frédéric Y.-M.","Baqué, Rémi (36069113000); Du Plessis, Olivier Ruault (23492206700); Dreuillet, Philippe (55976490000); Frédéric, Yves-Michel (35179220900)","36069113000; 23492206700; 55976490000; 35179220900","SETHI and RAMSES-NG flexible multi-spectral airborne remote sensing research platforms","2017","2016 CIE International Conference on Radar, RADAR 2016","","","8059303","","","","10.1109/RADAR.2016.8059303","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029324454&doi=10.1109%2fRADAR.2016.8059303&partnerID=40&md5=c0d92407d10160110dea0154f0b5c89c","SEHI and RAMSES-NG are airborne SAR systems developed by the French Aerospace Lab. ONERA, and integrating various sensors. The microwave ones cover from VHF-UHF to X Band, full polarimetric and very high resolution, along track and cross track interferometry and very high precision multi-baseline capacity for interferometry and tomography applications. The optronic sensors offer very high spatial resolution visible images and fine spectral scene analysis in VNIR and SWIR bands. This paper presents the flexible capacity of these platforms and last campaign results with various sensor configurations. © 2016 IEEE.","Interferometry; Radar; Synthetic aperture radar; Airborne remote sensing; Moving target detection; Optronic; Research platforms; Sensor configurations; Tomography applications; Very high resolution; Very high spatial resolutions; Remote sensing","Moving target detection and tracking; Optronic; Remote sensing; SAR; Very High Resolution","Conference paper","Final","","Scopus","2-s2.0-85029324454"
"Merkle N.; Müller R.; Reinartz P.","Merkle, N. (57194604557); Müller, R. (7404246697); Reinartz, P. (56216874200)","57194604557; 7404246697; 56216874200","Registration of optical and SAR satellite images based on geometric feature templates","2015","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","40","1W5","","447","452","5","10.5194/isprsarchives-XL-1-W5-447-2015","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974536576&doi=10.5194%2fisprsarchives-XL-1-W5-447-2015&partnerID=40&md5=0657dffb3aa3f27ae704d1bd6cf5986b","Image registration is required for different remote sensing applications, like change detection or image fusion. Since research studies have shown the outstanding absolute geometric accuracy of high resolution radar satellites images like TerraSAR-X, the importance of SAR images as source for geolocation enhancement has increased. Due to this fact, multi-sensor image to image registration of optical and SAR images can be used for the improvement of the absolute geometric processing and accuracy of optical ima ges with TerraSAR-X as reference. In comparison to the common optical and SAR image registration methods the proposed method is a combination of intensity-based and feature-based approaches. The proposed method avoids the direct and often difficult detection of features from the SAR images. SAR-like templates are generated from features detected from the optical image. These templates are used for an intensity-based matching with the SAR image. The results of the matching process are ground control points, which are used for the estimation of translation parameters followed by a subpixel translation of the optical image. The proposed image registration method is tested for two pairs of TerraSAR-X and QuickBird images and one pair of TerraSAR-X andWorldView-2 i mages of a suburban area. The results show that with the proposed method the geometric accuracy of optical images can be enhanced.","Feature extraction; Geometrical optics; Geometry; Image fusion; Image matching; Image processing; Image registration; Remote sensing; Rock mechanics; Satellites; Space-based radar; Synthetic aperture radar; Image; Matching; Multi sensor; Multi-spectral; Optical; Registration; Radar imaging","Image; Matching; Multisensor; Multispectral; Optical; Registration; SAR","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84974536576"
"Li J.; Zhao Y.; Dai J.; Zhu H.","Li, Jiahui (57207584746); Zhao, Youxin (57207583826); Dai, Jiguang (36677171900); Zhu, Hong (57226096239)","57207584746; 57207583826; 36677171900; 57226096239","Coastal zone classification based on multisource remote sensing imagery fusion","2018","Journal of Sensors","2018","","5902318","","","","10.1155/2018/5902318","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062633930&doi=10.1155%2f2018%2f5902318&partnerID=40&md5=0a200faf0ac9f78db3faec8c13304e02","The main objective of this paper was to assess the capability of multisource remote sensing imagery fusion for coastal zone classification. Five scenes of Gaofen- (GF-) 1 optic imagery and four scenes of synthetic aperture radar (SAR) (C-band Sentinel-1 and L-band ALOS-2) imagery were collected and matched. Note that GF-1 is the first satellite of the China high-resolution earth observation system, which acquires multispectral data with decametric spatial resolution, high temporal resolution, and wide coverage. The results showed that based on the comparison of C- and L-band SAR for coastal coverage, it is verified that C band is superior to L band and parameter subsets of σ0vv, σ0vh, and Dcross can be effectively used for coastal classification. A new fusion method based on the wavelet transform (WT) was also proposed and used for imagery fusion. Statistical values for the mean, entropy, gradient, and correlation coefficient of the proposed method were 67.526, 7.321, 6.440, and 0.955, respectively. We therefore conclude that the result of our proposed method is superior to GF-1 imagery and traditional HIS fusion results. Finally, the classification output was determined along with an assessment of classification accuracy and kappa coefficient. The kappa coefficient and overall accuracy of the classification were 0.8236 and 85.9774%, respectively, so the proposed fusion method had a satisfying performance for coastal coverage mapping. © 2018 Jiahui Li et al.","Coastal zones; Image classification; Radar imaging; Synthetic aperture radar; Wavelet transforms; Classification accuracy; Correlation coefficient; Earth observation systems; High temporal resolution; Multi-spectral data; Remote sensing imagery; Spatial resolution; Zone classifications; Remote sensing","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85062633930"
"Parkes S.; McClements C.; McLaren D.; Florit A.F.; Villafranca A.G.","Parkes, Steve (7005187836); McClements, Chris (6508235564); McLaren, David (36816060900); Florit, Albert Ferrer (16645308700); Villafranca, Alberto Gonzalez (23020220400)","7005187836; 6508235564; 36816060900; 16645308700; 23020220400","Spacefibre: The standard, simulation, IP cores and test equipment","2015","European Space Agency, (Special Publication) ESA SP","SP-732","","","","","","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943530100&partnerID=40&md5=c88c6ecc9a35666817d70bfd1779ce37","SpaceFibre is an emerging new standard for spacecraft on-board data-handling networks. Initially targeted to deliver multi-Gbit/s data rates for synthetic aperture radar and high-resolution, multi-spectral imaging instruments, SpaceFibre has developed into a unified network technology that integrates high bandwidth, with low latency, quality of service (QoS) and fault detection, isolation and recovery (FDIR). Furthermore SpaceFibre is backwards compatible with the widely used SpaceWire standard at the network level allowing simple interconnection of existing SpaceWire equipment to a SpaceFibre link or network. Developed by the University of Dundee for the European Space Agency (ESA) SpaceFibre is able to operate over fibre-optic and electrical cable and supports data rates of 2 Gbit/s in the near future and up to 5 Gbit/s long-term. Multi-laning improves the data-rate further to well over 20 Gbits/s. This paper details the current state of SpaceFibre which is now in the process of formal standardisation by the European Cooperation for Space Standardization (ECSS). It describes the SpaceFibre IP core being developed for ESA. The design of a SpaceFibre demonstration board is introduced and available SpaceFibre test and development equipment is described. The way in which several SpaceWire links can be concentrated over a single SpaceFibre link will be explained.","Data handling; Equipment testing; Fault detection; Intellectual property core; International cooperation; Internet protocols; Quality of service; Space flight; Spectroscopy; Standardization; Synthetic aperture radar; Electrical cables; European cooperation for space standardizations; European Space Agency; Isolation and recoveries; Multispectral imaging; Network technologies; Onboard data handling; Test equipments; Space-based radar","","Conference paper","Final","","Scopus","2-s2.0-84943530100"
"Stewart C.; Oren E.D.; Cohen-Sasson E.","Stewart, Christopher (57195356114); Oren, Eliezer D. (24515736400); Cohen-Sasson, Eli (57203097232)","57195356114; 24515736400; 57203097232","Satellite remote sensing analysis of the Qasrawet archaeological site in North Sinai","2018","Remote Sensing","10","7","1090","","","","10.3390/rs10071090","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050492192&doi=10.3390%2frs10071090&partnerID=40&md5=ab584a2c6cbfd764d8c73d6b2cdf9df1","North Sinai is of significant historical interest primarily because of its role since late prehistoric times as a land bridge between Egypt and the Levant. Access to this region is challenging due to its harsh geography and security concerns. Remote sensing constitutes a convenient method for archaeological prospection and monitoring over such regions with its low cost (relative to ground based sensing techniques), global coverage, and high temporal and spatial sampling. This paper describes part of a study to revisit a number of sites investigated during the North Sinai Survey (1972-1982) with very high resolution optical and Synthetic Aperture Radar satellite imagery. These were acquired throughout the summer of 2017 in the framework of a European Space Agency research project. The Synthetic Aperture Radar data includes Spotlight and Staring Spotlight modes of the TerraSAR-X mission, while the optical imagery was acquired by the Pleiades mission. The TerraSAR-X data were processed to derive filtered amplitude and consecutive coherence time series. The results of the TerraSAR-X data processing, and the pan-sharpened Pleiades data were compared with the results of the North Sinai Survey to detect possible additional buried structures in the radar data, or newly excavated sites in the optical data. While the analysis is still ongoing, results are reported here of the Qasrawet archaeological site, which was partially investigated by the North Sinai Survey expedition, but assumed to cover a much larger area. Herein, a number of newly excavated structures are apparent in the remote sensing data. The similarity of features in both the TerraSAR-X and Pleiades data suggest that all structures are surface residues, and therefore, that the subsurface mapping capabilities of the TerraSAR-X data in this area are limited. The utility of both data types for archaeological site monitoring are discussed. © 2018 by the authors.","Architecture; Data handling; History; Remote sensing; Satellite imagery; Space optics; Surveys; Synthetic aperture radar; Archaeology; Desert; Multi-spectral; North Sinai; PLEIADES; Prospection; Qasrawet; TerraSAR-X; Space-based radar","Archaeology; Desert; Multispectral; North Sinai; North Sinai Survey; Pleiades; Prospection; Qasrawet; SAR; TerraSAR-X","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85050492192"
"Vaduva C.; Danisor C.; Datcu M.","Vaduva, Corina (25032255600); Danisor, Cosmin (56540042300); Datcu, Mihai (7004523124)","25032255600; 56540042300; 7004523124","Temporal analysis of SAR imagery for permanent and evolving Earth land cover behavior assessment","2017","2017 9th International Workshop on the Analysis of Multitemporal Remote Sensing Images, MultiTemp 2017","","","8035260","","","","10.1109/Multi-Temp.2017.8035260","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032358593&doi=10.1109%2fMulti-Temp.2017.8035260&partnerID=40&md5=09c4ded4c8d42f26570be5bd527ff5e4","In the era of constantly increasing Earth Observation (EO) data collections, information extraction and data analysis should be enhanced with a multi-temporal component enabled by the temporal resolution of satellite missions and create handy, yet powerful tools for those applications involving monitoring of land cover. The image time series, as results of the satellite revisiting period, gives you insights not only on a certain area, but also on its representation at different moments of time. In order to limit the issues that might arise due to irregular time sampling of multispectral data, the authors propose a Synthetic Aperture Radar (SAR) image time series for analysis. To this point, the main goal is to mine the satellite image time series (SITS) for understanding the temporal behaviour of an area in terms of evolution and persistency. The paper introduces an analytical approach, combining coherent and no coherent analysis of SAR SITS content. We propose the Latent Dirichlet Allocation model to extract categories of evolution from the SAR SITS and techniques which study statistical and coherent proprieties of the targets to identify the structures with stable electromagnetic characteristics over time, named Persistent Scatterers (PS). The obtained results indicate an evolutionary character hidden inside the persistent class. The results obtained on 30 ERS images encourages further analysis on Sentinel 1 data. © 2017 IEEE.","Data mining; Image analysis; Information analysis; Remote sensing; Satellites; Space-based radar; Statistics; Synthetic aperture radar; Time series; Time series analysis; Categories of evolution; Earth observation data; Electromagnetic characteristic; Latent Dirichlet allocation; Multi-spectral data; Persistent scatterers; SAR Images; Synthetic aperture radar (SAR) images; Radar imaging","Categories of evolution; Latent Dirichlet Allocation; Persistent Scatterers; SAR image time series","Conference paper","Final","","Scopus","2-s2.0-85032358593"
"Thushari H.N.; Manawadu L.","Thushari, Halpegamage Nadeeka (57194040551); Manawadu, Lasantha (55356018400)","57194040551; 55356018400","Flood monitoring in Gampaha district using SAR data as a case study in the lower basin in Attanagalu oya (River)","2018","Proceedings - 39th Asian Conference on Remote Sensing: Remote Sensing Enabling Prosperity, ACRS 2018","4","","","2476","2485","9","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071835852&partnerID=40&md5=b448df64af65048d63593d5a6e7ec26b","Radar image data find special application in flood monitoring due to their properties of all weather, day/night and cloud-piercing capabilities. However, the classification and object extraction of radar image are very difficult because their imaging mechanism is quite different from that of multi spectral image. One of the largest limitations of radar automated classification is the occurrence of speckle noise. ALOS satellite obtained PALSAR radar data during floods by the emergency observation requests. The PALSAR data can easily detect the water surface because its wave length is L-band. Flood on 18th May 2010 at Attanagalu Oya basin in Gampaha District, Sri Lanka, shows the effectiveness and efficiency of this method. The results of the analysis were timely provided to the central and local governments to help them to make decision on the reduction of flood disasters. Remote sensing methods based on optical, medium resolution imagery, such as Landsat and SPOT, are limited in their applicability. This paper presents and compares a few techniques using remote sensing data which are used to flood mapping & eventually used to analyze flood propagation. Geometric correction and typical noise smoothing methods of the PALSAR data are used here and with the “not enough satisfaction” of speckle reduction, one more reduction method called wavelet thresholding was applied. The resulting images almost coincide with the reported flood regions. Fusion of satellite images with different spatial and spectral resolutions plays here an important role in visualizing information effectively. GIS relate technologies are very useful in flood monitoring and damage evaluation. In this study, GIS & Remote Sensing provide a better evaluation that useful for understanding overall situation & in an emergency rapid response to global disasters like flood is firmly established and flood monitoring has become an easy task with the advent of the said technology. © 2018 Proceedings - 39th Asian Conference on Remote Sensing: Remote Sensing Enabling Prosperity, ACRS 2018","Data flow analysis; Data reduction; Disasters; Feature extraction; Floods; Geographic information systems; Radar; Radar imaging; Space-based radar; Speckle; Spectroscopy; Synthetic aperture radar; ALOS PALSAR; Automated classification; Effectiveness and efficiencies; Geometric correction; Multispectral images; Special applications; Speckle reduction; Wavelet thresholding; Remote sensing","ALOS PALSAR; Radar; Remote Sensing; Speckle Reduction","Conference paper","Final","","Scopus","2-s2.0-85071835852"
"Gargiulo F.; Angelino C.V.; Cicala L.; Persechino G.; Lega M.","Gargiulo, Francesco (55984041900); Angelino, Cesario Vincenzo (24778070500); Cicala, Luca (8304895700); Persechino, Giuseppe (16646461800); Lega, Massimiliano (26023394400)","55984041900; 24778070500; 8304895700; 16646461800; 26023394400","Remote sensing in the fight against environmental crimes: The case study of the cattle-breeding facilities in southern Italy","2016","International Journal of Sustainable Development and Planning","11","5","","663","671","8","10.2495/SDP-V11-N5-663-671","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991585417&doi=10.2495%2fSDP-V11-N5-663-671&partnerID=40&md5=ffae184c934efd65aa8a43e0b59a7d66","Enforcement of environmental regulation is a persistent challenge and timely detection of the violations is key to holding the violators accountable. The use of remote sensing data is becoming an effective practice in the fight against environmental crimes. In this work, a novel and effective approach for the detection of potentially hazardous cattle-breeding facilities, exploiting both synthetic aperture radar and optical multispectral data together with geospatial analyses in the geographic information system (GIS) environment, is proposed. Experiments on data available for the area of Caserta (Southern Italy), show that the proposed technique provides very high detection capability, up to 90%, with a acceptable false alarm rate, becoming a useful tool in the hand of agencies engaged in the protection of territory. © 2016 WIT Press.","Campania [Italy]; Caserta; Italy; Bos; Crime; Data fusion; Environmental regulations; Geographic information systems; Hazards; Image analysis; Synthetic aperture radar; Detection capability; Effective approaches; Environmental crimes; Environmental hazards; Geo-spatial analysis; Multi-spectral data; Multisensor data fusion; Multispectral images; cattle; crime; dairy farming; data processing; detection method; environmental hazard; environmental planning; GIS; hazard assessment; image analysis; multispectral image; remote sensing; synthetic aperture radar; Remote sensing","Environmental hazard detection; GIS; Image analysis; Multisensor data fusion; Multispectral images; Remote sensing; SAR","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-84991585417"
"Affaitati F.; Muñoz I.","Affaitati, Francesco (55847572600); Muñoz, Isidro (55811004300)","55847572600; 55811004300","State of copernicus and the sentinels a flight dynamics operational prospective","2018","2018 AIAA SPACE and Astronautics Forum and Exposition","","","AIAA 2018-5338","","","13","10.2514/6.2018-5338","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056166964&doi=10.2514%2f6.2018-5338&partnerID=40&md5=af4f30eebb47aa8188580e3b888fe368","On April 25th 2018 Sentinel 3B was launched toward its orbit. The event marked an important milestone on the Copernicus project because the first constellation of Sentinels satellites get completed. Just after four years form the first Sentinel 1A launch, seven satellites have been put into operations to complete the prime Space Segment of the Copernicus Project. Copernicus is the most ambitious Earth observation program to date. It provides accurate, timely and easily accessible information to improve the management of the environment, understand and mitigate the effects of climate change and ensure civil security. Copernicus is the new name for the Global Monitoring for Environment and Security program, previously known as GMES. This initiative is headed by the European Commission (EC) in partnership with the European Space Agency (ESA). Sentinel 1 constellation, a polar orbiting twin satellite mission equipped with C-band synthetic aperture radar, was launched on April the 3rd 2014 and April the 25th 2016 with a Soyuz rocket from Europe's Spaceport in French Guiana. Sentinel2 constellation, a polar orbiting two satellite mission equipped with multispectral high-resolution imaging mission for land monitoring was launched Sentinel 2A on 23rd of June 2015 and Sentinel-2B followed on 7th of March 2017. Sentinel 3 constellation, twin satellites always in polar orbit, 180° apart, carrying four instruments that work in synergy, a multi-spectral band instrument, a temperature radiometer, a radar altimeter, and a microware radiometer, was first delivered to Space on February the 16th 2016 and the twin satellite the 25th of April 2018. Least but not last Sentinel 5P, the Precursor of the future Sentinel 5 constellation, was launched in October the 13th 2017, with a Rockot launcher from Plesetsk, Russia. Currently all are in operations delivering valid and precious science data to the User Community. In fact most of the prime Copernicus services have been activated and relay on precise, continuous and reliable data from Sentinels satellites, among other data (third-party satellites, ground instruments, etc). The federation of seven satellites have been delivered under the control of the European Space Operation Center located here in Darmstadt, making use of different launch pads and rockets, but sharing the same Ground Segment infrastructure. For all Sentinel satellites ESOC took care of the LEOP operations and early commissioning. In most of the cases ESOC is also responsible of the routine operations; Sentinel 3 constellation is with EUMETSAT operation center located always in Darmstadt. The ESOC Flight Dynamics Unit then delivered the LEOP flight dynamic services for all Sentinels and it is currently operating all Sentinels under ESOC control in routine phase. It is therefore time for our Copernicus Flight Dynamics Unit to evaluate and compare retrospectively all operations done so far during LEOP and routine phase. In this paper we will start form a general overview of each Sentinel constellation to highlight commonalities and peculiarities of each Sentinel from Flight Dynamics prospective. Not all satellites are the same. Facts and Figures of each constellation are briefly reported highlighting elements which are driving risk assessment and costs in operations. Finally operations across Sentinels are compared, in particular orbit maintenance maneuvers and Space Debris operations. Some considerations of the LEOP operations are highlighted which are driving factor in defining an orbit injection and a reference orbit acquisition plan, in particular trade-off between reliability and cost-effective operations. And with the same emphasis some aspects of our Space Debris policy and procedures are analyzed, which are today a limiting factor in reducing costs in operations. © 2018, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.","Climate change; Cost effectiveness; Earth (planet); Economic and social effects; Flight dynamics; Observatories; Orbits; Radiometers; Risk assessment; Rockets; Satellites; Space applications; Space debris; Space flight; Synthetic aperture radar; Copernicus; Earth observation programs; Earth observations; European space operation centers; Global Monitoring for Environment and Security; High-resolution imaging; LEOP operations; Sentinels; Space-based radar","Copernicus; Earth observation; Flight dynamics; LEOP operations; Sentinels; Space debris","Conference paper","Final","","Scopus","2-s2.0-85056166964"
"Li W.","Li, Weiguo (26664080400)","26664080400","Growth monitoring of winter wheat based on optical remote sensing and SAR data fusion","2016","37th Asian Conference on Remote Sensing, ACRS 2016","1","","","149","154","5","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018986086&partnerID=40&md5=1642e8c9c89b98cc593d90fd5f53e999","Multi-spectral remote sensing image in combination with radar image are conducive to the south area of extraction and crop growth monitoring. This study used three cities about Baoying, Gaoyou and Xinghua in the centre of Jiangsu Province in China as the study area, and made the Landsat / TM image and ERS/SAR image fusion in the winter wheat early jointing period, and then explored the remote sensing method of winter wheat planted area extraction. Based on the Optimum Index Factor (OIF) and spectral separability, selected bands 3-4-5 combination as the best band to classify. The traditional pixel-based classification results vulnerable to ""the feature in different spectrum"" and ""foreign feature with the spectrum"" effects. This study used object-oriented image classification approach with an object as a procession unit, and combined with a wealth of features in space, texture information for wheat area extraction, and then compared with pixel-based classification method (SVM classification) results. The results show the classification accuracy of SVM and object-oriented classification method is 78.59% and 94.16%, respectively. The object-oriented classification method can accurately extract the planting area of winter wheat, which is much better than the SVM classification method. Based on the extraction of winter wheat planting area, this study also monitored the winter wheat growth, and availably obtained the data and spatial distribution information of winter wheat in these counties. This method can give a technical support for the winter wheat planting area and growth information rapid access in the South China.","Classification (of information); Crops; Data fusion; Extraction; Image fusion; Image processing; Image reconstruction; Pixels; Radar imaging; Space optics; Space-based radar; Synthetic aperture radar; Classification accuracy; Classification approach; Growth conditions; Object oriented classification; Optical remote sensing; Pixel based classifications; Remote sensing images; Winter wheat; Remote sensing","Data fusion; Growth condition; Object-oriented classification; Winter wheat","Conference paper","Final","","Scopus","2-s2.0-85018986086"
"Anat R.; Samuel A.; Waizman G.; Tsodikovich D.; Tfilin S.; Cotti J.; Feingersh T.","Anat, Rockah (57191575848); Samuel, A. (57204342008); Waizman, G. (57191574791); Tsodikovich, D. (57191573029); Tfilin, S. (57191575744); Cotti, J. (57492728900); Feingersh, T. (6507356342)","57191575848; 57204342008; 57191574791; 57191573029; 57191575744; 57492728900; 6507356342","ASIF - Automated system for image fusion","2015","Proceedings of the International Astronautical Congress, IAC","7","","","4888","4894","6","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991579904&partnerID=40&md5=b67d223df89056a6c5b0742d66dfbbde","Remote sensing involves various types of sensors that scan earth's surface and produce images containing diverse types of information. Each sensor provides unique data that is transformed to information from the scene. We are presenting here a software tool called ASIF (Automated System for image fusion) which automatically combines each sensor's data into one synergistic combination of imagery (a fused image). With ASIF the user can quickly generate a single image containing the fused data instead of investigating several images, providing a new way of observing convenient information at a region of interest. ASIF, as an integrating tool of EO (Electro-Optical) and SAR (Synthetic Aperture Radar) images provides fused information from the images. It performs optimal pre-processing algorithms for overcoming the difficulties in combining different contexts. Every optimized process was evolved after an extensive research on a diverse group of EO-SAR datasets. The fusion optimization is oriented for visual interpretation enhancement based on: surface, objects and infrastructures. ASIF involves state of the art image and signal processing steps that estimate the required processing of inputs in an adaptive manner, oriented for optimal results for visual human perception and analysis. These handle automatically all required geometric and radiometric pre-processing stages. The fusion modes are determined by the input EO-SAR images that are available over the requested fegion of interest. Input data may be: panchromatic EO, RGB only EO, multi-spectral EO, multi- polarized SAR, multi-frequency and multi-Temporal SAR data. At each resulting fusion product we reveal the latent added value of its member input images, in order to get resolution improvement, data certainty, objects detection and verification, change detection, completion of details and so on. ASIF system allows a new interesting interpretation product that resolves open questions that rise from the surface and provides us a comprehensive view of it. It provides us opportunities that better exploit the use of the sensors' data beyond the conventional and straightforward understanding. © 2015 by the American Institute Federation of Aeronautics and Astronautics. Inc. All rights reserved.","Adaptive optics; Automation; Data fusion; Image fusion; Image processing; Image segmentation; Reconfigurable hardware; Remote sensing; Sensor data fusion; Signal processing; Space-based radar; Synthetic aperture radar; Fusion optimization; Multi-temporal SAR; Pre-processing algorithms; Region of interest; Resolution improvement; SAR(synthetic aperture radar); Synergistic combinations; Visual interpretation; Radar imaging","","Conference paper","Final","","Scopus","2-s2.0-84991579904"
"Wang X.L.; Chen C.X.","Wang, X.L. (57188693490); Chen, C.X. (56867778200)","57188693490; 56867778200","Image fusion for synthetic aperture radar and multispectral images based on sub-bandmodulated non-subsampled contourlet transform and pulse coupled neural network methods","2016","Imaging Science Journal","64","2","","87","93","6","10.1080/13682199.2015.1136101","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962240757&doi=10.1080%2f13682199.2015.1136101&partnerID=40&md5=6a01bdd427596dc6c8676a9ea39d3c76","Fusion of synthetic aperture radar (SAR) and multispectral (MS) images can contribute to a better visual perception of the objects observed. Unfortunately, many classical approaches have been proven to be unsuitable for this task due to their intrinsic differences in imaging mechanism. In the non-subsampled contourlet transform domain, an alternative fusion method based on pulse coupled neural networks is proposed. To control the amount of SAR features to be integrated into MS image, a gradient-threshold combined modulation is designed for modulating the SAR sub-band coefficients. Experiments demonstrate that the proposed method outperforms its counterparts in spectral preservation and feature enhancement. © 2016 The Royal Photographic Society.","Image enhancement; Image fusion; Neural networks; Object recognition; Radar; Radar imaging; Combined modulation; Feature enhancement; Gradient thresholds; Intrinsic differences; Multi-spectral; Multispectral images; Non-sub-sampled contourlet transforms; Pulse coupled neural network; Synthetic aperture radar","Image fusion; Multispectral; Non-subsampled contourlet transform; Pulse coupled neural networks; Synthetic aperture radar","Article","Final","","Scopus","2-s2.0-84962240757"
