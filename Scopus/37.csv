"Authors","Author full names","Author(s) ID","Titles","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","DOI","Cited by","Link","Abstract","Indexed Keywords","Author Keywords","Document Type","Publication Stage","Open Access","Source","EID"
"Kirillov S.N.; Pokrovskij P.S.; Baukov A.A.; Skonnikov P.N.","Kirillov, S.N. (7007036382); Pokrovskij, P.S. (57190179225); Baukov, A.A. (37009669100); Skonnikov, P.N. (57205464791)","7007036382; 57190179225; 37009669100; 57205464791","Multispectral image processing algorithms for enhanced vision systems in the Arctic","2019","IOP Conference Series: Earth and Environmental Science","302","1","012063","","","","10.1088/1755-1315/302/1/012063","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071858611&doi=10.1088%2f1755-1315%2f302%2f1%2f012063&partnerID=40&md5=6c9d392e32ecca7746d4eb61dd7b4284","The issues of enhanced vision multispectral systems application for robotic complexes control in the Arctic are considered. The existing contrast enhancement methods are observed. Probability characteristics of images being subject to contrast enhancement parameters are estimated. Based on these characteristics, the authors concluded that image areas requiring the greatest contrast enhancement are the areas with low saturation and magnitude gradients, at certain brightness values. Image quality improvement method is proposed. It performs processing only in the areas where it is necessary to enhance the contrast, practically without affecting the most homogeneous or structured image parts. The processed image saturation remains due to the processing of both luminance channel and saturation channel. The algorithm proposed also provides contrast enhancement of shaded image areas. The calculated values of various objective image quality indices indicate that the contrast enhancement algorithm proposed provides better results than known approaches. In addition, different spectral range image fusion algorithm ensuring visibility in the presence of interfering factors is proposed. It differs from known methods by adaptive weight adjustment in different areas of image. The example confirming the effectiveness of the fusion method proposed is shown. For its comparison with known methods, the values of fusion objective quality indices are calculated. The fusion algorithm proposed is shown to surpass known methods by various quality assessments. The conclusion about the expediency of using the algorithms developed in technical vision systems of robotic complexes in the Arctic is made. © Published under licence by IOP Publishing Ltd.","Image fusion; Image quality; Luminance; Robotics; Contrast Enhancement; Enhanced vision systems; Image quality improvements; Multispectral image processing; Multispectral systems; Objective image quality; Objective qualities; Saturation channels; Image enhancement","","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85071858611"
"Siewert S.; Angoth V.; Krishnamurthy R.; Mani K.; Mock K.; Singh S.B.; Srivistava S.; Wagner C.; Claus R.; Vis M.D.","Siewert, Sam (57195443863); Angoth, Vivek (43660976300); Krishnamurthy, Ramnarayan (57191199882); Mani, Karthikeyan (57191203216); Mock, Kenrick (6603757736); Singh, Surjith B. (57191199476); Srivistava, Saurav (57191196417); Wagner, Chris (57225761574); Claus, Ryan (57191201053); Vis, Matthew Demi (57191205227)","57195443863; 43660976300; 57191199882; 57191203216; 6603757736; 57191199476; 57191196417; 57225761574; 57191201053; 57191205227","Software defined multi-spectral imaging for Arctic sensor networks","2016","Proceedings of SPIE - The International Society for Optical Engineering","9840","","98401V","","","","10.1117/12.2222966","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987892083&doi=10.1117%2f12.2222966&partnerID=40&md5=7c739a6288d8d6b0486586f919a3b9dd","Availability of off-the-shelf infrared sensors combined with high definition visible cameras has made possible the construction of a Software Defined Multi-Spectral Imager (SDMSI) combining long-wave, near-infrared and visible imaging. The SDMSI requires a real-time embedded processor to fuse images and to create real-time depth maps for opportunistic uplink in sensor networks. Researchers at Embry Riddle Aeronautical University working with University of Alaska Anchorage at the Arctic Domain Awareness Center and the University of Colorado Boulder have built several versions of a low-cost drop-in-place SDMSI to test alternatives for power efficient image fusion. The SDMSI is intended for use in field applications including marine security, search and rescue operations and environmental surveys in the Arctic region. Based on Arctic marine sensor network mission goals, the team has designed the SDMSI to include features to rank images based on saliency and to provide on camera fusion and depth mapping. A major challenge has been the design of the camera computing system to operate within a 10 to 20 Watt power budget. This paper presents a power analysis of three options: 1) multi-core, 2) field programmable gate array with multi-core, and 3) graphics processing units with multi-core. For each test, power consumed for common fusion workloads has been measured at a range of frame rates and resolutions. Detailed analyses from our power efficiency comparison for workloads specific to stereo depth mapping and sensor fusion are summarized. Preliminary mission feasibility results from testing with off-the-shelf long-wave infrared and visible cameras in Alaska and Arizona are also summarized to demonstrate the value of the SDMSI for applications such as ice tracking, ocean color, soil moisture, animal and marine vessel detection and tracking. The goal is to select the most power efficient solution for the SDMSI for use on UAVs (Unoccupied Aerial Vehicles) and other drop-in-place installations in the Arctic. The prototype selected will be field tested in Alaska in the summer of 2016. © 2016 SPIE.","Arctic vehicles; Budget control; Cameras; Computer graphics; Drops; Field programmable gate arrays (FPGA); Image fusion; Infrared detectors; Infrared devices; Infrared radiation; Logic gates; Mapping; Marine applications; Program processors; Reconfigurable hardware; Sensor networks; Soil moisture; Soil testing; Spectroscopy; Stereo vision; Arctic; Co-processors; Long wave infrared; Multi spectral imager; Near Infrared; Power efficient; Real time; Saliency; Sensor fusion; Stereo image processing","Arctic; Field programmable gate array; General purpose graphics coprocessor; Long-wave infrared; Multi-spectral imager; Near-infrared; Power efficient; Real-time; Saliency; Sensor fusion; Software defined; Stereo vision","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84987892083"
"Grohnfeldt C.H.","Grohnfeldt, Claas Hendrik (55946211600)","55946211600","Multi-sensor data fusion for multi- and Hyperspectral resolution enhancement based on sparse representations","2017","DLR Deutsches Zentrum fur Luft- und Raumfahrt e.V. - Forschungsberichte","2017-January","50","","1","201","200","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037543692&partnerID=40&md5=23f79f8eb8341089e0439f766372a299","Our world is subject to intense observation. Offshore zones, arctic areas, deserts, rainforests, rivers, agricultural land and cities are continuously monitored from space. There is no surface on Earth that goes unobserved by a remote sensing satellite. This transparency facilitates our modern life, offering seemingly inexhaustible opportunities. Yet, there are limits. Physical, technological and financial factors limit the development of sensors of ever-increasing accuracy. Trade-offs must be made. Optical imaging sensors compromise on either detailed spectral information, allowing for the discrimination of materials, or high spatial resolution, which elucidates the geometry of the scene. Multi-sensor data fusion mitigates these limitations. The idea is to combine complementary data of different spectral and spatial characteristics to construct products representative of an ""ideal"" synthetic sensor. This is an inherently ill-posed problem. The difficulty arises in maximizing both spatial and spectral resolutions, due to the number of degrees of freedom. This dissertation presents sophisticated solutions to two of the most demanding multi-sensor data fusion problems in remote sensing, namely pan-sharpening and the fusion of hyperspectral and multispectral data. Two algorithms are thoroughly designed and tailored to the respective problems, i.e., Jointly Sparse Fusion of Images (J-SparseFI) for pan-sharpening and Jointly Sparse Fusion of Hyperspectral and Multispectral Imagery (J-SparseFI-HM) for the fusion of hyperspectral and multispectral data. These severely ill-posed problems are handled by incorporating additional information, to reduce the inherent degrees of freedom and produce fusion products that better approximate the ground truth. The physical properties of the synthesized sensor are accounted for by a sensor observation model. Prior knowledge about image patches featuring sparse representations of suitable dictionaries is exploited to reduce the overall fusion problem to a large number of small, I1/2-regularized convex optimization problems. Prior information about the mutual correlation of adjacent multi- and hyperspectral channels is extensively used to robustify estimation accuracies. Both techniques leverage distributed compressive sensing theory, restricting the solution of an underdetermined system by considering a jointly sparse ensemble of signals. The J-SparseFI and J-SparseFI-HM algorithms are specifically tailored to their respective fusion problems. In J-SparseFI, a decision-based spectral and channel mutual correlation analysis is conducted to find suitable groups of multispectral channels and corresponding high-resolution source data for dictionary learning. J-SparseFI-HM incorporates a spatially adaptive Correlation-based HyperSpectral Grouping (CorHySpeG) concept and the data for dictionary learning is found via non-negative least squares regression. A novel alternating local-non-local-global optimization procedure is designed for J-SparseFI-HM, which enhances spatial consistency across individually processed patches and spectral consistency across group-wise processed hyperspectral channels. Highly parallel stand-alone software solutions are optimized for operation on the SuperMUC supercomputer of the Leibniz Supercomputing Center. Detailed parameter descriptions, sensitivity analyses and default setting recommendations are provided. The quality of the data fusion products is assessed and compared to the state-of-the-art in pan-sharpening and hyperspectral-multispectral image fusion, for a large variety of test scenarios and sensor combinations. This thesis comprehensively demonstrates that J-SparseFI and J-SparseFI-HM are new quality benchmarks for multiresolution multi-sensor data fusion.","Adaptive optics; Arid regions; Benchmarking; Convex optimization; Data fusion; Data handling; Degrees of freedom (mechanics); Economic and social effects; Euler equations; Global optimization; Image fusion; Mechanics; Optimization; Remote sensing; Sensitivity analysis; Signal processing; Signal reconstruction; Space optics; Supercomputers; Convex optimization problems; Hyperspectral Data; Joint sparse signals; Multi-spectral image fusions; Multisensor data fusion; Number of degrees of freedom; Resolution enhancement; Spectral and spatial characteristics; Sensor data fusion","Hyperspectral data processing; Joint sparse signal recovery; Multi-sensor data fusion; Remote sensing; Resolution enhancement; Signal processing","Article","Final","","Scopus","2-s2.0-85037543692"
"Witharana C.; Bhuiyan M.A.E.; Liljedahl A.K.; Kanevskiy M.; Epstein H.E.; Jones B.M.; Daanen R.; Griffin C.G.; Kent K.; Ward Jones M.K.","Witharana, Chandi (55453025500); Bhuiyan, Md Abul Ehsan (57213791557); Liljedahl, Anna K. (23091638200); Kanevskiy, Mikhail (12039350600); Epstein, Howard E. (7102707599); Jones, Benjamin M. (16636910800); Daanen, Ronald (22949833100); Griffin, Claire G. (56924571500); Kent, Kelcy (57216670596); Ward Jones, Melissa K. (57209825924)","55453025500; 57213791557; 23091638200; 12039350600; 7102707599; 16636910800; 22949833100; 56924571500; 57216670596; 57209825924","Understanding the synergies of deep learning and data fusion of multispectral and panchromatic high resolution commercial satellite imagery for automated ice-wedge polygon detection","2020","ISPRS Journal of Photogrammetry and Remote Sensing","170","","","174","191","17","10.1016/j.isprsjprs.2020.10.010","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094846781&doi=10.1016%2fj.isprsjprs.2020.10.010&partnerID=40&md5=c0d38cee5866370c29f0a6c79242cea7","The utility of sheer volumes of very high spatial resolution (VHSR) commercial imagery in mapping the Arctic region is new and actively evolving. Commercial satellite sensors typically record image data in low-resolution multispectral (MS) and high-resolution panchromatic (PAN) mode. Spatial resolution is needed to accurately describe feature shapes and textural patterns, such as ice-wedge polygons (IWPs) that are rapidly transforming surface features due to degrading permafrost, while spectral resolution allows capturing of land-use and land-cover types. Data fusion, the process of combining PAN and MS images with complementary characteristics often serves as an integral component of remote sensing mapping workflows. The fusion process generates spectral and spatial artifacts that may affect the classification accuracies of subsequent automated image analysis algorithms, such as deep learning (DL) convolutional neural nets (CNN). We employed a detailed multidimensional assessment to understand the performances of an array of eight application-oriented data fusion algorithms when applied to VHSR image scenes for DLCNN-based mapping of ice-wedge polygons. Our findings revealed the scene dependency of data fusion algorithms and emphasized the need for careful selection of the proper algorithm. Results suggested that the fusion algorithms that preserve spatial character of original PAN imagery favor the DLCNN model performances. The choice of fusion approach needs to be considered of equal importance to the required training dataset for successful applications using DLCNN on VHRS imagery in order to enable an accurate mapping effort of permafrost thaw across the Arctic region. © 2020 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Arctic; Convolutional neural networks; Geometry; Ice; Image fusion; Image processing; Image resolution; Land use; Mapping; Permafrost; Remote sensing; Satellite imagery; Application-oriented; Automated image analysis; Classification accuracy; Commercial satellites; Complementary characteristics; Data fusion algorithm; Land use and land cover; Very high spatial resolutions; data set; image analysis; image classification; machine learning; panchromatic image; permafrost; polygon; remote sensing; satellite imagery; spatial resolution; spectral resolution; Deep learning","Arctic; Commercial satellite imagery; Data fusion; Deep learning; Ice-wedge polygon; Permafrost","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85094846781"
