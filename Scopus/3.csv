"Authors","Author full names","Author(s) ID","Titles","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","DOI","Cited by","Link","Abstract","Indexed Keywords","Author Keywords","Document Type","Publication Stage","Open Access","Source","EID"
"Li Y.; Huang J.Z.; Gao W.L.; Jia J.D.; Tao S.; Ren Y.Z.; Liu X.L.","Li, Yan (57246418800); Huang, Jin Z. (57937919700); Gao, Wan L. (57937469800); Jia, Jing D. (57322686700); Tao, Sha (57211427383); Ren, Yan Z. (57194343285); Liu, Xin L. (57224690186)","57246418800; 57937919700; 57937469800; 57322686700; 57211427383; 57194343285; 57224690186","COMPARISON OF INVERSION METHODS FOR MAIZE CANOPY TIME-SERIES LAI BASED ON SUPREME RECONSTRUCTED IMAGES","2022","Journal of the ASABE","65","5","","1019","1028","9","10.13031/ja.15011","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140392070&doi=10.13031%2fja.15011&partnerID=40&md5=a403ec020dfa49ccfe80a0eb09841a6a","Accurate time-series crop leaf area index (LAI) monitoring can provide data support for field management and early yield estimation. The Sentinel-2 satellite has a high spatial, temporal, and spectral resolution, and its unique three red-edge bands provide an ideal data source for LAI estimation. However, the inconsistent spatial resolution of different bands hinders the application potential of Sentinel-2 images. In view of this problem, we focused on mining more information provided by the high spatial resolution bands of Sentinel-2 images using the Super-Resolution for Multispectral Multiresolution Estimation (SupReME) algorithm. Furthermore, The SNAP (Sentinel Application Platform) biophysical processor and the PROSAIL radiation transfer model coupled with Random Forest (RF) model were applied to estimate time-series LAI of maize canopy at 10 m spatial resolution, and the Leaf Area Index Wireless Sensor Network (LAINet) measurements were used for accuracy verification. Finally, the effectiveness of images reconstructed by SupReME and the two inversion methods for time-series LAI estimation were evaluated. The results showed that: (1) the Sentinel-2 images reconstructed by SupReME can improve spatial characteristics while maintaining spectral invariance, and they were more advantageous for LAI estimation than the original images; (2) The SNAP biophysical processor suits a quick large-scale estimation with robustness, while the PROSAIL coupled RF model achieved a higher coefficient of determination (R2) and a lower root mean square error (RMSE) (R2 increased by more than 0.1, RMSE decreased by more than 0.33) for time-series LAI estimation in this specific study area; (3) both inversion methods showed apparent underestimation at the late growth stage. This study verifies the feasibility of obtaining high spatial resolution images using a super-resolution algorithm for LAI inversion and provides the effect of two commonly used inversion methods for time-series LAI estimation at 10 m resolution. © 2022 American Society of Agricultural and Biological Engineers.","Biophysics; Image enhancement; Image reconstruction; Image resolution; Mean square error; Time series; Wireless sensor networks; Application platforms; Estimation algorithm; Leaf Area Index; Multi-spectral; Multiresolution; PROSAIL model; Random forests; Sentinel application platform biophysical processor; Super-resolution for multispectral multiresolution estimation algorithm; Superresolution; accuracy assessment; algorithm; biophysics; comparative study; error analysis; estimation method; inversion layer; leaf area index; satellite data; Sentinel; spatial resolution; time series analysis; Decision trees","Leaf area index; PROSAIL model; Random forest; SNAP biophysical processor; SupReME algorithm","Article","Final","","Scopus","2-s2.0-85140392070"
"Zabalza M.; Bernardini A.","Zabalza, Maialen (57759668500); Bernardini, Angela (57760233200)","57759668500; 57760233200","Super-Resolution of Sentinel-2 Images Using a Spectral Attention Mechanism","2022","Remote Sensing","14","12","2890","","","","10.3390/rs14122890","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132574283&doi=10.3390%2frs14122890&partnerID=40&md5=f954cd95a7f86ab6be7cef2167467fd4","Many visual applications require high-resolution images for an adequate interpretation of the data stored within them. In remote sensing, the appearance of satellites such as Sentinel or Landsat has facilitated the access to data thanks to their free offer of multispectral images. However, the spatial resolution of these satellites is insufficient for many tasks. Therefore, the objective of this work is to apply deep learning techniques to increase the resolution of the Sentinel-2 Read-Green-Blue-NIR (RGBN) bands from the original 10 m to 2.5 m. This means multiplying the number of pixels in the resulting image by 4, improving the perception and visual quality. In this work, we implement a state-of-the-art residual learning-based model called Super-Resolution Residual Network (SRResNet), which we train using PlanetScope-Sentinel pairs of images. Our model, named SARNet (Spectral Attention Residual Network), incorporates Residual Channel Attention Blocks (RCAB) to improve the performance of the network and the visual quality of the results. The experiments we have carried out show that SARNet offers better results than other state-of-the-art methods. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Image enhancement; Landsat; Learning systems; Optical resolving power; Attention mechanisms; Channel attention; Deep learning; Image super resolutions; Planetscope; Remote-sensing; Sentinel-2; Superresolution; Visual applications; Visual qualities; Remote sensing","channel attention; deep learning; image super-resolution; PlanetScope; remote sensing; Sentinel-2","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85132574283"
"Zhang C.; Wang Q.; Lu P.; Ge Y.; Atkinson P.M.","Zhang, Chengyuan (57216611828); Wang, Qunming (55649569623); Lu, Ping (41861974200); Ge, Yong (26655529300); Atkinson, Peter M. (7201906181)","57216611828; 55649569623; 41861974200; 26655529300; 7201906181","Fast and Slow Changes Constrained Spatio-Temporal Subpixel Mapping","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3133534","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121401087&doi=10.1109%2fTGRS.2021.3133534&partnerID=40&md5=847522ac382358ab1142787f2b08f697","Subpixel mapping (SPM) is a technique to tackle the mixed-pixel problem and produces land cover and land use (LCLU) maps at a finer spatial resolution than the original coarse data. However, uncertainty exists unavoidably in SPM, which is an ill-posed downscaling problem. Spatio-temporal SPM methods have been proposed to deal with this uncertainty, but current methods fail to explore fully the information in the time-series images, especially more rapid changes over a short-time interval. In this article, a fast and slow changes constrained spatio-temporal subpixel mapping (FSSTSPM) method is proposed to account for fast LCLU changes over a short time interval and slow changes over a long time interval. Both fast and slow changes-based temporal constraints are proposed and incorporated simultaneously into the FSSTSPM to increase the accuracy of SPM. The proposed FSSTSPM method was validated using two synthetic datasets with various proportion errors. It was also applied to oil-spill mapping using a real PlanetScope-Sentinel-2 dataset and Amazon deforestation mapping using a real Landsat-Moderate Resolution Imaging Spectroradiometer (MODIS) dataset. The results demonstrate the superiority of FSSTSPM. Moreover, the advantage of FSSTSPM is more obvious with an increase in proportion errors. The concepts of the fast and slow changes, together with the derived temporal constraints, provide a new insight to enhance SPM by taking fuller advantage of the temporal information in the available time-series images.  © 2022 IEEE.","Deforestation; Hopfield neural networks; Image enhancement; Land use; Mapping; Oil spills; Pixels; Remote sensing; Satellite imagery; Time series; Down-scaling; Hopfield neural network; Land cover; Land cover and land use; Remote-sensing; Spatial resolution; Spatio-temporal; Spatio-temporal dependence; Sub-pixel mapping; Subpixel mapping; Superresolution mapping; Temporal dependence; Uncertainty; data set; deforestation; digital mapping; image resolution; land cover; land use; mapping method; MODIS; spatiotemporal analysis; Image resolution","Downscaling; Hopfield neural network (HNN); land cover and land use (LCLU); spatio-temporal dependence; subpixel mapping (SPM); super-resolution mapping","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85121401087"
"Ayala C.; Aranda C.; Galar M.","Ayala, C. (55642388700); Aranda, C. (57211636468); Galar, M. (35731257600)","55642388700; 57211636468; 35731257600","Towards fine-grained road maps extraction using sentinel-2 imagery","2021","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","3","","9","14","5","10.5194/isprs-annals-V-3-2021-9-2021","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113177615&doi=10.5194%2fisprs-annals-V-3-2021-9-2021&partnerID=40&md5=6e43dc8fe386c565d1ada49f03483778","Nowadays, it is highly important to keep road maps up-to-date since a great deal of services rely on them. However, to date, these labours have demanded a great deal of human attention due to their complexity. In the last decade, promising attempts have been carried out to fully-automatize the extraction of road networks from remote sensing imagery. Nevertheless, the vast majority of methods rely on aerial imagery (< 1 m), whose costs are not yet affordable for maintaining up-to-date maps. This work proves that it is also possible to accurately detect roads using high resolution satellite imagery (10 m). Accordingly, we have relied on Sentinel-2 imagery considering its freely availability and the higher revisit times compared to aerial imagery. It must be taken into account that the lack of spatial resolution of this sensor drastically increases the difficulty of the road detection task, since the feasibility to detect a road depends on its width, which can reach sub-pixel size in Sentinel-2 imagery. For that purpose, a new deep learning architecture which combines semantic segmentation and super-resolution techniques is proposed. As a result, fine-grained road maps at 2.5 m are generated from Sentinel-2 imagery.  © Author(s) 2021.","Aerial photography; Antennas; Deep learning; Extraction; Image segmentation; Remote sensing; Roads and streets; Semantics; Aerial imagery; High resolution satellite imagery; Human attention; Learning architectures; Remote sensing imagery; Semantic segmentation; Spatial resolution; Super resolution; Satellite imagery","Convolutional Neural Networks; Deep Learning; Remote Sensing; Road Network Extraction; Sentinel-2","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85113177615"
"Pineda F.; Ayma V.; Aduviri R.; Beltran C.","Pineda, Ferdinand (57216822078); Ayma, Victor (56566776600); Aduviri, Robert (57207467513); Beltran, Cesar (55602499700)","57216822078; 56566776600; 57207467513; 55602499700","Super Resolution Approach Using Generative Adversarial Network Models for Improving Satellite Image Resolution","2020","Communications in Computer and Information Science","1070 CCIS","","","291","298","7","10.1007/978-3-030-46140-9_27","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084819739&doi=10.1007%2f978-3-030-46140-9_27&partnerID=40&md5=9fe165b60f94c8fbbadd58a0c7da0341","Recently, the number of satellite imaging sensors deployed in space has experienced a considerable increase, but most of these sensors provide low spatial resolution images, and only a small proportion contribute with images at higher resolutions. This work proposes an alternative to improve the spatial resolution of Landsat-8 images to the reference of Sentinel-2 images, by applying a Super Resolution (SR) approach based on the use of Generative Adversarial Network (GAN) models for image processing, as an alternative to traditional methods to achieve higher resolution images, hence, remote sensing applications could take advantage of this new information and improve its outcomes. We used two datasets to train and validate our approach, the first composed by images from the DIV2K open access dataset and the second by images from Sentinel-2 satellite. The experimental results are based on the comparison of the similarity between the Landsat-8 images obtained by the super resolution processing by our approach (for both datasets), against its corresponding reference from Sentinel-2 satellite image, computing the Peak Signal-to-Noise Ratio (PSNR) and the Structural Similarity (SSIM) as metrics for this purpose. In addition, we present a visual report in order to compare the performance of each trained model, analysis that shows interesting improvements of the resolution of Landsat-8 satellite images. © Springer Nature Switzerland AG 2020.","Big data; Image resolution; Information management; Optical resolving power; Remote sensing; Signal to noise ratio; Small satellites; Adversarial networks; Higher resolution images; Peak signal to noise ratio; Remote sensing applications; Satellite imaging; Spatial resolution; Spatial resolution images; Structural similarity; Image enhancement","Landsat-8; Sentinel-2; SR-GAN; Super Resolution","Conference paper","Final","","Scopus","2-s2.0-85084819739"
"Gargiulo M.; Mazza A.; Gaetano R.; Ruello G.; Scarpa G.","Gargiulo, Massimiliano (57200856555); Mazza, Antonio (57200854745); Gaetano, Raffaele (23491959900); Ruello, Giuseppe (6603038881); Scarpa, Giuseppe (7004081145)","57200856555; 57200854745; 23491959900; 6603038881; 7004081145","Fast super-resolution of 20 m Sentinel-2 bands using convolutional neural networks","2019","Remote Sensing","11","22","2635","","","","10.3390/rs11222635","34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075367036&doi=10.3390%2frs11222635&partnerID=40&md5=c70e6bcf1ebf436f61ec5327ae6aacf7","Images provided by the ESA Sentinel-2 mission are rapidly becoming the main source of information for the entire remote sensing community, thanks to their unprecedented combination of spatial, spectral and temporal resolution, as well as their associated open access policy. Due to a sensor design trade-off, images are acquired (and delivered) at different spatial resolutions (10, 20 and 60 m) according to specific sets of wavelengths, with only the four visible and near infrared bands provided at the highest resolution (10 m). Although this is not a limiting factor in general, many applications seem to emerge in which the resolution enhancement of 20 m bands may be beneficial, motivating the development of specific super-resolution methods. In this work, we propose to leverage Convolutional Neural Networks (CNNs) to provide a fast, upscalable method for the single-sensor fusion of Sentinel-2 (S2) data, whose aim is to provide a 10 m super-resolution of the original 20 m bands. Experimental results demonstrate that the proposed solution can achieve better performance with respect to most of the state-of-the-art methods, including other deep learning based ones with a considerable saving of computational burden. © 2019 by the authors.","Convolution; Data fusion; Deep learning; Economic and social effects; Infrared devices; Neural networks; Optical resolving power; Remote sensing; Computational burden; Convolutional neural network; Land-cover classification; Pan-sharpening; Resolution enhancement; State-of-the-art methods; Superresolution methods; Visible and near infrared; Sensor data fusion","Convolutional neural network; Data fusion; Landcover classification; Multi-resolution analysis; Pansharpening","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85075367036"
"Kawulok M.; Kostrzewa D.; Benecki P.; Skonieczny L.","Kawulok, Michal (24474818300); Kostrzewa, Daniel (50661666400); Benecki, Pawel (55644906700); Skonieczny, Lukasz (57204519073)","24474818300; 50661666400; 55644906700; 57204519073","Evaluating super-resolution reconstruction of satellite images","2017","Proceedings of the International Astronautical Congress, IAC","7","","","4593","4600","7","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051444595&partnerID=40&md5=2d38663ecd2e078262d671b1c8c0b26a","Super-resolution reconstruction (SRR) consists in enhancing image spatial resolution given a single image or a bunch of images presenting the same scene. Potential benefits of SRR are evident, when images of high resolution are required, but are unavailable due to technological limitations or economic reasons. Obviously, this is inherent to satellite imagery—medium or high resolution data (e.g., Sentinel-2 images) could be processed to obtain images of higher resolution, whose accessibility is much lower due to their price, lower coverage and longer revisit times. Although SRR is a well-studied problem of computer vision, to the best of our knowledge, no satisfactory solution exists that would allow for enhancing satellite images in practice. One of the pivotal obstacles we identified, is concerned with the evaluation methodology commonly adopted while developing the SRR techniques—an image of high resolution (ℎ) is downscaled using different offsets and degradation operators to obtain a set of low-resolution images { ()}. The goal is to reconstruct the original image from {()} and the similarity between the outcome ′(ℎ) and(ℎ), commonly measured with peak signal-to-noise ratio (PSNR), is used to evaluate the quality of SRR. While such procedure is sufficient to verify some aspects of the algorithms, the assumptions imposed on the degradation model may actually not hold. Unfortunately, there are no benchmarks encompassing the real images acquired at different resolutions, which could correspond to the real-world conditions. In this paper, we intend to fill the aforementioned gap with our validation framework, encompassing (i) synthetic images, (ii) satellite images degraded using known operators, and (iii) images covering roughly the same area acquired using sensors of different resolution ({()} is composed of either multiple images of the same area, or different spectra of a hyper-spectral image). Furthermore, we extend the measures used to compare ′(ℎ) with (ℎ)—not only do we rely on various similarity measures (such as PSNR), but also we explore how to exploit landmark detectors to assess whether and how SRR reduces the ground sampling distance (GSD). Importantly, we utilize the elaborated evaluation metrics while defining the objective function, whose optimization allows for reconstructing the super-resolution image. In the work reported here, we optimize that function using evolutionary computation and we present the initial, yet very encouraging results, obtained for real-world data, including Sentinel-2 images. This allows us to outline the future research pathways which will lead to developing effective SRR methods suitable for practical applications. © 2018 International Astronautical Federation IAF. All rights reserved.","Function evaluation; Image processing; Image reconstruction; Optical resolving power; Photodegradation; Quality control; Satellite imagery; Signal to noise ratio; Spectroscopy; Evaluation methodologies; Ground sampling distances; Image similarity; Image spatial resolution; Peak Signal to Noise Ratio (PSNR); Satisfactory solutions; Super resolution reconstruction; Technological limitations; Image enhancement","Image processing; Image similarity metrics; Super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85051444595"
"Galar M.; Sesma R.; Ayala C.; Albizua L.; Aranda C.","Galar, Mikel (35731257600); Sesma, Rubén (57211638474); Ayala, Christian (55642388700); Albizua, Lourdes (35423280700); Aranda, Carlos (57211636468)","35731257600; 57211638474; 55642388700; 35423280700; 57211636468","Super-resolution of Sentinel-2 images using convolutional neural networks and real ground truth data","2020","Remote Sensing","12","18","2941","","","","10.3390/RS12182941","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091855430&doi=10.3390%2fRS12182941&partnerID=40&md5=02e3ae602f52177b88996157444217f9","Earth observation data is becoming more accessible and affordable thanks to the Copernicus programme and its Sentinel missions. Every location worldwide can be freely monitored approximately every 5 days using the multi-spectral images provided by Sentinel-2. The spatial resolution of these images for RGBN (RGB + Near-infrared) bands is 10 m, which is more than enough for many tasks but falls short for many others. For this reason, if their spatial resolution could be enhanced without additional costs, any posterior analyses based on these images would be benefited. Previous works have mainly focused on increasing the resolution of lower resolution bands of Sentinel-2 (20 m and 60 m) to 10 m resolution. In these cases, super-resolution is supported by bands captured at finer resolutions (RGBN at 10 m). On the contrary, this paper focuses on the problem of increasing the spatial resolution of 10 m bands to either 5 m or 2.5 m resolutions, without having additional information available. This problem is known as single-image super-resolution. For standard images, deep learning techniques have become the de facto standard to learn the mapping from lower to higher resolution images due to their learning capacity. However, super-resolution models learned for standard images do not work well with satellite images and hence, a specific model for this problem needs to be learned. The main challenge that this paper aims to solve is how to train a super-resolution model for Sentinel-2 images when no ground truth exists (Sentinel-2 images at 5 m or 2.5 m). Our proposal consists of using a reference satellite with a high similarity in terms of spectral bands with respect to Sentinel-2, but with higher spatial resolution, to create image pairs at both the source and target resolutions. This way, we can train a state-of-the-art Convolutional Neural Network to recover details not present in the original RGBN bands. An exhaustive experimental study is carried out to validate our proposal, including a comparison with the most extended strategy for super-resolving Sentinel-2, which consists in learning a model to super-resolve from an under-sampled version at either 40 m or 20 m to the original 10 m resolution and then, applying this model to super-resolve from 10 m to 5 m or 2.5 m. Finally, we will also show that the spectral radiometry of the native bands is maintained when super-resolving images, in such a way that they can be used for any subsequent processing as if they were images acquired by Sentinel-2. © 2020 by the authors.","Convolution; Convolutional neural networks; Deep learning; Image resolution; Infrared devices; Learning systems; Optical resolving power; Spectroscopy; Earth observation data; Higher resolution images; Learning techniques; Multispectral images; Posterior analysis; Reference satellites; Spectral radiometry; Super-resolution models; Image enhancement","Convolutional neural networks; Deep learning; Multi-spectral image; Sentinel-2; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85091855430"
"Isa S.M.; Suharjito; Kusuma G.P.; Cenggoro T.W.","Isa, Sani M. (57216658927); Suharjito (55390566600); Kusuma, Gede Putera (24474615100); Cenggoro, Tjeng Wawan (56411932900)","57216658927; 55390566600; 24474615100; 56411932900","Supervised conversion from Landsat-8 images to Sentinel-2 images with deep learning","2021","European Journal of Remote Sensing","54","1","","182","208","26","10.1080/22797254.2021.1875267","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103200799&doi=10.1080%2f22797254.2021.1875267&partnerID=40&md5=c3c618c3dfc398594a7a075ea23973a4","In a specific remote sensing study design, the utilization of images from a particular satellite is necessary. However, the images might be unavailable in a certain time range. Therefore, a conversion method from available remote sensing images at the time range is required. In this paper, we proposed machine learning models that are capable to convert Landsat-8 images to Sentinel-2 images. The models are inspired by the advancement of super-resolution model based on Deep learning. The result of this study shows that the proposed models can predict Sentinel-2 images which are quantitatively and qualitatively similar to the original images. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Learning systems; Remote sensing; Conversion methods; LANDSAT; Machine learning models; Original images; Remote sensing images; Study design; Super-resolution models; Time range; image resolution; Landsat; prediction; remote sensing; satellite data; Sentinel; supervised learning; Deep learning","deep learning; Landsat-8; remote sensing; Satellite image conversion; Sentinel-2","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85103200799"
"","","","2022 24th ISPRS Congress ""Imaging Today, Foreseeing Tomorrow"", Commission IV","2022","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","4","","","","1656","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132022491&partnerID=40&md5=5c94fce249da7ab9aa261d626d8d8601","The proceedings contain 43 papers. The topics discussed include: radiometric calibration performance of a multispectral camera with a single sensor and multiple heads; point cloud simulator for space in-orbit close range autonomous operations; impact of deep learning-based super-resolution on building footprint extraction; a novel geometric key-frame selection method for visual-inertial slam and odometry systems; importance of precise gravity field modeling in direct georeferencing and aerial photogrammetry: a case study for Sweden; a combined color and wave-based approach to satellite derived bathymetry using deep learning; multi-temporal data augmentation for high frequency satellite imagery: a case study in sentinel-1 and Sentinel-2 building and road segmentation; database storage and transparent memory loading of big spatial datasets implemented with the dual half-edge data structure; an artificial intelligence-based solution for the classification of oak decline potential; geomatics vocational education in China: current situation and recent developments; and collaborative education model on GIS major under the professional certification of engineering education.","","","Conference review","Final","","Scopus","2-s2.0-85132022491"
"Razzak M.T.; Mateo-García G.; Lecuyer G.; Gómez-Chova L.; Gal Y.; Kalaitzis F.","Razzak, Muhammed T. (57226329712); Mateo-García, Gonzalo (57192947904); Lecuyer, Gurvan (57214899061); Gómez-Chova, Luis (6603354695); Gal, Yarin (56462312200); Kalaitzis, Freddie (57221042086)","57226329712; 57192947904; 57214899061; 6603354695; 56462312200; 57221042086","Multi-spectral multi-image super-resolution of Sentinel-2 with radiometric consistency losses and its effect on building delineation","2023","ISPRS Journal of Photogrammetry and Remote Sensing","195","","","1","13","12","10.1016/j.isprsjprs.2022.10.019","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141808181&doi=10.1016%2fj.isprsjprs.2022.10.019&partnerID=40&md5=b9410798943473dfb4eb384dbe9fbbea","High resolution remote sensing imagery is used in a broad range of tasks, including detection and classification of objects. High-resolution imagery is however expensive to obtain, while lower resolution imagery is often freely available and can be used for a range of social good applications. To that end, we curate a multi-spectral multi-image dataset for super-resolution of satellite images. We use PlanetScope imagery from the SpaceNet-7 challenge as the high resolution reference and multiple Sentinel-2 revisits of the same location as the low-resolution imagery. We present the first results of applying multi-image super-resolution (MISR) to multi-spectral remote sensing imagery. We, additionally, introduce a radiometric-consistency module into the MISR model to preserve the high radiometric resolution and quality of the Sentinel-2 sensor. We show that MISR is superior to single-image super-resolution (SISR) and other baselines on a range of image fidelity metrics. Furthermore, we present the first assessment of the utility of multi-image super-resolution on a semantic and instance segmentation – common remote sensing tasks – showing that utilizing multiple images results in better performance in these downstream tasks, but MISR pre-processing is non-essential. © 2022 The Author(s)","Image segmentation; Object detection; Optical resolving power; Radiometry; Semantics; Building detection; Image super resolutions; Low-resolution imagery; Multi-image super-resolution; Multi-images; Multi-spectral; Radiometrics; Segmentation; Sentinel 2; Superresolution; detection method; image resolution; MISR; remote sensing; satellite data; satellite imagery; segmentation; Sentinel; Remote sensing","Building detection; Multi-image super-resolution; Segmentation; Sentinel 2; Super-resolution","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85141808181"
"","","","2022 24th ISPRS Congress ""Imaging Today, Foreseeing Tomorrow"", Commission V and Youth Forum","2022","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","5","","","","1656","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132243998&partnerID=40&md5=be755863992a11c56a7dd15de876180f","The proceedings contain 4 papers. The topics discussed include: radiometric calibration performance of a multispectral camera with a single sensor and multiple heads; point cloud simulator for space in-orbit close range autonomous operations; impact of deep learning-based super-resolution on building footprint extraction; a novel geometric key-frame selection method for visual-inertial slam and odometry systems; importance of precise gravity field modeling in direct georeferencing and aerial photogrammetry: a case study for Sweden; a combined color and wave-based approach to satellite derived bathymetry using deep learning; multi-temporal data augmentation for high frequency satellite imagery: a case study in sentinel-1 and Sentinel-2 building and road segmentation; database storage and transparent memory loading of big spatial datasets implemented with the dual half-edge data structure; an artificial intelligence-based solution for the classification of oak decline potential; geomatics vocational education in China: current situation and recent developments; and collaborative education model on GIS major under the professional certification of engineering education.","","","Conference review","Final","","Scopus","2-s2.0-85132243998"
"","","","24th ISPRS Congress, Commission I","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","1","","","","2619","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091106228&partnerID=40&md5=8497988fb8031bca7b1ac8b91026a140","The proceedings contain 342 papers. The topics discussed include: learning super-resolution for sentinel-2 images with real ground truth data from a reference satellite; combined patch-wise minimal-maximal pixels regularization for deblurring; urban material classification using spectral and textural features retrieved from autoencoders; a worldwide 3D GCP database inherited from 20 years of massive multi-satellite observations; deep learning based feature matching and its application in image orientation; a novel RPC bias model for improving the positioning accuracy of satellite images; land salinization dynamics based on feature space combinations from landsat image in Tongyu County, Northeast China; a new index for identifying water body from sentinel-2 satellite remote sensing imagery; land cover classification using convolutional neural network with remote sensing data and digital surface model; assessing resilience of infrastructures towards exogenous events by using PS-INSAR-based surface motion estimates and machine learning regression techniques; region-based fuzzy clustering image segmentation algorithm with Kullback-Leibler distance; experiences from the project course in geoinformatics; and refugees stories told by maps: a challenge for students in a scientific Olympiad.","","","Conference review","Final","","Scopus","2-s2.0-85091106228"
"Long J.; Peng Y.","Long, Jian (57218616379); Peng, Yuanxi (7403418922)","57218616379; 7403418922","Blind fusion of hyperspectral multispectral images based on matrix factorization","2021","Remote Sensing","13","21","4219","","","","10.3390/rs13214219","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118119744&doi=10.3390%2frs13214219&partnerID=40&md5=cb9252aa3697716d4af18cf0dbdd9042","The fusion of low spatial resolution hyperspectral images and high spatial resolution multispectral images in the same scenario is important for the super-resolution of hyperspectral images. The spectral response function (SRF) and the point spread function (PSF) are two crucial prior pieces of information in fusion, and most of the current algorithms need to provide these two preliminary pieces of information in advance, even for semi-blind fusion algorithms at least the SRF. This causes limitations in the application of fusion algorithms. This paper aims to solve the dependence of the fusion method on the point spread function and proposes a method to estimate the spectral response function from the images involved in the fusion to achieve blind fusion. We conducted experiments on simulated datasets Pavia University, CAVE, and the remote sensing images acquired by two spectral cameras, Sentinel 2 and Hyperion. The experimental results show that our proposed SRF estimation method can improve the PSNR value by 5 dB on average compared with other state-of-the-art SRF estimation results. The proposed blind fusion method can improve the PSNR value of fusion results by 3–15 dB compared with other blind fusion methods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Factorization; Hyperspectral imaging; Image fusion; Image resolution; Matrix algebra; Optical transfer function; Remote sensing; Spectroscopy; Function estimation; Fusion algorithms; Fusion methods; HyperSpectral; Hyperspectral imaging super-resolution; Matrix factorizations; Multispectral images; Point-Spread function; Spectral response functions; Superresolution; Matrix factorization","Hyperspectral imaging super-resolution; Image fusion; Matrix factorization","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85118119744"
"Salgueiro L.; Marcello J.; Vilaplana V.","Salgueiro, Luis (57344768400); Marcello, Javier (6602158797); Vilaplana, Verónica (23394280500)","57344768400; 6602158797; 23394280500","SEG-ESRGAN: A Multi-Task Network for Super-Resolution and Semantic Segmentation of Remote Sensing Images","2022","Remote Sensing","14","22","5862","","","","10.3390/rs14225862","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142757845&doi=10.3390%2frs14225862&partnerID=40&md5=f90f1dd556609820e4fea22fe78d391f","The production of highly accurate land cover maps is one of the primary challenges in remote sensing, which depends on the spatial resolution of the input images. Sometimes, high-resolution imagery is not available or is too expensive to cover large areas or to perform multitemporal analysis. In this context, we propose a multi-task network to take advantage of the freely available Sentinel-2 imagery to produce a super-resolution image, with a scaling factor of 5, and the corresponding high-resolution land cover map. Our proposal, named SEG-ESRGAN, consists of two branches: the super-resolution branch, that produces Sentinel-2 multispectral images at 2 m resolution, and an encoder–decoder architecture for the semantic segmentation branch, that generates the enhanced land cover map. From the super-resolution branch, several skip connections are retrieved and concatenated with features from the different stages of the encoder part of the segmentation branch, promoting the flow of meaningful information to boost the accuracy in the segmentation task. Our model is trained with a multi-loss approach using a novel dataset to train and test the super-resolution stage, which is developed from Sentinel-2 and WorldView-2 image pairs. In addition, we generated a dataset with ground-truth labels for the segmentation task. To assess the super-resolution improvement, the PSNR, SSIM, ERGAS, and SAM metrics were considered, while to measure the classification performance, we used the IoU, confusion matrix and the F1-score. Experimental results demonstrate that the SEG-ESRGAN model outperforms different full segmentation and dual network models (U-Net, DeepLabV3+, HRNet and Dual_DeepLab), allowing the generation of high-resolution land cover maps in challenging scenarios using Sentinel-2 10 m bands. © 2022 by the authors.","Image enhancement; Optical resolving power; Remote sensing; Semantic Web; Semantics; Signal encoding; Statistical tests; High resolution; Land cover maps; Multi tasks; Multi-task network; Remote sensing images; Semantic segmentation; Sentinel-2; Superresolution; Task networks; Worldview-2; Semantic Segmentation","multi-task network; semantic segmentation; Sentinel-2; super-resolution; WorldView-2","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85142757845"
"Huangfu K.; Li J.; Zhang X.; Zhang J.; Cui H.; Sun Q.","Huangfu, Kuan (57219898366); Li, Jian (55983731500); Zhang, Xinjia (57206939178); Zhang, Jinping (55720385500); Cui, Hao (57217480102); Sun, Quan (57219900220)","57219898366; 55983731500; 57206939178; 55720385500; 57217480102; 57219900220","Remote estimation of water quality parameters of medium-and small-sized inland rivers using sentinel-2 imagery","2020","Water (Switzerland)","12","11","3124","1","18","17","10.3390/w12113124","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095971607&doi=10.3390%2fw12113124&partnerID=40&md5=fd4465a1e508532ca60aab287f1fcf3d","In the application of quantitative remote sensing in water quality monitoring, the existence of mixed pixels greatly affects the accuracy of water quality parameter inversion, especially for narrow inland rivers. Improving the image spatial resolution and weakening the interference of mixed pixels in the image are some of the urgent problems to be solved in the study of water quality monitoring of medium-and small-sized inland rivers. We processed Sentinel-2 multispectral images using the super-resolution algorithm and generated a set of 10 m spatial resolution images with basically unchanged reflection characteristics. Both qualitative and quantitative evaluation results show that the super-resolution algorithm can weaken the influence of mixed pixels while maintaining spectral invariance. Before the application of the super-resolution algorithm, the inversion accuracy of water quality parameters in this study were as follows: for NH3-N, the R2 was 0.61, the root mean squared error (RMSE) was 0.177 and the mean absolute percentage error (MAPE) was 29.33%; for Chemical Oxygen Demand (COD), the R2 was 0.26, the RMSE was 0.756 and the MAPE was 4.62%; for Total Phosphorus (TP), the R2 was 0.69, the RMSE was 0.032 and the MAPE was 30.58%. After the application of the super-resolution algorithm, the inversion accuracy of water quality parameters in this study were as follows: for NH3-N, the R2 was 0.67, the RMSE was 0.161 and the MAPE was 25.88%; for COD, the R2 was 0.53, the RMSE was 0.546 and the MAPE was 3.36%; for TP, the R2 was 0.60, the RMSE was 0.034 and the MAPE was 24.28%. Finally, the spatial distribution of NH3-N, COD and TP was obtained by using a machine learning model. The results showed that the application of the super-resolution algorithm can effectively improve the retrieval accuracy of NH3-N, COD and TP, which illustrates the application potential of the super-resolution algorithm in water quality remote sensing quantitative monitoring. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Ammonia; Chemical oxygen demand; Image enhancement; Image resolution; Mean square error; Optical resolving power; Pixels; Remote sensing; Rivers; Turing machines; Water quality; Image spatial resolution; Mean absolute percentage error; Quantitative remote sensing; Reflection characteristics; Spatial resolution images; Super resolution algorithms; Water quality monitoring; Water quality parameters; accuracy assessment; algorithm; error analysis; image resolution; machine learning; parameterization; phosphorus; pixel; remote sensing; Sentinel; spatial resolution; water quality; Parameter estimation","Chemical oxygen demand; NH<sub>3</sub>-N; Remote sensing; Sentinel-2; Spectrum; Super-resolution algorithm; Total phosphorus; Water quality monitoring; Which provides thethepossibility totoobtainobtainhigher-precision waterwaterqualityqualityinversioninversionresults.results","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85095971607"
"Valsesia D.; Magli E.","Valsesia, Diego (55968886600); Magli, Enrico (7003771643)","55968886600; 7003771643","Super-Resolved Multi-Temporal Segmentation with Deep Permutation-Invariant Networks","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","995","998","3","10.1109/IGARSS46834.2022.9884811","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141898474&doi=10.1109%2fIGARSS46834.2022.9884811&partnerID=40&md5=72ce2ef5e1929f1cda64a8b454712d19","Multi-image super-resolution from multi-temporal satellite acquisitions of a scene has recently enjoyed great success thanks to new deep learning models. In this paper, we go beyond classic image reconstruction at a higher resolution by studying a super-resolved inference problem, namely semantic segmentation at a spatial resolution higher than the one of sensing platform. We expand upon recently proposed models exploiting temporal permutation invariance with a multi-resolution fusion module able to infer the rich semantic information needed by the segmentation task. The model presented in this paper has recently won the AI4EO challenge on Enhanced Sentinel 2 Agriculture. © 2022 IEEE.","Computer vision; Image reconstruction; Optical resolving power; Semantic Segmentation; Semantics; Classic images; Image super resolutions; Images reconstruction; Images segmentations; Learning models; Multi-images; Multi-temporal; Satellite acquisition; Superresolution; Temporal segmentations; Deep neural networks","deep neural networks; image segmentation; Super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85141898474"
"Lanaras C.; Bioucas-Dias J.; Galliani S.; Baltsavias E.; Schindler K.","Lanaras, Charis (56568192000); Bioucas-Dias, José (55901520500); Galliani, Silvano (23134476500); Baltsavias, Emmanuel (6603939930); Schindler, Konrad (8557497200)","56568192000; 55901520500; 23134476500; 6603939930; 8557497200","Super-resolution of Sentinel-2 images: Learning a globally applicable deep neural network","2018","ISPRS Journal of Photogrammetry and Remote Sensing","146","","","305","319","14","10.1016/j.isprsjprs.2018.09.018","167","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054157072&doi=10.1016%2fj.isprsjprs.2018.09.018&partnerID=40&md5=c68a033c3a355a6eba4e50a52d6efaad","The Sentinel-2 satellite mission delivers multi-spectral imagery with 13 spectral bands, acquired at three different spatial resolutions. The aim of this research is to super-resolve the lower-resolution (20 m and 60 m Ground Sampling Distance – GSD) bands to 10 m GSD, so as to obtain a complete data cube at the maximal sensor resolution. We employ a state-of-the-art convolutional neural network (CNN) to perform end-to-end upsampling, which is trained with data at lower resolution, i.e., from 40 → 20 m, respectively 360 → 60 m GSD. In this way, one has access to a virtually infinite amount of training data, by downsampling real Sentinel-2 images. We use data sampled globally over a wide range of geographical locations, to obtain a network that generalises across different climate zones and land-cover types, and can super-resolve arbitrary Sentinel-2 images without the need of retraining. In quantitative evaluations (at lower scale, where ground truth is available), our network, which we call DSen2, outperforms the best competing approach by almost 50% in RMSE, while better preserving the spectral characteristics. It also delivers visually convincing results at the full 10 m GSD. © 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Convolution; Deep learning; Neural networks; Optical resolving power; Satellite imagery; Signal sampling; Spectroscopy; Convolutional neural network; Convolutional Neural Networks (CNN); Ground sampling distances; Quantitative evaluation; Sentinel-2; Sharpening of bands; Spectral characteristics; Super resolution; artificial neural network; image resolution; learning; sampling; satellite imagery; satellite mission; Sentinel; Deep neural networks","Convolutional neural network; Deep learning; Sentinel-2; Sharpening of bands; Super-resolution","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85054157072"
"Kapilaratne R.G.C.J.; Kakuta S.; Kaneta S.","Kapilaratne, R.G.C.J. (57194537565); Kakuta, S. (56536327700); Kaneta, S. (57219049570)","57194537565; 56536327700; 57219049570","Enhanced super resolution for remote sensing imageries","2022","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","3","","53","60","7","10.5194/isprs-Annals-V-3-2022-53-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132043853&doi=10.5194%2fisprs-Annals-V-3-2022-53-2022&partnerID=40&md5=e739cd48d213e5e5de51b63d8bcee7db","Single image super resolution (SISR) technology has been attracted much attention from remote sensing community due to its proven potentials in remote sensing applications. Existing SISR techniques varying from conventional interpolation methods to different network architectures. Generative adversarial networks (GANs) are one of the latest network architectures proven a greater potential as a SISR method whereas least attention has been given by the remote sensing community. Several studies have already been carried out on this context. However, yet there is no generalized GAN based approach to super resolve remote sensing imageries. Therefore, this study investigated the potentials of enhanced super resolution generative adversarial (ESRGAN) model to super resolve very high to medium resolution images from high to coarse resolution images for remote sensing applications. Two models were trained and Worldview-3 (WV3) images used as for very high resolution images. Whereas, down sampled WV3 and Sentinel-2(S2) were used as low resolution counterparts. Model performances were qualitatively and quantitatively analysed using standard metrics such as PSNR, SSIM, UIQI, CC, SAM, SID. Evaluation results emphasised super resolved images were preserved the original quality of the satellite images to a greater extent while improving its ground resolution.  © Authors 2022.","Deep learning; Generative adversarial networks; Image enhancement; Network architecture; Optical resolving power; Deep learning; ESRGAN; Image super resolutions; Remote sensing applications; Remote sensing imagery; Remote-sensing; Sentinel-2.; Single images; Superresolution; Worldview-3; Remote sensing","Deep Learning; ESRGAN; Remote Sensing; Sentinel-2.; Super Resolution; WorldView-3","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85132043853"
"","","","24th ISPRS Congress, Commission V and Youth Forum","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","5","","","","2619","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092318791&partnerID=40&md5=4ee0fc2b4aea2021075fee4eb47d5d55","The proceedings contain 342 papers. The topics discussed include: learning super-resolution for sentinel-2 images with real ground truth data from a reference satellite; combined patch-wise minimal-maximal pixels regularization for deblurring; urban material classification using spectral and textural features retrieved from autoencoders; a worldwide 3D GCP database inherited from 20 years of massive multi-satellite observations; deep learning based feature matching and its application in image orientation; a novel RPC bias model for improving the positioning accuracy of satellite images; land salinization dynamics based on feature space combinations from landsat image in Tongyu County, Northeast China; a new index for identifying water body from sentinel-2 satellite remote sensing imagery; land cover classification using convolutional neural network with remote sensing data and digital surface model; assessing resilience of infrastructures towards exogenous events by using PS-INSAR-based surface motion estimates and machine learning regression techniques; region-based fuzzy clustering image segmentation algorithm with Kullback-Leibler distance; experiences from the project course in geoinformatics; and refugees stories told by maps: a challenge for students in a scientific Olympiad.","","","Conference review","Final","","Scopus","2-s2.0-85092318791"
"Vaqueiro M.; Fonseca J.M.; Oliveira H.; Mora A.","Vaqueiro, Miguel (57474931600); Fonseca, José Manuel (34769664200); Oliveira, Henrique (55922541100); Mora, André (15728256600)","57474931600; 34769664200; 55922541100; 15728256600","Multi-image Super-Resolution Algorithm Supported on Sentinel-2 Satellite Images Geolocation Error","2021","Proceedings - 2021 International Young Engineers Forum in Electrical and Computer Engineering, YEF-ECE 2021","","","","50","57","7","10.1109/YEF-ECE52297.2021.9505092","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125673913&doi=10.1109%2fYEF-ECE52297.2021.9505092&partnerID=40&md5=0c2d7b7c82d2ce613aa4b1d43aa3835d","Every year, the hottest seasons are marked by forest fires. Monitoring these forest areas is more effective with the help of satellite imagery, since ground operations are hampered by vegetation density and height, making them less productive and more expensive. However, nowadays, freely available imagery from Sentinel-2 satellite has a maximum spatial resolution of 10 meters per pixel, a low resolution to identify small or thin structures in the image, such as roads, bridges, buildings, rivers, fuel breaks, among others. To improve image’s resolution, a new super-resolution algorithm, named KGEONP – K Geographically Nearest Pixels, is proposed in this paper. It benefits from Sentinel-2 regular observations (it has a revisit of 5 days) and the georeferencing error of its images (whose maximum value is 1.5 pixels). KGEONP seeks to add as much information as possible to the super-resolved image, by using data from K-nearest pixels and their spatial distance for computing each new pixel’s value. KGEONP was applied to Sentinel-2 images to increase resolution by a factor of 10 and was compared to state-of-the-art super-resolution techniques. It showed quite satisfactory results, with the capacity of increasing resolution and maintaining the structural data of the source images. © 2021 IEEE.","Deforestation; Errors; Image enhancement; Optical resolving power; Satellite imagery; Earth observations; Geolocations; Georeferencing; Georeferencing error; Image super resolutions; Multi-images; Satellite images; Sentinel-2; Super resolution algorithms; Superresolution; Pixels","Earth Observation; Georeferencing Error; Satellite Imagery; Sentinel-2; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85125673913"
"Fernandez R.; Fernandez-Beltran R.; Kang J.; Pla F.","Fernandez, Rafael (57222243976); Fernandez-Beltran, Ruben (55838551300); Kang, Jian (57192706813); Pla, Filiberto (7006504936)","57222243976; 55838551300; 57192706813; 7006504936","Sentinel-3 Super-Resolution Based on Dense Multireceptive Channel Attention","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9488297","7359","7372","13","10.1109/JSTARS.2021.3097410","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110863947&doi=10.1109%2fJSTARS.2021.3097410&partnerID=40&md5=b8c5d4973b68f7c7d7d6eaf3deb3e099","The unprecedented availability of remote sensing data from different complementary Sentinel missions provides increasing opportunities to alleviate the spatial limitations of Sentinel-3 (S3) from an intersensor perspective. Nonetheless, effectively exploiting such intersensor synergies still raises important challenges for super-resolution (SR) algorithms in terms of operational data availability, sensor alignment and substantial resolution changes, among others. In this scenario, this article sets a new SR framework for spatially enhancing S3 ocean and land color instrument (OLCI) products by taking advantage of the higher spatial resolution of the Sentinel-2 (S2) multispectral instrument (MSI). To achieve this goal, we initially study some of the most important deep learning-based approaches. Then, we define a novel Level-4 SR framework which integrates a new convolutional neural network specially designed for super-resolving OLCI data. In contrast to other networks, the proposed SR architecture (termed as SRS3) employs a dense multireceptive field together with a residual channel attention mechanism to relieve the particularly low spatial resolution of OLCI while extracting more discriminating features for the large spatial resolution differences with respect to MSI. The experimental part of the work, conducted using ten coupled OLCI and MSI operational data, reveals the suitability of the presented Level-4 SR framework within the Copernicus programme context as well as the advantages of the proposed architecture with respect different state-of-the-art models when spatially enhancing OLCI products. The related codes will be publicly available at https://github.com/rufernan/SRS3. © 2008-2012 IEEE.","Deep learning; Image resolution; Network architecture; Optical resolving power; Remote sensing; Attention mechanisms; Learning-based approach; Operational data; Proposed architectures; Receptive fields; Remote sensing data; Spatial resolution; State of the art; algorithm; artificial neural network; data processing; remote sensing; Sentinel; spatial resolution; Convolutional neural networks","Convolutional nural network (CNN); level-4 data processing; ocean and land color instrument (OLCI); sentinel-3 (s3); super-resolution (SR)","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85110863947"
"Htitiou A.; Boudhar A.; Benabdelouahab T.","Htitiou, Abdelaziz (57212145169); Boudhar, Abdelghani (35090979500); Benabdelouahab, Tarik (56766050800)","57212145169; 35090979500; 56766050800","Deep Learning-Based Spatiotemporal Fusion Approach for Producing High-Resolution NDVI Time-Series Datasets; [  Approche de fusion spatiotemporelle basée sur l’apprentissage profond pour produire des séries temporelles de NDVI à haute résolution]","2021","Canadian Journal of Remote Sensing","47","2","","182","197","15","10.1080/07038992.2020.1865141","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100805494&doi=10.1080%2f07038992.2020.1865141&partnerID=40&md5=e11a28e6b81aa194febd968a1bec2b11","The availability of concurrently high spatiotemporal resolution remote sensing data is highly desirable as they represent a key element for effective monitoring in various environmental applications. However, due to the tradeoff between the spatial resolution and acquisition frequency of current satellites, such data are still lacking. Many studies have been undertaken trying to overcome these problems; however, a couple of long-standing limitations remain, including accommodating abrupt temporal changes, dealing with complex and heterogeneous landscapes, and integrating other satellite datasets as well. Accordingly, this paper proposes a deep learning spatiotemporal data fusion approach based on Very Deep Super-Resolution (VDSR) to fuse the NDVI retrievals from Sentinel-2 and Landsat 8 images. The performances of VDSR are analyzed in comparison with those of two other classical methods, the enhanced spatial and temporal adaptive reflectance fusion model (ESTARFM) and the flexible spatiotemporal data fusion (FSDAF) method. The results obtained indicate that VDSR outperforms other data fusion algorithms as it generated the least blurred images and the most accurate predictions of synthetic NDVI values, particularly in areas with heterogeneous landscapes and abrupt land-cover changes. The proposed algorithm has broad prospects to improve near-real-time agricultural monitoring purposes and derivation of crop status conditions in the field-scale. ©, Copyright © CASI.","Agricultural robots; Image fusion; Remote sensing; Agricultural monitoring; Data fusion algorithm; Environmental applications; Frequency of currents; Heterogeneous landscapes; Spatio-temporal data; Spatio-temporal fusions; Spatio-temporal resolution; Deep learning","","Article","Final","","Scopus","2-s2.0-85100805494"
"Pham V.-D.; Bui Q.-T.","Pham, Vu-Dong (57202350777); Bui, Quang-Thanh (57189899688)","57202350777; 57189899688","Spatial resolution enhancement method for Landsat imagery using a Generative Adversarial Network","2021","Remote Sensing Letters","12","7","","654","665","11","10.1080/2150704X.2021.1918789","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105127268&doi=10.1080%2f2150704X.2021.1918789&partnerID=40&md5=92fd70c5ee8e4a888827caa02442244e","Landsat and Sentinel-2 are two freely accessible satellite data that are relevant for global land cover monitoring. However, the uses of the latter data set are growing because of its higher spatial resolutions and the availability of benchmark data sets for deep learning applications. In this study, we integrate a style transfer (perceptual loss estimation from Sentinel 2 benchmark data) into a Generative Adversarial Network (GAN) to construct a single image super-resolution model. The proposed model upscales Landsat 8 images (using red, green, blue, and near-infrared bands at 30 m and Panchromatic band 15 m for high-resolution features exploiting) to 10 m (with Sentinel-2 as reference). Compared to pan-sharpening and other upscaling methods, the proposed method can produce more realistic, spatial convincing images at 10 m resolution and more similar to Sentinel-2 images than the other commonly used super-resolution imaging algorithms. As a result, the proposed method extends the usage of high-resolution benchmark data sets for lower resolution imagery to enrich supplement data sources for land cover classification. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","Benchmarking; Classification (of information); Deep learning; Infrared devices; Optical resolving power; Adversarial networks; Land cover classification; Near infrared band; Panchromatic bands; Spatial resolution; Spatial-resolution enhancement; Super resolution imaging; Upscaling methods; algorithm; image resolution; land cover; Landsat; satellite data; satellite imagery; Sentinel; spatial resolution; Image enhancement","","Article","Final","","Scopus","2-s2.0-85105127268"
"Galar M.; Sesma R.; Ayala C.; Aranda C.","Galar, M. (35731257600); Sesma, R. (57211638474); Ayala, C. (55642388700); Aranda, C. (57211636468)","35731257600; 57211638474; 55642388700; 57211636468","Super-resolution for sentinel-2 images","2019","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","2/W16","","95","102","7","10.5194/isprs-archives-XLII-2-W16-95-2019","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074682230&doi=10.5194%2fisprs-archives-XLII-2-W16-95-2019&partnerID=40&md5=95ff6610fd7dfda236bb9906d67685e7","Obtaining Sentinel-2 imagery of higher spatial resolution than the native bands while ensuring that output imagery preserves the original radiometry has become a key issue since the deployment of Sentinel-2 satellites. Several studies have been carried out on the upsampling of 20m and 60m Sentinel-2 bands to 10 meters resolution taking advantage of 10m bands. However, how to super-resolve 10m bands to higher resolutions is still an open problem. Recently, deep learning-based techniques has become a de facto standard for single-image super-resolution. The problem is that neural network learning for super-resolution requires image pairs at both the original resolution (10m in Sentinel-2) and the target resolution (e.g., 5m or 2.5m). Since there is no way to obtain higher resolution images for Sentinel-2, we propose to consider images from others sensors having the greatest similarity in terms of spectral bands, which will be appropriately pre-processed. These images, together with Sentinel-2 images, will form our training set. We carry out several experiments using state-of-the-art Convolutional Neural Networks for single-image super-resolution showing that this methodology is a first step toward greater spatial resolution of Sentinel-2 images. © Authors 2019. CC BY 4.0 License.","Convolution; Deep learning; Deep neural networks; Geometrical optics; Image resolution; Neural networks; Optical resolving power; Remote sensing; Convolutional neural network; Higher resolution; Higher resolution images; Neural network learning; Optical image; Sentinel-2; Spatial resolution; Super resolution; Image enhancement","Convolutional neural network; Deep learning; Image enhancement; Optical images; Sentinel-2; Super-resolution","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85074682230"
"Panagiotopoulou A.; Charou E.; Stefouli M.; Platis K.; Madamopoulos N.; Bratsolis E.","Panagiotopoulou, Antigoni (24479152700); Charou, Eleni (6507509159); Stefouli, Marianthi (6506668706); Platis, Konstantinos (57206729641); Madamopoulos, Nicholas (6604012410); Bratsolis, Emmanuel (6603338911)","24479152700; 6507509159; 6506668706; 57206729641; 6604012410; 6603338911","Sentinel-2 'low resolution band' optimization using Super-Resolution techniques:Lysimachia Lake pilot area of analysis","2019","10th International Conference on Information, Intelligence, Systems and Applications, IISA 2019","","","8900684","","","","10.1109/IISA.2019.8900684","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075886765&doi=10.1109%2fIISA.2019.8900684&partnerID=40&md5=289ac4963fd5745e3efe416f32138cc6","This work super-resolves the lowest-resolution 60m/pixel Sentinel-2 B1 and B9 to the highest-resolution 10m/pixel. Two different categories of super-resolution (SR) techniques are utilized, in specific a SR technique which performs information transfer among different bands and the stochastic regularized SR technique Var-norm+BTV. The study area is the Lysimachia Lake, Western Greece. The Sentinel-2 image of 10th November 2018 has been selected to test the different techniques. © 2019 IEEE.","Lakes; Stochastic systems; Highest resolutions; Information transfers; Low resolution; Sentinel-2; Study areas; Super resolution; Super resolution reconstruction; Western Greece; Optical resolving power","Lysimachia Lake; Sentinel-2; Super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85075886765"
"","","","Image and Signal Processing for Remote Sensing XXVII","2021","Proceedings of SPIE - The International Society for Optical Engineering","11862","","","","","298","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118597273&partnerID=40&md5=91938b70e08b6997e317f40a385043b4","The proceedings contain 33 papers. The topics discussed include: stereo matching of remote sensing images using deep stereo matching; object detection with noisy annotations in high-resolution remote sensing images using robust EfficientDet; few shot object detection in remote sensing images; fire segmentation using a squeezesegv2; deep-learning-based remote sensing video super-resolution for Jilin-1 satellite; useable machine learning for Sentinel-2 multispectral satellite imagery; self-supervised multi-task learning for semantic segmentation of urban scenes; impact of different compression rates for hyperspectral data compression based on a convolutional autoencoder; and hyperspectral image classification using spectral-spatial hypergraph convolution neural network.","","","Conference review","Final","","Scopus","2-s2.0-85118597273"
"Zhu Y.; Geiß C.; So E.","Zhu, Yue (57212228519); Geiß, Christian (39862777100); So, Emily (24377128400)","57212228519; 39862777100; 24377128400","Image super-resolution with dense-sampling residual channel-spatial attention networks for multi-temporal remote sensing image classification","2021","International Journal of Applied Earth Observation and Geoinformation","104","","102543","","","","10.1016/j.jag.2021.102543","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121645574&doi=10.1016%2fj.jag.2021.102543&partnerID=40&md5=bcd843b753add4cad96e91bbc9768ba7","Image super-resolution (SR) techniques can benefit a wide range of applications in the remote sensing (RS) community, including image classification. This issue is particularly relevant for image classification on time series data, considering RS datasets that feature long temporal coverage generally have a limited spatial resolution. Recent advances in deep learning brought new opportunities for enhancing the spatial resolution of historic RS data. Numerous convolutional neural network (CNN)-based methods showed superior performance in terms of developing efficient end-to-end SR models for natural images. However, such models were rarely exploited for promoting image classification based on multispectral RS data. This paper proposes a novel CNN-based framework to enhance the spatial resolution of time series multispectral RS images. Thereby, the proposed SR model employs Residual Channel Attention Networks (RCAN) as a backbone structure, whereas based on this structure the proposed models uniquely integrate tailored channel-spatial attention and dense-sampling mechanisms for performance improvement. Subsequently, state-of-the-art CNN-based classifiers are incorporated to produce classification maps based on the enhanced time series data. The experiments proved that the proposed SR model can enable unambiguously better performance compared to RCAN and other (deep learning-based) SR techniques, especially in a domain adaptation context, i.e., leveraging Sentinel-2 images for generating SR Landsat images. Furthermore, the experimental results confirmed that the enhanced multi-temporal RS images can bring substantial improvement on fine-grained multi-temporal land use classification. © 2021","artificial neural network; image classification; image resolution; land use; remote sensing; sampling; spatial resolution; time series","Attention mechanism; Convolutional neural networks; Dense connection; Image super-resolution; Multi-temporal land use classification","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85121645574"
"Latte N.; Lejeune P.","Latte, Nicolas (24923269000); Lejeune, Philippe (8700431500)","24923269000; 8700431500","PlanetScope radiometric normalization and sentinel-2 super-resolution (2.5 m): A straightforward spectral-spatial fusion of multi-satellite multi-sensor images using residual convolutional neural networks","2020","Remote Sensing","12","15","2366","","","","10.3390/RS12152366","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089677000&doi=10.3390%2fRS12152366&partnerID=40&md5=7438e5dc2c6c821cc563b44167b2ad62","Sentinel-2 (S2) imagery is used in many research areas and for diverse applications. Its spectral resolution and quality are high but its spatial resolutions, of at most 10 m, is not sufficient for fine scale analysis. A novel method was thus proposed to super-resolve S2 imagery to 2.5 m. For a given S2 tile, the 10 S2 bands (four at 10mand six at 20 m) were fused with additional images acquired at higher spatial resolution by the PlanetScope (PS) constellation. The radiometric inconsistencies between PS microsatellites were normalized. Radiometric normalization and super-resolution were achieved simultaneously using state-of-the-art super-resolution residual convolutional neural networks adapted to the particularities of S2 and PS imageries (including masks of clouds and shadows). The method is described in detail, from image selection and downloading to neural network architecture, training, and prediction. The quality was thoroughly assessed visually (photointerpretation) and quantitatively, confirming that the proposed method is highly spatially and spectrally accurate. The method is also robust and can be applied to S2 images acquired worldwide at any date. © 2020 by the authors.","Convolution; Image acquisition; Network architecture; Optical resolving power; Radiometry; Diverse applications; Image selection; Microsatellites; Multi sensor images; Radiometric normalization; Spatial resolution; State of the art; Super resolution; Convolutional neural networks","CubeSat-Dove; Deep learning; Image pansharpening; Image super-resolution; Multi-sensor image fusion; Radiometric correction","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85089677000"
"Lanaras C.; Bioucas-Dias J.; Baltsavias E.; Schindler K.","Lanaras, Charis (56568192000); Bioucas-Dias, Jose (55901520500); Baltsavias, Emmanuel (6603939930); Schindler, Konrad (8557497200)","56568192000; 55901520500; 6603939930; 8557497200","Super-Resolution of Multispectral Multiresolution Images from a Single Sensor","2017","IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops","2017-July","","8014928","1505","1513","8","10.1109/CVPRW.2017.194","53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030228739&doi=10.1109%2fCVPRW.2017.194&partnerID=40&md5=ed43e6e4c188debea8c56e80f96c0af1","Some remote sensing sensors, acquire multispectral images of different spatial resolutions in variable spectral ranges (e.g. Sentinel-2, MODIS). The aim of this research is to infer all the spectral bands, of multiresolution sensors, in the highest available resolution of the sensor. We formulate this problem as a minimisation of a convex objective function with an adaptive (edge-reserving) regulariser. The data-fitting term accounts for individual blur and downsampling per band, while the regulariser 'learns' the discontinuities from the higher resolution bands and transfers them to other bands. We also observed that the data can be represented in a lower-dimensional subspace, reducing the dimensionality of the problem and significantly improving its conditioning. In a series of experiments with simulated data, we obtain results that outperform state-of-the-art, while showing competitive qualitative results on real Sentinel-2 data. © 2017 IEEE.","Computer vision; Remote sensing; Convex objectives; Dimensional subspace; Higher resolution; Multiresolution images; Multispectral images; Remote sensing sensors; Spatial resolution; State of the art; Pattern recognition","","Conference paper","Final","","Scopus","2-s2.0-85030228739"
"Carbonneau P.E.; Belletti B.; Micotti M.; Lastoria B.; Casaioli M.; Mariani S.; Marchetti G.; Bizzi S.","Carbonneau, P.E. (6507408602); Belletti, B. (37057135400); Micotti, M. (56291963900); Lastoria, B. (13403134500); Casaioli, M. (8961966100); Mariani, S. (8961965800); Marchetti, G. (57200319835); Bizzi, S. (50861158200)","6507408602; 37057135400; 56291963900; 13403134500; 8961966100; 8961965800; 57200319835; 50861158200","UAV-based training for fully fuzzy classification of Sentinel-2 fluvial scenes","2020","Earth Surface Processes and Landforms","45","13","","3120","3140","20","10.1002/esp.4955","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089465320&doi=10.1002%2fesp.4955&partnerID=40&md5=1a24d6d9a163c45ba182376e2988ec14","An estimated 76% of global stream area is occupied by channels with widths above 30 m. Sentinel-2 imagery with resolutions of 10 m could supply information about the composition of river corridors at national and global scales. Fuzzy classification models that infer sub-pixel composition could further be used to compensate for small channel widths imaged at 10 m of spatial resolution. A major challenge to this approach is the acquisition of suitable training data useable in machine learning models that can predict land-cover type information from image radiance values. In this contribution, we present a method which combines unmanned aerial vehicles (UAVs) and Sentinel-2 imagery in order to develop a fuzzy classification approach capable of large-scale investigations. Our approach uses hyperspatial UAV imagery in order to derive high-resolution class information that can be used to train fuzzy classification models for Sentinel-2 data where all bands are super-resolved to a spatial resolution of 10 m. We use a multi-temporal UAV dataset covering an area of 5.25 km2. Using a novel convolutional neural network (CNN) classifier, we predict sub-pixel membership for Sentinel-2 pixels in the fluvial corridor as divided into classes of water, vegetation and dry sediment. Our CNN model can predict fuzzy class memberships with median errors from −5% to +3% and mean absolute errors from 10% to 20%. We also show that our CNN fuzzy predictor can be used to predict crisp classes with accuracies from 95.5% to 99.9%. Finally, we use an example to show how a fuzzy CNN model trained with localized UAV data can be applied to longer channel reaches and detect new vegetation growth. We therefore argue that the novel use of UAVs as field validation tools for freely available satellite data can bridge the scale gap between local and regional fluvial studies. © 2020 The Authors. Earth Surface Processes and Landforms published by John Wiley & Sons Ltd. © 2020 The Authors. Earth Surface Processes and Landforms published by John Wiley & Sons Ltd","Antennas; Convolutional neural networks; Forecasting; Fuzzy systems; Image resolution; Pixels; Unmanned aerial vehicles (UAV); Vegetation; Class information; Earth surface process; Fluvial corridors; Fuzzy classification; Machine learning models; Mean absolute error; Spatial resolution; Vegetation growth; aerial survey; fluvial geomorphology; fuzzy mathematics; image classification; image resolution; machine learning; model validation; pixel; satellite data; satellite imagery; Sentinel; spatial resolution; unmanned vehicle; Classification (of information)","fluvial environments; fuzzy supervised classification; machine learning; Sentinel-2; super-resolution; UAV","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85089465320"
"Kawulok M.; Tarasiewicz T.; Nalepa J.; Tyrna D.; Kostrzewa D.","Kawulok, Michal (24474818300); Tarasiewicz, Tomasz (57221256061); Nalepa, Jakub (55441340400); Tyrna, Diana (57481733800); Kostrzewa, Daniel (50661666400)","24474818300; 57221256061; 55441340400; 57481733800; 50661666400","DEEP LEARNING FOR MULTIPLE-IMAGE SUPER-RESOLUTION OF SENTINEL-2 DATA","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","3885","3888","3","10.1109/IGARSS47720.2021.9553243","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126008243&doi=10.1109%2fIGARSS47720.2021.9553243&partnerID=40&md5=71324907b81afad204a2782e275474e4","Super-resolution (SR) reconstruction is a common term for techniques aimed at generating a high-resolution image from a single low-resolution image or multiple images showing the same scene. Multiple-image SR benefits from data fusion which allows for more accurate reconstruction of the underlying high-resolution information. Deep learning is extensively used for single-image SR, but its application to multiple-image SR is much less explored. Recently, several deep networks were proposed to enhance Proba-V images, and in this paper, we focus on employing them to super-resolve the Sentinel-2 images. In particular, we investigate the influence of the training data, including real and simulated low-resolution images, on the final SR outcome. Also, we make the simulated data publicly available. © 2021 IEEE.","","Deep learning; Multiple-image super-resolution; Satellite imaging; Super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85126008243"
"Ayala C.; Aranda C.; Galar M.","Ayala, C. (55642388700); Aranda, C. (57211636468); Galar, M. (35731257600)","55642388700; 57211636468; 35731257600","Pushing the Limits of Sentinel-2 for Building Footprint Extraction","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","322","325","3","10.1109/IGARSS46834.2022.9883103","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140396814&doi=10.1109%2fIGARSS46834.2022.9883103&partnerID=40&md5=1d43f1dec0e19e650e43f5e1038dae70","Building footprint maps are of high importance nowadays since a wide range of services relies on them to work. However, activities to keep these maps up-to-date are costly and time-consuming due to the great deal of human intervention required. Several automation attempts have been carried out in the last decade aiming at fully automatizing them. However, taking into account the complexity of the task and the current limitations of semantic segmentation deep learning models, the vast majority of approaches rely on aerial imagery (<1 m). As a result, prohibitive costs and high revisit times prevent the remote sensing community from maintaining up-to-date building maps. This work proposes a novel deep learning architecture to accurately extract building footprints from high resolution satellite imagery (10 m). Accordingly, super-resolution and semantic segmentation techniques have been fused to make it possible not only to improve the building's boundary definition but also to detect buildings with sub-pixel width. As a result, fine-grained building maps at 2.5 m are generated using Sentinel-2 imagery, closing the gap between satellite and aerial semantic segmentation. © 2022 IEEE.","Aerial photography; Antennas; Buildings; Convolutional neural networks; Deep learning; Satellite imagery; Semantic Segmentation; Semantics; Building detection; Building footprint; Convolutional neural network; Current limitation; Deep learning; Human intervention; Learning models; Remote-sensing; Semantic segmentation; Sentinel-2; Remote sensing","Building Detection; Convolutional Neural Networks; Deep Learning; Remote Sensing; Sentinel-2","Conference paper","Final","","Scopus","2-s2.0-85140396814"
"Park S.; Kim Y.; Kim M.","Park, Seongwook (57226324750); Kim, Yeongho (58026673300); Kim, Minsik (57226324770)","57226324750; 58026673300; 57226324770","Impact Analysis of Deep Learning Super-resolution Technology for Improving the Accuracy of Ship Detection Based on Optical Satellite Imagery","2022","Korean Journal of Remote Sensing","38","5-1","","559","570","11","10.7780/kjrs.2022.38.5.1.10","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144517892&doi=10.7780%2fkjrs.2022.38.5.1.10&partnerID=40&md5=1f508b99d450582e9bbd2992162ed45f","When a satellite image has low spatial resolution, it is difficult to detect small objects. In this research, we aim to check the effect of super resolution on object detection. Super resolution is a software method that increases the resolution of an image. Unpaired super resolution network is used to improve Sentinel-2's spatial resolution from 10 m to 3.2 m. Faster-RCNN, RetinaNet, FCOS, and S2ANet were used to detect vessels in the Sentinel-2 images. We experimented the change in vessel detection performance when super resolution is applied. As a result, the Average Precision (AP) improved by at least 12.3% and up to 33.3% in the ship detection models trained with the super-resolution image. False positive and false negative cases also decreased. This implies that super resolution can be an important pre-processing step in object detection, and it is expected to greatly contribute to improving the accuracy of other image-based deep learning technologies along with object detection. © Korean Journal of Remote Sensing. All rights reserved.","","Deep learning; Remote sensing; Sentinel-2; Ship detection; Super-resolution","Article","Final","","Scopus","2-s2.0-85144517892"
"Panagiotopoulou A.; Bratsolis E.; Grammatikopoulos L.; Petsa E.; Charou E.; Poirazidis K.; Martinis A.; Madamopoulos N.","Panagiotopoulou, Antigoni (24479152700); Bratsolis, Emmanuel (6603338911); Grammatikopoulos, Lazaros (16068804700); Petsa, Eleni (6508237326); Charou, Eleni (6507509159); Poirazidis, Konstantinos (57203888036); Martinis, Aristotelis (25641948100); Madamopoulos, Nicholas (6604012410)","24479152700; 6603338911; 16068804700; 6508237326; 6507509159; 57203888036; 25641948100; 6604012410","Sentinel-2 Images at 2.5m Spatial Resolution via Deep-Learning: A Case Study in Zakythnos","2022","IVMSP 2022 - 2022 IEEE 14th Image, Video, and Multidimensional Signal Processing Workshop","","","","","","","10.1109/IVMSP54334.2022.9816272","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135185442&doi=10.1109%2fIVMSP54334.2022.9816272&partnerID=40&md5=913bebe5e979cb73d035cadba99bffc0","High-resolution (HR) satellite images can provide detailed information about land usage/land cover. Often, it is necessary that the satellite sensor inherent spatial resolution is increased through algorithmic processing of the image data acquired. Machine-learning and in particular deep-learning based super-resolution (SR) techniques are an effective tool for increasing the spatial resolution of images. In the current work, Sentinel-2 images are super-resolved to spatial resolution equal to 2.5 m/pixel by means of deep-learning based SR techniques. The area of study is Zakynthos island in Greece. A novel index called Normalized Carotenoid Reflectance Index (NCRI) is proposed for the assessment of land cover by olive trees.  © 2022 IEEE.","Deep learning; Forestry; Image resolution; Learning systems; Reflection; Remote sensing; Deep-learning; Land cover; Learning-based super-resolution; Normalized carotenoid reflectance index; Olive tree; Reflectance index; Resolution techniques; Sentinel-2; Spatial resolution; Superresolution; Carotenoids","deep-learning; normalized carotenoid reflectance index; olive tree; Sentinel-2; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85135185442"
"Fotiadou K.; Tsagkatakis G.; Tsakalides P.","Fotiadou, Konstantina (25824915900); Tsagkatakis, Grigorios (34870845200); Tsakalides, Panagiotis (6701848334)","25824915900; 34870845200; 6701848334","Spectral Super Resolution of Hyperspectral Images via Coupled Dictionary Learning","2019","IEEE Transactions on Geoscience and Remote Sensing","57","5","8535036","2777","2797","20","10.1109/TGRS.2018.2877124","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056563919&doi=10.1109%2fTGRS.2018.2877124&partnerID=40&md5=b7d1e812c81817d6701bbabc05524c1e","High-spectral resolution imaging systems play a critical role in the identification and characterization of objects in a scene of interest. Unfortunately, multiple factors impair spectral resolution, as in the case of modern snapshot spectral imagers that associate each hyperpixel with a specific spectral band. In this paper, we introduce a novel postacquisition computational technique aiming to enhance the spectral dimensionality of imaging systems by exploiting the mathematical frameworks of sparse representations and dictionary learning. We propose a coupled dictionary learning model which considers joint feature spaces, composed of low- and high-spectral resolution hypercubes, in order to achieve spectral superresolution performance. We formulate our spectral coupled dictionary learning optimization problem within the context of the alternating direction method of multipliers, and we manage to update the involved quantities via closed-form expressions. In addition, we consider a realistic spectral subsampling scenario, taking into account the spectral response functions of different satellites. Moreover, we apply our spectral superresolution algorithm on real satellite data acquired by Landsat-8 and Sentinel-2 sensors. Finally, we have investigated the problem of hyperspectral image unmixing using the recovered high-spectral resolution data cube, and we are able to demonstrate that the proposed scheme provides significant value in hyperspectral image understanding techniques. Experimental results demonstrate the ability of the proposed approach to synthesize high-spectral-resolution 3-D hypercubes, achieving better performance compared to state-of-the-art resolution enhancement methods. © 1980-2012 IEEE.","Geometry; Hyperspectral imaging; Image resolution; Imaging systems; Remote sensing; Spectral resolution; Spectroscopy; Alternating direction method of multipliers; Dictionary learning; Remote sensing image processing; Resolution enhancement; Sparse representation; Super resolution; algorithm; data acquisition; experimental study; image analysis; image processing; imaging method; numerical model; optimization; pixel; satellite altimetry; Sentinel; spectral analysis; spectral resolution; Image enhancement","Alternating direction method of multipliers; coupled dictionary learning; hyperspectral image enhancement; remote sensing image processing; sparse representations; spectral resolution enhancement; spectral super-resolution","Article","Final","","Scopus","2-s2.0-85056563919"
"Acito N.; Diani M.; Corsini G.","Acito, Nicola (8390872300); Diani, Marco (7003735775); Corsini, Giovanni (7103074007)","8390872300; 7003735775; 7103074007","PRISMA Spatial Resolution Enhancement by Fusion with Sentinel-2 Data","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","62","79","17","10.1109/JSTARS.2021.3132135","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120878788&doi=10.1109%2fJSTARS.2021.3132135&partnerID=40&md5=5fbb2d984dd0d010dcf2cb44099fda6f","This article deals with the problem of improving the spatial resolution of hyperspectral (HS) data from the PRecursore IperSpettrale della Missione Applicativa (PRISMA) mission. For this purpose, higher spatial resolution data from the Sentinel-2 (S2) mission are exploited. Particularly, 10 S2 bands at 10 and 20 m spatial resolution are used to accomplish the PRISMA super-resolution (SR) task. The article presents a new end-to-end procedure, called PRISMA-SR, that starting from the S2 data and the low-resolution PRISMA image, provides a super-resolved image with a spatial resolution of 10 m and the same spectral resolution as the PRISMA HS sensor. The first step of the PRISMA-SR procedure consists in fusing S2 data at different spatial resolutions to obtain a synthetic MS image with 10 m spatial resolution and 10 spectral bands. Then, an unsupervised procedure is applied to coregister the fused S2 image and the PRISMA image. Finally, the two images at different spatial resolutions are properly combined in order to obtain the super-resolved HS image. Solutions for each step of the PRISMA-SR processing chain are proposed and discussed. Simulated data are used to show the effectiveness of the PRISMA-SR scheme and to investigate the impact on its performance of each step of the processing chain. Real S2 and PRISMA images are finally considered to provide an example of the application of the PRISMA-SR. © 2008-2012 IEEE.","Chains; Data fusion; Data handling; Hyperspectral imaging; Spectroscopy; European Space Agency; HyperSpectral; Hyperspectral Data; Hyperspectral data processing; Hyperspectral-multispectral data fusion; Multi-spectral data; Processing chain; Satellite mission; Spatial resolution; Superresolution; data processing; data set; satellite imagery; Sentinel; spatial resolution; spectral analysis; Image resolution","Hyperspectral (hs) data processing; Hyperspectral (hs)-multispectral (ms) data fusion; Satellite missions","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85120878788"
"Liebel L.; Körner M.","Liebel, L. (56938680000); Körner, M. (57190168095)","56938680000; 57190168095","Single-image super resolution for multispectral remote sensing data using convolutional neural networks","2016","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","41","","","883","890","7","10.5194/isprsarchives-XLI-B3-883-2016","91","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978081674&doi=10.5194%2fisprsarchives-XLI-B3-883-2016&partnerID=40&md5=dadf2c4296fb6012db985cae90e14967","In optical remote sensing, spatial resolution of images is crucial for numerous applications. Space-borne systems are most likely to be affected by a lack of spatial resolution, due to their natural disadvantage of a large distance between the sensor and the sensed object. Thus, methods for single-image super resolution are desirable to exceed the limits of the sensor. Apart from assisting visual inspection of datasets, post-processing operations-e.g., segmentation or feature extraction-can benefit from detailed and distinguishable structures. In this paper, we show that recently introduced state-of-The-Art approaches for single-image super resolution of conventional photographs, making use of deep learning techniques, such as convolutional neural networks (CNN), can successfully be applied to remote sensing data. With a huge amount of training data available, end-To-end learning is reasonably easy to apply and can achieve results unattainable using conventional handcrafted algorithms. We trained our CNN on a specifically designed, domain-specific dataset, in order to take into account the special characteristics of multispectral remote sensing data. This dataset consists of publicly available SENTINEL-2 images featuring 13 spectral bands, a ground resolution of up to 10m, and a high radiometric resolution and thus satisfying our requirements in terms of quality and quantity. In experiments, we obtained results superior compared to competing approaches trained on generic image sets, which failed to reasonably scale satellite images with a high radiometric resolution, as well as conventional interpolation methods.","Convolution; Feature extraction; Image resolution; Neural networks; Optical resolving power; Radiometry; Space optics; Convolutional neural network; Deep learning; Multispectral remote sensing; Optical remote sensing; Radiometric resolution; Sentinel-2; Single images; State-of-the-art approach; Remote sensing","Convolutional Neural Networks; Deep Learning; Sentinel-2; Single-Image Super Resolution","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-84978081674"
"Zhang R.; Cavallaro G.; Jitsev J.","Zhang, Run (57222248284); Cavallaro, Gabriele (55636444100); Jitsev, Jenia (26023272900)","57222248284; 55636444100; 26023272900","Super-Resolution of Large Volumes of Sentinel-2 Images with High Performance Distributed Deep Learning","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323734","617","620","3","10.1109/IGARSS39084.2020.9323734","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101993700&doi=10.1109%2fIGARSS39084.2020.9323734&partnerID=40&md5=45e7113e1f079b4a3c527fd702cd89a4","This work proposes a novel distributed deep learning model for Remote Sensing (RS) images super-resolution. High Performance Computing (HPC) systems with GPUs are used to accelerate the learning of the unknown low to high resolution mapping from large volumes of Sentinel-2 data. The proposed deep learning model is based on self-attention mechanism and residual learning. The results demonstrate that state-of-the-art performance can be achieved by keeping the size of the model relatively small. Synchronous data parallelism is applied to scale up the training process without severe performance loss. Distributed training is thus shown to speed up learning substantially while keeping performance intact. © 2020 IEEE.","Geology; Learning systems; Optical resolving power; Program processors; Remote sensing; Attention mechanisms; Data parallelism; High performance computing systems; Performance loss; Remote sensing images; State-of-the-art performance; Super resolution; Training process; Deep learning","distributed deep learning; high performance computing; Sentinel-2; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85101993700"
"","","","2022 24th ISPRS Congress ""Imaging Today, Foreseeing Tomorrow"", Commission II","2022","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","2","","","","1656","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132260519&partnerID=40&md5=3a44894dababbcd8ea7605cf50a7938a","The proceedings contain 53 papers. The topics discussed include: radiometric calibration performance of a multispectral camera with a single sensor and multiple heads; point cloud simulator for space in-orbit close range autonomous operations; impact of deep learning-based super-resolution on building footprint extraction; a novel geometric key-frame selection method for visual-inertial slam and odometry systems; importance of precise gravity field modeling in direct georeferencing and aerial photogrammetry: a case study for Sweden; a combined color and wave-based approach to satellite derived bathymetry using deep learning; multi-temporal data augmentation for high frequency satellite imagery: a case study in sentinel-1 and Sentinel-2 building and road segmentation; database storage and transparent memory loading of big spatial datasets implemented with the dual half-edge data structure; an artificial intelligence-based solution for the classification of oak decline potential; geomatics vocational education in China: current situation and recent developments; and collaborative education model on GIS major under the professional certification of engineering education.","","","Conference review","Final","","Scopus","2-s2.0-85132260519"
"Ayala C.; Aranda C.; Galar M.","Ayala, C. (55642388700); Aranda, C. (57211636468); Galar, M. (35731257600)","55642388700; 57211636468; 35731257600","SUB-PIXEL WIDTH ROAD NETWORK EXTRACTION USING SENTINEL-2 IMAGERY","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","2174","2177","3","10.1109/IGARSS47720.2021.9555128","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129806040&doi=10.1109%2fIGARSS47720.2021.9555128&partnerID=40&md5=271f1d0645c924d15057a31a93a9cf6a","Nowadays, road maps play a key role in our society. Therefore, keeping those maps up-to-date is highly important. The extraction of road networks from satellite imagery is a complex problem, not only because of occlusions, shadows produced by non-road objects, but also due to the limited spatial resolution of the imagery used. The feasibility to detect a road depends on its width, which can reach sub-pixel size in some satellite products. In the last decade, many attempts have been carried out to automatize this labour. However, the vast majority of methods rely on aerial imagery, whose costs are not yet affordable for maintaining up-to-date maps. This work demonstrates that it is also possible to accurately detect roads using freely available Sentinel-2 imagery, regardless of their width. For that purpose, a new deep learning architecture which combines semantic segmentation and super-resolution techniques is proposed. As a result, fine-grained road network maps at 2.5 m are generated from 10 m imagery taken as input. To evaluate this proposal a data-set composed of 20 cities spread across the Spanish territory is used.  © 2021 IEEE.","Aerial photography; Antennas; Convolutional neural networks; Deep neural networks; Extraction; Pixels; Roads and streets; Satellite imagery; Semantic Segmentation; Semantics; Complex problems; Convolutional neural network; Deep learning; Non-road; Remote-sensing; Road network; Road network extraction; Roadmap; Sentinel-2; Sub-pixels; Remote sensing","Convolutional Neural Networks; Deep Learning; Remote Sensing; Road Network Extraction; Sentinel-2","Conference paper","Final","","Scopus","2-s2.0-85129806040"
"Gargiulo M.; Dell'aglio D.A.G.; Iodice A.; Riccio D.; Ruello G.","Gargiulo, M. (57200856555); Dell'aglio, D.A.G. (57202729372); Iodice, A. (7003793925); Riccio, D. (7006577607); Ruello, G. (6603038881)","57200856555; 57202729372; 7003793925; 7006577607; 6603038881","A CNN-based Super-resolution Technique for Active Fire Detection on Sentinel-2 Data","2019","Progress in Electromagnetics Research Symposium","2019-June","","9017857","418","426","8","10.1109/PIERS-Spring46901.2019.9017857","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081992611&doi=10.1109%2fPIERS-Spring46901.2019.9017857&partnerID=40&md5=12f5ad36cc40e80e72790d9e59f1963d","Remote Sensing applications can benefit from a relatively fine spatial resolution multispectral (MS) images and a high revisit frequency ensured by the twin satellites Sentinel-2. Unfortunately, only four out of thirteen bands are provided at the highest resolution of 10 meters, and the others at 20 or 60 meters. For instance the Short-Wave Infrared (SWIR) bands, provided at 20 meters, are very useful to detect active fires. Aiming to a more detailed Active Fire Detection (AFD) maps, we propose a super-resolution data fusion method based on Convolutional Neural Network (CNN) to move towards the 10-m spatial resolution the SWIR bands. The proposed CNN-based solution is compared to alternative methods in terms of some accuracy metrics. Moreover we have tested the super-resolved bands from an application point of view by monitoring active fire through classic indices. Advantages and limits of our proposed approach are validated on specific geographical area (the mount Vesuvius, close to Naples) that was damaged by widespread fires during the summer of 2017. © 2019 IEEE.","Convolutional neural networks; Data fusion; Fire detectors; Image resolution; Infrared radiation; Optical resolving power; Photonics; Piers; Remote sensing; Data fusion methods; Geographical area; Highest resolutions; Multispectral images; Remote sensing applications; Short wave infrared bands; Spatial resolution; Super resolution; Fires","","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85081992611"
"","","","2022 24th ISPRS Congress ""Imaging Today, Foreseeing Tomorrow"", Commission III","2022","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","3","","","","1656","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132034443&partnerID=40&md5=a48264e28ca5fc6046de8c3476daca26","The proceedings contain 93 papers. The topics discussed include: radiometric calibration performance of a multispectral camera with a single sensor and multiple heads; point cloud simulator for space in-orbit close range autonomous operations; impact of deep learning-based super-resolution on building footprint extraction; a novel geometric key-frame selection method for visual-inertial slam and odometry systems; importance of precise gravity field modeling in direct georeferencing and aerial photogrammetry: a case study for Sweden; a combined color and wave-based approach to satellite derived bathymetry using deep learning; multi-temporal data augmentation for high frequency satellite imagery: a case study in sentinel-1 and Sentinel-2 building and road segmentation; database storage and transparent memory loading of big spatial datasets implemented with the dual half-edge data structure; an artificial intelligence-based solution for the classification of oak decline potential; geomatics vocational education in China: current situation and recent developments; and collaborative education model on GIS major under the professional certification of engineering education.","","","Conference review","Final","","Scopus","2-s2.0-85132034443"
"Su W.; Yao C.; Li Y.; Zhang M.; Zhao G.; Liu J.","Su, Wei (56506117700); Yao, Chan (57210915740); Li, Ying (57189603280); Zhang, Mingzheng (57020048200); Zhao, Guoqiang (57223217432); Liu, Junming (54410835800)","56506117700; 57210915740; 57189603280; 57020048200; 57223217432; 54410835800","LAI Retrieving of Corn Canopy Based on SupReMe Image Reconstruction and Random Forest; [基于SupReMe影像重建和RF的玉米冠层LAI反演]","2021","Nongye Jixie Xuebao/Transactions of the Chinese Society for Agricultural Machinery","52","4","","190","196and256","196066","10.6041/j.issn.1000-1298.2021.04.020","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105278888&doi=10.6041%2fj.issn.1000-1298.2021.04.020&partnerID=40&md5=ee9eb9713e6ab8cc272a9f3dfbccd198","Leaf area index (LAI) is of great significance for crop growth monitoring, agricultural disaster stress monitoring and yield prediction. There are three red-edge bands (705 nm, 740 nm, 783 nm) for Sentinel-2 satellite images, which are very sensitive to vegetation growth. Unfortunately, the spatial resolution of these three red-edge bands (20 m) is inconsistent with that of visible and near infrared bands (10 m), which limits the application of Sentinel-2 images. For solving this problem, the six bands with spatial resolution of 20 m was reconstructed into the spatial resolution of 10 m by using super-resolution for multispectral multiresolution estimation (SupReMe) algorithm. Using the reconstructed Sentinel-2 image, the corn canopy LAI was retrieved by using the PROSAIL radiative transfer model and the random forest machine learning method. The results showed that the space details of Sentinel-2 image were improved while the spectral invariance was maintained after reconstruction by using SupReMe algorithm. The determination coefficients (R2) of LAI retrieving using reconstructed image was improved from 0.70 to 0.68 compared with resampling Sentinel-2 image, and the root mean square error (RSME) was improved from 0.240 to 0.262. The results showed that the SupReMe method can be used to reconstruct the spatial resolution of Sentinel-2 image and the reconstructed image can be used to improve corn canopy LAI retrieving accuracy. © 2021, Chinese Society of Agricultural Machinery. All right reserved.","Agricultural robots; Decision trees; Image enhancement; Image resolution; Infrared devices; Learning systems; Mean square error; Radiative transfer; Random forests; Superconducting materials; Yield stress; Agricultural disasters; Determination coefficients; Radiative transfer model; Reconstructed image; Root mean square errors; Spatial resolution; Spectral invariances; Visible and near infrared; Image reconstruction","Corn canopy; Leaf area index; PROSAIL model; Random forest; Super-resolution reconstruction; SupReMe algorithm","Article","Final","","Scopus","2-s2.0-85105278888"
"Kawulok M.; Tarasiewicz T.; Ziaja M.; Tyrna D.; Kostrzewa D.; Nalepa J.","Kawulok, Michal (24474818300); Tarasiewicz, Tomasz (57221256061); Ziaja, Maciej (57289153600); Tyrna, Diana (57481733800); Kostrzewa, Daniel (50661666400); Nalepa, Jakub (55441340400)","24474818300; 57221256061; 57289153600; 57481733800; 50661666400; 55441340400","Multiple-image super-resolution reconstruction using deep learning: A Sentinel-2 case study","2021","Proceedings of the International Astronautical Congress, IAC","B1","","","","","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127817910&partnerID=40&md5=07be06fca8e01bac741b2c1c9768a36b","Super-resolution reconstruction embraces a variety of techniques aimed at generating a high-resolution image from a low-resolution input. The goals of super-resolution range from hallucination that consists in producing a visually-attractive high-resolution image to reconstructing the real high-resolution information that is commonly required in Earth observation scenarios. The latter can be achieved by fusing a number of images with the same georeference, captured at a different time. Such multi-image super-resolution solutions underpinned with deep learning have been recently proposed for enhancing images acquired with the Proba-V sensor. This satellite captures images of 100 m and 300 m ground sampling distance, which makes it relatively easy to collect sufficient amounts of real-world data that can be used for training deep convolutional neural networks. As such data are unavailable for most of other satellites, alternative ways for training the networks must be adopted. In this paper, we demonstrate our solution for super-resolving multispectral Sentinel-2 images, and we present its most important components that may help implement multi-image super-resolution for other satellites. Our main focus is on the data that are used for training, as well as on the low-resolution images that are presented for reconstruction. We expect that the reported techniques will allow for increasing the capabilities of using Sentinel-2 images in a variety of practical Earth observation scenarios, but even more importantly, the presented methodology may be helpful in exploiting multiple-image SR for enhancing images captured with other satellites. Copyright © 2021 by the International Astronautical Federation (IAF). All rights reserved.","Convolutional neural networks; Deep neural networks; Image reconstruction; Observatories; Optical resolving power; Satellites; Deep learning; Earth observations; High-resolution images; Image super resolutions; Image super-resolution reconstruction; Multi-image super-resolution; Multi-images; Multiple image; Sentinel-2; Super-resolution reconstruction; Image enhancement","Deep learning; Multi-image super-resolution; Sentinel-2; Super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85127817910"
"Bratsolis E.; Panagiotopoulou A.; Stefouli M.; Charou E.; Madamopoulos N.; Perantonis S.","Bratsolis, Emmanuel (6603338911); Panagiotopoulou, Antigoni (24479152700); Stefouli, Marianthi (6506668706); Charou, Eleni (6507509159); Madamopoulos, Nicholas (6604012410); Perantonis, Stavros (7004909153)","6603338911; 24479152700; 6506668706; 6507509159; 6604012410; 7004909153","Comparison of optimized mathematical methods in the improvement of raster data and map display resolution of sentinel-2 images","2018","Proceedings - International Conference on Image Processing, ICIP","","","8451729","2521","2525","4","10.1109/ICIP.2018.8451729","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062916418&doi=10.1109%2fICIP.2018.8451729&partnerID=40&md5=c4d6988d9ad67929b7e2d627cc4d7623","High-Resolution (HR) satellite images are a prerequisite in many applications such as astronomy, remote sensing, geoscience and geographical information systems, not only for providing better visualization but also for extracting extra information details. In the present work a comparative study of different single image resolution enhancement techniques is carried out on Sentinel-2 images of bands B2, B3, B4 and B8. The authors describe the stochastic regularized super-resolution (SR) reconstruction technique and compare with others. The techniques under comparison are stochastic regularized SR reconstruction (SRSR), spatial-wavelet SR reconstruction (SWSR) and the conventional interpolation techniques nearest neighbor (NN), bilinear (BL), bicubic (BC) and spline (SP). These techniques are tested against each other in terms of Root Mean Square Error (RMSE), Xydeas and Petrovich (XP), and Correlation Coefficient (CC). Simulated experiments of single image resolution increase take place. © 2018 IEEE.","Image reconstruction; Image resolution; Interpolation; Mean square error; Optical resolving power; Remote sensing; Stochastic systems; Wavelet transforms; Correlation coefficient; Interpolation techniques; Resolution increase; Root mean square errors; Satellite images; Simulated experiments; Stochastic regularized technique; Super resolution reconstruction; Image enhancement","Interpolation; Satellite image resolution enhancement; Spatial-wavelet transform; Stochastic regularized technique; Super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85062916418"
"Li Y.; Wang Y.; Li B.; Wu S.","Li, Yunhe (55647591200); Wang, Yi (57204548320); Li, Bo (57777715900); Wu, Shaohua (57189245768)","55647591200; 57204548320; 57777715900; 57189245768","Super-Resolution of Remote Sensing Images for ×4 Resolution without Reference Images","2022","Electronics (Switzerland)","11","21","3474","","","","10.3390/electronics11213474","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141875470&doi=10.3390%2felectronics11213474&partnerID=40&md5=2b0b794fd72a9dfbed4cf586766ec1e8","Sentinel-2 satellites can provide free optical remote-sensing images with a spatial resolution of up to 10 M, but the spatial details provided are not enough for many applications, so it is worth considering improving the spatial resolution of Sentinel-2 satellites images through super-resolution (SR). Currently, the most effective SR models are mainly based on deep learning, especially the generative adversarial network (GAN). Models based on GAN need to be trained on LR–HR image pairs. In this paper, a two-step super-resolution generative adversarial network (TS-SRGAN) model is proposed. The first step is having the GAN train the degraded models. Without supervised HR images, only the 10 m resolution images provided by Sentinel-2 satellites are used to generate the degraded images, which are in the same domain as the real LR images, and then to construct the near-natural LR–HR image pairs. The second step is to design a super-resolution generative adversarial network with strengthened perceptual features, to enhance the perceptual effects of the generated images. Through experiments, the proposed method obtained an average NIQE as low as 2.54, and outperformed state-of-the-art models according to other two NR-IQA metrics, such as BRISQUE and PIQE. At the same time, the comparison of the intuitive visual effects of the generated images also proved the effectiveness of TS-SRGAN. © 2022 by the authors.","","generative adversarial network; remote-sensing image; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85141875470"
"Fernandez R.; Fernandez-Beltran R.; Pla F.","Fernandez, Rafael (57222243976); Fernandez-Beltran, Ruben (55838551300); Pla, Filiberto (7006504936)","57222243976; 55838551300; 7006504936","SENTINEL-3 IMAGE SUPER-RESOLUTION USING DATA FUSION AND CONVOLUTIONAL NEURAL NETWORKS","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","2867","2870","3","10.1109/IGARSS47720.2021.9554826","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129884916&doi=10.1109%2fIGARSS47720.2021.9554826&partnerID=40&md5=85e41091ceadaed2fc3a7c5855bf1103","With the increasing availability of Sentinel-2 (S2) and Sentinel-3 (S3) data, developing higher-level data products becomes a very attractive option to relieve the spatial limitations of the Ocean and Land Colour Instrument (OLCI) of S3. In this context, this paper investigates the suitability of super-resolving operational OLCI products using the Multi-Spectral Instrument (MSI) of S2 as an offline spatial reference. Specifically, the proposed approach assembles a multi-spectral data fusion scheme together with a convolutinal neural network (CNN) mapping function to project the OLCI sensor onto its corresponding spatial reference which is synthetically generated by the OLCI/MSI fusion. In this way, the trained model is able to super-resolve operational OLCI products under demand without the need of using MSI data. The experimental part of the work shows the suitability of the proposed approach in the context of the Copernicus programme. © 2021 IEEE","Convolutional neural networks; Photomapping; Sensor data fusion; Spectral resolution; Convolutional neural network; Data products; Image super resolutions; Multi-spectral; Offline; Sentinel-2; Sentinel-3; Spatial reference; Super-resolution; Superresolution; Image fusion","image fusion; Sentinel-2 (S2); Sentinel-3 (S3); super-resolution (SR)","Conference paper","Final","","Scopus","2-s2.0-85129884916"
"","","","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","3","","","","2619","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090340500&partnerID=40&md5=0028849c5a722e5d84e936acd25e198e","The proceedings contain 342 papers. The topics discussed include: learning super-resolution for sentinel-2 images with real ground truth data from a reference satellite; combined patch-wise minimal-maximal pixels regularization for deblurring; urban material classification using spectral and textural features retrieved from autoencoders; a worldwide 3D GCP database inherited from 20 years of massive multi-satellite observations; deep learning based feature matching and its application in image orientation; a novel RPC bias model for improving the positioning accuracy of satellite images; land salinization dynamics based on feature space combinations from landsat image in Tongyu County, Northeast China; a new index for identifying water body from sentinel-2 satellite remote sensing imagery; land cover classification using convolutional neural network with remote sensing data and digital surface model; assessing resilience of infrastructures towards exogenous events by using PS-INSAR-based surface motion estimates and machine learning regression techniques; region-based fuzzy clustering image segmentation algorithm with Kullback-Leibler distance; experiences from the project course in geoinformatics; and refugees stories told by maps: a challenge for students in a scientific Olympiad.","","","Conference review","Final","","Scopus","2-s2.0-85090340500"
"Li W.; Jiang J.; Guo T.; Zhou M.; Tang Y.; Wang Y.; Zhang Y.; Cheng T.; Zhu Y.; Cao W.; Yao X.","Li, Wei (57205166392); Jiang, Jiale (56289787100); Guo, Tai (57209567732); Zhou, Meng (57203944956); Tang, Yining (57208160329); Wang, Ying (57767139300); Zhang, Yu (56662268900); Cheng, Tao (56278310400); Zhu, Yan (8921604000); Cao, Weixing (55489902600); Yao, Xia (14022139100)","57205166392; 56289787100; 57209567732; 57203944956; 57208160329; 57767139300; 56662268900; 56278310400; 8921604000; 55489902600; 14022139100","Generating red-edge images at 3M spatial resolution by fusing sentinel-2 and planet satellite products","2019","Remote Sensing","11","12","1422","","","","10.3390/rs11121422","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068177402&doi=10.3390%2frs11121422&partnerID=40&md5=c29bc81d9238fbb43dba448e861a04b9","High-resolution satellite images can be used to some extent to mitigate the mixed-pixel problem caused by the lack of intensive production, farmland fragmentation, and the uneven growth of field crops in developing countries. Specifically, red-edge (RE) satellite images can be used in this context to reduce the influence of soil background at early stages as well as saturation due to crop leaf area index (LAI) at later stages. However, the availability of high-resolution RE satellite image products for research and application globally remains limited. This study uses the weight-and-unmixing algorithm as well as the SUPer-REsolution for multi-spectral Multi-resolution Estimation (Wu-SupReME) approach to combine the advantages of Sentinel-2 spectral and Planet spatial resolution and generate a high-resolution RE product. The resultant fused image is highly correlated (R2 > 0.98) with Sentinel-2 image and clearly illustrates the persistent advantages of such products. This fused image was significantly more accurate than the originals when used to predict heterogeneous wheat LAI and therefore clearly illustrated the persistence of Sentinel-2 spectral and Planet spatial advantage, which indirectly proved that the fusion methodology of generating high-resolution red-edge products from Planet and Sentinel-2 images is possible. This study provided method reference for multi-source data fusion and image product for accurate parameter inversion in quantitative remote sensing of vegetation. © 2019 by the authors.","Crops; Developing countries; Image fusion; Image resolution; Planets; Remote sensing; Fusion image; Sentinel-2; SupReME; Unmixing; Wheat LAI; Satellites","Fusion image; Planet; Sentinel-2; SupReME; Weight-and-unmixing; Wheat LAI","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85068177402"
"Zhang M.; Su W.; Fu Y.; Zhu D.; Xue J.-H.; Huang J.; Wang W.; Wu J.; Yao C.","Zhang, Mingzheng (57020048200); Su, Wei (56506117700); Fu, Yuting (57210915922); Zhu, D. (8903358300); Xue, Jing-Hao (7202881908); Huang, Jianxi (8206714700); Wang, Wei (57211077340); Wu, J. (57210921790); Yao, Chan (57210915740)","57020048200; 56506117700; 57210915922; 8903358300; 7202881908; 8206714700; 57211077340; 57210921790; 57210915740","Super-resolution enhancement of Sentinel-2 image for retrieving LAI and chlorophyll content of summer corn","2019","European Journal of Agronomy","111","","125938","","","","10.1016/j.eja.2019.125938","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071854270&doi=10.1016%2fj.eja.2019.125938&partnerID=40&md5=8a608ed4631751d4db063e2e8fce440f","Sentinel-2 satellite is a new generation of multi-spectral remote sensing technique with high spatial, temporal and spectral resolution. Especially, Sentinel-2 incorporates three red-edge bands with central wavelength at 705, 740 and 783 nm, which are very sensitive to vegetation changing, heath and variations. Unfortunately, their spatial resolution is only 20 m, which is lower comparably. This spatial resolution brings difficulties for mining the potential of Sentinel-2 image in vegetation monitoring. Therefore, we focus on enhancing the spatial resolution of Sentinel-2 red edge band images to 10m using the SupReME algorithm. Furthermore, the summer corn canopy leaf area index (LAI), leaves chlorophyll content (LCC) and canopy chlorophyll content (CCC) were retrieved by the linear and physical models for the corn growth monitoring purpose. The results showed that the spatial resolution of Sentinel-2 images had been enhanced to 10m from original 20m, and the estimation accuracy (EA) was over 97% for pixels planted by summer corn. Moreover, the accuracy of summer corn canopy LAI, LCC and CCC was improved respectively using enhanced Sentinel-2 images by SupReME method. During these three parameters retrieval, the red-edge bands or SWIR bands were introduced into optimal cost function and vegetation index which the accuracy of these models was high. The SupReME algorithm provides a valuable way for Sentinel-2 images enhancement, which is of great potential to mining Sentinel-2 images and multitude its application. © 2019","Zea mays; accuracy assessment; algorithm; chlorophyll; leaf area index; maize; numerical model; radiative transfer; remote sensing; satellite imagery; Sentinel; spatial resolution; spectral resolution; summer","Chlorophyll content; LAI; Radiative transfer model; Sentinel-2 image; SupReME algorithm","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85071854270"
"Raphiphan Y.; Khetkeeree S.; Liangrocapart S.","Raphiphan, Yaowamal (57224214829); Khetkeeree, Suphongsa (57194030107); Liangrocapart, Sompong (8924421800)","57224214829; 57194030107; 8924421800","Sharpening the Sentinel-2A Infrared Bands via Image Residual Optimization","2022","19th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, ECTI-CON 2022","","","","","","","10.1109/ECTI-CON54298.2022.9795632","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133377020&doi=10.1109%2fECTI-CON54298.2022.9795632&partnerID=40&md5=3496e160f1571061b8f86480e36d39cb","Due to the infrared bands, i.e., short-wave infrared (SWIR) and narrow near-infrared (narrow NIR) bands, obtained from the Sentinel-2 multispectral instrument has a lower resolution than the visible-near infrared (VNIR) bands. Therefore, the capability of applications that employ infrared information is often limited by its spatial resolution. To overcome this problem, we propose a method for sharpening these infrared bands. This method is based on the multiresolution analysis (MRA) method, which focuses on the image residual in the spatial domain. The sharpened image can be obtained from the combination of the low-frequency (LF) and high-frequency (HF) components. The residual image is performed as the HF components, which can be estimated from the difference between the original image and its smoothing (blurring) version. The bicubic interpolation was applied to generate the LF component. The least-square error of the image residual was employed to determine the optimal injection weight, which can be expressed in the analytic form. The Sentinel-2A images of Central Thailand were used to test our proposed method and then compared to conventional sharpening methods, such as Gram-Schmitt, Intensity-Hue-Saturation (HIS), and Brovey methods. The results show that our proposed method can give quality metrics higher than others. Moreover, our composited infrared band image also gives color similar to the native composite image. © 2022 IEEE.","Infrared devices; Remote sensing; Image upscaling; Infrared bands; Least squares errors; Multi-resolution analysis; Multiresolution analyse-based; Multiresolutions analysis; Near infrared band; Pan-sharpening; Superresolution; Upscaling; Infrared radiation","image upscaling; least-square error; MRA-based; pan-sharpening; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85133377020"
"Paris C.; Bioucas-Dias J.; Bruzzone L.","Paris, Claudia (56042202900); Bioucas-Dias, Jose (55901520500); Bruzzone, Lorenzo (7006892410)","56042202900; 55901520500; 7006892410","A Novel Sharpening Approach for Superresolving Multiresolution Optical Images","2019","IEEE Transactions on Geoscience and Remote Sensing","57","3","8472286","1545","1546","1","10.1109/TGRS.2018.2867284","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054202902&doi=10.1109%2fTGRS.2018.2867284&partnerID=40&md5=392443fc778db05349fcecb407255124","This paper aims to provide a compact superresolution formulation specific for multispectral (MS) multiresolution optical data, i.e., images characterized by different scales across different spectral bands. The proposed method, named multiresolution sharpening approach (MuSA), relies on the solution of an optimization problem tailored to the properties of those images. The superresolution problem is formulated as the minimization of an objective function containing a data-fitting term that models the blurs and downsamplings of the different bands and a patch-based regularizer that promotes image self-similarity guided by the geometric details provided by the high-resolution bands. By exploiting the approximately low-rank property of the MS data, the ill-posedness of the inverse problem in hand is strongly reduced, thus sharply improving its conditioning. The state-of-the-art color block-matching and 3D filtering (C-BM3D) image denoiser is used as a patch-based regularizer by leveraging the 'plug-and-play' framework: the denoiser is plugged into the iterations of the alternating direction method of multipliers. The main novelties of the proposed method are: 1) the introduction of an observation model tailored to the specific properties of (MS) multiresolution images and 2) the exploitation of the high-spatial-resolution bands to guide the grouping step in the color block-matching and 3D filtering (C-BM3D) denoiser, which constitutes a form of regularization learned from the high-resolution channels. The results obtained on the real and synthetic Sentinel 2 data sets give an evidence of the effectiveness of the proposed approach. © 1980-2012 IEEE.","Musa; Color; Color matching; Geometrical optics; Image denoising; Image resolution; Motion compensation; Optical resolving power; Remote sensing; Satellite imagery; Alternating direction method of multiplier (ADMM); Bayes method; Block matching and 3d filtering; Dimensionality reduction; Image color analysis; MODIS; Multiresolution images; Optical imaging; Plug and play; Self-similarities; Signal resolution; Spatial resolution; Super resolution; data set; geometry; image analysis; inverse problem; numerical model; optical method; optimization; remote sensing; spectral resolution; three-dimensional modeling; Inverse problems","Alternating direction method of multipliers (ADMM); color block-matching and 3D filtering (C-BM3D); dimensionality reduction; multispectral (MS) multiresolution images; plug-and-play; remote sensing; self-similarity; superresolution","Article","Final","","Scopus","2-s2.0-85054202902"
"Wu S.; Yang P.; Ren J.; Chen Z.; Liu C.","Wu, Shangrong (55607162400); Yang, Peng (55510452900); Ren, Jianqiang (14021882100); Chen, Zhongxin (14021042100); Liu, Changan (56420745800)","55607162400; 55510452900; 14021882100; 14021042100; 56420745800","A Novel Sub-Pixel Mapping Model Based on Pixel Aggregation Degree for Small-Sized Land-Cover","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8899769","3073","3076","3","10.1109/IGARSS.2019.8899769","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077698542&doi=10.1109%2fIGARSS.2019.8899769&partnerID=40&md5=73826dd954c035f841ffd1ad1082a452","To further improve the accuracy of remote sensing classification and land-cover recognition at sub-pixel level, a novel sub-pixel mapping (SPM) model was first proposed by introducing the concept of pixel aggregation degree (PAD) which could simulate the spatial distribution of small-sized land-cover. In the proposed novel SPM model, based on the distribution of sub-pixel random initialization, PAD algorithm was optimized sub-pixel distribution to obtain final SPM results. Using a Sentinel-2 remote sensing data, related SPM experiments were performed to verify both accuracy and effect of PAD SPM model. The experimental results indicated that the SPM accuracy based on PAD model were superior to the classification results of the K-mean and the SPM results of traditional spatial attraction model. It was shown that the PAD model had certain feasibility and applicability which provided a new idea to better break the limitations of remote sensing image spatial resolution, and was beneficial to the subsequent research and application of remote sensing image. © 2019 IEEE.","Geology; Mapping; Pixels; Classification results; Land cover; Optimization algorithms; Remote sensing classification; Remote sensing images; Research and application; Sub-pixel mapping; Super-resolution mappings; Remote sensing","optimization algorithm; pixel aggregation degree; small-sized land-cover; sub-pixel mapping; super-resolution mapping","Conference paper","Final","","Scopus","2-s2.0-85077698542"
"Ciotola M.; Ragosta M.; Poggi G.; Scarpa G.","Ciotola, M. (57239080700); Ragosta, M. (57482714100); Poggi, G. (7005255639); Scarpa, G. (7004081145)","57239080700; 57482714100; 7005255639; 7004081145","A FULL-RESOLUTION TRAINING FRAMEWORK FOR SENTINEL-2 IMAGE FUSION","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","1260","1263","3","10.1109/IGARSS47720.2021.9553199","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126048737&doi=10.1109%2fIGARSS47720.2021.9553199&partnerID=40&md5=46a1a617adc1e855caea5f9b48a22303","This work presents a new unsupervised framework for training deep learning models for super-resolution of Sentinel-2 images by fusion of its 10-m and 20-m bands. The proposed scheme avoids the resolution downgrade process needed to generate training data in the supervised case. On the other hand, a proper loss that accounts for cycle-consistency between the network prediction and the input components to be fused is proposed. Despite its unsupervised nature, in our preliminary experiments the proposed scheme has shown promising results in comparison to the supervised approach. Besides, by construction of the proposed loss, the resulting trained network can be ascribed to the class of multi-resolution analysis methods. © 2021 IEEE.","","Convolutional neural network; Data-fusion; Machine learning; Sentinel-2; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85126048737"
"Abadal S.; Salgueiro L.; Marcello J.; Vilaplana V.","Abadal, Saüc (57345222200); Salgueiro, Luis (57344768400); Marcello, Javier (6602158797); Vilaplana, Verónica (23394280500)","57345222200; 57344768400; 6602158797; 23394280500","A dual network for super-resolution and semantic segmentation of sentinel-2 imagery","2021","Remote Sensing","13","22","4547","","","","10.3390/rs13224547","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119333436&doi=10.3390%2frs13224547&partnerID=40&md5=e25e818f298bd6b4bf49de4703f49aee","There is a growing interest in the development of automated data processing workflows that provide reliable, high spatial resolution land cover maps. However, high-resolution remote sensing images are not always affordable. Taking into account the free availability of Sentinel-2 satellite data, in this work we propose a deep learning model to generate high-resolution segmentation maps from low-resolution inputs in a multi-task approach. Our proposal is a dual-network model with two branches: the Single Image Super-Resolution branch, that reconstructs a high-resolution version of the input image, and the Semantic Segmentation Super-Resolution branch, that predicts a high-resolution segmentation map with a scaling factor of 2. We performed several experiments to find the best architecture, training and testing on a subset of the S2GLC 2017 dataset. We based our model on the DeepLabV3+ architecture, enhancing the model and achieving an improvement of 5% on IoU and almost 10% on the recall score. Furthermore, our qualitative results demonstrate the effectiveness and usefulness of the proposed approach. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolution; Convolutional neural networks; Data handling; Deep learning; Network architecture; Optical resolving power; Remote sensing; Semantic Web; Semantics; Statistical tests; Automated data processing; Convolutional neural network; Deep learning; High resolution; High spatial resolution; Segmentation map; Semantic segmentation; Sentinel-2; Superresolution; Work-flows; Semantic Segmentation","Convolutional neural network; Deep learning; Semantic segmentation; Sentinel-2; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85119333436"
"Panagiotopoulou A.; Grammatikopoulos L.; Kalousi G.; Charou E.","Panagiotopoulou, Antigoni (24479152700); Grammatikopoulos, Lazaros (16068804700); Kalousi, Georgia (57223009413); Charou, Eleni (6507509159)","24479152700; 16068804700; 57223009413; 6507509159","Sentinel-2 and SPOT-7 Images in Machine Learning Frameworks for Super-Resolution","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12667 LNCS","","","462","476","14","10.1007/978-3-030-68787-8_34","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104407750&doi=10.1007%2f978-3-030-68787-8_34&partnerID=40&md5=760731382977b68e82515020f1757747","Monitoring construction sites from space using high-resolution (HR) imagery enables remote tracking instead of physically traveling to a site. Thus, valuable resources are saved while recording of the construction site progression at anytime and anywhere in the world is feasible. In the present work Sentinel-2 (S2) images at 10 m (m) are spatially super-resolved per factor 4 by means of deep-learning. Initially, the very-deep super-resolution (VDSR) network is trained with matching pairs of S2 and SPOT-7 images at 2.5 m target resolution. Then, the trained VDSR network, named SPOT7-VDSR, becomes able to increase the resolution of S2 images which are completely unknown to the net. Additionally, the VDSR net technique and bicubic interpolation are applied to increase the resolution of S2. Numerical and visual comparisons are carried out on the area of interest Karditsa, Greece. The current study of super-resolving S2 images is novel in the literature and can prove very useful in application cases where only S2 images are available and not the corresponding SPOT-7 higher-resolution ones. During the present super-resolution (SR) experimentations, the proposed net SPOT7-VDSR outperforms the VDSR net up to 8.24decibel in peak signal to noise ratio (PSNR) and bicubic interpolation up to 16.9% in structural similarity index (SSIM). © 2021, Springer Nature Switzerland AG.","Deep learning; Interpolation; Optical resolving power; Pattern recognition; Area of interest; Bicubic interpolation; Construction sites; Higher resolution; Monitoring construction; Peak signal to noise ratio; Structural similarity indices (SSIM); Visual comparison; Signal to noise ratio","Deep-learning; Sentinel-2; Spatial resolution; SPOT-7; SPOT7-VDSR; Super-resolution; VDSR","Conference paper","Final","","Scopus","2-s2.0-85104407750"
"Galar M.; Sesma R.; Ayala C.; Albizua L.; Aranda C.","Galar, M. (35731257600); Sesma, R. (57211638474); Ayala, C. (55642388700); Albizua, L. (35423280700); Aranda, C. (57211636468)","35731257600; 57211638474; 55642388700; 35423280700; 57211636468","Learning Super-Resolution for Sentinel-2 Images with Real Ground Truth Data from A Reference Satellite","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","1","","9","16","7","10.5194/isprs-annals-V-1-2020-9-2020","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091084506&doi=10.5194%2fisprs-annals-V-1-2020-9-2020&partnerID=40&md5=8b2fd2c1efd7620a6a22af3e15e3181c","Copernicus program via its Sentinel missions is making earth observation more accessible and affordable for everybody. Sentinel-2 images provide multi-spectral information every 5 days for each location. However, the maximum spatial resolution of its bands is 10m for RGB and near-infrared bands. Increasing the spatial resolution of Sentinel-2 images without additional costs, would make any posterior analysis more accurate. Most approaches on super-resolution for Sentinel-2 have focused on obtaining 10m resolution images for those at lower resolutions (20m and 60m), taking advantage of the information provided by bands of finer resolutions (10m). Otherwise, our focus is on increasing the resolution of the 10m bands, that is, super-resolving 10m bands to 2.5m resolution, where no additional information is available. This problem is known as single-image super-resolution and deep learning-based approaches have become the state-of-the-art for this problem on standard images. Obviously, models learned for standard images do not translate well to satellite images. Hence, the problem is how to train a deep learning model for super-resolving Sentinel-2 images when no ground truth exist (Sentinel-2 images at 2.5m). We propose a methodology for learning Convolutional Neural Networks for Sentinel-2 image super-resolution making use of images from other sensors having a high similarity with Sentinel-2 in terms of spectral bands, but greater spatial resolution. Our proposal is tested with a state-of-the-art neural network showing that it can be useful for learning to increase the spatial resolution of RGB and near-infrared bands of Sentinel-2. © 2020 Copernicus GmbH. All rights reserved.","Convolutional neural networks; Image resolution; Infrared devices; Learning systems; Optical resolving power; Earth observations; Image super resolutions; Learning-based approach; Near infrared band; Posterior analysis; Reference satellites; Resolution images; Spatial resolution; Deep learning","Convolutional Neural Networks; Deep Learning; Multi-Spectral Images; Sentinel-2; Super-Resolution","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85091084506"
"Armannsson S.E.; Sigurdsson J.; Sveinsson J.R.; Ulfarsson M.O.","Armannsson, Sveinn E. (57224686207); Sigurdsson, Jakob (7006736374); Sveinsson, Johannes R. (7003642214); Ulfarsson, Magnus O. (6507677875)","57224686207; 7006736374; 7003642214; 6507677875","TUNING PARAMETER SELECTION FOR SENTINEL-2 SHARPENING USING WALD'S PROTOCOL","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","2871","2874","3","10.1109/IGARSS47720.2021.9553346","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108172775&doi=10.1109%2fIGARSS47720.2021.9553346&partnerID=40&md5=fc17329332698064df5d7ce376df6a56","In recent years numerous model-based methods for super-resolution of Sentinel-2 (S2) multispectral images have been suggested. Super-resolution aims to enhance the resolution of a captured image by upscaling and enhancing the details. The performance of model-based methods relies on carefully selecting regularizers and tuning parameters. This paper investigates whether using Wald's protocol, i.e., selecting tuning parameters at reduced-resolution, translates to a good performance at a full-scale. To investigate this, we use the recently proposed S2Sharp method and show that selecting its tuning parameters using Wald's protocol improves its performance. © 2021 IEEE.","","Image fusion; Image sharpening; Multispectral (MS) multiresolution images; Parameter selection; Scale invariance; Sentinel-2 constellation; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85108172775"
"Wang X.-Q.; Ji T.-Y.","Wang, Xuan-Qi (57224203667); Ji, Teng-Yu (56898567800)","57224203667; 56898567800","NSTMR: Super Resolution of Sentinel-2 Images Using Nonlocal Nonconvex Surrogate of Tensor Multirank","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9440747","5694","5706","12","10.1109/JSTARS.2021.3083495","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107172026&doi=10.1109%2fJSTARS.2021.3083495&partnerID=40&md5=06cae9708a3a84bdace323ddf45b34a1","In this article, we address the super-resolution problems, which estimate the high-resolution multispectral images from the multispectral Sentinel-2 (S2) images with different resolutions. Since S2 images can be naturally represented by tensors, we reformulate the degradation process as the tensor-based form. Based on the degradation mechanism, we build a tensor-based optimization model for S2 images super-resolution problem, which fully exploits intrinsic nonlocal spatial similarity and global spectral redundancy. Specifically, the model consists of the data fidelity term and the low-multirank regularizer tailored to thoroughly mining the inherent spatial-nonlocal and spectral redundancy. Then, we develop an efficient alternating direction method of multipliers algorithm with theoretically guaranteed convergence to tackle the resulting tensor optimization problem. Numerical experiments including simulated and real data demonstrate that our method outperforms the competing methods visually and qualitatively. © 2008-2012 IEEE.","Data visualization; Degradation; Numerical methods; Optical resolving power; Optimization; Redundancy; Degradation mechanism; Different resolutions; Numerical experiments; Optimization modeling; Optimization problems; Spatial similarity; Spectral redundancies; Super resolution; image resolution; optimization; qualitative analysis; satellite imagery; Sentinel; spatial analysis; theoretical study; Tensors","Alternating direction method of multipliers (ADMMs); global spectral redundancy; nonlocal spatial similarity; sentinel-2 (S2) image","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85107172026"
"","","","24th ISPRS Congress, Commission II","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","2","","","","2619","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091064519&partnerID=40&md5=0aface4b795996185a7927b98bfbf0ac","The proceedings contain 342 papers. The topics discussed include: learning super-resolution for sentinel-2 images with real ground truth data from a reference satellite; combined patch-wise minimal-maximal pixels regularization for deblurring; urban material classification using spectral and textural features retrieved from autoencoders; a worldwide 3D GCP database inherited from 20 years of massive multi-satellite observations; deep learning based feature matching and its application in image orientation; a novel RPC bias model for improving the positioning accuracy of satellite images; land salinization dynamics based on feature space combinations from landsat image in Tongyu County, Northeast China; a new index for identifying water body from sentinel-2 satellite remote sensing imagery; land cover classification using convolutional neural network with remote sensing data and digital surface model; assessing resilience of infrastructures towards exogenous events by using PS-INSAR-based surface motion estimates and machine learning regression techniques; region-based fuzzy clustering image segmentation algorithm with Kullback-Leibler distance; experiences from the project course in geoinformatics; and refugees stories told by maps: a challenge for students in a scientific Olympiad.","","","Conference review","Final","","Scopus","2-s2.0-85091064519"
"Adigun O.; Olsen P.A.; Chandra R.","Adigun, Olaoluwa (57196019273); Olsen, Peder A. (57937499600); Chandra, Ranveer (57937648900)","57196019273; 57937499600; 57937648900","Location Aware Super-Resolution for Satellite Data Fusion","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","3758","3761","3","10.1109/IGARSS46834.2022.9884391","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140391000&doi=10.1109%2fIGARSS46834.2022.9884391&partnerID=40&md5=4ecf8c85ec34dc3528f3f38e480cb425","Satellite data fusion involves images with different spatial, temporal, and spectral resolution. These images are taken under different illumination conditions, with different sensors and atmospheric noise. We use classic super-resolution algorithms to synthesize commercial satellite images (Pléiades) from a public satellite source (Sentinel-2). Each super-resolution method is then further improved by adaptive sharpening to the location by use of matrix completion (regression with missing pixels). Finally, we consider ensemble systems and a residual channel attention dual network with stochastic dropout. The resulting systems are visibly less blurry with higher fidelity and yield improved performance. © 2022 IEEE.","Data fusion; Matrix algebra; Optical resolving power; Satellites; Atmospheric noise; Cloud removal; Illumination conditions; Location-aware; Matrix completion; Satellite data; Sensors noise; Spatial temporals; Superresolution; Temporal and spectral resolutions; Stochastic systems","cloud removal; matrix completion; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85140391000"
"Zhang K.; Sumbul G.; Demir B.","Zhang, Kexin (57221087691); Sumbul, Gencer (57196192158); Demir, Begum (15131434800)","57221087691; 57196192158; 15131434800","An Approach to Super-Resolution of Sentinel-2 Images Based on Generative Adversarial Networks","2020","2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium, M2GARSS 2020 - Proceedings","","","9105165","69","72","3","10.1109/M2GARSS47143.2020.9105165","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086704517&doi=10.1109%2fM2GARSS47143.2020.9105165&partnerID=40&md5=9f39cc5fcc004c7aac1a60ab0390b2aa","This paper presents a generative adversarial network based super-resolution (SR) approach (which is called as S2GAN) to enhance the spatial resolution of Sentinel-2 spectral bands. The proposed approach consists of two main steps. The first step aims to increase the spatial resolution of the bands with 20m and 60m spatial resolutions by the scaling factors of 2 and 6, respectively. To this end, we introduce a generator network that performs SR on the lower resolution bands with the guidance of the bands associated to 10m spatial resolution by utilizing the convolutional layers with residual connections and a long skip-connection between inputs and outputs. The second step aims to distinguish SR bands from their ground truth bands. This is achieved by the proposed discriminator network, which alternately characterizes the high level features of the two sets of bands and applying binary classification on the extracted features. Then, we formulate the adversarial learning of the generator and discriminator networks as a min-max game. In this learning procedure, the generator aims to produce realistic SR bands as much as possible so that the discriminator incorrectly classifies SR bands. Experimental results obtained on different Sentinel-2 images show the effectiveness of the proposed approach compared to both conventional and deep learning based SR approaches. © 2020 IEEE.","Deep learning; Geology; Image resolution; Optical resolving power; Remote sensing; Adversarial learning; Adversarial networks; Binary classification; High-level features; Learning procedures; Lower resolution; Spatial resolution; Super resolution; Discriminators","generative adversarial network; remote sensing; Sentinel-2 images; super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85086704517"
"Latif H.; Ghuffar S.; Ahmad H.M.","Latif, Hasan (57971676700); Ghuffar, Sajid (14630367300); Ahmad, Hafiz Mughees (57208205069)","57971676700; 14630367300; 57208205069","Super-resolution of Sentinel-2 images using Wasserstein GAN","2022","Remote Sensing Letters","13","12","","1194","1202","8","10.1080/2150704X.2022.2136019","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142262873&doi=10.1080%2f2150704X.2022.2136019&partnerID=40&md5=6ed46ccc6359ea33ed4a46f5cec66add","The Sentinel-2 satellites deliver 13 band multi-spectral imagery with bands having 10 m, 20 m or 60 m spatial resolution. The low-resolution bands can be upsampled to match the high resolution bands to extract valuable information at higher spatial resolution. This paper presents a Wasserstein Generative Adversarial Network (WGAN) based approach named as DSen2-WGAN to super-resolve the low-resolution (i.e., 20 m and 60 m) bands of Sentinel-2 images to a spatial resolution of 10 m. A proposed generator is trained in an adversarial manner using the min-max game to super-resolve the low-resolution bands with the guidance of available high-resolution bands in an image. The performance evaluated using metrics such as Signal Reconstruction Error (SRE) and Root Mean Squared Error (RMSE) shows the effectiveness of the proposed approach as compared to the state-of-the-art method, DSen2 as the DSen2-WGAN reduced RMSE by 14.68% and 7%, while SRE improved by almost 4% and 1.6% for 6 (Formula presented.) and 2 (Formula presented.) super-resolution. Lastly, for further evaluation, we have used trained DSen2-WGAN model to super-resolve the bands of EuroSAT dataset, a satellite image classification dataset based on Sentinel-2 images. The per band classification accuracy of low-resolution bands shows significant improvement after super-resolution using our proposed approach. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Air navigation; Classification (of information); Image resolution; Mean square error; Signal reconstruction; Spectroscopy; High resolution; High spatial resolution; Lower resolution; Multispectral imagery; Network-based approach; Reconstruction error; Root mean squared errors; Signals reconstruction; Spatial resolution; Superresolution; data set; image classification; image resolution; satellite data; Sentinel; spatial resolution; Generative adversarial networks","","Article","Final","","Scopus","2-s2.0-85142262873"
"Liu Z.; Zhu H.; Chen Z.","Liu, Ziyu (58087753100); Zhu, Han (57221180146); Chen, Zhenzhong (57985265500)","58087753100; 57221180146; 57985265500","Adversarial Spectral Super-Resolution for Multispectral Imagery Using Spatial Spectral Feature Attention Module","2023","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","","","1","14","13","10.1109/JSTARS.2023.3238853","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147300696&doi=10.1109%2fJSTARS.2023.3238853&partnerID=40&md5=9c1fcd62e9714f69543d9e53282a0dbf","Acquiring high-quality hyperspectral imagery with high spatial and spectral resolution plays an important role in remote sensing. Due to the limited capacity of sensors, providing high spatial and spectral resolution is still a challenging issue. Spectral super-resolution (SSR) increases the spectral dimensionality of multispectral images to achieve resolution enhancement. In this paper, we propose a spectral resolution enhancement method based on the generative adversarial network (GAN) framework without introducing additional spectral responses prior. In order to adaptively rescale informative features for capturing interdependencies in the spectral and spatial dimensions, a spatial spectral feature attention module (SSFAM) is introduced. The proposed method jointly exploits spatio-spectral distribution in the hyperspectral manifold to increase spectral resolution while maintaining spatial content consistency. Experiments are conducted on both synthetic Landsat 8 and Sentinel-2 radiance data and real co-registered ALI and Hyperion (MS and HS) images, which indicates the superiority of the proposed method compared to other state-of-the-art methods. Author","Generative adversarial networks; Hyperspectral imaging; Image enhancement; Remote sensing; Spectral resolution; Adversarial learning; Attention mechanisms; Correlation; Hyper-spectral imageries; Images reconstruction; Spatial resolution; Spectral feature; Spectral super-resolution; Superresolution; Image reconstruction","adversarial learning; attention Mechanism; Cameras; Correlation; Hyperspectral imagery; Hyperspectral imaging; Image reconstruction; Sensors; Spatial resolution; spectral super-resolution; Superresolution","Article","Article in press","All Open Access; Gold Open Access","Scopus","2-s2.0-85147300696"
"Piestova I.O.; Stankevich S.A.; Kostolny J.","Piestova, Iryna O. (57195922301); Stankevich, Sergey A. (16176794100); Kostolny, Jozef (55364488000)","57195922301; 16176794100; 55364488000","Multispectral imagery super-resolution with logical reallocation of spectra","2017","Proceedings of the International Conference on Information and Digital Technologies, IDT 2017","","","8024316","322","326","4","10.1109/DT.2017.8024316","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030105477&doi=10.1109%2fDT.2017.8024316&partnerID=40&md5=d48d4d2720efde117fffcaa682d4e806","The multispectral imagery spatial resolution enhancement with logical reallocation of spectra is presented. This method includes preprocessing, subpixel resampling, subpixel neighborhood analysis and subpixel values reallocation using similar spectra spatial cross-coupling. This method intended primarily for European Sentinel-2 multispectral satellite system, but it can be adapted to other multispectral systems with non-uniform spatial resolution too. © 2017 IEEE.","Chemical reactions; Image resolution; Optical resolving power; Pixels; Remote sensing; Cross-couplings; logical reallocation; Multi-spectral imagery; Multispectral systems; Neighborhood analysis; Spatial resolution; Spatial-resolution enhancement; Super resolution; Image enhancement","logical reallocation; multispectral imagery; subpixels cross-coupling; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85030105477"
"Lin C.-H.; Bioucas-Dias J.M.","Lin, Chia-Hsiang (55967027800); Bioucas-Dias, Jose M. (55901520500)","55967027800; 55901520500","An Explicit and Scene-Adapted Definition of Convex Self-Similarity Prior with Application to Unsupervised Sentinel-2 Super-Resolution","2020","IEEE Transactions on Geoscience and Remote Sensing","58","5","8931230","3352","3365","13","10.1109/TGRS.2019.2953808","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084155939&doi=10.1109%2fTGRS.2019.2953808&partnerID=40&md5=83f5615adfddb8fe2a9bdbd3c397edcc","Sentinel-2 satellite, launched by the European Space Agency, plays a critical role in various Earth observation missions. However, the spatial resolutions of Sentinel-2 images are different across its spectral bands, including four bands with a resolution of 10 m, six bands with a resolution of 20 m, and three bands with a resolution of 60 m. To facilitate the effectiveness of analyzing these images, super-resolving of the low-/medium-resolution bands to a higher resolution is desired. As in any image restoration inverse problems, we exploit image self-similarity, a commonly observed property in natural images, which underlies the state-of-The-Art techniques, e.g., in image denoising. However, the design of self-similarity priors in nondiagonal inverse problems is challenging; often, a denoiser based on self-similarity is plugged into the iterations of an algorithm, without a guarantee of convergence in general. In this article, for the first time, we introduce a convex and scene-Adapted regularizer built explicitly on a self-similarity graph directly learned from the Sentinel-2 images. We then develop a fast algorithm, termed Sentinel-2 super-resolution via scene-Adapted self-similarity (SSSS). We experimentally show the superiority of SSSS over four commonly observed scenes, indicating the potential usage of our convex self-similarity regularization in other imaging inverse problems. © 1980-2012 IEEE.","Differential equations; Earth (planet); Image denoising; Image reconstruction; Optical resolving power; Space applications; Earth observations; European Space Agency; Fast algorithms; Higher resolution; Self-similarities; Spatial resolution; State-of-the-art techniques; Super resolution; EOS; image resolution; satellite imagery; satellite mission; Sentinel; spatial resolution; unsupervised classification; Inverse problems","Convex optimization; scene-Adapted self-similarity; self-similarity; Sentinel-2 satellite; super-resolution","Article","Final","","Scopus","2-s2.0-85084155939"
"Zhu X.; Xu Y.; Wei Z.","Zhu, Xi (57213192472); Xu, Yang (57188730185); Wei, Zhihui (55761764700)","57213192472; 57188730185; 55761764700","Super-Resolution of Sentinel-2 Images Based on Deep Channel-Attention Residual Network","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8897860","628","631","3","10.1109/IGARSS.2019.8897860","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077700619&doi=10.1109%2fIGARSS.2019.8897860&partnerID=40&md5=e12019b1ad725728e503bb30266a6360","Sentinel-2 data has become an important tool for current and future earth observation due to its high quality, free availability and world-wide coverage. However, some of the spectral bands are sensed at reduced resolution due to design considerations and sensor hardware limitations. So in this paper we present a super-resolution method based on Convolutional Neural Networks (CNNs) to infer all the 20m spectral bands in the highest available resolution. This is accomplished by using an improved residual network and meanwhile we propose a channel attention mechanism to adaptively rescale the characteristics of the channels by considering the interdependencies among the channels. The proposed solution compares against several alternative methods according to different quality indexes. Our network provides the best results and a compelling visual effect on the sentinel-2 images. © 2019 IEEE.","Convolution; Geology; Optical resolving power; Remote sensing; Attention mechanisms; channel attention; Design considerations; Earth observations; Reduced resolution; Sentinel-2; Super resolution; Superresolution methods; Convolutional neural networks","channel attention; convolutional neural network; residual network; Sentinel-2; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85077700619"
"Ulfarsson M.O.; Dalla Mura M.","Ulfarsson, M.O. (6507677875); Dalla Mura, M. (36499129800)","6507677875; 36499129800","A low-rank method for sentinel-2 sharpening using cyclic descent","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8519256","8857","8860","3","10.1109/IGARSS.2018.8519256","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051675357&doi=10.1109%2fIGARSS.2018.8519256&partnerID=40&md5=aea1b6ee3cf15503ab4f169c2d911ece","Multiresolution optical remote sensing systems often have a spatial resolution that varies between bands. An example is the Sentinel-2 (S2) constellation which has three levels of spatial resolution 10m, 20m, and 60m. Recently, researchers have exploited the spectral/spatial correlation inherent in multispectral data to sharpen the lower resolution S2 bands. In this paper, we propose a low-rank method that formulates the sharpening process as a solution to a cost function. We develop an iterative algorithm based on cyclic descent and call it S2Sharp-CD. We evaluate the method on a simulated dataset and compare it to a state-of-the-art approach. © 2018 IEEE.","Cost functions; Data fusion; Geology; Image processing; Image resolution; Iterative methods; Optical data processing; Cyclic descents; Iterative algorithm; Multi-spectral data; Optical remote sensing; Sentinel-2 constellation; Spatial resolution; State-of-the-art approach; Super resolution; Remote sensing","Cyclic descent; Data fusion; Image processing; Sentinel-2 constellation; Superresolution","Conference paper","Final","","Scopus","2-s2.0-85051675357"
"Wagner L.; Liebel L.; Körner M.","Wagner, L. (57203101042); Liebel, L. (56938680000); Körner, M. (57190168095)","57203101042; 56938680000; 57190168095","DEEP RESIDUAL LEARNING for SINGLE-IMAGE SUPER-RESOLUTION of MULTI-SPECTRAL SATELLITE IMAGERY","2019","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","4","2/W7","","189","196","7","10.5194/isprs-annals-IV-2-W7-189-2019","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084643909&doi=10.5194%2fisprs-annals-IV-2-W7-189-2019&partnerID=40&md5=2a603b108ce7e232383eeb2009482bf8","Analyzing optical remote sensing imagery depends heavily on their spatial resolution. At the same time, this data is adversely affected by fixed sensor parameters and environmental influences. Methods for increasing the quality of such data and concomitantly optimizing its information content are, thus, in high demand. In particular, single-image super-resolution (SISR) approaches aim to achieve this goal solely by observing the individual images. We propose to adapt a generic deep residual neural network architecture for SISR to deal with the special properties of remote sensing satellite imagery, especially taking into account the different spatial resolutions of individual Sentinel-2 bands, i.e., ground sampling distances of 20 m and 10 m. As a result, this method is able to increase the perceived resolution of the 20 m channels and mesh all spectral bands. Experimental evaluation and ablation studies on large datasets have shown superior performance compared to the state-of-the-art and that the model is not bound by its capacity. © 2019 ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences. All rights reserved.","Image analysis; Large dataset; Network architecture; Optical resolving power; Remote sensing; Satellite imagery; Environmental influences; Experimental evaluation; Ground sampling distances; Information contents; Optical remote-sensing imagery; Remote sensing satellites; Spatial resolution; Special properties; Deep learning","Convolutional Neural Networks; Deep Learning; Remote Sensing; Residual Learning; Sentinel-2; Single-Image Super-Resolution","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85084643909"
"","","","2022 IEEE Mediterranean and Middle-East Geoscience and Remote Sensing Symposium, M2GARSS 2022 - Proceedings","2022","2022 IEEE Mediterranean and Middle-East Geoscience and Remote Sensing Symposium, M2GARSS 2022 - Proceedings","","","","","","208","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136436295&partnerID=40&md5=5a86bbc9bb605d8d037ab367f80cd9db","The proceedings contain 50 papers. The topics discussed include: a new active image captioning fusion strategy; a relevant, hard and diverse triplet sampling method for multi-label remote sensing image retrieval; learning to align Arabic and English text to remote sensing images using transformers; a joint semantic segmentation loss function for imbalanced datasets; rapid mapping of landslides from sentinel-2 data using unsupervised deep learning; local spectral super-resolution for ALSAT-2B images with application to anomaly detection; an encoder-decoder U-Net based model for overheated photovoltaic modules extraction from orthorectified remotely sensed thermal infrared UAV imagery; spectral unmixing and clustering techniques for changes detection in multitemporal hyperspectral remote sensing data; nonnegative tensor factorization based fusion for changes detection in multiresolution remote sensing images; and fully unsupervised binary change detection for hyperspectral images using Laplacian eigenmaps and clustering.","","","Conference review","Final","","Scopus","2-s2.0-85136436295"
"Nguyen H.V.; Ulfarsson M.O.; Sveinsson J.R.; Mura M.D.","Nguyen, Han V. (57222240069); Ulfarsson, Magnus O. (6507677875); Sveinsson, Johannes R. (7003642214); Mura, Mauro Dalla (57218455473)","57222240069; 6507677875; 7003642214; 57218455473","Sentinel-2 Sharpening Using a Single Unsupervised Convolutional Neural Network with MTF-Based Degradation Model","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9464640","6882","6896","14","10.1109/JSTARS.2021.3092286","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111144938&doi=10.1109%2fJSTARS.2021.3092286&partnerID=40&md5=7e5370c6a46cbd450007d030f7a0df17","The Sentinel-2 (S2) constellation provides multispectral images at 10 m, 20 m, and 60 m resolution bands. Obtaining all bands at 10 m resolution would benefit many applications. Recently, many model-based and deep learning (DL)-based sharpening methods have been proposed. However, the downside of those methods is that the DL-based methods need to be trained separately for the 20 m and the 60 m bands in a supervised manner at reduced resolution, while the model-based methods heavily depend on the hand-crafted image priors. To break the gap, this article proposes a novel unsupervised DL-based S2 sharpening method using a single convolutional neural network (CNN) to sharpen the 20 and 60 m bands at the same time at full resolution. The proposed method replaces the hand-crafted image prior by the deep image prior (DIP) provided by a CNN structure whose parameters are easily optimized using a DL optimizer. We also incorporate the modulation transfer function-based degradation model as a network layer, and add all bands to both network input and output. This setting improves the DIP and exploits the advantage of multitask learning since all S2 bands are highly correlated. Extensive experiments with real S2 data show that our proposed method outperforms competitive methods for reduced-resolution evaluation and yields very high quality sharpened image for full-resolution evaluation.  © 2008-2012 IEEE.","Convolution; Convolutional neural networks; Deep learning; Multi-task learning; Network layers; Quality control; Degradation model; Full resolutions; Highly-correlated; Model-based method; Model-based OPC; Multispectral images; Network inputs; Reduced resolution; artificial neural network; degradation; experimental study; image resolution; multispectral image; remote sensing; Sentinel; Learning systems","Convolutional neural networks (CNNs); image fusion; MTF-based degradation; Sentinel-2 image sharpening; super-resolution; unsupervised deep learning","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85111144938"
"Stefouli M.; Panagiotopoulou A.; Charou E.; Spastra P.; Bratsolis E.; Madamopoulos N.; Perantonis S.","Stefouli, Marianthi (6506668706); Panagiotopoulou, Antigoni (24479152700); Charou, Eleni (6507509159); Spastra, Panagiota (57213822906); Bratsolis, Emmanuel (6603338911); Madamopoulos, Nicholas (6604012410); Perantonis, Stavros (7004909153)","6506668706; 24479152700; 6507509159; 57213822906; 6603338911; 6604012410; 7004909153","Lignite mine monitoring and mapping using freely-available radar and optical satellite imagery","2019","International Journal of Mining and Mineral Engineering","10","2-4","","131","157","26","10.1504/IJMME.2019.104445","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078066864&doi=10.1504%2fIJMME.2019.104445&partnerID=40&md5=cf9d969a4318b4316e3a36194128d35c","A methodology for monitoring and mapping lignite mining areas using Sentinel-1 and Sentinel-2 ESA Copernicus satellite systems is presented. A stochastic regularised super-resolution reconstruction (SRSR) for the enhancement of the Sentinel-2 optical data is developed, and a land monitoring/change analysis based on the enhanced Sentinel-2 images is performed. Additionally, the ground motion is monitored using the Sentinel-1 radar data via the Rheticus service. The proposed methodology is tested on the Amyntaio lignite mine in Ptolemais basin, Greece, for Sentinel images obtained from 2014 to 2018. The Amyntaio area has been of particular interest, as a landslide event occurred on June 10th, 2017, causing major operational disruption and a severe economic loss to the Public Power Plant Cooperation of Greece SA. The methodology proves to be useful for facilitating mapping and monitoring mining and post-mining areas facing similar problems with the Amyntaio lignite site. Copyright © 2019 Inderscience Enterprises Ltd.","Image enhancement; Landslides; Lignite; Lignite mines; Losses; Mapping; Open pit mining; Optical resolving power; Radar; Satellite imagery; Self organizing maps; Space flight; Space-based radar; Stochastic systems; Ground motions; Land-cover change; Lorentzian estimator; Multi-spectral; Regularisation; Rheticus service; Sentinel-1; Sentinel-2; Super resolution reconstruction; Radar imaging","BTV regularisation; Ground motion; Land cover change analysis; Landslides; Lignites; Lorentzian estimator; Multispectral; Radar; Rheticus service; Self-organising maps; Sentinel-1; Sentinel-2; SOM; Super-resolution reconstruction; Surface mining","Conference paper","Final","","Scopus","2-s2.0-85078066864"
"Nguyen H.V.; Ulfarsson M.O.; Sveinsson J.R.","Nguyen, Han V. (57222240069); Ulfarsson, Magnus O. (6507677875); Sveinsson, Johannes R. (7003642214)","57222240069; 6507677875; 7003642214","SHARPENING THE 20 M BANDS OF SENTINEL-2 IMAGE USING AN UNSUPERVISED CONVOLUTIONAL NEURAL NETWORK","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","2875","2878","3","10.1109/IGARSS47720.2021.9555082","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128986256&doi=10.1109%2fIGARSS47720.2021.9555082&partnerID=40&md5=e7015a2e83d14d555904ea2217e81173","This paper proposes a novel method for sharpening the 20 m bands of the multispectral images acquired by the Sentinel- 2 (S2) constellation. We formulate the S2 sharpening as an inverse problem and solve it using an unsupervised convolutional neural network (CNN), called S2UCNN. The proposed method extends the deep image prior provided by a CNN structure with S2 domain knowledge. We incorporate a modulation transfer function-based degradation model as a network layer. We add the 10 m bands to both the network input and output to take advantage of the multitask learning. Experimental results with a real S2 dataset show that the proposed method outperforms the competitive methods on reduced-resolution data and gives very high quality sharpened image on full-resolution data.  © 2021 IEEE.","Convolution; Convolutional neural networks; Domain Knowledge; Inverse problems; Network layers; Remote sensing; Convolutional neural network; Image priors; Multispectral images; Neural networks structure; Novel methods; Remote-sensing; Sentinel-2; Sharpening; Superresolution; Unsupervised convolutional neural network; Image fusion","image fusion; Remote sensing; Sentinel-2; sharpening; super-resolution; unsupervised convolutional neural network","Conference paper","Final","","Scopus","2-s2.0-85128986256"
"Panagiotopoulou A.; Charou E.; Poirazidis K.; Voutos Y.; Martinis A.; Grammatikopoulos L.; Petsa E.; Bratsolis E.; Mylonas P.","Panagiotopoulou, Antigoni (24479152700); Charou, Eleni (6507509159); Poirazidis, Konstantinos (57203888036); Voutos, Yorghos (57198449490); Martinis, Aristotelis (25641948100); Grammatikopoulos, Lazaros (16068804700); Petsa, Eleni (6508237326); Bratsolis, Emmanuel (6603338911); Mylonas, Phivos (6603293346)","24479152700; 6507509159; 57203888036; 57198449490; 25641948100; 16068804700; 6508237326; 6603338911; 6603293346","Deep-Learning Based Super-Resolution of Sentinel-2 Images for Monitoring Supercentenarian Olive Trees","2021","ACM International Conference Proceeding Series","","","","143","148","5","10.1145/3503823.3503851","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125677348&doi=10.1145%2f3503823.3503851&partnerID=40&md5=cc0a93d33b9adfa3f22283f3f7f8a36b","In the present work deep-learning based super-resolution (SR) is applied on Sentinel-2 images of the Zakynthos island, Greece, with the intention of detecting stress levels in supercentenarian olive trees due to water deficiency. The aim of this study is monitoring the stress in supercentenarian olive trees over time and over season. Specifically, the Carotenoid Reflectance Index 2 (CRI2) is calculated utilizing the Sentinel-2 bands B2 and B5. CRI2 maps at 10m and at 2.5mspatial resolutions are generated. In fact, the images of band B2 with original spatial resolution 10m are super-resolved to 2.5m. Regarding the images of band B5, these are SR resolved from 20m firstly to 10m and secondly to 2.5m. Deep-learning based SR techniques, namely DSen2 and RakSRGAN, are utilized for enhancing the spatial resolution to 10m and 2.5m. The following five seasons are considered autumn 2019, spring 2019, spring 2020, summer 2019 and summer 2020. In the future, comparisons with field measurements could better assess for the proposed methodology effectiveness regarding the recognition of stress levels in very old olive trees. © 2021 ACM.","Deep learning; Ecosystems; Forestry; Deep-learning; Image super resolutions; Learning-based super-resolution; Reflectance index; Sentinel-2; Spatial resolution; Stress levels; Supercentenarian olive tree; Superresolution; Water-deficiency; Image resolution","Deep-Learning; Image super-resolution; Sentinel-2; Supercentenarian olive tree","Conference paper","Final","","Scopus","2-s2.0-85125677348"
"Nguyen H.V.; Ulfarsson M.O.; Sveinsson J.R.; Sigurdsson J.","Nguyen, Han V. (57222240069); Ulfarsson, Magnus O. (6507677875); Sveinsson, Johannes R. (7003642214); Sigurdsson, Jakob (7006736374)","57222240069; 6507677875; 7003642214; 7006736374","Zero-Shot Sentinel-2 Sharpening Using a Symmetric Skipped Connection Convolutional Neural Network","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323614","613","616","3","10.1109/IGARSS39084.2020.9323614","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102005792&doi=10.1109%2fIGARSS39084.2020.9323614&partnerID=40&md5=ec6e2abccbe671f05365f718490b7c6e","Sentinel-2 (S2) satellite constellations can provide multispectral images of 10 m, 20 m, and 60 m resolution for visible, near-infrared (NIR) and short-wave infrared (SWIR) in the electromagnetic spectrum. In this paper, we present a sharpening method based on a symmetric skipped connection convolutional neural network, called SSC-CNN, to sharpen 20 m bands using 10 m bands. The main advantage of SSC-CNN architecture is that it brings the features of the input branch to the output, thus improving convergence without using too many deep layers. The proposed method uses the reduced-scale combination of 10 m bands and 20 m bands, and the observed 20 m bands as the training pairs. The experimental results using two Sentinel-2 datasets show that our method outperforms competitive methods in quantitative metrics and visualization. © 2020 IEEE.","Convolution; Geology; Infrared devices; Infrared radiation; Remote sensing; Deep layer; Electromagnetic spectra; Multispectral images; Near infra red; Quantitative metrics; Reduced scale; Satellite constellations; Short wave infrared; Convolutional neural networks","convolutional neural network; image fusion; image sharpening; Sentinel-2; super resolution","Conference paper","Final","","Scopus","2-s2.0-85102005792"
"Beaulieu M.; Foucher S.; Haberman D.; Stewart C.","Beaulieu, Mario (57198137843); Foucher, Samuel (6701728686); Haberman, Dan (57207883024); Stewart, Colin (57207874202)","57198137843; 6701728686; 57207883024; 57207874202","Deep image-to-image transfer applied to resolution enhancement of sentinel-2 images","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8517655","2611","2614","3","10.1109/IGARSS.2018.8517655","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063165638&doi=10.1109%2fIGARSS.2018.8517655&partnerID=40&md5=687dfcbdc82d2366fa413457b47b6717","Single Image Super-Resolution (SISR) is looking at restoring the missing high-resolution information from a single low-resolution image in order to increase the apparent spatial resolution by a factor of two or more. In recent years, convolution neural networks have been applied with great success to the problem of improving spatial resolution from a single image. With the advent of low-resolution (10 m) optical sensors such as Sentinel-2, it is interesting to explore the possibility of improving image resolution with Deep Learning (DL) techniques. The purpose of this article is to investigate the potential performances of recent DL super-resolution techniques. The techniques explored here include not only techniques for enhancing high-frequency content but also so-called image-to-image translation techniques based on Generative Adversarial Neural Networks (GAN). From our preliminary results, we show that GANs have the ability to restore complex textural information. © 2018 IEEE","","Deep Learning; GAN; Optical Images; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85063165638"
"Armannsson S.E.; Ulfarsson M.O.; Sigurdsson J.; Nguyen H.V.; Sveinsson J.R.","Armannsson, Sveinn E. (57224686207); Ulfarsson, Magnus O. (6507677875); Sigurdsson, Jakob (7006736374); Nguyen, Han V. (57222240069); Sveinsson, Johannes R. (7003642214)","57224686207; 6507677875; 7006736374; 57222240069; 7003642214","A comparison of optimized sentinel-2 super-resolution methods using wald’s protocol and bayesian optimization","2021","Remote Sensing","13","11","2192","","","","10.3390/rs13112192","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108170131&doi=10.3390%2frs13112192&partnerID=40&md5=e8f051ff097cbf6ceff9cbe61eebf56f","In the context of earth observation and remote sensing, super-resolution aims to enhance the resolution of a captured image by upscaling and enhancing its details. In recent years, numerous methods for super-resolution of Sentinel-2 (S2) multispectral images have been suggested. Most of those methods depend on various tuning parameters that affect how effective they are. This paper’s aim is twofold. Firstly, we propose to use Bayesian optimization at a reduced scale to select tuning parameters. Secondly, we choose tuning parameters for eight S2 super-resolution methods and compare them using real and synthetic data. While all the methods give good quantitative results, Area-To-Point Regression Kriging (ATPRK), Sentinel-2 Sharpening (S2Sharp), and Sentinel-2 Symmetric Skip Connection convolutional neural network (S2 SSC) perform markedly better on several datasets than the other methods tested in this paper. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural networks; Image enhancement; Remote sensing; Bayesian optimization; Earth observations; Multispectral images; Quantitative result; Regression-kriging; Super resolution; Superresolution methods; Tuning parameter; Optical resolving power","Data fusion; Image sharpening; Multispectral (MS) multiresolution images; Sentinel-2; Sharpening of bands; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85108170131"
"Romero L.S.; Marcello J.; Vilaplana V.","Romero, Luis Salgueiro (57218455911); Marcello, Javier (6602158797); Vilaplana, Verónica (23394280500)","57218455911; 6602158797; 23394280500","Super-resolution of Sentinel-2 imagery using generative adversarial networks","2020","Remote Sensing","12","15","2424","","","","10.3390/RS12152424","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089853089&doi=10.3390%2fRS12152424&partnerID=40&md5=6bb6fc362a861fc8952daf3ca71d5b36","Sentinel-2 satellites provide multi-spectral optical remote sensing images with four bands at 10 m of spatial resolution. These images, due to the open data distribution policy, are becoming an important resource for several applications. However, for small scale studies, the spatial detail of these images might not be sufficient. On the other hand, WorldView commercial satellites offer multi-spectral images with a very high spatial resolution, typically less than 2 m, but their use can be impractical for large areas or multi-temporal analysis due to their high cost. To exploit the free availability of Sentinel imagery, it is worth considering deep learning techniques for single-image super-resolution tasks, allowing the spatial enhancement of low-resolution (LR) images by recovering high-frequency details to produce high-resolution (HR) super-resolved images. In this work, we implement and train a model based on the Enhanced Super-Resolution Generative Adversarial Network (ESRGAN) with pairs of WorldView-Sentinel images to generate a super-resolved multispectral Sentinel-2 output with a scaling factor of 5. Our model, named RS-ESRGAN, removes the upsampling layers of the network to make it feasible to train with co-registered remote sensing images. Results obtained outperform state-of-the-art models using standard metrics like PSNR, SSIM, ERGAS, SAM and CC. Moreover, qualitative visual analysis shows spatial improvements as well as the preservation of the spectral information, allowing the super-resolved Sentinel-2 imagery to be used in studies requiring very high spatial resolution. © 2020 by the authors.","Deep learning; Image analysis; Image resolution; Network layers; Open Data; Optical resolving power; Remote sensing; Spectroscopy; Commercial satellites; Data distribution policies; Low resolution images; Multi-temporal analysis; Optical remote sensing; Remote sensing images; Spectral information; Very high spatial resolutions; Image enhancement","Deep learning; Generative adversarial network; Sentinel-2; Super-resolution; WorldView","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85089853089"
"Sha L.; Zhang W.; Ma J.; Li Z.; Sun R.; Qin M.","Sha, Lingyu (57937361200); Zhang, Wenjuan (35235960300); Ma, Jianhang (57937214000); Li, Zhen (57938098400); Sun, Ruiqi (57937801200); Qin, Meng (57937214100)","57937361200; 35235960300; 57937214000; 57938098400; 57937801200; 57937214100","Full-Spectrum Spectral Super-Resolution Method Based on LSMM","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","2390","2393","3","10.1109/IGARSS46834.2022.9883706","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140362606&doi=10.1109%2fIGARSS46834.2022.9883706&partnerID=40&md5=1b60e10c177ef2814097e643d0cb02c0","Full-spectrum remote sensing images can simultaneously provide reflectance and emission information about objects, which has great application value. Hyperspectral imaging can record hundreds of spectral bands, but due to technical and space limitations, full-spectrum hyperspectral images (HSI) are difficult to obtain. Recently, we proposed a spectral super-resolution method based on the Linear Spectral Mixing Model (LSMM), which can generate full-spectrum hyperspectral images (HSI) from multispectral images (MSI). After the spectral-unmixing of MSI, we transform MS endmembers into full-spectrum HS endmembers by spectral library. Since the abundance of MSI and HSI with the same spatial resolution is consistent, we linearly mixed the abundance and HS endmember to obtain the full spectrum HSI. In this work, we use Sentinel-2 dataset and EO-1 ALI/Hyperion images to verify the accuracy and applicability. Compared with other works, our method can simulate full-spectrum HSI of large-area scenes without real HSI, which has a certain accuracy and provides more comprehensive information for applications. © 2022 IEEE.","Optical resolving power; Remote sensing; Spectroscopy; Endmembers; Full-spectrum; HyperSpectral; Images simulations; Linear spectral mixing models; Multispectral images; Remote sensing images; Spectral super-resolution; Superresolution; Superresolution methods; Hyperspectral imaging","Full-spectrum; hyperspectral; image simulation; spectral super-resolution","Conference paper","Final","","Scopus","2-s2.0-85140362606"
"Yu C.-H.; Hsieh M.-C.; Ren H.","Yu, Ching-Hsiang (57798132800); Hsieh, Mon-Chai (57797898500); Ren, Hsuan (7202794047)","57798132800; 57797898500; 7202794047","Self-Supervised Super-Resolution on Sentinel-2 Imagery; [基於自監督學習之超解析度成像法應用於Sentinel-2 衛星影像]","2022","Journal of the Chinese Institute of Civil and Hydraulic Engineering","34","3","","243","248","5","10.6652/JoCICHE.202205_34(3).0007","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134034292&doi=10.6652%2fJoCICHE.202205_34%283%29.0007&partnerID=40&md5=2cfc5d98ee95250c4fb32eae6a01700f","Convolutional neural networks have been adopted in super-resolution algorithm inrecent years. These supervised learning methods can train the model through external image sets to improve the image resolution of specific feature such as faces or buildings. Because they need large amount of training images, it usually consumes lots of computation cost. This study implements the Zeroshot Super-resolution (ZSSR) method developed by Assaf Shocher and applied to improve the spatial resolution of Sentinel-2 images. ZSSR is a self-supervised learning method that does not need the pre-training process with image data set. It only needs to learn the internal structural features of the test image itself. The experimental results show that ZSSR can improve peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) by 4.67% and 3.35% compared with bicubic interpolation, which are comparable to supervised learning methods that consume training resources. The results also show, that the repeated internal structural features in remote sensing images are suitable for self-supervised learning super-resolution algorithms. © 2022, Chinese Institute of Civil and Hydraulic Engineering. All right reserved.","Convolution; Convolutional neural networks; Image enhancement; Learning systems; Remote sensing; Satellite imagery; Signal to noise ratio; Supervised learning; Computation costs; Convolutional neural network; Images sets; Large amounts; Self-supervised; Structural feature; Super resolution algorithms; Superresolution; Supervised learning methods; Training image; Image resolution","Convolutional neural network; Satellite imagery; Self-supervised; Superresolution","Article","Final","","Scopus","2-s2.0-85134034292"
"","","","2022 24th ISPRS Congress ""Imaging Today, Foreseeing Tomorrow"", Commission I","2022","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","1","","","","1656","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132795471&partnerID=40&md5=2e161be71ff41860137ea2dd04a27aa4","The proceedings contain 219 papers. The topics discussed include: radiometric calibration performance of a multispectral camera with a single sensor and multiple heads; point cloud simulator for space in-orbit close range autonomous operations; impact of deep learning-based super-resolution on building footprint extraction; a novel geometric key-frame selection method for visual-inertial slam and odometry systems; importance of precise gravity field modeling in direct georeferencing and aerial photogrammetry: a case study for Sweden; a combined color and wave-based approach to satellite derived bathymetry using deep learning; multi-temporal data augmentation for high frequency satellite imagery: a case study in sentinel-1 and Sentinel-2 building and road segmentation; database storage and transparent memory loading of big spatial datasets implemented with the dual half-edge data structure; an artificial intelligence-based solution for the classification of oak decline potential; geomatics vocational education in China: current situation and recent developments; and collaborative education model on GIS major under the professional certification of engineering education.","","","Conference review","Final","","Scopus","2-s2.0-85132795471"
"","","","Proceedings - 2021 International Young Engineers Forum in Electrical and Computer Engineering, YEF-ECE 2021","2021","Proceedings - 2021 International Young Engineers Forum in Electrical and Computer Engineering, YEF-ECE 2021","","","","","","147","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125641305&partnerID=40&md5=35f97ecb01046fa635b036ad41ebbc1c","The proceedings contain 23 papers. The topics discussed include: online model generation for scalable predictive process monitoring; flight control of hybrid drones towards enabling parcel relay maneuvers; model predictive control strategies for parcel relay maneuvers using drones; multi-image super-resolution algorithm supported on Sentinel-2 satellite images geolocation error; integration of remote interfaces for industrial automation applications; speed test and cluster analysis processing method of hydraulic mechanism in high-voltage circuit breakers; agent-based simulation of consumer occupancy distribution in shopping centers; and sensorless switched reluctance machine and speed control: a study to remove the position encoder at high-speed of operation.","","","Conference review","Final","","Scopus","2-s2.0-85125641305"
"Sigurdsson J.; Armannsson S.E.; Ulfarsson M.O.; Sveinsson J.R.","Sigurdsson, Jakob (7006736374); Armannsson, Sveinn E. (57224686207); Ulfarsson, Magnus O. (6507677875); Sveinsson, Johannes R. (7003642214)","7006736374; 57224686207; 6507677875; 7003642214","Fusing Sentinel-2 and Landsat 8 Satellite Images Using a Model-Based Method","2022","Remote Sensing","14","13","3224","","","","10.3390/rs14133224","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133860643&doi=10.3390%2frs14133224&partnerID=40&md5=36a359caa11fe4e2c3c864be45cbb3cc","The Copernicus Sentinel-2 (S2) constellation comprises of two satellites in a sun-synchronous orbit. The S2 sensors have three spatial resolutions: 10, 20, and 60 m. The Landsat 8 (L8) satellite has sensors that provide seasonal coverage at spatial resolutions of 15, 30, and 60 m. Many remote sensing applications require the spatial resolutions of all data to be at the highest resolution possible, i.e., 10 m for S2. To address this demand, researchers have proposed various methods that exploit the spectral and spatial correlations within multispectral data to sharpen the S2 bands to 10 m. In this study, we combined S2 and L8 data. An S2 sharpening method called Sentinel-2 Sharpening (S2Sharp) was modified to include the 30 m and 15 m spectral bands from L8 and to sharpen all bands (S2 and L8) to the highest resolution of the data, which was 10 m. The method was evaluated using both real and simulated data. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Image fusion; Orbits; Remote sensing; High resolution; Image sharpening; LANDSAT; Landsat 8; Multi-spectral; Multiresolution images; Multispectral  multiresolution image; Sentinel-2; Spatial resolution; Superresolution; Landsat","data fusion; image sharpening; Landsat 8; multispectral (MS) multiresolution images; Sentinel-2; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85133860643"
"Yoo S.; Lee J.; Bae J.; Jang H.; Sohn H.-G.","Yoo, Suhong (55349137600); Lee, Jisang (57188868981); Bae, Junsu (57209239711); Jang, Hyoseon (56038983600); Sohn, Hong-Gyoo (7201426313)","55349137600; 57188868981; 57209239711; 56038983600; 7201426313","Automatic generation of aerial orthoimages using sentinel-2 satellite imagery with a context-based deep learning approach","2021","Applied Sciences (Switzerland)","11","3","1089","1","25","24","10.3390/app11031089","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100107892&doi=10.3390%2fapp11031089&partnerID=40&md5=27eeffe7835281ba6170fab0cdf3ff54","Aerial images are an outstanding option for observing terrain with their high-resolution (HR) capability. The high operational cost of aerial images makes it difficult to acquire periodic observation of the region of interest. Satellite imagery is an alternative for the problem, but low-resolution is an obstacle. In this study, we proposed a context-based approach to simulate the 10 m resolution of Sentinel-2 imagery to produce 2.5 and 5.0 m prediction images using the aerial or-thoimage acquired over the same period. The proposed model was compared with an enhanced deep super-resolution network (EDSR), which has excellent performance among the existing super-resolution (SR) deep learning algorithms, using the peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM), and root-mean-squared error (RMSE). Our context-based ResU-Net outperformed the EDSR in all three metrics. The inclusion of the 60 m resolution of Sentinel-2 imagery performs better through fine-tuning. When 60 m images were included, RMSE decreased, and PSNR and SSIM increased. The result also validated that the denser the neural network, the higher the quality. Moreover, the accuracy is much higher when both denser feature dimensions and the 60 m images were used. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","","Aerial orthoimage; Image simulation; Residual U-Net; Sentinel-2; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85100107892"
"Li Y.; Gao W.; Jia J.; Tao S.; Ren Y.","Li, Yan (57246418800); Gao, Wanlin (8931933300); Jia, Jingdun (55349327200); Tao, Sha (57211427383); Ren, Yanzhao (57194343285)","57246418800; 8931933300; 55349327200; 57211427383; 57194343285","Developing and evaluating the feasibility of a new spatiotemporal fusion framework to improve remote sensing reflectance and dynamic LAI monitoring","2022","Computers and Electronics in Agriculture","198","","107037","","","","10.1016/j.compag.2022.107037","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130372766&doi=10.1016%2fj.compag.2022.107037&partnerID=40&md5=24ab1490e1086667b6289fcfe7409803","Multi-sensor fusion provides an effective way for applications requiring remote sensing data with high spatiotemporal resolution. Especially for agricultural areas with complex planting structures and rapid changes in crop phenology, more detailed and dense time-series remote sensing data are necessary. The Sentinel-2 Multispectral Imager (S2-MSI) sensor with high spatial resolution (10–60 m) and temporal resolution (5–10 days) plays a key role in spatiotemporal fusion. But the inconsistent spatial resolution of the various bands hinders its potential application at 10 m resolution, and the multiple available fine images it provides are not fully utilized for spatiotemporal fusion. It is worth exploring how to maximize the spatial and temporal resolution of S2-MSI images to help improve the effect of spatiotemporal fusion and the dynamic monitoring of rapid crop growth. In this research, a new spatiotemporal fusion (STF) framework is developed to fuse the S2-MSI image (10 m) enhanced by Super-Resolution for multispectral Multiresolution Estimation (SupReME) algorithm and MODIS image (460 m) with a large spatial ratio (46). The proposed fusion method in the new STF framework combines the existing STF methods with Consistent Adjustment of the Climatology to Actual Observations (CACAO) algorithm, abbreviated as CA-STF. The accuracy of the fused reflectance and its capability for dynamic LAI monitoring were tested in Daman Superstation of Heihe watershed. The results indicate that: (1) the new STF framework is competent to fuse multi-source images with a ratio of 46 and outperforms the existing STF methods for both near-real-time and post-growth applications; (2) the proposed CA-STF method improves the fusion accuracy and spatial details even if only two S2-MSI images are available, especially for post-growth applications; (3) the vegetation indices (VIs) calculated from the fused images by the new STF framework provide a better correlation with LAINet measurements and improve dynamic LAI monitoring in accuracy and spatial details. This study proposes a framework to maximize the spatial and temporal resolution of S2-MSI images for spatiotemporal fusion. The synthetic daily time-series images with a high resolution of 10 m will have great potential for monitoring the dynamic changes of the land surface. © 2022 Elsevier B.V.","China; Heihe; Heilongjiang; Image enhancement; Image resolution; Reflection; Remote sensing; Time series; Vegetation; Consistent adjustment of the climatology to actual observation; Estimation algorithm; Fusion methods; Multi-spectral; Multiresolution; Multispectral imagers; Sentinel-2 multispectral imager; Spatio-temporal fusions; Super-resolution for multispectral multiresolution estimation algorithm; Superresolution; leaf area index; MODIS; remote sensing; spatiotemporal analysis; spectral reflectance; watershed; Crops","CACAO; Sentinel-2 Multispectral Imager (S2-MSI); Spatiotemporal fusion; SupReME algorithm","Article","Final","","Scopus","2-s2.0-85130372766"
"Gong Y.; Liao P.; Zhang X.; Zhang L.; Chen G.; Zhu K.; Tan X.; Lv Z.","Gong, Yuanfu (57200512932); Liao, Puyun (57208162705); Zhang, Xiaodong (57192504939); Zhang, Lifei (57207389916); Chen, Guanzhou (56181390800); Zhu, Kun (57200511212); Tan, Xiaoliang (57202231708); Lv, Zhiyong (23111268400)","57200512932; 57208162705; 57192504939; 57207389916; 56181390800; 57200511212; 57202231708; 23111268400","Enlighten-gan for super resolution reconstruction in mid-resolution remote sensing images","2021","Remote Sensing","13","6","1104","","","","10.3390/rs13061104","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103080085&doi=10.3390%2frs13061104&partnerID=40&md5=5d1cb69627959e3776eec7312ce71b58","Previously, generative adversarial networks (GAN) have been widely applied on super resolution reconstruction (SRR) methods, which turn low-resolution (LR) images into high-resolution (HR) ones. However, as these methods recover high frequency information with what they observed from the other images, they tend to produce artifacts when processing unfamiliar images. Optical satellite remote sensing images are of a far more complicated scene than natural images. Therefore, applying the previous networks on remote sensing images, especially mid-resolution ones, leads to unstable convergence and thus unpleasing artifacts. In this paper, we propose Enlighten-GAN for SRR tasks on large-size optical mid-resolution remote sensing images. Specifically, we design the enlighten blocks to induce network converging to a reliable point, and bring the Self-Supervised Hierarchical Perceptual Loss to attain performance improvement overpassing the other loss functions. Furthermore, limited by memory, large-scale images need to be cropped into patches to get through the network separately. To merge the reconstructed patches into a whole, we employ the internal inconsistency loss and cropping-and-clipping strategy, to avoid the seam line. Experiment results certify that Enlighten-GAN outperforms the state-of-the-art methods in terms of gradient similarity metric (GSM) on mid-resolution Sentinel-2 remote sensing images. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Global system for mobile communications; Optical resolving power; Remote sensing; Adversarial networks; High-frequency informations; Low resolution images; Optical satellites; Remote sensing images; Similarity metrics; State-of-the-art methods; Super resolution reconstruction; Image reconstruction","Generative adversarial network; Mid-resolution remote sensing images; Super resolution reconstruction","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85103080085"
"Ulfarsson M.O.; Palsson F.; Dalla Mura M.; Sveinsson J.R.","Ulfarsson, Magnus O. (6507677875); Palsson, Frosti (55052918200); Dalla Mura, Mauro (36499129800); Sveinsson, Johannes R. (7003642214)","6507677875; 55052918200; 36499129800; 7003642214","Sentinel-2 sharpening using a reduced-rank method","2019","IEEE Transactions on Geoscience and Remote Sensing","57","9","8694937","6408","6420","12","10.1109/TGRS.2019.2906048","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072023379&doi=10.1109%2fTGRS.2019.2906048&partnerID=40&md5=832a78bb32913c8da1b38d41ebecc03a","Recently, the Sentinel-2 (S2) satellite constellation was deployed for mapping and monitoring the Earth environment. Images acquired by the sensors mounted on the S2 platforms have three levels of spatial resolution: 10, 20, and 60 m. In many remote sensing applications, the availability of images at the highest spatial resolution (i.e., 10 m for S2) is often desirable. This can be achieved by generating a synthetic high-resolution image through data fusion. To this end, researchers have proposed techniques exploiting the spectral/spatial correlation inherent in multispectral data to sharpen the lower resolution S2 bands to 10 m. In this paper, we propose a novel method that formulates the sharpening process as a solution to an inverse problem. We develop a cyclic descent algorithm called S2Sharp and an associated tuning parameter selection algorithm based on generalized cross validation and Bayesian optimization. The tuning parameter selection method is evaluated on a simulated data set. The effectiveness of S2Sharp is assessed experimentally by comparisons to state-of-the-art methods using both simulated and real data sets. © 1980-2012 IEEE.","Data fusion; Image fusion; Image resolution; Remote sensing; Cyclic descents; Generalized cross validation; Image sharpening; Remote sensing applications; Satellite constellations; Sentinel-2 (S2) constellation; State-of-the-art methods; Super resolution; Inverse problems","Cyclic descent (CD); data fusion; image sharpening; Sentinel-2 (S2) constellation; superresolution","Article","Final","","Scopus","2-s2.0-85072023379"
"Alboody A.; Puigt M.; Roussel G.; Vantrepotte V.; Jamet C.; Tran T.K.","Alboody, Ahed (24528545800); Puigt, Matthieu (9132941600); Roussel, Gilles (57197306458); Vantrepotte, Vincent (22954813300); Jamet, Cedric (8600546000); Tran, Trung Kien (57217442266)","24528545800; 9132941600; 57197306458; 22954813300; 8600546000; 57217442266","Experimental Comparison of Multi-Sharpening Methods Applied to Sentinel-2 MSI and Sentinel-3 OLCI Images","2021","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2021-March","","9484009","","","","10.1109/WHISPERS52202.2021.9484009","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112845236&doi=10.1109%2fWHISPERS52202.2021.9484009&partnerID=40&md5=2b0e58f3cf7340bccdfdc9bdab25341b","Multi-spectral images are crucial to detect and to understand phenomena in marine observation. However, in coastal areas, these phenomena are complex and their analyze requires multi-spectral images with both a high spatial and spectral resolution. Unfortunately, no satellite is able to provide both at the same time. As a consequence, multi-sharpening techniques - a.k.a. fusion or super- resolution of multi-spectral and/or hyper-spectral images - were proposed and consist of combining information from at least two multi-spectral images with different spatial and spectral resolutions. The fused image then combines their best characteristics. Various methods - based on different strategies and tools - have been proposed to solve this problem. This article presents a comparative review of fusion methods applied to Sentinel-2 MSI (13 spectral bands with a spatial resolution ranging from 10 to 60 m) and Sentinel-3 OLCI (21 spectral bands with a spatial resolution of 300 m) images. Indeed, both satellites are extensively used in marine observation and, to the best of the authors' knowledge, the fusion of their data was partially investigated (and not in the way we aim to do in this paper). To that end, we provide both a quantitative analysis of the performance of some state-of-the-art methods on simulated images, and a qualitative analysis on real images.  © 2021 IEEE.","Hyperspectral imaging; Image fusion; Image resolution; Remote sensing; Spectral resolution; Spectroscopy; Experimental comparison; Hyper-spectral images; Marine observations; Multispectral images; Qualitative analysis; Spatial resolution; State-of-the-art methods; Strategies and tools; Image analysis","Image fusion; Real data; Remote sensing; Sentinel-2 MSI; Sentinel-3 OLCI; Simulations","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85112845236"
"Ao Z.; Sun Y.; Xin Q.","Ao, Zurui (55511761800); Sun, Ying (56939016200); Xin, Qinchuan (54421662600)","55511761800; 56939016200; 54421662600","Constructing 10-m NDVI Time Series from Landsat 8 and Sentinel 2 Images Using Convolutional Neural Networks","2021","IEEE Geoscience and Remote Sensing Letters","18","8","9125996","1461","1465","4","10.1109/LGRS.2020.3003322","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100754831&doi=10.1109%2fLGRS.2020.3003322&partnerID=40&md5=f78d584f2ab87beb8548fc51d8ba621d","Normalized difference vegetation index (NDVI) carries valuable information related to the photosynthetic activity of vegetation and is essential for monitoring phenological changes and ecosystem dynamics. The medium to high spatial resolution satellite images from Landsat 8 and Sentinel 2 offer opportunities to generate dense NDVI time series at 10-m resolution to improve our understanding of the land surface processes. However, synergistic use of Landsat 8 and Sentinel 2 for generating frequent and consistent NDVI data remains challenging as they have different spatial resolutions and spectral response functions. In this letter, we developed an attentional super resolution convolutional neural network (ASRCNN) for producing 10-m NDVI time series through fusion of Landsat 8 and Sentinel 2 images. We evaluated its performance in two heterogeneous areas. Quantitative assessments indicated that the developed network outperforms five commonly used fusion methods [i.e., enhanced deep convolutional spatiotemporal fusion network (EDCSTFN), super resolution convolutional neural network (SRCNN), spatial and temporal adaptive reflectance fusion model (STARFM), enhanced STARFM (ESTARFM), and flexible spatiotemporal data fusion (FSDAF)]. The influence of the method selection on the fusion accuracy is much greater than that of the fusion strategy in blending Landsat-Sentinel NDVI. Our results illustrate the advantages and potentials of the deep learning approaches on satellite data fusion. © 2004-2012 IEEE.","Convolution; Data fusion; Deep learning; Forestry; Image enhancement; Optical resolving power; Time series; Vegetation; High spatial resolution; Land-surface process; Normalized difference vegetation index; Photosynthetic activity; Quantitative assessments; Spatio-temporal data; Spatio-temporal fusions; Spectral response functions; accuracy assessment; artificial neural network; image analysis; Landsat; NDVI; phenology; satellite data; Sentinel; time series analysis; Convolutional neural networks","Convolutional neural network (CNN); data fusion; deep learning; remote sensing; spatiotemporal data","Article","Final","","Scopus","2-s2.0-85100754831"
"Pineda F.; Ayma V.; Beltran C.","Pineda, F. (57216822078); Ayma, V. (56566776600); Beltran, C. (55602499700)","57216822078; 56566776600; 55602499700","A generative adversarial network approach for super-resolution of sentinel-2 satellite images","2020","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","43","B1","","9","14","5","10.5194/isprs-archives-XLIII-B1-2020-9-2020","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091133545&doi=10.5194%2fisprs-archives-XLIII-B1-2020-9-2020&partnerID=40&md5=6de901c895119a77b97c4ee7b956660b","High-resolution satellite images have always been in high demand due to the greater detail and precision they offer, as well as the wide scope of the fields in which they could be applied; however, satellites in operation offering very high-resolution (VHR) images has experienced an important increase, but they remain as a smaller proportion against existing lower resolution (HR) satellites. Recent models of convolutional neural networks (CNN) are very suitable for applications with image processing, like resolution enhancement of images; but in order to obtain an acceptable result, it is important, not only to define the kind of CNN architecture but the reference set of images to train the model. Our work proposes an alternative to improve the spatial resolution of HR images obtained by Sentinel-2 satellite by using the VHR images from PeruSat1, a peruvian satellite, which serve as the reference for the super-resolution approach implementation based on a Generative Adversarial Network (GAN) model, as an alternative for obtaining VHR images. The VHR PeruSat-1 image dataset is used for the training process of the network. The results obtained were analyzed considering the Peak Signal to Noise Ratios (PSNR) and the Structural Similarity (SSIM). Finally, some visual outcomes, over a given testing dataset, are presented so the performance of the model could be analyzed as well. © 2020 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives.","Convolutional neural networks; Optical resolving power; Satellites; Signal to noise ratio; Statistical tests; Well testing; Adversarial networks; High resolution satellite images; Peak signal to noise ratio; Resolution enhancement; Satellite images; Spatial resolution; Structural similarity; Very high resolution (VHR) image; Image enhancement","GAN; PeruSat-1; Sentinel-2; Super-Resolution","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85091133545"
"Gargiulo M.","Gargiulo, Massimiliano (57200856555)","57200856555","Advances on CNN-Based Super-Resolution of Sentinel-2 Images","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8899186","3165","3168","3","10.1109/IGARSS.2019.8899186","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075353253&doi=10.1109%2fIGARSS.2019.8899186&partnerID=40&md5=4689d84e041d124c573ebf12a2c49023","Thanks to their temporal-spatial coverage and free access, Sentinel-2 images are very interesting for the community. However, a relatively coarse spatial resolution, compared to that of state-of-the-art commercial products, motivates the study of super-resolution techniques to mitigate such a limitation. Specifically, thirtheen bands are sensed simultaneously but at different spatial resolutions: 10, 20, and 60 meters depending on the spectral location. Here, building upon our previous convolutional neural network (CNN) based method [1], we propose an improved CNN solution to super-resolve the 20-m resolution bands benefiting spatial details conveyed by the accompanying 10-m spectral bands. © 2019 IEEE.","Convolution; Data fusion; Deep learning; Deep neural networks; Geology; Optical resolving power; Remote sensing; Commercial products; Free access; Pan-sharpening; Spatial coverage; Spatial resolution; Spectral band; State of the art; Super resolution; Convolutional neural networks","convolutional neural network; Data fusion; deep learning; pansharpening","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85075353253"
"Li Q.; Barrett B.; Williams R.; Hoey T.; Boothroyd R.","Li, Qing (57971676800); Barrett, Brian (35993628500); Williams, Richard (57198060439); Hoey, Trevor (7006871602); Boothroyd, Richard (57033931800)","57971676800; 35993628500; 57198060439; 7006871602; 57033931800","Enhancing performance of multi-temporal tropical river landform classification through downscaling approaches","2022","International Journal of Remote Sensing","43","17","","6445","6462","17","10.1080/01431161.2022.2139164","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142282905&doi=10.1080%2f01431161.2022.2139164&partnerID=40&md5=57ac70d9a645779844792f12ea8d8fa3","Multi-temporal remote sensing imagery has the potential to classify river landforms to reconstruct the evolutionary trajectory of river morphologies. Whilst open-access archives of high spatial resolution imagery are increasingly available from satellite sensors, such as Sentinel-2, there remains a fundamental challenge of maximising the utility of information in each band whilst maintaining a sufficiently fine resolution to identify landforms. Although image fusion and downscaling methods on Sentinel-2 imagery have been investigated for many years, there is a need to assess their performance for multi-temporal object-based river landform classification. This investigation first compared three downscaling methods: area to point regression kriging (ATPRK), super-resolution based on Sen2Res, and nearest neighbour resampling. We assessed performance of the three downscaling methods by accuracy, precision, recall and F1-score. ATPRK was the optimal downscaling approach, achieving an overall accuracy of 0.861. We successively engaged a set of experiments to determine an optimal training model, exploring single and multi-date scenarios. We find that not only does remote sensing imagery with better quality improve river landform classification performance, but multi-date datasets for establishing machine learning models should be considered for contributing higher classification accuracy. This paper presents a workflow for automated river landform recognition that could be applied to other tropical rivers with similar hydro-geomorphological characteristics. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Classification (of information); Image classification; Image enhancement; Image fusion; Remote sensing; Rivers; Satellite imagery; Tropics; Down-scaling; Downscaling methods; Image downscaling; Landform classification; Multi-temporal; Multitemporal classification; Performance; Remote sensing imagery; River landform; Tropical rivers; downscaling; fluvial geomorphology; image analysis; kriging; landform; machine learning; regression analysis; remote sensing; spatial resolution; Landforms","image downscaling; landform classification; multi-temporal classification; river landforms","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85142282905"
"Fernandez R.; Fernandez-Beltran R.; Pla F.","Fernandez, Rafael (57222243976); Fernandez-Beltran, Ruben (55838551300); Pla, Filiberto (7006504936)","57222243976; 55838551300; 7006504936","Inter-Sensor Remote Sensing Image Enhancement for Operational Sentinel-2 and Sentinel-3 Data Products","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324071","1504","1507","3","10.1109/IGARSS39084.2020.9324071","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102010234&doi=10.1109%2fIGARSS39084.2020.9324071&partnerID=40&md5=7e63a302423c3f8b2adf11c8230671a0","The recent availability of operational data from the Sentinel-2 and Sentinel-3 missions provides widespread opportunities to generate diverse high-level remote sensing products. However, the synergies between both multi-spectral instruments are often difficult to exploit from an operational perspective. Standard pansharpening algorithms may encounter important disadvantages due to the limited intersensor data availability in actual production environments. Moreover, the lack of a real high-resolution ground-truth for super-resolution techniques may affect the radiometric quality of the final result. In this scenario, this work investigates the viability of using the Multi-Spectral Instrument of Sentinel-2 for super-resolving data products acquired by the Ocean and Land Colour Instrument of Sentinel-3. Specifically, we define an inter-sensor image enhancement framework which combines a PCA-based component substitution pansharpening scheme with a CNN-based spatial enhancing super-resolution mapping. The conducted experiments reveal the suitability of the proposed approach for generating Level-4 data products within the Copernicus programme context. © 2020 IEEE.","Geology; Optical resolving power; Remote sensing; Component substitution; Data availability; Enhancement framework; Production environments; Radiometric quality; Remote sensing images; Sentinel-3 Mission; Super-resolution mappings; Image enhancement","image fusion; pansharpening; Sentinel-2 (S2); Sentinel-3 (S3); super-resolution (SR)","Conference paper","Final","","Scopus","2-s2.0-85102010234"
"Lin H.; Long J.; Peng Y.; Zhou T.","Lin, Hong (58046202900); Long, Jian (57218616379); Peng, Yuanxi (7403418922); Zhou, Tong (57222290947)","58046202900; 57218616379; 7403418922; 57222290947","Hyperspectral Multispectral Image Fusion via Fast Matrix Truncated Singular Value Decomposition","2023","Remote Sensing","15","1","207","","","","10.3390/rs15010207","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145874808&doi=10.3390%2frs15010207&partnerID=40&md5=36c873f573c9b6783650e2daf5649f41","Recently, methods for obtaining a high spatial resolution hyperspectral image (HR-HSI) by fusing a low spatial resolution hyperspectral image (LR-HSI) and high spatial resolution multispectral image (HR-MSI) have become increasingly popular. However, most fusion methods require knowing the point spread function (PSF) or the spectral response function (SRF) in advance, which are uncertain and thus limit the practicability of these fusion methods. To solve this problem, we propose a fast fusion method based on the matrix truncated singular value decomposition (FTMSVD) without using the SRF, in which our first finding about the similarity between the HR-HSI and HR-MSI is utilized after matrix truncated singular value decomposition (TMSVD). We tested the FTMSVD method on two simulated data sets, Pavia University and CAVE, and a real data set wherein the remote sensing images are generated by two different spectral cameras, Sentinel 2 and Hyperion. The advantages of FTMSVD method are demonstrated by the experimental results for all data sets. Compared with the state-of-the-art non-blind methods, our proposed method can achieve more effective fusion results while reducing the fusing time to less than 1% of such methods; moreover, our proposed method can improve the PSNR value by up to 16 dB compared with the state-of-the-art blind methods. © 2022 by the authors.","Hyperspectral imaging; Image resolution; Optical transfer function; Remote sensing; Singular value decomposition; Fusion methods; High spatial resolution; High spatial resolution multispectral images; HyperSpectral; Hyperspectral imaging super-resolution; Image spatial resolution; matrix; Spectral response functions; Superresolution; Truncated singular value decomposition; Image fusion","hyperspectral imaging super-resolution; image fusion; truncated singular value decomposition","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85145874808"
"","","","24th ISPRS Congress, Commission IV","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","4","","","","2619","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092125735&partnerID=40&md5=0486cc8540f614046d56d3d8f76e6f34","The proceedings contain 342 papers. The topics discussed include: learning super-resolution for sentinel-2 images with real ground truth data from a reference satellite; combined patch-wise minimal-maximal pixels regularization for deblurring; urban material classification using spectral and textural features retrieved from autoencoders; a worldwide 3D GCP database inherited from 20 years of massive multi-satellite observations; deep learning based feature matching and its application in image orientation; a novel RPC bias model for improving the positioning accuracy of satellite images; land salinization dynamics based on feature space combinations from landsat image in Tongyu County, Northeast China; a new index for identifying water body from sentinel-2 satellite remote sensing imagery; land cover classification using convolutional neural network with remote sensing data and digital surface model; assessing resilience of infrastructures towards exogenous events by using PS-INSAR-based surface motion estimates and machine learning regression techniques; region-based fuzzy clustering image segmentation algorithm with Kullback-Leibler distance; experiences from the project course in geoinformatics; and refugees stories told by maps: a challenge for students in a scientific Olympiad.","","","Conference review","Final","","Scopus","2-s2.0-85092125735"
"Lavreniuk M.; Kussul N.; Shelestov A.; Lavrenyuk A.; Shumilo L.","Lavreniuk, Mykola (56667743100); Kussul, Nataliia (6602485938); Shelestov, Andrii (6507365226); Lavrenyuk, Alla (16444915500); Shumilo, Leonid (57208256914)","56667743100; 6602485938; 6507365226; 16444915500; 57208256914","Super Resolution Approach for the Satellite Data Based on the Generative Adversarial Networks","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","1095","1098","3","10.1109/IGARSS46834.2022.9884460","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140369300&doi=10.1109%2fIGARSS46834.2022.9884460&partnerID=40&md5=9273c26a2a94b7f402c373876be0b2e1","In the past few years, medium and high-resolution data became freely available for downloading. It provides great opportunity for researchers not to select between solving the task with high-resolution data on small territory or on global scale, but with low-resolution satellite images. Due to high spectral and spatial resolution of the data, Sentinel-1 and Sentinel-2 are very popular sources of information. Nevertheless, in practice if we would like to receive final product in 10 m resolution we should use bands with 10 m resolution. Sentinel-2 has four such bands, but also has other bands, especially red-edge 20 m resolution bands that are useful for vegetation analysis and often are omitted due to lower resolution. Thus, in this study we propose methodology for enhancing resolution (super-resolution) of the existing low-resolution images to higher resolution images. The main idea is to use advanced methods of deep learning-Generative Adversarial Networks (GAN) and train it to increase the resolution for the satellite images. Experimental results for the Sentinel-2 data showed that this approach is efficient and could be used for creating high resolution products. © 2022 IEEE.","Deep learning; Image enhancement; Optical resolving power; Remote sensing; Satellites; Deep learning; Global scale; High resolution data; High spatial resolution; High spectral resolution; Lower resolution; Satellite data; Satellite images; Sentinel-2; Superresolution; Generative adversarial networks","deep learning; GAN; Generative Adversarial Networks; Sentinel-2; super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85140369300"
"","","","10th Iberian Conference on Pattern Recognition and Image Analysis, IbPRIA 2022","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13256 LNCS","","","","","692","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129811435&partnerID=40&md5=e853d46351bc3a4dd5fdc1f607fc8317","The proceedings contain 54 papers. The special focus in this conference is on Pattern Recognition and Image Analysis. The topics include: On the Performance of Deep Learning Models for Respiratory Sound Classification Trained on Unbalanced Data; automated Adequacy Assessment of Cervical Cytology Samples Using Deep Learning; exploring Alterations in Electrocardiogram During the Postoperative Pain; differential Gene Expression Analysis of the Most Relevant Genes for Lung Cancer Prediction and Sub-type Classification; Detection of Epilepsy in EEGs Using Deep Sequence Models – A Comparative Study; facial Emotion Recognition for Sentiment Analysis of Social Media Data; heartbeat Selection Based on Outlier Removal; characterization of Emotions Through Facial Electromyogram Signals; classification of Untranscribed Handwritten Notarial Documents by Textual Contents; multimodal Feature Evaluation and Fusion for Emotional Well-Being Monitorization; temporal Convolutional Networks for Robust Face Liveness Detection; maxDropoutV2: An Improved Method to Drop Out Neurons in Convolutional Neural Networks; transparent Management of Adjacencies in the Cubic Grid; abbreviating Labelling Cost for Sentinel-2 Image Scene Classification Through Active Learning; feature-Based Classification of Archaeal Sequences Using Compression-Based Methods; a First Approach to Image Transformation Sequence Retrieval; discriminative Learning of Two-Dimensional Probabilistic Context-Free Grammars for Mathematical Expression Recognition and Retrieval; golf Swing Sequencing Using Computer Vision; domain Adaptation in Robotics: A Study Case on Kitchen Utensil Recognition; incremental Vocabularies in Machine Translation Through Aligned Embedding Projections; An Innovative Vision System for Floor-Cleaning Robots Based on YOLOv5; LIDAR Signature Based Node Detection and Classification in Graph Topological Maps for Indoor Navigation; visual Event-Based Egocentric Human Action Recognition; an Edge-Based Computer Vision Approach for Determination of Sulfonamides in Water; visual Semantic Context Encoding for Aerial Data Introspection and Domain Prediction; an End-to-End Approach for Seam Carving Detection Using Deep Neural Networks; proposal of a Comparative Framework for Face Super-Resolution Algorithms in Forensics; on the Use of Transformers for End-to-End Optical Music Recognition; preface.","","","Conference review","Final","","Scopus","2-s2.0-85129811435"
"Zhen J.; Jiang X.; Zhao D.; Wang J.; Miao J.; Wu G.","Zhen, Jianing (57204697590); Jiang, Xiapeng (57223266834); Zhao, Demei (57224629311); Wang, Junjie (56627055800); Miao, Jing (57224644463); Wu, Guofeng (7404975854)","57204697590; 57223266834; 57224629311; 56627055800; 57224644463; 7404975854","Retrieving canopy nitrogen content of mangrove forests from Sentinel-2 super-resolution reconstruction data; [利用Sentinel-2影像超分辨率重建的红树林冠层氮含量反演]","2022","National Remote Sensing Bulletin","26","6","","1206","1219","13","10.11834/jrs.20221461","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136691263&doi=10.11834%2fjrs.20221461&partnerID=40&md5=fd67b6b30c3e61a3599648d0681ccf46","Nitrogen content is an essential element in the whole life cycle of vegetation. The estimation of mangrove Canopy Nitrogen Content (CNC) by remote sensing is greatly important for mangrove health monitoring. At present, studies that use satellite hyperspectral data to retrieve CNC of forest at regional scales, especially for mangroves, are few. In addition, the low spatial resolution of most satellite hyperspectral images and the difficulty of measuring the average leaf nitrogen content of a single image pixel in real time limit the inversion accuracy. In this study, the super-resolution reconstruction of Sentinel-2 image and in-site measurement data was used for retrieving mangrove CNC to explore the application potential of enhanced Sentinel-2 image in mangrove monitoring. Taking Zhanjiang Gaoqiao Mangrove National Nature Reserve, China as the study area, the red edge bands, near-infrared, and short wave bands of Sentinel-2 were reconstructed from 20 m to 10 m by resampling, Sen2Res, and SupReMe algorithms, respectively. The reconstructed images are used to build 40 vegetation indices and analyze their correlation with CNC. Then, the SVM-RFE iterative feature deletion method was used to determine the optimal variable combination of mangrove CNC estimation, and the Kernel Ridge Regression (KRR) model was used to construct the prediction model of mangrove CNC. Finally, the optimal model was used to map CNC spatial distribution of mangrove forests. Significant differences in canopy nitrogen content and leaf nitrogen content were found among different mangrove species, and the variation of intraspecific CNC was abundant. The reconstructed images based on Sen2Res and supreme super resolution algorithm not only had high spectral consistency (the R2 values of all bands are above 0.96) with the resampled image, but also significantly improved the clarity and spatial detail of the image compared with the 20 m resolution image. The bands sensitive to mangrove CNC are mainly concentrated in the red band (B4), red-edge band (B5), near-infrared band (B8a), and short-wave infrared band (B11 and B12). Vegetation indices related to red-edge band (RSSI and TCARIre1/OSAVI) are also effective variables to predict mangrove CNC. The inversion accuracy (R2val>0.579) of the reconstructed 10 m image based on the three methods is better than that of the original 20 m image (R2val=0.504). The fitting accuracy of the inversion model based on the reconstructed Sen2Res image (R2val=0.630, RMSE_val=5.133, RE_val=0.179) is almost the same as the resampled (R2val=0.640, RMSE_val=5.064, RE_val=0.179), and its model validation accuracy (R2cv=0.497, RMSE_cv=5.985, RE_cv=0.214) is higher. In addition, the variable number of Sen2Res is the most reasonable. Based on the spectral details and model accuracy of reconstructed images, Sentinel-2 images constructed by Sen2Res algorithm have good application potential in mangrove canopy nitrogen content estimation and can provide effective method reference and data support for fine monitoring of mangrove canopy health status at regional scale. Compared with vegetation, such as crops and grasslands, the factors influencing CNC inversion of mangroves are more complex. Although the influence of the main canopy structure factor (LAI) was considered in this study, other factors, such as species, community structure, leaf inclination, and synergistic changes, in other biochemical components should be further investigated. © 2022 National Remote Sensing Bulletin. All rights reserved.","Forestry; Image enhancement; Image reconstruction; Image resolution; Infrared devices; Infrared radiation; Iterative methods; Life cycle; Nitrogen; Pixels; Regression analysis; Satellites; Spectroscopy; Vegetation mapping; Canopy nitrogen content; Images reconstruction; Kernel ridge regressions; Mangrove canopy; Mangrove forest; Nitrogen content; Red edge; Remote-sensing; Sentinel-2; SVM-RFE; Remote sensing","canopy nitrogen content; image reconstruction; KRR; mangrove forests; remote sensing; Sentinel-2; SVM-RFE","Article","Final","","Scopus","2-s2.0-85136691263"
"Chen Y.; Ge Y.; An R.; Chen Y.","Chen, Yuehong (56084228300); Ge, Yong (26655529300); An, Ru (8584392800); Chen, Yu (57193862260)","56084228300; 26655529300; 8584392800; 57193862260","Super-resolution mapping of impervious surfaces from remotely sensed imagery with points-of-interest","2018","Remote Sensing","10","2","242","","","","10.3390/rs10020242","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042527042&doi=10.3390%2frs10020242&partnerID=40&md5=33e4604734f163651cdd921f346447c4","The accurate mapping of impervious surfaces is of key significance for various urban applications. Usually, traditional methods extract the proportion image of impervious surfaces from remote sensing images; however, the proportion image cannot specify where the impervious surfaces spatially distribute within a pixel. Meanwhile, impervious surfaces often locate urban areas and have a strong correlation with the relatively new big (geo)data points of interest (POIs). This study, therefore, proposed a novel impervious surfaces mapping method (super-resolution mapping of impervious surfaces, SRMIS) by combining a super-resolution mapping technique and POIs to increase the spatial resolution of impervious surfaces in proportion images and determine the accurate spatial location of impervious surfaces within each pixel. SRMIS was evaluated using a 10-m Sentinel-2 image and a 30-m Landsat 8 Operational Land Imager (OLI) image of Nanjing city, China. The experimental results show that SRMIS generated satisfactory impervious surface maps with better-classified image quality and greater accuracy than a traditional hard classifier, the two existing super-resolution mapping (SRM) methods of the subpixel-swapping algorithm, or the method using both pixel-level and subpixel-level spatial dependence. The experimental results show that the overall accuracy increase of SRMIS was from 2.34% to 5.59% compared with the hard classification method and the two SRM methods in the first experiment, while the overall accuracy of SRMIS was 1.34-3.09% greater than that of the compared methods in the second experiment. Hence, this study provides a useful solution to combining SRM techniques and the relatively new big (geo)data (i.e., POIs) to extract impervious surface maps with a higher spatial resolution than that of the input remote sensing images, and thereby supports urban research. © 2018 by the authors.","Image resolution; Mapping; Optical resolving power; Pixels; Remote sensing; Impervious surface; Points of interest; Spatial dependence; Super-resolution mappings; Urban remote sensing; Image processing","Impervious surfaces; Points of interest; Spatial dependence; Super-resolution mapping; Urban remote sensing","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85042527042"
"Gargiulo M.; Mazza A.; Gaetano R.; Ruello G.; Scarpa G.","Gargiulo, Massimiliano (57200856555); Mazza, Antonio (57200854745); Gaetano, Raffaele (23491959900); Ruello, Giuseppe (6603038881); Scarpa, Giuseppe (7004081145)","57200856555; 57200854745; 23491959900; 6603038881; 7004081145","A CNN-based fusion method for super-resolution of Sentinel-2 data","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8518447","4713","4716","3","10.1109/IGARSS.2018.8518447","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063139995&doi=10.1109%2fIGARSS.2018.8518447&partnerID=40&md5=307a978f4465a1b665b9faa38e43794c","Sentinel-2 data represent a rich source of information for the community due to the free access and to the temporal-spatial coverage assured. However, some of the spectral bands are sensed at reduced resolution due to a compromise between technological limitations and Copernicus program's objectives. For this reason in this work we present a new superresolution method based on Convolutional Neural Networks (CNNs) to rise the resolution of the short wave infra-red (SWIR) band from 20 to 10 meters, that is the highest resolution provided. This is accomplished by fusing the target band with the finer-resolution ones. The proposed solution compares favourably against several alternative methods according to different quality indexes. In addition we have also tested the use of the super-resolved band from an applicative perspective by detecting water basins through the Modified Normalized Difference Water Index (MNDWI). © 2018 IEEE.","","Convolutional neural network; Deep learning; Normalized difference water index; Pansharpening; Sentinel-2","Conference paper","Final","","Scopus","2-s2.0-85063139995"
"Chouteau F.; Gabet L.; Fraisse R.; Bonfort T.; Harnoufi B.; Greiner V.; Le Goff M.; Ortner M.; Paveau V.","Chouteau, F. (57741618500); Gabet, L. (6602421964); Fraisse, R. (6602321380); Bonfort, T. (57740828200); Harnoufi, B. (57741308000); Greiner, V. (57741308100); Le Goff, M. (57192703544); Ortner, M. (57216016719); Paveau, V. (57740665400)","57741618500; 6602421964; 6602321380; 57740828200; 57741308000; 57741308100; 57192703544; 57216016719; 57740665400","JOINT SUPER-RESOLUTION AND IMAGE RESTORATION FOR PLÉIADES NEO IMAGERY","2022","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","43","B1-2022","","9","15","6","10.5194/isprs-archives-XLIII-B1-2022-9-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131934830&doi=10.5194%2fisprs-archives-XLIII-B1-2022-9-2022&partnerID=40&md5=53605b4934c6bddb5f1d7d9b34484d97","Modern Earth Observation optical satellite systems, such as Airbus's Pleiades Neo (PNeo) push the boundaries of high spatial resolution by providing commercial imagery products with up to 30cm ground sampling distance (GSD). To further enhance the quality of the images, the in-space imaging system is usually complemented by on-ground image restoration processing, such as deconvolution and denoising (Latry et al., 2012). Recent advances leverage Convolutional Neural Networks (CNNs) to improve the image restoration quality (K. Zhang et al., 2021a).Single Image Super-Resolution (SISR), or Zoom, the process of obtaining a higher resolution (HR) image from a lower resolved (LR) source, has recently gained traction for both medium resolution sensors such as Sentinel 2 (Lanaras et al., 2018) and high resolution such as Pléiades and GeoEye-1 (Zhu et al., 2020). This process further enhances the resolution of the image to improve downstream applications such as mapping (L. Zhang et al., 2021) and small objects recognition (Shermeyer and Van Etten, 2019). While SISR for remote sensing has been successfully tackled using CNNs (Rohith and Kumar, 2021) the main challenge for reaching acceptable image quality performance lies in the generation of realistic LR/HR training pairs (K. Zhang et al., 2021b). In this paper, we propose:<ul><li>a dedicated simulation chain leveraging extremely-high-resolution (EHR) aerial imagery to generate realistic 30cm Pléiades Neo images and their corresponding fully restored HR equivalent at 15cm GSD</li><li>A residual-based CNN architecture which we train to jointly restore and zoom the images All contributions are assessed on real PNEO images.</li></ul>We deployed the trained models in a production context, to enhance the full Pléiades Neo products - with a swath of 47k pixels - in an efficient and scalable manner.  © 2022 F. Chouteau et al.","Aerial photography; Antennas; Convolution; Convolutional neural networks; Deep learning; Image enhancement; Image quality; Image reconstruction; Optical resolving power; Restoration; Satellite imagery; Convolutional neural network; Deep learning; Ground sampling distances; High resolution; Image super resolutions; Pleiade neo; PLEIADES; Remote-sensing; Single images; Single-image super-resolution; Remote sensing","Convolutional Neural Networks; Deep Learning; Pleiades Neo; Remote Sensing; Single-Image Super-Resolution","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85131934830"
"Masoud K.M.; Persello C.; Tolpekin V.A.","Masoud, Khairiya Mudrik (57215009156); Persello, Claudio (23493587700); Tolpekin, Valentyn A. (16418092800)","57215009156; 23493587700; 16418092800","Delineation of agricultural field boundaries from sentinel-2 images using a novel super-resolution contour detector based on fully convolutional networks","2020","Remote Sensing","12","1","59","","","","10.3390/RS12010059","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079647338&doi=10.3390%2fRS12010059&partnerID=40&md5=c6c7d9ffa393c7752b143889daf5c2df","Boundaries of agricultural fields are important features necessary for defining the location, shape, and spatial extent of agricultural units. They are commonly used to summarize production statistics at the field level. In this study, we investigate the delineation of agricultural field boundaries (AFB) from Sentinel-2 satellite images acquired over the Flevoland province, the Netherlands, using a deep learning technique based on fully convolutional networks (FCNs). We designed a multiple dilation fully convolutional network (MD-FCN) for AFB detection from Sentinel-2 images at 10 m resolution. Furthermore, we developed a novel super-resolution semantic contour detection network (named SRC-Net) using a transposed convolutional layer in the FCN architecture to enhance the spatial resolution of the AFB output from 10 m to 5 m resolution. The SRC-Net also improves the AFB maps at 5 m resolution by exploiting the spatial-contextual information in the label space. The results of the proposed SRC-Net outperform alternative upsampling techniques and are only slightly inferior to the results of the MD-FCN for AFB detection from RapidEye images acquired at 5 m resolution. © 2019 by the authors.","Agriculture; Convolution; Deep learning; Optical resolving power; Semantics; Agricultural fields; Contextual information; Convolutional networks; Important features; Learning techniques; Sentinel-2; Spatial resolution; Super-resolution mappings; Image acquisition","Agricultural field boundary; Fully convolutional network; Sentinel-2; Super-resolution mapping","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85079647338"
"Ciotola M.; Martinelli A.; Mazza A.; Scarpa G.","Ciotola, M. (57239080700); Martinelli, A. (57937431100); Mazza, A. (57200854745); Scarpa, G. (7004081145)","57239080700; 57937431100; 57200854745; 7004081145","An Adversarial Training Framework for Sentinel-2 Image Super-Resolution","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","3782","3785","3","10.1109/IGARSS46834.2022.9883144","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140358132&doi=10.1109%2fIGARSS46834.2022.9883144&partnerID=40&md5=978c0b9124123088c41e78a34f7b4e22","In this work is presented a new adversarial training framework for deep learning neural networks for super-resolution of Sentinel 2 images, exploiting the data fusion techniques on 10 and 20 meters bands. The proposed scheme is fully convolutional and tries to answer the need for generalization in scale, producing realistic and detailed accurate images. Furthermore, the presence of a mathcal{L}-{1} loss limits the instability of GAN training, limiting possible problems of spectral dis-tortion. In our preliminary experiments, the GAN training scheme has shown comparable results in comparison with the baseline approach. © 2022 IEEE.","Computer vision; Data fusion; Deep learning; Optical resolving power; Convo-lutional neural network; Data fusion technique; Deep learning; Generalisation; Image super resolutions; Learning neural networks; Neural-networks; Sentinel-2; Superresolution; Training framework; Generative adversarial networks","Convo-lutional Neural Network; Data-Fusion; Deep Learning; Generative Adversarial Network; Sentinel-2; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85140358132"
"Chen B.; Li J.; Jin Y.","Chen, Bin (57210117458); Li, Jing (57207737643); Jin, Yufang (7404457584)","57210117458; 57207737643; 7404457584","Deep learning for feature-level data fusion: Higher resolution reconstruction of historical landsat archive","2021","Remote Sensing","13","2","167","1","23","22","10.3390/rs13020167","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099179435&doi=10.3390%2frs13020167&partnerID=40&md5=16cb0d20fb4cfacbe0f3984caadbbf53","Long-term record of fine spatial resolution remote sensing datasets is critical for monitoring and understanding global environmental change, especially with regard to fine scale processes. However, existing freely available global land surface observations are limited by medium to coarse resolutions (e.g., 30 m Landsat) or short time spans (e.g., five years for 10 m Sentinel-2). Here we developed a feature-level data fusion framework using a generative adversarial network (GAN), a deep learning technique, to leverage the overlapping Landsat and Sentinel-2 observations during 2016–2019, and reconstruct 10 m Sentinel-2 like imagery from 30 m historical Landsat archives. Our tests with both simulated data and actual Landsat/Sentinel-2 imagery showed that the GANbased fusion method could accurately reconstruct synthetic Landsat data at an effective resolution very close to that of the real Sentinel-2 observations. We applied the GAN-based model to two dynamic systems: (1) land over dynamics including phenology change, cropping rotation, and water inundation; and (2) human landscape changes such as airport construction, coastal expansion, and urbanization, via historical reconstruction of 10 m Landsat observations from 1985 to 2018. The resulting comparison further validated the robustness and efficiency of our proposed framework. Our pilot study demonstrated the promise of transforming 30 m historical Landsat data into a 10 m Sentinel-2-like archive with advanced data fusion. This will enhance Landsat and Sentinel-2 data science, facilitate higher resolution land cover and land use monitoring, and global change research. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Data fusion; Data Science; Forestry; Image reconstruction; Land use; Metadata; Remote sensing; Adversarial networks; Airport construction; Effective resolutions; Global environmental change; Global land surface; Historical reconstruction; Learning techniques; Spatial resolution; Deep learning","Data fusion; Data reconstruction; GAN; Machine learning; Super resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85099179435"
"Lombana L.; Martínez-Graña A.","Lombana, Lorena (57222197390); Martínez-Graña, Antonio (55524044800)","57222197390; 55524044800","A Flood Mapping Method for Land Use Management in Small-Size Water Bodies: Validation of Spectral Indexes and a Machine Learning Technique","2022","Agronomy","12","6","1280","","","","10.3390/agronomy12061280","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131517176&doi=10.3390%2fagronomy12061280&partnerID=40&md5=fb308794df475578db8ff2d6f6ef2ff4","The assessment of flood disasters is considered an essential factor in land use management, being necessary to understand and define the magnitude of past events. In this regard, several flood diagnoses have been developed using Sentinel-2 multispectral imagery, especially in large water bodies. However, one of the main challenges is still related to floods, where water surfaces have sizes similar to the spatial resolution of the analyzed satellite images, being difficult to detect and map. Therefore, the present study developed a combined methodology for flood mapping in small-sized water bodies using Sentinel-2 MSI imagery. The method consisted of evaluating the effectiveness of the application and combination of (a) a super-resolution algorithm to improve image resolution, (b) a set of seven spectral indices for highlighting water-covered areas, such as AWE indices, and (c) two methods for flood mapping, including a machine learning method based on unsupervised classification (EM cluster) and 14 thresholding methods for automatic determination. The processes were evaluated in the Carrión River, Palencia, Spain. It was determined that the approach with the best results in flood mapping was the one that combined AWE spectral indices with methods such as Huang and Wang, Li and Tam, Otsu, moment preservation, and EM cluster classification, showing global accuracy and Kappa coefficient values higher than 0.88 and 0.75, respectively, when applying the quantitative accuracy index. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","","cluster analysis; flood mapping; Sentinel-2; spectral indices","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85131517176"
"Kussul N.; Shelestov A.; Yailymova H.; Shumilo L.; Drozd S.","Kussul, Nataliia (6602485938); Shelestov, Andrii (6507365226); Yailymova, Hanna (57202424721); Shumilo, Leonid (57208256914); Drozd, Sophia (57456870300)","6602485938; 6507365226; 57202424721; 57208256914; 57456870300","Agriculture Land Appraisal with Use of Remote Sensing and Infrastructure Data","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","2785","2788","3","10.1109/IGARSS46834.2022.9884045","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140357841&doi=10.1109%2fIGARSS46834.2022.9884045&partnerID=40&md5=eb8b51ef384d51205e0438cb2db12049","1st July 2021 the law on the creation of land market start effect in Ukraine. As a result, land appraisal became cornerstone task in Ukrainian agriculture sector. The official methodology on land appraisal includes use of soil fertility characteristics combined with coefficients related to the distance to the infrastructure objects or settlements and placing of field in specific functional areas, like recreational, or areas with high level of radiation pollution. In this study we collected open source infostructure geospatial information and characteristics of fields obtained from remote sensing data-crop types and Normalized Difference Vegetation Index to build land price predictive model trained on the official land market information. This work designed to investigate potential of geo-informational technologies and remote sensing in the land appraisal use. We separated all available ground truth land price data into three groups by fields size-very small, small, medium and big. We found different relationships between field characteristics and prices. For very small fields the most important features are area, altitude, slope, bonitet and distances to elevators, villages and roads. For small fields the most important are bonitet, altitude, area and distances to cities and roads. For medium and big field's area, slope, distance to cities, roads and historical NDVI. © 2022 IEEE.","Agriculture; Commerce; Deep learning; Generative adversarial networks; Agriculture sectors; Deep learning; GAN; Land markets; Land prices; Remote-sensing; Sentinel-2; Soil fertility; Superresolution; Ukraine; Remote sensing","deep learning; GAN; Generative Adversarial Networks; Sentinel-2; super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85140357841"
"Michel J.; Vinasco-Salinas J.; Inglada J.; Hagolle O.","Michel, Julien (55437838200); Vinasco-Salinas, Juan (57850040700); Inglada, Jordi (55996140200); Hagolle, Olivier (6602243908)","55437838200; 57850040700; 55996140200; 6602243908","SEN2VENµS, a Dataset for the Training of Sentinel-2 Super-Resolution Algorithms","2022","Data","7","7","96","","","","10.3390/data7070096","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136213278&doi=10.3390%2fdata7070096&partnerID=40&md5=fe1676aa47e39d3679f1f864d1674459","Boosted by the progress in deep learning, Single Image Super-Resolution (SISR) has gained a lot of interest in the remote sensing community, who sees it as an opportunity to compensate for satellites’ ever-limited spatial resolution with respect to end users’ needs. This is especially true for Sentinel-2 because of its unique combination of resolution, revisit time, global coverage and free and open data policy. While there has been a great amount of work on network architectures in recent years, deep-learning-based SISR in remote sensing is still limited by the availability of the large training sets it requires. The lack of publicly available large datasets with the required variability in terms of landscapes and seasons pushes researchers to simulate their own datasets by means of downsampling. This may impair the applicability of the trained model on real-world data at the target input resolution. This paper presents SEN2VENµS, an open-data licensed dataset composed of 10 m and 20 m cloud-free surface reflectance patches from Sentinel-2, with their reference spatially registered surface reflectance patches at 5 m resolution acquired on the same day by the VENµS satellite. This dataset covers 29 locations on earth with a total of 132,955 patches of 256 × 256 pixels at 5 m resolution and can be used for the training and comparison of super-resolution algorithms to bring the spatial resolution of 8 of the Sentinel-2 bands up to 5 m. Data Set:https://zenodo.org/deposit/6514159. Data Set License: Etalab Open Licence Version 2.0, Creative Commons BY-NC 4.0, Creative Commons BY 4.0. © 2022 by the authors.","Deep learning; Image resolution; Network architecture; Open Data; Reflection; Remote sensing; Dataset; Image super resolutions; Open datum; Remote-sensing; Sentinel-2; Single images; Single-image super-resolution; Spatial resolution; Super resolution algorithms; Surface reflectance; Large dataset","dataset; Sentinel-2; single-image super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85136213278"
"Tao Y.; Xiong S.; Song R.; Muller J.-P.","Tao, Yu (56539197700); Xiong, Siting (56009476000); Song, Rui (57215778562); Muller, Jan-Peter (7404871794)","56539197700; 56009476000; 57215778562; 7404871794","Towards streamlined single-image super-resolution: Demonstration with 10 m sentinel-2 colour and 10–60 m multi-spectral vnir and swir bands","2021","Remote Sensing","13","13","2614","","","","10.3390/rs13132614","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110158244&doi=10.3390%2frs13132614&partnerID=40&md5=6db3aca28506cea46448cf9d7df79a45","Higher spatial resolution imaging data are considered desirable in many Earth observation applications. In this work, we propose and demonstrate the TARSGAN (learning Terrestrial image deblurring using Adaptive weighted dense Residual Super-resolution Generative Adversarial Net-work) system for Super-resolution Restoration (SRR) of 10 m/pixel Sentinel-2 “true” colour images as well as all the other multispectral bands. In parallel, the ELF (automated image Edge detection and measurements of edge spread function, Line spread function, and Full width at half maximum) system is proposed to achieve automated and precise assessments of the effective resolutions of the input and SRR images. Subsequent ELF measurements of the TARSGAN SRR results suggest an averaged effective resolution enhancement factor of about 2.91 times (equivalent to ~3.44 m/pixel for the 10 m/pixel bands) given a nominal SRR upscaling factor of 4 times. Several examples are provided for different types of scenes from urban landscapes to agricultural scenes and sea-ice floes. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Agricultural robots; Display devices; Edge detection; Optical resolving power; Sea ice; Earth observations; Edge spread function; Effective resolutions; ELF measurements; Image edge detection; Line spread functions; Spatial resolution; Super-resolution restoration; Image enhancement","Effective resolution assessment; Image quality; Multispectral; Sentinel; Sentinel-2; Sharpness; SR; SRR; Super-resolution restoration","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85110158244"
"Dell'Aglio D.A.G.; Gargiulo M.; Iodice A.; Riccio D.; Ruello G.","Dell'Aglio, D.A.G. (57202729372); Gargiulo, M. (57200856555); Iodice, A. (7003793925); Riccio, D. (7006577607); Ruello, G. (6603038881)","57202729372; 57200856555; 7003793925; 7006577607; 6603038881","Active Fire Detection in Multispectral Super-Resolved Sentinel-2 Images by Means of Sam-Based Approach","2019","5th International Forum on Research and Technologies for Society and Industry: Innovation to Shape the Future, RTSI 2019 - Proceedings","","","8895538","124","127","3","10.1109/RTSI.2019.8895538","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075638562&doi=10.1109%2fRTSI.2019.8895538&partnerID=40&md5=7217bd01b2ac64e53dd9446645b1e2c5","In the last years, Sentinel-2 data have become extensively used by the remote sensing community due to their relatively fine spatial resolution, high revisit time ensured by the twin satellites Sentinel- 2 and, of course, their free availability. However, not all the bands are provided at the highest resolution (10 meters). For instance, the Short-Wave Infrared (SWIR) bands, very useful for fires monitoring applications, are provided at 20 meters. Therefore, in order to have a more detailed Active Fire maps, we have proposed a super-resolution data fusion method based on Convolutional Neural Network (CNN), hereafter SRNN+. Then we have compared the standard Active Fire Detection (AFDs) based on indices (AFIs) [1], widely used in literature for active fires monitoring purpose, with a method based on the Spectral Angular Mapper (SAM) [2]. The proposed analysis is validated on the widespread fires that damaged the volcano Vesuvius (Italy) during the summer of 2017. © 2019 IEEE.","Convolution; Data fusion; Fire detectors; Infrared radiation; Neural networks; Optical resolving power; Remote sensing; Active fires; Convolutional neural network; Data fusion methods; Highest resolutions; Monitoring applications; Monitoring purpose; Short wave infrared bands; Super resolution; Fires","active fire indices; active fires; convolutional neural network; Data fusion; SAM; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85075638562"
"Qian X.; Jiang T.-X.; Zhao X.-L.","Qian, Xiao (58017688400); Jiang, Tai-Xiang (57195246028); Zhao, Xi-Le (24073933900)","58017688400; 57195246028; 24073933900","SelfS2: Self-Supervised Transfer Learning for Sentinel-2 Multispectral Image Super-Resolution","2023","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","16","","","215","227","12","10.1109/JSTARS.2022.3224987","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144042547&doi=10.1109%2fJSTARS.2022.3224987&partnerID=40&md5=919b8cccbd500f8f22ab24d3911324c4","The multispectral image captured by the Sentinel-2 satellite contains 13 spectral bands with different resolutions, which may hider some of the subsequent applications. In this article, we design a novel method to super-resolve 20-and 60-m coarse bands of the S2 images to 10 m, achieving a complete dataset at the 10-m resolution. To tackle this inverse problem, we leverage the deep image prior expressed by the convolution neural network (CNN). Specifically, a plain ResNet architecture is adopted, and the 3-D separable convolution is utilized to better capture the spatial-spectral features. The loss function is tailored based on the degradation model, enforcing the network output obeying the degradation process. Meanwhile, a network parameter initialization strategy is designed to further mine the abundant fine information provided by existing 10-m bands. The network parameters are inferred solely from the observed S2 image in a self-supervised manner without involving any extra training data. Finally, the network outputs the super-resolution result. On the one hand, our method could utilize the high model capacity of CNNs and work without large amounts of training data required by many deep learning techniques. On the other hand, the degradation process is fully considered, and each module in our work is interpretable. Numerical results on synthetic and real data illustrate that our method could outperform compared state-of-the-art methods.  © 2008-2012 IEEE.","Deep learning; Inverse problems; Numerical methods; Optical resolving power; Deep image prior; Degradation process; Image priors; Multispectral images; Network parameters; Self-supervised learning; Sentinel-2 satellite; Separable 3d convolution; Superresolution; Training data; artificial neural network; image processing; image resolution; multispectral image; Sentinel; supervised learning; Convolution","Deep image prior; self-supervised learning; Sentinel-2 satellite; separable 3-D convolution; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85144042547"
"Shao Z.; Cai J.; Fu P.; Hu L.; Liu T.","Shao, Zhenfeng (7202244409); Cai, Jiajun (57193551962); Fu, Peng (57207967909); Hu, Leiqiu (55642592500); Liu, Tao (56043220000)","7202244409; 57193551962; 57207967909; 55642592500; 56043220000","Deep learning-based fusion of Landsat-8 and Sentinel-2 images for a harmonized surface reflectance product","2019","Remote Sensing of Environment","235","","111425","","","","10.1016/j.rse.2019.111425","135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073688762&doi=10.1016%2fj.rse.2019.111425&partnerID=40&md5=c007c08a8b1222b20426acc2492efc67","Landsat and Sentinel-2 sensors together provide the most widely accessible medium-to-high spatial resolution multispectral data for a wide range of applications, such as vegetation phenology identification, crop yield estimation, and forest disturbance detection. Improved timely and accurate observations of the Earth's surface and dynamics are expected from the synergistic use of Landsat and Sentinel-2 data, which entails coordinating the spatial resolution gap between Landsat (30 m) and Sentinel-2 (10 m or 20 m) images. However, widely used data fusion techniques may not fulfil community's needs for generating a temporally dense reflectance product at 10 m spatial resolution from combined Landsat and Sentinel-2 images because of their inherent algorithmic weaknesses. Inspired by the recent advances in deep learning, this study developed an extended super-resolution convolutional neural network (ESRCNN) to a data fusion framework, specifically for blending Landsat-8 Operational Land Imager (OLI) and Sentinel-2 Multispectral Imager (MSI) data. Results demonstrated the effectiveness of the deep learning-based fusion algorithm in yielding a consistent and comparable dataset at 10 m from Landsat-8 and Sentinel-2. Further accuracy assessments revealed that the performance of the fusion network was influenced by both the number of input auxiliary Sentinel-2 images and temporal interval (i.e., difference in image acquisition dates) between auxiliary Sentinel-2 images and the target Landsat-8 image. Compared to the benchmark algorithm, area-to-point regression kriging (ATKPK), the deep learning-based fusion framework proved better in the quantitative assessment in terms of RMSE (root mean square error), correlation coefficient (CC), universal image quality index (UIQI), relative global-dimensional synthesis error (ERGAS), and spectral angle mapper (SAM). ESRCNN better preserved the reflectance distribution as the original image compared to ATPRK, resulting in an improved image quality. Overall, the developed data fusion network that blends Landsat-8 and Sentinel-2 images has the potential to help generate continuous reflectance observations of higher temporal frequency than that can be obtained from a single Landsat-like sensor. © 2019 Elsevier Inc.","Benchmarking; Data fusion; Image enhancement; Image fusion; Image quality; Image resolution; Learning algorithms; Mean square error; Neural networks; Reflection; Sensor data fusion; Continuous monitoring; Convolutional neural network; Correlation coefficient; High spatial resolution; LANDSAT; Quantitative assessments; RMSE (root mean square error); Sentinel-2; benchmarking; detection method; estimation method; Landsat; qualitative analysis; satellite data; satellite imagery; Sentinel; spatial resolution; surface reflectance; vegetation mapping; Deep learning","Continuous monitoring; Data fusion; Deep learning; Landsat-8; Sentinel-2","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85073688762"
"Poursanidis D.; Traganos D.; Reinartz P.; Chrysoulakis N.","Poursanidis, Dimitris (36085250400); Traganos, Dimosthenis (57194590031); Reinartz, Peter (56216874200); Chrysoulakis, Nektarios (6603353298)","36085250400; 57194590031; 56216874200; 6603353298","On the use of Sentinel-2 for coastal habitat mapping and satellite-derived bathymetry estimation using downscaled coastal aerosol band","2019","International Journal of Applied Earth Observation and Geoinformation","80","","","58","70","12","10.1016/j.jag.2019.03.012","55","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065736859&doi=10.1016%2fj.jag.2019.03.012&partnerID=40&md5=a3fde6e1687683433c57278ae99f39ff","Coastal habitats provide a plethora of ecosystem services, yet they undergo continuous pressure and degradation due to the human-induced climate change. Conservation and management imply continuous monitoring and mapping of their spatial distribution at first. The present study explores the capabilities of the Copernicus Sentinel-2 mission and the contribution of its coastal aerosol band 1 (443 nm) for the mapping of the dominant Mediterranean coastal marine habitats and the bathymetry in three survey sites in the East Mediterranean. The selected sites have shallow to deep habitats and a high variability of oceanographic and seabed morphological conditions. The major findings of our study demonstrate the advantages of the downscaled Sentinel-2 coastal aerosol band 1 for both optically shallow habitat and satellite-derived bathymetry mapping due to its great water penetration. The use of Sentinel-2 band 1 allows detection of Posidonia oceanica seagrass beds down to 32.2 m of depth. Sentinel-2 constellation with its 10-m spatial resolution at most of the spectral bands, 5-day revisit frequency and open data policy can be an important tool to provide crucial missing information on the spatial distribution of coastal habitats and on their bathymetry distribution, especially in data-poor and/or remote areas with large gaps in a retrospective, rapid and non-intrusive manner. As such, it becomes a crucial ally for the conservation and management of coastal habitats globally. © 2019 Elsevier B.V.","Posidonia oceanica; aerosol composition; aerosol formation; bathymetry; satellite data; satellite imagery; seagrass; Sentinel; spatial resolution","Coastal habitat mapping; Posidonia oceanica; Satellite-derived bathymetry; Seagrass; Sentinel-2; Super-resolution","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85065736859"
"Hoque M.R.U.; Wu J.; Kwan C.; Koperski K.; Li J.","Hoque, Md Reshad Ul (57215344852); Wu, Jian (57193141747); Kwan, Chiman (7201421216); Koperski, Krzysztof (6603540174); Li, Jiang (56226550100)","57215344852; 57193141747; 7201421216; 6603540174; 56226550100","ArithFusion: An Arithmetic Deep Model for Temporal Remote Sensing Image Fusion","2022","Remote Sensing","14","23","6160","","","","10.3390/rs14236160","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143761796&doi=10.3390%2frs14236160&partnerID=40&md5=6d162c4fc285294f57b7c7e89e83f5f4","Different satellite images may consist of variable numbers of channels which have different resolutions, and each satellite has a unique revisit period. For example, the Landsat-8 satellite images have 30 m resolution in their multispectral channels, the Sentinel-2 satellite images have 10 m resolution in the pan-sharp channel, and the National Agriculture Imagery Program (NAIP) aerial images have 1 m resolution. In this study, we propose a simple yet effective arithmetic deep model for multimodal temporal remote sensing image fusion. The proposed model takes both low- and high-resolution remote sensing images at (Formula presented.) together with low-resolution images at a future time (Formula presented.) from the same location as inputs and fuses them to generate high-resolution images for the same location at (Formula presented.). We propose an arithmetic operation applied to the low-resolution images at the two time points in feature space to take care of temporal changes. We evaluated the proposed model on three modality pairs for multimodal temporal image fusion, including downsampled WorldView-2/original WorldView-2, Landsat-8/Sentinel-2, and Sentinel-2/NAIP. Experimental results show that our model outperforms traditional algorithms and recent deep learning-based models by large margins in most scenarios, achieving sharp fused images while appropriately addressing temporal changes. © 2022 by the authors.","Antennas; Deep learning; Generative adversarial networks; Image fusion; Satellite imagery; Space optics; Deep learning; Generative adversarial network; HRNet; LANDSAT; Neural-networks; Remote sensing images; Remote-sensing; Satellite images; Superresolution; U-net; Remote sensing","deep learning; generative adversarial network (GAN); HRNet; image fusion; neural networks; remote sensing; super-resolution; U-Net","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85143761796"
"Karmakar C.; Antunes A.; Datcu M.","Karmakar, Chandrabali (57220177379); Antunes, Ana (57938121000); Datcu, Mihai (7004523124)","57220177379; 57938121000; 7004523124","Achieving Information Super-resolution for Sentinel-2 NDVI Through Gaussian Process Regression","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","338","341","3","10.1109/IGARSS46834.2022.9883934","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140399561&doi=10.1109%2fIGARSS46834.2022.9883934&partnerID=40&md5=230edeb564b13a64852ca35fcafe2f9c","Super-resolution is used to recover high resolution images from low resolution images. We use this concept in a slightly different context to achieve higher quality knowledge from low resolution satellite images. The technique involves transfer learning from high to low resolution images using a Gaussian Process Regression model. We use high resolution drone images to train the model. This technique is applied in three case studies to verify the consistency of results in case of NDVI computation. However, the same technique can be applied to obtain for other application of satellite images in plant vigor assessment. © 2022 IEEE.","Gaussian distribution; Gaussian noise (electronic); Optical resolving power; Remote sensing; Drone image; Gaussian process regression; High-resolution images; Information super-resolution; Low resolution images; NDVI; Satellite images; Sentinel-2 image; Superresolution; Transfer learning; Drones","Drone Images; Gaussian Process Regression; Information Super-resolution; NDVI; Sentinel-2 Images; Transfer Learning","Conference paper","Final","","Scopus","2-s2.0-85140399561"
"Salgueiro L.; Marcello J.; Vilaplana V.","Salgueiro, Luis (57344768400); Marcello, Javier (6602158797); Vilaplana, Verónica (23394280500)","57344768400; 6602158797; 23394280500","Single-image super-resolution of sentinel-2 low resolution bands with residual dense convolutional neural networks","2021","Remote Sensing","13","24","5007","","","","10.3390/rs13245007","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121470362&doi=10.3390%2frs13245007&partnerID=40&md5=86569e24c75991656da8771235196c95","Sentinel-2 satellites have become one of the main resources for Earth observation images because they are free of charge, have a great spatial coverage and high temporal revisit. Sentinel-2 senses the same location providing different spatial resolutions as well as generating a multi-spectral image with 13 bands of 10, 20, and 60 m/pixel. In this work, we propose a single-image super-resolution model based on convolutional neural networks that enhances the low-resolution bands (20 m and 60 m) to reach the maximal resolution sensed (10 m) at the same time, whereas other approaches provide two independent models for each group of LR bands. Our proposed model, named Sen2-RDSR, is made up of Residual in Residual blocks that produce two final outputs at maximal resolution, one for 20 m/pixel bands and the other for 60 m/pixel bands. The training is done in two stages, first focusing on 20 m bands and then on the 60 m bands. Experimental results using six quality metrics (RMSE, SRE, SAM, PSNR, SSIM, ERGAS) show that our model has superior performance compared to other state-of-the-art approaches, and it is very effective and suitable as a preliminary step for land and coastal applications, as studies involving pixel-based classification for Land-Use-Land-Cover or the generation of vegetation indices. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolution; Convolutional neural networks; Deep neural networks; Image enhancement; Land use; Spectroscopy; Convolutional neural network; Deep learning; Earth observation images; Free of charge; Image super resolutions; Lower resolution; Sentinel-2; Single images; Spatial coverage; Superresolution; Optical resolving power","Convolutional neural network; Deep learning; Sentinel-2; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85121470362"
"Pouliot D.; Latifovic R.; Pasher J.; Duffe J.","Pouliot, Darren (8212745300); Latifovic, Rasim (6603031730); Pasher, Jon (16048197700); Duffe, Jason (6603325238)","8212745300; 6603031730; 16048197700; 6603325238","Landsat super-resolution enhancement using convolution neural networks and Sentinel-2 for training","2018","Remote Sensing","10","3","394","","","","10.3390/rs10030394","60","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044173539&doi=10.3390%2frs10030394&partnerID=40&md5=faecc38b73d3cf2c0bdadd85850a3657","Landsat is a fundamental data source for understanding historical change and its effect on environmental processes. In this research we test shallow and deep convolution neural networks (CNNs) for Landsat image super-resolution enhancement, trained using Sentinel-2, in three study sites representing boreal forest, tundra, and cropland/woodland environments. The analysis sought to assess baseline performance and determine the capacity for spatial and temporal extension of the trained CNNs. This is not a data fusion approach and a high-resolution image is only needed to train the CNN. Results show improvement with the deeper network generally achieving better results. For spatial and temporal extension, the deep CNN performed the same or better than the shallow CNN, but at greater computational cost. Results for temporal extension were influenced by change potentiality reducing the performance difference between the shallow and deep CNN. Visual examination revealed sharper images regarding land cover boundaries, linear features, and within-cover textures. The results suggest that spatial enhancement of the Landsat archive is feasible, with optimal performance where CNNs can be trained and applied within the same spatial domain. Future research will assess the enhancement on time series and associated land cover applications. © 2018 by the authors.","Convolution; Data fusion; Optical resolving power; Base-line performance; Convolution neural network; Environmental process; High resolution image; Land cover applications; LANDSAT; Sentinel-2; Super resolution; Image enhancement","Convolution neural network; Landsat; Sentinel-2; Super resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85044173539"
