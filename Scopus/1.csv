"Authors","Author full names","Author(s) ID","Titles","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","DOI","Cited by","Link","Abstract","Indexed Keywords","Author Keywords","Document Type","Publication Stage","Open Access","Source","EID"
"Ji H.; Di H.; Wang S.; Shi Q.","Ji, Haowei (57985145200); Di, Huijun (7005326748); Wang, Shunzhou (57204129139); Shi, Qingxuan (56162102700)","57985145200; 7005326748; 57204129139; 56162102700","Cascade Scale-Aware Distillation Network for Lightweight Remote Sensing Image Super-Resolution","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13537 LNCS","","","274","286","12","10.1007/978-3-031-18916-6_23","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142846790&doi=10.1007%2f978-3-031-18916-6_23&partnerID=40&md5=73f736bf098e0a4d89a5fa36039636d8","Recently, convolution neural network based methods have dominated the remote sensing image super-resolution (RSISR). However, most of them own complex network structures and a large number of network parameters, which is not friendly to computational resources limited scenarios. Besides, scale variations of objects in the remote sensing image are still challenging for most methods to generate high-quality super-resolution results. To this end, we propose a scale-aware group convolution (SGC) for RSISR. Specifically, each SGC firstly uses group convolutions with different dilation rates for extracting multi-scale features. Then, a scale-aware feature guidance approach and enhancement approach are leveraged to enhance the representation ability of different scale features. Based on SGC, a cascaded scale-aware distillation network (CSDN) is designed, which is composed of multiple SGC based cascade scale-aware distillation blocks (CSDBs). The output of each CSDB will be fused via the backward feature fusion module for final image super-resolution reconstruction. Extensive experiments are performed on the commonly-used UC Merced dataset. Quantitative and qualitative experiment results demonstrate the effectiveness of our method. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2022.","Air navigation; Complex networks; Convolution; Optical resolving power; Remote sensing; Convolution neural network; Feature distillation; Feature learning; Image super resolutions; Lightweight neural network; Multi-scale feature learning; Multi-scale features; Neural-networks; Remote sensing image super-resolution; Remote sensing images; Distillation","Feature distillation; Lightweight neural network; Multi-scale feature learning; Remote sensing image super-resolution","Conference paper","Final","","Scopus","2-s2.0-85142846790"
"Wang X.; Cheng Y.; Mei X.; Jiang J.; Ma J.","Wang, Xinya (57221484390); Cheng, Yingsong (58088284100); Mei, Xiaoguang (55800813300); Jiang, Junjun (54902306100); Ma, Jiayi (26638975600)","57221484390; 58088284100; 55800813300; 54902306100; 26638975600","Group Shuffle and Spectral-Spatial Fusion for Hyperspectral Image Super-Resolution","2022","IEEE Transactions on Computational Imaging","8","","","1223","1236","13","10.1109/TCI.2023.3235153","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147269765&doi=10.1109%2fTCI.2023.3235153&partnerID=40&md5=163bbdcb42939a74412defc79e985bde","Recently, super-resolution (SR) tasks for single hyperspectral images have been extensively investigated and significant progress has been made by introducing advanced deep learning-based methods. However, hyperspectral image SR is still a challenging problem because of the numerous narrow and successive spectral bands of hyperspectral images. Existing methods adopt the group reconstruction mode to avoid the unbearable computational complexity brought by the high spectral dimensionality. Nevertheless, the group data lose the spectral responses in other ranges and preserve the information redundancy caused by continuous and similar spectrograms, thus containing too little information. In this paper, we propose a novel single hyperspectral image SR method named GSSR, which pioneers the exploration of tweaking spectral band sequence to improve the reconstruction effect. Specifically, we design the group shuffle that leverages interval sampling to produce new groups for separating adjacent and extremely similar bands. In this way, each group of data has more varied spectral responses and less redundant information. After the group shuffle, the spectral-spatial feature fusion block is employed to exploit the spectral-spatial features. To compensate for the adjustment of spectral order by the group shuffle, the local spectral continuity constraint module is subsequently appended to constrain the features for ensuring the spectral continuity. Experimental results on both natural and remote sensing hyperspectral images demonstrate that the proposed method achieves the best performance compared to the state-of-the-art methods.  © 2015 IEEE.","Deep learning; Hyperspectral imaging; Image enhancement; Image fusion; Optical resolving power; Remote sensing; Spectrographs; Constraint module; Continuity constraints; Features extraction; Features fusions; Group shuffle; HyperSpectral; Hyperspectral image; Images reconstruction; Local spectral continuity constraint module; Spatial features; Spatial resolution; Spectral-spatial feature fusion block; Spectrograms; Superresolution; Image reconstruction","group shuffle; Hyperspectral image; local spectral continuity constraint module; spectral-spatial feature fusion block; super-resolution","Article","Final","","Scopus","2-s2.0-85147269765"
"Sun Y.; Zhi X.; Jiang S.; Gong J.; Shi T.; Wang N.","Sun, Yu (57216366423); Zhi, Xiyang (36740955600); Jiang, Shikai (57195961425); Gong, Jinnan (57211654546); Shi, Tianjun (57226673430); Wang, Nan (57607580000)","57216366423; 36740955600; 57195961425; 57211654546; 57226673430; 57607580000","Imaging Simulation Method for Novel Rotating Synthetic Aperture System Based on Conditional Convolutional Neural Network","2023","Remote Sensing","15","3","688","","","","10.3390/rs15030688","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147971013&doi=10.3390%2frs15030688&partnerID=40&md5=e8473faf1e5545282e8bbdcbb69b34d8","The novel rotating synthetic aperture (RSA) is a new optical imaging system that uses the method of rotating the rectangular primary mirror for dynamic imaging. It has the advantage of being lightweight, with no need for splicing and real-time surface shape maintenance on orbit. The novel imaging method leads to complex image quality degradation characteristics. Therefore, it is vital to use the image quality improvement method to restore and improve the image quality to meet the application requirements. For the RSA system, a new system that has not been applied in orbit, it is difficult to construct suitable large datasets. Therefore, it is necessary to study and establish the dynamic imaging characteristic model of the RSA system, and on this basis provide data support for the corresponding image super resolution and restoration method through simulation. In this paper, we first analyze the imaging characteristics and mathematically model the rectangular rotary pupil of the RSA system. On this basis, combined with the analysis of the physical interpretation of the blur kernel, we find that the optimal blur kernel is not the point spread function (PSF) of the imaging system. Therefore, the simulation method of convolving the input image directly with the PSF is flawed. Furthermore, the weights of a convolutional neural network (CNN) are the same for each input. This means that the normal convolutional layer is not only difficult to accurately estimate the time-varying blur kernel, but also difficult to adapt to the change in the length–width ratio of the primary mirror. To that end, we propose a blur kernel estimation conditional convolutional neural network (CCNN) that is equivalent to multiple normal CNNs. We extend the CNN to a conditional model by taking an encoding as an additional input and using conditionally parameterized convolutions instead of normal convolutions. The CCNN can simulate the imaging characteristics of the rectangular pupil with different length–width ratios and different rotation angles in a controllable manner. The results of semi-physical experiments show that the proposed simulation method achieves a satisfactory performance, which can provide data and theoretical support for the image restoration and super-resolution method of the RSA system. © 2023 by the authors.","Convolution; Convolutional neural networks; Dynamics; Image enhancement; Image quality; Image reconstruction; Imaging systems; Large dataset; Optical resolving power; Optical transfer function; Restoration; Synthetic apertures; Aperture system; Conditional convolutional neural network; Convolutional neural network; Dynamic imaging; Images simulations; Imaging characteristics; Optical remote sensing; Primary mirrors; Rectangular pupils; Rotating synthetic aperture; Optical remote sensing","conditional convolutional neural network; image simulation; optical remote sensing; rectangular pupil; rotating synthetic aperture","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85147971013"
"Wang X.; Yi J.; Guo J.; Song Y.; Lyu J.; Xu J.; Yan W.; Zhao J.; Cai Q.; Min H.","Wang, Xuan (57206602416); Yi, Jinglei (57896639700); Guo, Jian (57547825000); Song, Yongchao (57744415600); Lyu, Jun (57219317602); Xu, Jindong (35176864300); Yan, Weiqing (55929241300); Zhao, Jindong (57964367300); Cai, Qing (57476388900); Min, Haigen (56654773400)","57206602416; 57896639700; 57547825000; 57744415600; 57219317602; 35176864300; 55929241300; 57964367300; 57476388900; 56654773400","A Review of Image Super-Resolution Approaches Based on Deep Learning and Applications in Remote Sensing","2022","Remote Sensing","14","21","5423","","","","10.3390/rs14215423","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141844839&doi=10.3390%2frs14215423&partnerID=40&md5=300921e628739e7248e683000e8df55c","At present, with the advance of satellite image processing technology, remote sensing images are becoming more widely used in real scenes. However, due to the limitations of current remote sensing imaging technology and the influence of the external environment, the resolution of remote sensing images often struggles to meet application requirements. In order to obtain high-resolution remote sensing images, image super-resolution methods are gradually being applied to the recovery and reconstruction of remote sensing images. The use of image super-resolution methods can overcome the current limitations of remote sensing image acquisition systems and acquisition environments, solving the problems of poor-quality remote sensing images, blurred regions of interest, and the requirement for high-efficiency image reconstruction, a research topic that is of significant relevance to image processing. In recent years, there has been tremendous progress made in image super-resolution methods, driven by the continuous development of deep learning algorithms. In this paper, we provide a comprehensive overview and analysis of deep-learning-based image super-resolution methods. Specifically, we first introduce the research background and details of image super-resolution techniques. Second, we present some important works on remote sensing image super-resolution, such as training and testing datasets, image quality and model performance evaluation methods, model design principles, related applications, etc. Finally, we point out some existing problems and future directions in the field of remote sensing image super-resolution. © 2022 by the authors.","Deep learning; Design; Image quality; Image reconstruction; Learning algorithms; Learning systems; Optical resolving power; Quality control; 'current; Deep learning; Evaluation methods; Image processing technology; Image super resolutions; Modeling designs; Remote sensing images; Remote-sensing; Satellite image processing; Superresolution methods; Remote sensing","deep learning; evaluation methods; image super-resolution; model design; remote sensing","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85141844839"
"Yao D.; Liang H.; Campos J.; Yan L.; Yan C.; Jiang C.; Tan S.; Liang C.; Wang H.; Meng L.; Cheng Y.","Yao, Dong (57215836069); Liang, Hangang (58026153100); Campos, Juan (7201617405); Yan, Lei (8328907300); Yan, Chunhui (57194328053); Jiang, Chunming (57957018400); Tan, Songnian (58026959800); Liang, Chao (58027209500); Wang, Hanyu (57215828297); Meng, Lingtong (57200932753); Cheng, Yanping (57501217000)","57215836069; 58026153100; 7201617405; 8328907300; 57194328053; 57957018400; 58026959800; 58027209500; 57215828297; 57200932753; 57501217000","Calculation and restoration of lost spatial information in division-of-focal-plane polarization remote sensing using polarization super-resolution technology","2023","International Journal of Applied Earth Observation and Geoinformation","116","","103155","","","","10.1016/j.jag.2022.103155","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144533234&doi=10.1016%2fj.jag.2022.103155&partnerID=40&md5=6666b8459e312c7279b4745c78f2a38f","Spatial resolution plays a crucial role in the process of polarization remote sensing method for Earth observation, and the problem of resolution improvement has always been an important research direction in the field of remote sensing. To address the spatial resolution loss and information errors in division-of-focal-plane (DoFP) polarization remote sensing systems, this study proposes a new polarization super-resolution (PSR) remote sensor and a data recovery method. We calibrate the relative displacement between image plane and detector in the laboratory, and verify the effectiveness of this method by actual external imaging. The experimental results demonstrate that the system can eliminate the spatial resolution loss caused by the DoFP technology, and the real image resolution is doubled in both the horizontal and vertical directions. We also verify the effectiveness of this new instrument and data recovery method. By comparing the results of this method with the existing algorithms, it is found that it has a great improvement under the same evaluation parameters, and the texture features of the target scene were significantly enhanced. Moreover, the system can simultaneously perceive multidimensional information, such as high-resolution intensity images and pixel-level polarization information of the target scene, and therefore, can potentially be applied in remote sensing systems. © 2022 The Authors","data set; image resolution; pixel; polarization; remote sensing; spatiotemporal analysis","Calibration method; Division-of-focal-plane; Effect evaluation; Polarization remote sensing; Super-resolution","Article","Final","","Scopus","2-s2.0-85144533234"
"Dong R.; Mou L.; Zhang L.; Fu H.; Zhu X.X.","Dong, Runmin (57205415789); Mou, Lichao (55953611600); Zhang, Lixian (57207392945); Fu, Haohuan (8713118400); Zhu, Xiao Xiang (55696622200)","57205415789; 55953611600; 57207392945; 8713118400; 55696622200","Real-world remote sensing image super-resolution via a practical degradation model and a kernel-aware network","2022","ISPRS Journal of Photogrammetry and Remote Sensing","191","","","155","170","15","10.1016/j.isprsjprs.2022.07.010","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134751750&doi=10.1016%2fj.isprsjprs.2022.07.010&partnerID=40&md5=f825fc3da2135ef635468c7e029ba41d","Super-resolution is an essential task in remote sensing. It can enhance low-resolution remote sensing images and benefit downstream tasks such as building extraction and small object detection. However, existing remote sensing image super-resolution methods may fail in many real-world scenarios because they are trained on ﻿synthetic data generated by a single degradation model or on﻿ ﻿a limited amount of real data collected from specific satellites. ﻿To achieve super-resolution of real-world remote sensing images with different qualities in a unified framework, we propose a practical degradation model and a kernel-aware network (KANet). The proposed degradation model ﻿includes ﻿blur kernels estimated from real images and blur kernels generated from pre-defined distributions, which improves the diversity of training data and covers more real-world scenarios. ﻿The proposed KANet consists of a kernel prediction subnetwork and a kernel-aware super-resolution subnetwork. The ﻿former estimates the blur kernel of each ﻿image, making it possible to cope with real images of different qualities in an adaptive way. The latter iteratively solves ﻿two subproblems, degradation and high-frequency recovery, based on unfolding optimization. Furthermore, we propose a kernel-aware layer to adaptively ﻿integrate the predicted blur kernel into super-resolution process. The proposed KANet achieves state-of-the-art performance for real-world image super-resolution and outperforms the competing methods by 0.2–0.8 dB in the peak signal-to-noise ratio (PSNR). Extensive experiments on both synthetic and real-world images demonstrate that our approach ﻿is of high practicability and ﻿can be readily applied to high-resolution remote sensing applications. © 2022 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Blind equalization; Deep learning; Image enhancement; Image reconstruction; Iterative methods; Object detection; Optical resolving power; Signal to noise ratio; Blind Super-resolution; Blur kernel estimations; Deblur; Deep learning; Degradation model; Image degradation; Image reconstruct; Image super resolutions; Remote sensing images; Superresolution; degradation; remote sensing; resolution; signal-to-noise ratio; Remote sensing","Blind super-resolution; Blur-kernel estimation; Deblur; Deep learning; Image degradation; Image reconstruct","Article","Final","","Scopus","2-s2.0-85134751750"
"Liu H.; Liu M.; Zhang T.; Deng W.; Liu X.; Liu J.","Liu, Hanyu (57972337300); Liu, Meng (57198348336); Zhang, Tianxu (7404373651); Deng, Wenbing (57971111200); Liu, Xiaotai (57971920600); Liu, Jianwei (57971309300)","57972337300; 57198348336; 7404373651; 57971111200; 57971920600; 57971309300","Study Of Super-resolution Methods Based On Fitted Dual Quadratic Polynomials","2022","2022 International Conference on Artificial Intelligence and Computer Information Technology, AICIT 2022","","","","","","","10.1109/AICIT55386.2022.9930297","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142290461&doi=10.1109%2fAICIT55386.2022.9930297&partnerID=40&md5=c2e7dff690c556dea47520353908bb75","As an important index to measure infrared images, spatial resolution plays a key role in infrared remote sensing imaging, navigation guidance of aircraft and recognition of military targets. However, the pixel density of infrared imaging detectors is much lower than that of visible light detectors, resulting in low resolution of infrared images obtained. Infrared images also have shortcomings such as high noise, fuzzy interference and loss of high-frequency information, which affect the detection and recognition of targets. In this thesis, an infrared image super-resolution degradation model is established based on the degradation factors that occur in the infrared imaging process. The influence of noise and blur on improving the resolution of infrared images is analyzed, and in this way, a full-flow reconstruction model of infrared image super-resolution is established. On the basis of noise and blur removal,a super-resolution method based on fitted dual quadratic polynomials is proposed for the low resolution of infrared images. This method makes full use of the pixel information of the original image, and uses the fitted interpolation polynomial to expand the pixels of the low-resolution image to obtain a high-resolution image. On the basis of improving the resolution, the infrared image noise and blur are better suppressed, the detailed features are reflected and the subjective quality is improved.  © 2022 IEEE.","Air navigation; Image enhancement; Military photography; Optical resolving power; Pixels; Remote sensing; Thermography (imaging); Biquadratic polynomial; Degenerate model; Image spatial resolution; Image super resolutions; Infrared image; Infrared remote sensing; Lower resolution; Quadratic polynomial; Superresolution; Superresolution methods; Polynomials","biquadratic polynomial; degenerate model; infrared images; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85142290461"
"Wang Y.; Bashir S.M.A.; Khan M.; Ullah Q.; Wang R.; Song Y.; Guo Z.; Niu Y.","Wang, Yi (12763268500); Bashir, Syed Muhammad Arsalan (56385198200); Khan, Mahrukh (57197808732); Ullah, Qudrat (57212812840); Wang, Rui (57226734727); Song, Yilin (57339519000); Guo, Zhe (36026786800); Niu, Yilong (18234173100)","12763268500; 56385198200; 57197808732; 57212812840; 57226734727; 57339519000; 36026786800; 18234173100","Remote sensing image super-resolution and object detection: Benchmark and state of the art","2022","Expert Systems with Applications","197","","116793","","","","10.1016/j.eswa.2022.116793","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125859223&doi=10.1016%2fj.eswa.2022.116793&partnerID=40&md5=151a05325bb6827420a29e481c57df4f","For the past two decades, there have been significant efforts to develop methods for object detection in Remote Sensing (RS) images. In most cases, the datasets for small object detection in remote sensing images are inadequate. Many researchers used scene classification datasets for object detection, which has its limitations; for example, the large-sized objects outnumber the small objects in object categories. Thus, they lack diversity; this further affects the detection performance of small object detectors in RS images. This paper reviews current datasets and object detection methods (deep learning-based) for remote sensing images. We also propose a large-scale, publicly available benchmark Remote Sensing Super-resolution Object Detection (RSSOD) dataset. The RSSOD dataset consists of 1,759 hand-annotated images with 22,091 instances of very high-resolution (VHR) images with a spatial resolution of ∼ 0.05 m. There are five classes with varying frequencies of labels per class; the images are annotated in You Only Look Once (YOLO) and Common Objects in Context (COCO) format. The image patches are extracted from satellite images, including real image distortions such as tangential scale distortion and skew distortion. The proposed RSSOD dataset will help researchers benchmark the state-of-the-art object detection methods across various classes, especially for small objects using image super-resolution. We also propose a novel Multi-class Cyclic super-resolution Generative adversarial network with Residual feature aggregation (MCGR) and auxiliary YOLOv5 detector to benchmark image super-resolution-based object detection and compare with the existing state-of-the-art methods based on image super-resolution (SR). The proposed MCGR achieved state-of-the-art performance for image SR with an improvement of 1.2 dB in peak signal-to-noise ratio (PSNR) compared to the current state-of-the-art non-local sparse network (NLSN). MCGR achieved best object detection mean average precisions (mAPs) of 0.758, 0.881, 0.841, and 0.983, respectively, for five-class, four-class, two-class, and single classes, respectively surpassing the performance of the state-of-the-art object detectors YOLOv5, EfficientDet, Faster RCNN, SSD, and RetinaNet. © 2022 Elsevier Ltd","Benchmarking; Classification (of information); Deep learning; Generative adversarial networks; Image enhancement; Image resolution; Image segmentation; Large dataset; Object recognition; Remote sensing; Signal to noise ratio; Deep learning object detection; Image super resolutions; MCGR; Multiclass GAN; Object detection in remote sensing; Remote sensing benchmark; Remote sensing images; Remote-sensing; Small object detection; Object detection","Deep learning object detection; MCGR; multiclass GAN; Object detection in remote sensing; Remote sensing benchmark; Small object detection","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85125859223"
"Razzak M.T.; Mateo-García G.; Lecuyer G.; Gómez-Chova L.; Gal Y.; Kalaitzis F.","Razzak, Muhammed T. (57226329712); Mateo-García, Gonzalo (57192947904); Lecuyer, Gurvan (57214899061); Gómez-Chova, Luis (6603354695); Gal, Yarin (56462312200); Kalaitzis, Freddie (57221042086)","57226329712; 57192947904; 57214899061; 6603354695; 56462312200; 57221042086","Multi-spectral multi-image super-resolution of Sentinel-2 with radiometric consistency losses and its effect on building delineation","2023","ISPRS Journal of Photogrammetry and Remote Sensing","195","","","1","13","12","10.1016/j.isprsjprs.2022.10.019","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141808181&doi=10.1016%2fj.isprsjprs.2022.10.019&partnerID=40&md5=b9410798943473dfb4eb384dbe9fbbea","High resolution remote sensing imagery is used in a broad range of tasks, including detection and classification of objects. High-resolution imagery is however expensive to obtain, while lower resolution imagery is often freely available and can be used for a range of social good applications. To that end, we curate a multi-spectral multi-image dataset for super-resolution of satellite images. We use PlanetScope imagery from the SpaceNet-7 challenge as the high resolution reference and multiple Sentinel-2 revisits of the same location as the low-resolution imagery. We present the first results of applying multi-image super-resolution (MISR) to multi-spectral remote sensing imagery. We, additionally, introduce a radiometric-consistency module into the MISR model to preserve the high radiometric resolution and quality of the Sentinel-2 sensor. We show that MISR is superior to single-image super-resolution (SISR) and other baselines on a range of image fidelity metrics. Furthermore, we present the first assessment of the utility of multi-image super-resolution on a semantic and instance segmentation – common remote sensing tasks – showing that utilizing multiple images results in better performance in these downstream tasks, but MISR pre-processing is non-essential. © 2022 The Author(s)","Image segmentation; Object detection; Optical resolving power; Radiometry; Semantics; Building detection; Image super resolutions; Low-resolution imagery; Multi-image super-resolution; Multi-images; Multi-spectral; Radiometrics; Segmentation; Sentinel 2; Superresolution; detection method; image resolution; MISR; remote sensing; satellite data; satellite imagery; segmentation; Sentinel; Remote sensing","Building detection; Multi-image super-resolution; Segmentation; Sentinel 2; Super-resolution","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85141808181"
"Zhang J.; Xu T.; Li J.; Jiang S.; Zhang Y.","Zhang, Jizhou (57191089564); Xu, Tingfa (7401627083); Li, Jianan (57193959735); Jiang, Shenwang (57191544699); Zhang, Yuhan (57203889411)","57191089564; 7401627083; 57193959735; 57191544699; 57203889411","Single-Image Super Resolution of Remote Sensing Images with Real-World Degradation Modeling","2022","Remote Sensing","14","12","2895","","","","10.3390/rs14122895","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132836917&doi=10.3390%2frs14122895&partnerID=40&md5=dddcb3429f998eac0c247bba2343801c","Limited resolution is one of the most important factors hindering the application of remote sensing images (RSIs). Single-image super resolution (SISR) is a technique to improve the spatial resolution of digital images and has attracted the attention of many researchers. In recent years, with the advancement of deep learning (DL) frameworks, many DL-based SISR models have been proposed and achieved state-of-the-art performance; however, most SISR models for RSIs use the bicubic downsampler to construct low-resolution (LR) and high-resolution (HR) training pairs. Considering that the quality of the actual RSIs depends on a variety of factors, such as illumination, atmosphere, imaging sensor responses, and signal processing, training on “ideal” datasets results in a dramatic drop in model performance on real RSIs. To address this issue, we propose to build a more realistic training dataset by modeling the degradation with blur kernels and imaging noises. We also design a novel residual balanced attention network (RBAN) as a generator to estimate super-resolution results from the LR inputs. To encourage RBAN to generate more realistic textures, we apply a UNet-shape discriminator for adversarial training. Both referenced evaluations on synthetic data and non-referenced evaluations on actual images were carried out. Experimental results validate the effectiveness of the proposed framework, and our model exhibits state-of-the-art performance in quantitative evaluation and visual quality. We believe that the proposed framework can facilitate super-resolution techniques from research to practical applications in RSIs processing. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Image enhancement; Optical resolving power; Quality control; Remote sensing; Textures; Balanced attention; Deep learning; Image super resolutions; Real-world; Real-world degradation; Remote sensing image; Remote sensing images; Single images; Super resolution; Superresolution; Deep learning","balanced attention; deep learning (DL); real-world degradation; remote sensing images (RSIs); super resolution (SR)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85132836917"
"Sarkar D.; Gunturi S.K.","Sarkar, Dipu (57206206698); Gunturi, Sravan Kumar (57219345730)","57206206698; 57219345730","Online health status monitoring of high voltage insulators using deep learning model","2022","Visual Computer","38","12","","4457","4468","11","10.1007/s00371-021-02308-x","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115622790&doi=10.1007%2fs00371-021-02308-x&partnerID=40&md5=79528c0f75aaa70efc09efcaee23e6db","The inspection of electrical components has long been an important issue in the power distribution system. Unmanned drones are impressive surveillance systems with a powerful spatial and remote sensing capability. This paper proposes a system to monitor the health of the ceramic insulators that uses aerial images as a source of information and deep structured learning model for the data interpretation. The key drawbacks of existing monitoring systems are poor detection accuracy and lack of real-time execution, making it more complicated to obtain attributes from aerial photographs. The focus of this paper is to increase accuracy of detection while operating in real-time using You Only Look Once version 3 (YOLOv3). The novelty of the proposed system is that it combines deep learning and the Internet of Things using a single embedded device called Raspberry Pi. For the scientific investigation, we equipped Raspberry Pi with a test image as an input to detect an insulator’s health status using YOLOv3. Many aerial images are not clear due to motion blur. Excluding such low-resolution training images will affect accuracy. So we used a super-resolution CNN to reconstruct a blurred image as high-resolution image. The efficiency of the proposed system has been tested using a private data set consisting of a variety of scenes containing high-voltage power line insulators. The results show that the suggested system is quick and accurate in the identification and classification of insulators. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Antennas; E-learning; Health; Learning systems; Monitoring; Real time systems; Remote sensing; Aerial images; Electrical components; Health monitoring; Health status; High voltage insulators; Learning models; Power-distribution system; SRCNN; Status monitoring; You only look once version 3; Deep learning","Health monitoring; SRCNN; YOLOv3","Article","Final","","Scopus","2-s2.0-85115622790"
"Salgueiro L.; Marcello J.; Vilaplana V.","Salgueiro, Luis (57344768400); Marcello, Javier (6602158797); Vilaplana, Verónica (23394280500)","57344768400; 6602158797; 23394280500","SEG-ESRGAN: A Multi-Task Network for Super-Resolution and Semantic Segmentation of Remote Sensing Images","2022","Remote Sensing","14","22","5862","","","","10.3390/rs14225862","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142757845&doi=10.3390%2frs14225862&partnerID=40&md5=f90f1dd556609820e4fea22fe78d391f","The production of highly accurate land cover maps is one of the primary challenges in remote sensing, which depends on the spatial resolution of the input images. Sometimes, high-resolution imagery is not available or is too expensive to cover large areas or to perform multitemporal analysis. In this context, we propose a multi-task network to take advantage of the freely available Sentinel-2 imagery to produce a super-resolution image, with a scaling factor of 5, and the corresponding high-resolution land cover map. Our proposal, named SEG-ESRGAN, consists of two branches: the super-resolution branch, that produces Sentinel-2 multispectral images at 2 m resolution, and an encoder–decoder architecture for the semantic segmentation branch, that generates the enhanced land cover map. From the super-resolution branch, several skip connections are retrieved and concatenated with features from the different stages of the encoder part of the segmentation branch, promoting the flow of meaningful information to boost the accuracy in the segmentation task. Our model is trained with a multi-loss approach using a novel dataset to train and test the super-resolution stage, which is developed from Sentinel-2 and WorldView-2 image pairs. In addition, we generated a dataset with ground-truth labels for the segmentation task. To assess the super-resolution improvement, the PSNR, SSIM, ERGAS, and SAM metrics were considered, while to measure the classification performance, we used the IoU, confusion matrix and the F1-score. Experimental results demonstrate that the SEG-ESRGAN model outperforms different full segmentation and dual network models (U-Net, DeepLabV3+, HRNet and Dual_DeepLab), allowing the generation of high-resolution land cover maps in challenging scenarios using Sentinel-2 10 m bands. © 2022 by the authors.","Image enhancement; Optical resolving power; Remote sensing; Semantic Web; Semantics; Signal encoding; Statistical tests; High resolution; Land cover maps; Multi tasks; Multi-task network; Remote sensing images; Semantic segmentation; Sentinel-2; Superresolution; Task networks; Worldview-2; Semantic Segmentation","multi-task network; semantic segmentation; Sentinel-2; super-resolution; WorldView-2","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85142757845"
"Zhang Z.; Su Z.; Song W.; Ning K.","Zhang, Zhihao (57219589123); Su, Zhitong (57971797000); Song, Wei (57263716500); Ning, Keqing (36926065800)","57219589123; 57971797000; 57263716500; 36926065800","Global Attention Super-Resolution Algorithm for Nature Image Edge Enhancement","2022","Sustainability (Switzerland)","14","21","13865","","","","10.3390/su142113865","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148088359&doi=10.3390%2fsu142113865&partnerID=40&md5=1e76deb3a282dc34aabe280cfa96ceab","Single-image super-resolution (SR) has long been a research hotspot in computer vision, playing a crucial role in practical applications such as medical imaging, public security and remote sensing imagery. However, all currently available methods focus on reconstructing texture details, resulting in blurred edges and incomplete structures in the reconstructed images. To address this problem, an edge-enhancement-based global attention image super-resolution network (EGAN) combining channel- and self-attention mechanisms is proposed for modeling the hierarchical features and intra-layer features in multiple dimensions. Specifically, the channel contrast-aware attention (CCA) module learns the correlations between the intra-layer feature channels and enhances the contrast in the feature maps for richer features in the edge structures. The cyclic shift window multi-head self-attention (CS-MSA) module captures the long-range dependencies between layered features and captures more valuable features in the global information network. Experiments are conducted on five benchmark datasets for × 2, × 3 and × 4 SR. The experimental results show that for × 4 SR, our network improves the average PSNR by 0.12 dB, 0.19 dB and 0.12 dB over RCAN, HAN and NLSN, respectively, and can reconstruct a clear and complete edge structure. © 2022 by the authors.","","channel contrast-aware attention; cyclic shift window multi-head self-attention; deep learning; global attention; single-image super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85148088359"
"Wang Y.; Wu H.; Shuai L.; Peng C.; Yang Z.","Wang, YunYan (55734131800); Wu, Huaxuan (57225129464); Shuai, Luo (57609957300); Peng, Chen (57608894800); Yang, Zhiwei (57609957400)","55734131800; 57225129464; 57609957300; 57608894800; 57609957400","Detection of plane in remote sensing images using super-resolution","2022","PLoS ONE","17","4 April","e0265503","","","","10.1371/journal.pone.0265503","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128595759&doi=10.1371%2fjournal.pone.0265503&partnerID=40&md5=af62465dc52e9aeaa1dc03ad4f316346","The object detection of remote sensing image often has low accuracy and high missed or false detection rate due to the large number of small objects, instance level noise and cloud occlusion. In this paper, a new object detection model based on SRGAN and YOLOV3 is proposed, which is called SR-YOLO. It solves the problems of SRGAN network sensitivity to hyper-parameters and modal collapse. Meanwhile, The FPN network in YOLOv3 is replaced by PANet, shortened the distance between the lowest and the highest layers, and the SR-YOLO model has strong robustness and high detection ability by using the enhanced path to enrich the characteristics of each layer. The experimental results on the UCAS-High Resolution Aerial Object Detection Dataset showed SR-YOLO has achieved excellent performance. Compared with YOLOv3, the average precision (AP) of SR-YOLO increased from 92.35% to 96.13%, the log-average miss rate (MR-2) decreased from 22% to 14%, and the Recall rate increased from 91.36% to 95.12%. © 2022 Wang et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","Neural Networks, Computer; Remote Sensing Technology; algorithm; Article; benchmarking; measurement accuracy; measurement precision; model; noise; optical resolution; remote sensing","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85128595759"
"Nguyen B.M.; Tian G.; Vo M.-T.; Michel A.; Corpetti T.; Granero-Belinchon C.","Nguyen, Binh Minh (57477646600); Tian, Ganglin (57477900600); Vo, Minh-Triet (57478278300); Michel, Aurélie (57197087071); Corpetti, Thomas (14018992700); Granero-Belinchon, Carlos (57191894740)","57477646600; 57477900600; 57478278300; 57197087071; 14018992700; 57191894740","Convolutional Neural Network Modelling for MODIS Land Surface Temperature Super-Resolution","2022","European Signal Processing Conference","2022-August","","","1806","1810","4","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141011890&partnerID=40&md5=148bfb8ed7604c0b560801bf3e35a76c","Nowadays, thermal infrared satellite remote sensors enable to extract very interesting information at large scale, in particular Land Surface Temperature (LST). However such data are limited in spatial and/or temporal resolutions which prevents from an analysis at fine scales. For example, MODIS satellite provides daily acquisitions with 1Km spatial resolutions which is not sufficient to deal with highly heterogeneous landscapes. Therefore, image super-resolution is a crucial task to better exploit MODIS LSTs. This issue is tackled in this paper. We introduce a deep learning-based algorithm, named Multi-residual U-Net, for super-resolution of MODIS LST single-images. Our proposed network is a modified version of U-Net architecture, which aims at super-resolving the input LST image from 1Km to 250m per pixel. The results show that our Multi-residual U-Net outperforms other state-of-the-art methods. © 2022 European Signal Processing Conference, EUSIPCO. All rights reserved.","Atmospheric temperature; Convolutional neural networks; Deep learning; Land surface temperature; Optical resolving power; Radiometers; Signal processing; Surface measurement; Surface properties; Convolutional neural network; Infrared satellites; Interesting information; Land surface temperature; MODIS; Neural network model; Remote sensors; Superresolution; Thermal-infrared; U-net; Remote sensing","CNN; LST; MODIS; Super-Resolution; U-Net","Conference paper","Final","","Scopus","2-s2.0-85141011890"
"Chen N.; Zhang B.","Chen, Nan (57208390275); Zhang, Biao (57875873700)","57208390275; 57875873700","Multi-Scale Semi-Coupled Convolutional Sparse Coding for the Super-Resolution Reconstruction of Remote Sensing Image; [多尺度半耦合卷积稀疏编码的遥感影像超分辨率重建]","2022","Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics","34","3","","382","391","9","10.3724/SP.J.1089.2022.18903","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127153224&doi=10.3724%2fSP.J.1089.2022.18903&partnerID=40&md5=1cd716522cadcfca528269dd58d2aa6f","The traditional convolutional sparse coding super-resolution method only introduces the linear projection relationship in the feature space conversion and fails to consider the local detail in the feature map learning, which causes the reconstruction results to be unsatisfactory in terms of edges and details. The convolutional sparse coding theory is introduced into the super-resolution reconstruction framework of remote sensing images and a multi-scale semi-coupled convolutional sparse coding super-resolution reconstruction method is proposed. Firstly, the input image is decomposed by multi-scale to extract smooth components and multi-scale texture components, and the final smoothing components are reconstructed by bicubic interpolation. Then, the texture components of each scale are reconstructed by semi-coupled convolution sparse coding. The nonlinear convolution operator is used as the projection function between the high-resolution feature map and the low-resolution feature map of texture component at each scale and the non-local self-similarity structure in the feature map learning for constrained optimization is introduced to better reconstruct the texture image at each scale. Finally, the reconstructed smooth component and the texture component at each scale are superimposed to obtain the final reconstructed image. Remote sensing images from 4 different sensors are used as experimental images and the state-of-the-art super-resolution reconstruction methods are compared. Experimental results show that the reconstructed images obtained by the proposed method are better than other methods in quantitative analysis index PSNR and FSIM and show clearer boundary and detailed information and have a certain anti-noise performance. © 2022, Beijing China Science Journal Publishing Co. Ltd. All right reserved.","Constrained optimization; Discrete cosine transforms; Image coding; Image reconstruction; Learning systems; Optical resolving power; Remote sensing; Space optics; Textures; Convolutional sparse coding; Feature map; Local selfsimilarity; Multi-scale strategy; Multi-scales; Non-local self-similarity; Nonlocal; Semi-coupling dictionary; Sparse coding; Super-resolution reconstruction; Convolution","Convolutional sparse coding; Multi-scale strategy; Non-local self-similarity; Semi-coupling dictionary; Super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85127153224"
"Yu B.; Lei B.; Guo J.; Sun J.; Li S.; Xie G.","Yu, Bo (57693043500); Lei, Bin (14063767500); Guo, Jiayi (57194143247); Sun, Jiande (12645161300); Li, Shengtao (55267842900); Xie, Guangshuai (57983770400)","57693043500; 14063767500; 57194143247; 12645161300; 55267842900; 57983770400","Remote Sensing Image Super-Resolution via Residual-Dense Hybrid Attention Network","2022","Remote Sensing","14","22","5780","","","","10.3390/rs14225780","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142770800&doi=10.3390%2frs14225780&partnerID=40&md5=bf3d14380958dd91daaab2a471025d92","Nowadays, remote sensing datasets with long temporal coverage generally have a limited spatial resolution, most of the existing research uses the single image super-resolution (SISR) method to reconstruct high-resolution (HR) images. However, due to the lack of information in low-resolution (LR) images and the ill-posed nature of SISR, it is difficult to reconstruct the fine texture of HR images under large-scale magnification factors (e.g., four times). To address this problem, we propose a new reference-based super-resolution method called a Residual-Dense Hybrid Attention Network (R-DHAN), which uses the rich texture information in the reference image to make up for the deficiency of the original LR image. The proposed SR model employs Super-Resolution by Neural Texture Transfer (SRNTT) as a backbone. Based on this structure, we propose a dense hybrid attention block (DHAB) as a building block of R-DHAN. The DHAB fuses the input and its internal features of current block. While making full use of the feature information, it uses the interdependence between different channels and different spatial dimensions to model and obtains a strong representation ability. In addition, a hybrid channel-spatial attention mechanism is introduced to focus on important and useful regions to better reconstruct the final image. Experiments show that compared with SRNTT and some classical SR techniques, the proposed R-DHAN method performs well in quantitative evaluation and visual quality. © 2022 by the authors.","Image reconstruction; Image texture; Optical resolving power; Textures; Attention mechanisms; Dense connection mechanism; High-resolution images; Image super resolutions; Low resolution images; Remote-sensing; Single images; Superresolution; Superresolution methods; Texture transfer; Remote sensing","attention mechanism; dense connection mechanism; remote sensing; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85142770800"
"Ren Z.; Zhao J.; Chen C.; Lou Y.; Ma X.","Ren, Zhipeng (55485751400); Zhao, Jianping (57214842243); Chen, Chunyi (8411428400); Lou, Yan (57890087500); Ma, Xiaocong (57218572829)","55485751400; 57214842243; 8411428400; 57890087500; 57218572829","Dual-Path Adversarial Generation Network for Super-Resolution Reconstruction of Remote Sensing Images","2023","Applied Sciences (Switzerland)","13","3","1245","","","","10.3390/app13031245","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147934086&doi=10.3390%2fapp13031245&partnerID=40&md5=058a0c3a16bf332a6f586aa1de98261c","Satellite remote sensing images contain adequate ground object information, making them distinguishable from natural images. Due to the constraint hardware capability of the satellite remote sensing imaging system, coupled with the surrounding complex electromagnetic noise, harsh natural environment, and other factors, the quality of the acquired image may not be ideal for follow-up research to make suitable judgment. In order to obtain clearer images, we propose a dual-path adversarial generation network model algorithm that particularly improves the accuracy of the satellite remote sensing image super-resolution. This network involves a dual-path convolution operation in a generator structure, a feature mapping attention mechanism that first extracts important feature information from a low-resolution image, and an enhanced deep convolutional network to extract the deep feature information of the image. The deep feature information and the important feature information are then fused in the reconstruction layer. Furthermore, we also improve the algorithm structure of the loss function and discriminator to achieve a relatively optimal balance between the output image and the discriminator, so as to restore the super-resolution image closer to human perception. Our algorithm was validated on the public UCAS-AOD datasets, and the obtained results showed significantly improved performance compared to other methods, thus exhibiting a real advantage in supporting various image-related field applications such as navigation monitoring. © 2023 by the authors.","","attention mechanism; navigation monitoring; remote sensing image; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85147934086"
"Kapilaratne R.G.C.J.; Kakuta S.; Kaneta S.","Kapilaratne, R.G.C.J. (57194537565); Kakuta, S. (56536327700); Kaneta, S. (57219049570)","57194537565; 56536327700; 57219049570","Enhanced super resolution for remote sensing imageries","2022","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","3","","53","60","7","10.5194/isprs-Annals-V-3-2022-53-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132043853&doi=10.5194%2fisprs-Annals-V-3-2022-53-2022&partnerID=40&md5=e739cd48d213e5e5de51b63d8bcee7db","Single image super resolution (SISR) technology has been attracted much attention from remote sensing community due to its proven potentials in remote sensing applications. Existing SISR techniques varying from conventional interpolation methods to different network architectures. Generative adversarial networks (GANs) are one of the latest network architectures proven a greater potential as a SISR method whereas least attention has been given by the remote sensing community. Several studies have already been carried out on this context. However, yet there is no generalized GAN based approach to super resolve remote sensing imageries. Therefore, this study investigated the potentials of enhanced super resolution generative adversarial (ESRGAN) model to super resolve very high to medium resolution images from high to coarse resolution images for remote sensing applications. Two models were trained and Worldview-3 (WV3) images used as for very high resolution images. Whereas, down sampled WV3 and Sentinel-2(S2) were used as low resolution counterparts. Model performances were qualitatively and quantitatively analysed using standard metrics such as PSNR, SSIM, UIQI, CC, SAM, SID. Evaluation results emphasised super resolved images were preserved the original quality of the satellite images to a greater extent while improving its ground resolution.  © Authors 2022.","Deep learning; Generative adversarial networks; Image enhancement; Network architecture; Optical resolving power; Deep learning; ESRGAN; Image super resolutions; Remote sensing applications; Remote sensing imagery; Remote-sensing; Sentinel-2.; Single images; Superresolution; Worldview-3; Remote sensing","Deep Learning; ESRGAN; Remote Sensing; Sentinel-2.; Super Resolution; WorldView-3","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85132043853"
"Gao K.; He H.; Lu D.; Xu L.; Ma L.; Li J.","Gao, Kyle (57344224500); He, Hongjie (57222872355); Lu, Dening (57208824244); Xu, Linlin (55921131900); Ma, Lingfei (57190372479); Li, Jonathan (57235845600)","57344224500; 57222872355; 57208824244; 55921131900; 57190372479; 57235845600","Optimizing and Evaluating Swin Transformer for Aircraft Classification: Analysis and Generalizability of the MTARSI Dataset","2022","IEEE Access","10","","","134427","134439","12","10.1109/ACCESS.2022.3231327","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146226496&doi=10.1109%2fACCESS.2022.3231327&partnerID=40&md5=e204469400b62bd9a1b4fe9701e611d5","Aircraft classification via remote sensing images has many commercial and military applications. The Swin-Transformer has shown great promise, recently dominating general-purpose image classification benchmarks such as ImageNet. In this paper, we test whether the performance of the Swin-Transformer on general-purpose image classification translates to domain-specific aircraft classification using the Multi-Type Aircraft from the Remote Sensing Images dataset. We also investigate the effect of training procedure vs. model selection on the validation score. Our carefully trained Swin-Transformer model achieved an impressive 99.4 % validation set accuracy without super-resolution, and 99.5 % with super-resolution. Moreover, the generalization of models trained on the MTARSI dataset to real-world and synthetic aircraft classification is evaluated with some out-of-distribution samples. Our results demonstrate that the lack of complexity and heterogeneity of the MTARSI dataset, and the labeling errors resulted in models which struggle to achieve high accuracy on the adopted test samples despite near perfect validation scores.  © 2013 IEEE.","Classification (of information); Deep learning; Image classification; Military applications; Military photography; Optical resolving power; Statistical tests; Aircraft classification; Deep learning; Images classification; MTARSI dataset; Out-of-distribution; Remote sensing images; Remote-sensing; Self-attention; Swin transformer; Vision transformer; Remote sensing","Aircraft classification; deep learning; MTARSI dataset; out-of-distribution; remote sensing; self-attention; Swin transformer; vision transformer","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85146226496"
"Yan J.; Chen Y.; Zhang Q.; Xu Z.; Zhang Y.; Xia C.; Fan J.","Yan, Junhua (55467725200); Chen, Yang (55430076800); Zhang, Qiqi (58084731500); Xu, Zhenyu (57209684872); Zhang, Yin (56781573800); Xia, Chongxiang (58084731600); Fan, Junjie (57226119025)","55467725200; 55430076800; 58084731500; 57209684872; 56781573800; 58084731600; 57226119025","Super-resolution Inversion and Reconstruction for Remote Sensing Images of Bands of Interest","2022","Journal of Imaging Science and Technology","66","6","060504-1","","","","10.2352/J.ImagingSci.Technol.2022.66.6.060504","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147139498&doi=10.2352%2fJ.ImagingSci.Technol.2022.66.6.060504&partnerID=40&md5=1716c04e2565eb2d30dabbca3a7e0da0","The super-resolution inversion and reconstruction algorithm of remote sensing image of band of interest is proposed in this paper. Based on the existing multi-resolution hyperspectral images, a spectral reflectance dictionary is constructed, according to which the objects in radiation calibrated and atmospheric corrected scene spectral reflectance images are sorted and classified using the end element extraction algorithm and the correlation distance method. Based on the classification results, a dictionary of scene feature spectral reflectance is constructed. Based on this, the sparse representation method and the secondary optimization algorithm based on image similarity are used to solve and optimize the feature distribution of the scene image. According to the feature distribution of the scene image, using the remote sensing link imaging model, super-resolution inversion reconstruction is performed to obtain a high-resolution remote sensing image of a band of interest. Experimental results show that the proposed algorithm can reconstruct low-resolution remote-sensing images of different bands into high-resolution remote-sensing images. Thus, the proposed algorithm can effectively boost image resolution, enrich image details and improve the target detection capability by the image. © Society for Imaging Science and Technology 2022.","Image enhancement; Image reconstruction; Reflection; Remote sensing; Feature distribution; High-resolution remote sensing images; HyperSpectral; Inversion algorithm; Reconstruction algorithms; Reflectance images; Remote sensing images; Scene image; Spectral reflectances; Superresolution; Image resolution","","Article","Final","","Scopus","2-s2.0-85147139498"
"Yu M.; Wang H.; Liu C.; Lin D.","Yu, Mengbei (57223211542); Wang, Hongjuan (57210918053); Liu, Chang (57240736300); Lin, Deping (55608464000)","57223211542; 57210918053; 57240736300; 55608464000","Super-resolution reconstruction of remote sensing images based on SRGAN","2022","Proceedings of SPIE - The International Society for Optical Engineering","12473","","124730U","","","","10.1117/12.2653847","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144046247&doi=10.1117%2f12.2653847&partnerID=40&md5=cd5db18d4b97c3d4861777f4b69804a5","In the field of remote sensing images, due to the limitations of hardware equipment, image transmission, natural environment and other reasons, the resolution of the obtained remote sensing images cannot reach the desired resolution. The emergence of image super-resolution reconstruction technology can improve the resolution of remote sensing images without increasing the high cost. Image super-resolution reconstruction refers to the fact that low-resolution images can obtain high-resolution images through certain algorithmic techniques. With the rapid development of deep learning ideas, researchers have applied it to the field of image super-resolution reconstruction and achieved good results. Image super-resolution reconstruction also shifts from traditional reconstruction methods to deep learning-based methods. The emergence of the idea of Generative Adversarial Networks has further advanced the field of image super-resolution reconstruction. By using the idea of Generative Adversarial Network (GAN), researchers can obtain more realistic high-resolution images. This paper mainly uses the SRGAN model, the image dataset DIV2K for super-resolution reconstruction, and uses a dense residual structure in the generator network to obtain more image information, so that the effect of image reconstruction is more realistic. Through the experimental verification on the SIRI-WHU remote sensing test data set, the two evaluation indicators of peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) are compared, and the effect is improved. Better generation results can also be observed through subjective human vision. © 2022 SPIE.","Deep learning; Generative adversarial networks; Image enhancement; Optical resolving power; Remote sensing; Signal to noise ratio; Statistical tests; Algorithmic techniques; High costs; High-resolution images; Image super-resolution reconstruction; Image-based; Low resolution images; Natural environments; Reconstruction method; Remote sensing images; Super-resolution reconstruction; Image reconstruction","Generative Adversarial Networks; Image Super-Resolution Reconstruction","Conference paper","Final","","Scopus","2-s2.0-85144046247"
"Zhang N.; Wang Y.; Feng S.","Zhang, Nenghuan (57343902900); Wang, Yongbin (13607280200); Feng, Shuang (35186075800)","57343902900; 13607280200; 35186075800","A Lightweight Remote Sensing Image Super-Resolution Method and Its Application in Smart Cities","2022","Electronics (Switzerland)","11","7","1050","","","","10.3390/electronics11071050","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127019018&doi=10.3390%2felectronics11071050&partnerID=40&md5=39c15e3f694c2fc5c0a41c6f50798019","With the growth of urban population, a series of urban problems have emerged, and how to speed up smart city construction has received extensive attention. Remote sensing images have the advantages of wide spatial coverage and rich information, and it is suitable for use as research data for smart cities. However, due to limitations in the imaging sensor conditions and complex weather, remote sensing images face the problems of insufficient resolution and cloud occlusion, which cannot meet the resolution requirements of smart city tasks. The remote sensing image super-resolution (SR) technique can improve the details and texture information without upgrading the imaging sensor system, which becomes a feasible solution for the above problems. In this paper, we propose a novel remote sensing image super-resolution method which leverages the texture features from internal and external references to help with SR reconstruction. We introduce the transformer attention mechanism to select and extract parts of texture features with high reference values to ensure that the network is lightweight, effective, and easier to deploy on edge computing devices. In addition, our network can automatically learn and adjust the alignment angles and scales of texture features for better SR results. Extensive comparison experiments show that our proposed method achieves superior performance compared with several state-of-the-art SR methods. In addition, we also evaluate the application value of our proposed SR method in urban region function recognition in smart cities. The dataset used in this task is low-quality. The comparative experiment between the original dataset and the SR dataset generated by our proposed SR method indicates that our method can effectively improve the recognition accuracy. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","","remote sensing image; smart cities; super-resolution technique; urban region function recognition","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85127019018"
"Xue Y.; Li L.; Wang Z.; Jiang C.; Liu M.; Wang J.; Sun K.; Ma H.","Xue, Yuan (57606502800); Li, Liangliang (57892001300); Wang, Zheyuan (57609170600); Jiang, Chenchen (57607036200); Liu, Minqin (58040201900); Wang, Jiawen (57449876800); Sun, Kaipeng (57406783200); Ma, Hongbing (57198975424)","57606502800; 57892001300; 57609170600; 57607036200; 58040201900; 57449876800; 57406783200; 57198975424","RFCNet: Remote Sensing Image Super-Resolution Using Residual Feature Calibration Network","2023","Tsinghua Science and Technology","28","3","","475","485","10","10.26599/TST.2022.9010018","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145439840&doi=10.26599%2fTST.2022.9010018&partnerID=40&md5=9c10efdc9f869298b254911d88959146","In the field of single remote sensing image Super-Resolution (SR), deep Convolutional Neural Networks (CNNs) have achieved top performance. To further enhance convolutional module performance in processing remote sensing images, we construct an efficient residual feature calibration block to generate expressive features. After harvesting residual features, we first divide them into two parts along the channel dimension. One part flows to the Self-Calibrated Convolution (SCC) to be further refined, and the other part is rescaled by the proposed Two-Path Channel Attention (TPCA) mechanism. SCC corrects local features according to their expressions under the deep receptive field, so that the features can be refined without increasing the number of calculations. The proposed TPCA uses the means and variances of feature maps to obtain accurate channel attention vectors. Moreover, a region-level nonlocal operation is introduced to capture long-distance spatial contextual information by exploring pixel dependencies at the region level. Extensive experiments demonstrate that the proposed residual feature calibration network is superior to other SR methods in terms of quantitative metrics and visual quality.  © 1996-2012 Tsinghua University Press.","Calibration; Deep neural networks; Image enhancement; Optical resolving power; Remote sensing; Attention mechanisms; Calibration network; Convolutional neural network; Image super resolutions; Performance; Remote sensing images; Super-resolution; Superresolution; Two paths; Convolution","attention mechanism; Convolutional Neural Network (CNN); remote sensing image; Super-Resolution (SR)","Article","Final","","Scopus","2-s2.0-85145439840"
"Tingting S.","Tingting, Song (57450105000)","57450105000","A Light Model for Super-Resolution of Remote Sensing Images","2022","Journal of Physics: Conference Series","2171","1","012029","","","","10.1088/1742-6596/2171/1/012029","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124509002&doi=10.1088%2f1742-6596%2f2171%2f1%2f012029&partnerID=40&md5=4b0fce87d20d40823a805755abacd54c","Remote sensing image super-resolution is an important research topic, which helps to improve the quality of remote sensing images. However, because remote sensing images are usually quite large while the satellite equipment often have low computing capacity and small memory, it is appealing to develop lightweight and fast models to perform the super-resolution task for the remote sensing images. In this paper, we empirically study the effectiveness of conventional super-resolution approaches for remote sensing images, and propose an effective way to reduce the model parameters and computational cost. Specifically, motivated by Res2Net, we design a new multi-scale hierarchy residual block to replace the ResBlock in EDSR to provide a more diverse receptive field for each residual block. The proposed modified method has fewer parameters and faster speed compared with the original EDSR. Moreover, we also build two benchmark super-resolution datasets (i.e., DOTA-SR and LEVIR-SR) from DOTA and LEVIR-CD, respectively, for experimental evaluation. We perform experiments on the two datasets, and results show that our method is light and have comparable performance over the existing super-resolution baselines. © 2022 Institute of Physics Publishing. All rights reserved.","Image enhancement; Remote sensing; Computational costs; Computing capacity; FAST model; Image super resolutions; Light models; Modeling parameters; Remote sensing images; Research topics; Satellite equipment; Superresolution; Optical resolving power","","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85124509002"
"Wang Z.; Li L.; Xing L.; Wang J.; Sun K.; Ma H.","Wang, Zheyuan (57609170600); Li, Liangliang (57892001300); Xing, Linxin (57918126100); Wang, Jiawen (57449876800); Sun, Kaipeng (57406783200); Ma, Hongbing (57198975424)","57609170600; 57892001300; 57918126100; 57449876800; 57406783200; 57198975424","Information Purification Network for Remote Sensing Image Super-Resolution","2023","Tsinghua Science and Technology","28","2","","310","321","11","10.26599/TST.2022.9010002","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139387168&doi=10.26599%2fTST.2022.9010002&partnerID=40&md5=9c13033ab0a71818cd87d6c69c634506","Recently, several well-performing deep convolutional neural networks were proposed for remote sensing image super-resolution (SR). However, these methods rarely consider that remote sensing images are corruptible by additional noise, blurring, and other factors. Therefore, to eliminate the interference of these factors, especially the noise, we propose a novel information purification network (IPN) for remote sensing image SR. The proposed information purification block (IPB) can process channel-wise features differently by channel separation and rescale spatial-wise features adaptively through the proposed multi-scale spatial attention mechanism. We further design an information group to explore a more powerful expressive combination of IPBs. Moreover, long and short skip connections can transmit abundant low-frequency information, making IPBs pay more attention to high-frequency information. We mix the images under various degradation models as training data in the training phase. In this way, the network can directly reconstruct various degraded images. Experiments on AID and UC Merced Land-Use datasets under multiple degradation models demonstrate that the proposed IPN performs better than state-of-the-art methods.  © 1996-2012 Tsinghua University Press.","Convolution; Deep neural networks; Image processing; Land use; Optical resolving power; Remote sensing; Channel separation; Convolutional neural network; Deep convolutional neural network; Degradation model; Image super resolutions; Information purification network; Novel information; Process channels; Remote sensing images; Superresolution; Purification","deep convolutional neural networks; information purification network; remote sensing image; super-resolution","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85139387168"
"Theron K.J.; Pryke J.S.; Latte N.; Samways M.J.","Theron, K. Jurie (57212026699); Pryke, James S. (16319927900); Latte, Nicolas (24923269000); Samways, Michael J. (7004518089)","57212026699; 16319927900; 24923269000; 7004518089","Mapping an alien invasive shrub within conservation corridors using super-resolution satellite imagery","2022","Journal of Environmental Management","321","","116023","","","","10.1016/j.jenvman.2022.116023","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136479793&doi=10.1016%2fj.jenvman.2022.116023&partnerID=40&md5=569969d343a4d23ca5efb0793dfdac61","Alien invasive plant species are one of the main drivers of global biodiversity loss. Methods for monitoring the spread of alien invasive plants are needed to improve management and mitigate impact on local biodiversity. Recent advances in deep learning and image fusion holds great potential for mapping and managing alien invasive plants. One such method is super-resolution image reconstruction, where a neural network learns to downscale images from coarse to fine resolution. Within the commercial timber production landscape of KwaZulu-Natal, endangered grassland corridors are threatened by American bramble invasion, impacting plants, birds, arthropods, and soil restoration. Here we aim to improve our understanding of bramble invasion dynamics through using super-resolved satellite mosaics. Bramble was classified with very high accuracies (85%) from the super-resolved satellite mosaic, compared to other conventional satellite imagery with different spectral and spatial resolutions. Using landscape analyses, we identified plantation tree harvesting and prescribed burning to be major drivers increasing bramble cover within the landscape. Bramble cover was highest one year following plantation tree harvesting. Continuous prescribed burning positively influenced bramble. Bramble cover was also high close to streams, and under future invasion projections, bramble will severely impact Ensifera species alongside low priority grasshopper species habitat. Results also indicate that bramble has a significant negative impact on intermediate priority grasshoppers and plant species richness. For controlling bramble invasion within commercial timber production landscapes, we recommend the adoption rotational harvesting, as harvesting entire plantation blocks throughout the landscape will dramatically increase invasion potential of bramble. Current bramble removal programmes should prioritize riparian areas. Special attention is needed to control bramble one year after timber harvesting, as this is when bramble cover is highest. We show the benefits of using super-resolved mosaics to gain new insights into alien invasive species dynamics, while further development of this technique will aid in managing invasive alien plant species at local scales. © 2022 Elsevier Ltd","Animals; Biodiversity; Birds; Conservation of Natural Resources; Ecosystem; Introduced Species; Plants; Satellite Imagery; South Africa; Trees; KwaZulu; KwaZulu-Natal; KwaZulu-Natal; Natal; South Africa; invasive species; adoption; arthropod; article; attention; bird; Caelifera; deep learning; Ensifera; grassland; human; human experiment; image reconstruction; invasive species; nonhuman; plantation; prescribed burning; remote sensing; Rubus; satellite imagery; shrub; soil; species habitat; species richness; animal; biodiversity; ecosystem; environmental protection; introduced species; plant; procedures; South Africa; tree","Conservation corridors; Deep learning; Invasion dynamics; Management; Plantation forestry; Remote sensing; Rubus cuneifolius","Article","Final","","Scopus","2-s2.0-85136479793"
"Chang P.-C.; Lin J.-T.; Lin C.-H.; Tang P.-W.; Liu Y.","Chang, Pai-Chuan (57559591600); Lin, Jhao-Ting (57224920496); Lin, Chia-Hsiang (55967027800); Tang, Po-Wei (57226838850); Liu, Yangrui (57226838991)","57559591600; 57224920496; 55967027800; 57226838850; 57226838991","A Fast Multidimensional Data Fusion Algorithm for Hyperspectral Spatiotemporal Super-Resolution","2022","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2022-September","","","","","","10.1109/WHISPERS56178.2022.9955073","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143121233&doi=10.1109%2fWHISPERS56178.2022.9955073&partnerID=40&md5=a27e107d2c665bc8ad3fb614fcea332f","In hyperspectral remote sensing, obtaining fine spatial-temporal and spatial-spectral resolution images are two critical fusion issues due to inherent optical sensor trade-offs. However, simultaneous realization of spatial, spectral, and temporal super-resolution is highly challenging. This paper formulates a new fusion framework incorporating all the three spatial/spectral/temporal dimensions to achieve hyperspectral spatiotemporal (HST) super-resolution. Additionally, unlike many fusion methods assuming availability of the spatial blurring matrix (SBM) in the forward model, we go a step further to blindly achieve HST super-resolution by automatically estimating the SBM. Subsequently, final results can be obtained through the fast iterative shrinkage-thresholding algorithm (FISTA) and the convex optimization-based coupled nonnegative matrix factorization (CO-CNMF) algorithm. We compare results of the proposed HST super-resolution method, termed GFCSR, with other extended spatiotemporal fusion frameworks designed for multispectral images, and, as it turns out, quantitative evaluations demonstrate the superiority of our algorithm.  © 2022 IEEE.","Economic and social effects; Image fusion; Iterative methods; Matrix algebra; Matrix factorization; Optical remote sensing; Optical resolving power; Spectroscopy; Convex optimisation; HyperSpectral; Hyperspectral image; matrix; Multidimensional data; Multispectral images; Nonnegative matrix factorization; Spatial temporals; Spatiotemporal super-resolution; Superresolution; Convex optimization","Convex optimization; hyperspectral image; image fusion; multispectral image; nonnegative matrix factorization; spatiotemporal super-resolution","Conference paper","Final","","Scopus","2-s2.0-85143121233"
"Prévost C.; Chainais P.; Boyer R.","Prévost, C. (57209888195); Chainais, P. (6505961382); Boyer, R. (8568997200)","57209888195; 6505961382; 8568997200","FAST FUSION OF HYPERSPECTRAL AND MULTISPECTRAL IMAGES: A TUCKER APPROXIMATION APPROACH","2022","Proceedings - International Conference on Image Processing, ICIP","","","","2076","2080","4","10.1109/ICIP46576.2022.9898065","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146708497&doi=10.1109%2fICIP46576.2022.9898065&partnerID=40&md5=4fae3111f641503c66c4e2765dfe98f9","Hyperspectral super-resolution based on coupled Tucker decomposition has been recently considered in the remote sensing community. The state-of-the-art approaches did not fully exploit the coupling of information contained in hyperspectral and multispectral images of the same scene. This paper proposes a new algorithm that overcomes this limitation. It accounts for both the high-resolution and the low-resolution information in the model by solving a set of least-squares problems. In addition, we provide exact recovery conditions for the super-resolution image in the noiseless case. Our simulations show that the proposed algorithm achieves very good reconstruction quality with a very low computational complexity. © 2022 IEEE.","Optical resolving power; Approximation approach; High resolution; HyperSpectral; Lower resolution; Multispectral images; Remote-sensing; State-of-the-art approach; Superresolution; Tucker approximations; Tucker decompositions; Remote sensing","","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85146708497"
"Sun Y.; Qin J.; Gao X.; Chai S.; Chen B.","Sun, Yubin (57233193500); Qin, Jiongming (57213003176); Gao, Xuliang (57224503880); Chai, Shuiqin (57205119018); Chen, Bin (55597856700)","57233193500; 57213003176; 57224503880; 57205119018; 55597856700","Attention-enhanced multi-scale residual network for single image super-resolution","2022","Signal, Image and Video Processing","16","5","","1417","1424","7","10.1007/s11760-021-02095-x","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123123572&doi=10.1007%2fs11760-021-02095-x&partnerID=40&md5=611f082efd061bf257ca30da2029d1a6","Single image super-resolution (SISR) has important applications in many fields. With the help of this technology, the broadband requirement of image transmission can be reduced, the effect of remote sensing observation can be improved, and the location of lesion cells can be accurately located. Convolutional neural networks (CNNs) using multi-scale feature extraction structure can gain a large amount of information from a low-resolution input, which is helpful to improve the performance of SISR. However, these CNNs usually treat different types of information equally. There is a lot of redundancy in the information obtained, which limits the representation ability of the networks. We proposed an attention-enhanced multi-scale residual block (AMRB), which increases the proportion of useful information by embedding convolutional block attention module. Furthermore, we construct an attention-enhanced multi-scale residual network based on one time feature fusion (OAMRN). Extensive experiments illustrate the necessity of the AMRB and the superiority of proposed OAMRN over the state-of-the-art methods in terms of both quantitative metrics and visual quality. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Convolution; Convolutional neural networks; Image enhancement; Remote sensing; CBAM; Convolutional neural network; Features extraction; Image super resolutions; Multi-scale features; Multi-scale residual network; Multi-scales; Remote-sensing; Single images; Superresolution; Optical resolving power","CBAM; Convolutional neural network; Multi-scale residual network; Super-resolution","Article","Final","","Scopus","2-s2.0-85123123572"
"Zhang W.; Li Z.; Chen S.; Wang Y.; Li H.","Zhang, Wenjuan (35235960300); Li, Zhen (57196398078); Chen, Shanjing (57871669100); Wang, Yuxi (57220191112); Li, Hongli (57937358300)","35235960300; 57196398078; 57871669100; 57220191112; 57937358300","A Scale-Adaptive Super-Resolution Algorithm for Single Remote Sensing Image","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","4110","4113","3","10.1109/IGARSS46834.2022.9883637","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140358618&doi=10.1109%2fIGARSS46834.2022.9883637&partnerID=40&md5=15f041786ab68d9d1cce544a63982692","Single image super-resolution (SISR) algorithm is to recover a high-resolution image from a single low-resolution one and has been widely applied in remote sensing (RS) reconstruction. Numerous SISR models have been proposed for RS ap-plications. However, most existing methods suffer from an inability to reconstruct multi-scale RS images using one fixed pre-trained model. Here, we design a scale-adaptive SISR algorithm for RS images. The main contributions are three-fold: (1) to be applied for the multi-scale reconstruction, we first employ the bicubic interpolation to stretch the images before import so that our convolutional neural network can focus on refining the details of reconstruction images; (2) to extract the deep information of ground surface from RS images, we design multi-scale residual network to recover the image details; (3) we adopt the least-absolute-error loss to constraint our network for reconstructing the RS images. It is demonstrated that our model achieves excellent performance for super-resolution of RS images. © 2022 IEEE.","Convolution; Convolutional neural networks; Image reconstruction; Optical resolving power; Convolutional neural network; High-resolution images; Image super resolutions; Lower resolution; Multi-scales; Remote sensing images; Remote-sensing; Single images; Super resolution algorithms; Superresolution; Remote sensing","convolutional neural network; Remote sensing images; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85140358618"
"Park S.; Kim Y.; Kim M.","Park, Seongwook (57226324750); Kim, Yeongho (58026673300); Kim, Minsik (57226324770)","57226324750; 58026673300; 57226324770","Impact Analysis of Deep Learning Super-resolution Technology for Improving the Accuracy of Ship Detection Based on Optical Satellite Imagery","2022","Korean Journal of Remote Sensing","38","5-1","","559","570","11","10.7780/kjrs.2022.38.5.1.10","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144517892&doi=10.7780%2fkjrs.2022.38.5.1.10&partnerID=40&md5=1f508b99d450582e9bbd2992162ed45f","When a satellite image has low spatial resolution, it is difficult to detect small objects. In this research, we aim to check the effect of super resolution on object detection. Super resolution is a software method that increases the resolution of an image. Unpaired super resolution network is used to improve Sentinel-2's spatial resolution from 10 m to 3.2 m. Faster-RCNN, RetinaNet, FCOS, and S2ANet were used to detect vessels in the Sentinel-2 images. We experimented the change in vessel detection performance when super resolution is applied. As a result, the Average Precision (AP) improved by at least 12.3% and up to 33.3% in the ship detection models trained with the super-resolution image. False positive and false negative cases also decreased. This implies that super resolution can be an important pre-processing step in object detection, and it is expected to greatly contribute to improving the accuracy of other image-based deep learning technologies along with object detection. © Korean Journal of Remote Sensing. All rights reserved.","","Deep learning; Remote sensing; Sentinel-2; Ship detection; Super-resolution","Article","Final","","Scopus","2-s2.0-85144517892"
"Zhang X.; Zhang A.; Portelli R.; Zhang X.; Guan H.","Zhang, Xintong (57885936200); Zhang, Aiwu (7402772582); Portelli, Raechel (57211902825); Zhang, Xizhen (57211274537); Guan, Hongliang (57201065463)","57885936200; 7402772582; 57211902825; 57211274537; 57201065463","ZY-1 02D Hyperspectral Imagery Super-Resolution via Endmember Matrix Constraint Unmixing","2022","Remote Sensing","14","16","4034","","","","10.3390/rs14164034","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137823032&doi=10.3390%2frs14164034&partnerID=40&md5=2f3755dd498f4c1b8003c297b5bd80d9","This paper proposes an endmember matrix constraint unmixing method for ZY-1 02D hyperspectral imagery (HSI) super-resolution reconstruction (SRR) to overcome the low resolution of ZY-1 02D HSI. The proposed method combines spectral unmixing and adds novel smoothing constraints to traditional non-negative matrix factorization to improve details and preserve the spectral information of traditional SRR methods. The full utilization of the endmember spectral matrix and endmember abundance matrix of HSI and multispectral imagery (MSI) reconstructs the high spatial resolution and high spectral fidelity HSI. Furthermore, given the ZY-1 02D HSI infrared bands are seriously corrupted by noise, the influence of denoising on the SRR accuracy is also discussed. Experiments show that the proposed method restores spatial details and spectral information and is robust for noise, preserving more spectral information. Therefore, the proposed method is a ZY-1 02D HSI SRR method with high spatial resolution and high spectral fidelity, which improves the spatial resolution while simultaneously solving spectral mixing and provides the possibility for the data further expansion. © 2022 by the authors.","Image reconstruction; Image resolution; Matrix algebra; Remote sensing; Satellite imagery; Spectroscopy; Endmembers; Hyper-spectral imageries; matrix; Nonnegative matrix factorization; Reconstruction method; Spectral information; Spectral unmixing; Super-resolution reconstruction; Unmixing; ZY-1 02d satellite; Non-negative matrix factorization","non-negative matrix factorization; spectral unmixing; super-resolution reconstruction; ZY-1 02D satellite","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85137823032"
"Soni S.R.; Pandey K.; Sharma V.","Soni, Shankar Raj (58066942000); Pandey, Kiran (58066942100); Sharma, Vivek (57224584576)","58066942000; 58066942100; 57224584576","MSISR : Modified Single Image Super-Resolution Using Relu Based 2D CNN for Satellite Images","2022","2022 13th International Conference on Computing Communication and Networking Technologies, ICCCNT 2022","","","","","","","10.1109/ICCCNT54827.2022.9984280","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146356783&doi=10.1109%2fICCCNT54827.2022.9984280&partnerID=40&md5=f6c876c1e1e7e01c6e346dbe1cab67cd","In this research, we presented a Modified Single Image Super-Resolution (MSISR) using enhanced very deep super resolution (VDSR). The suggested technique is based on convolutional neural networks and uses up-sampling and residual inputs for training (an essential part of SISR) with a level of 20. The proposed method hybrid fusion of the enhanced bi-cubic method. The proposed MSISR shows better result in terms of peak signal to noise ratio as well as structural similarity index measurement. The proposed method also show good visual outcomes as compare to other previous techniques in terms of butter and resolution. These two factors play a significant role in the outcome analysis of image super resolution (ISR). For the analysis of proposed method use standard data sets like the UC Mecred Field. Data Set are available for the training and testing of the proposed approach. For the simulation of proposed method used well know tool that is matrix laboratory version R2020B.  © 2022 IEEE.","Convolutional neural networks; Image analysis; Image enhancement; Optical resolving power; Radar imaging; Remote sensing; Signal sampling; Signal to noise ratio; Statistical tests; Synthetic aperture radar; CNN and hybrid fusion; Hybrid fusions; Image super resolutions; Relu; Remote sensing images; Residual; Satellite images; Single images; Synthetic aperture radar; Upsampling; Deep neural networks","CNN and hybrid fusion; Deep neural network; Relu; Remote Sensing Image; Residual; Satellite Image; synthetic aperture radar (SAR); up sampling","Conference paper","Final","","Scopus","2-s2.0-85146356783"
"Liu L.; Jiang Q.; Jin X.; Feng J.; Wang R.; Liao H.; Lee S.-J.; Yao S.","Liu, Ling (57469001800); Jiang, Qian (57194699462); Jin, Xin (56991832300); Feng, Jianan (57221777999); Wang, Ruxin (56227544500); Liao, Hangying (57780795800); Lee, Shin-Jye (34877262700); Yao, Shaowen (24473851600)","57469001800; 57194699462; 56991832300; 57221777999; 56227544500; 57780795800; 34877262700; 24473851600","CASR-Net: A color-aware super-resolution network for panchromatic image","2022","Engineering Applications of Artificial Intelligence","114","","105084","","","","10.1016/j.engappai.2022.105084","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133409811&doi=10.1016%2fj.engappai.2022.105084&partnerID=40&md5=eefb21da6ad7b93ebc5d539824525eef","Spatial resolution is the ability to distinguish the spatial details of remote sensing images, and high spatial resolution images are conducive to object recognition and visual interpretation. Spectral resolution is the ability to distinguish the spectral details of the ground objects in remote sensing images, and high spectral resolution images are of great significance to the classification and recognition of objects in remote sensing images. The image super-resolution model is used to enhance the spatial resolution of remote sensing image, but it cannot enhance the spectral resolution, while the image colorization model can increase the number of channels by predicting chromatic channels for the input image, thereby improving spectral resolution. In this paper, a color-aware super-resolution network that combines image colorization and super-resolution ideas is designed to improve the spectral and spatial resolution of panchromatic images. The color-aware super-resolution network mainly contains color-aware block and spatial-aware block, color-aware block is presented to predict color information for panchromatic images to improve the spectral resolution, meanwhile, spatial-aware block is used to restore the texture details for panchromatic images to improve the spatial resolution. The trained color-aware super-resolution network only needs to input panchromatic images to generate images with more spectral information and higher spatial resolution than input images. Extensive experiments demonstrate that our color-aware super-resolution network has a good performance in image colorization and super-resolution, and experimental results show that compare with some existing excellent image colorization methods and super-resolution methods, our method is excellent in objective indicators and visual effects. © 2022 Elsevier Ltd","Deep neural networks; Image enhancement; Image resolution; Object recognition; Remote sensing; Spectral resolution; Textures; High spatial resolution images; Image colorizations; Image spatial resolution; Image super resolutions; Input image; Objects recognition; Remote sensing images; Spatial resolution; Superresolution; Visual interpretation; Color","Deep neural network; Image colorization; Image super-resolution; Remote sensing image","Article","Final","","Scopus","2-s2.0-85133409811"
"Lu T.; Zhao K.; Wu Y.; Wang Z.; Zhang Y.","Lu, Tao (56406646300); Zhao, Kanghui (57220898298); Wu, Yuntao (55993578900); Wang, Zhongyuan (34973569100); Zhang, Yanduo (55993581700)","56406646300; 57220898298; 55993578900; 34973569100; 55993581700","Structure-Texture Parallel Embedding for Remote Sensing Image Super-Resolution","2022","IEEE Geoscience and Remote Sensing Letters","19","","6516105","","","","10.1109/LGRS.2022.3206348","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139380653&doi=10.1109%2fLGRS.2022.3206348&partnerID=40&md5=3bdfd90776645e24ea1815eb0d85b7c3","The structure and texture of images are crucial for remote sensing image super-resolution (SR). Generative adversarial networks (GANs) recover image details through adversarial training. However, the recovered images always have structural distortions, on the one hand, and GANs are difficult to train, on the other hand. In addition, some methods assist reconstruction by introducing prior information of the image, but this brings additional computational cost. To address this issue, we propose a novel structure-texture parallel embedding (SPE) method for SR of remote sensing images. Our method does not require additional image priors to reconstruct high-quality images. Specifically, we use the global structure information and local texture information of the image in the ascending space to guide the reconstruction result of the image. First, we design a structure preserving block (SPB) to extract global structural features in the ascending space of the image, so as to obtain global structure information for a priori representation. Then, we design a local texture attention module (LTAM) to restore richer texture details. We have conducted lots of experiments on Draper public dataset. Experimental results show that our proposed method not only achieves a better tradeoff between computational cost and performance, but also outperforms the existing several SR methods in terms of objective index evaluation and subjective visual effects.  © 2004-2012 IEEE.","Economic and social effects; Embeddings; Generative adversarial networks; Image texture; Optical resolving power; Remote sensing; Space optics; Textures; Attention mechanisms; Features extraction; Image super resolutions; Images reconstruction; Remote sensing image super-resolution; Remote sensing images; Remote-sensing; Structure-preserving; Superresolution; Texture attention mechanism; data set; image resolution; performance assessment; remote sensing; Image reconstruction","Remote sensing image super-resolution (SR); structure preserving; texture attention mechanism","Article","Final","","Scopus","2-s2.0-85139380653"
"Wang H.; Wu Y.; Ni Q.; Liu W.","Wang, Hancong (57807054000); Wu, Yin (56093628700); Ni, Qiang (57614625100); Liu, Wenbo (55723547200)","57807054000; 56093628700; 57614625100; 55723547200","A Novel Wireless Leaf Area Index Sensor Based on a Combined U-Net Deep Learning Model","2022","IEEE Sensors Journal","22","16","","16573","16585","12","10.1109/JSEN.2022.3188697","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134328841&doi=10.1109%2fJSEN.2022.3188697&partnerID=40&md5=8ad0e55d3bf3341ff686cb5f1b34da75","Leaf area index (LAI) is an important parameter for forestry vegetation canopy structure investigation and ecological environment model study. Traditional ground direct measuring method is too time and labor consuming, while the remote sensing technique lacks of adequate validation and comparative analysis. Here, a novel wireless LAI sensor based on a lightweight deep learning model (LAINET) has been designed with a Raspberry Pi microcomputer and a LoRa transceiver. The mainly metering pattern of sensor system is the digital hemispherical photo-graphy (DHP) methodology based on Beer-Lambert law: firstly, the crown canopy's image is captured and segmented by LAINET, then the vegetation gap fraction can be extracted to calculate the LAI value. Our proposed LAINET consists of a lightweight convolutional neural network (CNN) and a generative adversarial network (GAN). The average accuracy of semantic segmentation (i.e. CNN part) could reach 0.978, and the combination of GAN for image super-resolution reconstruction can improve the accuracy of gap fraction measurement more by 5.5%. In addition, LAINET effectively solves the problem of low segmentation accuracy brought by environmental effects, the separation accuracy in direct sunlight or clear weather has been improved significantly. So the ultimate LAI value can be calculated precisely and stably. Experiment results show that the proposed sensor obtains a fine measuring error of less than 4% when comparing with the commercial plant canopy analyzer HM-G20. Combined with Uninterruptible Power Supply module of 5200 mAh, the sensor can work effectively for about 8 months, principally meeting the deployment and measurement criteria of forestry LAI. Therefore, the wireless sensor presented in this paper has a great application prospect.  © 2001-2012 IEEE.","Deep learning; Forestry; Generative adversarial networks; Image enhancement; Neural networks; Radio transceivers; Remote sensing; Semantic Segmentation; Semantics; Timber; Vegetation mapping; Canopy fisheye image; Deep learning; Fisheye images; Images segmentations; Leaf Area Index; Learning models; Raspberry pi; Vegetation mapping; Wireless communications; Wireless sensor; Wireless sensor networks","canopy fisheye image; deep learning; Leaf area index; Raspberry Pi; wireless sensor","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85134328841"
"Huang F.; Xie T.; Liu Z.","Huang, Fei (57219158050); Xie, Ting (57219159843); Liu, Zhengcai (57209199570)","57219158050; 57219159843; 57209199570","Dual-branche attention network for super-resolution of remote sensing images","2023","International Journal of Remote Sensing","44","2","","492","516","24","10.1080/01431161.2023.2166370","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146644610&doi=10.1080%2f01431161.2023.2166370&partnerID=40&md5=5bdd59d2c25691e6eaf5fe66b35a9726","Remote sensing (RS) images are considered to be reflections of the real world. However, RS images often suffered from low resolution, making further research difficult to follow. Although super resolution (SR) techniques based on deep learning have achieved considerable breakthroughs, they show limited performance when dealing with low-quality RS images with complicated backgrounds; for instance, the SR results tend to loss details and have undesired structural distortion. Thus, this paper proposes an innovative dual-branch attention network (DBAN) to produce sufficient details and preserve clear structural information for SR results of RS images. It consists of two components: a feature extraction branch and a high-frequency information learning branch. The features extraction branch, formed as a densely residual structure, combines a series of dual attention blocks that are designed to exploit valid features from different dimensions, and then all these multi-scale features are reused through a global concatenation. The high-frequency information extraction branch, incorporating noise removing units (NRU) and high-frequency attention units (HFU), is responsible for producing the high-frequency features without noise, which enables DBAN to handle the problem of structural distortion. Meanwhile, a composite loss function based on a Laplacian pyramid is proposed to maximize the structural similarity between reconstruction results and real high-resolution RS images. The proposed network is efficient and lightweight because of its strong and effective attention to feature learning. Experimental results on three open-source RS image datasets and the JiLin-01 dataset demonstrate the effectiveness of our DBAN where higher accuracy over state-of-the-art methods in super-resolving complicated images was achieved. © 2023 Informa UK Limited, trading as Taylor & Francis Group.","Deep learning; Optical resolving power; Features extraction; High frequency HF; High-frequency informations; Image, attention; Lower resolution; Real-world; Remote sensing images; Remote-sensing; Structural distortions; Superresolution; artificial neural network; data set; image resolution; machine learning; remote sensing; Remote sensing","image, attention; remote sensing; Structural distortion; super-resolution","Article","Final","","Scopus","2-s2.0-85146644610"
"Rasheed M.T.; Shi D.","Rasheed, Muhammad Tahir (57813410800); Shi, Daming (56299801000)","57813410800; 56299801000","LSR: Lightening super-resolution deep network for low-light image enhancement","2022","Neurocomputing","505","","","263","275","12","10.1016/j.neucom.2022.07.058","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134741185&doi=10.1016%2fj.neucom.2022.07.058&partnerID=40&md5=0481527509cb9e3b5741e3e1f7806228","In long-range shooting during low-light, we can only obtain a Low-Resolution (LR) image with poor visibility due to the limitation of physical devices. To get high-quality distant images, optical lenses are the optimal choice, but they are quite expensive and bulky. Low-light enhancement and Super-Resolution (SR) are the necessity of mobile phones and surveillance cameras and have wide applications in video surveillance, remote sensing, and night photography. Usually, the images that are taken from long-range in low-light suffer the loss of details not only due to low photon count but also due to low Signal-to-Noise Ratio (SNR), which makes it a highly ill-posed problem. Therefore, to resolve these two problems simultaneously, we propose a Lightening Super-Resolution (LSR) deep network. The proposed network uses the back-projection to learn the enhanced and dark features in low-resolution space iteratively and up-sample the enhanced features at the last stage of the network to get the final enhanced and high-resolution image. In particular, to train the network, the low-light images of the publicly available LOw Light (LOL) dataset are down-sampled using bicubic interpolation, and ground truth images are used as enhanced high-resolution images. For a fair comparison, a series of already available SR networks have been trained on the mentioned dataset, and their performances are compared. The promising results open up many opportunities for future work. © 2022 Elsevier B.V.","Cost effectiveness; Lenses; Optical remote sensing; Optical resolving power; Security systems; Signal to noise ratio; Backprojections; High-resolution images; Low light; Low resolution images; Low-light image enhancement; Low-light images; Physical devices; Poor visibility; Soft zooming; Superresolution; Image enhancement","Back-projection; Low-light image enhancement; Soft zooming; Super-resolution","Article","Final","","Scopus","2-s2.0-85134741185"
"Yu T.; Yang R.; Huang Y.; Gao J.; Kuang Q.","Yu, Tingzhao (57189029985); Yang, Ruyi (57205206162); Huang, Yan (57909606000); Gao, Jinbing (57408960700); Kuang, Qiuming (57191916860)","57189029985; 57205206162; 57909606000; 57408960700; 57191916860","Terrain-Guided Flatten Memory Network for Deep Spatial Wind Downscaling","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","9468","9481","13","10.1109/JSTARS.2022.3218016","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141625530&doi=10.1109%2fJSTARS.2022.3218016&partnerID=40&md5=b89fdb96b2a3aff11024cdf42931e2ac","High-resolution wind analysis plays an essential role in pollutant dispersion and renewable energy utilization. This article focuses on spatial wind downscaling. Specifically, a novel terrain-guided flatten memory network (abbreviated as TIGAM) with axial similarity constraint is proposed. TIGAM consists of three elaborately designed blocks, i.e., the similarity block, the reconstruction block, and the denoise block. To achieve long-spatial dependence, the similarity block interpolates low-resolution data to high resolution in an axial attention manner. Meanwhile, the reconstruction block aims to obtain a clearer high-resolution representation in closed form. Taking both of the meteorological prior and network design principle into consideration, this article also proposes a flatten memory module with learnable input for high-resolution denoising. Furthermore, for accurate detail reconstruction, a terrain-guided enhanced loss is presented benefitting from the high-resolution remote sensing data. This loss function integrates wind spatial distribution and terrain elegantly. Extensive quantitative and qualitative experiments demonstrate the superiority of the proposed TIGAM.  © 2008-2012 IEEE.","Deep learning; Energy utilization; Landforms; Meteorology; Optical resolving power; Remote sensing; Wind speed; Deep learning; Down-scaling; Flatten memory network; Image super resolutions; Images reconstruction; Memory network; Meteorological method; Spatial resolution; Spatial wind downscaling; Superresolution; Wind speed; alternative energy; artificial intelligence; artificial neural network; downscaling; image analysis; memory; numerical model; remote sensing; satellite data; spatial resolution; Image reconstruction","Deep learning; flatten memory network; image super-resolution; meteorological methods; spatial wind downscaling","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85141625530"
"Wang Z.; Chen B.; Zhang H.; Liu H.","Wang, Zhengjue (56642130100); Chen, Bo (56387823300); Zhang, Hao (57210071079); Liu, Hongwei (57205480555)","56642130100; 56387823300; 57210071079; 57205480555","Unsupervised Hyperspectral and Multispectral Images Fusion Based on Nonlinear Variational Probabilistic Generative Model","2022","IEEE Transactions on Neural Networks and Learning Systems","33","2","","721","735","14","10.1109/TNNLS.2020.3028772","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124055283&doi=10.1109%2fTNNLS.2020.3028772&partnerID=40&md5=dd95665aa816cb3c3a76d0a9d1c35471","Due to hardware limitations, it is challenging for sensors to acquire images of high resolution in both spatial and spectral domains, which arouses a trend that utilizing a low-resolution hyperspectral image (LR-HSI) and a high-resolution multispectral image (HR-MSI) to fuse an HR-HSI in an unsupervised manner. Considering the fact that most existing methods are restricted by using linear spectral unmixing, we propose a nonlinear variational probabilistic generative model (NVPGM) for the unsupervised fusion task based on nonlinear unmixing. We model the joint full likelihood of the observed pixels in an LR-HSI and an HR-MSI, both of which are assumed to be generated from the corresponding latent representations, i.e., the abundance vectors. The sufficient statistics of the generative conditional distributions are nonlinear functions with respect to the latent variable, realized by neural networks, which results in a nonlinear spectral mixture model. For scalability and efficiency, we construct two recognition models to infer the latent representations, which are parameterized by neural networks as well. Simultaneously inferring the latent representations and optimizing the parameters are achieved using stochastic gradient variational inference, after which the target HR-HSI is retrieved via feedforward mapping. Though without supervised information about the HR-HSI, NVPGM still can be trained based on extra LR-HSI and HR-MSI data sets in advance unsupervisedly and processes the images at the test phase in real time. Three commonly used data sets are used to evaluate the effectiveness and efficiency of NVPGM, illustrating the outperformance of NVPGM in the unsupervised LR-HSI and HR-MSI fusion task.  © 2012 IEEE.","Efficiency; Image fusion; Remote sensing; Stochastic systems; Generative model; High resolution; Hyperspectral image; Lower resolution; Multispectral image; Multispectral images; Nonlinear fusion; Probabilistic generative model; Probabilistics; Superresolution; article; comparative effectiveness; stochastic model; Spectroscopy","Hyperspectral image (HSI); multispectral image (MSI); nonlinear fusion; probabilistic generative model; super-resolution","Article","Final","","Scopus","2-s2.0-85124055283"
"Yan H.-F.; Zhao Y.-Q.; Chan J.C.-W.; Kong S.G.","Yan, Hao-Fang (57482584200); Zhao, Yong-Qiang (35365726800); Chan, Jonathan Cheung-Wai (8840429000); Kong, Seong G (7203044888)","57482584200; 35365726800; 8840429000; 7203044888","Spectral Super-Resolution Based on Dictionary Optimization Learning via Spectral Library","2023","IEEE Transactions on Geoscience and Remote Sensing","61","","5400216","","","","10.1109/TGRS.2022.3229439","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144743522&doi=10.1109%2fTGRS.2022.3229439&partnerID=40&md5=d5dec68b086426aac61712b33b0b7181","Extensive works have been reported in hyperspectral images (HSIs) and multispectral images (MSIs) fusion to raise the spatial resolution of HSIs. However, the limited acquisition of HSIs has been an obstacle to such approaches. Spectral super-resolution (SSR) of MSI is a challenging and less investigated topic, which can also provide high-resolution synthetic HSIs. To deal with this high ill-posedness problem, we perform super-resolution enhancement of MSIs in the spectral domain by incorporating a spectral library as a priori. First, an aligned spectral library, which maps the open-source spectral library to a specific spectral library created for the reconstructed HR HSI, is represented. An intermediate latent HSI is obtained by fusing the spatial information from MSI and the hyperspectral information from a specific spectral library. Then, we use low-rank attribute embedding to transfer latent HSI into a robust subspace. Finally, a low-rank HSI dictionary representing the hyperspectral information is learned from the latent HSI. The adaptive sparse coefficient of MSI is obtained with a nonnegative constraint. By fusing these two terms, we get the final HR HSI. The proposed SSR model does not require any pretraining stages. We confirm the validity and superiority of our proposed SSR algorithm by comparing it with several benchmark state-of-the-art approaches on different datasets.  © 1980-2012 IEEE.","Hyperspectral imaging; Image resolution; Remote sensing; Correlation; Dictionary optimization learning; Embeddings; Images reconstruction; Low-rank attribute embedding; Optimisations; Spatial resolution; Spectral libraries; Spectral library alignment; Spectral super-resolution reconstruction; Super-resolution reconstruction; Superresolution; algorithm; image resolution; multispectral image; optimization; reconstruction; satellite imagery; spectral analysis; Image reconstruction","Dictionary optimization learning; low-rank attribute embedding (LAE); spectral library alignment (SLA); spectral super-resolution (SSR) reconstruction","Article","Final","","Scopus","2-s2.0-85144743522"
"Li Y.; Wang Y.; Li B.; Wu S.","Li, Yunhe (55647591200); Wang, Yi (57204548320); Li, Bo (57777715900); Wu, Shaohua (57189245768)","55647591200; 57204548320; 57777715900; 57189245768","Super-Resolution of Remote Sensing Images for ×4 Resolution without Reference Images","2022","Electronics (Switzerland)","11","21","3474","","","","10.3390/electronics11213474","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141875470&doi=10.3390%2felectronics11213474&partnerID=40&md5=2b0b794fd72a9dfbed4cf586766ec1e8","Sentinel-2 satellites can provide free optical remote-sensing images with a spatial resolution of up to 10 M, but the spatial details provided are not enough for many applications, so it is worth considering improving the spatial resolution of Sentinel-2 satellites images through super-resolution (SR). Currently, the most effective SR models are mainly based on deep learning, especially the generative adversarial network (GAN). Models based on GAN need to be trained on LR–HR image pairs. In this paper, a two-step super-resolution generative adversarial network (TS-SRGAN) model is proposed. The first step is having the GAN train the degraded models. Without supervised HR images, only the 10 m resolution images provided by Sentinel-2 satellites are used to generate the degraded images, which are in the same domain as the real LR images, and then to construct the near-natural LR–HR image pairs. The second step is to design a super-resolution generative adversarial network with strengthened perceptual features, to enhance the perceptual effects of the generated images. Through experiments, the proposed method obtained an average NIQE as low as 2.54, and outperformed state-of-the-art models according to other two NR-IQA metrics, such as BRISQUE and PIQE. At the same time, the comparison of the intuitive visual effects of the generated images also proved the effectiveness of TS-SRGAN. © 2022 by the authors.","","generative adversarial network; remote-sensing image; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85141875470"
"Wang W.; Zhou Z.; Zhang X.; Lv T.; Liu H.; Liang L.","Wang, Wenqing (56004232500); Zhou, Zhiqiang (57222619378); Zhang, Xiaoqiao (58001605700); Lv, Tu (58002277800); Liu, Han (56177336900); Liang, Lili (7202069475)","56004232500; 57222619378; 58001605700; 58002277800; 56177336900; 7202069475","DiTBN: Detail Injection-Based Two-Branch Network for Pansharpening of Remote Sensing Images","2022","Remote Sensing","14","23","6120","","","","10.3390/rs14236120","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143795850&doi=10.3390%2frs14236120&partnerID=40&md5=34cbfde37d37aabb0b1cc06d70aaf021","Pansharpening is one of the main research topics in the field of remote sensing image processing. In pansharpening, the spectral information from a low spatial resolution multispectral (LRMS) image and the spatial information from a high spatial resolution panchromatic (PAN) image are integrated to obtain a high spatial resolution multispectral (HRMS) image. As a prerequisite for the application of LRMS and PAN images, pansharpening has received extensive attention from researchers, and many pansharpening methods based on convolutional neural networks (CNN) have been proposed. However, most CNN-based methods regard pansharpening as a super-resolution reconstruction problem, which may not make full use of the feature information in two types of source images. Inspired by the PanNet model, this paper proposes a detail injection-based two-branch network (DiTBN) for pansharpening. In order to obtain the most abundant spatial detail features, a two-branch network is designed to extract features from the high-frequency component of the PAN image and the multispectral image. Moreover, the feature information provided by source images is reused in the network to further improve information utilization. In order to avoid the training difficulty for a real dataset, a new loss function is introduced to enhance the spectral and spatial consistency between the fused HRMS image and the input images. Experiments on different datasets show that the proposed method achieves excellent performance in both qualitative and quantitative evaluations as compared with several advanced pansharpening methods. © 2022 by the authors.","Convolution; Convolutional neural networks; Image enhancement; Image resolution; Convolutional neural network; Feature information; High spatial resolution multispectral images; Multispectral images; Pan-sharpening; Panchromatic image; Remote sensing images; Remote-sensing; Source images; Spatial resolution; Remote sensing","convolutional neural networks; multispectral image; pan-sharpening; panchromatic image; remote sensing","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85143795850"
"Li J.-T.; Bian Z.; Guo L.-X.","Li, Jiang-Ting (37006755000); Bian, Zheng (57208108900); Guo, Li-Xin (56498191400)","37006755000; 57208108900; 56498191400","Optimized complex object classification model: reconstructing the ISAR image of a hypersonic vehicle covered with a plasma sheath using a U-WGAN-GP framework","2022","International Journal of Remote Sensing","43","14","","5306","5323","17","10.1080/01431161.2022.2133578","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140244358&doi=10.1080%2f01431161.2022.2133578&partnerID=40&md5=8d670dc17d22a30cfa02d8a00b7ce710","This study aims to apply generative adversarial networks (GANs) to the effective classification of high/low resolution (HR/LR) image pairs obtained via inverse synthetic aperture radar (ISAR) for hypersonic objects covered with a plasma sheath. We propose a classification training model based on a Wasserstein GAN with a gradient penalty (U-WGAN-GP) framework, wherein a U-Net with an excellent jump connection structure is used as a generator, and a VGG-Net with high robustness is used as a discriminator, to support the reliable classification of HR/LR ISAR image pairs for the enhancement of ISAR image resolution. The WGAN-GP provides a shortcut for the gradient propagation of network parameters during the training stage through the stable encoder and decoder structure of U-Net. It inherits the echo intensity variation and position distribution characteristics of the scattering points between hypersonic objects in LR images and effectively transplants them into the generated super-resolution ISAR images, and it establishes end-to-end mapping between the HR/LR ISAR images. Moreover, the VGG-Net ensures that the generated super-resolution images are stable, controllable, and undistorted. In addition, the WGAN-GP structure combines the content and adversarial losses, optimizes the generator loss function, and uses the GP method to provide a stable and continuous training process. Finally, a traditional VGG-16 network classifier is added at the end of the training model. The proposed model is applied to an HR/LR image pair dataset of hypersonic objects. Compared with existing methods, the proposed method improved the classification and recognition accuracy from 54.4% to 81.8%. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Generative adversarial networks; Hypersonic aerodynamics; Hypersonic vehicles; Image enhancement; Image resolution; Inverse synthetic aperture radar; Plasma sheaths; Radar imaging; High-low; High/low resolution (HR/LR) image pair; Hypersonic object; Image pairs; Inverse synthetic aperture radar; Inverse synthetic aperture radar images; Lower resolution; Training model; U-net; Wasserstein generative adversarial network with gradient penalty; conceptual framework; image analysis; image resolution; inverse problem; remote sensing; synthetic aperture radar; Inverse problems","High/low resolution (HR/LR) image pairs; hypersonic objects; inverse synthetic aperture radar (ISAR); plasma sheath; U-Net; Wasserstein generative adversarial networks with gradient penalty (WGAN-GP)","Article","Final","","Scopus","2-s2.0-85140244358"
"Zhang L.; Dong R.; Yuan S.; Fu H.","Zhang, Lixian (57207392945); Dong, Runmin (57205415789); Yuan, Shuai (57213198049); Fu, Haohuan (8713118400)","57207392945; 57205415789; 57213198049; 8713118400","Srbuildingseg-E2: An Integrated Model for End-to-End Higher-Resolution Building Extraction","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","1356","1359","3","10.1109/IGARSS46834.2022.9883295","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140378677&doi=10.1109%2fIGARSS46834.2022.9883295&partnerID=40&md5=9e46a3a2df12f2ef904b859de9402ed0","Automatic and accurate extraction of buildings from remote sensing images plays a vital role in many applications. However, existing approaches for building extraction generally apply high-resolution remote sensing images as input to attain high-resolution extraction results, which is time consuming and limited due to its spatiotemporal accessibility and cost. To address this challenge, in this paper, we propose an end-to-end approach, i.e., SRBuildingSeg-E2, to achieve higher-resolution building extraction from relatively low resolution remote sensing images. By integrating super resolution and semantic segmentation techniques, our proposed approach can attain high-resolution representations using low-resolution input. The quantitative assessment results reveal its promising performance in higher-resolution building extraction. © 2022 IEEE.","Buildings; Deep learning; Optical resolving power; Remote sensing; Semantic Segmentation; Semantics; Building extraction; Deep learning; End to end; High resolution; Integrated modeling; Lower resolution; Remote sensing images; Semantic segmentation; Srbuildingseg; Superresolution; Extraction","building extraction; deep learning; semantic segmentation; SRBuildingSeg; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85140378677"
"Liu Z.; Feng R.; Wang L.; Zhong Y.; Zhang L.; Zeng T.","Liu, Ziyu (57865366100); Feng, Ruyi (55853730300); Wang, Lizhe (23029267900); Zhong, Yanfei (12039673900); Zhang, Liangpei (8359720900); Zeng, Tieyong (25423412800)","57865366100; 55853730300; 23029267900; 12039673900; 8359720900; 25423412800","Remote Sensing Image Super-Resolution via Dilated Convolution Network with Gradient Prior","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","2402","2405","3","10.1109/IGARSS46834.2022.9883673","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140375169&doi=10.1109%2fIGARSS46834.2022.9883673&partnerID=40&md5=8286ea9e12b62cf829f58f8c334d256d","Due to the limitations of the imaging sensor, the spatial resolution of satellite imagery is often insufficient, namely, low resolution (LR). Therefore, super-resolution (SR) is proposed, which strives to improve image resolution, perfectly to compensate for the shortcomings of satellite sensor imaging. In this study, we develop a unique dilated convolution network with gradient prior (DCNG) for remote sensing SR, aiming to extract powerful low-level features with gradient prior and efficitive network and then reconstruct the high-level feature details. The DCNG is built of two components: the Multi-Scale Feature Extraction Network and the Feature Reconstruction Network. In the Multi-Scale Feature Extraction Network, the Double-Path Dilated Residual Block (DPDRB) is designed with the dilation convolution operation to obtain the multi-scale features and increase the receptive field, the Global Self-attention Module (GSA) to catch the long-range dependency among picture patches, and a Gradient Propagation Network (GPN) is proposed to extract high-level gradient information. In the Feature Reconstruction Network, the Pixel Shuffle is introduced to reconstruct the feature by combining characteristics of different frequency bands. Experiments using Massachusetts_Roads and 3K VEHICLE_SR data sets indicate that our DCNG surpasses state-of-the-art algorithms in terms of quantitative and qualitative evaluations. © 2022 IEEE.","Computer vision; Convolution; Extraction; Feature extraction; Image enhancement; Image resolution; Satellite imagery; Attention; Dilated convolution; Feature reconstruction; Features extraction; Gradient prior; Multi-scale features; Reconstruction networks; Remote sensing super-resolution; Remote-sensing; Superresolution; Remote sensing","attention; dilated convolution; gradient prior; Remote sensing super-resolution","Conference paper","Final","","Scopus","2-s2.0-85140375169"
"Zheng J.; Zhou X.; Xu H.; Qing M.; Bai C.","Zheng, Jianwei (37087960400); Zhou, Xinjie (57549238400); Xu, Honghui (57220954971); Qing, Mengjie (57550009800); Bai, Cong (55248200400)","37087960400; 57549238400; 57220954971; 57550009800; 55248200400","Hyperspectral Image Super Resolution via Nonconvex Low-rank Constraint of Tensor Ring Factors; [张量环因子非凸秩约束的高光谱图像超解析]","2022","Guangzi Xuebao/Acta Photonica Sinica","51","2","0210003","","","","10.3788/gzxb20225102.0210003","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127065721&doi=10.3788%2fgzxb20225102.0210003&partnerID=40&md5=fbe3caa69a28cdcb2bb4d38479790f45","Hyperspectral Image (HSI) is composed of multiple discrete bands with specific frequencies. It not only contains rich spectral information but also provides real scenes that cannot be captured by human eyes, which is conducive to accurately target recognition. It has been widely used in earth remote sensing tasks such as compressed sensing, target classification, etc. However, limited by solar irradiance, optical imaging mechanism, and other factors, the equipment usually sacrifices part of the spatial resolution to ensure a high spectral resolution, which greatly limits the subsequent processing and application accuracy of spectral images. In contrast to HSI, Multispectral Image (MSI) obtained by multispectral sensor has high spatial resolution but low spectral resolution. To date, the fusion of High Spatial Resolution Multispectral Image (HR-MSI) and Low Spatial Resolution Hyperspectral Image (LR-HSI) in the same scene into High Spatial Resolution Hyperspectral Image (HR-HSI) is a common method to realize high-quality HSI reconstruction.In the early methods, multidimensional HSI data are often transformed into matrix processing. However, HSI is essentially a kind of 3D data with two spatial dimensions and one spectral dimension. Transforming multidimensional HSI data into matrix will inevitably destroy its spectral-spatial structural correlation and reduce the model performance.Tensor representation can effectively preserve the inherent structural information of spectral images. The method based on tensor decomposition has also become one of the effective schemes to solve the problem of HSI-MSI fusion. The methods based on tensor networks, such as Tensor Train (TT) decomposition and Tensor Ring (TR) decomposition, have stronger ability to mine the internal structure of data than other techniques. In addition, in recent years, some researchers have explored the potential properties of tensor ring factors. These methods have achieved satisfactory results, but with two problems remain. Firstly, these models expand the factors into mode-n matrix, ignoring the correlation between different modes; Secondly, the matrix nuclear norm constraint attempts to model the tensor in the vector space based on matrix Singular Value Decomposition (SVD), and its representation capacity will be lost. Tensor Nuclear Norm (TNN) based on t-SVD (tensor singular value decomposition) can effectively maintain the inherent low-rank structure of tensor and avoid the loss of original information in the process of tensor matricization. Besides, the larger singular value in the image usually corresponds to the more important information, such as contours, sharp edges and smooth regions. However, TNN treats each singular value equally, which means that the larger singular value will be punished greatly and will suffer from the loss of the more important information and lead to suboptimal solution in practical applications.Therefore, aiming at the problem of HSI-MSI fusion, a low-rank tensor ring decomposition based on nonconvex tensor rank constraint is proposed. Specifically, the intrinsic low-rank structure of hyperspectral images is mined by directly applying the nonconvex tensor nuclear norm constraint based on t-SVD. Firstly, HSI is projected into a low dimensional compact space by using the global spectral low-rank of the hyperspectral image. Then, following the spatial nonlocal similarity, the reduced image is divided into multiple patches, and the similar ones are gathered one by one to form several three-dimensional tensor groups. Furthermore, the tensor ring decomposition technique is used to mine its internal low-rank structure and explore the essential characteristics of tensor ring factors. Different from the way that expands the factors into matrices and applies the nuclear norm constraint, this paper proposes to directly apply the nonconvex tensor nuclear norm on each factor, which fully exploits the inherent tensor structure and effectively avoids the loss of spatial-spectral correlation. In addition, this paper introduces log-function instead of l1 norm to avoid excessive punishment of large singular values. Extensive experimental results show that the proposed method effectively improves the quality of the restored image. Compared with the latest fusion methods, the algorithm has better performance in quantitative evaluation and visual comparison. © 2022, Science Press. All right reserved.","Image reconstruction; Image resolution; Metadata; Remote sensing; Singular value decomposition; Spectral resolution; Tensors; Vector spaces; Alternating directions method of multipliers; matrix; Nonconvex; Rank constraints; Rank structure; Singular values; Spatial resolution; Super-resolution reconstruction; Tensor nuclear norm; Tensor ring; Spectroscopy","Alternating direction method of multipliers; Hyperspectral image; Super-resolution reconstruction; Tensor nuclear norm; Tensor ring","Article","Final","","Scopus","2-s2.0-85127065721"
"Wu J.; Cong R.; Fang L.; Guo C.; Zhang B.; Ghamisi P.","Wu, Jie (57972350500); Cong, Runmin (57972139900); Fang, Leyuan (57218451012); Guo, Chunle (57194397955); Zhang, Bob (57972140000); Ghamisi, Pedram (53663404300)","57972350500; 57972139900; 57218451012; 57194397955; 57972140000; 53663404300","Unpaired remote sensing image super-resolution with content-preserving weak supervision neural network","2023","Science China Information Sciences","66","1","119105","","","","10.1007/s11432-021-3575-1","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142286060&doi=10.1007%2fs11432-021-3575-1&partnerID=40&md5=2577078b369c3d2eab3d59f5e0a177d3","[No abstract available]","","","Letter","Final","","Scopus","2-s2.0-85142286060"
"Wang P.; Bayram B.; Sertel E.","Wang, Peijuan (57224642089); Bayram, Bulent (15130508500); Sertel, Elif (21934838300)","57224642089; 15130508500; 21934838300","A comprehensive review on deep learning based remote sensing image super-resolution methods","2022","Earth-Science Reviews","232","","104110","","","","10.1016/j.earscirev.2022.104110","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134841429&doi=10.1016%2fj.earscirev.2022.104110&partnerID=40&md5=b0cca12a3268e05e5493fcbe5e9c8efa","Satellite imageries are an important geoinformation source for different applications in the Earth Science field. However, due to the limitation of the optic and sensor technologies and the high cost to update the sensors and equipments, the spectral and spatial resolution of the Earth Observation satellites may not meet the desired requirements. Thus, Remote Sensing Image Super-resolution (RSISR) which aims at restoring the high-resolution (HR) remote sensing images from the given low-resolution (LR) images has drawn considerable attention and witnessed the rapid development of the deep learning (DL) algorithms. In this research, we aim to comprehensively review the DL-based single image super-resolution (SISR) methods on optical remote sensing images. First, we introduce the DL techniques utilized in SISR. Second, we summarize the RSISR algorithms thoroughly, including the DL models, commonly used remote sensing datasets, loss functions, and performance evaluation metrics. Third, we present a new multi-sensor dataset that consists of Very High-Resolution satellite images from different satellites of various landscapes and evaluate the performance of some state-of-the-art super-resolution methods on this dataset. Finally, we envision the challenges and future research in the RSISR field. © 2022 Elsevier B.V.","accuracy assessment; error analysis; GIS; remote sensing; satellite data; satellite imagery; spatial resolution","Deep learning; Remote sensing; Super-resolution","Review","Final","","Scopus","2-s2.0-85134841429"
"Aljarrah I.A.; Alshare E.M.","Aljarrah, Inad A. (12799816300); Alshare, Eman M. (57641058000)","12799816300; 57641058000","Improved Residual Dense Network for Large Scale Super-Resolution via Generative Adversarial Network","2022","International Journal of Communication Networks and Information Security","14","1","","118","125","7","10.54039/ijcnis.v14i1.5221","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128840584&doi=10.54039%2fijcnis.v14i1.5221&partnerID=40&md5=96e40e00eaf60ee414c18fd5ee27c8cd","Recent single image super resolution (SISR) studies were conducted extensively on small upscaling factors such as x2 and x4 on remote sensing images, while less work was conducted on large factors such as the factor x8 and x16. Owing to the high performance of the generative adversarial networks (GANs), in this paper, two GAN’s frameworks are implemented to study the SISR on the residual remote sensing image with large magnification under x8 scale factor, which is still lacking acceptable results. This work proposes a modified version of the residual dense network (RDN) and then it been implemented within GAN framework which named RDGAN. The second GAN framework has been built based on the densely sampled super resolution network (DSSR) and we named DSGAN. The used loss function for the training employs the adversarial, mean squared error (MSE) and the perceptual loss derived from the VGG19 model. We optimize the training by using Adam for number of epochs then switching to the SGD optimizer. We validate the frameworks on the proposed dataset of this work and other three remote sensing datasets: the UC Merced, WHURS19 and RSSCN7. To validate the frameworks, we use the following image quality assessment metrics: the PSNR and the SSIM on the RGB and the Y channel and the MSE. The RDGAN evaluation values on the proposed dataset were 26.02, 0.704, and 257.70 for PSNR, SSIM and the MSE, respectively, and the DSGAN evaluation on the same dataset yielded 26.13, 0.708 and 251.89 for the PSNR, the SSIM, and the MSE. © 2022 International Journal of Communication Networks and Information Security","","Generative adversarial network; Remote sensing; Residual dense generative adversarial network.; Residual dense network; Single image super-resolution","Article","Final","","Scopus","2-s2.0-85128840584"
"Yue X.; Chen X.; Zhang W.; Ma H.; Wang L.; Zhang J.; Wang M.; Jiang B.","Yue, Xiuchao (57459724800); Chen, Xiaoxuan (54781105800); Zhang, Wanxu (57003106800); Ma, Hang (57327563100); Wang, Lin (56769098400); Zhang, Jiayang (57834564100); Wang, Mengwei (57459462700); Jiang, Bo (57002004700)","57459724800; 54781105800; 57003106800; 57327563100; 56769098400; 57834564100; 57459462700; 57002004700","Super-Resolution Network for Remote Sensing Images via Preclassification and Deep–Shallow Features Fusion","2022","Remote Sensing","14","4","925","","","","10.3390/rs14040925","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124935460&doi=10.3390%2frs14040925&partnerID=40&md5=93483a9091d8c794037b024074344d91","A novel super-resolution (SR) method is proposed in this paper to reconstruct high-resolution (HR) remote sensing images. Different scenes of remote sensing images have great disparities in structural complexity. Nevertheless, most existing SR methods ignore these differences, which increases the difficulty to train an SR network. Therefore, we first propose a preclassification strategy and adopt different SR networks to process the remote sensing images with different structural complexity. Furthermore, the main edge of low-resolution images are extracted as the shallow features and fused with the deep features extracted by the network to solve the blurry edge problem in remote sensing images. Finally, an edge loss function and a cycle consistent loss function are added to guide the training process to keep the edge details and main structures in a reconstructed image. A large number of comparative experiments on two typical remote sensing images datasets (WHURS and AID) illustrate that our approach achieves better performance than state-of-the-art approaches in both quantitative indicators and visual qualities. The peak signal-to-noise ratio (PSNR) value and the structural similarity (SSIM) value using the proposed method are improved by 0.5353 dB and 0.0262, respectively, over the average values of five typical deep learning methods on the ×4 AID testing set. Our method obtains satisfactory reconstructed images for the subsequent applications based on HR remote sensing images. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Complex networks; Convolutional neural networks; Deep learning; Image reconstruction; Large dataset; Remote sensing; Signal to noise ratio; Convolutional neural network; Features fusions; High-resolution remote sensing images; Image super resolutions; Loss functions; Reconstructed image; Remote sensing images; Structural complexity; Superresolution; Superresolution methods; Optical resolving power","Convolutional neural network; Image super-resolution; Remote sensing image","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85124935460"
"Zhang W.; Chen H.; Chen W.; Yang S.","Zhang, Wei (57200731774); Chen, Hao (57192534817); Chen, Wen (57207883940); Yang, Shuting (57821179200)","57200731774; 57192534817; 57207883940; 57821179200","A Rooftop-Contour Guided 3D Reconstruction Texture Mapping Method for Building using Satellite Images","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","3456","3459","3","10.1109/IGARSS46834.2022.9883969","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140398270&doi=10.1109%2fIGARSS46834.2022.9883969&partnerID=40&md5=d30de65ad0b19f417d30d1541945754b","Low-quality digital surface model (DSM) and blurred textures result in poor visualization of building reconstructions. In this paper, an edge-based block decomposition method for building rooftop reconstruction and side walls generation is proposed, which is applied in three-dimensional (3D) reconstruction texture mapping of buildings. The rooftop is decomposed into blocks according to the contour of the building's rooftop in the orthophoto. Each block is combined with the DSM generated by the stereo pair of satellite images to reconstruct the rooftop and interpolate to generate the side walls to obtain a regularized 3D point cloud of the building. For better texture mapping effect, single image super-resolution (SISR) method is used to enhance the texture details of remote sensing images. Experimental results show that the proposed method has better visualization effect than other 3D reconstruction methods based on satellite data. © 2022 IEEE.","Data visualization; Image enhancement; Image reconstruction; Image texture; Mapping; Optical resolving power; Remote sensing; Satellites; Stereo image processing; Textures; Three dimensional computer graphics; 3d buildings; 3D reconstruction; Digital surface models; Image super resolutions; Rooftop reconstruction; Satellite images; Side wall generation; Side walls; Stereo pair; Texture mapping; Visualization","3D Building; Image super-resolution; Rooftop reconstruction; Side walls generation; Stereo pair","Conference paper","Final","","Scopus","2-s2.0-85140398270"
"Zhu F.; Wang C.; Zhu B.; Sun C.; Qi C.","Zhu, Fuzhen (12780819500); Wang, Chen (57980554000); Zhu, Bing (57199801240); Sun, Ce (58059130100); Qi, Chengxiao (57282587700)","12780819500; 57980554000; 57199801240; 58059130100; 57282587700","An improved generative adversarial networks for remote sensing image super-resolution reconstruction via multi-scale residual block","2023","Egyptian Journal of Remote Sensing and Space Science","26","1","","151","160","9","10.1016/j.ejrs.2022.12.008","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146055217&doi=10.1016%2fj.ejrs.2022.12.008&partnerID=40&md5=0718459def821c5b8689d5680f7a98b8","Existing image super-resolution algorithms still suffer from the problems of not extracting rich image features and losing realistic high-frequency details. In order to solve these problems, this paper proposes an improved generative adversarial network algorithm for super-resolution reconstruction of remote sensing images by multi-scale residual blocks. The original generative adversarial network (GAN) structure is improved and multi-scale residual blocks are introduced in the generator to fuse features at different scales. After extracting the parallel information of multi-scale features, information is exchanged between multi-resolution information streams to obtain contextual information through spatial and channel attention mechanisms, and multi-scale features are fused according to the attention mechanism. In the discriminator, the concept of relative average GAN (RaGAN) is introduced, and the loss function of the network is redesigned so that the discriminator can predict relative probabilities instead of absolute probabilities thus enabling clear learning of edge and texture details. Experimental results show that the proposed method in this paper significantly outperforms state-of-the-art (SOTA) methods in terms of both subjective and objective metrics.In three test datasets, compared with SOTA methods, the Peak Signal to Noise Ratio(PSNR) is improved by a maximum of 1.18 dB, 0.84 dB and 1.29 dB respectively, and the Structural Similarity Index (SSIM) is improved by 0.0264, 0.0077 and 0.0109 respectively in scale of 2, 3 and 4 times images super-resolution.The model proposed in this paper effectively improved the super-resolution re-construction results of remote sensing images. © 2022 National Authority of Remote Sensing & Space Science","Image enhancement; Image reconstruction; Optical resolving power; Remote sensing; Signal to noise ratio; Textures; Attention mechanisms; Image super resolutions; Image super-resolution reconstruction; Multi-scale features; Multi-scale residual block; Multi-scales; Relative average GAN; Remote sensing images; State-of-the-art methods; Super-resolution reconstruction; algorithm; artificial neural network; image processing; image resolution; reconstruction; remote sensing; signal-to-noise ratio; Generative adversarial networks","GAN; Multi-scale residual block; RaGAN; Super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85146055217"
"Geng M.; Wu F.; Wang D.","Geng, Mingkun (57766750300); Wu, Fanlu (55993433800); Wang, Dong (56918736400)","57766750300; 55993433800; 56918736400","Lightweight Mars remote sensing image super-resolution reconstruction network; [轻量化火星遥感影像超分辨率重建网络]","2022","Guangxue Jingmi Gongcheng/Optics and Precision Engineering","30","12","","1487","1498","11","10.37188/OPE.20223012.1487","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132960143&doi=10.37188%2fOPE.20223012.1487&partnerID=40&md5=50f8889d0ac7a9bf73c71f028a8ca487","A lightweight Laplacian pyramid image super-resolution reconstruction convolution neural network based on deep Laplacian pyramid networks (LapSRNs) is proposed to accommodate the numerous parameters used in super-resolution reconstruction methods based on deep learning. First, shallow features are embedded from the input low resolution image (LR) input. Subsequently, using recursive blocks that allow parameter sharing and contain shared-source skip connections, deep features are extracted from the shallow features. Additionally, residual image (RI) containing high-frequency information is inferred. Next, the RI and input LR are upsampled via a transposed convolutional layer and added pixel by pixel to obtain a super-resolution image. The total number of parameters used in this method is only 3.98% of that used in the LapSRN for three scales, and the peak signal to noise ratio index increases by 0.031 3 and 0.116 7 dB under 4 times and 8 times super-resolutions, respectively. The proposed method reduces the number of parameters by 81.6%, 90.8%, and 88.8% under 2 times, 4 times, and 8 times resolutions, while the super-resolution effect is maintained. © 2022, Science Press. All right reserved.","Convolution; Convolutional neural networks; Deep learning; Image reconstruction; Laplace transforms; Optical resolving power; Signal to noise ratio; Convolutional neural network; Image pyramids; Image super-resolution reconstruction; Laplacian image pyramid; Laplacian Pyramid; Laplacians; Lightweight; Low resolution images; Super-resolution reconstruction; Superresolution; Pixels","Convolutional neural network; Laplacian image pyramid; Lightweight; Super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85132960143"
"Zou H.; He S.; Cao X.; Sun L.; Wei J.; Liu S.; Liu J.","Zou, Huanxin (8366222500); He, Shitian (57222956907); Cao, Xu (57211094852); Sun, Li (57311427800); Wei, Juan (57310676500); Liu, Shuo (57860009000); Liu, Jian (57867763000)","8366222500; 57222956907; 57211094852; 57311427800; 57310676500; 57860009000; 57867763000","Rescaling-Assisted Super-Resolution for Medium-Low Resolution Remote Sensing Ship Detection","2022","Remote Sensing","14","11","2566","","","","10.3390/rs14112566","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131559434&doi=10.3390%2frs14112566&partnerID=40&md5=f53ecf7022ea67cb098da34bcda8f948","Medium-low resolution (M-LR) remote sensing ship detection is a challenging problem due to the small target sizes and insufficient appearance information. Although image super resolution (SR) has become a popular solution in recent years, the ability of image SR is limited since much information is lost in input images. Inspired by the powerful information embedding ability of the encoder in image rescaling, in this paper, we introduce image rescaling to guide the training of image SR. Specifically, we add an adaption module before the SR network, and use the pre-trained rescaling network to guide the optimization of the adaption module. In this way, more information is embedded in the adapted M-LR images, and the subsequent SR module can utilize more information to achieve better performance. Extensive experimental results demonstrate the effectiveness of our method on image SR. More importantly, our method can be used as a pre-processing approach to improve the detection performance. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Remote sensing; Ships; Image rescaling; Image super resolutions; Lower resolution; Medium-low resolution remote sensing image; Remote sensing images; Remote-sensing; Rescaling; Ship detection; Small targets; Superresolution; Optical resolving power","image rescaling; image super-resolution; medium-low resolution remote sensing images; ship detection","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85131559434"
"He H.; Gao K.; Tan W.; Wang L.; Fatholahi S.N.; Chen N.; Chapman M.A.; Li J.","He, H. (55349691100); Gao, K. (57344224500); Tan, W. (57188719498); Wang, L. (56420751000); Fatholahi, S.N. (57219033628); Chen, N. (57208390275); Chapman, M.A. (57203027250); Li, J. (57235557700)","55349691100; 57344224500; 57188719498; 56420751000; 57219033628; 57208390275; 57203027250; 57235557700","IMPACT OF DEEP LEARNING-BASED SUPER-RESOLUTION ON BUILDING FOOTPRINT EXTRACTION","2022","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","43","B1-2022","","31","37","6","10.5194/isprs-archives-XLIII-B1-2022-31-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131922452&doi=10.5194%2fisprs-archives-XLIII-B1-2022-31-2022&partnerID=40&md5=34eb687ceb8769942220d4fccdd38027","Automated building footprints extraction from High Spatial Resolution (HSR) remote sensing images plays important roles in urban planning and management, and hazard and disease control. However, HSR images are not always available in practice. In these cases, super-resolution, especially deep learning (DL)-based methods, can provide higher spatial resolution images given lower resolution images. In a variety of remote sensing applications, DL based super-resolution methods are widely used. However, there are few studies focusing on the impact of DL-based super-resolution on building footprint extraction. As such, we present an exploration of this topic. Specifically, we first super-resolve the Massachusetts Building Dataset using bicubic interpolation, a pre-trained Super-Resolution CNN (SRCNN), a pre-trained Residual Channel Attention Network (RCAN), a pre-trained Residual Feature Aggregation Network (RFANet). Then, using the dataset under its original resolution, as well as the four different super-resolutions of the dataset, we employ the High-Resolution Network (HRNet) v2 to extract building footprints. Our experiments show that super-resolving either training or test datasets using the latest high-performance DL-based super-resolution method can improve the accuracy of building footprints extraction. Although SRCNN based building footprint extraction gives the highest Overall Accuracy, Intersection of Union and F1 score, we suggest using the latest super-resolution method to process images before building footprint extraction due to the fixed scale ratio of pre-trained SRCNN and low speed of convergence in training.  © 2022 H. He et al.","Buildings; Deep learning; Disease control; Image resolution; Remote sensing; Building footprint; Building footprint extraction; Deep learning; High resolution; High-resolution network v2; Impact; Learning-based super-resolution; Massachusetts; Superresolution; The massachusetts building dataset; Extraction","Building Footprint Extraction; Deep Learning; HRNet v2; Impact; Super-resolution; the Massachusetts Building Dataset","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85131922452"
"Wang X.; Wang X.; Zhao K.; Zhao X.; Song C.","Wang, Xianghai (8340645000); Wang, Xinying (57885863900); Zhao, Keyun (57887027000); Zhao, Xiaoyang (57203865767); Song, Chuanming (9333538200)","8340645000; 57885863900; 57887027000; 57203865767; 9333538200","FSL-Unet: Full-Scale Linked Unet With Spatial-Spectral Joint Perceptual Attention for Hyperspectral and Multispectral Image Fusion","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5539114","","","","10.1109/TGRS.2022.3208125","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139406588&doi=10.1109%2fTGRS.2022.3208125&partnerID=40&md5=5ae2f92050f02f367e8ff06c54d892ad","The application of hyperspectral image (HSI) is more and more extensive, but the lower spatial resolution seriously affects its application effect. Using low-resolution HSI (LR-HSI) and high-resolution (HR) multispectral image (MSI) fusion technology to achieve super-resolution reconstruction of HSI has become a mainstream method. However, most of the existing fusion methods do not make full use of the large-scale range of remote sensing images and neglect the preservation of spatial-spectral information in the fusion process. Considering that the spectral information in fused HR-HSI mainly depends on HSI, and the spatial information mainly depends on MSI, this article proposes a full-scale linked Unet with spatial-spectral joint perceptual attention (SSJPA) for hyperspectral and MSI fusion (FSL-Unet). The FSL-Unet consists of two modules. The first is the spatial-spectral attention extraction (SSAE) module, which is used to calculate the spectral attention of LR-HSI and the spatial attention of HR-MSI at different scales. The second is the full-scale link U-shaped fusion (FLUF) module, which adopts a multilevel feature extraction strategy, using denser full-scale skip connections to explore feature information in a finer-grained range, enabling the flexible combination of multiscale and multipath features. At the same time, we propose SSJPA on the encoder side of FLUF. SSJPA can make full use of the attention maps computed by the SSAE and then effectively embed spatial and spectral information into the fused image, enabling uninterrupted information transfer and aggregation. To demonstrate the effectiveness of FSL-Unet, we selected five public hyperspectral datasets for experiments. Compared with the other eight state-of-the-art fusion methods, the experimental results show that the FSL-Unet achieves competitive results. The source code for FSL-Unet can be downloaded from https://github.com/wxy11-27/FSL-Unet.  © 1980-2012 IEEE.","Extraction; Hyperspectral imaging; Image fusion; Image resolution; Remote sensing; Spectroscopy; Decoding; Features extraction; HyperSpectral; Hyperspectral image; Multi-spectral image fusions; Multispectral images; Perceptual attention; Spatial resolution; Superresolution; Unet; data set; image analysis; numerical method; spatial analysis; spectral analysis; Feature extraction","Hyperspectral image (HSI); image fusion; multispectral image (MSI); perceptual attention; Unet","Article","Final","","Scopus","2-s2.0-85139406588"
"Cai F.; Wu K.-Y.; Wang F.","Cai, Feng (57888175100); Wu, Ke-Yu (57324654500); Wang, Feng (56459216100)","57888175100; 57324654500; 56459216100","Remote Sensing Image Super-Resolution Via Attentional Feature Aggregation Generative Adversarial Network","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","2598","2601","3","10.1109/IGARSS46834.2022.9884863","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141821238&doi=10.1109%2fIGARSS46834.2022.9884863&partnerID=40&md5=39a0f2d24636b6be3ed4ff7137c98de3","The extraction of high-frequency details is generally neglected in single image super-resolution (SISR) for remote sensing images. In this paper, we propose an attentional feature aggregation generative adversarial network (AFA-GAN) with the capability of strong feature extraction and attentional feature fusion to generate high-resolution remote sensing images. We adopt the residual feature aggregation framework for the feature extraction to make full use of the hierarchical features on the residual branches. To better fuse global and local features with inconsistent scales, an attentional feature fusion mechanism is utilized in residual feature aggregation modules. The comprehensive experiments with state-of-the-art SISR methods on the UC Merced dataset demonstrate the effectiveness and superiority of our AFA-GAN. © 2022 IEEE.","Computer vision; Extraction; Feature extraction; Optical resolving power; Remote sensing; Attentional feature aggregation; Feature aggregation; Features extraction; Features fusions; Generative adversarial network; High frequency HF; Image super resolutions; Remote sensing images; Single image super-resolution; Single images; Generative adversarial networks","attentional feature aggregation (AFA); generative adversarial network (GAN); Remote sensing images; single image super-resolution (SISR)","Conference paper","Final","","Scopus","2-s2.0-85141821238"
"Sun M.; Chen S.","Sun, Mingbo (57164213800); Chen, Shengbo (27171613500)","57164213800; 27171613500","Deep Learning-Based Super-Resolution Reconstruction and Algorithm Acceleration of Mars Hyperspectral CRISM Data","2022","Remote Sensing","14","13","3062","","","","10.3390/rs14133062","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135907261&doi=10.3390%2frs14133062&partnerID=40&md5=12534d6f3bfcf72005a8c3f34b7e7243","In Mars exploration, hyper-spectrometry plays an important role due to its high spectral resolution. However, due to the technical difﬁculty and the data size, the spatial resolution or the coverage of hyperspectral data is often limited. This limitation can be alleviated by deep learning-based super-resolution (SR) reconstruction. But the spatial size and batch size of the input training data is limited due to the large number of spectral channels. To improve the efﬁciency of model training and SR reconstruction, a dataset based on CRISM hyperspectral data is created in this paper, and its redundancy is analyzed in both spectral and spatial spital dimensions. Compression algorithms based on data selection and PCA are used to reduce the size of the input training data. A network that can perform spatial SR and spectral enhancement is also proposed to make the network can be trained with the compressed data. With these compression algorithms and network, high-resolution data with 235 bands can be reconstructed from the low-resolution data with only 40 bands. Compared with the network trained on the original low-resolution data with 235 bands, the model training time and the SR reconstruction runtime can be reduced to 30% and 23% with practically no accuracy loss. The effectiveness of compression algorithms based on data selection also indicates that maybe not all the bands need to be transmitted from the Mars probes or be collected. Furthermore, it would, in principle, help improve the efﬁciency of satellite data transmission and simplify the design of the hyper-spectrometer. Additionally, a method for spatial dimension correlation evaluation is also proposed in this paper. The spatial compression shows that the proposed method can reﬂect the correlation of spatial texture between patches, and the model can be acceptably trained with only half of the original data. © 2022 by the authors.","Data reduction; Deep learning; Image reconstruction; Martian surface analysis; Spectral resolution; Spectroscopy; Textures; Compression algorithms; Deep learning; HyperSpectral; Hyperspectral Data; Hyperspectral image; Learning-based super-resolution; Mars exploration; Remote-sensing; Super-resolution reconstruction; Superresolution; Remote sensing","data compression; deep learning; hyperspectral image; Mars exploration; remote sensing; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85135907261"
"Liu Z.; Zhu H.; Chen Z.","Liu, Ziyu (58087753100); Zhu, Han (57221180146); Chen, Zhenzhong (57985265500)","58087753100; 57221180146; 57985265500","Adversarial Spectral Super-Resolution for Multispectral Imagery Using Spatial Spectral Feature Attention Module","2023","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","","","1","14","13","10.1109/JSTARS.2023.3238853","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147300696&doi=10.1109%2fJSTARS.2023.3238853&partnerID=40&md5=9c1fcd62e9714f69543d9e53282a0dbf","Acquiring high-quality hyperspectral imagery with high spatial and spectral resolution plays an important role in remote sensing. Due to the limited capacity of sensors, providing high spatial and spectral resolution is still a challenging issue. Spectral super-resolution (SSR) increases the spectral dimensionality of multispectral images to achieve resolution enhancement. In this paper, we propose a spectral resolution enhancement method based on the generative adversarial network (GAN) framework without introducing additional spectral responses prior. In order to adaptively rescale informative features for capturing interdependencies in the spectral and spatial dimensions, a spatial spectral feature attention module (SSFAM) is introduced. The proposed method jointly exploits spatio-spectral distribution in the hyperspectral manifold to increase spectral resolution while maintaining spatial content consistency. Experiments are conducted on both synthetic Landsat 8 and Sentinel-2 radiance data and real co-registered ALI and Hyperion (MS and HS) images, which indicates the superiority of the proposed method compared to other state-of-the-art methods. Author","Generative adversarial networks; Hyperspectral imaging; Image enhancement; Remote sensing; Spectral resolution; Adversarial learning; Attention mechanisms; Correlation; Hyper-spectral imageries; Images reconstruction; Spatial resolution; Spectral feature; Spectral super-resolution; Superresolution; Image reconstruction","adversarial learning; attention Mechanism; Cameras; Correlation; Hyperspectral imagery; Hyperspectral imaging; Image reconstruction; Sensors; Spatial resolution; spectral super-resolution; Superresolution","Article","Article in press","All Open Access; Gold Open Access","Scopus","2-s2.0-85147300696"
"Wang S.; Wang H.; She S.; Zhang Y.; Qiu Q.; Xiao Z.","Wang, Suhong (57954422400); Wang, Hongqing (57953727400); She, Shufeng (57953727500); Zhang, Yanping (57953498200); Qiu, Qingju (57953498300); Xiao, Zhifeng (36138845900)","57954422400; 57953727400; 57953727500; 57953498200; 57953498300; 36138845900","Swin-T-NFC CRFs: An encoder–decoder neural model for high-precision UAV positioning via point cloud super resolution and image semantic segmentation","2023","Computer Communications","197","","","52","60","8","10.1016/j.comcom.2022.10.011","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141319485&doi=10.1016%2fj.comcom.2022.10.011&partnerID=40&md5=99aa2405c75c8060acc54e23f19f3772","3D point cloud and remote sensing images have been the primary data types for the development of high-precision positioning systems. Equipped with a LiDAR and a camera, an Unmanned Aerial Vehicle (UAV) can explore an uncharted territory and gather both 3D scans and aerial images in real time to dynamically inspect the surroundings. However, the high cost of a high-resolution LiDAR hinders the development of the perception module of an UAV. Also, it is essential to adopt accurate image semantic segmentation (SemSeg) algorithms to better understand the sensing environment. As hardware advancement is ongoing, support from the software side is crucial. A promising strategy for cost control in building a LiDAR-based positioning system is through point cloud super-resolution (SupRes), a technique that improves the point cloud resolution via algorithms. This study investigates a deep learning-based framework that adopts a classic encoder–decoder structure for both point cloud SupRes and image SemSeg. Unlike prior studies that mainly use convolutional neural networks (CNNs) for feature extraction, our model, named Swin-T-NFC CRFs, consists of a Vision Transformer (ViT)-based encoder and a fully connected conditional random fields (FC-CRFs)-based decoder, connected via a pyramid pooling module and multiple skip connections. Moreover, both encoder and decoder are coupled with a shifted window strategy that allows cross-window connection. As such, patches from different windows of the feature map can participate in self-attention computation, leading to more powerful modeling ability. Experimental results demonstrate that our method can effectively boost the prediction accuracy, reduce the error, and consistently outperform the state-of-the-art methods on simulated/real-world point cloud datasets and the urban drone dataset version 6. © 2022 Elsevier B.V.","Antennas; Convolutional neural networks; Decoding; Deep learning; Optical radar; Optical resolving power; Remote sensing; Semantics; Signal encoding; Unmanned aerial vehicles (UAV); Aerial vehicle; Fully connected CRF; High precision positioning; Image semantics; Point cloud super-resolution; Point-clouds; Semantic segmentation; Shifted window; Superresolution; Vision transformer; Semantic Segmentation","Fully connected CRFs; High-precision positioning; Point cloud super-resolution; Shifted windows; Vision Transformer","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85141319485"
"Zhao Z.; Ren C.; Teng Q.; He X.","Zhao, Zhibo (57419279700); Ren, Chao (57207076112); Teng, Qizhi (7005503530); He, Xiaohai (9237988800)","57419279700; 57207076112; 7005503530; 9237988800","A practical super-resolution method for multi-degradation remote sensing images with deep convolutional neural networks","2022","Journal of Real-Time Image Processing","19","6","","1139","1154","15","10.1007/s11554-022-01245-9","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138184640&doi=10.1007%2fs11554-022-01245-9&partnerID=40&md5=1fd64565de0db2ce864c451a6ebcfb74","Recent studies have proved that convolutional neural networks (CNNs) have great potential for image super-resolution (SR) tasks. However, most existing methods rely on paired high-resolution (HR) and low-resolution (LR) images to train the CNN, where the LR images are routinely synthesized by applying predefined degradation operations (e.g., bicubic). Because the degradation process of LR images is usually unknown and more complex than those predefined, these methods suffer a significant performance decrease when applied to real-world SR problems. In addition, a deeper and wider network structure enables superior performance while increasing the network parameters and inference time, making it difficult to process real-time data. Inspired by the above motivations, we present an efficient two-step SR method for multi-degradation remote sensing images. Specifically, we first present a novel kernel estimation framework based on generative adversarial networks that can accurately extract the latent blur kernel from the input LR image without any image priors. We then train an efficient SR deep neural network with paired HR and corresponding LR images degraded with the generated kernels. To better balance network parameters and network performance, the densely connected attention mechanism and multi-scale feature extract blocks are introduced in the SR network by increasing the flow of feature information within the network. Extensive experiments indicate that the proposed method outperforms current methods with desired network parameters and complexity, making it feasible to enable real-time image processing. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Complex networks; Convolution; Convolutional neural networks; Deep neural networks; Image processing; Optical resolving power; Remote sensing; Convolutional neural network; High resolution; Kernel models; Low resolution images; Multi-degradation; Network parameters; Performance; Remote sensing images; Superresolution; Superresolution methods; Generative adversarial networks","Convolutional neural network; Kernel modeling; Multi-degradation; Remote sensing image; Super-resolution","Article","Final","","Scopus","2-s2.0-85138184640"
"Zamir S.W.; Arora A.; Khan S.; Hayat M.; Khan F.S.; Yang M.-H.; Shao L.","Zamir, Syed Waqas (36700800900); Arora, Aditya (57216373385); Khan, Salman (56415451600); Hayat, Munawar (55613268900); Khan, Fahad Shahbaz (36100204000); Yang, Ming-Hsuan (7404927015); Shao, Ling (55643855000)","36700800900; 57216373385; 56415451600; 55613268900; 36100204000; 7404927015; 55643855000","Learning Enriched Features for Fast Image Restoration and Enhancement","2023","IEEE Transactions on Pattern Analysis and Machine Intelligence","45","2","","1934","1948","14","10.1109/TPAMI.2022.3167175","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128308943&doi=10.1109%2fTPAMI.2022.3167175&partnerID=40&md5=315ebeff535acabaf41ecf3ff3cda7f6","Given a degraded input image, image restoration aims to recover the missing high-quality image content. Numerous applications demand effective image restoration, e.g., computational photography, surveillance, autonomous vehicles, and remote sensing. Significant advances in image restoration have been made in recent years, dominated by convolutional neural networks (CNNs). The widely-used CNN-based methods typically operate either on full-resolution or on progressively low-resolution representations. In the former case, spatial details are preserved but the contextual information cannot be precisely encoded. In the latter case, generated outputs are semantically reliable but spatially less accurate. This paper presents a new architecture with a holistic goal of maintaining spatially-precise high-resolution representations through the entire network, and receiving complementary contextual information from the low-resolution representations. The core of our approach is a multi-scale residual block containing the following key elements: (a) parallel multi-resolution convolution streams for extracting multi-scale features, (b) information exchange across the multi-resolution streams, (c) non-local attention mechanism for capturing contextual information, and (d) attention based multi-scale feature aggregation. Our approach learns an enriched set of features that combines contextual information from multiple scales, while simultaneously preserving the high-resolution spatial details. Extensive experiments on six real image benchmark datasets demonstrate that our method, named as MIRNet-v2, achieves state-of-the-art results for a variety of image processing tasks, including defocus deblurring, image denoising, super-resolution, and image enhancement. The source code and pre-trained models are available at https://github.com/swz30/MIRNetv2.  © 1979-2012 IEEE.","Color photography; Computer vision; Convolution; Image denoising; Image enhancement; Media streaming; Neural networks; Optical resolving power; Remote sensing; Restoration; And contrast enhancement; Contrast Enhancement; Deblurring; Defocus; Dual-pixel defocus deblurring; Feature representation; Features extraction; Low-light image enhancement; Low-light images; Multi-scale feature representation; Multi-scale features; Spatial resolution; Streaming medium; Superresolution; Image reconstruction","and contrast enhancement; dual-pixel defocus deblurring; image denoising; low-light image enhancement; Multi-scale feature representation; super-resolution","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85128308943"
"Guo L.; Yang R.; Zhong Z.; Zhang R.; Zhang B.","Guo, Linyang (57724842000); Yang, Runxian (57343506200); Zhong, Zhichao (57343657800); Zhang, Ran (57344092200); Zhang, Bo (57343657900)","57724842000; 57343506200; 57343657800; 57344092200; 57343657900","Target recognition method of small UAV remote sensing image based on fuzzy clustering","2022","Neural Computing and Applications","34","15","","12299","12315","16","10.1007/s00521-021-06650-y","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119293869&doi=10.1007%2fs00521-021-06650-y&partnerID=40&md5=bc5a86119692744d74e0ce679f8b674f","In order to improve the target recognition effect of small UAV (unmanned aerial vehicle) remote sensing image, this paper proposes a new super-resolution reconstruction method based on the recurrent convolutional network, which can achieve different degrees of super-resolution effect by controlling the number of cycles. Moreover, it can control the number of iterations of small UAVs with different degrees of blur and can be better adapted to the recognition scenarios of UAVs. In addition, this paper studies the target recognition method of small UAV remote sensing image, combines fuzzy clustering method to construct the intelligent remote sensing image target recognition model, combines it with the UAV structure, realizes remote sensing recognition by UAV, and designs experiments to analyze the effect of remote sensing recognition. Further, this paper improves the recognition algorithm and positioning algorithm of remote sensing image, so that recognition and positioning of UAV video remote sensing image can get better results. Finally, this paper verifies the performance of the system through simulation experiments. The research results show that the method proposed in this paper has certain reliability. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Antennas; Fuzzy clustering; Image enhancement; Optical resolving power; Remote sensing; Convolutional networks; Image-based; Recognition methods; Reconstruction method; Remote sensing images; Remote-sensing; Small unmanned aerial vehicles; Super-resolution reconstruction; Superresolution; Target recognition; Unmanned aerial vehicles (UAV)","Fuzzy clustering; Remote sensing image; Small UAV; Target recognition","Article","Final","","Scopus","2-s2.0-85119293869"
"Liu L.; Shi Z.; Zao Y.; Chen H.","Liu, Liqin (57215536317); Shi, Zhenwei (23398841900); Zao, Yifan (57224195810); Chen, Hao (57188762580)","57215536317; 23398841900; 57224195810; 57188762580","Hyperspectral Image Generation From Rgb Images With Semantic and Spatial Distribution Consistency","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","1804","1807","3","10.1109/IGARSS46834.2022.9884531","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140367502&doi=10.1109%2fIGARSS46834.2022.9884531&partnerID=40&md5=fe0b472fe1f95cd17aa232409f29172e","Generating hyperspectral images (HSI) from RGB imagery can obtain HSI with both high spatial and spectral resolution, which overcomes the limitations of imaging hardware conditions. Many HSI generation methods target learning a 3-n mapping from RGB to HSI, lacking concern of the spectral categories and spatial distribution. In this paper, we propose an HSI generation method preserving the band structure similarity and semantic information. We design an MLP based classifier and trained it on many spectra of known semantic categories. Then we use it to map the spectra to semantic space and constrain the distance between the embedding of generated spectra and that of the real ones. Meanwhile, a structure similarity loss is added to constrain the spatial information. Experiment results verified the superiority of the proposed method. © 2022 IEEE.","Image classification; Photomapping; Remote sensing; Spatial distribution; Spectroscopy; Generation method; HyperSpectral; Hyperspectral image; Hyperspectral image classification; Image generations; RGB images; Sepctral super-resolution; Spectra's; Structure similarity; Superresolution; Semantics","HSI classification; Hyperspectral Image; Image generation; Sepctral Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85140367502"
"Zhang T.; Chen H.; Chen S.; Bian C.","Zhang, Tianlin (57202676973); Chen, Hongzhen (57192534540); Chen, Shi (57204157606); Bian, Chunjiang (55598820200)","57202676973; 57192534540; 57204157606; 55598820200","Edge-enhanced efficient network for remote sensing image super-resolution","2022","International Journal of Remote Sensing","43","14","","5324","5347","23","10.1080/01431161.2022.2128924","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140207163&doi=10.1080%2f01431161.2022.2128924&partnerID=40&md5=126f3862a21d4a381fed0fc466d574b9","The super-resolution (SR) reconstruction is drawing increasing attention in remote-sensing image processing, owing to improving the spatial resolution and enriching the details of initially obtaining low-resolution (LR) images. Different from natural images, remote sensing images usually have more complex image distribution and degradation processes. Although current deep convolutional neural network (DCNN)-based approaches reach better performance by deepening the network and introducing attention mechanism, this is usually accompanied by more parameters, more computation, and more complex designs. To improve the performance and efficiency of SR reconstruction of remote sensing images, we proposed the edge-enhanced efficient network (EESR). Specifically, we design an inception-like multi-branch convolution block, named edge-enhanced convolution block (EEB), to enrich edge-aware capabilities of the network, which includes multi-order gradient extraction and other feature enhancement branches. Furthermore, re-parameterization is introduced into the inference stage of the network, aiming at boosting efficient inference. We re-parameterize the weights of EEB to the edge-enhanced convolution (EEC) via equivalent transformation to reduce the parameters and computational cost of the inference model. In addition, we construct a paired SR dataset named GF2-Port for remote sensing images with degradation simulation, based on the data of GaoFen-2 port and strait. Extensive experiments on both established and public datasets indicate that the proposed EESR outperforms other comparable approaches in terms of balancing restoration accuracy and inference efficiency. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Complex networks; Convolutional neural networks; Deep neural networks; Efficiency; Image enhancement; Image reconstruction; Optical resolving power; Remote sensing; Complex image; Image degradation; Image super resolutions; Low resolution images; Natural images; Performance; Remote sensing image processing; Remote sensing images; Spatial resolution; Super-resolution reconstruction; image analysis; image resolution; network analysis; reconstruction; remote sensing; spatiotemporal analysis; Convolution","","Article","Final","","Scopus","2-s2.0-85140207163"
"Li W.; Feng Y.; Chen Y.; Zhang L.","Li, Wanyu (57697449300); Feng, Yuchen (57937731300); Chen, Yao (57938323700); Zhang, Libao (35325855000)","57697449300; 57937731300; 57938323700; 35325855000","SD-DCRN: SALIENCY DRIVEN DOUBLE-CHANNEL RESIDUAL NETWORK FOR SUPER-RESOLUTION OF REMOTE SENSING IMAGES","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","3774","3777","3","10.1109/IGARSS46834.2022.9883346","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140383679&doi=10.1109%2fIGARSS46834.2022.9883346&partnerID=40&md5=f0cdbed1318fb6e6c806b39d5d43542f","Traditional methods of super-resolution of remote sensing images generally ignore the fact that significant areas usually have a higher demand for super-resolution compared to nonsignificant areas. According to this feature of remote sensing images, we propose a new model of super-resolutio-n based on double-channel residual dense network driven by saliency analysis. Firstly, we use a cascaded partial decoder model to obtain the saliency image of remote sensing images which contributes to distinguishing significant areas and background areas. Secondly, we adopt different super-resolution strategies for regions with different salient values and texture complexity. For the non-salient regions, we adopt the smaller number of RDBs and their internal convolution layers to save computer resources. For the salient regions, we increase the number of RDBs and layers to extract more complex features for super-resolution of the salient regions, which is conducive to the reconstruction of complex texture. Finally, the reconstructed salient regions and non-salient regions are superimposed to obtain the complete super-resolution results. Our experimental results show that the comprehensive perform of our method outperforms other super-resolution models in terms of metrics based on the peak signal-to-noise ratio and structural similarity. © 2022 IEEE.","Complex networks; Image analysis; Optical resolving power; Remote sensing; Signal to noise ratio; Textures; Dense network; Double-channel; Double-channel residual dense network; High demand; Remote sensing images; Remote-sensing; Resolution strategy; Saliency analysis; Salient regions; Superresolution; Image enhancement","double-channel residual dense network; image enhancement; Remote sensing; saliency analysis; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85140383679"
"Liu Y.; Liu F.","Liu, Yuting (57919347900); Liu, Fan (57207949715)","57919347900; 57207949715","Pansharpening Based on Convolution Sparse Representation and NSCT","2022","Journal of Taiyuan University of Technology","53","4","","713","720","7","10.16355/j.cnki.issn1007-9432tyut.2022.04.016","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139453177&doi=10.16355%2fj.cnki.issn1007-9432tyut.2022.04.016&partnerID=40&md5=9fd69d20119bbe4ee31da9a3f184b5b7","In order to make full use of the spatial detail information of remote sensing images, a remote sensing image fusion method based on convolution sparse representation and non-subsampled contourlet transform (NSCT) was proposed. First, the convolution sparse representation is used to establish a model to complete the super-resolution of image and achieve the purpose of detail enhancement. Then, the two images are fused, and the super-resolution image and panchromatic image are subjected to NSCT transformation to obtain their respective high-resolution sub-band images and low-resolution sub-band images. Appropriate methods are adopted according to the characteristics of different sub-bands. The new sub-band information is obtained by the fusion rules, and finally the NSCT inverse transform is performed to obtain fusion result. Experiments proved that the fusion image obtained by this method is superior to these of other methods in both visual effects and objective indicators. © 2022, Taiyuan University of Technology. All rights reserved.","","convolution sparse representation; fusion rules; non-subsampled contourlet transform; remote sensing image","Article","Final","","Scopus","2-s2.0-85139453177"
"Liu Y.; Teng Q.; He X.; Ren C.; Chen H.","Liu, Yixiao (57283689100); Teng, Qizhi (7005503530); He, Xiaohai (9237988800); Ren, Chao (57207076112); Chen, Honggang (57051696700)","57283689100; 7005503530; 9237988800; 57207076112; 57051696700","Multimodal Sensors Image Fusion for Higher Resolution Remote Sensing Pan Sharpening","2022","IEEE Sensors Journal","22","18","","18021","18034","13","10.1109/JSEN.2022.3195243","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139452417&doi=10.1109%2fJSEN.2022.3195243&partnerID=40&md5=d21fd6eaeac4f593de14432f77d4bf3c","Panchromatic (PAN) sensors and multispectral (MS) sensors are usually applied to remote sensing tasks. Pan sharpening is an effective image fusion method based on multimodal sensors. In pan sharpening, high-resolution (HR) PAN images from PAN sensors and corresponding low-resolution MS images from MS sensors are used to obtain the HR MS images. Normally, the ideal pan-sharpening image is a fused MS image with the same resolution as the PAN image. We hope to obtain the pan-sharpening images with higher resolution, which will not only preserve spatial structure information and spectral information from PAN images and MS images but also achieve super-resolution reconstruction. For this purpose, a novel pan-sharpening framework, called multilevel and multiscale fusion network (MLMSFN), is constructed. To our knowledge, our framework is the first work to achieve beyond the limit of existing image resolution in pan sharpening. We evaluate the effectiveness of our designed method, and the experiments testify that our method can obtain higher resolution pan-sharpening images.  © 2001-2012 IEEE.","Image fusion; Remote sensing; High resolution; Multilevel and multiscale; Multilevels; Multimodal sensor; Multispectral images; Multispectral sensors; Pan-sharpening; Sensor image fusion; Super-resolution; Superresolution; Image resolution","Multilevel and multiscale; multimodal sensors; pan sharpening; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85139452417"
"Barati Sedeh H.; Pires D.G.; Chandra N.; Gao J.; Tsvetkov D.; Terekhov P.; Kravchenko I.; Litchinitser N.","Barati Sedeh, Hooman (57214822438); Pires, Danilo G. (57192962168); Chandra, Nitish (57194199402); Gao, Jiannan (57219202206); Tsvetkov, Dmitrii (57225671064); Terekhov, Pavel (57192653586); Kravchenko, Ivan (58045258400); Litchinitser, Natalia (35597189700)","57214822438; 57192962168; 57194199402; 57219202206; 57225671064; 57192653586; 58045258400; 35597189700","Manipulation of Scattering Spectra with Topology of Light and Matter","2023","Laser and Photonics Reviews","","","","","","","10.1002/lpor.202200472","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145821732&doi=10.1002%2flpor.202200472&partnerID=40&md5=83e04050de4b9dbc5507dd6a665b914e","Structured lights, including beams carrying spin and orbital angular momenta, radially and azimuthally polarized vector beams, as well as spatiotemporal optical vortices, have attracted significant interest due to their unique amplitude, phase front, polarization, and temporal structures, enabling a variety of applications in optical and quantum communications, micromanipulation, and super-resolution imaging. In parallel, structured optical materials, metamaterials, and metasurfaces consisting of engineered unit cells—meta-atoms, opened new avenues for manipulating the flow of light and optical sensing. While several studies explored structured light effects on the individual meta-atoms, their shapes are largely limited to simple spherical geometries. However, the synergy of the structured light and complex-shaped meta-atoms has not been fully explored. In this paper, the role of the helical wavefront of Laguerre–Gaussian beams in the excitation and suppression of higher-order resonant modes inside all-dielectric meta-atoms of various shapes, aspect ratios, and orientations, is demonstrated and the excitation of various multipolar moments that are not accessible via unstructured light illumination is predicted. The presented study elucidates the role of the complex phase distribution of the incident light in shape-dependent resonant scattering, which is of utmost importance in a wide spectrum of applications ranging from remote sensing to spectroscopy. © 2023 Wiley-VCH GmbH.","Aspect ratio; Atoms; Electric excitation; Gaussian beams; Optical communication; Optical remote sensing; Polarization; High-index nanoparticle; Higher index; Mie resonance; Multipole decomposition; Multipoles; Orbital angular momentum; Radially polarized vector beams; Scattering spectra; Spin angular momentum; Structured Light; Incident light","high-index nanoparticles; Mie resonances; multipole decomposition; structured light","Article","Article in press","","Scopus","2-s2.0-85145821732"
"Tang Y.; Wang Z.-Y.","Tang, Yu (58018544200); Wang, Zi-Yi (57212589279)","58018544200; 57212589279","Research and design of image super-resolution algorithm based on attention mechanism","2022","Proceedings of SPIE - The International Society for Optical Engineering","12475","","1247507","","","","10.1117/12.2659367","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144087277&doi=10.1117%2f12.2659367&partnerID=40&md5=865443f6df4d6017f8f6566ddf6c1f89","Image super-resolution algorithm is a technology that changes the image from low-resolution to high-resolution. It is widely used in various fields, including but not limited to image compression technology, satellite remote sensing imaging, urban traffic monitoring, medical imaging and so on. At present, the method based on deep learning has a very good effect on the super-resolution processing of low-resolution images, but some algorithms still have some problems, such as the loss of detail texture of the reconstructed image, and the large gap between the reconstruction results and the computational resources. To solve the above problems, this paper proposes a network model based on channel attention mechanism. The network model consists of three parts: the first part is a shallow feature extraction block, which is composed of a convolution layer and an activation layer, which is mainly used to extract the low-level features of the input image; The second part is the deep extraction block based on the channel attention mechanism, and the depth separable convolution is added to the local residual block of this part to effectively reduce the huge parameters generated by training. This module mainly extracts the high-level features of the input image; The third part is the reconstruction module, which is used to fuse the original image features extracted from the previous two parts and output the reconstructed image. Finally, the experimental results show that using this method will effectively improve the peak signal-to-noise ratio and structural similarity index of the reconstructed image. © 2022 SPIE.","Convolutional neural networks; Deep learning; Extraction; Image compression; Image enhancement; Image reconstruction; Learning algorithms; Learning systems; Medical imaging; Optical resolving power; Remote sensing; Signal to noise ratio; Textures; Attention mechanisms; Convolutional neural network; Deep learning; Image super resolutions; Image super-resolution algorithm; Input image; Lower resolution; Network models; Reconstructed image; Super resolution algorithms; Convolution","attention mechanism; convolutional neural network; deep learning; Image super-resolution algorithm","Conference paper","Final","","Scopus","2-s2.0-85144087277"
"Xiao X.; Lu Y.","Xiao, Xiao (57937664300); Lu, Yilong (57937815500)","57937664300; 57937815500","Large Remote Sensing Image Super Resolution Using Self Attention Conditional Coordinate Network","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","3778","3781","3","10.1109/IGARSS46834.2022.9883625","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140388222&doi=10.1109%2fIGARSS46834.2022.9883625&partnerID=40&md5=3d638a94b8ed29f63050c83c6346c921","Optical imagery is one of the most important sources for model remote sensing. Super resolution of the optical data could be very useful for industry and academia. Conventional solutions from computer vision only offers super resolution on small images describing relatively smaller scene and optimized towards human perception. In this paper, we proposed a new deep learning model for large remote sensing image super resolution. By using conditional coordinate and self-attention, the model could achieve arbitrary large image super resolution task with special focus on correctness of the details. Numerical evaluation of the model is carried out based on real satellite remote sensing data. Result shows a promising performance with PSNR > 33 text{dB} and SSIM > 0.93. © 2022 IEEE.","Deep neural networks; Optical remote sensing; Deep learning; Human perception; Image super resolutions; Neural-networks; Optical data; Optical imagery; Remote sensing images; Remote-sensing; Smallest image; Superresolution; Optical resolving power","Deep Learning; Neural Networks; Super Resolution","Conference paper","Final","","Scopus","2-s2.0-85140388222"
"Shang C.; Jiang S.; Ling F.; Li X.; Zhou Y.; Du Y.","Shang, Cheng (57209801137); Jiang, Shan (57198704721); Ling, Feng (56278268300); Li, Xiaodong (55878368700); Zhou, Yadong (57207472820); Du, Yun (56420121700)","57209801137; 57198704721; 56278268300; 55878368700; 57207472820; 56420121700","Spectral-Spatial Generative Adversarial Network for Super-Resolution Land Cover Mapping With Multispectral Remotely Sensed Imagery","2023","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","16","","","522","537","15","10.1109/JSTARS.2022.3228741","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144774026&doi=10.1109%2fJSTARS.2022.3228741&partnerID=40&md5=3284eca3eb21b450a28c16cc8502de49","Super-resolution mapping (SRM) can effectively predict the spatial distribution of land cover classes within mixed pixels at a higher spatial resolution than the original remotely sensed imagery. The uncertainty of land cover fraction errors within mixed pixels is one of the most important factors affecting SRM accuracy. Studies have shown that SRM methods using deep learning techniques have significantly improved land cover mapping accuracy but have not coped well with spectral-spatial errors. This study proposes an end-to-end SRM model using a spectral-spatial generative adversarial network (SGS) with the direct input of multispectral remotely sensed imagery, which deals with spectral-spatial error. The proposed SGS comprises the following three parts: first, cube-based convolution for spectral unmixing is adopted to generate land cover fraction images. Second, a residual-in-residual dense block fully and jointly considers spectral and spatial information and reduces spectral errors. Third, a relativistic average GAN is designed as a backbone to further improve the super-resolution performance and reduce spectral-spatial errors. SGS was tested in one synthetic and two realistic experiments with multi/hyperspectral remotely sensed imagery as the input, comparing the results with those of hard classification and several classic SRM methods. The results showed that SGS performed well at reducing land cover fraction errors, reconstructing spatial details, removing unpleasant and unrealistic land cover artifacts, and eliminating false recognition.  © 2008-2012 IEEE.","Deep learning; Errors; Generative adversarial networks; Image resolution; Photomapping; Pixels; Remote sensing; Deep learning; Distribution-functions; GraphicaL model; Land cover; Land cover fraction; Layout; Remote-sensing; Spatial errors; Spatial resolution; Spectral-spatial error; Superresolution; Superresolution mapping; image resolution; land cover; machine learning; mapping; multispectral image; remote sensing; spatial analysis; spectral analysis; Distribution functions","Deep learning (DL); generative adversarial network (GAN); land cover fractions; spectral-spatial errors; super-resolution mapping (SRM)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85144774026"
"Musunuri Y.R.; Kwon O.-S.; Kung S.-Y.","Musunuri, Yogendra Rao (57191337595); Kwon, Oh-Seol (16316350900); Kung, Sun-Yuan (7102989364)","57191337595; 16316350900; 7102989364","SRODNet: Object Detection Network Based on Super Resolution for Autonomous Vehicles","2022","Remote Sensing","14","24","6270","","","","10.3390/rs14246270","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144622410&doi=10.3390%2frs14246270&partnerID=40&md5=6ccfa3680334d84c9b14bd507b2322c1","Object detection methods have been applied in several aerial and traffic surveillance applications. However, object detection accuracy decreases in low-resolution (LR) images owing to feature loss. To address this problem, we propose a single network, SRODNet, that incorporates both super-resolution (SR) and object detection (OD). First, a modified residual block (MRB) is proposed in the SR to recover the feature information of LR images, and this network was jointly optimized with YOLOv5 to benefit from hierarchical features for small object detection. Moreover, the proposed model focuses on minimizing the computational cost of network optimization. We evaluated the proposed model using standard datasets such as VEDAI-VISIBLE, VEDAI-IR, DOTA, and Korean highway traffic (KoHT), both quantitatively and qualitatively. The experimental results show that the proposed method improves the accuracy of vehicular detection better than other conventional methods. © 2022 by the authors.","Antennas; Autonomous vehicles; Feature extraction; Object recognition; Optical resolving power; Remote sensing; Autonomous Vehicles; Detection networks; Low resolution images; Modified residual block; Network-based; Object detection method; Object detection network; Objects detection; Remote sensing data; Superresolution; Object detection","autonomous vehicles; modified residual block; object detection network; remote sensing data; super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85144622410"
"Wu H.; Li W.; Zhang L.","Wu, Hanlin (57221263814); Li, Wanyu (57697449300); Zhang, Libao (35325855000)","57221263814; 57697449300; 35325855000","Cross-scale coupling network for continuous-scale image super-resolution; [跨尺度耦合的连续比例因子图像超分辨率]","2022","Journal of Image and Graphics","27","5","","1604","1615","11","10.11834/jig.210815","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130237876&doi=10.11834%2fjig.210815&partnerID=40&md5=6604714c07240acd5254052ed1e96a65","Objective: Single image super-resolution (SISR) aims to restore a high-resolution (HR) image through adding high-frequency details to its corresponding low-resolution (LR). Such application scenarios like medical imaging and remote sensing harness super-resolve LR images to multiple scales to customize the accuracy requirement. Moreover, these scales should not be restricted to integers but arbitrary positive numbers. However, a scalable super-resolution(SR) model training will leak a high computational and storage cost. Hence, it is of great significance to construct a single SR model that can process arbitrary scale factors. Deep learning technology has greatly improved the performance of SISR, but most of them are designed for specific integer scale factors. Early pre-sampling methods like the super-resolution convolutional neural network (SRCNN) can achieve continuous-scale upsampling but low computational efficiency. The post-upsampling methods use the deconvolutional or sub-pixel layer of the final step of network to obtain upsampling. However, the structure of the sub-pixel layer and deconvolutional layer is related to the scale factor, resulting in the SR network just be trained for a single scale factor each time. multi-scale deep super-resolution (MDSR) uses multiple upsampling branches to process different scale factors, but it can only super-resolve trained integer scales. Meta super-resolution (Meta-SR) is the first scale-arbitrary SR network that builds a meta-upsampling module. The meta-upsampling module uses a fully connected network to dynamically predict the weights of feature mapping in the span of the LR space and HR space. However, the Meta-SR upsampling module has high computational complexity and the number of parameters in the feature extraction part is extremely huge. Method: We illustrated a cross-scale coupling network (CSCN) for continuous-scale image SR. First, we devise a fully convolutional cross-scale coupled upsampling (CSC-Up) module to reach potential decimal scale efficient and end-to-end results. Our strategy is a continuous-scale upsampling module construction through coupling features of multiple scales. The CSC-up module first maps LR features to multiple HR spaces based on a variety of multiscales derived of multiple upsampling branches. Then, the features of multiple HR spaces are adaptively fused to obtain the SR image of the targeted scale. The CSC-Up module can be easily plugged into existing SR networks. We only need to replace the original upsampling module with our CSC-Up module to obtain a continuous-scale SR network. Second, multi-scale features extraction is beneficial to SR tasks. We facilitate a novel cross-scale convolutional (CS-Conv) layer, which can adaptively extract and couple features from multiple scales and exploit cross-scale contextual information. In addition, we utilize a feedback mechanism in the cross-scale feature learning part, using high-level features to refine low-level ones. Such a recurrent structure can increase the capacity of the network without the number of parameters generated. We train our model on the 800 images of diverse 2K resalution(DIV2K) dataset. In the training step, we randomly crop LR patches of size 32×32 as inputs. The input LR patches are generated based on the bicubic downsampling model and rotated or flipped for data augmentation in random. Our model is trained for 400 epochs with a mini-batch size of 16, and each epoch contains 1 000 iterations. The initial learning rate is 1×10-3 and halves at the 1.5×105, 2.5×105 and 3.5×105 iterations. Our demonstration is implemented based on the PyTorch framework and one Telsa V100 GPU training. Result: Our method is in comparison with two state-of-the-art (SotA) continuous-scale SR methods, Meta-EDSR(enhanced deep super-resolution) and Meta-RDN. Meanwhile, we define a new benchmark via bicubic resampling the output of a residual dense network (RDN) to the target size, named Bi-RDN. To verify the generality of our CSC-Up module, we replace the original upsampling layer of the RDN with a CSC-Up module and construct a continuous-scale RDN (CS-RDN). We also use the self-ensemble method to further improve the performance of CSCN, named CSCN+. The quantitative evaluation metrics in related to peak signal-to-noise ratio (PSNR) and structure similarity index metric (SSIM). Our CSCN obtains comparable results with Meta-RDN, and CSCN+ obtains the good results on all scale factors. CS-RDN also obtains satisfactory results, demonstrating that the proposed CSC-Up module can be well adapted to the existing SR methods and obtain satisfactory non-integer SR results. We also compare our CSCN with six SotA methods on integer scale factors, including super-resolution convolutional neural network(SRCNN), coarse-to-fine SRCNN (CFSRCNN), RDN, SR feedback network (SRFBN), iterative SR network (ISRN), and meta-RDN, respectively. Comparing the results of RDN and CS-RDN, we sort out that our CSC-Up module can achieve comparable or better results to that of a single-scale upsampling module. Meanwhile, our proposed CSCN and CS-RDN can be trained once and release a single model. Our proposed CSCN uses a simpler and more efficient continuous-scale upsampling module and obtains corresponding results with Meta-SR. CSCN+ achieves the best performance on all datasets and scales. Moreover, the number of parameters in our model is 6 M, which is only 27% of Meta-RDN (22 M). Benefiting from the feedback structure, our method can well balance the number of network parameters and model performance. Thus, our proposed CSCN and CSCN+ are prior to comparing SotAs. Conclusion: We propose a novel CSC-Up model that can be easily plugged into the existing SR networks to activate the continuous-scale SR. We also introduce a CS-Conv layer to learn scale-robust features and adopt feedback connections to design a lightweight CSCN. Compared with the previous single-scale SR networks, the proposed CSCN tends to time efficiency and suitable model storage space. © 2022, Editorial Office of Journal of Image and Graphics. All right reserved.","","Continuous-scale; Cross-scale convolution; Cross-scale coupling; Deep learning; Single image super-resolution(SISR)","Article","Final","","Scopus","2-s2.0-85130237876"
"Sha L.; Zhang W.; Ma J.; Li Z.; Sun R.; Qin M.","Sha, Lingyu (57937361200); Zhang, Wenjuan (35235960300); Ma, Jianhang (57937214000); Li, Zhen (57938098400); Sun, Ruiqi (57937801200); Qin, Meng (57937214100)","57937361200; 35235960300; 57937214000; 57938098400; 57937801200; 57937214100","Full-Spectrum Spectral Super-Resolution Method Based on LSMM","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","2390","2393","3","10.1109/IGARSS46834.2022.9883706","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140362606&doi=10.1109%2fIGARSS46834.2022.9883706&partnerID=40&md5=1b60e10c177ef2814097e643d0cb02c0","Full-spectrum remote sensing images can simultaneously provide reflectance and emission information about objects, which has great application value. Hyperspectral imaging can record hundreds of spectral bands, but due to technical and space limitations, full-spectrum hyperspectral images (HSI) are difficult to obtain. Recently, we proposed a spectral super-resolution method based on the Linear Spectral Mixing Model (LSMM), which can generate full-spectrum hyperspectral images (HSI) from multispectral images (MSI). After the spectral-unmixing of MSI, we transform MS endmembers into full-spectrum HS endmembers by spectral library. Since the abundance of MSI and HSI with the same spatial resolution is consistent, we linearly mixed the abundance and HS endmember to obtain the full spectrum HSI. In this work, we use Sentinel-2 dataset and EO-1 ALI/Hyperion images to verify the accuracy and applicability. Compared with other works, our method can simulate full-spectrum HSI of large-area scenes without real HSI, which has a certain accuracy and provides more comprehensive information for applications. © 2022 IEEE.","Optical resolving power; Remote sensing; Spectroscopy; Endmembers; Full-spectrum; HyperSpectral; Images simulations; Linear spectral mixing models; Multispectral images; Remote sensing images; Spectral super-resolution; Superresolution; Superresolution methods; Hyperspectral imaging","Full-spectrum; hyperspectral; image simulation; spectral super-resolution","Conference paper","Final","","Scopus","2-s2.0-85140362606"
"He D.; Shi Q.; Liu X.; Zhong Y.; Xia G.; Zhang L.","He, Da (57188721489); Shi, Qian (55286447700); Liu, Xiaoping (15757680000); Zhong, Yanfei (12039673900); Xia, Guisong (12781686200); Zhang, Liangpei (8359720900)","57188721489; 55286447700; 15757680000; 12039673900; 12781686200; 8359720900","Generating annual high resolution land cover products for 28 metropolises in China based on a deep super-resolution mapping network using Landsat imagery","2022","GIScience and Remote Sensing","59","1","","2036","2067","31","10.1080/15481603.2022.2142727","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142252013&doi=10.1080%2f15481603.2022.2142727&partnerID=40&md5=ef85df116808996ee4ebfba9a3ef2e99","High resolution of global land cover dynamic is indicative for understanding the influence of anthropogenic activity on environmental change. However, most of the land cover products are based on Landsat image that only has 30 m resolution, which is insufficient to distinguish the heterogenous urban structure; while very high spatial resolution image usually has low temporal resolution, which is difficult to monitor the urban dynamic. Deep-learning-driven super-resolution mapping is a prevailing way of achieving very-high-resolution land cover dynamic products in aspect of alleviating the mixed pixel problem of Landsat image. However, two limitations are obvious: 1) the fixed grid of kernel during the upsampling process favors spatial homogeneity and suppresses the learning of spatial heterogeneity of urban composition and 2) geometric or radiation variation over large spatial and long temporal extent in remote sensing images makes the super-resolution mapping approach difficult to transfer for application. Here, we attempt to solve these two limitations: 1) a progressive edge-guided super-resolution architecture is designed to allow nonuniformed kernel specific at the low-confidence edge region and intensify the learning of heterogenous compositions’ patterns and 2) an alternating optimization strategy is designed to minimize the resultant entropy and modulate the classification hyperplane to accommodate to the manifold of the discrepant region. Validation experiments are investigated based on a fine-grained and large-extent super-resolution (FLAS) dataset constructed in this study, and it is found that our approach remarkably enhances rich detailed patterns of heterogenous region and outperforms other state-of-the-art algorithms. Besides, we applied DETNet to the large spatial extent of 28 metropolises in China (>40,000 km2) and the large temporal extent of continuous 21-year (2000–2020) in Wuhan city to examine transferability. From the land cover areas variation, we find that the expansion rate of cropland is faster than the urban expansion over the past 10 years, which are gradually becoming the principal source for the encroachment of forest and lakes. From detailed urban dynamic reflected by the 21-year products, we find that urban-villages between the old city zone and the outer high-tech development zone are gradually disappeared. The captured dynamic is consistence with the urban-village renovation policy during this period, which is meant to redistribute the spatial configuration of the city for a more sustainable urban structure. We believe that the proposed method can facilitate a seamless and fine-grained observation system that can fill the weakness of the existing land cover activities and provide a brand-new insight into the urban dynamic and its underlying mechanism. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","China; environmental change; human activity; image resolution; land cover; Landsat; metropolitan area; remote sensing; satellite imagery; urban area; urban design; urbanization","deep learning; land cover product; remote sensing; super-resolution mapping; urbanization","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85142252013"
"Chen S.; Ogawa Y.; Zhao C.; Sekimoto Y.","Chen, Shenglong (57346901000); Ogawa, Yoshiki (57194137370); Zhao, Chenbo (57937294600); Sekimoto, Yoshihide (53364561900)","57346901000; 57194137370; 57937294600; 53364561900","Large-scale individual building extraction from open-source satellite imagery via super-resolution-based instance segmentation approach","2023","ISPRS Journal of Photogrammetry and Remote Sensing","195","","","129","152","23","10.1016/j.isprsjprs.2022.11.006","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145602975&doi=10.1016%2fj.isprsjprs.2022.11.006&partnerID=40&md5=1dfaab380843d90636d747819b83e324","Building footprint is a primary dataset of an urban geographic information system (GIS) database. Therefore, it is essential to establish a robust and automated framework for large-scale building extraction. However, the characteristic of remote sensing images complicates the application of the instance segmentation method based on the Mask R-CNN model, which ought to be improved toward extracting and fusing multi-scale features. Moreover, open-source satellite image datasets with wider spatial coverage and temporal resolution than high-resolution images may exhibit different coloration and resolution. This study proposes a large-scale building extraction framework based on super-resolution (SR) and instance segmentation using a relatively lower-resolution (>0.6 m) open-sourced dataset. The framework comprises four steps: color normalization and image super-resolution, scene classification, building extraction, and scene mosaicking. We took Hyogo Prefecture, Japan (19,187 km2) as a test area and extracted 1,726,006 (29.12 km2) of the 3,301,488 buildings (32.46 km2), where the number of buildings and footprint area increased by 3.0 % and 5.0 % respectively. The result indicated that the color normalization and image super-resolution could improve the visual quality of open-source satellite images and contribute to building extraction accuracy. Moreover, the improved Mask R-CNN based on Multi-Path Vision Transformer (MPViT) backbone achieved F1 scores of 0.71, 0.70, 0.81, and 0.67 for non-built-up, rural, suburban, and urban areas, respectively, which is better than those of the baseline model and other mainstream instance segmentation approaches. This study demonstrates the potential of acquiring acceptable building footprint maps from open-source satellite images, which has significant practical implications. © 2022 The Author(s)","Honshu; Hyogo; Japan; Kinki; Buildings; Extraction; Image enhancement; Image segmentation; Large dataset; Open Data; Optical resolving power; Satellite imagery; Building extraction; Building footprint; Instance segmentation; Large scale buildings; Open datum; Open-source; Remote-sensing; Satellite images; Superresolution; Transformer; building; data set; GIS; image resolution; remote sensing; satellite imagery; segmentation; Remote sensing","Building extraction; Instance segmentation; Open data; Remote sensing; Super-resolution; Transformer","Article","Final","","Scopus","2-s2.0-85145602975"
"Tang S.; Liu J.; Xie X.; Yang S.; Zeng W.; Wang X.","Tang, Shu (55262558800); Liu, Jianing (57804690500); Xie, Xianbo (57984245600); Yang, Shuli (57216083179); Zeng, Wanling (57984427700); Wang, Xinyi (57984962800)","55262558800; 57804690500; 57984245600; 57216083179; 57984427700; 57984962800","A Stage-Mutual-Affine Network for Single Remote Sensing Image Super-Resolution","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13537 LNCS","","","249","261","12","10.1007/978-3-031-18916-6_21","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142798123&doi=10.1007%2f978-3-031-18916-6_21&partnerID=40&md5=d63e54df90724a71db1264382d9e6ad6","The deep neural network (DNN) has made significant progress in the single remote sensing image super-resolution (SRSISR). The success of DNN-based SRSISR methods mainly stems from the use of the global information and the fusion of shallow features and the deep features, which fits the non-local self-similarity characteristic of the remote sensing image very well. However, for the fusion of different depth (level) features, most DNN-based SRSISR methods always use the simple skip-connection, e.g. the element-wise addition or concatenation, to transform the feature coming from preceding layers to later layers directly. To achieve sufficient complementation between different levels and capture more informative features, in this paper, we propose a stage-mutual-affine network (SMAN) for high-quality SRSISR. First, for the use of the global information, we construct a convolution-transformer dual-branch module (CTDM), in which we propose an adaptive multi-head attention (AMHA) strategy to dynamically rescale the head-wise features of the transformer for more effective global information extraction. Then, the global information is fused with the local structure information extracted by the convolution branch for more accurate recurrence information reconstruction. Second, a novel hierarchical feature aggregation module (HFAM) is proposed to effectively fuse shallow features and deep features by using a mutual affine convolution operation. The superiority of the proposed HFAM is that it achieves sufficient complementation and enhances the representational capacity of the network by extracting the global information and exploiting the interdependencies between different levels of features, effectively. Extensive experiments demonstrate the superior performance of our SMAN over the state-of-the-art methods in terms of both qualitative evaluation and quantitative metrics. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2022.","Deep neural networks; Image fusion; Information use; Optical resolving power; Remote sensing; Deep feature; Global informations; Image super resolutions; Mutual affine; Network-based; Remote sensing images; Shallow feature; Single remote sensing image super resolution; Superresolution methods; Transformer; Convolution","Deep features; Mutual affine; Shallow features; Single remote sensing image super resolution; Transformer","Conference paper","Final","","Scopus","2-s2.0-85142798123"
"Cui B.; Zhang H.; Jing W.; Liu H.; Cui J.","Cui, Binge (13103784300); Zhang, Haoqing (57445960800); Jing, Wei (57220178788); Liu, Huifang (57445094400); Cui, Jianming (57445524900)","13103784300; 57445960800; 57220178788; 57445094400; 57445524900","SRSe-Net: Super-Resolution-Based Semantic Segmentation Network for Green Tide Extraction","2022","Remote Sensing","14","3","710","","","","10.3390/rs14030710","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124280468&doi=10.3390%2frs14030710&partnerID=40&md5=005551e9d8f9c0a56487b0444d5d9e94","Due to the phenomenon of mixed pixels in low-resolution remote sensing images, the green tide spectral features with low Enteromorpha coverage are not obvious. Super-resolution technology based on deep learning can supplement more detailed information for subsequent semantic segmentation tasks. In this paper, a novel green tide extraction method for MODIS images based on super-resolution and a deep semantic segmentation network was proposed. Inspired by the idea of transfer learning, a super-resolution model (i.e., WDSR) is first pre-trained with high spatial resolution GF1-WFV images, and then the representations learned in the GF1-WFV image domain are transferred to the MODIS image domain. The improvement of remote sensing image resolution enables us to better distinguish the green tide patches from the surrounding seawater. As a result, a deep semantic segmentation network (SRSe-Net) suitable for large-scale green tide information extraction is proposed. The SRSe-Net introduced the dense connection mechanism on the basis of U-Net and replaces the convolution operations with dense blocks, which effectively obtained the detailed green tide boundary information by strengthening the propagation and reus-ing features. In addition, the SRSe-Net reducs the pooling layer and adds a bridge module in the final stage of the encoder. The experimental results show that a SRSe-Net can obtain more accurate segmentation results with fewer network parameters. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Image enhancement; Image resolution; Radiometers; Remote sensing; Semantic Web; Semantics; Green tides; Harmful algal blooms; Image domain; Lower resolution; Mixed pixel; Remote sensing images; Semantic segmentation; Spectral feature; Superresolution; Transfer learning; Semantic Segmentation","Harmful algal blooms; Remote sensing images; Super-resolution; Transfer learning","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85124280468"
"Fang S.; Guo Q.; Cao Y.","Fang, Shuai (7402422537); Guo, Qing (57796600400); Cao, Yang (57022583200)","7402422537; 57796600400; 57022583200","WDBSTF: A Weighted Dual-Branch Spatiotemporal Fusion Network Based on Complementarity between Super-Resolution and Change Prediction","2022","Remote Sensing","14","22","5883","","","","10.3390/rs14225883","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142722791&doi=10.3390%2frs14225883&partnerID=40&md5=6a93d0d75ece432938b591460771eea6","Spatiotemporal fusion (STF) is a solution to generate satellite images with both high-spatial and high-temporal resolutions. The deep learning-based STF algorithms focus on spatial dimensions to build a super-resolution (SR) model or the temporal dimensions to build a change prediction (CP) model, or the task itself to build a data-driven end-to-end model. The multi-source images used for STF usually have large spatial scale gaps and temporal spans. The large spatial scale gaps lead to poor spatial details based on a SR model; the large temporal spans make it difficult to accurately reconstruct changing areas based on a CP model. We propose a weighted dual-branch spatiotemporal fusion network based on complementarity between super-resolution and change prediction (WDBSTF), which includes the SR branch and CP branch, and a weight module representing the complementarity of the two branches. The SR branch makes full use of edge information and high-resolution reference images to obtain high-quality spatial features for image reconstruction. The CP branch decomposes complex problems via a two-layer cascaded network, changes features from the difference image, and selects high-quality spatial features through the attention mechanism. The fusion result of the CP branch has rich image details, but the fusion accuracy in the changing area is low due to the lack of detail. The SR branch has consistent and excellent fusion performances in the changing and no-changing areas, but the image details are not rich enough compared with the CP branch due to the large amplification factor. Next, a weighted network was designed to combine the advantages of the two branches to produce improved fusion results. We evaluated the performance of the WDBSTF in three representative scenarios, and both visual and quantitative evaluations demonstrate the state-of-the-art performance of our algorithm. (On the LGC dataset, our method outperforms the suboptimal method by 2.577% on SSIM. On the AHB dataset, our method outperforms the suboptimal method by 1.684% on SSIM. On the CIA dataset, our method outperforms the suboptimal method by 5.55% on SAM). © 2022 by the authors.","Deep learning; Forecasting; Image enhancement; Image fusion; Network layers; Optical resolving power; Remote sensing; Attention mechanisms; Change prediction; Edge enhancements; Image super resolutions; Remote sensing image super-resolution; Remote sensing images; Spatio-temporal fusions; Sub-optimal method; Superresolution; Weighted networks; Image reconstruction","attention mechanism; CNNs; edge enhancement; remote sensing images super-resolution; spatiotemporal fusion; weighted network","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85142722791"
"Chen S.; Lan J.; Liu H.; Chen C.; Wang X.","Chen, Shuai (57195431910); Lan, Jinhui (7102691503); Liu, Haoting (34882031200); Chen, Chengkai (58031863300); Wang, Xiaohan (57915571700)","57195431910; 7102691503; 34882031200; 58031863300; 57915571700","Helmet Wearing Detection of Motorcycle Drivers Using Deep Learning Network with Residual Transformer-Spatial Attention","2022","Drones","6","12","415","","","","10.3390/drones6120415","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144877413&doi=10.3390%2fdrones6120415&partnerID=40&md5=472c7b966720d61569b417814b73ea13","Aiming at the existing problem of unmanned aerial vehicle (UAV) aerial photography for riders’ helmet wearing detection, a novel aerial remote sensing detection paradigm is proposed by combining super-resolution reconstruction, residual transformer-spatial attention, and you only look once version 5 (YOLOv5) image classifier. Due to its small target size, significant size change, and strong motion blur in UAV aerial images, the helmet detection model for riders has weak generalization ability and low accuracy. First, a ladder-type multi-attention network (LMNet) for target detection is designed to conquer these difficulties. The LMNet enables information interaction and fusion at each stage, fully extracts image features, and minimizes information loss. Second, the Residual Transformer 3D-spatial Attention Module (RT3DsAM) is proposed in this work, which digests information from global data that is important for feature representation and final classification detection. It also builds self-attention and enhances correlation between information. Third, the rider images detected by LMNet are cropped out and reconstructed by the enhanced super-resolution generative adversarial networks (ESRGAN) to restore more realistic texture information and sharp edges. Finally, the reconstructed images of riders are classified by the YOLOv5 classifier. The results of the experiment show that, when compared with the existing methods, our method improves the detection accuracy of riders’ helmets in aerial photography scenes, with the target detection mean average precision (mAP) evaluation indicator reaching 91.67%, and the image classification top1 accuracy (TOP1 ACC) gaining 94.23%. © 2022 by the authors.","","helmet wearing detection; LMNet; residual transformer-spatial attention; super-resolution reconstruction; UAV","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85144877413"
"Wang X.; Jiang W.; Zhao L.; Liu B.; Wang Y.","Wang, Xueqin (56736285400); Jiang, Wenzong (57275223800); Zhao, Lifei (57274635800); Liu, Baodi (16319146900); Wang, Yanjiang (57223714000)","56736285400; 57275223800; 57274635800; 16319146900; 57223714000","Multi-scale feature learning network with channel self-attention for remote sensing single-image super-resolution","2022","International Journal of Remote Sensing","43","18","","6669","6688","19","10.1080/01431161.2022.2143732","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142725024&doi=10.1080%2f01431161.2022.2143732&partnerID=40&md5=599484a21dcc11d200dfec906d411094","The performance of the remote sensing image super-resolution (SR) task has been significantly improved by applying deep learning. However, previously reported methods usually require sufficient synthetic datasets obtained by bicubic downsampling for long-term training, which can get better results when the input of the test phase is still the bicubic downsampling low-resolution (LR) image. However, when the input does not meet this bicubic downsampling situation, the performance of the model will be significantly degraded, and the generated SR image will be blurred. In order to better adapt to remote sensing image SR in different situations, this paper proposes a multi-scale feature learning network with channel self-attention for remote sensing single-image super-resolution (MSFLCSA). The proposed MSFLCSA does not need any extra synthetic paired dataset but one LR input image for training. Further, MSFLCSA uses a well-designed channel self-attention multi-scale feature learning network to fully learn the repetitive multi-scale features of the input image to realize remote sensing image SR tasks. Specifically, the proposed MSFLCSA extracts features of different levels through multi-column convolutions with different receptive fields to better learn the multi-scale features inside remote sensing images. In addition, the channel self-attention module constructs the channel dependence relationship between channels, selectively emphasizes the interdependent channel features, and further improves the learned multi-scale feature representation. Various types of qualitative and quantitative experiments have validated the effectiveness of MSFLCSA. Compared with advanced technologies, MSFLCSA has achieved superior performance. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Deep learning; Image enhancement; Learning systems; Optical resolving power; Signal sampling; Channel self-attention; Down sampling; Feature learning; Image super resolutions; Learning network; Multi-scale features; Performance; Remote sensing images; Remote-sensing; Single images; image analysis; image classification; image resolution; machine learning; remote sensing; Remote sensing","Channel self-attention; image super-resolution; multi-scale feature; remote sensing image; single image","Article","Final","","Scopus","2-s2.0-85142725024"
"Wu J.; Tang Z.; Xu C.; Liu E.; Gao L.; Yan W.","Wu, Junfeng (57363647600); Tang, Zhenjie (57219742031); Xu, Congan (52164626800); Liu, Enhai (7202240258); Gao, Long (55448904500); Yan, Wenjun (57224188444)","57363647600; 57219742031; 52164626800; 7202240258; 55448904500; 57224188444","Super-resolution domain adaptation networks for semantic segmentation via pixel and output level aligning","2022","Frontiers in Earth Science","10","","974325","","","","10.3389/feart.2022.974325","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137869028&doi=10.3389%2ffeart.2022.974325&partnerID=40&md5=5f522054f7182aa4d966e24c4f5fb92a","Recently, unsupervised domain adaptation (UDA) has attracted increasing attention to address the domain shift problem in the semantic segmentation task. Although previous UDA methods have achieved promising performance, they still suffer from the distribution gaps between source and target domains, especially the resolution discrepancy in the remote sensing images. To address this problem, this study designs a novel end-to-end semantic segmentation network, namely, Super-Resolution Domain Adaptation Network (SRDA-Net). SRDA-Net can simultaneously achieve the super-resolution task and the domain adaptation task, thus satisfying the requirement of semantic segmentation for remote sensing images, which usually involve various resolution images. The proposed SRDA-Net includes three parts: a super-resolution and segmentation (SRS) model, which focuses on recovering high-resolution image and predicting segmentation map, a pixel-level domain classifier (PDC) for determining which domain the pixel belongs to, and an output-space domain classifier (ODC) for distinguishing which domain the pixel contribution is from. By jointly optimizing SRS with two classifiers, the proposed method can not only eliminate the resolution difference between source and target domains but also improve the performance of the semantic segmentation task. Experimental results on two remote sensing datasets with different resolutions demonstrate that SRDA-Net performs favorably against some state-of-the-art methods in terms of accuracy and visual quality. Code and models are available at https://github.com/tangzhenjie/SRDA-Net. Copyright © 2022 Wu, Tang, Xu, Liu, Gao and Yan.","image classification; image resolution; machine learning; mapping method; pixel; remote sensing; segmentation","deep learning; domain adaptation; remote sensing; semantic segmentation; super resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85137869028"
"Liang M.; Wang X.","Liang, Min (57226533656); Wang, XiLi (36761950100)","57226533656; 36761950100","Domain Adaptation and Super-Resolution Based Bi-Directional Semantic Segmentation Method for Remote Sensing Images","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","3500","3503","3","10.1109/IGARSS46834.2022.9883823","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140366563&doi=10.1109%2fIGARSS46834.2022.9883823&partnerID=40&md5=ed09019a58e0c031f0ef1303dc7de625","Image semantic segmentation methods based on convolutional neural network rely on supervised learning with ground truth, thus cannot be well extended to datasets that all of the data are unlabeled. Domain adaptation can solve the problem of inconsistent feature distribution between target and source domains. However, when the spatial resolution of remote sensing images in the source and target domains are not the same, those domain adaptation methods are not effective. In this paper, we propose a bi-directional semantic segmentation method based on super-resolution and domain adaption (BSSM-SRDA). With the help of generative adversarial learning, the method accomplishes semantic segmentation task from a low-resolution labelled data source domain to a high-resolution unlabelled data target domain by reducing differences in resolution and feature distribution. In addition, we propose a self-supervised learning algorithm that helps the domain discriminator to focus on those target data that has not been aligned with the source domain. The experiments demonstrate the superiority of the proposed method over other state-of-the-art methods on two remote sensing image datasets. © 2022 IEEE.","Convolutional neural networks; Learning algorithms; Learning systems; Optical resolving power; Remote sensing; Semantics; Supervised learning; Bi-directional; Domain adaptation; Feature distribution; Image semantics; Remote sensing images; Segmentation methods; Self-supervised learning; Semantic segmentation; Superresolution; Target domain; Semantic Segmentation","domain adaptation; Remote sensing image; self-supervised learning; semantic segmentation; super resolution","Conference paper","Final","","Scopus","2-s2.0-85140366563"
"Khoo J.J.D.; Lim K.H.; Pang P.K.","Khoo, John Julius Danker (57221834507); Lim, King Hann (25031784300); Pang, Po Ken (57209463435)","57221834507; 25031784300; 57209463435","Deep Learning Super Resolution of Sea Surface Temperature on South China Sea","2022","2022 International Conference on Green Energy, Computing and Sustainable Technology, GECOST 2022","","","","176","180","4","10.1109/GECOST55694.2022.10010371","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147041003&doi=10.1109%2fGECOST55694.2022.10010371&partnerID=40&md5=b0456d18133bc085bfce74991040fd90","Surface temperature is one of the key observations to analyse the greenhouse effect on the Earth. The surface of the ocean can be captured using satellite sensors and transmitted to a meteorological center for real-time analysis. The use of the deep learning paradigm in super resolution has its potential in geoscience applications to increase the data transmission latency and enhance low-quality observation from remote sensing data. In this paper, the deployment of Generative Adversarial Network (GAN) architecture is studied to apply resolution reconstruction using the South China Sea sea surface temperature data. In addition, the development of spectral normalization is added to the Enhanced Super Resolution Generative Adversarial Network (ESRGAN) architecture to improve the training mechanism of generator and discriminator. This improved ESRGAN is compared with its super resolution performance against peak signal-to-noise ratio and structural similarity index evaluation metrics. The experiment shows that the low resolution of South China Sea data can be inferred to obtain a higher resolution with a more realistic resolution as compared to the conventional upsampling approaches.  © 2022 IEEE.","Atmospheric temperature; Deep learning; Generative adversarial networks; Greenhouse effect; Network architecture; Oceanography; Optical resolving power; Remote sensing; Signal to noise ratio; Submarine geophysics; Surface waters; Deep learning; Geoscience applications; Learning paradigms; Real time analysis; Satellite sensors; Sea surface temperature; Sea surfaces; South China sea; Superresolution; Surface temperatures; Surface temperature","Deep Learning; Generative Adversarial Networks; Sea Surface Temperature; Super Resolution","Conference paper","Final","","Scopus","2-s2.0-85147041003"
"Xin L.; Li Z.; Wang S.","Xin, L. (57742773600); Li, Z. (57884534800); Wang, S. (57852799900)","57742773600; 57884534800; 57852799900","Super-resolution research on remote sensing images in the megacity based on improved srgan","2022","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","3","","603","609","6","10.5194/isprs-Annals-V-3-2022-603-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132009410&doi=10.5194%2fisprs-Annals-V-3-2022-603-2022&partnerID=40&md5=e08573da31b29a3d21c06ab392dd8075","Remote sensing images of Earth observation with high spatial resolution and high temporal resolution are critical for the application of remote sensing technology in Megacities.With the development of Smart City,more demands which are still difficult to be perfectly satisfied on the spatial resolution and temporal resolution of remote sensing images have been put forward.This paper studies the use of SRGAN which means Super-Resolution using a Generative Adversarial Network (a network structure that uses the loss function considering the perceptual loss and the adversarial loss to improve the spatial resolution of remote sensing images) for super-resolution reconstruction of single remote sensing image.It is able to enhance the spatial resolution of remote sensing images and improve the depth and breadth of remote sensing images.We adjust the reasonable parameters and network structure for our research by analysing the SRGAN in the network architecture, the perceptual loss and the adversarial loss.A super-resolution model is obtained by training with aerial photogrammetry images whose spatial resolution are 0.1 meter in Shanghai.We find the improved SRGAN has a good performance in in remote sensing image super-resolution by comparing the super-resoved images with real high-resolution images in visual perception, spatial position mapping accuracy and chromaticity spatial information. In addition, it is proved that the trained model is also effective to deal with Worldview-2 and SuperView-1 satellite images whose spatial resolution are 0.5 m. Our research shows that our method which can effectively realize the super-resolution of remote sensing images has great potential in the application of remote sensing technology such as urban mapping and changes monitoring.  © Authors 2022.","Antennas; Generative adversarial networks; Image enhancement; Mapping; Network architecture; Remote sensing; Satellite imagery; Deeplearning; High resolution satellite imagery; Megacities; Network structures; Remote sensing images; Remote sensing technology; Spatial resolution; SRGAN; Superresolution; Urban remote sensing; Image resolution","Deeplearning; High resolution satellite imagery; SRGAN; Super resolution; Urban Remote Sensing","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85132009410"
"Shi S.; Yin Z.; Wang L.","Shi, Shen (57214871713); Yin, Zengshan (14627968500); Wang, Long (57875754800)","57214871713; 14627968500; 57875754800","Dark Channel and Cross Channel Based Multi-Prior Combined Multi-Spectral Super-Resolution Algorithm; [暗通道与交叉通道多先验联合多光谱超分辨率算法]","2022","Guangxue Xuebao/Acta Optica Sinica","42","10","1010001","","","","10.3788/AOS202242.1010001","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133618222&doi=10.3788%2fAOS202242.1010001&partnerID=40&md5=95c7c047af85d0ef5b92385c32524e65","In order to solve the problem that super-resolution reconstruction of multi-spectral remote sensing images is susceptible to noise and chromatic aberration, a dark channel and cross channel based multi-prior combined multi-spectral super-resolution algorithm is proposed. First, dark channel prior and cross channel prior are introduced on the basis of traditional total variational prior. Then, based on the maximum posterior probability estimation theory, a multi-spectral super-resolution reconstruction algorithm with multi-prior combination is established. The proposed algorithm can achieve image edge information restoration, image texture information restoration, noise suppression, step effect suppression and chromatic aberration suppression, which can comprehensively improve the quality of reconstructed images. Finally, the experimental verification is carried out, and the results show that the reconstruction effect of the proposed algorithm is significantly improved compared with the existing algorithms under different signal-to-noise ratios (1040 dB) and chromatic aberrations. © 2022, Chinese Lasers Press. All right reserved.","Aberrations; Image enhancement; Image reconstruction; Image texture; Optical resolving power; Remote sensing; Signal to noise ratio; Spectroscopy; Textures; Chromatic aberration; Images processing; Multi-frame; Multi-frame super resolution; Multi-prior combination; Multi-spectral; Multispectral images; Super resolution algorithms; Super-resolution reconstruction; Superresolution; Restoration","Image processing; Multi-frame super resolution; Multi-prior combination; Multi-spectral image","Article","Final","","Scopus","2-s2.0-85133618222"
"Li Q.; Barrett B.; Williams R.; Hoey T.; Boothroyd R.","Li, Qing (57971676800); Barrett, Brian (35993628500); Williams, Richard (57198060439); Hoey, Trevor (7006871602); Boothroyd, Richard (57033931800)","57971676800; 35993628500; 57198060439; 7006871602; 57033931800","Enhancing performance of multi-temporal tropical river landform classification through downscaling approaches","2022","International Journal of Remote Sensing","43","17","","6445","6462","17","10.1080/01431161.2022.2139164","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142282905&doi=10.1080%2f01431161.2022.2139164&partnerID=40&md5=57ac70d9a645779844792f12ea8d8fa3","Multi-temporal remote sensing imagery has the potential to classify river landforms to reconstruct the evolutionary trajectory of river morphologies. Whilst open-access archives of high spatial resolution imagery are increasingly available from satellite sensors, such as Sentinel-2, there remains a fundamental challenge of maximising the utility of information in each band whilst maintaining a sufficiently fine resolution to identify landforms. Although image fusion and downscaling methods on Sentinel-2 imagery have been investigated for many years, there is a need to assess their performance for multi-temporal object-based river landform classification. This investigation first compared three downscaling methods: area to point regression kriging (ATPRK), super-resolution based on Sen2Res, and nearest neighbour resampling. We assessed performance of the three downscaling methods by accuracy, precision, recall and F1-score. ATPRK was the optimal downscaling approach, achieving an overall accuracy of 0.861. We successively engaged a set of experiments to determine an optimal training model, exploring single and multi-date scenarios. We find that not only does remote sensing imagery with better quality improve river landform classification performance, but multi-date datasets for establishing machine learning models should be considered for contributing higher classification accuracy. This paper presents a workflow for automated river landform recognition that could be applied to other tropical rivers with similar hydro-geomorphological characteristics. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Classification (of information); Image classification; Image enhancement; Image fusion; Remote sensing; Rivers; Satellite imagery; Tropics; Down-scaling; Downscaling methods; Image downscaling; Landform classification; Multi-temporal; Multitemporal classification; Performance; Remote sensing imagery; River landform; Tropical rivers; downscaling; fluvial geomorphology; image analysis; kriging; landform; machine learning; regression analysis; remote sensing; spatial resolution; Landforms","image downscaling; landform classification; multi-temporal classification; river landforms","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85142282905"
"Zhang Z.; Tian Y.; Li J.; Xu Y.","Zhang, Zili (57220548032); Tian, Yan (34873757700); Li, Jianxiang (57276192000); Xu, Yiping (8328944100)","57220548032; 34873757700; 57276192000; 8328944100","Unsupervised Remote Sensing Image Super-Resolution Guided by Visible Images","2022","Remote Sensing","14","6","1513","","","","10.3390/rs14061513","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127110948&doi=10.3390%2frs14061513&partnerID=40&md5=0ed7e6419d5eb5c39c338b7c86a32857","Remote sensing images are widely used in many applications. However, due to being limited by the sensors, it is difficult to obtain high-resolution (HR) images from remote sensing images. In this paper, we propose a novel unsupervised cross-domain super-resolution method devoted to reconstructing a low-resolution (LR) remote sensing image guided by an unpaired HR visible natural image. Therefore, an unsupervised visible image-guided remote sensing image superresolution network (UVRSR) is built. The network is divided into two learnable branches: a visible image-guided branch (VIG) and a remote sensing image-guided branch (RIG). As HR visible images can provide rich textures and sufficient high-frequency information, the purpose of VIG is to treat them as targets and make full use of their advantages in reconstruction. Specially, we first use a CycleGAN to drag the LR visible natural images to the remote sensing domain; then, we apply an SR network to upscale these simulated remote sensing domain LR images. However, the domain gap between SR remote sensing images and HR visible targets is massive. To enforce domain consistency, we propose a novel domain-ruled discriminator in the reconstruction. Furthermore, inspired by the zero-shot super-resolution network (ZSSR) to explore the internal information of remote sensing images, we add a remote sensing domain inner study to train the SR network in RIG. Sufficient experimental works show UVRSR can achieve superior results with state-of-the-art unpaired and remote sensing SR methods on several challenging remote sensing image datasets. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Discriminators; Optical resolving power; Textures; Content consistency; Cross-domain; Cross-domain super-resolution; Domain consistency; Domain-ruled discriminator; Natural images; Remote sensing images; Superresolution; Visible image; Visible natural image; Remote sensing","content consistency; cross-domain super-resolution; domain consistency; domain-ruled discriminator; remote sensing images; visible natural image","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85127110948"
"Fang S.; Guo Q.; Cao Y.; Zhang J.","Fang, Shuai (7402422537); Guo, Qing (57938173300); Cao, Yang (57022583200); Zhang, Jing (57211055913)","7402422537; 57938173300; 57022583200; 57211055913","A Two-Layers Super-Resolution Based Generation Adversarial Spatiotemporal Fusion Model","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","891","894","3","10.1109/IGARSS46834.2022.9883547","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140364937&doi=10.1109%2fIGARSS46834.2022.9883547&partnerID=40&md5=ca6a8cca3ffe4be9f310ce7f1b26e2b0","Remote sensing image spatiotemporal fusion (STF) algorism plays an important role by supplementing the lack of original high-resolution remote sensing satellite images in the study scenarios of dense time-series data. In recent years, the deep-learning-based STF algorithm has become a research hotspot with comparatively higher accuracy and robustness. However, due to the lack of sufficient high-quality images for training and the huge resolution gap between low-resolution images and high-resolution images, it is difficult to recover detailed information, especially for areas of land-cover change. In this paper, we propose a two-layers super-resolution based generation adversarial spatiotemporal fusion model(TLSRSTF) using smaller inputs to reduce pressure on data requirements and a mutual affine convolution to reduce model parameters. Specifically, we only use a pair of high-resolution and low-resolution images and a high-resolution image at any time. A spatial degradation consistency is constructed to adaptively determine the ratio of two layers of the super-resolution STF model. The quantitative and qualitative experimental results on public spatiotemporal fusion datasets demonstrate our superiority over the state-of-the-art methods. © 2022 IEEE.","Convolution; Deep learning; Image fusion; Optical resolving power; Remote sensing; Fusion model; High resolution remote sensing; High-resolution images; Low resolution images; Mutual affine convolution; Remote sensing images; Remote sensing satellites; Spatio-temporal fusions; Superresolution; Two-layer; Generative adversarial networks","Generative Adversarial Networks(GAN); Mutual Affine Convolution; Spatiotemporal Fusion","Conference paper","Final","","Scopus","2-s2.0-85140364937"
"Meng Y.; Li W.; Lei S.; Zou Z.; Shi Z.","Meng, Yapeng (57984756800); Li, Wenyuan (57204784272); Lei, Sen (57195618353); Zou, Zhengxia (56073977200); Shi, Zhenwei (23398841900)","57984756800; 57204784272; 57195618353; 56073977200; 23398841900","Large-Factor Super-Resolution of Remote Sensing Images With Spectra-Guided Generative Adversarial Networks","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5634111","","","","10.1109/TGRS.2022.3222360","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142837106&doi=10.1109%2fTGRS.2022.3222360&partnerID=40&md5=7e95902a868ae82cb77d9c293a163791","Large-factor image super-resolution (SR) is a challenging task due to the high uncertainty and incompleteness of the missing details to be recovered. In remote sensing images, the subpixel spectral mixing and semantic ambiguity of ground objects make this task even more challenging. In this article, we propose a novel method for large-factor SR of remote sensing images named spectra-guided generative adversarial networks (SpecGANs). In response to the above problems, we explore whether introducing additional hyperspectral images (HSIs) to GAN as conditional input can be the key to solving the problems. Different from previous approaches that mainly focus on improving the feature representation of a single source input, we propose a dual-branch network architecture to effectively fuse low-resolution (LR) red, green, blue (RGB) images and corresponding HSIs, which fully exploit the rich hyperspectral information as conditional semantic guidance. Due to the spectral specificity of ground objects, the semantic accuracy of the generated images is guaranteed. To further improve the visual fidelity of the generated output, we also introduce the Latent Code Bank with rich visual priors under a generative adversarial training framework so that high-resolution, detailed, and realistic images can be progressively generated. Extensive experiments show the superiority of our method over the state-of-art image SR methods in terms of both quantitative evaluation metrics and visual quality. Ablation experiments also suggest the necessity of adding spectral information and the effectiveness of our designed fusion module. To our best knowledge, we are the first to achieve up to 32x SR of remote sensing images with high visual fidelity under the premise of accurate ground object semantics. Our code can be publicly available at https://github.com/YapengMeng/SpecGAN. © 1980-2012 IEEE.","Computer vision; Deep neural networks; Generative adversarial networks; Hyperspectral imaging; Image enhancement; Network architecture; Optical resolving power; Quality control; Remote sensing; Semantics; Spectroscopy; Uncertainty analysis; Convolutional neural network; Deep convolutional neural network; Ground objects; HyperSpectral; Hyperspectral image; Images reconstruction; Remote sensing images; Superresolution; Task analysis; artificial neural network; image resolution; remote sensing; satellite imagery; spectral analysis; Image reconstruction","Deep convolutional neural networks (CNNs); generative adversarial networks (GANs); hyperspectral image (HSI); remote sensing image; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85142837106"
"Li W.; Abrashitova K.; Osnabrugge G.; Amitonova L.V.","Li, Wei (57407084700); Abrashitova, Ksenia (57193745903); Osnabrugge, Gerwin (57190004921); Amitonova, Lyubov V. (57208316205)","57407084700; 57193745903; 57190004921; 57208316205","Generative Adversarial Network for Superresolution Imaging through a Fiber","2022","Physical Review Applied","18","3","034075","","","","10.1103/PhysRevApplied.18.034075","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139278179&doi=10.1103%2fPhysRevApplied.18.034075&partnerID=40&md5=2e6eb182e6752354858101547fbdcc76","A multimode fiber represents the ultimate limit in miniaturization of imaging endoscopes. However, such a miniaturization usually comes as a cost of a low spatial resolution and a long acquisition time. Here we propose a fast superresolution-fiber-imaging technique employing compressive sensing through a multimode fiber with a data-driven machine-learning framework. We implement a generative adversarial network (GAN) to explore the sparsity inherent to the model and provide compressive reconstruction images that are not sparse in a representation basis. The proposed method outperforms other widespread compressive imaging algorithms in terms of both image quality and noise robustness. We experimentally demonstrate machine-learning ghost imaging below the diffraction limit at a sub-Nyquist speed through a thin multimode fiber probe. We believe that this work has great potential in applications in various fields ranging from biomedical imaging to remote sensing.  © 2022 authors. Published by the American Physical Society. Published by the American Physical Society under the terms of the ""https://creativecommons.org/licenses/by/4.0/""Creative Commons Attribution 4.0 International license. Further distribution of this work must maintain attribution to the author(s) and the published article's title, journal citation, and DOI.","Diffraction; Medical imaging; Miniature instruments; Multimode fibers; Optical resolving power; A.Fibres; Acquisition time; Compressive sensing; Data driven; Learning frameworks; Machine-learning; Miniaturisation; Spatial resolution; Super resolution imaging; Superresolution; Generative adversarial networks","","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85139278179"
"Lin H.; Long J.; Peng Y.; Zhou T.","Lin, Hong (58046202900); Long, Jian (57218616379); Peng, Yuanxi (7403418922); Zhou, Tong (57222290947)","58046202900; 57218616379; 7403418922; 57222290947","Hyperspectral Multispectral Image Fusion via Fast Matrix Truncated Singular Value Decomposition","2023","Remote Sensing","15","1","207","","","","10.3390/rs15010207","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145874808&doi=10.3390%2frs15010207&partnerID=40&md5=36c873f573c9b6783650e2daf5649f41","Recently, methods for obtaining a high spatial resolution hyperspectral image (HR-HSI) by fusing a low spatial resolution hyperspectral image (LR-HSI) and high spatial resolution multispectral image (HR-MSI) have become increasingly popular. However, most fusion methods require knowing the point spread function (PSF) or the spectral response function (SRF) in advance, which are uncertain and thus limit the practicability of these fusion methods. To solve this problem, we propose a fast fusion method based on the matrix truncated singular value decomposition (FTMSVD) without using the SRF, in which our first finding about the similarity between the HR-HSI and HR-MSI is utilized after matrix truncated singular value decomposition (TMSVD). We tested the FTMSVD method on two simulated data sets, Pavia University and CAVE, and a real data set wherein the remote sensing images are generated by two different spectral cameras, Sentinel 2 and Hyperion. The advantages of FTMSVD method are demonstrated by the experimental results for all data sets. Compared with the state-of-the-art non-blind methods, our proposed method can achieve more effective fusion results while reducing the fusing time to less than 1% of such methods; moreover, our proposed method can improve the PSNR value by up to 16 dB compared with the state-of-the-art blind methods. © 2022 by the authors.","Hyperspectral imaging; Image resolution; Optical transfer function; Remote sensing; Singular value decomposition; Fusion methods; High spatial resolution; High spatial resolution multispectral images; HyperSpectral; Hyperspectral imaging super-resolution; Image spatial resolution; matrix; Spectral response functions; Superresolution; Truncated singular value decomposition; Image fusion","hyperspectral imaging super-resolution; image fusion; truncated singular value decomposition","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85145874808"
"Liu H.; Qian Y.; Yang G.; Jiang H.","Liu, Hui (57193125948); Qian, Yurong (26027209500); Yang, Guangqi (57326927600); Jiang, Hao (57224819627)","57193125948; 26027209500; 57326927600; 57224819627","Super-Resolution Reconstruction Model of Spatiotemporal Fusion Remote Sensing Image Based on Double Branch Texture Transformers and Feedback Mechanism","2022","Electronics (Switzerland)","11","16","2497","","","","10.3390/electronics11162497","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137392223&doi=10.3390%2felectronics11162497&partnerID=40&md5=34cb4cff0f381e75a490fa415fdac696","High spatial-temporal resolution plays a vital role in the application of geoscience dynamic observance and prediction. However, thanks to the constraints of technology and budget, it is troublesome for one satellite detector to get high spatial-temporal resolution remote sensing images. Individuals have developed spatiotemporal image fusion technology to resolve this downside, and deep remote sensing images with spatiotemporal resolution have become a possible and efficient answer. Due to the fixed size of the receptive field of convolutional neural networks, the features extracted by convolution operations cannot capture long-range features, so the correlation of global features cannot be modeled in the deep learning process. We propose a spatiotemporal fusion model of remote sensing images to solve these problems based on a dual branch feedback mechanism and texture transformer. The model separates the network from the coarse-fine images with similar structures through the idea of double branches and reduces the dependence of images on time series. It principally merges the benefits of transformer and convolution network and employs feedback mechanism and texture transformer to extract additional spatial and temporal distinction features. The primary function of the transformer module is to learn global temporal correlations and fuse temporal features with spatial features. To completely extract additional elaborated features in several stages, we have a tendency to design a feedback mechanism module. This module chiefly refines the low-level representation through high-level info and obtains additional elaborated features when considering the temporal and spacial characteristics. We have a tendency to receive good results by comparison with four typical spatiotemporal fusion algorithms, proving our model’s superiority and robustness. © 2022 by the authors.","","detailed features; feedback mechanism; remote sensing images; spatiotemporal image fusion; texture tran-sformer","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85137392223"
"Fu Y.; Zhang X.; Wang M.","Fu, Yujia (57776361900); Zhang, Xiangrong (37076469400); Wang, Mingyang (57919947700)","57776361900; 37076469400; 57919947700","Super-Resolution Reconstruction of Remote Sensing Images Using Generative Adversarial Network with Shallow Information Enhancement","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","8529","8540","11","10.1109/JSTARS.2022.3209819","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139491442&doi=10.1109%2fJSTARS.2022.3209819&partnerID=40&md5=f967887b97beff71766faa594138489f","The super-resolution (SR) reconstruction method based on deep learning can significantly improve the spatial SR of remote sensing images. However, the current methods make insufficient use of the remote context information and channel information in shallow feature extraction, resulting in the limited effect of SR reconstruction. This article proposed a new SR reconstruction model, SIEGAN, which uses generative adversarial network with shallow information enhancement to improve the effect of SR reconstruction of remote sensing images. Similar to other generative adversarial models, SIEGAN is composed of generator and discriminator. But SIEGAN enhances the generator's ability to extract shallow information by using three different scale convolution operations. Specifically, a depthwise convolution is used to extract the local context information of each band of the image. A depthwise dilation convolution is used to capture the remote context information in the image. Finally, a 1×1 convolution is used to extract the correlation features between different channels in remote sensing images. In addition, SIEGAN uses U-Net network as its discriminator to provide detailed feedback per pixel to the generator to improve the model's ability to identify image details. And the spectral-spatial total variation loss function is introduced to ensure the spectral-spatial reliability of the reconstructed images. The experimental results on Gaofen-1 data proved that compared with the state-of-the-art models, SIEGAN has achieved better SR reconstruction performance. Furthermore, the reconstructed images by SIEGAN demonstrate better performance in land cover classification.  © 2008-2012 IEEE.","Convolution; Data mining; Deep learning; Extraction; Feature extraction; Generative adversarial networks; Image enhancement; Information use; Optical resolving power; Remote sensing; Semantics; Brain modeling; Context information; Features extraction; Images reconstruction; Multi-scale shallow information; Multi-scales; Remote sensing images; Remote-sensing; Super-resolution reconstruction; Superresolution; image classification; image resolution; network analysis; numerical model; remote sensing; satellite data; satellite imagery; spatial resolution; Image reconstruction","Generative adversarial network (GAN); multiscale shallow information; remote sensing images; super-resolution (SR) reconstruction","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85139491442"
"Mizuochi H.; Iwao K.; Yamamoto S.","Mizuochi, Hiroki (56292149100); Iwao, Koki (57564193200); Yamamoto, Satoru (57564446900)","56292149100; 57564193200; 57564446900","Thermal remote sensing over heterogeneous urban and suburban landscapes using sensor-driven super-resolution","2022","PLoS ONE","17","4 April","e0266541","","","","10.1371/journal.pone.0266541","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127715962&doi=10.1371%2fjournal.pone.0266541&partnerID=40&md5=e1adc49ece173f96515b72b355b24101","Thermal remote sensing is an important tool for monitoring regional climate and environment, including urban heat islands. However, it suffers from a relatively lower spatial resolution compared to optical remote sensing. To improve the spatial resolution, various “data-driven” image processing techniques (pan-sharpening, kernel-driven methods, and machine learning) have been developed in the previous decades. Such empirical super-resolution methods create visually appealing thermal images; however, they may sacrifice radiometric consistency because they are not necessarily sensitive to specific sensor features. In this paper, we evaluated a “sensor-driven” super-resolution approach that explicitly considers the sensor blurring process, to ensure radiometric consistency with the original thermal image during high-resolution thermal image retrieval. The sensor-driven algorithm was applied to a cloud-free Moderate Resolution Imaging Spectroradiometer (MODIS) scene of heterogeneous urban and suburban landscape that included built-up areas, low mountains with a forest, a lake, croplands, and river channels. Validation against the reference high-resolution thermal image obtained by the Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) shows that the sensor-driven algorithm can downscale the MODIS image to 250-m resolution, while maintaining a high statistical consistency with the original MODIS and ASTER images. Part of our algorithm, such as radiometric offset correction based on the Mahalanobis distance, may be integrated with other existing approaches in the future. Copyright: © 2022 Mizuochi et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","Cities; Environmental Monitoring; Hot Temperature; Remote Sensing Technology; Satellite Imagery; Article; controlled study; cropland; forest; geography; image quality; imaging algorithm; information processing; lake; mathematical computing; mathematical model; mountain; radiometry; remote sensing; river; suburban area; thermography; urban area; city; environmental monitoring; heat; procedures; satellite imagery","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85127715962"
"Yao P.; He P.; Cheng S.; Fu L.; Guo Z.; Zhao J.","Yao, Ping (57206347584); He, Peng (57192956908); Cheng, Siyuan (57261961400); Fu, Li (57215326325); Guo, Zhihao (57937820500); Zhao, Jianghong (57937520200)","57206347584; 57192956908; 57261961400; 57215326325; 57937820500; 57937520200","Dynamic Multi-Scale Network for Remote Sensing Image Super-Resolution","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","3766","3769","3","10.1109/IGARSS46834.2022.9883063","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140381484&doi=10.1109%2fIGARSS46834.2022.9883063&partnerID=40&md5=df22483202d1b5f4d2a83a58b9f8af90","Although single image super-resolution(SISR) method with deep neural network has already been explored in depth in natural images, further research on SISR in remote sensing image is still desired as aerial imagery has distinctive characteristics such as varied scenes across wide areas. In this paper, considering the scarcity of remote sensing images that may restrict the performance of data-driven neural network, we first propose a new data augmentation method, RotBlur, to promote sample diversity dramatically with a rotated cropped block at random angle. And we also design a Dynamic Multi-Scale Network(DMSN) to enhance details of low-resolution(LR) remote sensing images adaptively according to current scene of various images. Experiments performed on the UC Merced Land-Use dataset demonstrate that our DMSN outperforms several state-of-the-art methods in terms of PSNR of reconstructed images. © 2022 IEEE.","Aerial photography; Antennas; Deep neural networks; Image enhancement; Land use; Optical resolving power; Dynamic multi-scale network; Image super resolutions; Multi-scales; Natural images; Remote sensing images; Remote-sensing; Rot-blur; Single images; Superresolution; Superresolution methods; Remote sensing","Dynamic Multi-Scale Network; Remote Sensing; Rot-Blur; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85140381484"
"Lin T.-H.; Lin C.-H.","Lin, Tzu-Hsuan (57219377761); Lin, Chia-Hsiang (55967027800)","57219377761; 55967027800","Single Hyperspectral Image Super-Resolution Using Admm-Adam Theory","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","1756","1759","3","10.1109/IGARSS46834.2022.9883334","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140380152&doi=10.1109%2fIGARSS46834.2022.9883334&partnerID=40&md5=af0c247ad7c388042c6234b6ad64e8bd","In the remote sensing field, the spatial resolution of hyperspectral images (HSIs) is poor compared to RGB and multispectral images. Hence, hyperspectral image super-resolution (HISR) has become a popular topic recently. A branch of HISR methods is based on image fusion, but these methods rely on high-spatial-resolution counterpart image (e.g., multispectral image of the same scene) that is, however, not always available. Therefore, developing single hyperspectral image super-resolution (SHISR) method is highly desired. Due to the lack of abundant high-quality HSIs (i.e., big data) in satellite remote sensing, deep learning itself would be insufficient to well solve SHISR. We solve SHISR based on the recently invented ADMM-Adam learning theory, which blends the advantages from deep learning and convex optimization, thereby allowing software engineers to solve various challenging inverse problems without big data and sophisticated regularizer. For the first time, ADMM-Adam is adopted to solve SHISR in this paper, and experimental evidences well support its superiority even just with small data. © 2022 IEEE.","Big data; Deep learning; Image fusion; Image resolution; Inverse problems; Remote sensing; Spectroscopy; Adaptive moment estimation; Alternating direction method of multiplier; Alternating directions method of multipliers; Convex optimisation; Deep learning; HyperSpectral; Hyperspectral image; Image super resolutions; Moment estimation; Single image superresolution; Single images; Convex optimization","adaptive moment estimation (ADAM); alternating direction method of multipliers (ADMM); convex optimization; deep learning; Hyperspectral image; single image superresolution","Conference paper","Final","","Scopus","2-s2.0-85140380152"
"Shi M.; Gao Y.; Chen L.; Liu X.","Shi, Mengyang (57215970233); Gao, Yesheng (35589843500); Chen, Lin (57938172900); Liu, Xingzhao (35242655900)","57215970233; 35589843500; 57938172900; 35242655900","Dual-Branch Multiscale Channel Fusion Unfolding Network for Optical Remote Sensing Image Super-Resolution","2022","IEEE Geoscience and Remote Sensing Letters","19","","6519105","","","","10.1109/LGRS.2022.3221614","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142790426&doi=10.1109%2fLGRS.2022.3221614&partnerID=40&md5=3abd46fdc4d13fcee429ffd109b6d271","Single-image super-resolution (SR) technology is critical in remote sensing fields because it can effectively improve the details of target images. However, the application of deep learning is limited due to the lack of interpretability and the need for many parameters. This letter proposes an interpretable dual-branch multiscale channel fusion unfolding network (DMUNet) for optical remote sensing image (ORSI) SR. We design an unfolding network with double branches, each optimized with different strategies. Two branches focus on texture and edge reconstruction, respectively. This unfolding network follows the iteration process of the alternating direction method of multipliers (ADMM) and can learn the hyper-parameters adaptively. The functions of the two branches can complement each other. Further, to better fuse the feature maps of the two branches, a multiscale fusion module is proposed. This module can effectively fuse information between different branches, scales, and channels. It is noted that it only requires a little computation cost. Experiments on two public ORSI datasets demonstrate that our method can achieve significant performance in both quantitative evaluation and visual results. © 2004-2012 IEEE.","Deep learning; Image enhancement; Image fusion; Iterative methods; Optical resolving power; Textures; Alternating directions method of multipliers; Dual-branch; Image super resolutions; Multi-scales; Optical remote sensing; Optical remote sensing image; Remote sensing images; Single images; Superresolution; Unfoldings; design method; image analysis; image resolution; machine learning; remote sensing; texture; Optical remote sensing","Alternating direction method of multipliers (ADMM); dual-branch; optical remote sensing image (ORSI); super-resolution (SR); unfolding","Article","Final","","Scopus","2-s2.0-85142790426"
"","","","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","","","7702","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141574213&partnerID=40&md5=6208bbd91a5c058838762b6b19908055","The proceedings contain 1935 papers. The topics discussed include: interferometric analysis of the phenomena induced by the December 2018 lateral eruption of the Etna Volcano; comparison of InSar and numerical modelling for tailings dam monitoring the Cadia Failure, Australia; a study on algorithms and parameter settings for ds preprocessing part 2; planned differential interferometric SAR observations at Venus by the veritas mission; sparse unmixing using deep convolutional networks; deep blind unmixing using minimum simplex convolutional network; hyperspectral target detection using neural networks; on the transferability of single image height estimation for SAR intensity imagery; assessment of the accuracy of satellite-derived land surface temperature with IMD in-situ air temperature: a case study for Kullu region, Himachal Pradesh, India; synthetic aperture radar frequency scan for time-of-echo compression imaging mode; SAR super-resolution using physics-aware adaptive compressed sensing; bounding box regression network for building height retrieval using a single SAR image; and performance evaluation of unsupervised coregistration algorithms for multitemporal SAR images.","","","Conference review","Final","","Scopus","2-s2.0-85141574213"
"Kussul N.; Shelestov A.; Yailymova H.; Shumilo L.; Drozd S.","Kussul, Nataliia (6602485938); Shelestov, Andrii (6507365226); Yailymova, Hanna (57202424721); Shumilo, Leonid (57208256914); Drozd, Sophia (57456870300)","6602485938; 6507365226; 57202424721; 57208256914; 57456870300","Agriculture Land Appraisal with Use of Remote Sensing and Infrastructure Data","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","2785","2788","3","10.1109/IGARSS46834.2022.9884045","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140357841&doi=10.1109%2fIGARSS46834.2022.9884045&partnerID=40&md5=eb8b51ef384d51205e0438cb2db12049","1st July 2021 the law on the creation of land market start effect in Ukraine. As a result, land appraisal became cornerstone task in Ukrainian agriculture sector. The official methodology on land appraisal includes use of soil fertility characteristics combined with coefficients related to the distance to the infrastructure objects or settlements and placing of field in specific functional areas, like recreational, or areas with high level of radiation pollution. In this study we collected open source infostructure geospatial information and characteristics of fields obtained from remote sensing data-crop types and Normalized Difference Vegetation Index to build land price predictive model trained on the official land market information. This work designed to investigate potential of geo-informational technologies and remote sensing in the land appraisal use. We separated all available ground truth land price data into three groups by fields size-very small, small, medium and big. We found different relationships between field characteristics and prices. For very small fields the most important features are area, altitude, slope, bonitet and distances to elevators, villages and roads. For small fields the most important are bonitet, altitude, area and distances to cities and roads. For medium and big field's area, slope, distance to cities, roads and historical NDVI. © 2022 IEEE.","Agriculture; Commerce; Deep learning; Generative adversarial networks; Agriculture sectors; Deep learning; GAN; Land markets; Land prices; Remote-sensing; Sentinel-2; Soil fertility; Superresolution; Ukraine; Remote sensing","deep learning; GAN; Generative Adversarial Networks; Sentinel-2; super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85140357841"
"Michel J.; Vinasco-Salinas J.; Inglada J.; Hagolle O.","Michel, Julien (55437838200); Vinasco-Salinas, Juan (57850040700); Inglada, Jordi (55996140200); Hagolle, Olivier (6602243908)","55437838200; 57850040700; 55996140200; 6602243908","SEN2VENµS, a Dataset for the Training of Sentinel-2 Super-Resolution Algorithms","2022","Data","7","7","96","","","","10.3390/data7070096","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136213278&doi=10.3390%2fdata7070096&partnerID=40&md5=fe1676aa47e39d3679f1f864d1674459","Boosted by the progress in deep learning, Single Image Super-Resolution (SISR) has gained a lot of interest in the remote sensing community, who sees it as an opportunity to compensate for satellites’ ever-limited spatial resolution with respect to end users’ needs. This is especially true for Sentinel-2 because of its unique combination of resolution, revisit time, global coverage and free and open data policy. While there has been a great amount of work on network architectures in recent years, deep-learning-based SISR in remote sensing is still limited by the availability of the large training sets it requires. The lack of publicly available large datasets with the required variability in terms of landscapes and seasons pushes researchers to simulate their own datasets by means of downsampling. This may impair the applicability of the trained model on real-world data at the target input resolution. This paper presents SEN2VENµS, an open-data licensed dataset composed of 10 m and 20 m cloud-free surface reflectance patches from Sentinel-2, with their reference spatially registered surface reflectance patches at 5 m resolution acquired on the same day by the VENµS satellite. This dataset covers 29 locations on earth with a total of 132,955 patches of 256 × 256 pixels at 5 m resolution and can be used for the training and comparison of super-resolution algorithms to bring the spatial resolution of 8 of the Sentinel-2 bands up to 5 m. Data Set:https://zenodo.org/deposit/6514159. Data Set License: Etalab Open Licence Version 2.0, Creative Commons BY-NC 4.0, Creative Commons BY 4.0. © 2022 by the authors.","Deep learning; Image resolution; Network architecture; Open Data; Reflection; Remote sensing; Dataset; Image super resolutions; Open datum; Remote-sensing; Sentinel-2; Single images; Single-image super-resolution; Spatial resolution; Super resolution algorithms; Surface reflectance; Large dataset","dataset; Sentinel-2; single-image super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85136213278"
"Huan H.; Zou N.; Zhang Y.; Xie Y.; Wang C.","Huan, Hai (56122187900); Zou, Nan (57221980878); Zhang, Yi (57393500800); Xie, Yaqin (25931789100); Wang, Chao (57211834282)","56122187900; 57221980878; 57393500800; 25931789100; 57211834282","Remote sensing image reconstruction using an asymmetric multi-scale super-resolution network","2022","Journal of Supercomputing","78","17","","18524","18550","26","10.1007/s11227-022-04617-x","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131603435&doi=10.1007%2fs11227-022-04617-x&partnerID=40&md5=12377007d0c66ab5c7f902ca3c586c10","High-resolution (HR) remote sensing images demonstrate detailed geographical information; however, some remote sensing satellites are incapable of offering HR remote sensing images because of the restriction of hardware resources. The single-image super-resolution (SISR) reconstruction technique is considered as an important method to improve the resolution of remote sensing images; however, most super-resolution (SR) image reconstruction methods are not able to sufficiently extract and utilize image features, and there is much redundancy of network parameters. To address this problem, an asymmetric multi-scale super-resolution network (AMSSRN) is proposed. In this network, a residual multi-scale block (RMSB) and a residual multi-scale dilation block (RMSDB) are designed to extract both shallow and deep features from images. This asymmetric structure enables the deep features to be fully extracted while reducing the redundancy of the modules used to extract shallow features. In this work, a feature-refinement fusion (FRF) module is also established, which can make full use of extracted features to improve network performance. Experimental results indicate that compared with enhanced deep super-resolution (EDSR) network, the proposed AMSSRN can efficiently reduce the redundancy of network parameters and enhance the feature extraction capability: the maximum increases in peak signal-to-noise ratio (PSNR) and the structural similarity (SSIM) index can reach 0.23 dB and 0.9782, respectively. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Image enhancement; Image reconstruction; Optical resolving power; Redundancy; Signal to noise ratio; Asymmetric multi-scale super-resolution network; Feature refinement; Feature-refinement fusion module; Fusion modules; Multi-scales; Remote-sensing; Residual multi-scale block; Residual multi-scale dilation block; Scale blocks; Super-resolution reconstruction; Superresolution; Remote sensing","Asymmetric multi-scale super-resolution network; Feature-refinement fusion module; Remote sensing; Residual multi-scale block; Residual multi-scale dilation block; Super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85131603435"
"Aburaed N.; Alkhatib M.Q.; Marshall S.; Zabalza J.; Al Ahmad H.","Aburaed, Nour (56943462800); Alkhatib, Mohammed Q. (52463211300); Marshall, Stephen (7401823400); Zabalza, Jaime (55825361600); Al Ahmad, Hussain (57222050810)","56943462800; 52463211300; 7401823400; 55825361600; 57222050810","Complex-valued Neural Network for Hyperspectral Single Image Super Resolution","2023","Proceedings of SPIE - The International Society for Optical Engineering","12338","","123380H","","","","10.1117/12.2645086","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148039174&doi=10.1117%2f12.2645086&partnerID=40&md5=fd726c76a494cac6f722cc2a7d776366","Remote sensing applications are nowadays widely spread in various industrial fields, such as mineral and water exploration, geo-structural mapping, and natural hazards analysis. These applications require that the performance of image processing tasks, such as segmentation, object detection, and classification, to be of high accuracy. This can be achieved with relative ease if the given image has high spatial resolution as well as high spectral resolution. However, due to sensor limitations, spatial and spectral resolutions have an inherently inverse relationship and cannot be achieved simultaneously. Hyperspectral Images (HSI) have high spectral resolution, but suffer from low spatial resolution, which hinders utilizing them to their full potential. One of the most widely used approaches to enhance spatial resolution is Single Image Super Resolution (SISR) techniques. In the recent years, Deep Convolutional Neural Networks (DCNNs) have been widely used for HSI enhancement, as they have shown superiority over other traditional methods. Nonetheless, researches still aspire to enhance HSI quality further while overcoming common challenges, such as spectral distortions. Research has shown that properties of natural images can be easily captured using complex numbers. However, this has not been thoroughly investigated from the perspective of HSI SISR. In this paper, we propose a variation of a Complex Valued Neural Network (CVNN) architecture for HSI spatial enhancement. The benefits of approaching the problem from a frequency domain perspective will be answered and the proposed network will be compared to its real counterpart and other stateof- the-art approaches. The evaluation and comparison will be recorded qualitatively by visual comparison, and quantitatively using Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Spectral Angle Mapper (SAM).  © 2023 SPIE.","Complex networks; Convolutional neural networks; Deep neural networks; Frequency domain analysis; Image enhancement; Image resolution; Image segmentation; Inverse problems; Mineral exploration; Remote sensing; Signal to noise ratio; Spectral resolution; 3d-CNN; Complex-valued neural networks; High spectral resolution; HyperSpectral; Image super resolutions; Single image super resolution; Single images; Spatial enhancement; Spatial resolution; Superresolution; Object detection","3D-CNN; CNN; complex valued neural networks; Hyperspectral; single image super resolution; spatial enhancement; super resolution","Conference paper","Final","","Scopus","2-s2.0-85148039174"
"Hoque M.R.U.; Wu J.; Kwan C.; Koperski K.; Li J.","Hoque, Md Reshad Ul (57215344852); Wu, Jian (57193141747); Kwan, Chiman (7201421216); Koperski, Krzysztof (6603540174); Li, Jiang (56226550100)","57215344852; 57193141747; 7201421216; 6603540174; 56226550100","ArithFusion: An Arithmetic Deep Model for Temporal Remote Sensing Image Fusion","2022","Remote Sensing","14","23","6160","","","","10.3390/rs14236160","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143761796&doi=10.3390%2frs14236160&partnerID=40&md5=6d162c4fc285294f57b7c7e89e83f5f4","Different satellite images may consist of variable numbers of channels which have different resolutions, and each satellite has a unique revisit period. For example, the Landsat-8 satellite images have 30 m resolution in their multispectral channels, the Sentinel-2 satellite images have 10 m resolution in the pan-sharp channel, and the National Agriculture Imagery Program (NAIP) aerial images have 1 m resolution. In this study, we propose a simple yet effective arithmetic deep model for multimodal temporal remote sensing image fusion. The proposed model takes both low- and high-resolution remote sensing images at (Formula presented.) together with low-resolution images at a future time (Formula presented.) from the same location as inputs and fuses them to generate high-resolution images for the same location at (Formula presented.). We propose an arithmetic operation applied to the low-resolution images at the two time points in feature space to take care of temporal changes. We evaluated the proposed model on three modality pairs for multimodal temporal image fusion, including downsampled WorldView-2/original WorldView-2, Landsat-8/Sentinel-2, and Sentinel-2/NAIP. Experimental results show that our model outperforms traditional algorithms and recent deep learning-based models by large margins in most scenarios, achieving sharp fused images while appropriately addressing temporal changes. © 2022 by the authors.","Antennas; Deep learning; Generative adversarial networks; Image fusion; Satellite imagery; Space optics; Deep learning; Generative adversarial network; HRNet; LANDSAT; Neural-networks; Remote sensing images; Remote-sensing; Satellite images; Superresolution; U-net; Remote sensing","deep learning; generative adversarial network (GAN); HRNet; image fusion; neural networks; remote sensing; super-resolution; U-Net","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85143761796"
"Karmakar C.; Antunes A.; Datcu M.","Karmakar, Chandrabali (57220177379); Antunes, Ana (57938121000); Datcu, Mihai (7004523124)","57220177379; 57938121000; 7004523124","Achieving Information Super-resolution for Sentinel-2 NDVI Through Gaussian Process Regression","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","338","341","3","10.1109/IGARSS46834.2022.9883934","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140399561&doi=10.1109%2fIGARSS46834.2022.9883934&partnerID=40&md5=230edeb564b13a64852ca35fcafe2f9c","Super-resolution is used to recover high resolution images from low resolution images. We use this concept in a slightly different context to achieve higher quality knowledge from low resolution satellite images. The technique involves transfer learning from high to low resolution images using a Gaussian Process Regression model. We use high resolution drone images to train the model. This technique is applied in three case studies to verify the consistency of results in case of NDVI computation. However, the same technique can be applied to obtain for other application of satellite images in plant vigor assessment. © 2022 IEEE.","Gaussian distribution; Gaussian noise (electronic); Optical resolving power; Remote sensing; Drone image; Gaussian process regression; High-resolution images; Information super-resolution; Low resolution images; NDVI; Satellite images; Sentinel-2 image; Superresolution; Transfer learning; Drones","Drone Images; Gaussian Process Regression; Information Super-resolution; NDVI; Sentinel-2 Images; Transfer Learning","Conference paper","Final","","Scopus","2-s2.0-85140399561"
"Sahebkheir S.; Esmaeily A.; Saba M.","Sahebkheir, S. (58080369000); Esmaeily, A. (55576650000); Saba, M. (7006792420)","58080369000; 55576650000; 7006792420","SINGLE IMAGE SUPER RESOLUTION VIA COUPLED SPARSE AND LOW RANK DICTIONARY LEARNING","2023","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","10","4/W1-2022","","661","667","6","10.5194/isprs-annals-X-4-W1-2022-661-2023","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146943098&doi=10.5194%2fisprs-annals-X-4-W1-2022-661-2023&partnerID=40&md5=abb5116571aaebc774583f122af91b55","Limitations in imaging systems and the effects of changes in sensing have caused limitation in acquiring high resolution images such as satellite images and magnetic resonance imaging (MRI). Sparsity can reduce the noises and improve the resolution. Super resolution in medical and satellite imagery is essential because low resolution image analysis is very difficult. Sparsity techniques have significant influence on computer vision specially when the main objective is extracting the meaningful information. The success of sparsity is related to the nature of signals such as image and sound which are naturally sparse because they were founded based on Wavelet and Fourier equations. In this research, we proposed a method for restoring a clear image from the related low-resolution parts of both MRI and satellite images. First, we proposed a widespread structure for learning the couple low rank and sparse main characteristic representation. Combined optimization of the nuclear and L1 norms extracts the total low rank formation and the local patterns lodged in the image. In that case the reconstructed image will be more informative and matrix decomposition problem can recover a noisy observation matrix into an approximation of low rank matrix and a second matrix which contains some low dimensional structure. We assumed that by removing the blur and noise from these images, they would be reconstructed in the highest quality. The proposed method was compared with a variety dictionary learning approaches which addressed super resolution problem, such as tensor sparsity, Generative Bayesian and TV based methods. We demonstrated the results of applied method on MRI and satellite images, showing both visual and psnr improvements. Dealing with complex data in best manner shows the robustness of the proposed method. © Author(s) 2023. CC BY 4.0 License.","Image denoising; Image enhancement; Image reconstruction; Image resolution; Magnetic resonance imaging; Medical imaging; Satellite imagery; De-noising; Dictionary learning; Health management; Image super resolutions; Remote-sensing; Satellite images; Single images; Sparse and low ranks; Sparse representation; Superresolution; Remote sensing","Denoising; Dictionary Learning; Health Management; Image Super Resolution; Magnetic Resonance Imaging; Remote Sensing; Sparse Representation","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85146943098"
"Zhenghui Z.; Tuotuo L.; Qiyang S.; Tianjin T.; Xiaoyong W.","Zhenghui, Zhang (58103127200); Tuotuo, Li (58103127300); Qiyang, Sun (58103127400); Tianjin, Tang (57188998694); Xiaoyong, Wang (57192622861)","58103127200; 58103127300; 58103127400; 57188998694; 57192622861","Analysis of Influencing Factors of Space-based Super-resolution Imaging","2023","Proceedings of SPIE - The International Society for Optical Engineering","12557","","125571P","","","","10.1117/12.2651782","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148101267&doi=10.1117%2f12.2651782&partnerID=40&md5=675e95196866d9ecd6412a3daa00f314","Due to the diffraction limit of optical system and detector fabrication technology, super-resolution imaging has been an important means to achieve high spatial resolution in remote sensing. One super-resolution imaging method based on sub-pixels is explored in the paper, the mechanism and image reconstruction of the method are mainly studied. Taking one remote sensor as a sample, registration accuracy of homonymous points, which matters to super-resolution image reconstruction, and its influencing factors, are analyzed, showing that, the image resolution can be improved about 1.5 times when the registration accuracy of homonymous points is better than 0.12 pixels. © 2023 SPIE.","Diffraction; Image enhancement; Image resolution; Optical remote sensing; Optical systems; Pixels; Attitude accuracy; Detector fabrication; Diffraction limits; Dislocation arrangement; Registration accuracy; Relative distortion; Space-based; Sub-pixel dislocation arrangement; Sub-pixels; Super resolution imaging; Image reconstruction","attitude accuracy; registration accuracy; relative distortion; sub-pixel dislocation arrangement; Super-resolution imaging","Conference paper","Final","","Scopus","2-s2.0-85148101267"
"Luo H.; Zhang J.; Gai X.; Liu Y.","Luo, Haibo (35071632100); Zhang, Junchao (57191336646); Gai, Xingqin (56519490500); Liu, Yan (57441190000)","35071632100; 57191336646; 56519490500; 57441190000","Development status and prospects of polarization imaging technology (Invited); [偏振成像技术的发展现状与展望(特邀)]","2022","Hongwai yu Jiguang Gongcheng/Infrared and Laser Engineering","51","1","20210987","","","","10.3788/IRLA20210987","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124106908&doi=10.3788%2fIRLA20210987&partnerID=40&md5=51b8e6b9008b4999354c37bcefc7ecc4","Polarization imaging is a new way for photoelectric detection, which provides more one-dimensional information than conventional imaging systems. It has important application in the fields of industrial detection, biomedicine, earth remote sensing, modern military, aerospace and ocean. The typical applications, development history and status of polarization imaging were firstly analyzed and summarized. Then, the current methods of polarization imaging were reviewed. The latest research of polarization characteristics, transmission property, polarization imaging sensors, nonuniformity correction for division-of-focal-plane polarimeters, super resolution restoration for polarization image, and polarization information fusion approaches were introduced. Moreover, the future development direction of polarization imaging was prospected, which including focal plane polarization detector with high extinction ratio, division-of-focal-plane multispectral polarization detector, non-uniformity correction method with high precision, polarization image super resolution restoration method, and polarization information fusion(intensity image, degree of polarization and angle of polarization) so on. Copyright ©2022 Infrared and Laser Engineering. All rights reserved.","Image reconstruction; Information fusion; Optical resolving power; Photoelectricity; Polarization; Remote sensing; Restoration; Anti-interference; Development status; Focal Plane; Nonuniformity correction; Photoelectric anti-interference; Photoelectric detection; Photoelectrics; Polarization imaging; Super resolution imaging; Super-resolution restoration; Focusing","Non-uniformity correction; Photoelectric anti-interference; Photoelectric detection; Polarization imaging; Super-resolution imaging","Article","Final","","Scopus","2-s2.0-85124106908"
"La Grassa R.; Gallo I.; Re C.; Cremonese G.; Landro N.; Pernechele C.; Simioni E.; Gatti M.","La Grassa, Riccardo (57204648786); Gallo, Ignazio (7003336792); Re, Cristina (6603585550); Cremonese, Gabriele (56240953900); Landro, Nicola (57214364871); Pernechele, Claudio (6701418383); Simioni, Emanuele (55598125000); Gatti, Mattia (57903868600)","57204648786; 7003336792; 6603585550; 56240953900; 57214364871; 6701418383; 55598125000; 57903868600","An Adversarial Generative Network Designed for High-Resolution Monocular Depth Estimation from 2D HiRISE Images of Mars","2022","Remote Sensing","14","18","4619","","","","10.3390/rs14184619","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138727611&doi=10.3390%2frs14184619&partnerID=40&md5=1278e98bd7b4ca15a47aceec717c5f90","In computer vision, stereoscopy allows the three-dimensional reconstruction of a scene using two 2D images taken from two slightly different points of view, to extract spatial information on the depth of the scene in the form of a map of disparities. In stereophotogrammetry, the disparity map is essential in extracting the digital terrain model (DTM) and thus obtaining a 3D spatial mapping, which is necessary for a better analysis of planetary surfaces. However, the entire reconstruction process performed with the stereo-matching algorithm can be time consuming and can generate many artifacts. Coupled with the lack of adequate stereo coverage, it can pose a significant obstacle to 3D planetary mapping. Recently, many deep learning architectures have been proposed for monocular depth estimation, which aspires to predict the third dimension given a single 2D image, with considerable advantages thanks to the simplification of the reconstruction problem, leading to a significant increase in interest in deep models for the generation of super-resolution images and DTM estimation. In this paper, we combine these last two concepts into a single end-to-end model and introduce a new generative adversarial network solution that estimates the DTM at 4× resolution from a single monocular image, called SRDiNet (super-resolution depth image network). Furthermore, we introduce a sub-network able to apply a refinement using interpolated input images to better enhance the fine details of the final product, and we demonstrate the effectiveness of its benefits through three different versions of the proposal: SRDiNet with GAN approach, SRDiNet without adversarial network, and SRDiNet without the refinement learned network plus GAN approach. The results of Oxia Planum (the landing site of the European Space Agency’s Rosalind Franklin ExoMars rover 2023) are reported, applying the best model along all Oxia Planum tiles and releasing a 3D product enhanced by (Formula presented.). © 2022 by the authors.","Deep learning; E-learning; Generative adversarial networks; Image enhancement; Image reconstruction; Mapping; Optical resolving power; Remote sensing; Three dimensional computer graphics; 2D images; 3-D mapping; Deep learning; Depth Estimation; Depth image; Digital terrain model; Mars; Remote-sensing; Satellite images; Superresolution; Stereo image processing","3D mapping; deep learning; digital terrain model; Mars; remote sensing; satellite images; super resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85138727611"
"Yatheendradas S.; Kumar S.","Yatheendradas, Soni (8393867000); Kumar, Sujay (56122626400)","8393867000; 56122626400","A Novel Machine Learning–Based Gap-Filling of Fine-Resolution Remotely Sensed Snow Cover Fraction Data by Combining Downscaling and Regression","2022","Journal of Hydrometeorology","23","5","","637","658","21","10.1175/JHM-D-20-0111.1","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130603985&doi=10.1175%2fJHM-D-20-0111.1&partnerID=40&md5=31bb3ce239103b711c9e15e53f7d28df","Satellite-based remotely sensed observations of snow cover fraction (SCF) can have data gaps in spatially distributed coverage from sensor and orbital limitations. We mitigate these limitations in the example fine-resolution Moderate Resolution Imaging Spectroradiometer (MODIS) data by gap-filling using auxiliary 1-km datasets that either aid in downscaling from coarser-resolution (5 km) MODIS SCF wherever not fully covered by clouds, or else by themselves via regression wherever fully cloud covered. This study’s prototype predicts a 1-km version of the 500-m MOD10A1 SCF tar-get. Due to noncollocatedness of spatial gaps even across input and auxiliary datasets, we consider a recent gap-agnostic advancement of partial convolution in computer vision for both training and predictive gap-filling. Partial convolution accommodates spatially consistent gaps across the input images, effectively implementing a two-dimensional masking. To overcome reduced usable data from noncollocated spatial gaps across inputs, we innovate a fully generalized three-dimensional masking in this partial convolution. This enables a valid output value at a pixel even if only a single valid input variable and its value exist in the neighborhood covered by the convolutional filter zone centered around that pixel. Thus, our gap-agnostic technique can use significantly more examples for training (∼67%) and prediction (∼100%), instead of only less than 10% for the previous partial convolution. We train an example simple three-layer legacy super-resolution convolu-tional neural network (SRCNN) to obtain downscaling and regression component performances that are better than baseline values of either climatology or MOD10C1 SCF as relevant. Our generalized partial convolution can enable multiple Earth science applications like downscaling, regression, classification, and segmentation that were hindered by data gaps. © 2022 American Meteorological Society.","artificial neural network; data; downscaling; hydrology; machine learning; MODIS; regression analysis; remote sensing; resolution; satellite imagery; snow cover","Hydrology; Machine learning; Neural networks; Regression; Remote sensing; Satellite observations","Article","Final","","Scopus","2-s2.0-85130603985"
"Fang J.; Yang J.; Khader A.; Xiao L.","Fang, Jian (56975727800); Yang, Jingxiang (55964111200); Khader, Abdolraheem (57641899100); Xiao, Liang (9733464300)","56975727800; 55964111200; 57641899100; 9733464300","A Multiresolution Details Enhanced Attentive Dual-UNet for Hyperspectral and Multispectral Image Fusion","2023","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","16","","","638","655","17","10.1109/JSTARS.2022.3228941","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144801547&doi=10.1109%2fJSTARS.2022.3228941&partnerID=40&md5=5c7081f92e4ade76af91242e4647afad","The fusion-based super-resolution of hyperspectral images (HSIs) draws more and more attention in order to surpass the hardware constraints intrinsic to hyperspectral imaging systems in terms of spatial resolution. Low-resolution (LR)-HSI is combined with a high-resolution multispectral image (HR-MSI) to achieve HR-HSI. In this article, we propose multiresolution details enhanced attentive dual-UNet to improve the spatial resolution of HSI. The entire network contains two branches. The first branch is the wavelet detail extraction module, which performs discrete wavelet transform on MSI to extract spatial detail features and then passes through the encoding-decoding. Its main purpose is to extract the spatial features of MSI at different scales. The latter branch is the spatio-spectral fusion module, which aims to inject the detail features of the wavelet detail extraction network into the HSI to reconstruct the HSI better. Moreover, this network uses an asymmetric feature selective attention model to focus on important features at different scales. Extensive experimental results on both simulated and real data show that the proposed network architecture achieves the best performance compared with several leading HSI super-resolution methods in terms of qualitative and quantitative aspects. © 2008-2012 IEEE.","Data mining; Extraction; Hyperspectral imaging; Image coding; Image compression; Image enhancement; Image fusion; Image resolution; Independent component analysis; Network architecture; Remote sensing; Signal reconstruction; Attention mechanisms; Decoding; Discrete-wavelet-transform; Features extraction; HyperSpectral; Hyperspectral image; Multiscale; Spatial resolution; Unet; Discrete wavelet transforms","Attention mechanism; discrete wavelet transform; hyperspectral image (HSI); multiscale; UNet","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85144801547"
"Zabalza M.; Bernardini A.","Zabalza, Maialen (57759668500); Bernardini, Angela (57760233200)","57759668500; 57760233200","Super-Resolution of Sentinel-2 Images Using a Spectral Attention Mechanism","2022","Remote Sensing","14","12","2890","","","","10.3390/rs14122890","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132574283&doi=10.3390%2frs14122890&partnerID=40&md5=f954cd95a7f86ab6be7cef2167467fd4","Many visual applications require high-resolution images for an adequate interpretation of the data stored within them. In remote sensing, the appearance of satellites such as Sentinel or Landsat has facilitated the access to data thanks to their free offer of multispectral images. However, the spatial resolution of these satellites is insufficient for many tasks. Therefore, the objective of this work is to apply deep learning techniques to increase the resolution of the Sentinel-2 Read-Green-Blue-NIR (RGBN) bands from the original 10 m to 2.5 m. This means multiplying the number of pixels in the resulting image by 4, improving the perception and visual quality. In this work, we implement a state-of-the-art residual learning-based model called Super-Resolution Residual Network (SRResNet), which we train using PlanetScope-Sentinel pairs of images. Our model, named SARNet (Spectral Attention Residual Network), incorporates Residual Channel Attention Blocks (RCAB) to improve the performance of the network and the visual quality of the results. The experiments we have carried out show that SARNet offers better results than other state-of-the-art methods. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Image enhancement; Landsat; Learning systems; Optical resolving power; Attention mechanisms; Channel attention; Deep learning; Image super resolutions; Planetscope; Remote-sensing; Sentinel-2; Superresolution; Visual applications; Visual qualities; Remote sensing","channel attention; deep learning; image super-resolution; PlanetScope; remote sensing; Sentinel-2","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85132574283"
"Fu X.; Kouyama T.; Yang H.; Nakamura R.; Yoshikawa I.","Fu, Xuanchao (57937799100); Kouyama, Toru (16162149600); Yang, Hang (57482386400); Nakamura, Ryosuke (56711594400); Yoshikawa, Ichiro (35235779300)","57937799100; 16162149600; 57482386400; 56711594400; 35235779300","Toward Faster and Accurate Post-Disaster Damage Assessment: Development of End-to-End Building Damage Detection Framework with Super-Resolution Architecture","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","1588","1591","3","10.1109/IGARSS46834.2022.9883317","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140394652&doi=10.1109%2fIGARSS46834.2022.9883317&partnerID=40&md5=88b4139b5055b2af62dffafb2b08454d","Building damage detection (BDD) with satellite images has been frequently adopted as an essential reference for post-disaster rescue, whereas its timeliness is significantly impacted by the long revisit time of high-resolution remote sensing satellites. Therefore, a reliable super-resolution method which is optimized for accurate and detail BDD is fundamental one for advancing the BDD analysis even when we can use only low-resolution images after a disaster. Based on Super-Resolution Generative Adversarial Network (SRGAN) and U-Net convolutional network, an efficient and novel BDD framework is proposed in this paper for obtaining upsampled BDD results from low-resolution post-disaster images. We trained the framework using two disasters from the xBD dataset and tested three different structures. The results show that our training structure based on an end-to-end framework successfully generated super-resolution BDD maps from low-resolution images, which performed significantly better than those from a two-stage training structure. © 2022 IEEE.","Boolean functions; Deep learning; Disasters; Generative adversarial networks; Optical resolving power; Remote sensing; Building damage; Damage assessments; Deep learning; Detection framework; End to end; End-to-end network; Low resolution images; Post disasters; Superresolution; XBD dataset; Damage detection","building damage; deep learning; end-to-end network; Super-resolution; xBD dataset","Conference paper","Final","","Scopus","2-s2.0-85140394652"
"Yang M.; Fan X.; Wang Y.; Zhao H.","Yang, Mingyang (57194141001); Fan, Xuewu (10039940000); Wang, Yuming (57205550909); Zhao, Hui (56434715300)","57194141001; 10039940000; 57205550909; 56434715300","Experimental Study on the Exploration of Camera Scanning Reflective Fourier Ptychography Technology for Far-Field Imaging","2022","Remote Sensing","14","9","2264","","","","10.3390/rs14092264","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130273823&doi=10.3390%2frs14092264&partnerID=40&md5=f354ed95aacea9fb775d33c5e8fc230b","Fourier ptychography imaging is a powerful phase retrieval method that can be used to realize super-resolution. In this study, we establish a mathematical model of long-distance camera scanning based on reflective Fourier ptychography imaging. In order to guarantee the effective recovery of a high-resolution image in the experiment, we analyze the influence of laser coherence in different modes and the surface properties of diverse materials for diffused targets. For the analysis, we choose a single-mode fiber laser as the illumination source and metal materials with high diffused reflectivity as the experimental targets to ensure the validity of the experimental results. Based on the above, we emulate camera scanning with a single camera attached to an X-Y translation stage, and an experimental system with a working distance of 3310 mm is used as an example to image a fifty-cent coin. We also perform speckle analysis for rough targets and calculate the average speckle size using a normalized autocorrelation function in different positions. The method of calculating the average speckle size for everyday objects provides the premise for subsequent research on image quality evaluation; meanwhile, the coherence of the light field and the targets with high reflec-tivity under this experiment provide an application direction for the further development of the technique, such as computer vision, surveillance and remote sensing. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Cameras; Fiber lasers; Fourier transforms; Quality control; Remote sensing; Single mode fibers; Speckle; Synthetic apertures; Camera-scanning; Coherent illumination; Far-field imaging; Fourier; Fourier ptychography; High resolution; High-resolution imag-ing; Phase retrieval; Retrieval methods; Speckle size; Scanning","camera-scanning; coherent illumination; Fourier ptychography; high-resolution imag-ing; synthetic aperture","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85130273823"
"Mishra K.; Garg R.D.","Mishra, Kavach (57202200894); Garg, Rahul Dev (15044199700)","57202200894; 15044199700","Single-Frame Super-Resolution of Real-World Spaceborne Hyperspectral Data","2022","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2022-September","","","","","","10.1109/WHISPERS56178.2022.9955121","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143124003&doi=10.1109%2fWHISPERS56178.2022.9955121&partnerID=40&md5=d3048d67cd29e036d46e797625a38e64","Single-frame super-resolution (SFSR) is a well-researched issue in inverse imaging with the latest developments in the field of hyperspectral remote sensing. Paucity of open-source very high-resolution benchmark datasets restricts these algorithms from being applied to real-world scenes captured by hyperspectral sensors and the users have to contain with the outputs of the simulated trials. We attempt to narrow down this void by generating 15 m spatial resolution datasets from the 30 m spatial resolution Hyperion dataset of Ahmedabad, India through two classic SFSR algorithms: iterative back projection (IBP) and sparse representation (VSR). Visually inspecting land cover features and their spectral profiles in the super-resolved results against open-source panchromatic data shows the successful preservation of the spectral and spatial content of the original Hyperion data by VSR. No-reference image quality metrics confirm this finding although the processing time remains quite high compared to IBP.  © 2022 IEEE.","Data visualization; Hyperspectral imaging; Image resolution; Remote sensing; BRISQUE; Hyperion; Iterative back projections; NIQE; Open-source; Real-world; Single frame super resolutions; Space-borne; Sparse representation; Spatial resolution; Iterative methods","BRISQUE; Hyperion; Iterative back projection; NIQE; Sparse representation","Conference paper","Final","","Scopus","2-s2.0-85143124003"
"Peng R.; Chen J.; Liu Z.; Guo Z.","Peng, Ruyue (57912308100); Chen, Jianfei (55762222200); Liu, Zhao (57367679200); Guo, Zhimin (57724046200)","57912308100; 55762222200; 57367679200; 57724046200","Millimeter Wave Image Super Resolution Using Multichannel Depth Convolution Neural Network","2022","Progress In Electromagnetics Research M","113","","","225","235","10","10.2528/PIERM22070801","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139019431&doi=10.2528%2fPIERM22070801&partnerID=40&md5=c4f194b8e5ce367e7fcbb98284fb2aca","Benefit from the high resolution, penetrating and all-weather advantages of millimeter-wave (MMW) imaging, MMW imaging plays an important role in remote sensing, security inspection, navigation, etc. Among the MMW imaging systems, synthetic aperture imaging radiometer (SAIR) utilizes aperture synthetic technology to achieve higher imaging resolution, but the perception information is insufficient, resulting in poor image quality. To improve the image quality of passive SAIR MMW images effectively, we propose a novel multichannel depth convolutional neural network (MDCNN) in this paper. Aiming at the characteristics of original MMW images with more noise in low-frequency information and fewer features in high-frequency information, wavelet transform is incorporated into the MDCNN to obtain the high-and low-frequency components first. Then, dense residual block and skip connection technology are adopted to denoise and enhance target information in the four independent channels respectively. Finally, high-quality MMW images are synthesized by inverse wavelet transform. The simulation results show that the reconstructed images of MDCNN have better image quality (such as image contour and texture details) than other deep learning-based methods. © 2022, Electromagnetics Academy. All rights reserved.","Convolution; Convolutional neural networks; Deep learning; Image compression; Image enhancement; Image resolution; Inverse problems; Millimeter waves; Remote sensing; Synthetic apertures; Textures; Wavelet transforms; Convolution neural network; Convolutional neural network; High resolution; Image super resolutions; Millimeter-wave images; Millimeter-wave imaging; Millimetre-wave images; Millimetre-wave imaging; Multi channel; Synthetic aperture imaging radiometers; Image quality","","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85139019431"
"Vivone G.","Vivone, Gemine (42962520400)","42962520400","Multispectral and hyperspectral image fusion in remote sensing: A survey","2023","Information Fusion","89","","","405","417","12","10.1016/j.inffus.2022.08.032","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137737449&doi=10.1016%2fj.inffus.2022.08.032&partnerID=40&md5=74d053954415a6791388d5df054eb6bc","The fusion of multispectral (MS) and hyperspectral (HS) images has recently been put in the spotlight. The combination of high spatial resolution MS images with HS data showing a lower spatial resolution but a more accurate spectral resolution is the aim of these techniques. This survey presents a deep review of the literature designed for students and professionals who want to know more about the topic. The basis aspects of the MS and HS image fusion are presented and the related approaches are classified into three different classes (pansharpening-based, decomposition-based, and machine learning-based). The ending part of this survey is devoted to the description of widely used datasets for this task and the performance assessment problem, even describing open issues and drawing guidelines for future research. © 2022","Hyperspectral imaging; Image resolution; Machine learning; Remote sensing; Spectroscopy; Surveys; Hyperspectral image fusions; Low-rank; Machine-learning; Multi-spectral; Multi-spectral image fusions; Multispectral imaging; Pan-sharpening; Remote-sensing; Sparse representation; Superresolution; Image fusion","Hyperspectral imaging; Image fusion; Low-rank; Machine learning; Multispectral imaging; Pansharpening; Remote sensing; Sparse representation; Super-resolution; Tensors","Short survey","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85137737449"
"Jing H.; Shi J.; Qiu M.; Qi Y.; Zhu W.","Jing, Haizhao (57759652300); Shi, Jianglin (57207270235); Qiu, Mengzhe (57915825600); Qi, Yong (57760216500); Zhu, Wenxiao (57936774800)","57759652300; 57207270235; 57915825600; 57760216500; 57936774800","Super-resolution reconstruction method for space target images based on dense residual block-based GAN; [基于密集残差块生成对抗网络的空间目标图像超分辨率重建]","2022","Guangxue Jingmi Gongcheng/Optics and Precision Engineering","30","17","","2155","2165","10","10.37188/OPE.20223017.2155","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140292188&doi=10.37188%2fOPE.20223017.2155&partnerID=40&md5=5b447d74027034a3effeb28e9b256c36","To obtain the optical images of space targets with higher resolution and clarity， it is necessary to perform super-resolution reconstruction on the degraded images corrected by ground-based adaptive optics （AO） imaging telescopes. The image super-resolution reconstruction method based on deep learning has a fast operation speed and provides rich high-frequency detail information of the image； it has been widely used in natural， medical， and remote sensing images， among other applications. Aiming at the characteristics of spatial target AO images with a single background， limited resolution， motion blur， turbulent blur， and overexposure， this study proposes using a deep learning-based generative adversarial network （GAN） method to realize the super-resolution of spatial target AO images. For resolution reconstruction， a training set of spatial target AO simulation images is first constructed for neural network training， and a GAN super-resolution reconstruction method based on dense residual blocks is then proposed. By changing the traditional residual network to dense residual blocks， improving the network depth， and introducing a relative average loss function into the discriminator network， the discriminator becomes more robust， and the training of the generative adversarial network becomes more stable. Experiments show that the proposed method improves the peak-to-noise ratio （PSNR） and structural similarity index measure （SSIM） by more than 11.6% and 10.3%， respectively， compared with traditional interpolation super-resolution methods. In addition， it improves the PSNR and SSIM by 6.5% and 4.9% on average， respectively， compared with the deep learning-based blind image super-resolution method. The proposed method effectively realizes the clear reconstruction of a spatial target AO image， reduces the artifacts of the reconstructed image， enriches image details， and achieves a better reconstruction effect. © 2022 Guangxue Jingmi Gongcheng/Optics and Precision Engineering. All rights reserved.","Adaptive optics; Deep learning; Geometrical optics; Image enhancement; Image reconstruction; Learning systems; Medical imaging; Neural networks; Optical remote sensing; Optical resolving power; Dense residual block; Generative adversarial network（GAN）; Reconstruction method; Space object image; Space objects; Space targets; Super-resolution reconstruction; Superresolution; Superresolution methods; Target images; Generative adversarial networks","dense residual blocks; Generative Adversarial Network（GAN）; space object images; super resolution","Article","Final","","Scopus","2-s2.0-85140292188"
"Zhao Z.; Zhang Y.; Li C.; Xiao Y.; Tang J.","Zhao, Zhicheng (58086667600); Zhang, Yong (58086768000); Li, Chenglong (56699429900); Xiao, Yun (58086977500); Tang, Jin (24286986300)","58086667600; 58086768000; 56699429900; 58086977500; 24286986300","Thermal UAV Image Super-Resolution Guided by Multiple Visible Cues","2023","IEEE Transactions on Geoscience and Remote Sensing","61","","5000314","","","","10.1109/TGRS.2023.3234058","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147228017&doi=10.1109%2fTGRS.2023.3234058&partnerID=40&md5=2fffa72ec768d759231b6a9368bd2bab","Unmanned aerial vehicle (UAV) thermal-imaging has received much attention, but the insufficient image resolution caused by thermal imaging systems is still a crucial problem that limits the understanding of thermal UAV images. However, high-resolution visible images are relatively easy to access, and it is thus valuable for exploring useful information from visible image to assist thermal UAV image super-resolution (SR). In this article, we propose a novel multiconditioned guidance network (MGNet) to effectively mine the information of visible images for thermal UAV image SR. High-resolution visible UAV images usually contain salient appearance, semantic, and edge information, which plays a critical role in boosting the performance of thermal UAV image SR. Therefore, we design an effective multicue guidance module (MGM) to leverage the appearance, edge, and semantic cues from visible images to guide thermal UAV image SR. In addition, we build the first benchmark dataset for the task of thermal UAV image SR guided by visible images. It is collected by a multimodal UAV platform and composes of 1025 pairs of manually aligned visible and thermal images. Extensive experiments on the built dataset show that our MGNet can effectively leverage useful information from visible images to improve the performance of thermal UAV image SR and perform well against several state-of-the-art methods. The dataset is available at: https://github.com/mmic-lcl/Datasets-and-benchmark-code.  © 1980-2012 IEEE.","Antennas; Edge detection; Image enhancement; Image reconstruction; Image resolution; Information use; Infrared imaging; Object recognition; Remote sensing; Semantics; Unmanned aerial vehicles (UAV); Aerial vehicle; Feature modulation; Features extraction; Image edge detection; Image super resolutions; Images reconstruction; Multiple visible cue; Remote-sensing; Swin transformer; Task analysis; Thermal image super-resolution; Thermal images; Unmanned aerial vehicle; data set; image resolution; imaging method; unmanned vehicle; Feature extraction","Feature modulation; multiple visible cues; remote sensing; swin transformer; thermal image super-resolution (SR); unmanned aerial vehicle (UAV)","Article","Final","","Scopus","2-s2.0-85147228017"
"Sdraka M.; Papoutsis I.; Psomas B.; Vlachos K.; Ioannidis K.; Karantzalos K.; Gialampoukidis I.; Vrochidis S.","Sdraka, Maria (57209617754); Papoutsis, Ioannis (56763995400); Psomas, Bill (57221267044); Vlachos, Konstantinos (57735803400); Ioannidis, Konstantinos (54890480200); Karantzalos, Konstantinos (6507214354); Gialampoukidis, Ilias (55863740200); Vrochidis, Stefanos (23052810300)","57209617754; 56763995400; 57221267044; 57735803400; 54890480200; 6507214354; 55863740200; 23052810300","Deep Learning for Downscaling Remote Sensing Images: Fusion and super-resolution","2022","IEEE Geoscience and Remote Sensing Magazine","10","3","","202","255","53","10.1109/MGRS.2022.3171836","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131718940&doi=10.1109%2fMGRS.2022.3171836&partnerID=40&md5=9cfc534a903fe2cac7ba6fda6d5dc83a","The past few years have seen an accelerating integration of deep learning (DL) techniques into various remote sensing (RS) applications, highlighting their power to adapt and achieving unprecedented advancements. In the present review, we provide an exhaustive exploration of the DL approaches proposed specifically for the spatial downscaling of RS imagery. A key contribution of our work is the presentation of the major architectural components and models, metrics, and data sets available for this task as well as the construction of a compact taxonomy for navigating through the various methods. Furthermore, we analyze the limitations of the current modeling approaches and provide a brief discussion on promising directions for image enhancement, following the paradigm of general computer vision (CV) practitioners and researchers as a source of inspiration and constructive insight. © 2013 IEEE.","Deep learning; Remote sensing; Architectural components; Architectural modeling; Down-scaling; Learning approach; Learning techniques; Power; Remote sensing applications; Remote sensing imagery; Remote sensing images; Superresolution; computer vision; downscaling; exploration; learning; remote sensing; Image enhancement","","Article","Final","","Scopus","2-s2.0-85131718940"
"Li J.; Chan W.K.","Li, Jiahao (57220582702); Chan, Wai Kin (7403918514)","57220582702; 7403918514","Super-Resolution Virtual Scene of Flight Simulation Based on Convolutional Neural Networks","2023","Lecture Notes on Data Engineering and Communications Technologies","150","","","138","147","9","10.1007/978-3-031-17548-0_13","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139459114&doi=10.1007%2f978-3-031-17548-0_13&partnerID=40&md5=5b48fbc5094035c45045500c1f963180","We propose a method to establish super-resolution (SR) virtual scenes based on multi-spectral remote sensing images. Multi-spectral remote sensing images are processed, then the SR scenes are realized based on the convolutional neural network (CNN) with a special training set. The results show that the training set proposed in this paper can improve the generalization ability of CNN in processing remote sensing images, and different operation sequences can significantly affect the restoration quality of images. The terrain model is established in the physics engine based on the elevation data. Moreover, the flight simulation software with real-time SR virtual scenes is designed and implemented. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Computer software; Convolution; Convolutional neural networks; Flight simulators; Image enhancement; Remote sensing; Convolutional neural network; Flight simulation; Generalization ability; Multi-spectral; Operation sequences; Remote sensing images; Scene-based; Superresolution; Training sets; Virtual scenes; Optical resolving power","CNN; Multi-spectral; Super-resolution; Virtual scene","Book chapter","Final","","Scopus","2-s2.0-85139459114"
"Zhen L.; Liang W.","Zhen, Longxia (57909483000); Liang, Wei (57909904400)","57909483000; 57909904400","Planning and Design Method of Multiangle Ecological Building Edge Space under the Background of Rural Revitalization","2022","Mathematical Problems in Engineering","2022","","2848164","","","","10.1155/2022/2848164","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138848714&doi=10.1155%2f2022%2f2848164&partnerID=40&md5=3b53a982a4397b53cb000fa253675457","Under the background of rural revitalization, in order to realize the planning and design of ecological building edge space, a multi-perspective ecological building edge space planning and design method based on remote sensing image edge segmentation is proposed. The remote sensing visual detection of ecological buildings is realized by fusing multiscale features and multisource scene remote sensing images, and the extracted remote sensing image feature points are calibrated to extract the location information, texture features, super-resolution edge information features, and different levels of change features of the spatial distribution of the edge of ecological buildings. The background difference detection model of an ecological building remote sensing image is established, and the distance of the centroid of the corresponding level is calculated through frame dynamic planning and differential image clustering. Combined with the edge contour detection method of ecological building remote sensing image, the edge space planning and design are realized. The simulation results show that this method has higher accuracy in planning and better accuracy in detecting the contour of ecological building edge space and improves the dynamic planning and positioning ability of multi-perspective ecological building edge space distribution. © 2022 Longxia Zhen and Wei Liang.","Architectural design; Ecology; Image segmentation; Space optics; Textures; Design method; Dynamic planning; Ecological buildings; Multi angle; Multi-perspective; Planning and design; Planning method; Remote sensing images; Space design; Space planning; Remote sensing","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85138848714"
"Mei S.; Geng Y.; Hou J.; Du Q.","Mei, Shaohui (25822578400); Geng, Yunhao (57210926292); Hou, Junhui (36989331100); Du, Qian (7202060063)","25822578400; 57210926292; 36989331100; 7202060063","Learning hyperspectral images from RGB images via a coarse-to-fine CNN","2022","Science China Information Sciences","65","5","152102","","","","10.1007/s11432-020-3102-9","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114675716&doi=10.1007%2fs11432-020-3102-9&partnerID=40&md5=6d506bb4fc4d09700964f82ea896165e","Hyperspectral remote sensing is well-known for its extraordinary spectral distinguishability to discriminate different materials. However, the cost of hyperspectral image (HSI) acquisition is much higher compared to traditional RGB imaging. In addition, spatial and temporal resolutions are sacrificed to obtain very high spectral resolution owing to the limitations of sensor technologies. Therefore, in this paper, HSIs are reconstructed using easily acquired RGB images and a convolutional neural network (CNN). As a result, high spatial and temporal resolution RGB images can be inherited to HSIs. Specifically, a two-stage CNN, referred to as the spectral super-resolution network (SSR-Net), is designed to learn the transformation model between RGB images and HSIs from training data, including a band prediction network (BP-Net) to estimate hyperspectral bands from RGB images and a refinement network (RF-Net) to further reduce spectral distortion in the band prediction step. As a result, the learned joint features in the proposed SSR-Net can directly predict HSIs from their corresponding scenes in RGB images without prior knowledge. Experimental results obtained on several benchmark datasets demonstrate that the proposed SSR-Net outperforms several state-of-the-art methods by ensuring higher quality in HSI reconstruction, and significantly improves the performance of traditional RGB images in classification. © 2021, Science China Press and Springer-Verlag GmbH Germany, part of Springer Nature.","Backpropagation; Benchmarking; Classification (of information); Convolutional neural networks; Forecasting; Hyperspectral imaging; Image acquisition; Image reconstruction; Metadata; Remote sensing; Spectral resolution; Spectroscopy; Benchmark datasets; High spectral resolution; Hyperspectral remote sensing; Sensor technologies; Spatial and temporal resolutions; Spectral distortions; State-of-the-art methods; Transformation model; Image enhancement","convolutional neural network; deep learning; hyperspectral; reconstruction","Article","Final","","Scopus","2-s2.0-85114675716"
"Guo M.; Zhang Z.; Liu H.; Huang Y.","Guo, Mingqiang (34872040100); Zhang, Zeyuan (57567072200); Liu, Heng (57022065500); Huang, Ying (57013696500)","34872040100; 57567072200; 57022065500; 57013696500","NDSRGAN: A Novel Dense Generative Adversarial Network for Real Aerial Imagery Super-Resolution Reconstruction","2022","Remote Sensing","14","7","1574","","","","10.3390/rs14071574","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127852163&doi=10.3390%2frs14071574&partnerID=40&md5=3101b5c6877bde898c09b50c7a40375b","In recent years, more and more researchers have used deep learning methods for super-resolution reconstruction and have made good progress. However, most of the existing super-resolution reconstruction models generate low-resolution images for training by downsampling high-resolution images through bicubic interpolation, and the models trained from these data have poor reconstruction results on real-world low-resolution images. In the field of unmanned aerial vehicle (UAV) aerial photography, the use of existing super-resolution reconstruction models in reconstructing real-world low-resolution aerial images captured by UAVs is prone to producing some artifacts, texture detail distortion and other problems, due to compression and fusion processing of the aerial images, thereby resulting in serious loss of texture detail in the obtained low-resolution aerial images. To address this problem, this paper proposes a novel dense generative adversarial network for real aerial imagery super-resolution reconstruction (NDSRGAN), and we produce image datasets with paired high-and low-resolution real aerial remote sensing images. In the generative network, we use a multilevel dense network to connect the dense connections in a residual dense block. In the discriminative network, we use a matrix mean discriminator that can discriminate the generated images locally, no longer discriminating the whole input image using a single value but instead in chunks of regions. We also use smoothL1 loss instead of the L1 loss used in most existing super-resolution models, to accelerate the model convergence and reach the global optimum faster. Compared with traditional models, our model can better utilise the feature information in the original image and discriminate the image in patches. A series of experiments is conducted with real aerial imagery datasets, and the results show that our model achieves good performance on quantitative metrics and visual perception. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Aerial photography; Antennas; Deep learning; Generative adversarial networks; Image reconstruction; Optical resolving power; Textures; Unmanned aerial vehicles (UAV); Aerial imagery; Aerial images; Deep learning; Down sampling; Learning methods; Low resolution images; Lower resolution; Real-world; Remote-sensing; Super-resolution reconstruction; Remote sensing","aerial imagery; deep learning; generative adversarial network; remote sensing; super-resolution reconstruction","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85127852163"
"Karatsiolis S.; Padubidri C.; Kamilaris A.","Karatsiolis, Savvas (55569345400); Padubidri, Chirag (57222362784); Kamilaris, Andreas (36189564000)","55569345400; 57222362784; 36189564000","Exploiting Digital Surface Models for Inferring Super-Resolution for Remotely Sensed Images","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","4414213","","","","10.1109/TGRS.2022.3209340","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139526038&doi=10.1109%2fTGRS.2022.3209340&partnerID=40&md5=4a6e18e6e3566978fe6a4d1b304ca49f","Despite the plethora of successful super-resolution (SR) reconstruction (SRR) models applied to natural images, their application to remote sensing imagery tends to produce poor results. Remote sensing imagery is often more complicated than natural images, has its peculiarities such as being of lower resolution, contains noise, and often depicts large textured surfaces. As a result, applying nonspecialized SRR models like the enhanced SR generative adversarial network (ESRGAN) on remote sensing imagery results in artifacts and poor reconstructions. To address these problems, we propose a novel strategy for enabling an SRR model to output realistic remote sensing images: Instead of relying on feature-space similarities as a perceptual loss, the model considers pixel-level information inferred from the normalized digital surface model (nDSM) of the image. This allows the application of better-informed updates during the training of the model which sources from a task (elevation map inference) that is closely related to remote sensing. Nonetheless, the nDSM auxiliary information is not required during production, i.e., the model infers an SR image without additional data. We assess our model on two remotely sensed datasets of different spatial resolutions that also contain the DSMs of the images: The Data Fusion 2018 Contest (DFC2018) dataset and the dataset containing the national LiDAR flyby of Luxembourg. We compare our model with ESRGAN, and we show that it achieves better performance and does not introduce any artifacts in the results. In particular, the results for the high-resolution DFC2018 dataset are realistic and almost indistinguishable from the ground-truth images.  © 1980-2012 IEEE.","Deep learning; Generative adversarial networks; Image enhancement; Image reconstruction; Job analysis; Optical resolving power; Personnel training; Deep learning; Digital surface models; Images reconstruction; Loss measurement; Normalized digital surface model; Perceptual loss; Remote-sensing; Spatial resolution; Super-resolution reconstruction; Superresolution; Task analysis; pixel; remote sensing; satellite imagery; spatial resolution; Remote sensing","Deep learning (DL); normalized digital surface model (nDSM); perceptual loss; remote sensing; super-resolution (SR) reconstruction (SRR)","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85139526038"
"Deng C.; Luo X.; Wang W.","Deng, Chenwei (25958671000); Luo, Xingshi (57918908700); Wang, Wenzheng (57200598636)","25958671000; 57918908700; 57200598636","Multiple Frame Splicing and Degradation Learning for Hyperspectral Imagery Super-Resolution","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","8389","8401","12","10.1109/JSTARS.2022.3207777","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139392572&doi=10.1109%2fJSTARS.2022.3207777&partnerID=40&md5=ee8e6aaa016506897a550a60587025d4","Hyperspectral imagery (HSI) is an emerging remote sensing technology to discriminate different remote sensing objects. However, the HSI spatial resolution is relatively low due to the trade-off in restricted physical hardware and various imaging conditions, restricting the subsequent object detection applications. At present, the single hyperspectral super resolution (SHSR) strategy has encountered the bottleneck on more precise details extraction, and the fusion hyperspectral image super resolution (FHSR) strategy must need extra RGB/multispectral information, which is not suitable for general HSI usage. Also, both types of current strategies focus less on the multiple degradation causes of low spatial resolution. In this article, a step forward in designing a novel framework of multiple frame splicing strategy to greatly improve the SHSR quality, and applying multiple HSI degradation models to better fit the real degradation circumstance. Specifically, the framework is an end-to-end super resolution (SR) network that supersedes a single up-sampling module and removes complex attention residual model due to the same size of multiple splicing low-resolution input samples with high-resolution outputs. The effective framework will alleviate the vague at higher multiples, and accelerate the training convergence. Based on this framework, multiple degradation low-resolution samples can be simultaneously combined to fit better for the blind SR result. Concretely, the degradation focus on the blur, noise, compression, and their combinations to simulate the real degradation. Experimental results on three different hyperspectral datasets demonstrate that the proposed multiple frame splicing and degradation model (MFSDM) algorithm can significantly enhance the details in the recovered high-resolution hyperspectral images, and outperforms the state-of-the-art SHSR methods.  © 2008-2012 IEEE.","Economic and social effects; Image enhancement; Image reconstruction; Image resolution; Object detection; Remote sensing; Spectroscopy; HyperSpectral; Hyperspectral remote sensing; Hyperspectral super resolution; Image super resolutions; Images reconstruction; Multiple degradation super resolution; Multiple degradations; Multiple frame super resolution; Multiple-frame; Spatial resolution; Splicing; Superresolution; machine learning; model; remote sensing; satellite imagery; spatial resolution; Hyperspectral imaging","Hyperspectral remote sensing; hyperspectral super resolution; image super resolution; multiple degradation super resolution; multiple frame super resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85139392572"
"Wang J.; Shao Z.; Huang X.; Lu T.; Zhang R.","Wang, Jiaming (57206676342); Shao, Zhenfeng (7202244409); Huang, Xiao (57201292422); Lu, Tao (56406646300); Zhang, Ruiqian (57190385256)","57206676342; 7202244409; 57201292422; 56406646300; 57190385256","A Deep Unfolding Method for Satellite Super Resolution","2022","IEEE Transactions on Computational Imaging","8","","","933","944","11","10.1109/TCI.2022.3210329","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139526398&doi=10.1109%2fTCI.2022.3210329&partnerID=40&md5=dc852f87cd897cf87bb6e81b41cc2731","Despite that existing deep-learning-based super resolution methods for satellite images have achieved great performance, these methods are generally designed to stack unaccountable and dense modules (i.e., residual blocks and dense blocks) to reach an optimal mapping function between low-resolution and high-resolution patches/images at the expense of computing resources. To address this challenge, we propose a deep unfolding method (LDUM) that includes two major components: 1) the pretreatment network and 2) the unfolding blocks. The main responsibility of the pretreatment network is to generate initial high-resolution images. Further, we model high-resolution images with the prior information, which can be seen as a combination of low-resolution and high-frequency residual images, and solve the optimization problem via the iterative proximal strategy. Specifically, we unfold the iterative process into a deep neural network to refine the reconstructed results, as each layer serves as an iterative step of the proposed optimization model. Thus, the proposed method is able to iteratively generate residual maps and high-resolution images by combining the powerful feature extraction capability of data-driven deep-learning-based methods and the interpretability of traditional model-driven algorithms. Experiments show that the proposed method, featured by its interpretable and lightweight merits, outperforms other state-of-the-art methods from quantitative and qualitative perspectives.  © 2015 IEEE.","Deep neural networks; Iterative methods; Optical resolving power; Optimization; Remote sensing; Satellites; Computational modelling; Deep learning; High-resolution images; Images reconstruction; Optimisations; Remote-sensing; Superresolution; Task analysis; Unfoldings; Image reconstruction","deep learning; optimization; Super resolution; unfolding","Article","Final","","Scopus","2-s2.0-85139526398"
"Civicioglu P.; Besdok E.","Civicioglu, Pinar (55992889600); Besdok, Erkan (6602946869)","55992889600; 6602946869","Contrast stretching based pansharpening by using weighted differential evolution algorithm","2022","Expert Systems with Applications","208","","118144","","","","10.1016/j.eswa.2022.118144","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134614579&doi=10.1016%2fj.eswa.2022.118144&partnerID=40&md5=bf3b3a482db1d1f35a86670bdd60d738","Pansharpening techniques were developed to generate a super-resolution multispectral pansharpened image, PI, with the combination of a multispectral image carrying high-resolution spectral information with a panchromatic image carrying high resolution spatial information. For using energy resources and communication bandwidth efficiently, Earth Observation Satellites acquire multispectral images with lower spatial resolution when compared to panchromatic images. Contrast Stretching alters the range and statistical distribution of pixel values of an image to facilitate perception of image features and can be used to match histograms of distinct images. The Contrast Stretching Based Pansharpening method, CSP, has been introduced in this paper. CSP considers the pansharpening as a rescaling-based pixel-level image fusion problem in spatial domain. CSP uses the contrast stretching to generate two modified-multispectral images and one modified-panchromatic image, which are used to compute pansharpened image. The Weighted Differential Evolution Algorithm has been used to optimize the numerical values of internal parameters of CSP. The successes of CSP and 17 different pansharpening methods have been statistically compared by using three Test Image sets with different characteristics. Ten different image quality measures have been used in accuracy assessment analysis of the PIs generated by the related methods used in the Experiments. Statistical analysis exposed that CSP generates more pleasing PIs both quantitatively and qualitatively compared to the comparison methods employed in this paper. © 2022 Elsevier Ltd","Energy resources; Evolutionary algorithms; Geostationary satellites; Image fusion; Optimization; Pixels; Quality control; Contrast stretching; Differential evolution algorithms; High resolution; Linear contrast stretching; Linear contrasts; Multispectral images; Pan-sharpening; Pansharpened images; Remote-sensing; Weighted differential evolution algorithm; Remote sensing","Image fusion; Linear contrast stretching; Pansharpening; Remote sensing; Weighted differential evolution algorithm","Article","Final","","Scopus","2-s2.0-85134614579"
"Wang Z.; Shang H.; Wang S.","Wang, Zhilin (57219497032); Shang, Haixing (57423588300); Wang, Shuang (57413449500)","57219497032; 57423588300; 57413449500","Super-resolution reconstruction of remote sensing images based on Swin Transformer fusion attention network","2022","Proceedings of SPIE - The International Society for Optical Engineering","12473","","124730S","","","","10.1117/12.2653433","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144085453&doi=10.1117%2f12.2653433&partnerID=40&md5=0daa0c9b11ddeb3131a0c47c2e4d1ca6","Image super-resolution reconstruction technology in remote sensing can improve the spatial resolution of remote sensing images with the breakthrough of physical hardware limitations. With the development of deep learning technology, more and more algorithms proposed in the field of natural images are applied to the field of remote sensing super-resolution. Due to the large difference in the size of the objects in remote sensing images and the high complexity of the image, the reconstructed image will be blurred when the algorithm in the field of natural images is directly used. To address this problem, this paper proposes a shallow feature extraction feature fusion with multiple convolutions, followed by the extraction of high-frequency information using the Swin Transformer module with a fusion attention mechanism. The edge details of the image are extracted using the gradient of the image in the final reconstruction process, and complementary fusion is performed at the end of the network, which can effectively supplement the lack of shallow features caused by the deep network. Finally, experiments show that the proposed model obtains satisfactory reconstruction results of remote sensing images. © 2022 SPIE.","Deep learning; Extraction; Image enhancement; Image fusion; Image reconstruction; Optical resolving power; Deep learning; Image super-resolution reconstruction; Image-based; Learning technology; Natural images; Remote sensing images; Remote-sensing; Spatial resolution; Super-resolution reconstruction; Swin transformer; Remote sensing","deep learning; Image super-resolution reconstruction; remote sensing images; Swin Transformer","Conference paper","Final","","Scopus","2-s2.0-85144085453"
"Manuel C.; Zehnder P.; Kaya S.; Sullivan R.; Hu F.","Manuel, Cyrus (57925258900); Zehnder, Philip (57490388600); Kaya, Sertan (57202700520); Sullivan, Ruth (57754724200); Hu, Fangyao (46061200400)","57925258900; 57490388600; 57202700520; 57754724200; 46061200400","Impact of color augmentation and tissue type in deep learning for hematoxylin and eosin image super resolution","2022","Journal of Pathology Informatics","13","","100148","","","","10.1016/j.jpi.2022.100148","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139727952&doi=10.1016%2fj.jpi.2022.100148&partnerID=40&md5=a55bc91769a4518a653eab7f701a12d6","Single image super-resolution is an important computer vision task with applications including remote sensing, medical imaging, and surveillance. Modern work on super-resolution utilizes deep learning to synthesize high resolution (HR) images from low resolution images (LR). With the increased utilization of digitized whole slide images (WSI) in pathology workflows, digital pathology has emerged as a promising domain for super-resolution. Despite extensive existing research into super-resolution, there remain challenges specific to digital pathology. Here, we investigated image augmentation techniques for hematoxylin and eosin (H&E) WSI super-resolution and model generalizability across diverse tissue types. In addition, we investigated shortcomings with common quality metrics (peak signal-to-noise ratio (PSNR), structure similarity index (SSIM)) by conducting a perceptual quality survey for super-resolved pathology images. High performing deep super-resolution models were used to generate 20X HR images from LR images (5X or 10X equivalent) for 11 different tissues and 30 human evaluators were asked to score the quality of the generated versus the ground truth 20X HR images. The scores given by a human rater and the PSNR or the SSIM were compared to investigate the correlation between model training parameters. We found that models trained on multiple tissues generalized better than those trained on a single tissue type. We also found that PSNR correlated with perceptual quality (R = 0.26) less accurately than did SSIM (R = 0.64), suggesting that the SSIM quality metric is insufficient. The methods proposed in this study can be used to virtually magnify H&E images with better perceptual quality than interpolation methods (i.e., bicubic interpolation) commonly implemented in digital pathology software. The impact of deep SISR methods is more notable when scaling to 4X is needed, such as in the case of super-resolving a low magnification WSI from 10X to 40X. © 2022 The Authors","","Artificial intelligence; Deep learning; Digital pathology; Generative adversarial networks; Histopathology; Image processing; Whole slide imaging","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85139727952"
"Wang L.; Tan W.; Xu H.; He H.; Chen N.; Li D.; Chapman M.A.; Li J.","Wang, L. (56420751000); Tan, W. (57188719498); Xu, H. (57203930655); He, H. (57222872355); Chen, N. (57208390275); Li, D. (56140170000); Chapman, M.A. (57203027250); Li, J. (57235557700)","56420751000; 57188719498; 57203930655; 57222872355; 57208390275; 56140170000; 57203027250; 57235557700","DEEP LEARNING-BASED METHOD TO EXTEND THE TIME SERIES OF GLOBAL ANNUAL VIIRS-LIKE NIGHTTIME LIGHT DATA","2022","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","43","B1-2022","","73","78","5","10.5194/isprs-archives-XLIII-B1-2022-73-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131914345&doi=10.5194%2fisprs-archives-XLIII-B1-2022-73-2022&partnerID=40&md5=06273513b5eb0715645c2d49b96b6e85","The nighttime light (NTL) remote sensed imagery has been applied in monitoring human activities from many perspectives. As the two most widely used NTL satellites, the Defense Meteorological Satellite Program (DMSP) Operational Linescan System and the Suomi National Polar-orbiting Partnership (NPP)-Visible Infrared Imaging Radiometer Suite (VIIRS) have different spatial and radiometric resolutions. Thus, some long-time series analysis cannot be conducted without effective and accurate cross-calibration of these two datasets. In this study, we proposed a deep-learning based model to simulate VIIRS-liked DMSP NTL data by integrating the enhanced vegetation index (EVI) data product from MODIS. By evaluating the spatial pattern of the results, the modified Self-Supervised Sparse-to-Dense networks delivered satisfying results of spatial resolution downscaling. The quantitative analysing of the simulated VIIRS-liked DMSP NTL with original VIIRS NTL showed a good consistency at the pixel level of four selected sub datasets with R2 ranging from 0.64 to 0.76, and RMSE ranging from 3.96-9.55. Our method presents that the deep learning model can learn from relatively raw data instead of fine processed data based on expert knowledge to cross-sensor calibration and simulation NTL data.  © 2022 L. Wang et al.","Calibration; Deep learning; Orbits; Radiometers; Remote sensing; Thermography (imaging); Time series analysis; Deep learning; Defense Meteorological Satellite Programs; Down-scaling; Learning-based methods; Night time lights; Radiance calibration; Spatial resolution; Superresolution; Times series; Visible infrared imaging radiometer suites; Data fusion","Data Fusion; Deep Learning; DMSP; Downscaling; Radiance Calibration; Super Resolution; VIIRS","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85131914345"
"Rapuzzi A.; Nattero C.; Menapace M.; Campanella P.; Cademartori L.; Lomonaco C.","Rapuzzi, Andrea (57219610225); Nattero, Cristiano (54997952100); Menapace, Marco (26422352200); Campanella, Paolo (57188642472); Cademartori, Linda (57895017400); Lomonaco, Carola (57938251700)","57219610225; 54997952100; 26422352200; 57188642472; 57895017400; 57938251700","Downscaling of Satellite Air Quality Data Using Deep Learning¡","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","6606","6609","3","10.1109/IGARSS46834.2022.9884163","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140400751&doi=10.1109%2fIGARSS46834.2022.9884163&partnerID=40&md5=7e8b9171bed66d310ad430a5b02f0fa4","This research addresses the use of machine learning for downscaling pollution information from multiple satellite sources. The proposed solution uses a Convolutional Neural Network (CNN)-based segmentation architecture (U-Net [1]) to perform a resolution enhancement task. Readings obtained by spatially sparse ground stations are used as the ground truth to guide the task. A custom implementation of this solution won the AI4EO Air Quality & Health challenge [2] initiated in 2021 by the European Space Agency (ESA) [3], on a need expressed by the European Centre for Medium-Range Weather Forecasts (ECMWF) [4] and the Copernicus Atmosphere Monitoring Service (CAMS) [5]. In that successful case, the algorithm was trained and tested on volatile particulate matter (PM2.5, from Copernicus Atmosphere Monitoring Service) and nitrogen dioxide (NO2, from Sentinel-5P TROPOMI) data over three Areas of Interest: Northern Italy, California and South Africa. © 2022 IEEE.","Air quality; Convolutional neural networks; Deep learning; Remote sensing; Weather forecasting; Air quality data; Atmosphere monitoring; Convolutional neural network; Deep learning; Down-scaling; Earth observations; Machine-learning; Monitoring services; Multiple satellites; Superresolution; Nitrogen oxides","Air Pollution; Deep Learning; Downscaling; Earth Observation; Machine Learning; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85140400751"
"Wang L.; Wan L.; Bruzzone L.","Wang, Lifeng (57226450880); Wan, Liguo (57965701600); Bruzzone, Lorenzo (7006892410)","57226450880; 57965701600; 7006892410","A Sub-Pixel Convolution-Based Residual Network for Hyperspectral Image Change Detection","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","1059","1062","3","10.1109/IGARSS46834.2022.9884805","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141895235&doi=10.1109%2fIGARSS46834.2022.9884805&partnerID=40&md5=ded1e93e79a9f577b71cc214b5322dd4","The very high spectral resolution in hyperspectral images (HSIs) presents an opportunity to detect subtle land-cover changes. However, availability of HSIs acquired from different platforms requires the development of change detection (CD) methods for HSIs capable to process images with different spatial resolutions. In this paper, we propose an end-to-end sub-pixel convolution-based residual network (SPCNet) to detect changes between high resolution (HR) and low resolution (LR) HSIs. First, an efficient sub-pixel convolution layer is introduced to upscale the LR feature maps into the HR one. Then, the super resolution (SR) block is designed to generate more discriminative representations in sub-pixel-based LR images. Moreover, the sub-pixel-based feature of LR image and pixel-based feature of HR image are concatenated as an input to the designed ResNet for HSI CD. Experimental results on two HSI datasets demonstrate the effectiveness of the proposed SPCNet. © 2022 IEEE.","Change detection; Deep learning; Pixels; Remote sensing; Spectral resolution; Spectroscopy; Change detection; Deep learning; High resolution; HyperSpectral; Hyperspectral image; Image change detection; Remote-sensing; Residual network; Sub-pixels; Superresolution; Convolution","change detection; deep learning; Hyperspectral images; remote sensing; residual network; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85141895235"
"Ambudkar S.; Raj R.; Billa K.; Hukumchand R.","Ambudkar, Shravan (57937361900); Raj, Rahul (57937215100); Billa, Karthik (57937362000); Hukumchand, Richa (57937953900)","57937361900; 57937215100; 57937362000; 57937953900","Super-Resolution for Cross-Sensor Optical Remote Sensing Images","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","1880","1883","3","10.1109/IGARSS46834.2022.9883182","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140403342&doi=10.1109%2fIGARSS46834.2022.9883182&partnerID=40&md5=cb1f1f61246b1ec07e09992c1e85c92f","Generative adversarial network (GAN) models are becoming popular in the field of remote sensing for generating high spatial resolution images from their low resolution versions. In this study, four models including two basic Super-resolution GAN models and two non-GAN Deep Learning models were trained and tested to achieve 2.5m, and 5m spatial resolution from their 10m spatial resolution satellite data. The comparison of results showed that the SRGAN model performed better than the other deep learning models. The performance metrics were also found to be consistent with available literature. © 2022 IEEE.","Deep learning; Image enhancement; Image resolution; Learning systems; Optical remote sensing; High spatial resolution images; Learning models; Lower resolution; Network models; Optical remote sensing; Remote sensing images; Remote-sensing; Resolution enhancement; Spatial resolution; Superresolution; Generative adversarial networks","generative adversarial network; resolution enhancement; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85140403342"
"Liang M.; Wang X.-L.","Liang, Min (57226533656); Wang, Xi-Li (36761950100)","57226533656; 36761950100","Semantic Segmentation Model for Remote Sensing Images Combining Super Resolution and Domain Adaption; [结合超分辨率和域适应的遥感图像语义分割方法]","2022","Jisuanji Xuebao/Chinese Journal of Computers","45","12","","2619","2636","17","10.11897/SP.J.1016.2022.02619","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144541942&doi=10.11897%2fSP.J.1016.2022.02619&partnerID=40&md5=c45068813edecd34a2af74c74190f28d","The semantic segmentation method based on convolutional neural network rely on supervised learning with ground truth, but it cannot be well generalized to unlabeled datasets with different sources. Unsupervised domain adaptation can solve the problem of inconsistent feature distribution between unlabeled target domain data and labeled source domain data. This is due to that remote sensing images are often come from different sources, they are variable in their spatial resolution and are influenced by different imaging regions, imaging conditions and imaging times. Even images from the same region may have large differences in spectral features. The generalization of the semantic segmentation model relies on the reduction of these inter-domain differences mentioned above. Therefore, unsupervised domain adaptation methods for remote sensing image should not only reduce the differences in features between domains, but also address the problem of different spatial resolutions. This paper designs a new end-to-end semantic segmentation deep network combined with image super resolution-Semantic Segmentation Model Combining Super Resolution and Domain Adaption, which can reduce the spatial resolution difference and feature distribution difference between the low spatial resolution source domain and high spatial resolution target domain remote sensing images, and accomplish the super-resolution task for the source domain and the domain adaptation semantic segmentation task for the target domain. The SSM-SRDA model consists of three parts one is Semantic Segmentation Network with Super Resolution (SSNSR), the second is Pixel-level Domain Discriminator (PDD), and the third is Output-space Domain Discriminator (ODD). SSNSR consists of a semantic segmentation network and a super-resolution network, which share the same feature extraction network. The super-resolution network generates a high-resolution synthetic image with target image style from a low-resolution source domain image, which can eliminate spatial resolution differences and style differences to help the feature extraction module learn the same features between the source and target domains. The Feature Affinity-Loss module enhances the learning of the semantic segmentation deep network by the feature maps with more detailed structural information obtained by super-resolution. The pixel-level domain discriminator is used to reduce the pixel-level feature differences between the high-resolution target domain and the synthetic image of the source domain. High-resolution source domain synthetic images with target domain style are generated by generative adversarial learning with the super-resolution network and participate in the training of the model as additional training data. The output-space domain discriminator reduces the feature differences between source and target domain images in the output space of the semantic segmentation network. Through the adversarial learning of the semantic segmentation network and the two discriminators, SSM-SRDA aligns the feature distribution of the source domain and the target domain at the input and output stages of the segmentation network, and can be applied to the target domain datas of more different sources through domain adaptation. It is a practical and more popular model. Experiments show that SSM-SRDA is superior to the existing domain adaptive semantic segmentation methods on four sets of remote sensing image data sets, and the intersection ratio is improved by 0.7%, 1.7%, 2.2% and 3.3%, respectively. © 2022, Science Press. All right reserved.","Convolutional neural networks; Extraction; Feature extraction; Generative adversarial networks; Image enhancement; Image resolution; Learning systems; Pixels; Remote sensing; Semantics; Space optics; Adversarial learning; Domain adaptation; Feature distribution; Pixel level; Remote sensing images; Segmentation models; Semantic segmentation; Spatial resolution; Superresolution; Target domain; Semantic Segmentation","Adversarial learning; Domain adaptation; Remote sensing image; Semantic segmentation; Super resolution","Article","Final","","Scopus","2-s2.0-85144541942"
"Li Z.; Wang Y.; Zhang N.; Zhang Y.; Zhao Z.; Xu D.; Ben G.; Gao Y.","Li, Zheng (57206872666); Wang, Yongcheng (56437944700); Zhang, Ning (57188816117); Zhang, Yuxi (57222123094); Zhao, Zhikang (57221303854); Xu, Dongdong (56299205100); Ben, Guangli (57195509421); Gao, Yunxiao (57709713300)","57206872666; 56437944700; 57188816117; 57222123094; 57221303854; 56299205100; 57195509421; 57709713300","Deep Learning-Based Object Detection Techniques for Remote Sensing Images: A Survey","2022","Remote Sensing","14","10","2385","","","","10.3390/rs14102385","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130748833&doi=10.3390%2frs14102385&partnerID=40&md5=809935c3b96a474876b39318fd981329","Object detection in remote sensing images (RSIs) requires the locating and classifying of objects of interest, which is a hot topic in RSI analysis research. With the development of deep learning (DL) technology, which has accelerated in recent years, numerous intelligent and efficient detection algorithms have been proposed. Meanwhile, the performance of remote sensing imaging hardware has also evolved significantly. The detection technology used with high-resolution RSIs has been pushed to unprecedented heights, making important contributions in practical applications such as urban detection, building planning, and disaster prediction. However, although some scholars have authored reviews on DL-based object detection systems, the leading DL-based object detection improvement strategies have never been summarized in detail. In this paper, we first briefly review the recent history of remote sensing object detection (RSOD) techniques, including traditional methods as well as DL-based methods. Then, we systematically summarize the procedures used in DL-based detection algorithms. Most importantly, starting from the problems of complex object features, complex background information, tedious sample annotation that will be faced by high-resolution RSI object detection, we introduce a taxonomy based on various detection methods, which focuses on summarizing and classifying the existing attention mechanisms, multi-scale feature fusion, super-resolution and other major improvement strategies. We also introduce recognized open-source remote sensing detection benchmarks and evaluation metrics. Finally, based on the current state of the technology, we conclude by discussing the challenges and potential trends in the field of RSOD in order to provide a reference for researchers who have just entered the field. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Classification (of information); Complex networks; Deep neural networks; Learning algorithms; Object detection; Object recognition; Signal detection; Deep learning; Detection algorithm; High-resolution remote sensing images; Hot topics; Improvement strategies; Neural-networks; Objects detection; Remote sensing images; Remote-sensing; Weakly supervised learning; Remote sensing","deep learning; neural network; object detection; remote sensing; weakly supervised learning","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85130748833"
"Cai F.; Wu K.; Jia H.; Wang F.","Cai, Feng (57888175100); Wu, Keyu (57324654500); Jia, Hecheng (57226296459); Wang, Feng (56459216100)","57888175100; 57324654500; 57226296459; 56459216100","Super Resolution of Airplane Target in Remote Sensing Images via A Multi-Degradation Model","2022","2022 IEEE 14th International Conference on Advanced Infocomm Technology, ICAIT 2022","","","","330","333","3","10.1109/ICAIT56197.2022.9862621","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137903222&doi=10.1109%2fICAIT56197.2022.9862621&partnerID=40&md5=c958b4d073294c3a993303cfbb590c6f","In this paper, we argue that the degradation model assumed by existing work on super-resolution of remote sensing images deviates from those in real-world images. To address the above problem, this article proposes a super-resolution reconstruction method for unpaired airplanes in remote sensing images, which consists of a model that simulates the multiple degradations in real-world scenarios and a super-resolution generative adversarial network that generates high-resolution images. Specifically, the novel degradation model can cover a wide range of degradations in natural scenes, which contains diverse factors of additive Gaussian noise, Poisson noise, Brown Gaussian noise, Gaussian blur, etc. Experiments are conducted on the airplane targets in the Gaofen challenge dataset, and the results demonstrate the superiority of our method compared to state-of-the-art methods, especially in raw remote sensing images with multiple noise and blur, which may be preferred in other practical satellite applications with harsh circumstances.  © 2022 IEEE.","Computer vision; Gaussian distribution; Gaussian noise (electronic); Generative adversarial networks; Optical resolving power; Remote sensing; Aircraft target in remote sensing image; Aircraft targets; Degradation model; Image super resolutions; Multiple degradation model; Multiple degradations; Remote sensing image super-resolution; Remote sensing images; Superresolution; Aircraft","aircraft targets in remote sensing images; multiple degradation model; remote sensing image super-resolution","Conference paper","Final","","Scopus","2-s2.0-85137903222"
"Zhu H.; Tang H.; Hu Y.; Tao H.; Xie C.","Zhu, Hongyu (57223364087); Tang, Hao (57824978800); Hu, Yaocong (57201550850); Tao, Huanjie (57200616909); Xie, Chao (57189246390)","57223364087; 57824978800; 57201550850; 57200616909; 57189246390","Lightweight Single Image Super-Resolution with Selective Channel Processing Network","2022","Sensors","22","15","5586","","","","10.3390/s22155586","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135203194&doi=10.3390%2fs22155586&partnerID=40&md5=7bc60ceddacc79d5f7e0b86686fda0bb","With the development of deep learning, considerable progress has been made in image restoration. Notably, many state-of-the-art single image super-resolution (SR) methods have been proposed. However, most of them contain many parameters, which leads to a significant amount of calculation consumption in the inference phase. To make current SR networks more lightweight and resource-friendly, we present a convolution neural network with the proposed selective channel processing strategy (SCPN). Specifically, the selective channel processing module (SCPM) is first designed to dynamically learn the significance of each channel in the feature map using a channel selection matrix in the training phase. Correspondingly, in the inference phase, only the essential channels indicated by the channel selection matrixes need to be further processed. By doing so, we can significantly reduce the parameters and the calculation consumption. Moreover, the differential channel attention (DCA) block is proposed, which takes into consideration the data distribution of the channels in feature maps to restore more high-frequency information. Extensive experiments are performed on the natural image super-resolution benchmarks (i.e., Set5, Set14, B100, Urban100, Manga109) and remote-sensing benchmarks (i.e., UCTest and RESISCTest), and our method achieves superior results to other state-of-the-art methods. Furthermore, our method keeps a slim size with fewer than 1 M parameters, which proves the superiority of our method. Owing to the proposed SCPM and DCA, our SCPN model achieves a better trade-off between calculation cost and performance in both general and remote-sensing SR applications, and our proposed method can be extended to other computer vision tasks for further research. © 2022 by the authors.","Algorithms; Attention; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Benchmarking; Deep learning; Economic and social effects; Image reconstruction; Optical resolving power; Restoration; Differential channel attention; Differential channels; Image super resolutions; Lightweight image super-resolution; Selective channel processing; Selective channels; Single image super-resolution; Single images; Superresolution; algorithm; attention; image processing; nuclear magnetic resonance imaging; procedures; Remote sensing","differential channel attention; lightweight image super-resolution; selective channel processing; single image super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85135203194"
"Ye F.; Wu Z.; Xu Y.; Liu H.; Wei Z.","Ye, Fei (57671266100); Wu, Zebin (20437030300); Xu, Yang (57188730185); Liu, Hongyi (54903598800); Wei, Zhihui (55761764700)","57671266100; 20437030300; 57188730185; 54903598800; 55761764700","Bayesian Hyperspectral Image Super-Resolution in the Presence of Spectral Variability","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5545613","","","","10.1109/TGRS.2022.3228313","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144811480&doi=10.1109%2fTGRS.2022.3228313&partnerID=40&md5=4b2a956d58ab6ed71461056b3df00684","Synthesizing a high-resolution (HR) hyperspectral image (HSI) by merging a low-resolution (LR) HSI with a corresponding HR multispectral image (MSI) has become a promising HSI super-resolution scheme. Most existing HSI-MSI fusion methods are effective to some extent, while several challenges remain. First, the spectral response of a given material exhibits considerable variability due to different acquisition times and conditions, however, variations in spectral signatures are often neglected. Second, a majority of off-the-shelf methods require predefined degradation operators, which can be unavailable in practice. To tackle the above issues, we introduce a novel fusion approach with a Bayesian framework. Specifically, we regard the up-sampled LR-HSI as the low-frequency component of the underlying HR-HSI. We characterize the texture features of high-and low-frequency components, respectively, which can enlarge modeling capacity and bypass the absence of degradation operators. Furthermore, we depict the relative smoothness of reflectance spectra with the Gaussian process. Extensive experiments on synthesized and real datasets illustrate the superiority of the proposed strategy in terms of fusion performance and robustness to spectral variability. © 1980-2012 IEEE.","Barium compounds; Bayesian networks; Hyperspectral imaging; Inference engines; Optical resolving power; Remote sensing; Bayes method; Bayesian inference; High resolution; HyperSpectral; Hyperspectral image; Multispectral images; Spatial resolution; Spectral variability; Superresolution; Bayesian analysis; image resolution; multispectral image; spectral analysis; Image fusion","Bayesian inference; hyperspectral image (HSI); image fusion; multispectral image (MSI); spectral variability; super-resolution","Article","Final","","Scopus","2-s2.0-85144811480"
"Bhattacharya S.; Remane K.; Kindel B.; Tang G.","Bhattacharya, Swastik (57937652200); Remane, Kedar (57937361400); Kindel, Bruce (6602584093); Tang, Gongguo (57762339700)","57937652200; 57937361400; 6602584093; 57762339700","Spectral Super-Resolution for Hyperspectral Image Reconstruction Using Dictionary and Machine Learning","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","1764","1767","3","10.1109/IGARSS46834.2022.9883055","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140380379&doi=10.1109%2fIGARSS46834.2022.9883055&partnerID=40&md5=91cac625112270db7538e8ea37dcf448","Hyperspectral sensors measure the radiance spectrum across hundreds of wavelength channels with a resolution typically on the order of 10 nm represented by the full-width-half-maximum (FWHM). The spectra are used in the study of surface materials in the biological, geological and oceanographic sciences to name a few, utilizing quantitative spectroscopic techniques. The instruments developed to measure such data are expensive due to the increased number of bands, and create large datasets that can be difficult to downlink for a given instance. Repeat cycle of space-borne hyperspectral observations of the earth surface is also less than those of multi-spectral sensors. It becomes incumbent to develop mechanisms that could be cost-effective and give desired results. With this aim, spectral Super-Resolution (SR) is attempted on the Airborne Visible and Infra-Red Imaging Spectrometer (AVIRIS) data to reconstruct the hyperspectral band radiance from equally-spaced narrow multi-spectral bands using dictionary learning, followed by denoising using machine learning. The hyperspectral band radiance are first estimated from 30 selected input multi-spectral bands using dictionary trained through K-Singular Value Decomposition (K-SVD), followed by denoising using Random Forest Regression. An overall Signal-to-Noise Ratio (SNR) of 31.58dB is observed from reconstruction after denoising using Random Forest. © 2022 IEEE.","Cost effectiveness; Decision trees; Earth (planet); Hyperspectral imaging; Large dataset; Machine learning; Optical resolving power; Remote sensing; Signal to noise ratio; Singular value decomposition; Spectrometers; Spectroscopy; De-noising; Dictionary learning; HyperSpectral; Images reconstruction; Machine-learning; Multi-spectral; Signal and image processing; Spectral band; Spectral super-resolution; Superresolution; Image reconstruction","Dictionary Learning; Image Reconstruction; Signal and Image Processing; Spectral Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85140380379"
"Liu X.; Xu Y.; Che Y.; Tang J.","Liu, Xuhui (57219759539); Xu, Yan (57198771680); Che, Yali (57988870000); Tang, Jie (57719061000)","57219759539; 57198771680; 57988870000; 57719061000","Super-resolution reconstruction of remote sensing images based on convolutional neural networks","2022","2022 5th International Conference on Data Science and Information Technology, DSIT 2022 - Proceedings","","","","","","","10.1109/DSIT55514.2022.9943916","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143154567&doi=10.1109%2fDSIT55514.2022.9943916&partnerID=40&md5=83a1d5a23cd660f6e73a401f6d30d20c","Aiming at the problem that the current remote sensing image super-resolution reconstruction algorithm extracts insufficient image information and lacks high-frequency information such as edges and textures, this paper proposes a remote sensing image super-resolution reconstruction algorithm based on multi-scale extraction and attention mechanism. The algorithm uses the Inception-ResNet module to fuse information extracted at different levels to obtain richer image features; introduces an attention mechanism to obtain high-frequency information and enriches texture details; uses a residual network to supplement image information and alleviate network gradient problems. Experiments show that the peak signal-to-noise ratio and structural similarity of the proposed algorithm are better than those of SRCNN, VDSR, SRGAN, and other comparison algorithms, and the reconstruction effect has more detailed information and clearer edge texture than the comparison algorithms.  © 2022 IEEE.","Convolutional neural networks; Edge detection; Image reconstruction; Image texture; Optical resolving power; Remote sensing; Signal to noise ratio; Attention mechanisms; High-frequency informations; Image information; Image super-resolution reconstruction; Image-based; Multi-scale features; Reconstruction algorithms; Remote sensing images; Residual network; Super-resolution reconstruction; Textures","attention mechanism; multi-scale features; residual network; super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85143154567"
"Zhang Q.; Jia R.-S.; Li Z.-H.; Li Y.-C.; Sun H.-M.","Zhang, Qi (57367179500); Jia, Rui-Sheng (25927894300); Li, Zeng-Hu (57563441600); Li, Yong-Chao (57411683300); Sun, Hong-Mei (55729286100)","57367179500; 25927894300; 57563441600; 57411683300; 55729286100","Superresolution reconstruction of optical remote sensing images based on a multiscale attention adversarial network","2022","Applied Intelligence","52","15","","17896","17911","15","10.1007/s10489-022-03548-7","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127706645&doi=10.1007%2fs10489-022-03548-7&partnerID=40&md5=82bde35960d7e8ee7f087ef8569b915c","Due to the influence of imaging equipment and environmental conditions on optical remote sensing image acquisition, image resolution is generally low. Superresolution reconstruction technology is an important way to improve image quality. However, the existing optical remote sensing image superresolution reconstruction methods have some problems, such as insufficient feature extraction, blurred texture details of reconstructed images, and excessive network accumulation. To solve the above problems, a superresolution reconstruction method for optical remote sensing images based on a multiscale attention adversarial network is proposed in this paper. The method takes a generative adversarial network (GAN) as the basic framework. The generator uses four multiscale attention residual blocks (MSARBs) to extract image multiscale feature information and carries out feature fusion through a binary feature fusion structure (BFFS) to generate more realistic images. The discriminator uses a depth convolution network to distinguish the differences between real images and superresolution images. In the aspect of loss function construction, the perceptual loss and adversarial loss are combined to improve the perceptual quality of the images. Experimental results show that this method is superior to the compared algorithm in regard to the objective evaluation metrics of peak signal-to-noise ratio (PSNR) and structural similarity (SSIM), and its reconstructed images have better visual effect. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Image acquisition; Image enhancement; Image fusion; Image quality; Image reconstruction; Image resolution; Optical remote sensing; Signal to noise ratio; Textures; Adversarial networks; Features fusions; Image-based; Multiscale attention residual network; Optical remote sensing; Optical remote sensing image; Reconstructed image; Reconstruction method; Remote sensing images; Super-resolution reconstruction; Generative adversarial networks","Generative adversarial network; Multiscale attention residual network; Optical remote sensing images; Superresolution reconstruction","Article","Final","","Scopus","2-s2.0-85127706645"
"Li J.; Ke M.; Ma Y.; Cui J.","Li, Jian (55983731500); Ke, Meiru (57947292100); Ma, Yurong (57947449400); Cui, Jian (57947937100)","55983731500; 57947292100; 57947449400; 57947937100","Remote Monitoring of NH3-N Content in Small-Sized Inland Waterbody Based on Low and Medium Resolution Multi-Source Remote Sensing Image Fusion","2022","Water (Switzerland)","14","20","3287","","","","10.3390/w14203287","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140882288&doi=10.3390%2fw14203287&partnerID=40&md5=ecb66266c507c3776e286b34d7086738","In applying quantitative remote sensing in water quality monitoring for small inland rivers, the time-frequency of monitoring dramatically impacts the accuracy of time-spatial changes estimates of the water quality parameters. Due to the limitation of satellite sensor design and the influence of atmospheric conditions, the number of spatiotemporal dynamic monitoring images of water quality parameters is insufficient. Meanwhile, MODIS and other high temporal resolution images’ spatial resolution is too low to effectively extract small inland river boundaries. To solve the problem, many researchers used Spatio-temporal fusion models in multisource data remote sensing monitoring of ground features. The wildly used Spatio-temporal fusion models, such as FSDAF (flexible spatial-temporal data fusion), have poor performance in heterogeneous changes of ground objects. We proposed a spatiotemporal fusion algorithm SR-FSDAF (Super-resolution based flexible spatiotemporal data fusion) to solve the problem. Based on the FSDAF, it added ESPCN to reconstruct the spatial change prediction image, so as to obtain better prediction results for heterogeneous changes. Both qualitative and quantitative evaluation results showed that our fusion algorithm obtained better results. We compared the band sensitivity of the images before and after fusion to find out that the sensitive band combination of NH3-N has not changed, which proved that the fusion method can be used to improve the time-frequency of NH3-N inversion. After the fusion, we compared the accuracy of linear regression and random forest inversion models and selected the random forest model with better accuracy to predict the NH3-N concentration. The inversion accuracy of NH3-N was as follows: the R2 was 0.75, the MAPE was 23.7% and the RMSE was 0.15. The overall concentration change trend of NH3-N in the study area was high-water period < water-stable period < low water period. NH3-N pollution was serious in some reaches. © 2022 by the authors.","Decision trees; Forecasting; Image enhancement; Image fusion; Monitoring; Radiometers; Remote sensing; River pollution; Water quality; Fusion model; Inland rivers; LANDSAT; Landsat-8; MODIS; NH3-N; Remote-sensing; Spatio-temporal fusions; Spatiotemporal fusion model; Water quality monitoring; accuracy assessment; algorithm; ammonium; concentration (composition); data inversion; design; health monitoring; Landsat; MODIS; monitoring system; regression analysis; remote sensing; water quality; Landsat","Landsat-8; MODIS; NH<sub>3</sub>-N; remote sensing; spatiotemporal fusion model; water quality monitoring","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85140882288"
"Mishra D.; Hadar O.","Mishra, Divya (57485985200); Hadar, Ofer (7004643957)","57485985200; 7004643957","Self-FuseNet: Data Free Unsupervised Remote Sensing Image Super-Resolution","2023","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","","","1","18","17","10.1109/JSTARS.2023.3239758","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147265423&doi=10.1109%2fJSTARS.2023.3239758&partnerID=40&md5=a7c1e77a3941292c5e9835cc38db60de","Real-world degradations deviate from ideal degradations, as most deep learning-based scenarios involve the ideal synthesis of low-resolution counterpart images by popularly used bicubic interpolation. Moreover, supervised learning approaches rely on many high-resolution and low-resolution image pairings to reconstruct missing information based on their association, developed by complex long hours of deep neural network training. Additionally, the trained model&#x0027;s generalizability on various image datasets with various distributions is not guaranteed. To overcome this challenge, we proposed our novel Self-FuseNet, particularly for extremely poor-resolution satellite images. Also, the network exhibits strong generalization performance on additional datasets (both &#x201C;Ideal&#x201D; and &#x201C;Non-Ideal&#x201D; scenarios). The network is especially for those image datasets suffering from two significant limitations: (1) non-availability of ground truth high-resolution images and (2) limitation of a large count of the unpaired dataset for deep neural network training. The benefit of the proposed model is threefold: First, it does not require any significant extensive training data, either paired or unpaired but only a single low-resolution image without prior knowledge of its distribution. Secondly, it is a simple and effective model for super-resolving very poor-resolution images, saving computational resources and time. Third, using UNet, the processing of data is accelerated by the network&#x0027;s wide skip connections, allows image reconstruction with fewer parameters. Rather than using an inverse approach, as common in most deep learning scenarios, we introduced a forward approach to super-resolve exceptionally low-resolution remote sensing images. This demonstrates its supremacy over recently proposed state-of-the-art methods for unsupervised single real-world image blind super-resolution. Author","Data handling; Deep neural networks; Image fusion; Inverse problems; Optical resolving power; Remote sensing; Blind image super-resolution; Deep learning; Features extraction; Image super resolutions; Images reconstruction; Self-fusion; Spatial resolution; Superresolution; Unsupervised image super-resolution; Image reconstruction","Blind image super-resolution; data fusion; Deep learning; deep learning; Feature extraction; Image reconstruction; Satellites; self-fusion; Spatial resolution; Superresolution; Training; unsupervised image super-resolution","Article","Article in press","All Open Access; Gold Open Access","Scopus","2-s2.0-85147265423"
"Ayala C.; Aranda C.; Galar M.","Ayala, C. (55642388700); Aranda, C. (57211636468); Galar, M. (35731257600)","55642388700; 57211636468; 35731257600","Pushing the Limits of Sentinel-2 for Building Footprint Extraction","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","322","325","3","10.1109/IGARSS46834.2022.9883103","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140396814&doi=10.1109%2fIGARSS46834.2022.9883103&partnerID=40&md5=1d43f1dec0e19e650e43f5e1038dae70","Building footprint maps are of high importance nowadays since a wide range of services relies on them to work. However, activities to keep these maps up-to-date are costly and time-consuming due to the great deal of human intervention required. Several automation attempts have been carried out in the last decade aiming at fully automatizing them. However, taking into account the complexity of the task and the current limitations of semantic segmentation deep learning models, the vast majority of approaches rely on aerial imagery (<1 m). As a result, prohibitive costs and high revisit times prevent the remote sensing community from maintaining up-to-date building maps. This work proposes a novel deep learning architecture to accurately extract building footprints from high resolution satellite imagery (10 m). Accordingly, super-resolution and semantic segmentation techniques have been fused to make it possible not only to improve the building's boundary definition but also to detect buildings with sub-pixel width. As a result, fine-grained building maps at 2.5 m are generated using Sentinel-2 imagery, closing the gap between satellite and aerial semantic segmentation. © 2022 IEEE.","Aerial photography; Antennas; Buildings; Convolutional neural networks; Deep learning; Satellite imagery; Semantic Segmentation; Semantics; Building detection; Building footprint; Convolutional neural network; Current limitation; Deep learning; Human intervention; Learning models; Remote-sensing; Semantic segmentation; Sentinel-2; Remote sensing","Building Detection; Convolutional Neural Networks; Deep Learning; Remote Sensing; Sentinel-2","Conference paper","Final","","Scopus","2-s2.0-85140396814"
"Wang Y.; Yin D.; Lou L.; Li X.; Cheng P.; Huang Y.","Wang, Yilin (57225158731); Yin, Dongxu (57886872700); Lou, Liming (57429038800); Li, Xinying (57886413900); Cheng, Pengle (14062947900); Huang, Ying (57862589900)","57225158731; 57886872700; 57429038800; 57886413900; 14062947900; 57862589900","Luotuo Mountain Waste Dump Cover Interpretation Combining Deep Learning and VDVI Based on Data from an Unmanned Aerial Vehicle (UAV)","2022","Remote Sensing","14","16","4043","","","","10.3390/rs14164043","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137846226&doi=10.3390%2frs14164043&partnerID=40&md5=26ffda9fdd198d882c321ad40ea50720","Exposed mine gangue hills are prone to environmental problems such as soil erosion, surface water pollution, and dust. Revegetation of gangue hills can effectively combat the problem. Effective ground cover monitoring means can significantly improve the efficiency of vegetation restoration. We used UAV aerial photography to acquire data and used the Real-SR network to reconstruct the data in super-resolution; the Labv3+ network was used to segment the ground cover into green areas, open spaces, roads, and waters, and VDVI and Otsu were used to extract the vegetation from the green areas. The final ground-cover decomposition accuracy of this method can reach 82%. The application of a super-resolution reconstruction network improves the efficiency of UAV aerial photography; the ground interpretation method of deep learning combined with a vegetation index solves both the problem that vegetation index segmentation cannot cope with the complex ground and the problem of low accuracy due to little data for deep-learning image segmentation. © 2022 by the authors.","Aerial photography; Deep learning; Efficiency; Image enhancement; Image reconstruction; Image segmentation; Optical resolving power; Remote sensing; Revegetation; Soil conservation; Surface waters; Vegetation; Water conservation; Aerial vehicle; AS-soils; Deep learning; Environmental problems; Green areas; Ground covers; Remote sensing interpretation; Unmanned aerial vehicle; Vegetation index; Waste dumps; Antennas","deep learning; remote sensing interpretation; UAV","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85137846226"
"Dun X.; Fu Q.; Li H.; Sun T.; Wang J.; Sun Q.","Dun, Xiong (57196789835); Fu, Qiang (56970358300); Li, Haotian (57205202524); Sun, Tiancheng (57208855938); Wang, Jian (57658338700); Sun, Qilin (57386860300)","57196789835; 56970358300; 57205202524; 57208855938; 57658338700; 57386860300","Recent progress in computational imaging; [计算成像前沿进展]","2022","Journal of Image and Graphics","27","6","","1840","1876","36","10.11834/jig.220061","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131853330&doi=10.11834%2fjig.220061&partnerID=40&md5=2c9672a51fc8b7dae761a11e8c0541de","Computational imaging breaks the limitation of traditional digital imaging to acquire the information deeper (e.g., high dynamic range imaging and low light imaging) and broader (e.g., spectrum, light field, and 3D imaging). Driven by industry, especially mobile phone manufacturer medical and automotive, computational imaging has become ubiquitous in our daily lives and plays a critical role in accelerating the revolution of industry. It is a new imaging technique that combines illumination, optics, image sensors, and post-processing algorithms. This review takes the latest methods, algorithms, and applications as the mainline and reports the state-of-the-art progress by jointly analyzing the articles and reports at home and aboard. This review covers the topics of end-to-end optics and algorithms design, high dynamic range imaging, light-field imaging, spectrum imaging, lensless imaging, low light imaging, 3D imaging, and computational photography. It focuses on the development status, frontier dynamics, hot issues, and trends in each computational imaging topic. The camera systems have long-term been designed in separated steps: experience-driven lens design followed by costume designed post-processing. Such a general-propose approach achieved success in the past but left the question open for specific tasks and the best compromise among optics, post-processing, and costs. Recent advances aim to build the gap in an end-to-end fashion. To realize the joint optics and algorithms designing, different differentiable optics models have been realized step by step, including the differentiable diffractive optics model, the differentiable refractive optics, and the differentiable complex lens model based on differentiable ray-tracing. Beyond the goal of capturing a sharp and clear image on the sensor, it offers enormous design flexibility that can not only find a compromise between optics and post-processing, but also open up the design space for optical encoding. The end-to-end camera design offers competitive alternatives to modern optics and camera system design. High dynamic range (HDR) imaging has become a commodity imaging technique as evidenced by its applications across many domains, including mobile consumer photography, robotics, drones, surveillance, content capture for display, driver assistance systems, and autonomous driving. This review analyzes the advantages, disadvantages, and industrial applications through analyzing a series of HDR imaging techniques, including optical modulation, multi-exposure, multi-sensor fusion, and post-processing algorithms. Conventional cameras do not record most of the information about the light distribution entering from the world. Light-field imaging records the full 4D light field measuring the amount of light traveling along each ray that intersects the sensor. This review reports how the light field is applied to super-resolution, depth estimation, 3D measurement, and so on and analyzes the state-of-the-art method and industrial application. It also reports the research progress and industrial application in particle image velocimetry and 3D flame imaging. Spectral imaging technique has been used widely and successfully in resource assessment, environmental monitoring, disaster warning, and other remote sensing domains. Spectral image data can be described as a three-dimensional cube. This imaging technique involves capturing the spectrum for each pixel in an image; As a result, the digital images produce detailed characterizations of the scene or object. This review explains multiple methods to acquire spectrum volume data, including the current multi-channel filter, solving the wavelength response curve inversely based on deep learning, diffraction grating, multiplexing, metasurface, and other optimizations to achieve hyper-spectrum acquisition. Lensless imaging eliminates the need for geometric isomorphism between a scene and an image while constructing compact and lightweight imaging systems. It has been applied to bright-field imaging, cytometry, holography, phase recovery, fluorescence, and the quantitative sensing of specific sample properties derived from such images. However, the low reconstructed signal-to-noise ratio makes it an unsolved challenging inverse problem. This review reports the recent progress in designing and optimizing planar optical elements and high-quality image reconstruction algorithms combined with specific applications. Imaging under a low light illumination will be affected by Poisson noise, which becomes increasingly strong as the power of the light source decreases. In the meantime, a series of visual degradation like decreased visibility, intensive noise, and biased color will occur. This review analyzes the challenges of low light imaging and conclude the corresponding solutions, including the noise removal methods of single/multi-frame, flash, and new sensors to deal with the conditions when the sensor exposure to low light. Shape acquisition of three-dimensional objects plays a vital role for various real-world applications, including automotive, machine vision, reverse engineering, industrial inspections, and medical imaging. This review reports the latest active solutions which have been widely applied, including structured light, direct time-of-flight, and indirect time-of-flight. It also notes the difficulties like ambient light (e.g., sunlight), indirect inference (e.g., the mutual reflection of the concave surface, scattering of foggy) of depth acquisition based on those active methods. The use of computation methods in photography refers to digital image capture and processing techniques that use digital calculation instead of optical processes. It can not only improve the camera ability but also add more new features that were not possible at all with traditional film-based photography. Computational photography is an essential branch of computation imaging developed from traditional photography - however, computational photography emphasizes taking a photograph digitally. Limited by the physical size and image quality, computational photography focuses on reasonably arranging the computational resources and showing the high-quality image that pleasures the customer's feeling. As 90 percent of the information transmitted to our human brain is visual, the imaging system plays a vital role for most future intelligence systems. Computational imaging drastically releases human information acquisition ability in no matter depth or scope. For new techniques like metaverse, computational imaging offers a general input tool to collect multi-dimensional visual information for rebuilding the virtual world. This review covers key technological developments, applications, insights, and challenges over the recent years and examines current trends to predict future capabilities. © 2022, Editorial Office of Journal of Image and Graphics. All right reserved.","","Active 3D imaging; Computational photography; End-to-end camera design; High dynamic range imaging; Lensless imaging; Light-field imaging; Low light imaging; Spectral imaging","Review","Final","","Scopus","2-s2.0-85131853330"
"Liu J.; Yuan Z.; Pan Z.; Fu Y.; Liu L.; Lu B.","Liu, Jinzhe (57930292300); Yuan, Zhiqiang (57224201612); Pan, Zhaoying (57899990900); Fu, Yiqun (57929346100); Liu, Li (57221211535); Lu, Bin (57930105500)","57930292300; 57224201612; 57899990900; 57929346100; 57221211535; 57930105500","Diffusion Model with Detail Complement for Super-Resolution of Remote Sensing","2022","Remote Sensing","14","19","4834","","","","10.3390/rs14194834","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139951722&doi=10.3390%2frs14194834&partnerID=40&md5=ec946c99a473639d88a304f76209666b","Remote sensing super-resolution (RSSR) aims to improve remote sensing (RS) image resolution while providing finer spatial details, which is of great significance for high-quality RS image interpretation. The traditional RSSR is based on the optimization method, which pays insufficient attention to small targets and lacks the ability of model understanding and detail supplement. To alleviate the above problems, we propose the generative Diffusion Model with Detail Complement (DMDC) for RS super-resolution. Firstly, unlike traditional optimization models with insufficient image understanding, we introduce the diffusion model as a generation model into RSSR tasks and regard low-resolution images as condition information to guide image generation. Next, considering that generative models may not be able to accurately recover specific small objects and complex scenes, we propose the detail supplement task to improve the recovery ability of DMDC. Finally, the strong diversity of the diffusion model makes it possibly inappropriate in RSSR, for this purpose, we come up with joint pixel constraint loss and denoise loss to optimize the direction of inverse diffusion. The extensive qualitative and quantitative experiments demonstrate the superiority of our method in RSSR with small and dense targets. Moreover, the results from direct transfer to different datasets also prove the superior generalization ability of DMDC. © 2022 by the authors.","Diffusion; Image enhancement; Image resolution; Inverse problems; Remote sensing; Constraint loss; Detail supplement; Diffusion model; High quality; Pixel constraint loss; Remote sensing images; Remote sensing super-resolution; Remote-sensing; Small targets; Superresolution; Pixels","detail supplement; diffusion model; pixel constraint loss; remote sensing super-resolution; small targets","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85139951722"
"Qin P.; Huang H.; Tang H.; Wang J.; Liu C.","Qin, Peng (57215550489); Huang, Huabing (57216494536); Tang, Hailong (57210148473); Wang, Jie (56050004800); Liu, Chong (57970016500)","57215550489; 57216494536; 57210148473; 56050004800; 57970016500","MUSTFN: A spatiotemporal fusion method for multi-scale and multi-sensor remote sensing images based on a convolutional neural network","2022","International Journal of Applied Earth Observation and Geoinformation","115","","103113","","","","10.1016/j.jag.2022.103113","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142150477&doi=10.1016%2fj.jag.2022.103113&partnerID=40&md5=397559d93ab6afae2c76f93f62f85af1","Spatiotemporal data fusion is a commonly-used and well-proven technique to enhance the application potential of multi-source remote sensing images. However, most existing methods have trouble in generating quality fusion results when areas covered by the images undergoes rapid land cover changes or images have substantial registration errors. While deep learning algorithms have demonstrated their capabilities for imagery fusion, it is challenging to apply deep-learning-based fusion methods in regions that experiences persistent cloud covers and have limited cloud-free imagery observations. To address these challenges, we developed a Multi-scene Spatiotemporal Fusion Network (MUSTFN) algorithm based on a Convolutional Neural Network (CNN). Our approach uses multi-level features to fuse images at different resolutions acquired by multiple sensors. Furthermore, MUSTFN uses the multi-scale features to overcome the effects of geometric registration errors between different images. Additionally, a multi-constrained loss function is proposed to improve the accuracy of imagery fusion over large areas and solve fusion and gap-filling problems simultaneously by utilizing cloud-contaminated images with the fine-tuning method. Compared with several commonly-used methods, our proposed MUSTFN performs better in fusing the 30-m Landsat-7 images and 500-m MODIS images over a small area that has undergone large changes (the average relative Mean Absolute Errors (rMAE) of the first four bands are 6.8% by MUSTFN as compared to 14.1% by the Enhanced Spatial and Temporal Adaptive Reflectance Fusion Model (ESTARFM), 12.8% by the Flexible Spatiotemporal Data Fusion (FSDAF), 8.4% by the Extended Super-Resolution Convolutional Neural Network (ESRCNN), 8.1% by the Spatiotemporal Fusion Using a Generative Adversarial Network (STFGAN)). In particularly for images at different resolutions with different registration accuracies (e.g., 16-m Chinese GaoFen-1 and 500-m MODIS), MUSTFN achieved fusion results of good quality with an average rMAE of 9.3% in spectral reflectance at the first four bands. Finally, we demonstrated the applicability of MUSTFN (average rMAE of 9.18%) when fusing long-term Landsat-8 composite images and MODIS images over a large region (830 km × 600 km). Overall, our results suggest the effectiveness of MUSTFN to address the challenges in imagery fusion, including rapid land cover changes between image acquisition dates, geometric misregistration between images and limited availabilities of cloud-free images. The program of MUSTFN is freely available at: https://github.com/qpyeah/MUSTFN. © 2022 The Authors","algorithm; artificial neural network; image processing; remote sensing; satellite data; spatiotemporal analysis","CNN; Large-area image fusion; Multi-scale fusion scenarios; Multi-sensor satellite data; Spatiotemporal fusion","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85142150477"
"Long J.; Peng Y.; Zhao L.; Zhou T.; Li J.","Long, Jian (57218616379); Peng, Yuanxi (7403418922); Zhao, Liyuan (57205879555); Zhou, Tong (57222290947); Li, Jun (57202722259)","57218616379; 7403418922; 57205879555; 57222290947; 57202722259","Semi-blind hyperspectral and multispectral image fusion based on a non-factorization model","2022","Infrared Physics and Technology","125","","104232","","","","10.1016/j.infrared.2022.104232","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131453858&doi=10.1016%2fj.infrared.2022.104232&partnerID=40&md5=77dafc092f1a2430c93583331779beb7","Fusion of low-resolution hyperspectral images (LR-HSI) with high-resolution multispectral images (HR-MSI) is currently the most cost-effective method for acquiring high-resolution hyperspectral images (HR-HSI). The existing fusion models like spectral unmixing, matrix-factorization, and tensor-factorization require decomposing the target HR-HSI into multiple factor matrices or tensors before fusion. Usually requires a large number of variable optimization processes. So, the above approaches do not apply to the arguably real-time scenario. Moreover, the miscellaneous intermediate estimates render poor fusion stability. This paper proposes a novel non-factorization model to address the above problems. The model firstly gets access to a rough estimate of HR-HSI through the Moore–Penrose inverse operation. Then, we acquire the further HR-HSI forecast according to the correlation between the target HR-HSI and LR-HSI singular values through the coupled singular value decomposition (SVD) of the rough HR-HSI and LR-HIS. Finally, we obtain the precise HR-HSI estimates via the multiplicative update rule. Our proposed model directly estimates the target HR-HSI, reduces the estimation process of intermediate variables, effectively saves calculation time, and enhances the stability of the fusion. We conduct experiments on remote sensing, ground-based, and real datasets to validate our proposed model's real-time and stability. © 2022 Elsevier B.V.","Cost effectiveness; Factorization; Hyperspectral imaging; Image fusion; Inverse problems; Remote sensing; Singular value decomposition; Tensors; Factorization model; High resolution; Hyperspectral image fusions; Hyperspectral imaging super-resolution; Lower resolution; Non-factorization-based; Real- time; Semi-blind; Semi-blind fusion; Superresolution; Spectroscopy","Hyperspectral imaging super-resolution; Non-factorization-based; Semi-Blind fusion","Article","Final","","Scopus","2-s2.0-85131453858"
"Min J.; Zhang Y.; Yu Y.; Lv K.; Wang Z.; Zhang L.","Min, Jie (57226783874); Zhang, Yongsheng (56414442400); Yu, Ying (55731485300); Lv, Kefeng (57730290400); Wang, Ziquan (57196351372); Zhang, Lei (57196133151)","57226783874; 56414442400; 55731485300; 57730290400; 57196351372; 57196133151","Enhanced Remote Sensing Image SRGAN Algorithm and Its Application in Improving the Accuracy of 3D Reconstruction; [增强型遥感影像SRGAN算法及其在三维重建精度提升中的应用]","2022","Journal of Geo-Information Science","24","8","","1631","1644","13","10.12082/dqxxkx.2022.210766","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137638286&doi=10.12082%2fdqxxkx.2022.210766&partnerID=40&md5=47a95d9b46e8eded52331a3e5d81ba44","Remote sensing images are important data sources for terrain mapping, 3D reconstruction, and other tasks. The spatial resolution of remote sensing images determines the representation ability of the measured object on the image and plays an important role in the positioning accuracy and reconstruction effect of 3D model in the later stage. In view of the characteristics of high resolution remote sensing images including large scale, complex target features, and rich details, an enhanced SRGAN algorithm for remote sensing image reconstruction is proposed to meet the needs of 3D model reconstruction. The proposed algorithm overcomes the problems of edge effect and fuzzy reconstruction using traditional methods for super-resolution reconstruction. In traditional methods, there is limitation that simple convolutional networks can only extract the shallow feature information of the image and cannot retain the rich details of the image with the increasing resolution. The proposed algorithm is based on the generative adversarial networks using deep learning, in which dense residual blocks are used to extract deep features, and multi-scale discrimination is introduced into the discriminant model. In the training, the generation model and the discrimination model learn features together and are optimized to finally obtain a super-resolution reconstruction model suitable for remote sensing image application. This model can improve the resolution and image quality of remote sensing images, and ensure the integrity and accuracy of feature texture, detail information, and high-frequency target. In our study, the proposed algorithm is compared with the Bicubic, SRGAN, and ESRGAN algorithms. Our results show that the PSNR of the proposed algorithm is improved by about three units, the Penetration Index (PI) is stable and closer to one, and the SSIM and clarity index Q are also improved. In 3D reconstruction, the number of image dense matching points is increased, and the error is reduced. The measured point values of the model are closer to the measured point values from the field. The visual perception of the model is also more real and delicate, which indicates that the precision and positioning accuracy of the 3D model can be significantly improved using the remote sensing images constructed by the proposed algorithm. The results demonstrate the proposed algorithm that considers the characteristics of remote sensing images performs better than other algorithms for the super-resolution reconstruction, and the geometric accuracy and visual accuracy of the real 3D models based on the constructed images are also significantly improved. © 2022, Science Press. All right reserved.","3D modeling; Convolution; Convolutional neural networks; Deep learning; Generative adversarial networks; Image enhancement; Image quality; Image resolution; Mapping; Remote sensing; Textures; Three dimensional computer graphics; 3D reconstruction; Deep learning; High resolution remote sensing; Images processing; Multi-scale relative discrimination; Multi-scales; Positioning accuracy; Remote sensing images; SRGAN; Super-resolution reconstruction; accuracy assessment; algorithm; image processing; image resolution; machine learning; remote sensing; satellite imagery; three-dimensional modeling; Image reconstruction","3D reconstruction; Deep learning; High-resolution remote sensing; Image processing; Multi-scale relative discrimination; Positioning accuracy; SRGAN; Super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85137638286"
"Aburaed N.; Alkhatib M.Q.; Marshall S.; Zabalza J.; Al Ahmad H.","Aburaed, Nour (56943462800); Alkhatib, Mohammed Q. (52463211300); Marshall, Stephen (7401823400); Zabalza, Jaime (55825361600); Al Ahmad, Hussain (57222050810)","56943462800; 52463211300; 7401823400; 55825361600; 57222050810","A Comparative Study of Loss Functions for Hyperspectral SISR","2022","European Signal Processing Conference","2022-August","","","484","487","3","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141010183&partnerID=40&md5=ab49a12819fe06a77252787b549364ed","The spatial enhancement of Hyperspectral Imagery (HSI) is a popular research area among the community of image processing in general and remote sensing in particular. HSI contribute to a wide variety of industrial applications, such as Land Cover Land Use. The characterstic that distinguishes HSI from other type of images is the ability to uniquely describe objects with spectral signatures. This can be achieved due to the sensor's ability to capture reflectance in narrowly spaced wavelength bands, which yields an HSI cube with hundreds of bands. However, this ability compromises the spatial resolution of HSI, which must be improved for practicality and usability. There are several studies in the literature related to HSI Super Resolution (HSI-SR), especially using Convolutional Neural Networks (CNNs). Nonetheless, the investigation of the most suitable loss functions to train these networks is necessary and remains as an area to investigate. This paper conducts a comparative study of the most widely used loss functions and their effect on one of the state-of-the-art HSI-SR CNNs, mainly 3D-SRCNN. The paper also proposes a hybrid loss function based on the comparative results, and proves its superiority against other loss functions in terms of Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index Measurement (SSIM), and Spectral Angle Mapper (SAM). © 2022 European Signal Processing Conference, EUSIPCO. All rights reserved.","Image enhancement; Land use; Optical resolving power; Signal to noise ratio; Spectroscopy; 3d SR-convolutional neural network; Comparatives studies; Convolutional neural network; Hyper-spectral imageries; HyperSpectral; Loss functions; Research areas; Spatial enhancement; Superresolution; Remote sensing","3D SR-CNN; CNN; Hyperspectral; Loss Function; Super Resolution","Conference paper","Final","","Scopus","2-s2.0-85141010183"
"Bao W.; Zhu Z.; Hu G.; Zhou X.; Zhang D.; Yang X.","Bao, Wenxia (35193489800); Zhu, Ziqiang (58061683400); Hu, Gensheng (8644853100); Zhou, Xingen (7410094794); Zhang, Dongyan (58061772700); Yang, Xianjun (36976459000)","35193489800; 58061683400; 8644853100; 7410094794; 58061772700; 36976459000","UAV remote sensing detection of tea leaf blight based on DDMA-YOLO","2023","Computers and Electronics in Agriculture","205","","107637","","","","10.1016/j.compag.2023.107637","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146145004&doi=10.1016%2fj.compag.2023.107637&partnerID=40&md5=f4fd354efc5bcdd745d5a3ae883850ef","Tea leaf blight (TLB) is a common disease that affects the yield and quality of tea. Timely and accurate detection and monitoring of TLB can help support the precise control of the disease. This study proposed an unmanned aerial vehicle (UAV) remote sensing method based on DDMA-YOLO for effectively detecting and monitoring TLB while reducing the workload and time consumption of this process. This method used the RCAN to reconstruct high-resolution tea images to solve the problem of insufficient resolution of UAV remote sensing images. In this method, Retinex was selected to enhance the image contrast and to reduce the influence of uneven illumination. The amount of training sample data was expanded to improve the model's generalization performance. The DDMA-YOLO model was constructed to improve the accuracy of monitoring TLB. The DDMA-YOLO model was developed using the YOLOv5 network as the baseline and by adding a multiscale RFB module to the backbone to improve the extraction ability of the detailed features of diseased leaves and to reduce the problem of missed detection caused by small leaves. A dual-dimensional mixed attention (DDMA) was added to the Neck, which parallels coordinate attention with channel attention and spatial attention, integrates nonlocal attention information and local attention information, and reduces missed detection and false detection caused by dense blade distribution. The experimental results show that the proposed method was superior to the classic target detection methods Fast R-CNN, SSD, RetinaNet, YOLOv3, YOLOv4 and YOLOv5. Compared with the baseline network, the AP@0.5 of the proposed method increased by 3.8%, and the recall increased by 6.5%. © 2023 Elsevier B.V.","Aircraft detection; Antennas; Disease control; Image enhancement; Unmanned aerial vehicles (UAV); Aerial vehicle; Dual-dimensional mixed attention; Leaf blights; Multiscale RFB; Remote sensing monitoring; Remote-sensing; Superresolution; Tea leaf blight; Tea-leaves; Unmanned aerial vehicle remote sensing monitoring; crop yield; detection method; disease prevalence; image analysis; remote sensing; satellite imagery; spectral resolution; unmanned vehicle; Remote sensing","DDMA; Multiscale RFB; Super resolution; Tea leaf blight; UAV remote sensing monitoring","Article","Final","","Scopus","2-s2.0-85146145004"
"He J.; Li J.; Yuan Q.; Shen H.; Zhang L.","He, Jiang (57189887884); Li, Jie (57214207213); Yuan, Qiangqiang (36635300800); Shen, Huanfeng (8359721100); Zhang, Liangpei (8359720900)","57189887884; 57214207213; 36635300800; 8359721100; 8359720900","Spectral Response Function-Guided Deep Optimization-Driven Network for Spectral Super-Resolution","2022","IEEE Transactions on Neural Networks and Learning Systems","33","9","","4213","4227","14","10.1109/TNNLS.2021.3056181","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101743298&doi=10.1109%2fTNNLS.2021.3056181&partnerID=40&md5=3bde0ec62ce3fc03d13824617a497f51","Hyperspectral images (HSIs) are crucial for many research works. Spectral super-resolution (SSR) is a method used to obtain high-spatial-resolution (HR) HSIs from HR multispectral images. Traditional SSR methods include model-driven algorithms and deep learning. By unfolding a variational method, this article proposes an optimization-driven convolutional neural network (CNN) with a deep spatial-spectral prior, resulting in physically interpretable networks. Unlike the fully data-driven CNN, auxiliary spectral response function (SRF) is utilized to guide CNNs to group the bands with spectral relevance. In addition, the channel attention module (CAM) and the reformulated spectral angle mapper loss function are applied to achieve an effective reconstruction model. Finally, experiments on two types of data sets, including natural and remote sensing images, demonstrate the spectral enhancement effect of the proposed method, and also, the classification results on the remote sensing data set verified the validity of the information enhanced by the proposed method.  © 2012 IEEE.","Classification (of information); Convolution; Deep learning; Image enhancement; Image resolution; Neural networks; Noise abatement; Remote sensing; Spectroscopy; Convolutional neural network; HyperSpectral; Hyperspectral image; Images reconstruction; Minimisation; Optimisations; Optimization driven; Spatial resolution; Spectral response function; Spectral response functions; Spectral super-resolution .; Superresolution; article; attention; convolutional neural network; deep learning; loss of function mutation; remote sensing; validity; Image reconstruction","Convolutional neural network (CNN); hyperspectral image (HSI); optimization driven; spectral response function (SRF); spectral super-resolution (SSR)","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85101743298"
"Zuo H.; Fu C.; Li S.; Ye J.; Zheng G.","Zuo, Haobo (58031680000); Fu, Changhong (55837108000); Li, Sihang (57221848759); Ye, Junjie (57221701084); Zheng, Guangze (57226009378)","58031680000; 55837108000; 57221848759; 57221701084; 57226009378","DeconNet: End-to-End Decontaminated Network for Vision-Based Aerial Tracking","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5635712","","","","10.1109/TGRS.2022.3230043","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144796660&doi=10.1109%2fTGRS.2022.3230043&partnerID=40&md5=2c73905f7e91e2356f9cc8b9b17595d1","Vision-based aerial tracking has proven enormous potential in the field of remote sensing recently. However, challenges such as occlusion, fast motion, and illumination variation remain crucial issues for realistic aerial tracking applications. These challenges, frequently occurring from the aerial perspectives, can easily cause object feature pollution. With the contaminated object features, the credibility of trackers is prone to be substantially degraded. To address this issue, this work proposes a novel end-to-end decontaminated network, i.e., DeconNet, to alleviate object feature pollution efficiently and effectively. DeconNet mainly consists of downsampling and upsampling phases. Specifically, the decontaminated downsampling network first decreases the polluted object information with two convolution branches, enhancing the object location information. Subsequently, the decontaminated upsampling network applies the super-resolution technology to restore the object scale and shape information, with the low-to-high (LTH) encoder for further decontamination. In addition, the pooling distance (PD) loss function is carefully designed to improve the decontamination effect of the decontaminated downsampling network. Comprehensive evaluations on four well-known aerial tracking benchmarks validate the effectiveness of DeconNet. Especially, the proposed tracker has superior performance on the sequences with feature pollution. Besides, real-world tests on an aerial platform have proven the efficiency of DeconNet with 30.6 fps.  © 1980-2012 IEEE.","Antennas; Network coding; Pollution detection; Signal sampling; Aerial tracking; Down sampling; Downsampling-upsampling strategy; End to end; End-to-end decontaminated network; Low-to-high; Low-to-high encoder; Pooling distance loss; Upsampling; Vision based; Vision-based aerial tracking; aerial survey; algorithm; network analysis; remote sensing; software; tracking; Remote sensing","Downsampling-upsampling strategy; end-to-end decontaminated network (DeconNet); low-to-high (LTH) encoder; pooling distance (PD) loss; vision-based aerial tracking","Article","Final","","Scopus","2-s2.0-85144796660"
"Karalasingham S.; Deo R.C.; Casillas-Perez D.; Raj N.; Salcedo-Sanz S.","Karalasingham, Sagthitharan (57909439000); Deo, Ravinesh C. (8630380500); Casillas-Perez, David (57189662377); Raj, Nawin (57202303498); Salcedo-Sanz, Sancho (12789591800)","57909439000; 8630380500; 57189662377; 57202303498; 12789591800","Downscaling Surface Albedo to Higher Spatial Resolutions With an Image Super-Resolution Approach and PROBA-V Satellite Images","2023","IEEE Access","11","","","5558","5577","19","10.1109/ACCESS.2023.3236253","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147314822&doi=10.1109%2fACCESS.2023.3236253&partnerID=40&md5=1e395f91d98b3639dafc1e673d332317","For bifacial solar photovoltaic panels, surface albedo plays a crucial role in estimating the radiant energy. Since land surfaces are heterogeneous, the actual albedo of the surface where the solar photovoltaic panel is placed can vary widely and its temporality and sparsity present a significant challenge for renewable energy engineers. This paper develops a new image super-resolution deep learning model based on convolutional neural network to generate high resolution spatial representations of surface albedo from coarse resolution remote sensing-based data. For selected Australian locations, we generated a higher resolution surface albedo using imagery from PROBA-V/SPOT Earth Observation satellites. We proposed a Deep Downscaling Spectral Model with Attention (DDSA) with the capability of processing 10-day albedo images captured at a relatively low (≈ 1 km) resolution. The proposed DDSA was then applied to downscale observed surface albedo and generate predicted albedo at 500 m, 333 m and 250 m resolutions. The proposed model was benchmarked with alternative deep learning, super-resolution approaches: Super-Resolution Convolution Neural Network (SRCNN), Enhanced Deep Super-Resolution network (EDSR), Efficient Sub-Pixel Convolutional Neural Network (ESPCN) and Residual Dense Network (RDN). The results showed that the proposed DDSA model outperformed all comparative models in terms of the mean square error (MSE) $\approx ~0.0041$ , signal-to-noise ratio (PSNR) $\approx ~39.471$ , Structural Similarity Index (SSIM) $\approx ~0.999$ vs. an MSE $\approx $ [0.0140-0.0387], PSNR $\approx $ [29.761-33.850], SSIM $\approx $ [0.9994-0.999]). We also cross-validated the downscaled images with satellite imagery and ground-based observations, which reaffirmed the proposed DDSA model's ability to produce high resolution surface albedo maps and its potential applications for granular scale tracking and mapping solar energy where bifacial solar photovoltaic panels are placed. © 2013 IEEE.","Deep learning; Mean square error; Neural networks; Optical resolving power; Remote sensing; Satellite imagery; Signal to noise ratio; Solar concentrators; Solar power generation; Surface measurement; Surface waters; Bifacial solar photovoltaic system; Depth-wise separable convolution; Down-scaling; Energy resolutions; Image super resolutions; Land surface; Predictive models; Remote-sensing; Sea surfaces; Solar photovoltaic system; Spatial resolution; Superresolution; Surface albedo; Surface albedo downscaling; Convolution","bifacial solar photovoltaic system; depth-wise separable convolution; image super resolution; Surface albedo downscaling","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85147314822"
"Huang G.; Liu Y.; Lu W.; Zhang Y.; Peng H.","Huang, Guoxing (57189599542); Liu, Yipeng (47962202000); Lu, Weidang (34973243500); Zhang, Yu (57221362299); Peng, Hong (57158112500)","57189599542; 47962202000; 34973243500; 57221362299; 57158112500","Remote Sensing Image Super-Resolution Based on Lorentz Fitting","2022","Mobile Networks and Applications","27","4","","1615","1628","13","10.1007/s11036-021-01870-x","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124329228&doi=10.1007%2fs11036-021-01870-x&partnerID=40&md5=d9c4fcb1565ddec1586b85b10006eed9","Due to the effect of the model mismatch error between the point spread function (PSF) and actual blur kernel, the performance of remote sensing image super-resolution (SR) is usually poor. In this paper, we propose a novel remote sensing image super-resolution method based on Lorentz fitting, to improve the reconstruction performance in actual application. Note that the actual blur kernel of remote sensing image is non-stationary and usually has non-smooth phenomenon in kernel edge. It is also asymmetric that the degree of blur is not same in radial and tangential directions, and blur is in a sense that the amount of blur depends on pixel locations in a sensor. This paper presents a flexible parametric blur kernel model based on a linear combination of Lorentz basic two-dimensional (2-D) patterns. The proposed model can provide flexible shapes for blur kernel with a different symmetry and non-smooth edge, which can model complicated blur due to various degradation factors accurately. Combining with the proposed PSF model and the optimized adaptive step size strategy, we proposed a remote sensing image super-resolution method to accelerate the convergence of super-resolution outputs. Experiment results have shown that the proposed method outperforms the other recent developed PSF model based remote sensing image super-resolution methods. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Image enhancement; Image resolution; Remote sensing; Asymmetric blur model; Blur estimation; Blur modeling; Image super resolutions; Lorentz fitting; Parametric blur estimation; Performance; Remote sensing images; Remote-sensing; Superresolution methods; Optical transfer function","Asymmetric blur model; Image super-resolution; Lorentz fitting; Parametric blurs estimation; Remote sensing","Article","Final","","Scopus","2-s2.0-85124329228"
"Wang H.; Li N.; Li X.; Zhou C.; Song L.","Wang, Huiji (57738091700); Li, Nan (57307918800); Li, Xuankui (57737658900); Zhou, Cheng (57191414180); Song, Lijun (8692680100)","57738091700; 57307918800; 57737658900; 57191414180; 8692680100","Three-dimensional Correlation Imaging Based on Time-of-flight Technology; [基于飞行时间技术的三维关联成像]","2022","Guangzi Xuebao/Acta Photonica Sinica","51","5","0511003","","","","10.3788/gzxb20225105.0511003","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131795346&doi=10.3788%2fgzxb20225105.0511003&partnerID=40&md5=47b435f001c3e51299abbaf7aec56b37","Different from traditional optical imaging technology, correlated imaging uses a single-pixel detector and a spatial light modulator to reconstruct object image information based on correlation calculations, having the characteristics of super-resolution, non-local, and anti-interference. Time-of-flight (TOF) technology is an effective method for optical remote sensing and three-dimensional imaging of target recognition. Compared with traditional laser correlation imaging, 3D correlation imaging can not only obtain the two-dimensional light field intensity information of the target object, but also effectively obtain the longitudinal distance information between the target objects, so that the size and position of the imaging target can be quantitatively analyzed. Three-dimensional correlation imaging technology mainly includes steroscopic vision and TOF imaging technology. To improve the image reconstruction quality of intensity 3D correlation imaging, this paper employs differential correlation imaging reconstruction algorithm and TOF technology, and the theoretical formula of intensity correlation 3D imaging is deduced. The working mode is that the short-pulse laser forms pseudothermal light through the rotating frosted glass. After passing through the beam splitter, one of the beams irradiates the target object to be measured and then is received by the Photomultiplier Tube (PMT); the other beam is detected by the array detector. The high-speed data acquisition system digitizes the peak light intensity signal detected by the PMT into discrete data points, uses the TOF technology to divide the detection signal into slice signals of different time (distance), and then integrates the signals in the respective slices to obtain the slice signal detection value, and finally the DGI algorithm is used to perform two-dimensional correlation imaging reconstruction calculation for each slice signal separately. This paper mainly investigates the influence of the light source laser power and reconstruction algorithm parameters on the imaging quality in the pseudo-thermo-optic 3D correlation imaging. The imaging results of two flat objects to be measured (the front-end target is a four-pointed star and the back-end target is the letter F) with a distance of 80 cm and a resolution of 200 pixel × 200 pixel in the numerical simulation are given. Among them, the simulation pulse laser uses the function p(t)=exp(-τ2/σ2), the detection times is 20 000, and the sampling rate is 50%. In order to further verify its effectiveness, a pseudo-thermo-optical 3D correlation imaging experimental system is built. This paper uses a 532 nm pulsed laser as the light source and frosted glass as the spatial light modulator to build a set of pseudo-thermal light three-dimensional correlation imaging experimental system, which realizes the three-dimensional image reconstruction of a 200 pixel×200 pixel target object with a longitudinal distance of 60 cm at an absolute distance of 5.5 m in the laboratory environment. The reconstructed 3D slice images that are lower than the set threshold parameters in the simulation and experimental results are reset to zero, thereby reducing the influence of the background noise of other slice images on the quality of the reconstructed images during the 3D correlation imaging stacking process. Within a certain threshold parameter range, appropriately increasing the threshold parameter can effectively improve the reconstruction quality of 3D correlated imaging images. To further investigate the performance of the 3D correlation imaging experimental system, experimental tests are carried out for 3D correlation imaging under different laser powers, respectively. The experimental verification shows that by properly increasing the power of the laser light source, the influence of the time jitter of the echo signal on the reconstructed image quality can be effectively suppressed, and the longitudinal distance reconstruction quality and measurement accuracy of the 3D image can be further improved. The work has a reference significance for promoting the application of intensity 3D correlation imaging technology in the field of lidar imaging. © 2022, Science Press. All right reserved.","Data acquisition; Image enhancement; Image reconstruction; Imaging systems; Light modulators; Optical correlation; Photomultipliers; Remote sensing; Signal detection; Timing circuits; 3D object; Correlation imaging; Differential correlation; Differential correlation imaging algorithm; Imaging algorithm; Multi-target 3d object; Multi-targets; Three-dimensional correlation; Three-dimensional correlation imaging; Time-of-flight technologies; Timing alignment; Pixels","Differential correlation imaging algorithm; Multi-target 3D objects; Three-dimensional correlation imaging; Time-of-flight technology; Timing alignment","Article","Final","","Scopus","2-s2.0-85131795346"
"Aburaed N.; Alkhatib M.Q.; Marshall S.; Zabalza J.; Ahmad H.A.","Aburaed, Nour (56943462800); Alkhatib, Mohammed Q. (52463211300); Marshall, Stephen (7401823400); Zabalza, Jaime (55825361600); Ahmad, Hussain Al (57222050810)","56943462800; 52463211300; 7401823400; 55825361600; 57222050810","SISR of Hyperspectral Remote Sensing Imagery Using 3D Encoder-Decoder RUNet Architecture","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","1516","1519","3","10.1109/IGARSS46834.2022.9883578","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140372024&doi=10.1109%2fIGARSS46834.2022.9883578&partnerID=40&md5=e3861785f80a9a7c5f9da7334a153f8f","Single Image Super Resolution (SISR) refers to the spatial enhancement of an image from a single Low Resolution (LR) observation. This topic is of particular interest to remote sensing community, especially in the area of Hyperspectral Imagery (HSI) due to their high spectral resolution but limited spatial resolution. Enhancing the spatial resolution of HSI is a pre-requisite that boosts the accuracy of other image processing tasks, such as object detection and classification. This paper deals with SISR of HSI through the 3D expansion of Robust UNet (RUNet). The network is developed, trained, and tested over two datasets, and compared against the original 2D-RUNet and other state-of-the-art approaches. Quantitative and qualitative evaluation show the superiority of 3D-RUNet and its ability to preserve the spectral fidelity of the enhanced HSI. © 2022 IEEE.","Image enhancement; Image resolution; Object detection; Signal encoding; Spectral resolution; Spectroscopy; 3d convolution; 3d-robust unet; Hyper-spectral imageries; HyperSpectral; Hyperspectral remote sensing; Image super resolutions; Remote-sensing; Single image super resolution; Single images; Spatial resolution; Remote sensing","3D Convolution; 3D-RUNet; Hyperspectral; Remote Sensing; Single Image Super Resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85140372024"
"Gavade A.B.; Rajpurohit V.S.","Gavade, Anil B (57215036982); Rajpurohit, Vijay S (24473204700)","57215036982; 24473204700","S-DolLion-MSVNN: A Hybrid Model for Developing the Super-Resolution Image From the Multispectral Satellite Image","2022","Computer Journal","65","4","","757","772","15","10.1093/comjnl/bxaa106","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130094277&doi=10.1093%2fcomjnl%2fbxaa106&partnerID=40&md5=e51541422fcd4ee372e1e1a980c50743","Super-resolution offers a new image with high resolution from the low-resolution (LR) image that is highly employed for the numerous remote sensing applications. Most of the existing techniques for formation of the super-resolution image exhibit the loss of quality and deviation from the original multi-spectral LR image. Thus, this paper aims at proposing an efficient super-resolution method using the hybrid model. The hybrid model is developed using the support vector regression model and multi-support vector neural network (MSVNN), and the weights of the MSVNN is tuned optimally using the proposed algorithm. The proposed DolLion algorithm is the integration of the dolphin echolocation algorithm and lion optimization algorithm that exhibits better convergence and offers a global optimal solution. The experimentation is performed using the datasets taken from the multi-spectral scene images. The optimal and effective formation of the super-resolution image using the proposed hybrid model outperforms the existing methods, and the analysis using the second-derivative-like measure of enhancement (SDME) ensures that the proposed method is better and yields a maximum SDME of 67.6755 dB. © 2020 The British Computer Society 2020. All rights reserved.","Image enhancement; Regression analysis; Remote sensing; DE; LOA; Regression modelling; Resolution images; Super-resolution image; Superresolution; Support regression model; Support vector; Support vector neural network; Vector neural networks; Optical resolving power","DE; LOA; super-resolution image; support regression model; support vector neural network","Article","Final","","Scopus","2-s2.0-85130094277"
"Wang Q.; Wang S.; Chen M.; Zhu Y.","Wang, Qingjian (57984916500); Wang, Sen (38863494200); Chen, Mingfang (57842977400); Zhu, Yang (57984916400)","57984916500; 38863494200; 57842977400; 57984916400","DARN: Distance Attention Residual Network for Lightweight Remote-Sensing Image Superresolution","2023","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","16","","","714","724","10","10.1109/JSTARS.2022.3227509","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144746523&doi=10.1109%2fJSTARS.2022.3227509&partnerID=40&md5=93da8e7ba9869c073953e8d495f96fd8","The application of single-image superresolution (SISR) in remote sensing is of great significance. Although the state-of-the-art convolution neural network (CNN)-based SISR methods have achieved excellent results, the large model and slow speed make it difficult to deploy in real remote sensing tasks. In this article, we propose a compact and efficient distance attention residual network (DARN) to achieve a better compromise between model accuracy and complexity. The distance attention residual connection block (DARCB), the core component of the DARN, uses multistage feature aggregation to learn more accurate feature representations. The main branch of the DARCB adopts a shallow residual block (SRB) to flexibly learn residual information to ensure the robustness of the model. We also propose a distance attention block (DAB) as a bridge between the main branch and the branch of the DARCB; the DAB can effectively alleviate the loss of detail features in the deep CNN extraction process. Experimental results on two remote sensing and five super-resolution benchmark datasets demonstrate that the DARN achieves a better compromise than existing methods in terms of performance and model complexity. In addition, the DARN achieves the optimal solution compared with the state-of-the-art lightweight remote sensing SISR method in terms of parameter amount, computation amount, and inference speed. Our code will be available at https://github.com/candygogogogo/DARN. © 2008-2012 IEEE.","Benchmarking; Complex networks; Extraction; Feature extraction; Image reconstruction; Job analysis; Optical resolving power; Remote sensing; Computational modelling; Convolution neural network; Features extraction; Image super resolutions; Images reconstruction; Lightweight; Remote-sensing; Single image super-resolution; Single images; Superresolution; Task analysis; accuracy assessment; artificial neural network; complexity; image analysis; image resolution; remote sensing; Convolution","Convolution neural network; lightweight; remote sensing; single image superresolution (SISR)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85144746523"
"Pan Y.; Duan L.; Li M.; Song P.; Xv N.; Liu J.; Le Y.; Li M.; Wang C.; Yu S.; Rosenfeld D.; Seinfeld J.H.; Li P.","Pan, Yuqing (57778922000); Duan, Lei (57779945600); Li, Mingqi (57780289800); Song, Pinqing (57777905900); Xv, Nan (57494240200); Liu, Jing (55810523700); Le, Yifei (57779945700); Li, Mengying (57215425821); Wang, Cui (57876146600); Yu, Shaocai (7405728922); Rosenfeld, Daniel (58032009600); Seinfeld, John H. (57219263313); Li, Pengfei (56397302900)","57778922000; 57779945600; 57780289800; 57777905900; 57494240200; 55810523700; 57779945700; 57215425821; 57876146600; 7405728922; 58032009600; 57219263313; 56397302900","Widespread missing super-emitters of nitrogen oxides across China inferred from year-round satellite observations","2023","Science of the Total Environment","864","","161157","","","","10.1016/j.scitotenv.2022.161157","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144817654&doi=10.1016%2fj.scitotenv.2022.161157&partnerID=40&md5=523cd900fa9962c85e05abe15a47cb73","Nitrogen oxides (NOx ≡ NO + NO2) play a central role in air pollution and are targeted for emission mitigation by environmental protection agencies globally. Unique challenges for mitigation are presented by super-emitters, typically with the potential to dominate localized NOx budgets. Nevertheless, identifying super-emitters still challenges emission mitigation, while the spatial resolution of emission monitoring rises continuously. Here we develop an efficient, super-resolution (1 × 1 km2) inverse model based on year-round TROPOMI satellite observations over China. Consequently, we resolve hundreds of super-emitters in virtually every corner of China, even in remote and mountainous areas. They are attributed to individual plants or parks, mostly associated with industrial sectors, like energy, petrochemical, and iron and steel industries. State-of-the-art bottom-up emission estimates (i.e., MEICv1.3 and HTAPv2), as well as classic top-down inverse methods (e.g., a CTM coupled with the Ensemble Kalman Filter), do not adequately identify these super-emitters. Remarkably, more than one hundred super-emitters are unambiguously missed, while the establishments or discontinuations of the super-emitters potentially lead to under- or over-estimates, respectively. Moreover, evidence shows that these super-emitters generally dominate the NOx budget in a localized area (e.g., equivalent to a spatial scale of a medium-sized county). Although our dataset is incomplete nationwide due to the undetectable super-emitters on top of high pollution, our results imply that super-emitters contribute significantly to national NOx budgets and thus suggest the necessity to address the NOx budget by revisiting super-emitters on a large scale. Integrating the results we obtain here with a multi-tiered observation system can lead to identification and mitigation of anomalous NOx emissions. © 2022","China; Budget control; Environmental Protection Agency; Inverse problems; Optical resolving power; Satellites; Steelmaking; China; Emissions mitigation; Emissions monitoring; Environmental Protection Agency's; Localised; Nitrogen oxides (NO x); NO x; Satellite observations; Spatial resolution; Super-emitter; atmospheric pollution; data set; emission control; emission inventory; ensemble forecasting; Kalman filter; nitrogen oxides; observational method; petrochemical industry; pollution monitoring; remote sensing; satellite data; targeting; Nitrogen oxides","China; Nitrogen oxides; Satellite observations; Super-emitters","Article","Final","","Scopus","2-s2.0-85144817654"
"Chu F.; Liu H.; Wang Z.; Cao Z.","Chu, Fengguo (58066885900); Liu, Hu (57196120901); Wang, Ziyu (58067042900); Cao, Zhiyuan (58066886000)","58066885900; 57196120901; 58067042900; 58066886000","Super-resolution Reconstruction of Airborne Remote Sensing Images based on Multi-scale Fusion","2022","2022 3rd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering, ICBAIE 2022","","","","648","651","3","10.1109/ICBAIE56435.2022.9985886","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146338222&doi=10.1109%2fICBAIE56435.2022.9985886&partnerID=40&md5=dbf558c84d54cbfad12d08b5eebdaf74","To extract more detailed features of airborne remote sensing images to obtain more information, super-resolution reconstruction is performed on them. However, the existing super-resolution reconstruction algorithms of airborne remote sensing images have poor feature extraction capabilities, and smooth image edges, and are difficult to restore high-frequency information effectively. In this paper, the residual features of different residual modules are densely connected to form a dense group (DG), which combines different residual features to reduce the redundancy of features and ensure the effective transmission of high-frequency residual features. Further, the residual features of DG are densely connected to realize the reuse of information, and combined with multi-scale fusion, a two-branch lightweight multi-scale fusion super-resolution reconstruction network is proposed. The experimental results show that the algorithm has good performance and is lightweight, and can obtain a better reconstruction effect.  © 2022 IEEE.","Edge detection; Image fusion; Information use; Optical resolving power; Remote sensing; Airborne remote sensing; Airborne remote sensing image; Component; Dense network; Image-based; Lightweight; Multiscale fusion; Remote sensing images; Residual dense network; Super-resolution reconstruction; Image reconstruction","airborne remote sensing image; component; lightweight; multi-scale fusion; residual dense network; super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85146338222"
"Yang X.; Li F.; Lu M.; Xin L.; Lu X.; Zhang N.","Yang, Xue (57204629969); Li, Feng (57171116800); Lu, Ming (56399795000); Xin, Lei (57183670600); Lu, Xiaotian (57189345043); Zhang, Nan (57202033633)","57204629969; 57171116800; 56399795000; 57183670600; 57189345043; 57202033633","New super-resolution reconstruction method based on Mixed Sparse Representations; [混合稀疏表示模型的超分辨率重建]","2022","National Remote Sensing Bulletin","26","8","","1685","1697","12","10.11834/jrs.20219409","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138624495&doi=10.11834%2fjrs.20219409&partnerID=40&md5=72b4e5f23e72b173d5dae4de7fdf80fa","When processing remote sensing images with complex features, the conventional Super-Resolution Reconstruction (SRR) methods are often not ideal, especially for remote sensing images containing various non-uniform object information. A universal method to solve this problem is difficult to construct at present. A new SR reconstruction method of mixed sparse representation model (MSR-SRR) combined with the sparse representation and non-convex high-order total variational regularizer has been proposed to solve this problem. In this method, the sparse representation of remote sensing images in multiple transform domains is regarded as a prior probability model, and the SR reconstruction is completed by regularization. The obtained image not only retains the edge information of the image result by SR reconstruction, but also smoothens the“ladder effect”of the image. The efficiency of operation and the quality of SR reconstruction results are improved by an effective re-weighted l1 alternating direction method. Results show that the sharpness of the image increases by 31.74% on the average, the half-peak width of PSFs is the largest, and the Gaussian variance value reaches 1.8415. The GF-4 satellite images have been selected to carry out validation experiment to verify the feasibility and validity of MSR-SRR. The reconstruction results show that the images using the MSR-SRR method have better definition, richer details, and higher quality than those with non-uniform interpolation, the POCS method, and IBP method. The support vector machine method is used to classify and evaluate the accuracy of the images before and after SR reconstruction. The results show that the overall accuracy and Kappa coefficient of the reconstructed super-resolution image are improved more significantly than the original image classification results. The OA value increases by 5.96%, and the Kappa coefficient increases by 9.7%. The findings confirmed that the MSR-SRR method is effective and feasible and has extensive practical value. © 2022 Chinese Society of Forestry. All rights reserved.","Image classification; Image enhancement; Image reconstruction; Optical resolving power; Support vector machines; GF-4; Mixed sparse representation; Non-convex; Reconstruction method; Remote-sensing; Sparse representation; Super-resolution reconstruction; Total variation; Total-variation; Remote sensing","GF-4; Mixed Sparse Representation (MSR); Non-convex; remote sensing; Super-Resolution Reconstruction (SRR); Total Variation (TV)","Article","Final","","Scopus","2-s2.0-85138624495"
"Li R.; Shen Y.","Li, Ronghao (58018957900); Shen, Ying (56763084800)","58018957900; 56763084800","YOLOSR-IST: A deep learning method for small target detection in infrared remote sensing images based on super-resolution and YOLO","2023","Signal Processing","208","","108962","","","","10.1016/j.sigpro.2023.108962","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148033686&doi=10.1016%2fj.sigpro.2023.108962&partnerID=40&md5=65403992da601a1c659dc76f84c640c5","Infrared remote sensing imaging has a wide range of military and civilian applications. The detection of dim small targets is one of the most valuable research topics in this field. However, model-driven methods are not robust enough to noise, target size and contrast in images, and the currently proposed deep learning methods have insufficient ability to process and fuse important features, resulting in more missed detections and false alarms in these methods. To solve these problems, in this paper, a detection method based on super-resolution and deep learning is proposed. First, we use super-resolution preprocessing and multiple data augmentation on the input images. Secondly, based on the characteristics of infrared small target, we propose a new deep learning network named YOLOSR-IST. This network is based on a series of improvements on YOLOv5, including adding Coordinate Attention to backbone, introducing a high-resolution feature map P2 in the feature fusion, and replacing bottleneck layer of the C3 module in the head of the network with Swin Transformer Blocks. The proposed method achieves mAP@0.5 of 99.2% and 94.6% on two public datasets respectively, and solves the problem of missed detections and false alarms more effectively compared with current advanced data-driven detection methods. © 2023","Deep learning; Errors; Learning systems; Optical resolving power; Remote sensing; Deep learning; Detection methods; Falsealarms; Infrared remote sensing; Learning methods; Missed detections; Remote sensing images; Small target detection; Superresolution; YOLOv5; Military applications","Deep learning; Infrared remote sensing; Small target detection; Super-resolution; YOLOv5","Article","Final","","Scopus","2-s2.0-85148033686"
"Cai Y.; Yang Y.; Shang Y.; Shen Z.; Yin J.","Cai, Yuxiang (57392976200); Yang, Yingchun (57881064400); Shang, Yongheng (57711843000); Shen, Zhengwei (57272299200); Yin, Jianwei (8249720800)","57392976200; 57881064400; 57711843000; 57272299200; 8249720800","DASRSNet: Multitask Domain Adaptation for Super-Resolution-Aided Semantic Segmentation of Remote Sensing Images","2023","IEEE Transactions on Geoscience and Remote Sensing","61","","5600218","","","","10.1109/TGRS.2022.3232129","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146253965&doi=10.1109%2fTGRS.2022.3232129&partnerID=40&md5=fbd0135e11bc710fdae28751d59896ce","Unsupervised domain adaptation (UDA) has become an important technique for cross-domain semantic segmentation (SS) in the remote sensing community and obtained remarkable results. However, when transferring from high-resolution (HR) remote sensing images to low-resolution (LR) images, the existing UDA frameworks always fail to segment the LR target images, especially for small objects (e.g., cars), due to the severe spatial resolution shift problem. In this article, to improve the segmentation ability of UDA models for LR target images and small objects, we propose a novel multitask domain adaptation network (DASRSNet) for SS of remote sensing images with the aid of super-resolution (SR). The proposed DASRSNet contains domain adaptation for SS (DASS) branch, domain adaptation for SR (DASR) branch, and feature affinity (FA) module. Specifically, the DASS and DASR branches share the same encoder to extract the domain-invariant features for the target and source domains, and these two branches utilize different decoders and discriminators to conduct cross-domain SS task and SR task, which align the domain shift in output space and image space, respectively. Finally, the FA module, which involves the proposed FA loss, is applied to enhance the affinity of SS features and SR features for both source and target domains. The experimental results on the cross-city aerial datasets demonstrate the effectiveness and superiority of our DASRSNet against the recent UDA models.  © 1980-2012 IEEE.","Antennas; Feature extraction; Image enhancement; Image resolution; Job analysis; Semantic Segmentation; Semantics; Space optics; Adaptation models; Adversarial learning; Domain adaptation; Features extraction; Multi-task learning; Multitask learning; Remote sensing images; Remote-sensing; Semantic segmentation; Spatial resolution; Super-resolution; Superresolution; Task analysis; Unsupervised domain adaptation; algorithm; image resolution; machine learning; model; remote sensing; segmentation; unsupervised classification; Remote sensing","Adversarial learning; multitask learning (MTL); remote sensing images; semantic segmentation (SS); super-resolution (SR); unsupervised domain adaptation (UDA)","Article","Final","","Scopus","2-s2.0-85146253965"
"Wang F.; Wang C.; Chen M.; Gong W.; Zhang Y.; Han S.; Situ G.","Wang, Fei (57272090000); Wang, Chenglong (56573535200); Chen, Mingliang (55733271500); Gong, Wenlin (26640292100); Zhang, Yu (57393190800); Han, Shensheng (7405944503); Situ, Guohai (6602918047)","57272090000; 56573535200; 55733271500; 26640292100; 57393190800; 7405944503; 6602918047","Far-field super-resolution ghost imaging with a deep neural network constraint","2022","Light: Science and Applications","11","1","1","","","","10.1038/s41377-021-00680-w","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122089390&doi=10.1038%2fs41377-021-00680-w&partnerID=40&md5=03fd60febc89705ddf31d1c69a481ecf","Ghost imaging (GI) facilitates image acquisition under low-light conditions by single-pixel measurements and thus has great potential in applications in various fields ranging from biomedical imaging to remote sensing. However, GI usually requires a large amount of single-pixel samplings in order to reconstruct a high-resolution image, imposing a practical limit for its applications. Here we propose a far-field super-resolution GI technique that incorporates the physical model for GI image formation into a deep neural network. The resulting hybrid neural network does not need to pre-train on any dataset, and allows the reconstruction of a far-field image with the resolution beyond the diffraction limit. Furthermore, the physical model imposes a constraint to the network output, making it effectively interpretable. We experimentally demonstrate the proposed GI technique by imaging a flying drone, and show that it outperforms some other widespread GI techniques in terms of both spatial resolution and sampling ratio. We believe that this study provides a new framework for GI, and paves a way for its practical applications. © 2022, The Author(s).","Deep neural networks; Diffraction; Image reconstruction; Medical imaging; Pixels; Remote sensing; Biomedical imaging; Far-field; Ghost imaging; Large amounts; Low light conditions; Neural network constraints; Physical modelling; Remote-sensing; Single pixel; Superresolution; Optical resolving power","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85122089390"
"Xu Y.; Luo W.; Hu A.; Xie Z.; Xie X.; Tao L.","Xu, Yongyang (57095192900); Luo, Wei (55584802653); Hu, Anna (57205419850); Xie, Zhong (36164790400); Xie, Xuejing (57212576401); Tao, Liufeng (57210018064)","57095192900; 55584802653; 57205419850; 36164790400; 57212576401; 57210018064","TE-SAGAN: An Improved Generative Adversarial Network for Remote Sensing Super-Resolution Images","2022","Remote Sensing","14","10","2425","","","","10.3390/rs14102425","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130994887&doi=10.3390%2frs14102425&partnerID=40&md5=28149b448945d41d9c05e4fe052bb09d","Resolution is a comprehensive reflection and evaluation index for the visual quality of remote sensing images. Super-resolution processing has been widely applied for extracting information from remote sensing images. Recently, deep learning methods have found increasing application in the super-resolution processing of remote sensing images. However, issues such as blurry object edges and existing artifacts persist. To overcome these issues, this study proposes an improved generative adversarial network with self-attention and texture enhancement (TE-SAGAN) for remote sensing super-resolution images. We first designed an improved generator based on the residual dense block with a self-attention mechanism and weight normalization. The generator gains the feature extraction capability and enhances the training model stability to improve edge contour and texture. Subsequently, a joint loss, which is a combination of L1-norm, perceptual, and texture losses, is designed to optimize the training process and remove artifacts. The L1-norm loss is designed to ensure the consistency of low-frequency pixels; perceptual loss is used to entrench medium-and high-frequency details; and texture loss provides the local features for the super-resolution process. The results of experiments using a publicly available dataset (UC Merced Land Use dataset) and our dataset show that the proposed TE-SAGAN yields clear edges and textures in the super-resolution reconstruction of remote sensing images. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Image enhancement; Image texture; Land use; Optical resolving power; Remote sensing; Textures; Attention mechanisms; Joint loss; Normalisation; Remote sensing images; Remote-sensing; Resolution images; Self-attention mechanism; Super-resolution image; Superresolution; Weight normalization; Generative adversarial networks","generative adversarial network; joint loss; self-attention mechanism; super-resolution image; weight normalization","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85130994887"
"Lee S.-J.; Lee S.-G.","Lee, Seung-Jae (55517126500); Lee, Sun-Gu (54398799900)","55517126500; 54398799900","Super-Resolution Procedure for Target Responses in KOMPSAT-5 Images","2022","Sensors","22","19","7189","","","","10.3390/s22197189","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139811315&doi=10.3390%2fs22197189&partnerID=40&md5=fbb1b99e397d6e75b5f98271d8696c3e","Recently, target analysis using satellite SAR images has received much attention in the area of satellite SAR remote sensing. Because the spatial resolution of the target response in the satellite SAR image is a main factor that has a large effect on target analysis performances, the improvement of the spatial resolution of target response is required to enhance the target analysis capability. However, the spatial resolution is already determined in the satellite SAR system design process. To solve the above problem, the super-resolution techniques that have been applied to radar images can be utilized. However, the application of the super-resolution techniques to the target response in the satellite SAR image is not simple due to the following reasons. First, the target’s motion induces severe blurring of the target response, which impedes the successful improvement of spatial resolution. Next, the zero-region in the frequency spectrum of the target image containing the target response also hinders the generation of the super-resolved image. To successfully improve spatial resolution of the satellite SAR image, the super-resolution techniques should be combined with proper preprocessing steps that can cope with the above two issues. In this paper, the whole super-resolution procedure for target responses in KOMPSAT-5 images is described. To the best of the authors’ knowledge, the description of the whole super-resolution procedure for target responses is the first ever attempt in the area of satellite SAR. First, a target image containing the target response is extracted from a large-scale KOMPSAT-5 image. Subsequently, the target image is transformed to be appropriate for the utilization of super-resolution techniques by proper preprocessing steps, considering the direction of super resolution and the motion of the target. Then, some super-resolution techniques are utilized to improve the spatial resolutions and qualities of the target images. The super-resolution performances of the proposed scheme are validated using various target images for point static, extended static, and extended moving targets. The novelties of this paper can be summarized as follows: (1) the practical design of whole super-resolution processing for real satellite SAR images; (2) the performance evaluation of super-resolution techniques on real satellite SAR images. The results show that the proposed scheme can led to noticeable improvements of spatial resolution of the target images for various types of targets with reliable computation times. In addition, the proposed scheme also enhanced PSLR, ISLR, and IC, leading to clearer scattering information of the principal scatterers. Consequently, the proposed method can assist in extracting more precise and meaningful information for targets represented in KOMPSAT-5 images, which means great potential for target recognition. © 2022 by the authors.","Motion; Image analysis; Image enhancement; Image resolution; Radar imaging; Radar target recognition; Remote sensing; Satellites; Space-based radar; KOMPSAT-5; Resolution techniques; SAR Images; SAR remote sensing; Satellite SAR; Spatial resolution; Superresolution; Target analysis; Target images; Target response; motion; Synthetic aperture radar","KOMPSAT-5; SAR remote sensing; satellite SAR; super-resolution; target response","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85139811315"
"Salaudeen H.; Çelebi E.","Salaudeen, Habeeb (57481579000); Çelebi, Erbuğ (35101468100)","57481579000; 35101468100","Pothole Detection Using Image Enhancement GAN and Object Detection Network","2022","Electronics (Switzerland)","11","12","1882","","","","10.3390/electronics11121882","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131893482&doi=10.3390%2felectronics11121882&partnerID=40&md5=e4f337cd6b2d8168d35f0dbff1484921","Many datasets used to train artificial intelligence systems to recognize potholes, such as the challenging sequences for autonomous driving (CCSAD) and the Pacific Northwest road (PNW) datasets, do not produce satisfactory results. This is due to the fact that these datasets present complex but realistic scenarios of pothole detection tasks than popularly used datasets that achieve better results but do not effectively represents realistic pothole detection task. In remote sensing, super-resolution generative adversarial networks (GAN), such as enhanced super-resolution generative adversarial networks (ESRGAN), have been employed to mitigate the issues of small-object detection, which has shown remarkable performance in detecting small objects from low-quality images. Inspired by this success in remote sensing, we apply similar techniques with an ESRGAN super-resolution network to improve the image quality of road surfaces, and we use different object detection networks in the same pipeline to detect instances of potholes in the images. The architecture we propose consists of two main components: ESRGAN and a detection network. For the detection network, we employ both you only look once (YOLOv5) and EfficientDet networks. Comprehensive experiments on different pothole detection datasets show better performance for our method compared to similar state-of-the-art methods for pothole detection. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","","deep learning; GAN; object detection; pothole detection; small object detection; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85131893482"
"Yu C.-H.; Hsieh M.-C.; Ren H.","Yu, Ching-Hsiang (57798132800); Hsieh, Mon-Chai (57797898500); Ren, Hsuan (7202794047)","57798132800; 57797898500; 7202794047","Self-Supervised Super-Resolution on Sentinel-2 Imagery; [基於自監督學習之超解析度成像法應用於Sentinel-2 衛星影像]","2022","Journal of the Chinese Institute of Civil and Hydraulic Engineering","34","3","","243","248","5","10.6652/JoCICHE.202205_34(3).0007","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134034292&doi=10.6652%2fJoCICHE.202205_34%283%29.0007&partnerID=40&md5=2cfc5d98ee95250c4fb32eae6a01700f","Convolutional neural networks have been adopted in super-resolution algorithm inrecent years. These supervised learning methods can train the model through external image sets to improve the image resolution of specific feature such as faces or buildings. Because they need large amount of training images, it usually consumes lots of computation cost. This study implements the Zeroshot Super-resolution (ZSSR) method developed by Assaf Shocher and applied to improve the spatial resolution of Sentinel-2 images. ZSSR is a self-supervised learning method that does not need the pre-training process with image data set. It only needs to learn the internal structural features of the test image itself. The experimental results show that ZSSR can improve peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) by 4.67% and 3.35% compared with bicubic interpolation, which are comparable to supervised learning methods that consume training resources. The results also show, that the repeated internal structural features in remote sensing images are suitable for self-supervised learning super-resolution algorithms. © 2022, Chinese Institute of Civil and Hydraulic Engineering. All right reserved.","Convolution; Convolutional neural networks; Image enhancement; Learning systems; Remote sensing; Satellite imagery; Signal to noise ratio; Supervised learning; Computation costs; Convolutional neural network; Images sets; Large amounts; Self-supervised; Structural feature; Super resolution algorithms; Superresolution; Supervised learning methods; Training image; Image resolution","Convolutional neural network; Satellite imagery; Self-supervised; Superresolution","Article","Final","","Scopus","2-s2.0-85134034292"
"Wu H.; Ni N.; Zhang L.","Wu, Hanlin (57221263814); Ni, Ning (57324094400); Zhang, Libao (15062022100)","57221263814; 57324094400; 15062022100","Lightweight Stepless Super-Resolution of Remote Sensing Images via Saliency-Aware Dynamic Routing Strategy","2023","IEEE Transactions on Geoscience and Remote Sensing","61","","5601717","","","","10.1109/TGRS.2023.3236624","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147279097&doi=10.1109%2fTGRS.2023.3236624&partnerID=40&md5=6a274cdbc1a5dcf2197b623c9876bd12","Deep learning-based algorithms have greatly improved the performance of remote sensing image (RSI) super-resolution (SR). However, increasing network depth and parameters cause a huge burden of computing and storage. Directly reducing the depth or width of existing models results in a large performance drop. We observe that the SR difficulty of different regions in an RSI varies greatly, and existing methods use the same deep network to process all regions in an image, resulting in a waste of computing resources. In addition, existing SR methods generally predefine integer scale factors and cannot perform stepless SR, i.e., a single model can deal with any potential scale factor. Retraining the model on each scale factor wastes considerable computing resources and model storage space. To address the above problems, we propose a saliency-aware dynamic routing network (SalDRN) for lightweight and stepless SR of RSIs. First, we introduce visual saliency as an indicator of region-level SR difficulty and integrate a lightweight saliency detector into the SalDRN to capture pixel-level visual characteristics. Then, we devise a saliency-aware dynamic routing strategy that employs path selection switches to adaptively select feature extraction paths of appropriate depth according to the SR difficulty of subimage patches. Finally, we propose a novel lightweight stepless upsampling module whose core is an implicit feature function for realizing mapping from low-resolution feature space to high-resolution feature space. Comprehensive experiments verify that the SalDRN can achieve a good tradeoff between performance and complexity. The code is available at https://github.com/hanlinwu/SalDRN.  © 1980-2012 IEEE.","Complex networks; Deep learning; Economic and social effects; Extraction; Image enhancement; Optical resolving power; Remote sensing; Routing algorithms; Computational modelling; Features extraction; Lightweight; Remote-sensing; Routings; Saliency analysis; Stepless; Superresolution; Task analysis; algorithm; artificial neural network; complexity; image analysis; image resolution; remote sensing; satellite imagery; Feature extraction","Lightweight; remote sensing; saliency analysis; stepless; super-resolution (SR)","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85147279097"
"Feng L.; Muller J.-P.; Yu C.; Deng C.; Zhang J.","Feng, Lang (57199899274); Muller, Jan-Peter (7404871794); Yu, Chaoqun (57886237300); Deng, Chao (57886705900); Zhang, Jingfa (14032411600)","57199899274; 7404871794; 57886237300; 57886705900; 14032411600","Elevation Extraction from Spaceborne SAR Tomography Using Multi-Baseline COSMO-SkyMed SAR Data","2022","Remote Sensing","14","16","4093","","","","10.3390/rs14164093","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137765548&doi=10.3390%2frs14164093&partnerID=40&md5=11c8ea4c4a966f0ca6a78a50e52b23ed","SAR tomography (TomoSAR) extends SAR interferometry (InSAR) to image a complex 3D scene with multiple scatterers within the same SAR cell. The phase calibration method and the super-resolution reconstruction method play a crucial role in 3D TomoSAR imaging from multi-baseline SAR stacks, and they both influence the accuracy of the 3D SAR tomographic imaging results. This paper presents a systematic processing method for 3D SAR tomography imaging. Moreover, with the newly released TanDEM-X 12 m DEM, this study proposes a new phase calibration method based on SAR InSAR and DEM error estimation with the super-resolution reconstruction compressive sensing (CS) method for 3D TomoSAR imaging using COSMO-SkyMed Spaceborne SAR data. The test, fieldwork, and results validation were executed at Zipingpu Dam, Dujiangyan, Sichuan, China. After processing, the 1 m resolution TomoSAR elevation extraction results were obtained. Against the terrestrial Lidar ‘truth’ data, the elevation results were shown to have an accuracy of 0.25 ± 1.04 m and a RMSE of 1.07 m in the dam area. The results and their subsequent validation demonstrate that the X band data using the CS method are not suitable for forest structure reconstruction, but are fit for purpose for the elevation extraction of manufactured facilities including buildings in the urban area. © 2022 by the authors.","Calibration; Compressed sensing; Image reconstruction; Optical resolving power; Processing; Radar imaging; Remote sensing; Space-based radar; Surveying; Synthetic aperture radar; Tomography; Calibration method; Compressive sensing; Elevation extraction; Multi-baseline; Phase calibration; SAR data; SAR-interferometry; Spaceborne SAR; Spaceborne SAR tomography; Super-resolution reconstruction; Extraction","compressive sensing; elevation extraction; phase calibration; spaceborne SAR tomography","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85137765548"
"Dror I.; Mishra D.; Shmueli R.; Blumberg D.; Maman S.; Choukroun D.; Hadar O.","Dror, Itai (7004020484); Mishra, Divya (57485985200); Shmueli, Ron (9639479000); Blumberg, Dan (57962513800); Maman, Shimrit (37111154200); Choukroun, Daniel (12778249200); Hadar, Ofer (7004643957)","7004020484; 57485985200; 9639479000; 57962513800; 37111154200; 12778249200; 7004643957","Multiple Image Super-Resolution from the BGU SWIR CubeSat Satellite","2022","Proceedings of SPIE - The International Society for Optical Engineering","12226","","122260I","","","","10.1117/12.2633778","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141750059&doi=10.1117%2f12.2633778&partnerID=40&md5=bc04d28729f07ab7c695f9863abc6338","The BGU CubeSat satellite is from a class of low-cost, compact satellites. Its dimensions are 10x10x30 cm. It is equipped with a low resolution 256x320 pixels short wave infrared (SWIR) camera at the 1.55-1.7mm wavelength band. Images are transmitted in bursts of tens of images at a time with few pixel shifts from the first image to the last. Each image burst is suitable for Multiple Image Super Resolution (MISR) enhancements. MISR can construct a high-resolution (HR) image from several low-resolution (LR) images yielding an image that can resolve more details that are crucial for research in remote sensing. In this research, we verify the applicability of SOTA deep learning MISR models that were developed following the publication of the PROBA-V MISR satellite dataset at the visible red and near IR. Our SWIR multiple images differ from PROBA-V by the spectral band and by the method of collecting multiple images of the exact location. Our imagery data is acquired by a burst of very close temporal images. PROBA-V revisits the satellite at a period smaller than 30 days, assuming the soil dryness is about the same. We compare the results of Single Image Super-Resolution (SISR) and MISR techniques to ""off-the-shelf"" products. The quality of the super-resolved images is compared by non-reference metrics suitable for remote sensing applications and by experts' visual inspection. Unlike remarkable achievements by the GAN technique that can achieve very appealing results that are not always faithful to the original ground truth, the super-resolved images should preserve the original details as much as possible for further scientific remote sensing analysis. © 2022 SPIE.","Deep learning; Infrared radiation; Optical resolving power; Pixels; Remote sensing; Small satellites; BGUSAT; Cubesat; Deep learning; Image super resolutions; Low-costs; Lower resolution; Multiple image; Multiple image super resolution; PROBA-V; Short wave infrared; Image enhancement","BGUSAT; Cubesat; Deep Learning; Multiple Image Super Resolution; PROBA-V; SWIR","Conference paper","Final","","Scopus","2-s2.0-85141750059"
"Turkar Y.; Aluckal C.; De S.; Turkar V.; Agarwadkar Y.","Turkar, Yash (57215286031); Aluckal, Christo (57216289399); De, Shaunak (57938285600); Turkar, Varsha (26424462800); Agarwadkar, Yogesh (56529579200)","57215286031; 57216289399; 57938285600; 26424462800; 56529579200","Generative-Network Based Multimedia Super-Resolution for Uav Remote Sensing","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","527","530","3","10.1109/IGARSS46834.2022.9884486","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140384908&doi=10.1109%2fIGARSS46834.2022.9884486&partnerID=40&md5=1a22fa5af72bc5b4eae0bef46c09a9c9","Unmanned Aerial Vehicle (UAV) based aerial mapping has taken over the surveying industry thanks to low costs and ease of use. Although these UAVs have relatively high-resolution imaging systems, there exists a near exponential relationship between the ground sampling distance (GSD) and the number of images required-which is a function of flight altitude. To tackle this, we use a generative network based super-resolution approach to increase the GSD of images which effectively reduces flight time. In this paper we test the efficiency and efficacy of this approach using two multimedia super-resolution implementations. We also provide quantitative results comparing the two using various image processing metrics. © 2022 IEEE.","Antennas; Costs; Image resolution; Remote sensing; Aerial vehicle; Conclusion; Ground sampling distances; Introduction; Methodology; Network-based; Reference; Result; Superresolution; UAV remote sensing; Unmanned aerial vehicles (UAV)","Conclusion; Introduction; Methodology; References; Results","Conference paper","Final","","Scopus","2-s2.0-85140384908"
"Tian J.; Peng D.; Guan H.; Ding H.","Tian, Juan (57899695800); Peng, Daifeng (56622117600); Guan, Haiyan (48260990900); Ding, Haiyong (25638449000)","57899695800; 56622117600; 48260990900; 25638449000","RACDNet: Resolution- and Alignment-Aware Change Detection Network for Optical Remote Sensing Imagery","2022","Remote Sensing","14","18","4527","","","","10.3390/rs14184527","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138496071&doi=10.3390%2frs14184527&partnerID=40&md5=a8340be3f11fe9c7d79eec3a767667ee","Change detection (CD) methods work on the basis of co-registered multi-temporal images with equivalent resolutions. Due to the limitation of sensor imaging conditions and revisit period, it is difficult to acquire the desired images, especially in emergency situations. In addition, accurate multi-temporal images co-registration is largely limited by vast object changes and matching algorithms. To this end, a resolution- and alignment-aware change detection network (RACDNet) is proposed for multi-resolution optical remote-sensing imagery CD. In the first stage, to generate high-quality bi-temporal images, a light-weighted super-resolution network is proposed by fully considering the construction difficulty of different regions, which facilitates to detailed information recovery. Adversarial loss and perceptual loss are further adopted to improve the visual quality. In the second stage, deformable convolution units are embedded in a novel Siamese–UNet architecture for bi-temporal deep features alignment; thus, robust difference features can be generated for change information extraction. We further use an atrous convolution module to enlarge the receptive field, and an attention module to bridge the semantic gap between the encoder and decoder. To verify the effectiveness of our RACDNet, a novel multi-resolution change detection dataset (MRCDD) is created by using Google Earth. The quantitative and qualitative experimental results demonstrate that our RACDNet is capable of enhancing the details of the reconstructed images significantly, and the performance of CD surpasses other state-of-the-art methods by a large margin. © 2022 by the authors.","Change detection; Deformation; Image enhancement; Optical remote sensing; Optical resolving power; Semantics; Atrous convolution; Attention unit; Change detection; Deformable convolution; Detection networks; Feature alignment; Multi-temporal image; Optical remote-sensing imagery; Siamese–unet; Superresolution; Convolution","atrous convolution; attention unit; change detection; deformable convolution; feature alignment; siamese–UNet; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85138496071"
"Sigurdsson J.; Armannsson S.E.; Ulfarsson M.O.; Sveinsson J.R.","Sigurdsson, Jakob (7006736374); Armannsson, Sveinn E. (57224686207); Ulfarsson, Magnus O. (6507677875); Sveinsson, Johannes R. (7003642214)","7006736374; 57224686207; 6507677875; 7003642214","Fusing Sentinel-2 and Landsat 8 Satellite Images Using a Model-Based Method","2022","Remote Sensing","14","13","3224","","","","10.3390/rs14133224","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133860643&doi=10.3390%2frs14133224&partnerID=40&md5=36a359caa11fe4e2c3c864be45cbb3cc","The Copernicus Sentinel-2 (S2) constellation comprises of two satellites in a sun-synchronous orbit. The S2 sensors have three spatial resolutions: 10, 20, and 60 m. The Landsat 8 (L8) satellite has sensors that provide seasonal coverage at spatial resolutions of 15, 30, and 60 m. Many remote sensing applications require the spatial resolutions of all data to be at the highest resolution possible, i.e., 10 m for S2. To address this demand, researchers have proposed various methods that exploit the spectral and spatial correlations within multispectral data to sharpen the S2 bands to 10 m. In this study, we combined S2 and L8 data. An S2 sharpening method called Sentinel-2 Sharpening (S2Sharp) was modified to include the 30 m and 15 m spectral bands from L8 and to sharpen all bands (S2 and L8) to the highest resolution of the data, which was 10 m. The method was evaluated using both real and simulated data. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Image fusion; Orbits; Remote sensing; High resolution; Image sharpening; LANDSAT; Landsat 8; Multi-spectral; Multiresolution images; Multispectral  multiresolution image; Sentinel-2; Spatial resolution; Superresolution; Landsat","data fusion; image sharpening; Landsat 8; multispectral (MS) multiresolution images; Sentinel-2; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85133860643"
"Liu C.; Zhao J.; Wang D.; Wang Y.; Rong L.; Lin S.","Liu, Ce (58074455200); Zhao, Jie (57169114700); Wang, Dayong (10045139300); Wang, Yunxin (56737286000); Rong, Lu (57667479500); Lin, Shufeng (57361375600)","58074455200; 57169114700; 10045139300; 56737286000; 57667479500; 57361375600","Study on Space/Frequency Domain Response Mechanism of Optical Synthetic Aperture Imaging System","2022","Proceedings of SPIE - The International Society for Optical Engineering","12478","","124782W","","","","10.1117/12.2654787","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146693636&doi=10.1117%2f12.2654787&partnerID=40&md5=0fa292c42974a6caaef319eb1739d783","Optical synthetic aperture (OSA) imaging system is an effective method for astronomical telescopes to realize super-resolution imaging, which has important applications in astronomical observation and space remote sensing. The time-division multiplexing sub-aperture array is a potentially powerful way to construct the larger array configuration by changing the basic array configuration several times with less apertures. In this paper, according to the theory of incoherent optical imaging, the physical mechanism of space/frequency domain response of OSA system is discussed. From the basic pinhole-aperture array to the circular-aperture array, the evolution of the point spread function (PSF) and the modulation transfer function (MTF) is analyzed. The inherent laws and imaging differences between the time-division multiplexing sub-aperture array and the traditional synthetic aperture array are revealed. Also, it is shown that under the specific array condition, the reconstructed image obtained by the time-division multiplexing synthetic aperture system can approach the imaging quality and resolution given by the traditional synthetic aperture array. It provides a new perspective for the array configuration design of OSA imaging system. © 2022 SPIE.","Image resolution; Imaging systems; Optical radar; Optical remote sensing; Optical signal processing; Synthetic apertures; Time division multiplexing; Aperture arrays; Array configurations; Frequency domain response; Optical synthetic aperture; Point-Spread function; Space-frequency domain; Subaperture; Super resolution imaging; Synthetic aperture imaging systems; Time-division multiplexing; Optical transfer function","modulation transfer function; Optical synthetic aperture; point spread function; super resolution imaging; time-division multiplexing","Conference paper","Final","","Scopus","2-s2.0-85146693636"
"Li Y.; Gao W.; Jia J.; Tao S.; Ren Y.","Li, Yan (57246418800); Gao, Wanlin (8931933300); Jia, Jingdun (55349327200); Tao, Sha (57211427383); Ren, Yanzhao (57194343285)","57246418800; 8931933300; 55349327200; 57211427383; 57194343285","Developing and evaluating the feasibility of a new spatiotemporal fusion framework to improve remote sensing reflectance and dynamic LAI monitoring","2022","Computers and Electronics in Agriculture","198","","107037","","","","10.1016/j.compag.2022.107037","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130372766&doi=10.1016%2fj.compag.2022.107037&partnerID=40&md5=24ab1490e1086667b6289fcfe7409803","Multi-sensor fusion provides an effective way for applications requiring remote sensing data with high spatiotemporal resolution. Especially for agricultural areas with complex planting structures and rapid changes in crop phenology, more detailed and dense time-series remote sensing data are necessary. The Sentinel-2 Multispectral Imager (S2-MSI) sensor with high spatial resolution (10–60 m) and temporal resolution (5–10 days) plays a key role in spatiotemporal fusion. But the inconsistent spatial resolution of the various bands hinders its potential application at 10 m resolution, and the multiple available fine images it provides are not fully utilized for spatiotemporal fusion. It is worth exploring how to maximize the spatial and temporal resolution of S2-MSI images to help improve the effect of spatiotemporal fusion and the dynamic monitoring of rapid crop growth. In this research, a new spatiotemporal fusion (STF) framework is developed to fuse the S2-MSI image (10 m) enhanced by Super-Resolution for multispectral Multiresolution Estimation (SupReME) algorithm and MODIS image (460 m) with a large spatial ratio (46). The proposed fusion method in the new STF framework combines the existing STF methods with Consistent Adjustment of the Climatology to Actual Observations (CACAO) algorithm, abbreviated as CA-STF. The accuracy of the fused reflectance and its capability for dynamic LAI monitoring were tested in Daman Superstation of Heihe watershed. The results indicate that: (1) the new STF framework is competent to fuse multi-source images with a ratio of 46 and outperforms the existing STF methods for both near-real-time and post-growth applications; (2) the proposed CA-STF method improves the fusion accuracy and spatial details even if only two S2-MSI images are available, especially for post-growth applications; (3) the vegetation indices (VIs) calculated from the fused images by the new STF framework provide a better correlation with LAINet measurements and improve dynamic LAI monitoring in accuracy and spatial details. This study proposes a framework to maximize the spatial and temporal resolution of S2-MSI images for spatiotemporal fusion. The synthetic daily time-series images with a high resolution of 10 m will have great potential for monitoring the dynamic changes of the land surface. © 2022 Elsevier B.V.","China; Heihe; Heilongjiang; Image enhancement; Image resolution; Reflection; Remote sensing; Time series; Vegetation; Consistent adjustment of the climatology to actual observation; Estimation algorithm; Fusion methods; Multi-spectral; Multiresolution; Multispectral imagers; Sentinel-2 multispectral imager; Spatio-temporal fusions; Super-resolution for multispectral multiresolution estimation algorithm; Superresolution; leaf area index; MODIS; remote sensing; spatiotemporal analysis; spectral reflectance; watershed; Crops","CACAO; Sentinel-2 Multispectral Imager (S2-MSI); Spatiotemporal fusion; SupReME algorithm","Article","Final","","Scopus","2-s2.0-85130372766"
"Li W.; Wu F.; Cao D.","Li, Weisheng (36067507500); Wu, Fengyan (57888662200); Cao, Dongwen (57262675000)","36067507500; 57888662200; 57262675000","Dual-Branch Remote Sensing Spatiotemporal Fusion Network Based on Selection Kernel Mechanism","2022","Remote Sensing","14","17","4282","","","","10.3390/rs14174282","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137864410&doi=10.3390%2frs14174282&partnerID=40&md5=fba481db23e5a77c7a1573203a8dbe6d","Popular deep-learning-based spatiotemporal fusion methods for creating high-temporal–high-spatial-resolution images have certain limitations. The reconstructed images suffer from insufficient retention of high-frequency information and the model suffers from poor robustness, owing to the lack of training datasets. We propose a dual-branch remote sensing spatiotemporal fusion network based on a selection kernel mechanism. The network model comprises a super-resolution network module, a high-frequency feature extraction module, and a difference reconstruction module. Convolution kernel adaptive mechanisms are added to the high-frequency feature extraction module and difference reconstruction module to improve robustness. The super-resolution module upgrades the coarse image to a transition image matching the fine image; the high-frequency feature extraction module extracts the high-frequency features of the fine image to supplement the high-frequency features for the difference reconstruction module; the difference reconstruction module uses the structural similarity for fine-difference image reconstruction. The fusion result is obtained by combining the reconstructed fine-difference image with the known fine image. The compound loss function is used to help network training. Experiments are carried out on three datasets and five representative spatiotemporal fusion algorithms are used for comparison. Subjective and objective evaluations validate the superiority of our proposed method. © 2022 by the authors.","Convolution; Convolutional neural networks; Deep learning; Extraction; Feature extraction; Image fusion; Image reconstruction; Optical resolving power; Convolutional neural network; Features extraction; Fine images; Frequency features; High frequency HF; Kernel mechanism; Network-based; Remote-sensing; Selection kernel; Spatio-temporal fusions; Remote sensing","convolutional neural network; remote sensing; selection kernel; spatiotemporal fusion","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85137864410"
"Xie X.; Li L.; An Z.; Lu G.; Zhou Z.","Xie, Xiaozhu (55455751500); Li, Linhao (57204549892); An, Zhe (57205610783); Lu, Gang (57709221200); Zhou, Zhiqiang (55728196000)","55455751500; 57204549892; 57205610783; 57709221200; 55728196000","Small Ship Detection Based on Hybrid Anchor Structure and Feature Super-Resolution","2022","Remote Sensing","14","15","3530","","","","10.3390/rs14153530","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137086106&doi=10.3390%2frs14153530&partnerID=40&md5=6bbf1be38c46bf1b2703dda6ec839f06","Small ships in remote sensing images have blurred details and are difficult to detect. Existing algorithms usually detect small ships based on predefined anchors with different sizes. However, limited by the number of different sizes, it is difficult for anchor-based methods to match small ships of different sizes and structures during training, as they can easily cause misdetections. In this paper, we propose a hybrid anchor structure to generate region proposals for small ships, so as to take full advantage of both anchor-based methods with high localization accuracy and anchor-free methods with fewer misdetections. To unify the output evaluation and obtain the best output, a label reassignment strategy is proposed, which reassigns the sample labels according to the harmonic intersection-over-union (IoU) before and after regression. In addition, an adaptive feature pyramid structure is proposed to enhance the features of important locations on the feature map, so that the features of small ship targets are more prominent and easier to identify. Moreover, feature super-resolution technology is introduced for the region of interest (RoI) features of small ships to generate super-resolution feature representations with a small computational cost, as well as generative adversarial training to improve the realism of super-resolution features. Based on the super-resolution feature, ship proposals are further classified and regressed by using super-resolution features to obtain more accurate detection results. Detailed ablation and comparison experiments demonstrate the effectiveness of the proposed method. © 2022 by the authors.","Feature extraction; Image segmentation; Optical resolving power; Ships; Anchor structure; Different sizes; Different structure; Feature super-resolution; Generative adversarial training; Hybrid anchor structure; Hybrid anchors; Remote sensing images; Ship detection; Superresolution; Remote sensing","feature super-resolution; generative adversarial training; hybrid anchor structure; ship detection","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85137086106"
"Cheng R.; Wang H.; Luo P.","Cheng, Ruihong (57945516400); Wang, Huajun (55689029400); Luo, Ping (57945409400)","57945516400; 55689029400; 57945409400","Remote sensing image super-resolution using multi-scale convolutional sparse coding network","2022","PLoS ONE","17","10 October","e0276648","","","","10.1371/journal.pone.0276648","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140817020&doi=10.1371%2fjournal.pone.0276648&partnerID=40&md5=7b0430d44cda714d96ad50e13ea1ffef","With the development of convolutional neural networks, impressive success has been achieved in remote sensing image super-resolution. However, the performance of super-resolution reconstruction is unsatisfactory due to the lack of details in remote sensing images when compared to natural images. Therefore, this paper presents a novel multiscale convolutional sparse coding network (MCSCN) to carry out the remote sensing images SR reconstruction with rich details. The MCSCN, which consists of a multiscale convolutional sparse coding module (MCSCM) with dictionary convolution units, can improve the extraction of high frequency features. We can obtain more plentiful feature information by combining multiple sizes of sparse features. Finally, a layer based on sub-pixel convolution that combines global and local features takes as the reconstruction block. The experimental results show that the MCSCN gains an advantage over several existing state-of-the-art methods in terms of peak signal-to-noise ratio and structural similarity. © 2022 Cheng et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","Algorithms; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Remote Sensing Technology; Signal-To-Noise Ratio; article; extraction; remote sensing; signal noise ratio; algorithm; image processing; nuclear magnetic resonance imaging; procedures; remote sensing","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85140817020"
"Dong X.; Yokoya N.; Wang L.; Uezato T.","Dong, Xiaoyu (57212387140); Yokoya, Naoto (36440631200); Wang, Longguang (57193752437); Uezato, Tatsumi (55702187300)","57212387140; 36440631200; 57193752437; 55702187300","Learning Mutual Modulation for Self-supervised Cross-Modal Super-Resolution","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13679 LNCS","","","1","18","17","10.1007/978-3-031-19800-7_1","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142739272&doi=10.1007%2f978-3-031-19800-7_1&partnerID=40&md5=4860b52ea76f17b0095c1ca3202329c1","Self-supervised cross-modal super-resolution (SR) can overcome the difficulty of acquiring paired training data, but is challenging because only low-resolution (LR) source and high-resolution (HR) guide images from different modalities are available. Existing methods utilize pseudo or weak supervision in LR space and thus deliver results that are blurry or not faithful to the source modality. To address this issue, we present a mutual modulation SR (MMSR) model, which tackles the task by a mutual modulation strategy, including a source-to-guide modulation and a guide-to-source modulation. In these modulations, we develop cross-domain adaptive filters to fully exploit cross-modal spatial dependency and help induce the source to emulate the resolution of the guide and induce the guide to mimic the modality characteristics of the source. Moreover, we adopt a cycle consistency constraint to train MMSR in a fully self-supervised manner. Experiments on various tasks demonstrate the state-of-the-art performance of our MMSR. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Adaptive filtering; Adaptive filters; Optical resolving power; Remote sensing; Cross-modal; High resolution; Lower resolution; Multi-modal; Mutual modulation; Remote-sensing; Self-supervised super-resolution; Source resolution; Superresolution; Training data; Modulation","Cross-modal; Multi-modal; Mutual modulation; Remote sensing; Self-supervised super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85142739272"
"Shi M.; Gao Y.; Chen L.; Liu X.","Shi, Mengyang (57215970233); Gao, Yesheng (35589843500); Chen, Lin (57192609739); Liu, Xingzhao (35242655900)","57215970233; 35589843500; 57192609739; 35242655900","Dual-Resolution Local Attention Unfolding Network for Optical Remote Sensing Image Super-Resolution","2022","IEEE Geoscience and Remote Sensing Letters","19","","6016105","","","","10.1109/LGRS.2022.3224041","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144027172&doi=10.1109%2fLGRS.2022.3224041&partnerID=40&md5=044ff65e6afcb253968bf0c473240325","Single-image super-resolution (SR) technology based on deep learning is widely applied in remote sensing. In recent years, the deep unfolding SR strategy has been proposed, which combines the neural networks with the traditional optimization-based algorithms, making the neural networks interpretable and achieving high performance. However, the typical deep unfolding algorithms usually treat different kinds of blurring kernels in the same way, so the algorithms cannot take advantage of the properties of blurring kernels, limiting the algorithm's performance. To design an SR network that can fully use the properties of the Gaussian blurring kernels, a dual-resolution local attention unfolding network (DLANet) is proposed. Based on the Gaussian blurring functions, a low-resolution (LR) space branch is designed to supplement the high-resolution (HR) space branch. Specifically, for the Gaussian blurring kernels, the closer the pixel is to the center, the greater the weight is. It means that the pixel points retained after downsampling will contain more information about the original corresponding pixel points, and it could be easier to estimate their original pixel values. So we design two branches. The HR branch completes the estimation of the whole image, and the LR branch only estimates the points retained after downsampling. To better complete the feature fusion of the two branches, we propose a row-column decoupling local attention module. This module can retain more information when fuse features and the row-column decoupling strategy can reduce the computational complexity. Comprehensive experiments demonstrate the superiority of our method over the current state-of-the-art on remote sensing datasets. © 2022 IEEE.","Deep learning; Gaussian distribution; Optical remote sensing; Optical resolving power; Pixels; Signal sampling; Space optics; Blurring kernels; Dual resolutions; Features extraction; Gaussian blurring kernel; Gaussians; Images reconstruction; Kernel; Local attention; Neural-networks; Remote-sensing; Superresolution; Unfoldings; algorithm; artificial neural network; image resolution; pixel; remote sensing; sampling; Image reconstruction","Dual-resolution; Gaussian blurring kernels; local attention; super-resolution (SR); unfolding","Article","Final","","Scopus","2-s2.0-85144027172"
"Karwowska K.; Wierzbicki D.","Karwowska, Kinga (57608598400); Wierzbicki, Damian (56835658600)","57608598400; 56835658600","Improving Spatial Resolution of Satellite Imagery Using Generative Adversarial Networks and Window Functions","2022","Remote Sensing","14","24","6285","","","","10.3390/rs14246285","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144608432&doi=10.3390%2frs14246285&partnerID=40&md5=aca3bea7c96713d4cf2678e7208784dc","Dynamic technological progress has contributed to the development of systems imaging of the Earth’s surface as well as data mining methods. One such example is super-resolution (SR) techniques that allow for the improvement of the spatial resolution of satellite imagery on the basis of a low-resolution image (LR) and an algorithm using deep neural networks. The limitation of these solutions is the input size parameter, which defines the image size that is adopted by a given neural network. Unfortunately, the value of this parameter is often much smaller than the size of the images obtained by Earth Observation satellites. In this article, we presented a new methodology for improving the resolution of an entire satellite image, using a window function. In addition, we conducted research to improve the resolution of satellite images acquired with the World View 2 satellite using the ESRGAN network, we determined the number of buffer pixels that will make it possible to obtain the best image quality. The best reconstruction of the entire satellite imagery using generative neural networks was obtained using a Triangular window (for 10% coverage). The Hann-Poisson window worked best when more overlap between images was used. © 2022 by the authors.","Data mining; Deep neural networks; Generative adversarial networks; Image enhancement; Remote sensing; Satellite imagery; Images processing; Network functions; Neural network application; Neural-networks; Remote-sensing; Satellite images; Spatial resolution; Surface mining methods; Technological progress; Window functions; Image resolution","image processing; image resolution; neural network application; remote sensing; satellites","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85144608432"
"Lavreniuk M.; Kussul N.; Shelestov A.; Lavrenyuk A.; Shumilo L.","Lavreniuk, Mykola (56667743100); Kussul, Nataliia (6602485938); Shelestov, Andrii (6507365226); Lavrenyuk, Alla (16444915500); Shumilo, Leonid (57208256914)","56667743100; 6602485938; 6507365226; 16444915500; 57208256914","Super Resolution Approach for the Satellite Data Based on the Generative Adversarial Networks","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","1095","1098","3","10.1109/IGARSS46834.2022.9884460","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140369300&doi=10.1109%2fIGARSS46834.2022.9884460&partnerID=40&md5=9273c26a2a94b7f402c373876be0b2e1","In the past few years, medium and high-resolution data became freely available for downloading. It provides great opportunity for researchers not to select between solving the task with high-resolution data on small territory or on global scale, but with low-resolution satellite images. Due to high spectral and spatial resolution of the data, Sentinel-1 and Sentinel-2 are very popular sources of information. Nevertheless, in practice if we would like to receive final product in 10 m resolution we should use bands with 10 m resolution. Sentinel-2 has four such bands, but also has other bands, especially red-edge 20 m resolution bands that are useful for vegetation analysis and often are omitted due to lower resolution. Thus, in this study we propose methodology for enhancing resolution (super-resolution) of the existing low-resolution images to higher resolution images. The main idea is to use advanced methods of deep learning-Generative Adversarial Networks (GAN) and train it to increase the resolution for the satellite images. Experimental results for the Sentinel-2 data showed that this approach is efficient and could be used for creating high resolution products. © 2022 IEEE.","Deep learning; Image enhancement; Optical resolving power; Remote sensing; Satellites; Deep learning; Global scale; High resolution data; High spatial resolution; High spectral resolution; Lower resolution; Satellite data; Satellite images; Sentinel-2; Superresolution; Generative adversarial networks","deep learning; GAN; Generative Adversarial Networks; Sentinel-2; super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85140369300"
"Zhen J.; Jiang X.; Zhao D.; Wang J.; Miao J.; Wu G.","Zhen, Jianing (57204697590); Jiang, Xiapeng (57223266834); Zhao, Demei (57224629311); Wang, Junjie (56627055800); Miao, Jing (57224644463); Wu, Guofeng (7404975854)","57204697590; 57223266834; 57224629311; 56627055800; 57224644463; 7404975854","Retrieving canopy nitrogen content of mangrove forests from Sentinel-2 super-resolution reconstruction data; [利用Sentinel-2影像超分辨率重建的红树林冠层氮含量反演]","2022","National Remote Sensing Bulletin","26","6","","1206","1219","13","10.11834/jrs.20221461","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136691263&doi=10.11834%2fjrs.20221461&partnerID=40&md5=fd67b6b30c3e61a3599648d0681ccf46","Nitrogen content is an essential element in the whole life cycle of vegetation. The estimation of mangrove Canopy Nitrogen Content (CNC) by remote sensing is greatly important for mangrove health monitoring. At present, studies that use satellite hyperspectral data to retrieve CNC of forest at regional scales, especially for mangroves, are few. In addition, the low spatial resolution of most satellite hyperspectral images and the difficulty of measuring the average leaf nitrogen content of a single image pixel in real time limit the inversion accuracy. In this study, the super-resolution reconstruction of Sentinel-2 image and in-site measurement data was used for retrieving mangrove CNC to explore the application potential of enhanced Sentinel-2 image in mangrove monitoring. Taking Zhanjiang Gaoqiao Mangrove National Nature Reserve, China as the study area, the red edge bands, near-infrared, and short wave bands of Sentinel-2 were reconstructed from 20 m to 10 m by resampling, Sen2Res, and SupReMe algorithms, respectively. The reconstructed images are used to build 40 vegetation indices and analyze their correlation with CNC. Then, the SVM-RFE iterative feature deletion method was used to determine the optimal variable combination of mangrove CNC estimation, and the Kernel Ridge Regression (KRR) model was used to construct the prediction model of mangrove CNC. Finally, the optimal model was used to map CNC spatial distribution of mangrove forests. Significant differences in canopy nitrogen content and leaf nitrogen content were found among different mangrove species, and the variation of intraspecific CNC was abundant. The reconstructed images based on Sen2Res and supreme super resolution algorithm not only had high spectral consistency (the R2 values of all bands are above 0.96) with the resampled image, but also significantly improved the clarity and spatial detail of the image compared with the 20 m resolution image. The bands sensitive to mangrove CNC are mainly concentrated in the red band (B4), red-edge band (B5), near-infrared band (B8a), and short-wave infrared band (B11 and B12). Vegetation indices related to red-edge band (RSSI and TCARIre1/OSAVI) are also effective variables to predict mangrove CNC. The inversion accuracy (R2val>0.579) of the reconstructed 10 m image based on the three methods is better than that of the original 20 m image (R2val=0.504). The fitting accuracy of the inversion model based on the reconstructed Sen2Res image (R2val=0.630, RMSE_val=5.133, RE_val=0.179) is almost the same as the resampled (R2val=0.640, RMSE_val=5.064, RE_val=0.179), and its model validation accuracy (R2cv=0.497, RMSE_cv=5.985, RE_cv=0.214) is higher. In addition, the variable number of Sen2Res is the most reasonable. Based on the spectral details and model accuracy of reconstructed images, Sentinel-2 images constructed by Sen2Res algorithm have good application potential in mangrove canopy nitrogen content estimation and can provide effective method reference and data support for fine monitoring of mangrove canopy health status at regional scale. Compared with vegetation, such as crops and grasslands, the factors influencing CNC inversion of mangroves are more complex. Although the influence of the main canopy structure factor (LAI) was considered in this study, other factors, such as species, community structure, leaf inclination, and synergistic changes, in other biochemical components should be further investigated. © 2022 National Remote Sensing Bulletin. All rights reserved.","Forestry; Image enhancement; Image reconstruction; Image resolution; Infrared devices; Infrared radiation; Iterative methods; Life cycle; Nitrogen; Pixels; Regression analysis; Satellites; Spectroscopy; Vegetation mapping; Canopy nitrogen content; Images reconstruction; Kernel ridge regressions; Mangrove canopy; Mangrove forest; Nitrogen content; Red edge; Remote-sensing; Sentinel-2; SVM-RFE; Remote sensing","canopy nitrogen content; image reconstruction; KRR; mangrove forests; remote sensing; Sentinel-2; SVM-RFE","Article","Final","","Scopus","2-s2.0-85136691263"
"Shi M.; Gao Y.; Chen L.; Liu X.","Shi, Mengyang (57215970233); Gao, Yesheng (35589843500); Chen, Lin (57938172900); Liu, Xingzhao (35242655900)","57215970233; 35589843500; 57938172900; 35242655900","Structured Deep Unfolding Network for Optical Remote Sensing Image Super-Resolution","2022","IEEE Geoscience and Remote Sensing Letters","19","","6519005","","","","10.1109/LGRS.2022.3221612","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142842639&doi=10.1109%2fLGRS.2022.3221612&partnerID=40&md5=56699cf04d8c39637007c7c6655d43fd","Single-image super-resolution technology is critical in remote sensing, effectively improving the resolution of target images, with super-resolution algorithms based on deep learning demonstrating superior performance. However, most neural networks present shortcomings, such as a lack of interpretability and requiring a long training time, limiting them in some application scenarios. Moreover, due to the multidegradation factors, tasks put forward higher requirements for the adaptability of algorithms. Therefore, this work develops a structured deep unfolding network (SDUNet), which is adaptable and requires a lower training time by cascading multiple small network modules. Additionally, the unfolding strategy proposed deals with multiple degradations, fully exploiting prior knowledge. The suggested method is challenged against state-of-the-art neural network methods on one optical remote sensing image (ORSI) dataset and one natural image dataset. The experimental results demonstrate our method's effectiveness in requiring less training time, involving fewer parameters, and achieving a higher reconstruction performance for ORSI super-resolution. © 2004-2012 IEEE.","Deep learning; Image enhancement; Optical resolving power; Deep unfolding; Image super resolutions; Multi-degradation; Optical remote sensing; Optical remote sensing image; Remote sensing images; Structured; Superresolution; Training time; Unfoldings; algorithm; image analysis; image resolution; remote sensing; satellite imagery; Optical remote sensing","Deep unfolding; multidegradation; optical remote sensing image (ORSI); structured; super-resolution","Article","Final","","Scopus","2-s2.0-85142842639"
"Tong K.; Wu Y.","Tong, Kang (57216151911); Wu, Yiquan (55850753800)","57216151911; 55850753800","Deep learning-based detection from the perspective of small or tiny objects: A survey","2022","Image and Vision Computing","123","","104471","","","","10.1016/j.imavis.2022.104471","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130364351&doi=10.1016%2fj.imavis.2022.104471&partnerID=40&md5=d0d7065c35119612ac49a5087c87fc8d","Detecting small or tiny objects is always a difficult and challenging issue in computer vision. In this paper, we provide a latest and comprehensive survey of deep learning-based detection approaches from the perspective of small or tiny objects. Our survey is featured by thorough and exhaustive analysis of small or tiny object detection. We comprehensively introduce 30 existing datasets about small or tiny objects, and summarize different definitions of small or tiny objects based on different application scenarios, such as pedestrian detection, traffic signs detection, face detection, remote sensing target detection and object detection in common life. Then small or tiny object detection techniques are overviewed systematically from seven aspects, including super-resolution techniques, context-based information, multi-scale representation learning, anchor mechanism, training strategy, data augmentation, and schemes based on loss function. Finally, the detection performance of small or tiny objects on 12 popular datasets is analyzed in depth. Based on performance analysis, we also discuss the promising research directions in the future. We hope this survey could provide researchers guidance to catalyze understanding of small or tiny object detection and further facilitate research on small or tiny object detection systems. © 2022 Elsevier B.V.","Convolutional neural networks; Deep learning; Face recognition; Object recognition; Remote sensing; Surveys; Traffic signs; Application scenario; Convolutional neural network; Dataset; Deep learning; Detection approach; Object based; Objects-based; Pedestrian detection; Small or tiny object; Traffic sign detection; Object detection","Convolutional neural networks; Datasets; Deep learning; Object detection; Small or tiny objects","Review","Final","","Scopus","2-s2.0-85130364351"
"Danan E.; Shabairou N.; Danan Y.; Zalevsky Z.","Danan, Eliezer (57442531100); Shabairou, Nadav (57196217722); Danan, Yossef (56674568600); Zalevsky, Zeev (7005705399)","57442531100; 57196217722; 56674568600; 7005705399","Signal-to-Noise Ratio Improvement for Multiple-Pinhole Imaging Using Supervised Encoder–Decoder Convolutional Neural Network Architecture","2022","Photonics","9","2","69","","","","10.3390/photonics9020069","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124126244&doi=10.3390%2fphotonics9020069&partnerID=40&md5=d9f466864c29fab16986e96dc95fd727","Digital image devices have been widely applied in many fields, such as individual recognition and remote sensing. The captured image is a degraded image from the latent observation, where the degradation processing is affected by some factors, such as lighting and noise corruption. Specifically, noise is generated in the processing of transmission and compression from the unknown latent observation. Thus, it is essential to use image denoising techniques to remove noise and recover the latent observation from the given degraded image. In this research, a supervised encoder–decoder convolution neural network was used to fix image distortion stemming from the limited accuracy of inverse filter methods (Wiener filter, Lucy–Richardson deconvolution, etc.). Particularly, we will correct image degradation that mainly stems from duplications arising from multiple-pinhole array imaging. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","","Coded aperture imaging; Convolutional neural network; Deep learning; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85124126244"
"Wang X.; Hu Q.; Jiang J.; Ma J.","Wang, Xinya (57221484390); Hu, Qian (57958351200); Jiang, Junjun (54902306100); Ma, Jiayi (26638975600)","57221484390; 57958351200; 54902306100; 26638975600","A Group-Based Embedding Learning and Integration Network for Hyperspectral Image Super-Resolution","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5541416","","","","10.1109/TGRS.2022.3217406","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141445429&doi=10.1109%2fTGRS.2022.3217406&partnerID=40&md5=b7ca0d527520ed69e78d37234a76b275","Although natural image super-resolution methods have achieved impressive performance, single hyperspectral image super-resolution still remains a challenge due to the high dimensionality. In recent years, many single hyperspectral image super-resolution methods adopted the group-convolution strategy to design the network for reducing the computational burden. However, these methods still process all spectral bands at once during the deep feature extraction and reconstruction, which increases the difficulty of fully exploring the inherent data characteristic of hyperspectral images. Moreover, the advanced group-based methods make insufficient exploitation of complementary information contained in different bands, resulting in limited reconstruction performance. In this article, we propose a novel group-based single hyperspectral image super-resolution method termed group-based embedding learning and integration network (GELIN) to reconstruct high-resolution images in a group-by-group manner, which alleviates the difficulty of feature extraction and reconstruction for hyperspectral images. Specifically, a spatial-spectral embedding learning module is designed to extract rewarding spatial details and explore the correlations among spectra simultaneously. Considering the high similarity among different bands, a neighboring group integration module is proposed to fully exploit the complementary information contained in neighboring image groups to recover missing details in the target image group. Experimental results on both natural and remote sensing hyperspectral datasets demonstrate that the proposed method is superior to other state-of-the-art methods both visually and metrically.  © 1980-2012 IEEE.","Convolution; Extraction; Hyperspectral imaging; Image reconstruction; Optical resolving power; Remote sensing; Spectroscopy; Correlation; Features extraction; Group convolution; HyperSpectral; Hyperspectral image; Images reconstruction; Neighboring group; Spatial resolution; Superresolution; artificial neural network; image analysis; image resolution; machine learning; remote sensing; Feature extraction","Group convolution; hyperspectral image; neighboring groups; super-resolution","Article","Final","","Scopus","2-s2.0-85141445429"
"Chouteau F.; Gabet L.; Fraisse R.; Bonfort T.; Harnoufi B.; Greiner V.; Le Goff M.; Ortner M.; Paveau V.","Chouteau, F. (57741618500); Gabet, L. (6602421964); Fraisse, R. (6602321380); Bonfort, T. (57740828200); Harnoufi, B. (57741308000); Greiner, V. (57741308100); Le Goff, M. (57192703544); Ortner, M. (57216016719); Paveau, V. (57740665400)","57741618500; 6602421964; 6602321380; 57740828200; 57741308000; 57741308100; 57192703544; 57216016719; 57740665400","JOINT SUPER-RESOLUTION AND IMAGE RESTORATION FOR PLÉIADES NEO IMAGERY","2022","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","43","B1-2022","","9","15","6","10.5194/isprs-archives-XLIII-B1-2022-9-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131934830&doi=10.5194%2fisprs-archives-XLIII-B1-2022-9-2022&partnerID=40&md5=53605b4934c6bddb5f1d7d9b34484d97","Modern Earth Observation optical satellite systems, such as Airbus's Pleiades Neo (PNeo) push the boundaries of high spatial resolution by providing commercial imagery products with up to 30cm ground sampling distance (GSD). To further enhance the quality of the images, the in-space imaging system is usually complemented by on-ground image restoration processing, such as deconvolution and denoising (Latry et al., 2012). Recent advances leverage Convolutional Neural Networks (CNNs) to improve the image restoration quality (K. Zhang et al., 2021a).Single Image Super-Resolution (SISR), or Zoom, the process of obtaining a higher resolution (HR) image from a lower resolved (LR) source, has recently gained traction for both medium resolution sensors such as Sentinel 2 (Lanaras et al., 2018) and high resolution such as Pléiades and GeoEye-1 (Zhu et al., 2020). This process further enhances the resolution of the image to improve downstream applications such as mapping (L. Zhang et al., 2021) and small objects recognition (Shermeyer and Van Etten, 2019). While SISR for remote sensing has been successfully tackled using CNNs (Rohith and Kumar, 2021) the main challenge for reaching acceptable image quality performance lies in the generation of realistic LR/HR training pairs (K. Zhang et al., 2021b). In this paper, we propose:<ul><li>a dedicated simulation chain leveraging extremely-high-resolution (EHR) aerial imagery to generate realistic 30cm Pléiades Neo images and their corresponding fully restored HR equivalent at 15cm GSD</li><li>A residual-based CNN architecture which we train to jointly restore and zoom the images All contributions are assessed on real PNEO images.</li></ul>We deployed the trained models in a production context, to enhance the full Pléiades Neo products - with a swath of 47k pixels - in an efficient and scalable manner.  © 2022 F. Chouteau et al.","Aerial photography; Antennas; Convolution; Convolutional neural networks; Deep learning; Image enhancement; Image quality; Image reconstruction; Optical resolving power; Restoration; Satellite imagery; Convolutional neural network; Deep learning; Ground sampling distances; High resolution; Image super resolutions; Pleiade neo; PLEIADES; Remote-sensing; Single images; Single-image super-resolution; Remote sensing","Convolutional Neural Networks; Deep Learning; Pleiades Neo; Remote Sensing; Single-Image Super-Resolution","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85131934830"
"Li Y.; Li J.; He L.","Li, Yunfei (57218424664); Li, Jun (24481713500); He, Lin (57192205017)","57218424664; 24481713500; 57192205017","A Single Image Pair-Based Convolutional Neural Network method for Spatio-Temporal Fusion; [单样本对卷积神经网络遥感图像时空融合]","2022","National Remote Sensing Bulletin","26","8","","1614","1623","9","10.11834/jrs.20219348","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141720665&doi=10.11834%2fjrs.20219348&partnerID=40&md5=c23381618123115600a9df9f317b5743","Due to the limitations of hardware technology and launching cost, there is a tradeoff between the spatial resolution and temporal resolution of satellite images. In order to access to the data with both high spatial and high temporal resolution, spatio-temporal fusion (STF) of remotely sensed images came into being. In recent years, convolutional neural networks (CNNs) have been successfully adopted in this field and some efficient STF methods based on CNNs were developed. However, these methods require a significant number of training image pairs, where each pair generally consists of a high spatial resolution image and a low spatial resolution image. Such a requirement limits the applicability of STF methods to real scenarios, as in many cases there is no wide availability of image pairs for training. To overcome this important limitation, in this paper we introduce a single image pair-based method (based on CNNs) for STF of remotely sensed images. Our method, called SS-CNN, uses the spatial information provided by the average image (obtained across the available spectral bands) of the high spatial resolution image to perform CNN-based super-resolution mapping (SRM) between the low and high spatial resolution images. Three experiments, including two simulated and one real ones, were used to evaluate the STF accuracy of SS-CNN. The obtained experimental results clearly demonstrate the effectiveness of our newly proposed method. © 2022 Science Press. All rights reserved.","Convolutional neural networks; Image fusion; Photomapping; Remote sensing; Convolutional neural network; Fusion methods; Hardware technology; High spatial resolution images; Image pairs; Neural network method; Remotely sensed images; Single image pair; Single images; Spatio-temporal fusions; Image resolution","CNN; remotely sensed images; single image pair; spatio-temporal fusion","Article","Final","","Scopus","2-s2.0-85141720665"
"Luo J.; Zhang Y.; Zhang Y.; Huang Y.; Yang J.","Luo, Jiawei (57221234005); Zhang, Yongchao (56042343300); Zhang, Yin (55975581400); Huang, Yulin (23014806800); Yang, Jianyu (9239230100)","57221234005; 56042343300; 55975581400; 23014806800; 9239230100","Two-dimensional Super-resolution Imaging for Real Aperture Radar by Iterative Adaptive Approach","2022","Proceedings of the IEEE Radar Conference","","","","","","","10.1109/RadarConf2248738.2022.9764238","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146201510&doi=10.1109%2fRadarConf2248738.2022.9764238&partnerID=40&md5=a4c9b060a8e9b608038ffa3fa9fa2e44","Real-aperture radar (RAR) super-resolution imaging is an important remote sensing technique, which has been widely studied and discussed recently. However, traditional super-resolution imaging approaches are commonly implemented for earth surface observation and mapping whose essence is to enhance the azimuth resolution of the image. In this paper, we consider the RAR super-resolution imaging problem of azimuth-pitch two-dimensional scanning, and extend the traditional azimuth-distance two-dimensional planar imaging to azimuth-pitch-distance three-dimensional imaging of the airspace. The core of this problem is the azimuth-pitch two-dimensional super-resolution processing. First, a fixed platform azimuth-pitch two-dimensional scanning radar echo model is introduced. Then, the two-dimensional convolutional echo model is transformed into a standard linear estimation form through discretization and vectorization. Finally, by constructing a weighted least squares cost function and employing the matrix inverse lemma, the target backscattering coefficient can be iteratively estimated. The proposed method has competitive two-dimensional resolution capability compared with existing ones. The simulation verifies the effectiveness of the proposed method. © 2022 IEEE.","Backscattering; Cost functions; Fixed platforms; Image enhancement; Imaging systems; Iterative methods; Optical resolving power; Radar imaging; Remote sensing; Adaptive approach; Earth's surface; Echo model; Real aperture radar; Remote sensing techniques; Super resolution imaging; Surface mapping; Surface observation; Two-dimensional; Two-dimensional scanning; Inverse problems","Real aperture radar; super-resolution imaging; two-dimensional","Conference paper","Final","","Scopus","2-s2.0-85146201510"
"Liu J.; Sun Y.; Ren K.; Zhao Y.; Deng K.; Wang L.","Liu, Jia (36816241900); Sun, Yongjian (57211860991); Ren, Kaijun (35093112400); Zhao, Yanlai (45662261300); Deng, Kefeng (54583346900); Wang, Lizhe (23029267900)","36816241900; 57211860991; 35093112400; 45662261300; 54583346900; 23029267900","A Spatial Downscaling Approach for WindSat Satellite Sea Surface Wind Based on Generative Adversarial Networks and Dual Learning Scheme","2022","Remote Sensing","14","3","769","","","","10.3390/rs14030769","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124521852&doi=10.3390%2frs14030769&partnerID=40&md5=5769dd6774b23f35947860e44e4eceec","Sea surface wind (SSW) is a crucial parameter for meteorological and oceanographic research, and accurate observation of SSW is valuable for a wide range of applications. However, most existing SSW data products are at a coarse spatial resolution, which is insufficient, especially for regional or local studies. Therefore, in this paper, to derive finer-resolution estimates of SSW, we present a novel statistical downscaling approach for satellite SSW based on generative adversarial networks and dual learning scheme, taking WindSat as a typical example. The dual learning scheme performs a primal task to reconstruct high resolution SSW, and a dual task to estimate the degradation kernels, which form a closed loop and are simultaneously learned, thus introducing an additional constraint to reduce the solution space. The integration of a dual learning scheme as the generator into the generative adversarial network structure further yield better downscaling performance by fine-tuning the generated SSW closer to high-resolution SSW. Besides, a model adaptation strategy was exploited to enhance the capacity for downscaling from low-resolution SSW without high-resolution ground truth. Comprehensive experiments were conducted on both the synthetic paired and unpaired SSW data. In the study areas of the East Coast of North America and the North Indian Ocean, in this work, the downscaling results to 0.25° (high resolution on the synthetic dataset), 0.03125° (8× downscaling), and 0.015625° (16× downscaling) of the proposed approach achieve the highest accuracy in terms of root mean square error and R-Square. The downscaling resolution can be enhanced by increasing the basic blocks in the generator. The highest downscaling reconstruction quality in terms of peak signal-to-noise ratio and structural similarity index was also achieved on the synthetic dataset with high-resolution ground truth. The experimental results demonstrate the effectiveness of the proposed downscaling network and the superior performance compared with the other typical advanced downscaling methods, including bicubic interpolation, DeepSD, dual regression networks, and adversarial DeepSD. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Mean square error; Remote sensing; Satellites; Signal to noise ratio; Space optics; Surface waters; Deep learning; Down-scaling; Dual learning; High resolution; Learning schemes; Satellite remote sensing; Sea surface wind; Statistical downscaling; Superresolution; WindSat; Generative adversarial networks","Deep learning; Dual learning; Generative adversarial network; Satellite remote sensing; Sea surface wind; Statistical downscaling; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85124521852"
"Cheng K.; Rong L.; Jiang S.; Zhan Y.","Cheng, Keyang (8878638900); Rong, Lan (57226236582); Jiang, Senlin (57952043900); Zhan, Yongzhao (7102620105)","8878638900; 57226236582; 57952043900; 7102620105","Double drive adaptive super-resolution reconstruction method of remote sensing images for object detection; [面向目标检测的双驱自适应遥感图像超分重建方法]","2022","Beijing Hangkong Hangtian Daxue Xuebao/Journal of Beijing University of Aeronautics and Astronautics","48","8","","1343","1352","9","10.13700/j.bh.1001-5965.2021.0517","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141923568&doi=10.13700%2fj.bh.1001-5965.2021.0517&partnerID=40&md5=ed95badd1d1e95809326ad70ad9d0dc3","The existing optical remote sensing image super-resolution reconstruction method is mainly to generate visually satisfactory images, and does not take into account the particularity of the subsequent target detection task, so it cannot be effectively applied to target detection. Therefore, a double drive adaptive multi-scale optical remote sensing image super-resolution reconstruction method for target detection is proposed. The super-resolution reconstruction network and target detection network are combined for joint optimization. According to the characteristics of optical remote sensing image, an adaptive multi-scale remote sensing image super-partition reconstruction network is designed. The selective kernel network and adaptive gating unit are integrated to extract and fuse features, and the primary remote sensing image is reconstructed. Through the double drive module, and task driven will feature a priori driver loses to the above points in the network, on the one hand, improve the performance of target detection. The proposed method was tested on UCAS-AOD and NWPU VHR-10 datasets, and compared with the five mainstream algorithms, peak signal-to-noise ratio and average accuracy improved by 1. 86 dB and 3. 73%, respectively, compared with the FDSR algorithm. Experimental results show that compared with other methods, the combination of the proposed algorithm and optical remote sensing image target detection can achieve better results and the comprehensive performance is the best. © 2022 Beijing University of Aeronautics and Astronautics (BUAA). All rights reserved.","Feature extraction; Image reconstruction; Object recognition; Optical remote sensing; Optical resolving power; Signal to noise ratio; Feature priori driven; Multi-scales; Objects detection; Optical remote sensing; Reconstruction method; Remote sensing images; Super-resolution reconstruction; Super-resolution reconstruction of remote sensing image; Targets detection; Task-driven; Object detection","features priori driven; multi-scale; object detection; super-resolution reconstruction of remote sensing images; task driven","Article","Final","","Scopus","2-s2.0-85141923568"
"Mishra K.; Garg R.D.","Mishra, Kavach (57202200894); Garg, Rahul Dev (15044199700)","57202200894; 15044199700","BLUR KERNEL'S EFFECT on PERFORMANCE of SINGLE-FRAME SUPER-RESOLUTION ALGORITHMS for SPATIALLY ENHANCING HYPERION and PRISMA DATA","2022","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","46","M-2-2022","","165","171","6","10.5194/isprs-Archives-XLVI-M-2-2022-165-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136252684&doi=10.5194%2fisprs-Archives-XLVI-M-2-2022-165-2022&partnerID=40&md5=d815971683dee7a8056855332fbdfd0e","Single-frame super-resolution (SFSR) achieves the goal of generating a high-resolution image from a single low-resolution input in a three-step process, namely, noise removal, up-sampling and deblurring. Scale factor and blur kernel are essential parameters of the up-sampling and deblurring steps. Few studies document the impact of these parameters on the performance of SFSR algorithms for improving the spatial resolution of real-world remotely-sensed datasets. Here, the effect of changing blur kernel has been studied on the behaviour of two classic SFSR algorithms: iterative back projection (IBP) and gaussian process regression (GPR), which are applied to two spaceborne hyperspectral datasets for scale factors 2, 3 and 4. Eight full-reference image quality metrics and algorithm processing time are deployed for this purpose. A literature-based re-interpretation of Wald's reduced resolution protocol has also been used in this work for choosing the reference image. Intensive intra-Algorithm comparisons of various simulation scenarios reveal each algorithm's best performing Gaussian blur kernel parameters. Inter-Algorithm comparison shows the better performing algorithm out of the two, thereby paving the way for further research in SFSR of remotely-sensed images.  © Copyright: ","Image enhancement; Iterative methods; Optical resolving power; Parameter estimation; Remote sensing; Signal sampling; Algorithm comparison; Deblurring; High-resolution images; Hyperspectral remote sensing; Reference image; Scale Factor; Single frame super resolutions; Super resolution algorithms; Upsampling; Wald protocol; Image quality","Hyperspectral remote sensing; image quality; Single-frame super-resolution; Wald's protocol","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85136252684"
"Liu H.; Gu Y.","Liu, Huan (57069409100); Gu, Yanfeng (7403045983)","57069409100; 7403045983","Deep Joint Estimation Network for Satellite Video Super-Resolution With Multiple Degradations","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5621015","","","","10.1109/TGRS.2022.3163790","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127514553&doi=10.1109%2fTGRS.2022.3163790&partnerID=40&md5=8ab46cc94a1cd3f0212ae2d0708d4b0d","Super-resolution (SR) for satellite video data has been a hot research topic in the field of remote sensing video analysis. The existing satellite video SR methods assume that the blur kernel in the imaging degradation model is known. However, the blur kernel in real satellite videos is usually unknown, which inevitably results in poor performance when the true blur kernel is not consistent with a predefined blur kernel. To address this issue, this article proposes a deep joint estimation network for satellite video SR (JENSVSR), which jointly estimates blur kernels and SR frames. Specifically, JENSVSR is composed of a video SR subnetwork and a blur kernel estimation subnetwork. On one hand, the video SR subnetwork makes use of multiple video frames to generate super-resolved satellite frames. To effectively fuse information from adjacent frames, an alignment and fusion module is proposed in the feature space. On the other hand, the blur estimation subnetwork is also proposed to predict blur kernels. The two subnetworks are coupled by cross-task feature fusion modules (CTFFMs) to achieve joint estimation rather than two-step independent estimation. The performance of our proposed method is evaluated on synthetic and real satellite videos. The experimental results show that our proposed method is superior to the current state-of-the-art SR methods. © 1980-2012 IEEE.","Image reconstruction; Optical resolving power; Remote sensing; Space optics; Blur kernel estimations; Images reconstruction; Kernel; Multiple degradations; Satellite video; Spatial resolution; Subnetworks; Super-resolution; Superresolution; Video super-resolution; estimation method; image resolution; imaging method; remote sensing; satellite data; videography; Satellites","Blur kernel estimation; multiple degradations; satellite video; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85127514553"
"Wang S.; Zhou T.; Lu Y.; Di H.","Wang, Shunzhou (57204129139); Zhou, Tianfei (56517418000); Lu, Yao (56939379300); Di, Huijun (7005326748)","57204129139; 56517418000; 56939379300; 7005326748","Contextual Transformation Network for Lightweight Remote-Sensing Image Super-Resolution","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3132093","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120569746&doi=10.1109%2fTGRS.2021.3132093&partnerID=40&md5=d43f3baa63556d9612712539de0273d7","Current super-resolution networks typically reduce network parameters and multiadds operations by designing lightweight structures, but lightening the convolution layer is often ignored. In this work, we observe that 3 × 3 convolutions occupy a high percentage of network parameters in most lightweight super-resolution networks. This motivates us to consider lightening super-resolution networks by replacing 3 × 3 convolutions with lightweight convolutions, while maintaining the performance. To achieve this, we propose a lightweight convolution layer named contextual transformation layer (CTL). It can yield efficient contextual features through a context feature extraction module and enrich extracted contextual features through a context feature transformation module. Based on CTLs, we build a lightweight super-resolution network called contextual transformation network (CTN) for remote-sensing image super-resolution. Specifically, we use two CTLs to construct a contextual transformation block (CTB) for hierarchical feature learning. Interleaved with a CTB, a context enhancement module (CEM) is employed to enhance the extracted feature representations. All extracted features are processed by a contextual feature aggregation module for final remote-sensing image super-resolution. Extensive experiments are performed on a remote-sensing image super-resolution benchmark named UC Merced. Our method achieves superior results to the other state-of-the-art methods. To demonstrate the generalization ability of our CTL, we extend our CTN to two relevant tasks: Natural image super-resolution and natural image denoising. Experimental results on natural image super-resolution benchmarks (i.e., Set5, Set14, B100, Urban100, and Manga109) and natural image denoising benchmarks (i.e., SIDD and DND) further prove the superiority of our method. Our code is publicly available at https://github.com/BITszwang/CTNet.  © 2022 IEEE.","Convolution; Image denoising; Machine learning; Optical resolving power; Contextual feature; Contextual feature learning; Feature learning; Image super resolutions; Lightweight neural network; Natural images; Neural-networks; Remote sensing images; Remote-sensing; Superresolution; artificial neural network; image processing; remote sensing; satellite imagery; Remote sensing","Contextual feature learning; image super-resolution; lightweight neural network; remote sensing","Article","Final","","Scopus","2-s2.0-85120569746"
"Zhang N.; Wang Y.; Wang X.","Zhang, Nenghuan (57343902900); Wang, Yongbin (13607280200); Wang, Xiaoguang (55557038800)","57343902900; 13607280200; 55557038800","Blind Super-Resolution Network for Remote Sensing Image","2021","IEEE Information Technology, Networking, Electronic and Automation Control Conference, ITNEC 2021","","","","424","428","4","10.1109/ITNEC52019.2021.9587196","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119290946&doi=10.1109%2fITNEC52019.2021.9587196&partnerID=40&md5=cd1056c19cf6106687266d72a469e92b","In the past few years, image super-resolution has achieved remarkable progress, but due to the texture particularity of remote sensing images, the performance in remote sensing images are not very good. We consider that the texture of the same object in remote sensing image is highly similar, so that relevant textures can be transferred from the high resolution remote sensing image to the low resolution remote sensing image. In this paper, we propose a novel super-resolution network for remote sensing image. Specifically, we take a low resolution image and a reference high resolution image as the inputs, then utilize transformer structure to learn the texture transfer which allows the model to enhance the texture details of the low resolution image, to generate the super-resolution image. Experiments on public datasets show that our method achieves visual improvements. © 2021 IEEE.","Image enhancement; Image texture; Optical resolving power; Remote sensing; Blind Super-resolution; High-resolution remote sensing images; Image super resolutions; Low resolution images; Lower resolution; Performance; Remote sensing images; Superresolution; Texture transfer; Transformer structure; Textures","remote sensing image; super-resolution; texture transfer; transformer structure","Conference paper","Final","","Scopus","2-s2.0-85119290946"
"Shen H.; Qiu Z.; Yue L.; Zhang L.","Shen, Huanfeng (8359721100); Qiu, Zhonghang (57212385287); Yue, Linwei (56225521100); Zhang, Liangpei (8359720900)","8359721100; 57212385287; 56225521100; 8359720900","Deep-Learning-Based Super-Resolution of Video Satellite Imagery by the Coupling of Multiframe and Single-Frame Models","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3121303","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118256263&doi=10.1109%2fTGRS.2021.3121303&partnerID=40&md5=56ed4861cc8d7f4a9f0179075fa0d5b4","Image super-resolution (SR) is an effective solution to the limitation of the spatial resolution of video satellite images, which is caused by the degradation and compression in the imaging phase. For the processing of satellite videos, the commonly employed deep-learning-based single-frame SR (SFSR) framework has limited performance without using complementary information between the video frames. On the other side, the multiframe SR (MFSR) can utilize temporal subpixel information to super-resolve the high-resolution (HR) imagery. However, although deeper and wider deep learning network provides powerful feature representations for SR methods, it has always been a challenge to accurately reconstruct the boundaries of ground objects in video satellite images. In this article, to address these issues, we propose an edge-guided video SR (EGVSR) framework for video satellite image SR, which couples the MFSR model and the edge-SFSR (E-SFSR) model in a unified network. The EGVSR framework is composed of an MFSR branch and an edge branch. The MFSR branch is used to extract the complementary features from the consecutive video frames. Concurrently, the edge branch acts as an SFSR model to translate the edge maps from the low-resolution modality to the HR one. At the final SR stage, the DBFM is built to focus on the promising inner representations of the features of the two branches and fuse them. Extensive experiments on video satellite imagery show that the proposed EGVSR method can achieve superior performance compared to the representative deep-learning-based SR methods.  © 1980-2012 IEEE.","Deep learning; Edge detection; Image reconstruction; Image resolution; Remote sensing; Satellite imagery; Sols; Deep learning; Edge prior; Features extraction; Image edge detection; Images reconstruction; Remote-sensing; Spatial resolution; Superresolution; Video satellite; coupling; image resolution; satellite imagery; spatial resolution; Feature extraction","Deep learning; edge prior; super-resolution (SR); video satellite","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85118256263"
"Zhang C.; Wang Q.; Lu P.; Ge Y.; Atkinson P.M.","Zhang, Chengyuan (57216611828); Wang, Qunming (55649569623); Lu, Ping (41861974200); Ge, Yong (26655529300); Atkinson, Peter M. (7201906181)","57216611828; 55649569623; 41861974200; 26655529300; 7201906181","Fast and Slow Changes Constrained Spatio-Temporal Subpixel Mapping","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3133534","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121401087&doi=10.1109%2fTGRS.2021.3133534&partnerID=40&md5=847522ac382358ab1142787f2b08f697","Subpixel mapping (SPM) is a technique to tackle the mixed-pixel problem and produces land cover and land use (LCLU) maps at a finer spatial resolution than the original coarse data. However, uncertainty exists unavoidably in SPM, which is an ill-posed downscaling problem. Spatio-temporal SPM methods have been proposed to deal with this uncertainty, but current methods fail to explore fully the information in the time-series images, especially more rapid changes over a short-time interval. In this article, a fast and slow changes constrained spatio-temporal subpixel mapping (FSSTSPM) method is proposed to account for fast LCLU changes over a short time interval and slow changes over a long time interval. Both fast and slow changes-based temporal constraints are proposed and incorporated simultaneously into the FSSTSPM to increase the accuracy of SPM. The proposed FSSTSPM method was validated using two synthetic datasets with various proportion errors. It was also applied to oil-spill mapping using a real PlanetScope-Sentinel-2 dataset and Amazon deforestation mapping using a real Landsat-Moderate Resolution Imaging Spectroradiometer (MODIS) dataset. The results demonstrate the superiority of FSSTSPM. Moreover, the advantage of FSSTSPM is more obvious with an increase in proportion errors. The concepts of the fast and slow changes, together with the derived temporal constraints, provide a new insight to enhance SPM by taking fuller advantage of the temporal information in the available time-series images.  © 2022 IEEE.","Deforestation; Hopfield neural networks; Image enhancement; Land use; Mapping; Oil spills; Pixels; Remote sensing; Satellite imagery; Time series; Down-scaling; Hopfield neural network; Land cover; Land cover and land use; Remote-sensing; Spatial resolution; Spatio-temporal; Spatio-temporal dependence; Sub-pixel mapping; Subpixel mapping; Superresolution mapping; Temporal dependence; Uncertainty; data set; deforestation; digital mapping; image resolution; land cover; land use; mapping method; MODIS; spatiotemporal analysis; Image resolution","Downscaling; Hopfield neural network (HNN); land cover and land use (LCLU); spatio-temporal dependence; subpixel mapping (SPM); super-resolution mapping","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85121401087"
"Lu Z.; Liu C.","Lu, Zhenghao (57343634900); Liu, Cong (57138870000)","57343634900; 57138870000","Multiscale feature reuse mixed attention network for image reconstruction; [多尺度特征复用混合注意力网络的图像重建]","2021","Journal of Image and Graphics","26","11","","2645","2658","13","10.11834/jig.200549","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119295286&doi=10.11834%2fjig.200549&partnerID=40&md5=53a389324e08824b158ffcbc0cc299f6","Objective: Obtaining a high-resolution image directly is very difficult due to the interference of the external environment and hardware conditions. A low-resolution image is usually obtained at first, and then one or more image super-resolution methods are employed to obtain the corresponding high-resolution image. In addition, the number of collected images is large. Therefore, how to reconstruct a high-resolution image from a low-resolution image at a low cost has become a research hotspot in the field of computer vision. This research widely exists in the fields of medicine, remote sensing, and public safety. In recent years, many image super-resolution methods have been proposed, and these techniques can be broadly categorized into interpolation-, projection-, and learning-based methods. Among these methods, the convolutional neural network, a typical approach of the learning-based method, has attracted more attention in recent years but still has several problems. First, the reconstruction effect is often improved by simply deepening the network, which will make the network very complex and increase the difficulty of the training. Second, the high-frequency information in an image is difficult to reconstruct. The attention mechanism has been applied to overcome this problem, but the existing attention mechanisms are usually directly quoted from many high-level vision tasks, without considering the particularity of the super-resolution reconstruction tasks. Third, the existing upsampling methods have several limitations such as feature loss and training oscillations, which are difficult to solve in the field of super-resolution reconstruction. To address these problems, this paper proposes a mixed attention network model based on multiscale feature reuse for super-resolution reconstruction. The model improves the performance of the network by using several novelty strategies including multipath network, long and short hop connections, compensation reconstruction block, and mixed attention mechanism. Method: The proposed network is mainly composed of five parts: the preprocessing module, the multiscale feature reuse mixed attention module, the upsampling module, the compensation reconstruction module, and the reconstruction module. The first part is the preprocessing module, which uses a convolutional layer to extract shallow features and expand the number of channels in the feature map. The second part is the multiscale feature reuse mixed attention module. This part contains three important subparts including a multichannel network, a mixed attention mechanism, and the jump connections. The multichannel network can increase the receptive fields of different feature maps and improve the reuse of multiscale features. The mixed attention mechanism can better capture the high-frequency information, and the jump connections can reduce the degradation problem of deep network and improve the learning ability. Moreover, the interdependence between shallow features and deep features can be learned by using the depth method and the widening method. The third part is the upsampling module, which uses the subpixel method to upsample the feature map to the target size. The shallow and deep features are upsampled simultaneously and fused to compensate the feature loss caused by the upsampling operation. The fourth part is the compensation reconstruction module, which is composed of a convolutional layer and a mixed attention module. This part is used to perform the secondary feature compensation and stabilize the model training on the feature maps obtained through upsampling. The fifth part is the reconstruction module, which uses a convolutional layer to expand the number of channels of the feature map to the original number to obtain the reconstructed high-resolution image. In the training phase, the DIV2K(DIVerse 2K) dataset is taken as the training set, and each image is processed by several enhancement methods such as random rotation and horizontal flip. Adaptive momentum estimation(ADAM) is used as the optimizer, and L1 is used as the objective function. Each run uses 800 epochs. Result: The proposed method is compared with several current state-of-the-art methods including super-resolution convolutional neural network(SRCNN), super-resolution using very deep convolutional networks(VDSR), deep Laplacian pyramid super-resolution networks(LapSRN), memory network for image restoration(MemNet), super-resolution network for multiple degradations(SRMDNF), cascading residual network(CARN), multi-path adaptive modulation network(MAMNet), and the simplified version of residual channel attention network (RCAN-mini). Peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) are applied to evaluate the performance of these algorithms on widely used benchmark testsets such as Set5, Set14, BSD100(Berkeley segmentation dataset), and Urban100. When the scale factor is 3, the PSNR/SSIM values obtained by this model on each testsets are 34.40 dB/0.927 3, 30.35 dB/0.842 7, 29.11 dB/0.805 2, and 28.23 dB/0.854 0 in order. In terms of PSNR index, compared with RCAN-mini, it is increased by 0.15 dB, 0.08 dB, 0.07 dB, and 0.24 dB on four testsets. Compared with other methods, the reconstruction results are also improved. Conclusion: A multiscale feature reuse mixed attention network, which applies a new network structure and an attention mechanism to improve the performance of super-resolution, is proposed. This model is compared with other methods by quantization experiment and visual experiment. Experiment results show that the proposed method can achieve the best reconstruction effect on the edge and texture information and can obtain higher values on the evaluation indicators of PSNR and SSIM than other methods. © 2021, Editorial Office of Journal of Image and Graphics. All right reserved.","","Edge; Feature compensation; Mixed attention; Multi-scale feature reuse; Super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85119295286"
"Li J.; Shen H.; Li H.; Jiang M.; Yuan Q.","Li, Jie (57214207213); Shen, Huanfeng (8359721100); Li, Huifang (36782247100); Jiang, Menghui (57210173702); Yuan, Qiangqiang (36635300800)","57214207213; 8359721100; 36782247100; 57210173702; 36635300800","Radiometric quality improvement of hyperspectral remote sensing images: A technical tutorial on variational framework","2021","Journal of Applied Remote Sensing","15","3","031502","","","","10.1117/1.JRS.15.031502","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116449561&doi=10.1117%2f1.JRS.15.031502&partnerID=40&md5=c00e1f4b6ba382e42202e4d4ee8c2807","In hyperspectral remote sensing imagery, the sensor, atmosphere, topography, and other factors often bring about some degradations, such as noise, haze, clouding, and shadowing. Due to inevitable tradeoff between spatial resolution and spectral resolution, low spatial details of hyperspectral images (HSIs) also limit the range of potential applications. Compensating for these degradations through quality improvement is a key preprocessing step in the exploitation of HSIs. A comprehensive analysis of the quality improvement techniques for HSIs is presented. The closely connected techniques, such as denoising, destriping, dehazing, cloud removal, and super-resolution, are linked as a whole by a general reconstruction model in a variational framework. Furthermore, we classify the methods into four categories according to their processing strategies for HSIs, including single-channel prior-based model, cross-channel prior-based model, tensor-based model, and data-driven prior-based model. Then, for several specific tasks, we briefly introduce their architectures of quality improvement, which combine different models and available complementary information from other spectral bands and/or temporal/sensor images. Some experimental results in different tasks are presented to show the effect of variational framework and draw some meaningful conclusions. Finally, some advantages on variational framework are discussed, and several promising directions are provided to serve as guidelines for future work.  © 2021 Society of Photo-Optical Instrumentation Engineers (SPIE).","Image enhancement; Image fusion; Radiometry; Remote sensing; Spectroscopy; Topography; Hyperspectral remote sensing; Hyperspectral Remote Sensing Image; Images reconstruction; Quality improvement; Radiometric quality; Radiometric quality improvement; Remote sensing imagery; Spatial resolution; Variational framework; Variational modeling; Image reconstruction","hyperspectral image; image fusion; image reconstruction; image restoration; radiometric quality improvement; variational model","Review","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85116449561"
"","","","2021 2nd International Conference on Signal Processing and Computer Science, SPCS 2021","2021","Journal of Physics: Conference Series","2031","1","","","","554","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117583057&partnerID=40&md5=f431cc4b2fd0d3a607f4491e9e7626c6","The proceedings contain 68 papers. The topics discussed include: research on acoustic emission signal denoising based on autoencoder; application of photoplethysmography signal in diagnosis of cerebrovascular disease and its extraction method based on wavelet transform; prediction of polar vortex intensity signal based on convolution smoothing and long short-term memory; a methodology for removing biofouling of the hull based on ultrasonic guided waves; analysis on the applicability of high-resolution remote sensing images for highway construction; infrared image detection of insulators based on Centernet model; a new super-resolution restoration method with generated adversarial network for underground video images in coal; analysis and research on radar gesture micro-motion feature extraction method; an improved multi-target recognition method for vehicle linear frequency modulated continuous wave radar; and an optimal selection algorithm based on Q-learning for dual media communication system with full-duplex relays.","","","Conference review","Final","","Scopus","2-s2.0-85117583057"
"Shen B.; Wang R.; Law A.C.C.; Kamath R.; Choo H.; Kong Z.","Shen, Bo (57219789668); Wang, Rongxuan (57217224774); Law, Andrew Chung Chee (57208403313); Kamath, Rakesh (57218712182); Choo, Hahn (9739562200); Kong, Zhenyu (56051308000)","57219789668; 57217224774; 57208403313; 57218712182; 9739562200; 56051308000","Super Resolution for Multi-Sources Image Stream Data Using Smooth and Sparse Tensor Completion and Its Applications in Data Acquisition of Additive Manufacturing","2022","Technometrics","64","1","","2","17","15","10.1080/00401706.2021.1905074","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105157747&doi=10.1080%2f00401706.2021.1905074&partnerID=40&md5=1f82ee745cd789953ae0b3a3cdd72ca5","Recent developments of advanced imaging systems spur their applications in many areas, ranging from satellite remote sensing for geographic information to thermal imaging analysis for manufacturing process monitoring and control. Due to different specifications of imaging systems, the resulting image stream data (videos) have different spatial and temporal resolutions. This proposed work is based on the image stream data captured by multiple imaging systems for the same object with different but complementary spatial and temporal resolutions. For example, one system has high spatial but low temporal resolutions while the other one has opposite resolutions. The goal of this article is to develop a new super resolution method that integrates these different types of image stream data to improve both spatial and temporal resolutions, which is critical to obtaining more insightful information for more effective quality control of targeted processes or systems. To fulfill this goal, a new tensor completion model is developed by considering both smooth and sparse features simultaneously and is thus termed smooth and sparse tensor completion (SSTC). The results of the extensive case studies illustrate the superiority of our method over the elaborately selected benchmark methods. © 2021 American Statistical Association and the American Society for Quality.","3D printers; Data acquisition; Image enhancement; Image resolution; Imaging systems; Infrared imaging; Optical resolving power; Process control; Process monitoring; Remote sensing; Tensors; Geographic information; Manufacturing process; Satellite remote sensing; Spatial and temporal resolutions; Superresolution methods; Temporal resolution; Tensor completion; Thermal imaging analysis; Data streams","CANDECOMP/PARAFAC (CP) decomposition; Rank estimation; Smooth and sparse decomposition","Article","Final","","Scopus","2-s2.0-85105157747"
"Clabaut É.; Lemelin M.; Germain M.; Bouroubi Y.; St-Pierre T.","Clabaut, Étienne (57211641688); Lemelin, Myriam (55845571900); Germain, Mickaël (7201845387); Bouroubi, Yacine (42961054400); St-Pierre, Tony (57297977400)","57211641688; 55845571900; 7201845387; 42961054400; 57297977400","Model specialization for the use of esrgan on satellite and airborne imagery","2021","Remote Sensing","13","20","4044","","","","10.3390/rs13204044","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117227601&doi=10.3390%2frs13204044&partnerID=40&md5=0490fea79fd11b226c9e096e6bf7063e","Training a deep learning model requires highly variable data to permit reasonable generalization. If the variability in the data about to be processed is low, the interest in obtaining this generalization seems limited. Yet, it could prove interesting to specialize the model with respect to a particular theme. The use of enhanced super-resolution generative adversarial networks (ERSGAN), a specific type of deep learning architecture, allows the spatial resolution of remote sensing images to be increased by “hallucinating” non-existent details. In this study, we show that ESRGAN create better quality images when trained on thematically classified images than when trained on a wide variety of examples. All things being equal, we further show that the algorithm performs better on some themes than it does on others. Texture analysis shows that these performances are correlated with the inverse difference moment and entropy of the images. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Image enhancement; Optical resolving power; Remote sensing; Satellite imagery; Textures; Airborne imagery; ESRGAN; Generalisation; Haralick; Learning architectures; Learning models; Spatial resolution; Specialisation; Superresolution; Variable data; Generative adversarial networks","ESRGAN; Generative adversarial networks; Haralick; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85117227601"
"Zhang B.; Ma M.; Wang M.; Hong D.; Yu L.; Wang J.; Gong P.; Huang X.","Zhang, Bo (57875944000); Ma, Muyuan (57847657000); Wang, Mingqing (57211749480); Hong, Danfeng (56108179600); Yu, Le (55277716700); Wang, Jie (57881408100); Gong, Peng (57211236643); Huang, Xiaomeng (8905764300)","57875944000; 57847657000; 57211749480; 56108179600; 55277716700; 57881408100; 57211236643; 8905764300","Enhanced Resolution of FY4 Remote Sensing Visible Spectrum Images Utilizing Super-Resolution and Transfer Learning Techniques","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","7391","7399","8","10.1109/JSTARS.2022.3197401","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136143158&doi=10.1109%2fJSTARS.2022.3197401&partnerID=40&md5=a713870bf40d8ab085103ead5c8045ef","Remote sensing images acquired by the FY4 satellite are crucial for regional cloud monitoring and meteorological services. Inspired by the success of deep learning networks in image super-resolution, we applied image super-resolution to FY4 visible spectrum (VIS) images. However, training a robust network directly for FY4 VIS image super-resolution remains challenging due to the limited provision of high resolution FY4 sample data. Here, we propose a super-resolution and transfer learning model, FY4-SR-Net. It is composed of pretraining and fine-tuning models. The pretraining model was developed using a deep residual network and a large number of FY4 A 4 and 1 km resolution VIS images as the training data. The knowledge derived from 4 km to 1 km resolution images was incorporated into FY4 B 1 km to 0.25 km resolution VIS images. The FY4-SR-Net is fine-tuned by incorporating limited 1 km and 0.25 km resolution panchromatic images, and then producing 1km super-resolution VIS images of the FY4 satellite. Using the one-day FY4 test dataset for qualitative and quantitative evaluations, the FY4-SR-Net outperformed the classic bicubic interpolation approach with a 16.12% reduction in root-mean-square error and a 2.97% rise in peak signal-to-noise ratio averages. The structural similarity value average increased by 0.0026. This article provides a new precedent for improving the spatial resolution of FY4 series meteorological satellites, which has important scientific significance and application properties.  © 2008-2012 IEEE.","Deep learning; Image enhancement; Image resolution; Mean square error; Satellites; Signal to noise ratio; Statistical tests; Tuning; Fine tuning; Pre-training; Remote sensing images; Remote-sensing; Satellite broadcasting; Spatial resolution; Superresolution; Transfer learning; Visible spectrums; FengYun; image resolution; machine learning; model; remote sensing; spatial resolution; Remote sensing","Fine-tuning; pretraining; remote sensing images; super-resolution; transfer learning","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85136143158"
"Wang L.; Wang L.; Wang H.; Wang X.; Bruzzone L.","Wang, Lifeng (57226450880); Wang, Liguo (55745497100); Wang, Heng (57208215705); Wang, Xiaoyi (57074222100); Bruzzone, Lorenzo (7006892410)","57226450880; 55745497100; 57208215705; 57074222100; 7006892410","SPCNet: A Subpixel Convolution-Based Change Detection Network for Hyperspectral Images with Different Spatial Resolutions","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5533314","","","","10.1109/TGRS.2022.3189188","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134248285&doi=10.1109%2fTGRS.2022.3189188&partnerID=40&md5=6ed5b32d43a74af5542a8706026a3889","The very high spectral resolution in hyperspectral images (HSIs) offers an opportunity to detect subtle land-cover changes. However, the availability of HSIs acquired from different platforms requires the development of change detection (CD) methods capable of processing HSIs with different spatial resolutions. In this article, we propose a general end-to-end subpixel convolution-based residual network (SPCNet) to accomplish the CD task between high spatial resolution (HR) and low spatial resolution (LR) HSIs. To effectively tackle the resolution matching issue, a super-resolution (SR) block with an efficient subpixel convolution layer is introduced to upscale the LR feature maps into HR maps. The subpixel convolution layer can fully explore the subpixel context information by learning an array of upscaling filters. Moreover, the designed SPC module is embedded into the LR branch to generate more discriminative representations. More importantly, the SPC module as a plug-and-play unit has the potential to be embedded into other baseline networks to enhance the feature learning capability. Experimental results on four HSI datasets demonstrate the effectiveness of the proposed SPCNet. © 1980-2012 IEEE.","Change detection; Convolution; Deep learning; Image resolution; Job analysis; Pixels; Remote sensing; Spectral resolution; Spectroscopy; Change detection; Deep learning; Features extraction; HyperSpectral; Hyperspectral image; Multiscale image; Neural-networks; Remote-sensing; Residual network; Residual neural network; Spatial resolution; Sub-pixels; Subpixel convolution; Task analysis; spatial resolution; Feature extraction","Change detection (CD); Deep Learning; Hyperspectral images (HSIs); Multiscale images; Remote sensing; Residual network; Subpixel convolution","Article","Final","","Scopus","2-s2.0-85134248285"
"Choi Y.; Han S.; Kim Y.","Choi, Yeonju (57215967828); Han, Sanghyuck (37101680300); Kim, Yongwoo (57202143770)","57215967828; 37101680300; 57202143770","A no-reference cnn-based super-resolution method for kompsat-3 using adaptive image quality modification","2021","Remote Sensing","13","16","3301","","","","10.3390/rs13163301","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113531497&doi=10.3390%2frs13163301&partnerID=40&md5=64de6169214f980e3b156b6bd1198a44","In recent years, research on increasing the spatial resolution and enhancing the quality of satellite images using the deep learning-based super-resolution (SR) method has been actively conducted. In a remote sensing field, conventional SR methods required high-quality satellite images as the ground truth. However, in most cases, high-quality satellite images are difficult to acquire because many image distortions occur owing to various imaging conditions. To address this problem, we propose an adaptive image quality modification method to improve SR image quality for the KOrea Multi-Purpose Satellite-3 (KOMPSAT-3). The KOMPSAT-3 is a high performance optical satellite, which provides 0.7-m ground sampling distance (GSD) panchromatic and 2.8-m GSD multi-spectral images for various applications. We proposed an SR method with a scale factor of 2 for the panchromatic and pan-sharpened images of KOMPSAT-3. The proposed SR method presents a degradation model that generates a low-quality image for training, and a method for improving the quality of the raw satellite image. The proposed degradation model for low-resolution input image generation is based on Gaussian noise and blur kernel. In addition, top-hat and bottom-hat transformation is applied to the original satellite image to generate an enhanced satellite image with improved edge sharpness or image clarity. Using this enhanced satellite image as the ground truth, an SR network is then trained. The performance of the proposed method was evaluated by comparing it with other SR methods in multiple ways, such as edge extraction, visual inspection, qualitative analysis, and the performance of object detection. Experimental results show that the proposed SR method achieves improved reconstruction results and perceptual quality compared to conventional SR methods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Gaussian noise (electronic); Image acquisition; Image quality; Object detection; Optical resolving power; Remote sensing; Satellites; Spectroscopy; Bottom hat transformation; Ground sampling distances; Korea multi-purpose satellites; Learning-based super-resolution; Modification methods; Multispectral images; Qualitative analysis; Superresolution methods; Image enhancement","Deep learning; KOMPSAT-3; Remote sensing; Super-resolution; Top-hat and bottom-hat transformation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85113531497"
"Zhang Q.; Yang G.; Zhang G.","Zhang, Qian (56327323300); Yang, Guang (55716844300); Zhang, Guixu (55803635500)","56327323300; 55716844300; 55803635500","Collaborative Network for Super-Resolution and Semantic Segmentation of Remote Sensing Images","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3099300","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112606904&doi=10.1109%2fTGRS.2021.3099300&partnerID=40&md5=dca6fcac79629b9320b3195e00945acc","In the past few years, multitask learning (MTL) has been widely used in a single model to solve the problems of multiple businesses. MTL enables each task to achieve high performance and greatly reduces computational resource overhead. In this work, we designed a collaborative network that simultaneously solves the super-resolution semantic segmentation and super-resolution image reconstruction. This algorithm can obtain high-resolution semantic segmentation and super-resolution reconstruction results by taking relatively low-resolution images as input when high-resolution data are inconvenient or computing resources are limited. The framework consists of three parts: the semantic segmentation branch (SSB), the super-resolution branch (SRB), and the structural affinity block (SAB). Specifically, the SSB, SRB, and SAB are responsible for completing super-resolution semantic segmentation, image super-resolution reconstruction, and associated features, respectively. Our proposed method is simple and efficient, and it can replace the different branches with most of the state-of-the-art models. The International Society for Photogrammetry and Remote Sensing (ISPRS) segmentation benchmarks were used to evaluate our models. In particular, super-resolution semantic segmentation on the Potsdam dataset reduced Intersection over Union (IoU) by only 1.8% when the resolution of the input image was reduced by a factor of two. The experimental results showed that our framework can obtain more accurate semantic segmentation and super-resolution reconstruction results than the single model. © 1980-2012 IEEE.","Brandenburg [Germany]; Germany; Potsdam; Image reconstruction; Learning systems; Linearization; Optical resolving power; Remote sensing; Semantic Web; Semantics; Collaborative network; Computational resources; Image super-resolution reconstruction; International society; Low resolution images; Structural affinities; Super resolution reconstruction; Super-resolution image reconstruction; algorithm; reconstruction; remote sensing; segmentation; semantic standardization; Image segmentation","Multitask learning (MTL); remote sensing; semantic segmentation; super resolution","Article","Final","","Scopus","2-s2.0-85112606904"
"He L.; Cheng J.; Zhan Z.; Yang W.; Liu P.","He, Lei (56461800200); Cheng, Jiahao (57223434516); Zhan, Zhiyu (57223436716); Yang, Wenbo (57222429576); Liu, Peiran (57223435782)","56461800200; 57223434516; 57223436716; 57222429576; 57223435782","Single image super-resolution reconstruction based on multi-level perceptual residual convolutional network; [多层次感知残差卷积网络的单幅图像超分重建]","2021","Journal of Image and Graphics","26","4","","776","786","10","10.11834/jig.200168","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105867507&doi=10.11834%2fjig.200168&partnerID=40&md5=980e346d437fc7bb4afcb147755226db","Objective: Single image super-resolution reconstruction (SISR) is a classic problem in computer vision. SISR aims to reconstruct one high-resolution image from single or many low-resolution (LR) images. Currently, image super-resolution (SR) technology is widely used in medical imaging, satellite remote sensing, video surveillance, and other fields. However, the SR problem is an essentially complex and morbid problem. To solve this problem, many SISR methods have been proposed, including interpolation-based methods and reconstruction-based methods. Due to large amplification factors, the repair performance will drop sharply, and the reconstructed results are very poor. With the rise of deep learning, deep convolutional neural networks have also been used to solve this problem. Researchers have proposed a series of models and made significant progress. With the gradual understanding of deep learning techniques, researchers have found that deep network brings better results than shallow network, and too deep network can cause gradient explosion or disappearance. In addition, the gradient explosion or disappearance can cause the model to be untrainable and thus unable to achieve the best results through training. In recent years, most networks based on deep learning for single-image SR reconstruction adopt single-scale convolution kernels. Generally, a 3×3 convolution kernel is used for feature extraction. Although single-scale convolution kernels can also extract a lot of detailed information, these algorithms usually ignore the problem of different receptive field sizes caused by different convolution kernel sizes. Receptive fields of different sizes will make the network pay attention to different features; therefore, only using a 3×3 convolution kernel will cause the network to ignore the macroscopic relation between different feature images. Considering these problems, this study proposes a multi-level perception network based on GoogLeNet, residual network, and dense convolutional network. Method: First, the feature extraction module is used as the input, which can extract low-frequency image features. The feature extraction module consists of two 3×3 convolution layers, which is input to multiple densely connected multi-level perception modules. The multi-level perception module is composed of 3×3 and 5×5 convolution kernels. The 3×3 convolution kernel is responsible for extracting detailed feature information, and the 5×5 convolution kernel is responsible for extracting global feature information. Second, the multi-level perception module is divided into shallow multi-level feature extraction, deep multi-level feature extraction, and tandem compression unit. The shallow multi-level feature extraction is composed of 3×3 chain convolution and 5×5 chain convolution. The former is responsible for extracting fine local feature information in shallow features, whereas the latter is responsible for extracting global features in shallow features. The deep multi-level feature extraction is also composed of 3×3 chain convolution and 5×5 chain convolution. The former extracts fine local feature information in deep features, whereas the latter extracts global feature information in deep features. In the tandem compression unit, the global feature information in shallow features, the fine local feature information in deep features, the global information in deep features, and the initial input are concatenated together and then compressed into the same dimension as the input image. In this way, not only low-level and high-level features of the image can be ensured, but also the macro relationship between the features can be guaranteed. Finally, the reconstruction module is used to obtain the final output by combining the upscaling image with the residual image. This study adopts the DIV2K dataset, which consists of 800 high-definition images, and each image has probably 2 million pixels. In order to make full use of these data, the picture is randomly rotated by 90°, 180°, and 270° and horizontally flipped. Result: The reconstructed results are evaluated by using the peak signal-to-noise ratio (PSNR) and structural similarity index and compared with some state-of-the-art SR reconstruction methods. The reconstructed results with 2 scaling factor show that the PSNRs of the proposed algorithm in four benchmark test sets (Set5, Set14, Berkeley Segmentation Dataset(BSD100), and Urban100) are 37.851 1 dB, 33.933 8 dB, 32.219 1 dB, and 32.148 9 dB, respectively, which are all higher than those of the other methods. Conclusion: Compared with other algorithms, the proposed convolutional network model in this study can better take into account the problem of the receptive field and fully extracts different levels of hierarchical features through multi-scale convolution. At the same time, the model uses the structural feature information of the LR image itself to complete the reconstruction, and good reconstructed results can be obtained by using this model. © 2021, Editorial and Publishing Board of Journal of Image and Graphics. All right reserved.","","Convolutional neural network(CNN); Deep learning; Dense connection; DIV2K; Multi-level perception; Residual network; Single image super-resolution(SISR)","Article","Final","","Scopus","2-s2.0-85105867507"
"Mei S.; Zhang B.; Ma M.; Jia S.","Mei, Shaohui (25822578400); Zhang, Bowei (57227930900); Ma, Mingyang (57195938976); Jia, Sen (7202859948)","25822578400; 57227930900; 57195938976; 7202859948","Predicting near-infrared hyperspectral images from visible hyperspectral images; [近红外高光谱图像数据预测技术]","2021","Journal of Image and Graphics","26","8","","1786","1795","9","10.11834/jig.210184","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113298549&doi=10.11834%2fjig.210184&partnerID=40&md5=757b0f618534d92451d47f8ae1236d32","Objective: Hyperspectral remote sensing method is a major development in remote sensing field. It uses a lot of narrow band electromagnetic bands to obtain spectral data. It covers visible, near infrared, middle infrared, and far infrared bands, and its spectral resolution can reach the nanometer level. Therefore, hyperspectral remote sensing can find more surface features and has been widely used in covering global environment, land use, resource survey, natural disasters, and even interstellar exploration. Compared with RGB and multispectral images, hyperspectral images not only can improve the information richness but also can provide more reasonable and effective analysis and processing for the related tasks. As a result, they have important application value in many fields. However, the cost of spectral detection systems is relatively high, especially the optical detector that is used to acquire high spectral data. At present, most of the spectrometers can support the spectral imaging from 400 nm to 1 000 nm, while few of them support that from 1 000 nm to 2 500 nm. The reason is that the spectrometer is harder to produce and more expensive with the increase in spectra. The bands of hyperspectral images have internal relations. The performance of low-spectrum spectrometer can be improved by fully utilizing the low spectra to predict high spectra. In other words, the low spectrum spectrometer can be used to obtain the high spectra that are near the spectra which are usually obtained by high-spectrum spectrometer. The cost of getting hyperspectral images will be greatly reduced. Therefore, high spectra prediction has promising applications and prospects in improving spectrometer performance. Nowadays, a single sensor can generally take a limited number of spectra. Thus, the commonly used spectrometers contain multiple sensors. If one of these sensors suffers from a sudden situation and cannot work normally in the process of flight aerial photography, then the data we can obtain will be unusable and we will have to have a flight again, which will cause cost increase and resource waste. Similarly, if a spectrometer mounted on a satellite fails to work normally in case of emergency, then it will suffer much greater loss. However, if we can fully utilize the low spectra to predict high spectra, which means using the low-spectrum spectrometer to obtain the hyperspectral image that is near the spectra from real high-spectrum spectrometer, the loss caused by these situations can be compensated in a great extent. Method: In recent years, convolutional neural networks (CNNs) have been widely used in various image processing tasks. We propose a hyperspectral image prediction framework based on a CNN as inspired by the great achievements of deep learning in the field of image spatial super resolution. The designed network is based on the residual network, which can fully use multiscale feature maps to obtain better performance and ensure fast convergence. In the CNN, 2D convolution layers use convolution kernels to obtain feature maps, and convolution kernels use relation between space and spectra, which is also helpful to obtain better results. In our network, each of the convolution layers has an activation layer, in which the rectified linear unit function is used. Batch normal layers are used to normalize the feature map, which can improve the feature extracting ability of CNN. Given an input, the proposed network extracts the low-band data features of the hyperspectral image. Then, it uses the extracted features together with the original low-spectra data to predict the high-spectra data for predicting the high spectra with the low spectra. We also design an evaluation system to prove the feasibility and effectiveness of the infrared spectrum prediction. The feasibility is evaluated by three classical image quality evaluation indices (peak signal-to-noise ratio (PSNR), structural similarity (SSIM), and spectral angle (SA)). The feasibility is also evaluated by two classical classification evaluation indices (accuracy and average accuracy) by applying our predicted infrared spectrum to classification tasks. Result: Experiments on Cuprite and Salinas datasets are conducted to validate the effectiveness of the proposed method. On Cuprite dataset, we directly measure the quality of the predicted image through PSNR, SSIM, and SA. On Salinas dataset, we mainly use the predicted image data for classification tasks with support vector machine (SVM) and LeNet. All the experiments are implemented using Torch 1.3 platform with Python 3.7. In our experiments on Cuprite dataset, we use the spectra of the first two sensors to predict the spectra of the third sensor. Five hyperspectral images are present in the original data of Cuprite. The first three spectra of Cuprite are spliced into a large image as the training dataset, and the last two spectra are spliced as the test dataset. In this experiment, 30 training epochs are conducted. The PSNR, SSIM, and SA of the predicted images by the trained network on the test set are 40.145 dB, 0.996, and 0.777 rad, respectively, which indicates that the proposed method can predict high spectra from low spectra, which is near the ground truth. The PSNR, SSIM, and SA on the Salinas dataset are 39.55 dB, 0.997, and 1.78 rad, respectively. The accuracy and average accuracy of SVM and LeNet by using the predicted high-spectra data for classification are both improved by approximately 1% compared with the results which use only low-spectra data. Conclusion: Although many CNN methods have been proposed to realize spatial super resolution, few of them realize spectral super resolution, which is also important. Therefore, we propose the new application in remote sensing field called spectrum prediction, which uses a CNN to predict high spectra from low spectra. The proposed method can expand the use efficiency of sensor chips and also help deal with spectrometer failure and improve the quality of spectral data. © 2021, Editorial Office of Journal of Image and Graphics. All right reserved.","","Convolutional neural network(CNN); Deep learning; Hyperspectral classification; Hyperspectral image; Spectrum prediction","Article","Final","","Scopus","2-s2.0-85113298549"
"Zhu Y.; Geiß C.; So E.","Zhu, Yue (57212228519); Geiß, Christian (39862777100); So, Emily (24377128400)","57212228519; 39862777100; 24377128400","Image super-resolution with dense-sampling residual channel-spatial attention networks for multi-temporal remote sensing image classification","2021","International Journal of Applied Earth Observation and Geoinformation","104","","102543","","","","10.1016/j.jag.2021.102543","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121645574&doi=10.1016%2fj.jag.2021.102543&partnerID=40&md5=bcd843b753add4cad96e91bbc9768ba7","Image super-resolution (SR) techniques can benefit a wide range of applications in the remote sensing (RS) community, including image classification. This issue is particularly relevant for image classification on time series data, considering RS datasets that feature long temporal coverage generally have a limited spatial resolution. Recent advances in deep learning brought new opportunities for enhancing the spatial resolution of historic RS data. Numerous convolutional neural network (CNN)-based methods showed superior performance in terms of developing efficient end-to-end SR models for natural images. However, such models were rarely exploited for promoting image classification based on multispectral RS data. This paper proposes a novel CNN-based framework to enhance the spatial resolution of time series multispectral RS images. Thereby, the proposed SR model employs Residual Channel Attention Networks (RCAN) as a backbone structure, whereas based on this structure the proposed models uniquely integrate tailored channel-spatial attention and dense-sampling mechanisms for performance improvement. Subsequently, state-of-the-art CNN-based classifiers are incorporated to produce classification maps based on the enhanced time series data. The experiments proved that the proposed SR model can enable unambiguously better performance compared to RCAN and other (deep learning-based) SR techniques, especially in a domain adaptation context, i.e., leveraging Sentinel-2 images for generating SR Landsat images. Furthermore, the experimental results confirmed that the enhanced multi-temporal RS images can bring substantial improvement on fine-grained multi-temporal land use classification. © 2021","artificial neural network; image classification; image resolution; land use; remote sensing; sampling; spatial resolution; time series","Attention mechanism; Convolutional neural networks; Dense connection; Image super-resolution; Multi-temporal land use classification","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85121645574"
"Jiang W.; Zhao L.; Wang Y.; Liu W.; Liu B.","Jiang, Wenzong (57275223800); Zhao, Lifei (57274635800); Wang, Yanjiang (57223714000); Liu, Weifeng (36739405100); Liu, Baodi (16319146900)","57275223800; 57274635800; 57223714000; 36739405100; 16319146900","Cross-dimension attention guided self-supervised remote sensing single-image super-resolution","2021","Remote Sensing","13","19","3835","","","","10.3390/rs13193835","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115871882&doi=10.3390%2frs13193835&partnerID=40&md5=7920da7dc021f6239b505d3e6442ba25","In recent years, the application of deep learning has achieved a huge leap in the performance of remote sensing image super-resolution (SR). However, most of the existing SR methods employ bicubic downsampling of high-resolution (HR) images to obtain low-resolution (LR) images and use the obtained LR and HR images as training pairs. This supervised method that uses ideal kernel (bicubic) downsampled images to train the network will significantly degrade performance when used in realistic LR remote sensing images, usually resulting in blurry images. The main reason is that the degradation process of real remote sensing images is more complicated. The training data cannot reflect the SR problem of real remote sensing images. Inspired by the self-supervised methods, this paper proposes a cross-dimension attention guided self-supervised remote sensing single-image super-resolution method (CASSISR). It does not require pre-training on a dataset, only utilizes the internal information reproducibility of a single image, and uses the lower-resolution image downsampled from the input image to train the cross-dimension attention network (CDAN). The cross-dimension attention module (CDAM) selectively captures more useful internal duplicate information by modeling the interdependence of channel and spatial features and jointly learning their weights. The proposed CASSISR adapts well to real remote sensing image SR tasks. A large number of experiments show that CASSISR has achieved superior performance to current state-of-the-art methods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Optical resolving power; Supervised learning; Attention module; High-resolution images; Image super resolutions; Low resolution images; Performance; Remote sensing images; Remote-sensing; Self-supervised; Single images; Superresolution methods; Remote sensing","Attention module; Image super-resolution; Remote sensing image; Self-supervised","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85115871882"
"Peng Y.; Wang X.; Zhang J.; Liu S.","Peng, Yali (14042266200); Wang, Xuning (57222261571); Zhang, Junwei (57219419351); Liu, Shigang (26663071300)","14042266200; 57222261571; 57219419351; 26663071300","Pre-training of gated convolution neural network for remote sensing image super-resolution","2021","IET Image Processing","15","5","","1179","1188","9","10.1049/ipr2.12096","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102046156&doi=10.1049%2fipr2.12096&partnerID=40&md5=38ef4e99ffc0dca809e234e440840a12","Many very deep neural networks are proposed to obtain accurate super-resolution reconstruction of remote sensing images. However, the deeper the network for image SR is, the more difficult it is to train. The low-resolution inputs and features contain abundant low-frequency information and noise, which are treated equally as the high-frequency information to across the network. To solve these problems, a novel single-image super-resolution algorithm named pre-training of gated convolution neural network (PGCNN) is proposed for remote sensing images. The proposed PGCNN consists of several residual blocks with long skip connections. Each residual block contains an additional well-designed gated convolution unit, which provides different weights to high-frequency information and low-frequency information to control the transmission of information, making the main network focus on learning high-frequency information. Compared with several state-of-the-art methods, experimental results on the remote sensing datasets (SIRI-WHU, NWPU-RESISC45, RSSCN7 and UC-Merced-Land-Use) show that the proposed PGCNN has the accuracy and visual improvements. © 2021 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology","Convolution; Deep neural networks; Land use; Optical resolving power; Remote sensing; Convolution neural network; High-frequency informations; Low resolution; Remote sensing images; Single images; State-of-the-art methods; Super resolution reconstruction; Visual improvements; Neural networks","","Article","Final","","Scopus","2-s2.0-85102046156"
"Kang X.; Li J.; Duan P.; Ma F.; Li S.","Kang, Xudong (47061561600); Li, Jier (57826229200); Duan, Puhong (57188576823); Ma, Fuyan (57222245204); Li, Shutao (7409240361)","47061561600; 57826229200; 57188576823; 57222245204; 7409240361","Multilayer Degradation Representation-Guided Blind Super-Resolution for Remote Sensing Images","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5534612","","","","10.1109/TGRS.2022.3192680","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135217045&doi=10.1109%2fTGRS.2022.3192680&partnerID=40&md5=4250540cb3bea9eb77b45a279cfd355c","Remote sensing image super-resolution (SR) aims to boost the image resolution while recovering rich high-frequency details. Currently, most of the SR methods are based on an assumption that the degradation kernel is a specific downsampler. However, the degradation kernel is unknown and sophisticated for real remote sensing scenes, leading to a severe performance drop. To alleviate this problem, we propose a multilayer degradation representation-guided blind SR method for remote sensing images, which mainly consists of three key steps. First, an unsupervised representation learning is exploited to learn the degradation representation from low-resolution images. Then, a degradation-guided deep residual module is designed to model high-order features across different scales from the original images. Finally, a multilayer degradation-aware feature fusion mechanism is proposed to restore the finer details. Experiments on synthetic and real datasets demonstrate that the proposed method can achieve promising performance with respect to other state-of-the-art SR approaches.  © 1980-2012 IEEE.","Computer vision; Extraction; Image reconstruction; Image representation; Image resolution; Remote sensing; Blind Super-resolution; Degradation-guided feature extraction; Features extraction; Features fusions; Images reconstruction; Kernel; Multi-layer feature fusion; Multi-layers; Remote sensing images; Remote-sensing; Representation learning; Superresolution; data set; degradation; learning; remote sensing; Feature extraction","Blind super-resolution (SR); degradation-guided feature extraction; multilayer feature fusion; remote sensing image; representation learning","Article","Final","","Scopus","2-s2.0-85135217045"
"Chen W.; Zheng X.; Lu X.","Chen, Wenjing (57219550574); Zheng, Xiangtao (56022876500); Lu, Xiaoqiang (35180125200)","57219550574; 56022876500; 35180125200","Semisupervised Spectral Degradation Constrained Network for Spectral Super-Resolution","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2021.3079961","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107232939&doi=10.1109%2fLGRS.2021.3079961&partnerID=40&md5=b5ad0548b3b207764c1bf1d8c412e843","Recently, various deep learning-based methods have been designed to improve the spectral resolution of the multispectral image (MSI) to obtain the hyperspectral image (HSI). These methods usually rely on sufficient MSI/HSI pairs for supervised training. However, collecting plentiful HSIs is time-consuming. In this letter, a semisupervised spectral degradation constrained network (SSDCN) is proposed to improve the spectral resolution of MSI. SSDCN is an autoencoder-like network that is composed of an encoder subnetwork for estimating HSI from input MSI and a decoder subnetwork for reconstructing MSI from the estimated HSI. A semisupervised training method is proposed to explore both MSI/HSI pairs and MSIs without ground-truth HSIs to optimize SSDCN. Simulated and two real databases are employed to demonstrate the effectiveness of SSDCN.  © 2004-2012 IEEE.","Deep learning; Image enhancement; Spectral resolution; Spectroscopy; Auto encoders; Learning-based methods; Multispectral images; Real database; Semi-supervised; Semi-supervised trainings; Super resolution; Supervised trainings; accuracy assessment; image analysis; remote sensing; satellite data; spectral analysis; Learning systems","Deep learning; hyperspectral image (HSI); multispectral image (MSI); semisupervised training; spectral degradation; spectral super-resolution","Article","Final","","Scopus","2-s2.0-85107232939"
"Wang Y.; Dong J.; Wang B.; Khanna S.; Singh A.; Hussain S.A.","Wang, Yani (57767137700); Dong, Jinfang (57711287600); Wang, Bo (57836521800); Khanna, Shaweta (57710777500); Singh, Anupam (57211625912); Hussain, Syed Abid (57670505400)","57767137700; 57711287600; 57836521800; 57710777500; 57211625912; 57670505400","Superresolution Reconstruction Method of Software Remote Sensing Image Based on Convolutional Neural Network","2022","Journal of Sensors","2022","","1777112","","","","10.1155/2022/1777112","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130762740&doi=10.1155%2f2022%2f1777112&partnerID=40&md5=ae3bf16f1f47561163be46aa2f1c50d3","In order to solve the problem of long training time for remote sensing image super-resolution reconstruction algorithm, a method for remote sensing image superresolution reconstruction based on convolutional neural network is proposed, which combines dense convolutional network, parallel CNN structure, and subpixel convolution. The features of low-resolution images are extracted using dense convolutional networks, parallel CNNs are used to reduce network parameters, and subpixel convolutions are used to complete feature reconstruction. The results show that the final PSNR value of the black curve with the number of iterations of the three methods in the training process is the highest 27.3, followed by the middle curve, and the worst curve is 27.0. It is proved that the method extracts more features, retains more image details, and improves the reconstruction effect of the image; it greatly reduces the parameters in the network and avoids the phenomenon of overfitting in the deep network. © 2022 Yani Wang et al.","Convolutional neural networks; Image enhancement; Image reconstruction; Optical resolving power; Pixels; Remote sensing; Convolutional networks; Convolutional neural network; Image super-resolution reconstruction; Image-based; Reconstruction algorithms; Reconstruction method; Remote sensing images; Sub-pixels; Super-resolution reconstruction; Training time; Convolution","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85130762740"
"Morimoto H.; Kidera S.","Morimoto, Hayatomomaru (57211640264); Kidera, Shouhei (14031687600)","57211640264; 14031687600","Super-Resolution Multilayer Structure Analysis via Depth Adaptive Compressed Sensing for Terahertz Subsurface Imaging","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2020.3043481","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098767272&doi=10.1109%2fLGRS.2020.3043481&partnerID=40&md5=5a2bd3795e2b32f3668eb27684e78ebd","Super-resolution subsurface imaging based on sparse regularization is presented in assuming the terahertz (THz) band multilayer structure analysis. The THz wave subsurface imaging with $\mu $ -scale spatial resolution and penetration depth are promising for several applications, such as nondestructive testing and chemical/biomedical compound analyses. The sparse regularization-based compressed sensing (CS) approach has considerable potential to provide super-resolution subsurface imaging in a time-of-flight estimation. However, using optical lens-based measurements, e.g., THz time-domain spectroscopic (THz-TDS) systems, a depth resolution is highly dependent on the depth of each layer, which becomes more critical in the out-of-focus case. This study demonstrated that the above depth-dependence could be solved by using an appropriate depth-dependent reference signal, by using the THz-TDS measured data.  © 2004-2012 IEEE.","Chemical analysis; Compressed sensing; Laser pulses; Lenses; Multilayers; Nondestructive examination; Optical resolving power; Time domain analysis; Compressive sensing; Depth resolution; Multilayer structures; Reference signals; Sparse regularizations; Spatial resolution; Sub-surface imaging; Time of flight estimation; imaging method; remote sensing; satellite imagery; spectral resolution; Terahertz waves","Compressed sensing (CS); multilayer structure analysis; super-resolution depth imaging; terahertz time-domain spectroscopic (THz-TDS) system","Article","Final","","Scopus","2-s2.0-85098767272"
"Meng L.; Yan C.; Zhuang W.; Zhang W.; Geng X.; Yan X.-H.","Meng, Lingsheng (57208481382); Yan, Chi (57199153732); Zhuang, Wei (24823152200); Zhang, Weiwei (56457126700); Geng, Xupu (57216523547); Yan, Xiao-Hai (34972376600)","57208481382; 57199153732; 24823152200; 56457126700; 57216523547; 34972376600","Reconstructing High-Resolution Ocean Subsurface and Interior Temperature and Salinity Anomalies from Satellite Observations","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3109979","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115708320&doi=10.1109%2fTGRS.2021.3109979&partnerID=40&md5=b2ef795e4942b2d48afa8bda087dcf1f","Accurately retrieving ocean interior parameters from remote sensing observations is essential for ocean and climate studies because direct observations are sparse and costly. Furthermore, high-resolution structure of seawater properties is critical for understanding the oceanic processes and changes on multiple scales. Here, we designed a new method based on a deep neural network to retrieve subsurface temperature anomaly (STA) and subsurface salinity anomaly (SSA) in the Pacific Ocean at high (1/4°) and super (1/12°) horizontal resolution. We utilized multisource satellite-observed sea surface data (e.g., sea level, temperature, salinity, and wind vector) as inputs. The results revealed that our model retrieved the high- and super-resolution STA/SSA with high accuracy, and the model was reliable in a wide range of depths (near surface to 4000 m) and times (all months in 2014). Regarding the high-resolution STA (SSA) estimation, the average coefficient of determination ( R2 ) was 0.984 (0.966), and the average root-mean-squared error (RMSE) was 0.068 °C (0.016 psu). For the super-resolution STA, the average R2 was 0.988 and RMSE was 0.093 °C. Here, we established an effective technique that improved the resolution and accuracy of estimating the ocean interior parameters from satellite observation. The new technique provides some new insights into oceanic observation and dynamics.  © 1980-2012 IEEE.","Pacific Ocean; Deep neural networks; Mean square error; Optical resolving power; Remote sensing; Satellites; Sea level; Surface treatment; Surface waters; Deep learning; High resolution; Ocean salinity; Ocean temperature; Parameters estimation; Remote sensing.; Remote-sensing; Salinity (geophysical); Sea surfaces; Spatial resolution; remote sensing; resolution; salinity; satellite data; seawater; temperature profile; Parameter estimation","Deep learning; High resolution; Ocean temperature and salinity; Parameter estimation; Remote sensing","Article","Final","","Scopus","2-s2.0-85115708320"
"Feng X.; Zhang W.; Su X.; Xu Z.","Feng, Xubin (57201876230); Zhang, Wuxia (54390588100); Su, Xiuqin (18438569800); Xu, Zhengpu (57217677334)","57201876230; 54390588100; 18438569800; 57217677334","Optical remote sensing image denoising and super-resolution reconstructing using optimized generative network in wavelet transform domain","2021","Remote Sensing","13","9","1858","","","","10.3390/rs13091858","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106526544&doi=10.3390%2frs13091858&partnerID=40&md5=e89da686618affee80112bc1b00efb5f","High spatial quality (HQ) optical remote sensing images are very useful for target detection, target recognition and image classification. Due to the influence of imaging equipment accuracy and atmospheric environment, HQ images are difficult to acquire, while low spatial quality (LQ) remote sensing images are very easy to acquire. Hence, denoising and super-resolution (SR) reconstruction technology are the most important solutions to improve the quality of remote sensing images very effectively, which can lower the cost as much as possible. Most existing methods usually only employ denoising or SR technology to obtain HQ images. However, due to the complex structure and the large noise of remote sensing images, the quality of the remote sensing image obtained only by denoising method or SR method cannot meet the actual needs. To address these problems, a method of reconstructing HQ remote sensing images based on Generative Adversarial Network (GAN) named “Restoration Generative Adversarial Network with ResNet and DenseNet” (RRDGAN) is proposed, which can acquire better quality images by incorporating denoising and SR into a unified framework. The generative network is implemented by fusing Residual Neural Network (ResNet) and Dense Convolutional Network (DenseNet) in order to consider denoising and SR problems at the same time. Then, total variation (TV) regularization is used to furthermore enhance the edge details, and the idea of Relativistic GAN is explored to make the whole network converge better. Our RRDGAN is implemented in wavelet transform (WT) domain, since different frequency parts could be handled separately in the wavelet domain. The experimental results on three different remote sensing datasets shows the feasibility of our proposed method in acquiring remote sensing images. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural networks; Image acquisition; Image denoising; Image enhancement; Image reconstruction; Optical resolving power; Wavelet transforms; Adversarial networks; Atmospheric environment; Convolutional networks; Optical remote sensing; Remote sensing images; Super resolution reconstruction; Total variation regularization; Wavelet-transform domain; Remote sensing","Denoising; Densely connection network (DenseNet); Generative adversarial network (GAN); Relativistic; Remote sensing; Residual network (ResNet); Super-resolution; Total variation (TV); Wavelet transform (WT)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85106526544"
"Yu L.; Du Z.; Dong R.; Zheng J.; Tu Y.; Chen X.; Hao P.; Zhong B.; Peng D.; Zhao J.; Li X.; Yang J.; Fu H.; Yang G.; Gong P.","Yu, Le (55277716700); Du, Zhenrong (57188842171); Dong, Runmin (57205415789); Zheng, Juepeng (57783520300); Tu, Ying (57212584870); Chen, Xin (57200816094); Hao, Pengyu (55553753600); Zhong, Bo (57205877879); Peng, Dailiang (17342419500); Zhao, Jiyao (57202588935); Li, Xiyu (57235216100); Yang, Jianyu (57056765100); Fu, Haohuan (8713118400); Yang, Guangwen (8684892000); Gong, Peng (57211236643)","55277716700; 57188842171; 57205415789; 57783520300; 57212584870; 57200816094; 55553753600; 57205877879; 17342419500; 57202588935; 57235216100; 57056765100; 8713118400; 8684892000; 57211236643","FROM-GLC Plus: toward near real-time and multi-resolution land cover mapping","2022","GIScience and Remote Sensing","59","1","","1026","1047","21","10.1080/15481603.2022.2096184","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133529185&doi=10.1080%2f15481603.2022.2096184&partnerID=40&md5=1b98707f90420bc3e770a3dfb5b20be4","Global land cover has undergone extensive and rapid changes as a result of human activities and climate change. These changes have had a significant impact on biodiversity, the surface energy balance, and sustainable development. Global land cover data underpins research on the development of earth system models, resource management, and evaluation of the ecological environment. However, there are limitations in the classification detail, spatial resolution, and rapid change monitoring capability of global land cover change data. Building on the earlier Global Land Cover Mapping (Finer Resolution Observation and Monitoring–Global Land Cover, FROM-GLC), we developed the improved Global Land Cover Change Monitoring Platform (FROM-GLC Plus) using methods such as multi-season sample space-time migration, multi-source data time series reconstruction, and machine learning. The FROM-GLC Plus system provides a capacity for producing global land cover change data set from the 1980s with flexibility in spatio–temporal details. The preliminary results show that FROM-GLC Plus provides a framework for near real-time land cover mapping at multi-temporal (annual to daily) and multi-resolution (30 m to sub-meter) levels. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","image classification; image resolution; land cover; machine learning; mapping method; real time; remote sensing; spatial resolution; spatiotemporal analysis","data fusion; land cover mapping; machine learning; Remote sensing; sample migration; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85133529185"
"Tu J.; Mei G.; Ma Z.; Piccialli F.","Tu, Jingzhi (57217008206); Mei, Gang (57806891200); Ma, Zhengjing (57219977775); Piccialli, Francesco (42762051900)","57217008206; 57806891200; 57219977775; 42762051900","SWCGAN: Generative Adversarial Network Combining Swin Transformer and CNN for Remote Sensing Image Super-Resolution","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","5662","5673","11","10.1109/JSTARS.2022.3190322","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134297666&doi=10.1109%2fJSTARS.2022.3190322&partnerID=40&md5=7c6271eb172cba28091080f8603bf88a","Easy and efficient acquisition of high-resolution remote sensing images is of importance in geographic information systems. Previously, deep neural networks composed of convolutional layers have achieved impressive progress in super-resolution reconstruction. However, the inherent problems of the convolutional layer, including the difficulty of modeling the long-range dependency, limit the performance of these networks on super-resolution reconstruction. To address the abovementioned problems, we propose a generative adversarial network (GAN) by combining the advantages of the swin transformer and convolutional layers, called SWCGAN. It is different from the previous super-resolution models, which are composed of pure convolutional blocks. The essential idea behind the proposed method is to generate high-resolution images by a generator network with a hybrid of convolutional and swin transformer layers and then to use a pure swin transformer discriminator network for adversarial training. In the proposed method, first, we employ a convolutional layer for shallow feature extraction that can be adapted to flexible input sizes; second, we further propose the residual dense swin transformer block to extract deep features for upsampling to generate high-resolution images; and third, we use a simplified swin transformer as the discriminator for adversarial training. To evaluate the performance of the proposed method, we compare the proposed method with other state-of-the-art methods by utilizing the UCMerced benchmark dataset, and we apply the proposed method to real-world remote sensing images. The results demonstrate that the reconstruction performance of the proposed method outperforms other state-of-the-art methods in most metrics.  © 2008-2012 IEEE.","Benchmarking; Convolution; Deep neural networks; Image reconstruction; Optical resolving power; Remote sensing; Convolutional layer; Generative adversarial network; High-resolution images; High-resolution remote sensing images; Image super resolutions; Performance; Remote sensing images; State-of-the-art methods; Super-resolution reconstruction; Swin transformer; input-output analysis; numerical model; remote sensing; sampling; satellite data; satellite imagery; spatial resolution; Generative adversarial networks","Convolutional layers; generative adversarial network (GAN); remote sensing images; super-resolution reconstruction; swin transformer","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85134297666"
"Yang X.; Xie T.; Guo Y.; Zhou D.","Yang, Xin (57218080522); Xie, Tangxin (57215970468); Guo, Yingqing (57219564706); Zhou, Dake (56430227300)","57218080522; 57215970468; 57219564706; 56430227300","Remote sensing image super-resolution based on convolutional blind denoising adaptive dense connection","2021","IET Image Processing","15","11","","2508","2520","12","10.1049/ipr2.12236","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105969764&doi=10.1049%2fipr2.12236&partnerID=40&md5=81604592e63b9a15a5d0606381dc5c2b","The current super-resolution (SR) deep network is mainly applied to the common image and pays little attention to the image with noise. The remote sensing image contains much noise, so that the SR reconstruction effect is not satisfactory. Therefore, a convolution blind denoising adaptive dense connection SR (CBD-ADCSR) network for the remote sensing image is proposed in this paper. The whole model is divided into a convolution blind denoising (CBD) network for denoising and an ADCSR network for reconstruction. Firstly, the components of the network are given in detail and are analysed. Secondly, a data set making method is designed combining motion blur, defocusing blur and Gaussian noise, which is used to generate low-resolution image data sets with complex degradation for the model training. Finally, through the detailed comparative experiment, it is proved that the reconstruction effect of the CBD-ADCSR model is better than that of the most state-of-the-art algorithms in objective criteria. In addition, compared with the original ADCSR network, CBD-ADCSR has a stronger ability for noise suppression. © 2021 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology","Convolution; Gaussian noise (electronic); Image reconstruction; Optical resolving power; Blind denoising; Comparative experiments; Low resolution images; Noise suppression; Objective criteria; Remote sensing images; State-of-the-art algorithms; Super resolution; Remote sensing","","Article","Final","","Scopus","2-s2.0-85105969764"
"Zheng X.; Chen W.; Lu X.","Zheng, Xiangtao (56022876500); Chen, Wenjing (57219550574); Lu, Xiaoqiang (35180125200)","56022876500; 57219550574; 35180125200","Spectral Super-Resolution of Multispectral Images Using Spatial–Spectral Residual Attention Network","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3104476","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113346190&doi=10.1109%2fTGRS.2021.3104476&partnerID=40&md5=da9ce9598694f6c1a8aa307624be3699","The spectral super-resolution of multispectral image (MSI) refers to improving the spectral resolution of the MSI to obtain the hyperspectral image (HSI). Most recent works are based on the sparse representation to unfold the MSI into the 2-D matrix in advance for subsequent operations, which results in that the spatial information of MSI cannot be fully explored. In this article, a spatial–spectral residual attention network (SSRAN) is proposed to simultaneously explore the spatial and spectral information of MSI for reconstructing the HSI. The proposed SSRAN is composed of the feature extraction part, the nonlinear mapping part, and the reconstruction part. Firstly, the multispectral features of the input MSI are extracted in the feature extraction part. Second, in the nonlinear mapping part, the spatial–spectral residual blocks are proposed to explore spatial and spectral information of MSI for mapping the multispectral features to the hyperspectral features. Finally, in the reconstruction part, a 2-D convolution is used to reconstruct the HSI from the hyperspectral features. Also, a neighboring spectral attention module is specially designed to explicitly constrain the reconstructed HSI to maintain the correlation among neighboring spectral bands. The proposed SSRAN outperforms the state-of-the-art methods on both simulated and real databases. © 2021 IEEE.","Extraction; Feature extraction; Image enhancement; Optical resolving power; Spectroscopy; 2-D convolution; Multispectral images; Nonlinear mappings; Sparse representation; Spatial informations; Spectral information; State-of-the-art methods; Super resolution; correlation; image analysis; mapping; multispectral image; reconstruction; remote sensing; spatial analysis; spectral resolution; Photomapping","Convolution; Dictionaries; Feature extraction; Hyperspectral imaging; Image reconstruction; Superresolution; Task analysis","Article","Final","","Scopus","2-s2.0-85113346190"
"Chen S.; Liu X.; Meng S.","Chen, Siqi (57870097500); Liu, Xiao (57219490472); Meng, Shilong (57869951700)","57870097500; 57219490472; 57869951700","Generative Adversarial Network-Based Methods in Super Resolution","2022","ISCTT 2021 - 6th International Conference on Information Science, Computer Technology and Transportation","","","","375","381","6","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137114222&partnerID=40&md5=e1c785d61b87b993ae88d4ff346fa2c1","Super-resolution (SR) is a crucial image processing technique to optimize the resolution of images and videos. Recent years have witnessed significant development of SR approaches using Generative Adversarial Nets (GAN). Herein, a thorough overview on the latest achievements of SR approaches using GAN are given. Specifically, we firstly define the SR problem. Then, we introduce traditional and deep-learning (DL)-based SR techniques including Convolutional Neural Network (CNN) and GAN methods. Afterward, we explore the background of GAN and pay special attention to GAN-based approaches such as SRGAN, GMGAN, and Cycle-GAN. In addition, we also cover the applications of GAN-based SR approaches in real life, including medical diagnosis and remote sensing. © VDE VERLAG GMBH · Berlin · Offenbach.","Deep learning; Diagnosis; Image processing; Neural networks; Optical resolving power; Remote sensing; Convolutional neural network; Image processing technique; Learning-based super-resolution; Network-based; Remote-sensing; Resolution techniques; Superresolution; Generative adversarial networks","","Conference paper","Final","","Scopus","2-s2.0-85137114222"
"Li J.-X.; Zhao Y.-X.; Wang J.-H.","Li, Jia-Xing (57300081400); Zhao, Yong-Xian (57351688300); Wang, Jing-Hua (57200017263)","57300081400; 57351688300; 57200017263","A Review of Single Image Super-resolution Reconstruction Algorithms Based on Deep Learning; [基于深度学习的单幅图像超分辨率重建算法综述]","2021","Zidonghua Xuebao/Acta Automatica Sinica","47","10","","2341","2363","22","10.16383/j.aas.c190859","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119890166&doi=10.16383%2fj.aas.c190859&partnerID=40&md5=ce6e115b8264ac7fb4c39784154bcb29","Single image super-resolution (SISR) reconstruction is an important problem in the field of computer vision. It has important research significance and application value in security video surveillance, aircraft aerial photography and satellite remote sensing. In recent years, deep learning has made a breakthrough in many fields such as image classification, detection and recognition, and promoted the development of image super-resolution reconstruction technology. This paper first introduces the common public image datasets for single image super-resolution reconstruction. Then, the innovation and progress of single image super-resolution reconstruction based on deep learning are emphasized. Finally, the difficulties and challenges in the single image super-resolution reconstruction are discussed, and the future development trend is discussed. Copyright © 2021 Acta Automatica Sinica. All rights reserved.","Aerial photography; Antennas; Deep neural networks; Image reconstruction; Optical resolving power; Remote sensing; Security systems; Deep learning; Image super resolutions; Neural-networks; Reconstruction algorithms; Research applications; Research significances; Security video; Single image super-resolution; Single images; Single-image super-resolution reconstruction; Computer vision","Computer vision; Deep learning; Neural network; Single image super-resolution (SISR)","Review","Final","","Scopus","2-s2.0-85119890166"
"Wan Z.; Zhang Q.; Zhang G.","Wan, Zhechun (57726369800); Zhang, Qian (56327323300); Zhang, Guixu (55803635500)","57726369800; 56327323300; 55803635500","Low-Level Feature Enhancement Network for Semantic Segmentation of Buildings","2022","IEEE Geoscience and Remote Sensing Letters","19","","6510205","","","","10.1109/LGRS.2022.3173626","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131275276&doi=10.1109%2fLGRS.2022.3173626&partnerID=40&md5=3c696495ce1712eb4179bed34a229254","In recent years, convolutional neural networks (CNNs) have been widely used in extracting buildings from remote sensing images. Both semantic representation and spatial location details are crucial for this task. We propose the methods to enhance the performance of semantic segmentation by using these low-level features considering that man-made buildings in aerial images have strong textures and edges. Texture Enhancement Attention Module (TEAM) is proposed to strengthen feature in the position with rich texture and improve the semantic representation. Edge Extraction Module (EEM) is applied for directly guiding spatial details learning, which starts with super-resolution maps created by Super-Resolution Module (SRM). Detail Supplement Module (DSM) is designed to further provide the details for decoder. On this basis, we propose a low-level feature enhancement network (LFENet) for semantic segmentation of buildings. Experimental results on two aerial datasets show that our works greatly improve the accuracy over the baseline and other models.  © 2004-2012 IEEE.","Antennas; Buildings; Convolution; Edge detection; Extraction; Feature extraction; Image enhancement; Image texture; Neural networks; Optical resolving power; Remote sensing; Semantic Segmentation; Building extraction; Convolutional neural network; Correlation; Edge; Feature enhancement; Features extraction; Image edge detection; Low-level features; Semantic segmentation; Superresolution; artificial neural network; network analysis; satellite imagery; texture; Semantics","Building extraction; convolutional neural networks (CNNs); edge; semantic segmentation; texture","Article","Final","","Scopus","2-s2.0-85131275276"
"Li Y.; Song J.; Lu W.; Monkam P.; Ao Y.","Li, Yinshuo (57220091486); Song, Jianyong (55542116300); Lu, Wenkai (7404214627); Monkam, Patrice (57196191821); Ao, Yile (57203097796)","57220091486; 55542116300; 7404214627; 57196191821; 57203097796","Super-Resolution of Seismic Velocity Model Guided by Seismic Data","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3075622","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105864265&doi=10.1109%2fTGRS.2021.3075622&partnerID=40&md5=35cccdd5d96ce3e11ed2bdcdf4eca4f8","Recently, a multitask learning framework named M: multitask, R: global residual skip connection structure, U: encoder-decoder structure of U-Net, D: dense skip connection structure, and SR: super-resolution (M-RUDSR) has successfully improved the accuracy of full-waveform inversion (FWI) results by enhancing the resolution of the seismic velocity model. However, M-RUDSR does not make full use of seismic data even though it contains high wavenumber information, which can help enhance the resolution of the velocity model. Moreover, the effects of employing seismic data realized by simply increasing the model's input and output channels are limited since the seismic velocity model and seismic data are in different frequency bands. Therefore, we propose to consider super-resolution (SR) of seismic data and its edge images as supplementary auxiliary tasks of the seismic velocity model SR. Besides, the proposed method named M-RUDSRv2 improves the resolution of the seismic velocity model leveraging a three-step learning strategy. First, the model in M-RUDSRv2 is trained preliminarily on the specific data where the seismic velocity model and seismic data are in the same blurring levels. Then, the pretrained model is fine-tuned on the extensive data, where the seismic velocity model and seismic data are in various kinds of blurring levels, to achieve strong generalization ability. Finally, the fitted model focuses on improving the resolution of the seismic velocity model by adjusting the parameters in the loss function. Comparative experiments on synthetic and field data validate the superior performance of M-RUDSRv2 compared with M-RUDSR in SR of the seismic velocity model.  © 1980-2012 IEEE.","Geophysical prospecting; Optical resolving power; Seismic response; Seismic waves; Velocity; Comparative experiments; Connection structures; Different frequency; Full-waveform inversion; Generalization ability; Input and outputs; Seismic velocity models; Three-step learning; accuracy assessment; image analysis; remote sensing; satellite data; seismic velocity; Learning systems","Deep learning; multitask learning (MTL); seismic data; seismic velocity model; super-resolution","Article","Final","","Scopus","2-s2.0-85105864265"
"","","","12th IFIP TC 12 International Conference on Intelligent Information Processing, IIP 2022","2022","IFIP Advances in Information and Communication Technology","643 IFIP","","","","","548","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132016256&partnerID=40&md5=745a66aeb0f9052a07ef3856ed5aaaec","The proceedings contain 43 papers. The special focus in this conference is on Intelligent Information Processing. The topics include: A Game-Theoretic Analysis of Impulse Purchase; research on Blockchain Privacy Protection Mechanism in Financial Transaction Services Based on Zero-Knowledge Proof and Federal Learning; a Hybrid Parallel Algorithm With Multiple Improved Strategies; resource Scheduling for Human-Machine Collaboration in Multiagent Systems; pre-loaded Deep-Q Learning; using Multi-level Attention Based on Concept Embedding Enrichen Short Text to Classification; does Large Pretrained Dataset Always Help? On the Effect of Dataset Size on Big Transfer Model; augmenting Context Representation with Triggers Knowledge for Relation Extraction; high-Resolution Remote Sensing Image Semantic Segmentation Method Based on Improved Encoder-Decoder Convolutional Neural Network; preface; classification Between Rumors and Explanations of Rumors Based on Common and Difference Subsequences of Sentences; augmenting Convolution Neural Networks by Utilizing Attention Mechanism for Knowledge Tracing; a Hybrid Multi-objective Optimization Algorithm with Improved Neighborhood Rough Sets for Feature Selection; predicting Student Performance in Online Learning Using a Highly Efficient Gradient Boosting Decision Tree; A Method for AGV Double-Cycling Scheduling at Automated Container Terminals; inductive Light Graph Convolution Network for Text Classification Based on Word-Label Graph; super-Resolution of Defocus Thread Image Based on Cycle Generative Adversarial Networks; a Method on Online Learning Video Recommendation Method Based on Knowledge Graph; A HEp-2 Cell Image Classification Model Based on Deep Residual Shrinkage Network Combined with Dilated Convolution; attention Adaptive Chinese Named Entity Recognition Based on Vocabulary Enhancement; software Defect Prediction Method Based on Cost-Sensitive Random Forest; a Pear Leaf Diseases Image Recognition Model Based on Capsule Network.","","","Conference review","Final","","Scopus","2-s2.0-85132016256"
"Si W.; Han J.; Yang Z.; Ma X.; Deng Y.; Luo M.; Li C.; Zhao B.; Wang J.; Zhao B.","Si, Weiguo (57221230419); Han, Jiajia (57221233401); Yang, Zhi (57221061936); Ma, Xiao (57216557432); Deng, Yuanjing (55976473600); Luo, Meng (57217128453); Li, Chuang (57221583172); Zhao, Binbin (56437098600); Wang, Jian (57164103400); Zhao, Bin (57193354766)","57221230419; 57221233401; 57221061936; 57216557432; 55976473600; 57217128453; 57221583172; 56437098600; 57164103400; 57193354766","Research on Key Techniques for Super-resolution Reconstruction of Satellite Remote Sensing Images of Transmission Lines","2021","Journal of Physics: Conference Series","1848","1","012092","","","","10.1088/1742-6596/1848/1/012092","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104639974&doi=10.1088%2f1742-6596%2f1848%2f1%2f012092&partnerID=40&md5=3fab3d54f7b8e83535c74d3d69797265","The data point target on the satellite remote sensing image of the transmission line is restricted by satellite remote sensing imaging equipment and transmission conditions, which makes it difficult to guarantee the clarity of the transmission line. Image super-resolution technology aims to recover high-resolution images from low-resolution images to improve the detailed information of the transmission line itself, which is of great significance for the intelligent inspection of transmission line satellite remote sensing and hidden danger monitoring. Aiming at the problems of traditional methods relying on multi-frame image sequences and the reconstruction results are too smooth, this paper proposes a single-frame remote sensing image super-resolution method based on the boundary balance generation confrontation network. Experimental results show that this method can provide more high-frequency information, and the reconstruction result is closest to the real image. Compared with neighbor interpolation, bicubic interpolation and other methods based on deep convolutional neural networks, the PSNR of the results in this paper is significantly improved, and effectively enhances the detailed information of the transmission line and the surrounding environment. © Published under licence by IOP Publishing Ltd.","Convolutional neural networks; Data communication equipment; Deep neural networks; Electric lines; Image enhancement; Image reconstruction; Interpolation; Optical resolving power; Satellites; High-frequency informations; Image super resolutions; Intelligent inspection; Remote sensing images; Satellite remote sensing; Super resolution reconstruction; Surrounding environment; Transmission conditions; Remote sensing","","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85104639974"
"Heintz A.M.; Peck M.; Mackey I.","Heintz, Aneesh M. (57219250605); Peck, Mason (15751439900); Mackey, Ian (55856177200)","57219250605; 15751439900; 55856177200","Multi-Scale, Super-Resolution Remote Imaging via Deep Conditional Normalizing Flows","2022","AIAA Science and Technology Forum and Exposition, AIAA SciTech Forum 2022","","","AIAA 2022-2499","","","","10.2514/6.2022-2499","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123882845&doi=10.2514%2f6.2022-2499&partnerID=40&md5=859e9a58785c535484014772baaa65b0","Many onboard vision tasks for spacecraft navigation require high-quality remote sensing images with clearly decipherable features. However, design constraints and the operational and environmental conditions limit their quality. Enhancing images through post-processing is a cost-efficient solution. Current deep-learning methods that enhance low-resolution images through super-resolution do not quantify network uncertainty of predictions and are trained at a single scale, which hinders practical integration in image-acquisition pipelines. This work proposes performing multi-scale super-resolution using a deep normalizing flow network for uncertainty-quantified and Monte Carlo-based estimates so that image enhancement for spacecraft vision tasks may be more robust and predictable. The proposed network architecture outperforms state-of-the-art super-resolution models on in-orbit lunar imagery data. Simulations demonstrate its viability on task-based evaluations for landmark identification. © 2022, American Institute of Aeronautics and Astronautics Inc.. All rights reserved.","Deep learning; Image enhancement; Network architecture; Orbits; Remote sensing; Uncertainty analysis; Design constraints; Environmental conditions; High quality; Multi-scales; Operational conditions; Post-processing; Remote imaging; Remote sensing images; Spacecraft navigation; Superresolution; Optical resolving power","","Conference paper","Final","","Scopus","2-s2.0-85123882845"
"Yang Y.; Lam K.-M.; Sun X.; Dong J.; Jian M.; Luo H.","Yang, Yuting (57192115362); Lam, Kin-Man (55839377100); Sun, Xin (56366080900); Dong, Junyu (22634069200); Jian, Muwei (22634073600); Luo, Hanjiang (57743106400)","57192115362; 55839377100; 56366080900; 22634069200; 22634073600; 57743106400","Data Transformation for Super-Resolution on Ocean Remote Sensing Images","2022","IFIP Advances in Information and Communication Technology","643 IFIP","","","431","443","12","10.1007/978-3-031-03948-5_35","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132019761&doi=10.1007%2f978-3-031-03948-5_35&partnerID=40&md5=ca275e06065ae29f7ee13dbaf0aaf6ba","High-resolution ocean remote sensing imaging is of vital importance for research in the field of ocean remote sensing. However, the available ocean remote sensing images are often averaged data, whose resolution is lower than the instant remote sensing images. In this paper, we propose a data transformation method to process remote sensing images in different locations and resolutions. We target satellite-derived sea surface temperature (SST) images as a specific case-study. In detail, we use a modified very deep super-resolution (VDSR) model as our baseline model and propose a data transformation method to improve the robustness of the model. Furthermore, we also illustrates how the degree of difference in the data distribution influences the model’s robustness and also, how our proposed data transformation method can improve the model’s robustness. Experiment results prove that our method is effective and our model is robust. © 2022, IFIP International Federation for Information Processing.","Deep learning; Metadata; Oceanography; Optical resolving power; Remote sensing; Submarine geophysics; Surface properties; Surface waters; Case-studies; Datum transformation; Deep learning; High resolution; Ocean front; Ocean remote sensing; Remote sensing images; Remote sensing imaging; Superresolution; Transformation methods; Atmospheric temperature","Data transformation; Deep learning; Ocean-front; Sea surface temperature; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85132019761"
"Guo Y.; Zhou M.; Wang Y.; Wu G.; Shibasaki R.","Guo, Yimin (55880437000); Zhou, Minjian (57424327200); Wang, Yuxuan (57218456079); Wu, Guangming (57196352694); Shibasaki, Ryosuke (7003648498)","55880437000; 57424327200; 57218456079; 57196352694; 7003648498","Learn to Be Clear and Colorful: An End-to-End Network for Panchromatic Image Enhancement","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2022.3142994","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123362143&doi=10.1109%2fLGRS.2022.3142994&partnerID=40&md5=475414cbfb9320d8e87a1b135d825ecc","Benefiting from the high coverage and re-visiting frequency, the satellite imagery is an ideal data for large-scale, real-time earth observation. However, due to the limited resolution and chromatic information, the satellite images, especially the panchromatic images, are not capable of being used for accurate earth observations, such as road extraction, vehicle detection, and building segmentation. In this research, we propose a cascaded fully convolutional network (CFCN) consists of a residual dense super-resolution network (RDSRN) for grayscale image super-resolution (SR) and a residual deconvolution colorization network (RDCN) for grayscale image colorization. The unique architecture can simultaneously learn texture detail and color information from aerial images and then transfer to enhance panchromatic images. Furthermore, we also introduce an indirect evaluation metric, learned extraction similarity (LES), to estimate the image quality of the generated image in the absence of the ground truth. Experiments on a multispectral image dataset demonstrate that panchromatic images enhanced by the proposed CFCN are with both texture and color fidelity as compared to aerial image. For pre-trained U-Net, compared to the performance on raw panchromatic images, the CFCN enhanced images increase 12.8% of LES of overall accuracy (96.4% versus 83.6%). © 2022 IEEE.","Antennas; Color; Color image processing; Deep learning; Extraction; Image quality; Image segmentation; Image texture; Observatories; Optical resolving power; Quality control; Remote sensing; Satellite imagery; Convolutional networks; Deep learning; Earth observations; Gray scale; Image color analysis; Image colorizations; Learn+; Learned extraction similarity; Superresolution; Image enhancement","Buildings; Gray-scale; Image color analysis; Image quality; Measurement; Satellites; Superresolution","Article","Final","","Scopus","2-s2.0-85123362143"
"Raphiphan Y.; Khetkeeree S.; Liangrocapart S.","Raphiphan, Yaowamal (57224214829); Khetkeeree, Suphongsa (57194030107); Liangrocapart, Sompong (8924421800)","57224214829; 57194030107; 8924421800","Sharpening the Sentinel-2A Infrared Bands via Image Residual Optimization","2022","19th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, ECTI-CON 2022","","","","","","","10.1109/ECTI-CON54298.2022.9795632","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133377020&doi=10.1109%2fECTI-CON54298.2022.9795632&partnerID=40&md5=3496e160f1571061b8f86480e36d39cb","Due to the infrared bands, i.e., short-wave infrared (SWIR) and narrow near-infrared (narrow NIR) bands, obtained from the Sentinel-2 multispectral instrument has a lower resolution than the visible-near infrared (VNIR) bands. Therefore, the capability of applications that employ infrared information is often limited by its spatial resolution. To overcome this problem, we propose a method for sharpening these infrared bands. This method is based on the multiresolution analysis (MRA) method, which focuses on the image residual in the spatial domain. The sharpened image can be obtained from the combination of the low-frequency (LF) and high-frequency (HF) components. The residual image is performed as the HF components, which can be estimated from the difference between the original image and its smoothing (blurring) version. The bicubic interpolation was applied to generate the LF component. The least-square error of the image residual was employed to determine the optimal injection weight, which can be expressed in the analytic form. The Sentinel-2A images of Central Thailand were used to test our proposed method and then compared to conventional sharpening methods, such as Gram-Schmitt, Intensity-Hue-Saturation (HIS), and Brovey methods. The results show that our proposed method can give quality metrics higher than others. Moreover, our composited infrared band image also gives color similar to the native composite image. © 2022 IEEE.","Infrared devices; Remote sensing; Image upscaling; Infrared bands; Least squares errors; Multi-resolution analysis; Multiresolution analyse-based; Multiresolutions analysis; Near infrared band; Pan-sharpening; Superresolution; Upscaling; Infrared radiation","image upscaling; least-square error; MRA-based; pan-sharpening; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85133377020"
"Zhang X.","Zhang, Xiu (57421677200)","57421677200","Superresolution Reconstruction of Remote Sensing Image Based on Middle-Level Supervised Convolutional Neural Network","2022","Journal of Sensors","2022","","2603939","","","","10.1155/2022/2603939","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123245061&doi=10.1155%2f2022%2f2603939&partnerID=40&md5=a78b8377936c6bc69c3bf81a78277767","Image has become one of the important carriers of visual information because of its large amount of information, easy to spread and store, and strong sense of sense. At the same time, the quality of image is also related to the completeness and accuracy of information transmission. This research mainly discusses the superresolution reconstruction of remote sensing images based on the middle layer supervised convolutional neural network. This paper designs a convolutional neural network with middle layer supervision. There are 16 layers in total, and the seventh layer is designed as an intermediate supervision layer. At present, there are many researches on traditional superresolution reconstruction algorithms and convolutional neural networks, but there are few researches that combine the two together. Convolutional neural network can obtain the high-frequency features of the image and strengthen the detailed information; so, it is necessary to study its application in image reconstruction. This article will separately describe the current research status of image superresolution reconstruction and convolutional neural networks. The middle supervision layer defines the error function of the supervision layer, which is used to optimize the error back propagation mechanism of the convolutional neural network to improve the disappearance of the gradient of the deep convolutional neural network. The algorithm training is mainly divided into four stages: the original remote sensing image preprocessing, the remote sensing image temporal feature extraction stage, the remote sensing image spatial feature extraction stage, and the remote sensing image reconstruction output layer. The last layer of the network draws on the single-frame remote sensing image SRCNN algorithm. The output layer overlaps and adds the remote sensing images of the previous layer, averages the overlapped blocks, eliminates the block effect, and finally obtains high-resolution remote sensing images, which is also equivalent to filter operation. In order to allow users to compare the superresolution effect of remote sensing images more clearly, this paper uses the Qt5 interface library to implement the user interface of the remote sensing image superresolution software platform and uses the intermediate layer convolutional neural network and the remote sensing image superresolution reconstruction algorithm proposed in this paper. When the training epoch reaches 35 times, the network has converged. At this time, the loss function converges to 0.017, and the cumulative time is about 8 hours. This research helps to improve the visual effects of remote sensing images. © 2022 Xiu Zhang.","Backpropagation; Convolution; Deep neural networks; Extraction; Feature extraction; Image enhancement; Image reconstruction; Multilayer neural networks; Optical resolving power; Remote sensing; Convolutional neural network; Features extraction; Image super-resolution reconstruction; Image-based; Images reconstruction; Middle layer; Output layer; Reconstruction algorithms; Remote sensing images; Super-resolution reconstruction; Convolutional neural networks","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85123245061"
"Wang H.; Zhao X.; Liang S.; Wu D.; Zhang X.; Wang Q.; Zhao J.; Du X.; Zhou Q.","Wang, Haoyu (57214057511); Zhao, Xiang (55705124800); Liang, Shunlin (7402146514); Wu, Donghai (55792755800); Zhang, Xin (57077122400); Wang, Qian (57225186689); Zhao, Jiacheng (57196454200); Du, Xiaozheng (57203526888); Zhou, Qian (57211502409)","57214057511; 55705124800; 7402146514; 55792755800; 57077122400; 57225186689; 57196454200; 57203526888; 57211502409","Developing Long Time Series 1-km Land Cover Maps from 5-km AVHRR Data Using a Super-Resolution Method","2021","IEEE Transactions on Geoscience and Remote Sensing","59","7","9186343","5479","5493","14","10.1109/TGRS.2020.3018109","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112283765&doi=10.1109%2fTGRS.2020.3018109&partnerID=40&md5=b8b9372981bde59aaf8ad12da6f733cd","Dynamic land cover (LC) information is an essential part of environmental and ecological research. Therefore, acquiring dynamic LC data with high spatial resolution has attracted a great deal of attention in the remote sensing community. Nevertheless, the high-temporal resolution satellite data tend to have a coarse spatial resolution, and satellite data with high temporal resolution are often relatively low. Obtaining LC with high spatiotemporal resolution is extremely challenging. The super-resolution method can help researchers achieve this goal, and the recently developed neural-network-based deep learning algorithms have great potential for use as an alternative solution. This study proposes a focal loss temporal convolutional long short-term memory (FL-T-ConvLSTM) model for super-resolution LC classification research. It first trains the deep FL-T-ConvLSTM network to establish a transformation between low-resolution quantitative remote sensing parameters and high-resolution quantitative remote sensing parameters and then engages in nonlinear mapping with a high-resolution LC map. A long-term series 1-km super-resolution LC classification model based on deep learning was established and applied to the Beijing-Tianjin-Hebei region. Based on this method, a long-term series of 1-km LC maps from 1982 to 2019 can be obtained. The test accuracy and field validation accuracy of the model reached 90.1% and 86.8% when using reliable test samples and field test samples, respectively. This study provides a method for obtaining high-resolution LC classification products from low-resolution quantitative remote-sensing products.  © 1980-2012 IEEE.","Deep learning; Image resolution; Learning algorithms; Learning systems; Mathematical transformations; Optical resolving power; Alternative solutions; Beijing-tianjin-hebei regions; Classification models; High spatial resolution; High temporal resolution; Quantitative remote sensing; Spatio-temporal resolution; Superresolution methods; AVHRR; image resolution; land cover; map; satellite data; time series analysis; Remote sensing","Focal loss temporal convolutional long short-term memory (FL-T-ConvLSTM); Land cover (LC); Long time series; Quantitative remote sensing parameters; Super-resolution","Article","Final","","Scopus","2-s2.0-85112283765"
"Abadal S.; Salgueiro L.; Marcello J.; Vilaplana V.","Abadal, Saüc (57345222200); Salgueiro, Luis (57344768400); Marcello, Javier (6602158797); Vilaplana, Verónica (23394280500)","57345222200; 57344768400; 6602158797; 23394280500","A dual network for super-resolution and semantic segmentation of sentinel-2 imagery","2021","Remote Sensing","13","22","4547","","","","10.3390/rs13224547","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119333436&doi=10.3390%2frs13224547&partnerID=40&md5=e25e818f298bd6b4bf49de4703f49aee","There is a growing interest in the development of automated data processing workflows that provide reliable, high spatial resolution land cover maps. However, high-resolution remote sensing images are not always affordable. Taking into account the free availability of Sentinel-2 satellite data, in this work we propose a deep learning model to generate high-resolution segmentation maps from low-resolution inputs in a multi-task approach. Our proposal is a dual-network model with two branches: the Single Image Super-Resolution branch, that reconstructs a high-resolution version of the input image, and the Semantic Segmentation Super-Resolution branch, that predicts a high-resolution segmentation map with a scaling factor of 2. We performed several experiments to find the best architecture, training and testing on a subset of the S2GLC 2017 dataset. We based our model on the DeepLabV3+ architecture, enhancing the model and achieving an improvement of 5% on IoU and almost 10% on the recall score. Furthermore, our qualitative results demonstrate the effectiveness and usefulness of the proposed approach. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolution; Convolutional neural networks; Data handling; Deep learning; Network architecture; Optical resolving power; Remote sensing; Semantic Web; Semantics; Statistical tests; Automated data processing; Convolutional neural network; Deep learning; High resolution; High spatial resolution; Segmentation map; Semantic segmentation; Sentinel-2; Superresolution; Work-flows; Semantic Segmentation","Convolutional neural network; Deep learning; Semantic segmentation; Sentinel-2; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85119333436"
"Gong Z.; Wang N.; Cheng D.; Jiang X.; Xin J.; Yang X.; Gao X.","Gong, Zhaori (57788161400); Wang, Nannan (55694111900); Cheng, De (57243851400); Jiang, Xinrui (57210574242); Xin, Jingwei (56975916100); Yang, Xi (56124410500); Gao, Xinbo (57305287800)","57788161400; 55694111900; 57243851400; 57210574242; 56975916100; 56124410500; 57305287800","Learning Deep Resonant Prior for Hyperspectral Image Super-Resolution","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5532414","","","","10.1109/TGRS.2022.3185647","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133586670&doi=10.1109%2fTGRS.2022.3185647&partnerID=40&md5=c0e827f841e6dc429180686887eb9870","The hyperspectral image super-resolution (HSISR) task has been widely studied, and significant progress has been made by leveraging the deep convolution neural network (CNN) techniques. Nevertheless, the scarcity of training images hinders the research progress of the HSISR task. Moreover, the differences in imaging conditions and the number of spectral bands among different datasets make it very difficult to construct a unified deep neural network. In this article, we first present a nontraining-based HSISR method based on deep prior knowledge, which captures the image before restoring the high-resolution image by using the intrinsic characteristics of CNN. Then, we append a special network input processing module (IPM) onto the HSISR network to automatically adjust the structure of the input so that the choice of network structure is no longer limited, while the network design focuses on exploiting the spatial information of hyperspectral images (HSIs) and the correlation between spectral bands, making the method more suitable for HSISR tasks and greatly extending its applications. Extensive experimental results on the HSI datasets illustrate the effectiveness of the proposed method, and we have got comparable results with the state-of-the-art methods while requiring no training samples.  © 1980-2012 IEEE.","Convolution; Correlation methods; Hyperspectral imaging; Remote sensing; Spectroscopy; Convolutional neural network; Correlation; Deep convolutional neural network; Electronic Packaging; Hyperspectral remote sensing; Image super resolutions; Spatial resolution; Superresolution; Task analysis; image resolution; Deep neural networks","Deep convolutional neural network (DCNN); hyperspectral remote sensing; image super-resolution","Article","Final","","Scopus","2-s2.0-85133586670"
"Wang P.; Sertel E.","Wang, Peijuan (57224642089); Sertel, Elif (21934838300)","57224642089; 21934838300","Channel–spatial attention-based pan-sharpening of very high-resolution satellite images","2021","Knowledge-Based Systems","229","","107324","","","","10.1016/j.knosys.2021.107324","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111257831&doi=10.1016%2fj.knosys.2021.107324&partnerID=40&md5=50dfe1f3c6a513aa08ae70383e085c32","The pan-sharpening process aims to generate a new synthetic output image preserving the spatial details of panchromatic and spectral details of the multi-spectral image inputs. Recently, deep learning-based methods show substantial success in the remote sensing field mostly with the application of traditional Convolutional Neural Networks (CNNs). Most of the traditional CNN-based approaches treat all the channels equitably and cannot learn the correlation. Attention mechanism which can learn the correlations among the channels has been proven to be effective in super-resolution and object detection tasks. In this research, we introduced a novel deep learning framework, channel–spatial attention-based method for pan-sharpening (CSAPAN), by designing a Densely residual attention module (RAM). Besides, we train our model in the high-frequency domain and up-sample the low-resolution multispectral images by using the pixel shuffle method before stacking with the panchromatic images for further feature extraction. We evaluated our proposed CSAPAN along with traditional methods and CNN-based methods in reduced and full resolution and obtained satisfactory quantitative and qualitative results on Pleiades, Worldview-2, and QuickBird-2 satellite image datasets. © 2021 Elsevier B.V.","Convolutional neural networks; Deep learning; Frequency domain analysis; Object detection; Spectroscopy; Channel attention; Convolutional neural network; Image inputs; Learn+; Multispectral images; Pan-sharpening; Remote-sensing; Residual network; Spatial attention; Very high resolution satellite images; Remote sensing","Channel attention; Pan-sharpening; Remote sensing; Residual networks; Spatial attention","Article","Final","","Scopus","2-s2.0-85111257831"
"Dharejo F.A.; Deeba F.; Zhou Y.; Das B.; Jatoi M.A.; Zawish M.; Du Y.; Wang X.","Dharejo, Fayaz Ali (57195487028); Deeba, Farah (57215997317); Zhou, Yuanchun (55737417400); Das, Bhagwan (56493885700); Jatoi, Munsif Ali (55822002000); Zawish, Muhammad (57206720765); Du, Yi (35791161600); Wang, Xuezhi (56512501900)","57195487028; 57215997317; 55737417400; 56493885700; 55822002000; 57206720765; 35791161600; 56512501900","TWIST-GAN: Towards Wavelet Transform and Transferred GAN for Spatiooral Single Image Super Resolution","2021","ACM Transactions on Intelligent Systems and Technology","12","6","71","","","","10.1145/3456726","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123956833&doi=10.1145%2f3456726&partnerID=40&md5=423b9bbc6a776996628949b45f5fa79d","Single Image Super-resolution (SISR) produces high-resolution images with fine spatial resolutions from a remotely sensed image with low spatial resolution. Recently, deep learning and generative adversarial networks (GANs) have made breakthroughs for the challenging task of single image super-resolution (SISR). However, the generated image still suffers from undesirable artifacts such as the absence of texture-feature representation and high-frequency information. We propose a frequency domain-based spatiooral remote sensing single image super-resolution technique to reconstruct the HR image combined with generative adversarial networks (GANs) on various frequency bands (TWIST-GAN). We have introduced a new method incorporating Wavelet Transform (WT) characteristics and transferred generative adversarial network. The LR image has been split into various frequency bands by using the WT, whereas the transfer generative adversarial network predicts high-frequency components via a proposed architecture. Finally, the inverse transfer of wavelets produces a reconstructed image with super-resolution. The model is first trained on an external DIV2 K dataset and validated with the UC Merced Landsat remote sensing dataset and Set14 with each image size of 256 × 256. Following that, transferred GANs are used to process spatiooral remote sensing images in order to minimize computation cost differences and improve texture information. The findings are compared qualitatively and qualitatively with the current state-of-art approaches. In addition, we saved about 43% of the GPU memory during training and accelerated the execution of our simplified version by eliminating batch normalization layers. © 2021 Association for Computing Machinery.","Deep learning; Frequency domain analysis; Image compression; Image enhancement; Image reconstruction; Image resolution; Image texture; Remote sensing; Textures; Wavelet transforms; High-resolution images; Image super resolutions; Neural-networks; Remote-sensing; Remotely sensed images; Single images; Spatial resolution; Spatiooral; Superresolution; Wavelets transform; Generative adversarial networks","neural networks; spatiooral; super resolution; Wavelet transform","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85123956833"
"Huang B.; Guo Z.; Wu L.; He B.; Li X.; Lin Y.","Huang, Bo (57221167884); Guo, Zhiming (57193602601); Wu, Liaoni (35103994700); He, Boyong (57214668875); Li, Xianjiang (57375758100); Lin, Yuxing (57221168843)","57221167884; 57193602601; 35103994700; 57214668875; 57375758100; 57221168843","Pyramid information distillation attention network for super-resolution reconstruction of remote sensing images","2021","Remote Sensing","13","24","5143","","","","10.3390/rs13245143","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121356063&doi=10.3390%2frs13245143&partnerID=40&md5=f5b8ccefdd87b4d93e68c0c324c5b3ce","Image super-resolution (SR) technology aims to recover high-resolution images from low-resolution originals, and it is of great significance for the high-quality interpretation of remote sensing images. However, most present SR-reconstruction approaches suffer from network training dif-ficulties and the challenge of increasing computational complexity with increasing numbers of network layers. This indicates that these approaches are not suitable for application scenarios with limited computing resources. Furthermore, the complex spatial distributions and rich details of remote sensing images increase the difficulty of their reconstruction. In this paper, we propose the pyramid information distillation attention network (PIDAN) to solve these issues. Specifically, we propose the pyramid information distillation attention block (PIDAB), which has been developed as a building block in the PIDAN. The key components of the PIDAB are the pyramid information distillation (PID) module and the hybrid attention mechanism (HAM) module. Firstly, the PID module uses feature distillation with parallel multi-receptive field convolutions to extract short-and long-path feature information, which allows the network to obtain more non-redundant image fea-tures. Then, the HAM module enhances the sensitivity of the network to high-frequency image in-formation. Extensive validation experiments show that when compared with other advanced CNN-based approaches, the PIDAN achieves a better balance between image SR performance and model size. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Complex networks; Distillation; Image enhancement; Image reconstruction; Network layers; Remote sensing; Attention mechanisms; Feature distillation; High quality; High-resolution images; Image super resolutions; Lower resolution; Remote sensing images; Remote-sensing; Super-resolution reconstruction; Superresolution; Optical resolving power","Attention mechanism; Feature distillation; Remote sensing; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85121356063"
"Ping B.; Meng Y.; Xue C.; Su F.","Ping, Bo (56702601200); Meng, Yunshan (56421195000); Xue, Cunjin (35197573100); Su, Fenzhen (57210948280)","56702601200; 56421195000; 35197573100; 57210948280","Can the structure similarity of training patches affect the sea surface temperature deep learning super-resolution?","2021","Remote Sensing","13","18","3568","","","","10.3390/rs13183568","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114697670&doi=10.3390%2frs13183568&partnerID=40&md5=a37357a4f7131073401ae2d113242607","Meso-and fine-scale sea surface temperature (SST) is an essential parameter in oceanographic research. Remote sensing is an efficient way to acquire global SST. However, single infrared-based and microwave-based satellite-derived SST cannot obtain complete coverage and high-resolution SST simultaneously. Deep learning super-resolution (SR) techniques have exhib-ited the ability to enhance spatial resolution, offering the potential to reconstruct the details of SST fields. Current SR research focuses mainly on improving the structure of the SR model instead of training dataset selection. Different from generating the low-resolution images by downscaling the corresponding high-resolution images, the high-and low-resolution SST are derived from different sensors. Hence, the structure similarity of training patches may affect the SR model training and, consequently, the SST reconstruction. In this study, we first discuss the influence of training dataset selection on SST SR performance, showing that the training dataset determined by the structure similarity index (SSIM) of 0.6 can result in higher reconstruction accuracy and better image quality. In addition, in the practical stage, the spatial similarity between the low-resolution input and the objective high-resolution output is a key factor for SST SR. Moreover, the training dataset obtained from the actual AMSR2 and MODIS SST images is more suitable for SST SR because of the skin and sub-skin temperature difference. Finally, the SST reconstruction accuracies obtained from different SR models are relatively consistent, yet the differences in reconstructed image quality are rather significant. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Atmospheric temperature; Computerized tomography; Deep learning; Image quality; Image reconstruction; Optical resolving power; Remote sensing; Submarine geophysics; Surface properties; Surface waters; High resolution image; High-resolution output; Low resolution images; Oceanographic research; Reconstructed image; Reconstruction accuracy; Sea surface temperature (SST); Structure similarity; Oceanography","AMSR2; Deep learning; MODIS; Sea surface temperature (SST); Super-resolution (SR)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85114697670"
"Zhou Q.","Zhou, Qiaoliang (57553798300)","57553798300","Superresolution Reconstruction of Remote Sensing Image Based on Generative Adversarial Network","2022","Wireless Communications and Mobile Computing","2022","","9114911","","","","10.1155/2022/9114911","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127113909&doi=10.1155%2f2022%2f9114911&partnerID=40&md5=3d876711c29468b78ce7006bf16c849c","To recreate high-resolution, more detailed remote sensing images from existing low-resolution photos, this technique is known as remote sensing image superresolution reconstruction, and it has numerous uses. As an important research hotspot of neural networks, generative adversarial network (GAN) has made outstanding progress for image superresolution reconstruction. It solves the computational complexity and low reconstructed image quality of standard superresolution reconstruction algorithms. This research offers a superresolution reconstruction strategy with a self-attention generative adversarial network to improve the quality of reconstructed superresolution remote sensing images. The self-attention strategy as well as residual module is utilized to build a generator in this model that transforms low-resolution remote sensing images into superresolution ones. It aims to determine the discrepancy between a reconstructed picture and a true picture by using a deep convolutional network as a discriminator. For the purpose of enhancing the accuracy, content loss is used. This is done to obtain accurate detail reconstruction. According to the findings of the experiments, this approach is capable of regenerating higher-quality images.  © 2022 Qiaoliang Zhou.","Image enhancement; Image reconstruction; Optical resolving power; Remote sensing; High resolution; Hotspots; Image super-resolution reconstruction; Image-based; Lower resolution; Neural-networks; Reconstructed image; Remote sensing images; Super-resolution reconstruction; Superresolution; Generative adversarial networks","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85127113909"
"Wang Y.; Dong Y.; Liu H.","Wang, Yiqin (57302544400); Dong, Yunyun (57458717100); Liu, Huiling (53866658900)","57302544400; 57458717100; 53866658900","Super-resolution method of hyperspectral image based on GoogLeNet and spatial spectrum transformation; [基于GoogLeNet和空间谱变换的高光谱图像超分辨率方法]","2022","Guangxue Jishu/Optical Technique","48","1","","93","101","8","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124891540&partnerID=40&md5=e321283510fc66af216344cfac89034b","To improve the spatial resolution of hyperspectral image, a super-resolution (SR) method based on GoogLeNet and spatial spectrum transform is proposed. Firstly, the spectral SR framework of remote sensing image is designed to extract different reflection spectra from the image. Then, the coarse pixel spectrum is amplified by using the sparse coding of GoogLeNet, and projected into the high-resolution dictionary to invert the potential SR representation to obtain the super-resolution spectrum. Finally, in order to improve the fidelity of image reconstruction, a coding and decoding structure based on GoogLeNet network is proposed to realize spatial spectral prior transformation. The proposed method is demonstrated experimentally on KSC and other dataset. The results show that the proposed method can effectively reconstruct the image details and texture structure, and the average peak signal-to-noise ratio (APSNR), average structural similarity (ASSIM) and spectral angle mapping (SAM) are better than other comparison methods, and the spectral information is better preserved. Taking KSC data set as an example, APSNR, ASSIM and SAM are 25.643db, 0.789 and 0.084, respectively. © 2022, Editorial Board of Optical Technique. All right reserved.","","GoogLeNet; Hyperspectral image; Image reconstruction; Sparse coding; Spatial spectrum transform; Super resolution","Article","Final","","Scopus","2-s2.0-85124891540"
"Ren T.; Xu H.; Jiang G.; Yu M.; Zhang X.; Wang B.; Luo T.","Ren, Tingdi (57605422500); Xu, Haiyong (55462879200); Jiang, Gangyi (7401706697); Yu, Mei (57762346100); Zhang, Xuan (57605927600); Wang, Biao (57888440900); Luo, Ting (54397301800)","57605422500; 55462879200; 7401706697; 57762346100; 57605927600; 57888440900; 54397301800","Reinforced Swin-Convs Transformer for Simultaneous Underwater Sensing Scene Image Enhancement and Super-resolution","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","4209616","","","","10.1109/TGRS.2022.3205061","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137878445&doi=10.1109%2fTGRS.2022.3205061&partnerID=40&md5=55fdb6560fa249229efcd66661ed54a6","Underwater image enhancement (UIE) technology aims to tackle the challenge of restoring the degraded underwater images due to light absorption and scattering. Meanwhile, the ever-increasing requirement for higher resolution images from a lower resolution in the underwater domain cannot be overlooked. To address these problems, a novel U-Net-based reinforced Swin-Convs Transformer for simultaneous enhancement and superresolution (URSCT-SESR) method is proposed. Specifically, with the deficiency of U-Net based on pure convolutions, the Swin Transformer is embedded into U-Net for improving the ability to capture the global dependence. Then, given the inadequacy of the Swin Transformer capturing the local attention, the reintroduction of convolutions may capture more local attention. Thus, an ingenious manner is presented for the fusion of convolutions and the core attention mechanism to build a reinforced Swin-Convs Transformer block (RSCTB) for capturing more local attention, which is reinforced in the channel and the spatial attention of the Swin Transformer. Finally, experimental results on available datasets demonstrate that the proposed URSCT-SESR achieves the state-of-the-art performance compared with other methods in terms of both subjective and objective evaluations. The code is publicly available at https://github.com/TingdiRen/URSCT-SESR.  © 1980-2012 IEEE.","Convolution; Generative adversarial networks; Image reconstruction; Image resolution; Light absorption; Neural networks; Reinforcement; Atmospheric modeling; Convolutional neural network; Scene image; Superresolution; Swin-convs transformer; Transformer; U-net; Underwater image enhancements; Underwater image enhancemnet; image classification; image resolution; instrumentation; remote sensing; satellite imagery; Image enhancement","Super-resolution (SR); Swin-Convs Transformer; U-Net; underwater image enhancement (UIE)","Article","Final","","Scopus","2-s2.0-85137878445"
"Bai Y.; Zhu F.; Wu H.","Bai, Yuyang (57221500699); Zhu, Fuzhen (12780819500); Wu, Hong (55619294193)","57221500699; 12780819500; 55619294193","An improved remote sensing images super-resolution method based on densely connected network; [改进的密集连接网络遥感图像超分辨重建]","2021","Gaojishu Tongxin/Chinese High Technology Letters","31","10","","1037","1043","6","10.3772/j.issn.1002-0470.2021.10.004","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118693942&doi=10.3772%2fj.issn.1002-0470.2021.10.004&partnerID=40&md5=85826a9c78c6d712d422c6e1c0dab696","Remote sensing image super-resolution improves the detail information of remote sensing image, which is of great significance in remote sensing image processing. In order to further improve the super-resolution reconstructed effect of remote sensing image, an improved remote sensing image super-resolution algorithm based on densely connected network is proposed. First, the very deep super-resolution algorithm (VDSR) based on residual network is improved. Combined with densely connected network (DenseNet), the residual blocks in the residual network are replaced by densely blocks, and a group of densely layers and bottleneck layers are added to improve the DenseNet network structure. Second, the activation function is modified to PReLU function, and the L1 loss function is adopted in training. In order to make the super-resolution network have better effect on remote sensing images, remote sensing images are used as the training data set in training. The network converges when the epoch reaches about 35 times. Finally, the experimental results show that the effect of the improved algorithm is better than the effect of VDSR algorithm on remote sensing images. The PSNR increases by 1.05dB and the SSIM increases by 0.042 on average. © 2021, Editorial Department of the Journal of Chinese High Technology Letters. All right reserved.","","Deep learning; Densely connected network (DenseNet); Remote sensing image; Super-resolution","Article","Final","","Scopus","2-s2.0-85118693942"
"Chaoqi H.; Qize L.; Hualin L.; Jingbo W.","Chaoqi, He (57225206064); Qize, Li (57225207053); Hualin, Liu (57225215326); Jingbo, Wei (57225216121)","57225206064; 57225207053; 57225215326; 57225216121","Remote sensing images mosaicking method based on spatiotemporal fusion","2021","Laser and Optoelectronics Progress","58","14","1415002","","","","10.3788/LOP202158.1415002","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109582897&doi=10.3788%2fLOP202158.1415002&partnerID=40&md5=defc17f571beee5b82df2af6b567ad88","Due to the limited width of high-resolution satellites, earth observation applications involving a large area usually require mosaics of multiple high-resolution images taken at different times or different sensors. The process of mosaicing images usually includes 5 basic steps: sorting, registration, color balance, seam line detection, and overlap area fusion. The existing color balance methods do not make full use of the existing satellite data, and most of the algorithms only pursue visual effects, not the fidelity of the data. For this reason, a new spatio temporal fusion mosaic framework is proposed. The framework introduces the spatio temporal fusion method based on the enhanced deep super-resolution network, and the images of all shooting moments are adjusted to the same time through a global reference image to ensure consistent color styles. The method in this paper carries out mosaic testing in the red, green, and blue bands of LandSat8 images. The experimental results show that the proposed method is more effective than the existing mosaic methods. © 2021 Universitat zu Koln. All rights reserved.","","Color balance; Convolutional neural network; Machine vision; Remote sensing image mosaicking; Spatiotemporal fusion","Article","Final","","Scopus","2-s2.0-85109582897"
"Zou H.; He S.; Wang Y.; Li R.; Cheng F.; Cao X.","Zou, Huanxin (8366222500); He, Shitian (57222956907); Wang, Yingqian (57200449110); Li, Runlin (57222956493); Cheng, Fei (57222956824); Cao, Xu (57211094852)","8366222500; 57222956907; 57200449110; 57222956493; 57222956824; 57211094852","Ship detection based on medium-low resolution remote sensing data and super-resolved feature representation","2022","Remote Sensing Letters","13","4","","323","333","10","10.1080/2150704X.2022.2033343","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123855038&doi=10.1080%2f2150704X.2022.2033343&partnerID=40&md5=16a47dcb83604329f851368d67444546","Existing methods enhance medium-low resolution remote sensing ship detection by feeding super-resolved images to the detectors. Although these methods marginally improve the detection accuracy, the correlation between image super-resolution (SR) and ship detection is under-exploited. In this paper, we propose a simple but effective ship detection method called ShipSR-Det, in which both the output image and the intermediate features of the SR module are fed to the detection module. Using the super-resolved feature representation, the potential benefit introduced by image SR can be fully used for ship detection. We apply our method to the SSD and Faster-RCNN detectors and develop ShipSR-SSD and ShipSR-Faster-RCNN, respectively. Extensive ablation studies validate the effectiveness and generality of our method. Moreover, we compare ShipSR-Faster-RCNN with several state-of-the-art ship detection methods. Comparative results on the HRSC2016, DOTA and NWPU VHR-10 datasets demonstrate the superior performance of our proposed method. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Feature extraction; Remote sensing; Ships; Detection accuracy; Detection methods; Feature representation; Image super resolutions; Lower resolution; Remote sensing data; Remote-sensing; Resolution detection; Ship detection; Simple++; accuracy assessment; detection method; image resolution; remote sensing; satellite data; shipborne measurement; Image enhancement","","Article","Final","","Scopus","2-s2.0-85123855038"
"Che Y.; Wang Q.; Li S.; Li B.; Ma Y.","Che, Yingpu (57209659453); Wang, Qing (57215536351); Li, Shilin (57222750239); Li, Baoguo (7410083288); Ma, Yuntao (12140010900)","57209659453; 57215536351; 57222750239; 7410083288; 12140010900","Monitoring of maize phenotypic traits using super-resolution reconstruction and multimodal data fusion; [基于超分辨率重建和多模态数据融合的玉米表型性状监测]","2021","Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering","37","20","","169","178","9","10.11975/j.issn.1002-6819.2021.20.019","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121665042&doi=10.11975%2fj.issn.1002-6819.2021.20.019&partnerID=40&md5=496b8f780a22303ee161be5260c28fe0","High-throughput phenotyping has posed an urgent challenge on plant genetics, physiology, and breeding at present. Particularly, traditional manual cannot meet the needs of high-throughput phenotyping for breeding, due mainly to time-consuming and labour-intensive work with a limited sample size. Alternatively, the Unmanned Aerial Vehicle (UAV) Remote Sensing can be widely expected to serve as an important tool for crop phenotypic parameters. The main reason can be the high temporal and spatial resolution, fast image acquisition, easy operation and portability, as well as relatively low cost. However, it is also inevitable to balance the flight height and image resolution or accuracy during image acquisition. Efficient techniques are urgently needed to reconstruct the high-resolution images without lossing the measurement accuracy, while improving the spatial resolution and image acquisition. In this study, the maize phenotypic traits were effectively monitored using super-resolution reconstruction and multimodal data fusion. The UAV image sequences of maize were also captured at seedling, 6th leaf, 12th leaf, tasseling, and milk stage. The super-resolution images were then reconstructed combined with the wavelet transform and bicubic interpolation. The reconstructed images presented higher reconstruction quality, less distortion with peak signal-to-noise ratio of 21.5, structure similarity of 0.81, and mean absolute error ratio of 6.4%. A lower error was also achieved for the plant height and biomass estimation with the root mean square error of 3.9 cm and 0.19 kg, respectively. Ground Sampling Distance (GSD) of the reconstructed image at a flight height of 60 m was similar to that of the original image at a flight height of 30 m. Subsequently, the UAV at a flight height of 60 m was utilized to scan 0.2 hm² larger fields per minute than that at a flight height of 30 m. The plant height, canopy coverage and vegetation index were also extracted from the original and reconstructed images. Leaf area index was calculated by point cloud reconstructed by oblique photography. The original shape of point cloud was remained, while point cloud was compressed for a higher efficiency using 3-D voxel filtering. Specifically, a better correlation was achieved, where the measured LAI was the slope of 0.72 and the root mean square error of 0.14. All canopy structure, spectrum and population structure parameters were then used to construct estimation models of above ground biomass using single characteristic parameter and multimodal data. A higher estimation accuracy of above ground biomass was obtained by multimodal data fusion, compared with a single parameter with the coefficient of determination was 0.83 and root mean square error of 0.19 kg. Therefore, a combination of image super-resolution reconstruction and multimodal data fusion can be widely expected to deal with the canopy saturation for higher spatial resolution and estimation accuracy, indicating fully meeting the demand for higher throughput of data acquisition. Meanwhile, the finding can provide a highly effective and novel solution to the estimation of above ground biomass. More importantly, the correlation between genotype and phenotype can also be extended to cultivate high-quality maize varieties suitable for mechanized production. © 2021, Editorial Department of the Transactions of the Chinese Society of Agricultural Engineering. All right reserved.","Antennas; Errors; Image acquisition; Image compression; Image enhancement; Image quality; Image reconstruction; Image resolution; Mean square error; Plants (botany); Remote sensing; Signal to noise ratio; Wavelet transforms; Aboveground biomass; High-throughput phenotyping; Maize; Multimodal data fusion; Phenotypic traits; Point-clouds; Reconstructed image; Remote-sensing; Root mean square errors; Super-resolution reconstruction; Unmanned aerial vehicles (UAV)","Above ground biomass; Maize; Multimodal data fusion; Remote sensing; Super-resolution reconstruction; UAV","Article","Final","","Scopus","2-s2.0-85121665042"
"Mifdal J.; Coll B.; Froment J.; Duran J.","Mifdal, Jamila (57200605283); Coll, Bartomeu (8665878900); Froment, Jacques (7101820780); Duran, Joan (56496414900)","57200605283; 8665878900; 7101820780; 56496414900","Variational fusion of hyperspectral data by non-local filtering","2021","Mathematics","9","11","1265","","","","10.3390/math9111265","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107920540&doi=10.3390%2fmath9111265&partnerID=40&md5=8fd2dabd61cdf2ef96c287ed6e167021","The fusion of multisensor data has attracted a lot of attention in computer vision, partic-ularly among the remote sensing community. Hyperspectral image fusion consists in merging the spectral information of a hyperspectral image with the geometry of a multispectral one in order to infer an image with high spatial and spectral resolutions. In this paper, we propose a variational fusion model with a nonlocal regularization term that encodes patch-based filtering conditioned to the geometry of the multispectral data. We further incorporate a radiometric constraint that injects the high frequencies of the scene into the fused product with a band per band modulation according to the energy levels of the multispectral and hyperspectral images. The proposed approach proved robust to noise and aliasing. The experimental results demonstrate the performance of our method with respect to the state-of-the-art techniques on data acquired by commercial hyperspectral cameras and Earth observation satellites. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","","Data fusion; Hyperspectral imaging; Multispectral imaging; Non-local filtering; Super-resolution; Variational methods","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85107920540"
"Li Y.; Du Z.; Wu S.; Wang Y.; Wang Z.; Zhao X.; Zhang F.","Li, Yadong (57226097505); Du, Zhenhong (25929119800); Wu, Sensen (57200079324); Wang, Yuanyuan (57315767600); Wang, Zhongyi (57216175636); Zhao, Xianwei (57193860330); Zhang, Feng (56434720200)","57226097505; 25929119800; 57200079324; 57315767600; 57216175636; 57193860330; 56434720200","Progressive split-merge super resolution for hyperspectral imagery with group attention and gradient guidance","2021","ISPRS Journal of Photogrammetry and Remote Sensing","182","","","14","36","22","10.1016/j.isprsjprs.2021.09.023","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118122163&doi=10.1016%2fj.isprsjprs.2021.09.023&partnerID=40&md5=ad45547272694cc4406038a92c0e85a9","Hyperspectral image (HSI) has been an important valuable information source for many remote sensing applications due to its rich spectral information. However, limited by existing imaging system, the spatial resolution of HSI greatly limits its practical applications. In this paper, in order to deal with the challenge of feature extraction and super-resolution of HSI, a progressive split-merge super-resolution (PSMSR) framework is proposed to overcome the inherent resolution limitations, which apply a multi-level split strategy from the task level, spectral level and feature level. Within this framework, a gradient-guided group-attention network (GGAN) is designed to extract the spatial-spectral features and reconstruct realistic texture, where group attention block (GAB) aims to increase the distinguishing ability of spectral channels, and gradient information is fully fused in the reconstruction process to promote sharp edges and realistic texture. Compared with current state-of-the-art CNN-based SR methods, the proposed method achieves significant improvement in six evaluation metrics and visual quality on multiple and diverse scenes, and it obtains a higher classification accuracy in classification experiment and gets better SR results on real data, which proves that our method can effectively improve the spatial resolution while preserving the spectral correlation. In addition, a series of ablation experiments prove the effectiveness of each component of our method. © 2021 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Convolutional neural networks; Image reconstruction; Image resolution; Remote sensing; Textures; Convolutional neural network; Features extraction; Gradient reconstruction; Group attention module; Information sources; Remote sensing applications; Spatial resolution; Spectral feature; Spectral information; Superresolution; ablation; accuracy assessment; multispectral image; remote sensing; spatial resolution; spectral analysis; Spectroscopy","Convolutional neural network; Gradient reconstruction; Group attention module; Hyperspectral image; Super resolution","Article","Final","","Scopus","2-s2.0-85118122163"
"Li Y.; Mavromatis S.; Zhang F.; Du Z.; Sequeira J.; Wang Z.; Zhao X.; Liu R.","Li, Yadong (57226097505); Mavromatis, Sebastien (22433774300); Zhang, Feng (56434720200); Du, Zhenhong (25929119800); Sequeira, Jean (56231992200); Wang, Zhongyi (57216175636); Zhao, Xianwei (57193860330); Liu, Renyi (55809641900)","57226097505; 22433774300; 56434720200; 25929119800; 56231992200; 57216175636; 57193860330; 55809641900","Single-Image Super-Resolution for Remote Sensing Images Using a Deep Generative Adversarial Network with Local and Global Attention Mechanisms","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3093043","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110893958&doi=10.1109%2fTGRS.2021.3093043&partnerID=40&md5=9fc5b609b878823e950bf2c70f6490f1","Super-resolution (SR) technology is an important way to improve spatial resolution under the condition of sensor hardware limitations. With the development of deep learning (DL), some DL-based SR models have achieved state-of-the-art performance, especially the convolutional neural network (CNN). However, considering that remote sensing images usually contain a variety of ground scenes and objects with different scales, orientations, and spectral characteristics, previous works usually treat important and unnecessary features equally or only apply different weights in the local receptive field, which ignores long-range dependencies; it is still a challenging task to exploit features on different levels and reconstruct images with realistic details. To address these problems, an attention-based generative adversarial network (SRAGAN) is proposed in this article, which applies both local and global attention mechanisms. Specifically, we apply local attention in the SR model to focus on structural components of the earth's surface that require more attention, and global attention is used to capture long-range interdependencies in the channel and spatial dimensions to further refine details. To optimize the adversarial learning process, we also use local and global attentions in the discriminator model to enhance the discriminative ability and apply the gradient penalty in the form of hinge loss and loss function that combines $L1$ pixel loss, $L1$ perceptual loss, and relativistic adversarial loss to promote rich details. The experiments show that SRAGAN can achieve performance improvements and reconstruct better details compared with current state-of-the-art SR methods. A series of ablation investigations and model analyses validate the efficiency and effectiveness of our method. © 1980-2012 IEEE.","Convolutional neural networks; Deep learning; Learning systems; Optical resolving power; Remote sensing; Scales (weighing instruments); Adversarial learning; Adversarial networks; Discriminative ability; Long-range dependencies; Remote sensing images; Spectral characteristics; State-of-the-art performance; Structural component; artificial neural network; image resolution; remote sensing; spatial resolution; Image processing","Convolutional neural networks (CNNs); generative adversarial network (GAN); local and global attention module; remote sensing; single-image super super-resolution (SISR)","Article","Final","","Scopus","2-s2.0-85110893958"
"Qu Y.; Qi H.; Kwan C.; Yokoya N.; Chanussot J.","Qu, Ying (57192066795); Qi, Hairong (7202348750); Kwan, Chiman (7201421216); Yokoya, Naoto (36440631200); Chanussot, Jocelyn (6602159365)","57192066795; 7202348750; 7201421216; 36440631200; 6602159365","Unsupervised and Unregistered Hyperspectral Image Super-Resolution with Mutual Dirichlet-Net","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3079518","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107211983&doi=10.1109%2fTGRS.2021.3079518&partnerID=40&md5=ecc1f8b049316506f8137e274356834d","Hyperspectral images (HSIs) provide rich spectral information that has contributed to the successful performance improvement of numerous computer vision and remote sensing tasks. However, it can only be achieved at the expense of images' spatial resolution. HSI super-resolution (HSI-SR), thus, addresses this problem by fusing low-resolution (LR) HSI with the multispectral image (MSI) carrying much higher spatial resolution (HR). Existing HSI-SR approaches require the LR HSI and HR MSI to be well registered, and the reconstruction accuracy of the HR HSI relies heavily on the registration accuracy of different modalities. In this article, we propose an unregistered and unsupervised mutual Dirichlet-Net (u^{2}-MDN) to exploit the uncharted problem domain of HSI-SR without the requirement of multimodality registration. The success of this endeavor would largely facilitate the deployment of HSI-SR since registration requirement is difficult to satisfy in real-world sensing devices. The novelty of this work is threefold. First, to stabilize the fusion procedure of two unregistered modalities, the network is designed to extract spatial information and spectral information of two modalities with different dimensions through a shared encoder-decoder structure. Second, the mutual information (MI) is further adopted to capture the nonlinear statistical dependencies between the representations from two modalities (carrying spatial information) and their raw inputs. By maximizing the MI, spatial correlations between different modalities can be well characterized to further reduce the spectral distortion. We assume that the representations follow a similar Dirichlet distribution for their inherent sum-to-one and nonnegative properties. Third, a collaborative l2,1-norm is employed as the reconstruction error instead of the more common l2-norm to better preserve the spectral information. Extensive experimental results demonstrate the superior performance of u2-MDN as compared to the state of the art.  © 1980-2012 IEEE.","Image resolution; Optical resolving power; Remote sensing; Spectroscopy; Dirichlet distributions; Image super resolutions; Multi-modality registration; Multispectral images; Reconstruction accuracy; Registration accuracy; Spatial correlations; Statistical dependencies; accuracy assessment; computer vision; design; error analysis; image classification; image resolution; nonlinearity; spatial resolution; unsupervised classification; Image enhancement","Hyperspectral image (HSI); Mutual information (MI); Super-resolution (SR); Unregistered; Unsupervised deep learning","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85107211983"
"Djerida A.; Karoui M.S.","Djerida, Achraf (57209278554); Karoui, Moussa Sofiane (15750871100)","57209278554; 15750871100","Local Spectral Super-Resolution for ALSAT-2B Images with Application to Anomaly Detection","2022","2022 IEEE Mediterranean and Middle-East Geoscience and Remote Sensing Symposium, M2GARSS 2022 - Proceedings","","","","21","24","3","10.1109/M2GARSS52314.2022.9840206","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136417130&doi=10.1109%2fM2GARSS52314.2022.9840206&partnerID=40&md5=d0673405f759fae1212a6a9cfa9020f4","In this paper, a novel methodology is proposed to enhance the spectral resolution of optical remote sensing data that have very few spectral bands. Inspired by the availability of LANDSAT-8 images, a spectral super-resolution method is used and extended to enhance the resolution of ALSAT-2B images. First, a convenient LANDSAT-8 image that incorporates the targeted ALSAT-2B image is identified. Second, the LANDSAT-8 image is converted into dataset patches of RGB and B5, B6 and B7 spectral bands. A local spectral super-resolution method, based on deep learning, is then used to grasp the transformation between the considered patches. Finally, the learned transformation is applied to the ALSAT-2B scene. To assess the quality of the transformation, several criteria are used. In addition, the impact of the reconstructed bands is investigated on anomaly detection on a desert scene. Obtained results show a great improvement for the well-known Reed-Xiaoli detector.  © 2022 IEEE.","Deep learning; Image enhancement; Optical remote sensing; Optical resolving power; Anomaly detection; Deep-learning; LANDSAT; LANDSAT-8 and ALSAT-2b; Novel methodology; RGB images; Spectral band; Spectral super-resolution; Superresolution; Superresolution methods; Anomaly detection","Deep-learning; LANDSAT-8 and ALSAT-2B; RGB images; Spectral super-resolution","Conference paper","Final","","Scopus","2-s2.0-85136417130"
"Dong X.; Wang L.; Sun X.; Jia X.; Gao L.; Zhang B.","Dong, Xiaoyu (57212387140); Wang, Longguang (57193752437); Sun, Xu (23499533300); Jia, Xiuping (7201933692); Gao, Lianru (14031580000); Zhang, Bing (57210588483)","57212387140; 57193752437; 23499533300; 7201933692; 14031580000; 57210588483","Remote Sensing Image Super-Resolution Using Second-Order Multi-Scale Networks","2021","IEEE Transactions on Geoscience and Remote Sensing","59","4","9194276","3473","3485","12","10.1109/TGRS.2020.3019660","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103377700&doi=10.1109%2fTGRS.2020.3019660&partnerID=40&md5=7be9cdd67360ca848fd345fa1ccae3f0","Remotely sensed images, especially in urban areas, have highly complex spatial distribution, since the ground objects have diverse ranges of sizes and shapes. This largely increases the difficulty of super-resolution (SR) tasks. Current deep convolutional neural network (CNN)-based SR methods often show limited performance when coping with complicated images. This article develops a second-order multi-scale super-resolution network (SMSR) to explore reconstruction tasks for difficult cases. Specifically, we propose a single-path feature reuse which cleverly captures multi-scale feature information through aggregating the features learned at different depths of a single path. Further, we present a second-order learning mechanism, which double reuses small-difference and large-difference features at local and global levels, makes use of the learned multi-scale information at maximum. The proposed methods achieve multi-scale learning using small-size convolution only, resulting in a lightweight and high-performance SR network. Experimental results show the superiority of our SMSR over state-of-the-art methods in super-resolving complicated image patterns. The effectiveness of SMSR is also demonstrated through its support to object recognition task. © 1980-2012 IEEE.","Convolution; Deep neural networks; Object recognition; Optical resolving power; Remote sensing; Ground objects; Learning mechanism; Multi-scale features; Multi-scale informations; Remote sensing images; Remotely sensed images; State-of-the-art methods; Super resolution; artificial neural network; experimental study; image analysis; image resolution; machine learning; numerical method; pattern recognition; reconstruction; remote sensing; satellite imagery; spatial distribution; urban area; Convolutional neural networks","Feature reuse; multi-scale; remote sensing image; second-order; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85103377700"
"Deeba F.; Zhou Y.; Dharejo F.A.; Du Y.; Wang X.; Kun S.","Deeba, Farah (57215997317); Zhou, Yuanchun (55737417400); Dharejo, Fayaz Ali (57195487028); Du, Yi (35791161600); Wang, Xuezhi (56512501900); Kun, She (6603966856)","57215997317; 55737417400; 57195487028; 35791161600; 56512501900; 6603966856","Multi-scale Single Image Super-Resolution with Remote-Sensing Application Using Transferred Wide Residual Network","2021","Wireless Personal Communications","120","1","","323","342","19","10.1007/s11277-021-08460-w","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104104138&doi=10.1007%2fs11277-021-08460-w&partnerID=40&md5=2eba91f380e17512726a80b34f60c620","Super-resolution (SR) has received extensive attention in recent years for satellite image processing in a wide range of application scenarios, such as land classification, identification of changes, the discovery of resources, etc. Satellite images from satellite sensors are mostly low-resolution (LR) images, so they do not completely fulfill object detection and analysis criteria. SR has multiple residual network frameworks in deep learning that have improved performance and can extend thousands of layers in the system. However, each layer improves accuracy by doubling the number of layers, although training thousands of layers are too expensive, the process is slow, and there are functional recovery issues. We proposed a transferred wide residual Single Image Super-Resolution (SISR) remote sensing deep neural network model (WRSR). By increasing the width and reducing the residual network depth, the proposed approach has dramatically reduced memory costs. As a result, our model reduced memory costs by 21% in Enhanced Deep Residual Super-Resolution (EDSR) and 34% in SRResNet as a direct consequence of the in-depth reduction. The proposed architecture improves the efficiency of training loss by performing weight normalization instead of augmentation technology. We compared our method to five recent existing super-resolution (SR) deep neural network methods, tested over three public satellite image datasets and a standard reference (PRIM) dataset. Experiment analysis is evaluated in peak to signal noise ratio (PSNR) and structural similarity index measure (SSIM). © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Cost reduction; Deep learning; Deep neural networks; Object detection; Optical resolving power; Remote sensing; Satellites; Application scenario; Low resolution images; Neural network method; Neural network model; Proposed architectures; Remote sensing applications; Satellite image processing; Structural similarity index measures (SSIM); Neural networks","Low- resolution (LR); Remote-sensing images; Super-resolution (SR); Transfer wide residual network","Article","Final","","Scopus","2-s2.0-85104104138"
"Deeba F.; Zhou Y.; Dharejo F.A.; Khan M.A.; Das B.; Wang X.; Du Y.","Deeba, Farah (57215997317); Zhou, Yuanchun (55737417400); Dharejo, Fayaz Ali (57195487028); Khan, Muhammad Ashfaq (57203924131); Das, Bhagwan (56493885700); Wang, Xuezhi (56512501900); Du, Yi (35791161600)","57215997317; 55737417400; 57195487028; 57203924131; 56493885700; 56512501900; 35791161600","A plexus-convolutional neural network framework for fast remote sensing image super-resolution in wavelet domain","2021","IET Image Processing","15","8","","1679","1687","8","10.1049/ipr2.12136","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100713100&doi=10.1049%2fipr2.12136&partnerID=40&md5=eed45b6bde493d8e0beaf52acecabf0e","Satellite image processing has been widely used in recent years in a number of applications such as land classification, Identification transfer, resource exploration, super-resolution image, etc. Due to the orbital location, revision time, quick view angle limitations, and weather impact, the satellite images are challenging to manage. There are many types of resolution, such as spatial, spectral, and temporal. Still, in our case, we concentrated on spatial image resolution to super resolve the images from low-resolution images. For remote sensing image super-resolution fast wavelet-based super-resolution (FWSR), we propose a novel, fast wavelet-based plexus framework that performs super-resolution convolutional neural network (SRCNN)-like extraction of features based on three hidden layers. First, wavelet sub-band images are combined into a pre-defined full-scale data training factor, including approximation and interchangeable stand-alone units (frequency sub-bands). Second, to speed up image recovery, mapping the sub-band image of the wavelet is then measured using its approximate image. Third, the added sub-pixel layer at the end of the network model is intended to reproduce image quality using a plexus framework. The approximation sub-band images obtained after discrete wavelet transform wavelet decomposition are used as input rather than the original image because of their high-frequency data and preserved characteristics. Five current super-resolution neural network approaches are compared with the proposed technique and tested on three pubic satellite image datasets and two benchmark datasets. The experimental findings are well compared qualitatively and quantitatively. © 2021 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology","Convolution; Convolutional neural networks; Discrete wavelet transforms; Image resolution; Multilayer neural networks; Optical resolving power; Orbits; Remote sensing; Satellites; Wavelet decomposition; Benchmark datasets; Frequency sub band; High frequency data; Low resolution images; Orbital locations; Remote sensing images; Satellite image processing; Wavelet sub bands; Image processing","","Article","Final","","Scopus","2-s2.0-85100713100"
"Chen E.; Feng X.","Chen, Errui (36184996900); Feng, Xubin (57789065300)","36184996900; 57789065300","Single Space Object Image Denoising and Super Resolution Reconstructing based on Unpaired images","2022","IEEE Joint International Information Technology and Artificial Intelligence Conference (ITAIC)","2022-June","","","1572","1576","4","10.1109/ITAIC54216.2022.9836590","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136411493&doi=10.1109%2fITAIC54216.2022.9836590&partnerID=40&md5=cdd088c701b32143cec0510cb2eea83f","High quality space target image is of great significance for space attack and defense because space exploration missions are becoming more and more important. But high quality images of space object are difficult to obtain due to the large number of cosmic rays in the space environment, as well as the limitations of optical lenses, detectors and transmission links on satellites. Image denoising and super-resolution reconstruction are the most economical and effective methods to solve this problem. This paper presents an unpaired denoising and super-resolution reconstruction method for optical remote sensing images which could obtain the images has higher quality than dataset itself. In order to further improve the quality of optical remote sensing images, high quality natural images are added into the training set, and unpaired image data sets (natural images and optical remote sensing images belong to different fields and cannot correspond one to one) are adopted to complete the training of the whole network by using the idea of unsupervised learning. Through the verification tests of three optical remote sensing image data sets, it can be seen that the method in this paper has reconstructed high quality optical remote sensing images with higher resolution than the dataset itself.  © 2022 IEEE.","Cosmology; Image enhancement; Image reconstruction; Lenses; Optical resolving power; Space optics; Space research; Statistical tests; Component; Dual cycle; Generative adversiral network; High quality; Optical remote sensing; Remote sensing images; Space object image; Space objects; Super-resolution reconstruction; Unpaired; Optical remote sensing","component; dual cycle; generative adversiral network; space object image; unpaired","Conference paper","Final","","Scopus","2-s2.0-85136411493"
"Wang Y.; Zhao L.; Liu L.; Hu H.; Tao W.","Wang, Yuntao (57222484357); Zhao, Lin (57216842467); Liu, Liman (8656307500); Hu, Huaifei (18233400900); Tao, Wenbing (8931232700)","57222484357; 57216842467; 8656307500; 18233400900; 8931232700","Urnet: A u-shaped residual network for lightweight image super-resolution","2021","Remote Sensing","13","19","3848","","","","10.3390/rs13193848","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115885938&doi=10.3390%2frs13193848&partnerID=40&md5=6322a16b10b0c7acef4e5552ced264b4","It is extremely important and necessary for low computing power or portable devices to design more lightweight algorithms for image super-resolution (SR). Recently, most SR methods have achieved outstanding performance by sacrificing computational cost and memory storage, or vice versa. To address this problem, we introduce a lightweight U-shaped residual network (URNet) for fast and accurate image SR. Specifically, we propose a more effective feature distillation pyramid residual group (FDPRG) to extract features from low-resolution images. The FDPRG can effectively reuse the learned features with dense shortcuts and capture multi-scale information with a cascaded feature pyramid block. Based on the U-shaped structure, we utilize a step-by-step fusion strategy to improve the performance of feature fusion of different blocks. This strategy is different from the general SR methods which only use a single Concat operation to fuse the features of all basic blocks. Moreover, a lightweight asymmetric residual non-local block is proposed to model the global context information and further improve the performance of SR. Finally, a high-frequency loss function is designed to alleviate smoothing image details caused by pixel-wise loss. Simultaneously, the proposed modules and high-frequency loss function can be easily plugged into multiple mature architectures to improve the performance of SR. Extensive experiments on multiple natural image datasets and remote sensing image datasets show the URNet achieves a better trade-off between image SR performance and model complexity against other state-of-the-art SR methods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Distillation; Economic and social effects; Image enhancement; Remote sensing; Dense shortcut; Effective feature distillation; High frequency loss; Image super resolutions; Lightweight image super-resolution; Single image super-resolution; Single images; U-shaped; U-shaped residual network; Optical resolving power","Dense shortcut; Effective feature distillation; High-frequency loss; Lightweight image super-resolution; Single image super-resolution; U-shaped residual network","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85115885938"
"He W.; Hong D.; Scarpa G.; Uezato T.; Yokoya N.","He, Wei (58103367900); Hong, Danfeng (56108179600); Scarpa, Giuseppe (7004081145); Uezato, Tatsumi (55702187300); Yokoya, Naoto (36440631200)","58103367900; 56108179600; 7004081145; 55702187300; 36440631200","Multisource remote sensing image fusion","2021","Deep Learning for the Earth Sciences: A Comprehensive Approach to Remote Sensing, Climate Science and Geosciences","","","","136","149","13","10.1002/9781119646181.ch10","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128883931&doi=10.1002%2f9781119646181.ch10&partnerID=40&md5=87a23d817b5967cbb71b223611092e4b","Multisource remote sensing image fusion refers to the process of fusing multiple image sources to obtain detailed and accurate information about the surface that cannot be obtained using a single image. A variety of multisource image fusion techniques have been proposed in the field of remote sensing to realize resolution enhancement or super-resolution tasks such as pansharpening and multiband image fusion. In recent years, deep learning (DL) approaches have been successfully applied to multisource image fusion problems, and achieved state-of-the-art performance and computational efficiency at the inference. This chapter provides a review of DL techniques developed for pansharpening and multiband image fusion. A methodological overview of state-of-the-art DL-based approaches and comparative experiments are presented to illustrate the advantages and characteristics of DL-based methods. This chapter also provides a discussion of future research challenges and directions for the development of multisource image fusion techniques. © 2021 John Wiley & Sons Ltd. All rights reserved.","","Deep learning; Multiband image fusion; Multisource remote sensing image fusion; Pansharpening; Transfer learning","Book chapter","Final","","Scopus","2-s2.0-85128883931"
"Deepak S.; Patra D.; Moorthi S.M.","Deepak, Shashikant (57216807543); Patra, DIpti (23985620900); Moorthi, S. Manthira (54395659100)","57216807543; 23985620900; 54395659100","Single image super-resolution reconstruction of remotely sensed images using MRF-2D phase congruency model","2021","Journal of Applied Remote Sensing","15","4","046507","","","","10.1117/1.JRS.15.046507","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122650203&doi=10.1117%2f1.JRS.15.046507&partnerID=40&md5=a2e37fe8c09e66de86febcdf17114cbd","Recently, the deep learning (DL)-based solution for single image super-resolution reconstruction has been extensively used. Though these methods have shown exceptional results, the computational requirement is very high and requires high-end graphic processors. Motivated to establish an efficient method without such requirement, we propose a modified Markov random field (MRF) model and two-dimensional (2D) phase congruency-based single-image super-resolution reconstruction method for remote sensing images. The 2D phase congruency-based feature extraction method is used to compute features such as edge and texture maps to achieve higher accuracy in finding similar example patches in feature space. To address an essential aspect of successful texture reconstruction, we have incorporated a texture prior for the computation of joint probability in our work. Image Euclidean distance (Ieuc) is integrated to achieve higher accuracy in finding the similarity between image patches in feature space and modeling compatibility functions. The experimental results demonstrate that the results of the proposed method are at par with the DL-based methods and outperform other state-of-the-art methods in perceptual quality as well as peak signal-to-noise ratio and structural similarity index parameters. Moreover, it shows significant improvement in the texture regions while reconstructing sharper edges for ×4 upscaling. © 2021 Society of Photo-Optical Instrumentation Engineers (SPIE).","Deep learning; Image reconstruction; Image segmentation; Markov processes; Optical resolving power; Remote sensing; Signal to noise ratio; Space optics; Textures; 2D phase congruency; Belief propagation; Euclidean distance; High-accuracy; Image euclidean distance; Markov Random Fields; Phase congruency; Remote-sensing; Single-image super-resolution reconstruction; Super-resolution reconstruction; Belief propagation","belief propagation; image Euclidean distance; Markov random field; phase congruency; remote sensing; super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85122650203"
"Liu B.; Zhao L.; Li J.; Zhao H.; Liu W.; Li Y.; Wang Y.; Chen H.; Cao W.","Liu, Baodi (16319146900); Zhao, Lifei (57274635800); Li, Jiaoyue (57299552400); Zhao, Hengle (57376940600); Liu, Weifeng (36739405100); Li, Ye (35770968700); Wang, Yanjiang (57223714000); Chen, Honglong (24174425300); Cao, Weijia (55558020600)","16319146900; 57274635800; 57299552400; 57376940600; 36739405100; 35770968700; 57223714000; 24174425300; 55558020600","Saliency-guided remote sensing image super-resolution","2021","Remote Sensing","13","24","5144","","","","10.3390/rs13245144","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121442780&doi=10.3390%2frs13245144&partnerID=40&md5=fca1807ae0681758c0b7de7375f163af","Deep learning has recently attracted extensive attention and developed significantly in remote sensing image super-resolution. Although remote sensing images are composed of various scenes, most existing methods consider each part equally. These methods ignore the salient objects (e.g., buildings, airplanes, and vehicles) that have more complex structures and require more attention in recovery processing. This paper proposes a saliency-guided remote sensing image super-resolution (SG-GAN) method to alleviate the above issue while maintaining the merits of GAN-based methods for the generation of perceptual-pleasant details. More specifically, we exploit the salient maps of images to guide the recovery in two aspects: On the one hand, the saliency detection network in SG-GAN learns more high-resolution saliency maps to provide additional structure priors. On the other hand, the well-designed saliency loss imposes a second-order restriction on the super-resolution process, which helps SG-GAN concentrate more on the salient objects of remote sensing images. Experimental results show that SG-GAN achieves competitive PSNR and SSIM compared with the advanced super-resolution methods. Visual results demonstrate our superiority in restoring structures while generating remote sensing super-resolution images. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Computer system recovery; Deep learning; Object detection; Optical resolving power; Remote sensing; Complexes structure; Detection networks; Image super resolutions; Learn+; Remote sensing images; Saliency detection; Salient maps; Salient object detection; Salient objects; Superresolution; Generative adversarial networks","Generative adversarial network; Image super-resolution; Remote sensing image; Salient object detection","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85121442780"
"Zhang D.; Shao J.; Li X.; Shen H.T.","Zhang, Dongyang (57197844592); Shao, Jie (57002035900); Li, Xinyao (57214236476); Shen, Heng Tao (7404523209)","57197844592; 57002035900; 57214236476; 7404523209","Remote Sensing Image Super-Resolution via Mixed High-Order Attention Network","2021","IEEE Transactions on Geoscience and Remote Sensing","59","6","9151234","5183","5196","13","10.1109/TGRS.2020.3009918","41","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106718508&doi=10.1109%2fTGRS.2020.3009918&partnerID=40&md5=4633e6933bb8376e7dc8c2b9a0120e10","Recently, remote sensing images have become increasingly popular in a number of tasks, such as environmental monitoring. However, the observed images from satellite sensors often suffer from low-resolution (LR), making it difficult to meet the requirements for further analysis. Super-resolution (SR) aims to increase the image resolution while providing finer spatial details, which perfectly remedies the weakness of satellite images. Therefore, in this article, we propose an innovative mixed high-order attention network (MHAN) for remote sensing SR. It comprises two components: a feature extraction network for feature extraction, and a feature refinement network with high-order attention (HOA) mechanism for detail restoration. In the feature extraction network, we replace the elementwise addition with weighted channelwise concatenation in all skip connections, which greatly facilitates the information flow. In the feature refinement network, rather than exploring the first-order statistics (spatial or channel attention), we introduce the HOA module to restore the missing details. Finally, to fully exploit hierarchical features, we introduce the frequency-aware connection to bridge the feature extraction and feature refinement networks. Experiments on two widely used remote sensing image data sets demonstrate that our MHAN not only obtains better accuracy than the state-of-the-art methods but also shows the superiority in terms of running time and GPU cost. Code is available at https://github.com/ZhangDY827/MHAN.  © 1980-2012 IEEE.","Extraction; Feature extraction; Image resolution; Optical resolving power; Restoration; Environmental Monitoring; Feature refinement; First-order statistics; Hierarchical features; Information flows; Remote sensing images; Satellite sensors; State-of-the-art methods; algorithm; detection method; image resolution; network analysis; remote sensing; Remote sensing","Attention; image super-resolution (SR); satellite image","Article","Final","","Scopus","2-s2.0-85106718508"
"Morimoto H.; Yamauchi Y.; Kidera S.","Morimoto, Hayatomomaru (57211640264); Yamauchi, Yoshihiro (57238285200); Kidera, Shouhei (14031687600)","57211640264; 57238285200; 14031687600","Contrast Source Inversion-Based Multilayered Object Analysis for Terahertz Wave Imaging","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2021.3099199","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113824936&doi=10.1109%2fLGRS.2021.3099199&partnerID=40&md5=bf242f1d70faded4d86f002e93bd4290","A complex permittivity profile reconstruction for multilayered objects was presented in this study by incorporating compressed sensing (CS)-based thickness estimation with contrast source inversion (CSI) non-linear inverse scattering (IS) method using a terahertz (THz) frequency band. Several studies investigated permittivity estimation for multiple layers. However, they require a prior knowledge of the thickness of each layer. Moreover, a critical problem in this field is the simultaneous estimation of both the dielectric constant and the thickness of each layer. To address this, a super-resolution thickness estimator using a CS filter and the CSI-based dielectric profile reconstruction scheme was used. This problem was effectively solved by introducing the cost function estimated using the CSI scheme, where the number of layers is given. The finite-difference time-domain (FDTD) numerical test indicated that the proposed method provides an accurate estimation of the thickness and dielectric profile in double-layered objects.  © 2004-2012 IEEE.","Compressed sensing; Cost functions; Finite difference time domain method; Frequency estimation; Inverse problems; Numerical methods; Permittivity; Terahertz waves; Thickness measurement; Complex permittivity; Contrast source inversion; Dielectric profiles; Finite -difference time domains (FDTD); Simultaneous estimation; Terahertz frequencies; Terahertz wave imaging; Thickness estimation; data inversion; imaging method; remote sensing; satellite data; Time domain analysis","Compressed sensing (CS); contrast source inversion (CSI); multilayer structure analysis; terahertz time-domain spectroscopic (THz-TDS) system","Article","Final","","Scopus","2-s2.0-85113824936"
"Dong R.; Zhang L.; Fu H.","Dong, Runmin (57205415789); Zhang, Lixian (57207392945); Fu, Haohuan (8713118400)","57205415789; 57207392945; 8713118400","RRSGAN: Reference-Based Super-Resolution for Remote Sensing Image","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2020.3046045","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099726810&doi=10.1109%2fTGRS.2020.3046045&partnerID=40&md5=9011834a954982a4325984a5efa39e97","Remote sensing image super-resolution (SR) plays an important role by supplementing the lack of original high-resolution (HR) images in the study scenarios of large spatial areas or long time series. However, due to the lack of imagery information in low-resolution (LR) images, single-image super-resolution (SISR) is an inherently ill-posed problem. Especially, it is difficult to reconstruct the fine textures of HR images at large upscaling factors (e.g., four times). In this work, based on Google Earth HR images, we explore the potential of the reference-based super-resolution (RefSR) method on remote sensing images, utilizing rich texture information from HR reference (Ref) images to reconstruct the details in LR images. This method can use existing HR images to help reconstruct the LR images of long time series or a specific time. We build a reference-based remote sensing SR data set (RRSSRD). Furthermore, by adopting the generative adversarial network (GAN), we propose a novel end-to-end reference-based remote sensing GAN (RRSGAN) for SR. RRSGAN can extract the Ref features and align them to the LR features. Eventually, the texture information in the Ref features can be transferred to the reconstructed HR images. In contrast to the existing RefSR methods, we propose a gradient-assisted feature alignment method that adopts the deformable convolutions to align the Ref and LR features and a relevance attention module (RAM) to improve the robustness of the model in different scenarios (e.g., land cover changes and cloud coverage). The experimental results demonstrate that RRSGAN is robust and outperforms the state-of-the-art SISR and RefSR methods in both quantitative evaluation and visual results, which indicates the great potential of the RefSR method for remote sensing tasks.  © 1980-2012 IEEE.","Image reconstruction; Image texture; Optical resolving power; Textures; Time series; Adversarial networks; High resolution image; Ill posed problem; Land-cover change; Low resolution images; Quantitative evaluation; Remote sensing images; Texture information; image resolution; remote sensing; satellite imagery; Remote sensing","Deep learning; Remote sensing imagery; Super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85099726810"
"Zhang J.; Shao M.; Wan Z.; Li Y.","Zhang, Jing (57276842200); Shao, Minhao (57217281230); Wan, Zekang (57221564292); Li, Yunsong (55986546100)","57276842200; 57217281230; 57221564292; 55986546100","Multi-scale feature mapping network for hyperspectral image super-resolution","2021","Remote Sensing","13","20","4180","","","","10.3390/rs13204180","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118226413&doi=10.3390%2frs13204180&partnerID=40&md5=6690031920d980f9f7a30f5d957f499f","Hyperspectral Image (HSI) can continuously cover tens or even hundreds of spectral segments for each spatial pixel. Limited by the cost and commercialization requirements of remote sensing satellites, HSIs often lose a lot of information due to insufficient image spatial resolution. For the high-dimensional nature of HSIs and the correlation between the spectra, the existing Super-Resolution (SR) methods for HSIs have the problems of excessive parameter amount and insufficient information complementarity between the spectra. This paper proposes a Multi-Scale Feature Mapping Network (MSFMNet) based on the cascaded residual learning to adaptively learn the prior information of HSIs. MSFMNet simplifies each part of the network into a few simple yet effective network modules. To learn the spatial-spectral characteristics among different spectral segments, a multi-scale feature generation and fusion Multi-Scale Feature Mapping Block (MSFMB) based on wavelet transform and spatial attention mechanism is designed in MSFMNet to learn the spectral features between different spectral segments. To effectively improve the multiplexing rate of multi-level spectral features, a Multi-Level Feature Fusion Block (MLFFB) is designed to fuse the multi-level spectral features. In the image reconstruction stage, an optimized sub-pixel convolution module is used for the up-sampling of different spectral segments. Through a large number of verifications on the three general hyperspectral datasets, the superiority of this method compared with the existing hyperspectral SR methods is proved. In subjective and objective experiments, its experimental performance is better than its competitors. Copyright: © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Image reconstruction; Large dataset; Optical resolving power; Photomapping; Pixels; Remote sensing; Wavelet transforms; Attention mechanisms; Feature mapping; Image super resolutions; Image super-resolution; Learn+; Multi-scale features; Multilevels; Spectra's; Spectral feature; Superresolution methods; Spectroscopy","Attention mechanism; Hyperspectral image; Image super-resolution (SR); Multi-scale feature","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85118226413"
"Armannsson S.E.; Ulfarsson M.O.; Sigurdsson J.; Nguyen H.V.; Sveinsson J.R.","Armannsson, Sveinn E. (57224686207); Ulfarsson, Magnus O. (6507677875); Sigurdsson, Jakob (7006736374); Nguyen, Han V. (57222240069); Sveinsson, Johannes R. (7003642214)","57224686207; 6507677875; 7006736374; 57222240069; 7003642214","A comparison of optimized sentinel-2 super-resolution methods using wald’s protocol and bayesian optimization","2021","Remote Sensing","13","11","2192","","","","10.3390/rs13112192","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108170131&doi=10.3390%2frs13112192&partnerID=40&md5=e8f051ff097cbf6ceff9cbe61eebf56f","In the context of earth observation and remote sensing, super-resolution aims to enhance the resolution of a captured image by upscaling and enhancing its details. In recent years, numerous methods for super-resolution of Sentinel-2 (S2) multispectral images have been suggested. Most of those methods depend on various tuning parameters that affect how effective they are. This paper’s aim is twofold. Firstly, we propose to use Bayesian optimization at a reduced scale to select tuning parameters. Secondly, we choose tuning parameters for eight S2 super-resolution methods and compare them using real and synthetic data. While all the methods give good quantitative results, Area-To-Point Regression Kriging (ATPRK), Sentinel-2 Sharpening (S2Sharp), and Sentinel-2 Symmetric Skip Connection convolutional neural network (S2 SSC) perform markedly better on several datasets than the other methods tested in this paper. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural networks; Image enhancement; Remote sensing; Bayesian optimization; Earth observations; Multispectral images; Quantitative result; Regression-kriging; Super resolution; Superresolution methods; Tuning parameter; Optical resolving power","Data fusion; Image sharpening; Multispectral (MS) multiresolution images; Sentinel-2; Sharpening of bands; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85108170131"
"Yang Z.; Diao C.; Li B.","Yang, Zijun (57278056200); Diao, Chunyuan (55531715700); Li, Bo (57188689924)","57278056200; 55531715700; 57188689924","A robust hybrid deep learning model for spatiotemporal image fusion","2021","Remote Sensing","13","24","5005","","","","10.3390/rs13245005","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121454390&doi=10.3390%2frs13245005&partnerID=40&md5=65ca8720811c489c7e88ed1195b7d8fc","Dense time-series remote sensing data with detailed spatial information are highly desired for the monitoring of dynamic earth systems. Due to the sensor tradeoff, most remote sensing systems cannot provide images with both high spatial and temporal resolutions. Spatiotemporal image fusion models provide a feasible solution to generate such a type of satellite imagery, yet existing fusion methods are limited in predicting rapid and/or transient phenological changes. Additionally, a systematic approach to assessing and understanding how varying levels of temporal phenological changes affect fusion results is lacking in spatiotemporal fusion research. The objective of this study is to develop an innovative hybrid deep learning model that can effectively and robustly fuse the satellite imagery of various spatial and temporal resolutions. The proposed model integrates two types of network models: super-resolution convolutional neural network (SRCNN) and long short-term memory (LSTM). SRCNN can enhance the coarse images by restoring degraded spatial details, while LSTM can learn and extract the temporal changing patterns from the time-series images. To systematically assess the effects of varying levels of phenological changes, we identify image phenological transition dates and design three temporal phenological change scenarios representing rapid, moderate, and minimal phenological changes. The hybrid deep learning model, alongside three benchmark fusion models, is assessed in different scenarios of phenological changes. Results indicate the hybrid deep learning model yields significantly better results when rapid or moderate phenological changes are present. It holds great potential in generating high-quality time-series datasets of both high spatial and temporal resolutions, which can further benefit terrestrial system dynamic studies. The innovative approach to understanding phenological changes’ effect will help us better comprehend the strengths and weaknesses of current and future fusion models. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural networks; Image enhancement; Image fusion; Remote sensing; Satellite imagery; Time series; CNN; Deep learning; High spatial resolution; High temporal resolution; Learning models; Phenological changes; Spatial and temporal resolutions; Spatio-temporal fusions; Spatiotemporal images; Times series; Long short-term memory","CNN; Deep learning; LSTM; Phenological change; Spatiotemporal fusion","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85121454390"
"Liu M.; Shi Q.; Li J.; Chai Z.","Liu, Mengxi (57208160778); Shi, Qian (55286447700); Li, Jianlong (57865350700); Chai, Zhuoqun (57712381300)","57208160778; 55286447700; 57865350700; 57712381300","Learning Token-Aligned Representations with Multimodel Transformers for Different-Resolution Change Detection","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","4413013","","","","10.1109/TGRS.2022.3200684","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137572006&doi=10.1109%2fTGRS.2022.3200684&partnerID=40&md5=78216b2da6266e90ac143c01c50372f8","Different-resolution change detection (DRCD) is now becoming an urgent problem to be solved, which is of great potential in rapid monitoring, such as disaster assessment and urban expansion. In DRCD tasks, bitemporal inputs are given in the form of different resolutions, and thus, conventional change detection (CD) methods cannot be applied directly. Previous studies have attempted to deal with this problem by reconstructing the low-resolution (LR) image into a high-resolution (HR) one, including interpolation and super-resolution (SR). However, these solutions are limited by the availability of training data, making it hard to meet different kinds of needs. Besides, these image-level strategies have also ignored the interaction and alignment of high-level features. Therefore, we propose a new approach based on multimodel Transformers (MM-Trans), which solves the resolution gaps of bitemporal inputs in DRCD tasks from the perspective of feature alignment. In the MM-Trans, a weight-unshared feature extractor is first utilized to precisely capture the features of the different-resolution inputs. Then, a spatial-aligned Transformer (sp-Trans) is introduced to align the LR-image features to the same size of the HR-image ones, which can be optimized in a learnable way by an auxiliary token loss. After that, a semantic-aligned Transformer (se-Trans) is adopted, in which the bitemporal features can be further interacted and aligned semantically. Finally, a prediction head is employed to obtain fine-grained change results. Experiments conducted on three common CD datasets, CDD, S2Looking, and HTCD dataset, have shown the advancement of the MM-Trans and fully demonstrated its potential in DSCD tasks.  © 1980-2012 IEEE.","Change detection; Deep learning; Image resolution; Interpolation; Job analysis; Remote sensing; Semantics; Change detection; Deep learning; Feature alignment; Features extraction; Land surface; Remote-sensing; Spatial resolution; Task analysis; Transformer; assessment method; data set; detection method; monitoring; satellite data; satellite imagery; urbanization; Feature extraction","Change detection (CD); deep learning (DL); feature alignment; remote sensing; transformer","Article","Final","","Scopus","2-s2.0-85137572006"
"Rohith G.; Kumar L.S.","Rohith, G. (57217188288); Kumar, Lakshmi Sutha (35778418900)","57217188288; 35778418900","Paradigm shifts in super-resolution techniques for remote sensing applications","2021","Visual Computer","37","7","","1965","2008","43","10.1007/s00371-020-01957-8","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090118147&doi=10.1007%2fs00371-020-01957-8&partnerID=40&md5=5bff268d60bd09ff7443b6ceabdaf275","Super-resolution (SR) algorithms have now become a bottleneck for several remote sensing applications. SR is a technique that enhances minute details of the image by increasing spatial resolution of imaging systems. SR overcomes the problems of conventional resolution enhancement techniques such as introduction of noise, spectral distortion, and lack of clarity in the details of the image. In this paper, a survey has been conducted since the inception of SR algorithm till the latest state-of-the-art SR techniques to elucidate the importance of the SR algorithms that lead to paradigm shifts in the last two decades revolutionizing toward visually pleasing high-resolution image. Inspired from the natural images, the algorithms addressing the SR problems such as ill-posed, prior and regularization problem, inverse problem, multi-frame problem and illumination and shadow problem in remote sensing applications are analyzed. For an intuitive understanding of the paradigm shifts, publicly available images are tested with representative paradigm shift SR algorithms. The result of this paradigm shift analysis is done both qualitatively and quantitatively in terms of blurs in the image, pattern clarity, edge strength, and super-resolving capability. The convergence of the natural image to the remote sensed image is critically analyzed. The challenges with possible solutions for super-resolving the remote sensed image are recommended. On experimentation, it is found that deep learning-based SR algorithms produces visually pleasing images retaining sharp edges, enhanced spatial data, and clarity in feature representation while zooming at a certain level beyond interest. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Data visualization; Deep learning; Image analysis; Image enhancement; Image resolution; Inverse problems; Optical resolving power; Remote sensing; Feature representation; High resolution image; Intuitive understanding; Multi-frame problems; Remote sensing applications; Resolution enhancement technique; Spatial resolution; Spectral distortions; Edge detection","Deep learning; Frequency- and spatial-domain methods; Remote sensing applications; Super-resolution","Review","Final","","Scopus","2-s2.0-85090118147"
"Chen D.-L.; Zhang L.; Huang H.","Chen, De-Lei (57222575169); Zhang, Lei (55943333900); Huang, Hua (57193328047)","57222575169; 55943333900; 57193328047","Robust Extraction and Super-Resolution of Low-Resolution Flying Airplane from Satellite Video","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3064064","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103262679&doi=10.1109%2fTGRS.2021.3064064&partnerID=40&md5=ce6fc640b122564ea68a6cf944e6f251","Extracting the flying airplane from the satellite video and enhancing its resolution are significant and demanding tasks in the remote sensing community. The challenge mainly lies in that the flying airplane target in the satellite video often suffers from detail loss due to complex background and limited spaceborne imaging device. In this article, a novel constructive model is proposed to model the airplane of low resolution for more complete extraction, and a new reflective symmetry shape prior is integrated into the super-resolution process to obtain the higher resolution result. Concretely, each frame can be decomposed as a linear combination of foreground and background with specific mixture ratios. With the assumption of uniform linear motion and the rigidity of the airplane, a periodic change of mixture ratios through frames is induced, which can construct the airplane as complete as possible by adopting the proposed iterative matting optimization. To further enhance the resolution of the extracted airplane, an improved alternating direction method of multipliers (ADMM) is utilized to solve the super-resolution problem with the reflective symmetry of the shape as prior. The effectiveness of our method with respect to extraction and super-resolution is borne out by the experiments on both synthetic and real data.  © 1980-2012 IEEE.","Extraction; Iterative methods; Mixtures; Optical resolving power; Remote sensing; Satellites; Alternating direction method of multipliers; Complex background; Constructive model; Higher resolution; Linear combinations; Reflective symmetry; Synthetic and real data; Uniform linear motions; aircraft; image resolution; satellite data; videography; Aircraft","Airplane; matting; multiframe; subpixel; super-resolution (SR); symmetry","Article","Final","","Scopus","2-s2.0-85103262679"
"Li J.; Zhang Z.; Tian Y.; Xu Y.; Wen Y.; Wang S.","Li, Jianxiang (57276192000); Zhang, Zili (57220548032); Tian, Yan (34873757700); Xu, Yiping (8328944100); Wen, Yihong (57222186481); Wang, Shicheng (57221278036)","57276192000; 57220548032; 34873757700; 8328944100; 57222186481; 57221278036","Target-Guided Feature Super-Resolution for Vehicle Detection in Remote Sensing Images","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2021.3112172","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122535974&doi=10.1109%2fLGRS.2021.3112172&partnerID=40&md5=0bb633c7f8a0caced57464ca43a27206","Vehicle detection in remote sensing images remains a challenge because most vehicles are small and cover only a relatively small area due to the low ground sample distance. Although image super-resolution can improve small object detection performance as a preprocessing step, methods for improving the quality of the entire image tend to focus on the majority backgrounds that are not important for detection and involve high computational cost. Inspired by the promising feature-level super-resolution method, in this letter, we propose a novel anchor-free vehicle detection network for small vehicle detection in remote sensing images. Specifically, a target-guided feature super-resolution network is proposed to enhance the features of the potential target. Besides, we propose a novel feature fusion module to improve the feature representation of shallow layers, which accounts for small object detection. Extensive experiments on three public remote sensing detection datasets [cars overhead with context (COWC), Vehicle Detection in Aerial Imagery (VEDAI), and UCAS-AOD] amply demonstrate that our method can achieve significant performance with a mean average precision of 0.933, 0.756, and 0.961, respectively.  © 2004-2012 IEEE.","Aerial photography; Feature extraction; Image enhancement; Object detection; Object recognition; Optical resolving power; Remote sensing; Detection performance; Feature super-resolution; Ground sample distances; Image super resolutions; Pre-processing step; Remote sensing images; Small area; Small object detection; Superresolution; Vehicles detection; detection method; remote sensing; satellite imagery; spectral resolution; vehicle component; Antennas","Feature super-resolution; remote sensing images; vehicle detection","Article","Final","","Scopus","2-s2.0-85122535974"
"Nguyen N.L.; Anger J.; Davy A.; Arias P.; Facciolo G.","Nguyen, Ngoc Long (57222104420); Anger, Jeremy (57195130757); Davy, Axel (57207796143); Arias, Pablo (16315312800); Facciolo, Gabriele (26664580300)","57222104420; 57195130757; 57207796143; 16315312800; 26664580300","Self-Supervised Super-Resolution for Multi-Exposure Push-Frame Satellites","2022","Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition","2022-June","","","1848","1858","10","10.1109/CVPR52688.2022.00190","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129605494&doi=10.1109%2fCVPR52688.2022.00190&partnerID=40&md5=44b2a403679ec5de70453ee7c708097c","Modern Earth observation satellites capture multi-exposure bursts of push-frame images that can be super-resolved via computational means. In this work, we propose a super-resolution method for such multi-exposure sequences, a problem that has received very little attention in the literature. The proposed method can handle the signal-dependent noise in the inputs, process sequences of any length, and be robust to inaccuracies in the exposure times. Furthermore, it can be trained end-to-end with self-supervision, without requiring ground truth high resolution frames, which makes it especially suited to handle real data. Central to our method are three key contributions: i) a base-detail decomposition for handling errors in the exposure times, ii) a noise-level-aware feature encoding for improved fusion of frames with varying signal-to-noise ratio and iii) a permutation invariant fusion strategy by temporal pooling operators. We evaluate the proposed method on synthetic and real data and show that it outperforms by a significant margin existing single-exposure approaches that we adapted to the multi-exposure case. © 2022 IEEE.","Color photography; Computer vision; Machine learning; Optical resolving power; Signal to noise ratio; Computational photography; Earth observation satellites; Exposure-time; Low-level vision; Multi exposure; Photogrammetry and remote sensing; Remote-sensing; Satellite captures; Self-& semi-& meta- & unsupervised learning; Superresolution; Remote sensing","Computational photography; Low-level vision; Photogrammetry and remote sensing; Self-& semi-& meta- & unsupervised learning","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85129605494"
"You S.","You, Shuangyu (57547499500)","57547499500","PCB Defect Detection based on Generative Adversarial Network","2022","2022 2nd International Conference on Consumer Electronics and Computer Engineering, ICCECE 2022","","","","557","560","3","10.1109/ICCECE54139.2022.9712737","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126957873&doi=10.1109%2fICCECE54139.2022.9712737&partnerID=40&md5=34c8b8364f44fc29ad2025d6ab643cb3","This paper proposes a PCB defect detection scheme based on the generative confrontation network, which can be applied to the automatic detection system of PCB vision inspection (vision inspection). We use the edge-enhanced super-resolution GAN (EESRGAN) applied in the field of remote sensing to enhance the PCB images and complete the super-resolution detection of the reconstructed picture. And use the PCB pictures of different preprocessing models in an end-to-end manner to compare the recognition of PCB defects after training. Experiments on the PCB data set show that the PCB pictures after sliding cutting are input into the result of EESRGAN training, which can relatively accurately identify the 6 types of defects contained in the data set. Our results show the effectiveness of our data processing methods.  © 2022 IEEE.","Data handling; Defects; Generative adversarial networks; Image enhancement; Organic pollutants; Polychlorinated biphenyls; Remote sensing; Automatic detection systems; Data set; Detection scheme; Edge-enhanced super-resolution GAN; End to end; PCB defects detections; Remote-sensing; Resolution detection; Superresolution; Vision inspection; Optical resolving power","EESRGAN; Generative Adversarial Network; PCB defect detection","Conference paper","Final","","Scopus","2-s2.0-85126957873"
"He S.; Zou H.; Wang Y.; Li R.; Cheng F.; Cao X.; Li M.","He, Shitian (57222956907); Zou, Huanxin (8366222500); Wang, Yingqian (57200449110); Li, Runlin (57222956493); Cheng, Fei (57222956824); Cao, Xu (57211094852); Li, Meilin (57209947350)","57222956907; 8366222500; 57200449110; 57222956493; 57222956824; 57211094852; 57209947350","Enhancing Mid-Low-Resolution Ship Detection with High-Resolution Feature Distillation","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2021.3110404","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121784865&doi=10.1109%2fLGRS.2021.3110404&partnerID=40&md5=8d351b0db1b38c5bbfaf4e54b34f07fd","To enhance mid-low-resolution ship detection, existing methods generally use image super-resolution (SR) as a preprocessing step and feed the super-resolved images to the detectors. However, these methods only use high-resolution (HR) images as ground-truth labels to supervise the training of their SR module but overlook the rich HR information in the detection stage. Inspired by the recent advances in knowledge distillation, in this letter, we design a feature distillation framework to fully exploit the information in ground-truth HR images to handle mid-low-resolution ship detection. Our framework consists of a student network and a teacher network. The student network first super-resolves input images using an SR module and then feeds the super-resolved images to the detection module. The teacher network whose architecture is the same as the student detection module directly takes HR images as input to generate HR feature representation and then distills these HR features to the student network through a distillation loss. Using our feature distillation framework, HR images are not only used as ground-truth labels to train the SR module but also provide 'ground-truth' features to train the detection module, which enhances the detection performance of the student network. We apply our framework to several popular detectors, including FCOS, Faster-RCNN, Mask-RCNN, and Cascase-RCNN, and conduct extensive ablation studies to validate its effectiveness and generality. Experimental results on the HRSC2016, DOTA, and NWPU VHR-10 datasets demonstrate that, when applying our framework to Faster-RCNN, our method can outperform several state-of-the-art detection methods in terms of mAP50 and mAP75.  © 2004-2012 IEEE.","Distillation; Feature extraction; Image enhancement; Remote sensing; Ships; Students; Ground truth; High resolution; High-resolution images; Knowledge distillation; Low resolution images; Mid-low-resolution image; Remote-sensing; Ship detection; Super-resolution; Superresolution; detection method; distillation; image analysis; image resolution; Optical resolving power","Knowledge distillation (KD); mid-low-resolution images; remote sensing; ship detection; super-resolution (SR)","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85121784865"
"Ibrahim M.R.; Benavente R.; Lumbreras F.; Ponsa D.","Ibrahim, Mohamed Ramzy (57214653554); Benavente, Robert (7007006606); Lumbreras, Felipe (6505807843); Ponsa, Daniel (6507631360)","57214653554; 7007006606; 6505807843; 6507631360","3DRRDB: Super Resolution of Multiple Remote Sensing Images using 3D Residual in Residual Dense Blocks","2022","IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops","2022-June","","","322","331","9","10.1109/CVPRW56347.2022.00047","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137769064&doi=10.1109%2fCVPRW56347.2022.00047&partnerID=40&md5=5319f89d1bad817ba564ec9332577508","The rapid advancement of Deep Convolutional Neural Networks helped in solving many remote sensing problems, especially the problems of super-resolution. However, most state-of-the-art methods focus more on Single Image Super-Resolution neglecting Multi-Image Super-Resolution. In this work, a new proposed 3D Residual in Residual Dense Blocks model (3DRRDB) focuses on remote sensing Multi-Image Super-Resolution for two different single spectral bands. The proposed 3DRRDB model explores the idea of 3D convolution layers in deeply connected Dense Blocks and the effect of local and global residual connections with residual scaling in Multi-Image Super-Resolution. The model tested on the Proba-V challenge dataset shows a significant improvement above the current state-of-the-art models scoring a Corrected Peak Signal to Noise Ratio (cPSNR) of 48.79 dB and 50.83 dB for Near Infrared (NIR) and RED Bands respectively. Moreover, the proposed 3DRRDB model scores a Corrected Structural Similarity Index Measure (cSSIM) of 0.9865 and 0.9909 for NIR and RED bands respectively © 2022 IEEE.","Convolution; Convolutional neural networks; Deep neural networks; Infrared devices; Optical resolving power; Signal to noise ratio; Block modeling; Convolutional neural network; Image super resolutions; Multi-images; Near Infrared; Near-infrared; Remote sensing images; Remote-sensing; Sensing problems; Superresolution; Remote sensing","","Conference paper","Final","","Scopus","2-s2.0-85137769064"
"Liu H.; Qian Y.; Zhong X.; Chen L.; Yang G.","Liu, Hui (57271529100); Qian, Yurong (26027209500); Zhong, Xiwu (57271946700); Chen, Long (57224988947); Yang, Guangqi (57326927600)","57271529100; 26027209500; 57271946700; 57224988947; 57326927600","Research on super-resolution reconstruction of remote sensing images: a comprehensive review","2021","Optical Engineering","60","10","100901","","","","10.1117/1.OE.60.10.100901","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118741379&doi=10.1117%2f1.OE.60.10.100901&partnerID=40&md5=f76aef96b8095594801f93d57cc91c23","The super-resolution (SR) reconstruction of remote sensing images is a low-cost and efficient method to improve their resolution, and it is often used for further image analysis. To understand the development of SR reconstruction of remote sensing images and research hotspots and trends, we examined its history and reviewed existing methods categorized into traditional, learning-based, and deep-learning-based methods. To evaluate the reconstruction performance, we conducted experiments comparing various algorithms for the single- and multi-frame SR reconstruction of remote sensing images considering three datasets. The experimental results indicate the advantages and limitations of single- and multi-frame reconstruction, with the latter showing a higher performance. Finally, we provide directions for future development of this SR reconstruction.  © 2021 Society of Photo-Optical Instrumentation Engineers (SPIE).","Deep learning; Image enhancement; Image reconstruction; Optical resolving power; Remote sensing; Hotspots; Image-analysis; Low-costs; Method categorized; Multi-frame; Performance; Remote sensing images; Single frames; Super-resolution reconstruction; Traditional learning; Image analysis","image analysis; methods categorized; remote sensing images; super-resolution reconstruction","Review","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85118741379"
"Ai J.; Fan G.; Mao Y.; Jin J.; Xing M.; Yan H.","Ai, Jiaqiu (35319586300); Fan, Gaowei (57263273200); Mao, Yuxiang (57221601419); Jin, Jing (57212715723); Xing, Mengdao (7005922869); Yan, He (55550832600)","35319586300; 57263273200; 57221601419; 57212715723; 7005922869; 55550832600","An Improved SRGAN Based Ambiguity Suppression Algorithm for SAR Ship Target Contrast Enhancement","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2021.3111553","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115129298&doi=10.1109%2fLGRS.2021.3111553&partnerID=40&md5=3a36826aa9ab1932d1845423a1b4cc1a","Due to the specific characteristics of synthetic aperture radar (SAR), there will be ambiguity interference in SAR images, resulting in low contrast of the ship target to the clutter. This letter proposes an improved super-resolution generative adversarial network (ISRGAN) based ambiguity suppression algorithm for SAR ship target contrast enhancement. The proposed ISRGAN is the first attempt of using GAN for SAR ambiguity suppression. As a post-processing procedure, it does not need prior information of SAR systems, so it can be applied to various observation scenes and different acquisition modes. The generator of ISRGAN embeds the residual dense network (RDN) to optimally fuse the global and local features of the image, and it effectively improves the completeness of the feature information used for SAR ship target contrast enhancement. The superiority of ISRGAN on ambiguity suppression is validated on the Chinese Gaofen-3 imagery.  © 2004-2012 IEEE.","Image enhancement; Radar imaging; Ships; Acquisition modes; Adversarial networks; Contrast Enhancement; Feature information; Post-processing procedure; Prior information; Super resolution; Suppression algorithm; accuracy assessment; algorithm; remote sensing; synthetic aperture radar; Synthetic aperture radar","Azimuth ambiguity suppression; improved super-resolution generative adversarial network (ISRGAN); synthetic aperture radar (SAR); target contrast enhancement","Article","Final","","Scopus","2-s2.0-85115129298"
"Kim H.-H.; Seo D.; Jung J.; Kim Y.","Kim, Hyun-Ho (57200532414); Seo, Doochun (57694220200); Jung, JaeHeon (57710642500); Kim, Yongwoo (57202143770)","57200532414; 57694220200; 57710642500; 57202143770","A Study on Lightweight CNN-based Interpolation Method for Satellite Images","2022","Korean Journal of Remote Sensing","38","2","","167","177","10","10.7780/kjrs.2022.38.2.3","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130126643&doi=10.7780%2fkjrs.2022.38.2.3&partnerID=40&md5=d4465758fdcd1df0e4fa5656655f1cba","In order to obtain satellite image products using the image transmitted to the ground station after capturing the satellite images, many image pre/post-processing steps are involved. During the pre/post-processing, when converting from level 1R images to level 1G images, geometric correction is essential. An interpolation method necessary for geometric correction is inevitably used, and the quality of the level 1G images is determined according to the accuracy of the interpolation method. Also, it is crucial to speed up the interpolation algorithm by the level processor. In this paper, we proposed a lightweight CNN-based interpolation method required for geometric correction when converting from level 1R to level 1G. The proposed method doubles the resolution of satellite images and constructs a deep learning network with a lightweight deep convolutional neural network for fast processing speed. In addition, a feature map fusion method capable of improving the image quality of multispectral (MS) bands using panchromatic (PAN) band information was proposed. The images obtained through the proposed interpolation method improved by about 0.4 dB for the PAN image and about 4.9 dB for the MS image in the quantitative peak signal-to-noise ratio (PSNR) index compared to the existing deep learning-based interpolation methods. In addition, it was confirmed that the time required to acquire an image that is twice the resolution of the 36,500×36,500 input image based on the PAN image size is improved by about 1.6 times compared to the existing deep learning-based interpolation method. © 2022 Sami Publishing Company. All rights reserved.","","Interpolation; Remote sensing; Satellite images; Super-resolution","Article","Final","","Scopus","2-s2.0-85130126643"
"Chen S.; Qi H.; Nan K.","Chen, Shiyu (57393347000); Qi, Hua (56542423700); Nan, Ke (57211431508)","57393347000; 56542423700; 57211431508","Pansharpening via Super-Resolution Iterative Residual Network with a Cross-Scale Learning Strategy","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3138096","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122089090&doi=10.1109%2fTGRS.2021.3138096&partnerID=40&md5=49c1c3b6916e2fb2cc2c8ed6b96e0557","Pansharpening exploits the high-spatial-resolution panchromatic (HR PAN) images to restore the spatial resolution of the corresponding low-spatial-resolution multi-spectral (LR MS) image, producing a fused image and high-spatial-resolution multi-spectral (HR MS) image. Recently, many methods based on convolutional neural networks (CNNs) have been put forth for the pansharpening task, but most of them still have some limitations, such as the simple stacked convolutional architectures resulting in information distortion, and some scale-related problems caused by the supervised learning strategy. Therefore, we propose a method named super-resolution iterative residual (SRIR) network with a cross-scale (CS) learning strategy to overcome these drawbacks. Regarding the SRIR we propose, we design an upsampling network based on a sub-pixel convolution structure to replace the traditional upsampling pre-processing. We adopt the iterative networks framework and design a new spatial information injection module to continuously inject spatial and spectral features into the network, which can enhance the information flow and transmission. We produce approximate HR MS with a guidance filter and map the residual information between the approximate HR MS and the reference HR MS by SRIR to enhance the quality of fused images. Regarding the CS we propose, we train the network at degraded scale, which is named deep prior, and then design a finer-scale unsupervised fine-tuning loss function to refine the network parameters with deep priors, to overcome the scale effect. Experiments show the following: 1) SRIR-based pansharpening method can obtain the best result at the degraded scale; 2) the scale-effect is negatively correlated with the depth of the network, meaning that the deeper the network, the stronger the robustness to scale effect; 3) the CS learning strategy can widely improve the performance of CNNs-based pansharpening methods in full-resolution; and 4) our method can produce better results at full-resolution scale than all the other traditional and deep learning methods.  © 1980-2012 IEEE.","Convolution; Deep learning; Image enhancement; Iterative methods; Neural networks; Signal sampling; Supervised learning; A super-resolution iterative residual network; Convolutional neural network; Cross-scale learning strategy; Fine tuning; Fine-scale; Fine-scale unsupervised fine-tuning loss function; Learning strategy; Loss functions; Neural-networks; Pan-sharpening; Residual neural network; Spatial resolution; Superresolution; artificial neural network; machine learning; remote sensing; spatial resolution; Image resolution","A super-resolution iterative residual (SRIR) network; Cross-scale (CS) learning strategy; Finer-scale unsupervised fine-tuning loss function; Pansharpening","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85122089090"
"Wang J.; Shao Z.; Huang X.; Lu T.; Zhang R.; Li Y.","Wang, Jiaming (57206676342); Shao, Zhenfeng (7202244409); Huang, Xiao (57201292422); Lu, Tao (56406646300); Zhang, Ruiqian (57190385256); Li, Yong (57223768875)","57206676342; 7202244409; 57201292422; 56406646300; 57190385256; 57223768875","From Artifact Removal to Super-Resolution","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5627715","","","","10.1109/TGRS.2022.3196709","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135754017&doi=10.1109%2fTGRS.2022.3196709&partnerID=40&md5=2ab1d77f49794834081a3f5fa02221d3","Deep-learning-based super-resolution (SR) methods have been extensively studied and have achieved significant performance with deep convolutional neural networks. However, the results still suffer from the ringing effect, especially in satellite image SR tasks, due to the loss of image details in the satellite degradation process. In this article, we build a novel satellite SR framework by decomposing a high-resolution image into three components, i.e., low-resolution (LR), artifact, and high-frequency information. Specifically, we propose an artifact removal network with a self-adaption difference convolution (SDC) to fully exploit the structure prior in the LR image and predict the artifact map. Considering that the artifact map and the high-frequency map share a similar pattern, we introduce the supervised structure correction (SSC) block that establishes a bridge between the high-frequency generation process and the artifact removal process. Experimental results on satellite images demonstrate that the proposed method owns an improved tradeoff between the performance and the computational cost compared to existing state-of-the-art satellite and natural SR methods. The source code is available at https://github.com/jiaming-wang/ARSRN.  © 1980-2012 IEEE.","Convolution; Deep neural networks; Edge detection; Generative adversarial networks; Image enhancement; Job analysis; Optical resolving power; Remote sensing; Satellites; Artifact removal; Difference convolution; Image edge detection; Images reconstruction; Performance; Remote-sensing; Superresolution; Superresolution methods; Task analysis; artificial neural network; image analysis; image resolution; remote sensing; satellite data; satellite imagery; Image reconstruction","Artifact removal; difference convolution; remote sensing; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85135754017"
"Xiao Y.; Su X.; Yuan Q.; Liu D.; Shen H.; Zhang L.","Xiao, Yi (57216363750); Su, Xin (57200950410); Yuan, Qiangqiang (36635300800); Liu, Denghong (57218290625); Shen, Huanfeng (8359721100); Zhang, Liangpei (8359720900)","57216363750; 57200950410; 36635300800; 57218290625; 8359721100; 8359720900","Satellite Video Super-Resolution via Multiscale Deformable Convolution Alignment and Temporal Grouping Projection","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3107352","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114712645&doi=10.1109%2fTGRS.2021.3107352&partnerID=40&md5=d92f85e82f429736bf5be83fea7bfa03","As a new earth observation tool, satellite video has been widely used in remote-sensing field for dynamic analysis. Video super-resolution (VSR) technique has thus attracted increasing attention due to its improvement to spatial resolution of satellite video. However, the difficulty of remote-sensing image alignment and the low efficiency of spatial–temporal information fusion make poor generalization of the conventional VSR methods applied to satellite videos. In this article, a novel fusion strategy of temporal grouping projection and an accurate alignment module are proposed for satellite VSR. First, we propose a deformable convolution alignment module with a multiscale residual block to alleviate the alignment difficulties caused by scarce motion and various scales of moving objects in remote-sensing images. Second, a temporal grouping projection fusion strategy is proposed, which can reduce the complexity of projection and make the spatial features of reference frames play a continuous guiding role in spatial–temporal information fusion. Finally, a temporal attention module is designed to adaptively learn the different contributions of temporal information extracted from each group. Extensive experiments on Jilin-1 satellite video demonstrate that our method is superior to current state-of-the-art VSR methods. © 2021 IEEE.","China; Jilin; Alignment; Convolution; Deformation; Information fusion; Optical resolving power; Satellites; Earth observations; Fusion strategies; Remote sensing images; Spatial features; Spatial resolution; Spatial temporals; Temporal information; Video super-resolution; optical instrument; remote sensing; satellite; spatial resolution; Remote sensing","Convolution; Image reconstruction; Optical imaging; Optical sensors; Remote sensing; Satellites; Spatial resolution","Article","Final","","Scopus","2-s2.0-85114712645"
"Jinzhen M.; Shuo Z.; Yu Z.; Yami F.; Yan Z.; Shuqing C.; Zongming L.","Jinzhen, Mu (57363206900); Shuo, Zhang (57363349800); Yu, Zhang (57223864009); Yami, Fang (57363057600); Yan, Zhou (57362767200); Shuqing, Cao (57363207000); Zongming, Liu (57362914400)","57363206900; 57363349800; 57223864009; 57363057600; 57362767200; 57363207000; 57362914400","Image Super-Resolution Using Quality Aware Generative Adversarial Networks","2022","Lecture Notes in Electrical Engineering","644 LNEE","","","1883","1893","10","10.1007/978-981-15-8155-7_158","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120644905&doi=10.1007%2f978-981-15-8155-7_158&partnerID=40&md5=8f29ad45aa44ec3901ff3a8bb7f73573","It has been demonstrated that GAN-based algorithms can generate realistic images in single image super-resolution. However, these methods usually generate undesired artifacts in the accompanied images. We proposes a new GAN-based super resolution method to further improve the performance of super-resolved results. In this fashion, we introduce dense compression unit as our basic unit. Then, we use an additional noise into the generator to enhance the quality of generator network. To enhance the supervision of texture recovery, we use a novel quality aware function that is inspired by the SSIM index as excellent regularizer for GAN objective functions. Finally, we demonstrate our method in extensive experiments that the generated images has more realistic textures and it has a great potential in remote sensing tiny-object detection. © 2022, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Generative adversarial networks; Object detection; Remote sensing; Textures; Basic units; Content loss; Image super resolutions; Performance; Quality aware; Realistic images; Single images; SSIM indices; Superresolution; Superresolution methods; Optical resolving power","Content loss; Generative adversarial networks; Quality aware; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85120644905"
"Sarkar D.; Gunturi S.K.","Sarkar, Dipu (57206206698); Gunturi, Sravan Kumar (57219345730)","57206206698; 57219345730","Wind turbine blade structural state evaluation by hybrid object detector relying on deep learning models","2021","Journal of Ambient Intelligence and Humanized Computing","12","8","","8535","8548","13","10.1007/s12652-020-02587-7","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092273043&doi=10.1007%2fs12652-020-02587-7&partnerID=40&md5=caf80f5638736c57a4cb89f908d379c5","Surveillance drones are remarkable devices for monitoring, as they have strong spatial and remote sensing capabilities. The prompt detection of peripheral damage to the blades of wind turbines is necessary to reduce downtime and prevent the potential failure of wind farms. Computer vision breakthroughs with deep learning have developed and been refined over time, mainly using convolution neural networks. From this perspective, we suggest a deep learning model for monitoring and diagnosing the blade health of wind turbines based on images captured by surveillance drones. The main limitations of standard monitoring devices are their poor detection accuracy and lack of real-time performance, making it complex to obtain the attributes of blades from aerial images. Based on the foregoing, this study introduces a method for increasing detection accuracy when carrying out operations in real time using You Only Look at Once version 3 (YOLOv3). We train and evaluate three deep learning models on the wind turbine image dataset. We find that many aerial images are unclear because of blurred motion. As avoiding such low-resolution images for training can affect accuracy, we use a super-resolution convolution neural network to reconstruct a blurred picture as a high-resolution one. The computational results demonstrate that YOLOv3 outperforms traditional models in terms of both accuracy and handling time. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Antennas; Convolution; Damage detection; Drones; Learning systems; Neural networks; Object detection; Remote sensing; Turbine components; Turbomachine blades; Wind power; Wind turbines; Computational results; Convolution neural network; Detection accuracy; Low resolution images; Potential failures; Real time performance; Traditional models; Wind turbine blades; Deep learning","Renewable energy; Surveillance drones; Wind turbine; YOLOv3","Article","Final","","Scopus","2-s2.0-85092273043"
"Mao D.; Yang J.; Zhang Y.; Huo W.; Luo J.; Pei J.; Zhang Y.; Huang Y.","Mao, Deqing (57194656090); Yang, Jianyu (9239230100); Zhang, Yongchao (56042343300); Huo, Weibo (56405211000); Luo, Jiawei (57221234005); Pei, Jifang (55787739300); Zhang, Yin (55975581400); Huang, Yulin (23014806800)","57194656090; 9239230100; 56042343300; 56405211000; 57221234005; 55787739300; 55975581400; 23014806800","Angular Superresolution of Real Aperture Radar Using Online Detect-Before-Reconstruct Framework","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3139355","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122560127&doi=10.1109%2fTGRS.2021.3139355&partnerID=40&md5=76d662096c8aec04162df1d5cc0c7190","Superresolution methods can be applied to real aperture radar (RAR) to improve its angular resolution by solving an inverse problem. However, traditional superresolution methods are achieved after batch data collection, which requires extensive operational complexity and storage space. To solve this problem for RAR, an online detect-before-reconstruct (DBR) framework is proposed in this article based on the sparse property of targets. First, along the range direction, each sample of the echo data is detected to reduce the computational complexity by reducing the dimension of the effective data. Second, along the azimuth direction, a data-adaptive online processing structure is proposed to reduce the storage requirement for the angular superresolution problem. Finally, within the online processing structure, a target data-adaptive updating strategy is proposed to reduce the number of iterations for each target grid. The online DBR-based framework can effectively reduce the operational complexity caused by the noise values of the echo data. Based on the proposed online processing structure, the storage requirement and the operational complexity of the angular superresolution for an RAR system can be greatly reduced without significant reconstruction performance loss. The results of simulations and experimental data verify the proposed framework.  © 1980-2012 IEEE.","Data reduction; Digital storage; Inverse problems; Inverse synthetic aperture radar; Optical resolving power; Problem solving; Radar antennas; Space-based radar; Angular super-resolution imaging; Aperture; Azimuth; Complexity theory; Online detect-before-reconstruct framework; Operational complexity; Radars antennas; Real aperture radar; Super resolution imaging; Superresolution; complexity; image analysis; remote sensing; satellite data; synthetic aperture radar; Radar imaging","Angular super-resolution imaging; Online detect-before-reconstruct (DBR) framework; Real aperture radar (RAR)","Article","Final","","Scopus","2-s2.0-85122560127"
"Zhao M.; Ning J.; Hu J.; Li T.","Zhao, Minghua (55477788900); Ning, Jiawei (57214794541); Hu, Jing (57191473546); Li, Tingting (57226062696)","55477788900; 57214794541; 57191473546; 57226062696","Hyperspectral image super-resolution under the guidance of deep gradient information","2021","Remote Sensing","13","12","2382","","","","10.3390/rs13122382","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109024996&doi=10.3390%2frs13122382&partnerID=40&md5=e76a3cfa8aaa207216148050d574e072","Hyperspectral image (HSI) super-resolution has gained great attention in remote sensing, due to its effectiveness in enhancing the spatial information of the HSI while preserving the high spectral discriminative ability, without modifying the imagery hardware. In this paper, we proposed a novel HSI super-resolution method via a gradient-guided residual dense network (G-RDN), in which the spatial gradient is exploited to guide the super-resolution process. Specifically, there are three modules in the super-resolving process. Firstly, the spatial mapping between the low-resolution HSI and the desired high-resolution HSI is learned via a residual dense network. The residual dense network is used to fully exploit the hierarchical features learned from all the convolutional layers. Meanwhile, the gradient detail is extracted via a residual network (ResNet), which is further utilized to guide the super-resolution process. Finally, an empirical weight is set between the fully obtained global hierarchical features and the gradient details. Experimental results and the data analysis on three benchmark datasets with different scaling factors demonstrated that our proposed G-RDN achieved favorable performance. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Benchmarking; Image enhancement; Remote sensing; Spectroscopy; Benchmark datasets; Discriminative ability; Gradient informations; Hierarchical features; Image super resolutions; Spatial gradients; Spatial informations; Superresolution methods; Optical resolving power","Hyperspectral image (HSI); Residual dense network (RDN); Spatial gradient; Super-resolution (SR)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85109024996"
"Hu J.; Zhang Y.; Zhao M.; Li P.; Li Y.","Hu, Jing (57191473546); Zhang, Yujing (57227204200); Zhao, Minghua (55477788900); Li, Peng (57199005531); Li, Yunsong (55986546100)","57191473546; 57227204200; 55477788900; 57199005531; 55986546100","Transformation of local gradient profiles for hyperspectral anomaly detection; [局部梯度轮廓变换的高光谱异常检测]","2021","Journal of Image and Graphics","26","8","","1847","1859","12","10.11834/jig.210148","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113301944&doi=10.11834%2fjig.210148&partnerID=40&md5=808f30de20402a728db851496b55cf1a","Objective: Anomaly detection is a fundamental problem in hyperspectral remote sensing image processing, and it attracts the interests of several researchers. The anomalies usually refer to the outliers with spectral and spatial signatures that differ from their surroundings. Compared with the background, the anomalies have two main characteristics. First, their spectra are severely different from those of their surroundings, and this phenomenon is called the spectral difference. Meanwhile, the anomalies are usually embedded into the local homogeneous background in a format of several pixels, and this phenomenon is named the spatial difference. Hyperspectral anomaly detection has been widely used in military and civilian applications, such as surveillance, disaster warning, and rescue. In most traditional approaches, anomalies are directly derived from the original hyperspectral image (HSI). However, the HSIs usually deviate from the real scene as limited by the imagery process, such as the complexity of the imagery condition and the limited number of electrons caused by the hundreds of bands. This deviation could reduce the anomaly detection precision. We propose a novel hyperspectral anomaly detection method via the transformation of local gradient profiles to deal with the limitations caused by the low spatial quality. The gradient profile is a 1D profile along the gradient direction of the edge pixel in the image and has been introduced in natural image super resolution. Observations have demonstrated that the shape statistics of the gradient profiles in natural image is quite stable and invariant. In this way, the statistical relationship of the sharpness of the gradient profile between the real scene and the input HSI can be utilized to transform the gradient profiles of the input HSI. Meanwhile, the transformation is applied locally to some probable anomalies to reduce the computational complexity and avoid the disturbance of the background. These transformed gradient profiles are used to provide a constraint on the enhanced HSI. Method: A novel hyperspectral anomaly detection method is proposed in this study. Some probable anomalies are coarsely selected via a threshold to reduce the computational complexity without affecting the detection performance. Specifically, the original HSI is detected via the classical Global-RX(Reed Xiaoli) detector, and the responses in the map are sorted and selected. Meanwhile, the gradient profiles of these coarsely selected anomalies are computed and transformed to obtain the sharper versions. Specifically, the distribution of the gradient profile is fitted by a generalized Gaussian distribution. The transformation from the input gradient profile to the desired one can be computed via a transformation formulation. These transformed gradient profiles are closer to those of the real scene than the original gradient profiles. The original HSI is enhanced with these transformed gradient profiles. Experimental data contain six real HSIs coming from four datasets. The original six HSIs and their enhanced versions are detected via the Global-RX detector. Experimental results demonstrate the necessity of the enhancement. Meanwhile, experimental results on detection accuracy superiority of the proposed method over some other preprocessing techniques, such as the discrete wavelet transformation (DWT-RX), the spectral derivatives (Deriv-RX), and the fractional Fourier entropy (FrFE-RX), further validate the effectiveness of our proposed local gradient profile transformation strategy. We utilize the collaborative representation-based detector (CRD) to detect the enhanced and original HSIs. The enhanced HSIs still achieve higher detection accuracy. Result: We incorporate six HSIs coming from four datasets, namely, San Diego, AVIRIS(airborne visible/infrared imaging spectrometer)-2, Airport, and Beach, to validate the performance of the proposed method. The quantitative evaluation metrics include the receiver operating curves and the area under the curve (AUC) value. We also exhibit the detection maps of each method for comparison. We validate the necessity of the enhancement. Thus, comparison of detection accuracy is made between the original and enhanced HSIs via the Global-RX detector. AUC values for the six original HSIs are 0.940 2, 0.934 1, 0.840 3, 0.952 5, 0.980 6, and 0.953 8, respectively. The corresponding AUC values for the enhanced HSIs are 0.977 8, 0.984 9, 0.983 5, 0.982 4, 0.998 6, and 0.995 6. Notably, the enhanced HSI always achieves a higher detection accuracy than the original HSI, which proves the necessity of the enhancement. We also compare our proposed method with three other preprocessing techniques, namely, the DWT-RX, Deriv-RX, and the FrFE-RX, which have average AUC values of 0.956 8, 0.957 9, and 0.964 0, respectively. Our proposed method with an average AUC value of 0.987 1 outperforms all the comparison methods. We also utilize the CRD to further validate the effectiveness of our proposed method. The AUC values for the original HSIs detected by the CRD are 0.977 4, 0.985 5, 0.983 6, 0.977 2, 0.991 6, and 0.939 3. The corresponding AUC values for the enhanced HSIs also detected by the CRD are 0.984 0, 0.987 7, 0.990 3, 0.988 8, 0.998 5, and 0.995 0. Notably, enhanced HSIs always outperform the original HSI via the CRD detector. Therefore, the gradient profile transformation is not only effective in promoting the detection accuracy but also outperforms the other preprocessing techniques. Comparing the time required by local and global gradient contour transforms shows that the former can reduce the time complexity by approximately 37.82%. Conclusion: In this study, we propose a novel hyperspectral anomaly detection method that incorporates a local gradient profile transformation to enhance the spatial information of the HSIs before detection. The experiment is conducted on six HSIs from four datasets. Experimental results show that our method outperforms several state-of-the-art anomaly detection approaches. The enhanced HSI and original HSI are detected by the Global-RX and the CRD, respectively. The experimental data demonstrate that the enhanced HSI always achieves a superior detection accuracy. © 2021, Editorial Office of Journal of Image and Graphics. All right reserved.","","Anomaly detection; Gradient profiles; Hyperspectral; Information enhancement; Remote sensing image","Article","Final","","Scopus","2-s2.0-85113301944"
"Ma Y.; Lv P.; Liu H.; Sun X.; Zhong Y.","Ma, Yunchuan (57226633426); Lv, Pengyuan (57102806500); Liu, Hao (56275670700); Sun, Xuehong (56962935200); Zhong, Yanfei (12039673900)","57226633426; 57102806500; 56275670700; 56962935200; 12039673900","Remote sensing image super-resolution based on dense channel attention network","2021","Remote Sensing","13","15","2966","","","","10.3390/rs13152966","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112131956&doi=10.3390%2frs13152966&partnerID=40&md5=666c9988712d535fd78aff6714ef1c54","In the recent years, convolutional neural networks (CNN)-based super resolution (SR) methods are widely used in the field of remote sensing. However, complicated remote sensing images contain abundant high-frequency details, which are difficult to capture and reconstruct effectively. To address this problem, we propose a dense channel attention network (DCAN) to reconstruct high-resolution (HR) remote sensing images. The proposed method learns multi-level feature information and pays more attention to the important and useful regions in order to better reconstruct the final image. Specifically, we construct a dense channel attention mechanism (DCAM), which densely uses the feature maps from the channel attention block via skip connection. This mechanism makes better use of multi-level feature maps which contain abundant high-frequency information. Further, we add a spatial attention block, which makes the network have more flexible discriminative ability. Experimental results demonstrate that the proposed DCAN method outperforms several state-of-the-art methods in both quantitative evaluation and visual quality. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural networks; Image reconstruction; Optical resolving power; Attention mechanisms; Discriminative ability; Feature information; High frequency HF; High-frequency informations; Quantitative evaluation; Remote sensing images; State-of-the-art methods; Remote sensing","Attention mechanism; Dense network; Remote sensing images; Super resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85112131956"
"Zhang Z.; Zhang J.; Liu C.","Zhang, Zheng (57256240100); Zhang, Jiabin (57276731200); Liu, Changan (57260783600)","57256240100; 57276731200; 57260783600","Multi-channel feature extraction and super-resolution reconstruction of remote sensing images","2021","Journal of Physics: Conference Series","2006","1","012031","","","","10.1088/1742-6596/2006/1/012031","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115014820&doi=10.1088%2f1742-6596%2f2006%2f1%2f012031&partnerID=40&md5=bad8b0b25ba934c879c90148f3d6ebd5","Super-resolution reconstruction is an imaging method to improve image resolution. It refers to reconstruct a clear high-resolution image from a low-resolution image. High-resolution remote sensing images can provide more detailed information and higher density, but in the field of remote sensing, because of the limitation of the hardware and vast distances, the remote sensing images are fuzzy sometimes. To facilitate subsequent tasks, this paper proposes a multi-channel feature extraction generative adversarial remote sensing image reconstruction method. According to the characteristics of remote sensing image, a generator is designed, which adds Laplace operator to enhance the edge information of the image, and uses multi-channel feature extraction, which not only enhances the ability of feature extraction but also reduces the number of parameters. In this paper, the super-resolution reconstruction task is carried out based on the 2X magnification factor, and the experimental results are evaluated on SET5/14 and NWPU-RESISC45 dataset. The experimental results show that the images generated by this method have a higher detailed texture and better super-resolution reconstruction effect of remote sensing images. © 2021 Institute of Physics Publishing. All rights reserved.","Extraction; Feature extraction; Image enhancement; Image reconstruction; Image resolution; Optical resolving power; Textures; Edge information; High resolution image; High resolution remote sensing images; Laplace operator; Low resolution images; Magnification factors; Remote sensing images; Super resolution reconstruction; Remote sensing","","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85115014820"
"Yilmaz V.","Yilmaz, Volkan (57004516700)","57004516700","A comprehensive investigation of image fusion methods for spatial enhancement of hyperspectral images","2022","International Journal of Remote Sensing","43","11","","4151","4186","35","10.1080/01431161.2022.2109223","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136524797&doi=10.1080%2f01431161.2022.2109223&partnerID=40&md5=e404254c5bc27a8bb027e0e7b3cc1c60","The coarse spatial resolutions of hyperspectral (HS) satellite images limit their use in many applications. The spatial structure quality of HS images can be improved by fusing them either with higher-resolution panchromatic (PAN) images, or with higher-resolution multispectral (MS) images. Fusion of HS images can be done with fusion methods that are designed to fuse MS and PAN images, and the fusion methods developed for the fusion of HS and MS images. A wide variety of HS-MS and MS-PAN image fusion techniques can be used for the fusion of HS images, which leads the users to a hesitation as to which method(s) should be used for optimal fusion performance. Hence, the current study aimed to qualitatively and quantitatively assess the HS image fusion performances of a total of 15 MS-PAN image fusion methods and 17 state-of-the-art HS-MS image fusion techniques within four experiments, with the hope to give some clues on the performances of the fusion techniques used. Experiments showed that the HS-MS fusion methods exhibited much better HS image fusion performance, compared to the MS-PAN fusion methods used. It was also concluded that the coupled nonnegative matrix factorization (CNMF), convolutional neural network (CNN) denoiser-based method (CNN-D), HS super-resolution (HySure) and fast fusion based on Sylvester equation with naive Gaussian prior (FUSE-G) techniques provided the most robust fusion results. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Hyperspectral imaging; Image fusion; Matrix algebra; Matrix factorization; Neural networks; Remote sensing; Spectroscopy; Fusion methods; Fusion performance; High resolution; HyperSpectral; Hyperspectral image fusions; Image fusion methods; Image fusion techniques; Multi-spectral; Multispectral images; Remote-sensing; image analysis; image classification; image resolution; remote sensing; spatiotemporal analysis; spectral analysis; Image enhancement","hyperspectral imaging; image enhancement; Image fusion; remote sensing","Article","Final","","Scopus","2-s2.0-85136524797"
"Khader A.; Yang J.; Xiao L.","Khader, Abdolraheem (57641899100); Yang, Jingxiang (55964111200); Xiao, Liang (9733464300)","57641899100; 55964111200; 9733464300","NMF-DuNet: Nonnegative Matrix Factorization Inspired Deep Unrolling Networks for Hyperspectral and Multispectral Image Fusion","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","5704","5720","16","10.1109/JSTARS.2022.3189551","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134272216&doi=10.1109%2fJSTARS.2022.3189551&partnerID=40&md5=08f8f6f817fd0ebca6db573889499310","The fusion of high-resolution multispectral image (HrMSI) and low-resolution hyperspectral image (LrHSI) has been acknowledged as a promising method for generating a high-resolution hyperspectral image (HrHSI), which is also termed to be an essential part for precise recognition and cataloguing of the underlying materials. In order to improve the fusion of the LrHSI and HrMSI performance, in this article, we propose a novel nonnegative matrix factorization inspired deep unrolling networks (NMF-DuNet) for fusing LrHSI and HrMSI. For this aim, initially, a variational fusion model regularized by nonnegative sparse prior is proposed and then is solved through the gradient descent optimization method and unrolled towards the deep network. The nonnegative coefficient matrices and orthogonal of the proposed transform coefficients constraints are both incorporated into the proposed method. Moreover, the fusion of HrMSI and LrHSI heavily depends on an imaging model that explains the degeneracy of HSI in the spectral and spatial regions. Practically, the imaging model is often unknown. The degradation model is represented implicitly via a proposed network, and both the degradation model and sparse priors are jointly optimized through the training process of the proposed network. Instead of being hand-crafted, all the parameters of NMF-DuNet are learned end-to-end. Compared to the previous state-of-the-art model-based and learning-based fusion approaches, the hardware-friendly proposed NMF-DuNet outperforms both the model-based and learning-based fusion approaches and requires a far smaller number of trainable parameters and storage space while preserving the real-time performance.  © 2008-2012 IEEE.","Deep learning; Image coding; Image fusion; Matrix algebra; Matrix factorization; Optimization; Spectroscopy; Computational modelling; Deep learning; HyperSpectral; Hyperspectral image superresolution; Image super resolutions; Lower resolution; Sparse coding; Sparse matrices; Spatial resolution; image resolution; machine learning; multispectral image; remote sensing; Hyperspectral imaging","Deep learning; hyperspectral image superresolution; hyperspectral imaging; images fusion; sparse coding (SC)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85134272216"
"Liu N.; Li W.; Tao R.","Liu, Na (57195673776); Li, Wei (57189633632); Tao, Ran (7102857080)","57195673776; 57189633632; 7102857080","GEOMETRIC LOW-RANK TENSOR APPROXIMATION FOR REMOTELY SENSED HYPERSPECTRAL AND MULTISPECTRAL IMAGERY FUSION","2022","ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","2022-May","","","2819","2823","4","10.1109/ICASSP43922.2022.9746041","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131226957&doi=10.1109%2fICASSP43922.2022.9746041&partnerID=40&md5=4e4fbf2a4b03d98d120e40baf77dc1a2","Improving the spatial resolution of a hyperspectral image (HSI) is of great significance in the remotely sensed field. By fusing a high-spatial-resolution multispectral image (MSI) with an HSI collected from the same scene, hyperspectral and multispectral (HS-MS) fusion has been an emerging technique to address the issue. Extracting complex spatial information from MSIs while maintaining abundant spectral information of HSIs is essential to generate the fused high-spatial-resolution HSI (HS2I). A common way is to learn low-rank/sparse representations from HSI and MSI, then reconstruct the fused HS2I based on tensor/matrix decomposition or unmixing paradigms, which ignore the intrinsic geometry proximity inherited by the low-rank property of the fused HS2I. This study proposes to estimate the high-resolution HS2I via low-rank tensor approximation with geometry proximity as side information learned from MSI and HSI by defined graph signals, which we name GLRTA. Row graph Gr and column graph Gc are defined on the horizontal slice and lateral slice of MSI tensor M respectively, while spectral band graph Gb is defined on a frontal slice of HSI tensor H. Experimental results demonstrate that the proposed GLRTA can effectively improve the reconstruction results compared to other competitive works. © 2022 IEEE","Geometry; Graph theory; Image enhancement; Image fusion; Image resolution; Spectroscopy; Tensors; Graph G; Graph signal processing; Hyper-spectral imageries; HyperSpectral; Image tensors; Low-rank tensor approximations; Multispectral images; Remote-sensing; Signal-processing; Superresolution; Remote sensing","Graph signal processing; hyperspectral imagery; low-rank tensor approximation; remote sensing; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85131226957"
"Zhang L.; Lu W.; Huang Y.; Sun X.; Zhang H.","Zhang, Lize (57233449400); Lu, Wen (55484285200); Huang, Yuanfei (57203161002); Sun, Xiaopeng (57201075215); Zhang, Hongyi (35748167800)","57233449400; 55484285200; 57203161002; 57201075215; 35748167800","Unpaired remote sensing image super-resolution with multi-stage aggregation networks","2021","Remote Sensing","13","16","3167","","","","10.3390/rs13163167","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113645201&doi=10.3390%2frs13163167&partnerID=40&md5=9576728e45d6e5c535405f46b866fb2e","Mainstream image super-resolution (SR) methods are generally based on paired training samples. As the high-resolution (HR) remote sensing images are difficult to collect with a limited imaging device, most of the existing remote sensing super-resolution methods try to down-sample the collected original images to generate an auxiliary low-resolution (LR) image and form a paired pseudo HR-LR dataset for training. However, the distribution of the generated LR images is generally inconsistent with the real images due to the limitation of remote sensing imaging devices. In this paper, we propose a perceptually unpaired super-resolution method by constructing a multi-stage aggregation network (MSAN). The optimization of the network depends on consistency losses. In particular, the first phase is to preserve the contents of the super-resolved results, by constraining the content consistency between the down-scaled SR results and the low-quality low-resolution inputs. The second stage minimizes perceptual feature loss between the current result and LR input to constrain perceptual-content consistency. The final phase employs the generative adversarial network (GAN) to adding photo-realistic textures by constraining perceptual-distribution consistency. Numerous experiments on synthetic remote sensing datasets and real remote sensing images show that our method obtains more plausible results than other SR methods quantitatively and qualitatively. The PSNR of our network is 0.06dB higher than the SOTA method—HAN on the UC Merced test set with complex degradation. © 2021 by the authors.","Imaging techniques; Optical resolving power; Textures; Adversarial networks; Aggregation network; Content consistency; Image super resolutions; Low resolution images; Remote sensing images; Remote sensing imaging; Superresolution methods; Remote sensing","Consistency losses; Multi-stage aggregation network; Remote sensing; Unpaired super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85113645201"
"Guo D.; Xia Y.; Xu L.; Li W.; Luo X.","Guo, Dongen (36720716400); Xia, Ying (36626744600); Xu, Liming (57210788847); Li, Weisheng (36067507500); Luo, Xiaobo (36562124600)","36720716400; 36626744600; 57210788847; 36067507500; 36562124600","Remote sensing image super-resolution using cascade generative adversarial nets","2021","Neurocomputing","443","","","117","130","13","10.1016/j.neucom.2021.02.026","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103100487&doi=10.1016%2fj.neucom.2021.02.026&partnerID=40&md5=13eeb3f927de11ca22dbba68502dde7c","Image super-resolution (SR) is a widely used and cost-effective technology in remote sensing image processing. Deep learning-based SR methods have shown promising performance, but they are prone to losing texture details. Instead, generative adversarial nets (GAN)-based methods can generate more visually acceptable results. However, GAN-based SR methods are suffering from scene variance and uncontrollable performance of discriminators as well as unstable training. Besides, both these two methods cannot yield arbitrary high-time SR images. To solve these issues, we propose a novel SR method for remote sensing images using Cascade Generative Adversarial Nets (CGAN) with introduction of content fidelity and scene constraint, which can achieve arbitrary high-time high-quality SR image. More specifically, the scene-constraint item is incorporated to constrain generated feature for avoiding the risk of scene change. Then, content fidelity is introduced to stabilize the training and avoid gradient vanishing. Besides, an edge enhancement module is designed to preserve edge detail and suppress the noise. CGAN with these three components has achieved higher quality SR results than other recent state-of-the-art methods. Compared with these methods, our proposed method outperformed average increments of 7.3% SSIM, 7.3% FSIM and 6.0% MSIM on WHU-RS19 and NWPU-RESISC45 datasets. In addition, the evaluation of GAN-train and GAN-test gained average increments of 6.3% and 4.5% on the WHU-RS19 and AID datasets, respectively. © 2021 Elsevier B.V.","Cost effectiveness; Deep learning; Image enhancement; Optical resolving power; Textures; Cascade structures; Content fidelity; Edge enhancements; Generative adversarial net; Image super resolutions; Performance; Remote sensing images; Scene constraints; Super resolution; Superresolution methods; article; deep learning; image processing; noise; remote sensing; Remote sensing","Cascade structure; Content fidelity; Edge enhancement; Generative adversarial nets; Remote sensing image; Scene constraint","Article","Final","","Scopus","2-s2.0-85103100487"
"He Z.; Li J.; Liu L.; He D.; Xiao M.","He, Zhi (36604533800); Li, Jun (24481713500); Liu, Lin (55715201000); He, Dan (57216097405); Xiao, Man (57222244031)","36604533800; 24481713500; 55715201000; 57216097405; 57222244031","Multiframe Video Satellite Image Super-Resolution via Attention-Based Residual Learning","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3072381","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107180087&doi=10.1109%2fTGRS.2021.3072381&partnerID=40&md5=041021fd5f2ec4f4a5b4ea8668d2a604","Video satellite can generate video image sequences with rich dynamic information, thus providing a new way for monitoring moving objects. However, to maintain high temporal resolution, video satellite images usually sacrifice their spatial resolution. Therefore, super-resolution (SR) plays a vital role in improving the quality of video satellite images. In this article, we propose a multiframe video SR neural network (MVSRnet) for video satellite image SR reconstruction. The proposed MVSRnet consists of three main subnetworks: an optical flow estimation subnetwork (OFEnet), an upscaling subnetwork (Upnet) and an attention-based residual learning subnetwork (ARLnet). The OFEnet aims to estimate low-resolution (LR) optical flow of multiple image frames. Upnet is then constructed to enhance the resolution of both input frames and the estimated LR optical flows. Motion compensation is subsequently performed according to the high-resolution (HR) optical flows. Finally, the compensated HR cube is fed to the ARLnet to generate SR results. Different from existing video satellite image SR methods, the proposed MVSRnet is a multiframe-based method with an attention mechanism, which can merge the motion information among adjacent frames and highlight the importance of extracted features. Experiments conducted on Jilin-1 and OVS-1 video satellite images demonstrate that the proposed MVSRnet significantly outperforms some state-of-the-art SR methods.  © 1980-2012 IEEE.","Image enhancement; Motion compensation; Optical flows; Optical resolving power; Satellites; Attention mechanisms; High temporal resolution; Motion information; Optical flow estimation; Quality of videos; Spatial resolution; State of the art; Video image sequences; artificial neural network; image resolution; satellite imagery; videography; Image reconstruction","Attention; Multiframe super-resolution (SR); Optical flow estimation; Remote sensing; Residual learning; Video satellite","Article","Final","","Scopus","2-s2.0-85107180087"
"Li D.","Li, Dezheng (57408408400)","57408408400","Research on mathematical optimization algorithm for image processing problem","2021","ACM International Conference Proceeding Series","","","3501497","483","486","3","10.1145/3501409.3501497","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122652729&doi=10.1145%2f3501409.3501497&partnerID=40&md5=34f20f9467d2b41142c1be638e85e9a7","Since the film camera came into being, image has become one of the most important ways for people to record scene information. Especially with the rapid development of digital imaging technology and electronic communication in recent years, image has become one of the most important ways of human cognition of the world. Thanks to the development of science and technology, there are more and more kinds of imaging equipment, such as NUCLEAR magnetic resonance imaging equipment in medical imaging system, synthetic aperture radar widely used in the military field, multi-spectral scanner for remote sensing imaging carried on aircraft or satellites, etc. The images acquired by these new imaging devices are increasingly being studied by scholars. This thesis mainly studies how to design a reasonable mathematical optimization model and an efficient solving algorithm to solve related problems when digital camera image is affected by noise, blur, low resolution, scratch and ink. This paper focuses on three important problems in image processing, which are image denoising and blur removal, image super-resolution and image repair. Therefore, the study of these three image problems has very important practical application value. In particular, these three image problems have the same characteristics. They can be regarded as inverse problems, can be solved by mathematical optimization model, and can be regarded as image restoration problems. © 2021 ACM.","Digital devices; Image denoising; Image reconstruction; Inverse problems; Magnetic resonance imaging; Medical imaging; Military applications; Military photography; Optical resolving power; Optimization; Radar imaging; Remote sensing; Synthetic aperture radar; Algorithms optimizations; Image problem; Image processing problems; Image repair; Image super resolutions; Images processing; Imaging equipment; Mathematical optimization model; Mathematical optimizations; Optimization algorithms; Photographic films","Algorithm optimization; image processing; image repair; image super-resolution","Conference paper","Final","","Scopus","2-s2.0-85122652729"
"Ayala C.; Aranda C.; Galar M.","Ayala, C. (55642388700); Aranda, C. (57211636468); Galar, M. (35731257600)","55642388700; 57211636468; 35731257600","Towards fine-grained road maps extraction using sentinel-2 imagery","2021","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","3","","9","14","5","10.5194/isprs-annals-V-3-2021-9-2021","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113177615&doi=10.5194%2fisprs-annals-V-3-2021-9-2021&partnerID=40&md5=6e43dc8fe386c565d1ada49f03483778","Nowadays, it is highly important to keep road maps up-to-date since a great deal of services rely on them. However, to date, these labours have demanded a great deal of human attention due to their complexity. In the last decade, promising attempts have been carried out to fully-automatize the extraction of road networks from remote sensing imagery. Nevertheless, the vast majority of methods rely on aerial imagery (< 1 m), whose costs are not yet affordable for maintaining up-to-date maps. This work proves that it is also possible to accurately detect roads using high resolution satellite imagery (10 m). Accordingly, we have relied on Sentinel-2 imagery considering its freely availability and the higher revisit times compared to aerial imagery. It must be taken into account that the lack of spatial resolution of this sensor drastically increases the difficulty of the road detection task, since the feasibility to detect a road depends on its width, which can reach sub-pixel size in Sentinel-2 imagery. For that purpose, a new deep learning architecture which combines semantic segmentation and super-resolution techniques is proposed. As a result, fine-grained road maps at 2.5 m are generated from Sentinel-2 imagery.  © Author(s) 2021.","Aerial photography; Antennas; Deep learning; Extraction; Image segmentation; Remote sensing; Roads and streets; Semantics; Aerial imagery; High resolution satellite imagery; Human attention; Learning architectures; Remote sensing imagery; Semantic segmentation; Spatial resolution; Super resolution; Satellite imagery","Convolutional Neural Networks; Deep Learning; Remote Sensing; Road Network Extraction; Sentinel-2","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85113177615"
"Guan X.; Zeng B.; Song X.; Gan T.; Chen J.","Guan, Xiaoling (57867304300); Zeng, Bowen (57867304400); Song, Xinning (57866509400); Gan, Tian (57867106700); Chen, Jiaqi (48160919100)","57867304300; 57867304400; 57866509400; 57867106700; 48160919100","Dynamic monitoring of urban expansion and economic development in Beijing based on multisource remote sensing images","2022","CTISC 2022 - 2022 4th International Conference on Advances in Computer Technology, Information Science and Communications","","","","","","","10.1109/CTISC54888.2022.9849808","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136976058&doi=10.1109%2fCTISC54888.2022.9849808&partnerID=40&md5=4719bf15f5a4c55979bfbb7973354b50","The rapid development of society has promoted the development of urbanization process. Impervious surface area as the most prominent feature of the urbanization process, accurate monitoring of its temporal and spatial dynamics plays a key role in comprehensive understanding the urbanization process. As a comprehensive technology of earth observation, remote sensing technology provides a fast and convenient way for urban expansion trend analysis with its characteristics of macroscopical, accurate and timely. Based on the time domain spectral characteristics of Landsat-8 remote sensing images and spectral indexes such as NDBI, NDVI and DEM, this paper uses the random forest classification algorithm in Google Earth Engine to extract the impervious surface area of Beijing in 2014, 2017 and 2020. The classification results are verified based on 2000 randomly selected verification points from high-resolution Google Earth images. The results show that the random forest classification algorithm based on GEE has high classification accuracy (the overall accuracy is higher than 95%, and the kappa coefficient is higher than 0.90). In addition, Nighttime light remote sensing image can reflect economy. Super-resolution convolutional neural network can improve the resolution of images. Combining the classification results with high-resolution NPP/VIIRS images, the dynamics of urban expansion and economic development can be clearly demonstrated.  © 2022 IEEE.","Decision trees; Economic and social effects; Expansion; Image enhancement; Random forests; Remote sensing; Time domain analysis; Beijing; Economic development; GEE; Impervious surface area; LANDSAT; Landsat-8; NPP/VIIRS; Random forests; SRCNN; Urban expansion; Landsat","Beijing; GEE; impervious surface area; Landsat-8; NPP/VIIRS; random forest; SRCNN","Conference paper","Final","","Scopus","2-s2.0-85136976058"
"Cresson R.","Cresson, Rémi (6508246223)","6508246223","SR4RS: A Tool for Super Resolution of Remote Sensing Images","2022","Journal of Open Research Software","10","1","","","","","10.5334/jors.369","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126694268&doi=10.5334%2fjors.369&partnerID=40&md5=250a99331c9086c913914a0f30e9bba7","The SR4RS software includes tools to apply super-resolution methods on remote sensing images. It employs TensorFlow on the deep learning side, and relies on GDAL and the Orfeo ToolBox to deal with geospatial data. The software is written in simple python, and provides user-oriented applications to train and apply state of the art models on images. © 2022 The Author(s).","","Geospatial; Orfeo toolbox; Remote sensing; Super-resolution; Tensorflow; User-oriented","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85126694268"
"Zhang Y.; Zong R.; Shang L.; Wang D.","Zhang, Yang (57191071243); Zong, Ruohan (57215609256); Shang, Lanyu (57207571159); Wang, Dong (57199176957)","57191071243; 57215609256; 57207571159; 57199176957","On Coupling Classification and Super-Resolution in Remote Urban Sensing: An Integrated Deep Learning Approach","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","4706617","","","","10.1109/TGRS.2022.3169703","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128595921&doi=10.1109%2fTGRS.2022.3169703&partnerID=40&md5=d28bf47c9c69b9e8e9b34e6b389783f1","Motivated by the state-of-the-art optical sensing and image processing technologies, remote urban sensing (RUS) has emerged as a powerful sensing paradigm to capture abundant visual information about the urban environment for intelligent city monitoring, planning, and management. In this article, we focus on a classification and super-resolution coupling (CSC) problem in RUS applications, where the goal is to explore the interdependence between two critical tasks (i.e., classification and super-resolution) to concurrently boost the performance of both the tasks. Two fundamental challenges exist in solving our problem: 1) it is challenging to obtain accurate classification results and generate high-quality reconstructed images without knowing either of them a priori and 2) the noise embedded in the image data could be amplified infinitely by the complex interdependence and coupling between the two tasks. To address these challenges, we develop SCLearn, a novel deep convolutional neural network architecture, to couple the classification task with the super-resolution task in an integrated learning framework to concurrently boost the performance of both the tasks. The evaluation results on a real-world RUS application over two different cities in Europe (Barcelona and Berlin) show that SCLearn consistently outperforms the state-of-the-art baselines by simultaneously achieving better land usage classification accuracy and higher reconstructed image quality under various application scenarios.  © 1980-2012 IEEE.","Classification (of information); Convolution; Deep neural networks; Image classification; Image reconstruction; Image segmentation; Information management; Job analysis; Network architecture; Optical data processing; Quality control; Convolutional neural network; Images reconstruction; Integrated deep learning; Sensing applications; Smart urban sensing; State of the art; Superresolution; Task analysis; Urban sensing; algorithm; image classification; image processing; image resolution; integrated approach; remote sensing; urban area; Optical resolving power","Classification; integrated deep learning; smart urban sensing; super-resolution","Article","Final","","Scopus","2-s2.0-85128595921"
"Wei B.; Zhao Z.; Han J.; Lu J.; Qi H.","Wei, Bingchen (57759682100); Zhao, Zhuang (56083081400); Han, Jing (55728851800); Lu, Jun (57206674671); Qi, Haocun (57704137700)","57759682100; 56083081400; 55728851800; 57206674671; 57704137700","Rapid Hyperspectral Imaging System via Sub-Sampling Coding","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","2986","2997","11","10.1109/JSTARS.2022.3164725","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127739467&doi=10.1109%2fJSTARS.2022.3164725&partnerID=40&md5=73da717a70cad3b46ea8c44955f0f034","In recent years, with the rapid advancement of hyperspectral imaging technology, a growing number of hyperspectral reconstruction approaches have arisen. However, most present technologies have the drawback of being unable to perform both quick spectrum measurement and high image resolution at the same time. In order to address this issue, this article proposes a rapid hyperspectral imaging system via subsampling coding. First, the hyperspectral scene is subsampled using the designed Hadamard coding matrix, then a suitable network structure for the hyperspectral image (HSI) super-resolution is investigated, and lastly high-resolution HSIs are obtained while the number of encodings is reduced. The experimental results reveal that this method is adaptable to a variety of imaging situations and performs well. At the same time, in the field of hyperspectral remote sensing, the problem of relatively low spatial resolution of HSI can be better solved. Furthermore, the method has unlimited image spectral dimensions, good generalization ability and noise reduction capabilities.  © 2008-2012 IEEE.","Deep learning; Encoding (symbols); Error correction; Hyperspectral imaging; Image coding; Image reconstruction; Imaging systems; Neural networks; Noise abatement; Remote sensing; Spectroscopy; Deep learning; Encodings; Error correction codes; Hyperspectral image; Images reconstruction; Neural-networks; Spatial resolution; Sub-sampling; Superresolution; artificial neural network; image resolution; imaging method; machine learning; multispectral image; sampling; Image resolution","Deep learning; hyperspectral image (HSI); neural networks; subsampling; super-resolution (SR)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85127739467"
"Ying J.; Shen H.-L.; Cao S.-Y.","Ying, Jiacheng (57224191214); Shen, Hui-Liang (55477355600); Cao, Si-Yuan (57216041593)","57224191214; 55477355600; 57216041593","Unaligned Hyperspectral Image Fusion via Registration and Interpolation Modeling","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3081136","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107234137&doi=10.1109%2fTGRS.2021.3081136&partnerID=40&md5=378d7f0264e6ab9c9598d99db22c3f52","In satellite remote sensing, the hyperspectral sensor acquires high-spectral-resolution and low-spatial-resolution hyperspectral images (HSIs). Conversely, the multispectral sensor acquires low-spectral-resolution and high-spatial-resolution multispectral images (MSIs). Thus, HSI and MSI fusion is required to promote both spatial and spectral resolutions. Currently, most algorithms are based on the assumption that the HSI and MSI are perfectly aligned. However, this is hardly achievable in real scenarios when the two sensors acquire images from different viewpoints. In this article, we propose a fusion algorithm that consists of two stages, i.e., image registration and image fusion. For image registration, we introduce the normalized edge difference (NED) for image similarity measure considering the different resolutions of the original images. For image fusion, we incorporate the interpolation process in the spatial degradation model to compensate for the interpolation error. Experimental results show that our algorithm performs better than the state of the arts for unaligned image fusion.  © 1980-2012 IEEE.","Image registration; Image resolution; Interpolation; Remote sensing; Spectral resolution; Spectroscopy; Different resolutions; High spatial resolution multispectral images; High spectral resolution; Hyperspectral sensors; Interpolation error; Multispectral sensors; Satellite remote sensing; Spatial degradation; algorithm; image analysis; interpolation; remote sensing; sensor; Image fusion","Hyperspectral image (HSI); Image fusion; Image interpolation; Image registration; Image super-resolution; Multispectral image (MSI)","Article","Final","","Scopus","2-s2.0-85107234137"
"He W.; Wang C.; Sun Z.","He, Wenlei (57921370500); Wang, Chaoli (57907091700); Sun, Zhanquan (57215661166)","57921370500; 57907091700; 57215661166","Super-resolution Reconstruction of Satellite Imagery Based on Generative Adversarial Network","2021","Information and Control","50","2","","195","203","8","10.13976/j.cnki.xk.2021.0181","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137653769&doi=10.13976%2fj.cnki.xk.2021.0181&partnerID=40&md5=797224bbccebfd2cbeac7b49a69bbc27","Although most indices associated with the super-resolution reconstruction of a single remote sensing image based on deep earning have been significantly mproved, the effect observed by the human eyes is not obvious. Previous methods for creating low-resolution mages cause some information losses. To avoid this problem, we use different scales to obtain high-and low-resolution remote sensing image pairs as training data sets. Through this method, we can effectively avoid the loss of original image information caused by downsampling. We use a generative adversarial network (GAN) image super-resolution model based on deep residual blocks so that the model can better learn a priori information. Thus, the quality of the mage generated by the algorithm and the efficiency improve. We also add the spatial position information between mage features to the contextual loss function, thereby reducing mage artifacts caused by feature matching errors. Then, we add a relative discriminator to evaluate the relative authenticity of the obtained image and optimize the super-resolution effect. Experimental results on MWPU-RESISG45 dataset verify that the proposed method greatly enhances PSNR (peak signal to noise ratio), SSIM (structural similarity), and AG(average gradient) indicators. The human eye observation reveals that the network outputs a good super-resolution effect map. © 2021 The Authors. All rights reserved.","","contextual loss function; convolutional neural network (CNN); generative adversarial network (GAN); remote sensing magery; super-resolution","Article","Final","","Scopus","2-s2.0-85137653769"
"Shen X.; Liu X.; Yao Y.; Feng T.","Shen, X. (57457580300); Liu, X. (57208296205); Yao, Y. (57716728400); Feng, T. (12782146100)","57457580300; 57208296205; 57716728400; 12782146100","Comparison of multi-images deep learning super resolution for passive microwave images of arctic sea ICE","2021","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","43","B3-2021","","497","502","5","10.5194/isprs-archives-XLIII-B3-2021-497-2021","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115864127&doi=10.5194%2fisprs-archives-XLIII-B3-2021-497-2021&partnerID=40&md5=b61b299d02dce96f87eb126390e3d4f1","The observation of Arctic sea ice is of great significance to monitoring of the polar environment, research on global climate change and application of Arctic navigation. Compared to optical imagery and SAR imagery, passive microwave images can be obtained for all-sky conditions with high time resolution. However, the spatial resolution of passive microwave images is relatively low (6.25km - 25km) for the observation of detailed sea ice characteristics and small-scale sea ice geographical phenomena. Therefore, in this paper, considering the suitability of different alignment and fusion strategies to the characteristics of passive microwave images of sea ice, two multi-images deep learning super-resolution (SR) algorithms, Recurrent Back-Projection Network (RBPN) and network of Temporal Group Attention (TGA), are selected to test the effects of SR technique for passive microwave images of sea ice. Both qualitative and quantitative comparisons are provided for the SR results oriented from two algorithms. Overall, the SR performance of TGA algorithm outperforms RBPN algorithm for the passive microwave images of sea ice. © 2021 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives. All rights reserved.","Climate change; Deep learning; Microwaves; Optical resolving power; Radar imaging; Remote sensing; Synthetic aperture radar; Backprojections; Deep learning; Image super resolutions; Microwave images; Multi-image super resolution; Multi-images; Passive microwave image; Passive microwaves; Projection network; Superresolution; Sea ice","Deep learning; Multi-image super resolution; Passive microwave images; Sea ice","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85115864127"
"Long J.; Peng Y.","Long, Jian (57218616379); Peng, Yuanxi (7403418922)","57218616379; 7403418922","Blind fusion of hyperspectral multispectral images based on matrix factorization","2021","Remote Sensing","13","21","4219","","","","10.3390/rs13214219","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118119744&doi=10.3390%2frs13214219&partnerID=40&md5=cb9252aa3697716d4af18cf0dbdd9042","The fusion of low spatial resolution hyperspectral images and high spatial resolution multispectral images in the same scenario is important for the super-resolution of hyperspectral images. The spectral response function (SRF) and the point spread function (PSF) are two crucial prior pieces of information in fusion, and most of the current algorithms need to provide these two preliminary pieces of information in advance, even for semi-blind fusion algorithms at least the SRF. This causes limitations in the application of fusion algorithms. This paper aims to solve the dependence of the fusion method on the point spread function and proposes a method to estimate the spectral response function from the images involved in the fusion to achieve blind fusion. We conducted experiments on simulated datasets Pavia University, CAVE, and the remote sensing images acquired by two spectral cameras, Sentinel 2 and Hyperion. The experimental results show that our proposed SRF estimation method can improve the PSNR value by 5 dB on average compared with other state-of-the-art SRF estimation results. The proposed blind fusion method can improve the PSNR value of fusion results by 3–15 dB compared with other blind fusion methods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Factorization; Hyperspectral imaging; Image fusion; Image resolution; Matrix algebra; Optical transfer function; Remote sensing; Spectroscopy; Function estimation; Fusion algorithms; Fusion methods; HyperSpectral; Hyperspectral imaging super-resolution; Matrix factorizations; Multispectral images; Point-Spread function; Spectral response functions; Superresolution; Matrix factorization","Hyperspectral imaging super-resolution; Image fusion; Matrix factorization","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85118119744"
"Cao K.; Cheng Y.; Liu K.; Wang J.; Wang H.","Cao, Kaicheng (57192540078); Cheng, Yongqiang (56242314000); Liu, Kang (56071351500); Wang, Jianqiu (57204603299); Wang, Hongqiang (35779607700)","57192540078; 56242314000; 56071351500; 57204603299; 35779607700","Coherent-Detecting and Incoherent-Modulating Microwave Coincidence Imaging with Off-Grid Errors","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2021.3127713","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119426306&doi=10.1109%2fLGRS.2021.3127713&partnerID=40&md5=36fa842049cb66fffbca3ff1260fbc03","In this letter, a novel microwave coincidence imaging (MCI) approach is proposed based on a multiple-input single-output (MISO) radar system to deal with the low signal-to-noise ratio (SNR) scenarios and off-grid problem. First, in coherent-detecting part, a linear frequency modulated (LFM) signal is transmitted, and dechirping processes are conducted to enhance the SNR of echoes. Then, in incoherent-modulating part, the post random phase-shifting modulations are conducted on the echoes, hence the temporal-spatial orthogonal reference radiation field of MCI is constructed, which provides the potential information of super-resolution. Further, to solve the off-grid problem of target's scatterers in MCI, a new projecting-residual-based selection criterion is also proposed, combined with the preexisting signal subspace matching (SSM) method. The proposed method could largely eliminate the off-grid errors while conduct a reference matrix selection procedure, hence the reconstruction accuracy and computational complexity can be much improved and reduced, respectively. Finally, the validity of the proposed method and the super-resolution ability of MCI are verified by experiments.  © 2004-2012 IEEE.","Chirp modulation; Coherent scattering; Incoherent scattering; Optical resolving power; Signal receivers; Signal to noise ratio; Coincidence imaging; Matrix selection; Microwave coincidence imaging; Off-grids; Receiver; Signal sub-space; Signal subspace matching; Subspace matching; Superresolution; accuracy assessment; detection method; image analysis; microwave imagery; remote sensing; Radar imaging","Matrix selection; microwave coincidence imaging (MCI); off-grid; signal subspace matching (SSM); super-resolution","Article","Final","","Scopus","2-s2.0-85119426306"
"Xiaolin F.; Fan H.; Ming Y.; Tongxin Z.; Ran B.; Zenghui Z.; Zhiyuan G.","Xiaolin, Fang (57374618300); Fan, Hu (57375151000); Ming, Yang (57375258400); Tongxin, Zhu (57375258500); Ran, Bi (57375044300); Zenghui, Zhang (57512991000); Zhiyuan, Gao (57806849700)","57374618300; 57375151000; 57375258400; 57375258500; 57375044300; 57512991000; 57806849700","Small object detection in remote sensing images based on super-resolution","2022","Pattern Recognition Letters","153","","","107","112","5","10.1016/j.patrec.2021.11.027","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121301883&doi=10.1016%2fj.patrec.2021.11.027&partnerID=40&md5=d7767c719a83f668699dfe2338750f9c","Accurate objects detection in remote sensing images is very important, because security, transportation, and rescue applications in military and civilian fields require fully analyzing and using these images. To address the problem that many small-sized objects in remote sensing images are difficult to detect, this paper proposes an improved S2ANET-SR model based on S2A-NET network. In this paper, the original and reduced image are fed to the detection network at the same time, and then a super-resolution enhancement module for the reduced image is designed to enhance the feature extraction of small objects, after that, the perceptual loss and texture matching loss is proposed as supervision. Extensional experiments are conducted to evaluate the performance on the general remote sensing dataset DOTA, and the results show that our proposed method can achieve 74.47% mAP, which is 0.79% better than the accuracy of S2A-NET. © 2021 Elsevier B.V.","Feature extraction; Image enhancement; Military applications; Object recognition; Optical resolving power; Remote sensing; Textures; Detection networks; Features extraction; Image-based; Model-based OPC; Objects detection; Remote sensing images; Resolution enhancement; Security transportation; Small object detection; Superresolution; Object detection","Object detection; Remote sensing images; Super-Resolution","Article","Final","","Scopus","2-s2.0-85121301883"
"Shao E.; Feng J.; Wang Y.; Xia T.; Li Y.","Shao, Erzhuo (57223171988); Feng, Jie (57206757859); Wang, Yingheng (57223993068); Xia, Tong (57205022544); Li, Yong (57189401839)","57223171988; 57206757859; 57223993068; 57205022544; 57189401839","One-shot Transfer Learning for Population Mapping","2021","International Conference on Information and Knowledge Management, Proceedings","","","","1588","1597","9","10.1145/3459637.3482460","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119203097&doi=10.1145%2f3459637.3482460&partnerID=40&md5=85eea4b4028bafddc034b130127c9504","Fine-grained population distribution data is of great importance for many applications, e.g., urban planning, traffic scheduling, epidemic modeling, and risk control. However, due to the limitations of data collection, including infrastructure density, user privacy, and business security, such fine-grained data is hard to collect and usually, only coarse-grained data is available. Thus, obtaining fine-grained population distribution from coarse-grained distribution becomes an important problem. To tackle this problem, existing methods mainly rely on sufficient fine-grained ground truth for training, which is not often available for the majority of cities. That limits the applications of these methods and brings the necessity to transfer knowledge between data-sufficient source cities to data-scarce target cities. In knowledge transfer scenario, we employ single reference fine-grained ground truth in target city, which is easy to obtain via remote sensing or questionnaire, as the ground truth to inform the large-scale urban structure and support the knowledge transfer in target city. By this approach, we transform the fine-grained population mapping problem into a one-shot transfer learning problem. In this paper, we propose a novel one-shot transfer learning framework PSRNet to transfer spatialoral knowledge across cities from three views. From the view of network structure, we build a dense connection-based population mapping network with temporal feature enhancement to capture the complicated spatialoral correlation between population distributions of different granularities. From the view of data, we design a generative model to synthesize fine-grained population samples with POI distribution and the single fine-grained ground truth in data-scarce target city. From the view of optimization, after combining above structure and data, we propose a pixel-level adversarial domain adaption mechanism for universal feature extraction and knowledge transfer during training with scarce ground truth for supervision. Experiments on real-life datasets of 4 cities demonstrate that PSRNet has significant advantages over 8 state-of-the-art baselines by reducing RMSE and MAE by more than 25%. Our code and datasets are released in Github (https://github.com/erzhuoshao/PSRNet-CIKM). © 2021 ACM.","Disease control; Population distribution; Population dynamics; Population statistics; Remote sensing; Coarse-grained; Epidemic modeling; Fine grained; Ground truth; Knowledge transfer; Modelling controls; Risks controls; Superresolution; Traffic scheduling; Transfer learning; Knowledge management","population distribution; super-resolution; transfer learning","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85119203097"
"Li M.; Zou X.; Rao W.; Li Y.; Han C.; Li N.; Ma Y.; Zhang S.; Liu S.","Li, Minglei (55966001900); Zou, Xin (57850218700); Rao, Wei (57849268100); Li, Ying (57872628300); Han, Chengzhi (57849743900); Li, Ning (57849023500); Ma, Youqing (55554122300); Zhang, Shuo (55667863700); Liu, Shaochuang (16307467400)","55966001900; 57850218700; 57849268100; 57872628300; 57849743900; 57849023500; 55554122300; 55667863700; 16307467400","The visual measurement system in the parachute used on the Tianwen-1 Mars exploration mission","2022","Remote Sensing Letters","13","9","","924","934","10","10.1080/2150704X.2022.2106456","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136176473&doi=10.1080%2f2150704X.2022.2106456&partnerID=40&md5=725785cdda775bab9f9917f1a4ea6697","The parachute of the probe plays an important role in the deceleration of the Mars landing mission. This paper provides an overview of the visual measurement system of the parachute in Tianwen-1 exploration mission. Using two monitoring cameras, the system has captured stereo images during the parachute deployment. The morphological and motion parameters of the parachute are reconstructed by image-based feature tracking and 3D reconstruction methods. To improve the image quality, a super-resolution (SR) reconstruction method based on sparse dictionary coding is proposed. In addition, we use a multi-scale feature tracking method to track the feature points and update the motion parameters. The system has been verified by the test on the Earth and successfully applied on the onboard images. The reconstructed parachute parameters are important in the post-flight performance assessment, and the research results can be used as a regression analysis means for the structural design. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Codes (symbols); Image coding; Image enhancement; Image reconstruction; Martian surface analysis; Regression analysis; Stereo image processing; Structural design; Exploration missions; Feature-tracking; Landing mission; Mars exploration; Mars landing; Measurement system; Motion parameters; Reconstruction method; Stereoimages; Visual measurements; exploration; reconstruction; regression analysis; remote sensing; Parachutes","","Article","Final","","Scopus","2-s2.0-85136176473"
"Lei S.; Shi Z.; Mo W.","Lei, Sen (57195618353); Shi, Zhenwei (23398841900); Mo, Wenjing (57387315000)","57195618353; 23398841900; 57387315000","Transformer-Based Multistage Enhancement for Remote Sensing Image Super-Resolution","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3136190","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121813147&doi=10.1109%2fTGRS.2021.3136190&partnerID=40&md5=6e8611e30324a263b5a9465c5e67a677","Convolutional neural networks have made a great breakthrough in recent remote sensing image super-resolution (SR) tasks. Most of these methods adopt upsampling layers at the end of the models to perform enlargement, which ignores feature extraction in the high-dimension space, and thus, limits SR performance. To address this problem, we propose a new SR framework for remote sensing images to enhance the high-dimensional feature representation after the upsampling layers. We name the proposed method as a transformer-based enhancement network (TransENet), where transformers are introduced to exploit features at different levels. The core of the TransENet is a transformer-based multistage enhancement structure, which can be combined with traditional SR frameworks to fuse multiscale high-/low-dimension features. Specifically, in this structure, the encoders aim to embed the multilevel features in the feature extraction part and the decoders are used to fuse these encoded embeddings. Experimental results demonstrate that our proposed TransENet can improve super-resolved results and obtain superior performance over several state-of-the-art methods.  © 1980-2012 IEEE.","Convolution; Decoding; Extraction; Feature extraction; Finite element method; Image enhancement; Image representation; Optical resolving power; Remote sensing; Features extraction; Finite element analyse; Image super resolutions; Multi-stages; Remote sensing images; Remote-sensing; Superresolution; Task analysis; Transformer; image classification; image resolution; remote sensing; satellite imagery; Deep neural networks","Deep convolutional neural networks (CNNs); remote sensing images; super-resolution (SR); transformer","Article","Final","","Scopus","2-s2.0-85121813147"
"Miao X.; Zhang Y.; Zhang J.","Miao, Xinyuan (57189663218); Zhang, Ye (57214252416); Zhang, Junping (55961672900)","57189663218; 57214252416; 55961672900","Spatial fusion enhancement of thermal infrared images based on multi-resolution analysis and low-rank guided filter; [多分辨率低秩导向滤波的热红外图像空间融合]","2021","National Remote Sensing Bulletin","25","11","","2255","2269","14","10.11834/jrs.20219358","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120411507&doi=10.11834%2fjrs.20219358&partnerID=40&md5=59b487ead4a873f07e71193a1a68cef7","Owing to the special imaging principle in the long-wave infrared region, thermal infrared remote sensing images contain the temperature and emissivity features of targets. However, the low spatial resolution of thermal infrared images limits its wide application. With the development of remote sensing technology, multisource remote sensing images in the same region can provide complete information of a target for researchers. On the basis of the high spatial resolution of visible band images, thermal infrared image fusion enhancement and subpixel feature extraction have a high application value.Therefore, a new method named subpixel temperature retrieval of thermal infrared images based on multiresolution superpixel low-rank representation and residual correlation is proposed in this paper. The method achieves two goals by fusing visible and thermal infrared images in a super-resolution way: (1) enhancement of spatial characteristics for thermal infrared images based on adaptive fusion and (2) estimation of subpixel temperature and super resolution for thermal infrared images.The main processing and advantages of the algorithm are listed as follows: (1) For superpixel segmentation and low-rank restoration at multiresolution, superpixel blocks, instead of traditional blocks, are used as low-rank restoration units to enhance the stability of species in each unit and suppress structural noise. (2) Through constructing a guided linear filter, the high-spatial-resolution feature of the visible image can be transferred to the thermal infrared image while keeping the spectral information of the thermal infrared image unchanged. (3) For the estimation of subpixel temperature and super resolution of thermal infrared images, the correlation between the residuals of VIS and fusion images is established at the low-resolution layer and applied to the high-resolution layer to preserve image details.To validate the effectiveness of the proposed method, the visible and thermal infrared data in the 2014 IGARSS data fusion contest are used for experiments. The algorithm is evaluated in three aspects: (1) the improvement of spatial characteristics for thermal infrared images through adaptive low-rank representation, such as noise suppression, intraclass smoothing, and edge enhancement; (2) the spectral information protection of thermal infrared images in homogeneous and heterogenous regions; (3) the super-resolution effect and the accuracy of subpixel temperature retrieval. Compared with the traditional supervised graph-based feature fusion method, the proposed method has the best edge-sharpening, noise suppression, and spatial smoothing effects. It can protect the spectral information of thermal infrared images for different region types. The super-resolution image obtained by the proposed algorithm achieves high-temperature retrieval accuracy, and the overall root-mean-square error is less than 1 K. The average classification accuracy is improved by more than 20%. © 2021, Science Press. All right reserved.","Edge detection; Graphic methods; Image enhancement; Image resolution; Image segmentation; Infrared devices; Infrared imaging; Infrared radiation; Pixels; Remote sensing; Restoration; Guided filters; Infrared image fusions; Low-rank representations; Multi-resolution self-adaption low-rank representation; Self adaption; Sub-pixels; Subpixel temperature retrieval; Super pixels; Super-pixel segmentation; Temperature retrieval; Thermal infrared images; Visible and thermal infrared image fusion; Image fusion","Guided filter; Multi-resolution self-adaption low-rank representation; Subpixel temperature retrieval; Super-pixel segmentation; Visible and thermal infrared image fusion","Article","Final","","Scopus","2-s2.0-85120411507"
"Liu R.; Cui B.; Fang X.; Guo B.; Ma Y.; An J.","Liu, Rongjie (56317759800); Cui, Binge (57807678500); Fang, Xi (57807678600); Guo, Baotao (57807215100); Ma, Yi (35220028600); An, Jubai (7202509647)","56317759800; 57807678500; 57807678600; 57807215100; 35220028600; 7202509647","Super-Resolution of GF-1 Multispectral Wide Field of View Images via a Very Deep Residual Coordinate Attention Network","2022","IEEE Geoscience and Remote Sensing Letters","19","","5513305","","","","10.1109/LGRS.2022.3190018","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134297038&doi=10.1109%2fLGRS.2022.3190018&partnerID=40&md5=935413f5c9cede7434d7f067ca53d602","GF-1 multispectral wide field of view (WFV) images, with a spatial resolution of 16 m, have been widely used in Earth monitoring. However, the spatial details provided by WFV images are not sufficient for many applications. Thus, this letter proposes a novel WFV image super-resolution (SR) algorithm called Gaofen residual coordinate attention network (GFRCAN) based on a very deep residual coordinate attention network. To form a very deep network, the residual-in-residual (RIR) structure consisting of several residual groups (RGs) with long skip connections is used. Meanwhile, the residual coordinate attention block (RCOAB) and adaptive multiscale spatial attention module (AMSA) are incorporated to focus on the high-frequency information and multiscale features adaptive weighted fusion. Besides, the spectral and spatial details of SR images are improved by incorporating peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) into the loss function. Both subjective and objective evaluation results show that the proposed model outperforms the state-of-the-art methods.  © 2004-2012 IEEE.","Image enhancement; Image resolution; Remote sensing; Signal to noise ratio; Coordinate attention; Features extraction; GF-1 wide field of view; Image super resolutions; Multi-spectral; Remote sensing images; Spatial resolution; Superresolution; Wide field-ofview; satellite data; Data mining","Coordinate attention; GF-1 multispectral wide field of view (WFV); remote sensing images; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85134297038"
"Xie J.; Fang L.; Zhang B.; Chanussot J.; Li S.","Xie, Jie (57210957012); Fang, Leyuan (57218451012); Zhang, Bob (57217861698); Chanussot, Jocelyn (6602159365); Li, Shutao (7409240361)","57210957012; 57218451012; 57217861698; 6602159365; 7409240361","Super Resolution Guided Deep Network for Land Cover Classification from Remote Sensing Images","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3120891","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117777912&doi=10.1109%2fTGRS.2021.3120891&partnerID=40&md5=3c92c3e9453a108dbed15f797fcad970","The low resolution of remote sensing images often limits the land cover classification (LCC) performance. Super resolution (SR) can improve the image resolution, while greatly increasing the computational burden for the LCC due to the larger size of the input image. In this article, the SR-guided deep network (SRGDN) framework is proposed, which can generate meaningful structures from higher resolution images to improve the LCC performance without consuming more computational costs. In general, the SRGDN consists of two branches (i.e., SR branch and LCC branch) and a guidance module. The SR branch aims to increase the resolution of remote sensing images. Since high- and low-resolution image pairs cannot be directly provided by imaging sensors to train the SR branch, we introduce a self-supervised generative adversarial network (GAN) to estimate the downsampling kernel that can produce these image pairs. The LCC branch adopts the high-resolution network (HRNet) to retain as much resolution information with a few downsampling operations as possible. The guidance module teaches the LCC branch to learn the high-resolution information from the SR branch without the utilization of the higher-resolution images as the inputs. Furthermore, the guidance module introduces spatial pyramid pooling (SPP) to match the feature maps of different sizes in the two branches. In the testing stage, the guidance module and SR branch can be removed, and therefore do not create additional computational costs. Experimental results on three real datasets demonstrate the superiority of the proposed method over several well-known LCC approaches.  © 1980-2012 IEEE.","Image classification; Image resolution; Remote sensing; Signal sampling; Classification performance; Computational costs; Down sampling; Guidance; High resolution; High-resolution images; Image pairs; Land cover classification; Remote sensing images; Superresolution; artificial neural network; image analysis; land cover; remote sensing; satellite imagery; Image enhancement","Guidance; land cover classification (LCC); remote sensing image; super resolution (SR)","Article","Final","","Scopus","2-s2.0-85117777912"
"Wei Z.; Liu Y.","Wei, Zikang (57218709574); Liu, Yunqing (36340113500)","57218709574; 36340113500","Construction of super-resolution model of remote sensing image based on deep convolutional neural network","2021","Computer Communications","178","","","191","200","9","10.1016/j.comcom.2021.06.022","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111859641&doi=10.1016%2fj.comcom.2021.06.022&partnerID=40&md5=42ca5e284c8f5ff7d85603b33e3164ae","With the continuous improvement of satellite remote sensing technology, using super-resolution image reconstruction technology to reconstruct remote sensing images has important application significance for social development. In the generator model proposed in this paper, the standard convolution layer in the residual network structure is replaced by empty convolution to improve the overall performance of the model while keeping the number of parameters unchanged and the receptive field of convolution at each stage unchanged. By analyzing the advantages of residual network, dense connection network, and cavity convolution in the field of image super resolution, an optimized super-resolution reconstruction model of GAN image with cavity convolution is constructed with dense connection block of cavity residue as a generator component. The cloud computing-based service model is introduced into the image reconstruction system, and the background management module is built through the cloud service system, which is responsible for model training, image transmission, image processing request and database reading. Through experimental analysis, it is proved that the whole automatic data processing from automatic matching data to processing data can be completed, and the performance is better than the traditional service mode, which can produce great economic benefits. © 2021 Elsevier B.V.","Cloud computing; Data handling; Deep neural networks; Economic and social effects; Image enhancement; Image reconstruction; Optical resolving power; Remote sensing; Cloud-computing; Continuous improvements; Convolution algorithm; Convolutional neural network; Image-based; Performance; Remote sensing images; Satellite remote sensing; Super resolution; Super-resolution models; Convolution","Cloud computing; Convolution algorithm; Remote sensing image; Super resolution","Article","Final","","Scopus","2-s2.0-85111859641"
"Wang Y.; Sun G.; Guo S.","Wang, Yuwu (57217011318); Sun, Guobing (57197195443); Guo, Shengwei (57297857800)","57217011318; 57197195443; 57297857800","Target detection method for low-resolution remote sensing image based on ESRGAN and ReDet","2021","Photonics","8","10","431","","","","10.3390/photonics8100431","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117216653&doi=10.3390%2fphotonics8100431&partnerID=40&md5=59e6d2953b206376c2513f1de03862d1","With the widespread use of remote sensing images, low-resolution target detection in remote sensing images has become a hot research topic in the field of computer vision. In this paper, we propose a Target Detection on Super-Resolution Reconstruction (TDoSR) method to solve the problem of low target recognition rates in low-resolution remote sensing images under foggy con-ditions. The TDoSR method uses the Enhanced Super-Resolution Generative Adversarial Network (ESRGAN) to perform defogging and super-resolution reconstruction of foggy low-resolution remote sensing images. In the target detection part, the Rotation Equivariant Detector (ReDet) algo-rithm, which has a higher recognition rate at this stage, is used to identify and classify various types of targets. While a large number of experiments have been carried out on the remote sensing image dataset DOTA-v1.5, the results of this paper suggest that the proposed method achieves good results in the target detection of low-resolution foggy remote sensing images. The principal result of this paper demonstrates that the recognition rate of the TDoSR method increases by roughly 20% when compared with low-resolution foggy remote sensing images. © 2021 by the authors. Li-censee MDPI, Basel, Switzerland.","","ESRGAN; ReDet; Remote sensing images; Super-resolution reconstruction; Target detection","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85117216653"
"Hu J.-F.; Huang T.-Z.; Deng L.-J.; Dou H.-X.; Hong D.; Vivone G.","Hu, Jin-Fan (57219691918); Huang, Ting-Zhu (56193452300); Deng, Liang-Jian (55207151100); Dou, Hong-Xia (57190565317); Hong, Danfeng (56108179600); Vivone, Gemine (42962520400)","57219691918; 56193452300; 55207151100; 57190565317; 56108179600; 42962520400","Fusformer: A Transformer-Based Fusion Network for Hyperspectral Image Super-Resolution","2022","IEEE Geoscience and Remote Sensing Letters","19","","6012305","","","","10.1109/LGRS.2022.3194257","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135736154&doi=10.1109%2fLGRS.2022.3194257&partnerID=40&md5=e566ed6dc9502590a9cccc3bd456f2d1","Hyperspectral image super-resolution (HISR) is to fuse a low-resolution hyperspectral image (LR-HSI) and a high-resolution multispectral image (HR-MSI), aiming to obtain a high-resolution hyperspectral image (HR-HSI). Recently, various convolution neural network (CNN)-based techniques have been successfully applied to address the HISR problem. However, these methods generally only consider the relation of a local neighborhood by convolution kernels with a limited receptive field, thus ignoring the global relationship in a feature map. In this letter, we design a Transformer-based architecture (called Fusformer) for the HISR problem, which is the first attempt to apply the Transformer architecture to this task to the best of our knowledge. Because of the excellent ability of feature representations, especially by the self-attention (SA) in the Transformer, our approach can globally explore the intrinsic relationship within features. Considering the specific HISR problem, since the LR-HSI holds the primary spectral information, our method estimates the spatial residual between the upsampled low-resolution multispectral image (LR-MSI) and the desired HR-HSI, reducing the burden of training the whole data in a smaller mapping space. Various experiments show that our approach outperforms current state-of-the-art (SOTA) HISR methods. The code is available at https://github.com/J-FHu/Fusformer.  © 2004-2012 IEEE.","Computer architecture; Convolution; Hyperspectral imaging; Job analysis; Optical resolving power; Photomapping; Remote sensing; Spectroscopy; Features extraction; High resolution; HyperSpectral; Hyperspectral image super-resolution; Image super resolutions; Remote-sensing; Superresolution; Task analysis; Transformer; artificial neural network; image resolution; numerical method; remote sensing; spectral analysis; Image fusion","Hyperspectral image super-resolution (HISR); Image fusion; Remote sensing; Transformer","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85135736154"
"Cai D.; Zhang P.","Cai, Durong (57821998000); Zhang, Peng (57214124179)","57821998000; 57214124179","T3SR: Texture Transfer Transformer for Remote Sensing Image Superresolution","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","7346","7358","12","10.1109/JSTARS.2022.3198557","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136608404&doi=10.1109%2fJSTARS.2022.3198557&partnerID=40&md5=f6a44094d1033dcf8a430627999ce57a","Remote sensing image superresolution has made significant progress in recent years, aiming to restore natural and realistic high-resolution images from low-resolution images. However, most image superresolution remote sensing methods are improved only by deepening their network and expanding the network size, consuming substantial computing resources and imposing a bottleneck in development. Here, we propose an end-to-end image superresolution network called texture transfer transformer for remote sensing image superresolution (T3SR). For the first time, T3SR introduces image texture transfer into remote sensing, which achieves the most advanced results. Specifically, T3SR divides image superresolution into two stages: texture transfer and feature fusion. First, to solve the problems of missing textures, artifacts, and blurring in a single image superresolution approach, we design a texture transfer module to serve the shallow texture transfer. Second, to further reduce the dependence of the model on the reference image, we propose a U-Transformer-based feature fusion scheme to reduce the dependence on the reference image. Finally, we conduct numerous experiments on standard public datasets to fully evaluate our approach. In addition to verifying the method's superiority based on the reference image paradigm, we also test the performance without the reference image. All results show that our method yields an abundant texture and finish with better visual results. Moreover, the best score is also obtained in the quantitative parameters of PSNR and SSIM. Compared with the best available approach, T3SR has an improved performance by 0.79 dB and 0.33 dB in the datasets of WHU-RS19 and RSSCN7, respectively.  © 2008-2012 IEEE.","Computer vision; Image enhancement; Image fusion; Image texture; Latexes; Optical resolving power; Rendering (computer graphics); Correlation; Image super resolutions; Reference image; Remote sensing images; Remote-sensing; Self-references; Superresolution; Task analysis; Texture transfer; Transformer; image processing; image resolution; network analysis; remote sensing; texture; Remote sensing","Image superresolution; reference image; self-reference; texture transfer","Article","Final","","Scopus","2-s2.0-85136608404"
"Wu T.; Song X.; Gan T.; Zeng B.; Chen J.","Wu, Tao (57866302100); Song, Xinning (57866509400); Gan, Tian (57867106700); Zeng, Bowen (57867304400); Chen, Jiaqi (48160919100)","57866302100; 57866509400; 57867106700; 57867304400; 48160919100","Super-resolution Reconstruction of Night-light Images Based on Improved SRCNN","2022","CTISC 2022 - 2022 4th International Conference on Advances in Computer Technology, Information Science and Communications","","","","","","","10.1109/CTISC54888.2022.9849813","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137003124&doi=10.1109%2fCTISC54888.2022.9849813&partnerID=40&md5=025ddbeee1e63d7704a90dbf530f39e2","Night-light remote sensing images have been used in numerous fields and have brought much value to human society. However, the low resolution is a major drawback of night-light images, limiting its application in many ways. Image processing research proposes super-resolution reconstruction technology, which can obtain high-resolution images from low-resolution images. It is often used in some fields that need image details. We improve the SRCNN network structure by removing the bicubic interpolation with high computational complexity and replacing it with a deconvolutional layer. We added a feature extraction layer. We can extract more features in the image by using two convolution layers to extract the enlarged image. Finally, we also optimize the convolutional layer of the nonlinear mapping to reduce the training time. We produced a training set and a test set of night light images to evaluate the effect of network improvement. Through the final comparison, our method can improve the resolution of luminous image, which is greatly improved compared with SRCNN.  © 2022 IEEE.","Image enhancement; Image reconstruction; Optical resolving power; Remote sensing; Human society; Image-based; Neural-networks; Night lights; Night lights image; Remote sense; Remote sensing images; SRCNN; Super-resolution reconstruction; Superresolution; Convolution","Neural network; Night-light images; Remote sense; Satellites; SRCNN; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85137003124"
"Tang J.; Zhang J.; Chen D.; Al-Nabhan N.; Huang C.","Tang, Jiali (36095002400); Zhang, Jie (57210605957); Chen, Dan (57199412501); Al-Nabhan, Najla (55347507600); Huang, Chenrong (53877428900)","36095002400; 57210605957; 57199412501; 55347507600; 53877428900","Single-frame super-resolution for remote sensing images based on improved deep recursive residual network","2021","Eurasip Journal on Image and Video Processing","2021","1","20","","","","10.1186/s13640-021-00560-8","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106954528&doi=10.1186%2fs13640-021-00560-8&partnerID=40&md5=83c559f4600343459ab51c3e160ae234","Single-frame image super-resolution (SISR) technology in remote sensing is improving fast from a performance point of view. Deep learning methods have been widely used in SISR to improve the details of rebuilt images and speed up network training. However, these supervised techniques usually tend to overfit quickly due to the models’ complexity and the lack of training data. In this paper, an Improved Deep Recursive Residual Network (IDRRN) super-resolution model is proposed to decrease the difficulty of network training. The deep recursive structure is configured to control the model parameter number while increasing the network depth. At the same time, the short-path recursive connections are used to alleviate the gradient disappearance and enhance the feature propagation. Comprehensive experiments show that IDRRN has a better improvement in both quantitation and visual perception. © 2021, The Author(s).","Deep learning; Learning systems; Optical resolving power; Remote sensing; Learning methods; Performance points; Recursive structure; Remote sensing images; Single frame image; Single frame super resolutions; Super-resolution models; Visual perception; Image enhancement","Deep learning; Recursive residual network; Remote sensing; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85106954528"
"Panagiotopoulou A.; Bratsolis E.; Grammatikopoulos L.; Petsa E.; Charou E.; Poirazidis K.; Martinis A.; Madamopoulos N.","Panagiotopoulou, Antigoni (24479152700); Bratsolis, Emmanuel (6603338911); Grammatikopoulos, Lazaros (16068804700); Petsa, Eleni (6508237326); Charou, Eleni (6507509159); Poirazidis, Konstantinos (57203888036); Martinis, Aristotelis (25641948100); Madamopoulos, Nicholas (6604012410)","24479152700; 6603338911; 16068804700; 6508237326; 6507509159; 57203888036; 25641948100; 6604012410","Sentinel-2 Images at 2.5m Spatial Resolution via Deep-Learning: A Case Study in Zakythnos","2022","IVMSP 2022 - 2022 IEEE 14th Image, Video, and Multidimensional Signal Processing Workshop","","","","","","","10.1109/IVMSP54334.2022.9816272","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135185442&doi=10.1109%2fIVMSP54334.2022.9816272&partnerID=40&md5=913bebe5e979cb73d035cadba99bffc0","High-resolution (HR) satellite images can provide detailed information about land usage/land cover. Often, it is necessary that the satellite sensor inherent spatial resolution is increased through algorithmic processing of the image data acquired. Machine-learning and in particular deep-learning based super-resolution (SR) techniques are an effective tool for increasing the spatial resolution of images. In the current work, Sentinel-2 images are super-resolved to spatial resolution equal to 2.5 m/pixel by means of deep-learning based SR techniques. The area of study is Zakynthos island in Greece. A novel index called Normalized Carotenoid Reflectance Index (NCRI) is proposed for the assessment of land cover by olive trees.  © 2022 IEEE.","Deep learning; Forestry; Image resolution; Learning systems; Reflection; Remote sensing; Deep-learning; Land cover; Learning-based super-resolution; Normalized carotenoid reflectance index; Olive tree; Reflectance index; Resolution techniques; Sentinel-2; Spatial resolution; Superresolution; Carotenoids","deep-learning; normalized carotenoid reflectance index; olive tree; Sentinel-2; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85135185442"
"Bai H.; Bai T.; Li W.; Liu X.","Bai, Hao (57220206932); Bai, Tingzhu (8938560200); Li, Wei (57034823700); Liu, Xun (26662773700)","57220206932; 8938560200; 57034823700; 26662773700","A building segmentation network based on improved spatial pyramid in remote sensing images","2021","Applied Sciences (Switzerland)","11","11","5069","","","","10.3390/app11115069","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107849781&doi=10.3390%2fapp11115069&partnerID=40&md5=3f775af1d7216de375758ae7fa501e35","Building segmentation is widely used in urban planning, disaster prevention, human flow monitoring and environmental monitoring. However, due to the complex landscapes and highdensity settlements, automatically characterizing building in the urban village or cities using remote sensing images is very challenging. Inspired by the rencent deep learning methods, this paper proposed a novel end-to-end building segmentation network for segmenting buildings from remote sensing images. The network includes two branches: one branch uses Widely Adaptive Spatial Pyramid (WASP) structure to extract multi-scale features, and the other branch uses a deep residual network combined with a sub-pixel up-sampling structure to enhance the detail of building boundaries. We compared our proposed method with three state-of-the-art networks: DeepLabv3+, ENet, ESPNet. Experiments were performed using the publicly available Inria Aerial Image Labelling dataset (Inria aerial dataset) and the Satellite dataset II(East Asia). The results showed that our method outperformed the other networks in the experiments, with Pixel Accuracy reaching 0.8421 and 0.8738, respectively and with mIoU reaching 0.9034 and 0.8936 respectively. Compared with the basic network, it has increased by about 25% or more. It can not only extract building footprints, but also especially small building objects. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","","CNN; Remote sensing; ResNet; Semantic segmentation; Spatial pyramid; Super resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85107849781"
"Bashir S.M.A.; Wang Y.","Bashir, Syed Muhammad Arsalan (56385198200); Wang, Yi (12763268500)","56385198200; 12763268500","Small object detection in remote sensing images with residual feature aggregation-based super-resolution and object detector network","2021","Remote Sensing","13","9","1854","","","","10.3390/rs13091854","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106517229&doi=10.3390%2frs13091854&partnerID=40&md5=98b765460da6dde1bfa9f0ccc129d0ab","This paper deals with detecting small objects in remote sensing images from satellites or any aerial vehicle by utilizing the concept of image super-resolution for image resolution enhancement using a deep-learning-based detection method. This paper provides a rationale for image super-resolution for small objects by improving the current super-resolution (SR) framework by incorporating a cyclic generative adversarial network (GAN) and residual feature aggregation (RFA) to improve detection performance. The novelty of the method is threefold: first, a framework is proposed, independent of the final object detector used in research, i.e., YOLOv3 could be replaced with Faster R-CNN or any object detector to perform object detection; second, a residual feature aggregation network was used in the generator, which significantly improved the detection performance as the RFA network detected complex features; and third, the whole network was transformed into a cyclic GAN. The image super-resolution cyclic GAN with RFA and YOLO as the detection network is termed as SRCGAN-RFA-YOLO, which is compared with the detection accuracies of other methods. Rigorous experiments on both satellite images and aerial images (ISPRS Potsdam, VAID, and Draper Satellite Image Chronology datasets) were performed, and the results showed that the detection performance increased by using super-resolution methods for spatial resolution enhancement; for an IoU of 0.10, AP of 0.7867 was achieved for a scale factor of 16. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Aircraft detection; Antennas; Deep learning; Feature extraction; Image enhancement; Image resolution; Object recognition; Optical resolving power; Remote sensing; Small satellites; Adversarial networks; Detection performance; Image resolution enhancements; Image super resolutions; Remote sensing images; Small object detection; Spatial-resolution enhancement; Superresolution methods; Object detection","Deep learning; Generative adversarial networks; Image classification; Object detection in satellite images; Remote sensing; Residual feature aggregation (RFA); Vehicle detection","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85106517229"
"Liu X.; Zhu Y.; Zhu Q.; Sun J.","Liu, Xinrong (57823777500); Zhu, Yaoqin (8692941700); Zhu, Qiliang (57824049300); Sun, Jin (55716292300)","57823777500; 8692941700; 57824049300; 55716292300","A Spark-based Parallel NPTSR Algorithm for Hyperspectral Image fusion","2022","Proceedings - 2021 9th International Conference on Advanced Cloud and Big Data, CBD 2021","","","","13","18","5","10.1109/CBD54617.2021.00012","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135142369&doi=10.1109%2fCBD54617.2021.00012&partnerID=40&md5=c172e8769e34a6b667715aa231165dff","NPTSR is a super-resolution method for hyperspectral image fusion that uses tensor-tensor product to characterize nonlocal patch for the purpose of fusing hyperspectral images and multispectral images. Due to its high computational efficiency in single-machine environments, it is difficult to adapt NPTSR to large-scale remote sensing datasets and large numbers of iterations during the hyperspectral image super-resolution procedure. To address the above-mentioned limitations, this paper proposes a Spark-based parallel method for NPTSR algorithm. We develop a parallel method for nonlocal patches extraction relying on the characteristics of remote sensing data in tensor representation. In addition, we design the parallel implementation of the iterative procedure involved in NPTSR algorithm to accelerate its execution on Spark. Experimental results show that, compared with the serial version, the parallel NPTSR algorithm achieves significant speedup while guaranteeing similar image fusion accuracy and convergence rate. Moreover, the parallel implementation exhibits decent scalability to the increasing size of hyperspectral dataset.  © 2022 IEEE.","Computational efficiency; Image fusion; Iterative methods; Large dataset; Optical resolving power; Remote sensing; Spectroscopy; HyperSpectral; Hyperspectral image; Hyperspectral image fusions; Nonlocal; NPTSR; Parallel implementations; Parallel method; Superresolution methods; Tensor computation; Tensor products; Tensors","hyperspectral image; image fusion; NPTSR; parallel algorithm; tensor computation","Conference paper","Final","","Scopus","2-s2.0-85135142369"
"Farooq M.; Dailey M.N.; Mahmood A.; Moonrinta J.; Ekpanyapong M.","Farooq, Muhammad (57212081048); Dailey, Matthew N. (56187964300); Mahmood, Arif (55636036300); Moonrinta, Jednipat (36460177500); Ekpanyapong, Mongkol (6506112110)","57212081048; 56187964300; 55636036300; 36460177500; 6506112110","Human face super-resolution on poor quality surveillance video footage","2021","Neural Computing and Applications","33","20","","13505","13523","18","10.1007/s00521-021-05973-0","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104103307&doi=10.1007%2fs00521-021-05973-0&partnerID=40&md5=10c866b5f78fe21082b5f3990b8d1892","Most super-resolution (SR) methods proposed to date do not use real ground-truth high-resolution (HR) and low-resolution (LR) image pairs; instead, the vast majority of methods use synthetic LR images generated from the HR images. This approach yields excellent performance on synthetic datasets, but on real-world poor quality surveillance video footage, they suffer from performance degradation. A promising alternative is to apply recent advances in style transfer for unpaired datasets, but state-of-the-art work along these lines has used LR images and HR images from completely different datasets, introducing more variation between the HR and LR domains than necessary. In this paper, we propose methods that overcome both of these shortcomings, applying unpaired style transfer learning methods to face SR but using HR and LR datasets that share important properties. The key is to acquire roughly paired training data from a high-quality main stream and a lower-quality sub-stream of the same IP camera. Based on this principle, we have constructed four datasets comprising more than 400 people, with 1–15 weakly aligned real HR–LR pairs for each subject. We adopt a cycle generative adversarial networks (Cycle GANs) approach that produces impressive super-resolved images for low-quality test images never seen during training. Experiments prove the efficacy of the method. The approach to face SR advocated for in this paper makes possible many real-world applications requiring the extraction of high-quality face images from low-resolution video streams such as those produced by security cameras. Developers of diverse applications such as face recognition, 3D face reconstruction, face alignment, face parsing, human–computer interaction, remote sensing, and access control will benefit from the methods introduced in this work. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Access control; Cameras; Data streams; Formal languages; Human computer interaction; Learning systems; Optical resolving power; Remote sensing; Security systems; Transfer learning; 3D face reconstruction; Adversarial networks; Computer interaction; Diverse applications; Low resolution images; Low resolution video; Performance degradation; Transfer learning methods; Face recognition","Cycle GANs; Face hallucination; Super-resolution","Article","Final","","Scopus","2-s2.0-85104103307"
"Tuo X.; Zhang Y.; Huang Y.; Yang J.","Tuo, Xingyu (57213190611); Zhang, Yin (55975581400); Huang, Yulin (23014806800); Yang, Jianyu (9239230100)","57213190611; 55975581400; 23014806800; 9239230100","Fast Sparse-TSVD Super-Resolution Method of Real Aperture Radar Forward-Looking Imaging","2021","IEEE Transactions on Geoscience and Remote Sensing","59","8","9228888","6609","6620","11","10.1109/TGRS.2020.3027053","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103363033&doi=10.1109%2fTGRS.2020.3027053&partnerID=40&md5=d4754769969a9cd31a2c6eda9918e11f","Most existing super-resolution imaging methods fail to work in low signal-to-noise ratio (SNR) condition due to the ill-posed antenna measurement matrix, but the sparse-truncated singular value decomposition (TSVD) method can effectively suppress noise and improve azimuth resolution in low SNR condition. However, the current sparse-TSVD method encounters large computation cost, resulting in a slow algorithm speed. In this work, a fast sparse-TSVD super-resolution imaging method of real aperture radar is proposed. First, the proposed method is based on the results of TSVD, using the truncated unitary matrix and diagonal matrix to reconstruct the signal convolution model. The dimension of the reconstructed antenna measurement matrix reduces from $N \times N$ to $k \times N$ , and the dimension of the reconstructed echo matrix reduces from $N \times 1$ to $k \times 1$ , where $N$ is azimuth sampling points and $k$ is truncation parameter, $N \gg k$. Much of the expensive matrix- multiplication computation can then be performed on the smaller matrices, thereby accelerating the algorithm. Second, an objective function is established as the ${l_{1}}$ constraint based on the regularization strategy. Lastly, this article employs iterative reweighted least square (IRLS) method to solve the objective function, and the dimension of the reversed matrix is lessened from $N \times N$ to $k \times k$ , speeding up the algorithm further. The simulation and real data verify that the proposed algorithm not only improves the azimuth resolution in low SNR condition but also increases computational efficiency compared with the sparse-TSVD method.  © 1980-2012 IEEE.","Computational efficiency; Iterative methods; Least squares approximations; Optical resolving power; Radar; Radar antennas; Radar imaging; Singular value decomposition; Iterative reweighted least square; Low signal-to-noise ratio; MAtrix multiplication; Regularization strategies; Super resolution imaging; Superresolution methods; Truncated singular value decomposition; Truncation parameter; image resolution; imaging method; numerical model; remote sensing; synthetic aperture radar; Signal to noise ratio","Real aperture radar (RAR); sparse-truncated singular value decomposition (TSVD); super-resolution","Article","Final","","Scopus","2-s2.0-85103363033"
"Lin R.; Wang L.; Xia T.","Lin, Ruikai (57225129631); Wang, Liyuan (57225127394); Xia, Tao (57225129909)","57225129631; 57225127394; 57225129909","Research on Image Super-resolution Technology Based on Sparse Constraint SegNet Network","2021","Journal of Physics: Conference Series","1952","2","022005","","","","10.1088/1742-6596/1952/2/022005","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109211675&doi=10.1088%2f1742-6596%2f1952%2f2%2f022005&partnerID=40&md5=e32e0622318acdb719ff63ecf0aab403","Aiming at the problems of long time-consuming and low accuracy in extracting buildings with traditional machine learning methods. In this paper, the SegNet semantic segmentation models on deep learning is used to improve the algorithm, and a high-resolution remote sensing image building extraction algorithm based on sparse constrained SegNet are proposed. First, regular terms and Dropout are added to the SegNet model, which greatly reduces the occurrence of model over-fitting; secondly, in order to extract richer semantic features for the model, the algorithm introduces a pyramid pooling module; finally, the Lorentz function sparse constraint factor is introduced to the SPNet model, Construct a new semantic segmentation model LSPNet. In order to verify the reliability and applicability of the proposed algorithm, the optimized LSPNet model is used to identify and extract the buildings in the high-resolution data set. Experimental results show that compared with traditional machine learning methods, this method has the advantages of fast convergence and high accuracy, and has a good application prospect.  © Published under licence by IOP Publishing Ltd.","Deep learning; Image enhancement; Image segmentation; Remote sensing; Semantics; Application prospect; Building extraction; Extracting buildings; High resolution data; High resolution remote sensing images; Image super resolutions; Machine learning methods; Semantic segmentation; Learning systems","Deep learning; feature extraction; semantic segmentation; sparse constraint","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85109211675"
"Wang J.; Shao Z.; Huang X.; Lu T.; Zhang R.; Ma J.","Wang, Jiaming (57206676342); Shao, Zhenfeng (57203905559); Huang, Xiao (57201292422); Lu, Tao (56406646300); Zhang, Ruiqian (57190385256); Ma, Jiayi (26638975600)","57206676342; 57203905559; 57201292422; 56406646300; 57190385256; 26638975600","Enhanced image prior for unsupervised remoting sensing super-resolution","2021","Neural Networks","143","","","400","412","12","10.1016/j.neunet.2021.06.005","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109071626&doi=10.1016%2fj.neunet.2021.06.005&partnerID=40&md5=70dcc8ff5c43455549965e9d7e5d66ca","Numerous approaches based on training low-high resolution image pairs have been proposed to address the super-resolution (SR) task. Despite their success, low-high resolution image pairs are usually difficult to obtain in certain scenarios, and these methods are limited in the actual scene (unknown or non-ideal image acquisition process). In this paper, we proposed a novel unsupervised learning framework, termed Enhanced Image Prior (EIP), which achieves SR tasks without low/high resolution image pairs. We first feed random noise maps into a designed generative adversarial network (GAN) for satellite image SR reconstruction. Then, we convert the reference image to latent space as the enhanced image prior. Finally, we update the input noise in the latent space with a recurrent updating strategy, and further transfer the texture and structured information from the reference image. Results on extensive experiments on the Draper dataset show that EIP achieves significant improvements over state-of-the-art unsupervised SR methods both quantitatively and qualitatively. Our experiments on satellite (SuperView-1) images reveal the potential of the proposed approach in improving the resolution of remote sensing imagery compared with the supervised algorithms. Source code is available at https://github.com/jiaming-wang/EIP. © 2021 Elsevier Ltd","Algorithms; Image Processing, Computer-Assisted; Image enhancement; Optical resolving power; Remote sensing; Textures; Unsupervised learning; High-resolution images; Ideal images; Image pairs; Image priors; Latent space; Low-high; Nonideal; Prior enhancement; Reference image; Super resolution; algorithm; article; human; human experiment; learning; noise; quantitative analysis; satellite imagery; image processing; Satellite imagery","Latent space; Prior enhancement; Satellite imagery; Super resolution; Unsupervised learning","Article","Final","","Scopus","2-s2.0-85109071626"
"Fan C.; Hu Z.; Jia L.; Min H.","Fan, Chunxiao (7402656564); Hu, Zhou (57218534052); Jia, Lu (55541053400); Min, Hai (35170861100)","7402656564; 57218534052; 55541053400; 35170861100","A novel lossless compression encoding framework for SAR remote sensing images","2021","Signal, Image and Video Processing","15","3","","441","448","7","10.1007/s11760-020-01763-8","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089443209&doi=10.1007%2fs11760-020-01763-8&partnerID=40&md5=ea79db90fdc1ff9a511371a7d989ee47","The resolution of SAR (synthetic-aperture radar) remote sensing images becomes higher to provide more details, but these images contain more data, which creates a limitation in terms of transport and storage. Most of existing image data compression frameworks are lossy or designed for spectral images. In this paper, we propose a novel lossless compression encoding framework for SAR remote sensing images. In the proposed framework, an outline of the image and the high-frequency components are separated and processed separately to increase the relativity of adjacent pixels. So the accuracy of prediction is improved, which makes the data compression more effective. The outline image is down-sampled to reduce data size, and the nonlocally centralized sparse representation-based super-resolution method is used to predict pixel values using the information in nonlocal similar regions. The proposed framework is evaluated with the ground range detected and PauliRGB images captured by SAR satellites. The results show that the proposed technique can get an efficient compression performance and it outperforms existing lossless compression frameworks in terms of compression efficiency. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","Digital storage; Encoding (symbols); Image coding; Pixels; Radar imaging; Remote sensing; Signal encoding; Spectroscopy; Synthetic aperture radar; Compression efficiency; Compression performance; High frequency components; Image data compression; Remote sensing images; SAR(synthetic aperture radar); Sparse representation; Superresolution methods; Image compression","Encoding; Image compression; Remote sensing; Synthetic-aperture radar","Article","Final","","Scopus","2-s2.0-85089443209"
"Su H.; Wang A.; Zhang T.; Qin T.; Du X.; Yan X.-H.","Su, Hua (57203702610); Wang, An (57224212415); Zhang, Tianyi (57220870835); Qin, Tian (57218291774); Du, Xiaoping (56506043800); Yan, Xiao-Hai (34972376600)","57203702610; 57224212415; 57220870835; 57218291774; 56506043800; 34972376600","Super-resolution of subsurface temperature field from remote sensing observations based on machine learning","2021","International Journal of Applied Earth Observation and Geoinformation","102","","102440","","","","10.1016/j.jag.2021.102440","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120691324&doi=10.1016%2fj.jag.2021.102440&partnerID=40&md5=a9a342e882819ae6e870592e282cb2b0","Subsurface ocean observations are sparse and insufficient, significantly constraining studies of ocean processes. Retrieving high-resolution subsurface dynamic parameters from remote sensing observations using specific inversion models is possible but challenging. This study proposed two kinds of machine learning algorithms, namely, Convolutional Neural Network (CNN) and Light Gradient Boosting Machine (LightGBM), to reconstruct the subsurface temperature (ST) of the ocean's upper 1000 m with a high resolution of 0.25° based on the satellite-based sea surface parameters combined with Argo float and EN4 profile data. We managed to improve the spatial resolution of ST from 1° to 0.25°. We employed two machine learning algorithms to set up monotemporal models of the four seasons and time-series models and adopted the determination coefficient (R2) and Root Mean Squared Error (RMSE) to evaluate the models’ prediction accuracy. The results show that LightGBM outperformed CNN in the case of small training samples. By contrast, in the case of big training samples, CNN outperformed LightGBM. Meanwhile, the ST with a high resolution of 0.25° predicted by the time-series CNN model can better observe mesoscale phenomena. This study provides more useful and higher-resolution data support for further studies on the warming and variability of the ocean interior under global warming. © 2021 The Author(s)","algorithm; Argo; artificial neural network; global ocean; image resolution; machine learning; remote sensing; sea surface temperature","Convolutional Neural Network; Global Ocean; LightGBM; Remote Sensing; Subsurface Temperature; Super-Resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85120691324"
"Zhang X.; Li Z.; Zhang T.; Liu F.; Tang X.; Chen P.; Jiao L.","Zhang, Xiangrong (55802358000); Li, Zhenyu (56512574400); Zhang, Tianyang (57219551169); Liu, Fengsheng (57255784400); Tang, Xu (57020306700); Chen, Puhua (57138970200); Jiao, Licheng (7102491544)","55802358000; 56512574400; 57219551169; 57255784400; 57020306700; 57138970200; 7102491544","Remote Sensing Image Super-Resolution via Dual-Resolution Network Based on Connected Attention Mechanism","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3106681","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114716910&doi=10.1109%2fTGRS.2021.3106681&partnerID=40&md5=d893c214453b17ad688d72c70fa1d35a","Limited by hardware conditions and complex degradation processes, the obtained remote sensing images (RSIs) are often low-resolution (LR) data with insufficient high-frequency information. Image super-resolution (SR) aims to improve the spatial resolution of images and add reasonable detailed information. Although existing convolutional neural network (CNN)-based methods achieve good performance by adding residual structure and attention mechanism to the network, simply stacking the residual structure and embedding the attention module directly on the residual branch lead to localized use of features and information loss. To address the above problems, we propose a dual-resolution connected attention network (DRCAN). Specifically, a high-resolution (HR) learning branch is constructed to complement the mapping learning between LR images and HR images, and a connected attention module with residual learning is introduced to make full use of the different levels of intermediate layer features. Besides, we collect data at different resolutions from Google Earth to form a dataset named XD IPIU for RSIs SR. Extensive experiments demonstrate the effectiveness of the proposed model and DRCAN shows the state-of-the-art performance in terms of quantitative evaluation and visual quality. © 2021 IEEE.","Convolutional neural networks; Optical resolving power; Remote sensing; Attention mechanisms; Degradation process; Different resolutions; High-frequency informations; Image super resolutions; Quantitative evaluation; Remote sensing images; State-of-the-art performance; artificial neural network; complexity; degradation; hardware; image resolution; interpolation; mapping; Markov chain; reconstruction; remote sensing; satellite imagery; spatial resolution; Image enhancement","Degradation; Feature extraction; Hidden Markov models; Image reconstruction; Interpolation; Remote sensing; Superresolution","Article","Final","","Scopus","2-s2.0-85114716910"
"Feng J.; Jiang Q.; Tseng C.-H.; Jin X.; Liu L.; Zhou W.; Yao S.","Feng, Jianan (57221777999); Jiang, Qian (57194699462); Tseng, Ching-Hsun (57212460507); Jin, Xin (56991832300); Liu, Ling (57469001800); Zhou, Wei (56857006600); Yao, Shaowen (24473851600)","57221777999; 57194699462; 57212460507; 56991832300; 57469001800; 56857006600; 24473851600","A Deep Multitask Convolutional Neural Network for Remote Sensing Image Super-Resolution and Colorization","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5407915","","","","10.1109/TGRS.2022.3154435","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125305269&doi=10.1109%2fTGRS.2022.3154435&partnerID=40&md5=0956d6ccf81099dce55e802b8ed1d94c","Remote sensing data have become increasingly vital in target detection, disaster monitoring, and military surveillance. Abundant pan-sharpening and super-resolution (SR) methods based on deep learning have been proposed and have achieved remarkable performance. However, pan-sharpening requires paired panchromatic (PAN) and multispectral (MS) images, and SR cannot increase the spectral resolution of PAN. Thus, we introduce a computational imaging-based method to recover or produce the incomplete data of single PAN or MS. This work also explores the integration of multiple tasks by a single neural network. We start with SR and colorization, study the feasibility of simultaneously finishing SR colorization, and use a model trained in SR colorization to finish pan-sharpening without MS. A generic neural network, remote sensing image improvement network (RSI-Net), is designed for remote sensing image SR, colorization, simultaneous SR colorization, and pan-sharpening. To verify its performance, RSI-Net is compared with the state-of-the-art SR and colorization methods. Experiments show that RSI-Net can be competitive in visual effects and evaluation indexes, and it performs well at simultaneous SR colorization, and RSI-Net finishes pan-sharpening and only needs to input PAN. Our experiments confirm the effect of integrating multiple tasks. © 1980-2012 IEEE.","Computational Imaging; Deep neural networks; Image analysis; Job analysis; Military photography; Optical resolving power; Remote sensing; Convolutional neural network; Deep learning; Features extraction; Gray scale; Image color analysis; Image colorizations; Image super resolutions; Neural-networks; Remote sensing images; Remote-sensing; Task analysis; artificial neural network; image resolution; machine learning; numerical model; remote sensing; satellite imagery; Convolution","Convolutional neural network (CNN); deep learning (DL); image colorization; image super-resolution (SR); remote sensing image","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85125305269"
"Liu L.; Li W.; Shi Z.; Zou Z.","Liu, Liqin (57215536317); Li, Wenyuan (57204784272); Shi, Zhenwei (23398841900); Zou, Zhengxia (56073977200)","57215536317; 57204784272; 23398841900; 56073977200","Physics-Informed Hyperspectral Remote Sensing Image Synthesis With Deep Conditional Generative Adversarial Networks","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5528215","","","","10.1109/TGRS.2022.3173532","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130678301&doi=10.1109%2fTGRS.2022.3173532&partnerID=40&md5=d0c26ffea5447d5804eb35757065b4df","High-resolution hyperspectral remote sensing images are of great significance to agricultural, urban, and military applications. However, collecting and labeling hyperspectral images are time-consuming, expensive, and usually heavily rely on domain knowledge. In this article, we propose a new method for generating high-resolution hyperspectral images and subpixel ground-truth annotations from RGB images. Given a single high-resolution RGB image as its conditional input, unlike previous methods that directly predict spectral reflectance and ignores the physics behind it, we consider both imaging mechanism and spectral mixing, introduce a deep generative network that first recovers the spectral abundance for each pixel, and then generate the final spectral data cube with the standard USGS spectral library. In this way, our method not only synthesizes high-quality spectral data existing in the real world but also generates subpixel-level spectral abundance with well-defined spectral reflectance characteristics. We also introduce a spatial discriminative network and a spectral discriminative network to improve the fidelity of the synthetic output from both spatial and spectral perspectives. The whole framework can be trained end-to-end in an adversarial training paradigm. We refer to our method as 'Physics-informed Deep Adversarial Spectral Synthesis (PDASS).' On the IEEE grss_dfc_2018 dataset, our method achieves an MPSNR of 47.56 on spectral reconstruction accuracy and outperforms other state-of-the-art methods. As latent variables, the generated spectral abundance and the atmospheric absorption coefficients of sunlight also suggest the effectiveness of our method.  © 1980-2012 IEEE.","Generative adversarial networks; Hyperspectral imaging; Military applications; Optical resolving power; Pixels; Reflection; Remote sensing; Spectroscopy; Adversarial networks; Atmospheric modeling; Generation adversarial network; Images reconstruction; Imaging modeling; Remote-sensing; Spatial resolution; Spectral super-resolution; Superresolution; artificial neural network; image analysis; image resolution; imaging method; physics; pixel; remote sensing; satellite imagery; spectral analysis; Image reconstruction","Generation adversarial networks (GANs); hyperspectral image; imaging model; remote sensing; spectral super-resolution (SSR)","Article","Final","","Scopus","2-s2.0-85130678301"
"Xu J.; Liu W.; Qin Y.; Xu G.","Xu, Jianming (57825321000); Liu, Weichun (57835195800); Qin, Yang (57824901700); Xu, Guangrong (57825155200)","57825321000; 57835195800; 57824901700; 57825155200","Image Super-Resolution Reconstruction Method for Lung Cancer CT-Scanned Images Based on Neural Network","2022","BioMed Research International","2022","","3543531","","","","10.1155/2022/3543531","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135202208&doi=10.1155%2f2022%2f3543531&partnerID=40&md5=8e459600bfbbcca736f32e75179aefb6","The super-resolution (SR) reconstruction of a single image is an important image synthesis task especially for medical applications. This paper is studying the application of image segmentation for lung cancer images. This research work is utilizing the power of deep learning for resolution reconstruction for lung cancer-based images. At present, the neural networks utilized for image segmentation and classification are suffering from the loss of information where information passes through one layer to another deep layer. The commonly used loss functions include content-based reconstruction loss and generative confrontation network. The sparse coding single-image super-resolution reconstruction algorithm can easily lead to the phenomenon of incorrect geometric structure in the reconstructed image. In order to solve the problem of excessive smoothness and blurring of the reconstructed image edges caused by the introduction of this self-similarity constraint, a two-layer reconstruction framework based on a smooth layer and a texture layer is proposed for a medical application of lung cancer. This method uses a global nonzero gradient number constrained reconstruction model to reconstruct the smooth layer. The proposed sparse coding method is used to reconstruct high-resolution texture images. Finally, a global and local optimization models are used to further improve the quality of the reconstructed image. An adaptive multiscale remote sensing image super-division reconstruction network is designed. The selective core network and adaptive gating unit are integrated to extract and fuse features to obtain a preliminary reconstruction. Through the proposed dual-drive module, the feature prior drive loss and task drive loss are transmitted to the super-resolution network. The proposed work not only improves the subjective visual effect but the robustness has also been enhanced with more accurate construction of edges. The statistical evaluators are used to test the viability of the proposed scheme. © 2022 Jianming Xu et al.","Algorithms; Humans; Image Processing, Computer-Assisted; Lung Neoplasms; Neural Networks, Computer; Tomography, X-Ray Computed; Article; computer assisted tomography; deep learning; deep neural network; human; image processing; image reconstruction; image segmentation; lung cancer; reconstruction algorithm; remote sensing; algorithm; diagnostic imaging; image processing; lung tumor; procedures; x-ray computed tomography","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85135202208"
"Qu T.; Zhang Y.; Wu J.","Qu, Tan (55489972700); Zhang, Yan (57210134646); Wu, Jiaji (8567123700)","55489972700; 57210134646; 8567123700","A novel AFNCS algorithm for super-resolution SAR in curve trajectory","2021","Multimedia Systems","27","4","","837","844","7","10.1007/s00530-020-00715-z","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096238318&doi=10.1007%2fs00530-020-00715-z&partnerID=40&md5=af7aa8cc513bb397697e384d480b2548","With the improvement of SAR resolution, super-resolution SAR imaging is more and more widely used in the all-time and all-weather video surveillance and remote sensing imaging. One implementation of super-resolution SAR is that radar works in the spotlight mode. In the case with highly squinted angle and acceleration, the azimuth space variance and the coupling between range and azimuth will become serious in super-resolution imaging. Thus, an azimuth frequency nonlinear chirp scaling algorithm is proposed to solve this problem. Based on the acceleration model, the accurate 2-D spectrum is performed by adopting the method of series reversion. The space-variance of missile-borne SAR in curved flight path is analyzed and an azimuth polynomial phase filter is constructed to make the coefficients of the perturbation function has sufficient flexibility to eliminate the spatial-variant couple terms between range and azimuth. In addition, the gradient operation is used to expand the space-variant coefficients of azimuth modulation term, and the perturbation function is applied to eliminate the space-variant in azimuth direction. The proposed focusing method can process the missile-borne SAR data obtained in spotlight mode in highly squinted angle with high efficiency. The simulation results verify the effectiveness of the proposed imaging approach. The integration of the research in this paper and the deep learning will further pave the way of super-resolution SAR imaging applications in disaster monitoring, security and surveillance. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Deep learning; Image segmentation; Missiles; Optical resolving power; Remote sensing; Security systems; Space-based radar; Synthetic aperture radar; Acceleration models; Azimuth modulation; Disaster monitoring; Non-linear chirp scaling; Perturbation functions; Remote sensing imaging; Security and surveillances; Super resolution imaging; Radar imaging","Azimuth frequency nonlinear chirp scaling; Curve trajectory; Spotlight SAR; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85096238318"
"Zhang L.; Nie J.; Wei W.; Li Y.; Zhang Y.","Zhang, Lei (56042339600); Nie, Jiangtao (57215969384); Wei, Wei (56421092200); Li, Yong (57194455274); Zhang, Yanning (56075029000)","56042339600; 57215969384; 56421092200; 57194455274; 56075029000","Deep Blind Hyperspectral Image Super-Resolution","2021","IEEE Transactions on Neural Networks and Learning Systems","32","6","9136736","2388","2400","12","10.1109/TNNLS.2020.3005234","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107500508&doi=10.1109%2fTNNLS.2020.3005234&partnerID=40&md5=cdfa5bb0199ff0a21eca6628d64bf7ef","The production of a high spatial resolution (HR) hyperspectral image (HSI) through the fusion of a low spatial resolution (LR) HSI with an HR multispectral image (MSI) has underpinned much of the recent progress in HSI super-resolution. The premise of these signs of progress is that both the degeneration from the HR HSI to LR HSI in the spatial domain and the degeneration from the HR HSI to HR MSI in the spectral domain are assumed to be known in advance. However, such a premise is difficult to achieve in practice. To address this problem, we propose to incorporate degeneration estimation into HSI super-resolution and present an unsupervised deep framework for 'blind' HSIs super-resolution where the degenerations in both domains are unknown. In this framework, we model the latent HR HSI and the unknown degenerations with deep network structures to regularize them instead of using handcrafted (or shallow) priors. Specifically, we generate the latent HR HSI with an image-specific generator network and structure the degenerations in spatial and spectral domains through a convolution layer and a fully connected layer, respectively. By doing this, the proposed framework can be formulated as an end-To-end deep network learning problem, which is purely supervised by those two input images (i.e., LR HSI and HR MSI) and can be effectively solved by the backpropagation algorithm. Experiments on both natural scene and remote sensing HSI data sets show the superior performance of the proposed method in coping with unknown degeneration either in the spatial domain, spectral domain, or even both of them. © 2012 IEEE.","Backpropagation; Image resolution; Optical resolving power; Remote sensing; Spectroscopy; Strain measurement; High spatial resolution; Image super resolutions; Multispectral images; Network learning; Network structures; Spatial resolution; Spectral domains; Super resolution; Deep learning","Deep unsupervised learning; fusion-based hyperspectral image (HSI) super-resolution; unknown degeneration","Article","Final","","Scopus","2-s2.0-85107500508"
"Wang X.; Ma J.; Jiang J.","Wang, Xinya (57221484390); Ma, Jiayi (26638975600); Jiang, Junjun (54902306100)","57221484390; 26638975600; 54902306100","Hyperspectral Image Super-Resolution via Recurrent Feedback Embedding and Spatial-Spectral Consistency Regularization","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3064450","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103154134&doi=10.1109%2fTGRS.2021.3064450&partnerID=40&md5=3a60f2a90cd489f4c9dfe55dc330e857","Hyperspectral images with tens to hundreds of spectral bands usually suffer from low spatial resolution due to the limitation of the amount of incident energy. Without auxiliary images, the single hyperspectral image super-resolution (SR) method is still a challenging problem because of the high-dimensionality characteristic and special spectral patterns of hyperspectral images. Failing to thoroughly explore the coherence among hyperspectral bands and preserve the spatial-spectral structure of the scene, the performance of existing methods is still limited. In this article, we propose a novel single hyperspectral image SR method termed RFSR, which models the spectrum correlations from a sequence perspective. Specifically, we introduce a recurrent feedback network to fully exploit the complementary and consecutive information among the spectra of the hyperspectral data. With the group strategy, each grouping band is first super-resolved by exploring the consecutive information among groups via feedback embedding. For better preservation of the spatial-spectral structure among hyperspectral data, a regularization network is subsequently appended to enforce spatial-spectral correlations over the intermediate estimation. Experimental results on both natural and remote sensing hyperspectral images demonstrate the advantage of our approach over the state-of-the-art methods. © 1980-2012 IEEE.","Embeddings; Optical resolving power; Recurrent neural networks; Remote sensing; High dimensionality; Hyperspectral Data; Image super resolutions; Regularization networks; Spatial resolution; Spectral correlation; Spectrum correlations; State-of-the-art methods; data set; image analysis; image classification; image resolution; remote sensing; spatial analysis; spectral analysis; Spectroscopy","Feedback embedding; hyperspectral image; recurrent network; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85103154134"
"Zhang L.; Dong R.; Yuan S.; Li W.; Zheng J.; Fu H.","Zhang, Lixian (57207392945); Dong, Runmin (57205415789); Yuan, Shuai (57213198049); Li, Weijia (57191833776); Zheng, Juepeng (57207468262); Fu, Haohuan (8713118400)","57207392945; 57205415789; 57213198049; 57191833776; 57207468262; 8713118400","Making low-resolution satellite images reborn: A deep learning approach for super-resolution building extraction","2021","Remote Sensing","13","15","2872","","","","10.3390/rs13152872","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111456677&doi=10.3390%2frs13152872&partnerID=40&md5=8b9774360fba9ad74970857feb2c743a","Existing methods for building extraction from remotely sensed images strongly rely on aerial or satellite-based images with very high resolution, which are usually limited by spatiotem-porally accessibility and cost. In contrast, relatively low-resolution images have better spatial and temporal availability but cannot directly contribute to fine-and/or high-resolution building ex-traction. In this paper, based on image super-resolution and segmentation techniques, we propose a two-stage framework (SRBuildingSeg) for achieving super-resolution (SR) building extraction using relatively low-resolution remotely sensed images. SRBuildingSeg can fully utilize inherent information from the given low-resolution images to achieve high-resolution building extraction. In contrast to the existing building extraction methods, we first utilize an internal pairs generation module (IPG) to obtain SR training datasets from the given low-resolution images and an edge-aware super-resolution module (EASR) to improve the perceptional features, following the dual-encoder building segmentation module (DES). Both qualitative and quantitative experimental results demonstrate that our proposed approach is capable of achieving high-resolution (e.g., 0.5 m) building extraction results at 2×, 4× and 8× SR. Our approach outperforms eight other methods with respect to the extraction result of mean Intersection over Union (mIoU) values by a ratio of 9.38%, 8.20%, and 7.89% with SR ratio factors of 2, 4, and 8, respectively. The results indicate that the edges and borders reconstructed in super-resolved images serve a pivotal role in subsequent building extraction and reveal the potential of the proposed approach to achieve super-resolution building extraction. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Antennas; Buildings; Deep learning; Extraction; Image segmentation; Optical resolving power; Remote sensing; Building extraction; Image super resolutions; Low resolution images; Remotely sensed images; Segmentation techniques; Temporal availability; Training data sets; Very high resolution; Image enhancement","Building extraction; Deep learning; Remote sensing imagery; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85111456677"
"Zhang Z.; Zhang C.; Wu M.; Han Y.; Yin H.; Kong A.; Chen F.","Zhang, Ziyun (57215773184); Zhang, Chengming (16835435800); Wu, Menxin (7405594817); Han, Yingjuan (57225052187); Yin, Hao (57215779384); Kong, Ailing (57215534548); Chen, Fangfang (57225034051)","57215773184; 16835435800; 7405594817; 57225052187; 57215779384; 57215534548; 57225034051","Super-resolution method using generative adversarial network for Gaofen wide-field-view images","2021","Journal of Applied Remote Sensing","15","2","028506","","","","10.1117/1.JRS.15.028506","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109017050&doi=10.1117%2f1.JRS.15.028506&partnerID=40&md5=1e874a476e14df20afcb3c7a1509cd13","Accurate information on the spatial distribution of crops is of great significance for scientific research and production practices. Such accurate information can be extracted from high-spatial-resolution optical remote sensing images. However, acquiring these images with a wide coverage is difficult. We established a model named multispectral super-resolution generative adversarial network (MS_SRGAN) for generating high-resolution 4-m images using Gaofen 1 wide-field-view (WFV) 16-m images. The MS_SRGAN model contains a generator and a discriminator. The generator network is composed of feature extraction units and feature fusion units with a symmetric structure, and the attention mechanism is introduced to constrain the spectral value of the feature map during feature extraction. The generator loss introduces feature loss to describe the feature difference of the image. This is realized using pre-trained discriminator parameters and a partial discriminator network. In addition to realizing feature loss, the discriminator network, which is a simple convolutional neural network, also realizes adversarial loss. Adversarial loss can provide some fake high frequency details to the generator to get a more sharpened image. In the Gaofen 1 WFV image test, the performance of MS_SRGAN was compared with that of Bicubic, EDSR, SRGAN, and ESRGAN. The results show that the spectral angle mapper (3.387) and structural similarity index measure (0.998) of MS_SRGAN are higher than those of the other models. In addition, the image obtained by MS_SRGAN is more realistic; its texture details and color distribution are closer to the reference image to a greater extent.  © The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.","Convolutional neural networks; Extraction; Feature extraction; Image acquisition; Optical resolving power; Remote sensing; Textures; Attention mechanisms; High spatial resolution; Optical remote sensing; Scientific researches; Spectral angle mappers; Structural similarity index measures; Superresolution methods; Symmetric structures; Discriminators","convolutional neural network; Gaofen 1 WFV image; Gaofen 2 image; generative adversarial network; multispectral image; super-resolution","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85109017050"
"Zhao M.; Ning J.; Hu J.; Li T.","Zhao, Minghua (55477788900); Ning, Jiawei (57214794541); Hu, Jing (57191473546); Li, Tingting (57226062696)","55477788900; 57214794541; 57191473546; 57226062696","Hyperspectral Image Super-Resolution via Deep Image Gradient Guided Residual Dense Network","2022","Proceedings of SPIE - The International Society for Optical Engineering","12083","","120830G","","","","10.1117/12.2623589","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125574593&doi=10.1117%2f12.2623589&partnerID=40&md5=84fd99e4a6148eb19a61a21db792a984","Hyperspectral image (HSI) super-resolution attracts the great interest in remote sensing, since its effectiveness in obtaining the HSI with rich spatial information while preserving the high spectral discriminative ability, without modifying the imagery equipment. This paper proposes a novel HSI super-resolution method via gradient guided residual dense network (G-RDN), in which the spatial gradient is utilized to guide the super-resolution process. Specifically, there are three modules in the super-resolving process. Firstly, the spatial mapping between the low-resolution HSI and the desired high resolution HSI is learnt via a residual dense network. The residual dense network (RDN) is exploited to fully exploit the hierarchical features learnt from all the convolutional layers. Meanwhile, the gradient detail is extracted via a residual net (ResNet), which is further utilized to guide the super-resolution process. Finally, the fully obtained global hierarchical features is merged with the gradient details via an empirical weight. Experimental results and data analysis on three benchmark datasets show that our method achieves favorable performance. © 2022 SPIE.","Benchmarking; Remote sensing; Spectroscopy; Dense network; Hierarchical features; Image gradients; Image super resolutions; Learn+; Remote-sensing; Residual dense network; Resolution process; Spatial gradients; Superresolution; Optical resolving power","Hyperspectral image; Residual dense network; Spatial gradient; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85125574593"
"Chen H.; Luo B.","Chen, Hang (55778342600); Luo, Bin (57209592752)","55778342600; 57209592752","Multi⁃angle Remote Sensing Images Super⁃Resolution Reconstruction Using Dynamic Upsampling Filter Deep Network; [利用动态上采样滤波深度网络进行多角度遥感影像超分辨率重建]","2021","Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University","46","11","","1716","1726","10","10.13203/j.whugis20200651","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119097648&doi=10.13203%2fj.whugis20200651&partnerID=40&md5=3e4a441e97e82e6f7f3c4931cad35024","Objectives: Deep learning based on super⁃resolution reconstruction technology has been widely used in multi⁃temporal hyperspectral images, high⁃resolution image reconstruction. Multi⁃angle remote sensing images have rich complementary information, which is suitable for super⁃resolution reconstruction. Methods: An end⁃to⁃end super⁃resolution reconstruction method based on dynamic upsampling filter network is proposed for high⁃resolution multi⁃angle remote sensing images. The network of the method includes an end⁃to⁃end two⁃way network, in which one branch is used dynamic upsampling filter block to improve the image resolution. Another branch network is used to learn the high⁃frequency information in the image. In order to verify the effectiveness of the proposed method, 2, 3 and 4 times super⁃resolution reconstruction simulation experiments and real experiments are carried out with Worldview⁃2 multi⁃angle remote sensing images from Atlanta,America and Rio de Janeiro, Brazil, respectively. Several groups of comparative experiments are carried out. Results and Conclusions: Experimental results show that the proposed method can effectively improve the spatial resolution of the target image while taking into account the angle dimension information of multi angle images, and effectively maintain the image details. © 2021, Editorial Board of Geomatics and Information Science of Wuhan University. All right reserved.","Atlanta; Brazil; Georgia; Rio de Janeiro [Brazil]; Rio de Janeiro [Rio de Janeiro (STT)]; United States; Atlanta; Deep learning; Image enhancement; Image reconstruction; Image resolution; Remote sensing; Signal sampling; Deep learning; Dynamic upsampling filter; End to end; Image super-resolution reconstruction; Multi-angle remote sensing; Multi-temporal; Multi⁃angle remote sensing image; Remote sensing images; Super-resolution reconstruction; Up-sampling filter; computer simulation; filter; image resolution; machine learning; reconstruction; remote sensing; spatial resolution; Spectroscopy","Deep learning; Dynamic upsampling filter; Multi⁃angle remote sensing images; Super⁃resolution reconstruction","Article","Final","","Scopus","2-s2.0-85119097648"
"Wu Y.; Chen Z.; He S.; Wang J.","Wu, Yiming (57221662991); Chen, Zeyu (57221425723); He, Shiming (55286036700); Wang, Jin (57200027740)","57221662991; 57221425723; 55286036700; 57200027740","Information multiple distillation super resolution network based on feedback mechanism","2021","TENSYMP 2021 - 2021 IEEE Region 10 Symposium","","","","","","","10.1109/TENSYMP52854.2021.9550997","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117457358&doi=10.1109%2fTENSYMP52854.2021.9550997&partnerID=40&md5=4847568c722556f05378edee5fb52ff1","There are lots of image data in the field of remote sensing, most of which have low-resolution due to the limited image sensor. The super-resolution method can effectively restore the low-resolution image to the high-resolution image. However, the existing super-resolution method has both heavy computing burden and number of parameters, which greatly limits the super resolution method in the mobile terminal. For saving costs, we propose the information multiple distillation network based on feedback mechanism (Feedback-IMDN), which considers the feedback mechanism as the framework to attain lower features through high-level refining. Further, for high-level feature extraction, we use the information multiple distillation blocks (IMDBs) to carry out hierarchical feature extraction with the method of course learning in the case of a small number of parameters. Compared to other state-of-the-art lightweight algorithms, our proposed algorithm can reach convergences more rapidly with fewer parameters, and the performance of the network can be markedly enhanced on the image texture and object contour reconstruction with better peak signal-to-noise ratio (PSNR) and structural similarity (SSIM).  © 2021 IEEE.","Distillation; Extraction; Feature extraction; Feedback control; Image coding; Image enhancement; Image reconstruction; Image texture; Parameter estimation; Remote sensing; Signal to noise ratio; Textures; Feedback mechanisms; High-resolution images; Image data; Low resolution images; Lower resolution; Mobile terminal; Network-based; Remote-sensing; Superresolution; Superresolution methods; Optical resolving power","feedback mechanism; information distillation; super resolution","Conference paper","Final","","Scopus","2-s2.0-85117457358"
"Chen R.; Li X.; Zhang Y.; Zhou P.; Wang Y.; Shi L.; Jiang L.; Ling F.; Du Y.","Chen, Rui (57215416824); Li, Xiaodong (55878368700); Zhang, Yihang (55658053900); Zhou, Pu (57225050471); Wang, Yalan (57225059331); Shi, Lingfei (57193206756); Jiang, Lai (57225033677); Ling, Feng (56278268300); Du, Yun (56420121700)","57215416824; 55878368700; 55658053900; 57225050471; 57225059331; 57193206756; 57225033677; 56278268300; 56420121700","Spatiotemporal continuous impervious surface mapping by fusion of landsat time series data and google earth imagery","2021","Remote Sensing","13","12","2409","","","","10.3390/rs13122409","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108988939&doi=10.3390%2frs13122409&partnerID=40&md5=e3789c0808a62b35847625cc241a40ef","The monitoring of impervious surfaces in urban areas using remote sensing with fine spatial and temporal resolutions is crucial for monitoring urban development and environmental changes in urban areas. Spatiotemporal super-resolution mapping (STSRM) fuses fine-spatial-coarsetemporal remote sensing data with coarse-spatial-fine-temporal data, allowing for urban impervious surface mapping at both fine-spatial and fine-temporal resolutions. The STSRM involves two main steps: unmixing the coarse-spatial-fine-temporal remote sensing data to class fraction images, and downscaling the fraction images to sub-pixel land cover maps. Yet, challenges exist in each step when applying STSRM in mapping impervious surfaces. First, the impervious surfaces have high spectral variability (i.e., high intra-class and low inter-class variability), which impacts the accurate extraction of sub-pixel scale impervious surface fractions. Second, downscaling the fraction images to sub-pixel land cover maps is an ill-posed problem and would bring great uncertainty and error in the predictions. This paper proposed a new Spatiotemporal Continuous Impervious Surface Mapping (STCISM) method to deal with these challenges in fusing Landsat and Google Earth imagery. The STCISM used the Multiple Endmember Spectral Mixture Analysis and the Fisher Discriminant Analysis to minimize the within-class variability and maximize the between-class variability to reduce the spectral unmixing uncertainty. In addition, the STCISM adopted a new temporal consistency check model to incorporate temporal contextual information to reduce the uncertainty in the time-series impervious surface prediction maps. Unlike the traditional temporal consistency check model that assumed the impervious-to-pervious conversion is unlikely to happen, the new model allowed the bidirectional conversions between pervious and impervious surfaces. The temporal consistency check was used as a post-procession method to correct the errors in the prediction maps. The proposed STCISM method was used to predict time-series impervious surface maps at 5 m resolution of Google Earth image at the Landsat frequency. The results showed that the proposed STCISM outperformed the STSRM model without using the temporal consistency check and the STSRM model using the temporal consistency check based on the unidirectional pervious-to-impervious surface conversion rule. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Discriminant analysis; Fisher information matrix; Forecasting; Mapping; Pixels; Remote sensing; Time series; Uncertainty analysis; Urban growth; Contextual information; Environmental change; Fisher discriminant analysis; Multiple endmember spectral mixture analysis; Spatial and temporal resolutions; Spectral variability; Super-resolution mappings; Urban impervious surfaces; Model checking","Impervious surface; Landsat; Spectral variability; Temporal consistency; Time series","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85108988939"
"Cui H.; Zhang G.; Wang T.-Y.; Li X.; Qi J.","Cui, Hao (57210701957); Zhang, Guo (57204670748); Wang, Tao-Yang (55940283500); Li, Xin (56996899300); Qi, Ji (57211483444)","57210701957; 57204670748; 55940283500; 56996899300; 57211483444","Combined Model Color-Correction Method Utilizing External Low-Frequency Reference Signals for Large-Scale Optical Satellite Image Mosaics","2021","IEEE Transactions on Geoscience and Remote Sensing","59","6","9193955","4993","5007","14","10.1109/TGRS.2020.3018591","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106764133&doi=10.1109%2fTGRS.2020.3018591&partnerID=40&md5=6259dfb5224fa90b420ddee2a0d381d7","Optical satellites are affected by factors such as seasonal and atmospheric variation, illumination, and sensor distortion. Thus, satellite images covering large-scale area often show conspicuous color differences, resulting in poor color continuity of the mosaicked satellite image. This study proposes a novel combined model color correction (CMCC) method for high-resolution optical satellite images, which constructively combines a defogging model with a radiation correction model. First, this study analyzed the feasibility of using easily available low-resolution satellite images as external references to correct the color of high-resolution images and describes the selection criteria for external references. Second, considering the negative effects of atmosphere on the color and clarity of remote sensing images, we proposed an optical satellite image enhancement method, which is based on the content characteristics of remote sensing images and the dark channel prior defogging method. Finally, we designed a two-stage color correction process: 1) correcting the color of downsampled images via low-frequency modeling and replacement and 2) mapping the color of downsampled images to original images through local modeling and super-resolution color correction. Furthermore, this study proposes an indicator of quality considered mean absolute error (QCMAE) for quantitative evaluation of the color correction result. We selected 328 Gaofen-1 (GF-1) high-resolution images for the experiments. Visual effects and statistical results of images after being processed by the proposed CMCC are both superior to the three state-of-the-art methods, which verifies the effectiveness and reliability of the proposed method.  © 1980-2012 IEEE.","Indicator indicator; Satellites; Color; Image enhancement; Optical resolving power; Remote sensing; Satellites; Atmospheric variations; High resolution image; High-resolution optical satellite images; Mean absolute error; Optical satellite images; Quantitative evaluation; Remote sensing images; State-of-the-art methods; color; correction; frequency analysis; optical method; satellite imagery; seasonal variation; sensor; signal processing; Color image processing","Color correction; image enhancement; image mosaic; low frequency signal","Article","Final","","Scopus","2-s2.0-85106764133"
"Raimundo J.; Lopez-Cuervo Medina S.; Prieto J.F.","Raimundo, J. (57221918066); Lopez-Cuervo Medina, S. (57221910882); Prieto, J.F. (7201826710)","57221918066; 57221910882; 7201826710","Resolution enhancement of infrared thermal imaging by pansharpening algorithms","2021","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","46","M-1-2021","","593","599","6","10.5194/isprs-archives-XLVI-M-1-2021-593-2021","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118597221&doi=10.5194%2fisprs-archives-XLVI-M-1-2021-593-2021&partnerID=40&md5=09b4972e218839812e364528aa179902","One common tool in Cultural Heritage inspections is thermal cameras, which are sensitive to the infrared part of the electromagnetic spectrum. But the resolution of these sensors is quite lower than other kinds like visible spectrum range cameras. Typically, the sensors in thermal cameras do not exceed the megapixel frontier. This limitation becomes a problem when trying to combine the information from the thermal images with data from other sensors with much higher resolution such as visible RGB cameras in the same project.</p>In Remote Sensing, algorithms have been designed to fuse multispectral images with panchromatic images (in origin from satellite platforms) to enhance the resolution of lower resolution images with higher resolution ones. These processes are known as pansharpening. Although pansharpening procedures are widely known, they have not been tested working with thermal imaging. The first approach of merging thermal and visual spectrum images to enhance the resolution of the original thermal image involved applying the intensity-hue-saturation (IHS) algorithm (Laguela et al., 2012, Kuenzer and Dech, 2013). These works only studied one particular algorithm and they did not include any quality study of the results.</p>Our work contains a complete review of a bigger pansharpening algorithms' set and provides an in-depth study of thermal imaging pansharpening, with a numerical assessment. Our research allows the use of thermal sensors with a lower resolution than other types of sensors used simultaneously in the same project. © 2021 International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives. All Rights Reserved.","Cameras; Image enhancement; Infrared devices; Infrared imaging; High resolution; Infrared thermal imaging; Multi-spectral; Pan-sharpening; Remote-sensing; Resolution enhancement; Superresolution; Thermal camera; Thermal images; Thermal-imaging; Remote sensing","Infrared; Multispectral; Pansharpening; Remote Sensing; Resolution Enhancement; Super-resolution; Thermal Imaging","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85118597221"
"Zhang N.; Wang Y.; Zhang X.; Xu D.; Wang X.; Ben G.; Zhao Z.; Li Z.","Zhang, Ning (57188816117); Wang, Yongcheng (56437944700); Zhang, Xin (57774426900); Xu, Dongdong (56299205100); Wang, Xiaodong (57208088951); Ben, Guangli (57195509421); Zhao, Zhikang (57221303854); Li, Zheng (57206872666)","57188816117; 56437944700; 57774426900; 56299205100; 57208088951; 57195509421; 57221303854; 57206872666","A Multi-Degradation Aided Method for Unsupervised Remote Sensing Image Super Resolution with Convolution Neural Networks","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2020.3042460","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098758819&doi=10.1109%2fTGRS.2020.3042460&partnerID=40&md5=59cb2f182a51c3e6373198b42dfd1fdd","In remote sensing, it is desirable to improve image resolution by using the image super-resolution (SR) technique. However, there are two challenges: the first one is that high-resolution (HR) images are insufficient or unavailable; another one is that the single degradation model such as bicubic (BIC) cannot super-resolve favorable images in the real world. To address the above two problems, this article presents a multi-degradation, unsupervised SR method based on deep learning. This framework consists of a degrader $ {D}$ to fit the image degradation model and a generator $ {G}$ to generate SR image. By introducing $ {D}$, calculating the loss function between SR image and HR image as supervised SR methods did can be converted into calculating loss between low resolution (LR) image and image degraded by SR image, thereby realizing unsupervised learning. Experiments on several degradation models show that our method renders the state-of-the-art results compared with existing unsupervised SR methods, and achieves competitive results in contrast with supervised SR methods. Moreover, for real remote sensing images obtained by the Jilin-1 satellite, our method obtained more plausible results visually, which demonstrate the potential in real-world applications.  © 1980-2012 IEEE.","Deep learning; Image resolution; Learning systems; Neural networks; Optical resolving power; Remote sensing; Convolution neural network; Degradation model; High resolution image; Image degradation model; Image super resolutions; Low resolution images; Remote sensing images; State of the art; artificial neural network; degradation; image resolution; remote sensing; satellite; Image enhancement","Deep neural network (DNN); multi-degradation; remote sensing image; super-resolution (SR); unsupervised learning","Article","Final","","Scopus","2-s2.0-85098758819"
"Lei S.; Shi Z.","Lei, Sen (57195618353); Shi, Zhenwei (23398841900)","57195618353; 23398841900","Hybrid-Scale Self-Similarity Exploitation for Remote Sensing Image Super-Resolution","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3069889","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104266856&doi=10.1109%2fTGRS.2021.3069889&partnerID=40&md5=db5fce18b6d5c0840886eb78613e5769","Recently, deep convolutional neural networks (CNNs) have made great progress in remote sensing image super-resolution (SR). The CNN-based methods can learn powerful feature representation from plenty of low- and high-resolution counterparts. For remote sensing images, there are many similar ground targets recurred inside the image itself, both within the same scale and across different scales. In this article, we argue that this internal recurrence can be used for learning stronger feature representation, and we propose a new hybrid-scale self-similarity exploitation network (HSENet) for remote sensing image SR. Specifically, we introduce a single-scale self-similarity exploitation module (SSEM) to compute the feature correlation within the same scale image. Moreover, we design a cross-scale connection structure (CCS) to capture the recurrences across different scales. By combining SSEM and CCS, we further develop a hybrid-scale self-similarity exploitation module (HSEM) to construct the final HSENet, which simultaneously exploits single- and cross-scale similarities. Experimental results demonstrate that HSENet can obtain superior performance over several state-of-the-art methods. Besides, the effectiveness of our method is also verified by the assistance to the remote sensing scene classification task. © 1980-2012 IEEE.","Convolutional neural networks; Deep neural networks; Optical resolving power; Connection structures; Feature correlation; Feature representation; Remote sensing images; Scale similarity; Scene classification; Self-similarities; State-of-the-art methods; artificial neural network; classification; correlation; design; remote sensing; Remote sensing","Deep convolutional neural networks (CNNs); Remote sensing images; Self-similarity; Super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85104266856"
"","","","2022 IEEE Mediterranean and Middle-East Geoscience and Remote Sensing Symposium, M2GARSS 2022 - Proceedings","2022","2022 IEEE Mediterranean and Middle-East Geoscience and Remote Sensing Symposium, M2GARSS 2022 - Proceedings","","","","","","208","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136436295&partnerID=40&md5=5a86bbc9bb605d8d037ab367f80cd9db","The proceedings contain 50 papers. The topics discussed include: a new active image captioning fusion strategy; a relevant, hard and diverse triplet sampling method for multi-label remote sensing image retrieval; learning to align Arabic and English text to remote sensing images using transformers; a joint semantic segmentation loss function for imbalanced datasets; rapid mapping of landslides from sentinel-2 data using unsupervised deep learning; local spectral super-resolution for ALSAT-2B images with application to anomaly detection; an encoder-decoder U-Net based model for overheated photovoltaic modules extraction from orthorectified remotely sensed thermal infrared UAV imagery; spectral unmixing and clustering techniques for changes detection in multitemporal hyperspectral remote sensing data; nonnegative tensor factorization based fusion for changes detection in multiresolution remote sensing images; and fully unsupervised binary change detection for hyperspectral images using Laplacian eigenmaps and clustering.","","","Conference review","Final","","Scopus","2-s2.0-85136436295"
"Wang Z.; Li L.; Xue Y.; Jiang C.; Wang J.; Sun K.; Ma H.","Wang, Zheyuan (57609170600); Li, Liangliang (57892001300); Xue, Yuan (57606502800); Jiang, Chenchen (57607036200); Wang, Jiawen (57449876800); Sun, Kaipeng (57406783200); Ma, Hongbing (57198975424)","57609170600; 57892001300; 57606502800; 57607036200; 57449876800; 57406783200; 57198975424","FeNet: Feature Enhancement Network for Lightweight Remote-Sensing Image Super-Resolution","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5622112","","","","10.1109/TGRS.2022.3168787","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128670155&doi=10.1109%2fTGRS.2022.3168787&partnerID=40&md5=46e3e206eca19b28ab01a3dd7ed1d1cf","In the field of remote sensing, due to memory consumption and computational burden, the single-image super-resolution (SISR) methods based on deep convolution neural networks (CNNs) are limited in practical application. To address this problem, we propose a lightweight feature enhancement network (FeNet) for accurate remote-sensing image super-resolution (SR). Considering the existence of equipment with extremely poor hardware facilities, we further design a lighter FeNet-baseline with about 158K parameters. Specifically, inspired by lattice structure, we construct a lightweight lattice block (LLB) as a nonlinear feature extraction function to improve the expression ability. Here, channel separation operation makes the upper and lower branches of the LLB only responsible for half of the features, and the weight coefficients calculated through the attention mechanism enable the upper and lower branches to communicate efficiently. Based on LLB, the feature enhancement block (FEB) is designed in a nested manner to obtain expressive features, where different layers are responsible for the features with different texture richness, and then features from different layers are sequentially fused from deep to shallow. Model parameters and multi-adds operations are used to evaluate network complexity, and extensive experiments on two remote-sensing and four SR benchmark test datasets show that our methods can achieve a good tradeoff between complexity and performance. Our code will be available at https://github.com/wangzheyuan-666/FeNet.  © 1980-2012 IEEE.","Benchmarking; Complex networks; Convolution; Deep neural networks; Economic and social effects; Extraction; Image enhancement; Image reconstruction; Optical resolving power; Remote sensing; Convolutional neural network; Feature enhancement; Features extraction; Head; Image super resolutions; Images reconstruction; Lightweight feature enhancement network; Remote-sensing; Single image super-resolution; Single images; Superresolution; Task analysis; data set; design; image resolution; remote sensing; Feature extraction","Convolutional neural network; lightweight feature enhancement network (FeNet); remote sensing; single image super-resolution (SISR)","Article","Final","","Scopus","2-s2.0-85128670155"
"Lin L.; Shen H.; Li J.; Yuan Q.","Lin, Liupeng (57188711703); Shen, Huanfeng (8359721100); Li, Jie (57214207213); Yuan, Qiangqiang (36635300800)","57188711703; 8359721100; 57214207213; 36635300800","FDFNet: A Fusion Network for Generating High-Resolution Fully PolSAR Images","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2021.3127958","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119419650&doi=10.1109%2fLGRS.2021.3127958&partnerID=40&md5=215cca509f66d5718108a8b76fb52cee","Deep learning shows potential superiority in the image fusion field. To solve the problem of the spatial resolution degradation of polarimetric synthetic aperture radar (PolSAR) images caused by system limitation, we propose a fully PolSAR images and DualSAR images fusion network (FDFNet). We use low resolution (LR)-PolSAR super-resolution (LPSR) and modified cross attention mechanism (MCroAM) to perform data fusion on LR-PolSAR and high resolution (HR)-dual-polarization synthetic aperture radar (DualSAR) and design a polarimetric decomposition attention module to introduce the polarimetric parameters of LR-PolSAR images to maintain polarimetric information. Besides, we use the differential information between LR-PolSAR and HR-DualSAR to guide spatial resolution reconstruction. The loss function based on the L1 norm is used to constrain the network training process. The experimental results show the superiority of the proposed method over the existing methods in visual and quantitative evaluation. In addition, polarimetric decomposition experiments verify the effectiveness of the proposed method to maintain polarimetric information.  © 2004-2012 IEEE.","Deep learning; Image resolution; Polarimeters; Differential information; Dual-polarization SAR; Fully polarimetric SAR; High resolution; L1 norm; Loss functions; Polarimetric decomposition; Polarimetric informations; Polarimetric parameters; Spatial resolution; decomposition analysis; image analysis; learning; quantitative analysis; remote sensing; spatial resolution; synthetic aperture radar; Image fusion","Differential information; dual-polarization synthetic aperture radar (DualSAR); fully-polarimetric synthetic aperture radar (PolSAR); fusion; polarimetric decomposition","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85119419650"
"Wu H.; Zhang L.; Ma J.","Wu, Hanlin (57221263814); Zhang, Libao (35325855000); Ma, Jie (57205916758)","57221263814; 35325855000; 57205916758","Remote Sensing Image Super-Resolution via Saliency-Guided Feedback GANs","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2020.3042515","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098788589&doi=10.1109%2fTGRS.2020.3042515&partnerID=40&md5=315a94441bc03b62dc3b253c3b5166c6","In remote sensing images (RSIs), the visual characteristics of different regions are versatile, which poses a considerable challenge to single image super-resolution (SISR). Most existing SISR methods for RSIs ignore the diverse reconstruction needs of different regions and thus face a serious contradiction between high perception quality and less spatial distortion. The mean square error (MSE) optimization-based methods produce results of unsatisfactory visual quality, while generative adversarial networks (GANs) can produce photo-realistic but severely distorted results caused by pseudotextures. In addition, increasingly deeper networks, although providing powerful feature representations, also face problems of overfitting and occupying too much storage space. In this article, we propose a new saliency-guided feedback GAN (SG-FBGAN) to address these problems. The proposed SG-FBGAN applies different reconstruction principles for areas with varying levels of saliency and uses feedback (FB) connections to improve the expressivity of the network while reducing parameters. First, we propose a saliency-guided FB generator with our carefully designed paired-feedback block (PFBB). The PFBB uses two branches, a salient and a nonsalient branch, to handle the FB information and generate powerful high-level representations for salient and nonsalient areas, respectively. Then, we measure the visual perception quality of salient areas, nonsalient areas, and the global image with a saliency-guided multidiscriminator, which can dramatically eliminate pseudotextures. Finally, we introduce a curriculum learning strategy to enable the proposed SG-FBGAN to handle complex degradation models. Comprehensive evaluations and ablation studies validate the effectiveness of our proposal.  © 1980-2012 IEEE.","Learning systems; Mean square error; Optical resolving power; Space optics; Adversarial networks; Comprehensive evaluation; Degradation model; Feature representation; Learning strategy; Optimization based methods; Remote sensing images; Spatial distortion; algorithm; image resolution; remote sensing; satellite imagery; Remote sensing","Deep learning (DL); generative adversarial network (GAN); remote sensing; saliency detection; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85098788589"
"Chen X.; Guo S.; Jia H.; Liu B.; Li Z.; Han Z.","Chen, Xi’ai (57157869600); Guo, Siyu (57848420300); Jia, Huidi (57211911074); Liu, Baichen (57218386564); Li, Zhenyu (57847518400); Han, Zhi (56438533600)","57157869600; 57848420300; 57211911074; 57218386564; 57847518400; 56438533600","Group Sparsity Regularized High Order Tensor for HSIs Super-Resolution","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13458 LNAI","","","125","137","12","10.1007/978-3-031-13841-6_12","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136927379&doi=10.1007%2f978-3-031-13841-6_12&partnerID=40&md5=a2333413bd15051995a1d0404b6084b6","Super-resolution of hyperspectral images is a crucial task in remote sensing applications. In this paper, we propose a group sparsity regularized high order tensor model for hyperspectral images super-resolution. In our model, a relaxed low tensor train rank estimation strategy is applied to exploit the correlations of local spatial structure along the spectral mode. Weighted group sparsity regularization is used to model the local group sparsity. An efficient algorithm is derived under the framework of alternative direction multiplier method. Extensive experimental results on public datasets have proved that the proposed method is effective compared with the state-of-art methods. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Optical resolving power; Remote sensing; Spectroscopy; Group sparsities; Higher-order tensor; HSI super-resolution; HyperSpectral; Image super resolutions; Relaxed tensor train rank; Remote sensing applications; Superresolution; Tensor model; Tensor trains; Tensors","Group sparsity; High order tensor; HSI super-resolution; Relaxed tensor train rank","Conference paper","Final","","Scopus","2-s2.0-85136927379"
"Tao Y.; Muller J.-P.","Tao, Yu (56539197700); Muller, Jan-Peter (7404871794)","56539197700; 7404871794","Super-resolution restoration of spaceborne ultra-high-resolution images using the ucl optigan system","2021","Remote Sensing","13","12","2269","","","","10.3390/rs13122269","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108893859&doi=10.3390%2frs13122269&partnerID=40&md5=5a4502223f127ddc550ac2a938414e15","We introduce a robust and light-weight multi-image super-resolution restoration (SRR) method and processing system, called OpTiGAN, using a combination of a multi-image maximum a posteriori approach and a deep learning approach. We show the advantages of using a combined twostage SRR processing scheme for significantly reducing inference artefacts and improving effective resolution in comparison to other SRR techniques. We demonstrate the optimality of OpTiGAN for SRR of ultra-high-resolution satellite images and video frames from 31 cm/pixel WorldView-3, 75 cm/pixel Deimos-2 and 70 cm/pixel SkySat. Detailed qualitative and quantitative assessments are provided for the SRR results on a CEOS-WGCV-IVOS geo-calibration and validation site at Baotou, China, which features artificial permanent optical targets. Our measurements have shown a 3.69 times enhancement of effective resolution from 31 cm/pixel WorldView-3 imagery to 9 cm/pixel SRR. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Image enhancement; Optical resolving power; Restoration; Calibration and validations; Effective resolutions; Learning approach; Maximum a posteriori; Processing systems; Qualitative and quantitative assessments; Super-resolution restoration; Ultrahigh resolution; Image reconstruction","Deimos-2; Earth observation; EarthDaily Analytics®; Generative adversarial network; HD video; Maxar® WorldView-3; OpTiGAN; Planet® SkySat; Remote sensing; Satellite; Super-resolution restoration; Ultra-high resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85108893859"
"Cai J.; Huang B.","Cai, Jiajun (57193551962); Huang, Bo (55388074800)","57193551962; 55388074800","Super-Resolution-Guided Progressive Pansharpening Based on a Deep Convolutional Neural Network","2021","IEEE Transactions on Geoscience and Remote Sensing","59","6","9172104","5206","5220","14","10.1109/TGRS.2020.3015878","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106733063&doi=10.1109%2fTGRS.2020.3015878&partnerID=40&md5=677f8d68e0827b186dbd9b0d4c91eab0","Pansharpening and super-resolution (SR) methods share the same target to improve the spatial resolution of images. Based on this similarity, we propose and develop a novel pansharpening algorithm that is guided by a deep SR convolutional neural network. The proposed framework comprises three components: an SR process, a progressive pansharpening process, and a high-pass residual module. Specifically, the SR process extracts inner spatial detail that is present in multispectral images. Then, progressive pansharpening is used as a detailed pansharpening process, and the high-pass residual module helps by directly injecting spatial detail from panchromatic images. The performance of the proposed network has been compared with that of traditional and other deep-learning-based pansharpening algorithms based on QuickBird, WorldView-3, and Landsat-8 data, and the results demonstrate the superiority of our algorithm.  © 1980-2012 IEEE.","Convolution; Deep learning; Deep neural networks; Image enhancement; Optical resolving power; High-pass; Multispectral images; Pan-sharpening; Panchromatic images; Quickbird; Spatial resolution; Super resolution; Three component; algorithm; artificial neural network; data processing; image resolution; panchromatic image; remote sensing; satellite imagery; Convolutional neural networks","Deep learning; multispectral (MS) image; panchromatic image; pansharpening; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85106733063"
"Li J.; Du S.; Song R.; Wu C.; Li Y.; Du Q.","Li, Jiaojiao (55934244200); Du, Songcheng (57413650000); Song, Rui (36460216100); Wu, Chaoxiong (57218706945); Li, Yunsong (55986546100); Du, Qian (7202060063)","55934244200; 57413650000; 36460216100; 57218706945; 55986546100; 7202060063","HASIC-Net: Hybrid Attentional Convolutional Neural Network with Structure Information Consistency for Spectral Super-Resolution of RGB Images","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5522515","","","","10.1109/TGRS.2022.3142258","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122858286&doi=10.1109%2fTGRS.2022.3142258&partnerID=40&md5=e05db093819dfaa94cd87c105ab1c454","Spectral super-resolution (SSR), referring to the recovery of a reasonable hyperspectral image (HSI) from a single RGB image, has achieved satisfactory performance as part of the continued development of a convolutional neural network (CNN) in remote sensing image processing. However, the majority of existing algorithms focus on the pursuit of networks with deeper or broader architecture. Such algorithms have a poor channel or band feature extraction and fusing performance, and fail to fully leverage the input RGB images. To overcome these issues, we present a novel hybrid attentional CNN with structure information consistency (HASIC-net) that uses a two-pathway architecture. Specifically, both sides are stacked with several 2-D residual groups (2-DRGs) and residual groups (1-DRGs) equipped with channel or band attention (BA) modules, which mainly focuses on extracting channel statistics and bandwise features, respectively, by a parallel pooling architecture. We introduce several transversal connections from 2-DRG to 1-DRG to realize the interaction of information flow between both sides. In addition, we take the structure information of both RGB images and HSI into consideration and devise a structure information consistency (SIC) module to merge the structure tensor prior to the RGB images with the input of each 2-DRG. We then combine spectral gradient constraint loss with mean relative absolute error as a novel loss function to further restrain the spectral distortion and smooth the reconstructed spectral response curves. Experimental results on four benchmark datasets (i.e., NTIRE 2020, NTIRE 2018, CAVE, and Harvard) demonstrate that our proposed HASIC-net achieves state-of-the-art performance. © 1980-2012 IEEE.","Benchmarking; Convolution; Deep neural networks; Extraction; Feature extraction; Hyperspectral imaging; Network architecture; Optical resolving power; Remote sensing; Silicon carbide; Spectroscopy; Channel or band attention module; Convolutional neural network; Encodings; Features extraction; Images reconstruction; Spectral gradient constraint; Spectral gradients; Spectral super-resolution; Structure information; Structure information consistency; Superresolution; hybrid; information system; resolution; spectral analysis; Image reconstruction","Channel or band attention (BA) modules (CBAMs); spectral gradient constraint; spectral super-resolution (SSR); structure information consistency (SIC)","Article","Final","","Scopus","2-s2.0-85122858286"
"Jiang W.; Zhao L.; Wang Y.-J.; Liu W.; Liu B.-D.","Jiang, Wenzong (57275223800); Zhao, Lifei (57274635800); Wang, Yan-Jiang (57223714000); Liu, Weifeng (36739405100); Liu, Bao-Di (16319146900)","57275223800; 57274635800; 57223714000; 36739405100; 16319146900","U-Shaped Attention Connection Network for Remote-Sensing Image Super-Resolution","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2021.3127988","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119426625&doi=10.1109%2fLGRS.2021.3127988&partnerID=40&md5=818cd4090e74b2be28e1fdc8444e8d2f","In recent years, deep learning-based remote-sensing image super-resolution (SR) methods have made significant progress, and these methods require a large number of synthetic data for training. To obtain sufficient training data, researchers often generate synthetic data via fixed bicubic downsampling methods. However, the synthesized data cannot reflect the complex degradation process of real remote-sensing images. Thus, performance will dramatically reduce when these methods work in real low-resolution (LR) remote-sensing images. This letter proposes a U-shaped attention connection network (US-ACN) for remote-sensing image SR to solve this issue. Our US-ACN does not rely on any synthetic external dataset for training and merely requires one LR image to complete the training. The US-ACN utilizes remote-sensing images' strong internal feature repetitiveness and fully learns this internal repetitive feature through a well-designed US-ACN to achieve the remote-sensing image SR. In addition, we design a 3-D attention module to generate effective 3-D weights by modeling channel and spatial attention weights, which is more helpful for the learning of internal features. Through the U-shaped connection among attention modules, context information propagation and attention weights learning are fully utilized. Many experiments show that our US-ACN adequately adapts to the remote-sensing image SR in various situations and performs advanced performance.  © 2004-2012 IEEE.","Information dissemination; Optical resolving power; Remote sensing; Attention connection; Down sampling; Image super resolutions; Internal features; Performance; Remote sensing images; Superresolution methods; Synthetic data; Training data; U-shaped; artificial neural network; image resolution; remote sensing; satellite imagery; Deep learning","Attention connection; image super-resolution (SR); internal feature; remote-sensing image; U-shaped","Article","Final","","Scopus","2-s2.0-85119426625"
"Chen X.; Ben Z.","Chen, Xingji (57738164500); Ben, Zhengyi (57737343700)","57738164500; 57737343700","Multi-target Super-resolution Technology of Remote Sensing based on L Regularization","2022","2022 7th International Conference on Intelligent Computing and Signal Processing, ICSP 2022","","","","1747","1751","4","10.1109/ICSP54964.2022.9778607","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131840267&doi=10.1109%2fICSP54964.2022.9778607&partnerID=40&md5=f420e7237bdee27cb65f33dcda75b1d5","Based on regularization theory, L regularizer is used as a constraint term for regularized deconvolution for super-resolution imaging of remote sensing targets. In this paper, a super-resolution imaging model is established with L regulars as constraints, and the super-resolution imaging problem is transformed into a constrained optimization problem. Then, a half - threshold iterative algorithm for L - regular deconvolution convolution model is derived. Finally, point target simulation shows that the super-resolution imaging method based on L-regular deconvolution can achieve lower relative error than truncated singular value decomposition (TSVD) results, and has higher azimuth resolution and better robustness. © 2022 IEEE.","Constrained optimization; Convolution; Deconvolution; Image processing; Iterative methods; Remote sensing; Singular value decomposition; Deconvolutions; L regularization; Multi-targets; Regularisation; Regularization theory; Remote sensing images; Remote-sensing; Signal-processing; Super resolution imaging; Superresolution; Optical resolving power","L regularization; remote sensing image; signal processing; super resolution","Conference paper","Final","","Scopus","2-s2.0-85131840267"
"Mu J.; Li S.; Liu Z.; Zhou Y.","Mu, Jinzhen (57219133143); Li, Shuang (56288781000); Liu, Zongming (57869062600); Zhou, Yan (57188815143)","57219133143; 56288781000; 57869062600; 57188815143","Integration of gradient guidance and edge enhancement into super-resolution for small object detection in aerial images","2021","IET Image Processing","15","13","","3037","3052","15","10.1049/ipr2.12288","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108818533&doi=10.1049%2fipr2.12288&partnerID=40&md5=a24cfb4a97fbcc4a87bdf786f63f3dd2","Detecting small objects are difficult because of their poor-quality appearance and small size, and such issues are especially pronounced for aerial images of great importance. To address the small object detection (SOD) problem, a united architecture that tries to upsample small objects into super-resolved versions, achieving characteristics similar to those large objects and thus resulting in more discriminative detection is used. For this purpose, a new end-to-end multi-task generative adversarial network (GAN) is proposed. In the architecture, the generator is a super-resolution (SR) network, and the discriminator is a multi-task network. In the generator, a gradient guide and an edge-enhancement strategy are introduced to alleviate structural distortions. In the discriminator, a faster region-based convolutional neural network (FRCNN) is incorporated for the task of object detection. Specifically, the discriminator outputs a distribution scalar to measure the realness. Then, each super-resolved image passes through the discriminator with a realness distribution, classification scores, and bounding box regression offsets. Furthermore, the losses of the detection task are backpropagated into the generator during training rather than being optimized independently. Extensive experiments on the challenging cars overhead with context dataset (COWC), detectIon in optical remote sensing images (DIOR), vision meets drones (VisDrone), and dataset for object detection in aerial images (DOTA) demonstrate the effectiveness of the proposed method in reconstructing structures while generating natural super-resolved images and show the superiority of the proposed method in detecting small objects over state-of-the-art detectors. © 2021 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology","Air navigation; Aircraft detection; Antennas; Backpropagation; Convolutional neural networks; Discriminators; Image enhancement; Image segmentation; Network architecture; Object recognition; Optical resolving power; Remote sensing; Adversarial networks; Detection tasks; Edge enhancements; Optical remote sensing; Small object detection; State of the art; Structural distortions; Super resolution; Object detection","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85108818533"
"Han X.; Zhang H.; Xue J.-H.; Sun W.","Han, Xiaolin (57201580646); Zhang, Huan (57223176585); Xue, Jing-Hao (7202881908); Sun, Weidong (55726588900)","57201580646; 57223176585; 7202881908; 55726588900","A Spectral-Spatial Jointed Spectral Super-Resolution and Its Application to HJ-1A Satellite Images","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2021.3073501","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105074272&doi=10.1109%2fLGRS.2021.3073501&partnerID=40&md5=7a11accf0d9c52b411f065ac459ca18e","To generate a high-spatial-resolution hyperspectral (HHS) image from a high-spatial-resolution multispectral (HMS) image, both spatial information and spectral information should be considered simultaneously if we want to build a more accurate mapping from HMS to HHS. To this end, a spectral and spatial jointed spectral super-resolution method is proposed in this letter using an end-to-end learning strategy for each subspace with the cluster-based multibranch backpropagation neural network (BPNN). More specifically, in addition to the spectra similarity, a modified superpixel segmentation is introduced to jointly take spatial contextual information into account, and a new framework with it is given. Comparisons on the Columbia University Automated Vision Environment (CAVE) data set show that our proposed method outperforms other relative state-of-the-art methods more than 0.3 in the root mean squared error (RMSE) and more than 1.0 in the spectral angle mapper (SAM) index. Especially, an exemplary application is demonstrated using the synchronized observation data collected by the multispectral and hyperspectral sensors mounted on the HJ-1A satellite at the same time.  © 2004-2012 IEEE.","Backpropagation; Image resolution; Learning systems; Mean square error; Optical resolving power; Back-propagation neural networks; Contextual information; High spatial resolution; Root mean squared errors; Spectral angle mappers; State-of-the-art methods; Superpixel segmentations; Superresolution methods; remote sensing; satellite imagery; spectral analysis; spectral resolution; Photomapping","HJ-1A satellite image; spectral and spatial jointed; spectral super-resolution; subspace-based learning","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85105074272"
"Wei W.; Nie J.; Zhang L.; Zhang Y.","Wei, Wei (56421092200); Nie, Jiangtao (57215969384); Zhang, Lei (56042339600); Zhang, Yanning (56075029000)","56421092200; 57215969384; 56042339600; 56075029000","Unsupervised Recurrent Hyperspectral Imagery Super-Resolution Using Pixel-Aware Refinement","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2020.3039534","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097937518&doi=10.1109%2fTGRS.2020.3039534&partnerID=40&md5=6d47c9ca25098c249f7d3a2cf9f3ec9a","Unsupervised fusion-based hyperspectral imagery (HSI) super-resolution (SR) is an essential task of HSI processing, which aims to reconstruct a high-resolution (HR) HSI using only an observed low-resolution HSI and a conventional HR image. Although a large number of unsupervised HSI SR methods have been proposed, the heuristic handcrafted image priors adopted by the majority of these methods restrict their capacity to capture specific characteristics of the HSI, as well as their ability to generalize to noisy observation images. In this study, we investigate a fusion-based HSI SR framework with the deep image prior, in which the deep neural network (rather than a heuristic handcrafted image prior) is exploited to capture plenty of image statistics. Within this framework, we further propose an unsupervised recurrence-based HSI SR method using pixel-aware refinement, which utilizes the intermediate reconstruction results to self-supervise unsupervised learning. Due to containing the information of the image-specific characteristic, the proposed method achieves better performance, in terms of both accuracy and robustness to noise, compared with the existing methods. Extensive experiments on four HSI data sets demonstrate the effectiveness of the proposed method.  © 1980-2012 IEEE.","Deep neural networks; Image fusion; Optical resolving power; Pixels; Recurrent neural networks; Remote sensing; Spectroscopy; High resolution; Hyper-spectral imageries; Hyperspectral imagery; Image statistics; Low resolution; Noisy observations; Robustness to noise; Super resolution; Heuristic methods","Hyperspectral image super-resolution (SR); pixel-aware refinement; unsupervised deep learning","Article","Final","","Scopus","2-s2.0-85097937518"
"Li X.; Ling F.; Foody G.M.; Boyd D.S.; Jiang L.; Zhang Y.; Zhou P.; Wang Y.; Chen R.; Du Y.","Li, Xiaodong (55878368700); Ling, Feng (56278268300); Foody, Giles M. (7007014233); Boyd, Doreen S. (7202871470); Jiang, Lai (57225033677); Zhang, Yihang (55658053900); Zhou, Pu (57225050471); Wang, Yalan (57225059331); Chen, Rui (57215416824); Du, Yun (56420121700)","55878368700; 56278268300; 7007014233; 7202871470; 57225033677; 55658053900; 57225050471; 57225059331; 57215416824; 56420121700","Monitoring high spatiotemporal water dynamics by fusing MODIS, Landsat, water occurrence data and DEM","2021","Remote Sensing of Environment","265","","112680","","","","10.1016/j.rse.2021.112680","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114126166&doi=10.1016%2fj.rse.2021.112680&partnerID=40&md5=2b086e179f40e92ec2abc271b9d6f934","Monitoring the spatiotemporal dynamics of surface water from remote sensing imagery is essential for understanding water's impact on the global ecosystem and climate change. There is often a tradeoff between the spatial and temporal resolutions of imagery acquired from current satellite sensors and as such various spatiotemporal image fusion methods have been explored to circumvent the challenges this situation presents (e.g., STARFM). However, some challenges persist in mapping surface water at the desired fine spatial and temporal resolution. Principally, the spatiotemporal changes of water bodies are often abrupt and controlled by topographic conditions, which are usually unaddressed in current spatiotemporal image fusion methods. This paper proposes the SpatioTemporal Surface Water Mapping (STSWM) method, which aims to predict Landsat-like, 30 m, surface water maps at an 8-day time step (same as the MODIS 8-day composite product) by integrating topographic information into the analysis. In addition to MODIS imagery acquired on the date of map prediction and a pair of MODIS and Landsat images acquired temporally close to the date of prediction, STSWM also uses the surface water occurrence (SWO, which represents the frequency with which water is present in a pixel) and DEM data to provide, respectively, topographic information below and above the water surface. These data are used to translate the coarse spatial resolution water distribution representation observed by MODIS into a 30 m spatial resolution water distribution map. The STSWM was used to generate an 8-day time series surface water maps of 30 m resolution in six inundation regions globally, and was compared with several other state-of-the-art spatiotemporal methods. The stratified random sampling design was used, and unbiased estimators of the accuracies were provided. The results show that STSWM generated the most accurate surface water map in which the spatial details of surface water were well-represented. © 2021 The Authors","Climate change; Forecasting; Image fusion; Image resolution; Mapping; Radiometers; Remote sensing; Satellite imagery; 'current; Abrupt water change; DEM; LANDSAT; Spatial and temporal resolutions; Spatiotemporal images; Spatiotemporal surface water mapping; Super resolution; Surface water occurrence; Water mapping; climate change; data acquisition; digital elevation model; environmental monitoring; Landsat; MODIS; remote sensing; satellite data; satellite imagery; satellite sensor; spatial resolution; spatiotemporal analysis; surface water; trade-off; Surface waters","Abrupt water change; DEM; Spatiotemporal surface water mapping; Superresolution; Surface water occurrence (SWO)","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85114126166"
"Can Karaca A.; Ucurmak I.; Kemal Gullu M.","Can Karaca, Ali (55292760600); Ucurmak, Ibrahim (57221820066); Kemal Gullu, Mehmet (57200237519)","55292760600; 57221820066; 57200237519","Efficient resolution enhancement of JPEG2000 compressed multispectral images using deep super-resolution methods","2021","2021 International Conference on INnovations in Intelligent SysTems and Applications, INISTA 2021 - Proceedings","","","","","","","10.1109/INISTA52262.2021.9548453","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116634147&doi=10.1109%2fINISTA52262.2021.9548453&partnerID=40&md5=74c9b3327bd694433926645fb57d9a3e","Multispectral imaging is one of the most important Earth observation techniques in remote sensing. Although their advantages, multispectral imaging systems continuously capture images resulting in enormous data volumes. To this end, some of the multispectral satellites use JPEG2000 based compression methods. However, the images that are compressed at low bit-rates contain compression artifacts and may present low-performances in remote sensing applications such as target detection and classification. In this paper, we propose the usage of three single image super-resolution methods, SRResNet, EDSR, and WDSR, for the resolution enhancement of JPEG2000 compressed images. First, the multispectral image is subsampled at factor of 4 along both spatial axes, and then the resulting image is compressed with JPEG2000. Finally, super-resolution methods are performed to improve the resolution and reduce the compression artifacts. Experiments were carried out on the Onera dataset shared by IEEE GRSS. The results are compared in terms of quality metrics such as signal-to-noise ratios, mean spectral angle, maximum spectral angle, and maximum absolute difference. Experimental results demonstrate that the proposed approaches provide higher quality metrics and better visual performance compared to bicubic upsampling. © 2021 IEEE.","Digital image storage; Image compression; Image enhancement; Optical resolving power; Signal to noise ratio; Compression artifacts; Image super resolutions; JPEG 2000; JPEG2000 compression; Multispectral images; Multispectral-image compression; Quality metrices; Resolution enhancement; Spectral angles; Superresolution methods; Remote sensing","Image super-resolution; JPEG2000 compression; Multispectral image compression","Conference paper","Final","","Scopus","2-s2.0-85116634147"
"Jia S.; Wang Z.; Li Q.; Jia X.; Xu M.","Jia, Sen (57681305300); Wang, Zhihao (57253694800); Li, Qingquan (55831292900); Jia, Xiuping (7201933692); Xu, Meng (57206827164)","57681305300; 57253694800; 55831292900; 7201933692; 57206827164","Multiattention Generative Adversarial Network for Remote Sensing Image Super-Resolution","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5624715","","","","10.1109/TGRS.2022.3180068","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131761657&doi=10.1109%2fTGRS.2022.3180068&partnerID=40&md5=3ff02c05e0246c450feae23e75918e27","Image super-resolution (SR) methods can generate remote sensing images with high spatial resolution without increasing the cost of acquisition equipment, thereby providing a feasible way to improve the quality of remote sensing images. Clearly, image SR is a severe ill-posed problem. With the development of deep learning, the powerful fitting ability of deep neural networks has solved this problem to some extent. Since the texture information of various remote sensing images are totally different from each other, in this article, we proposed a network based on generative adversarial network (GAN) to achieve high-resolution remote sensing images, named multiattention GAN (MA-GAN). The main body of the generator in MA-GAN contains three blocks: pyramid convolutional residual dense (PCRD) block, attention-based upsampling (AUP) block, and attention-based fusion (AF) block. Specifically, the developed attention pyramid convolutional (AttPConv) operator in the PCRD block combines multiscale convolution and channel attention (CA) to automatically learn and adjust the scale of residuals for better representation. The established AUP block uses pixel attention (PA) to perform arbitrary scales of upsampling. The AF block uses branch attention (BA) to integrate upsampled low-resolution images with high-level features. Besides, the loss function takes both adversarial loss and feature loss into consideration to guide the learning procedure of the generator. We have compared our MA-GAN approach with several state-of-the-art methods on a number of remote sensing scenes, and the experimental results consistently demonstrate the effectiveness of the proposed MA-GAN. For study replication, the source code will be released at: https://github.com/ZhihaoWang1997/MA-GAN.  © 1980-2012 IEEE.","Convolution; Deep neural networks; Image enhancement; Image resolution; Remote sensing; Signal sampling; Generative adversarial network; Generator; Image super resolutions; Remote sensing images; Remote-sensing; Spatial resolution; Super resolution; Superresolution; Task analysis; Upsampling; artificial neural network; experimental study; remote sensing; satellite data; Generative adversarial networks","Generative adversarial network (GAN); remote sensing image; super-resolution (SR)","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85131761657"
"Huang B.; He B.; Wu L.; Guo Z.","Huang, Bo (57221167884); He, Boyong (57214668875); Wu, Liaoni (35103994700); Guo, Zhiming (57193602601)","57221167884; 57214668875; 35103994700; 57193602601","Deep residual dual-attention network for super-resolution reconstruction of remote sensing images","2021","Remote Sensing","13","14","2784","","","","10.3390/rs13142784","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111247775&doi=10.3390%2frs13142784&partnerID=40&md5=0ce1f3977aedcfc82b4a59e86bf88e1b","A super-resolution (SR) reconstruction of remote sensing images is becoming a highly active area of research. With increasing upscaling factors, richer and more abundant details can progressively be obtained. However, in comparison with natural images, the complex spatial distribution of remote sensing data increases the difficulty in its reconstruction. Furthermore, most SR reconstruction methods suffer from low feature information utilization and equal processing of all spatial regions of an image. To improve the performance of SR reconstruction of remote sensing images, this paper proposes a deep convolutional neural network (DCNN)-based approach, named the deep residual dual-attention network (DRDAN), which achieves the fusion of global and local information. Specifically, we have developed a residual dual-attention block (RDAB) as a building block in DRDAN. In the RDAB, we firstly use the local multi-level fusion module to fully extract and deeply fuse the features of the different convolution layers. This module can facilitate the flow of information in the network. After this, a dual-attention mechanism (DAM), which includes both a channel attention mechanism and a spatial attention mechanism, enables the network to adaptively allocate more attention to regions carrying high-frequency information. Extensive experiments indicate that the DRDAN outperforms other comparable DCNN-based approaches in both objective evaluation indexes and subjective visual quality. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolution; Convolutional neural networks; Deep neural networks; Image enhancement; Optical resolving power; Remote sensing; Attention mechanisms; Feature information; Global and local informations; High-frequency informations; Objective evaluation; Reconstruction method; Remote sensing images; Super resolution reconstruction; Image reconstruction","Attention mechanism; Remote sensing; Residual learning; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85111247775"
"Lloyd D.T.; Abela A.; Farrugia R.A.; Galea A.; Valentino G.","Lloyd, David T. (57219569804); Abela, Aaron (57219568988); Farrugia, Reuben A. (16032732100); Galea, Anthony (57202815371); Valentino, Gianluca (43061705400)","57219569804; 57219568988; 16032732100; 57202815371; 43061705400","Optically Enhanced Super-Resolution of Sea Surface Temperature Using Deep Learning","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3094117","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110870667&doi=10.1109%2fTGRS.2021.3094117&partnerID=40&md5=2bfd415934729e4fc46f9cab48032f58","Sea surface temperature (SST) can be measured from space using infrared sensors on Earth-observing satellites. However, the tradeoff between spatial resolution and swath size (and hence revisit time) means that SST products derived from remote sensing measurements commonly only have a moderate resolution (>1 km). In this article, we adapt the design of a super-resolution neural network architecture [specifically very deep super-resolution (VDSR)] to enhance the resolution of both top-of-atmosphere thermal images of sea regions and bottom-of-atmosphere SST images by a factor of 5. When tested on an unseen dataset, the trained neural network yields thermal images that have an RMSE $2-3\times $ smaller than interpolation, with a 6-9 dB improvement in PSNR. A major contribution of the proposed neural network architecture is that it fuses optical and thermal images to propagate the high-resolution information present in the optical image to the restored thermal image. To illustrate the potential benefits of using super-resolution (SR) in the context of oceanography, we present super-resolved SST images of a gyre and an ocean front, revealing details and features otherwise poorly resolved by moderate resolution satellite images. © 1980-2012 IEEE.","Atmospheric temperature; Deep learning; Geometrical optics; Image enhancement; Infrared detectors; Network architecture; Neural networks; Optical resolving power; Remote sensing; Submarine geophysics; Surface properties; Surface waters; Earth observing satellite; Moderate resolution; Potential benefits; Satellite images; Sea surface temperature (SST); Spatial resolution; Top of atmospheres; Trained neural networks; gyre; imaging method; Landsat; satellite sensor; sea surface temperature; Sentinel; spatial resolution; Oceanography","Data fusion; deep learning; gyre; Landsat 8; ocean front; sea surface temperature (SST); Sentinel 3; super-resolution (SR); thermal infrared","Article","Final","","Scopus","2-s2.0-85110870667"
"Deng L.; Zhang Y.; Wang X.","Deng, Liwei (51663261700); Zhang, Yuanzhi (57839766400); Wang, Xiaofei (57219132572)","51663261700; 57839766400; 57219132572","High-definition processing of remote sensing images based on CUT-CycleGAN","2021","Chinese Control Conference, CCC","2021-July","","","8158","8162","4","10.23919/CCC52363.2021.9549656","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117263619&doi=10.23919%2fCCC52363.2021.9549656&partnerID=40&md5=e289a72501a1a8d376e7030485de4cf6","High-definition remote sensing images are more and more widely used in research and life. However, due to hardware conditions and transmission rate limitations, it is too expensive to directly obtain high-definition original images. So, it has become a research hotspot on how to use algorithms to receive high-definition remote sensing images from low-resolution images. In view of the existing super-resolution methods for remote sensing images, the dependence on a large number of matching low-resolution and high-resolution(LR-HR) data sets and the slow network training time. In this paper, contrast learning is used for unpaired image-to-image conversion model (CUT-CycleGAN), which uses cyclic consistency to achieve the purpose of training using unpaired images, and adds a contrast learning framework to effectively shorten CycleGAN's training time and to improve efficiency. The experiment selects SRGAN, CycleGAN, EDSR, and FSRCNN four existing super-resolution methods to compare with the method in this paper. The results show that the training time of CUT-CycleGAN is reduced by nearly 55.7%, and after training with unpaired images, the quality of the generated high-definition images is good enough. © 2021 Technical Committee on Control Theory, Chinese Association of Automation.","Image enhancement; Learning systems; Optical resolving power; Remote sensing; Comparative learning; Condition; High definition; Image-based; Remote sensing images; Remote-sensing; Superresolution; Superresolution methods; Training time; Transmission rates; Generative adversarial networks","Comparative learning; Generative adversarial network; Remote sensing; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85117263619"
"Long J.; Peng Y.; Zhou T.; Zhao L.; Li J.","Long, Jian (57218616379); Peng, Yuanxi (7403418922); Zhou, Tong (57200242626); Zhao, Liyuan (57205879555); Li, Jun (57202722259)","57218616379; 7403418922; 57200242626; 57205879555; 57202722259","Fast and stable hyperspectral multispectral image fusion technique using moore–penrose inverse solver","2021","Applied Sciences (Switzerland)","11","16","7365","","","","10.3390/app11167365","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112548582&doi=10.3390%2fapp11167365&partnerID=40&md5=ddd91497a6e705b2c545db497d1c8cef","Fusion low-resolution hyperspectral images (LR-HSI) and high-resolution multispectral images (HR-MSI) are important methods for obtaining high-resolution hyperspectral images (HR-HSI). Some hyperspectral image fusion application areas have strong real-time requirements for image fusion, and a fast fusion method is urgently needed. This paper proposes a fast and stable fusion method (FSF) based on matrix factorization, which can largely reduce the computational workloads of image fusion to achieve fast and efficient image fusion. FSF introduces the Moore– Penrose inverse in the fusion model to simplify the estimation of the coefficient matrix and uses singular value decomposition (SVD) to simplify the estimation of the spectral basis, thus significantly reducing the computational effort of model solving. Meanwhile, FSF introduces two multiplicative iterative processes to optimize the spectral basis and coefficient matrix to achieve stable and high-quality fusion. We have tested the fusion method on remote sensing and ground-based datasets. The experiments show that our proposed method can achieve the performance of several state-of-the-art algorithms while reducing execution time to less than 1% of such algorithms. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","","Hyperspectral imaging super-resolution; Image fusion; Matrix factorization","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85112548582"
"Liu M.; Shi Q.; Marinoni A.; He D.; Liu X.; Zhang L.","Liu, Mengxi (57208160778); Shi, Qian (55286447700); Marinoni, Andrea (23018988200); He, Da (57188721489); Liu, Xiaoping (15757680000); Zhang, Liangpei (8359720900)","57208160778; 55286447700; 23018988200; 57188721489; 15757680000; 8359720900","Super-Resolution-Based Change Detection Network with Stacked Attention Module for Images with Different Resolutions","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3091758","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112178949&doi=10.1109%2fTGRS.2021.3091758&partnerID=40&md5=48703e9bc5766adbf461bd0008427191","Change detection (CD) aims to distinguish surface changes based on bitemporal images. Since high-resolution (HR) images cannot be typically acquired continuously over time, bitemporal images with different resolutions are often adopted for CD in practical applications. Traditional subpixel-based methods for CD using images with different resolutions may lead to substantial error accumulation when the HR images are employed, which is because of intraclass heterogeneity and interclass similarity. Therefore, it is necessary to develop a novel method for CD using images with different resolutions that are more suitable for the HR images. To this end, we propose a super-resolution-based change detection network (SRCDNet) with a stacked attention module (SAM). The SRCDNet employs a super-resolution (SR) module containing a generator and a discriminator to directly learn the SR images through adversarial learning and overcome the resolution difference between the bitemporal images. To enhance the useful information in multiscale features, a SAM consisting of five convolutional block attention modules (CBAMs) is integrated to the feature extractor. The final change map is obtained through a metric learning-based change decision module, wherein a distance map between bitemporal features is calculated. Ablation study and comparative experiments on two large datasets, building change detection dataset (BCDD) and season-varying change detection dataset (CDD), and a real-image experiment on the Google dataset fully demonstrate the superiority of the proposed method. The source code of SRCDNet is available at https://github.com/liumency/SRCDNet. © 1980-2012 IEEE.","Optical resolving power; Adversarial learning; Building change detection; Comparative experiments; Different resolutions; Feature extractor; High resolution image; Multi-scale features; Substantial errors; data set; detection method; heterogeneity; image analysis; image resolution; spatial resolution; Large dataset","Change detection (CD); fully convolutional networks (FCNs); metric learning; remote sensing images; super-resolution","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85112178949"
"Zhang Y.; Luo J.; Zhang Y.; Huang Y.; Cai X.; Yang J.; Mao D.; Li J.; Tuo X.; Zhang Y.","Zhang, Yongchao (56042343300); Luo, Jiawei (57221234005); Zhang, Yongwei (57207478944); Huang, Yulin (23014806800); Cai, Xiaochun (57879895600); Yang, Jianyu (9239230100); Mao, Deqing (57194656090); Li, Jie (57221237046); Tuo, Xingyu (57213190611); Zhang, Yin (55975581400)","56042343300; 57221234005; 57207478944; 23014806800; 57879895600; 9239230100; 57194656090; 57221237046; 57213190611; 55975581400","Resolution Enhancement for Large-Scale Real Beam Mapping Based on Adaptive Low-Rank Approximation","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5116921","","","","10.1109/TGRS.2022.3202073","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137609564&doi=10.1109%2fTGRS.2022.3202073&partnerID=40&md5=ea0dbc65a91a7481535f3abeecb93992","Recently, a variety of super-resolution (SR) methods have been devoted to enhancing the angular resolution of real beam mapping (RBM) imagery in modern microwave remote sensing applications. When addressing large-scale datasets, however, they suffer from notably high computational complexity due to high-dimensional matrix inversion, multiplication, or singular value decomposition (SVD). To overcome this limitation, this article presents a low-complexity SR strategy based on adaptive low-rank approximation (LRA). Our underlying idea is first to construct a random matrix sketching to sample the raw echo measurements and restore the surface map of reflectivity in a low-dimensional linear space. The resulting low-complexity strategy enables substantial computational complexity reduction for a group of SR methods, at the cost of introducing a manually adjusted LRA parameter. Using the Fourier transform-based antenna analysis method, we further reveal that the LRA parameter that ensures support resolution improvement can be determined by a closed-form function of the aperture length, the wavelength, and the field of view, allowing for adaptively and efficiently selecting the optimal LRA parameter that well balances the tradeoff between LRA error and computational efficiency. We use both simulated and real datasets to demonstrate that the proposed LRA-based SR strategy can provide significant speedup without performance loss.  © 1980-2012 IEEE.","Antennas; Computational complexity; Computational efficiency; Economic and social effects; Image enhancement; Optical resolving power; Remote sensing; Singular value decomposition; Adaptive parameter selection; Adaptive parameters; Closed form; Closed-form function; Form function; Low rank approximations; Low-rank approximation; Parameter selection; Real beam mapping; Super-resolution; Superresolution; antenna; detection method; image resolution; mapping method; parameter estimation; remote sensing; satellite imagery; Mapping","Adaptive parameter selection; closed-form function; low-rank approximation (LRA); real beam mapping (RBM); super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85137609564"
"Ha V.K.; Ren J.; Wang Z.; Sun G.; Zhao H.; Marshall S.","Ha, Viet Khanh (57204285939); Ren, Jinchang (23398632100); Wang, Zheng (24175350400); Sun, Genyun (16317854100); Zhao, Huimin (55715798100); Marshall, Stephen (7401823400)","57204285939; 23398632100; 24175350400; 16317854100; 55715798100; 7401823400","Multiscale Spatial Fusion and Regularization Induced Unsupervised Auxiliary Task CNN Model for Deep Super-Resolution of Hyperspectral Images","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","4583","4598","15","10.1109/JSTARS.2022.3176969","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130794925&doi=10.1109%2fJSTARS.2022.3176969&partnerID=40&md5=f94cc8dc2e42ab19724f944567c2818a","Hyperspectral images (HSI) feature rich spectral information in many narrow bands but at a cost of a relatively low spatial resolution. As such, various methods have been developed for enhancing the spatial resolution of the low-resolution HSI (Lr-HSI) by fusing it with high-resolution multispectral images (Hr-MSI). The difference in spectrum range and spatial dimensions between the Lr-HSI and Hr-MSI has been fundamental but challenging for multispectral/hyperspectral (MS/HS) fusion. In this article, a multiscale spatial fusion and regularization induced auxiliary task based convolutional neural network model is proposed for deep super-resolution of HSI, where an Lr-HSI is fused with an Hr-MSI to reconstruct a high-resolution HSI (Hr-HSI) counterpart. The multiscale fusion is used to efficiently address the discrepancy in spatial resolutions between the two inputs. Based on the general assumption that the acquired Hr-MSI and the reconstructed Hr-HSI share similar underlying characteristics, the auxiliary task is proposed to learn a representation for improved generality of the model and reduced overfitting. Experimental results on five public datasets have validated the effectiveness of our approach in comparison with several state-of-the-art methods.  © 2008-2012 IEEE.","Image enhancement; Image fusion; Image reconstruction; Image resolution; Neural networks; Auxiliary task; Bayes method; Convolutional neural network; Hyperspectral image; Images reconstruction; Multi-scale spatial fusion; Multi-scales; Spatial resolution; Super-resolution; Superresolution; Task analysis; artificial neural network; image processing; model; multispectral image; remote sensing; spatial resolution; unsupervised classification; Spectroscopy","Auxiliary task; convolutional neural networks (CNN); hyperspectral image (HSI); multiscale spatial fusion; super-resolution (SR)","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85130794925"
"Zhang Z.; Gao K.; Wang J.; Min L.; Ji S.; Ni C.; Chen D.","Zhang, Zhenzhou (57215083882); Gao, Kun (57204363389); Wang, Junwei (57211379037); Min, Lei (57220203993); Ji, Shijing (57428079000); Ni, Chong (36094615900); Chen, Dayu (57427658000)","57215083882; 57204363389; 57211379037; 57220203993; 57428079000; 36094615900; 57427658000","Gradient Enhanced Dual Regression Network: Perception-Preserving Super-Resolution for Multi-Sensor Remote Sensing Imagery","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2021.3134798","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123536211&doi=10.1109%2fLGRS.2021.3134798&partnerID=40&md5=2faf188fa46af629816cd2a34010be9c","Most existing learning-based single image super-resolution (SISR) methods mainly focus on improving reconstruction accuracy, but they always generate overly smoothed results that fail to match the visual perception. Although perceptual quality can be greatly improved via introducing adversarial loss, image fidelity may decrease to some extent. Moreover, most methods are trained and evaluated on simulated datasets and their performance would drop significantly on real remote sensing imagery. To solve the above problems, we propose a new SISR algorithm named gradient enhanced dual regression network (GEDRN). Based on the dual regression framework, we use share-source residual structure and non-local operation to learn abundant low-frequency information and long-distance spatial correlations. Besides, we not only introduce additional gradient information to avoid blurry results but also apply gradient loss and perceptual loss to further improve the perceptual quality. Our GEDRN is trained and tested on real-world multi-sensor satellite images. Experimental results demonstrate the superiority of the proposed method in achieving much better perceptual quality and ensuring high fidelity.  © 2004-2012 IEEE.","Image enhancement; Neural networks; Optical resolving power; Remote sensing; Satellite imagery; Convolutional neural network; Gradient enhanced dual regression network; Multi sensor; Multi-sensor satellite imagery; Perceptual quality; Remote sensing imagery; Sensor satellites; Single images; Superresolution; image resolution; regression analysis; satellite imagery; satellite sensor; Regression analysis","Convolutional neural networks (CNNs); gradient enhanced dual regression network (GEDRN); multi-sensor satellite imagery; super-resolution","Article","Final","","Scopus","2-s2.0-85123536211"
"Liu Z.; Feng R.; Wang L.; Han W.; Zeng T.","Liu, Ziyu (57865366100); Feng, Ruyi (55853730300); Wang, Lizhe (57875383600); Han, Wei (57191570975); Zeng, Tieyong (25423412800)","57865366100; 55853730300; 57875383600; 57191570975; 25423412800","Dual Learning-Based Graph Neural Network for Remote Sensing Image Super-Resolution","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5628614","","","","10.1109/TGRS.2022.3199750","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136839906&doi=10.1109%2fTGRS.2022.3199750&partnerID=40&md5=82130dc3860809d4f90603b552e2cddb","High-resolution (HR) remote sensing imagery plays a critical role in remote sensing image interpretation, and single image super-resolution (SISR) reconstruction technology is becoming increasingly valuable and significant. The state-of-the-art deep-learning-based SISR methods have demonstrated remarkable advantages while reconstructing complex texture details still remains a big challenge. Besides, as a typical ill-posed inverse problem, how to determine the optimal solution is another important topic. To address these problems, in this work, a dual learning-based graph neural network (DLGNN) is proposed, in which the graph neural network (GNN) is utilized to consider the self-similarity patches in remote sensing imagery by aggregating cross-scale neighboring feature patches, and dual learning strategy is adopted to refine the reconstruction results by constraining the mapping process in terms of the loss function, transferring the typical ill-posed problem to a well-posed one. Abundant experiments on 3K VEHICLE_SR datasets and Massachusetts Roads demonstrate the validity and outstanding performance for remote sensing image super-resolution (SR) tasks compared with other state-of-the-art SR construction methods. Code is available at https://github.com/CUG-RS/DLGNN. © 1980-2012 IEEE.","Massachusetts; United States; Deep learning; Inverse problems; Job analysis; Optical resolving power; Remote sensing; Dual learning; Features extraction; Graph neural networks; Images reconstruction; Remote sensing imagery; Remote-sensing; Superresolution; Task analysis; artificial neural network; image resolution; remote sensing; satellite imagery; Image reconstruction","Dual learning; graph neural network; remote sensing imagery; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85136839906"
"Li J.; Liu W.; Zhang K.; Liu B.","Li, Jiaoyue (57299552400); Liu, Weifeng (57835192100); Zhang, Kai (55769748056); Liu, Baodi (16319146900)","57299552400; 57835192100; 55769748056; 16319146900","Edge Loss for Remote Sensing Image Super-Resolution","2021","Frontiers in Artificial Intelligence and Applications","345","","","262","267","5","10.3233/FAIA210411","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123641314&doi=10.3233%2fFAIA210411&partnerID=40&md5=19ad01fe50cbbe874f489bddd25ce1e1","Remote sensing image super-resolution (SR) plays an essential role in many remote sensing applications. Recently, remote sensing image super-resolution methods based on deep learning have shown remarkable performance. However, directly utilizing the deep learning methods becomes helpless to recover the remote sensing images with a large number of complex objectives or scene. So we propose an edge-based dense connection generative adversarial network (SREDGAN), which minimizes the edge differences between the generated image and its corresponding ground truth. Experimental results on NWPU-VHR-10 and UCAS-AOD datasets demonstrate that our method improves 1.92 and 0.045 in PSNR and SSIM compared with SRGAN, respectively. © 2022 The authors and IOS Press.","Deep learning; Optical resolving power; Remote sensing; Edge difference; Edge loss; Edge-based; Ground truth; Image super resolutions; Learning methods; Performance; Remote sensing applications; Remote sensing images; Superresolution methods; Generative adversarial networks","Edge loss; Generative adversarial network; Image super-resolution; Remote sensing image","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85123641314"
"Zhang H.; Wang P.; Jiang Z.","Zhang, Haopeng (54788751800); Wang, Pengrui (57210155510); Jiang, Zhiguo (35336923600)","54788751800; 57210155510; 35336923600","Nonpairwise-Trained Cycle Convolutional Neural Network for Single Remote Sensing Image Super-Resolution","2021","IEEE Transactions on Geoscience and Remote Sensing","59","5","9151194","4250","4261","11","10.1109/TGRS.2020.3009224","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104790062&doi=10.1109%2fTGRS.2020.3009224&partnerID=40&md5=4a7426fa96856775f57c39f68be97ca8","Single image super-resolution (SISR) is to recover the high spatial resolution image from a single low spatial resolution one, which is a useful procedure for many remote sensing applications. Most previous convolutional neural network (CNN)-based methods adopt supervised learning. However, paired high-resolution and low-resolution remote sensing images are actually hard to acquire for supervised learning SR methods. To handle this problem, we propose a novel cycle convolutional neural network (Cycle-CNN). Our network consists of two generative CNNs for down-sampling and SR separately and can be trained with unpaired data. We perform comprehensive experiments on panchromatic and multispectral images of the GaoFen-2 satellite and the UC Merced land use data set. Experimental results indicate that our method achieves state-of-the-art CNN-based SR results and is robust against noise and blur in remote sensing images. Comprehensively considering super-resolved image quality and time costs, our proposed method outperforms the compared learning-based SISR approaches. © 1980-2012 IEEE.","Convolution; Image resolution; Land use; Learning systems; Optical resolving power; Remote sensing; Supervised learning; High resolution; High spatial resolution images; Low resolution; Multispectral images; Remote sensing applications; Remote sensing images; Spatial resolution; State of the art; algorithm; data set; detection method; image resolution; remote sensing; satellite imagery; spatial resolution; supervised learning; Convolutional neural networks","Convolutional neural network (CNN); nonpairwise training; remote sensing image; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85104790062"
"Liu C.; Fan Z.; Zhang G.","Liu, Cong (57887302900); Fan, Zhihao (57887990500); Zhang, Guixu (55803635500)","57887302900; 57887990500; 55803635500","GJTD-LR: A Trainable Grouped Joint Tensor Dictionary With Low-Rank Prior for Single Hyperspectral Image Super-Resolution","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5537617","","","","10.1109/TGRS.2022.3204049","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137886760&doi=10.1109%2fTGRS.2022.3204049&partnerID=40&md5=fb82f25c23cca270ee72672f8eb2b87a","Reconstructing a high-resolution hyperspectral image (HR-HSI) using a single low-resolution hyperspectral image (LR-HSI) is a significant technique for increasing the spatial resolution of HSIs and overcoming the physical limitation of the HSI sensor. Most single HSI super-resolution methods have achieved great success recently. However, owning to the difficulty of acquiring an HSI, the available training samples are relatively few, which will inevitably lead to relatively low performance. To address this issue, in this article, we propose a novel single HSI super-resolution method by combining a trainable grouped joint tensor dictionary and a low-rank prior (GJTD-LR). First, we design a trainable grouped joint tensor dictionary, which can build an accurate mapping relationship between training HR-HSIs and their corresponding LR-HSIs with relatively few training samples. To be specific, the training HR-HSI and LR-HSI pairs are decomposed into a joint tensor dictionary and a set of sparse coefficients using tensor-tensor product to fully preserve the spectral correlation. In addition, we apply a grouped strategy to divide the training images into several groups and learn a compact joint dictionary for each group. Second, a tensor low-rank model is forced into the reconstruction model to further capture the spatial correlation. Finally, GJTD-LR is optimized using alternating direction method of multipliers (ADMM), soft threshold algorithm, singular value decomposition, and Fourier domain transform. The experimental results on both remote sensed HSIs and indoor HSIs show the superiority of GJTD-LR to some other traditional and advanced single HSI super-resolution methods.  © 1980-2012 IEEE.","Image reconstruction; Image resolution; Remote sensing; Sampling; Singular value decomposition; Spectroscopy; Correlation; Group joint tensor dictionary; HyperSpectral; Hyperspectral image super-resolution; Image super resolutions; Images reconstruction; Low-rank prior; Spatial resolution; Superresolution; Tensor products; Tensor-tensor product; algorithm; image resolution; Tensors","Group joint tensor dictionary; hyperspectral image (HSI) super-resolution; low-rank prior; tensor-tensor product","Article","Final","","Scopus","2-s2.0-85137886760"
"Reddy K.A.; Teja P.S.V.S.P.; Teja G.K.; Divya K.; Aravinth J.","Reddy, Kasu Ameesh (57852602400); Teja, Potti Sri Venkata Surya Pavan (57852674300); Teja, Grandhi Krishna (57289571100); Divya, Karanam (57214485938); Aravinth, J. (55315364600)","57852602400; 57852674300; 57289571100; 57214485938; 55315364600","Multispectral Image Super Resolution with Auto-Encoder Model and Fusion Technique","2022","7th International Conference on Communication and Electronics Systems, ICCES 2022 - Proceedings","","","","1485","1490","5","10.1109/ICCES54183.2022.9835943","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136322455&doi=10.1109%2fICCES54183.2022.9835943&partnerID=40&md5=b5f012da60b65a052cbe1f7b4f1dcc7a","Obtaining High Resolution(HR) Multispectral Images which are not readily available is one of the more critical objectives in remote sensing applications as these images can be used for various agricultural applications and previously various other methods like pansharpening have been introduced. This paper proposes a novel convolutional auto-encoder for training the multispectral images obtained from Sentinel -2A Satellite and then pass the degraded multispectral image to obtain the reconstructed Multispectral Image which is spectrally enhanced and then fuse the image obtained from reconstruction with the original degraded image to obtain a spatial HR Multispectral Image. This fusion is done using various state of the art methods like Principal Component Analysis(PCA), Discrete Wavelet Transform Level-l(DWT) and Stationary Wavelet Transform Level-l(SWT) and the performance metrics.  © 2022 IEEE.","Convolution; Discrete wavelet transforms; Image enhancement; Image fusion; Learning systems; Remote sensing; Signal encoding; Signal reconstruction; Auto encoders; Convolutional autoencoder; Discrete-wavelet-transform; Fusion techniques; High resolution; Image super resolutions; Modelling techniques; Multispectral images; Principal-component analysis; Stationary wavelet transforms; Principal component analysis","Convolutional Autoencoder; Discrete Wavelet Transform(DWT); Multispectral Images; Principal Component Analysis(PCA); Stationary Wavelet Transform(SWT)","Conference paper","Final","","Scopus","2-s2.0-85136322455"
"Valsesia D.; Magli E.","Valsesia, Diego (55968886600); Magli, Enrico (7003771643)","55968886600; 7003771643","Permutation Invariance and Uncertainty in Multitemporal Image Super-Resolution","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3130673","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120539195&doi=10.1109%2fTGRS.2021.3130673&partnerID=40&md5=edc5260ce87c471e5a333487ca07ee6d","Recent advances have shown how deep neural networks can be extremely effective at super-resolving remote-sensing imagery, starting from a multitemporal collection of low-resolution (LR) images. However, existing models have neglected the issue of temporal permutation, whereby the temporal ordering of the input images does not carry any relevant information for the super-resolution (SR) task and causes such models to be inefficient with the, often scarce, ground-truth data that available for training. Thus, models ought not to learn feature extractors that rely on temporal ordering. In this article, we show how building a model that is fully invariant to temporal permutation significantly improves performance and data efficiency. Moreover, we study how to quantify the uncertainty of the super-resolved image so that the final user is informed on the local quality of the product. We show how uncertainty correlates with temporal variation in the series, and how quantifying it further improves model performance. Experiments on the Proba-V challenge dataset show significant improvements over the state of the art without the need for self-ensembling, as well as improved data efficiency, reaching the performance of the challenge winner with just 25% of the training data.  © 1980-2012 IEEE.","Deep neural networks; Optical resolving power; Remote sensing; Convolutional neural network; Multi-temporal; Multitemporal super-resolution; Remote-sensing; Self-attention; Spatial resolution; Superresolution; Uncertainty; Uncertainty estimation; image resolution; numerical method; remote sensing; satellite imagery; uncertainty analysis; Efficiency","Convolutional neural networks (CNNs); multitemporal super-resolution (SR); self-attention; uncertainty estimation","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85120539195"
"Vassilo K.; Taha T.; Mehmood A.","Vassilo, Kyle (57218712112); Taha, Tarek (23013518500); Mehmood, Asif (36133731600)","57218712112; 23013518500; 36133731600","Infrared Image Super Resolution with Deep Neural Networks","2021","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2021-March","","9484045","","","","10.1109/WHISPERS52202.2021.9484045","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112856133&doi=10.1109%2fWHISPERS52202.2021.9484045&partnerID=40&md5=f61b4cd0953a391f10c4c0ff47aecdd8","Recent studies have shown that Deep Learning (DL) algorithms can significantly improve Super Resolution (SR) performance. Single image SR is useful in producing High Resolution (HR) images from their Low Resolution (LR) counterparts. The motivation for SR is the potential to assist algorithms such as object detection, localization, and classification. Insufficient work has been conducted using Generative Adversarial Networks (GANs) for SR on infrared (IR) images despite its promising ability to increase object detection accuracy by extracting more precise features from a given image. This work adopts the idea of a relativistic GAN that utilizes Residual in Residual Dense blocks (RRDBs) for feature ex- traction, a novel residual image addition, and a Pixel Transposed Convolutional Layer (PixelTCL) for up-sampling. Recent work has validated the use of GANs for Visible Light (VL) images, making them a strong candidate. The inclusion of these components produce more realistic and natural features while also receiving superior metric values.  © 2021 IEEE.","Deep learning; Deep neural networks; Infrared imaging; Neural networks; Object detection; Object recognition; Optical resolving power; Remote sensing; Signal receivers; Spectroscopy; Adversarial networks; Detection accuracy; High resolution image; Image super resolutions; Low resolution; Natural features; Residual images; Super resolution; Hyperspectral imaging","Deep Learning; Generative Adversarial Network; Infrared Imaging; Super Resolution","Conference paper","Final","","Scopus","2-s2.0-85112856133"
"Yechao W.; Xiaoli C.; Yun S.; Guoxian Z.; Yanli L.; Fang X.; Jingjing G.; Xiaoming Z.","Yechao, Wang (57216708516); Xiaoli, Chen (57508469700); Yun, Su (57673466900); Guoxian, Zheng (57572608300); Yanli, Liu (55742182800); Fang, Xu (57572608400); Jingjing, Ge (57573376100); Xiaoming, Zhong (57220185329)","57216708516; 57508469700; 57673466900; 57572608300; 55742182800; 57572608400; 57573376100; 57220185329","Aperture-scanning Fourier ptychography for super-resolution macroscopic imaging","2022","Proceedings of SPIE - The International Society for Optical Engineering","12169","","121693S","","","","10.1117/12.2623810","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128042266&doi=10.1117%2f12.2623810&partnerID=40&md5=09e1e636f07c01f84ff17c6cbfdd5ac9","We study a super-resolution synthetic aperture imaging scheme called macroscopic fourier aperture scanning imaging. By scanning the aperture on the Fourier plane of the optical system, we get a series of low resolution images of the scene. Then, the collected images are synthesized iteratively in the frequency domain. In the initial stage of recovery, the high-resolution complex wave front is recovered without any phase information. The mathematical model of the imaging system is established, and the scene super-resolution imaging and phase recovery are realized through simulation. This macroscopic fourier superposition imaging technology has broad application prospects in the fields of long-distance high-resolution imaging, remote sensing detection and so on. © 2022 SPIE","Fourier series; Frequency domain analysis; Image resolution; Optical systems; Recovery; Remote sensing; Synthetic apertures; Wavefronts; Fourier; Fourier planes; Imaging schemes; Low resolution images; PTYCHOGRAPGY; Scanning imaging; SUPER-RESOLUATION; Superresolution; Synthesised; Synthetic aperture imaging; Scanning","PTYCHOGRAPGY; SUPER-RESOLUATION","Conference paper","Final","","Scopus","2-s2.0-85128042266"
"Zhao F.; Hu Z.","Zhao, Feng (57199966780); Hu, Zhifeng (57222632602)","57199966780; 57222632602","Image super resolution reconstruction algorithm based on convolution neural network","2021","Journal of Physics: Conference Series","2025","1","012033","","","","10.1088/1742-6596/2025/1/012033","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117956631&doi=10.1088%2f1742-6596%2f2025%2f1%2f012033&partnerID=40&md5=811e9721603088f0a5088b05a81dc504","Aiming at the characteristics of large amount of remote sensing image data, large terrain fluctuations and wide coverage, this paper proposes a method for super-resolution reconstruction of remote sensing image. This method combines dense network and deep back projection network to form dense projection. The unit forms a deep dense projection network, which solves the problems of insufficient texture, loss of image details and training difficulty in the super-resolution reconstruction of remote sensing image. The experimental results show that on multiple remote sensing image datasets, compared other traditional methods, the PSNR and SSIM are significantly improved, and reconstructed remote sensing image texture signs and details are more abundant. © Journal of Physics: Conference Series 2021.","Convolution; Convolutional neural networks; Deep neural networks; Image enhancement; Image texture; Optical resolving power; Remote sensing; Textures; Backprojections; Convolution neural network; Convolutional neural network; Deep back projection network; Image super-resolution reconstruction; Large amounts; Projection network; Reconstruction algorithms; Remote sensing images; Super-resolution reconstruction; Image reconstruction","Convolutional neural network; Deep back projection network; Super-resolution reconstruction","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85117956631"
"Lu X.; Yang D.; Zhang J.; Jia F.","Lu, Xiaochen (56420776800); Yang, Dezheng (57221558779); Zhang, Junping (55961672900); Jia, Fengde (57193743139)","56420776800; 57221558779; 55961672900; 57193743139","Hyperspectral image super-resolution based on spatial correlation-regularized unmixing convolutional neural network","2021","Remote Sensing","13","20","4074","","","","10.3390/rs13204074","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117275186&doi=10.3390%2frs13204074&partnerID=40&md5=e5650676c6fbac0db293d425b2dddc07","Super-resolution (SR) technology has emerged as an effective tool for image analysis and interpretation. However, single hyperspectral (HS) image SR remains challenging, due to the high spectral dimensionality and lack of available high-resolution information of auxiliary sources. To fully exploit the spectral and spatial characteristics, in this paper, a novel single HS image SR approach is proposed based on a spatial correlation-regularized unmixing convolutional neural network (CNN). The proposed approach takes advantage of a CNN to explore the collaborative spatial and spectral information of an HS image and infer the high-resolution abundance maps, thereby reconstructing the anticipated high-resolution HS image via the linear spectral mixture model. Moreover, a dual-branch architecture network and spatial spread transform function are employed to characterize the spatial correlation between the high-and low-resolution HS images, aiming at promoting the fidelity of the super-resolved image. Experiments on three public remote sensing HS images demonstrate the feasibility and superiority in terms of spectral fidelity, compared with some state-of-the-art HS image super-resolution methods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolution; Convolutional neural networks; Deep neural networks; Remote sensing; Spectroscopy; Convolutional neural network; Deep learning; Effective tool; High resolution; HyperSpectral; Image Analysis and Interpretation; Image super resolutions; Spatial correlations; Superresolution; Unmixing; Optical resolving power","convolutional neural network; Deep learning; Hyperspectral; Super-resolution; Unmixing","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85117275186"
"Ao Z.; Sun Y.; Xin Q.","Ao, Zurui (55511761800); Sun, Ying (56939016200); Xin, Qinchuan (54421662600)","55511761800; 56939016200; 54421662600","Constructing 10-m NDVI Time Series from Landsat 8 and Sentinel 2 Images Using Convolutional Neural Networks","2021","IEEE Geoscience and Remote Sensing Letters","18","8","9125996","1461","1465","4","10.1109/LGRS.2020.3003322","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100754831&doi=10.1109%2fLGRS.2020.3003322&partnerID=40&md5=f78d584f2ab87beb8548fc51d8ba621d","Normalized difference vegetation index (NDVI) carries valuable information related to the photosynthetic activity of vegetation and is essential for monitoring phenological changes and ecosystem dynamics. The medium to high spatial resolution satellite images from Landsat 8 and Sentinel 2 offer opportunities to generate dense NDVI time series at 10-m resolution to improve our understanding of the land surface processes. However, synergistic use of Landsat 8 and Sentinel 2 for generating frequent and consistent NDVI data remains challenging as they have different spatial resolutions and spectral response functions. In this letter, we developed an attentional super resolution convolutional neural network (ASRCNN) for producing 10-m NDVI time series through fusion of Landsat 8 and Sentinel 2 images. We evaluated its performance in two heterogeneous areas. Quantitative assessments indicated that the developed network outperforms five commonly used fusion methods [i.e., enhanced deep convolutional spatiotemporal fusion network (EDCSTFN), super resolution convolutional neural network (SRCNN), spatial and temporal adaptive reflectance fusion model (STARFM), enhanced STARFM (ESTARFM), and flexible spatiotemporal data fusion (FSDAF)]. The influence of the method selection on the fusion accuracy is much greater than that of the fusion strategy in blending Landsat-Sentinel NDVI. Our results illustrate the advantages and potentials of the deep learning approaches on satellite data fusion. © 2004-2012 IEEE.","Convolution; Data fusion; Deep learning; Forestry; Image enhancement; Optical resolving power; Time series; Vegetation; High spatial resolution; Land-surface process; Normalized difference vegetation index; Photosynthetic activity; Quantitative assessments; Spatio-temporal data; Spatio-temporal fusions; Spectral response functions; accuracy assessment; artificial neural network; image analysis; Landsat; NDVI; phenology; satellite data; Sentinel; time series analysis; Convolutional neural networks","Convolutional neural network (CNN); data fusion; deep learning; remote sensing; spatiotemporal data","Article","Final","","Scopus","2-s2.0-85100754831"
"Ni N.; Wu H.; Zhang L.","Ni, Ning (57324094400); Wu, Hanlin (57221263814); Zhang, Libao (35325855000)","57324094400; 57221263814; 35325855000","Hierarchical Feature Aggregation and Self-Learning Network for Remote Sensing Image Continuous-Scale Super-Resolution","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2021.3122985","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118541681&doi=10.1109%2fLGRS.2021.3122985&partnerID=40&md5=8706101956c553c6c881baff3ad2f4b3","Conducting research on remote sensing image (RSI) super-resolution (SR) is important, especially in terms of the continuous scale, which is beneficial to the application of RSI, such as RSI object detection and data fusion. Continuous-scale SR aims to use a single model to achieve SR at arbitrary (integer and noninteger) scale factors. Therefore, in this letter, we propose a hierarchical feature aggregation and self-learning network for RSI continuous-scale SR (RSI-HFAS). Our network can magnify the RSI continuously, which is beneficial for extracting the RSI multiscale features. First, we design a hierarchical feature aggregation module (HFAM) that is used for hierarchical feature extraction by placing convolutional layers on different floors and completing global feature fusion, which is crucial for achieving RSI continuous-scale SR with a single model. Second, the proposed network introduces a feedback mechanism, which can refine the hierarchical feature through feature feedback and enrich the texture parts of the RSI step by step. Finally, we design a self-learning upscaling structure to dynamically predict the number and weights of the upsampling filters, which can achieve RSI continuous-scale SR. Compared to the meta-learning based on enhanced deep SR (META-EDSR) method, our experimental results show a nearly 0.2-dB improvement on the metrics of the peak signal-to-noise ratio (PSNR). © 2004-2012 IEEE.","Convolution; Data fusion; Extraction; Feedback control; Image reconstruction; Job analysis; Learning systems; Object detection; Object recognition; Optical resolving power; Remote sensing; Continuous scale; Features extraction; Feedback mechanisms; Hierarchical features; Images reconstruction; Remote sensing images; Remote-sensing; Superresolution; Task analysis; algorithm; data set; image resolution; remote sensing; satellite imagery; signal-to-noise ratio; Feature extraction","Continuous-scale; feedback mechanism; hierarchical feature; remote sensing image (RSI); super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85118541681"
"Panchal P.; Raman V.C.; Baraskar T.; Sinha S.; Purohit S.; Modi J.","Panchal, Poojan (57216312490); Raman, Vignesh Charan (57216314498); Baraskar, Trupti (36871711400); Sinha, Shambhavi (57336512200); Purohit, Swaraj (57337347400); Modi, Jaynam (57337347500)","57216312490; 57216314498; 36871711400; 57336512200; 57337347400; 57337347500","Reconstruction of Missing Data in Satellite Imagery Using SN-GANs","2022","Lecture Notes in Networks and Systems","286","","","629","638","9","10.1007/978-981-16-4016-2_60","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119013878&doi=10.1007%2f978-981-16-4016-2_60&partnerID=40&md5=d26cfbaf737f3013a7a3d9b000135b61","In the field of remote sensing satellite imagery, malfunctions in the available raw data are prominent. Especially in Short-Wave Infrared (SWIR) detectors used in satellite imaging cameras, which suffer from dropouts in pixel and line direction in raw data. With the recent development in generative adversarial networks and its vast application in inpainting the missing data, the possibility to predict and fill in the missing data accurately with contextual attention has become prevalent. This paper presents SN-GANs (SN-generative adversarial networks) which is two-staged architecture, and it is based on the concept of feed forward neural networks with contextual attention layers. While reconstructing the corrupted part of the images, the model takes surrounding pixels into consideration. Moreover, this architecture is adept enough to fill in the multiple lines and pixel dropouts efficiently even in super-resolution satellite images. The available traditional methods fail to address the loss of data that incurs, while inpainting a 16-bit raw image because they are effective enough for 8-bit RGB images. SN-GANs have effectively resolved this issue with a lossless image inpainting method for 16-bit satellite images as it retains the features of non-corrupted data. The performance of the model is evaluated using similarity metrics like structural similarity index measure (SSIM), peak signal-to-noise ratio (PSNR) and mean-squared error (MSE). © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","","Column-dropouts; Deep learning; GANS; Image reconstruction; Satellite imagery; SN-GANs; SWIR","Conference paper","Final","","Scopus","2-s2.0-85119013878"
"Liu W.; Yang J.; Zhao J.; Guo F.","Liu, Wensong (57195479901); Yang, Jie (57190286025); Zhao, Jinqi (56236855700); Guo, Fengcheng (57195551078)","57195479901; 57190286025; 56236855700; 57195551078","A Dual-Domain Super-Resolution Image Fusion Method with SIRV and GALCA Model for PolSAR and Panchromatic Images","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3134099","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121398373&doi=10.1109%2fTGRS.2021.3134099&partnerID=40&md5=1b25c8467704814abe219977ee8e7723","Hyperspectral/multispectral and panchromatic of optical remote sensing images are commonly used for multisensor image fusion, which has been applied in various applications of Earth observation. However, the utilization of optical remote sensing data suffers from the limitation of bad weather and cloud contamination. To address aforementioned issue and enhance spatial details of polarimetric synthetic aperture radar (PolSAR) image, a novel dual-domain super-resolution image fusion method is proposed by combining improved spherically invariant random vector (ISIRV) model with generalized adaptive linear combination approximation (GALCA) technology in this study. The proposed method decomposes the task of image fusion into polarimetric and texture domain fusion by integrating polarimetric components of PolSAR image and texture detail component of panchromatic image, which can significantly improve spatial resolutions of the PolSAR image while preserving polarimetric information. The data fusion experiment is implemented with three data sets including panchromatic images of Gaofen-1 (GF-1) and Gaofen-2 (GF-2) and the quad-pol SAR data of Gaofen-3 (GF-3) and Radarsat-2. Results show that the proposed dual-domain image fusion method provides a better performance compared with state-of-the-art multisensor fusion methods (BT, PCA, GS, indusion, and PRACS) regarding qualitative and quantitative evaluations. In addition, results of image fusion are applied to image classification over agricultural and urban areas of China, which shows that classification accuracy is significantly improved when compared with the result using only the original image. © 1980-2012 IEEE.","China; Adaptive optics; Image enhancement; Image resolution; Image texture; Optical sensors; Polarimeters; Remote sensing; Synthetic aperture radar; Generalized ALCA method; Improved SIRV model; Optical imaging; Optical scattering; Polarimetric domain; Remote-sensing; Resolution images; Spatial resolution; Super-resolution image fusion; Superresolution; Texture domain; accuracy assessment; image classification; image resolution; satellite data; satellite imagery; synthetic aperture radar; Image fusion","Generalized adaptive linear combination approximation (ALCA) method; improved spherically invariant random vector (SIRV) model; polarimetric domain; super-resolution image fusion; texture domain","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85121398373"
"Tang S.; Chen Z.; Zhang M.","Tang, Shimin (57838612800); Chen, Zhiqiang (35483405000); Zhang, Molan (57226831430)","57838612800; 35483405000; 57226831430","Spectral Quality Evaluation of Reconstructed Hyperspectral Images","2021","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2021-March","","9483970","","","","10.1109/WHISPERS52202.2021.9483970","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112849162&doi=10.1109%2fWHISPERS52202.2021.9483970&partnerID=40&md5=c04361a2d10878313b06feb0e90cfc77","With the advance in imaging optics, hyperspectral images (or cubes) have become low-cost and real-Time for acquiring images in the field, specifically thanks to the recent development of different 'snapshot' hyperspectral imaging systems. However, cameras producing high resolutions in both the spectral domains and the spatial domains are still rare or considered to be high-cost. Algorithm-based pansharpening, or in general image reconstruction methods, are often used to create high spatial-resolution cubes by fusing high-spatial gray or color images and low spatial-resolution hyperspectral images. Moreover, most of these methods emphasized achieving high visual quality in spatial resolution but not considering the spectral accuracy in the reconstructed images. This paper aims to evaluate the spectral quality of reconstructed images from multiple methods. A commercial hyperspectral camera (Cubert S185) was used to conduct the research. Important conclusions include that spectral information is lost to different degrees per different reconstruction methods when the spatial resolution is raised too high. The trade-off between spatial sharpening and retaining spectral information is important for machine learning tasks.  © 2021 IEEE.","Cameras; Economic and social effects; Hyperspectral imaging; Image quality; Image resolution; Quality control; Real time systems; Remote sensing; Spectroscopy; High spatial resolution; Hyper-spectral cameras; Image reconstruction methods; Reconstructed image; Reconstruction method; Spatial resolution; Spectral accuracy; Spectral information; Image reconstruction","Hyperspectral image; Spectrum analysis; Super Resolution","Conference paper","Final","","Scopus","2-s2.0-85112849162"
"Liu C.; Wang Y.","Liu, Cong (57138870000); Wang, Yaxin (57266384700)","57138870000; 57266384700","Remote Sensing Image Super-Resolution Reconstruction Based on Dual-Parallel Residual Network; [基于双并行残差网络的遥感图像超分辨率重建]","2021","Moshi Shibie yu Rengong Zhineng/Pattern Recognition and Artificial Intelligence","34","8","","760","767","7","10.16451/j.cnki.issn1003-6059.202108009","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115346769&doi=10.16451%2fj.cnki.issn1003-6059.202108009&partnerID=40&md5=65094f8dd0149bb149494a7e8d123d5e","The image super-resolution reconstruction algorithm generates a poor effect for the remote sensing images due to different sizes of ground objects and high complexity in the images. Aiming at this problem, a dual-parallel lightweight residual attention network is proposed to increase the reconstruction result. Firstly, a multi-scale shallow feature extraction block(MFEB) is put forward to gain the feature information of different receptive field sizes. The problem of the ground objects with different sizes can be solved by MFEB. Secondly, a lightweight residual attention block(LRAB) is designed with asymmetric convolution and attention mechanism. And thus, the model parameters are reduced and more high-frequency information is captured. Then, the parallel network with different convolution kernels is designed to fuse different receptive fields. Besides, lots of skip connections are employed in residual blocks to increase the reusability of information. Finally, experiments show that the proposed model produces superior performance. © 2021, Science Press. All right reserved.","Convolution; Optical resolving power; Remote sensing; Reusability; Asymmetric convolution; Different sizes; Features extraction; Ground objects; Image super-resolution reconstruction; Lightweight; Multi-scales; Parallel network; Remote sensing images; Super-resolution reconstruction; Image reconstruction","Asymmetric Convolution; Lightweight; Parallel Network; Remote Sensing Image; Super-Resolution Reconstruction","Article","Final","","Scopus","2-s2.0-85115346769"
"Yang Z.; Wang Y.","Yang, Zhiwei (57225126998); Wang, Yunyan (55734131800)","57225126998; 55734131800","Image Enhancement and Improvement Algorithm Based on Esrgan Singal Frame Remote Sensing Image","2021","Journal of Physics: Conference Series","1952","2","022012","","","","10.1088/1742-6596/1952/2/022012","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109215707&doi=10.1088%2f1742-6596%2f1952%2f2%2f022012&partnerID=40&md5=0923ff999a706afabade40947471dc47","Traditional spline interpolation algorithm for reconstruction of visual effects are not good, based on Super Resolution against Network (Super - Resolution Generative Adversarial Network, SRGAN) edge character to deal with such problems as imperfect, using a generated based on the enhanced Super Resolution against Network to improve the Resolution of ordinary optical remote sensing images, the first Network generated by high Resolution data sets to train (G network), then lower Resolution test data model test, The test results and real results are put into the discrimination network (D network) to get the adversarial loss, and then the generated network is modified according to the adversarial loss. The superiority of the network is improved by introducing dense residuals to SRGAN, modifying the judgment object of the discriminator to be relatively real, and using the eigenvalue before activation to improve the perceived loss. The desert, farmland, forest and mountain data were tested on AID data set, and the algorithm in this paper could obtain the recomposition of the real image more closely. Compared with SRResNet and SRGAN algorithms, PSNR improved by about 4.0db and SSIM improved by about 0.14. This method improves the feature comprehensiveness by increasing the network fineness degree, and USES the modified perception loss to get the brightness closer to the real image, which is beneficial to improve the quality of single frame remote sensing image.  © Published under licence by IOP Publishing Ltd.","Discriminators; Edge detection; Eigenvalues and eigenfunctions; Interpolation; Optical data processing; Optical resolving power; Remote sensing; Adversarial networks; High resolution data; Lower resolution; Optical remote sensing; Remote sensing images; Spline interpolation; Super resolution; Visual effects; Image enhancement","Confrontation; image; network; Reconstruction error; Remote; sensing; Super resolution","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85109215707"
"Hayashi T.; Ando T.; Kidera S.","Hayashi, Takumi (57207728494); Ando, Takeru (57221222455); Kidera, Shouhei (14031687600)","57207728494; 57221222455; 14031687600","Three-dimensional Doppler-associated radar imaging method based on bi-directional data processing","2022","IET Radar, Sonar and Navigation","16","1","","145","160","15","10.1049/rsn2.12171","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115977345&doi=10.1049%2frsn2.12171&partnerID=40&md5=3386811dd55277cb5fef38c01bba8639","Using a microwave or millimetre wave radar system, this study aims to achieve highly accurate Doppler velocity estimation and radar imaging that would be suitable for various remote-sensing sensors, such as self-driving, surveillance, or security applications. In particular, micro-Doppler signatures are one of the most promising approaches for human recognition; however, the traditional limitations of both velocity and temporal resolution need to be addressed. The weighted kernel density (WKD) algorithm using super-resolution Doppler velocity estimation has been one solution. Using WKD, this study incorporates the range points migration (RPM) method of radar imaging to enhance accuracy in both Doppler velocity and radar imaging using an iterative data selection scheme. Furthermore, to obtain more informative Doppler-associated RPM-based images using less data by exploiting a unique feature of WKD and RPM methods, this study introduces the image integration approach along the slow-time profile. In this framework, bi-directional data processing between Doppler velocity and imaging analysis is achieved. At each pulse hit sequence, both numerical and experimental tests demonstrate that the proposed method yields a more accurate Doppler-associated radar image compared with the methods in previous studies. © 2021 The Authors. IET Radar, Sonar & Navigation published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.","Doppler radar; Iterative methods; Microwave sensors; Millimeter waves; Network security; Numerical methods; Remote sensing; Velocity; Bi-directional; Directional data; Doppler; Doppler velocity; Doppler velocity estimations; Highly accurate; Imaging method; Kernel density; Millimeter-wave radar; Millimetre-wave radar; Radar imaging","Doppler radar; millimetre wave radar; radar imaging; radar signal processing","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85115977345"
"Karwowska K.; Wierzbicki D.","Karwowska, Kinga (57608598400); Wierzbicki, Damian (56835658600)","57608598400; 56835658600","Using Super-Resolution Algorithms for Small Satellite Imagery: A Systematic Review","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","3292","3312","20","10.1109/JSTARS.2022.3167646","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128587279&doi=10.1109%2fJSTARS.2022.3167646&partnerID=40&md5=7595d234dde87dfdf922fb730a09fef9","In recent years, we have witnessed significant development in the space sector, in particular regarding Earth imaging. Small satellites, whose size and construction make their production much cheaper, are becoming increasingly popular. As a result, a larger number of satellites may be placed in space, and thus, they may perform more frequent observations of selected spots on Earth. Unfortunately, the construction of these satellites also affects their observation capacity as they have a weaker spatial resolution. Scientists have been dealing with the problem of improving the spatial resolution of satellite imaging for many years. Numerous methods were developed that allow for the best possible representation of high-resolution images based on low-resolution images. However, the application of traditional solutions to improve the resolution of digital images requires an additional high-resolution image. As far as images obtained by small satellites (e.g., nano, micro, or mini) are concerned, the difference between the spatial resolution of panchromatic and multispectral images is small (e.g., for SkySat-3 - SkySat-15 satellites, it is only 0.16 m). The need to increase the spatial resolution of an image that does not have a corresponding higher resolution image (e.g., a panchromatic image or a sequence of images) causes additional problems. This article presents a review of the methods to improve the spatial resolution of small-satellite imaging. The authors analyze the interpolation, pansharpening, and digital image processing methods. Additionally, the article focuses on presenting solutions based on deep learning that enables the enhancement of the spatial resolution of images obtained from small satellites. The methodology of creating databases used for network training is described. Finally, the authors present the main limitations of the analyzed solutions and future development trends that will enable to improve the spatial resolution with the use of a single image. © 2008-2012 IEEE.","Deep learning; Earth (planet); Image enhancement; Image resolution; Satellite imagery; Convolutional neural network; Deep learning; Digital image; Image super resolutions; Neural-networks; Pan-sharpening; Single image super-resolution; Single images; Small-satellite; Spatial resolution; Superresolution; algorithm; artificial intelligence; artificial neural network; image analysis; image resolution; machine learning; remote sensing; satellite imagery; spatial resolution; Neural networks","Convolutional neural networks; deep learning; neural networks; single image super-resolution (SISR); super- resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85128587279"
"Huang S.; Messinger D.W.","Huang, Sihan (57218177897); Messinger, David W. (57607579600)","57218177897; 57607579600","An Unsupervised Laplacian Pyramid Network for Radiometrically Accurate Data Fusion of Hyperspectral and Multispectral Imagery","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5527517","","","","10.1109/TGRS.2022.3168511","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128607170&doi=10.1109%2fTGRS.2022.3168511&partnerID=40&md5=5e86fb12c42b520539593ed9db9ac03b","Improving the spatial resolution of hyperspectral images (HSIs) has traditionally been an important topic in the field of remote sensing. Many approaches have been proposed based on various theories, including component substitution, multiresolution analysis, spectral unmixing, Bayesian probability, and tensor representation. However, these methods have some common disadvantages such that their performance degrades dramatically as the up-scale ratio increases, and they have little concern for the per-pixel radiometric accuracy of the sharpened image. Moreover, many learning-based methods have been proposed through decades of innovations, but most of them require a large set of training pairs, which is unpractical for many real problems. To solve these problems, we propose a stable hyperspectral sharpening method based on the Laplacian pyramid and the generative convolutional neural network (CNN), which achieves superior radiometric accuracy of the sharpened data in different up-scale ratios based on one single input pair. First, with a low-resolution HSI (LR-HSI) and high-resolution multispectral image (HR-MSI) pair, the preliminary high-resolution HSI (HR-HSI) is calculated via linear regression. Then, the high-frequency details of the preliminary HR-HSI are estimated via the subtraction between it and the CNN-generated-blurry version. By injecting the details to the output of the generative CNN with the LR-HSI as input, the final HR-HSI is obtained. Nine different state-of-the-art sharpening methods are chosen as our baselines, and three different datasets with different scene content are tested. Furthermore, the target detection method, the adaptive coherence estimator (ACE), is conducted on the reconstructed HR-HSI to evaluate the per-pixel radiometric accuracy. The results demonstrate that the proposed method has the best and the most stable performance in terms of spectral and spatial accuracies.  © 1980-2012 IEEE.","Convolution; Deep neural networks; Hyperspectral imaging; Image enhancement; Image resolution; Laplace transforms; Pixels; Radiometry; Remote sensing; Spectroscopy; Tensors; Bayes method; Convolutional neural network; Deep image prior; HyperSpectral; Hyperspectral sharpening; Image priors; Laplace equation; Laplacian Pyramid; Spatial resolution; Superresolution; artificial neural network; imagery; Laplace transform; remote sensing; satellite data; spatial resolution; unsupervised classification; Image fusion","Convolutional neural network (CNN); hyperspectral sharpening; image fusion; Laplacian pyramid; super-resolution","Article","Final","","Scopus","2-s2.0-85128607170"
"Simsek M.; Polat E.","Simsek, Murat (57198315114); Polat, Ediz (6602452700)","57198315114; 6602452700","Performance evaluation of pan-sharpening and dictionary learning methods for sparse representation of hyperspectral super-resolution","2021","Signal, Image and Video Processing","15","6","","1099","1106","7","10.1007/s11760-020-01836-8","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100172919&doi=10.1007%2fs11760-020-01836-8&partnerID=40&md5=b187fa30273fc9cf5b59801bfafd7c65","Because it contains high spectral information, hyperspectral imagery has been used in many areas. However, hyperspectral imagery has low spatial resolution because of imaging hardware limitation. Recently, many methods have been available for improving spatial resolution of hyperspectral images. Pan-sharpening and dictionary learning-based sparse representation methods are well-known methods for improving spatial resolution. In this study, a quantitative analysis of super-resolution methods for hyperspectral imagery is performed for identifying the best method in terms of reconstruction quality and processing time. K-SVD, ODL and Bayesian methods are employed for dictionary learning-based sparse representations. On the other hand, IHS and PCA-based methods are employed for pan-sharpening methods. The experimental results show that the ODL method outperforms others in terms of reconstruction quality measured by RMSE values and processing times. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd. part of Springer Nature.","Bayesian networks; Hyperspectral imaging; Image enhancement; Image resolution; Optical resolving power; Quality control; Remote sensing; Spectroscopy; Dictionary learning; Hyper-spectral imageries; Reconstruction quality; Sparse representation; Spatial resolution; Spectral information; Super resolution; Superresolution methods; Learning systems","Dictionary learning; Hyperspectral images; Pan-sharpening; Sparse representation; Super-resolution","Article","Final","","Scopus","2-s2.0-85100172919"
"Peng S.; Deng L.-J.; Hu J.-F.; Zhuo Y.","Peng, Siran (57887406400); Deng, Liang-Jian (55207151100); Hu, Jin-Fan (57219691918); Zhuo, Yuwei (57888979300)","57887406400; 55207151100; 57219691918; 57888979300","Source-Adaptive Discriminative Kernels based Network for Remote Sensing Pansharpening","2022","IJCAI International Joint Conference on Artificial Intelligence","","","","1283","1289","6","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137876503&partnerID=40&md5=7c5a263ad0368048a8fcd3280679d207","For the pansharpening problem, previous convolutional neural networks (CNNs) mainly concatenate high-resolution panchromatic (PAN) images and low-resolution multispectral (LR-MS) images in their architectures, which ignores the distinctive attributes of different sources. In this paper, we propose a convolution network with source-adaptive discriminative kernels, called ADKNet, for the pansharpening task. Those kernels consist of spatial kernels generated from PAN images containing rich spatial details and spectral kernels generated from LR-MS images containing abundant spectral information. The kernel generating process is specially designed to extract information discriminately and effectively. Furthermore, the kernels are learned in a pixel-by-pixel manner to characterize different information in distinct areas. Extensive experimental results indicate that ADKNet outperforms current state-of-the-art (SOTA) pansharpening methods in both quantitative and qualitative assessments, in the meanwhile only with about 60,000 network parameters. Also, the proposed network is extended to the hyperspectral image super-resolution (HSISR) problem, still yields SOTA performance, proving the universality of our model. The code is available at http://github.com/liangjiandeng/ADKNet. © 2022 International Joint Conferences on Artificial Intelligence. All rights reserved.","Convolution; Convolutional neural networks; Remote sensing; Spectroscopy; 'current; Convolutional neural network; Extract informations; High resolution; Low resolution multispectral images; Pan-sharpening; Remote-sensing; Spatial kernels; Spectral information; Spectral kernels; Pixels","","Conference paper","Final","","Scopus","2-s2.0-85137876503"
"Ciotola M.; Vitale S.; Mazza A.; Poggi G.; Scarpa G.","Ciotola, Matteo (57239080700); Vitale, Sergio (57201522451); Mazza, Antonio (57200854745); Poggi, Giovanni (57560931500); Scarpa, Giuseppe (7004081145)","57239080700; 57201522451; 57200854745; 57560931500; 7004081145","Pansharpening by Convolutional Neural Networks in the Full Resolution Framework","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5408717","","","","10.1109/TGRS.2022.3163887","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127466395&doi=10.1109%2fTGRS.2022.3163887&partnerID=40&md5=198052b2f9867d9557b06d6efb134600","In recent years, there has been a growing interest in deep learning-based pansharpening. Thus far, research has mainly focused on architectures. Nonetheless, model training is an equally important issue. A first problem is the absence of ground truths, unavoidable in pansharpening. This is often addressed by training networks in a reduced-resolution domain and using the original data as ground truth, relying on an implicit scale invariance assumption. However, on full-resolution images, results are often disappointing, suggesting such invariance not to hold. A further problem is the scarcity of training data, which causes a limited generalization ability and a poor performance on off-training-test images. In this article, we propose a full-resolution training framework for deep learning-based pansharpening. The framework is fully general and can be used for any deep learning-based pansharpening model. Training takes place in the high-resolution domain, relying only on the original data, thus avoiding any loss of information. To ensure spectral and spatial fidelity, a suitable two-component loss is defined. The spectral component enforces consistency between the pansharpened output and the low-resolution multispectral input. The spatial component, computed at high resolution, maximizes the local correlation between each pansharpened band and the panchromatic input. At testing time, the target-adaptive operating modality is adopted, achieving good generalization with a limited computational overhead. Experiments carried out on WorldView-3, WorldView-2, and GeoEye-1 images show that methods trained with the proposed framework guarantee a pretty good performance in terms of both full-resolution numerical indexes and visual quality. © 1980-2012 IEEE.","Deep learning; Job analysis; Neural networks; Numerical methods; Remote sensing; Full resolutions; Ground truth; High resolution; Multi-resolution analysis; Multiresolutions analysis; Pan-sharpened; Pan-sharpening; Remote-sensing; Spatial resolution; Task analysis; artificial neural network; image analysis; image resolution; numerical model; training; unsupervised classification; WorldView; Multiresolution analysis","Convolutional neural network (CNN); data fusion; deep learning; image enhancement; multiresolution analysis (MRA); spectral distortion; structural consistency; super resolution; unsupervised learning","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85127466395"
"An T.; Zhang X.; Huo C.; Xue B.; Wang L.; Pan C.","An, Tai (57424018000); Zhang, Xin (55792938900); Huo, Chunlei (24080315500); Xue, Bin (57220896004); Wang, Lingfeng (55721448100); Pan, Chunhong (8558023500)","57424018000; 55792938900; 24080315500; 57220896004; 55721448100; 8558023500","TR-MISR: Multiimage Super-Resolution Based on Feature Fusion With Transformers","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","1373","1388","15","10.1109/JSTARS.2022.3143532","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123378888&doi=10.1109%2fJSTARS.2022.3143532&partnerID=40&md5=95dff27ba2f421ed53ecd66bf736106d","Multiimage super-resolution (MISR), as one of the most promising directions in remote sensing, has become a needy technique in the satellite market. A sequence of images collected by satellites often has plenty of views and a long time span, so integrating multiple low-resolution views into a high-resolution image with details emerges as a challenging problem. However, most MISR methods based on deep learning cannot make full use of multiple images. Their fusion modules are incapable of adapting to an image sequence with weak temporal correlations well. To cope with these problems, we propose a novel end-to-end framework called TR-MISR. It consists of three parts: An encoder based on residual blocks, a transformer-based fusion module, and a decoder based on subpixel convolution. Specifically, by rearranging multiple feature maps into vectors, the fusion module can assign dynamic attention to the same area of different satellite images simultaneously. In addition, TR-MISR adopts an additional learnable embedding vector that fuses these vectors to restore the details to the greatest extent. TR-MISR has successfully applied the transformer to MISR tasks for the first time, notably reducing the difficulty of training the transformer by ignoring the spatial relations of image patches. Extensive experiments performed on the PROBA-V Kelvin dataset demonstrate the superiority of the proposed model that provides an effective method for transformers in other low-level vision tasks.  © 2008-2012 IEEE.","Deep learning; Image fusion; Job analysis; Remote sensing; Satellites; Deep learning; End-to-end network; Features extraction; Features fusions; Image super resolutions; Multi-image super-resolution; Multi-images; Remote-sensing; Superresolution; Task analysis; Transformer; digital mapping; machine learning; remote sensing; satellite data; satellite imagery; spatial resolution; Image resolution","Deep learning; end-to-end networks; feature extraction and fusion; multiimage super-resolution (MISR); remote sensing; transformers","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85123378888"
"Zhang Y.; Sun J.; Qiu R.; Liu H.; Zhang X.; Xuan J.","Zhang, Ying (55881844700); Sun, Jingyi (57224950383); Qiu, Rudong (57219050564); Liu, Huilan (14070149900); Zhang, Xi (50362324400); Xuan, Jiabin (57200961249)","55881844700; 57224950383; 57219050564; 14070149900; 50362324400; 57200961249","Spatial scale effect of a typical polarized remote sensor on detecting ground objects","2021","Sensors","21","13","4418","","","","10.3390/s21134418","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108704194&doi=10.3390%2fs21134418&partnerID=40&md5=c4df4db22800e479e183f1b5d3608cbc","For polarized remote sensors, the polarization images of ground objects acquired at different spatial scales will be different due to the spatial heterogeneity of the ground object targets and the limitation of imaging resolution. In this paper, the quantitative inversion problem of a typical polarized remote sensor at different spatial scales was studied. Firstly, the surface roughness of coatings was inversed based on the polarized bidirectional reflectance distribution function (pBRDF) model according to their polarization images at different distances. A linear-mixed pixel model was used to make a preliminary correction of the spatial scale effect. Secondly, the super-resolution image reconstruction of the polarization imager was realized based on the projection onto convex sets (POCS) method. Then, images with different resolutions at a fixed distance were obtained by utilizing this super-resolution image reconstruction method and the optimal spatial scale under the scene can be acquired by using information entropy as an evaluation indicator. Finally, the experimental results showed that the roughness inversion of coatings has the highest accuracy in the optimal spatial scale. It has been proved that our proposed method can provide a reliable way to reduce the spatial effect of the polarized remote sensor and to improve the inversion accuracy. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Coatings; Distribution functions; Object detection; Optical resolving power; Polarization; Remote sensing; Set theory; Surface roughness; Bidirectional reflectance distribution functions; Different resolutions; Evaluation indicators; Information entropy; Polarization images; Projection onto convex sets; Spatial heterogeneity; Super-resolution image reconstruction; Image reconstruction","Polarized remote sensor; Spatial heterogeneity; Spatial scale effect; Super resolution image reconstruction","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85108704194"
"Du W.; Guo C.; Zhou D.","Du, Wenyuan (57559303800); Guo, Chengjun (38861475100); Zhou, Dong (56591084000)","57559303800; 38861475100; 56591084000","Application of Improved Target Detection Algorithm in Aerial Remote Sensing Image","2021","Proceedings of the International Astronautical Congress, IAC","B5","","","","","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127407850&partnerID=40&md5=e41dcfd120ea8afa49ff0322ea766c13","Target detection is one of the core tasks of computer vision. With the development of artificial neural networks, target detection has been greatly improved and gradually applied to more fields. In this paper, an improved algorithm combining super-resolution reconstruction and Faster RCNN is proposed to detect small targets in aerial remote sensing images. Aerial remote sensing image is taken from several hundred meters to nearly ten thousand meters, which leads to many targets in aerial remote sensing image are small targets. Although the target detection algorithm based on CNN have made the huge progress in improving the performance of target detection algorithms, there is still a big gap between the detection performance of large targets and small targets. The main reason is that the small target just occupies a small proportion of pixels in the image, which contains less information, and when the image passes through multiple convolutional layers, the resulting feature map may not keep the characteristics of the small target. Thus, in order to solve these problems, the article proposes an improved algorithm based on the Faster RCNN structure. We aim to increase the feature information of small targets by fusing super-resolution reconstruction methods. Besides, in order to solve the problem that there is only a little feature information contained in small targets, the algorithm sets a threshold to reconstruct the candidate frames generated by RPN network in Faster RCNN with super-resolution. Then it inputs the image of small target candidate frames with increased feature information into the original network to complete the target detection task. In addition, the paper introduces feature pyramid network (FPN) algorithm into the original Faster RCNN network structure. By combining the high-resolution of low-level features with the high semantic information of high-level features, it makes a separate prediction on each feature layer after fusion. We evaluated our proposed architecture on the highly competitive aerial remote sensing image dataset (RSOD-Dataset). The framework proposed in this paper effectively improves the accuracy of small target detection in aerial remote sensing images, and provides a foundation for the research of target detection in aerial remote sensing images. Copyright © 2021 by the International Astronautical Federation (IAF). All rights reserved.","Convolutional neural networks; Feature extraction; Image enhancement; Image reconstruction; Optical resolving power; Remote sensing; Semantics; Signal detection; Aerial remote sensing; Aerial remote sensing image; Feature information; Improved * algorithm; Remote sensing images; Small target detection; Small targets; Super-resolution reconstruction; Target detection algorithm; Targets detection; Antennas","Aerial remote sensing image; Small target detection; Super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85127407850"
"Wang M.; Zhang X.; Shi K.; Zhang X.; Lei D.; Yang X.","Wang, Mingjie (57218835599); Zhang, Xinlu (57218145213); Shi, Keyu (57218951929); Zhang, Xin (57221515075); Lei, Dandan (57218951000); Yang, Xuguang (57192909650)","57218835599; 57218145213; 57218951929; 57221515075; 57218951000; 57192909650","Image super-resolution reconstruction algorithm based on improved GAN","2020","ACM International Conference Proceeding Series","","","3414487","","","","10.1145/3414274.3414487","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090886009&doi=10.1145%2f3414274.3414487&partnerID=40&md5=9f57bd3a14532232580304e94c25b009","Image super-resolution reconstruction (ISR) technology based on deep learning has become a hot topic in the field of machine vision because it can reconstruct low-resolution image into high-resolution image, which has been extensive used in many research field such as remote sensing imaging, medical image processing, video monitoring and other fields. However, the conventional deep learning method is not ideal for image super-resolution reconstruction at high magnification, which result in a fact that there is still a gap between the existing research results and practical applications. The paper proposed an ISR algorithm based on improved GAN. Wasserstein distance is introduced to gauge the distance between the real distribution and the generated distribution. The network generator uses the depth residual network, the network discriminator uses the feedforward neural network, the optimization goal is set to minimize the perceptual loss, and the algorithm is applied to the public data set for testing. We can clearly find from test results that compared with other algorithms, the improved GAN can recover the high-frequency details in the low-resolution image with immediate effect, and has better perception effect of human eyes. © 2020 ACM.","Data Science; Deep learning; Feedforward neural networks; Image enhancement; Learning systems; Medical imaging; Optical resolving power; Remote sensing; Statistical tests; High magnifications; High resolution image; Image super-resolution reconstruction; Low resolution images; Optimization goals; Real distribution; Remote sensing imaging; Wasserstein distance; Image reconstruction","Depth residual network; Feedforward neural network; Image super-resolution reconstruction; Improved GAN; Perceptual loss; Wasserstein distance","Conference paper","Final","","Scopus","2-s2.0-85090886009"
"Wang B.; Mei S.; Feng Y.; Du Q.","Wang, Baorui (57255138300); Mei, Shaohui (25822578400); Feng, Yan (36696426500); Du, Qian (57254219600)","57255138300; 25822578400; 36696426500; 57254219600","HYPERSPECTRAL IMAGERY SUPER-RESOLUTION BASED ON SELF-CALIBRATED ATTENTION RESIDUAL NETWORK","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","3896","3899","3","10.1109/IGARSS47720.2021.9554761","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129794782&doi=10.1109%2fIGARSS47720.2021.9554761&partnerID=40&md5=09bd233079e87dee85087bfc639ed20a","Hyperspectral remote sensing images are well-known for their abundant spectral characteristics to discriminate different object materials. However, due to the constraints of sensor limitations and exceedingly high acquisition costs, it is difficult to obtain high spatial resolution hyperspectral imagery. Though many methods have been focusing on the restoration of the spatial structure information, spectral information may be over-smoothed during such spatial super-resolution. In this paper, a novel self-calibrated attention residual network (SCARN) is proposed to increase spatial resolution of hyperspectral images while retain spectral consistency. In particular, a self-calibrated attention residual block (SCARB) is elaborately designed to fully exploit the spatial information and the correlation between the spectra of the hyperspectral data. Concretely, self-calibrated convolution, instead of standard convolution, is adopted to adaptively construct long-range spatial and spectral dependencies around each spatial location of hyperspectral imagery, and attention module is inserted to improve the representation ability of spectral information. Finally, global and local residual connections are designed to ease the network training difficulty and maintain a higher restoration accuracy. Experimental results over two benchmark hyperspectral datasets demonstrate the effectiveness and superiority of the proposed SCARN method against the state-of-the-art methods. © 2021 IEEE","Image enhancement; Image resolution; Remote sensing; Restoration; Spectroscopy; Acquisition costs; High spatial resolution; Hyper-spectral imageries; Hyperspectral Remote Sensing Image; Residual connection; Self-calibrated convolution; Sensor limitations; Spectral characteristics; Spectral information; Superresolution; Convolution","Hyperspectral imagery; Residual connection; Self-calibrated convolution; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85129794782"
"Bergamasco L.; Martinatti L.; Bovolo F.; Bruzzone L.","Bergamasco, Luca (57214091122); Martinatti, Luca (57482539500); Bovolo, Francesca (9943212600); Bruzzone, Lorenzo (7006892410)","57214091122; 57482539500; 9943212600; 7006892410","AN UNSUPERVISED CHANGE DETECTION TECHNIQUE BASED ON A SUPER-RESOLUTION CONVOLUTIONAL AUTOENCODER","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","3337","3340","3","10.1109/IGARSS47720.2021.9553859","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126054600&doi=10.1109%2fIGARSS47720.2021.9553859&partnerID=40&md5=5d9d2f805c7388766d2d4d7bef492adf","Deep Learning (DL) methods are widely used for Change Detection (CD) in multi-temporal Remote Sensing (RS) images. The recently reported unsupervised DL CD methods alleviate the problem of the labeled data collection affecting the supervised ones. Many of them exploit the DL models (e.g., Convolutional Autoencoder (CAE)) as a feature extractor and use the retrieved features to detect the changes. However, these features do not efficiently preserve the geometrical details, and they do not optimize the selection of informative features for change detection. We propose an unsupervised DL CD method that exploits the features extracted by a CAE trained with a super-resolution based loss function. The loss function allows the CAE to be trained to reconstruct the spatial information thus generating features preserving the geometrical details. The proposed method exploits a feature selection based on the Structured Similarity Index (SSIM) to perform a texture analysis and chooses couples of bi-temporal features providing relevant information about changes. We tested the proposed method on a couple of bi-temporal Landsat-8 images representing a burned area near Granada, Spain. © 2021 IEEE","","Convolutional autoencoder; Deep learning; Multitemporal analysis; Super resolution; Unsupervised change detection; Unsupervised learning","Conference paper","Final","","Scopus","2-s2.0-85126054600"
"Wang B.; Zhang J.; Jin Z.; Gu H.; Zou Y.; Li Y.; Zuo C.","Wang, Bowen (57204607674); Zhang, Ju (57381756600); Jin, Ziheng (57381932700); Gu, Haojie (57381932800); Zou, Yan (56278157500); Li, Yuhai (57361136900); Zuo, Chao (36007852700)","57204607674; 57381756600; 57381932700; 57381932800; 56278157500; 57361136900; 36007852700","Low-light-level image pixel super-resolution reconstruction method","2021","Proceedings of SPIE - The International Society for Optical Engineering","12057","","1205734","","","","10.1117/12.2606246","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121482406&doi=10.1117%2f12.2606246&partnerID=40&md5=16893d936b3f4d6439f4336e91bfb810","Wide field-of-view (FOV) and high-resolution (HR) imaging systems have become indispensable information acquisition equipment in many applications, such as video surveillance, target detection and remotely sensed imagery. However, due to the constraints of spatial sampling and detector processing level, the ability of remote sensing to obtain high spatial resolution is limited, especially in the wide FOV imaging. To solve these problems, we propose a multi-scale feature extraction (MSFE) network to realize super-resolution imaging in a low-light- level (LLL) environment. In order to perform data fusion and information extraction for low resolution (LR) images, the network extracts high-frequency detail information from different dimensions by combining the channel attention mechanism module and skip connection module. In this way, redundant low-frequency signals can pass through the network tail-ends, furthermore, the more important high-frequency components calculation can be focused. The qualitative and quantitative analysis results show that the proposed method achieves the most advanced performance compared with other state-of-the-art methods, which shows the superiority of the design framework and the effectiveness of presenting modules. © 2021 COPYRIGHT SPIE.","Data fusion; Deep learning; Image reconstruction; Image resolution; Remote sensing; Security systems; Deep learning network; Features extraction; Image pixels; Learning network; Low light level; Low-light-level image; Multi-scale feature extraction; Multi-scale features; Superresolution; Wide field-ofview; Feature extraction","Deep learning network; Low-light-level; Multi-scale feature extraction; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85121482406"
"Yang F.; Ma F.; Huo S.; Wang Y.","Yang, Feixia (57194184931); Ma, Fei (55245276100); Huo, Shuai (57226523502); Wang, Yanwei (57213688942)","57194184931; 55245276100; 57226523502; 57213688942","Multi-sensor data fusion of remotely-sensed images with sparse and logarithmic low-rank regularization for shadow removal and denoising","2021","International Journal of Remote Sensing","42","18","","6961","6983","22","10.1080/01431161.2021.1941388","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111831363&doi=10.1080%2f01431161.2021.1941388&partnerID=40&md5=19a443c064feefa8bd2617f4b56d1938","Hyperspectral images have high spectral resolution but low spatial resolution, which results in a large number of mixed pixels. As an economical and effective means to improve image quality, the fusion of hyperspectral and multispectral data from different sensors can achieve the reconstruction of super-resolution images. As a representative of fusion method, coupled non-negative matrix factorization is an ill-posed problem, in which the number of endmembers was set to be no less than the groundtruth without requiring an accurate value. However, this often results in spectral shadows and spatial information redundancy, especially when the observed images are contaminated by noise. To address these problems above, this article incorporates sparse and low-rank regularization to reformulate a bi-convex fusion problem for the removal of shadows and noise, in which the logarithmic sum function is employed to suppress the small singular components of endmember and abundance matrices. Then, an efficient solver is designed to obtain the closed-form solutions via matrix-vector operators, in which the alternating direction method of multipliers is utilized to split the variables using equality constraints. The experimental results of real datasets demonstrate that the proposed fusion method can effectively enhance the quality of reconstructed super-resolution images especially in high-noise environments, which also verifies the validation of incorporated regularization. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","Factorization; Image enhancement; Image fusion; Image reconstruction; Matrix algebra; Spectral resolution; Spectroscopy; Alternating direction method of multipliers; Closed form solutions; High noise environments; High spectral resolution; Multisensor data fusion; Nonnegative matrix factorization; Remotely sensed images; Sparse and low ranks; data processing; data quality; data set; image analysis; image resolution; matrix; multispectral image; pixel; remote sensing; spatial resolution; spectral resolution; vector; Sensor data fusion","","Article","Final","","Scopus","2-s2.0-85111831363"
"Tuo X.; Zhang Y.; Huang Y.; Yang J.","Tuo, Xingyu (57213190611); Zhang, Yin (55975581400); Huang, Yulin (23014806800); Yang, Jianyu (9239230100)","57213190611; 55975581400; 23014806800; 9239230100","A Fast Sparse Azimuth Super-Resolution Imaging Method of Real Aperture Radar Based on Iterative Reweighted Least Squares with Linear Sketching","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9361073","2928","2941","13","10.1109/JSTARS.2021.3061430","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101751755&doi=10.1109%2fJSTARS.2021.3061430&partnerID=40&md5=a1a3a1494533550ce6304411b9586cd7","It is greatly significant to achieve radar forward-looking region imaging. Due to the limitation of phase ambiguity and small Doppler gradient in forward-looking region, synthetic aperture radar and Doppler beam sharpening cannot work for forward-looking imaging, while real aperture radar (RAR) has arbitrary imaging geometry. Nevertheless, restricted by the antenna aperture, azimuth resolution of RAR is coarse, super-resolution technology is required to improve its azimuth resolution. Exploiting the sparse prior information of the target, the super-resolution problem can be transformed into an $L_1$ norm minimization problem mathematically. Iterative reweighted algorithm can effectively solve the $L_1$ norm minimization problem by replacing $L_1$ norm with reweighted $L_2$ norm and computing the weight in each iteration. However, it suffers from a large computational load due to the repeated multiplications and inversions of large matrices. In this article, a fast azimuth super-resolution imaging method of RAR based on iterative reweighted least squares (IRLS) with linear sketching (LS) was proposed to achieve fast super-resolution imaging of RAR. The LS theory is employed to compress echo matrix and antenna measurement matrix into much smaller matrices via multiplying them by an embedded matrix. Then, the IRLS solver was utilized to address the reconstructed objective function. Much of the expensive computation can then be performed on the smaller matrices, thereby accelerating the algorithm. Simulations and experimental data prove that the proposed algorithm can offer a time complexity reduction without loss of imaging performance.  © 2008-2012 IEEE.","Iterative methods; Least squares approximations; Matrix algebra; Optical resolving power; Radar antennas; Synthetic aperture radar; Antenna measurement; Computational loads; Imaging performance; Iterative reweighted least square; L1-norm minimizations; Objective functions; Real aperture radar; Super resolution imaging; algorithm; complexity; computer simulation; experimental study; geometry; image analysis; image resolution; least squares method; numerical model; performance assessment; remote sensing; Radar imaging","Iterative reweighted least squares (IRLS); linear sketching (LS); real aperture radar (RAR); super-resolution imaging","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85101751755"
"Wang Q.; Zhang C.; Atkinson P.M.","Wang, Qunming (55649569623); Zhang, Chengyuan (57216611828); Atkinson, Peter M. (7201906181)","55649569623; 57216611828; 7201906181","Sub-pixel mapping with point constraints","2020","Remote Sensing of Environment","244","","111817","","","","10.1016/j.rse.2020.111817","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084074406&doi=10.1016%2fj.rse.2020.111817&partnerID=40&md5=1aaaa68c4d77d2ee58df36ce3ec3cbf7","Remote sensing images contain abundant land cover information. Due to the complex nature of land cover, however, mixed pixels exist widely in remote sensing images. Sub-pixel mapping (SPM) is a technique for predicting the spatial distribution of land cover classes within mixed pixels. As an ill-posed inverse problem, the uncertainty of prediction cannot be eliminated and hinders the production of accurate sub-pixel maps. In contrast to conventional methods that use continuous geospatial information (e.g., images) to enhance SPM, in this paper, a SPM method with point constraints into SPM is proposed. The method of fusing point constraints is implemented based on the pixel swapping algorithm (PSA) and utilizes the auxiliary point information to reduce the uncertainty in the SPM process and increase map accuracy. The point data are incorporated into both the initialization and optimization processes of PSA. Experiments were performed on three images to validate the proposed method. The influences of the performances were also investigated under different numbers of point data, different spatial characters of land cover and different zoom factors. The results show that by using the point data, the proposed SPM method can separate more small-sized targets from aggregated artifacts and the accuracies are increased obviously. The proposed method is also more accurate than the advanced radial basis function interpolation-based method. The advantage of using point data is more evident when the point data size and scale factor are large and the spatial autocorrelation of the land cover is small. As the amount of point data increases, however, the increase in accuracy becomes less noticeable. Furthermore, the SPM accuracy can still be increased even if the point data and coarse proportions contain errors. © 2020 Elsevier Inc.","Aggregates; Image enhancement; Inverse problems; Mapping; Radial basis function networks; Remote sensing; Spatial variables measurement; Conventional methods; Geo-spatial informations; ILL-posed inverse problem; Land cover informations; Radial basis function interpolation; Remote sensing images; Spatial autocorrelations; Sub-pixel mapping; algorithm; autocorrelation; land cover; mapping method; pixel; remote sensing; satellite imagery; spatial distribution; Pixels","Downscaling; Pixel swapping algorithm (PSA); Point constraints; Remote sensing images; Sub-pixel mapping (SPM); Super-resolution mapping","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85084074406"
"Zhang Y.; Zhang Z.; Li T.","Zhang, Yaobin (57222508386); Zhang, Zhiheng (57222509945); Li, Tingle (57747873300)","57222508386; 57222509945; 57747873300","Research on Image Super-resolution Reconstruction Based on Deep Learning","2021","IOP Conference Series: Earth and Environmental Science","1802","4","042034","","","","10.1088/1742-6596/1802/4/042034","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102944528&doi=10.1088%2f1742-6596%2f1802%2f4%2f042034&partnerID=40&md5=a3d6b00dbade363c9ce4ea5b7f99cd78","Image super-resolution processing technology refers to the technology of reconstructing high-resolution images by using low-resolution images with mutual displacement of multiple frames of the same scene. At present, image super-resolution processing technology is widely used in image reconstruction in various fields, such as: medical images, remote sensing images, robot vision, etc. In recent years, deep learning has also been widely used in various fields, especially in computer vision and speech processing. Since image super-resolution reconstruction the method of deep learning is introduced into the technology. Due to the good performance advantages of the deep learning method, it has become an important method for the research of image superresolution reconstruction technology. In this paper, the current status of domestic and foreign research on image super-resolution reconstruction is first simplified. Then, the theory of deep learning was explained, mainly the artificial neural network theory, the related theory of super-resolution reconstruction based on deep learning, and the method of image super-resolution reconstruction based on deep learning. © Published under licence by IOP Publishing Ltd.","Computer aided design; Computer vision; Engineering education; Image reconstruction; Learning systems; Manufacture; Medical imaging; Medical robotics; Neural networks; Optical resolving power; Remote sensing; Speech processing; High resolution image; Image super resolutions; Image super-resolution reconstruction; Low resolution images; Mutual displacement; Processing technologies; Remote sensing images; Super resolution reconstruction; Deep learning","","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85102944528"
"Deng W.; Zhu Q.; Sun X.; Lin W.; Guan Q.","Deng, Weihuan (57224183913); Zhu, Qiqi (56420945500); Sun, Xiongli (57213190878); Lin, Weihua (57224195800); Guan, Qingfeng (55838509944)","57224183913; 56420945500; 57213190878; 57224195800; 55838509944","EML-GAN: GENERATIVE ADVERSARIAL NETWORK-BASED END-TO-END MULTI-TASK LEARNING ARCHITECTURE FOR SUPER-RESOLUTION RECONSTRUCTION AND SCENE CLASSIFICATION OF LOW-RESOLUTION REMOTE SENSING IMAGERY","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","5397","5400","3","10.1109/IGARSS47720.2021.9554060","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129901449&doi=10.1109%2fIGARSS47720.2021.9554060&partnerID=40&md5=0fe7a3c2eada4f8431bd4807afd84b84","High spatial resolution remote sensing images (HSR-RSIs) are critical to providing fine land cover/land use information for scene classification. The global low spatial resolution remote sensing images (LSR-RSIs) can be easily obtained at present, whereas it is still a challenge to acquire large-scale HSR-RSIs. In this paper, an algorithmic-based architecture is proposed to improve the spatial resolution of RSIs beyond the limits of imaging sensors. The generative adversarial network-based end-to-end multi-task learning architecture (EML-GAN) is proposed for LSR-RSIs super-resolution reconstruction and scene classification simultaneously. In EML-GAN, the generator network is used to recover the fine geometric structures of LSR-RSIs by fusing the deep contextual, structure, and edge information. In addition, the discriminator network is designed to predict the scene label and distinguish the real/fake of the input data. The proposed architecture is evaluated on a public dataset and two self-made dataset. The experimental results show that the proposed architecture improves the visual effect and classification performance of LSR-RSIs. © 2021 IEEE","Classification (of information); Image classification; Image reconstruction; Image resolution; Network architecture; Remote sensing; End to end; High spatial resolution; Learning architectures; Multitask learning; Network-based; Proposed architectures; Remote sensing images; Scene classification; Super-resolution reconstruction; Generative adversarial networks","generative adversarial network; remote sensing images; Scene classification; super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85129901449"
"","","","24th ISPRS Congress, Commission I","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","1","","","","2619","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091106228&partnerID=40&md5=8497988fb8031bca7b1ac8b91026a140","The proceedings contain 342 papers. The topics discussed include: learning super-resolution for sentinel-2 images with real ground truth data from a reference satellite; combined patch-wise minimal-maximal pixels regularization for deblurring; urban material classification using spectral and textural features retrieved from autoencoders; a worldwide 3D GCP database inherited from 20 years of massive multi-satellite observations; deep learning based feature matching and its application in image orientation; a novel RPC bias model for improving the positioning accuracy of satellite images; land salinization dynamics based on feature space combinations from landsat image in Tongyu County, Northeast China; a new index for identifying water body from sentinel-2 satellite remote sensing imagery; land cover classification using convolutional neural network with remote sensing data and digital surface model; assessing resilience of infrastructures towards exogenous events by using PS-INSAR-based surface motion estimates and machine learning regression techniques; region-based fuzzy clustering image segmentation algorithm with Kullback-Leibler distance; experiences from the project course in geoinformatics; and refugees stories told by maps: a challenge for students in a scientific Olympiad.","","","Conference review","Final","","Scopus","2-s2.0-85091106228"
"Liu S.-Q.; Li B.; Zhao B.; Huang L.; Wu Y.-Z.; Bao W.-M.","Liu, Shi-qi (55210452400); Li, Bing (57191481831); Zhao, Bo (55767163300); Huang, Lei (57215233252); Wu, Yue-zhou (35390132000); Bao, Wei-min (43160980800)","55210452400; 57191481831; 55767163300; 57215233252; 35390132000; 43160980800","A super resolution target separation and reconstruction approach for single channel sar against deceptive jamming","2021","Defence Technology","","","","","","","10.1016/j.dt.2021.10.008","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121793956&doi=10.1016%2fj.dt.2021.10.008&partnerID=40&md5=c6ebd09b78851ee500464fc5ccecbf5b","The excellent remote sensing ability of synthetic aperture radar (SAR) will be misled seriously when it encounters deceptive jamming which possesses high fidelity and fraudulence. In this paper, the dynamic synthetic aperture (DSA) scheme is used to extract the difference between the true and false targets. A simultaneous deceptive jamming suppression and target reconstruction method is proposed for a single channel SAR system to guarantee remote sensing ability. The system model is formulated as a sparse signal recovery problem with an unknown parametric dictionary to be estimated. An iterative re-weighted method is employed to jointly handle the dictionary parameter learning and target reconstruction problem in an majorization-minimization framework, where a surrogate function majorizing the Gaussian entropy in the objective function is introduced to circumvent its non-convexity. After dictionary parameter learning, the grid mismatching problem in a fixed grid based method is avoided. Therefore, the proposed method can reap a super resolution result. Besides, a simple yet effective DSA section scheme is developed for the SAR data excerpting, in which only two DSAs are required. Experimental results about location error and reconstruction power error reveal that the proposed method is able to achieve a good performance in deceptive jamming suppression. © 2021 China Ordnance Society","Iterative methods; Jamming; Learning systems; Optical resolving power; Remote sensing; Signal reconstruction; Deceptive jamming; Deceptive jamming suppression; Jamming suppression; Majorization-minimization; Minimisation; Off-grid reconstruction; Off-grids; Single channels; Superresolution; Synthetic aperture radar; Synthetic aperture radar","Deceptive jamming suppression; Majorization-minimization; Off-grid reconstruction; Synthetic aperture radar (SAR)","Article","Article in press","All Open Access; Gold Open Access","Scopus","2-s2.0-85121793956"
"Ge W.; Wang Z.; Wang G.; Tan S.; Zhang J.","Ge, Wenyi (55782079500); Wang, Zhitao (57222554407); Wang, Guigui (57190274143); Tan, Shihan (57190282499); Zhang, Jianwei (57195437554)","55782079500; 57222554407; 57190274143; 57190282499; 57195437554","Remote sensing image super-resolution for the visual system of a flight simulator: Dataset and baseline","2021","Aerospace","8","3","76","","","","10.3390/aerospace8030076","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103208331&doi=10.3390%2faerospace8030076&partnerID=40&md5=6f11f15ea40c56b725a7a9cabd7b53fb","High-resolution remote sensing images are the key data source for the visual system of a flight simulator for training a qualified pilot. However, due to hardware limitations, it is an expensive task to collect spectral and spatial images at very high resolutions. In this work, we try to tackle this issue with another perspective based on image super-resolution (SR) technology. First, we present a new ultra-high-resolution remote sensing image dataset named Airport80, which is captured from the airspace near various airports. Second, a deep learning baseline is proposed by applying the generative and adversarial mechanism, which is able to reconstruct a high-resolution image during a single image super-resolution. Experimental results for our benchmark demonstrate the effectiveness of the proposed network and show it has reached satisfactory performances. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","","Flight simulator; Generative adversarial network; Remote sensing image; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85103208331"
"Yu Z.; Yang K.; Luo Y.; Wang P.; Yang Z.","Yu, Zhenyu (57192660625); Yang, Kun (57205570364); Luo, Yi (55712582900); Wang, Pei (57216525166); Yang, Ze (57201366854)","57192660625; 57205570364; 55712582900; 57216525166; 57201366854","Research on the Lake Surface Water Temperature Downscaling Based on Deep Learning","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9428586","5550","5558","8","10.1109/JSTARS.2021.3079357","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105879992&doi=10.1109%2fJSTARS.2021.3079357&partnerID=40&md5=58dcd306c13ea7a86ecd9c98d695eaae","Lake surface water temperature (LSWT) is an important factor of water ecological environment. As global warming, LSWT is also on the rise. Research on the main reasons of LSWT rising is the basis for controlling and improving the regional ecological environment. However, it is difficult for the existing remote sensing images to take into account the temporal and spatial resolution. Low-resolution images have a serious impact on data accuracy and even produce incorrect results. Therefore, obtaining high temporal and spatial resolution images by downscaling is of great significance to more accurately analyze the temporal and spatial characteristics of LSWT. In this article, Dianchi Lake is selected as research area, and the high spatial resolution image (Landsat) and high temporal resolution image (MODIS) are taken as data. Based on the downscaling algorithm of statistics and learning, DisTrad- super-resolution convolutional neural network (SRCNN) downscaling model is proposed, and the monthly average dataset of LSWT with 50 m resolution is constructed. The results showed 1) DisTrad-SRCNN can reflect the most distribution characteristics of LSWT (SSIMday = 0.96, PSNRday = 23.97; SSIMnight = 0.95, PSNRnight = 24.99). 2) LSWT had an overall upward trend (CRday = 0.22 °C/10a, CRnight = 0.21 °C/10a), showing a cyclical change of cold-warm-cold about 4 years. 3) The northern and lakeshore area were basically in the high temperature, and the whole lake presents a 4-5-year warm-cold-warm periodic change; the LSWT closer to the urban and residential areas and its change rate were relatively high, which indirectly reflected the serious impact of human activities on LSWT. © 2008-2012 IEEE.","Ecology; Global warming; Image resolution; Lakes; Remote sensing; Temperature; Distribution characteristics; Ecological environments; High spatial resolution images; High temporal resolution; Low resolution images; Remote sensing images; Surface water temperature; Temporal and spatial; Deep learning","DisTrad; downscaling; lake surface water temperature (LSWT); plateau lakes; super-resolution convolutional neural network (SRCNN)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85105879992"
"Huangfu K.; Li J.; Zhang X.; Zhang J.; Cui H.; Sun Q.","Huangfu, Kuan (57219898366); Li, Jian (55983731500); Zhang, Xinjia (57206939178); Zhang, Jinping (55720385500); Cui, Hao (57217480102); Sun, Quan (57219900220)","57219898366; 55983731500; 57206939178; 55720385500; 57217480102; 57219900220","Remote estimation of water quality parameters of medium-and small-sized inland rivers using sentinel-2 imagery","2020","Water (Switzerland)","12","11","3124","1","18","17","10.3390/w12113124","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095971607&doi=10.3390%2fw12113124&partnerID=40&md5=fd4465a1e508532ca60aab287f1fcf3d","In the application of quantitative remote sensing in water quality monitoring, the existence of mixed pixels greatly affects the accuracy of water quality parameter inversion, especially for narrow inland rivers. Improving the image spatial resolution and weakening the interference of mixed pixels in the image are some of the urgent problems to be solved in the study of water quality monitoring of medium-and small-sized inland rivers. We processed Sentinel-2 multispectral images using the super-resolution algorithm and generated a set of 10 m spatial resolution images with basically unchanged reflection characteristics. Both qualitative and quantitative evaluation results show that the super-resolution algorithm can weaken the influence of mixed pixels while maintaining spectral invariance. Before the application of the super-resolution algorithm, the inversion accuracy of water quality parameters in this study were as follows: for NH3-N, the R2 was 0.61, the root mean squared error (RMSE) was 0.177 and the mean absolute percentage error (MAPE) was 29.33%; for Chemical Oxygen Demand (COD), the R2 was 0.26, the RMSE was 0.756 and the MAPE was 4.62%; for Total Phosphorus (TP), the R2 was 0.69, the RMSE was 0.032 and the MAPE was 30.58%. After the application of the super-resolution algorithm, the inversion accuracy of water quality parameters in this study were as follows: for NH3-N, the R2 was 0.67, the RMSE was 0.161 and the MAPE was 25.88%; for COD, the R2 was 0.53, the RMSE was 0.546 and the MAPE was 3.36%; for TP, the R2 was 0.60, the RMSE was 0.034 and the MAPE was 24.28%. Finally, the spatial distribution of NH3-N, COD and TP was obtained by using a machine learning model. The results showed that the application of the super-resolution algorithm can effectively improve the retrieval accuracy of NH3-N, COD and TP, which illustrates the application potential of the super-resolution algorithm in water quality remote sensing quantitative monitoring. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Ammonia; Chemical oxygen demand; Image enhancement; Image resolution; Mean square error; Optical resolving power; Pixels; Remote sensing; Rivers; Turing machines; Water quality; Image spatial resolution; Mean absolute percentage error; Quantitative remote sensing; Reflection characteristics; Spatial resolution images; Super resolution algorithms; Water quality monitoring; Water quality parameters; accuracy assessment; algorithm; error analysis; image resolution; machine learning; parameterization; phosphorus; pixel; remote sensing; Sentinel; spatial resolution; water quality; Parameter estimation","Chemical oxygen demand; NH<sub>3</sub>-N; Remote sensing; Sentinel-2; Spectrum; Super-resolution algorithm; Total phosphorus; Water quality monitoring; Which provides thethepossibility totoobtainobtainhigher-precision waterwaterqualityqualityinversioninversionresults.results","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85095971607"
"Guo C.; Jiang J.; Wang Q.; Chen G.","Guo, Cheng (57465802400); Jiang, Juhao (57465215600); Wang, Qing (57218339522); Chen, Guannan (16238204100)","57465802400; 57465215600; 57218339522; 16238204100","Multi-Frame Super-Resolution Algorithm Based on Attention Mechanism","2021","2021 6th International Conference on Signal and Image Processing, ICSIP 2021","","","","431","435","4","10.1109/ICSIP52628.2021.9688891","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125168096&doi=10.1109%2fICSIP52628.2021.9688891&partnerID=40&md5=db9cb7101d7b2f52620825b35125f1e9","In the field of computer vision, image super-resolution is a difficult task, which have many applications in remote sensing, military and so on. In this paper, we introduce the convolutional block attention module (CBAM) into super-resolution problem, proposing a novel method called multi-frame super-resolution (MFSR) algorithm based on attention mechanism. Our proposed MFSR algorithm uses a three-layer CNN as benchmark and cascades CBAM at the end of each CNN block. The proposed algorithm can deliver a high-resolution output corresponding to the center (3rd) input frame. The average PSNR and SSIM of our algorithm are 33.318dB and 0.906 respectively, which outperform other MFSR algorithm.  © 2021 IEEE.","Military applications; Remote sensing; Attention mechanisms; Attentional mechanism; Image super resolutions; Multi-frame; Multi-frame image super-resolution; PSNR; Remote-sensing; SSIM; Super resolution algorithms; Superresolution; Optical resolving power","Attentional Mechanism; Multi-frame image super-resolution; PSNR; SSIM","Conference paper","Final","","Scopus","2-s2.0-85125168096"
"Bai Y.; Zou T.; Ye S.; Qin Z.; Gao G.; Gu Y.","Bai, Yang (57193866543); Zou, Tongyuan (57222242992); Ye, Shujia (57222244086); Qin, Zhenqiang (57222245472); Gao, Guoming (56140165800); Gu, Yanfeng (7403045983)","57193866543; 57222242992; 57222244086; 57222245472; 56140165800; 7403045983","Weak Target Detection in High-Resolution Remote Sensing Images by Combining Super-Resolution and Deformable FPN","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323260","292","295","3","10.1109/IGARSS39084.2020.9323260","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101972229&doi=10.1109%2fIGARSS39084.2020.9323260&partnerID=40&md5=d08403e1578da48e2a3d56ba1f3c38ce","Weak target detection plays an important role in military and civilian fields. However, due to the limitation of the target size and the influence of complex background, the detection of weak target is a huge challenge. Therefore, based on high-resolution remote sensing image, this paper proposes a weak target detection network which combines super-resolution and deformable convolution. Firstly, the high-resolution remote sensing image is expanded and enhanced to eliminate the influence of complex background. Secondly, a detection network based on the deformable convolution and feature pyramid network (FPN) is used to solve the problem of less information caused by the fewer target pixels. In addition, this paper establishes a detection dataset only containing weak vehicles. The experimental results show that the proposed method achieves better detection results in the weak target detection problem. © 2020 IEEE.","Complex networks; Convolution; Deformation; Geology; Image enhancement; Object recognition; Optical resolving power; Complex background; Detection networks; Feature pyramid; High resolution remote sensing images; Super resolution; Target size; Weak target detection; Weak targets; Remote sensing","deformable convolution; super-resolution; Weak target detection","Conference paper","Final","","Scopus","2-s2.0-85101972229"
"He D.; Zhong Y.; Shi Q.; Liu X.","He, Da (57188721489); Zhong, Yanfei (12039673900); Shi, Qian (55286447700); Liu, Xiaoping (15757680000)","57188721489; 12039673900; 55286447700; 15757680000","RETHINKING THE HIGH FREQUENCY COMPONENTS IN DEEP SUB-PIXEL MAPPING NETWORK","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","5366","5369","3","10.1109/IGARSS47720.2021.9553075","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126001860&doi=10.1109%2fIGARSS47720.2021.9553075&partnerID=40&md5=67a45d9ad6e3c9570fed79321047d5c0","Deep sub-pixel mapping network (DSMNet) is a state-of-the-art approach in the field of sub-pixel mapping (SPM, also called super resolution mapping), combining deep learning theory, to solve the mixed pixel problem, which is ubiquitous in remote sensing images due to the spatial-resolving limitation. However, traditional DSMNet usually do not consider the multi-scale distribution characteristics of the real geographical distribution exposed in urban landscape. Furthermore, the heterogeneous distribution characteristics (high-frequency components) are the most important for SPM, but are difficult to learn and usually ignored in the tradition network models. In this paper, the high-frequency component aware (HFCA) module was proposed, based on the hierarchical supervised deep sub-pixel mapping network (HiDSMNet). HiDSMNet establishes a hierarchical supervised architecture for explicit multi-scale supervision to prompt the network to learn a multi-scale representation. Besides, HFCA module is integrated to prompt the network to intensify the learning of the high-frequency representation. The experimental results with three public datasets validated the superiority of the proposed HiDSMNet. © 2021 IEEE.","","Deep sub-pixel mapping network (DSMNet); Hierarchical supervised architecture; High-frequency components; Sub-pixel mapping (SPM)","Conference paper","Final","","Scopus","2-s2.0-85126001860"
"Hu L.; Qin M.; Zhang F.; Du Z.; Liu R.","Hu, Linshu (57215775327); Qin, Mengjiao (57193907473); Zhang, Feng (56434720200); Du, Zhenhong (25929119800); Liu, Renyi (55809641900)","57215775327; 57193907473; 56434720200; 25929119800; 55809641900","RSCNN: A cnn-based method to enhance low-light remote-sensing images","2021","Remote Sensing","13","1","62","1","13","12","10.3390/rs13010062","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098793118&doi=10.3390%2frs13010062&partnerID=40&md5=40c119233e4d86ef700acfca9023f744","Image enhancement (IE) technology can help enhance the brightness of remote-sensing images to obtain better interpretation and visualization effects. Convolutional neural networks (CNN), such as the Low-light CNN (LLCNN) and Super-resolution CNN (SRCNN), have achieved great success in image enhancement, image super resolution, and other image-processing applications. Therefore, we adopt CNN to propose a new neural network architecture with end-to-end strategy for low-light remote-sensing IE, named remote-sensing CNN (RSCNN). In RSCNN, an upsampling operator is adopted to help learn more multi-scaled features. With respect to the lack of labeled training data in remote-sensing image datasets for IE, we use real natural image patches to train firstly and then perform fine-tuning operations with simulated remote-sensing image pairs. Reasonably designed experiments are carried out, and the results quantitatively show the superiority of RSCNN in terms of structural similarity index (SSIM) and peak signal-to-noise ratio (PSNR) over conventional techniques for low-light remote-sensing IE. Furthermore, the results of our method have obvious qualitative advantages in denoising and maintaining the authenticity of colors and textures. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","","Convolutional neural network; Low-light enhancement; Remote-sensing image","Note","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85098793118"
"","","","24th ISPRS Congress, Commission V and Youth Forum","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","5","","","","2619","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092318791&partnerID=40&md5=4ee0fc2b4aea2021075fee4eb47d5d55","The proceedings contain 342 papers. The topics discussed include: learning super-resolution for sentinel-2 images with real ground truth data from a reference satellite; combined patch-wise minimal-maximal pixels regularization for deblurring; urban material classification using spectral and textural features retrieved from autoencoders; a worldwide 3D GCP database inherited from 20 years of massive multi-satellite observations; deep learning based feature matching and its application in image orientation; a novel RPC bias model for improving the positioning accuracy of satellite images; land salinization dynamics based on feature space combinations from landsat image in Tongyu County, Northeast China; a new index for identifying water body from sentinel-2 satellite remote sensing imagery; land cover classification using convolutional neural network with remote sensing data and digital surface model; assessing resilience of infrastructures towards exogenous events by using PS-INSAR-based surface motion estimates and machine learning regression techniques; region-based fuzzy clustering image segmentation algorithm with Kullback-Leibler distance; experiences from the project course in geoinformatics; and refugees stories told by maps: a challenge for students in a scientific Olympiad.","","","Conference review","Final","","Scopus","2-s2.0-85092318791"
"Yan L.; Chang K.","Yan, Li (56390996600); Chang, Kun (57222198694)","56390996600; 57222198694","A new super resolution framework based on multi-task learning for remote sensing images","2021","Sensors","21","5","1743","1","20","19","10.3390/s21051743","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101883506&doi=10.3390%2fs21051743&partnerID=40&md5=12fe6507d06b07764d8c500079d636e2","Super-resolution (SR) algorithms based on deep learning have dominated in various tasks, including medical imaging, street view surveillance and face recognition. In the remote sensing field, most of the current SR methods utilize the low-resolution (LR) images that directly bicubic downsampled the high-resolution (HR) images as not only train set but also test set, thus achieving high PSNR/SSIM scores but showing performance drop in application because the degradation model in remote sensing images is subjected to Gaussian blur with unknown parameters. Inspired by multi-task learning strategy, we propose a multiple-blur-kernel super-resolution framework (MSF), in which a multiple-blur-kernel learning module (MLM) optimizes the parameters of the network transferable and sensitive for SR procedures with different blur kernels. Besides, to simul-taneously exploit the prior of the large-scale remote sensing images and recurrent information in a single test image, a class-feature capture module (CCM) and an unsupervised learning module (ULM) are leveraged in our framework. Extensive experiments show that our framework outper-forms the current state-of-the-art SR algorithms in remotely sensed imagery SR with unknown Gaussian blur kernel. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Face recognition; Learning systems; Medical imaging; Multi-task learning; Optical resolving power; Recurrent neural networks; Degradation model; High resolution image; Kernel learning; Low resolution images; Remote sensing images; Remotely sensed imagery; State of the art; Super resolution; article; controlled study; convolutional neural network; deep learning; diagnostic imaging; facial recognition; human; human experiment; imagery; remote sensing; Remote sensing","Convolutional neural network; Gaussian blur kernels; Multi-task learning; Unsupervised learning strategy","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85101883506"
"Qi L.; Li J.; Wang Y.; Lei M.; Gao X.","Qi, Lin (57208783823); Li, Jie (7410068291); Wang, Ying (56757732900); Lei, Mingyu (57217129645); Gao, Xinbo (7403873424)","57208783823; 7410068291; 56757732900; 57217129645; 7403873424","Deep spectral convolution network for hyperspectral image unmixing with spectral library","2020","Signal Processing","176","","107672","","","","10.1016/j.sigpro.2020.107672","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086389939&doi=10.1016%2fj.sigpro.2020.107672&partnerID=40&md5=52d1444c1168a4e0907767a55288e28d","Spectral unmixing is an important task for hyperspectral remote sensing image processing, which infers the pure spectral signatures (endmembers) in hyperspectral image (HSI) and their corresponding fractions (abundances). Recently, deep learning has become a powerful tool for HSI analysis, such as HSI classification and HSI super-resolution. In this paper, we propose a new unmixing algorithm that uses the convolutional neural network (CNN) for hyperspectral data incorporating spectral library, which can be applied for a series of HSIs after training. The proposed deep spectral convolution network extracts features and then executes the estimating process from these extracted spectral characteristics to acquire the fractional abundances on a fixed spectral library. Meanwhile, considering the incorporation of spectral library, a deeper convolutional network has been adopted to achieve better results. Moreover, we construct a new loss function, which includes pixel reconstruction error, abundance sparsity, and abundance cross-entropy to train the aforementioned network in an end-to-end manner. Experiments on both simulated and real HSIs indicate the advantage of the proposed method, which can obviously enhance the abundance estimation accuracy. © 2020 Elsevier B.V.","Convolution; Convolutional neural networks; Deep learning; Remote sensing; Spectroscopy; Abundance estimation; Convolutional networks; Hyperspectral Remote Sensing Image; Reconstruction error; Spectral characteristics; Spectral convolution; Spectral signature; Unmixing algorithms; Image processing","Deep learning; End-to-end model; Hyperspectral unmixing; Spectral convolution network; Spectral library","Article","Final","","Scopus","2-s2.0-85086389939"
"Zhang X.; Ge Y.; Ling F.; Chen J.; Chen Y.; Jia Y.","Zhang, Xining (57219904196); Ge, Yong (26655529300); Ling, Feng (56278268300); Chen, Jin (55717837500); Chen, Yuehong (56084228300); Jia, Yuanxin (57171309000)","57219904196; 26655529300; 56278268300; 55717837500; 56084228300; 57171309000","Graph Convolutional Networks-Based Super-Resolution Land Cover Mapping","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9497702","7667","7681","14","10.1109/JSTARS.2021.3100400","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112627072&doi=10.1109%2fJSTARS.2021.3100400&partnerID=40&md5=e7aa580b15e0a4795deae4ea8d984e9b","Super-resolution mapping (SRM) is an effective technology to solve the problem of mixed pixels because it can be used to generate fine-resolution land cover maps from coarse-resolution remote sensing images. Current methods based on deep neural networks have been successfully applied to SRM, as they can learn complex spatial patterns from training data. However, they lack the ability to learn structural information between adjacent land cover classes, which is vital in the reconstruction of spatial distribution. In this article, an SRM method based on graph convolutional networks (GCNs), named {\rm{SR}}{{\rm{M}}_{{\rm{GCN}}}}, is proposed to improve SRM results by capturing structure information on the graph. In {\rm{SR}}{{\rm{M}}_{{\rm{GCN}}}}, a supervised inductive learning strategy with mini-graphs as input is considered, which is an extension of the GCN framework. Furthermore, two operations are designed in terms of adjacency matrix construction and an information propagation rule to help reconstruct detailed information of geographical objects. Experiments on three datasets with different spatial resolutions demonstrate the qualitative and quantitative superiority of {\rm{SR}}{{\rm{M}}_{{\rm{GCN}}}} over three other popular SRM methods.  © 2008-2012 IEEE.","Backpropagation; Convolution; Deep neural networks; Information dissemination; Learning systems; Mapping; Optical resolving power; Remote sensing; Convolutional networks; Geographical objects; Inductive learning strategies; Information propagation; Remote sensing images; Structural information; Structure information; Super-resolution mappings; artificial neural network; data set; graphical method; image analysis; image resolution; land cover; pixel; quantitative analysis; remote sensing; Convolutional neural networks","Deep neural networks (DNNs); graph convolutional networks (GCNs); land cover; subpixel; super-resolution mapping (SRM)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85112627072"
"Htitiou A.; Boudhar A.; Benabdelouahab T.","Htitiou, Abdelaziz (57212145169); Boudhar, Abdelghani (35090979500); Benabdelouahab, Tarik (56766050800)","57212145169; 35090979500; 56766050800","Deep Learning-Based Spatiotemporal Fusion Approach for Producing High-Resolution NDVI Time-Series Datasets; [  Approche de fusion spatiotemporelle basée sur l’apprentissage profond pour produire des séries temporelles de NDVI à haute résolution]","2021","Canadian Journal of Remote Sensing","47","2","","182","197","15","10.1080/07038992.2020.1865141","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100805494&doi=10.1080%2f07038992.2020.1865141&partnerID=40&md5=e11a28e6b81aa194febd968a1bec2b11","The availability of concurrently high spatiotemporal resolution remote sensing data is highly desirable as they represent a key element for effective monitoring in various environmental applications. However, due to the tradeoff between the spatial resolution and acquisition frequency of current satellites, such data are still lacking. Many studies have been undertaken trying to overcome these problems; however, a couple of long-standing limitations remain, including accommodating abrupt temporal changes, dealing with complex and heterogeneous landscapes, and integrating other satellite datasets as well. Accordingly, this paper proposes a deep learning spatiotemporal data fusion approach based on Very Deep Super-Resolution (VDSR) to fuse the NDVI retrievals from Sentinel-2 and Landsat 8 images. The performances of VDSR are analyzed in comparison with those of two other classical methods, the enhanced spatial and temporal adaptive reflectance fusion model (ESTARFM) and the flexible spatiotemporal data fusion (FSDAF) method. The results obtained indicate that VDSR outperforms other data fusion algorithms as it generated the least blurred images and the most accurate predictions of synthetic NDVI values, particularly in areas with heterogeneous landscapes and abrupt land-cover changes. The proposed algorithm has broad prospects to improve near-real-time agricultural monitoring purposes and derivation of crop status conditions in the field-scale. ©, Copyright © CASI.","Agricultural robots; Image fusion; Remote sensing; Agricultural monitoring; Data fusion algorithm; Environmental applications; Frequency of currents; Heterogeneous landscapes; Spatio-temporal data; Spatio-temporal fusions; Spatio-temporal resolution; Deep learning","","Article","Final","","Scopus","2-s2.0-85100805494"
"Yanovsky I.; Qin J.; Lambrigtsen B.","Yanovsky, Igor (16403652300); Qin, Jing (53980312700); Lambrigtsen, Bjorn (6603478504)","16403652300; 53980312700; 6603478504","Spatio-temporal resolution enhancement for geostationary microwave data","2020","16th Specialist Meeting on Microwave Radiometry and Remote Sensing of the Environment, MicroRad 2020 - Proceedings","","","9342539","","","","10.1109/MicroRad49612.2020.9342539","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101332519&doi=10.1109%2fMicroRad49612.2020.9342539&partnerID=40&md5=85b820a82533ce62f90bbd436975ddbe","In this paper, we provide a formulation for enhancing the spatio-temporal resolution of a remote sensing sequence of images. Such an image sequence could be captured by a sensor that convolves a physical scene with a spatio-temporal point spread function whose two-dimensional spatial component is the microwave instrument's point spread function and whose one-dimensional temporal component is the rectangular kernel with sensor exposure time as its support. We perform resolution enhancement in the space-time domain, as opposed to solving the deconvolution problem for each observation. Simultaneous space-time optimization achieves a more efficient and more accurate reconstruction. The proposed deconvolution method employs total variation regularization and solves the formulation via the Split-Bregman optimization algorithm. In our experiments, we use a simulated microwave image sequence of a hurricane and demonstrate that the proposed methodology improves the accuracy when compared to the observed sequence.  © 2020 IEEE.","Image enhancement; Microwaves; Optical transfer function; Radiometry; Remote sensing; Space optics; Deconvolution method; Deconvolution problem; Microwave instruments; Optimization algorithms; Resolution enhancement; Sequence of images; Spatio-temporal resolution; Total variation regularization; Microwave sensors","Geostationary satellite; Microwave imaging; Remote sensing; Spatio-temporal resolution; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85101332519"
"Wang P.; Yao H.; Zhang G.","Wang, Peng (57189493188); Yao, Hongyu (57220160389); Zhang, Gong (35241577600)","57189493188; 57220160389; 35241577600","Super-resolution flood inundation mapping for multispectral image based on super-pixel scale; [超像元尺度下的多光谱图像超分辨率洪水淹没制图]","2021","National Remote Sensing Bulletin","25","2","","641","652","11","10.11834/jrs.20210199","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103158759&doi=10.11834%2fjrs.20210199&partnerID=40&md5=603f4ce7aeb92aaa18f4e687fdc0534a","Super Resolution Mapping (SRM) technology can effectively handle mixed pixels in remote sensing image and obtain the accurate distribution information of land-cover class. SRM technology is currently successfully applied to flood inundation mapping for multispectral image, which is called Super Resolution Flood Inundation Mapping (SRFIM). However, the existing SRFIM methods are often based on pixel-scale spatial correlation. This method considers the spatial relationship between pixels in the set rectangular window, but the shape of the inundation area or the non-inundation area is irregular in reality. Thus, the pixel-scale spatial correlation is insufficiently accurate, which affects the final accuracy of flood inundation mapping. Super-resolution flood inundation mapping of multispectral image based on super-pixel scale spatial correlation (SSSC-SRFIM) is proposed to solve the abovementioned problem. In SSSC-SRFIM, the original coarse multispectral image is first improved by bicubic interpolation to obtain the improved image, and the fractional image with the proportion value of each subpixel belonging to inundation area is obtained by unmixing the improved image. The first principal component of the improved image is then extracted by principal component analysis, and the image segmentation based on multi-resolution is used to segment the first principal component to obtain the super-pixels with irregular shape. Next, the fractional image and super-pixels are integrated, and the random walk algorithm is introduced to calculate the super-pixel-scale spatial correlation. Finally, according to the super-pixel-scale spatial correlation, the label of the inundation area or the non-inundation area is assigned to each sub-pixel by the class allocation method based on the unit of object. Thus, the final result of flood inundation mapping is produced.Two Landsat 8 OLI multispectral images are used to evaluate the method. The proposed SSSC-SRFIM method has better performance than the traditional methods.In the proposed SSSC-SRFIM, the super-pixel-scale spatial correlation is more accurate than pixel-scale spatial correlation because the irregular distribution shape of the actual inundation and non-inundation areas is considered. Therefore, better flood inundation mapping result can be obtained by the proposed SSSC-SRFIM. © 2021, Science Press. All right reserved.","Flood control; Floods; Image enhancement; Image segmentation; Optical resolving power; Pixels; Remote sensing; Bicubic interpolation; First principal components; Flood inundation mappings; Random walk algorithms; Remote sensing images; Spatial correlations; Spatial relationships; Super-resolution mappings; Mapping","Flood inundation; Image segmentation; Multispectral image; Random walk algorithm; Remote sensing; Super-pixel; Super-resolution mapping","Article","Final","","Scopus","2-s2.0-85103158759"
"Li W.; Yang C.; Peng Y.; Zhang X.","Li, Weisheng (36067507500); Yang, Chao (57263586100); Peng, Yidong (57192995836); Zhang, Xiayan (57219233195)","36067507500; 57263586100; 57192995836; 57219233195","A Multi-Cooperative Deep Convolutional Neural Network for Spatiotemporal Satellite Image Fusion","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","","10174","10188","14","10.1109/JSTARS.2021.3113163","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115163134&doi=10.1109%2fJSTARS.2021.3113163&partnerID=40&md5=fe8b2ef65e762a1ee49abf3181490716","Remote sensing satellite images with high temporal and high spatial resolution play a critical role in earth science applications. However, it is difficult for a single satellite to obtain such images due to technical and cost constraints. Therefore, spatiotemporal image fusion based on deep learning has received extensive attention in recent years. This article proposes a multicooperative deep convolutional neural network (MCDNet) for spatiotemporal satellite image fusion. This method is a new multinetwork model in which multiple networks work together to reconstruct the predicted image. The multinetwork model consists of a super-resolution network, a difference reconstruction network, and a collaborative training network. First, the super-resolution network uses the combination of a novel multiscale mechanism and dilated convolutions to make full use of the spectral information of the coarse image and upgrade it to a transitional image that matches the fine image. The difference reconstruction network uses structural relevance to complete the reconstruction of the fine difference image. The collaborative training network extracts the hidden information from the fine image and uses the time relevance to restrict the training of the difference reconstruction network. Finally, the fine difference image and the known fine image are combined to complete the image fusion. The new compound loss function can help multinetwork models better complete cooperative training. Through experiments on two datasets and comparison with existing fusion algorithms, the subjective and objective results prove that MCDNet can effectively reconstruct higher-quality prediction images. © 2008-2012 IEEE.","Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Image reconstruction; Optical resolving power; Remote sensing; Satellites; Collaborative training; High spatial resolution; Multiscale mechanisms; Reconstruction networks; Remote sensing satellites; Science applications; Spatiotemporal images; Spectral information; algorithm; artificial neural network; data set; remote sensing; satellite imagery; spatiotemporal analysis; training; Image fusion","Convolutional neural network (CNN); dilated convolution; multiscale mechanism; spatiotemporal fusion","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85115163134"
"Guo A.; Dian R.; Li S.","Guo, Anjing (57200751372); Dian, Renwei (57192573953); Li, Shutao (7409240361)","57200751372; 57192573953; 7409240361","Unsupervised Blur Kernel Learning for Pansharpening","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324543","633","636","3","10.1109/IGARSS39084.2020.9324543","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101965002&doi=10.1109%2fIGARSS39084.2020.9324543&partnerID=40&md5=b4ebb6be412d1935e818c8e83a4f872a","Deep learning (DL) for pansharpening has recently attracted considerable attentions. To construct training data, DL based pansharpening approaches often downsample the original multispectral image (MSI) and panchromatic image (PAN) with fixed blur kernel, which can be different from the real point spread functions (PSF) of the satellites. And a mismatched blur kernel will cause the pansharpening performance to drop dramatically. In this paper, we propose a novel blur kernel learning method for pansharpening, which can learn the spatial and spectral blur kernels between PAN and MSI in an unsupervised way. Specifically, we analyze the relationship between PAN and MSI, and then construct a mini net for blur kernel learning. Once the spatial blur kernel is found, a convolutional neural network (CNN) for pansharpening is trained on the downsampled dataset using the learned spatial blur kernel. Experimental results on GF-2 images demonstrate the superiority of the proposed method. © 2020 IEEE.","Convolutional neural networks; Deep learning; Geology; Optical transfer function; Remote sensing; Kernel learning; Kernel learning methods; Multispectral images; Pan-sharpening; Panchromatic (Pan) image; Training data; Learning systems","blur kernel learning; deep learning; hyperspectral image super-resolution; Pansharpening","Conference paper","Final","","Scopus","2-s2.0-85101965002"
"He J.; Li J.; Yuan Q.","He, Jiang (57189887884); Li, Jie (57214207213); Yuan, Qiangqiang (36635300800)","57189887884; 57214207213; 36635300800","Data-Driven and Model-Driven Spectral Superresolution Algorithms: Combination, Analysis and Application for Classification","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324488","2687","2690","3","10.1109/IGARSS39084.2020.9324488","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102008476&doi=10.1109%2fIGARSS39084.2020.9324488&partnerID=40&md5=df05f8d92920dae7689ae0f153663108","In this paper, five spectral superresolution (SSR) algorithms are compared to verify the availability of SSR results as input data in classification. To enhance the spectral resolution, SSR algorithms are proposed to increase the channel number of multispectral images, which can be divided into model-driven and data-driven methods. To combine the advantage of these two types of algorithms, we proposed an optimization-inspired convolutional neural network (OCNN) by unfolding a traditional variational model. The proposed method combines data-driven training with model-driven optimization together to enhance the spectral resolution of high-resolution (HR) multispectral images (MSIs) to obtain HR hyperspectral images (HSIs). Experiments in both SSR and classification are made to show the proposed method is of efficiency and superiority. © 2020 IEEE.","Convolutional neural networks; Geology; Remote sensing; Spectral resolution; Spectroscopy; Channel number; Data-driven methods; High resolution; Model-driven optimization; Multispectral images; Super resolution; Super resolution algorithms; Variational modeling; Image enhancement","Classification; Spectral information; Spectral superresolution","Conference paper","Final","","Scopus","2-s2.0-85102008476"
"","","","15th Conference on Image and Graphics Technology and Applications, IGTA 2020","2021","Communications in Computer and Information Science","1314 CCIS","","","","","324","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107336660&partnerID=40&md5=732561f30fcff4a8e043e84759d04152","The proceedings contain 24 papers. The special focus in this conference is on Image and Graphics Technology and Applications. The topics include: Infrared Small Target Recognition with Improved Particle Filtering Based on Feature Fusion; single Image Super-Resolution Based on Generative Adversarial Networks; Simplifying Sketches with Conditional GAN; Improved Method of Target Tracking Based on SiamRPN; An Improved Target Tracking Method Based on DIMP; target Recognition Framework and Learning Mode Based on Parallel Images; view Consistent 3D Face Reconstruction Using Siamese Encoder-Decoders; an Angle-Based Smoothing Method for Triangular and Tetrahedral Meshes; AUIF: An Adaptive User Interface Framework for Multiple Devices; A Striping Removal Method Based on Spectral Correlation in MODIS Data; deep Attention Network for Remote Sensing Scene Classification; thin Cloud Removal Using Cirrus Spectral Property for Remote Sensing Images; accurate Estimation of Motion Blur Kernel Based on Genetic Algorithms; graph Embedding Discriminant Analysis and Semi-Supervised Extension for Face Recognition; 3D Human Body Reconstruction from a Single Image; abnormal Crowd Behavior Detection Based on Movement Trajectory; image Recognition Method of Defective Button Battery Base on Improved MobileNetV1; preface; control and on-Board Calibration Method for in-Situ Detection Using the Visible and Near-Infrared Imaging Spectrometer on the Yutu-2 Rover; full Convolutional Color Constancy with Attention; fast and Accurate Face Alignment Algorithm Based on Deep Knowledge Distillation; multi-modal 3-D Medical Image Fusion Based on Tensor Robust Principal Component Analysis.","","","Conference review","Final","","Scopus","2-s2.0-85107336660"
"Ma J.; Zhang L.; Zhang J.","Ma, Jie (57205916758); Zhang, Libao (35325855000); Zhang, Jue (56513505100)","57205916758; 35325855000; 56513505100","SD-GAN: Saliency-Discriminated GAN for Remote Sensing Image Superresolution","2020","IEEE Geoscience and Remote Sensing Letters","17","11","8933080","1973","1977","4","10.1109/LGRS.2019.2956969","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095797768&doi=10.1109%2fLGRS.2019.2956969&partnerID=40&md5=815e545e039bd3a0e0768e85794499f2","Recently, convolutional neural networks have shown superior performance in single-image superresolution. Although existing mean-square-error-based methods achieve high peak signal-to-noise ratio (PSNR), they tend to generate oversmooth results. Generative adversarial network (GAN)-based methods can provide high-resolution (HR) images with higher perceptual quality, but produce pseudotextures in images, which generally leads to lower PSNR. Besides, different regions in remote sensing images (RSIs) reflect discrepant surface topography and visual characteristics. This means a uniform reconstruction strategy may not be suitable for all targets in RSIs. To solve these problems, we propose a novel saliency-discriminated GAN for RSI superresolution. First, hierarchical weakly supervised saliency analysis is introduced to compute a saliency map, which is subsequently employed to distinguish the diverse demands of regions in the following generator and discriminator part. Different from previous GANs, the proposed residual dense saliency generator takes saliency maps as a supplementary condition in the generator. Simultaneously, combining the characteristic of RSIs, we design a new paired discriminator to enhance the perceptual quality, which measures the distance between generated images and HR images in salient areas and nonsalient areas, respectively. Comprehensive evaluations validate the superiority of the proposed model.  © 2004-2012 IEEE.","Convolutional neural networks; Image segmentation; Mean square error; Optical resolving power; Remote sensing; Signal to noise ratio; Topography; Adversarial networks; Comprehensive evaluation; High resolution image; Peak signal to noise ratio; Perceptual quality; Remote sensing images; Saliency analysis; Super resolution; image analysis; image resolution; machine learning; remote sensing; satellite altimetry; signal-to-noise ratio; topographic mapping; Image enhancement","Deep learning; generative adversarial network (GAN); remote sensing; saliency analysis; superresolution","Article","Final","","Scopus","2-s2.0-85095797768"
"Vitale S.; Scarpa G.","Vitale, Sergio (57201522451); Scarpa, Giuseppe (7004081145)","57201522451; 7004081145","A Cross-Scale Loss for CNN-Based Pansharpening","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324219","645","648","3","10.1109/IGARSS39084.2020.9324219","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101988913&doi=10.1109%2fIGARSS39084.2020.9324219&partnerID=40&md5=2677dc35c9d8781c89608ab0866c004e","To cope with the lack of input-output training samples, deep learning (DL) methods for pansharpening usually resort to Wald's protocol or other similar downscaling processes. By doing so, the scaled versions of the multispectral (MS) and panchromatic (PAN) components serve as input while the original MS plays as output during the training phase. As a side effect, the informational gap between reduced and full scales causes a mismatch between the training and test phases. In fact, DL methods typically provide a pretty good performance at reduced scale, with a good margin over traditional solutions that tends to vanish in the full-resolution framework. In this work, we propose a training framework that involves both the reduced and the full scale versions of the multiresolution image samples. This is achieved thanks to a suitably defined loss which comprises costs for both scales. Our numerical and visual experimental results confirm that the proposed approach provides an improved performance in the full-resolution case. © 2020 IEEE.","Deep learning; Geology; Downscaling process; Full resolutions; Input-output training; Multi-spectral; Multiresolution images; Pan-sharpening; Training framework; Training phase; Remote sensing","convolutional neural network; data fusion; machine learning; Pansharpening; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85101988913"
"Peng Y.; Li W.; Luo X.; Du J.","Peng, Yidong (57192995836); Li, Weisheng (36067507500); Luo, Xiaobo (36562124600); Du, Jiao (55416429400)","57192995836; 36067507500; 36562124600; 55416429400","Hyperspectral Image Superresolution Using Global Gradient Sparse and Nonlocal Low-Rank Tensor Decomposition with Hyper-Laplacian Prior","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9417623","5453","5469","16","10.1109/JSTARS.2021.3076170","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105109885&doi=10.1109%2fJSTARS.2021.3076170&partnerID=40&md5=daada1c67772e13d2e2a8a97a0af6846","This article presents a novel global gradient sparse and nonlocal low-rank tensor decomposition model with a hyper-Laplacian prior for hyperspectral image (HSI) superresolution to produce a high-resolution HSI (HR-HSI) by fusing a low-resolution HSI (LR-HSI) with an HR multispectral image (HR-MSI). Inspired by the investigated hyper-Laplacian distribution of the gradients of the difference images between the upsampled LR-HSI and latent HR-HSI, we formulate the relationship between these two datasets as a ℓ _{p} (0 < p < 1)-norm term to enforce spectral preservation. Then, the relationship between the HR-MSI and latent HR-HSI is built using a tensor-based fidelity term to recover the spatial details. To effectively capture the high spatio-spectral-nonlocal similarities of the latent HR-HSI, we design a novel nonlocal low-rank Tucker decomposition to model the 3-D regular tensors constructed from the grouped nonlocal similar HR-HSI cubes. The global spatial-spectral total variation regularization is then adopted to ensure the global spatial piecewise smoothness and spectral consistency of the reconstructed HR-HSI from nonlocal low-rank cubes. Finally, an alternating direction method of multipliers-based algorithm is designed to efficiently solve the optimization problem. Experiments on both the synthetic and real datasets collected by different sensors show the effectiveness of the proposed method, from visual and quantitative assessments.  © 2008-2012 IEEE.","Image coding; Laplace transforms; Optical resolving power; Spectroscopy; Tensors; Alternating direction method of multipliers; Image super resolutions; Laplacian distribution; Non-local similarities; Optimization problems; Quantitative assessments; Synthetic and real data; Total variation regularization; algorithm; decomposition analysis; image processing; image resolution; optimization; remote sensing; spatial resolution; spectral resolution; Learning to rank","Global gradient sparse; hyper-Laplacian; hyperspectral image; nonlocal low-rank; superresolution; total variation; tucker decomposition","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85105109885"
"Zhang R.; Cavallaro G.; Jitsev J.","Zhang, Run (57222248284); Cavallaro, Gabriele (55636444100); Jitsev, Jenia (26023272900)","57222248284; 55636444100; 26023272900","Super-Resolution of Large Volumes of Sentinel-2 Images with High Performance Distributed Deep Learning","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323734","617","620","3","10.1109/IGARSS39084.2020.9323734","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101993700&doi=10.1109%2fIGARSS39084.2020.9323734&partnerID=40&md5=45e7113e1f079b4a3c527fd702cd89a4","This work proposes a novel distributed deep learning model for Remote Sensing (RS) images super-resolution. High Performance Computing (HPC) systems with GPUs are used to accelerate the learning of the unknown low to high resolution mapping from large volumes of Sentinel-2 data. The proposed deep learning model is based on self-attention mechanism and residual learning. The results demonstrate that state-of-the-art performance can be achieved by keeping the size of the model relatively small. Synchronous data parallelism is applied to scale up the training process without severe performance loss. Distributed training is thus shown to speed up learning substantially while keeping performance intact. © 2020 IEEE.","Geology; Learning systems; Optical resolving power; Program processors; Remote sensing; Attention mechanisms; Data parallelism; High performance computing systems; Performance loss; Remote sensing images; State-of-the-art performance; Super resolution; Training process; Deep learning","distributed deep learning; high performance computing; Sentinel-2; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85101993700"
"Ayala C.; Aranda C.; Galar M.","Ayala, C. (55642388700); Aranda, C. (57211636468); Galar, M. (35731257600)","55642388700; 57211636468; 35731257600","SUB-PIXEL WIDTH ROAD NETWORK EXTRACTION USING SENTINEL-2 IMAGERY","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","2174","2177","3","10.1109/IGARSS47720.2021.9555128","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129806040&doi=10.1109%2fIGARSS47720.2021.9555128&partnerID=40&md5=271f1d0645c924d15057a31a93a9cf6a","Nowadays, road maps play a key role in our society. Therefore, keeping those maps up-to-date is highly important. The extraction of road networks from satellite imagery is a complex problem, not only because of occlusions, shadows produced by non-road objects, but also due to the limited spatial resolution of the imagery used. The feasibility to detect a road depends on its width, which can reach sub-pixel size in some satellite products. In the last decade, many attempts have been carried out to automatize this labour. However, the vast majority of methods rely on aerial imagery, whose costs are not yet affordable for maintaining up-to-date maps. This work demonstrates that it is also possible to accurately detect roads using freely available Sentinel-2 imagery, regardless of their width. For that purpose, a new deep learning architecture which combines semantic segmentation and super-resolution techniques is proposed. As a result, fine-grained road network maps at 2.5 m are generated from 10 m imagery taken as input. To evaluate this proposal a data-set composed of 20 cities spread across the Spanish territory is used.  © 2021 IEEE.","Aerial photography; Antennas; Convolutional neural networks; Deep neural networks; Extraction; Pixels; Roads and streets; Satellite imagery; Semantic Segmentation; Semantics; Complex problems; Convolutional neural network; Deep learning; Non-road; Remote-sensing; Road network; Road network extraction; Roadmap; Sentinel-2; Sub-pixels; Remote sensing","Convolutional Neural Networks; Deep Learning; Remote Sensing; Road Network Extraction; Sentinel-2","Conference paper","Final","","Scopus","2-s2.0-85129806040"
"Raimundo J.; Medina S.L.-C.; Prieto J.F.; de Mata J.A.","Raimundo, Javier (57221918066); Medina, Serafin Lopez-Cuervo (57221910882); Prieto, Juan F. (7201826710); de Mata, Julian Aguirre (55956277100)","57221918066; 57221910882; 7201826710; 55956277100","Super resolution infrared thermal imaging using pansharpening algorithms: Quantitative assessment and application to uav thermal imaging","2021","Sensors (Switzerland)","21","4","1265","1","18","17","10.3390/s21041265","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100587983&doi=10.3390%2fs21041265&partnerID=40&md5=30314375f2b0a7bfd3e9af6944b73fe4","The lack of high-resolution thermal images is a limiting factor in the fusion with other sensors with a higher resolution. Different families of algorithms have been designed in the field of remote sensors to fuse panchromatic images with multispectral images from satellite platforms, in a process known as pansharpening. Attempts have been made to transfer these pansharpening algorithms to thermal images in the case of satellite sensors. Our work analyses the potential of these algorithms when applied to thermal images from unmanned aerial vehicles (UAVs). We present a comparison, by means of a quantitative procedure, of these pansharpening methods in satellite images when they are applied to fuse high-resolution images with thermal images obtained from UAVs, in order to be able to choose the method that offers the best quantitative results. This analysis, which allows the objective selection of which method to use with this type of images, has not been done until now. This algorithm selection is used here to fuse images from thermal sensors on UAVs with other images from different sensors for the documentation of heritage, but it has applications in many other fields. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Antennas; Infrared imaging; Remote sensing; Satellites; Algorithm selection; High resolution image; Infrared thermal imaging; Multispectral images; Panchromatic images; Quantitative assessments; Quantitative result; Satellite platforms; Image analysis","Infrared; Multispectral; Pansharpening; Remote sensing; Resolution enhancement; Super-resolution; Thermal imaging","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85100587983"
"Patel J.R.; Joshi M.V.; Bhatt J.S.","Patel, Jignesh R. (57207881727); Joshi, Manjunath V. (7202602032); Bhatt, Jignesh S. (55636450600)","57207881727; 7202602032; 55636450600","A Novel Approach for Hyperspectral Image Superresolution Using Spectral Unmixing and Transfer Learning","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324059","1512","1515","3","10.1109/IGARSS39084.2020.9324059","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101960469&doi=10.1109%2fIGARSS39084.2020.9324059&partnerID=40&md5=e28b87195bc15aaf45bf7b36059cf778","Hyperspectral image (HSI) Super-resolution (SR) methods enhance the spatial resolution. In this paper, we propose a novel SR approach for HSIs by making use of spectral unmixing and transfer learning. We first train a deep convolutional neural network (CNN) to learn the mapping between the low-resolution (LR) and high-resolution (HR) natural images and use the same for transfer learning to get the initial estimates of the super-resolved abundances where the input corresponds to LR abundances. To get the better estimates of abundances and hence improve the SR of HSIs, we use a regularization framework in which both the LR and HR abundances are modelled as Inhomogeneous Gaussian Markov field (IGMRF) that serves as the prior. Finally, the SR HSIs are obtained by using a linear mixing model that uses the SR abundances and the endmembers estimated using an appropriate technique. Experiments on synthetic as well as on real HSIs show that the proposed method performs better when compared to other existing approaches. The advantages of the proposed approach are: 1. The method do not require auxiliary image as used in many of the existing methods, 2. Spectral details are better preserved since the SR is carried out in abundance domain, 3. Computational complexity is reduced since the SR is carried out on abundances which are few in number when compared to HSIs. © 2020 IEEE.","Convolutional neural networks; Deep neural networks; Geology; Image enhancement; Optical resolving power; Remote sensing; Spectroscopy; Appropriate techniques; Image super-resolution; Initial estimate; Linear mixing models; Regularization framework; Spatial resolution; Spectral unmixing; Super resolution; Transfer learning","Convolutional neural network (CNN); Deep learning; Hyperspectral image (HSI) super-resolution; Inhomogeneous Gaussian Markov field (IGMRF)","Conference paper","Final","","Scopus","2-s2.0-85101960469"
"Ishimaru A.; Kuga Y.; Bright M.","Ishimaru, Akira (7005122046); Kuga, Yasuo (57205930653); Bright, Max (56640969900)","7005122046; 57205930653; 56640969900","Electromagnetics of complex environments applied to geophysical and biological media","2021","Advances in Mathematical Methods for Electromagnetics","","","","653","672","19","10.1049/SBEW528E_ch26","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113982197&doi=10.1049%2fSBEW528E_ch26&partnerID=40&md5=8a860875d30ab8e8a104174c5eb09b4a","One of the important areas of research is the study of electromagnetic and related wave theories, which have a wide range of practical applications in complex environments, such as microwave remote sensing of the Earth, object detection and imaging in clutter, medical optics and ultrasound imaging, characterization of metamaterials and composite and porous media, and communication through complex clutter environments. This chapter gives a review of wave theories applied to imaging in geophysical and biological media, including imaging through air turbulence and particulate matter, imaging near-ocean rough surfaces and communication and signal processing in clutter, coherence in multiple scattering and super resolution, time-reversal (TR) imaging, radiative transfer, waves in porous media, seismic CODA waves, and the memory effect. © The Institution of Engineering and Technology 2021.","","Biological media; Complex clutter environments; Complex environments; Electromagnetic wave scattering; Electromagnetic wave theories; Geophysical media; Image resolution; Medical optics; Microwave remote sensing; Object detection; Object detection; Porous media; Radiative transfer; Radiative transfer; Related wave theories; Remote sensing; Seismic CODA waves; Seismic waves; Time-reversal imaging; Ultrasound imaging","Book chapter","Final","","Scopus","2-s2.0-85113982197"
"Lei P.; Liu C.","Lei, Pengcheng (57197770597); Liu, Cong (57138870000)","57197770597; 57138870000","Inception residual attention network for remote sensing image super-resolution","2020","International Journal of Remote Sensing","41","24","","9565","9587","22","10.1080/01431161.2020.1800129","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094859452&doi=10.1080%2f01431161.2020.1800129&partnerID=40&md5=7601a21a1e3ed839ba6178746504e5b7","How to enhance the spatial resolution for a remote sensing image is an important issue that we face. Many image super-resolution (SR) techniques have been proposed for this purpose and deep convolutional neural network (CNN) is the most effective approach in recent years. However, we observe that most CNN-based SR methods treat low-frequency areas and high-frequency areas equally, hence hindering the recovery of high-frequency information. In this paper, we propose a network named inception residual attention network (IRAN) to address this problem. Specifically, we propose a spatial attention module to make the network adaptively learn the importance of different spatial areas, so as to pay more attention to the areas with high-frequency information. Furthermore, we present an inception module to fuse local multilevel features, so as to provide richer information for reconstructing detailed textures. In order to evaluate the effectiveness of the proposed method, a large number of experiments are performed on UCMerced-LandUse data set and the results show that the proposed method is superior to the current state-of-the-art methods in both visual effects and objective indicators. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","Deep neural networks; Image enhancement; Optical resolving power; Remote sensing; Textures; Effective approaches; High frequency HF; High-frequency informations; Image super resolutions; Remote sensing images; Spatial attention; Spatial resolution; State-of-the-art methods; artificial neural network; data set; image resolution; reconstruction; remote sensing; satellite imagery; spatial resolution; Convolutional neural networks","","Article","Final","","Scopus","2-s2.0-85094859452"
"Bose R.; Rangnekar V.; Banerjee B.; Chaudhuri S.","Bose, Rupak (57226749299); Rangnekar, Vikrant (57446059300); Banerjee, Biplab (55568183500); Chaudhuri, Subhasis (7402977965)","57226749299; 57446059300; 55568183500; 7402977965","Zero-Shot Remote Sensing Image Super-Resolution Based on Image Continuity and Self Tessellations","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13024 LNCS","","","649","662","13","10.1007/978-3-030-92659-5_42","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124309002&doi=10.1007%2f978-3-030-92659-5_42&partnerID=40&md5=847fdd5652e4979963bf113523c1a77f","The goal of zero-shot image super-resolution (SR) is to generate high-resolution (HR) images from never-before-seen image distributions. This is challenging, especially, because it is difficult to model the statistics of an image that the network has never seen before. Despite deep convolutional neural networks (CNN) being superior to traditional super-resolution (SR) methods, little attention has been given to generating remote sensing scene-based HR images which do not have any prior ground truths available for training. In this paper, we propose a framework that harnesses the inherent tessellated nature of remotely images using continuity to generate HR images that tackle atmospheric and radiometric condition variations. Our proposed solution utilizes self tessellations to fully harness the image heuristics to generate an SR image from a low resolution (LR) input. The salience of our approach lies in a two-fold data generation in a self-preservation case and a cascaded attention sharing mechanism on the latent space for content preservation while generating SR images. By learning a mapping from LR space to SR space while keeping the content statistics preserved helps in better quality image generation. The attention sharing between content and tessellations aids in learning the overall big picture for super-resolution without losing an eye on the main image to be super-resolved. We showcase our results with the generated images given the low resolution (LR) input images in zero-shot cases comparable to state-of-the-art results on EuroSAT and PatternNet datasets with metrics of SSIM and PSNR. We further show how this architecture can be leveraged for non-remote sensing (RS) applications. © 2021, Springer Nature Switzerland AG.","Convolutional neural networks; Deep neural networks; Optical resolving power; Space optics; Attention sharing; High-resolution images; Image distributions; Image super resolutions; Lower resolution; Remote sensing images; Remote-sensing; Resolution images; Superresolution; Superresolution methods; Remote sensing","Attention sharing; Remote sensing; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85124309002"
"Wang P.; Yao H.; Zhang G.; Kong Y.; Lu S.; Peng X.","Wang, Peng (57189493188); Yao, Hongyu (57220160389); Zhang, Gong (35241577600); Kong, Yingying (35186206400); Lu, Shifang (57220165827); Peng, Xiangyang (57214935616)","57189493188; 57220160389; 35241577600; 35186206400; 57220165827; 57214935616","Land cover target mapping at subpixel scale for Landsat 8 OLI image by using multiscale-infrared information","2021","International Journal of Remote Sensing","42","3","","1054","1076","22","10.1080/01431161.2020.1823039","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097071967&doi=10.1080%2f01431161.2020.1823039&partnerID=40&md5=83e96f36f4ec5164fb94eb0a22cc63fc","Land remote-sensing satellite (System, Landsat) 8 operational land imager (OLI) can provide land cover target mapping (LCTM) information. Due to the limitation of hardware and complexity of environment, Landsat 8 OLI image sometimes contains a large number of mixed pixels, which brings a challenge for LCTM. Super-resolution mapping (SM) handles the mixed pixels to obtain LCTM at subpixel scale. However, the scale information is single and the infrared information is not rich in the existing SM methods. In order to solve these issues, this paper proposes SM based on multiscale-infrared information (MII). There are two terms (i.e. multiscale and infrared terms) in MII. The multiscale term with multiscale information is produced through deep Laplacian pyramid network (DLPN), multiresolution segmentation, and extended random walker in turn. The infrared term with infrared information is derived by calculating the normalized difference target index (NDTI). The two terms are combined to generate a minimization term with multiscale-infrared information. Particle swarm optimization algorithm is applied to the minimization term to obtain the LCTM result. The experimental results on four Landsat 8 OLI images show that the MII provides better LCTM results than the traditional SM methods. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","Particle swarm optimization (PSO); Pixels; Remote sensing; Laplacian Pyramid; Multi-scale informations; Multiresolution segmentation; Normalized differences; Operational land imager; Particle swarm optimization algorithm; Remote sensing satellites; Super-resolution mappings; land cover; Landsat; mapping; pixel; remote sensing; Mapping","","Article","Final","","Scopus","2-s2.0-85097071967"
"Djerida A.; Djerriri K.; Karoui M.S.; El Amin larabi M.","Djerida, Achraf (57209278554); Djerriri, Khelifa (56548913000); Karoui, Moussa Sofiane (15750871100); El Amin larabi, Mohammed (57222052927)","57209278554; 56548913000; 15750871100; 57222052927","A NEW PUBLIC ALSAT-2B DATASET FOR SINGLE-IMAGE SUPER-RESOLUTION","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","8095","8098","3","10.1109/IGARSS47720.2021.9554452","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130059915&doi=10.1109%2fIGARSS47720.2021.9554452&partnerID=40&md5=6015441a4a03777e7e64191f2f6fd861","Recently, deep learning methods dominate the proposed solutions for image super-resolution due to their powerful properties. However, for remote sensing benchmarks, it is very expensive to obtain high spatial resolution images. Most of the super-resolution methods use down-sampling techniques to simulate low and high spatial resolution pairs and construct the training samples. As an alternative, the paper introduces a novel public remote sensing dataset (Alsat-2B) of low and high spatial resolution images (10m and 2.5m respectively) where the high-resolution images are obtained through pansharpening. Besides, the performance of some state-of-the-art methods is assessed based on common criteria. The obtained results reveal that the proposed scheme is promising and highlight the challenges in the dataset which show the need for advanced methods to grasp the relationship between the low and high-resolution patches. © 2021 IEEE","Deep learning; Image resolution; Alsat-2b; Dataset creation; Deep learning; High spatial resolution images; Image super resolutions; Learning methods; Property; Remote-sensing; Single images; Single-image super-resolution; Remote sensing","Alsat-2B; Dataset creation; Deep learning; Single-image super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85130059915"
"","","","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","3","","","","2619","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090340500&partnerID=40&md5=0028849c5a722e5d84e936acd25e198e","The proceedings contain 342 papers. The topics discussed include: learning super-resolution for sentinel-2 images with real ground truth data from a reference satellite; combined patch-wise minimal-maximal pixels regularization for deblurring; urban material classification using spectral and textural features retrieved from autoencoders; a worldwide 3D GCP database inherited from 20 years of massive multi-satellite observations; deep learning based feature matching and its application in image orientation; a novel RPC bias model for improving the positioning accuracy of satellite images; land salinization dynamics based on feature space combinations from landsat image in Tongyu County, Northeast China; a new index for identifying water body from sentinel-2 satellite remote sensing imagery; land cover classification using convolutional neural network with remote sensing data and digital surface model; assessing resilience of infrastructures towards exogenous events by using PS-INSAR-based surface motion estimates and machine learning regression techniques; region-based fuzzy clustering image segmentation algorithm with Kullback-Leibler distance; experiences from the project course in geoinformatics; and refugees stories told by maps: a challenge for students in a scientific Olympiad.","","","Conference review","Final","","Scopus","2-s2.0-85090340500"
"Deepak S.; Khorgade V.; Patra D.","Deepak, Shashikant (57216807543); Khorgade, Vrushali (57219488910); Patra, Dipti (23985620900)","57216807543; 57219488910; 23985620900","Single Image Super Resolution using a Hybrid Feature Dictionary for Remotely Sensed Images","2020","Proceedings of CONECCT 2020 - 6th IEEE International Conference on Electronics, Computing and Communication Technologies","","","9198523","","","","10.1109/CONECCT50063.2020.9198523","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093115346&doi=10.1109%2fCONECCT50063.2020.9198523&partnerID=40&md5=225fc2392264a0031df5de3f28b27131","In this paper, a sparse representation based single image super-resolution reconstruction (SRR) method using a self-learned hybrid feature dictionary is proposed. Efficient feature extraction plays a very important role in image SRR and most of the models use gradient-based feature extraction. These models, being an intensity-based, can be easily influenced by the intensity gradient to ignore essential edge profile and also fails to address the edge profiles like delta, roof and ramp edge which are very crucial for efficient reconstruction. Inspired by this, a hybrid feature based over-complete dictionary is formed by extracting various features of the LR input image. Features are extracted using the Fast Fourier Transform (FFT) procedure along with the first-and-second-order gradients. This dictionary is jointly trained with the HR image patch features using Orthogonal Matching Pursuit (OMP) and K-singular value decomposition (K-SVD) algorithm. By considering the similarity between the LR and HR image patch pairs, the output HR image is reconstructed using the sparse recovery model. Experimental analysis and results for remotely sensed data demonstrate that the proposed method reduces the computational complexity as well as outperforms other state-of-the-art methods in terms of qualitative and quantitative parameters. The average signal to noise ratio (PSNR) has improved significantly by +0.6 dB along with a notable boost in computational time and perceptual quality.  © 2020 IEEE.","Extraction; Fast Fourier transforms; Feature extraction; Optical resolving power; Remote sensing; Signal to noise ratio; Singular value decomposition; Efficient reconstruction; Gradient based feature; Orthogonal matching pursuit; Over-complete dictionaries; Quantitative parameters; Remotely sensed images; Single-image super-resolution reconstruction; State-of-the-art methods; Image reconstruction","dictionary training; feature extraction; remote sensing; sparse representation; Super-resolution reconstruction (SRR)","Conference paper","Final","","Scopus","2-s2.0-85093115346"
"Wang B.; Zou Y.; Zuo C.; Sun J.; Hu Y.","Wang, Bowen (57204607674); Zou, Yan (56278157500); Zuo, Chao (36007852700); Sun, Jiasong (56048572500); Hu, Yan (56681484200)","57204607674; 56278157500; 36007852700; 56048572500; 56681484200","Pixel super resolution imaging method based on coded aperture modulation","2021","Proceedings of SPIE - The International Society for Optical Engineering","11761","","1176111","","","","10.1117/12.2586429","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100192829&doi=10.1117%2f12.2586429&partnerID=40&md5=ddf8131f7c9b630fa5325bd6b5647fc1","In recent years, the development of computational imaging technology provides a new method for the realization of non-scanning super-resolution imaging. In this paper, a pixel super-resolution algorithm based on Fourier ptychographic technology is proposed, and the corresponding integrated and systematic programmable aperture coded super-resolution imaging system is constructed. By modulating the intensity with the coded aperture mask, utilizing different system point spread functions to obtain multiple samples of the original scene, and finally adopting sparse optimization iterative algorithm to reconstruct the original image, the result of super-resolution imaging is more than 3.5 times of Nyquist sampling frequency. In this tutorial, the proposed new super-resolution photoelectric imaging technology innovatively adopts the approach of coded aperture to realize image super-resolution imaging and effectively solve image pixelation. High-resolution images beyond the spatial resolution of the detector are obtained without any physical moving device or scanning mechanism. Compared with the traditional micro-scanning technology, it not only improves the reliability and stability of the system but also greatly reduces the cost and volume weight of the system.  © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Iterative methods; Optical resolving power; Optical transfer function; Photonics; Pixels; Scanning; System stability; Coded aperture masks; Computational imaging; High resolution image; Image super resolutions; Pixel super resolutions; Reliability and stability; Sparse optimizations; Super resolution imaging; Image resolution","Coded aperture; Multi-Image Reconstruction.; Remote Sensing; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85100192829"
"Wang H.; Nie Y.; Yan B.","Wang, Haijun (57188702678); Nie, Yalin (47962135300); Yan, Ben (36764112900)","57188702678; 47962135300; 36764112900","Single-Image Super-Resolution based on Steering Kernel and Gaussian Process Regression","2021","International Journal of Pattern Recognition and Artificial Intelligence","35","3","2154006","","","","10.1142/S0218001421540069","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096580989&doi=10.1142%2fS0218001421540069&partnerID=40&md5=8db4efad87eafdc18b3ecdbfaa4aa6d7","Single-image super-resolution (SR) imaging is a fundamental problem in image processing; it is important in entertainment, video surveillance, remote sensing, medicine, and other fields. Gaussian process regression (GPR) is a kernel method whereby nonlinear mapping relationships in data can be learned. However, the traditional Gaussian kernel function used in GPR is isotropic and fails to capture complex image structures. Accordingly, the structure information of image patches, termed steering kernel coefficients (SKCs), is extracted by a steering kernel function. After patches with similar structure are clustered according to their SKCs, an anisotropic automatic-relevance-determination (ARD) kernel function is used to learn the model for each cluster. Aiming at learning a structure-sensitive GPR model, we integrate the SKCs and ARD to achieve improved performance for GPR-based SR. Experiments demonstrate that the proposed method can effectively capture the structural relevance of image patches and yield promising results. © 2021 World Scientific Publishing Company.","Gaussian distribution; Gaussian noise (electronic); Optical resolving power; Remote sensing; Security systems; Automatic relevance determination; Gaussian kernel functions; Gaussian process regression; Nonlinear mapping relationship; Steering kernels; Structure information; Structure-sensitive; Video surveillance; Image processing","automatic relevance determination; clustering; Gaussian process regression; Steering kernel; super-resolution","Article","Final","","Scopus","2-s2.0-85096580989"
"Wang H.; Hu Q.; Chi J.; Wu C.; Yu X.","Wang, Huan (57208732586); Hu, Qian (57204765704); Chi, Jianning (40761307100); Wu, Chengdong (57208469667); Yu, Xiaosheng (36802973400)","57208732586; 57204765704; 40761307100; 57208469667; 36802973400","Multi-Receptive-Fields Convolutional Network for Remote Sensing Images Super-Resolution","2021","Proceedings of the 33rd Chinese Control and Decision Conference, CCDC 2021","","","","1525","1530","5","10.1109/CCDC52312.2021.9601623","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125181075&doi=10.1109%2fCCDC52312.2021.9601623&partnerID=40&md5=7d1a254cdc1b1d706cc857aae88b4e31","Recently, single image super-resolution (SISR) has been widely applied in the field of remote sensing image processing and obtained remarkable performance, focusing on restoring the high-resolution (HR) image from a low-resolution (LR) image. However, we observe that the existing CNN-based SISR methods mainly focus on wider or deeper architecture design, neglecting to exploit features at global receptive field. Moreover, the LR inputs and features contain abundant low-frequency information, which are perceived equally in the same receptive field, hence limiting the representational ability of CNNs. To solve these problems, we propose a Multi-Receptive-Fields Super Resolution Network (MRFSR) for remote sensing image reconstruction. The proposed network employs non-local neural network to enhance low-level complex features by expanding the receptive field of the shallow convolution layer. Moreover, we propose the multi-branch up- and down-sampling modules to deal with LR features in multiple receptive fields, which can enhance the high-frequency components and learn abstract feature representations in multiple scales, respectively. Extensive experiments on NPU-RESISC45 dataset shows that the proposed MRFSR can provide state-of-the-art or even better performance in both quantitative and qualitative measurements.  © 2021 IEEE.","Convolution; Convolutional neural networks; Deep neural networks; Image reconstruction; Multilayer neural networks; Remote sensing; Convolutional networks; Convolutional neural network; Deep learning; Image super resolutions; Lower resolution; Performance; Receptive fields; Remote sensing images; Single images; Superresolution; Optical resolving power","Convolutional Neural Network; Deep Learning; Remote Sensing Image; Super Resolution","Conference paper","Final","","Scopus","2-s2.0-85125181075"
"Barman T.; Deka B.; Prasad A.V.V.","Barman, Trishna (56100662400); Deka, Bhabesh (49663267700); Prasad, A.V.V. (56447855300)","56100662400; 49663267700; 56447855300","GPU-Accelerated Adaptive Dictionary Learning and Sparse Representations for Multispectral Image Super-resolution","2021","Proceedings of the 2021 IEEE 18th India Council International Conference, INDICON 2021","","","","","","","10.1109/INDICON52576.2021.9691521","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126392413&doi=10.1109%2fINDICON52576.2021.9691521&partnerID=40&md5=c21f6cbd0ea05af64eb9803996100af9","Recently, single image super-resolution (SISR) based on sparse representations has been gaining much attention from the research community in the field of remote sensing. In this paper, a fast SISR reconstruction framework is developed for multispectral remote sensing (MSRS) images based on adaptive dictionary learning and sparse representations. It consists of two major parts: first, a novel super-resolution approach is developed for MSRS using sparse coding and adaptive dictionary learning. High-frequency features present in the input low-resolution MS image are extracted by using Butterworth low-pass, difference of Gaussian (DoG), and Sobel filters in horizontal and vertical directions. The proposed feature extraction method reveals the edges and other detailed information present in the MS image effectively. Secondly, massively parallel algorithms are designed for adaptive dictionary learning and sparse reconstruction using the Compute Unified Device Architecture (CUDA)-enabled General Purpose-Graphics Processing Unit (GP-GPU) programming model. The proposed method GP-GPU implementation not only gives better results in terms of visual quality and objective fidelity criteria, but also significantly reduces the computation time compared to its CPU counterparts to achieve near-real time operating speed. © 2021 IEEE.","Butterworth filters; Computer graphics; Computer graphics equipment; Graphics processing unit; Image processing; Program processors; Remote sensing; Adaptive dictionary learning; Compute unified device architecture-enabled general purpose-graphic processing unit; Device architectures; GPU-accelerated; Graphics processing; Image super resolutions; Multispectral remote sensing; Processing units; Sparse representation; Superresolution; Optical resolving power","Adaptive dictionary learning; CUDA-enabled GP-GPU; Multispectral remote sensing; Sparse representations; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85126392413"
"","","","24th ISPRS Congress, Commission II","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","2","","","","2619","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091064519&partnerID=40&md5=0aface4b795996185a7927b98bfbf0ac","The proceedings contain 342 papers. The topics discussed include: learning super-resolution for sentinel-2 images with real ground truth data from a reference satellite; combined patch-wise minimal-maximal pixels regularization for deblurring; urban material classification using spectral and textural features retrieved from autoencoders; a worldwide 3D GCP database inherited from 20 years of massive multi-satellite observations; deep learning based feature matching and its application in image orientation; a novel RPC bias model for improving the positioning accuracy of satellite images; land salinization dynamics based on feature space combinations from landsat image in Tongyu County, Northeast China; a new index for identifying water body from sentinel-2 satellite remote sensing imagery; land cover classification using convolutional neural network with remote sensing data and digital surface model; assessing resilience of infrastructures towards exogenous events by using PS-INSAR-based surface motion estimates and machine learning regression techniques; region-based fuzzy clustering image segmentation algorithm with Kullback-Leibler distance; experiences from the project course in geoinformatics; and refugees stories told by maps: a challenge for students in a scientific Olympiad.","","","Conference review","Final","","Scopus","2-s2.0-85091064519"
"Li X.; Zhang Y.; Ge Z.; Cao G.; Shi H.; Fu P.","Li, Xuesong (57190391688); Zhang, Youqiang (57170955200); Ge, Zixian (57203007651); Cao, Guo (15050284500); Shi, Hao (57222899544); Fu, Peng (57204480006)","57190391688; 57170955200; 57203007651; 15050284500; 57222899544; 57204480006","Adaptive Nonnegative Sparse Representation for Hyperspectral Image Super-Resolution","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9399788","4267","4283","16","10.1109/JSTARS.2021.3072044","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104193548&doi=10.1109%2fJSTARS.2021.3072044&partnerID=40&md5=66b833c21c15ca12986dba78357f82c2","As the hyperspectral images (HSIs) usually have a low spatial resolution, HSI super-resolution has recently attracted more and more attention to enhance the spatial resolution of HSIs. A common method is to fuse the low-resolution (LR) HSI with a multispectral image (MSI) whose spatial resolution is higher than the HSI. In this article, we proposed a novel adaptive nonnegative sparse representation-based model to fuse an HSI and its corresponding MSI. First, basing the linear spectral unmixing, the nonnegative structured sparse representation model estimates the sparse codes of the desired high-resolution HSI from both the LR-HSI and the MSI. Then, the adaptive sparse representation can balance the relationship between the sparsity and collaboration by generating a suitable coefficient. Finally, in order to obtain more accurate results, we alternately optimize the spectral basis and coefficients rather than keeping the spectral basis fixed. The alternating direction method of multipliers is applied to solve the proposed optimization problem. The experimental results on both ground-based HSIs and real remote sensing HSIs show the superiority of our proposed approach to some other state-of-the-art HSI super-resolution methods.  © 2008-2012 IEEE.","Hydraulic structures; Image resolution; Optical resolving power; Remote sensing; Spectroscopy; Alternating direction method of multipliers; Image super resolutions; Linear spectral unmixing; Multispectral images; Optimization problems; Sparse representation; Structured sparse representations; Superresolution methods; experimental study; image resolution; multispectral image; optimization; remote sensing; spatial resolution; spectral analysis; Image enhancement","Adaptive sparse representation (ASR); hyperspectral image (HSI); spectral basis updating; super-resolution reconstruction","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85104193548"
"Liu M.; Shi Q.; Liu P.; Wan C.","Liu, Mengxi (57208160778); Shi, Qian (55286447700); Liu, Penghua (57191632651); Wan, Cheng (57222241570)","57208160778; 55286447700; 57191632651; 57222241570","Siamese Generative Adversarial Network for Change Detection under Different Scales","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323499","2543","2546","3","10.1109/IGARSS39084.2020.9323499","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101998421&doi=10.1109%2fIGARSS39084.2020.9323499&partnerID=40&md5=422672dc13ab48da34f0895a22057648","Change detection methods based on low-resolution (LR) images with higher temporal resolution often lead to fuzzy results, while high-resolution images (HRIs) can provide more detailed information to solve this problem. However, it's hard to obtain two tiles of HRIs with high-quality for rapid change detection in actual production due to low temporal resolution and high cost. Therefore, it is necessary to explore a change detection method combing low- and high-resolution images to acquire urban change areas more accurately and quickly. In this paper, an end-to-end siamese generative adversarial network (SiamGAN) integrating a super resolution network and the siamese structure was proposed for change detection under different scales. The super-resolution network is used to reconstruct low-resolution images into high-resolution images, while the siamese structure is adopted as the classification network to detect changes. In the experiments, SiamGAN achieved an F1 of 76.06% and an IoU of 61.52% in the test set, which is respectively 5.68% and 6.92% higher than the CNN-based methods using LR images after bicubic interpolation. The results show that our proposed method can effectively overcome difference in scale between low- and high-resolution images and perform change detection more precisely and rapidly. © 2020 IEEE.","Geology; Optical resolving power; Remote sensing; Adversarial networks; Bicubic interpolation; Change detection; Classification networks; High resolution image; Low resolution images; Super resolution; Temporal resolution; Chemical detection","Change detection; high resolution images; siamese network; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85101998421"
"Fu Y.; Liang Z.; You S.","Fu, Ying (56118557700); Liang, Zhiyuan (57224651248); You, Shaodi (36027010700)","56118557700; 57224651248; 36027010700","Bidirectional 3D Quasi-Recurrent Neural Network for Hyperspectral Image Super-Resolution","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9351612","2674","2688","14","10.1109/JSTARS.2021.3057936","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100842588&doi=10.1109%2fJSTARS.2021.3057936&partnerID=40&md5=7c1e80d361d9d4e25e0cc1aa7673e1ba","Hyperspectral imaging is unable to acquire images with high resolution in both spatial and spectral dimensions yet, due to physical hardware limitations. It can only produce low spatial resolution images in most cases and thus hyperspectral image (HSI) spatial super-resolution is important. Recently, deep learning-based methods for HSI spatial super-resolution have been actively exploited. However, existing methods do not focus on structural spatial-spectral correlation and global correlation along spectra, which cannot fully exploit useful information for super-resolution. Also, some of the methods are straightforward extension of RGB super-resolution methods, which have fixed number of spectral channels and cannot be generally applied to hyperspectral images whose number of channels varies. Furthermore, unlike RGB images, existing HSI datasets are small and limit the performance of learning-based methods. In this article, we design a bidirectional 3D quasi-recurrent neural network for HSI super-resolution with arbitrary number of bands. Specifically, we introduce a core unit that contains a 3D convolutional module and a bidirectional quasi-recurrent pooling module to effectively extract structural spatial-spectral correlation and global correlation along spectra, respectively. By combining domain knowledge of HSI with a novel pretraining strategy, our method can be well generalized to remote sensing HSI datasets with limited number of training data. Extensive evaluations and comparisons on HSI super-resolution demonstrate improvements over state-of-the-art methods, in terms of both restoration accuracy and visual quality. © 2008-2012 IEEE.","Hyperspectral imaging; Learning systems; Optical resolving power; Remote sensing; Spectroscopy; Global correlation; Image super resolutions; Learning-based methods; Spatial resolution images; Spectral correlation; Spectral dimensions; State-of-the-art methods; Superresolution methods; artificial neural network; correlation; image processing; image resolution; spatial resolution; spectral resolution; Recurrent neural networks","Bidirectional 3D quasi-recurrent neural network; global correlation along spectra; hyperspectral image super-resolution; structural spatial-spectral correlation","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85100842588"
"Hayashi T.; Kidera S.","Hayashi, Takumi (57207728494); Kidera, Shouhei (14031687600)","57207728494; 14031687600","BI-Directional Processing Algorithm with RPM and WKD Based Doppler Velocity Estimator for 3-D Doppler-Radar Imaging","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323981","2336","2339","3","10.1109/IGARSS39084.2020.9323981","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101977845&doi=10.1109%2fIGARSS39084.2020.9323981&partnerID=40&md5=f46e0a40d19962bbb48390177f1dd3d4","Super-resolution and highly accurate Doppler and imaging algorithm for microwave or millimeter wave (MMW) short range radar is presented here. As human body detection or recognition in self-driving, through-the-wall imaging, or security system, the micro-Doppler analysis is one of the promising approaches. In the previous study, we have proposed an innovative Doppler velocity estimation, named as weighted kernel density (WKD) estimator, which simultaneously achieves higher temporal and Doppler velocity resolutions. This paper focuses on bi-directional processing between the WKD based Doppler velocity estimator and the range points migration (RPM) based radar imaging, so that both estimation accuracies could be enhanced. 3-D Numerical simulation demonstrate the effectiveness of our method. © 2020 IEEE.","Doppler radar; Geology; Image processing; Millimeter waves; Numerical methods; Remote sensing; Velocity; 3-D numerical simulation; Doppler velocity estimations; Human body detections; Imaging algorithm; Millimeter wave (MMW); Processing algorithms; Short range radar; Through the wall imaging; Radar imaging","Millimeter wave (MMW) radar; Pulse Doppler-radar; Three-dimensional (3-D) imaging","Conference paper","Final","","Scopus","2-s2.0-85101977845"
"Qin J.; Yanovsky I.","Qin, Jing (53980312700); Yanovsky, Igor (16403652300)","53980312700; 16403652300","An effective super-resolution reconstruction method for geometrically deformed image sequences","2020","16th Specialist Meeting on Microwave Radiometry and Remote Sensing of the Environment, MicroRad 2020 - Proceedings","","","9342611","","","","10.1109/MicroRad49612.2020.9342611","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101310023&doi=10.1109%2fMicroRad49612.2020.9342611&partnerID=40&md5=3bb6349a1767a362c3137aa9cb2c5fe4","Despite of the technology advancements, remote sensing images usually suffer from a poor spatial resolution. To resolve this issue, a lot of research efforts have been devoted to developing resolution enhancement methods which retrieve a high-resolution image out of its low-resolution degraded versions. In this paper, we consider a nonlocal total variation (NLTV) based super-resolution method which handles low-resolution images with geometric deformations. In particular, we apply the framework of alternating direction method of multipliers (ADMM) to deduce an effective algorithm, which involves soft thresholding and gradient descent. Effectiveness and robustness to noise of the proposed method are verified by various numerical experiments.  © 2020 IEEE.","Gradient methods; Image enhancement; Image reconstruction; Microwaves; Numerical methods; Optical resolving power; Radiometry; Alternating direction method of multipliers; Geometric deformations; Nonlocal total variation (NLTV); Remote sensing images; Resolution enhancement; Super resolution reconstruction; Superresolution methods; Technology advancement; Remote sensing","Alternating direction method of multipliers (ADMM); Nonlocal total variation; Remote sensing images; Super-resolution image reconstruction","Conference paper","Final","","Scopus","2-s2.0-85101310023"
"Qin Q.; Dou J.; Tu Z.","Qin, Q. (36027088900); Dou, J. (46960910900); Tu, Z. (56623964400)","36027088900; 46960910900; 56623964400","Deep ResNet Based Remote Sensing Image Super-Resolution Reconstruction in Discrete Wavelet Domain","2020","Pattern Recognition and Image Analysis","30","3","","541","550","9","10.1134/S1054661820030232","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091109890&doi=10.1134%2fS1054661820030232&partnerID=40&md5=f98c1d70a48d22c1776a8beed7bdad32","Abstract: We present a single-image super-resolution (SR) method for Remote Sensing Image based on deep learning within Discrete Wavelet Domain in this paper. Our method is inspired Residual Learning. Firstly, an input image is decomposed by single level 2D Discrete wavelet transform to get four sub-bands. The four sub-bands coefficients are feeding into the Deep Learning Residual Network to predict correspondingly residual images; Adding four sub-band images and residual images as the new sub-bands of 2D wavelet transform; Finally, uses the inverse 2D Discrete wavelet transform to get the final output Super Resolution HR image. Our proposed method performs better than existing methods in accuracy and visual improvements in our results are easily noticeable. © 2020, Pleiades Publishing, Ltd.","Deep learning; Discrete wavelet transforms; Image compression; Inverse problems; Learning systems; Optical resolving power; Remote sensing; 2-d discrete wavelet transforms; 2-D wavelet transform; Discrete wavelets; Remote sensing images; Residual images; Single images; Super resolution; Visual improvements; Image reconstruction","Convolutional Neural Network; Deep Learning; Discrete Wavelet Transform; Residual Learning; Super Resolution","Article","Final","","Scopus","2-s2.0-85091109890"
"Deeba F.; Dharejo F.A.; Zhou Y.; Ghaffar A.; Memon M.H.; Kun S.","Deeba, Farah (57215997317); Dharejo, Fayaz Ali (57195487028); Zhou, Yuanchun (55737417400); Ghaffar, Abdul (57221918548); Memon, Mujahid Hussain (57223009892); Kun, She (6603966856)","57215997317; 57195487028; 55737417400; 57221918548; 57223009892; 6603966856","Single Image Super-Resolution with Application to Remote-Sensing Image","2020","2020 Global Conference on Wireless and Optical Technologies, GCWOT 2020","","","9391625","","","","10.1109/GCWOT49901.2020.9391625","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104408111&doi=10.1109%2fGCWOT49901.2020.9391625&partnerID=40&md5=139ccc577670011a040ebc53ba751bb9","To improve the resolution of satellite images, many researchers are committed to machine learning and neural network-based SR methods. SR has multiple residual network frameworks in deep learning that have improved performance and can extend thousands of layers in the system. However, each layer improves accuracy by doubling the number of layers, although training thousands of layers are too expensive, the process is slow, and there are functional recovery issues. To address these issues, we propose a super-resolution wide remote sensing residual network (WRSR), in which we increase the width and reduce the depth of the residual network, due to decreasing the depth of the network our model reduced memory costs. To enhance the resolution of the single image we showed that our method improves training loss performance by performing the weight normalization instead of augmentation technology. The results of the experiment show that the method performs well in terms of quantitative indicators (PSNR) and (SSIM). © 2020 IEEE.","Deep learning; Learning systems; Optical resolving power; Remote sensing; Functional recovery; Loss performance; Network frameworks; Number of layers; Quantitative indicators; Remote sensing images; Satellite images; Super resolution; Image enhancement","Low-resolution LR; remote-sensing images; super-resolution (SR); wide residual block","Conference paper","Final","","Scopus","2-s2.0-85104408111"
"Molini A.B.; Valsesia D.; Fracastoro G.; Magli E.","Molini, Andrea Bordone (57213164630); Valsesia, Diego (55968886600); Fracastoro, Giulia (56344146600); Magli, Enrico (7003771643)","57213164630; 55968886600; 56344146600; 7003771643","Deepsum++: Non-Local Deep Neural Network for Super-Resolution of Unregistered Multitemporal Images","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324418","609","612","3","10.1109/IGARSS39084.2020.9324418","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101990378&doi=10.1109%2fIGARSS39084.2020.9324418&partnerID=40&md5=a631bb5a9a8e43ecb871e041102bf303","Deep learning methods for super-resolution of a remote sensing scene from multiple unregistered low-resolution images have recently gained attention thanks to a challenge proposed by the European Space Agency. This paper presents an evolution of the winner of the challenge, showing how incorporating non-local information in a convolutional neural network allows to exploit self-similar patterns that provide enhanced regularization of the super-resolution problem. Experiments on the dataset of the challenge show improved performance over the state-of-the-art, which does not exploit non-local information. © 2020 IEEE.","Convolutional neural networks; Deep learning; Deep neural networks; Geology; Learning systems; Optical resolving power; Space optics; European Space Agency; Learning methods; Low resolution images; Multi-temporal image; Nonlocal; Self-similar patterns; State of the art; Super resolution; Remote sensing","CNN; Non-local; Super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85101990378"
"Yanovsky I.; Qin J.","Yanovsky, Igor (16403652300); Qin, Jing (53980312700)","16403652300; 53980312700","SPATIO-TEMPORAL SUPER-RESOLUTION RECONSTRUCTION OF REMOTE SENSING DATA","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","2907","2910","3","10.1109/IGARSS47720.2021.9553433","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126013137&doi=10.1109%2fIGARSS47720.2021.9553433&partnerID=40&md5=44fc898b31e057c7b6bda3f3038f13cc","We present a spatio-temporal super-resolution method for reconstructing a sequence of observations collected by imaging satellites. A sequence of observations is assumed to be defined on a low resolution spatio-temporal grid. It is further assumed that the sequence is generated by blurring of a captured scene with a spatio-temporal convolution kernel and is degraded by noise. Our method simultaneously exhibits deconvolution of the sequence of images from the effects of spatio-temporal blur, denoising of the data, and upsampling of the low-resolution sequence to a high resolution spatio-temporal grid. We perform the super-resolution in the space-time domain, as opposed to super-resolving the sequence separately and sequentially to a higher spatial and then temporal resolution grid. Simultaneous space-time optimization achieves a more efficient and more accurate reconstruction than reconstructing a sequence frame by frame. The proposed super-resolution methodology is based on total variation regularization and computes the solution using the alternating direction method of multipliers. Numerical results show our approach to be robust and computationally efficient. © 2021 IEEE.","","Alternating direction method of multipliers; Satellite images; Super-resolution; Upsampling","Conference paper","Final","","Scopus","2-s2.0-85126013137"
"Tao H.","Tao, Hongyuan (57222248450)","57222248450","Super-Resolution of Remote Sensing Images based on a Deep Plug-and-Play Framework","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324647","625","628","3","10.1109/IGARSS39084.2020.9324647","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102010850&doi=10.1109%2fIGARSS39084.2020.9324647&partnerID=40&md5=0b162fe906d1ddfb9b3c784390491ed6","Single image super-resolution (SISR) based on deep neural network (DNN) has been widely studied in recent years as a crucial technique for remote sensing (RS) applications. However, owing to the complexity and diversity of ground objects, there remains fundamental challenges to reconstruct a high-resolution (HS) RS image from a low-resolution (LR) RS image, especially with blur. In this paper, I propose a deep plug-and-play residual network, namely DPSRResNet, which can reconstruct high-quality HR RS images from LR SR images with Gaussian blur kernels via a deep plug-and-play framework. Specifically, a degradation model from the DPSR framework is given to utilize matured deblurring methods. Moreover, I adopt a deep plug-and-play algorithm to optimize the energy function, which allows plugging any super-resolver with a prior term. The proposed DPSRResNet is used as the crucial super-resolver for the framework, and a series of experimental results are presented to demonstrate the effectiveness of the proposed method on RS images. © 2020 IEEE.","Deep neural networks; Geology; Image reconstruction; Image resolution; Optical resolving power; Degradation model; Energy functions; Gaussian blur; Ground objects; High resolution; Low resolution; Remote sensing images; Super resolution; Remote sensing","plug-and-play; remote sensing image; residual network; Single image super-resolution","Conference paper","Final","","Scopus","2-s2.0-85102010850"
"Keshk H.M.; Yin X.-C.","Keshk, Hatem Magdy (56410910400); Yin, Xu-Cheng (35319162100)","56410910400; 35319162100","Obtaining Super-Resolution Satellites Images Based on Enhancement Deep Convolutional Neural Network","2021","International Journal of Aeronautical and Space Sciences","22","1","","195","202","7","10.1007/s42405-020-00297-0","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086744082&doi=10.1007%2fs42405-020-00297-0&partnerID=40&md5=8cc034e2eae69885ee5e45633ac3e1e6","Super-resolution reconstruction refers to the technique of reconstructing a high-resolution image from a single or a series of low-resolution images by digital image processing. This technology can not only increase the high-frequency information of the image, but also eliminate the low-resolution. Deep Learning has made breakthroughs in modern digital image processing. Compared to traditional algorithms, deep convolutional neural networks (DCNN) achieve superior performance on a series of challenging image-processing problems such as image classification and target detection. Enhancement Deep convolutional neural networks (EDCNN) learn through a large number of training samples, obtain relevant information within the image, and then use the information to achieve specific functions. EDCNN also has an excellent performance with remote sensing data. Performance evaluation was made with bicubic and other deep learning methods, EDCNN outperformed other deep learning algorithms. © 2020, The Korean Society for Aeronautical & Space Sciences.","Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Learning algorithms; Learning systems; Optical resolving power; Remote sensing; High resolution image; High-frequency informations; Image processing problems; Learning methods; Low resolution images; Remote sensing data; Super resolution; Super resolution reconstruction; Image enhancement","Convolutional neural network; Deep convolutional neural network; Deep learning; Remote sensing; Super-resolution","Article","Final","","Scopus","2-s2.0-85086744082"
"Chen J.; Feng R.; Wang L.; Han W.; Huang J.","Chen, Jia (57216636841); Feng, Ruyi (55853730300); Wang, Lizhe (23029267900); Han, Wei (57191570975); Huang, Jing (57222241051)","57216636841; 55853730300; 23029267900; 57191570975; 57222241051","Multi-Level Strategy-Based Spatial Information Prediction for Spatiotemporal Remote Sensing Imagery Fusion","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323312","637","640","3","10.1109/IGARSS39084.2020.9323312","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101954858&doi=10.1109%2fIGARSS39084.2020.9323312&partnerID=40&md5=99287335de36ba59af76dc85b58c3a25","Spatiotemporal fusion utilizes the complementarity of high-temporal-low-spatial (HTLS) and high-spatial-low-temporal (HSLT) resolution data to obtain high temporal and spatial (HTHS) resolution fusion data, which can effectively satisfy the demand for HTHS data. However, due to the difference of spatial resolution, it is difficult to obtain precise spatial information in spatiotemporal fusion. To solve this problem, a multi-level strategy-based spatial domain prediction algorithm is proposed to enhance the spatial information extraction in spatiotemporal remote sensing imagery fusion, which can reduce the noise superposition in the process of multiple reconstruction. By learning-based first and then interpolation-based Super resolution reconstruction, the proposed method can obtain better prediction of spatial information and improve the accuracy of spatiotemporal fusion. © 2020 IEEE.","Forecasting; Geology; Image enhancement; Prediction algorithms; Remote sensing imagery; Spatial information extraction; Spatial informations; Spatial resolution; Spatio-temporal fusions; Super resolution reconstruction; Temporal and spatial; Remote sensing","EDSR; Remote sensing; Spatiotemporal fusion; Super-resolution reconstruction; TPS","Conference paper","Final","","Scopus","2-s2.0-85101954858"
"Wang B.; Zou Y.; Li Y.; Lu W.; Zuo C.","Wang, Bowen (57204607674); Zou, Yan (56278157500); Li, Yuhai (57361136900); Lu, Wenlin (57397930700); Zuo, Chao (36007852700)","57204607674; 56278157500; 57361136900; 57397930700; 36007852700","Low-light-level image super-resolution reconstruction via deep learning network","2021","Proceedings of SPIE - The International Society for Optical Engineering","12065","","1206527","","","","10.1117/12.2606215","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122288976&doi=10.1117%2f12.2606215&partnerID=40&md5=94e69b3255d228133439c69ba52c7ce6","Wide field-of-view (FOV) and high-resolution (HR) imaging systems have become indispensable information acquisition equipment in many applications, such as video surveillance, target detection and remotely sensed imagery. However, due to the constraints of spatial sampling and detector processing level, the ability of remote sensing to obtain high spatial resolution is limited, especially in the wide FOV imaging. To solve these problems, we propose a multi-scale feature extraction (MSFE) network to realize super-resolution imaging in a low-light-level (LLL) environment. In order to perform data fusion and information extraction for low resolution (LR) images, the network extracts high-frequency detail information from difierent dimensions by combining the channel attention mechanism module and skip connection module. In this way, redundant low-frequency signals can pass through the network tail-ends, furthermore, the more important high-frequency components calculation can be focused. The qualitative and quantitative analysis results show that the proposed method achieves the most advanced performance compared with other state-of-the-art methods, which shows the superiority of the design framework and the efiectiveness of presenting modules. © 2021 SPIE.","Data fusion; Deep learning; Image reconstruction; Image resolution; Remote sensing; Security systems; Deep learning network; Features extraction; Image super-resolution reconstruction; Learning network; Low light level; Low-light-level image; Multi-scale feature extraction; Multi-scale features; Superresolution; Wide field-ofview; Feature extraction","Deep learning network; Low-light-level; Multi-scale feature extraction; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85122288976"
"Nguyen H.V.; Ulfarsson M.O.; Sveinsson J.R.; Mura M.D.","Nguyen, Han V. (57222240069); Ulfarsson, Magnus O. (6507677875); Sveinsson, Johannes R. (7003642214); Mura, Mauro Dalla (57218455473)","57222240069; 6507677875; 7003642214; 57218455473","Sentinel-2 Sharpening Using a Single Unsupervised Convolutional Neural Network with MTF-Based Degradation Model","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9464640","6882","6896","14","10.1109/JSTARS.2021.3092286","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111144938&doi=10.1109%2fJSTARS.2021.3092286&partnerID=40&md5=7e5370c6a46cbd450007d030f7a0df17","The Sentinel-2 (S2) constellation provides multispectral images at 10 m, 20 m, and 60 m resolution bands. Obtaining all bands at 10 m resolution would benefit many applications. Recently, many model-based and deep learning (DL)-based sharpening methods have been proposed. However, the downside of those methods is that the DL-based methods need to be trained separately for the 20 m and the 60 m bands in a supervised manner at reduced resolution, while the model-based methods heavily depend on the hand-crafted image priors. To break the gap, this article proposes a novel unsupervised DL-based S2 sharpening method using a single convolutional neural network (CNN) to sharpen the 20 and 60 m bands at the same time at full resolution. The proposed method replaces the hand-crafted image prior by the deep image prior (DIP) provided by a CNN structure whose parameters are easily optimized using a DL optimizer. We also incorporate the modulation transfer function-based degradation model as a network layer, and add all bands to both network input and output. This setting improves the DIP and exploits the advantage of multitask learning since all S2 bands are highly correlated. Extensive experiments with real S2 data show that our proposed method outperforms competitive methods for reduced-resolution evaluation and yields very high quality sharpened image for full-resolution evaluation.  © 2008-2012 IEEE.","Convolution; Convolutional neural networks; Deep learning; Multi-task learning; Network layers; Quality control; Degradation model; Full resolutions; Highly-correlated; Model-based method; Model-based OPC; Multispectral images; Network inputs; Reduced resolution; artificial neural network; degradation; experimental study; image resolution; multispectral image; remote sensing; Sentinel; Learning systems","Convolutional neural networks (CNNs); image fusion; MTF-based degradation; Sentinel-2 image sharpening; super-resolution; unsupervised deep learning","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85111144938"
"Nguyen H.V.; Ulfarsson M.O.; Sveinsson J.R.","Nguyen, Han V. (57222240069); Ulfarsson, Magnus O. (6507677875); Sveinsson, Johannes R. (7003642214)","57222240069; 6507677875; 7003642214","SHARPENING THE 20 M BANDS OF SENTINEL-2 IMAGE USING AN UNSUPERVISED CONVOLUTIONAL NEURAL NETWORK","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","2875","2878","3","10.1109/IGARSS47720.2021.9555082","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128986256&doi=10.1109%2fIGARSS47720.2021.9555082&partnerID=40&md5=e7015a2e83d14d555904ea2217e81173","This paper proposes a novel method for sharpening the 20 m bands of the multispectral images acquired by the Sentinel- 2 (S2) constellation. We formulate the S2 sharpening as an inverse problem and solve it using an unsupervised convolutional neural network (CNN), called S2UCNN. The proposed method extends the deep image prior provided by a CNN structure with S2 domain knowledge. We incorporate a modulation transfer function-based degradation model as a network layer. We add the 10 m bands to both the network input and output to take advantage of the multitask learning. Experimental results with a real S2 dataset show that the proposed method outperforms the competitive methods on reduced-resolution data and gives very high quality sharpened image on full-resolution data.  © 2021 IEEE.","Convolution; Convolutional neural networks; Domain Knowledge; Inverse problems; Network layers; Remote sensing; Convolutional neural network; Image priors; Multispectral images; Neural networks structure; Novel methods; Remote-sensing; Sentinel-2; Sharpening; Superresolution; Unsupervised convolutional neural network; Image fusion","image fusion; Remote sensing; Sentinel-2; sharpening; super-resolution; unsupervised convolutional neural network","Conference paper","Final","","Scopus","2-s2.0-85128986256"
"","","","2nd International Conference on Computer Vision, Image, and Deep Learning","2021","Proceedings of SPIE - The International Society for Optical Engineering","11911","","","","","525","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118427921&partnerID=40&md5=753f36e95a3ff6b665db0b67831402be","The proceedings contain 77 papers. The topics discussed include: emoji can improve university studentsâ€™ enthusiasm perception with their counselor: evidence from behavior and eye movements; research on the design and production of 3D animation; remote sensing image matching method based on neural network; application and verification of DSP+FPGA in SINS navigation computer circuit design; using the moving trapezoid body interpolation to reconstruct 3D meteorological radar image; emoji can improve university studentsâ€™ intimate perception with their counselor: evidence from behavior and eye movements; image inpainting with gradient guidance; target detection of automobile engine connecting rod image based on sub-pixel level; image mosaic based on improved SPHP mesh optimization method; a novel strategy of multi-scale conditional super-resolution; and brain MRI based on Otsu and region growth for ventricle segmentation.","","","Conference review","Final","","Scopus","2-s2.0-85118427921"
"Liu H.; Gu Y.; Wang T.; Li S.","Liu, Huan (57069409100); Gu, Yanfeng (7403045983); Wang, Tengfei (57768884900); Li, Shengyang (14031768000)","57069409100; 7403045983; 57768884900; 14031768000","Satellite Video Super-Resolution Based on Adaptively Spatiotemporal Neighbors and Nonlocal Similarity Regularization","2020","IEEE Transactions on Geoscience and Remote Sensing","58","12","9080534","8372","8383","11","10.1109/TGRS.2020.2987400","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097340626&doi=10.1109%2fTGRS.2020.2987400&partnerID=40&md5=13c96b0481ea44ba7c49936666a7ff70","Recently, super-resolution (SR) of satellite videos has received increasing attention as it can overcome the limitation of spatial resolution in applications of satellite videos to dynamic analysis. The low quality of satellite videos presents big challenges to the development of the spatial SR techniques, e.g., accurate motion estimation and motion compensation for multiframe SR. Therefore, reasonable image priors in maximum a posteriori (MAP) framework, where motion information among adjacent frames is involved, are needed to regularize the solution space and generate the corresponding high-resolution frames. In this article, an effective satellite video SR framework based on locally spatiotemporal neighbors and nonlocal similarity modeling is proposed. Firstly, local prior knowledge is represented by means of adaptively exploiting spatiotemporal neighbors. In this way, implicitly local motion information can be captured without explicit motion estimation. Secondly, the nonlocal spatial similarity is integrated into the proposed SR framework to enhance texture details. Finally, the locally spatiotemporal regularization and nonlocal similarity modeling bring out a complex optimization problem, which is solved via the iterated reweighted least squares in the proposed SR framework. The videos from the Jilin-1 satellite and the OVS-1A satellite are used for evaluating the proposed method. Experimental results show that the proposed method demonstrates better SR performance in preserving edges and texture details compared with the-state-of-art video SR methods.  © 1980-2012 IEEE.","Motion compensation; Optical resolving power; Satellites; Textures; Complex optimization problems; Maximum a posteriori; Motion information; Non-local similarities; Re-weighted least squares; Spatial resolution; Spatio-temporal regularizations; Video super-resolution; remote sensing; satellite altimetry; spatial resolution; spatiotemporal analysis; videography; Motion estimation","Adaptively spatiotemporal neighbors; implicit motion estimation; maximum a posteriori (MAP); nonlocal similarity; satellite video; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85097340626"
"Dong X.; Sun X.; Jia X.; Xi Z.; Gao L.; Zhang B.","Dong, Xiaoyu (57212387140); Sun, Xu (23499533300); Jia, Xiuping (7201933692); Xi, Zhihong (15047162700); Gao, Lianru (14031580000); Zhang, Bing (57210588483)","57212387140; 23499533300; 7201933692; 15047162700; 14031580000; 57210588483","Remote Sensing Image Super-Resolution Using Novel Dense-Sampling Networks","2021","IEEE Transactions on Geoscience and Remote Sensing","59","2","9107103","1618","1633","15","10.1109/TGRS.2020.2994253","44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099776747&doi=10.1109%2fTGRS.2020.2994253&partnerID=40&md5=7a029bd3b5a9b86799b8672c7f7ecf6a","Super-resolution (SR) techniques play a crucial role in increasing the spatial resolution of remote sensing data and overcoming the physical limitations of the spaceborne imaging systems. Though the convolutional neural network (CNN)-based methods have obtained good performance, they show limited capacity when coping with large-scale super-resolving tasks. The more complicated spatial distribution of remote sensing data further increases the difficulty in reconstruction. This article develops a dense-sampling super-resolution network (DSSR) to explore the large-scale SR reconstruction of the remote sensing imageries. Specifically, a dense-sampling mechanism, which reuses an upscaler to upsample multiple low-dimension features, is presented to make the network jointly consider multilevel priors when performing reconstruction. A wide feature attention block (WAB), which incorporates the wide activation and attention mechanism, is introduced to enhance the representation ability of the network. In addition, a chain training strategy is proposed to optimize further the performance of the large-scale models by borrowing knowledge from the pretrained small-scale models. Extensive experiments demonstrate the effectiveness of the proposed methods and show that the DSSR outperforms the state-of-the-art models in both quantitative evaluation and visual quality.  © 1980-2012 IEEE.","Convolutional neural networks; Image reconstruction; Image resolution; Optical resolving power; Attention mechanisms; Physical limitations; Quantitative evaluation; Remote sensing data; Remote sensing imagery; Remote sensing images; Sampling mechanisms; Small-scale models; algorithm; image resolution; network analysis; remote sensing; sampling; Remote sensing","Attention mechanism; dense sampling; remote sensing image; super-resolution; wide activation","Article","Final","","Scopus","2-s2.0-85099776747"
"Wu R.; Ma W.-K.; Fu X.; Li Q.","Wu, Ruiyuan (57194873872); Ma, Wing-Kin (7402703846); Fu, Xiao (57195386854); Li, Qiang (57216931780)","57194873872; 7402703846; 57195386854; 57216931780","Hyperspectral Super-Resolution via Global-Local Low-Rank Matrix Estimation","2020","IEEE Transactions on Geoscience and Remote Sensing","58","10","9044632","7125","7140","15","10.1109/TGRS.2020.2979908","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092396251&doi=10.1109%2fTGRS.2020.2979908&partnerID=40&md5=c2378db7f966a73cfcc66a371200f5eb","Hyperspectral super-resolution (HSR) is a problem that aims to estimate an image of high spectral and spatial resolutions from a pair of coregistered multispectral (MS) and hyperspectral (HS) images, which have coarser spectral and spatial resolutions, respectively. In this article, we pursue a low-rank matrix estimation approach for HSR. We assume that the spectral-spatial matrices associated with the whole image and the local areas of the image have low-rank structures. The local low-rank assumption, in particular, has the aim of providing a more flexible model for accounting for local variation effects due to endmember variability. We formulate the HSR problem as a global-local rank-regularized least-squares problem. By leveraging on the recent advances in nonconvex large-scale optimization, namely the smooth Schatten-p approximation and the accelerated majorization-minimization method, we develop an efficient algorithm for the global-local low-rank problem. Numerical experiments on synthetic, semi-real, and real data show that the proposed algorithm outperforms a number of benchmark algorithms in terms of recovery performance.  © 1980-2012 IEEE.","Approximation algorithms; Benchmarking; Hydraulic structures; Optical resolving power; Endmember variabilities; Large-scale optimization; Low-rank matrix estimations; Minimization methods; Numerical experiments; Recovery performance; Regularized least squares; Spatial resolution; estimation method; global change; matrix; remote sensing; spatial resolution; spectral analysis; Matrix algebra","Endmember variability (EV); hyperspectral (HS); hyperspectral super-resolution (HSR); low-rank matrix estimation","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85092396251"
"Romero L.S.; Marcello J.; Vilaplana V.","Romero, Luis Salgueiro (57218455911); Marcello, Javier (6602158797); Vilaplana, Verónica (23394280500)","57218455911; 6602158797; 23394280500","Super-resolution of Sentinel-2 imagery using generative adversarial networks","2020","Remote Sensing","12","15","2424","","","","10.3390/RS12152424","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089853089&doi=10.3390%2fRS12152424&partnerID=40&md5=6bb6fc362a861fc8952daf3ca71d5b36","Sentinel-2 satellites provide multi-spectral optical remote sensing images with four bands at 10 m of spatial resolution. These images, due to the open data distribution policy, are becoming an important resource for several applications. However, for small scale studies, the spatial detail of these images might not be sufficient. On the other hand, WorldView commercial satellites offer multi-spectral images with a very high spatial resolution, typically less than 2 m, but their use can be impractical for large areas or multi-temporal analysis due to their high cost. To exploit the free availability of Sentinel imagery, it is worth considering deep learning techniques for single-image super-resolution tasks, allowing the spatial enhancement of low-resolution (LR) images by recovering high-frequency details to produce high-resolution (HR) super-resolved images. In this work, we implement and train a model based on the Enhanced Super-Resolution Generative Adversarial Network (ESRGAN) with pairs of WorldView-Sentinel images to generate a super-resolved multispectral Sentinel-2 output with a scaling factor of 5. Our model, named RS-ESRGAN, removes the upsampling layers of the network to make it feasible to train with co-registered remote sensing images. Results obtained outperform state-of-the-art models using standard metrics like PSNR, SSIM, ERGAS, SAM and CC. Moreover, qualitative visual analysis shows spatial improvements as well as the preservation of the spectral information, allowing the super-resolved Sentinel-2 imagery to be used in studies requiring very high spatial resolution. © 2020 by the authors.","Deep learning; Image analysis; Image resolution; Network layers; Open Data; Optical resolving power; Remote sensing; Spectroscopy; Commercial satellites; Data distribution policies; Low resolution images; Multi-temporal analysis; Optical remote sensing; Remote sensing images; Spectral information; Very high spatial resolutions; Image enhancement","Deep learning; Generative adversarial network; Sentinel-2; Super-resolution; WorldView","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85089853089"
"","","","7th International Conference of Pioneering Computer Scientists, Engineers and Educators, ICPCSEE 2021","2021","Communications in Computer and Information Science","1452 CCIS","","","","","1055","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115713811&partnerID=40&md5=f06be6e5abb6d7c68eba6453168663ef","The proceedings contain 81 papers. The special focus in this conference is on Pioneering Computer Scientists, Engineers and Educators. The topics include: MA Mask R-CNN: MPR and AFPN Based Mask R-CNN; improved Non-negative Matrix Factorization Algorithm for Sparse Graph Regularization; a Blockchain-Based Scheme of Data Sharing for Housing Provident Fund; intelligent Storage System of Machine Learning Model Based on Task Similarity; predicting Stock Price Movement with Multiple Data Sources and Machine Learning Models; channel Context and Dual-Domain Attention Based U-Net for Skin Lesion Attributes Segmentation; study on the Protection and Product Development of Intangible Cultural Heritage with Computer Virtual Reality Technology; ECG-Based Arrhythmia Detection Using Attention-Based Convolutional Neural Network; Quantum Color Image Scaling on QIRHSI Model; WSN Data Compression Model Based on K-SVD Dictionary and Compressed Sensing; human Body Pose Recognition System Based on Teaching Interaction; adaptive Densely Residual Network for Image Super-Resolution; Real-Time Image and Video Artistic Style Rendering System Based on GPU; semantic Segmentation of High Resolution Remote Sensing Images Based on Improved ResU-Net; Exploring Classification Capability of CNN Features; generative Adversarial Network Based Status Generation Simulation Approach; the Construction of Case Event Logic Graph for Judgment Documents; anti-obfuscation Binary Code Clone Detection Based on Software Gene; thread Private Variable Access Optimization Technique for Sunway High-Performance Multi-core Processors; parallel Region Reconstruction Technique for Sunway High-Performance Multi-core Processors; research on Route Optimization of Battlefield Collection Equipment Based on Improved Ant Algorithm; a Collaborative Cache Strategy Based on Utility Optimization; integrating Local Closure Coefficient into Weighted Networks for Link Prediction.","","","Conference review","Final","","Scopus","2-s2.0-85115713811"
"Sustika R.; Suksmono A.B.; Danudirdjo D.; Wikantika K.","Sustika, Rika (56523358200); Suksmono, Andriyan Bayu (6602490139); Danudirdjo, Donny (14019254300); Wikantika, Ketut (6603393238)","56523358200; 6602490139; 14019254300; 6603393238","Generative Adversarial Network with Residual Dense Generator for Remote Sensing Image Super Resolution","2020","Proceeding - 2020 International Conference on Radar, Antenna, Microwave, Electronics and Telecommunications, ICRAMET 2020","","","9298648","34","39","5","10.1109/ICRAMET51080.2020.9298648","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099336277&doi=10.1109%2fICRAMET51080.2020.9298648&partnerID=40&md5=d15bcbb688d091181df293460aec5d83","Improving image resolution, especially spatial resolution, has been one of the most important concerns on remote sensing research communities. An efficient solution for improving spatial resolution is by using algorithm, known as super-resolution (SR). The super-resolution technique that received special attention recently is super-resolution based on deep learning. In this paper, we propose deep learning approach based on generative adversarial network (GAN) for remote sensing images super resolution. We used residual dense network (RDN) as generator network. Generally, deep learning with residual dense network (RDN) gives high performance on classical (objective) evaluation metrics meanwhile generative adversarial network (GAN) based approach shows a high perceptual quality. Experiment results show that combination of residual dense network generator with generative adversarial network training is found to be effective. Our proposed method outperforms the baseline method in terms of objective and perceptual quality evaluation metrics. © 2020 IEEE.","Deep learning; Image enhancement; Image resolution; Optical resolving power; Quality control; Radar; Adversarial networks; Evaluation metrics; Learning approach; Perceptual quality; Remote sensing images; Research communities; Spatial resolution; Super resolution; Remote sensing","convolutional neural network; generative adversarial network; image; remote sensing; residual dense network; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85099336277"
"Dong R.; Zhang L.; Fu H.","Dong, Runmin (57205415789); Zhang, Lixian (57207392945); Fu, Haohuan (8713118400)","57205415789; 57207392945; 8713118400","BLIND SUPER-RESOLUTION ON REMOTE SENSING IMAGES WITH BLUR KERNEL PREDICTION","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","2879","2882","3","10.1109/IGARSS47720.2021.9554620","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129808178&doi=10.1109%2fIGARSS47720.2021.9554620&partnerID=40&md5=8150e2a62d91624ecd550ecaef0bc849","Single image super-resolution (SISR) is essential in many remote sensing applications. Most of the existing SISR methods on remote sensing images assume that the low resolution (LR) images are synthesized from high-resolution (HR) images by bicubic downscaling. However, the performance of those methods is limited in the real-world remote sensing scenario as the actual degradation is sometimes different from the assumption. Therefore, we introduce the blind super-resolution (SR) concept and propose a super-resolution method with blur kernel prediction (BKPSR). BKPSR first predicts the blur kernel code for an image and then utilizes the blur kernel code to assist the image super-resolution. Experimental results indicate that our method outperforms existing SISR methods on real-world remote sensing images. © 2021 IEEE.","Blind equalization; Deep learning; Image processing; Optical resolving power; Blind Super-resolution; Blur kernel estimations; Deep learning; Image super resolutions; Kernel predictions; Real-world; Remote sensing applications; Remote sensing images; Single images; Superresolution methods; Remote sensing","Blind super-resolution; blur-kernel estimation; deep learning; remote sensing image","Conference paper","Final","","Scopus","2-s2.0-85129808178"
"Fang S.; Meng S.; Cao Y.; Zhang J.; Shi W.","Fang, Shuai (7402422537); Meng, Siyuan (57679448000); Cao, Yang (57482207100); Zhang, Jing (57834691500); Shi, Weikai (57228298100)","7402422537; 57679448000; 57482207100; 57834691500; 57228298100","ADAPTIVE CHANNEL ATTENTION AND FEATURE SUPER-RESOLUTION FOR REMOTE SENSING IMAGES SPATIOTEMPORAL FUSION","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","2572","2575","3","10.1109/IGARSS47720.2021.9555093","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129788162&doi=10.1109%2fIGARSS47720.2021.9555093&partnerID=40&md5=2d583ba1bc2fff996f7eaca1c79d4990","CNN-based Spatiotemporal image fusion (STIF) methods have achieved better performance than traditional researches. However, most CNN-based methods fail to make full use of hierarchical features, and ignore the quality and distribution characteristics of feature maps in fine-grained STIF. In this paper, we propose a network with channel attention and feature super-resolution for STIF (CAFSRNet). First, our method uses the low resolution time-domain changing images as input to extract changes more accurately and simplify computational overhead. Second, channel attention mechanism is introduced into Cross-spatial Resolution Mapping module to make the network pay more attention to informative features. Third, by adding feature super-resolution into the supervision process, we enhance the distribution of feature maps and the quality of mapping results. The qualitative and quantitative experimental results on various datasets demonstrate the superiority of our proposed method over the state-of-the-art methods. © 2021 IEEE.","Convolutional neural networks; Mapping; Optical resolving power; Remote sensing; Time domain analysis; Channel attention; Convolutional neural network; Feature map; Feature super-resolution; Learningbased; Network-based; Spatiotemporal image fusion; Spatiotemporal images; Superresolution; Image fusion","channel attention; Convolutional neural network (CNN); feature super-resolution; learningbased; Spatiotemporal image fusion","Conference paper","Final","","Scopus","2-s2.0-85129788162"
"Zhang Y.; Xiang S.; Wan Y.; Cao H.; Luo Y.; Zheng Z.","Zhang, Yongjun (55577971100); Xiang, Sizhe (57222240525); Wan, Yi (57213301632); Cao, Hui (57225746691); Luo, Yimin (57199124543); Zheng, Zhi (57213530274)","55577971100; 57222240525; 57213301632; 57225746691; 57199124543; 57213530274","DEM Extraction from Airborne Lidar Point Cloud in Thick-Forested Areas via Convolutional Neural Network","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323201","461","464","3","10.1109/IGARSS39084.2020.9323201","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102005605&doi=10.1109%2fIGARSS39084.2020.9323201&partnerID=40&md5=dcd960d745dc7074e90e83402c662cce","Digital Elevation Model (DEM), representing the height of the earth terrain, is one of the crucial geographic information products. One of the main data source of DEM is the airborne LiDAR point cloud with its non-ground-reflections filtered out. Point cloud filtering in thick-forested areas is difficult without enough ground control points when using conventional methods. In this paper, a supervised method is proposed to handle the problem of automatic DEM extraction with little ground control points. The design of the method is inspired by the successful application of the convolutional neural networks (CNN) in the image super resolution (SR) process. First, with the given LiDAR point cloud, the digital surface model (DSM) is resampled with regular grid. Then, by learning the spatial autocorrelation between the DSM and its corresponding DEM, a robust CNN model is established. Finally, the DEM in thick-forested areas can be generated from the DSM with the trained model. Experimental results at two different mountain sites in China validate the effectiveness of the proposed method of high-precision DEM generation. © 2020 IEEE.","Convolution; Extraction; Forestry; Geology; Optical radar; Remote sensing; Rock mechanics; Surveying; Conventional methods; Digital elevation model; Digital surface models; Geographic information; Ground control points; Image super resolutions; Spatial autocorrelations; Supervised methods; Convolutional neural networks","convolutional neural network (CNN); DEM extraction; Digital Elevation Model (DEM); Digital Surface Model (DSM); LiDAR point cloud","Conference paper","Final","","Scopus","2-s2.0-85102005605"
"Hu J.; Chen H.; Zhao M.; Li Y.","Hu, Jing (57191473546); Chen, Huilin (57222242348); Zhao, Minghua (55477788900); Li, Yunsong (55986546100)","57191473546; 57222242348; 55477788900; 55986546100","Deep Intra Fusion for Hyperspectral Image Super-Resolution","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324536","2663","2666","3","10.1109/IGARSS39084.2020.9324536","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102007907&doi=10.1109%2fIGARSS39084.2020.9324536&partnerID=40&md5=24b0af08740081912cbb81e249cebc18","Hyperspectral image (HSI) super-resolution is currently attracting great interest in remote sensing, since it allows the generation of high spatial resolution HSIs and circumventing the main limitation of the imagery sensors. This paper proposes a novel deep intra fusion network (IFN) for the HSI super-resolution, in which both the spatial and the spectral information have been fully and automatically exploited. Specifically, parallel convolutions are applied to two adjacent bands and their difference band, and obtain the high-dimensional features. Meanwhile, an automatically aggregation module is applied in the IFN to achieve the intra-fusion between these features. In this way, both the spatial information of the current band and the spectral information between neighboring bands are utilized in the super-resolving process. Experimental results and data analysis suggest the effectiveness of the proposed method. © 2020 IEEE.","Geology; Optical resolving power; Spectroscopy; High dimensional feature; High spatial resolution; HyperSpectral; Image super resolutions; Spatial informations; Spectral information; Super resolution; Remote sensing","deep intra fusion network; hyperspectral image; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85102007907"
"Chen N.; Sui L.; Zhang B.; He H.; Marcato Junior J.; Li J.","Chen, Nan (57208390275); Sui, Lichun (35173613800); Zhang, Biao (57224313750); He, Hongjie (57222872355); Marcato Junior, Jose (55640064500); Li, Jonathan (57235557700)","57208390275; 35173613800; 57224313750; 57222872355; 55640064500; 57235557700","Single Satellite Imagery Superresolution Based on Hybrid Nonlocal Similarity Constrained Convolution Sparse Coding","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9216608","7489","7505","16","10.1109/JSTARS.2020.3028774","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107344094&doi=10.1109%2fJSTARS.2020.3028774&partnerID=40&md5=0e752b7614bbfbb3bdd012ef56f247cc","The traditional superresolution methods based on image patches often ignore the consistency between the overlapped patches, causing block effects in produced images. The convolutional sparse coding based superresolution method uses the translation invariance of the convolution filter to directly encode the entire image, maintaining consistency and good performance. In this article, we propose a novel approach to single-image superresolution reconstruction based on hybrid nonlocal similarity constrained convolution sparse coding. We first decompose the input image into a smooth part and a texture part. The Bayesian nonparametric model can use more prior information of the original image, so we replace the previous bicubic interpolation with this method to better reconstruct the residual high-frequency information in the smooth part. When reconstructing the texture part, this article proposes a nonlocal similarity constrained convolutional sparse coding method, which transforms the reconstruction of the texture part to minimize the convolution sparse coding noise of the feature maps and classifies the image patches in the search space by using the correlation coefficients as the structural information, avoiding unnecessary weight calculation. Several methods were tested on satellite images extensively. Both visual inspection and quantitative analysis results demonstrate that our method outperforms other state-of-the-art methods and increases noise immunity effectively. © 2008-2012 IEEE.","Convolution; Image coding; Image reconstruction; Optical resolving power; Satellite imagery; Textures; Bayesian nonparametric modeling; Correlation coefficient; High-frequency informations; Single-image super-resolution reconstruction; State-of-the-art methods; Structural information; Superresolution methods; Translation invariance; Bayesian analysis; correlation; image resolution; reconstruction; remote sensing; satellite imagery; Image texture","Bayesian nonparametric model; convolution sparse coding; correlation coefficient; nonlocal (NL) similarity structure; superresolution (SR) reconstruction","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85107344094"
"Yau H.; Du X.","Yau, Henry (57210860847); Du, Xian (37028027600)","57210860847; 37028027600","Robust deep learning-based multi-image super-resolution using inpainting","2021","Journal of Electronic Imaging","30","1","013005","","","","10.1117/1.JEI.30.1.013005","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102026428&doi=10.1117%2f1.JEI.30.1.013005&partnerID=40&md5=cc9cf54c2a3803671060e404fd6d8633","Traditional super-resolution techniques are generally presented as optimization problems with variations in the choice of optimization methods and cost functions. Even for the overdetermined cases, the problem is ill-conditioned. The situation is worsened when considering underdetermined cases with unknown regions due to occlusions or lack of data. Deep learning-based methods have shown promise in solving a similar problem. One recent advancement has come in the form of partial convolutions, which were developed to perform infilling of holes in images. When used in an appropriate deep neural network, this particular variant of the convolutional filter has shown great promise in approximating missing spatial information. The method described is formulated as a two-stage process. Lower resolution images are first registered and placed on a high-resolution grid. The problem is then treated as an in-painting task where the missing regions are reconstructed using a deep neural network with partial convolutional filters. We compare our method against deep learning-based single image super-resolution methods and classical multi-image super-resolution techniques using two similarity metrics and show that our method is more robust to occlusions and errors in registration while also producing higher quality outputs.  © 2021 SPIE and IS&T.","Convolution; Convolutional neural networks; Cost functions; Deep neural networks; Learning systems; Optical resolving power; High-resolution grids; Learning-based methods; Lower resolution; Optimization method; Optimization problems; Similarity metrics; Spatial informations; Two-stage process; Deep learning","deep learning; inpainting; remote sensing; super-resolution","Article","Final","","Scopus","2-s2.0-85102026428"
"Zou F.; Xiao W.; Ji W.; He K.; Yang Z.; Song J.; Zhou H.; Li K.","Zou, Fuhao (7005632643); Xiao, Wei (57198552535); Ji, Wanting (57197800973); He, Kunkun (57216690258); Yang, Zhixiang (57216695066); Song, Jingkuan (57205085174); Zhou, Helen (56139009800); Li, Kai (57213221339)","7005632643; 57198552535; 57197800973; 57216690258; 57216695066; 57205085174; 56139009800; 57213221339","Arbitrary-oriented object detection via dense feature fusion and attention model for remote sensing super-resolution image","2020","Neural Computing and Applications","32","18","","14549","14562","13","10.1007/s00521-020-04893-9","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084302000&doi=10.1007%2fs00521-020-04893-9&partnerID=40&md5=795ef7197493452c818a0dfc589d6bcd","In this paper, we aim at developing a new arbitrary-oriented end-to-end object detection method to further push the frontier of object detection for remote sensing image. The proposed method comprehensively takes into account multiple strategies, such as attention mechanism, feature fusion, rotation region proposal as well as super-resolution pre-processing simultaneously to boost the performance in terms of localization and classification under the faster RCNN-like framework. Specifically, a channel attention network is integrated for selectively enhancing useful features and suppressing useless ones. Next, a dense feature fusion network is designed based on multi-scale detection framework, which fuses multiple layers of features to improve the sensitivity to small objects. In addition, considering the objects for detection are often densely arranged and appear in various orientations, we design a rotation anchor strategy to reduce the redundant detection regions. Extensive experiments on two remote sensing public datasets DOTA, NWPU VHR-10 and scene text dataset ICDAR2015 demonstrate that the proposed method can be competitive with or even superior to the state-of-the-art ones, like R2CNN and R2CNN++. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","Feature extraction; Object recognition; Optical resolving power; Remote sensing; Attention mechanisms; Attention model; Detection framework; Multiple strategy; Object detection method; Remote sensing images; State of the art; Super resolution; Object detection","Arbitrary oriented; Attention model; Dense feature pyramid network; Object detection; Remote sensing image; Rotation proposals; Super-resolution","Article","Final","","Scopus","2-s2.0-85084302000"
"Huang S.; Hu Y.; Gu M.; Gong C.; Zheng F.","Huang, Shuo (57226840610); Hu, Yong (57013575000); Gu, MingJian (57202891942); Gong, Cailan (7102694381); Zheng, Fuqiang (57217855616)","57226840610; 57013575000; 57202891942; 7102694381; 57217855616","Super-resolution infrared remote-sensing target-detection algorithm based on deep learning","2021","Laser and Optoelectronics Progress","58","16","1610015","","","","10.3788/LOP202158.1610015","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113964458&doi=10.3788%2fLOP202158.1610015&partnerID=40&md5=8f83ae659f66bd33c028c16c818ec9f7","Owing to the infrared diffraction iimit' the resolution of infrared remote sensing images is generally low' which makes precsse detection and recognition of fared targets difficult. To address this problem' an nnfrared target super resolution detection algorithm based on deep learmng ss proposed . The algorithm comprises two man parts. The tirst part implements Wide Activation for Efficient and accurate mage superrresoiufion (WDSR) to reconstruct mfrared remote sensrng mages' and uses nnfrared images processed by the downsamping method of the sensor as the trammg set. The second part mvolves target detection based on Faster regon-based convolutional neural network ( Faster RCNN ) . A muttsc!!! feature transfer network structure ss proposed . The low-evel features are nput to region proposal network ( RPN ) ' which reduces the simplificafion rate of weak and small target pixels . In addifion' a nonmaximum suppression method ss used to reduce the suppression of dense target detection frames. Compared wth Faster RCNN usng the same trannnng set' the proposed algorithm rncreased target detection accuracy' the overall recall rate' and the recall rate of small targets by 5.33%' 12.22%' and 13.25%' respectively. © 2021 Universitat zu Koln. All rights reserved.","","Deep learmng; Image processmg; Infared remote sensmg; Super resolution; Target detection","Article","Final","","Scopus","2-s2.0-85113964458"
"Wang Z.; Jiang K.; Yi P.; Han Z.; He Z.","Wang, Zhongyuan (57203515592); Jiang, Kui (57203871718); Yi, Peng (57203880354); Han, Zhen (56415515700); He, Zheng (53881225400)","57203515592; 57203871718; 57203880354; 56415515700; 53881225400","Ultra-dense GAN for satellite imagery super-resolution","2020","Neurocomputing","398","","","328","337","9","10.1016/j.neucom.2019.03.106","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075425341&doi=10.1016%2fj.neucom.2019.03.106&partnerID=40&md5=5268eacbe62512668065597c63767082","Image super-resolution (SR) techniques improve various remote sensing applications by allowing for finer spatial details than those captured by the original acquisition sensors. Recent advances in deep learning bring a new opportunity for SR by learning the mapping from low to high resolution. The most used convolutional neural networks (CNN) based approaches are prone to excessive smoothing or blurring due to the optimization objective in mean squared error (MSE). Instead, generative adversarial network (GAN) based approaches can achieve more perceptually acceptable results. However, the preliminary design of GANs generator with simple direct- or skip-connection residual blocks compromises its SR potential. Emerging dense convolutional network (DenseNet) equipped with dense connections has shown a promising prospect in classification and super-resolution. An intuitive idea to introduce DenseNet into GAN is expected to boost SR performance. However, because convolutional kernels in the existing residual block are arranged into a one-dimensional flat structure, the formation of dense connections highly relies on skip connections (linking the current layer to all subsequent layers with a shortcut path). In order to increase connection density, the depth of the layer has to be accordingly expanded, which in turn results in training difficulties such as vanishing gradient and information propagation loss. To this end, this paper proposes an ultra-dense GAN (udGAN) for image SR, where we reform the internal layout of the residual block into a two-dimensional matrix topology. This topology can provide additional diagonal connections so that we can still accomplish enough pathways with fewer layers. In particular, the pathways are almost doubled compared to previous dense connections under the same number of layers. The achievable rich connections are flexibly adapted to the diversity of image content, thus leading to improved SR performance. Extensive experiments on public benchmark datasets and real-world satellite imagery show that our model outperforms state-of-the-art counterparts in both subjective and quantitative assessments, especially those related to perception. © 2019 Elsevier B.V.","Backpropagation; Convolution; Deep learning; Image enhancement; Information dissemination; Mean square error; Neural networks; Optical resolving power; Remote sensing; Topology; Convolutional networks; Convolutional neural network; Image super resolutions; Information propagation; Quantitative assessments; Remote sensing applications; Super resolution; Ultra-dense residual block; Article; convolutional neural network; correlation analysis; data base; deep recursive residual network; dense convolutional network; generative adversarial network; image analysis; image processing; image quality; image reconstruction; priority journal; process optimization; satellite imagery; super resolution convolutional neural network; Satellite imagery","GAN; Satellite imagery; Super-resolution; Ultra-dense residual block","Article","Final","","Scopus","2-s2.0-85075425341"
"Heltin Genitha C.; Indhumathi M.; Sanjeevi S.","Heltin Genitha, C. (56419984000); Indhumathi, M. (57191610328); Sanjeevi, S. (6507719504)","56419984000; 57191610328; 6507719504","A genetic algorithm based approach to estimate the volume of a drinking water reservoir in Chennai city, South India, using multi-spectral satellite images","2021","Geocarto International","36","17","","1993","2009","16","10.1080/10106049.2019.1687590","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074952062&doi=10.1080%2f10106049.2019.1687590&partnerID=40&md5=2d1e07dd599751fc842c7db63a8bbbf9","This paper is concerned with the use of satellite image processing and remote sensing approaches to determine the water-spread area and capacity of a drinking water reservoir in Poondi, near Chennai City, south India. Estimation of water-spread area and volume of the reservoirs using traditional methods like field surveys, acoustic surveys and hydrographic surveys is time-consuming, laborious and expensive. To overcome these problems, many researchers have used satellite images and the per-pixel (hard classification), the sub-pixel (soft classification) and the super resolution mapping approaches. The conventional hard and soft classification approaches do not give accurate results due to the presence of mixed pixels in the image scene of the periphery of the reservoir. In this work, a per-pixel algorithm (Maximum Likelihood), a sub-pixel algorithm (Fuzzy C Means) and a super resolution mapping algorithm (Genetic algorithm) are developed and the water-spread area is estimated for the reservoir using multi-date Landsat8 OLI images. The volume of the reservoir at different water levels are estimated using the water-spread area and the Trapezoidal formula. The capacity estimated from satellite image-derived area is compared with the capacity data obtained from the Poondi reservoir authority. The error in estimation due to the per-pixel approach is 16.74%, while it is 9.06% for the sub-pixel approach and a mere 3.25% for the super-resolution approach. Thus, the super-resolution mapping approach results in minimum error when compared to the sub-pixel approach which in turn gives lesser error result when comparing with the per-pixel approach. © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Chennai; India; Tamil Nadu; computer simulation; drinking water; fuzzy mathematics; genetic algorithm; research work; satellite data; satellite imagery; spatial resolution; water quality","satellite image; sub-pixel mapping; Super resolution mapping; water-spread area","Article","Final","","Scopus","2-s2.0-85074952062"
"Yang T.; Shi H.; Guo J.; Liu D.; Qiao Z.","Yang, Ting (57204166559); Shi, Hongyin (34875778200); Guo, Jianwen (57214245131); Liu, Da (57292083800); Qiao, Zhijun (7103082744)","57204166559; 34875778200; 57214245131; 57292083800; 7103082744","Super-resolution performance studies for orbital-angular-momentum-based imaging radar","2021","International Journal of Remote Sensing","42","21","","8185","8206","21","10.1080/01431161.2021.1975842","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116931089&doi=10.1080%2f01431161.2021.1975842&partnerID=40&md5=512edc48e385d6d6ff6989d431b91bb9","Vortex electromagnetic (EM) wave carrying orbital angular momentum (OAM), whose unique wavefront distribution exhibits angular diversity characteristics, which provides a richer degree of freedom for information modulation. Although several works have reported that the EM vortex imaging has superior performance in target detection and imaging with azimuthal super-resolution, the underlying physical mechanism needs to be further developed. This article offers a solution to significantly refine the imaging resolution for conventional real-aperture imaging radar (CRAIR) using multiple OAM-carrying beams. Firstly, it is deduced that the various spatial frequency distributions and time-varying phase wavefront distributions of OAM beams promote the realization of OAM-based imaging radar (OAMIR) super-resolution imaging. Secondly, a scheme for adjusting the directivity of EM vortex beam is proposed, which can effectively acquire most spatial frequency components of the probed target, resulting in the target can be illuminated simultaneously by the main lobes of various beams carrying different topological charges. Thirdly, the point-spread function (PSF) comparison for CRAIR and OAMIR is carried out by theoretical analysis and numerical simulation, and the spatial azimuth resolution for OAMIR is derived. Finally, the signal mathematical model for OAMIR is established and analysed. Simulation results validate that the proposed OAM-based imaging paradigm breaks through the Rayleigh limit associated with conventional real-aperture imaging technology and achieves imaging performance superior to OAMIR in previous works. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","Angular distribution; Angular momentum; Degrees of freedom (mechanics); Optical resolving power; Optical transfer function; Vortex flow; Wavefronts; Angular diversity; Diversity characteristics; Electromagnetic vortices; Orbital angular momentum; Performance; Performance study; Spatial frequency; Superresolution; Target imaging; Targets detection; electromagnetic wave; image analysis; numerical model; radar imagery; remote sensing; satellite data; satellite imagery; Radar imaging","","Article","Final","","Scopus","2-s2.0-85116931089"
"Wang B.; Zhang S.; Feng Y.; Mei S.; Jia S.; Du Q.","Wang, Baorui (57255138300); Zhang, Shun (56198001500); Feng, Yan (36696426500); Mei, Shaohui (25822578400); Jia, Sen (7202859948); Du, Qian (7202060063)","57255138300; 56198001500; 36696426500; 25822578400; 7202859948; 7202060063","Hyperspectral Imagery Spatial Super-Resolution Using Generative Adversarial Network","2021","IEEE Transactions on Computational Imaging","7","","","948","960","12","10.1109/TCI.2021.3110103","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114738560&doi=10.1109%2fTCI.2021.3110103&partnerID=40&md5=ae42111f52deef50449fba0ec8cd0b9c","Hyperspectral imagery contains both spatial structure information and abundant spectral features of imaged objects. However, due to sensor limitations, abundant spectral information always comes at the sacrifice of low spatial resolution, which brings about difficulties with object analysis and identification. The super-resolution (SR) of HSIs, restored by the traditional interpolation algorithms or the network models trained with the mean-square-error-based loss function, tends to produce over-smoothed images. In this paper, we propose a novel Hyperspectral imagery Spatial Super-Resolution algorithm based on a Generative Adversarial Network (HSSRGAN). The generator network in HSSRGAN consists of two interacting part, i.e., a spatial feature enhanced network (SFEN) and a spectral refined network (SRN), while the discriminator network is employed to predict the probability that the authentic HR image is comparatively more similar than the forged generated image. Concretely, SFEN with the special dense residual blocks is designed to fully extract and enhance more deep hierarchical spatial features of hyperspectral imagery, while SRN is constructed to capture spectral interrelationships and refine the spatial context information so as to increase spatial resolution and alleviate spectral distortion. Moreover, SFEN and SRN are trained by the least-absolute-deviation based loss function to investigate spatial context and the spectral-angle-mapper based loss function to refine spectral information. We validate two versions of our proposed algorithm, 3D-HSSRGAN and 2D-HSSRGAN, on Pavia Centre dataset and Cuprite dataset. Experimental results show that the presented approach is superior to several existing state-of-the-art works.  © 2015 IEEE.","Image resolution; Mean square error; Optical resolving power; Oxide minerals; Remote sensing; Spectroscopy; Adversarial networks; Hyper-spectral imageries; Interpolation algorithms; Least absolute deviations; Spatial structure information; Spectral angle mappers; Spectral information; Super resolution algorithms; Image enhancement","Generative Adversarial Network(GAN); Hyperspectral Image; Spatial Resolution; Spatial Super-resolution","Article","Final","","Scopus","2-s2.0-85114738560"
"Lei D.; Zhang C.; Li Z.; Wu Y.","Lei, Dajiang (36627356400); Zhang, Ce (57216935063); Li, Zhixing (56181457200); Wu, Yu (56468297100)","36627356400; 57216935063; 56181457200; 56468297100","Remote Sensing Image Fusion Based on Generative Adversarial Network with Multi-stream Fusion Architecture; [基于多流融合生成对抗网络的遥感图像融合方法]","2020","Dianzi Yu Xinxi Xuebao/Journal of Electronics and Information Technology","42","8","","1942","1949","7","10.11999/JEIT17_190273","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089700151&doi=10.11999%2fJEIT17_190273&partnerID=40&md5=45ddf43c40faef4e31b10888e507a93d","The generative adversarial network receives extensive attention in the study of computer vision such as image fusion and image super-resolution, due to its strong ability of generating high quality images. At present, the remote sensing image fusion method based on generative adversarial network only learns the mapping between the images, and lacks the unique Pan-sharpening domain knowledge. This paper proposes a remote sensing image fusion method based on optimized generative adversarial network with the integration of the spatial structure information of panchromatic image. The proposed algorithm extracts the spatial structure information of the panchromatic image by the gradient operator. The extracted feature would be added to both the discriminator and the generator which uses a multi-stream fusion architecture. The corresponding optimization objective and fusion rules are then designed to improve the quality of the fused image. Experiments on images acquired by WorldView-3 satellites demonstrate that the proposed method can generate high quality fused images, which is better than the most of advanced remote sensing image fusion methods in both subjective visual and objective evaluation indicators.","Image enhancement; Network architecture; Remote sensing; Adversarial networks; Fusion architecture; High quality images; Image super resolutions; Objective evaluation; Panchromatic images; Remote sensing images; Spatial structure information; Image fusion","Computer vision; Generative adversarial network; Multi-stream fusion architecture; Remote sensing image fusion","Article","Final","","Scopus","2-s2.0-85089700151"
"Cao M.; Ji H.; Gao Z.; Mei T.","Cao, Min (57226775285); Ji, Hong (57205763449); Gao, Zhi (55256514200); Mei, Tincan (8914886000)","57226775285; 57205763449; 55256514200; 8914886000","Vehicle Detection in Remote Sensing Images Using Deep Neural Networks and Multi-Task Learning","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","2","","797","804","7","10.5194/isprs-annals-V-2-2020-797-2020","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091110780&doi=10.5194%2fisprs-annals-V-2-2020-797-2020&partnerID=40&md5=daec2d2a13004100f9a2033c9127ef4c","Vehicle detection in remote sensing image has been attracting remarkable attention over past years for its applications in traffic, security, military, and surveillance fields. Due to the stunning success of deep learning techniques in object detection community, we consider to utilize CNNs for vehicle detection task in remote sensing image. Specifically, we take advantage of deep residual network, multi-scale feature fusion, hard example mining and homography augmentation to realize vehicle detection, which almost integrates all the advanced techniques in deep learning community. Furthermore, we simultaneously address super-resolution (SR) and detection problems of low-resolution (LR) image in an end-to-end manner. In consideration of the absence of paired low-/highresolution data which are generally time-consuming and cumbersome to collect, we leverage generative adversarial network (GAN) for unsupervised SR. Detection loss is back-propagated to SR generator to boost detection performance. We conduct experiments on representative benchmark datasets and demonstrate that our model yields significant improvements over state-of-the-art methods in deep learning and remote sensing areas. © 2020 Copernicus GmbH. All rights reserved.","Deep neural networks; Learning systems; Military applications; Military photography; Military vehicles; Multi-task learning; Neural networks; Object detection; Remote sensing; Adversarial networks; Benchmark datasets; Detection performance; Learning techniques; Low resolution images; Multi-scale features; Remote sensing images; State-of-the-art methods; Deep learning","GAN; hard example mining; homography augmentation; multi-scale feature fusion; Remote sensing images; super-resolution; Vehicle detection","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85091110780"
"Ma J.; Wu H.; Zhang J.; Zhang L.","Ma, Jie (57205916758); Wu, Hanlin (57221263814); Zhang, Jue (56513505100); Zhang, Libao (35325855000)","57205916758; 57221263814; 56513505100; 35325855000","SD-FB-GAN: Saliency-Driven Feedback Gan for Remote Sensing Image Super-Resolution Reconstruction","2020","Proceedings - International Conference on Image Processing, ICIP","2020-October","","9190835","528","532","4","10.1109/ICIP40778.2020.9190835","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098652564&doi=10.1109%2fICIP40778.2020.9190835&partnerID=40&md5=d13a6e4f699e22b71ce072e504a572b0","The visual characteristics of different regions in remote sensing images are significantly versatile, which poses a huge challenge to single image super-resolution. Although generative adversarial network (GAN) has shown great potential in generating photo-realistic results, it provides unsatisfactory performance in objective metrics owning to pseudo textures brought by adversarial learning. In this paper, we propose a new saliency-driven feedback GAN to cope with these problems. We design a saliency-driven feedback generator based on paired-feedback blocks (PFBBs) and recurrent structure to provide strong reconstruction ability. In the PFBB, the saliency map serves as an indicator to reflect the texture complexity, so different reconstruction principles can be applied to restore areas with varying levels of saliency. Besides, we propose to measure the visual quality of salient areas, non-salient areas, and the whole image with multi-discriminators, which can dramatically eliminate pseudo textures. Comprehensive evaluations and ablation studies validate the superiority of our proposal. © 2020 IEEE.","Optical resolving power; Recurrent neural networks; Remote sensing; Textures; Adversarial learning; Adversarial networks; Comprehensive evaluation; Objective metrics; Photo-realistic; Remote sensing images; Texture complexity; Visual qualities; Image reconstruction","deep learning; GAN; Image reconstruction; saliency analysis; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85098652564"
"Mei H.; Zhang H.; Jiang Z.","Mei, Han (57482695500); Zhang, Haopeng (54788751800); Jiang, Zhiguo (35336923600)","57482695500; 54788751800; 35336923600","SELF-ATTENTION FUSION MODULE FOR SINGLE REMOTE SENSING IMAGE SUPER-RESOLUTION","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","2883","2886","3","10.1109/IGARSS47720.2021.9553766","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126011854&doi=10.1109%2fIGARSS47720.2021.9553766&partnerID=40&md5=e85ed0960c83299a8069c1c2650975cd","Single image super-resolution (SISR) is an important procedure to improve many remote sensing applications. Global features play an important role in pixel generation of SISR. In this paper, we proposed a self-attention fusion module named as SAF module which combines spatial attention and channel attention in parallel to handle this problem. Our self-attention fusion module can be flexibly added to many popular deep-learning-based SISR models to further improve their representation ability and learn global features. Experiments on UC Merced dataset indicate that SAF module can improve the performance of classic SISR models and achieve state-of-the-art super-resolution results. © 2021 IEEE","","Channel attention; Remote sensing images; Spatial attention; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85126011854"
"Zhou L.; Xia Y.; Liu Z.","Zhou, Luo (57443314600); Xia, Yan (57696663900); Liu, Zhen (57443504500)","57443314600; 57696663900; 57443504500","Super-Resolution Reconstruction of Remote Sensing Images Based on GAN","2021","Proceedings of 2021 IEEE International Conference on Data Science and Computer Application, ICDSCA 2021","","","","270","274","4","10.1109/ICDSCA53499.2021.9649727","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124205370&doi=10.1109%2fICDSCA53499.2021.9649727&partnerID=40&md5=eeb613b46ef8e793b5294be68161c987","In recent years, the methods of super-resolution image reconstruction that based on deep learning have become a hot topic in research of computer vision. The methods of super-resolution image reconstruction that based on the Generative Adversarial Network (GAN) are not controlled in network generation, the models are easy to collapse, the generalization ability is undesirable, and the time complexity degree is too high. To fill these gaps, we propose a super-resolution image reconstruction method based on the GAN of encoding and decoding, which improves the quality of image reconstruction. First of all, our approach uses a design network with regularized structure to avoid model collapse. Then we build a generation network structure that based on encoding and decoding to suppress the uncontrollable defects of GAN network generated images. Finally, in the last layer of the generator, NN convolutional feature layer is included to replace the Softmax layer, which speeds up the training of the model. The experimental results show that the super-resolution remote sensing image reconstructed by the proposed method has higher reconstruction quality and better generalization ability in the DOTA training data sets. At the same time, the image reconstruction process can take much less time. © 2021 IEEE.","Decoding; Deep learning; Encoding (symbols); Image coding; Image enhancement; Image reconstruction; Optical resolving power; Remote sensing; Signal encoding; Coding and decoding; Encoding and decoding; Generalization ability; Hot topics; Image-based; Images reconstruction; In networks; Remote sensing images; Super-resolution image reconstruction; Super-resolution reconstruction; Generative adversarial networks","Coding and Decoding; GAN; Remote Sensing Images; Super Resolution Reconstruction","Conference paper","Final","","Scopus","2-s2.0-85124205370"
"Xu P.; Tang H.; Ge J.; Feng L.","Xu, Penglei (57223433215); Tang, Hong (36816706600); Ge, Jiayi (57223428712); Feng, Lin (57223435507)","57223433215; 36816706600; 57223428712; 57223435507","ESPC_NASUnet: An End-to-End Super-Resolution Semantic Segmentation Network for Mapping Buildings from Remote Sensing Images","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9429949","5421","5435","14","10.1109/JSTARS.2021.3079459","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105882016&doi=10.1109%2fJSTARS.2021.3079459&partnerID=40&md5=97dbbc35095a2c527b1f8a297fba3387","Higher resolution building mapping from lower resolution remote sensing images is in great demand due to the lack of higher resolution data access, especially in the context of disaster assessment. High resolution building layout map is crucial for emergency rescue after the disaster. The emergency response time would be reduced if detailed building footprints were delineated from more easily available low-resolution data. To achieve this goal, we propose a super-resolution semantic segmentation network called ESPC_NASUnet, which consists of a feature super-resolution module and a semantic segmentation module. To the best of authors' knowledge, this is the first work to systematically explore a deep learning-based approach to generate semantic maps with higher spatial resolution from lower spatial resolution remote sensing images in an end-to-end fashion. The experimental results for two datasets suggest that the proposed network is the best among four different end-to-end architectures in terms of both pixel-level metrics and object-level metrics. In terms of pixel-level $F$1-score, the improvements are greater than 0.068 and 0.055. Regarding the object-level $F$1-score, the disparities between ESPC_NASUnet and other end-to-end methods are more than 0.083 and 0.161 in the two datasets, respectively. Compared with stage-wise methods, our end-to-end network is less impacted by low-resolution input images. Finally, the proposed network produces building semantic maps comparable to those generated by semantic segmentation networks trained with high-resolution images and the ground truth utilizing the two datasets. © 2008-2012 IEEE.","Buildings; Deep learning; Disasters; Image resolution; Image segmentation; Mapping; Optical resolving power; Pixels; Semantic Web; Semantics; Building footprint; Emergency response time; End-to-end network; High resolution image; Learning-based approach; Remote sensing images; Semantic segmentation; Spatial resolution; building; image processing; mapping; remote sensing; segmentation; spatial resolution; Remote sensing","Building extraction; end-to-end network; remote sensing; super-resolution semantic segmentation (SRSS)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85105882016"
"Wang J.; Wu Y.; Wang L.; Wang L.; Alfarraj O.; Tolba A.","Wang, Jin (57200027740); Wu, Yiming (57221662991); Wang, Liu (57221664913); Wang, Lei (57070577400); Alfarraj, Osama (36772742100); Tolba, Amr (56442428300)","57200027740; 57221662991; 57221664913; 57070577400; 36772742100; 56442428300","Lightweight Feedback Convolution Neural Network for Remote Sensing Images Super-Resolution","2021","IEEE Access","9","","9328537","15992","16003","11","10.1109/ACCESS.2021.3052946","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099727591&doi=10.1109%2fACCESS.2021.3052946&partnerID=40&md5=971c6af71a498b155e1434669b204709","There are lots of image data in the field of remote sensing, most of which have low-resolution due to the limited image sensor. The super-resolution method can effectively restore the low-resolution image to the high-resolution image. However, the existing super-resolution method has both heavy computing burden and number of parameters. For saving costs, we propose the feedback ghost residual dense network (FGRDN), which considers the feedback mechanism as the framework to attain lower features through high-level refining. Further, for feature extraction, we replace the convolution of the residual dense blocks (RDBs) with ghost modules (GMs), which can remove the redundant channels and avoid the increase of parameters along with the network depth. Finally, the spatial and channel attention module (SCM) is employed in the end of the RDB to learn more useful information from features. Compared to other SOTA lightweight algorithms, our proposed algorithm can reach convergences more rapidly with fewer parameters, and the performance of the network can be markedly enhanced on the image texture and object contour reconstruction with better peak signal-to-noise ratio (PSNR) and structural similarity (SSIM). © 2013 IEEE.","Convolution; Feedback; Image enhancement; Image reconstruction; Neural networks; Optical resolving power; Parameter estimation; Remote sensing; Signal to noise ratio; Textures; Convolution neural network; Feedback mechanisms; High resolution image; Low resolution images; Peak signal to noise ratio; Remote sensing images; Structural similarity; Superresolution methods; Image texture","attention mechanism; feedback mechanism; ghost module; Remote sensing; super-resolution","Article","Final","","Scopus","2-s2.0-85099727591"
"Dou J.; Tu Z.; Peng X.","Dou, Jianfang (46960910900); Tu, Zimei (56623964400); Peng, Xishuai (56927291200)","46960910900; 56623964400; 56927291200","Single Image Super-resolution Reconstruction with Wavelet based Deep Residual Learning","2020","Proceedings of the 32nd Chinese Control and Decision Conference, CCDC 2020","","","9164678","4270","4275","5","10.1109/CCDC49329.2020.9164678","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091555006&doi=10.1109%2fCCDC49329.2020.9164678&partnerID=40&md5=51213779c450f2a96fb723dc33bce86b","We present a single-image super-resolution (SR) method for Remote Sensing Image based on deep learning within Discrete Wavelet Domain in this paper. Our method is inspired Residual Learning. Firstly, an input image is decomposed by single level 2D Discrete wavelet transform to get four sub-bands; The four sub-bands coefficients are feeding into the Deep Learning Residual Network to predict correspondingly residual images; Adding four sub-band images and residual images as the new sub-bands of 2D wavelet transform; Finally, uses the inverse 2D Discrete wavelet transform to get the final output Super Resolution HR image. Our proposed method performs better than existing methods in accuracy and visual improvements in our results are easily noticeable. © 2020 IEEE.","Discrete wavelet transforms; Image compression; Image reconstruction; Inverse problems; Learning systems; Optical resolving power; Remote sensing; 2-d discrete wavelet transforms; 2-D wavelet transform; Discrete wavelets; Remote sensing images; Residual images; Single-image super-resolution reconstruction; Super resolution; Visual improvements; Deep learning","Convolutional Neural Network; Deep Learning; Discrete Wavelet Transform; Residual Learning; Super Resolution","Conference paper","Final","","Scopus","2-s2.0-85091555006"
"Zhao N.; Shi J.; Wang P.; Jiang Z.; Zhang H.","Zhao, Ning (57323789600); Shi, Jiawei (57214073877); Wang, Pengrui (57210155510); Jiang, Zhiguo (35336923600); Zhang, Haopeng (54788751800)","57323789600; 57214073877; 57210155510; 35336923600; 54788751800","Deep-learning-based remote sensing video super-resolution for Jilin-1 satellite","2021","Proceedings of SPIE - The International Society for Optical Engineering","11862","","118620E","","","","10.1117/12.2599926","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118559483&doi=10.1117%2f12.2599926&partnerID=40&md5=7ef6b6990028a1bca27db3d6ddb1f7bf","Due to far imaging distance and relatively harsh imaging conditions, the spatial resolution of remote sensing data are relatively low. Images/videos super-resolution is of great significance to effectively improve the spatial resolution and visual effect of remote sensing data. In this paper, we propose a deep-learning-based video super-resolution method for Jilin-1 remote sensing satellite. We use explicit motion compensation method by calculating the optical flow through the optical flow estimation network and compensating the motion of the image through warp operation. After obtaining the multi-frame images after motion compensation, it is necessary to use multi-frame image fusion for super-resolution reconstruction. We performed super-resolution experiments with scale factor 4 on Jilin-1 video dataset. In order to explore suitable fusion method, we compared two kinds of image fusion methods in the super-resolution network, i.e. concatenation by channel and 3D convolution, without motion compensation. Experimental results show that 3D convolution achieves better super-resolution performance, and video super-resolution result is better than the compared single image super-resolution method. We also performed experiments with motion compensation by optical flow estimation network. Experimental results show that the difference between the image after motion compensation and the reference frame becomes smaller. This indicates that the explicit motion compensation method can compensate the difference between the frames due to the target motion to a certain extent.  © 2021 SPIE.","Convolution; Deep learning; Image enhancement; Image fusion; Image resolution; Optical flows; Remote sensing; 3d convolu-tion; Deep learning; Optical ow estimation network; Optical-; Remote sensing data; Remote-sensing; Spatial resolution; Superresolution; Superresolution methods; Video super-resolution; Motion compensation","3D convolu-Tion; Deep learning; Optical ow estimation network; Remote sensing; Video super-resolution","Conference paper","Final","","Scopus","2-s2.0-85118559483"
"Zhu Q.; Fan X.; Zhong Y.; Guan Q.; Zhang L.; Li D.","Zhu, Qiqi (56420945500); Fan, Xin (57222248289); Zhong, Yanfei (12039673900); Guan, Qingfeng (55838509944); Zhang, Liangpei (8359720900); Li, Deren (57212271839)","56420945500; 57222248289; 12039673900; 55838509944; 8359720900; 57212271839","Super Resolution Generative Adversarial Network Based Image Augmentation for Scene Classification of Remote Sensing Images","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324043","573","576","3","10.1109/IGARSS39084.2020.9324043","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102001018&doi=10.1109%2fIGARSS39084.2020.9324043&partnerID=40&md5=2c6d3f95bad091ad3ea96988131867ed","High spatial resolution remote sensing image (RSI) scene classification, aimed at automatically labelling images with the given semantic categories, has been a hot issue. As it's difficult for RSI to quickly obtain a large number of training samples from a specific area. Traditional scene classification researches were mainly using deep learning models to transfer natural images to RSI. Considering the differences between natural images and RSI, we trained several Super Resolution GAN models by using different resolution RSI data from Google earth image. This paper proposed a novel SRGAN-CNN framework. Through transferring the data with scene classification dataset to obtain high resolution fake RSI. The experimental results demonstrate that the proposed framework can enhance transfer effect and help improve the accuracy of scene classification using low resolution RSI. © 2020 IEEE.","Classification (of information); Deep learning; Geology; Optical resolving power; Remote sensing; Semantics; Adversarial networks; Different resolutions; High spatial resolution; Remote sensing images; Scene classification; Semantic category; Super resolution; Training sample; Image classification","deep learning; Image super resolution; remote sensing images; scene classification","Conference paper","Final","","Scopus","2-s2.0-85102001018"
"Qize L.; Chaoqi H.; Jingbo W.","Qize, Li (57225207053); Chaoqi, He (57225206064); Jingbo, Wei (57225216121)","57225207053; 57225206064; 57225216121","Spatiotemporal fusion of one-pair image based on enhanced super-resolution network; [基于增强超分辨率网络的单对图像时空融合]","2021","Laser and Optoelectronics Progress","58","22","2228006","","","","10.3788/LOP202158.2228006","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119289945&doi=10.3788%2fLOP202158.2228006&partnerID=40&md5=e90b2291b3bffb2db3f1233aaf4c180a","Due to high-quality earth observation requires spatiotemporal continuous high-resolution remote sensing images, the research on spatiotemporal fusion is widely carried out and focused on Landsat and MODIS satellites. At present, the method of spatiotemporal fusion using convolutional neural networks has been proposed, but the network is shallow, so the fusion performance is limited. Aiming at the most widely used one-pair image spatiotemporal fusion, a new spatiotemporal fusion method based on deep neural network is established. Firstly, the basic network framework consists of two cascaded upsamplers with quadruple magnification to approximate the spatial difference and sensor difference between Landsat and MODIS satellites. Then, the residual error between the reconstructed image and the real image is learned by the convolutional neural network to make the reconstructed image closer to the real image. Moreover, the time prediction is carried out by highpass moduation strategy. Finally, the proposed method is tested on different Landsat and MODIS satellite images and compared with many spatiotemporal fusion algorithms. The experimental results show that, compared with the existing fusion algorithms, the reconstruction effect of the proposed method is better and the processing speed is faster. © 2021 Universitat zu Koln. All rights reserved.","","Convolutional neural networks; Deep residual networks; Landsat; Remote sensing; Spatiotemporal fusion","Article","Final","","Scopus","2-s2.0-85119289945"
"Saha S.; Kondmann L.; Song Q.; Zhu X.X.","Saha, Sudipan (57205200597); Kondmann, Lukas (57226870520); Song, Qian (57226717244); Zhu, Xiao Xiang (55696622200)","57205200597; 57226870520; 57226717244; 55696622200","Change Detection in Hyperdimensional Images Using Untrained Models","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","","11029","11041","12","10.1109/JSTARS.2021.3121556","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118236425&doi=10.1109%2fJSTARS.2021.3121556&partnerID=40&md5=4123afd33fd7cd445071d67ed8cf2d8e","Deep transfer-learning-based change detection methods are dependent on the availability of sensor-specific pretrained feature extractors. Such feature extractors are not always available due to lack of training data, especially for hyperspectral sensors and other hyperdimensional images. Moreover models trained on easily available multispectral (RGB/RGB-NIR) images cannot be reused on such hyperdimensional images due to their irregular number of bands. While hyperdimensional images show large number of spectral bands, they generally show much less spatial complexity, thus reducing the requirement of large receptive fields of convolution filters. Recent works in the computer vision have shown that even untrained deep models can yield remarkable result in some tasks like super-resolution and surface reconstruction. This motivates us to make a bold proposition that untrained lightweight deep model, initialized with some weight initialization strategy, can be used to extract useful semantic features from bi-temporal hyperdimensional images. Based on this proposition, we design a novel change detection framework for hyperdimensional images by extracting bitemporal features using an untrained model and further comparing the extracted features using deep change vector analysis to distinguish changed pixels from the unchanged ones. We further use the deep change hypervectors to cluster the changed pixels into different semantic groups. We conduct experiments on four change detection datasets: three hyperspectral datasets and a hyperdimensional polarimetric synthetic aperture radar dataset. The results clearly demonstrate that the proposed method is suitable for change detection in hyperdimensional remote sensing data.  © 2008-2012 IEEE.","Deep learning; Feature extraction; Hyperspectral imaging; Pixels; Radar imaging; Radar target recognition; Remote sensing; Semantics; Synthetic aperture radar; Tracking radar; Change detection; Deep image prior; Deep learning; Detection methods; Feature extractor; Features extraction; Hyperdimensional image; Image priors; Transfer learning; data set; machine learning; modeling; multispectral image; pixel; remote sensing; synthetic aperture radar; Spectroscopy","Change detection (CD); deep image prior; deep learning; hyperdimensional images; hyperspectral images","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85118236425"
"Chen B.; Li J.; Jin Y.","Chen, Bin (57210117458); Li, Jing (57207737643); Jin, Yufang (7404457584)","57210117458; 57207737643; 7404457584","Deep learning for feature-level data fusion: Higher resolution reconstruction of historical landsat archive","2021","Remote Sensing","13","2","167","1","23","22","10.3390/rs13020167","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099179435&doi=10.3390%2frs13020167&partnerID=40&md5=16cb0d20fb4cfacbe0f3984caadbbf53","Long-term record of fine spatial resolution remote sensing datasets is critical for monitoring and understanding global environmental change, especially with regard to fine scale processes. However, existing freely available global land surface observations are limited by medium to coarse resolutions (e.g., 30 m Landsat) or short time spans (e.g., five years for 10 m Sentinel-2). Here we developed a feature-level data fusion framework using a generative adversarial network (GAN), a deep learning technique, to leverage the overlapping Landsat and Sentinel-2 observations during 2016–2019, and reconstruct 10 m Sentinel-2 like imagery from 30 m historical Landsat archives. Our tests with both simulated data and actual Landsat/Sentinel-2 imagery showed that the GANbased fusion method could accurately reconstruct synthetic Landsat data at an effective resolution very close to that of the real Sentinel-2 observations. We applied the GAN-based model to two dynamic systems: (1) land over dynamics including phenology change, cropping rotation, and water inundation; and (2) human landscape changes such as airport construction, coastal expansion, and urbanization, via historical reconstruction of 10 m Landsat observations from 1985 to 2018. The resulting comparison further validated the robustness and efficiency of our proposed framework. Our pilot study demonstrated the promise of transforming 30 m historical Landsat data into a 10 m Sentinel-2-like archive with advanced data fusion. This will enhance Landsat and Sentinel-2 data science, facilitate higher resolution land cover and land use monitoring, and global change research. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Data fusion; Data Science; Forestry; Image reconstruction; Land use; Metadata; Remote sensing; Adversarial networks; Airport construction; Effective resolutions; Global environmental change; Global land surface; Historical reconstruction; Learning techniques; Spatial resolution; Deep learning","Data fusion; Data reconstruction; GAN; Machine learning; Super resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85099179435"
"Wang P.; Bayram B.; Sertel E.","Wang, Peijuan (57224642089); Bayram, Bulent (15130508500); Sertel, Elif (21934838300)","57224642089; 15130508500; 21934838300","Super-resolution of remotely sensed data using channel attention based deep learning approach","2021","International Journal of Remote Sensing","42","16","","6050","6067","17","10.1080/01431161.2021.1934598","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108058190&doi=10.1080%2f01431161.2021.1934598&partnerID=40&md5=e7957f923f18adbdb5fa4b1e67e8901f","Remote Sensing image super-resolution aims to improve the spectral and/or spatial resolution of the satellite imageries. In order to improve the performance of the CNN-based super-resolution methods, increasing the depth of the network is commonly used. However, this increases computational complexity and training difficulties only with small improvement of the performance. Meanwhile, the CNN kernels treat all the channels equally and cannot take the advantage of the abundant high-frequency information contained in the low-resolution images. To address these problems, Channel attention is one of the mechanisms and has been proven to be useful in many tasks. In this research, we proposed a channel attention-based framework for Remote Sensing Image Super-resolution (CARS) by constructing a novel residual channel attention block (RCAB) to further extract the features. In addition, a densely residual channel attention block (RCAB+) and densely residual spatial attention block (RSAB) were proposed to improve the performance. We adopted a post-upsampling architecture to reduce the computational complexity and time cost. Moreover, transfer learning strategy (CARS+T) was introduced to further improve the SR performance and proved to generate finer edge details. Experimentally, our proposed CARS, CARS_SA and CARS+T achieved competitive quantitative and qualitative results both on Data Fusion Contest Dataset and Pleiades Dataset that we created. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","Coherent scattering; Complex networks; Computational complexity; Data fusion; Image enhancement; Optical resolving power; Remote sensing; Transfer learning; High-frequency informations; Learning approach; Low resolution images; Remote sensing images; Remotely sensed data; Spatial attention; Spatial resolution; Superresolution methods; image resolution; machine learning; pattern recognition; remote sensing; satellite imagery; spatial resolution; spectral resolution; Deep learning","","Article","Final","","Scopus","2-s2.0-85108058190"
"","","","IGARSS 2021 - 2021 IEEE International Geoscience and Remote Sensing Symposium, Proceedings","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","","","8476","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126046485&partnerID=40&md5=1ecc3fc960ade7a320fbb6c5448bc6f5","The proceedings contain 2144 papers. The topics discussed include: the eigenvector-eigenvalue identity and radar polarimetry; on hyperspectral unmixing; sparse unmixing of hyperspectral data: the legacy of Sunsal; sparse representations and dictionary learning: from image fusion to motion estimation; on hyperspectral super-resolution; women in Copernicus: recommendations from women testimonials; women in geographic information sector; GEOCHICAS, improving how open mapping represents the world; space girls space women – a unique exhibition tours Nereus-regions and promotes female role models in space; and reaching stage 4 of vegetation product validation by exploiting the synergy between UAV, HR satellites and IoT measurements.","","","Conference review","Final","","Scopus","2-s2.0-85126046485"
"Zhang M.; Sun X.; Zhu Q.; Zheng G.","Zhang, Meilin (57687082800); Sun, Xiongli (57213190878); Zhu, Qiqi (56420945500); Zheng, Guizhou (57687607600)","57687082800; 57213190878; 56420945500; 57687607600","A SURVEY OF HYPERSPECTRAL IMAGE SUPER-RESOLUTION TECHNOLOGY","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","4476","4479","3","10.1109/IGARSS47720.2021.9554409","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128005026&doi=10.1109%2fIGARSS47720.2021.9554409&partnerID=40&md5=95cd93b6a72ca073c8ecb1efe95bf505","Hyperspectral images (HSIs) have very high spectral resolution, which can reflect the characteristics of different materials well. However, compared with RGB image or multispectral image (MSI), the spatial resolution of HSI is much lower, which limits its applications. Therefore, many super-resolution (SR) techniques have been proposed to reconstruct HSI with high spatial resolution image. To the best of our knowledge, there has not, to date, that been a study aimed at expatiating and summarizing the current research situation. Therefore, this is our motivation in this survey. In view of the promising development prospects in this field, this paper systematically reviews the existing SR methods of HSI. Specifically, two major categories are summarized, one is fusion-based methods, and the other is single HSI SR methods. At the end of the paper, several future development directions for HSI SR are given. © 2021 IEEE","Deep learning; Image resolution; Remote sensing; Spectral resolution; Spectroscopy; Surveys; Deep learning; High spectral resolution; Hyperspectral remote sensing; Image super resolutions; Multispectral images; RGB images; Singe hyperspectral image super-resolution; Spatial resolution; Superresolution methods; Image fusion","Deep learning; Hyperspectral remote sensing; Image fusion; Image super-resolution; Singe HSI SR","Conference paper","Final","","Scopus","2-s2.0-85128005026"
"Cheong J.W.; Kuthethoor P.; Dempster A.G.","Cheong, Joon Wayn (36085972100); Kuthethoor, Prahalad (57222240950); Dempster, Andrew G. (7006256792)","36085972100; 57222240950; 7006256792","Validation of Super-resolution GNSS-R using an Airborne Field Trial","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324368","5929","5932","3","10.1109/IGARSS39084.2020.9324368","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101997650&doi=10.1109%2fIGARSS39084.2020.9324368&partnerID=40&md5=c3c959a826e42eeb8dd17a30df613088","Conventional GNSS-R uses both coherent and noncoherent integration to obtain the Delay-Doppler map (DDM). In the field of phased array angle-of-arrival estimation, this is akin to the conventional beam-forming technique. It is also well known that super-resolution techniques such as MUSIC can obtain higher accuracy than conventional beamforming especially in the case of multiple signals. In this paper, we explore how this technique can be adapted to GNSS-R to obtain high resolution DDM representations. Its primary application will be to improve upon conventional GNSS-R altimetry. Further extrapolation of this result can also be used to isolate the DDM contributions of sea targets from sea clutter that reside within the same iso-delay region of the DDM. Airborne field trials conducted on 4th November 2011 are processed using both conventional GNSS-R and our proposed method that shows a clear improvement in its peak gradient, an important criterion for estimating a signal component's code delay. We further show a real-world example of a DDM formed by two distinct contributions that otherwise would not be detectable using the conventional DDM. © 2020 IEEE.","Beamforming; Geology; Optical resolving power; Salinity measurement; Angle of arrival estimation; Conventional beamforming; Delay-doppler maps; High resolution; Non coherent integration; Sea clutters; Signal components; Super resolution; Remote sensing","","Conference paper","Final","","Scopus","2-s2.0-85101997650"
"Choi Y.; Kim Y.","Choi, Yeonju (57215967828); Kim, Yongwoo (57202143770)","57215967828; 57202143770","A No-Reference Super Resolution for Satellite Image Quality Enhancement for KOMPSAT-3","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324422","220","223","3","10.1109/IGARSS39084.2020.9324422","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101979563&doi=10.1109%2fIGARSS39084.2020.9324422&partnerID=40&md5=384cef2b39294aff7fe366ed2413d191","Recently, a deep learning based super-resolution (SR) technology has been applied to satellite images to improve spatial resolution and sharpness, and to increase extractable information. In this paper, we propose a no-reference single image super-resolution method that improves the image quality by doubling spatial resolution of Korea Multi-Purpose Satellite-3 (K3), achieving a ground sampling distance (GSD) of 0.7 m. When training SR networks, the proposed method generates low-resolution (LR) images by applying the degradation model to K3 images and creates enhanced high-resolution images (HRe) by applying the top and bottom hat transformation to the original high-resolution (HRo) images. As a result of applying SR to the original K3 image, it was possible to obtain an image with improved quality. Additionally, as a result of testing the Baotou area used for satellite image quality evaluation, it was confirmed that the resolution is similar to the spatial resolution of Korea Multi-Purpose Satellite-3A (K3A), which is a GSD of 0.55 m. © 2020 IEEE.","Deep learning; Geology; Image quality; Image resolution; Optical resolving power; Remote sensing; Rhenium compounds; Satellites; Bottom hat transformation; Degradation model; Ground sampling distances; High resolution image; Korea multi-purpose satellites; Learning-based super-resolution; Low resolution images; Spatial resolution; Image enhancement","deep learning; KOMPSAT-3; satellite; super-resolution; top and bottom hat","Conference paper","Final","","Scopus","2-s2.0-85101979563"
"Huang Y.; Jiang Z.; Wang Q.; Jiang Q.; Pang G.","Huang, Yongsong (57214838902); Jiang, Zetao (24512367900); Wang, Qingzhong (57209217850); Jiang, Qi (57216755792); Pang, Guoming (57271443900)","57214838902; 24512367900; 57209217850; 57216755792; 57271443900","Infrared Image Super-Resolution via Heterogeneous Convolutional WGAN","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13032 LNAI","","","461","472","11","10.1007/978-3-030-89363-7_35","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119336194&doi=10.1007%2f978-3-030-89363-7_35&partnerID=40&md5=76d0ba3806088d01010ba8bc8d086b7a","Image super-resolution is important in many fields, such as surveillance and remote sensing. However, infrared (IR) images normally have low resolution since the optical equipment is relatively expensive. Recently, deep learning methods have dominated image super-resolution and achieved remarkable performance on visible images; however, IR images have received less attention. IR images have fewer patterns, and hence, it is difficult for deep neural networks (DNNs) to learn diverse features from IR images. In this paper, we present a framework that employs heterogeneous convolution and adversarial training, namely, heterogeneous kernel-based super-resolution Wasserstein GAN (HetSRWGAN), for IR image super-resolution. The HetSRWGAN algorithm is a lightweight GAN architecture that applies a plug-and-play heterogeneous kernel-based residual block. Moreover, a novel loss function that employs image gradients is adopted, which can be applied to an arbitrary model. The proposed HetSRWGAN achieves consistently better performance in both qualitative and quantitative evaluations. According to the experimental results, the whole training process is more stable. © 2021, Springer Nature Switzerland AG.","Deep neural networks; Generative adversarial networks; Infrared imaging; Optical data processing; Optical resolving power; Remote sensing; Heterogeneous kernel-based convolution; Image super resolutions; Images processing; Learning methods; Lower resolution; Optical equipment; Performance; Remote-sensing; Superresolution; Visible image; Convolution","Generative adversarial networks; Heterogeneous kernel-based convolution; Image processing; Infrared image; Super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85119336194"
"Li Y.; Iwamoto Y.; Lin L.; Chen Y.-W.","Li, Yinhao (57202580109); Iwamoto, Yutaro (54408573200); Lin, Lanfen (7404131803); Chen, Yen-Wei (56036268200)","57202580109; 54408573200; 7404131803; 56036268200","Parallel-Connected Residual Channel Attention Network for Remote Sensing Image Super-Resolution","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12628 LNCS","","","18","30","12","10.1007/978-3-030-69756-3_2","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104396519&doi=10.1007%2f978-3-030-69756-3_2&partnerID=40&md5=fcc5451e1688f26520a5938687dbee4a","In recent years, convolutional neural networks (CNNs) have obtained promising results in single-image super-resolution (SR) for remote sensing images. However, most existing methods are inadequate for remote sensing image SR due to the high computational cost required. Therefore, enhancing the representation ability with fewer parameters and a shorter prediction time is a challenging and critical task for remote sensing image SR. In this paper, we propose a novel CNN called a parallel-connected residual channel attention network (PCRCAN). Specifically, inspired by group convolution, we propose a parallel module with feature aggregation modules in PCRCAN. The parallel module significantly reduces the model parameters and fully integrates feature maps by widening the network architecture. In addition, to reduce the difficulty of training a complex deep network and improve model performance, we use a residual channel attention block as the basic feature mapping unit instead of a single convolutional layer. Experiments on a public remote sensing dataset UC Merced land-use dataset revealed that PCRCAN achieved higher accuracy, efficiency, and visual improvement than most state-of-the-art methods. © 2021, Springer Nature Switzerland AG.","Computer vision; Convolution; Convolutional neural networks; Image enhancement; Land use; Network architecture; Optical resolving power; Computational costs; Feature aggregation; Model performance; Parallel-connected; Remote sensing images; Shorter prediction; State-of-the-art methods; Visual improvements; Remote sensing","","Conference paper","Final","","Scopus","2-s2.0-85104396519"
"Zhang X.; Zhang A.; Li M.; Liu L.; Kang X.","Zhang, Xizhen (57211274537); Zhang, Aiwu (7402772582); Li, Mengnan (57218572608); Liu, Lulu (57214777362); Kang, Xiaoyan (57845353500)","57211274537; 7402772582; 57218572608; 57214777362; 57845353500","Restoration and calibration of tilting hyperspectral super-resolution image","2020","Sensors (Switzerland)","20","16","4589","1","21","20","10.3390/s20164589","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089613119&doi=10.3390%2fs20164589&partnerID=40&md5=782d5ac251964859e2ce8ea47e6c54af","Tilting sampling is a novel sampling mode for achieving a higher resolution of hyperspectral imagery. However, most studies on the tilting image have only focused on a single band, which loses the features of hyperspectral imagery. This study focuses on the restoration of tilting hyperspectral imagery and the practicality of its results. First, we reduced the huge data of tilting hyperspectral imagery by the p-value sparse matrix band selection method (pSMBS). Then, we restored the reduced imagery by optimal reciprocal cell combined modulation transfer function (MTF) method. Next, we built the relationship between the restored tilting image and the original normal image. We employed the least square method to solve the calibration equation for each band. Finally, the calibrated tilting image and original normal image were both classified by the unsupervised classification method (K-means) to confirm the practicality of calibrated tilting images in remote sensing applications. The results of classification demonstrate the optimal reciprocal cell combined MTF method can effectively restore the tilting image and the calibrated tiling image can be used in remote sensing applications. The restored and calibrated tilting image has a higher resolution and better spectral fidelity. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Calibration; Least squares approximations; Optical transfer function; Remote sensing; Restoration; Spectroscopy; Calibration equations; Combined modulation; Higher resolution; Hyper-spectral imageries; Least square methods; Remote sensing applications; Spectral fidelity; Unsupervised classification; Image reconstruction","Calibration; Modulation transfer function (MTF); Optimal reciprocal cell; Spectral fidelity; The least square method; Tilting sampling mode","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85089613119"
"Gao L.; Sun H.-M.; Cui Z.; Du Y.-B.; Sun H.-B.; Jia R.-S.","Gao, Li (57221482568); Sun, Hong-Mei (55729286100); Cui, Zhe (57218325391); Du, Yan-Bin (57221413033); Sun, Hai-Bin (57207025120); Jia, Rui-Sheng (25927894300)","57221482568; 55729286100; 57218325391; 57221413033; 57207025120; 25927894300","Super-resolution reconstruction of single remote sensing images based on residual channel attention","2021","Journal of Applied Remote Sensing","15","1","016513","","","","10.1117/1.JRS.15.016513","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103623109&doi=10.1117%2f1.JRS.15.016513&partnerID=40&md5=4933992be2b6797c799b6325aa5ce724","The existing methods of remote sensing image super-resolution reconstruction based on deep learning have some problems, such as insufficient feature extraction abilities, blurred image edges, and difficult model training. To solve these problems, a super-resolution reconstruction method combining residual channel attention (CA) is proposed. Based on the framework of generative adversarial networks, the residual structure is designed to enhance the ability of deep feature extraction ability for remote sensing images. The CA module is added to extract the deep feature information of remote sensing images, and the shallow features and deep features are fused using the skip connection. The perceptual loss function is combined with the loss function represented by the Wasserstein distance to improve the stability of model training. The experimental results show that this method is superior to the comparison algorithms in the objective evaluation criteria of the peak-signal-To-noise ratio and structural similarity of the reconstructed remote sensing images. After optimizing the model training process, the reconstructed remote sensing images are visually clearer and have sharper edges. © 2021 Society of Photo-Optical Instrumentation Engineers (SPIE).","Deep learning; Extraction; Feature extraction; Image enhancement; Image reconstruction; Optical resolving power; Signal to noise ratio; Adversarial networks; Feature information; Objective evaluation criteria; Peak signal to noise ratio; Remote sensing images; Structural similarity; Super resolution reconstruction; Wasserstein distance; Remote sensing","generative adversarial network; remote sensing image; residual channel attention; super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85103623109"
"Han X.; He T.; Ong Y.-S.; Zhong Y.","Han, Xiaobing (55267754400); He, Tiantian (56403933800); Ong, Yew-Soon (7006735298); Zhong, Yanfei (12039673900)","55267754400; 56403933800; 7006735298; 12039673900","Precise object detection using adversarially augmented local/global feature fusion","2020","Engineering Applications of Artificial Intelligence","94","","103710","","","","10.1016/j.engappai.2020.103710","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088228053&doi=10.1016%2fj.engappai.2020.103710&partnerID=40&md5=7c98cb2fc7e7c624b2319b95047dca33","Object detection, which aims at recognizing or locating the objects of interest in remote sensing imagery with high spatial resolutions (HSR), plays a significant role in many real-world scenarios, e.g., environment monitoring, urban planning, civil infrastructure construction, disaster rescuing, and geographic image retrieval. As a long-lasting challenging problem in both machine learning and geoinformatics communities, many approaches have been proposed to tackle it. However, previous methods always overlook the abundant information embedded in the HSR remote sensing images. The effectiveness of these methods, e.g., accuracy of detection, is therefore limited to some extent. To overcome the mentioned challenge, in this paper, we propose a novel two-phase deep framework, dubbed GLGOD-Net, to effectively detect meaningful objects in HSR images. GLGOD-Net firstly attempts to learn the enhanced deep representations from super-resolution image data. Fully utilizing the augmented image representations, GLGOD-Net then learns the fused representations into which both local and global latent features are implanted. Such fused representations learned by GLGOD-Net can be used to precisely detect different objects in remote sensing images. The proposed framework has been extensively tested on a real-world HSR image dataset for object detection and has been compared with several strong baselines. The remarkable experimental results validate the effectiveness of GLGOD-Net. The success of GLGOD-Net not only advances the cutting-edge of image data analytics, but also promotes the corresponding applicability of deep learning in remote sensing imagery. © 2020","Data Analytics; Deep learning; Image enhancement; Image retrieval; Object recognition; Remote sensing; Civil infrastructures; Environment monitoring; Geographic image retrieval; High spatial resolution; Real-world scenario; Remote sensing imagery; Remote sensing images; Super resolution; Object detection","Data augmentation; Geospatial object detection; High spatial resolution (HSR) remote sensing imagery; Local/global feature fusion; Super resolution generative adversarial network","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85088228053"
"Liu X.; Wang M.","Liu, Xiaoming (37045902200); Wang, Menghua (55814484000)","37045902200; 55814484000","Super-Resolution of VIIRS-Measured Ocean Color Products Using Deep Convolutional Neural Network","2021","IEEE Transactions on Geoscience and Remote Sensing","59","1","9097401","114","127","13","10.1109/TGRS.2020.2992912","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098732350&doi=10.1109%2fTGRS.2020.2992912&partnerID=40&md5=7a3fb13a690369e819f366076612c357","Since its launch in October 2011, the Visible Infrared Imaging Radiometer Suite (VIIRS) onboard the Suomi National Polar-orbiting Partnership (SNPP) satellite has provided high quality global ocean color products, which include normalized water-leaving radiance spectra nLw (λ) of six moderate (M) bands (M1-M6) at the wavelengths of 410, 443, 486, 551, 671, and 745 nm with a spatial resolution of 750-m, and one imagery (I) band at a wavelength of 638 nm with a spatial resolution of 375-m. Because the high-resolution I-band measurements are highly correlated spectrally to those of M-band data, it can be used as a guidance to super-resolve the M-band nLw (λ) imagery from 750-to 375-m spatial resolution. Super-resolving images from coarse spatial resolution to finer ones have been a field of very active research in recent years. However, no previous studies have been applied to satellite ocean color remote sensing, in particular, for VIIRS ocean color applications. In this study, we employ the deep convolutional neural network (CNN) technique to glean the high-frequency content from the VIIRS I1 band and transfer to super-resolved M-band ocean color images. The network is trained to super-resolve each of the VIIRS six M-bands nLw (λ) separately. In our results, the super-resolved (375-m) nLw (λ) images are much sharper and show finer spatial structures than the original images. Quantitative evaluations show that biases between the super-resolved and original nLw (λ) images are small for all bands. However, errors in the super-resolved nLw (λ) images are wavelength-dependent. The smallest error is found in the super-resolved nLw (551) and nLw (671) images, and error increases as the wavelength decreases from 486 to 410 nm. The results show that the networks have the capability to capture the correlations of the M-band and the I1 band images to super-resolved M-band images.  © 1980-2012 IEEE.","Color; Convolution; Deep neural networks; Errors; Image resolution; Oceanography; Orbits; Remote sensing; Satellite imagery; Thermography (imaging); High frequency HF; Ocean color products; Quantitative evaluation; Satellite Ocean Color; Spatial resolution; Spatial structure; Visible infrared imaging radiometer suites; Water-leaving radiances; algorithm; artificial neural network; ocean color; VIIRS; Convolutional neural networks","Deep convolutional neural network (CNN); image fusion; ocean color remote sensing; super-resolution; Visible Infrared Imaging Radiometer Suite (VIIRS)","Article","Final","","Scopus","2-s2.0-85098732350"
"Hou X.; Wang P.; An W.","Hou, Xin (57222592069); Wang, Pu (55718491300); An, Wei (7006908300)","57222592069; 55718491300; 7006908300","Frequency domain super-resolution of staggered imaging system","2021","Proceedings of SPIE - The International Society for Optical Engineering","11781","","117810Y","","","","10.1117/12.2590635","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103348228&doi=10.1117%2f12.2590635&partnerID=40&md5=2a285e31772282c565697fd119e0280f","The staggered imaging camera is an important kind of remote sensing satellite camera. The staggered imaging technology can improve the spatial resolution of the camera without changing the focal length and pixel size of the optical system. However, the image resolution directly obtained by the staggered imaging camera is not enough. The existing traditional super-resolution methods have certain interpretability; the performance of deep learning super-resolution is related to the quality and quantity of training data set. There is no suitable data set for the remote sensing image generated by the staggered imaging system. So the frequency domain super-resolution technology is proposed for the image of the staggered imaging system. Low resolution remote sensing image can be regarded as the result of effective shift and sum of high-resolution image in time domain. There is a certain phase difference between low-resolution remote sensing image and high-resolution image in frequency domain. The time-shift property of two-dimensional image Fourier transform is used to find the difference between low-resolution image and high-resolution real image in frequency domain. The super resolution image is obtained by compensation coefficient. The frequency domain super-resolution algorithm is sensitive to noise. In order to suppress the noise interference, a special frequency domain filter is designed to filter the noise. It is verified by SPOT5 data that the frequency domain super-resolution can completely recover the noiseless image. Under the condition of image noise, the peak signal-to-noise ratio and the structure similarity can reach 35.754dB and 0.97 in 1.001 seconds. © SPIE. Downloading of the abstract is permitted for personal use only.","Cameras; Computerized tomography; Deep learning; Frequency domain analysis; Imaging systems; Optical resolving power; Optical systems; Remote sensing; Signal to noise ratio; Compensation coefficients; Frequency domain filters; Peak signal to noise ratio; Remote sensing images; Remote sensing satellites; Super resolution algorithms; Superresolution methods; Two dimensional images; Image resolution","Four point staggered imaging; Frequency domain; Lossless recovery; Peak signal to noise ratio","Conference paper","Final","","Scopus","2-s2.0-85103348228"
"Wang C.; Ruifei Z.; Bai Y.; Zhang P.; Fan H.","Wang, Chao (57222581465); Ruifei, Zhu (56646483700); Bai, Yang (57695846100); Zhang, Peng (57750475600); Fan, Haiyang (57297816400)","57222581465; 56646483700; 57695846100; 57750475600; 57297816400","Single-frame super-resolution for high resolution optical remote-sensing data products","2021","International Journal of Remote Sensing","42","21","","8099","8123","24","10.1080/01431161.2021.1971790","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117227562&doi=10.1080%2f01431161.2021.1971790&partnerID=40&md5=57a39bea9cd92f2d85fce3864c3bf395","The resolution of remote-sensing images is directly related to the application value of data products. Due to differences in imaging characteristics between digital cameras and remote-sensing cameras, the existing network models cannot get the best super resolution (SR) results of satellite images. In response to the requirements of remote-sensing image production, we propose a single image super-resolution (SISR) reconstruction method for specific type of remote-sensing satellite. First, we measure and model the imaging degradation phenomenon of remote-sensing satellite, including the image blur and noise model. Then, high-quality aerial images are down-sampled and degraded to construct paired training image datasets. We chose the most popular Enhanced Super-Resolution Generative Adversarial Networks (ESRGAN) as the basic structure and optimized the number of Residual-in-Residual Dense Block (RRDB) modules to further improve the processing efficiency. Finally, we perform a series of quantitative measurements of the SR image results, including image interpretation capability, reconstruction accuracy, ground resolution distance, and data processing efficiency, using higher resolution remote-sensing images as the benchmark. The experimental results demonstrate that our proposed method has higher interpretation capability and reconstruction accuracy for the SR processing of specific type remote-sensing satellite. Our proposed method is evaluated within a real satellite image product, that demonstrated it has the capability of pipeline super-resolution processing of remote sensing data products. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","Antennas; Data handling; Image reconstruction; Optical resolving power; Pipeline processing systems; Remote sensing; Satellites; Data products; Imaging characteristics; Optical remote sensing data; Reconstruction accuracy; Remote sensing cameras; Remote sensing images; Remote sensing satellites; Satellite images; Single frame super resolutions; Superresolution; digital image; image resolution; quantitative analysis; remote sensing; satellite data; satellite imagery; Efficiency","","Article","Final","","Scopus","2-s2.0-85117227562"
"Isa S.M.; Suharjito; Kusuma G.P.; Cenggoro T.W.","Isa, Sani M. (57216658927); Suharjito (55390566600); Kusuma, Gede Putera (24474615100); Cenggoro, Tjeng Wawan (56411932900)","57216658927; 55390566600; 24474615100; 56411932900","Supervised conversion from Landsat-8 images to Sentinel-2 images with deep learning","2021","European Journal of Remote Sensing","54","1","","182","208","26","10.1080/22797254.2021.1875267","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103200799&doi=10.1080%2f22797254.2021.1875267&partnerID=40&md5=c3c618c3dfc398594a7a075ea23973a4","In a specific remote sensing study design, the utilization of images from a particular satellite is necessary. However, the images might be unavailable in a certain time range. Therefore, a conversion method from available remote sensing images at the time range is required. In this paper, we proposed machine learning models that are capable to convert Landsat-8 images to Sentinel-2 images. The models are inspired by the advancement of super-resolution model based on Deep learning. The result of this study shows that the proposed models can predict Sentinel-2 images which are quantitatively and qualitatively similar to the original images. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Learning systems; Remote sensing; Conversion methods; LANDSAT; Machine learning models; Original images; Remote sensing images; Study design; Super-resolution models; Time range; image resolution; Landsat; prediction; remote sensing; satellite data; Sentinel; supervised learning; Deep learning","deep learning; Landsat-8; remote sensing; Satellite image conversion; Sentinel-2","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85103200799"
"Zhao J.; Huang T.; Zhou Z.","Zhao, Jianwei (36618500900); Huang, Taoye (57211117496); Zhou, Zhenghua (55511512300)","36618500900; 57211117496; 55511512300","Hyperspectral image super-resolution using recursive densely convolutional neural network with spatial constraint strategy","2020","Neural Computing and Applications","32","18","","14471","14481","10","10.1007/s00521-019-04484-3","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073971702&doi=10.1007%2fs00521-019-04484-3&partnerID=40&md5=32ddb94098376337610fb8fc71f1c659","Hyperspectral images (HSIs) have been widely applied in real life, such as remote sensing, geological exploration, and so on. Many deep networks have been proposed to raise the resolution of HSIs for their better applications. But training their huge number of model parameters (weights and biases) needs more memory for storage and computation, which may bring some difficulties when they are applied in mobile terminal devices. In order to condense the deep networks and still keep the reconstruction effect, this paper proposes a compact deep network for HSI super-resolution (SR) by fusing the idea of recursion, dense connection, and spatial constraint (SCT) strategy. We name this method as recursive densely convolutional neural network with a spatial constraint strategy (SCT-RDCNN). The proposed method uses a novel designed recursive densely convolutional neural network (RDCNN) to learn the mapping relation between the low-resolution (LR) HSI and the high-resolution (HR) HSI and then adopts the SCT to improve the determined HR HSI.Compared with some existing deep-network-based HSI SR methods, the proposed method can use much less parameters (weight and bias) to attain or exceed the performance of methods with similar convolution layers because of the recursive structure and dense connection. It is significant and meaningful for the practical applications of the network in HSI SR due to the limitations of hardware devices. Some experiments on three HSI databases illustrate that our proposed SCT-RDCNN method outperforms several state-of-the-art HSI SR methods. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","Hyperspectral imaging; Neural networks; Optical resolving power; Remote sensing; Spectroscopy; Convolutional networks; Convolutional neural network; Dense connection; Geological exploration; Image super resolutions; Recursions; Spatial constraints; Super resolution; Convolution","Deep convolutional network; Dense connection; Hyperspectral image; Recursion; Super-resolution","Article","Final","","Scopus","2-s2.0-85073971702"
"Zhang S.; Yuan Q.; Li J.","Zhang, Shu (57221299696); Yuan, Qiangqiang (36635300800); Li, Jie (57214207213)","57221299696; 36635300800; 57214207213","Video Satellite Imagery Super Resolution for 'Jilin-1' via a Single-and-Multi Frame Ensembled Framework","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324509","2731","2734","3","10.1109/IGARSS39084.2020.9324509","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101981467&doi=10.1109%2fIGARSS39084.2020.9324509&partnerID=40&md5=f06b3e7e7d34ffe6be8079745a018a2c","Compared with traditional remote sensing images, satellite remote sensing video contains more useful information and can capture continuous dynamic video. Recently, many deep-learning based methods have been proposed for video super resolution. However, these methods tend to ignore the structural information and characteristics for video satellite imagery such as small ground targets, a wide range of scales and weak textures. To this end, this paper proposes a single-and-multi-frame ensembled framework called SMFE for remote sensing videos super-resolution. The SMFE framework combines a non-local based single image super resolution (SISR) network and a state-of-the-arts multi-frame super resolution (MFSR) network EDVR. Experiments have been performed to demonstrate the effectiveness of the proposed method on Jilin-1. © 2020 IEEE.","Arts computing; Deep learning; Geology; Optical resolving power; Satellite imagery; Small satellites; Textures; Continuous dynamics; Learning-based methods; Remote sensing images; Satellite remote sensing; State of the art; Structural information; Super resolution; Video super-resolution; Remote sensing","Jilin-1; super resolution; video satellite imagery","Conference paper","Final","","Scopus","2-s2.0-85101981467"
"Rajeshwari P.; Shyamala K.","Rajeshwari, P. (57209453218); Shyamala, K. (57216288745)","57209453218; 57216288745","Chest CT Image Super Resolution using Deep Learning Network Models","2021","2021 International Conference on Smart Generation Computing, Communication and Networking, SMART GENCON 2021","","","","","","","10.1109/SMARTGENCON51891.2021.9645873","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123989943&doi=10.1109%2fSMARTGENCON51891.2021.9645873&partnerID=40&md5=2f4033474245b01493331667321f4c89","Image Super Resolution is a process of converting a Low Resolution image into High Resolution image with better visual quality and improved details. It is one of the most popular technique in image processing and computer vision. Super Resolution is applied in wide range of real world applications like medical imaging, surveillance applications and reconstruction of high quality remote sensing images. In the recent years, Super Resolution using deep learning techniques significantly improved accuracy. In this paper, Implemented four deep learning network models to generate High Resolution images of chest CT scans and evaluated the quantitative measure Peak Signal-to-Noise Ratio to compare accuracy of each CNN based deep leaning network models such as Super-Resolution Convolutional Neural Network (SRCNN), Enhanced Deep Super-Resolution (EDSR), Very Deep Super-Resolution (VDSR) and Deep Recursive Convolutional Network (DRCN). © 2021 IEEE.","Computerized tomography; Convolution; Convolutional neural networks; Deep learning; Image enhancement; Medical imaging; Remote sensing; Signal to noise ratio; Chest CT; Convolution neural network; CT Image; Deep learning; High-resolution images; Image super resolutions; Learning network; Medical image; Network models; Superresolution; Optical resolving power","convolution neural networks; deep learning; medical images; super resolution","Conference paper","Final","","Scopus","2-s2.0-85123989943"
"Hu J.; Jia X.; Li Y.; He G.; Zhao M.","Hu, Jing (57191473546); Jia, Xiuping (7201933692); Li, Yunsong (55986546100); He, Gang (36630339700); Zhao, Minghua (55477788900)","57191473546; 7201933692; 55986546100; 36630339700; 55477788900","Hyperspectral Image Super-Resolution via Intrafusion Network","2020","IEEE Transactions on Geoscience and Remote Sensing","58","10","9057496","7459","7471","12","10.1109/TGRS.2020.2982940","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092358978&doi=10.1109%2fTGRS.2020.2982940&partnerID=40&md5=1f475414e1249c72c4ccd07d99504087","This article presents an intrafusion network (IFN) for hyperspectral image (HSI) super-resolution (SR). Given that the HSI is a 3-D data cube with both the spatial information and the spectral information, the key challenge to construct HSI SR is how to efficiently exploit the spectral information among consecutive low-resolution (LR) bands, besides the spatial information. The proposed IFN consists of three modules, including the spectral difference module, the parallel convolution module, and the intrafusion module, which directly utilizes both the spatial information and the spectral information for reconstructing the high-resolution HSI. Different from most of the existed methods that tackle the spatial and spectral information separately, the proposed spatial-spectral utilization is achieved in one integrated network, which opens up a new way for HSI SR. Meanwhile, applications of this three modules strategy (first spectral difference, then parallel convolution, and finally, intrafusion) on both the conventional convolutional neural network and the residual network with deeper depth have shown the generalization capacity of this proposal. Experimental results and data analysis demonstrate the effectiveness of the proposed method using three hyperspectral data sets.  © 1980-2012 IEEE.","Convolution; Optical resolving power; Spectroscopy; Generalization capacity; Hyperspectral Data; Image super resolutions; Integrated networks; Spatial informations; Spectral differences; Spectral information; Spectral utilization; image resolution; multispectral image; network analysis; remote sensing; satellite data; Convolutional neural networks","Hyperspectral image (HIS); intrafusion; spectral difference; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85092358978"
"Müller M.U.; Ekhtiari N.; Almeida R.M.; Rieke C.","Müller, M.U. (57220945741); Ekhtiari, N. (57219023760); Almeida, R.M. (57220707074); Rieke, C. (57219030309)","57220945741; 57219023760; 57220707074; 57219030309","Super-Resolution of Multispectral Satellite Images Using Convolutional Neural Networks","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","1","","33","40","7","10.5194/isprs-annals-V-1-2020-33-2020","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090027192&doi=10.5194%2fisprs-annals-V-1-2020-33-2020&partnerID=40&md5=1d4717aec7afed757b5e122e789c9d0b","Super-resolution aims at increasing image resolution by algorithmic means and has progressed over the recent years due to advances in the fields of computer vision and deep learning. Convolutional Neural Networks based on a variety of architectures have been applied to the problem, e.g. autoencoders and residual networks. While most research focuses on the processing of photographs consisting only of RGB color channels, little work can be found concentrating on multi-band, analytic satellite imagery. Satellite images often include a panchromatic band, which has higher spatial resolution but lower spectral resolution than the other bands. In the field of remote sensing, there is a long tradition of applying pan-sharpening to satellite images, i.e. bringing the multispectral bands to the higher spatial resolution by merging them with the panchromatic band. To our knowledge there are so far no approaches to super-resolution which take advantage of the panchromatic band. In this paper we propose a method to train state-of-the-art CNNs using pairs of lower-resolution multispectral and high-resolution pan-sharpened image tiles in order to create super-resolved analytic images. The derived quality metrics show that the method improves information content of the processed images. We compare the results created by four CNN architectures, with RedNet30 performing best. © 2020 Copernicus GmbH. All rights reserved.","Convolution; Convolutional neural networks; Deep learning; Image resolution; Network architecture; Optical resolving power; Remote sensing; Satellite imagery; Information contents; Lower resolution; Multispectral satellite image; Panchromatic bands; Processed images; Satellite images; Spatial resolution; State of the art; Image enhancement","Convolutional Neural Networks; Deep learning; Pansharpening; Satellite data","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85090027192"
"Cao X.-M.; Liu Z.-H.; Liu J.-B.","Cao, Xiao-Min (57218798443); Liu, Zhi-Hong (55714964100); Liu, Jin-Bao (14031717000)","57218798443; 55714964100; 14031717000","Super-resolution reconstruction method of remote sensing image based on projection network; [基于投影网络的遥感影像超分辨率重建方法]","2020","Guangdianzi Jiguang/Journal of Optoelectronics Laser","31","11","","1149","1156","7","10.16136/j.joel.2020.11.0224","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099513243&doi=10.16136%2fj.joel.2020.11.0224&partnerID=40&md5=52fd26c8f21a38b5e3cf0fb287a5f195","Aiming at the characteristics of large amount of remote sensing image data, large terrain fluctuations and wide coverage, this paper proposes a method for super-resolution reconstruction of remote sensing image based on convolutional neural network.This method combines dense network and deep back projection network to form dense projection.The unit forms a deep dense projection network, which solves the problems of insufficient texture representation, insufficient detail extraction, and difficult training in traditional algorithms in the super-resolution reconstruction of remote sensing images.The experimental results show that on multiple remote sensing image data sets, compared with other comparison methods, the PSNR and SSIM are significantly improved, and the reconstructed remote sensing image texture signs and details are more abundant. © 2020, Science Press in China. All right reserved.","","Convolution neural network; Deep dense projection network; Remote sensing image; Super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85099513243"
"","","","15th Asian Conference on Computer Vision, ACCV 2020","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12628 LNCS","","","","","198","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104484389&partnerID=40&md5=fc604bf4ddbf8e0f599582d24da4d51e","The proceedings contain 13 papers. The special focus in this conference is on Computer Vision. The topics include: Iterative Self-distillation for Precise Facial Landmark Localization; multiview Similarity Learning for Robust Visual Clustering; real-Time Spatio-Temporal Action Localization via Learning Motion Representation; parallel-Connected Residual Channel Attention Network for Remote Sensing Image Super-Resolution; unsupervised Multispectral and Hyperspectral Image Fusion with Deep Spatial and Spectral Priors; G-GCSN: Global Graph Convolution Shrinkage Network for Emotion Perception from Gait; Cell Detection and Segmentation in Microscopy Images with Improved Mask R-CNN; BdSL36: A Dataset for Bangladeshi Sign Letters Recognition; 3D Semantic Segmentation for Large-Scale Scene Understanding; a Weakly Supervised Convolutional Network for Change Segmentation and Classification; visible and Thermal Camera-Based Jaywalking Estimation Using a Hierarchical Deep Learning Framework.","","","Conference review","Final","","Scopus","2-s2.0-85104484389"
"Zhang C.; Bai B.; Zhou C.; Wei S.","Zhang, Chao (57200371575); Bai, Bin (57653886600); Zhou, Chuanjie (57222592207); Wei, Shaoning (57222592726)","57200371575; 57653886600; 57222592207; 57222592726","Super-solution technology for low light level imaging in the field of remote sensing","2021","Proceedings of SPIE - The International Society for Optical Engineering","11763","","117637T","","","","10.1117/12.2587484","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103355202&doi=10.1117%2f12.2587484&partnerID=40&md5=705b9338476c11304ec437f976b3eae5","We have designed the super-solution technology for low light level imaging in the field of remote sensing. Low light level image super-resolution is realized with a method of super-resolution processing based on worked example learning and the information of high-resolution visible image. Multi-frame image and single-frame image of the super-resolution algorithms are combined to apply in the low light level imaging in the field of remote sensing. With the ground targets as the reference, the results illustrate that the higher resolution images are obtained and a number of image data are satisfactory. This technology has impressive potential for improving the efficiency of low light level remote sensing. © 2021 SPIE","Optical resolving power; High resolution visible; Higher resolution images; Low light level imaging; Low-light-level image; Single frame image; Super resolution; Super resolution algorithms; Worked examples; Remote sensing","Low light level image; Remote sensing; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85103355202"
"Fernandez R.; Fernandez-Beltran R.; Kang J.; Pla F.","Fernandez, Rafael (57222243976); Fernandez-Beltran, Ruben (55838551300); Kang, Jian (57192706813); Pla, Filiberto (7006504936)","57222243976; 55838551300; 57192706813; 7006504936","Sentinel-3 Super-Resolution Based on Dense Multireceptive Channel Attention","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9488297","7359","7372","13","10.1109/JSTARS.2021.3097410","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110863947&doi=10.1109%2fJSTARS.2021.3097410&partnerID=40&md5=b8c5d4973b68f7c7d7d6eaf3deb3e099","The unprecedented availability of remote sensing data from different complementary Sentinel missions provides increasing opportunities to alleviate the spatial limitations of Sentinel-3 (S3) from an intersensor perspective. Nonetheless, effectively exploiting such intersensor synergies still raises important challenges for super-resolution (SR) algorithms in terms of operational data availability, sensor alignment and substantial resolution changes, among others. In this scenario, this article sets a new SR framework for spatially enhancing S3 ocean and land color instrument (OLCI) products by taking advantage of the higher spatial resolution of the Sentinel-2 (S2) multispectral instrument (MSI). To achieve this goal, we initially study some of the most important deep learning-based approaches. Then, we define a novel Level-4 SR framework which integrates a new convolutional neural network specially designed for super-resolving OLCI data. In contrast to other networks, the proposed SR architecture (termed as SRS3) employs a dense multireceptive field together with a residual channel attention mechanism to relieve the particularly low spatial resolution of OLCI while extracting more discriminating features for the large spatial resolution differences with respect to MSI. The experimental part of the work, conducted using ten coupled OLCI and MSI operational data, reveals the suitability of the presented Level-4 SR framework within the Copernicus programme context as well as the advantages of the proposed architecture with respect different state-of-the-art models when spatially enhancing OLCI products. The related codes will be publicly available at https://github.com/rufernan/SRS3. © 2008-2012 IEEE.","Deep learning; Image resolution; Network architecture; Optical resolving power; Remote sensing; Attention mechanisms; Learning-based approach; Operational data; Proposed architectures; Receptive fields; Remote sensing data; Spatial resolution; State of the art; algorithm; artificial neural network; data processing; remote sensing; Sentinel; spatial resolution; Convolutional neural networks","Convolutional nural network (CNN); level-4 data processing; ocean and land color instrument (OLCI); sentinel-3 (s3); super-resolution (SR)","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85110863947"
"Yang Y.; Lam K.-M.; Dong J.; Sun X.; Jian M.","Yang, Yuting (57192115362); Lam, Kin-Man (55839377100); Dong, Junyu (22634069200); Sun, Xin (56366080900); Jian, Muwei (22634073600)","57192115362; 55839377100; 22634069200; 56366080900; 22634073600","Super-resolution on remote sensing images","2021","Proceedings of SPIE - The International Society for Optical Engineering","11766","","1176615","","","","10.1117/12.2590197","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103277844&doi=10.1117%2f12.2590197&partnerID=40&md5=c5e7d2af5fb0351858e3520f2fb36ab0","High-resolution ocean remote sensing images are of vital importance in the research field of ocean remote sensing. However, the available ocean remote sensing images are composed of averaged data, whose resolution is lower than the instant remote sensing images. In this paper, we propose a very deep super-resolution learning model for remote-sensing image super-resolution. In our research, we target satellite-derived sea surface temperature (SST) images, a typical kind of ocean remote sensing image, as a specific case study of super-resolution on remote sensing images. In this paper, we propose a novel model architecture based on the very deep super-resolution (VDSR) model, to further enhance its performance. Furthermore, we evaluate the peak signal-to-noise ratio (PSNR) and perceptual loss of the model trained on the natural images and SST frames. We designed and applied our model to the China Ocean SST database, the Ocean SST database, and the Ocean-Front databases, all containing remote sensing images captured by advanced very high resolution radiometers (AVHRR). Experimental results show that our model performs better than the state-of-the-art models on SST frames.  © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Advanced very high resolution radiometers (AVHRR); Database systems; Deep learning; Imaging techniques; Oceanography; Optical resolving power; Signal to noise ratio; Surface waters; High resolution; Model architecture; Ocean remote sensing; Peak signal to noise ratio; Remote sensing images; Sea surface temperature (SST); State of the art; Super resolution; Remote sensing","","Conference paper","Final","","Scopus","2-s2.0-85103277844"
"Mullah H.U.; Deka B.; Prasad A.V.V.","Mullah, Helal Uddin (57188860954); Deka, Bhabesh (49663267700); Prasad, A.V.V. (56447855300)","57188860954; 49663267700; 56447855300","Fast multi-spectral image super-resolution via sparse representation","2020","IET Image Processing","14","12","","2833","2844","11","10.1049/iet-ipr.2019.0714","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092563786&doi=10.1049%2fiet-ipr.2019.0714&partnerID=40&md5=b3e75834e54acee963a9d9e8c129e946","Sparse reconstruction is used to solve the inverse problem of single image super-resolution (SR) as a patch-based sparsity promoting regularisation problem. A coupled trained overcomplete dictionary from high-resolution (HR) and lowresolution (LR) image patches containing significant features is proposed using sparse representation to produce HR patches from their LR counterparts. In this study, the authors develop a multi-core single image SR technique for LR multi-spectral images based on patch-wise sparse representation coupled with morphological component analysis driven feature extraction. Simulations are carried out to evaluate the proposed method using real remote sensing images of a few Indian satellites, RESOURCESAT-2 and CARTOSAT-2, as well as other satellites, such as QuickBird etc. Results are also compared with other existing SR methods to establish the superiority of the proposed method in terms of both objective metrics and visual analysis.  © The Institution of Engineering and Technology 2020.","Inverse problems; Optical resolving power; Remote sensing; Spectroscopy; Low resolution images; Morphological component analysis; Multispectral images; Objective metrics; Over-complete dictionaries; Remote sensing images; Sparse reconstruction; Sparse representation; Image analysis","","Article","Final","","Scopus","2-s2.0-85092563786"
"Plaza A.; Li J.; Figueiredo M.A.T.","Plaza, Antonio (7006613644); Li, Jun (24481713500); Figueiredo, Mário A.T. (34769730500)","7006613644; 24481713500; 34769730500","AN OVERVIEW OF THE CONTRIBUTIONS OF JOSÉ MANUEL BIOUCAS-DIAS TO REMOTE SENSING IMAGE PROCESSING","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","13","16","3","10.1109/IGARSS47720.2021.9554718","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129891260&doi=10.1109%2fIGARSS47720.2021.9554718&partnerID=40&md5=b6e163f398316fa58d13be6020a653f9","José Manuel Bioucas-Dias was an outstanding expert in many different IEEE-related areas, including inverse problems in imaging, signal and image processing, pattern recognition, optimization, and remote sensing. He authored or coauthored more than 250 publications, including more than 100 journal papers (66 of which published in IEEE journals) and over 200 peer-reviewed international conference papers and book chapters. His contributions have been extremely influential in many different fields, namely phase estimation and unwrapping, convex optimization and Bayesian inference for imaging inverse problems, with a special emphasis on remote sensing, including synthetic aperture radar (SAR), hyperspectral unmixing, fusion, super-resolution, classification, and segmentation. In this paper, we provide an overview of his outstanding contributions to remote sensing image processing. © 2021 IEEE","Bayesian networks; Convex optimization; Differential equations; Hyperspectral imaging; Inference engines; Inverse problems; Pattern recognition; Radar imaging; Synthetic aperture radar; Conference papers; Convex optimisation; Imaging processing; Journal paper; Optimisations; Phase-estimation; Phase-unwrapping; Remote sensing image processing; Remote-sensing; Signal and image processing; Remote sensing","Inverse problems; Optimization; Pattern recognition; Remote sensing; Signal and image processing","Conference paper","Final","","Scopus","2-s2.0-85129891260"
"Li X.; Zhang D.; Liang Z.; Ouyang D.; Shao J.","Li, Xinyao (57214236476); Zhang, Dongyang (57197844592); Liang, Zhenwen (57204106847); Ouyang, Deqiang (57193701886); Shao, Jie (57002035900)","57214236476; 57197844592; 57204106847; 57193701886; 57002035900","Fused recurrent network via channel attention for remote sensing satellite image super-resolution","2020","Proceedings - IEEE International Conference on Multimedia and Expo","2020-July","","9102948","","","","10.1109/ICME46284.2020.9102948","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090394532&doi=10.1109%2fICME46284.2020.9102948&partnerID=40&md5=e74d6d8faadf27309039c8e7347f0428","Remote sensing satellite images often suffer from low spatial resolution. Image super-resolution plays an important role in remote sensing image processing. However, existing methods show that increasing network depth will inevitably lead to the dramatic increase of model parameters and the over-fitting problem. Besides, most methods treat different types of information (low-frequency and high-frequency) equally. Motivated by these observations, we propose a fused recurrent network via channel attention (CA-FRN) in this paper. The basic module, recursive channel attention block (RCAB), pays enough attention to the high-frequency information and diminishes the low-frequency information adaptively through channel attention. Based on RCAB, we render our model effective by retaining and fusing hierarchical local information of both low-resolution and high-resolution, and we enhance the network performance simply by increasing the number of RCABs without adding extra parameters. We evaluate the proposed model on satellite images from different datasets, and the proposed CA-FRN is superior to the state-of-the-art methods. Code is available at https://github.com/lxy0922/CAFRN. © 2020 IEEE.","Communication satellites; Image processing; Optical resolving power; Recurrent neural networks; Satellites; High-frequency informations; Image super resolutions; Over fitting problem; Recurrent networks; Remote sensing image processing; Remote sensing satellites; Spatial resolution; State-of-the-art methods; Remote sensing","Channel attention; Fused recurrent network; Satellite image super-resolution","Conference paper","Final","","Scopus","2-s2.0-85090394532"
"Yang W.; Zhou F.; Zhu R.; Fukui K.; Wang G.; Xue J.-H.","Yang, Wenming (55364108400); Zhou, Fei (56446120900); Zhu, Rui (56433914500); Fukui, Kazuhiro (36479961800); Wang, Guijin (7407146835); Xue, Jing-Hao (7202881908)","55364108400; 56446120900; 56433914500; 36479961800; 7407146835; 7202881908","Deep learning for image super-resolution","2020","Neurocomputing","398","","","291","292","1","10.1016/j.neucom.2019.09.091","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075452962&doi=10.1016%2fj.neucom.2019.09.091&partnerID=40&md5=4f7ea4556c1d0f330c6b8d43dfc34298","[No abstract available]","algorithm; computer vision; deep learning; Editorial; facial recognition; image processing; image quality; image reconstruction; priority journal; remote sensing","","Editorial","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85075452962"
"","","","Image and Signal Processing for Remote Sensing XXVII","2021","Proceedings of SPIE - The International Society for Optical Engineering","11862","","","","","298","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118597273&partnerID=40&md5=91938b70e08b6997e317f40a385043b4","The proceedings contain 33 papers. The topics discussed include: stereo matching of remote sensing images using deep stereo matching; object detection with noisy annotations in high-resolution remote sensing images using robust EfficientDet; few shot object detection in remote sensing images; fire segmentation using a squeezesegv2; deep-learning-based remote sensing video super-resolution for Jilin-1 satellite; useable machine learning for Sentinel-2 multispectral satellite imagery; self-supervised multi-task learning for semantic segmentation of urban scenes; impact of different compression rates for hyperspectral data compression based on a convolutional autoencoder; and hyperspectral image classification using spectral-spatial hypergraph convolution neural network.","","","Conference review","Final","","Scopus","2-s2.0-85118597273"
"Zhang Q.; Zhang Y.; Zhang Y.; Huang Y.; Li W.; Yang J.","Zhang, Qiping (57207878759); Zhang, Yin (55975581400); Zhang, Yongchao (56042343300); Huang, Yulin (23014806800); Li, Wenchao (55718616300); Yang, Jianyu (9239230100)","57207878759; 55975581400; 56042343300; 23014806800; 55718616300; 9239230100","Majorize-Minimization Based Super-Resolution Method for Radar Forward-Looking Imaging","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324322","3188","3191","3","10.1109/IGARSS39084.2020.9324322","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101962716&doi=10.1109%2fIGARSS39084.2020.9324322&partnerID=40&md5=225b79a31fa06bfd7e0aa713f9975f04","Sparse regularization method has been widely used to realize super-resolution imaging in radar forward-looking imaging. However, most of existed methods directly minimize a nondifferentiable L1 regularization problem. In this paper, a Majorize-Minimization (MM) based super-resolution method is proposed to realize super-resolution for radar forward-looking imaging. According to MM principle, the proposed method converts the non-differentiable L1 regularization problem into a differentiable L2 regularization problem, and the real target distribution is obtained by solving the L2 regularization problem. Due to the introduction of the sparse prior, the proposed method can better improve the azimuth resolution of radar forward-looking imaging. In addition, the application of MM principle makes the non-differentiable L1 regularization easier to be solved. Finally, the superior performance of the proposed method is verified by simulation. © 2020 IEEE.","Geology; Optical resolving power; Radar; Remote sensing; Azimuth resolution; Forward looking; L1 regularizations; Non-differentiable; Sparse regularizations; Super resolution; Super resolution imaging; Superresolution methods; Radar imaging","Majorize-Minimization; radar imaging; regularization; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85101962716"
"Huan H.; Li P.; Zou N.; Wang C.; Xie Y.; Xie Y.; Xu D.","Huan, Hai (56122187900); Li, Pengcheng (57216279808); Zou, Nan (57221980878); Wang, Chao (57211834282); Xie, Yaqin (25931789100); Xie, Yong (14032451700); Xu, Dongdong (56299205100)","56122187900; 57216279808; 57221980878; 57211834282; 25931789100; 14032451700; 56299205100","End‐to‐end super‐resolution for remote‐sensing images using an improved multi‐scale residual network","2021","Remote Sensing","13","4","666","1","28","27","10.3390/rs13040666","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100866399&doi=10.3390%2frs13040666&partnerID=40&md5=64e4b4849fb04119bef50a50945984eb","Remote‐sensing images constitute an important means of obtaining geographic information. Image super‐resolution reconstruction techniques are effective methods of improving the spatial resolution of remote‐sensing images. Super‐resolution reconstruction networks mainly improve the model performance by increasing the network depth. However, blindly increasing the network depth can easily lead to gradient disappearance or gradient explosion, increasing the difficulty of training. This report proposes a new pyramidal multi‐scale residual network (PMSRN) that uses hierarchical residual‐like connections and dilation convolution to form a multi‐scale dilation residual block (MSDRB). The MSDRB enhances the ability to detect context information and fuses hierarchical features through the hierarchical feature fusion structure. Finally, a complementary block of global and local features is added to the reconstruction structure to alleviate the problem that useful original information is ignored. The experimental results showed that, compared with a basic multi‐scale residual network, the PMSRN increased the peak signal‐to‐noise ratio by up to 0.44 dB and the structural similarity to 0.9776. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Earth sciences; Remote sensing; Context information; Geographic information; Hierarchical features; Model performance; Reconstruction networks; Reconstruction techniques; Spatial resolution; Structural similarity; Image enhancement","Complementary block; Hierarchical feature fusion structure; Multi‐scale dilation residual block; Pyramidal multi‐scale residual network; Remote sensing; Super‐resolution reconstruction","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85100866399"
"Bull D.; Lim N.; Frank E.","Bull, Daniel (57447422500); Lim, Nick (57271916600); Frank, Eibe (7202332302)","57447422500; 57271916600; 7202332302","Perceptual improvements for Super-Resolution of Satellite Imagery","2021","International Conference Image and Vision Computing New Zealand","2021-December","","","","","","10.1109/IVCNZ54163.2021.9653355","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124412197&doi=10.1109%2fIVCNZ54163.2021.9653355&partnerID=40&md5=7a46f8145a7d8580de926c1bed29c91b","Super-resolution of satellite imagery poses unique challenges. We propose a hybrid method comprising two existing deep network super-resolution approaches, namely a feedforward network called DeepSUM, and ESRGAN, a GAN-based approach, to super-resolve multiple low-resolution images by a factor of four to obtain a single high-resolution image. We also introduce a novel loss function, called variation loss, to better define edges and textures to create a sharper, perceptually better output. Using our hybrid, we inherit some of the advantages of both deep learning approaches, resulting in super-resolved images that better show boundaries, textures, and details.  © 2021 IEEE.","Deep neural networks; Image enhancement; Optical resolving power; Remote sensing; Satellite imagery; Textures; Edge and textures; Feed-forward network; High-resolution images; Hybrid method; Learning approach; Loss functions; Low resolution images; Remote-sensing; Superresolution; Computer vision","Computer Vision; Deep Neural Network; Remote Sensing; Super-Resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85124412197"
"Cipolletti M.P.; Delrieux C.A.; Perillo G.M.E.","Cipolletti, M.P. (47961856700); Delrieux, C.A. (55887255100); Perillo, G.M.E. (7004233707)","47961856700; 55887255100; 7004233707","Automatic Determination, Feature-extraction, and Classification of Tidal-courses through Remote-sensing Images: Preliminary Studies","2021","2021 19th Workshop on Information Processing and Control, RPIC 2021","","","","","","","10.1109/RPIC53795.2021.9648432","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124145174&doi=10.1109%2fRPIC53795.2021.9648432&partnerID=40&md5=b430e4fb60238e269a480f7a81428d0e","Unlike rivers, tidal-paths present different drainage configurations within their complex distribution. The determinations of their features is the first step towards modeling their evolution. In this work, a methodology is presented for automatic morphometric extraction and characterization of tidal-paths over high resolution satellite images (IKONOS, 1 m resolution). The algorithm accurately computes the total length of the structure. In addition, it identifies and characterizes each branch by super-resolution. Then, the drainage paths without loops are classified defining the order in which they flood and ebb by effect of the tides. The method was tested on two tidal-paths with very different features: a rectangular or trellis drainage, and a dendritic one.  © 2021 IEEE.","Extraction; Image classification; Automatic determination; Direct measurement; Feature extraction and classification; High resolution satellite images; Morphometrics; Morphometry; Remote sensing images; Remote-sensing; Tidal course; Total length; Remote sensing","direct measurement; morphometry; remote-sensing; tidal courses","Conference paper","Final","","Scopus","2-s2.0-85124145174"
"Li L.; Zhou Z.; Cui S.","Li, Linhao (57204549892); Zhou, Zhiqiang (55728196000); Cui, Saijia (57299898400)","57204549892; 55728196000; 57299898400","Boosting Small Ship Detection in Optical Remote Sensing Images via Image Super-Resolution","2021","Proceedings of the 33rd Chinese Control and Decision Conference, CCDC 2021","","","","1508","1512","4","10.1109/CCDC52312.2021.9601674","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125184752&doi=10.1109%2fCCDC52312.2021.9601674&partnerID=40&md5=649763eca9e4925aad8eef3363ab157c","Small ships in optical remote sensing images are hard to detect due to the lack of sufficient detail information. In this paper, we adopt the image super-resolution technology to solve this problem. Specifically, an effective super-resolution network is designed to generate clear super-resolution ship images from small blurry ones produced by the ship detector. Inspired by the idea of generative adversarial network (GAN), the super-resolution network is trained together with a discriminator network in an adversarial way, aiming at generating more realistic super-resolution images. Moreover, to eliminate false detections, the discriminator network is also used to distinguish ship and non-ship images via an additional classification branch. Experimental results demonstrate the effectiveness of the proposed method.  © 2021 IEEE.","Discriminators; Geology; Optical resolving power; Remote sensing; Ships; False detections; Image super resolutions; Optical remote sensing; Remote sensing images; Resolution images; Ship detection; Superresolution; Generative adversarial networks","Generative adversarial network; Image super-resolution; Ship detection","Conference paper","Final","","Scopus","2-s2.0-85125184752"
"Zhang K.; Yang C.; Li X.; Zhou C.; Zhong R.","Zhang, Ke (57210949722); Yang, Cankun (36683799800); Li, Xiaojuan (55718181400); Zhou, Chunping (36611152200); Zhong, Ruofei (56222085000)","57210949722; 36683799800; 55718181400; 36611152200; 56222085000","High-efficiency microsatellite-using super-resolution algorithm based on the multi-modality super-cmos sensor","2020","Sensors (Switzerland)","20","14","4019","1","20","19","10.3390/s20144019","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088233502&doi=10.3390%2fs20144019&partnerID=40&md5=2043b56a754816185aa9b9654d96abb6","To realize the application of super-resolution technology from theory to practice, and to improve microsatellite spatial resolution, we propose a special super-resolution algorithm based on the multi-modality super-CMOS sensor which can adapt to the limited operation capacity of microsatellite computers.2 ) First, we designed an oblique sampling mode with the sensor rotated at an angle of 26.56◦(arctan1 to obtain high overlap ratio images with sub-pixel displacement. Secondly, the proposed super-resolution algorithm was applied to reconstruct the final high-resolution image. Because the satellite equipped with this sensor is scheduled to be launched this year, we also designed the simulation mode of conventional sampling and the oblique sampling of the sensor to obtain the comparison and experimental data. Lastly, we evaluated the super-resolution quality of images, the effectiveness, the practicality, and the efficiency of the algorithm. The results of the experiments showed that the satellite-using super-resolution algorithm combined with multi-modality super-CMOS sensor oblique-mode sampling can increase the spatial resolution of an image by about 2 times. The algorithm is simple and highly efficient, and can realize the super-resolution reconstruction of two remote-sensing images within 0.713 s, which has good performance on the microsatellite. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","CMOS integrated circuits; DNA sequences; Efficiency; Image enhancement; Image reconstruction; Image resolution; Optical resolving power; Remote sensing; High resolution image; Operation capacity; Remote sensing images; Spatial resolution; Sub-pixel displacements; Super resolution; Super resolution algorithms; Super resolution reconstruction; Image sampling","Algorithm engineering; Microsatellite spatial resolution; Multi-modality; Oblique sampling mode; Rotatable sensor; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85088233502"
"","","","2nd International Conference on 3D Imaging Technologies-Multidimensional Signal Processing and Deep Learning, 3DIT-MSPandDL 2020","2021","Smart Innovation, Systems and Technologies","234","","","","","345","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116887915&partnerID=40&md5=38c7c22c17f95214b06380a767766a0e","The proceedings contain 39 papers. The special focus in this conference is on 3D Imaging Technologies-Multidimensional Signal Processing and Deep Learning. The topics include: Appearance Defect Detection of Injection Parts Based on Deep Learning; thresholding Method for the Sonar Image of a Seabed Target Based on Two-Dimensional Renyi's Entropy; noise Reduction in Sonar Images of Seabed Targets Based on a Variational Method; sonar Image Segmentation of Seabed Targets Using a Variational Approach; balance the Robustness and Invisibility of Digital Watermarking by Image Entropy in Multiple Domains; research Progress of Electrical Resistance Tomography; research on Low-Resolution Image Matching and Recognition Algorithm Based on Unified Feature Space; research on Realistic Representation Technology in Virtual Environment; intelligent Customer Service Operation Management System Solution Based on Intelligent Voice Analysis; Research Status of Motor Imagery EEG Signal Based on Deep Learning; research on Car Seat Comfort Evaluation System Based on Chinese Population; research on Building Extraction from High-Resolution Remote Sensing Image Based on Improved U-Net; a Survey of Image Classification Algorithms Based on Graph Neural Networks; an Improved Method of Non-local Means Denoising Based on Histogram; short-Term Traffic Volume Prediction Based on Gray Wolf Optimization Algorithm; Biological Particle Recognition Based on BP Neural Network Algorithm; imageCube: A Low-Cost 6D Controller with Smooth Tracking for Mobile Augmented Reality; A Clinical Decision-Making System for COVID-19; License Plate Recognition System Based on OpenCV; LUCC and Landscape Pattern Variation in the Lower Tarim River by Remote Sensing; image Recognition Based on Super-Resolution Wasserstein Generative Adversarial Nets with Gradient Penalty.","","","Conference review","Final","","Scopus","2-s2.0-85116887915"
"Gao L.; Hong D.; Yao J.; Zhang B.; Gamba P.; Chanussot J.","Gao, Lianru (14031580000); Hong, Danfeng (56108179600); Yao, Jing (57218422895); Zhang, Bing (8835983800); Gamba, Paolo (7007165803); Chanussot, Jocelyn (6602159365)","14031580000; 56108179600; 57218422895; 8835983800; 7007165803; 6602159365","Spectral Superresolution of Multispectral Imagery with Joint Sparse and Low-Rank Learning","2021","IEEE Transactions on Geoscience and Remote Sensing","59","3","9120344","2269","2280","11","10.1109/TGRS.2020.3000684","71","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101899013&doi=10.1109%2fTGRS.2020.3000684&partnerID=40&md5=3ecd7b09dc8e3cd8dcf7a00d95db0043","Extensive attention has been widely paid to enhance the spatial resolution of hyperspectral (HS) images with the aid of multispectral (MS) images in remote sensing. However, the ability in the fusion of HS and MS images remains to be improved, particularly in large-scale scenes, due to the limited acquisition of HS images. Alternatively, we super-resolve MS images in the spectral domain by the means of partially overlapped HS images, yielding a novel and promising topic: spectral superresolution (SSR) of MS imagery. This is challenging and less investigated task due to its high ill-posedness in inverse imaging. To this end, we develop a simple but effective method, called joint sparse and low-rank learning (J-SLoL), to spectrally enhance MS images by jointly learning low-rank HS-MS dictionary pairs from overlapped regions. J-SLoL infers and recovers the unknown HS signals over a larger coverage by sparse coding on the learned dictionary pair. Furthermore, we validate the SSR performance on three HS-MS data sets (two for classification and one for unmixing) in terms of reconstruction, classification, and unmixing by comparing with several existing state-of-the-art baselines, showing the effectiveness and superiority of the proposed J-SLoL algorithm. Furthermore, the codes and data sets will be available at https://github.com/danfenghong/IEEE_TGRS_J-SLoL, contributing to the remote sensing (RS) community.  © 1980-2012 IEEE.","Classification (of information); Inverse problems; Learning to rank; Optical resolving power; Remote sensing; Learned dictionaries; Multi-spectral imagery; Multispectral images; Sparse and low ranks; Spatial resolution; Spectral domains; State of the art; Super resolution; data assimilation; learning; multispectral image; ranking; remote sensing; spatial resolution; spectral analysis; Image enhancement","Dictionary learning; hyperspectral; joint learning; low-rank; multispectral; remote sensing; sparse representation; superresolution","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85101899013"
"Hang R.; Liu Q.; Li Z.","Hang, Renlong (56082126900); Liu, Qingshan (36063739200); Li, Zhu (35751426200)","56082126900; 36063739200; 35751426200","Spectral super-resolution network guided by intrinsic properties of hyperspectral imagery","2021","IEEE Transactions on Image Processing","30","","9515578","7256","7265","9","10.1109/TIP.2021.3104177","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113226529&doi=10.1109%2fTIP.2021.3104177&partnerID=40&md5=9478acbd40a3f064fa1ce10c17189d41","Hyperspectral imagery (HSI) contains rich spectral information, which is beneficial to many tasks. However, acquiring HSI is difficult because of the limitations of current imaging technology. As an alternative method, spectral super-resolution aims at reconstructing HSI from its corresponding RGB image. Recently, deep learning has shown its power to this task, but most of the used networks are transferred from other domains, such as spatial super-resolution. In this paper, we attempt to design a spectral super-resolution network by taking advantage of two intrinsic properties of HSI. The first one is the spectral correlation. Based on this property, a decomposition subnetwork is designed to reconstruct HSI. The other one is the projection property, i.e., RGB image can be regarded as a three-dimensional projection of HSI. Inspired from it, a self-supervised subnetwork is constructed as a constraint to the decomposition subnetwork. These two subnetworks constitute our end-to-end super-resolution network. In order to test the effectiveness of it, we conduct experiments on three widely used HSI datasets (i.e., CAVE, NUS, and NTIRE2018). Experimental results show that our proposed network can achieve competitive reconstruction performance in comparison with several state-of-the-art networks.  © 1992-2012 IEEE.","Deep learning; Imaging techniques; Remote sensing; Spectroscopy; Hyper-spectral imageries; Hyperspectral imagery; Intrinsic property; Projection property; Spectral correlation; Spectral information; State of the art; Super resolution; article; comparative effectiveness; decomposition; deep learning; human; human experiment; imagery; Optical resolving power","Decomposition subnetwork; Intrinsic properties; Self-supervised subnetwork; Spectral super-resolution","Article","Final","","Scopus","2-s2.0-85113226529"
"Dong X.; Xi Z.; Sun X.; Yang L.","Dong, Xiaoyu (57212387140); Xi, Zhihong (15047162700); Sun, Xu (23499533300); Yang, Lina (55732979200)","57212387140; 15047162700; 23499533300; 55732979200","Remote Sensing Image Super-Resolution via Enhanced Back-Projection Networks","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323316","1480","1483","3","10.1109/IGARSS39084.2020.9323316","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101989843&doi=10.1109%2fIGARSS39084.2020.9323316&partnerID=40&md5=09f338f25742b3af6e921982155be560","Convolutional neural network (CNN)-based image super-resolution (SR) is one of the most active field of research in the remote sensing community. As a state-of-the-art super-resolving method, however, the dense deep back-projection network (DDBPN) ignores the mutual differences among the channel-wise features and discards the initial feature when performing reconstruction. In this paper, we develop an enhanced back-projection network (EBPN) with performance exceeding the DDBPN and other state-of-the-art methods. The performance improvement gains from introducing attention mechanism to capture the feature differences among channels and reconstructing images by using the element-wise sum of the upscaled initial feature and deep features learned at different depths. A retraining strategy is also employed to further boost the SR ability of EBPN for remote sensing images. Experimental results on a remote sensing dataset and four benchmark datasets demonstrate the superiority of EBPN. © 2020 IEEE.","Convolutional neural networks; Geology; Image enhancement; Optical resolving power; Attention mechanisms; Back projection; Benchmark datasets; Feature differences; Image super resolutions; Remote sensing images; State of the art; State-of-the-art methods; Remote sensing","attention mechanism; back-projection; remote sensing; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85101989843"
"Teh I.; McClymont D.; Carruth E.; Omens J.; McCulloch A.; Schneider J.E.","Teh, Irvin (36864470200); McClymont, Darryl (36976208900); Carruth, Eric (54404671800); Omens, Jeffrey (7005640655); McCulloch, Andrew (7102710961); Schneider, Jürgen E. (55465891500)","36864470200; 36976208900; 54404671800; 7005640655; 7102710961; 55465891500","Improved compressed sensing and super-resolution of cardiac diffusion MRI with structure-guided total variation","2020","Magnetic Resonance in Medicine","84","4","","1868","1880","12","10.1002/mrm.28245","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080973322&doi=10.1002%2fmrm.28245&partnerID=40&md5=b0916f5f999cfc6a55ad40ed52638c58","Purpose: Structure-guided total variation is a recently introduced prior that allows reconstruction of images using knowledge of the location and orientation of edges in a reference image. In this work, we demonstrate the advantages of a variant of structure-guided total variation known as directional total variation (DTV), over traditional total variation (TV), in the context of compressed-sensing reconstruction and super-resolution. Methods: We compared TV and DTV in retrospectively undersampled ex vivo diffusion tensor imaging and diffusion spectrum imaging data from healthy, sham, and hypertrophic rat hearts. Results: In compressed sensing at an undersampling factor of 8, the RMS error of mean diffusivity and fractional anisotropy relative to the fully sampled ground truth were 44% and 20% lower in DTV compared with TV. In super-resolution, these values were 29% and 14%, respectively. Similarly, we observed improvements in helix angle, transverse angle, sheetlet elevation, and sheetlet azimuth. The RMS error of the diffusion kurtosis in the undersampled data relative to the ground truth was uniformly lower (22% on average) with DTV compared to TV. Conclusion: Acquiring one fully sampled non-diffusion-weighted image and 10 diffusion-weighted images at 8× undersampling would result in an 80% net reduction in data needed. We demonstrate efficacy of the DTV algorithm over TV in reducing data sampling requirements, which can be translated into higher apparent resolution and potentially shorter scan times. This method would be equally applicable in diffusion MRI applications outside the heart. © 2020 The Authors. Magnetic Resonance in Medicine published by Wiley Periodicals, Inc. on behalf of International Society for Magnetic Resonance in Medicine","Algorithms; Animals; Diffusion Magnetic Resonance Imaging; Diffusion Tensor Imaging; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Rats; Retrospective Studies; Compressed sensing; Diffusion; Digital television; Magnetic resonance imaging; Optical resolving power; Television broadcasting; Tensors; Diffusion spectrum imaging; Diffusion weighted images; Directional total variations; Fractional Anisotropy; Mean diffusivity; Reference image; Super resolution; Total variation; algorithm; animal experiment; animal tissue; Article; comparative study; controlled study; diffusion tensor imaging; diffusion weighted imaging; directional total variation; ex vivo study; fractional anisotropy; image analysis; image reconstruction; mathematical computing; mathematical model; measurement accuracy; nonhuman; quantitative analysis; radiocardiography; radiological parameters; rat; remote sensing; traditional total variation; animal; diffusion tensor imaging; image processing; nuclear magnetic resonance imaging; retrospective study; Diffusion tensor imaging","cardiac MRI; compressed sensing; diffusion kurtosis; diffusion tensor imaging; directional total variation; super-resolution","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85080973322"
"Kawulok M.; Benecki P.; Nalepa J.; Kostrzewa D.","Kawulok, Michal (24474818300); Benecki, Pawel (55644906700); Nalepa, Jakub (55441340400); Kostrzewa, Daniel (50661666400)","24474818300; 55644906700; 55441340400; 50661666400","Evaluating Super-Resolution of Satellite Images: A Proba-V Case Study","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323908","641","644","3","10.1109/IGARSS39084.2020.9323908","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102002547&doi=10.1109%2fIGARSS39084.2020.9323908&partnerID=40&md5=89dd78c421195a4edd02484233662ae7","Super-resolution reconstruction is a process aimed at enhancing image spatial resolution. To evaluate the quality of super-resolution, the reconstruction outcome is compared with a ground-truth reference image, and the dissimilarity between them is commonly treated as a determinant of the reconstruction quality. While this is straightforward for simulated data, it becomes more challenging for real-world scenarios, in which reference images and the reconstruction inputs are acquired using different imaging sensors. In such cases, the dissimilarity also results from other factors concerned with different sensor characteristics. In a recently organized Proba-V Super Resolution Challenge, the reconstruction quality was assessed using a modified peak signal-to-noise ratio which compensates for small shifts and global changes in the brightness. In the study reported here, we investigate a number of image similarity metrics to verify their robustness against different levels of distortions applied to Proba-V images. We expect that the reported results will help in choosing appropriate metrics while developing new super-resolution solutions aimed at real-world scenarios. © 2020 IEEE.","Geology; Image reconstruction; Optical resolving power; Remote sensing; Signal to noise ratio; Appropriate metrics; Image spatial resolution; Peak signal to noise ratio; Real-world scenario; Reconstruction quality; Satellite images; Sensor characteristics; Super resolution reconstruction; Image enhancement","image similarity; satellite imaging; Super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85102002547"
"Prexl J.; Saha S.; Zhu X.X.","Prexl, Jonathan (57213813075); Saha, Sudipan (57205200597); Zhu, Xiao Xiang (55696622200)","57213813075; 57205200597; 55696622200","MITIGATING SPATIAL AND SPECTRAL DIFFERENCES FOR CHANGE DETECTION USING SUPER-RESOLUTION AND UNSUPERVISED LEARNING","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","3113","3116","3","10.1109/IGARSS47720.2021.9554789","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124686561&doi=10.1109%2fIGARSS47720.2021.9554789&partnerID=40&md5=35b7b0923616a905644c3df61e4e522f","Change detection (CD) is one of the most researched areas in remote sensing. However, most CD methods assume that the pre-change and post-change images are acquired by the same sensor, having the same set of spectral bands and same spatial resolution. This severely limits the applicability of CD methods. It is not trivial to apply the existing CD methods in multisensor scenario. Towards this direction, we propose an unsupervised CD method that can handle large differences in spatial resolution and can work with completely different set of spectral bands. The proposed method uses a self-supervised super-resolution strategy to upsample the lower resolution image, thus mitigating differences in spatial resolution. To mitigate spectral differences, a self-supervised learning strategy is used that ingests both images as input and trains a network using self-supervised loss accounting for the spectral differences in both images. Once trained this network is used in deep change vector analysis framework for change detection. We validated the proposed method in an experimental setup where the pre-change and post-change images have different spatial resolution (10 m and 20 m/pixel) and completely disjoint set of spectral bands. © 2021 IEEE","Deep learning; Remote sensing; Change detection; Change vector analysis; Deep change vector analyse; Deep learning; Detection methods; Multi sensor images; Multi-spatial resolution; Spatial resolution; Spectral band; Spectral differences; Image resolution","Change detection; Deep Change Vector Analysis; Deep learning; Multi-spatial resolution; Multisensor images","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85124686561"
"Courtrai L.; Pham M.-T.; Lefèvre S.","Courtrai, Luc (6507861482); Pham, Minh-Tan (56070990300); Lefèvre, Sébastien (57203070803)","6507861482; 56070990300; 57203070803","Small object detection in remote sensing images based on super-resolution with auxiliary generative adversarial networks","2020","Remote Sensing","12","19","3152","1","19","18","10.3390/rs12193152","37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092761573&doi=10.3390%2frs12193152&partnerID=40&md5=514218afa5c2d6b706c213d8d17edd87","This article tackles the problem of detecting small objects in satellite or aerial remote sensing images by relying on super-resolution to increase image spatial resolution, thus the size and details of objects to be detected. We show how to improve the super-resolution framework starting from the learning of a generative adversarial network (GAN) based on residual blocks and then its integration into a cycle model. Furthermore, by adding to the framework an auxiliary network tailored for object detection, we considerably improve the learning and the quality of our final super-resolution architecture, and more importantly increase the object detection performance. Besides the improvement dedicated to the network architecture, we also focus on the training of super-resolution on target objects, leading to an object-focused approach. Furthermore, the proposed strategies do not depend on the choice of a baseline super-resolution framework, hence could be adopted for current and future state-of-the-art models. Our experimental study on small vehicle detection in remote sensing data conducted on both aerial and satellite images (i.e., ISPRS Potsdam and xView datasets) confirms the effectiveness of the improved super-resolution methods to assist with the small object detection tasks. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Antennas; Image enhancement; Network architecture; Object recognition; Optical resolving power; Remote sensing; Small satellites; Adversarial networks; Aerial remote sensing; Detection performance; Image spatial resolution; Remote sensing data; Remote sensing images; Small object detection; Superresolution methods; Object detection","Auxiliary network; Cycle GAN; Deep learning; Generative adversarial network (GAN); Remote sensing; Small object detection; Super-resolution; Wasserstein GAN","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85092761573"
"Xu Y.; Li J.; Song H.; Du L.","Xu, Yingying (56420823300); Li, Jianhua (57210567990); Song, Haifeng (57199094666); Du, Lei (57217512568)","56420823300; 57210567990; 57199094666; 57217512568","Single-Image Super-Resolution Using Panchromatic Gradient Prior and Variational Model","2021","Mathematical Problems in Engineering","2021","","9944385","","","","10.1155/2021/9944385","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106356035&doi=10.1155%2f2021%2f9944385&partnerID=40&md5=47f8a8171272d5261d1a8f769f7d26bd","Single-image super-resolution (SISR) is a resolution enhancement technique and is known as an ill-posed problem. Motivated by the idea of pan-sharping, we propose a novel variational model for SISR. The structure tensor of the input low-resolution image is exploited to obtain the gradient of an imaginary panchromatic image. Then, by constraining the gradient consistency, the image edges and details can be better recovered during the procedure of restoration of high-resolution images. Besides, we resort to the nonlocal sparse and low-rank regularization of image patches to further improve the super-resolution performance. The proposed variational model is efficiently solved by ADMM-based algorithm. We do extensive experiments in natural images and remote sensing images with different magnifying factors and compare our method with three classical super-resolution methods. The subjective visual impression and quantitative evaluation indexes both show that our method can obtain higher-quality results.  © 2021 Yingying Xu et al.","Optical resolving power; Remote sensing; High resolution image; Low resolution images; Quantitative evaluation; Remote sensing images; Resolution enhancement technique; Sparse and low ranks; Superresolution methods; Variational modeling; Image enhancement","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85106356035"
"Zhang J.; Liu S.; Peng Y.; Li J.","Zhang, Junwei (57219419351); Liu, Shigang (26663071300); Peng, Yali (14042266200); Li, Jun (57206965333)","57219419351; 26663071300; 14042266200; 57206965333","Satellite image super-resolution based on progressive residual deep neural network","2020","Journal of Applied Remote Sensing","14","3","032610","","","","10.1117/1.JRS.14.032610","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092615263&doi=10.1117%2f1.JRS.14.032610&partnerID=40&md5=72083db54f6d5973a765754b0d6f2591","Satellite remote sensing has wide applications in many fields. However, the quality of the observed images captured from the satellite sensors exhibits significant variances and most images are low resolution. Therefore, they adversely affect the system performance in a variety of real-world applications such as object recognition and analysis. In order to enhance the resolution of remote sensing images, we propose a super-resolution neural network called progressive residual depth neural network (PRDNN). The progressive residual structure used by PRDNN can gradually discover the feature information of satellite images at different levels and different receptive fields, thus providing more detailed features for reconstructing super-resolution satellite images. The experimental results of the DOTA satellite image database demonstrate that the proposed method is superior to the most advanced super-resolution algorithm in recent years.  © 2020 Society of Photo-Optical Instrumentation Engineers (SPIE).","Deep neural networks; Image enhancement; Object recognition; Optical resolving power; Remote sensing; Satellites; Feature information; Receptive fields; Remote sensing images; Residual structure; Satellite images; Satellite remote sensing; Satellite sensors; Super resolution algorithms; Neural networks","convolutional neural network; progressive residual network; residual network; satellite imagery; super-resolution","Article","Final","","Scopus","2-s2.0-85092615263"
"Gong D.; Wang Z.; Zhang Y.","Gong, Dianqing (57215932885); Wang, Zhaofeng (34868884400); Zhang, Yili (35212759200)","57215932885; 34868884400; 35212759200","Spatial-temporal variation characteristics of greenhouse-vegetable land in Lhasa of Tibet from 2008 to 2018; [2008-2018年拉萨市温室蔬菜地时空变化特征]","2020","Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering","36","13","","233","241","8","10.11975/j.issn.1002-6819.2020.13.027","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089889111&doi=10.11975%2fj.issn.1002-6819.2020.13.027&partnerID=40&md5=bb8791fc95f65933e19178a8aee055ad","Greenhouse-vegetable production serves as a sort of farming, in which vegetable crops grow in built structures, such as wood, plastic, metal and net. Recently, the greenhouse-vegetable farming has become an ideal way to meet the increasing demand of residents for vegetable consumption, particularly on Lhasa in the cold regions. However, a clear understanding for the changing process is still lacking in the greenhouse pattern. This study aims to clarify the change characteristics in the spatial and temporal pattern of the greenhouse-vegetable land in Lhasa from 2008 to 2018, particularly on land use, soil texture and vegetable yield. 11 high-resolution remote sensing images of greenhouse were captured from Lhasa in the northwestern China, from 2008 to 2018. Combined with field research, the barycenter shift and geostatistical techniques were used to determine the total area of greenhouse-vegetable land in various districts or counties. The movement of barycenter position was related to the direction of tracking position, including the altitude gradient and slope. Super-resolution images were obtained for the layout of greenhouses facility in alpine regions, as well the early built greenhouses-vegetable land. The results show that, 1) there was an upward trend in the area of greenhouse-vegetable land in Lhasa from 2008 to 2018, with an average annual growth rate of 6.93%. Three stages were observed for the change features of greenhouse-vegetable land in the study period, including developing, adjustment, and stability. The annual average areas of greenhouse-vegetable land in each stage were 1 050 hm2, 1 413 hm2 and 1 668 hm2, respectively, while the average annual change rates were 11.08%, -2.13%, 0.77%, respectively. 2) In the past ten years, the proportion of greenhouse-vegetable land in Chengguan and Doilungdêqên of Lhasa decreased by 56.2%, while the proportion in Dagze and Quxu increased by 51.58%. 3) The newly developed greenhouse-vegetable lands were transferring to high-altitude and high-slope regions, far away from urban or industrial areas. In the altitude range of 3 675-3 800 m, the areas of greenhouse-vegetable lands increased from 22.05% to 30.41%, while that in the 6°-10° slop regions increased by 5.92%. 4) The spatial change of greenhouse-vegetable lands in Lhasa revealed that the newly added greenhouse-vegetable land much more than farmland, indicating the expansion of construction land. A basic driving force for the growth of greenhouse vegetable lands can be attributed to the large demand for vegetables and the high yield of the greenhouse. Regional land use can also be another important driving force for the distribution of greenhouse-vegetable land. In greenhouse-vegetable land operation, there was no obvious effect on soil texture, indicating the particle size of soil texture changed a little at different elevation gradients. The overall output of vegetables in Lhasa was increasing, with an average annual growth rate of 9.57%. The increase in the greenhouse area has effectively promoted the production capacity of vegetables, thereby to meet the demand of residents for vegetable consumption in Lhasa in the cold regions. © 2020, Editorial Department of the Transactions of the Chinese Society of Agricultural Engineering. All right reserved.","Greenhouse effect; Greenhouses; Land use; Particle size; Plastics industry; Remote sensing; Soils; Stages; Structures (built objects); Textures; Average annual growth rates; Elevation gradient; Geostatistical techniques; Greenhouse vegetables; High resolution remote sensing images; Northwestern China; Production capacity; Spatial and temporal patterns; Vegetables","Greenhouse; Land use; Remote sensing; Spatial and temporal change; Tibet plateau; Vegetable land","Article","Final","","Scopus","2-s2.0-85089889111"
"Shinde R.C.; Potnis A.V.; Durbha S.S.","Shinde, Rajat C. (57213188267); Potnis, Abhishek V. (57192087600); Durbha, Surya S. (54999762600)","57213188267; 57192087600; 54999762600","Online Point Cloud Super Resolution using Dictionary Learning for 3D Urban Perception","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323992","4414","4417","3","10.1109/IGARSS39084.2020.9323992","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102015855&doi=10.1109%2fIGARSS39084.2020.9323992&partnerID=40&md5=4ac8ab66a4c22b0b23dfaa36765cbf64","Real-time embedded vision tasks require extraction of complex geometric and morphological features from the raw 3D point cloud acquired using range scanning systems like lidar, radar etc. and depth cameras. Such applications are found in autonomous navigation, surveying, 3D mapping and localization tasks such as automatic target recognition (ATR). Typically, a dataset acquired during surveying by remote sensing lidar scanners, known as point cloud, is (1) huge in size and requires a big chunk of memory for processing at a single instance and, (2) experiences missing information due to rapid change in orientation of the sensor while scanning. In our work, we are addressing both the issues combinedly by proposing an online point cloud super-resolution approach for translating a low dimensional point cloud to a high dimensional dense point cloud by learning dictionaries in the low-dimensional subspace. We are presenting our approach for an urban road scenario by reconstructing dense point clouds of 3D objects and comparing results based on PSNR and Hausdorff distance. © 2020 IEEE.","Automatic target recognition; E-learning; Embedded systems; Geology; Optical radar; Optical resolving power; Real time systems; Surveys; Autonomous navigation; Dictionary learning; Hausdorff distance; High-dimensional; Low-dimensional subspace; Missing information; Morphological features; Super resolution; Remote sensing","3D vision and perception; lidar point cloud super-resolution; online dictionary learning","Conference paper","Final","","Scopus","2-s2.0-85102015855"
"Zhang S.; Yuan Q.; Li J.; Sun J.; Zhang X.","Zhang, Shu (57221299696); Yuan, Qiangqiang (36635300800); Li, Jie (57214207213); Sun, Jing (57193669635); Zhang, Xuguo (24741253600)","57221299696; 36635300800; 57214207213; 57193669635; 24741253600","Scene-adaptive remote sensing image super-resolution using a multiscale attention network","2020","IEEE Transactions on Geoscience and Remote Sensing","58","7","8978758","4764","4779","15","10.1109/TGRS.2020.2966805","45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087462655&doi=10.1109%2fTGRS.2020.2966805&partnerID=40&md5=82ef394c8f852d55a77de015198e8eef","Remote sensing image super-resolution has always been a major research focus, and many deep-learning-based algorithms have been proposed in recent years. However, since the structure of remote sensing images tends to be much more complex than that of natural images, several difficulties still remain for remote sensing images super-resolution. First, it is difficult to depict the nonlinear mapping between high-resolution (HR) and low-resolution (LR) images of different scenes with the same model. Second, the wide range of scales within the ground objects in remote sensing images makes it difficult for single-scale convolution to effectively extract features of various scales. To address the above-mentioned issues, we propose a multiscale attention network (MSAN) to extract the multilevel features of remote sensing images. The basic component of MSAN is the multiscale activation feature fusion block (MAFB). In addition, a scene-adaptive super-resolution strategy for remote sensing images is employed to more accurately describe the structural characteristics of different scenes. The experiments undertaken on several data sets confirm that the proposed algorithm outperforms the other state-of-the-art algorithms, in both evaluation indices and visual results.  © 1980-2012 IEEE.","Deep learning; Image processing; Optical resolving power; Evaluation index; Learning-based algorithms; Low resolution images; Nonlinear mappings; Remote sensing images; State-of-the-art algorithms; Structural characteristics; Super resolution; artificial neural network; image analysis; image resolution; remote sensing; spectral resolution; Remote sensing","Channel attention; deep learning; multiscale activation; remote sensing imagery; scene adaptive","Article","Final","","Scopus","2-s2.0-85087462655"
"Yu J.; Li W.; Li Z.; Wu J.; Yang H.; Yang J.","Yu, Jianwen (57222248110); Li, Wenchao (55718616300); Li, Zhongyu (55707013700); Wu, Junjie (55713990900); Yang, Haiguang (23971854200); Yang, Jianyu (9239230100)","57222248110; 55718616300; 55707013700; 55713990900; 23971854200; 9239230100","SAR Image Super-Resolution Base on Weighted Dense Connected Convolutional Network","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324079","2101","2104","3","10.1109/IGARSS39084.2020.9324079","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101960512&doi=10.1109%2fIGARSS39084.2020.9324079&partnerID=40&md5=6fb86867e3bc97777a46890a64ac98af","In this paper, a weighted dense connected convolutional network(WDCCN) is proposed for SAR image super-resolution. In the network, to enhance feature propagation and the super-resolution performance, each layer will receive the output from all the previous layers in a different weight proportion. At last, the experimental results indicate that weighted dense connected convolutional network can realize SAR image super-resolution well. © 2020 IEEE.","Convolution; Convolutional neural networks; Geology; Optical resolving power; Remote sensing; Synthetic aperture radar; Convolutional networks; SAR Images; Super resolution; Radar imaging","convolutional network; SAR; super-resolution; weighted dense connection","Conference paper","Final","","Scopus","2-s2.0-85101960512"
"Li Z.; Zhang Y.","Li, Zhuang (57213189340); Zhang, Ye (57214252416)","57213189340; 57214252416","Hyperspectral Anomaly Detection via Image Super-Resolution Processing and Spatial Correlation","2021","IEEE Transactions on Geoscience and Remote Sensing","59","3","9140416","2307","2320","13","10.1109/TGRS.2020.3005924","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101817717&doi=10.1109%2fTGRS.2020.3005924&partnerID=40&md5=cad937565f892d6ffb432e0d649b8de8","Anomaly detection is a key problem in hyperspectral image (HSI) analysis with important remote sensing applications. Traditional methods for hyperspectral anomaly detection are mostly based on the distinctive statistical features of the HSIs. However, the anomaly-detection performance of these methods has been negatively impacted by two major limitations: 1) failure to consider the spatial pixel correlation and the ground-object correlation and 2) the existence of the mixing pixels caused by both lower spatial resolution and higher spectral resolution, which leads to higher false-alarm rates. In this article, these two problems are largely solved through a novel hyperspectral anomaly-detection method based on image super-resolution (SR) and spatial correlation. The proposed method encompasses two innovative ideas. First, based on the spectral variability in the anomaly targets, an extended linear mixing model can be obtained with more accurate ground-object information. Then, image SR is used to improve the spatial resolution of the HSIs by injecting the ground-object information from the mixing model. This alleviates the effect of mixed pixels on anomaly detection. Second, spatial correlation is exploited jointly with the global Reed-Xiaoli (GRX) method and the ground-object correlation detection for anomaly detection. Experimental results show that the proposed method not only effectively improves the hyperspectral spatial resolution and reduces the false-alarm rate but also increases the detectability with the spatial correlation information. Furthermore, the results for the real HSIs demonstrate that the proposed method achieves higher rates of anomaly detection with lower false-alarm rates. © 1980-2012 IEEE.","Alarm systems; Errors; Image enhancement; Image resolution; Mixing; Object detection; Optical resolving power; Pixels; Remote sensing; Spectroscopy; Correlation detection; Detection performance; Hyperspectral anomaly detection; Image super resolutions; Linear mixing models; Remote sensing applications; Spectral variability; Statistical features; correlation; detection method; numerical method; numerical model; pixel; spatial resolution; Anomaly detection","Anomaly detection; hyperspectral image (HSI); spatial correlation; spectral variability; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85101817717"
"Li F.; Yang X.; Lu X.; Xin L.; Lu M.; Zhang N.","Li, Feng (57171116800); Yang, Xue (57204629969); Lu, Xiaotian (57189345043); Xin, Lei (57183670600); Lu, Ming (56399795000); Zhang, Nan (57202033633)","57171116800; 57204629969; 57189345043; 57183670600; 56399795000; 57202033633","A new hyper-temporal imaging mode for spaceborne CMOS cameras; [面向星载CMOS相机的超时相工作方式研究]","2021","National Remote Sensing Bulletin","25","1","","514","525","11","10.11834/jrs.20210607","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103150866&doi=10.11834%2fjrs.20210607&partnerID=40&md5=3bfe4876a3fbff783e48989345698ff8","Spaceborne cameras are often called as detector resolution limited system. This is because the detector array generally suffer under sampling. Therefore, high frequency information beyond the detector sampling frequency will leak into the detector array, i.e. every remote sensing image will include some high frequency components. Since the platform keep drifting and vibrating even in the geostationary orbit, every remote sensing image contains unique high frequency information. By collecting those high frequency components from a sequence of images, a high resolution image can be reconstructed. This is the theoretical basis of super resolution technique. Moreover, with the widespread use of spaceborne CMOS array detectors, it is possible to obtain hyper-temporal data, which brings opportunities for spaceborne CMOS Cameras. A new hyper-temporal imaging mode for spaceborne CMOS cameras was proposed in the paper. By using a CMOS camera to continuously and quickly capture sequence of data, many frames of images within the same area can be extracted. By solving an ill-conditioned equation, high resolution images with improved quality can be achieved, that is, digital time delay integration TDI (Time Delay Integration), Modulation Transfer Function (MTF) and Super Resolution can be implemented at the same time. In general, engineers would like to set long expose time for spaceborne cameras to ensure SNR for remote sensing images. However, long expose time inevitable bring blur which severely decrease the quality of remote sensing images. The advantage of this new imaging method is that it can freeze the images to avoid blur as speckle imaging technique widely used in astronomy community. To reconstruct an improved quality and high resolution image, we need a good understanding of the whole process of capturing LR images. Since spaceborne cameras can only capture the reflected light from the surface of the earth and the reflected light suffers from the air turbulence and diffusion from the optical lens system. Therefore, mathematically modeling the image degenerating procedure is very important. As we all know that image restoration is an ill-conditioned problem. In terms of solving the ill-conditioned problem, a mixed sparse representations is used. In general, it is very difficult to find a common sparse representation for remote sensing images because of complicated ground features. In the paper, a remote sensing image is regarded as a combination of sub-image of smooth, edges and point components, respectively. Since each domain transformation method is only capable of representing a particular kind of ground objects or textures, a group of domain transformations are used to sparsely represent each sub-images. By using the generalized sparse representation, image restoration can be solved through the traditional L1 norm based optimal algorithm method the iterative thresholding algorithm. Experimental results based on the low-orbit optical remote sensing satellite OVS-1A, Jilin-1 video 03 satellite and the geostationary optical satellite GF-4 show that both the signal-to-noise ratio, image clarity and spatial resolution have been significantly improved. The proposed method holds promise to bring new remote sensing imagery products with high resolution of improved quality for satellites in orbit. Moreover, the method can also save the cost for future planned satellites by reducing the volume and weight of the optical camera payload. © 2021, Science Press. All right reserved.","Cameras; CMOS integrated circuits; Geostationary satellites; Image reconstruction; Imaging techniques; Iterative methods; Lenses; Optical resolving power; Orbits; Remote sensing; Restoration; Signal to noise ratio; Textures; Time delay; High frequency components; High resolution image; High-frequency informations; Ill conditioned problems; Iterative thresholding; Optical remote sensing; Remote sensing imagery; Time delay integration; Image enhancement","Hyper-temporal data; Low orbit optical remote sensing satellite; Modulation Transfer Function(MFT); Small satellite; Time Delay Integration(TDI)","Article","Final","","Scopus","2-s2.0-85103150866"
"Gao H.; Zhang G.; Huang M.","Gao, Han (57226673088); Zhang, Guifeng (57860011200); Huang, Min (57689140100)","57226673088; 57860011200; 57689140100","Hyperspectral Image Super-Resolution via Structure-Tensor-Based Image Matting","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","","","","","","10.1109/JSTARS.2021.3102579","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112140105&doi=10.1109%2fJSTARS.2021.3102579&partnerID=40&md5=dcbbf8f0fd2832e457cd65de71b0e7c0","Hyperspectral (HS) imaging has achieved breakthroughs in many applications, such as remote sensing and object recognition. However, the spatial resolution of HS images is still insufficient due to the limitations of sensor technology and cost. In this paper, we propose an HS image super-resolution method that combines low-resolution (LR) HS images and high-resolution (HR) panchromatic (PAN) images. To exploit the spectral signatures in the LR-HS images while introducing details from the HR-PAN images during the image fusion procedure, an image matting model is used to fuse the original LR-HS images and the HR-PAN images. Specifically, to preserve the spectral components during the fusion procedure, two different alpha channels in the image matting model are generated based on the HS and PAN image structure tensors, which suppress spectral distortion and improve the quality of the reconstructed HR-HS image. Experimental results based on public datasets demonstrate the advantage of our proposed method in both preserving spectral information and enhancing HS image spatial resolution. CCBY","Hydraulic structures; Hyperspectral imaging; Image fusion; Image resolution; Object recognition; Optical resolving power; Remote sensing; Spectroscopy; Tensors; Image spatial resolution; Image super resolutions; Panchromatic (Pan) image; Sensor technologies; Spectral components; Spectral distortions; Spectral information; Spectral signature; Image enhancement","Distortion; Hyperspectral image; Hyperspectral imaging; image matting; Image reconstruction; Imaging; Spatial resolution; structure tensor; super-resolution; Superresolution; Tensors","Article","Article in press","All Open Access; Gold Open Access","Scopus","2-s2.0-85112140105"
"Geng T.; Liu X.-Y.; Wang X.; Sun G.","Geng, Tianyu (56816531700); Liu, Xiao-Yang (44361326100); Wang, Xiaodong (56461470100); Sun, Guiling (56310314900)","56816531700; 44361326100; 56461470100; 56310314900","Deep Shearlet Residual Learning Network for Single Image Super-Resolution","2021","IEEE Transactions on Image Processing","30","","9394753","4129","4142","13","10.1109/TIP.2021.3069317","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103767579&doi=10.1109%2fTIP.2021.3069317&partnerID=40&md5=2d32fe3043f5961bd3c03293272de9ea","Recently, the residual learning strategy has been integrated into the convolutional neural network (CNN) for single image super-resolution (SISR), where the CNN is trained to estimate the residual images. Recognizing that a residual image usually consists of high-frequency details and exhibits cartoon-like characteristics, in this paper, we propose a deep shearlet residual learning network (DSRLN) to estimate the residual images based on the shearlet transform. The proposed network is trained in the shearlet transform-domain which provides an optimal sparse approximation of the cartoon-like image. Specifically, to address the large statistical variation among the shearlet coefficients, a dual-path training strategy and a data weighting technique are proposed. Extensive evaluations on general natural image datasets as well as remote sensing image datasets show that the proposed DSRLN scheme achieves close results in PSNR to the state-of-the-art deep learning methods, using much less network parameters.  © 1992-2012 IEEE.","Convolutional neural networks; Learning systems; Optical resolving power; Remote sensing; High frequency HF; Learning strategy; Network parameters; Remote sensing images; Shearlet transforms; Sparse approximations; Statistical variations; Weighting techniques; art; article; deep learning; remote sensing; Deep learning","convolutional neural network; residual learning; shearlet transform; Single image super-resolution","Article","Final","","Scopus","2-s2.0-85103767579"
"Mao D.; Zhang Y.; Zhang Y.; Huo W.; Pei J.; Huang Y.","Mao, Deqing (57194656090); Zhang, Yongchao (56042343300); Zhang, Yin (55975581400); Huo, Weibo (56405211000); Pei, Jifang (55787739300); Huang, Yulin (23014806800)","57194656090; 56042343300; 55975581400; 56405211000; 55787739300; 23014806800","Target fast reconstruction of real aperture radar using data extrapolation-based parallel iterative adaptive approach","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9335023","2258","2269","11","10.1109/JSTARS.2021.3054046","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100510817&doi=10.1109%2fJSTARS.2021.3054046&partnerID=40&md5=5e1e9051593ac66fc5cff850b7242118","Real aperture radar (RAR) usually sweeps a wide sector to continuously observe the scenario of interest. Because its angular resolution is limited by the size of the antenna aperture, target reconstruction methods are widely applied to obtain super-resolution radar images. However, the wide-sector processing mode suffers from high operational complexity because of the high-dimensional matrix inversion. Even worse, for the targets located at the scene edge, its echo data are received less than half beamwidth. The incomplete echo data will lead to the deformation of the reconstructed targets by existing reconstruction methods. To overcome the two problems, a data extrapolation-based parallel iterative adaptive approach is proposed to fast reconstruct the targets in the whole sector without the distortion at the scene edge. First, the echo model of RAR is repaired to remedy the model error. Then, based on the correlation of the echo data within one beamwidth, an autoregressive model is adopted to extrapolate the data of the missing half beamwidth. Finally, a parallel iterative adaptive approach method is proposed to efficiently recover the targets by exploiting the regular characteristics of the repaired steering matrix. Simulations and experimental data are applied to verify the proposed method. © 2008-2012 IEEE.","Antennas; Extrapolation; Iterative methods; Radar; Angular resolution; Auto regressive models; Data extrapolation; Fast reconstruction; Iterative adaptive approaches (IAA); Operational complexity; Real aperture radar; Reconstruction method; complexity; correlation; error analysis; image resolution; model test; radar imagery; reconstruction; remote sensing; Matrix algebra","Parallel iterative adaptive approach (PIAA); real aperture radar (RAR); scene edge target reconstruction; super-resolution imaging","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85100510817"
"Zhang J.; Wan Z.; Shao M.; Li Y.","Zhang, Jing (57276842200); Wan, Zekang (57221564292); Shao, Minhao (57217281230); Li, Yunsong (55986546100)","57276842200; 57221564292; 57217281230; 55986546100","A Multi-path Neural Network for Hyperspectral Image Super-Resolution","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12890 LNCS","","","377","387","10","10.1007/978-3-030-87361-5_31","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117073253&doi=10.1007%2f978-3-030-87361-5_31&partnerID=40&md5=860f2e97c1ec7326ce9dd7adf74745df","The resolution of hyperspectral remote sensing images is largely limited by the cost and commercialization requirements of remote sensing satellites. Existing super-resolution methods for improving the spatial resolution of images cannot well integrate the correlation between spectral segments and the problem of excessive network parameters caused by high-dimensional characteristics. This paper studies a multipath-based residual feature learning method, which simplifies each part of the network into several simple and effective network modules to learn the spatial spectral features between different spectral segments. Through the designed multi-scale feature generation method based on wavelet transform and spatial attention mechanism, the non-linear mapping ability for features is effectively improved. The verification of three general hyperspectral data sets proves the superiority of this method compared with the existing hyperspectral SR methods. © 2021, Springer Nature Switzerland AG.","Image enhancement; Learning systems; Remote sensing; Spectroscopy; Wavelet transforms; Attention mechanisms; Commercialisation; Hyperspectral Remote Sensing Image; Image super resolutions; Multi-path architecture; Multipath; Neural-networks; Remote sensing satellites; Superresolution; Superresolution methods; Optical resolving power","Attention mechanism; Hyperspectral image; Multi-path architecture; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85117073253"
"Mao D.; Zhang Y.; Kang Y.; Zhang Y.; Huo W.; Huang Y.; Yang J.","Mao, Deqing (57194656090); Zhang, Yongchao (56042343300); Kang, Yao (57211242158); Zhang, Yin (55975581400); Huo, Weibo (56405211000); Huang, Yulin (23014806800); Yang, Jianyu (9239230100)","57194656090; 56042343300; 57211242158; 55975581400; 56405211000; 23014806800; 9239230100","Scene Edge Target Recovery of Scanning Radar Angular Super-Resolution Based on Data Extrapolation","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323387","6718","6721","3","10.1109/IGARSS39084.2020.9323387","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101955419&doi=10.1109%2fIGARSS39084.2020.9323387&partnerID=40&md5=91940c3647f7f60c5c2898052023c6fe","Radar antenna can work in scanning mode to obtain a wide region observation. However, for the targets located at the scene edge, the targets are only swept by less than half of the radar beam. Therefore, the scene edge targets are recovered distortedly using the conventional angular super-resolution methods. To keep the performance of recovered targets in the full scene, in this paper, a data extrapolation-based parallel iterative adaptive approach (PIAA) is proposed. First, we analyze the cause of scene edge target distortion. Then, the echo data is extrapolated by half of the radar beam to compensate the unobserved data. Last, a parallel iterative adaptive approach is proposed to recover the targets efficiently. Simulation data is applied to verify the proposed method. © 2020 IEEE.","Extrapolation; Geology; Iterative methods; Optical resolving power; Radar antennas; Recovery; Remote sensing; Scanning antennas; Data extrapolation; Iterative adaptive approaches (IAA); Scanning mode; Scanning radar; Simulation data; Super resolution; Superresolution methods; Target recovery; Radar","angular super-resolution; data extrapolation; parallel iterative adaptive approach; Scanning radar; scene edge target recovery","Conference paper","Final","","Scopus","2-s2.0-85101955419"
"Liu B.; Li H.; Zhou Y.; Peng Y.; Elazab A.; Wang C.","Liu, Bo (57221214127); Li, Heng (57220036007); Zhou, Yutao (57220033102); Peng, Yuqing (57220025030); Elazab, Ahmed (56523141500); Wang, Changmiao (57226651647)","57221214127; 57220036007; 57220033102; 57220025030; 56523141500; 57226651647","A super resolution method for remote sensing images based on cascaded conditional wasserstein GANs","2020","2020 3rd IEEE International Conference on Information Communication and Signal Processing, ICICSP 2020","","","9232066","284","289","5","10.1109/ICICSP50920.2020.9232066","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096514768&doi=10.1109%2fICICSP50920.2020.9232066&partnerID=40&md5=8a44523392137bdab79644c5f0436c29","High-resolution (HR) remote sensing imagery is quite beneficial for subsequent interpretation. Obtaining HR images can be achieved by upgrading the imaging device. Yet, the cost to perform this task is very huge. Thus, it is necessary to obtain HR images from low-resolution (LR) ones. In the literature, the super-resolution image reconstruction methods based on deep learning have unparalleled advantages in comparison to traditional reconstruction methods. This work is inspired by these current mainstream methods and proposes a novel cascaded conditional Wasserstein generative adversarial network (CCWGAN) architecture with the residual dense block to generate high quality remote sensing images. We validate the proposed method on the NWPU VHR-10 dataset. Experimental results show our CCWGAN method has superior performance compared with the state-of-the-art GAN methods. © 2020 IEEE.","Deep learning; Image reconstruction; Optical resolving power; Adversarial networks; High resolution; Reconstruction method; Remote sensing imagery; Remote sensing images; State of the art; Super-resolution image reconstruction; Superresolution methods; Remote sensing","Cascaded conditional generative adversarial networks; Remote sensing images; Residual dense block; Wasserstein generative adversarial networks","Conference paper","Final","","Scopus","2-s2.0-85096514768"
"","","","7th International Conference of Pioneering Computer Scientists, Engineers and Educators, ICPCSEE 2021","2021","Communications in Computer and Information Science","1451","","","","","1055","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115417831&partnerID=40&md5=8e3ecb39f537ed5de5801347839e6843","The proceedings contain 81 papers. The special focus in this conference is on Pioneering Computer Scientists, Engineers and Educators. The topics include: MA Mask R-CNN: MPR and AFPN Based Mask R-CNN; improved Non-negative Matrix Factorization Algorithm for Sparse Graph Regularization; a Blockchain-Based Scheme of Data Sharing for Housing Provident Fund; intelligent Storage System of Machine Learning Model Based on Task Similarity; predicting Stock Price Movement with Multiple Data Sources and Machine Learning Models; channel Context and Dual-Domain Attention Based U-Net for Skin Lesion Attributes Segmentation; study on the Protection and Product Development of Intangible Cultural Heritage with Computer Virtual Reality Technology; ECG-Based Arrhythmia Detection Using Attention-Based Convolutional Neural Network; Quantum Color Image Scaling on QIRHSI Model; WSN Data Compression Model Based on K-SVD Dictionary and Compressed Sensing; human Body Pose Recognition System Based on Teaching Interaction; adaptive Densely Residual Network for Image Super-Resolution; Real-Time Image and Video Artistic Style Rendering System Based on GPU; semantic Segmentation of High Resolution Remote Sensing Images Based on Improved ResU-Net; Exploring Classification Capability of CNN Features; generative Adversarial Network Based Status Generation Simulation Approach; the Construction of Case Event Logic Graph for Judgment Documents; anti-obfuscation Binary Code Clone Detection Based on Software Gene; thread Private Variable Access Optimization Technique for Sunway High-Performance Multi-core Processors; parallel Region Reconstruction Technique for Sunway High-Performance Multi-core Processors; research on Route Optimization of Battlefield Collection Equipment Based on Improved Ant Algorithm; a Collaborative Cache Strategy Based on Utility Optimization; integrating Local Closure Coefficient into Weighted Networks for Link Prediction.","","","Conference review","Final","","Scopus","2-s2.0-85115417831"
"Saxena N.","Saxena, Nikita (57546917300)","57546917300","Efficient Downscaling of Satellite Oceanographic Data with Convolutional Neural Networks","2020","GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems","","","","659","660","1","10.1145/3397536.3429335","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097261665&doi=10.1145%2f3397536.3429335&partnerID=40&md5=8f5b79d344b31e04f216cf0fbe886d96","Space-borne satellite radiometers measure Sea Surface Temperature (SST), which is pivotal to studies of air-sea interactions and ocean features. Under clear sky conditions, high resolution measurements are obtainable. But under cloudy conditions, data analysis is constrained to the available low resolution measurements. We assess the efficiency of Deep Learning (DL) architectures, particularly Convolutional Neural Networks (CNN) to downscale oceanographic data from low spatial resolution (SR) to high SR. With a focus on SST Fields of Bay of Bengal, this study proves that Very Deep Super Resolution CNN can successfully reconstruct SST observations from 15 km SR to 5km SR, and 5km SR to 1km SR. This outcome calls attention to the significance of DL models explicitly trained for the reconstruction of high SR SST fields by using low SR data. Inference on DL models can act as a substitute to the existing computationally expensive downscaling technique: Dynamical Downsampling. The complete code is available on this Github Repository.  © 2020 ACM.","Convolution; Deep learning; Geographic information systems; Information systems; Information use; Oceanography; Surface waters; Air sea interactions; Cloudy conditions; High-resolution measurements; Oceanographic data; Satellite radiometer; Sea surface temperature (SST); Spatial resolution; Super resolution; Convolutional neural networks","Deep Convolutional Neural Networks; Ocean Remote Sensing Data; Single Image Super Resolution","Conference paper","Final","","Scopus","2-s2.0-85097261665"
"Aburaed N.; Alkhatib M.Q.; Marshall S.; Zabalza J.; Al Ahmad H.","Aburaed, Nour (56943462800); Alkhatib, Mohammed Q. (52463211300); Marshall, Stephen (7401823400); Zabalza, Jaime (55825361600); Al Ahmad, Hussain (57222050810)","56943462800; 52463211300; 7401823400; 55825361600; 57222050810","3D Expansion of SRCNN for Spatial Enhancement of Hyperspectral Remote Sensing Images","2021","2021 4th International Conference on Signal Processing and Information Security, ICSPIS 2021","","","","9","12","3","10.1109/ICSPIS53734.2021.9652420","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124407138&doi=10.1109%2fICSPIS53734.2021.9652420&partnerID=40&md5=27aafcc7df5088fb2db6a3ab2e00949a","Hyperspectral Imagery (HSI) have high spectral resolution but suffer from low spatial resolution due to sensor tradeoffs. This limitation hinders utilizing the full potential of HSI. Single Image Super Resolution (SISR) techniques can be used to enhance the spatial resolution of HSI. Since these techniques rely on estimating missing information from one Low Resolution (LR) HSI, they are considered ill-posed. Furthermore, most spatial enhancement techniques cause spectral distortions in the estimated High Resolution (HR) HSI. This paper deals with the extension and modification of Convolutional Neural Networks (CNNs) to enhance HSI while preserving their spectral fidelity. The proposed method is tested, evaluated, and compared against other methodologies quantitatively using Peak Signal-to-noise Ratio (PSNR), Structural Similarity Index Measurement (SSIM), and Spectral Angle Mapper (SAM).  © 2021 IEEE.","Convolutional neural networks; Image enhancement; Image resolution; Remote sensing; Signal to noise ratio; Spectral resolution; Spectroscopy; 3d convolution; Hyper-spectral imageries; HyperSpectral; Hyperspectral Remote Sensing Image; Image super resolutions; Remote-sensing; Single image super resolution; Single images; Spatial enhancement; Spatial resolution; Convolution","3D convolution; Hyperspectral; remote sensing; single image super resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85124407138"
"Salvetti F.; Mazzia V.; Khaliq A.; Chiaberge M.","Salvetti, Francesco (57214105353); Mazzia, Vittorio (57212264110); Khaliq, Aleem (57212264656); Chiaberge, Marcello (7003345054)","57214105353; 57212264110; 57212264656; 7003345054","Multi-image super resolution of remotely sensed images using residual attention deep neural networks","2020","Remote Sensing","12","14","2207","","","","10.3390/rs12142207","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088648851&doi=10.3390%2frs12142207&partnerID=40&md5=b24e2d55636fa44143fbe5b4e9bc6fd2","Convolutional Neural Networks (CNNs) consistently proved state-of-the-art results in image Super-resolution (SR), representing an exceptional opportunity for the remote sensing field to extract further information and knowledge from captured data. However, most of the works published in the literature focused on the Single-image Super-resolution problem so far. At present, satellite-based remote sensing platforms offer huge data availability with high temporal resolution and low spatial resolution. In this context, the presented research proposes a novel residual attention model (RAMS) that efficiently tackles the Multi-image Super-resolution task, simultaneously exploiting spatial and temporal correlations to combine multiple images. We introduce the mechanism of visual feature attention with 3D convolutions in order to obtain an aware data fusion and information extraction of the multiple low-resolution images, transcending limitations of the local region of convolutional operations. Moreover, having multiple inputs with the same scene, our representation learning network makes extensive use of nestled residual connections to let flow redundant low-frequency signals and focus the computation on more important high-frequency components. Extensive experimentation and evaluations against other available solutions, either for Single or Multi-image Super-resolution, demonstrated that the proposed deep learning-based solution can be considered state-of-the-art for Multi-image Super-resolution for remote sensing applications. © 2020 by the authors.","Convolution; Convolutional neural networks; Data fusion; Data mining; Deep learning; Deep neural networks; Optical resolving power; Remote sensing; High frequency components; High temporal resolution; Image super resolutions; Low resolution images; Remote sensing applications; Remote sensing platforms; Remotely sensed images; Spatial and temporal correlation; Image processing","3D convolutional neural networks; Attention networks; Deep learning; Multi-image super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85088648851"
"Vella M.; Zhang B.; Chen W.; Mota J.F.C.","Vella, Marija (57217524998); Zhang, Bowen (57226875391); Chen, Wei (57231024200); Mota, João F.C. (49061361500)","57217524998; 57226875391; 57231024200; 49061361500","ENHANCED HYPERSPECTRAL IMAGE SUPER-RESOLUTION VIA RGB FUSION AND TV-TV MINIMIZATION","2021","Proceedings - International Conference on Image Processing, ICIP","2021-September","","","3837","3841","4","10.1109/ICIP42928.2021.9506715","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123975960&doi=10.1109%2fICIP42928.2021.9506715&partnerID=40&md5=928129062ba32ad99e9576d90f366b55","Hyperspectral (HS) images contain detailed spectral information that has proven crucial in applications like remote sensing, surveillance, and astronomy. However, because of hardware limitations of HS cameras, the captured images have low spatial resolution. To improve them, the low-resolution hyperspectral images are fused with conventional high-resolution RGB images via a technique known as fusion based HS image super-resolution. Currently, the best performance in this task is achieved by deep learning (DL) methods. Such methods, however, cannot guarantee that the input measurements are satisfied in the recovered image, since the learned parameters by the network are applied to every test image. Conversely, model-based algorithms can typically guarantee such measurement consistency. Inspired by these observations, we propose a framework that integrates learning and model based methods. Experimental results show that our method produces images of superior spatial and spectral resolution compared to the current leading methods, whether model- or DL-based. © 2021 IEEE.","Deep learning; Hyperspectral imaging; Image fusion; Learning systems; Optical resolving power; Remote sensing; Security systems; Spectroscopy; Deep learning; Hyper-spectral cameras; HyperSpectral; Image super resolutions; Minimisation; Optimisations; Remote-sensing; Spectral information; Superresolution; Total-variation; Image enhancement","Deep learning; Hyper-spectral imaging; Optimization; Super-resolution; Total variation","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85123975960"
"Xiao M.; He Z.; Wu J.","Xiao, Man (57222244031); He, Zhi (36604533800); Wu, Jiemin (57211501464)","57222244031; 36604533800; 57211501464","PySRResNet: Super Resolution for Video Satellite Imagery via Pyramid Residual Network","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323125","2105","2108","3","10.1109/IGARSS39084.2020.9323125","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101962629&doi=10.1109%2fIGARSS39084.2020.9323125&partnerID=40&md5=9cf3d4d71edcf94f34511abd4f88b33f","Video satellite is of great significance in change detection and military reconnaissance due to its high temporal resolution. However, restricted by the hardware conditions, spatial resolution must be sacrificed if temporal resolution is to be guaranteed. Because of this, how to reconstruct super resolution (SR) video satellite data is particularly important. Based on the proposed SR Residual Network (SRResNet), we proposed a Pyramid Residual Network (PySRResNet) model, using a pyramid structure to obtain features of different scales, including 1, 1/2 and 1/4, and concatenate them together to provide more detailed information for SR reconstruction. In addition, we reduced the number of blocks and removed the batch normalization layer to achieve good performance. Training with 'Jilin-1' video satellite images, our PySRResNet can get superior grades than other comparing models both in PSNR and SSIM, which demonstrates the effectiveness of PySRResNet in video satellite imagery SR reconstruction. © 2020 IEEE.","Geology; Optical resolving power; Remote sensing; Satellite imagery; Change detection; High temporal resolution; Military reconnaissance; Number of blocks; Pyramid structure; Satellite images; Spatial resolution; Temporal resolution; Image reconstruction","multi-scale features; PySRResNet; super resolution; video satellite images","Conference paper","Final","","Scopus","2-s2.0-85101962629"
"Wu C.; Li J.; Song R.; Li Y.","Wu, Chaoxiong (57218706945); Li, Jiaojiao (55934244200); Song, Rui (36460216100); Li, Yunsong (55986546100)","57218706945; 55934244200; 36460216100; 55986546100","Spectral Super-Resolution Using Hybrid 2D-3D Structure Tensor Attention Networks with Camera Spectral Sensitivity Prior","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323553","1857","1860","3","10.1109/IGARSS39084.2020.9323553","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101955422&doi=10.1109%2fIGARSS39084.2020.9323553&partnerID=40&md5=daadfd260182952fd5530ae2298d5e08","With the development of deep convolutional neural networks (CNNs), spectral super-resolution (SSR) has obtained a significant improvement, which aims to recover the hyperspectral image (HSI) from a single RGB. However, the existing mapping algorithms lack of utilization of the camera spectral sensitivity (CSS) and only focus on wider or deeper architecture design, neglecting to explore the feature correlations of intermediate layers, thus preventing the representational ability of CNNs. In our paper, a novel hybrid 2D-3D structure tensor attention networks (HSTAN) with CSS prior is proposed for SSR. In specific, a structure tensor attention (STA) embedded in the residual block is invented to extract the salient high-frequency spatial details for adequate spatial feature expression. Furthermore, the CSS is firstly exploited as a prior to avoid its influence of SSR quality, based on which the reconstructed RGB can be calculated naturally through the super-resolved HSI, then the final loss incorporates the discrepancies of RGB and the HSI as a finer constraint. Experimental results demonstrate the superiority of our proposed algorithm. © 2020 IEEE.","Cameras; Conformal mapping; Convolutional neural networks; Deep neural networks; Geology; Image enhancement; Optical resolving power; Photomapping; Remote sensing; Tensors; Architecture designs; Feature correlation; High frequency HF; Intermediate layers; Mapping algorithms; Spatial features; Spectral sensitivity; Structure tensors; Spectroscopy","camera spectral sensitivity prior; HSTAN; SSR; structure tensor attention","Conference paper","Final","","Scopus","2-s2.0-85101955422"
"Ji Leong W.; Joseph Horgan H.","Ji Leong, Wei (57219904637); Joseph Horgan, Huw (16205109500)","57219904637; 16205109500","DeepBedMap: A deep neural network for resolving the bed topography of Antarctica","2020","Cryosphere","14","11","","3687","3705","18","10.5194/tc-14-3687-2020","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096017317&doi=10.5194%2ftc-14-3687-2020&partnerID=40&md5=1a4344613cbc69353ef3ed92854b30ba","To resolve the bed elevation of Antarctica, we present DeepBedMap - a novel machine learning method that can produce Antarctic bed topography with adequate surface roughness from multiple remote sensing data inputs. The super-resolution deep convolutional neural network model is trained on scattered regions in Antarctica where high-resolution (250 m) ground-truth bed elevation grids are available. This model is then used to generate high-resolution bed topography in less surveyed areas. DeepBedMap improves on previous interpolation methods by not restricting itself to a low-spatial-resolution (1000 m) BEDMAP2 raster image as its prior image. It takes in additional high-spatialresolution datasets, such as ice surface elevation, velocity and snow accumulation, to better inform the bed topography even in the absence of ice thickness data from direct icepenetrating-radar surveys. The DeepBedMap model is based on an adapted architecture of the Enhanced Super-Resolution Generative Adversarial Network, chosen to minimize perpixel elevation errors while producing realistic topography. The final product is a four-times-upsampled (250 m) bed elevation model of Antarctica that can be used by glaciologists interested in the subglacial terrain and by ice sheet modellers wanting to run catchment- or continent-scale ice sheet model simulations. We show that DeepBedMap offers a rougher topographic profile compared to the standard bicubically interpolated BEDMAP2 and BedMachine Antarctica and envision it being used where a high-resolution bed elevation model is required.  © Author(s) 2020.","Antarctica; artificial neural network; cryosphere; topography","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85096017317"
"Ye C.; Yan L.; Zhang Y.; Zhan J.; Yang J.; Wang J.","Ye, Chongjun (57456821300); Yan, Lingyu (55359361400); Zhang, Yucheng (57331477900); Zhan, Jun (57457015100); Yang, Jie (57839564200); Wang, Junfang (57457000000)","57456821300; 55359361400; 57331477900; 57457015100; 57839564200; 57457000000","A Super-resolution Method of Remote Sensing Image Using Transformers","2021","Proceedings of the 11th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications, IDAACS 2021","2","","","905","910","5","10.1109/IDAACS53288.2021.9660904","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124795668&doi=10.1109%2fIDAACS53288.2021.9660904&partnerID=40&md5=0f59299da3a6c35943c191bac8fe431a","This paper proposes a Transformers-based super-resolution method for remote sensing images. Firstly, a remote sensing image super-resolution network based on convolutional neural network and Transformer module is constructed; then the training data is used to train the remote sensing image super-resolution network and the optimized network parameters are obtained; finally, the trained remote sensing image super-resolution network is used to super-resolve low-resolution remote sensing images to obtain high-resolution remote sensing images. Experiments are conducted on the public remote sensing dataset (UC Mercedes) and compared with several traditional super-resolution algorithms. The results show that the present algorithm is highly automated and has improved in both accuracy and efficiency.  © 2021 IEEE.","Convolution; Convolutional neural networks; Remote sensing; Convolutional neural network; Image super resolutions; Lower resolution; Network parameters; Network-based; Remote sensing images; Superresolution; Superresolution methods; Training data; Transformer; Optical resolving power","Convolutional Neural Networks(CNNs); Remote Sensing Image; Super-resolution; Transformers","Conference paper","Final","","Scopus","2-s2.0-85124795668"
"Rohith G.; Kumar L.S.","Rohith, G. (57217188288); Kumar, L.S. (35778418900)","57217188288; 35778418900","Effectiveness of Super-Resolution Technique on Vegetation Indices","2021","IEEE Access","9","","9471881","97197","97227","30","10.1109/ACCESS.2021.3094283","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110485693&doi=10.1109%2fACCESS.2021.3094283&partnerID=40&md5=0e2388bd021d8a5ba877bdd99aa61b79","The identification and interpretation of remote sensed (RS) objects in an image depend on how well the sensor captures the region. In rare cases, RS images may be vulnerable to a lack of interpretability issues in some parts of the image due to the sensor's limits and preprocessing techniques. Conventionally, the interpretation of the land cover pattern's shape and size is apparent when the distance between the sensor and object is closer to the visualization level of objects and viable with digital airborne imagery. In this paper, an integration of the Super-Resolution (SR) technique in the high-resolution imagery to achieve the closer visualization level for mapping the vegetation is proposed. This approach enables the higher interpretive potential to define the land pattern's shape and size with very high spatial resolution, closer proximity, detailed and distinguishable patterns. This approach helps to precisely predict the total vegetated study area for land use and land cover changes (LULCC) and chlorophyll-rich vegetation applications. The proposed algorithm is carried out in two phases. In the first phase, the SR technique applied test images are tested for vegetation detection and mapping the vegetation information in a region with fourteen vegetation indices. In the second phase, similar testing is done without applying SR for input test images. The experiment revealed that test images using the SR technique yielded higher average values of 5 percent and 1 percent for the Normalized Difference Vegetation Index (NDVI) and Fractional Vegetation Cover (FVC), respectively, as compared to images tested using the non-SR technique.  © 2013 IEEE.","Land use; Mapping; Mechanical variables measurement; Optical resolving power; Remote sensing; Vegetation; Visualization; Fractional vegetation cover; High resolution imagery; Identification and Interpretation; Land use and land cover change; Normalized difference vegetation index; Preprocessing techniques; Super resolution; Very high spatial resolutions; Image processing","convolutional neural networks; ground sampling distance (GSD); NDVI; Vegetation mapping","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85110485693"
"Chen L.; Liu H.; Yang M.; Qian Y.; Xiao Z.; Zhong X.","Chen, Long (57224988947); Liu, Hui (57271529100); Yang, Minhang (57271395900); Qian, Yurong (26027209500); Xiao, Zhengqing (57271804400); Zhong, Xiwu (57271946700)","57224988947; 57271529100; 57271395900; 26027209500; 57271804400; 57271946700","Remote Sensing Image Super-Resolution via Residual Aggregation and Split Attentional Fusion Network","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","","9546","9556","10","10.1109/JSTARS.2021.3113658","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115701558&doi=10.1109%2fJSTARS.2021.3113658&partnerID=40&md5=3ecbf467c5d00ab5eb34939cd687ac73","Remote sensing images contain various land surface scenes and different scales of ground objects, which greatly increases the difficulty of super-resolution tasks. The existing deep learning-based methods cannot solve this problem well. To achieve high-quality super-resolution of remote sensing images, a residual aggregation and split attentional fusion network (RASAF) is proposed in this article. It is mainly divided into the following three parts. First, a split attentional fusion block is proposed. It uses a basic split-fusion mechanism to achieve cross-channel feature group interaction, allowing the method to adapt to various land surface scene reconstructions. Second, to fully exploit multiscale image information, a hierarchical loss function is used. Third, residual learning is used to reduce the difficulty of training in super-resolution tasks. However, the respective residual branch features are used quite locally and fail to represent the real value. A residual aggregation mechanism is used to aggregate the local residual branch features to generate higher quality local residual branch features. The comparison of RASAF with some classical super-resolution methods using two widely used remote sensing datasets showed that the RASAF achieved better performance. And it achieves a good balance between performance and model parameter number. Meanwhile, the RASAF's ability to support multilabel remote sensing image classification tasks demonstrates its usefulness. © 2008-2012 IEEE.","Deep learning; Image fusion; Image reconstruction; Job analysis; Remote sensing; Surface measurement; Features extraction; Images reconstruction; Remote sensing images; Remote-sensing; Residual aggregation; Split attentional fusion; Super-resolution; Superresolution; Task analysis; image classification; image resolution; land surface; reconstruction; remote sensing; Optical resolving power","Remote sensing image; residual aggregation; split attentional fusion; super-resolution (SR)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85115701558"
"Zhao X.; Zhang X.","Zhao, Xiaodong (55705116900); Zhang, Xunying (57210568648)","55705116900; 57210568648","Multi-Frame Super-Resolution Reconstruction Algorithm of Optical Remote Sensing Images Based on Double Regularization Terms and Unsupervised Learning","2021","International Journal of Pattern Recognition and Artificial Intelligence","35","1","2154002","","","","10.1142/S0218001421540021","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095123990&doi=10.1142%2fS0218001421540021&partnerID=40&md5=e66286efe4b37b94dd676b1dd2719e00","High-resolution images have always been in urgent need in the fields of surveying, mapping, military and civilian. In this paper, first, based on anisotropic nonlinear diffusion tensor, a diffusion tensor regularization term which can make full use of direction selection smoothing property was constructed. Based on the improved gradient vector field (GVF), a regularization term which can constrain the continuity of gradient vectors for high-resolution and low-resolution images was constructed. On the basis of these, a multi-frame super-resolution reconstruction algorithm based on double regularization terms was proposed and verified by simulation. Second, combining PCA with adaptive dictionary learning, two constraints of reconstruction regularity based on improved nonlocal means and kernel regression were proposed for experimental verification, and an improved K-means clustering algorithm for initial centre selection of spatial characteristic measure clustering was proposed to enhance the stability of the algorithm. Then high-resolution image generated by learning method was used as the initial input of multi-frame reconstruction of optical remote sensing images. The experimental results show that the reconstruction algorithm based on partial differential equation and unsupervised learning achieves both subjective and objective results for the realization of super-resolution reconstruction of optical remote sensing images. © 2021 World Scientific Publishing Company.","Image enhancement; K-means clustering; Learning algorithms; Learning systems; Military photography; Optical resolving power; Remote sensing; Tensors; Unsupervised learning; Adaptive dictionary learning; Experimental verification; Improved k-means clustering; Low resolution images; Optical remote sensing; Reconstruction algorithms; Spatial characteristics; Super resolution reconstruction; Image reconstruction","area array and linear array; double regularization terms; Multi-frame super-resolution reconstruction; optical remote sensing images; unsupervised learning","Article","Final","","Scopus","2-s2.0-85095123990"
"Nguyen H.V.; Ulfarsson M.O.; Sveinsson J.R.; Sigurdsson J.","Nguyen, Han V. (57222240069); Ulfarsson, Magnus O. (6507677875); Sveinsson, Johannes R. (7003642214); Sigurdsson, Jakob (7006736374)","57222240069; 6507677875; 7003642214; 7006736374","Zero-Shot Sentinel-2 Sharpening Using a Symmetric Skipped Connection Convolutional Neural Network","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323614","613","616","3","10.1109/IGARSS39084.2020.9323614","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102005792&doi=10.1109%2fIGARSS39084.2020.9323614&partnerID=40&md5=ec6e2abccbe671f05365f718490b7c6e","Sentinel-2 (S2) satellite constellations can provide multispectral images of 10 m, 20 m, and 60 m resolution for visible, near-infrared (NIR) and short-wave infrared (SWIR) in the electromagnetic spectrum. In this paper, we present a sharpening method based on a symmetric skipped connection convolutional neural network, called SSC-CNN, to sharpen 20 m bands using 10 m bands. The main advantage of SSC-CNN architecture is that it brings the features of the input branch to the output, thus improving convergence without using too many deep layers. The proposed method uses the reduced-scale combination of 10 m bands and 20 m bands, and the observed 20 m bands as the training pairs. The experimental results using two Sentinel-2 datasets show that our method outperforms competitive methods in quantitative metrics and visualization. © 2020 IEEE.","Convolution; Geology; Infrared devices; Infrared radiation; Remote sensing; Deep layer; Electromagnetic spectra; Multispectral images; Near infra red; Quantitative metrics; Reduced scale; Satellite constellations; Short wave infrared; Convolutional neural networks","convolutional neural network; image fusion; image sharpening; Sentinel-2; super resolution","Conference paper","Final","","Scopus","2-s2.0-85102005792"
"Ma F.; Huo S.; Yang F.","Ma, Fei (55245276100); Huo, Shuai (57226523502); Yang, Feixia (57194184931)","55245276100; 57226523502; 57194184931","Graph-Based Logarithmic Low-Rank Tensor Decomposition for the Fusion of Remotely Sensed Images","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","","11271","11286","15","10.1109/JSTARS.2021.3123466","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118584609&doi=10.1109%2fJSTARS.2021.3123466&partnerID=40&md5=792b0718f7fe404a685e9fdea98c98ea","Hyperspectral images with high spatial resolution play an important role in material classification, change detection, and others. However, owing to the limitation of imaging sensors, it is difficult to directly acquire images with both high spatial resolution and high spectral resolution. Therefore, the fusion of remotely sensed images is an effective way to obtain high-resolution desired data, which is usually an ill-posed inverse problem and susceptible to noise corruption. To address these issues, a low-rank model based on tensor decomposition is proposed to fuse hyperspectral and multispectral images by incorporating graph regularization, in which the logarithmic low-rank function is utilized to suppress the small components for denoising. Furthermore, this article takes advantage of the local spatial similarity of remotely sensed images to enhance the reconstruction performance by constructing spatial graphs, and also promotes signature smoothing between adjacent endmember spectra using the neighborhood-based spectral graph regularization. Finally, a set of efficient solvers is carefully designed via alternating optimization for closed-from solutions and computational reduction, in which vector-matrix operators are adapted to solve the 3-D core tensor. Experimental tests on several real datasets illustrate that the proposed fusion method yields better reconstruction performance than the current state-of-the-art methods, and can significantly suppress noise at the same time.  © 2008-2012 IEEE.","Graphic methods; Hyperspectral imaging; Image enhancement; Image fusion; Image reconstruction; Image resolution; Inverse problems; Matrix algebra; Remote sensing; Spectral resolution; Tensors; Graph regularization; Hyperspectral image superresolution; Image super resolutions; Images reconstruction; Low rank; Matrix decomposition; Regularisation; Spatial resolution; Superresolution; Tensor decomposition; decomposition analysis; graphical method; image resolution; multispectral image; ranking; remote sensing; satellite imagery; Spectroscopy","Graph regularization; hyperspectral image (HSI) super-resolution; image fusion; low rank; tensor decomposition","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85118584609"
"Luo J.; Zhang Y.; Zhang Y.; Zhang Y.; Huang Y.; Yang H.; Yang J.","Luo, Jiawei (57221234005); Zhang, Yongchao (56042343300); Zhang, Yongwei (57207478944); Zhang, Yin (55975581400); Huang, Yulin (23014806800); Yang, Haiguang (23971854200); Yang, Jianyu (9239230100)","57221234005; 56042343300; 57207478944; 55975581400; 23014806800; 23971854200; 9239230100","ONLINE SUPER-RESOLUTION IMAGING FOR AIRBORNE SCANNING RADAR BASED ON SLIDING WINDOW RLS ALGORITHM","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","5067","5070","3","10.1109/IGARSS47720.2021.9553500","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126010013&doi=10.1109%2fIGARSS47720.2021.9553500&partnerID=40&md5=ffc0b4422897d617c2c1eb7b86236a07","Airborne radar high-squint looking imaging is an important research for remote sensing. The traditional Doppler beam sharpening based on fast Fourier transform (FFT) has good real-time performance but low cross-range resolution. Many super-resolution methods have been proposed to enhance the cross-range resolution for airborne radar. However, these methods generally adopt the batch processing mode with high computational complexity and high memory usage, which lead to poor real-time performance. This paper proposes an online super-resolution imaging approach for airborne scanning radar based on sliding window recursive least square (SWRLS) algorithm. The current scattering estimation can be derived recursively through downdating and updating. The proposed method effectively improves the cross-range resolution as well as the real-time performance and memory occupancy, which is beneficial to high-quint continuous real-time imaging for airborne radar. Simulation results are given to demonstrate the effectiveness of the proposed method. © 2021 IEEE.","","Airborne radar; High-squint looking; Online imaging; Sliding window","Conference paper","Final","","Scopus","2-s2.0-85126010013"
"Yang Z.; Zhao B.; Ma X.; Luo M.; Han J.; Si W.","Yang, Zhi (57221061936); Zhao, Binbin (56437098600); Ma, Xiao (57216557432); Luo, Meng (57217128453); Han, Jiajia (57221233401); Si, Weiguo (57221230419)","57221061936; 56437098600; 57216557432; 57217128453; 57221233401; 57221230419","Super Resolution Enhancement of Satellite Remote Sensing Images of Transmission Tower Based on Multi-map Residual Network and Wavelet Transform","2020","Proceedings - 2020 International Conference on Computer Vision, Image and Deep Learning, CVIDL 2020","","","9270467","16","20","4","10.1109/CVIDL51233.2020.00011","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098561129&doi=10.1109%2fCVIDL51233.2020.00011&partnerID=40&md5=a5eadff119389a6a97cd203fd9338327","Existing satellite remote sensing images are often used to observe the fuzzy phenomenon of transmission line bodies. It is necessary to enhance super-resolution, but traditional superresolution technology is difficult to obtain rich details and edge information of transmission towers. This paper proposes a multiscale edge enhancement method combining multi-map residual convolutional neural network and wavelet transform to solve these problems. Specifically, we first use a multi-map residual convolutional neural network to directly take the low-resolution image as the initial input of the network, and then use a convolutional layer to extract features. Secondly, a multi-mapping network is established by residual learning, and a batch normalization layer is added to optimize the network to enrich the feature information needed for high-resolution image aggregation. Finally, we use deconvolution layers to complete image upsampling and output high-resolution images, so the initial image can directly complete the end-to-end mapping relationship between low-resolution images and high-resolution images without performing preprocessing. On this basis, multiscale edge enhancement is performed on the transmission tower based on wavelet transform to obtain the final super-resolution enhancement result. Experiments on different benchmark data sets show that the proposed method is superior to the existing methods in the four quantitative indicators of peak signal-to-noise ratio, structural similarity, entropy and image detail enhancement. © 2020 IEEE.","Computer vision; Convolution; Convolutional neural networks; Deep learning; Fuzzy inference; Mapping; Multilayer neural networks; Optical resolving power; Remote sensing; Signal to noise ratio; Wavelet transforms; Feature information; High resolution image; Low resolution images; Mapping relationships; Peak signal to noise ratio; Quantitative indicators; Satellite remote sensing; Structural similarity; Image enhancement","convolutional neural network; edge enhancement; power transmission tower; satellite remote sensing; super-resolution; wavelet transform","Conference paper","Final","","Scopus","2-s2.0-85098561129"
"Xiao Y.; Su X.; Yuan Q.","Xiao, Yi (57715369200); Su, Xin (57682440400); Yuan, Qiangqiang (36635300800)","57715369200; 57682440400; 36635300800","A RECURRENT REFINEMENT NETWORK FOR SATELLITE VIDEO SUPER-RESOLUTION","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","2021-July","","","3865","3868","3","10.1109/IGARSS47720.2021.9553281","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126012557&doi=10.1109%2fIGARSS47720.2021.9553281&partnerID=40&md5=e3376ac5afb4a9a7d95771b81f50d470","Deep learning-based methods have shown superior performance in VSR tasks. However, satellite video frames are characterized by large width, low resolution, and lack of features. Consequently, the conventional VSR method is not suitable for satellite video. In this paper, a recurrent refinement network is proposed. Considering that the vast majority of remote sensing images belong to the static background, a single-image SR (SISR) method is first used to obtain high-resolution features for a specific target frame. To further complement the missing details, the network learns the complementary information enhanced by an Encoder-Decoder structure from adjacent frames to refine the results of SISR. To measure the contribution of different adjacent frames to the recovery of the target frame, a temporal attention mechanism is introduced in the final fusion stage. The experiment on the video data of Jilin-1 demonstrates the effectiveness of our method. © 2021 IEEE.","","Deep learning; Satellite video; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85126012557"
"Balaji Prabhu B.V.; Salian N.P.; Nikhil B.M.; Narasipura O.S.J.","Balaji Prabhu, B.V. (57202716108); Salian, Nikith P. (57223916625); Nikhil, B.M. (57209534063); Narasipura, Omkar Subbaram Jois (55626396900)","57202716108; 57223916625; 57209534063; 55626396900","Super-Resolution of Level-17 Images Using Generative Adversarial Networks","2021","Lecture Notes on Data Engineering and Communications Technologies","61","","","379","392","13","10.1007/978-981-33-4582-9_29","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106443712&doi=10.1007%2f978-981-33-4582-9_29&partnerID=40&md5=75752fd3e89aa1dc4645635fe587090f","The generative adversarial networks (GAN) deep learning models are being widely used in the field of image processing and its applications such as image generation, feature extraction, image recovery and image super-resolution to name a few. Image super-resolution has a board range of applications like satellite and aerial image analysis, medical image processing, compressed image/video enhancement, etc. This work implements an image super-resolution using generative adversarial network for super-resolution of level-17 low-resolution geospatial images obtained from Indian Remote Sensing (IRS) imagery. The results show that the generated super-resolution image can recuperate photo-realistic textures from low-resolution input pictures. The performance of the model is evaluated with qualitative measure indices such as structural similarity (SSIM) and peak signal-to-noise ratio (PSNR). The performance metric demonstrates that the model can generate images as close to that of the high-resolution image and it also has finer details. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Antennas; Deep learning; Image compression; Medical imaging; Optical resolving power; Remote sensing; Satellite imagery; Signal to noise ratio; Textures; Adversarial networks; Compressed images; High resolution image; Image super resolutions; Peak signal to noise ratio; Performance metrices; Satellite and aerial images; Structural similarity; Image enhancement","Deep learning; GAN; Indian remote sensing; Satellite image; Super-resolution","Book chapter","Final","","Scopus","2-s2.0-85106443712"
"Ning K.; Zhang Z.; Han K.; Han S.; Zhang X.","Ning, Keqing (36926065800); Zhang, Zhihao (57192639278); Han, Kai (57141420300); Han, Siyu (57226693080); Zhang, Xiqing (55662831100)","36926065800; 57192639278; 57141420300; 57226693080; 55662831100","Multi-Frame Super-Resolution Algorithm Based on a WGAN","2021","IEEE Access","9","","9452141","85839","85851","12","10.1109/ACCESS.2021.3088128","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112369897&doi=10.1109%2fACCESS.2021.3088128&partnerID=40&md5=20ec45b1c01d9c2afdda262c5f9ef38b","Image super-resolution reconstruction has been widely used in remote sensing, medicine and other fields. In recent years, due to the rise of deep learning research and the successful application of convolutional neural networks in the image field, the super-resolution reconstruction technology based on deep learning has also achieved great development. However, there are still some problems that need to be solved. For example, the current mainstream image super-resolution algorithms based on single or multiple frames pursue high performance indicators such as PSNR and SSIM, while the reconstructed image is relatively smooth and lacks many high-frequency details. It is not conducive to application in a real environment. To address such problem, this paper proposes a super-resolution reconstruction model of sequential images based on Generative Adversarial Networks (GAN). The proposed approach combines the registration module to fuse adjacent frames, effectively use the detailed information in multiple consecutive frames, and enhances the spatio-temporality of low-resolution images in sequential images. While the GAN was used to improve the effect of image high-frequency texture detail reconstruction, WGAN was introduced to optimize model training. The reconstruction results not only improved the PSNR and SSIM indexes but also reconstructed more high-frequency detail textures. Finally, in order to further improve the perception effect, an additional registration loss item RLT is introduced in the GAN network perception loss. Through extensive experiments, it shows that the model proposed in this paper effectively obtains the information between the sequence images. When the PSNR and SSIM indicators are improve, it can reconstruct better high-frequency texture details than the current advanced multi-frame algorithms. © 2013 IEEE.","Convolutional neural networks; Deep learning; Image reconstruction; Optical resolving power; Remote sensing; Textures; Adversarial networks; Image super resolutions; Image super-resolution reconstruction; Low resolution images; Performance indicators; Spatio temporalities; Super resolution algorithms; Super resolution reconstruction; Image enhancement","convolutional neural network; sequential images; Super-resolution reconstruction; Wasserstein generative adversarial network (WGAN)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85112369897"
"Yang S.; Wang X.","Yang, Shuai (57221292339); Wang, Xiaofei (36667500400)","57221292339; 36667500400","Sparse representation and SRCNN based spatio-temporal information fusion method of multi-sensor remote sensing data","2021","Journal of Network Intelligence","6","1","","40","53","13","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103315084&partnerID=40&md5=d79106e180a6fabecbd293fc25d73711","The classical spatio-temporal fusion algorithms STARFM and SPSTFM will have large fusion errors when the phenological changes or type changes appear. In this paper, based on the spatial feature information of the image, we proposed a new spatio temporal information fusion method which combines SRCNN (Super-Resolution Convolutional Neural Network) and sparse representation. Firstly, complete the feature reconstruction of the reflectance change image by combining SRCNN and sparse representation, and then the reconstructed image is superimposed by the time weight to obtain the predicated reflectance image. Experiments show that the proposed method is better than the classic spatio-temporal fusion algorithms STARFM and SPSTFM. © 2021, Taiwan Ubiquitous Information. All rights reserved.","Convolutional neural networks; Information fusion; Reflection; Remote sensing; Feature reconstruction; Phenological changes; Reconstructed image; Reflectance changes; Remote sensing data; Sparse representation; Spatio-temporal fusions; Spatiotemporal information; Sensor data fusion","Machine learning; Sparse representation; Spatio-temporal fusion; SRCNN","Article","Final","","Scopus","2-s2.0-85103315084"
"Koskowich B.; Starek M.","Koskowich, Bradley (57207878528); Starek, Michael (23494042900)","57207878528; 23494042900","Extracting Camera Pose Using Single Image Super Resolution Networks","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323098","1873","1876","3","10.1109/IGARSS39084.2020.9323098","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101997914&doi=10.1109%2fIGARSS39084.2020.9323098&partnerID=40&md5=0a063efd880e04b4685f656e0f9de40f","This work proposes a mechanism which can be used as a basis for allowing camera POSE information to be maintained reliably during loss or interference with inertial motion unit or positioning system integration. This basis is formed by employing image synthesis networks with atypical data for the network type: inputs are normal down scaled source imagery while outputs are native resolution images composed of the contents of the same scene viewed from a fixed offset position. The goal of this application is to simulate the presence of a binary camera from monocular hardware, which makes feasible certain POSE estimation workflows which would normally require binary cameras on monocular platforms. Being able to rapidly synthesize images of additional camera positions without having to physically navigate to those positions allows for two methods to build off each other. First, knowing that the model should consistently maintain a specific POSE from the source camera allows synthetic images to be used to artificially inflate available data during structure from motion processing with confidence in the accuracy of synthetic points. It also enables the comparison of an image at an actual physical location with the synthetic one later as a measure of POSE accuracy which can be incorporated into a solution for computing POSE of the image source. © 2020 IEEE.","Cameras; Geology; Remote sensing; Camera positions; Inertial motions; Physical locations; Pose information; Positioning system; Resolution images; Structure from motion; Synthetic images; Image processing","","Conference paper","Final","","Scopus","2-s2.0-85101997914"
"Kubade A.A.; Sharma A.; Rajan K.S.","Kubade, Ashish A (57219766008); Sharma, Avinash (57214355748); Rajan, K.S. (56397697900)","57219766008; 57214355748; 56397697900","Feedback Neural Network Based Super-Resolution of DEM for Generating High Fidelity Features","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323310","1671","1674","3","10.1109/IGARSS39084.2020.9323310","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101956601&doi=10.1109%2fIGARSS39084.2020.9323310&partnerID=40&md5=67f3ab887baa749f1ed8857b8380b81b","High resolution Digital Elevation Models(DEMs) are an important requirement for many applications like modelling water flow, landslides, avalanches etc. Yet publicly available DEMs have low resolution for most parts of the world. Despite tremendous success in image super-resolution task using deep learning solutions, there are very few works that have used these powerful systems on DEMs to generate HRDEMs. Motivated from feedback neural networks, we propose a novel neural network architecture that learns to add high frequency details iteratively to low resolution DEM, turning it into a high resolution DEM without compromising its fidelity. Our experiments confirm that without any additional modality such as aerial images(RGB), our network DSRFB achieves RMSEs of 0.59 to 1.27 across 4 different terrains having diverse geographical structures. © 2020 IEEE.","Antennas; Deep learning; Flow of water; Forestry; Geology; Network architecture; Optical resolving power; Remote sensing; Surveying; Different terrains; Digital elevation model; Geographical structure; High frequency HF; High-resolution DEM; Image super resolutions; Novel neural network; Super resolution; Neural networks","Digital Elevation Models; Feedback Neural Networks; Super-resolution; Terrains","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85101956601"
"Gong Y.; Liao P.; Zhang X.; Zhang L.; Chen G.; Zhu K.; Tan X.; Lv Z.","Gong, Yuanfu (57200512932); Liao, Puyun (57208162705); Zhang, Xiaodong (57192504939); Zhang, Lifei (57207389916); Chen, Guanzhou (56181390800); Zhu, Kun (57200511212); Tan, Xiaoliang (57202231708); Lv, Zhiyong (23111268400)","57200512932; 57208162705; 57192504939; 57207389916; 56181390800; 57200511212; 57202231708; 23111268400","Enlighten-gan for super resolution reconstruction in mid-resolution remote sensing images","2021","Remote Sensing","13","6","1104","","","","10.3390/rs13061104","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103080085&doi=10.3390%2frs13061104&partnerID=40&md5=5d1cb69627959e3776eec7312ce71b58","Previously, generative adversarial networks (GAN) have been widely applied on super resolution reconstruction (SRR) methods, which turn low-resolution (LR) images into high-resolution (HR) ones. However, as these methods recover high frequency information with what they observed from the other images, they tend to produce artifacts when processing unfamiliar images. Optical satellite remote sensing images are of a far more complicated scene than natural images. Therefore, applying the previous networks on remote sensing images, especially mid-resolution ones, leads to unstable convergence and thus unpleasing artifacts. In this paper, we propose Enlighten-GAN for SRR tasks on large-size optical mid-resolution remote sensing images. Specifically, we design the enlighten blocks to induce network converging to a reliable point, and bring the Self-Supervised Hierarchical Perceptual Loss to attain performance improvement overpassing the other loss functions. Furthermore, limited by memory, large-scale images need to be cropped into patches to get through the network separately. To merge the reconstructed patches into a whole, we employ the internal inconsistency loss and cropping-and-clipping strategy, to avoid the seam line. Experiment results certify that Enlighten-GAN outperforms the state-of-the-art methods in terms of gradient similarity metric (GSM) on mid-resolution Sentinel-2 remote sensing images. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Global system for mobile communications; Optical resolving power; Remote sensing; Adversarial networks; High-frequency informations; Low resolution images; Optical satellites; Remote sensing images; Similarity metrics; State-of-the-art methods; Super resolution reconstruction; Image reconstruction","Generative adversarial network; Mid-resolution remote sensing images; Super resolution reconstruction","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85103080085"
"He S.; Zou H.; Wang Y.; Li R.; Cheng F.","He, Shitian (57222956907); Zou, Huanxin (8366222500); Wang, Yingqian (57200449110); Li, Runlin (57222956493); Cheng, Fei (57222956824)","57222956907; 8366222500; 57200449110; 57222956493; 57222956824","SHIPSRDET: AN END-TO-END REMOTE SENSING SHIP DETECTOR USING SUPER-RESOLVED FEATURE REPRESENTATION","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","3541","3544","3","10.1109/IGARSS47720.2021.9554079","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117822698&doi=10.1109%2fIGARSS47720.2021.9554079&partnerID=40&md5=ceccfe0c6b066ed972f533c78f523964","High-resolution remote sensing images can provide abundant appearance information for ship detection. Although several existing methods use image super-resolution (SR) approaches to improve the detection performance, they consider image SR and ship detection as two separate processes and overlook the internal coherence between these two correlated tasks. In this paper, we explore the potential benefits introduced by image SR to ship detection, and propose an end-to-end network named ShipSRDet. In our method, we not only feed the super-resolved images to the detector but also integrate the intermediate features of the SR network with those of the detection network. In this way, the informative feature representation extracted by the SR network can be fully used for ship detection. Experimental results on the HRSC dataset validate the effectiveness of our method. Our ShipSRDet can recover the missing details from the input image and achieves promising ship detection performance. © 2021 IEEE","Feature extraction; Image enhancement; Optical resolving power; Remote sensing; Ships; Vehicle performance; Detection performance; End to end; Feature representation; High-resolution remote sensing images; Image super resolutions; Internal coherence; Remote-sensing; Resolution detection; Ship detection; Superresolution; Deep neural networks","deep neural network; image super-resolution; remote sensing; Ship detection","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85117822698"
"Alboody A.; Puigt M.; Roussel G.; Vantrepotte V.; Jamet C.; Tran T.K.","Alboody, Ahed (24528545800); Puigt, Matthieu (9132941600); Roussel, Gilles (57197306458); Vantrepotte, Vincent (22954813300); Jamet, Cedric (8600546000); Tran, Trung Kien (57217442266)","24528545800; 9132941600; 57197306458; 22954813300; 8600546000; 57217442266","Experimental Comparison of Multi-Sharpening Methods Applied to Sentinel-2 MSI and Sentinel-3 OLCI Images","2021","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2021-March","","9484009","","","","10.1109/WHISPERS52202.2021.9484009","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112845236&doi=10.1109%2fWHISPERS52202.2021.9484009&partnerID=40&md5=2b0e58f3cf7340bccdfdc9bdab25341b","Multi-spectral images are crucial to detect and to understand phenomena in marine observation. However, in coastal areas, these phenomena are complex and their analyze requires multi-spectral images with both a high spatial and spectral resolution. Unfortunately, no satellite is able to provide both at the same time. As a consequence, multi-sharpening techniques - a.k.a. fusion or super- resolution of multi-spectral and/or hyper-spectral images - were proposed and consist of combining information from at least two multi-spectral images with different spatial and spectral resolutions. The fused image then combines their best characteristics. Various methods - based on different strategies and tools - have been proposed to solve this problem. This article presents a comparative review of fusion methods applied to Sentinel-2 MSI (13 spectral bands with a spatial resolution ranging from 10 to 60 m) and Sentinel-3 OLCI (21 spectral bands with a spatial resolution of 300 m) images. Indeed, both satellites are extensively used in marine observation and, to the best of the authors' knowledge, the fusion of their data was partially investigated (and not in the way we aim to do in this paper). To that end, we provide both a quantitative analysis of the performance of some state-of-the-art methods on simulated images, and a qualitative analysis on real images.  © 2021 IEEE.","Hyperspectral imaging; Image fusion; Image resolution; Remote sensing; Spectral resolution; Spectroscopy; Experimental comparison; Hyper-spectral images; Marine observations; Multispectral images; Qualitative analysis; Spatial resolution; State-of-the-art methods; Strategies and tools; Image analysis","Image fusion; Real data; Remote sensing; Sentinel-2 MSI; Sentinel-3 OLCI; Simulations","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85112845236"
"Zhang Y.; Dong X.; Rashid M.T.; Shang L.; Han J.; Zhang D.; Wang D.","Zhang, Yang (57191071243); Dong, Xiangyu (57215286123); Rashid, Md Tahmid (57190247003); Shang, Lanyu (57207571159); Han, Jun (57209633331); Zhang, Daniel (57193607682); Wang, Dong (55574213902)","57191071243; 57215286123; 57190247003; 57207571159; 57209633331; 57193607682; 55574213902","PQA-CNN: Towards Perceptual Quality Assured Single-Image Super-Resolution in Remote Sensing","2020","2020 IEEE/ACM 28th International Symposium on Quality of Service, IWQoS 2020","","","9212942","","","","10.1109/IWQoS49365.2020.9212942","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094797763&doi=10.1109%2fIWQoS49365.2020.9212942&partnerID=40&md5=0a749f42ba580600ed058a978113a01e","Recent advances in remote sensing open up unprecedented opportunities to obtain a rich set of visual features of objects on the earth's surface. In this paper, we focus on a single-image super-resolution (SISR) problem in remote sensing, where the objective is to generate a reconstructed satellite image of high quality (i.e., a high spatial resolution) from a satellite image of relatively low quality. This problem is motivated by the lack of high quality satellite images in many remote sensing applications (e.g., due to the cost of high resolution sensors, communication bandwidth constraints, and historic hardware limitations). Two important challenges exist in solving our problem: i) it is not a trivial task to reconstruct a satellite image of high quality that meets the human perceptual requirement from a single low quality image; ii) it is challenging to rigorously quantify the uncertainty of the results of an SISR scheme in the absence of ground truth data. To address the above challenges, we develop PQA-CNN, a perceptual quality-assured conventional neural network framework, to reconstruct a high quality satellite image from a low quality one by designing novel uncertainty-driven neural network architectures and integrating an uncertainty quantification model with the framework. We evaluate PQA-CNN on a real-world remote sensing application on land usage classifications. The results show that PQA-CNN significantly outperforms the state-of-the-art super-resolution baselines in terms of accurately reconstructing high-resolution satellite images under various evaluation scenarios. © 2020 IEEE.","Image reconstruction; Network architecture; Neural networks; Optical resolving power; Quality of service; Satellites; Communication bandwidth; High resolution satellite images; High resolution sensors; High spatial resolution; Network frameworks; Perceptual quality; Remote sensing applications; Uncertainty quantifications; Remote sensing","Convolutional Neural Network; Perceptual Quality; Super-Resolution; Uncertainty-Aware","Conference paper","Final","","Scopus","2-s2.0-85094797763"
"Xie H.; Jiang H.; Liu X.; Li G.; Yang H.","Xie, Haiping (57223038193); Jiang, Haiyang (57224069259); Liu, Xiangyu (57209739775); Li, Gaoyuan (57223049231); Yang, Haitao (57218121328)","57223038193; 57224069259; 57209739775; 57223049231; 57218121328","Super resolution for remote sensing images via improved residual network","2020","Proceedings - 2020 5th International Conference on Mechanical, Control and Computer Engineering, ICMCCE 2020","","","9421814","2295","2298","3","10.1109/ICMCCE51767.2020.00496","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106950125&doi=10.1109%2fICMCCE51767.2020.00496&partnerID=40&md5=533793d0439deec83b75d2074766873b","According to the processing characteristics of remote sensing image super-resolution, this paper studies a super resolution method based on improved residual network. First, we optimize the structure of the residual block to meet the needs of super-resolution tasks; then, we further deepen the network level, so that the network has a stronger learning ability. The reconstruction results on the remote sensing images dataset show that the improved residual network achieves better visual effect, and the objective evaluation index is significantly improved, which proves the effectiveness of the proposed method. © 2020 IEEE.","Optical resolving power; Remote sensing; Learning abilities; Network level; Objective evaluation; Remote sensing images; Super resolution; Superresolution methods; Visual effects; Image enhancement","Component; Remote sensing; Residual networks; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85106950125"
"Xu Y.; Wu Z.; Chanussot J.; Wei Z.","Xu, Yang (57188730185); Wu, Zebin (20437030300); Chanussot, Jocelyn (6602159365); Wei, Zhihui (55761764700)","57188730185; 20437030300; 6602159365; 55761764700","Hyperspectral Images Super-Resolution via Learning High-Order Coupled Tensor Ring Representation","2020","IEEE Transactions on Neural Networks and Learning Systems","31","11","8948303","4747","4760","13","10.1109/TNNLS.2019.2957527","47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083421918&doi=10.1109%2fTNNLS.2019.2957527&partnerID=40&md5=e56d298db55c55ebf72cc070a21df2ef","Hyperspectral image (HSI) super-resolution is a hot topic in remote sensing and computer vision. Recently, tensor analysis has been proven to be an efficient technology for HSI image processing. However, the existing tensor-based methods of HSI super-resolution are not able to capture the high-order correlations in HSI. In this article, we propose to learn a high-order coupled tensor ring (TR) representation for HSI super-resolution. The proposed method first tensorizes the HSI to be estimated into a high-order tensor in which multiscale spatial structures and the original spectral structure are represented. Then, a coupled TR representation model is proposed to fuse the low-resolution HSI (LR-HSI) and high-resolution multispectral image (HR-MSI). In the proposed model, some latent core tensors in TR of the LR-HSI and the HR-MSI are shared, and we use the relationship between the spectral core tensors to reconstruct the HSI. In addition, the graph-Laplacian regularization is introduced to the spectral core tensors to preserve the spectral information. To enhance the robustness of the proposed model, Frobenius norm regularizations are introduced to the other core tensors. Experimental results on both synthetic and real data sets show that the proposed method achieves the state-of-The-Art super-resolution performance.  © 2012 IEEE.","Image processing; Optical resolving power; Remote sensing; Spectroscopy; Efficient technology; High order correlation; High order tensors; Multispectral images; Representation model; Spectral information; Spectral structure; Synthetic and real data; article; computer vision; image processing; learning; remote sensing; Tensors","Hyperspectral image (HSI); multiscale; multispectral image (MSI); super-resolution; tensor ring (TR)","Article","Final","","Scopus","2-s2.0-85083421918"
"Shin C.; Kim S.; Kim Y.","Shin, Changyeop (57214067386); Kim, Sungho (57214086723); Kim, Youngjung (57207442949)","57214067386; 57214086723; 57207442949","From Planetscope to Worldview: Micro-Satellite Image Super-Resolution with Optimal Transport Distance","2020","Proceedings - International Conference on Image Processing, ICIP","2020-October","","9190810","898","902","4","10.1109/ICIP40778.2020.9190810","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098624735&doi=10.1109%2fICIP40778.2020.9190810&partnerID=40&md5=fc9b61be8ab5943c1d25c95b33bc8189","The vast majority of prior work on satellite image super-resolution (SR) assumes the availability of paired training data, and then uses low-resolution (LR) images artificially generated by simple blurring and/or down-sampling. These methods often fail to produce convincing results in real-world data since the actual degradation is much more complex than manually designed. This paper presents a deep learning framework to model the degradation process of microsatellite image. To this end, we first introduce remote sensing dataset consisting of WorldView (0.4m) and PlanetScope (3m) satellite images. They are aligned to the same coordinate, but are collected at different days/times. Using such data, we design Degradation Network (DegNet), generating realistic micro-satellite images from its high-resolution (HR) counterpart. A degradation loss using an optimal transport distance is proposed which makes the empirical distribution, i.e., histogram of outputs to be similar to that of real microsatellite images. It faithfully reflects the degradation characteristic of micro-satellite while preserving the content of an input. Finally, a SR network is trained with the generated LR-HR pairs. Extensive experiments show that the proposed method greatly improves the SR performance on real-world data. © 2020 IEEE.","Deep learning; DNA sequences; Micro satellites; Optical resolving power; Remote sensing; Degradation characteristics; Degradation loss; Degradation process; Empirical distributions; Learning frameworks; Low resolution images; Optimal transport; Satellite images; Image processing","degradation learning; generative models; Micro-satellite image; optimal transport distance; satellite image super-resolution","Conference paper","Final","","Scopus","2-s2.0-85098624735"
"Roser P.; Birkhold A.; Preuhs A.; Ochs P.; Stepina E.; Strobel N.; Kowarschik M.; Fahrig R.; Maier A.","Roser, Philipp (57208545060); Birkhold, Annette (55914362700); Preuhs, Alexander (57193264102); Ochs, Philipp (57211654432); Stepina, Elizaveta (57219741843); Strobel, Norbert (6701745788); Kowarschik, Markus (6603428610); Fahrig, Rebecca (34569131100); Maier, Andreas (23392966100)","57208545060; 55914362700; 57193264102; 57211654432; 57219741843; 6701745788; 6603428610; 34569131100; 23392966100","XDose: toward online cross-validation of experimental and computational X-ray dose estimation","2021","International Journal of Computer Assisted Radiology and Surgery","16","1","","1","10","9","10.1007/s11548-020-02298-6","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097157063&doi=10.1007%2fs11548-020-02298-6&partnerID=40&md5=22d13cdae292145eafbb518d263813ef","Purpose: As the spectrum of X-ray procedures has increased both for diagnostic and for interventional cases, more attention is paid to X-ray dose management. While the medical benefit to the patient outweighs the risk of radiation injuries in almost all cases, reproducible studies on organ dose values help to plan preventive measures helping both patient as well as staff. Dose studies are either carried out retrospectively, experimentally using anthropomorphic phantoms, or computationally. When performed experimentally, it is helpful to combine them with simulations validating the measurements. In this paper, we show how such a dose simulation method, carried out together with actual X-ray experiments, can be realized to obtain reliable organ dose values efficiently. Methods: A Monte Carlo simulation technique was developed combining down-sampling and super-resolution techniques for accelerated processing accompanying X-ray dose measurements. The target volume is down-sampled using the statistical mode first. The estimated dose distribution is then up-sampled using guided filtering and the high-resolution target volume as guidance image. Second, we present a comparison of dose estimates calculated with our Monte Carlo code experimentally obtained values for an anthropomorphic phantom using metal oxide semiconductor field effect transistor dosimeters. Results: We reconstructed high-resolution dose distributions from coarse ones (down-sampling factor 2 to 16) with error rates ranging from 1.62 % to 4.91 %. Using down-sampled target volumes further reduced the computation time by 30 % to 60 %. Comparison of measured results to simulated dose values demonstrated high agreement with an average percentage error of under 10 % for all measurement points. Conclusions: Our results indicate that Monte Carlo methods can be accelerated hardware-independently and still yield reliable results. This facilitates empirical dose studies that make use of online Monte Carlo simulations to easily cross-validate dose estimates on-site. © 2020, The Author(s).","Computer Simulation; Humans; Monte Carlo Method; Phantoms, Imaging; Radiation Dosage; Radiometry; Retrospective Studies; X-Rays; metal oxide; Article; human; human tissue; in vivo study; Monte Carlo cross validation; Monte Carlo dose calculation algorithm; online monitoring; priority journal; proof of concept; remote sensing; X ray dose distribution; computer simulation; imaging phantom; Monte Carlo method; procedures; radiation dose; radiometry; retrospective study; X ray","Anthropomorphic phantom; Dosimetry; Monte Carlo simulation; MOSFET","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85097157063"
"Marques Junior A.; Menezes de Souza E.; Müller M.; Brum D.; Capella Zanotta D.; Horota R.K.; Silveira Kupssinskü L.; Veronez M.R.; Gonzaga L., Jr; Lessio Cazarin C.","Marques Junior, Ademir (57217374030); Menezes de Souza, Eniuce (57213198157); Müller, Marianne (57217226864); Brum, Diego (57205768241); Capella Zanotta, Daniel (57217374488); Horota, Rafael Kenji (57210920444); Silveira Kupssinskü, Lucas (57200304800); Veronez, Maurício Roberto (26023922300); Gonzaga, Luiz (56071435800); Lessio Cazarin, Caroline (57213199437)","57217374030; 57213198157; 57217226864; 57205768241; 57217374488; 57210920444; 57200304800; 26023922300; 56071435800; 57213199437","Improving Spatial Resolution of Multispectral Rock Outcrop Images Using RGB Data and Artificial Neural Networks","2020","Sensors (Basel, Switzerland)","20","12","","","","","10.3390/s20123559","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087141427&doi=10.3390%2fs20123559&partnerID=40&md5=ccbdc542bfedff3fd27a00c9c682dbc3","Spectral information provided by multispectral and hyperspectral sensors has a great impact on remote sensing studies, easing the identification of carbonate outcrops that contribute to a better understanding of petroleum reservoirs. Sensors aboard satellites like Landsat series, which have data freely available usually lack the spatial resolution that suborbital sensors have. Many techniques have been developed to improve spatial resolution through data fusion. However, most of them have serious limitations regarding application and scale. Recently Super-Resolution (SR) convolution neural networks have been tested with encouraging results. However, they require large datasets, more time and computational power for training. To overcome these limitations, this work aims to increase the spatial resolution of multispectral bands from the Landsat satellite database using a modified artificial neural network that uses pixel kernels of a single spatial high-resolution RGB image from Google Earth as input. The methodology was validated with a common dataset of indoor images as well as a specific area of Landsat 8. Different downsized scale inputs were used for training where the validation used the ground truth of the original size images, obtaining comparable results to the recent works. With the method validated, we generated high spatial resolution spectral bands based on RGB images from Google Earth on a carbonated outcrop area, which were then properly classified according to the soil spectral responses making use of the advantage of a higher spatial resolution dataset.","article; convolutional neural network; prediction; satellite imagery; soil","artificial neural network; CAVE; classification; high resolution; Landsat; multispectral; prediction; Super-Resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85087141427"
"Yue H.; Cheng J.; Liu Z.; Chen W.","Yue, Haosong (37014128300); Cheng, Jiaxiang (57207733866); Liu, Zhong (57190886072); Chen, Weihai (35776127700)","37014128300; 57207733866; 57190886072; 35776127700","Remote-sensing image super-resolution using classifier-based generative adversarial networks","2020","Journal of Applied Remote Sensing","14","4","046514","","","","10.1117/1.JRS.14.046514","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098650782&doi=10.1117%2f1.JRS.14.046514&partnerID=40&md5=6fb617d08f5f403af88d154f6511eb61","The rapid development of the aerospace industry has significantly increased the demand for remote-sensing images with high resolution and quality. Generating images with expected resolution from the samples obtained by common acquisition devices is a challenging task as the trade-off between cost and efficiency must be considered. We propose a super-resolution (SR) algorithm especially for remote-sensing images that is based on generative adversarial networks optimized by a classifier, which is called classifier-based super-resolution generative adversarial network (CSRGAN). We hypothesize that the confidence scores of classification can be a critical factor for representing the features in target remote-sensing images. To sufficiently take this factor into account during training, we add the class-score as an error into the loss function in addition to mean square error and high-dimensional features extracted from deep neural networks. Then, the classifier is utilized for both better SR performance and more precise classification. The classifier-testing branch of our system can also be flexibly combined with other network architectures to optimize SR performance on remote-sensing images. We validate the model on the NWPU-RESISC45 dataset considering both SR and classification performance. The final analysis is also provided and shows that the proposed CSRGAN outperforms existing algorithms.  © 2020 Society of Photo-Optical Instrumentation Engineers (SPIE).","Aerospace industry; Classification (of information); Deep neural networks; Economic and social effects; Image classification; Mean square error; Network architecture; Optical resolving power; Acquisition device; Adversarial networks; Classification performance; Confidence score; Critical factors; High dimensional feature; Remote sensing images; Super resolution; Remote sensing","classifier; generative adversarial networks; remote-sensing image; super-resolution","Article","Final","","Scopus","2-s2.0-85098650782"
"Zhang Q.; Zhang Y.; Zhang Y.; Huang Y.; Li W.; Yang J.","Zhang, Qiping (57207878759); Zhang, Yongchao (56042343300); Zhang, Yin (55975581400); Huang, Yulin (23014806800); Li, Wenchao (55718616300); Yang, Jianyu (9239230100)","57207878759; 56042343300; 55975581400; 23014806800; 55718616300; 9239230100","Fast Total Variation Superresolution Method for Radar Forward-Looking Imaging","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323315","6571","6574","3","10.1109/IGARSS39084.2020.9323315","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101983429&doi=10.1109%2fIGARSS39084.2020.9323315&partnerID=40&md5=4a5c2c2e49d5ae6fdf912cd77cabc124","Total variation (TV) method has been utilized to realize super-resolution and preserve contour information of target in radar forward-looking imaging. However, its real-time ability is restricted to matrix inversion. In this paper, a fast TV (FTV) superresolution method is proposed to improve the real-time superresolution ability of traditional TV method. The proposed FTV method utilizes the low displacement rank features of Toplitz matrix and realizes fast matrix inversion by Gohberg-Semencul (GS) representation. It not only effectively improves the azimuth resolution and preserve the contour information of target, but also reduced the computational complexity of traditional TV method to improve its real-time superresolution ability. The superior performance of the proposed FTV method is verified by simulation and measured data processing. © 2020 IEEE.","Data handling; Geology; Radar; Radar imaging; Remote sensing; Azimuth resolution; Contour information; Displacement ranks; Matrix inversions; Super resolution; Superresolution methods; Toplitz matrixes; Total variation; Optical resolving power","Gohberg-Semencul representation; radar imaging; Superresolution; Toeplitz; total variation","Conference paper","Final","","Scopus","2-s2.0-85101983429"
"Fernandez-Gallego J.A.; Kefauver S.C.; Gutierrez N.A.; Nieto-Taladriz M.T.; Araus J.L.","Fernandez-Gallego, Jose A. (57197716845); Kefauver, Shawn C. (8610975300); Gutierrez, Nieves A. (57212215017); Nieto-Taladriz, Maria T. (6602237827); Araus, Jose L. (55392718300)","57197716845; 8610975300; 57212215017; 6602237827; 55392718300","Implications of Very Deep Super-Resolution (VDSR) on RGB imagery for grain yield assessment in wheat","2020","2020 Virtual Symposium in Plant Omics Sciences, OMICAS 2020 - Conference Proceedings","","","","","","","10.1109/OMICAS52284.2020.9535654","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115950340&doi=10.1109%2fOMICAS52284.2020.9535654&partnerID=40&md5=d58bd2b7d74d8d93b73cac2a783c085f","RGB imagery has been widely used for crop management practices and phenotyping applications in recent years. Although RGB wavelengths (400-700 nm) are not able to capture all essential plant data (such as with full ultraviolet, near and long infrared wavelength coverage), RGB cameras are the most common types of cameras and are among the versatile imaging devices for proximal remote sensing applications. Deep learning strategies have improved a wide range of processes and deep learning concepts can be included in many applications. This work uses the Very Deep Super-Resolution (VDSP) technique to improve low-resolution RGB images in order to study grain yield assessment in wheat using vegetation indexes. The results show no significant differences between indexes calculated from low-resolution images and low-resolution images processed using VDSP with grain yield.  © 2020 IEEE.","Cameras; Crops; Deep learning; E-learning; Grain (agricultural product); Optical resolving power; Remote sensing; Crop management practices; Deep learning; Grain yield; Low resolution images; Near Infrared; Phenotyping; Plant data; RGB imagery; Superresolution; Wheat; Image enhancement","deep learning; digital image processing; grain yield; RGB imagery; wheat","Conference paper","Final","","Scopus","2-s2.0-85115950340"
"Azmi A.Z.U.; Suprijanto S.; Nadhira V.","Azmi, Ahmad Zahi Ulul (57198806363); Suprijanto, Suprijanto (7409811159); Nadhira, Vebi (35795805800)","57198806363; 7409811159; 35795805800","Reconstruction and regularization multi frame super resolution on vegetation index NIR image","2021","Proceedings of SPIE - The International Society for Optical Engineering","11789","","1178905","","","","10.1117/12.2585559","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103310185&doi=10.1117%2f12.2585559&partnerID=40&md5=0f649e5ee90b2fc69215acaf51c23b22","Vegetation index is measured using remote sensing with VNIR image acquired by satellites, one of them is PROBA-V. It gathers pair of low resolution (LR) images and high resolution (HR) images. The LR images is acquired faster but contains aliasing. Hence it can be processed into high resolution image using multi frame super resolution. But, to have an ideal LR image as a comparison, new synthetic LR image dataset is generated using only translation, gaussian PSF, and gaussian noise. Two type of approaches are used, reconstruction and regularization. Results from both methods are post-processed using median filter to remove noise due to error in super resolution process and poorly chosen hyperparameter. Then, the result is evaluated using PSNR and SSIM by compared to ground truth from dataset HR images. Also, simple bicubic interpolation is used to measure any information improvement by performing super resolution. For both LR images from dataset and synthesis, highest PSNR and SSIM are provided by regularization method due to its multiple iteration for predicting high resolution image, meanwhile reconstruction method only uses single iteration. © SPIE. Downloading of the abstract is permitted for personal use only.","Gaussian noise (electronic); Image acquisition; Iterative methods; Median filters; Optical resolving power; Remote sensing; Vegetation; Bicubic interpolation; High resolution image; Low resolution images; Multiple iterations; Reconstruction method; Regularization methods; Super resolution; Vegetation index; Image reconstruction","BTV regularization; Multi frame super resolution; NIR images; Reconstruction","Conference paper","Final","","Scopus","2-s2.0-85103310185"
"Fernandez R.; Fernandez-Beltran R.; Pla F.","Fernandez, Rafael (57222243976); Fernandez-Beltran, Ruben (55838551300); Pla, Filiberto (7006504936)","57222243976; 55838551300; 7006504936","Inter-Sensor Remote Sensing Image Enhancement for Operational Sentinel-2 and Sentinel-3 Data Products","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324071","1504","1507","3","10.1109/IGARSS39084.2020.9324071","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102010234&doi=10.1109%2fIGARSS39084.2020.9324071&partnerID=40&md5=7e63a302423c3f8b2adf11c8230671a0","The recent availability of operational data from the Sentinel-2 and Sentinel-3 missions provides widespread opportunities to generate diverse high-level remote sensing products. However, the synergies between both multi-spectral instruments are often difficult to exploit from an operational perspective. Standard pansharpening algorithms may encounter important disadvantages due to the limited intersensor data availability in actual production environments. Moreover, the lack of a real high-resolution ground-truth for super-resolution techniques may affect the radiometric quality of the final result. In this scenario, this work investigates the viability of using the Multi-Spectral Instrument of Sentinel-2 for super-resolving data products acquired by the Ocean and Land Colour Instrument of Sentinel-3. Specifically, we define an inter-sensor image enhancement framework which combines a PCA-based component substitution pansharpening scheme with a CNN-based spatial enhancing super-resolution mapping. The conducted experiments reveal the suitability of the proposed approach for generating Level-4 data products within the Copernicus programme context. © 2020 IEEE.","Geology; Optical resolving power; Remote sensing; Component substitution; Data availability; Enhancement framework; Production environments; Radiometric quality; Remote sensing images; Sentinel-3 Mission; Super-resolution mappings; Image enhancement","image fusion; pansharpening; Sentinel-2 (S2); Sentinel-3 (S3); super-resolution (SR)","Conference paper","Final","","Scopus","2-s2.0-85102010234"
"Akbari Asanjan A.; Das K.; Li A.; Chirayath V.; Torres-Perez J.; Sorooshian S.","Akbari Asanjan, Ata (57193920957); Das, Kamalika (57220640601); Li, Alan (57211156757); Chirayath, Ved (57110311100); Torres-Perez, Juan (55257966200); Sorooshian, Soroosh (7005052907)","57193920957; 57220640601; 57211156757; 57110311100; 55257966200; 7005052907","Learning Instrument Invariant Characteristics for Generating High-resolution Global Coral Reef Maps","2020","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","2617","2624","7","10.1145/3394486.3403312","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090425257&doi=10.1145%2f3394486.3403312&partnerID=40&md5=7ca5a76fb0d71a37722185c1d767506f","Coral reefs are one of the most biologically complex and diverse ecosystems within the shallow marine environment. Unfortunately, these underwater ecosystems are threatened by a number of anthropogenic challenges, including ocean acidification and warming, overfishing, and the continued increase of marine debris in oceans. This requires a comprehensive assessment of the world's coastal environments, including a quantitative analysis on the health and extent of coral reefs and other associated marine species, as a vital Earth Science measurement. However, limitations in observational and technological capabilities inhibit global sustained imaging of the marine environment. Harmonizing multimodal data sets acquired using different remote sensing instruments presents additional challenges, thereby limiting the availability of good quality labeled data for analysis. In this work, we develop a deep learning model for extracting domain invariant features from multimodal remote sensing imagery and creating high-resolution global maps of coral reefs by combining various sources of imagery and limited hand-labeled data available for certain regions. This framework allows us to generate, for the first time, coral reef segmentation maps at 2-meter resolution, which is a significant improvement over the kilometer-scale state-of-the-art maps. Additionally, this framework doubles accuracy and IoU metrics over baselines that do not account for domain invariance. © 2020 ACM.","Deep learning; Ecosystems; Labeled data; Quality control; Reefs; Remote sensing; Coastal environments; Comprehensive assessment; Invariant features; Marine environment; Ocean acidifications; Remote sensing imagery; Remote sensing instruments; Technological capability; Data mining","coral reef segmentation; domain adaptation; neural networks; super resolution","Conference paper","Final","","Scopus","2-s2.0-85090425257"
"","","","24th ISPRS Congress, Commission IV","2020","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","5","4","","","","2619","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092125735&partnerID=40&md5=0486cc8540f614046d56d3d8f76e6f34","The proceedings contain 342 papers. The topics discussed include: learning super-resolution for sentinel-2 images with real ground truth data from a reference satellite; combined patch-wise minimal-maximal pixels regularization for deblurring; urban material classification using spectral and textural features retrieved from autoencoders; a worldwide 3D GCP database inherited from 20 years of massive multi-satellite observations; deep learning based feature matching and its application in image orientation; a novel RPC bias model for improving the positioning accuracy of satellite images; land salinization dynamics based on feature space combinations from landsat image in Tongyu County, Northeast China; a new index for identifying water body from sentinel-2 satellite remote sensing imagery; land cover classification using convolutional neural network with remote sensing data and digital surface model; assessing resilience of infrastructures towards exogenous events by using PS-INSAR-based surface motion estimates and machine learning regression techniques; region-based fuzzy clustering image segmentation algorithm with Kullback-Leibler distance; experiences from the project course in geoinformatics; and refugees stories told by maps: a challenge for students in a scientific Olympiad.","","","Conference review","Final","","Scopus","2-s2.0-85092125735"
"Tang W.; Deng C.; Han Y.; Huang Y.; Zhao B.","Tang, Wei (57219250261); Deng, Chenwei (25958671000); Han, Yuqi (57195983797); Huang, Yun (57218183818); Zhao, Baojun (7403059245)","57219250261; 25958671000; 57195983797; 57218183818; 7403059245","SRARNet: A Unified Framework for Joint Superresolution and Aircraft Recognition","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","9254000","327","336","9","10.1109/JSTARS.2020.3037225","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098793454&doi=10.1109%2fJSTARS.2020.3037225&partnerID=40&md5=c78d7f87941ced8270ff13be6a7ce407","Aircraft recognition in high-resolution remote sensing images has rapidly progressed with the advance of convolutional neural networks (CNNs). However, the previous CNN-based methods may not work well for recognizing aircraft in low-resolution remote sensing images because the blurred aircraft in these images offer insufficient details to distinguish them from similar types of targets. An intuitive solution is to introduce superresolution preprocessing. However, conventional superresolution methods mainly focus on reconstructing natural images with detailed texture rather than constructing a high-resolution object with strong discriminative information for the recognition task. To address these problems, we propose a unified framework for joint superresolution and aircraft recognition (Joint-SRARNet) that tries to improve the recognition performance by generating discriminative, high-resolution aircraft from low-resolution remote sensing images. Technically, this network integrates superresolution and recognition tasks into the generative adversarial network (GAN) framework through a joint loss function. The generator is constructed as a joint superresolution and refining subnetwork that can upsample small blurred images into high-resolution ones and restore high-frequency information. In the discriminator, we introduce a new classification loss function that forces the discriminator to distinguish between real and fake images while recognizing the type of aircraft. In addition, the classification loss function is back-propagated to the generator to obtain high-resolution images with discriminative information for easier recognition. Extensive experiments on the challenging multitype aircraft of remote sensing images (MTARSI) dataset demonstrate the effectiveness of the proposed method in restoring a clear super-resolved image from a small blurred image and significant improvement in the recognition performance. To our knowledge, this is the first work on joint superresolution and aircraft recognition tasks.  © 2008-2012 IEEE.","Aircraft; Classification (of information); Image reconstruction; Optical resolving power; Remote sensing; Textures; Vehicle performance; Adversarial networks; High resolution image; High resolution remote sensing images; High-frequency informations; Remote sensing images; Super resolution; Superresolution methods; Unified framework; aerial photography; aircraft; artificial neural network; back propagation; image analysis; image resolution; remote sensing; Image enhancement","Aircraft recognition; multitask GAN; superresolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85098793454"
"Khademi G.; Ghassemian H.","Khademi, Ghassem (56898906800); Ghassemian, Hassan (57204122949)","56898906800; 57204122949","A primal-dual method for total-variation-based pansharpening","2021","International Journal of Remote Sensing","42","6","","2072","2104","32","10.1080/01431161.2020.1851064","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098644559&doi=10.1080%2f01431161.2020.1851064&partnerID=40&md5=e3071a70e67d01e7335924613491e00e","This paper presents a variational framework to enhance the spatial details of the low-resolution (LR) multispectral (MS) image by the rich spatial information obtained from the panchromatic (Pan) image. The target high-resolution (HR) MS image is estimated through an inverse super-resolution problem, where the LR MS and Pan images are the observations. The LR MS image is modelled by the decimation of the target HR MS image which takes into account the modulation transfer function (MTF) of the MS sensor. In addition, the Pan image is described as a linear combination of the bands of the target HR MS image. A variational pansharpening model is defined according to the image observation models and the total variation (TV) regularization. The target HR MS image is obtained by optimizing the variational model using an efficient primal-dual algorithm in the Euclidean setting. Compared to the other variational pansharpening algorithms adopting the vector representation, the proposed algorithm solves the pansharpening problem by a primal-dual algorithm in the Euclidean setting, resulting in a highly efficient and less complex algorithm. The result of comparing the proposed algorithm with a number of state-of-the-art pansharpening methods demonstrates that the proposed algorithm is visually and quantitatively able to produce much better results. Moreover, the proposed algorithm has several advantages such as higher accuracy in preserving small objects and sharp features, faster convergence, and lower memory requirements over the existing variational pansharpening methods. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","Inverse problems; Lower memory requirement; Multispectral images; Panchromatic (Pan) image; Primal dual algorithms; Spatial informations; Total variation regularization; Variational framework; Vector representations; algorithm; computer simulation; image analysis; image resolution; remote sensing; satellite data; satellite imagery; spatial resolution; Image enhancement","","Article","Final","","Scopus","2-s2.0-85098644559"
"Chirayath V.; Li A.; Torres-Perez J.; Segal-Rozenhaimer M.; Van Den Bergh J.","Chirayath, Ved (57110311100); Li, Alan (57211156757); Torres-Perez, Juan (55257966200); Segal-Rozenhaimer, Michal (57202922977); Van Den Bergh, Jarrett (57219238152)","57110311100; 57211156757; 55257966200; 57202922977; 57219238152","NASA NeMO-Net - A Neural Multimodal Observation and Training Network for Marine Ecosystem Mapping at Diverse Spatiotemporal Scales","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323188","3633","3636","3","10.1109/IGARSS39084.2020.9323188","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101992804&doi=10.1109%2fIGARSS39084.2020.9323188&partnerID=40&md5=a2e5a16dd07ae257d217c3081d4db8fe","We present NeMO-Net, the first open-source fully convolutional neural network (FCNN) and interactive learning and training software aimed at assessing the present and past dynamics of shallow marine systems through habitat mapping into geomorphological (9 classes) and biological classes (22 classes). Shallow marine systems, particularly coral reefs, are under significant pressures due to climate change, ocean acidification, and other anthropogenic pressures, leading to rapid, often devastating changes, in these fragile and diverse ecosystems. Historically, remote sensing of shallow marine habitats has been limited to meter-scale imagery due to the optical effects of ocean wave distortion, refraction, and optical attenuation. NeMO-Net combines 3D cm-scale distortion-free imagery captured using NASA's airborne FluidCam and fluid lensing remote sensing technology with low resolution airborne and spaceborne datasets of varying spatial resolutions, spectral spaces, calibrations, and temporal cadence in a supercomputer-based deep learning framework. NeMO-Net augments and improves the benthic habitat classification accuracy of low-resolution datasets across large geographic and temporal scales using high-resolution training data from FluidCam. NeMO-Net's FCNN uses ResNet and RefineNet to perform semantic segmentation and cloud masking of remote sensing imagery of shallow marine systems from drones, manned aircraft, and satellites, including FluidCam, WorldView, Planet, Sentinel, and Landsat. Deep Laplacian Pyramid Super-Resolution Networks (LapSRN) alongside Domain Adversarial Neural Networks (DANNs) are used to augment low resolution imagery with high resolution drone-based datasets as well as recognize domain-invariant features across multiple instruments to achieve high classification accuracies, ameliorating inter-sensor spatial, spectral and temporal heterogeneities. An online active learning and citizen science application is used to allows users to provide interactive training data for NeMO-Net in 2D and 3D, fully integrated within an active learning framework. Preliminary results from a test case in Fiji demonstrate 9-class classification accuracy exceeding 84%. © 2020 IEEE.","Classification (of information); Climate change; Convolutional neural networks; Deep learning; Drones; Ecosystems; Geology; Large dataset; Learning systems; Mapping; NASA; Open source software; Open systems; Satellites; Semantics; Supercomputers; Training aircraft; Water waves; Anthropogenic pressures; Classification accuracy; Low-resolution imagery; Remote sensing imagery; Remote sensing technology; Semantic segmentation; Spatio-temporal scale; Temporal heterogeneities; Remote sensing","coral reefs; fluid lensing; machine learning; Multimodal remote sensing; neural networks","Conference paper","Final","","Scopus","2-s2.0-85101992804"
"Liu Y.; Sun W.","Liu, Yuhang (57218344026); Sun, Weidong (55726588900)","57218344026; 55726588900","Blind Super-Resolution for Single Remote Sensing Image via Sparse Representation and Transformed Self-Similarity","2020","Journal of Physics: Conference Series","1575","1","012115","","","","10.1088/1742-6596/1575/1/012115","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088874639&doi=10.1088%2f1742-6596%2f1575%2f1%2f012115&partnerID=40&md5=452c4c5b2603d618994a99191bd8a9c8","Super-resolution (SR) reconstruction is one of the effective ways to improve the spatial resolution of remote sensing images, but the blur kernel estimation without any additional prior information is the key to the quality of SR reconstruction. Facing the above problem, a blind super-resolution method via sparse representation and transformed self-similarity is proposed in this paper. In this method, the blur kernel as well as the reconstructed high-resolution image are estimated at the same time using the structural self-similarity from a single image, a down-sampled version of the observed image is used as the training samples for the dictionary learning, and the internal patch search space is expanded using the transformed self-similarity to improve the quality of estimation. Experiment results show that, our method performs well both in quality of kernel estimation and SR reconstruction. © 2020 Published under licence by IOP Publishing Ltd.","Artificial intelligence; Image enhancement; Information systems; Information use; Optical resolving power; Remote sensing; Space optics; Blind Super-resolution; Blur kernel estimations; Dictionary learning; High resolution image; Remote sensing images; Sparse representation; Spatial resolution; Super resolution reconstruction; Image reconstruction","","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85088874639"
"Courtrai L.; Pham M.-T.; Friguet C.; Lefevre S.","Courtrai, Luc (6507861482); Pham, Minh-Tan (56070990300); Friguet, Chloe (35071291100); Lefevre, Sebastien (57203070803)","6507861482; 56070990300; 35071291100; 57203070803","Small Object Detection from Remote Sensing Images with the Help of Object-Focused Super-Resolution Using Wasserstein GANs","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9323236","260","263","3","10.1109/IGARSS39084.2020.9323236","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101963148&doi=10.1109%2fIGARSS39084.2020.9323236&partnerID=40&md5=8a904d6ebf4966e659c174dfc6e1c802","In this paper, we investigate and improve the use of a super-resolution approach to benefit the detection of small objects from aerial and satellite remote sensing images. The main idea is to focus the super-resolution on target objects within the training phase. Such a technique requires a reduced number of network layers depending on the desired scale factor and the reduced size of the target objects. The learning of our super-resolution network is performed using deep residual blocks integrated in a Wasserstein Generative adversarial network. Then, detection task is performed by exploiting two state-of-the-art detectors including Faster-RCNN and YOLOv3. Experiments were conducted on small vehicle detection from both aerial and satellite images from the VEDAI and xView data sets. Results showed that object-focused super-resolution improves the detection performance and facilitates the transfer learning from one data set to another. © 2020 IEEE.","Antennas; Geology; Image enhancement; Network layers; Optical resolving power; Remote sensing; Small satellites; Transfer learning; Adversarial networks; Detection performance; Detection tasks; Remote sensing images; Satellite images; Satellite remote sensing; Small object detection; Super resolution; Object detection","deep learning; remote sensing imagery; Small object detection; super-resolution; Wasserstein GANs","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85101963148"
"Aydin V.A.; Foroosh H.","Aydin, Vildan ATALAY (57208952190); Foroosh, Hassan (57207549389)","57208952190; 57207549389","Wavelet-based super resolution using pansharpened multispectral images","2021","Turkish Journal of Electrical Engineering and Computer Sciences","29","4","","2232","2246","14","10.3906/ELK-2009-176","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112719574&doi=10.3906%2fELK-2009-176&partnerID=40&md5=1812c1e62795f9de5a9476d6bbca002d","Several remote sensing applications require high-spatial-high-spectral resolution multispectral (MS) images. However, most MS sensors provide low-spatial-high-spectral resolution MS images together with high-spatial-low-spectral resolution panchromatic (PAN) bands. In order to increase the spatial resolution of MS bands to the resolution of PAN images and to obtain high-spatial/spectral resolution MS bands, either MS and PAN images are fused (i.e., pansharpening) or super resolution (SR) is performed using MS bands only. Nevertheless, existing methods do not utilize the available temporal and spatial information together. In this paper, we propose a multiframe SR algorithm using high-spatial/spectral resolution MS images (i.e., pansharpened), taking advantage of both spatial and temporal data, in order to exceed the spatial resolution of the available PAN bands. We first employ a wavelet-based pansharpening method on a set of MS and PAN images captured at different times. Then, we utilize these pansharpened MS bands in a wavelet-based multiframe SR scheme. The proposed method reveals the inter-wavelet-subband relationship of multitemporal images for SR. We demonstrate our results with comparisons on a Landsat 7 ETM+ dataset. 2232 – 2246","Image resolution; Remote sensing; High spectral resolution; Multi-temporal image; Multispectral images; Remote sensing applications; Spatial resolution; Super resolution; Temporal and spatial; Wavelet sub bands; Spectral resolution","Discrete wavelet transform; Pansharpening; Super resolution","Article","Final","","Scopus","2-s2.0-85112719574"
"Zhu X.; Talebi H.; Shi X.; Yang F.; Milanfar P.","Zhu, Xiang (57219506852); Talebi, Hossein (57527818600); Shi, Xinwei (57219510338); Yang, Feng (57219115052); Milanfar, Peyman (7004264375)","57219506852; 57527818600; 57219510338; 57219115052; 7004264375","Super-Resolving Commercial Satellite Imagery Using Realistic Training Data","2020","Proceedings - International Conference on Image Processing, ICIP","2020-October","","9190746","498","502","4","10.1109/ICIP40778.2020.9190746","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098663184&doi=10.1109%2fICIP40778.2020.9190746&partnerID=40&md5=d605393263008c9fe94f39f3e189f902","In machine learning based single image super-resolution, the degradation model is embedded in training data generation. However, most existing satellite image super-resolution methods use a simple down-sampling model with a fixed kernel to create training images. These methods work fine on synthetic data, but do not perform well on real satellite images. We propose a realistic training data generation model for commercial satellite imagery products, which includes not only the imaging process on satellites but also the post-process on the ground. We also propose a convolutional neural network optimized for satellite images. Experiments show that the proposed training data generation model is able to improve super-resolution performance on real satellite images. © 2020 IEEE.","Convolutional neural networks; Image enhancement; Optical resolving power; Commercial satellites; Degradation model; Imaging process; Satellite images; Super resolution; Synthetic data; Training data; Training image; Satellite imagery","Remote sensing; satellite imagery; super-resolution","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85098663184"
"Khan B.; Fraz M.M.; Mumtaz A.","Khan, Bostan (57546823000); Fraz, Muhammad Moazam (26666028400); Mumtaz, Adeel (24438091500)","57546823000; 26666028400; 24438091500","Enhanced Super-Resolution via Squeeze-and-Residual-Excitation in Aerial Imagery","2021","Proceedings - 2021 International Conference on Frontiers of Information Technology, FIT 2021","","","","19","24","5","10.1109/FIT53504.2021.00014","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126966516&doi=10.1109%2fFIT53504.2021.00014&partnerID=40&md5=faa5777580f618d69a0cf65a53065e33","Super-resolution (SR) presents us with an outstanding technique of enhancing applications associated with aerial and remote-sensing imagery, hence, tasks like classification, segmentation and object detection can benefit significantly from well-performing SR models. Extensive research is being done in the field of SR for both ground-level and aerial imagery where convolutional neural networks (CNN) have attained incredible progress. Numerous deep CNNs use the attention mechanism in their architectures and one such mechanism is the Squeeze-and-Excitation (SE) inter-channel attention. Although SE block has enhanced the performance of many models, there is no residual mechanism used within its structure. Therefore, in this paper, we propose the Squeeze-and-Residual-Excitation (SRE) attention block. SRE improves upon the SE block by using residual mechanism within its structure to deliver performance gain in the task of SR. Based on our SRE attention mechanism we propose an enhanced SR framework for remote-sensing imagery. We call our model the Squeeze-and-Residual-Excitation Holistic Attention Network (SRE-HAN) that outperforms other attention-based deep SR models for two levels of resolution enhancement: 4x- and 8x-upsampling on two diverse aerial imagery datasets: Satellite Imagery Multi-Vehicles Dataset (SIMD) consisting of 5000 high-resolution (HR) aerial images, and Cars-Overhead-With-Context (COWC). Furthermore, by using YoloV5 object-detection model, we carry out multiple experiments to substantiate the effectiveness of these SR models on the task of object detection on SIMD.  © 2021 IEEE.","Aerial photography; Antennas; Computer vision; Convolutional neural networks; Image enhancement; Object detection; Object recognition; Optical resolving power; Satellite imagery; Aerial imagery; Attention mechanisms; Convolutional neural network; Ground level; Multi-vehicles; Remote sensing imagery; Residual excitation; Squeeze-and-excitation; Super-resolution models; Superresolution; Remote sensing","Aerial Imagery; Remote Sensing Imagery; Squeeze-and-Excitation; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85126966516"
"Symolon W.; Dagli C.","Symolon, William (57226800082); Dagli, Cihan (7006792258)","57226800082; 7006792258","Single-Image Super Resolution Using Convolutional Neural Network","2021","Procedia Computer Science","185","","","213","222","9","10.1016/j.procs.2021.05.022","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112721646&doi=10.1016%2fj.procs.2021.05.022&partnerID=40&md5=f2e1109282b6613241e1b46da97e7db7","Increasing threats to U.S. national security satellite constellations have resulted in an increased interest in constellation resilience and satellite redundancy. CubeSats have contributed to commercial, scientific and government applications in remote sensing, communications, navigation and research and have the potential to enhance satellite constellation resilience. However, the inherent size, weight and power limitations of CubeSats enforce constraints on imaging hardware; the small lenses and short focal lengths result in imagery with low spatial resolution. Low resolution limits the utility of CubeSat images for military planning purposes and national intelligence applications. This paper implements a super-resolution deep learning architecture and proposes potential applications to CubeSat imagery. © 2021 Elsevier B.V.. All rights reserved.","Deep learning; Military applications; Military photography; National security; Neural networks; Remote sensing; Small satellites; CNN; Convolutional neural network; Cubesat; Cubesats; Elsevier; Image super resolutions; Remote communication; Satellite constellations; Single images; Super resolution; Optical resolving power","CNN; CubeSats; super resolution","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85112721646"
"Pineda F.; Ayma V.; Aduviri R.; Beltran C.","Pineda, Ferdinand (57216822078); Ayma, Victor (56566776600); Aduviri, Robert (57207467513); Beltran, Cesar (55602499700)","57216822078; 56566776600; 57207467513; 55602499700","Super Resolution Approach Using Generative Adversarial Network Models for Improving Satellite Image Resolution","2020","Communications in Computer and Information Science","1070 CCIS","","","291","298","7","10.1007/978-3-030-46140-9_27","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084819739&doi=10.1007%2f978-3-030-46140-9_27&partnerID=40&md5=9fe165b60f94c8fbbadd58a0c7da0341","Recently, the number of satellite imaging sensors deployed in space has experienced a considerable increase, but most of these sensors provide low spatial resolution images, and only a small proportion contribute with images at higher resolutions. This work proposes an alternative to improve the spatial resolution of Landsat-8 images to the reference of Sentinel-2 images, by applying a Super Resolution (SR) approach based on the use of Generative Adversarial Network (GAN) models for image processing, as an alternative to traditional methods to achieve higher resolution images, hence, remote sensing applications could take advantage of this new information and improve its outcomes. We used two datasets to train and validate our approach, the first composed by images from the DIV2K open access dataset and the second by images from Sentinel-2 satellite. The experimental results are based on the comparison of the similarity between the Landsat-8 images obtained by the super resolution processing by our approach (for both datasets), against its corresponding reference from Sentinel-2 satellite image, computing the Peak Signal-to-Noise Ratio (PSNR) and the Structural Similarity (SSIM) as metrics for this purpose. In addition, we present a visual report in order to compare the performance of each trained model, analysis that shows interesting improvements of the resolution of Landsat-8 satellite images. © Springer Nature Switzerland AG 2020.","Big data; Image resolution; Information management; Optical resolving power; Remote sensing; Signal to noise ratio; Small satellites; Adversarial networks; Higher resolution images; Peak signal to noise ratio; Remote sensing applications; Satellite imaging; Spatial resolution; Spatial resolution images; Structural similarity; Image enhancement","Landsat-8; Sentinel-2; SR-GAN; Super Resolution","Conference paper","Final","","Scopus","2-s2.0-85084819739"
"Li Y.-L.; Liu J.; Jiang X.; Huang X.","Li, Yue-Li (8367463100); Liu, Jianguo (36077207500); Jiang, Xiaoqing (57213198203); Huang, Xiaotao (7410243592)","8367463100; 36077207500; 57213198203; 7410243592","Coherent Signal Model for Angular Superresolution in Scanning Radar Imaging","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898983","2945","2948","3","10.1109/IGARSS.2019.8898983","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077712803&doi=10.1109%2fIGARSS.2019.8898983&partnerID=40&md5=98b5b1a08d634d3ef22faf325481af73","Noncoherent signal model is widely applied to angular superresolution in forward-looking imaging radar. However, relative phase influences the resolvability of the model in coherent applications. We propose a coherent signal model by replacing the antenna power pattern with the antenna radiation pattern. Experiment results have demonstrated significant resolution improvements for forward-looking imaging in coherent scanning radars. © 2019 IEEE.","Directional patterns (antenna); Geology; Optical resolving power; Radar; Radar antennas; Remote sensing; Coherent signals; Forward looking; Noncoherent signal; Power pattern; Relative phase; Resolution improvement; Scanning radar; Super resolution; Radar imaging","Angular superresolution; coherent signal model; forward-looking imaging; relative phase","Conference paper","Final","","Scopus","2-s2.0-85077712803"
"Tian Y.; Jia R.-S.; Xu S.-H.; Hua R.; Deng M.-D.","Tian, Yu (57210975126); Jia, Rui-Sheng (25927894300); Xu, Shao-Hua (35345868100); Hua, Rong (35770708800); Deng, Meng-Di (57210975118)","57210975126; 25927894300; 35345868100; 35770708800; 57210975118","Super-resolution reconstruction of remote sensing images based on convolutional neural network","2019","Journal of Applied Remote Sensing","13","4","046502","","","","10.1117/1.JRS.13.4.046502","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073737863&doi=10.1117%2f1.JRS.13.4.046502&partnerID=40&md5=ab2b448ee16d64400b129dcb02dac574","A method of super-resolution reconstruction of remote sensing images based on convolutional neural network is proposed to address the problems of low-resolution and poor visual quality of remote sensing images. In this method, a sample database with high-resolution (HR) and low-resolution (LR) remote sensing images was constructed. A convolutional neural network was then obtained by determining the intrinsic relationship between HR and LR remote sensing images in the sample database. Multiple pairs of HR and LR images were selected from the sample database and sent into a six-layer convolutional neural network. The experimental results showed that compared with other learning-based methods, such as the fast super-resolution convolutional neural network (FSRCNN), the image quality obtained by our method is improved both subjectively and objectively. Moreover, the training time was ∼17 % less than in the FSRCNN method. © 2019 Society of Photo-Optical Instrumentation Engineers (SPIE).","Convolution; Database systems; Deep learning; Deep neural networks; Image enhancement; Image reconstruction; Multilayer neural networks; Network layers; Optical resolving power; Convolutional neural network; High resolution; Learning-based methods; Remote sensing images; Sample Database; Super resolution; Super resolution reconstruction; Visual qualities; Remote sensing","convolutional neural network; deep learning; remote sensing image; super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85073737863"
"Wang Z.; He M.; Ye Z.; Xu K.; Nian Y.; Huang B.","Wang, Zhongliang (55803136200); He, Mi (36139403600); Ye, Zhen (55650661200); Xu, Ke (56302155100); Nian, Yongjian (18042162200); Huang, Bormin (7403681878)","55803136200; 36139403600; 55650661200; 56302155100; 18042162200; 7403681878","Reconstruction of Hyperspectral Images from Spectral Compressed Sensing Based on a Multitype Mixing Model","2020","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","13","","9094327","2304","2320","16","10.1109/JSTARS.2020.2994334","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086262986&doi=10.1109%2fJSTARS.2020.2994334&partnerID=40&md5=92098ffe7f1b62b9ab216667dff3da72","Hyperspectral compressed sensing (HCS) based on spectral unmixing technique has shown great reconstruction performance. In particular, the linear mixed model (LMM) has been widely used in HCS reconstruction. However, due to the complexity of environmental conditions, instrumental configurations, and material nonlinear mixing effects, LMM cannot accurately represent the hyperspectral images, which limits the improvement of reconstruction quality. In this article, first, by introducing spectral variability, nonlinear mixing, and residuals, a multitype mixed model (MMM) is proposed to establish a more accurate hyperspectral image model. Then, a novel MMM-based HCS is proposed, which performs spectral compressed sampling at the sampling stage only, and at the reconstruction stage, by using spectral unmixing, an MMM-based HCS super-resolution reconstruction algorithm from spectral compressed sensing data is developed, and the alternating direction multiplier method is employed to estimate each component of the MMM, furthermore, reasonable prior knowledge of each component is introduced to improve the estimation accuracy. Experimental results on hyperspectral datasets demonstrate that the proposed model outperforms those state-of-the-art methods based on the LMM in terms of HCS reconstruction quality. © 2008-2012 IEEE.","Compressed sensing; Image enhancement; Mixing; Spectroscopy; Alternating directions; Compressed samplings; Environmental conditions; Linear mixed models; Reconstruction quality; Spectral variability; State-of-the-art methods; Super resolution reconstruction; accuracy assessment; image processing; performance assessment; reconstruction; remote sensing; sampling; spectral resolution; Image reconstruction","Compressed sensing; Hyperspectral remote sensing; Linear mixing model (LMM); Spectral unmixing","Article","Final","","Scopus","2-s2.0-85086262986"
"Tang L.; Sun K.; Liu L.; Wang G.; Liu Y.","Tang, Lijuan (57190384121); Sun, Kezheng (57193716650); Liu, Luping (57210892937); Wang, Guangcheng (57209891180); Liu, Yutao (56031064700)","57190384121; 57193716650; 57210892937; 57209891180; 56031064700","A reduced-reference quality assessment metric for super-resolution reconstructed images with information gain and texture similarity","2019","Signal Processing: Image Communication","79","","","32","39","7","10.1016/j.image.2019.08.004","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071767418&doi=10.1016%2fj.image.2019.08.004&partnerID=40&md5=b09957b0916c76cc5c28c7fed6f1947a","Super-resolution (SR) image reconstruction has been extensively studied in recent years due to its broad uses in machine vision, medical imaging, remote sensing and monitoring systems. However, evaluating the performance of SR algorithms is still an ongoing problem. A number of image quality metrics have been reported in recent years, however, they are not specifically designed for SR reconstructed images, so they are usually limited when assessing SR images. Here, we propose a reduced-reference image quality assessment (IQA) metric for SR images. First, saliency detection is used on the high-resolution (HR) images, and low-resolution (LR) images are used to generate the corresponding saliency maps. Second, the information gain and texture similarity between the HR images and the LR images are calculated to quantify the image quality degradation. Finally, the information gain and the texture similarity are weighted to predict the quality of SR images. Extensive experiments illustrate that the proposed metric has better performance for SR images than the existing state-of-the-art IQA algorithms. © 2019 Elsevier B.V.","Image reconstruction; Image texture; Medical imaging; Optical resolving power; Remote sensing; Textures; Image quality assessment; Image quality metrics; Information gain; Reduced reference qualities; Reduced-reference image quality assessments; Super resolution reconstruction; Super-resolution image reconstruction; Texture similarity; Image quality","Image quality assessment; Information gain; Super-resolution reconstruction; Texture similarity","Article","Final","","Scopus","2-s2.0-85071767418"
"Wu C.; Zhang Z.; Chen L.; Yu W.","Wu, Chunxiao (57202537315); Zhang, Zenghui (14520653700); Chen, Longyong (36157598600); Yu, Wenxian (7403913710)","57202537315; 14520653700; 36157598600; 7403913710","Super-Resolution for MIMO Array SAR 3-D Imaging Based on Compressive Sensing and Deep Neural Network","2020","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","13","","9112264","3109","3124","15","10.1109/JSTARS.2020.3000760","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087544345&doi=10.1109%2fJSTARS.2020.3000760&partnerID=40&md5=c17f42a8075e0a590b4b4ffe8a7d1f6e","Multiple-input multiple-output (MIMO) array synthetic aperture radar (SAR) can straightly obtain the 3-D imagery of the illuminated scene with the single-pass flight. Generally, the Rayleigh resolution of the elevation direction is unacceptable due to the length limitation of linear array. The super-resolution imaging algorithms within the compressive sensing (CS) framework have been extensively studied because of the essential spatial sparsity in the elevation direction. However, the super-resolution performance of the existing sparse reconstruction algorithms will deteriorate dramatically in the case of lower signal-to-noise ratio (SNR) level or a few antenna elements. To overcome this problem, a new super-resolution imaging structure based on CS and deep neural network (DNN) for MIMO array SAR is proposed in this article. In this new algorithm, the spatial filtering based on CS is first proposed to reserve the signals only impinging from the prespecified space subregions. Thereafter, a group of parallel end-to-end DNN regression models are designed for mapping the potential sparse recovery mathematical model and further locating the true scatterers in the elevation direction. Finally, extensive simulations and airborne MIMO array SAR experiments are investigated to validate that the proposed method can realize the state-of-the-art super-resolution imaging against other existing related methods. © 2008-2012 IEEE.","Antennas; Compressed sensing; Logistic regression; MIMO radar; MIMO systems; Optical resolving power; Radar imaging; Signal to noise ratio; Synthetic aperture radar; Compressive sensing; Extensive simulations; Regression model; Sparse reconstruction; Spatial filterings; State of the art; Super resolution; Super resolution imaging; algorithm; artificial neural network; elevation; image resolution; radar imagery; remote sensing; signal-to-noise ratio; synthetic aperture radar; three-dimensional modeling; Deep neural networks","3-D imaging; Compressive sensing (CS); deep neural network (DNN); multiple-input multiple-output (MIMO); super-resolution; synthetic aperture radar (SAR)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85087544345"
"Wang H.-Y.; Juang J.-C.","Wang, Hao-Yu (57215897143); Juang, Jyh-Ching (7202725912)","57215897143; 7202725912","Retrieval of oceanwind speed using super-resolution delay-doppler maps","2020","Remote Sensing","12","6","916","","","","10.3390/rs12060916","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082305757&doi=10.3390%2frs12060916&partnerID=40&md5=3bd1dc4d4123308238f98d9725d93b73","The use of reflected Global Navigation Satellite System (GNSS) signals has shown to be effective for some remote sensing applications. In a GNSS Reflectometry (GNSS-R) system, a set of delay-Doppler maps (DDMs) related to scattered GNSS signals is formed and serves as a measurement of ocean wind speed and roughness. The design of the DDM receiver involves a trade-off between computation/communication complexity and the effectiveness of data retrieval. A fine-resolution DDM reveals more information in data retrieval while consuming more resources in terms of onboard processing and downlinking. As a result, existing missions typically use a compressed or low-resolution DDM as a data product, and a high-resolution DDM is processed for special purposes such as calibration. In this paper, a deep learning, super resolution algorithm is developed to construct a high-resolution DDM based on a low-resolution DDM. This may potentially enhance the data retrieval results with no impact on the instrument design. The proposed method is applied to process the DDM products disseminated by the Cyclone GNSS (CYGNSS) and the effectiveness of wind speed retrieval is demonstrated. © 2020 by the authors.","Communication satellites; Deep learning; Economic and social effects; Global positioning system; Optical resolving power; Reflection; Reflectometers; Remote sensing; Salinity measurement; Storms; Wind; Delay-doppler maps; Reflectometry; Single images; Super resolution; Wind speed; Search engines","Delay-doppler map (DDM); Global navigation satellite system reflectometry (GNSS-R); Single image super-resolution (SISR); Very-deep super-resolution (VDSR); Wind speed retrieval","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85082305757"
"Wang M.; He L.; Chang X.; Cheng Y.","Wang, Mi (57205635094); He, Luxiao (57201260628); Chang, Xueli (56421263200); Cheng, Yufeng (56861501800)","57205635094; 57201260628; 56421263200; 56861501800","Corrections to: Superresolution of single gaofen-4 visible-light and near-infrared (VNIR) image based on texture image extraction (IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing DOI: 10.1109/JSTARS.2019.2926490)","2019","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","12","8","8823074","3149","","","10.1109/JSTARS.2019.2937427","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072749190&doi=10.1109%2fJSTARS.2019.2937427&partnerID=40&md5=f37eaf1a7aff60b63f26d90894a244bc","In the above article [1], production errors are corrected as follows. Funding information should be added as follows: This work was supported in part by the China National Funds for Distinguished Young Scientists under Grant 61825103 and in part by the National Natural Science Foundation of China under Grant 91838303. On page 3, Ref. [36] should be cited in the sentence: ""For panchromatic and multispectral images of the same scene, the two have strong correlation [34]-[36]."" On page 5, the sentence ""For referenced frame construction, it is more important to choose which LR texture image."" should be ""For referenced frame construction, it is important to choose LR texture image."" On page 5, the sentence ""Local or global motion can be ignored since the data a single GF-4 VNIR image."" should be ""Local or global motion can be ignored since the input data is a single image."" On page 7, a sentence should be added as follows. In Tables III-V, the evaluation parameters of SR results in urban, lake, and mountain area, respectively, have been presented. The bold values in Tables III-V are the best parameters of the five methods."" An acknowledgement should be added as follows: ""The authors would like to thank CRESDA for providing the experimental data. Corrected references are as follows. [15] M. Irani and S. Peleg, ""Improving resolution by image registration,"" CVGIP, Graphical Models Image Process., vol. 53, no. 3, pp. 231-239, 1991.[19] R. R. Schultz and R. L. Stevenson, ""Extraction of HR frames from video sequences,"" IEEE Trans. Image Process., vol. 5, no. 6, pp. 996-1011, Jun. 1996. [28] C. Ledig et al., ""Photo-realistic single image super-resolution using a generative adversarial network,"" in Proc. IEEE Conf. Comput. Vision Pattern Recognit., Jul. 2017, pp. 105-114. [30] C. Dong, C. C. Loy, K. He, and X. Tang, ""Learning a deep convolutional network for image super-resolution,"" in Proc. Eur. Conf. Comput. Vision, 2014, pp. 184-199. [33] Y. Zhang, Y. Tian, Y. Kong, B. Zhong, and Y. Fu, ""Residual dense network for image super-resolution,"" in Proc. IEEE Conf. Comput. Vision Pattern Recognit., 2018, pp. 2472-2481. [34] X. U. Qi-Zhi and G. Feng, ""High fidelity panchromatic and multispectral image fusion based on ratio transform,"" Comput. Sci., vol. 41, no. 10, pp. 19-22, 2014. [37] R. C. Gonzalez and R. E. Woods, Digital Image Processing. Beijing, China: Publishing House Electron. Ind., 2007. © 2008-2012 IEEE.","","","Erratum","Final","","Scopus","2-s2.0-85072749190"
"","","","3rd Chinese Conference on Pattern Recognition and Computer Vision, PRCV 2020","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12305 LNCS","","","","","1936","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093816655&partnerID=40&md5=74e631ea45de48fc1e60f3f126db388d","The proceedings contain 158 papers. The special focus in this conference is on Pattern Recognition and Computer Vision. The topics include: Underwater Image Processing by an Adversarial Network with Feedback Control; inception Parallel Attention Network for Small Object Detection in Remote Sensing Images; hyperspectral Image Denoising Based on Graph-Structured Low Rank and Non-local Constraint; multi-human Parsing with Pose and Boundary Guidance; m2E-Net: Multiscale Morphological Enhancement Network for Retinal Vessel Segmentation; DUDA: Deep Unsupervised Domain Adaptation Learning for Multi-sequence Cardiac MR Image Segmentation; learning from Rankings with Multi-level Features for No-Reference Image Quality Assessment; reversible Data Hiding Based on Prediction-Error-Ordering; aggregating Spatio-temporal Context for Video Object Segmentation; Position and Orientation Detection of Insulators in Arbitrary Direction Based on YOLOv3; R-PFN: Towards Precise Object Detection by Recurrent Pyramidal Feature Fusion; image Super-Resolution Based on Non-local Convolutional Neural Network; VH3D-LSFM: Video-Based Human 3D Pose Estimation with Long-Term and Short-Term Pose Fusion Mechanism; automatic Tooth Segmentation and 3D Reconstruction from Panoramic and Lateral Radiographs; unregistered Hyperspectral and Multispectral Image Fusion with Synchronous Nonnegative Matrix Factorization; Cloud Detection Algorithm Using Advanced Fully Convolutional Neural Networks in FY3D-MERSI Imagery; multi-layer Pointpillars: Multi-layer Feature Abstraction for Object Detection from Point Cloud; building Detection via Complementary Convolutional Features of Remote Sensing Images; hyperspectral Image Super-Resolution via Self-projected Smooth Prior; 3D Point Cloud Segmentation for Complex Structure Based on PointSIFT; completely Blind Image Quality Assessment with Visual Saliency Modulated Multi-feature Collaboration; blood Flow Velocity Detection of Nailfold Microcirculation Based on Spatiotemporal Analysis; blind Super-Resolution with Kernel-Aware Feature Refinement; preface.","","","Conference review","Final","","Scopus","2-s2.0-85093816655"
"Li L.; Chen Y.; Xu T.; Shi K.; Huang C.; Liu R.; Lu B.; Meng L.","Li, Linyi (12781706800); Chen, Yun (55721092200); Xu, Tingbao (24304468000); Shi, Kaifang (55235145300); Huang, Chang (56460475700); Liu, Rui (56412259000); Lu, Binbin (55021752500); Meng, Lingkui (57197789940)","12781706800; 55721092200; 24304468000; 55235145300; 56460475700; 56412259000; 55021752500; 57197789940","Enhanced Super-Resolution Mapping of Urban Floods Based on the Fusion of Support Vector Machine and General Regression Neural Network","2019","IEEE Geoscience and Remote Sensing Letters","16","8","8636408","1269","1273","4","10.1109/LGRS.2019.2894350","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069509657&doi=10.1109%2fLGRS.2019.2894350&partnerID=40&md5=8efd7ed78cb4a8dd94e00c1b9d3875a9","Super-resolution mapping of urban flood (SMUF) is one of the hotspots in remote sensing and urban environment research. In this letter, a new SMUF method based on the fusion of support vector machine and general regression neural network (FSVMGRNN) was proposed to achieve enhanced performance. An SVM-SMUF algorithm was developed and a fusion criterion was formulated. Then, the FSVMGRNN-SMUF algorithm was developed. The results of FSVMGRNN-SMUF were evaluated using Landsat 8 OLI imagery of two representative cities in China. FSVMGRNN-SMUF yielded the most accurate SMUF results among the five SMUF methods according to visual comparisons and quantitative comparisons. The mapping accuracy of FSVMGRNN-SMUF related to the kernel functions was also analyzed and discussed. The results of this letter will help to boost practical applications of median-low resolution remote sensing images in urban flooding mapping, and to strengthen the means for monitoring and assessing urban flooding disasters. © 2019-2012 IEEE.","Floods; Mapping; Neural networks; Optical resolving power; Regression analysis; Remote sensing; Fusion algorithms; General regression neural network; Quantitative comparison; Remote sensing images; Super-resolution mappings; Urban environments; Urban floods; Visual comparison; accuracy assessment; algorithm; artificial neural network; flood; flooding; Landsat; mapping method; remote sensing; satellite imagery; support vector machine; Support vector machines","Fusion algorithm; general regression neural network (GRNN); super-resolution mapping; support vector machine (SVM); urban floods","Article","Final","","Scopus","2-s2.0-85069509657"
"Chen X.; Tao Y.; Tong L.; Su R.","Chen, Xiaowei (57326748000); Tao, Yiqi (57203617338); Tong, Lei (57196417994); Su, Ran (57219225351)","57326748000; 57203617338; 57196417994; 57219225351","GIS guided remote sensing image data for rural industry and space interaction mechanism modeling","2020","Proceedings of the 4th International Conference on Inventive Systems and Control, ICISC 2020","","","9171164","837","840","3","10.1109/ICISC47916.2020.9171164","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091751998&doi=10.1109%2fICISC47916.2020.9171164&partnerID=40&md5=cea3e7deb4e74558ce2faf37f4cea201","GIS guided remote sensing image data for rural industry and space interaction mechanism modeling is discussed in this manuscript. Aerospace remote sensing technology is a technology for obtaining the remote sensing image information data through the satellite ground observations, and these image data play an indispensable role in various fields. Hence, this paper proposes the following novel ideas. (1) In GIS management mode, spatial relation expression is clear at a glance, and the management and editing of the attribute fields are not restricted. (2) Super-resolution reconstruction can be regarded as the second-generation image restoration to a certain extent, we integrate the image processing technology to process the data. (3) The suggestions of the rural industry and space interaction mechanism modeling is provided. © 2020 IEEE.","Aerospace industry; Agriculture; Image reconstruction; Remote sensing; Space optics; Aerospace remote sensing; Ground observations; Image processing technology; Interaction mechanisms; Remote sensing images; Second generation; Spatial relations; Super resolution reconstruction; Geographic information systems","GIS System; Image Analysis; Remote Sensing; Rural Industry; space interaction","Conference paper","Final","","Scopus","2-s2.0-85091751998"
"Shao Z.; Wang L.; Wang Z.; Deng J.","Shao, Zhenfeng (57203905559); Wang, Lei (57211488504); Wang, Zhongyuan (57203515592); Deng, Juan (37021099200)","57203905559; 57211488504; 57203515592; 37021099200","Remote Sensing Image Super-Resolution Using Sparse Representation and Coupled Sparse Autoencoder","2019","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","12","8","8758165","2663","2674","11","10.1109/JSTARS.2019.2925456","73","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072644224&doi=10.1109%2fJSTARS.2019.2925456&partnerID=40&md5=782bc033ee02d5b186fec9241da21eb7","Remote sensing image super-resolution (SR) refers to a technique improving the spatial resolution, which in turn benefits to the subsequent image interpretation, e.g., target recognition, classification, and change detection. In popular sparse representation-based methods, due to the complex imaging conditions and unknown degradation process, the sparse coefficients of low-resolution (LR) observed images are hardly consistent with the real high-resolution (HR) counterparts, which leads to unsatisfactory SR results. To address this problem, a novel coupled sparse autoencoder (CSAE) is proposed in this paper to effectively learn the mapping relation between the LR and HR images. Specifically, the LR and HR images are first represented by a set of sparse coefficients, and then, a CSAE is established to learn the mapping relation between them. Since the proposed method leverages the feature representation ability of both sparse decomposition and CSAE, the mapping relation between the LR and HR images can be accurately obtained. Experimentally, the proposed method is compared with several state-of-the-art image SR methods on three real-world remote sensing image datasets with different spatial resolutions. The extensive experimental results demonstrate that the proposed method has gained solid improvements in terms of average peak signal-to-noise ratio and structural similarity measurement on all of the three datasets. Moreover, results also show that with larger upscaling factors, the proposed method achieves more prominent performance than the other competitive methods. © 2008-2012 IEEE.","Learning systems; Mapping; Optical resolving power; Remote sensing; Signal to noise ratio; Auto encoders; Feature representation; Image interpretation; Image super resolutions; Peak signal to noise ratio; Remote sensing images; Sparse representation; Structural similarity; artificial neural network; data set; image processing; mapping; remote sensing; signal-to-noise ratio; spatial resolution; Image enhancement","Coupled sparse autoencoder (CSAE); image super-resolution (SR); remote sensing image; sparse representation","Article","Final","","Scopus","2-s2.0-85072644224"
"Bobak J.; Alqadah H.; Nurnberger M.; Rudolph S.; Truesdale D.","Bobak, Justin (6603835802); Alqadah, Hatim (24476048200); Nurnberger, Michael (6603911095); Rudolph, Scott (17346939600); Truesdale, David (56622862900)","6603835802; 24476048200; 6603911095; 17346939600; 56622862900","Microwave Single Pixel Imager (MSPI) Overview and Imaging Algorithm","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898608","8837","8840","3","10.1109/IGARSS.2019.8898608","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074898705&doi=10.1109%2fIGARSS.2019.8898608&partnerID=40&md5=ba7864a9f914b986e8412f84decd8ab2","An overview of the MSPI system and a description of the imaging algorithm is presented. The imaging algorithm relies on compressive sensing techniques, and also performs a super resolution operation. Quantified performance simulations are included, with discussion of how these results align with environmental remote sensing needs. The unique aperture is discussed in a separate paper. © 2019 IEEE.","Geology; Compressive sensing; Environmental remote sensing; Imaging algorithm; Performance simulation; Single pixel; Super resolution; Remote sensing","","Conference paper","Final","","Scopus","2-s2.0-85074898705"
"Huang Z.-X.; Jing C.-W.","Huang, Zhi-Xing (57215537930); Jing, Chang-Wei (57542839000)","57215537930; 57542839000","Super-Resolution Reconstruction Method of Remote Sensing Image Based on Multi-Feature Fusion","2020","IEEE Access","8","","8963714","18764","18771","7","10.1109/ACCESS.2020.2967804","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081112726&doi=10.1109%2fACCESS.2020.2967804&partnerID=40&md5=dde8f91a5cb3bdf1f9a0c3c688eb09c8","The acquisition of remote sensing images is affected by imaging equipment and environmental conditions. Usually on lower performance devices, the resolution of the acquired images is also low. Among many methods, the super-resolution reconstruction method based on generative adversarial networks has obvious advantages over previous network models in reconstructing image texture details. However, it is found in experiments that not all of these reconstructed textures exist in the image itself. Aiming at the problem of whether the texture details of the reconstructed image are accurate and clear, we propose a super-resolution reconstruction method combining wavelet transform and generative adversarial network. Using wavelet multi-resolution analysis, training wavelet decomposition coefficients in the generative adversarial network can effectively improve the local detail information of the reconstructed image. Experimental results show that our method can effectively reconstruct more natural image textures and make the images more visually clear. In the remote sensing image test set, the four indicators of the algorithm, peak signal to noise ratio (PSNR), structural similarity (SSIM), Feature Similarity (FSIM) and Universal Image Quality (UIQ) are slightly better than the algorithms mentioned in the article. © 2020 IEEE.","Image acquisition; Image enhancement; Image quality; Image reconstruction; Optical resolving power; Remote sensing; Signal to noise ratio; Textures; Wavelet decomposition; Decomposition coefficient; Feature similarity(FSIM); Peak signal to noise ratio; Remote sensing images; Self correlation; Super resolution; Super resolution reconstruction; Wavelet multi-resolution analysis; Image texture","image texture; Remote sensing image; self-correlation; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85081112726"
"Li J.; Cui R.; Li Y.; Li B.; Du Q.; Ge C.","Li, Jiaojiao (55934244200); Cui, Ruxing (57211523782); Li, Yunsong (55986546100); Li, Bo (57188584536); Du, Qian (7202060063); Ge, Chiru (57189461615)","55934244200; 57211523782; 55986546100; 57188584536; 7202060063; 57189461615","Multitemporal Hyperspectral Image Super-Resolution through 3D Generative Adversarial Network","2019","2019 10th International Workshop on the Analysis of Multitemporal Remote Sensing Images, MultiTemp 2019","","","8866956","","","","10.1109/Multi-Temp.2019.8866956","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074259539&doi=10.1109%2fMulti-Temp.2019.8866956&partnerID=40&md5=b367650ef774fd46193554b7d9860789","The super-resolution of multitemporal hyperspectral imagery is considered, wherein a 3D generative adversarial network (GAN) is promoted and employed. Firstly, we put the SR process in a generative adversarial network (GAN) framework, so that the resulted high resolution HSI can keep more texture details. Secondly, the input of our method is of full bands due to 3D kernel exploited. Furthermore, a series of spatial-spectral constraints or loss functions are imposed to guide the training of our generative network so as to further alleviate spectral distortion and texture blur. The experiments on the houston datasets demonstrate that the proposed GAN-based SR method with the best generalization ability can yield very high quality results. © 2019 IEEE.","Image analysis; Optical resolving power; Spectroscopy; Textures; Adversarial networks; Generalization ability; High resolution; Hyper-spectral imageries; Image super resolutions; Spectral constraints; Spectral distortions; Super resolution; Remote sensing","GAN; generalization ability; hyperspectral super-resolution; Multitemporal Hyperspectral imagery","Conference paper","Final","","Scopus","2-s2.0-85074259539"
"Liu H.; Wu R.; Ma W.-K.","Liu, Huikang (57192167533); Wu, Ruiyuan (57194873872); Ma, Wing-Kin (7402703846)","57192167533; 57194873872; 7402703846","Is There Any Recovery Guarantee with Coupled Structured Matrix Factorization for Hyperspectral Super-Resolution?","2019","2019 IEEE 8th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing, CAMSAP 2019 - Proceedings","","","9022516","480","484","4","10.1109/CAMSAP45676.2019.9022516","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082399149&doi=10.1109%2fCAMSAP45676.2019.9022516&partnerID=40&md5=4c2d8f715fd93629272b456e7961417a","Coupled structured matrix factorization (CoSMF) for hyperspectral super-resolution (HSR) has recently drawn significant interest in hyperspectral imaging for remote sensing. Presently there are very few studies on the theoretical recovery guarantees of CoSMF. This paper makes one such endeavor by considering the CoSMF formulation by Wei et al., which, simply speaking, is similar to coupled non-negative matrix factorization. Assuming no noise, we show sufficient conditions under which the globably optimal solution to the CoSMF problem is guaranteed to deliver certain recovery accuracies. Our analysis suggests that sparsity and the pure-pixel (or separability) condition play a hidden role in enabling CoSMF to achieve some good recovery characteristics. © 2019 IEEE.","Array processing; Factorization; Hyperspectral imaging; Optical resolving power; Recovery; Remote sensing; Spectroscopy; HyperSpectral; Nonnegative matrix factorization; Optimal solutions; Pure pixel; Structured matrixes; Super resolution; Matrix algebra","coupled structured matrix factorization; hyperspectral super-resolution; recovery guarantee","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85082399149"
"Tran K.; Panahi A.; Adiga A.; Sakla W.; Krim H.","Tran, Kenneth (57052318100); Panahi, Ashkan (36470876800); Adiga, Aniruddha (36447297900); Sakla, Wesam (14069004700); Krim, Hamid (26643057600)","57052318100; 36470876800; 36447297900; 14069004700; 26643057600","Nonlinear Multi-scale Super-resolution Using Deep Learning","2019","ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","2019-May","","8682354","3182","3186","4","10.1109/ICASSP.2019.8682354","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069000640&doi=10.1109%2fICASSP.2019.8682354&partnerID=40&md5=7553e8638c9a937e4390ebb9c7d1e70f","We propose a deep learning architecture capable of performing up to 8× single image super-resolution. Our architecture incorporates an adversarial component from the super-resolution generative adversarial networks (SRGANs) and a multi-scale learning component from the multiple scale super-resolution network (MSSRNet), which only together can recover smaller structures inherent in satellite images. To further enhance our performance, we integrate progressive growing and training to our network. This, aided by feed forwarding connections in the network to move along and enrich information from previous inputs, produces super-resolved images at scaling factors of 2, 4, and 8. To ensure and enhance the stability of GANs, we employ Wasserstein GANs (WGANs) during training. Experimentally, we find that our architecture can recover small objects in satellite images during super-resolution whereas previous methods cannot. © 2019 IEEE.","Audio signal processing; Network architecture; Optical resolving power; Remote sensing; Small satellites; Speech communication; Adversarial networks; GANs; Learning architectures; Multiple scale; Remote sensing data; Satellite images; Scaling factors; Super resolution; Deep learning","dilated convolutions; GANs; remote sensing data; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85069000640"
"Xiong Y.; Guo S.; Chen J.; Deng X.; Sun L.; Zheng X.; Xu W.","Xiong, Yingfei (57216764463); Guo, Shanxin (56529951100); Chen, Jinsong (55326493300); Deng, Xinping (35232927300); Sun, Luyi (57218130658); Zheng, Xiaorou (57216768681); Xu, Wenna (57216770502)","57216764463; 56529951100; 55326493300; 35232927300; 57218130658; 57216768681; 57216770502","Improved SRGAN for remote sensing image super-resolution across locations and sensors","2020","Remote Sensing","12","8","1263","","","","10.3390/RS12081263","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084550192&doi=10.3390%2fRS12081263&partnerID=40&md5=e1ba3308aa42d433ea5851b798d59ab1","Detailed and accurate information on the spatial variation of land cover and land use is a critical component of local ecology and environmental research. For these tasks, high spatial resolution images are required. Considering the trade-offbetween high spatial and high temporal resolution in remote sensing images, many learning-based models (e.g., Convolutional neural network, sparse coding, Bayesian network) have been established to improve the spatial resolution of coarse images in both the computer vision and remote sensing fields. However, data for training and testing in these learning-based methods are usually limited to a certain location and specific sensor, resulting in the limited ability to generalize the model across locations and sensors. Recently, generative adversarial nets (GANs), a new learning model from the deep learning field, show many advantages for capturing high-dimensional nonlinear features over large samples. In this study, we test whether the GAN method can improve the generalization ability across locations and sensors with some modification to accomplish the idea ""training once, apply to everywhere and different sensors"" for remote sensing images. This work is based on super-resolution generative adversarial nets (SRGANs), where we modify the loss function and the structure of the network of SRGANs and propose the improved SRGAN (ISRGAN), which makes model training more stable and enhances the generalization ability across locations and sensors. In the experiment, the training and testing data were collected from two sensors (Landsat 8 OLI and Chinese GF 1) from different locations (Guangdong and Xinjiang in China). For the cross-location test, the model was trained in Guangdong with the Chinese GF 1 (8 m) data to be tested with the GF 1 data in Xinjiang. For the cross-sensor test, the same model training in Guangdong with GF 1 was tested in Landsat 8 OLI images in Xinjiang. The proposed method was compared with the neighbor-embedding (NE) method, the sparse representation method (SCSR), and the SRGAN. The peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) were chosen for the quantitive assessment. The results showed that the ISRGAN is superior to the NE (PSNR: 30.999, SSIM: 0.944) and SCSR (PSNR: 29.423, SSIM: 0.876) methods, and the SRGAN (PSNR: 31.378, SSIM: 0.952), with the PSNR = 35.816 and SSIM = 0.988 in the cross-location test. A similar result was seen in the cross-sensor test. The ISRGAN had the best result (PSNR: 38.092, SSIM: 0.988) compared to the NE (PSNR: 35.000, SSIM: 0.982) and SCSR (PSNR: 33.639, SSIM: 0.965) methods, and the SRGAN (PSNR: 32.820, SSIM: 0.949). Meanwhile, we also tested the accuracy improvement for land cover classification before and after super-resolution by the ISRGAN. The results show that the accuracy of land cover classification after super-resolution was significantly improved, in particular, the impervious surface class (the road and buildings with high-resolution texture) improved by 15%. © 2020 by the authors.","Ability testing; Bayesian networks; Convolutional neural networks; Deep learning; Image coding; Image resolution; Land use; Learning systems; Location; Optical resolving power; Remote sensing; Signal to noise ratio; Textures; Environmental researches; Generalization ability; High spatial resolution images; High temporal resolution; High-resolution textures; Land cover classification; Learning-based methods; Peak signal to noise ratio; Image enhancement","Image downscaling; Model generalization; SRGAN; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85084550192"
"Wei J.; Xu Y.; Cai W.; Wu Z.; Chanussot J.; Wei Z.","Wei, Jie (57198756322); Xu, Yang (57188730185); Cai, Wanting (57207874095); Wu, Zebin (20437030300); Chanussot, Jocelyn (6602159365); Wei, Zhihui (55761764700)","57198756322; 57188730185; 57207874095; 20437030300; 6602159365; 55761764700","A Two-Stream Multiscale Deep Learning Architecture for Pan-Sharpening","2020","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","13","","9185040","5455","5465","10","10.1109/JSTARS.2020.3021074","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092423062&doi=10.1109%2fJSTARS.2020.3021074&partnerID=40&md5=d06df7683bb7943dfe313323d392b2a5","Pan-sharpening, which fuses the high-resolution panchromatic (PAN) image and the low-resolution multispectral image (MSI), is a hot topic in remote sensing. Recently, deep learning technology has been successfully applied in pan-sharpening. However, the existing methods ignore that the MSI and PAN image are at different resolutions and use the same networks to extract features of the two images. To address this problem, we propose a two-stream deep learning architecture, called coupled multiscale convolutional neural network, for pan-sharpening. The proposed network has three components, feature extraction subnetworks, fusion layer, and super-resolution subnetwork. In the feature extraction subnetworks, two subnetworks are used to extract the features of the MSI and PAN image separately. Different sizes of convolutional kernels are used in the first layers due to the different spatial resolutions. Thus, the source images are mapped to the similar scale. Then a multiscale asymmetric convolution factorization is used to extract features at different scales. In the fusion layer, the two feature extraction subnetworks are coupled. Features at the same scale are first summed, and then the features of all scales are concatenated as one feature map. At last, a super-resolution subnetwork is used to generate the high-resolution MSI. Experimental results on both synthetic and real data sets demonstrate that the proposed method outperforms the other state-of-The-Art pan-sharpening methods. © 2008-2012 IEEE.","Convolution; Convolutional neural networks; Extraction; Feature extraction; Image processing; Network architecture; Optical resolving power; Remote sensing; Convolutional kernel; Different resolutions; Learning architectures; Learning technology; Low resolution multispectral images; Panchromatic (Pan) image; Spatial resolution; Synthetic and real data; artificial neural network; image processing; machine learning; remote sensing; Deep learning","Convolutional neural network (CNN); image fusion; multiscale; pan-sharpening","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85092423062"
"Galar M.; Sesma R.; Ayala C.; Aranda C.","Galar, M. (35731257600); Sesma, R. (57211638474); Ayala, C. (55642388700); Aranda, C. (57211636468)","35731257600; 57211638474; 55642388700; 57211636468","Super-resolution for sentinel-2 images","2019","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","2/W16","","95","102","7","10.5194/isprs-archives-XLII-2-W16-95-2019","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074682230&doi=10.5194%2fisprs-archives-XLII-2-W16-95-2019&partnerID=40&md5=95ff6610fd7dfda236bb9906d67685e7","Obtaining Sentinel-2 imagery of higher spatial resolution than the native bands while ensuring that output imagery preserves the original radiometry has become a key issue since the deployment of Sentinel-2 satellites. Several studies have been carried out on the upsampling of 20m and 60m Sentinel-2 bands to 10 meters resolution taking advantage of 10m bands. However, how to super-resolve 10m bands to higher resolutions is still an open problem. Recently, deep learning-based techniques has become a de facto standard for single-image super-resolution. The problem is that neural network learning for super-resolution requires image pairs at both the original resolution (10m in Sentinel-2) and the target resolution (e.g., 5m or 2.5m). Since there is no way to obtain higher resolution images for Sentinel-2, we propose to consider images from others sensors having the greatest similarity in terms of spectral bands, which will be appropriately pre-processed. These images, together with Sentinel-2 images, will form our training set. We carry out several experiments using state-of-the-art Convolutional Neural Networks for single-image super-resolution showing that this methodology is a first step toward greater spatial resolution of Sentinel-2 images. © Authors 2019. CC BY 4.0 License.","Convolution; Deep learning; Deep neural networks; Geometrical optics; Image resolution; Neural networks; Optical resolving power; Remote sensing; Convolutional neural network; Higher resolution; Higher resolution images; Neural network learning; Optical image; Sentinel-2; Spatial resolution; Super resolution; Image enhancement","Convolutional neural network; Deep learning; Image enhancement; Optical images; Sentinel-2; Super-resolution","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85074682230"
"","","","ICTRS 2019 - Proceedings of the 8th International Conference on Telecommunications and Remote Sensing","2019","ACM International Conference Proceeding Series","","","","","","77","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123040835&partnerID=40&md5=9f36312bf767dc8644794a992f6e034d","The proceedings contain 9 papers. The topics discussed include: choice of a model of the ionosphere to use in high latitudes; sigma shift keying (SSK): FPGA implementation; spectrum's definition, Fourier transform's cross-correlation and compensation properties in ISAR imaging; pulsar signal detection and recognition; an approach for microscopy image restoration; applying sparse based spatial super-resolution for Himawari-8 satellite image; ethical hacking for boosting IoT vulnerability management: a first look into bug bounty programs and responsible disclosures; low cost V2X traffic lights and vehicles communication solution for dynamic routing; and measuring and clustering moving objects.","","","Conference review","Final","","Scopus","2-s2.0-85123040835"
"Burdziakowski P.","Burdziakowski, Pawel (57079016000)","57079016000","Increasing the geometrical and interpretation quality of unmanned aerial vehicle photogrammetry products using super-resolution algorithms","2020","Remote Sensing","12","5","810","","","","10.3390/rs12050810","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081927929&doi=10.3390%2frs12050810&partnerID=40&md5=297a7f3df26797b29b20d0d5ef032047","Unmanned aerial vehicles (UAVs) have now become very popular in photogrammetric and remote-sensing applications. Every day, these vehicles are used in new applications, new terrains, and new tasks, facing new problems. One of these problems is connected with flight altitude and the determined ground sample distance in a specific area, especially within cities and industrial and construction areas. The problem is that a safe flight altitude and camera parameters do not meet the required or demanded ground sampling distance or the geometrical and texture quality. In the cases where the flight level cannot be reduced and there is no technical ability to change the UAV camera or lens, the author proposes the use of a super-resolution algorithm for enhancing images acquired by UAVs and, consequently, increase the geometrical and interpretation quality of the final photogrammetric product. The main study objective was to utilize super-resolution (SR) algorithms to improve the geometric and interpretative quality of the final photogrammetric product, assess its impact on the accuracy of the photogrammetric processing and on the traditional digital photogrammetry workflow. The research concept assumes a comparative analysis of photogrammetric products obtained on the basis of data collected from small, commercial UAVs and products obtained from the same data but additionally processed by the super-resolution algorithm. As the study concludes, the photogrammetric products that are created as a result of the algorithms' operation on high-altitude images show a comparable quality to the reference products from low altitudes and, in some cases, even improve their quality. © 2020 by the authors.","Antennas; Cameras; Geometry; Image enhancement; Optical resolving power; Photogrammetry; Remote sensing; Textures; Unmanned aerial vehicles (UAV); Comparative analysis; Digital photogrammetry; Ground sample distances; Ground sampling distances; New applications; Remote sensing applications; Super resolution; Super resolution algorithms; Aerial photography","Photogrammetry; Super-resolution; UAV","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85081927929"
"Tuo X.; Zhang Y.; Mao D.; Kang Y.; Huang Y.","Tuo, Xingyu (57213190611); Zhang, Yin (55975581400); Mao, Deqing (57194656090); Kang, Yao (57211242158); Huang, Yulin (23014806800)","57213190611; 55975581400; 57194656090; 57211242158; 23014806800","A Radar Forward-Looking Super-Resolution Method Based on Singular Value Weighted Truncation","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898704","9180","9183","3","10.1109/IGARSS.2019.8898704","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077703079&doi=10.1109%2fIGARSS.2019.8898704&partnerID=40&md5=dc204f1dfd6ba0832053d707e67e0cb5","The truncated singular value decomposition (TSVD) method has been applied to radar forward-looking imaging, however which suffers limited resolution. Especially under low signal to noise ratio (SNR) condition, there is a contradiction between keeping more singular values to improve resolution and suppressing noise amplification. In this paper, a method based on singular value weighted truncation is proposed to improve the resolution under low SNR condition. First, this paper analyses the essence of the conventional TSVD method. Then, the passage constructs a new singular value function to reserve more singular value on the original truncation parameter. Compared with the conventional TSVD method, the more singular values are retained which can improve the resolution under the premise of suppressing noise. Simulations demonstrate the effectiveness of the proposed method. © 2019 IEEE.","Geology; Optical resolving power; Radar; Remote sensing; Singular value decomposition; Forward looking; Limited resolution; Low signal-to-noise ratio; Super resolution; Superresolution methods; Suppressing noise; Truncated singular value decomposition; Truncation parameter; Signal to noise ratio","Radar forward-looking; super-resolution.; truncated singular value decomposition","Conference paper","Final","","Scopus","2-s2.0-85077703079"
"Gu F.; Zhang H.; Wang C.; Wu F.","Gu, Feng (57205776909); Zhang, Hong (56179236500); Wang, Chao (55141316100); Wu, Fan (57104120200)","57205776909; 56179236500; 55141316100; 57104120200","SAR Image Super-Resolution Based on Noise-Free Generative Adversarial Network","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8899202","2575","2578","3","10.1109/IGARSS.2019.8899202","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077718212&doi=10.1109%2fIGARSS.2019.8899202&partnerID=40&md5=307d0f20e5820821cb10bd710579743c","Deep learning has been successfully applied to the ordinary image super-resolution (SR). However, since the synthetic aperture radar (SAR) images are often disturbed by multiplicative noise known as speckle and more blurry than ordinary images, there are few deep learning methods for the SAR image SR. In this paper, a deep generative adversarial network (DGAN) is proposed to reconstruct the pseudo high-resolution (HR) SAR images. First, a generator network is constructed to remove the noise of low-resolution SAR image and generate HR SAR image. Second, a discriminator network is used to differentiate between the pseudo super-resolution images and the realistic HR images. The adversarial objective function is introduced to make the pseudo HR SAR images closer to real SAR images. The experimental results show that our method can maintain the SAR image content with high-level noise suppression. The performance evaluation based on peak signal-to-noise-ratio and structural similarity index shows the superiority of the proposed method to the conventional CNN baselines. © 2019 IEEE.","Deep learning; Geology; Learning systems; Optical resolving power; Remote sensing; Signal to noise ratio; Synthetic aperture radar; Adversarial networks; Image super resolutions; Multiplicative noise; Objective functions; Peak signal to noise ratio; Structural similarity indices; Super resolution; Synthetic aperture radar (SAR) images; Radar imaging","generative adversarial network; super-resolution; Synthetic aperture radar","Conference paper","Final","","Scopus","2-s2.0-85077718212"
"Junzhi Y.","Junzhi, Yang (57219258249)","57219258249","Zero-Shot Super Resolution for Satellite Remote Sensing Images","2019","ICSIDP 2019 - IEEE International Conference on Signal, Information and Data Processing 2019","","","9173007","","","","10.1109/ICSIDP47821.2019.9173007","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091902372&doi=10.1109%2fICSIDP47821.2019.9173007&partnerID=40&md5=9bfa5d3bd982830acb9cac96d11c17a7","Due to the great distance between the satellite platform and the ground targets of interests, various factors such as weather and light conditions degrade the image quality captured by the sensors. Single image super resolution (SISR) has always been an important research field in satellite remote sensing image process. With large amounts of low resolution to high resolution (LR-HR) pairs generated by predefined downscaling process, usually noise-free bicubic interpolation with anti-alias, recent deep learning models have shown great improvements on natural image under such ideal conditions. However the real-world degrading process of remote sensing (RS) images differs greatly from the ideal configuration, the state-of-the-art models lose their power when faced with the practical problems. This letter adapted the recently proposed zero shot super resolution scheme to accommodate satellite RS images, both quantitative and qualitative results show that our method outperforms the previous DL-based models by a clear margin. © 2019 IEEE.","Data handling; Deep learning; Optical resolving power; Remote sensing; Satellites; Bicubic interpolation; Downscaling process; Light conditions; Practical problems; Remote sensing images; Satellite platforms; Satellite remote sensing; State of the art; Image enhancement","LR-HR pairs; satellite remote sensing; super resolution; zero shot","Conference paper","Final","","Scopus","2-s2.0-85091902372"
"Sheikholeslami M.M.; Nadi S.; Naeini A.A.; Ghamisi P.","Sheikholeslami, Mohammad Moein (57216977121); Nadi, Saeed (57196248173); Naeini, Amin Alizadeh (54791202700); Ghamisi, Pedram (53663404300)","57216977121; 57196248173; 54791202700; 53663404300","An efficient deep unsupervised superresolution model for remote sensing images","2020","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","13","","9086776","1937","1945","8","10.1109/JSTARS.2020.2984589","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085629398&doi=10.1109%2fJSTARS.2020.2984589&partnerID=40&md5=d82dd28871fc5285af1b2bf72d60b3b3","Superresolution (SR) has provided an effective solution to the increasing need for high-resolution images in remote sensing applications. Among various SR methods, deep learning-based SR (DLSR) has made a significant breakthrough. However, supervised DLSR methods require a considerable amount of training data, which is hardly available in the remote sensing field. To address this issue, some research works have recently proposed and revealed the capability of deep learning in unsupervised SR. This article presents an efficient unsupervised SR (EUSR) deep learning model using dense skip connections, which boosts the reconstruction performance in parallel with the reduction of computational burden. To do this, several blocks containing densely connected convolutional layers are implemented to increase the depth of the model. Some skip connections also concatenate feature maps of different blocks to enable better SR performance. Moreover, a bottle-neck block abstracts the feature maps in fewer feature maps to remarkably reduce the computational burden. According to our experiments, the proposed EUSR leads to better results than the state-of-the-art DLSR method in terms of reconstruction quality with less computational burden. Furthermore, results indicate that the EUSR is more robust than its rival in dealing with images of different classes and larger sizes. © 2008-2012 IEEE.","Bottles; Deep learning; Learning systems; Optical resolving power; Computational burden; Effective solution; High resolution image; Reconstruction quality; Remote sensing applications; Remote sensing images; State of the art; Super-resolution models; image resolution; machine learning; reconstruction; remote sensing; Remote sensing","Deep learning; remote sensing; superresolution (SR)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85085629398"
"Kawulok M.; Piechaczek S.; Hrynczenko K.; Benecki P.; Kostrzewa D.; Nalepa J.","Kawulok, Michal (24474818300); Piechaczek, Szymon (57203969234); Hrynczenko, Krzysztof (57203971746); Benecki, Pawel (55644906700); Kostrzewa, Daniel (50661666400); Nalepa, Jakub (55441340400)","24474818300; 57203969234; 57203971746; 55644906700; 50661666400; 55441340400","On Training Deep Networks for Satellite Image Super-Resolution","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8899098","3125","3128","3","10.1109/IGARSS.2019.8899098","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077691121&doi=10.1109%2fIGARSS.2019.8899098&partnerID=40&md5=a6461bb4df75c2988375edfb80c57d40","The capabilities of super-resolution (SR) reconstruction (i.e., techniques for enhancing image spatial resolution) have been boosted recently by the use of deep convolutional neural networks. For SR, they are learned using huge training sets composed of original images, each of which is coupled with a low-resolution counterpart. In this paper, we explore how the SR performance depends on the procedure employed to obtain the training data. Up to date, this has not been given much attention - commonly, bicubic downsampling is used. Our extensive experimental study indicates that the training data characteristics have a large impact on the reconstruction accuracy, and the widely-adopted approach is not the most effective for dealing with satellite images. Overall, we argue that developing better training data preparation routines may be pivotal in making SR suitable for real-world applications. © 2019 IEEE.","Convolution; Convolutional neural networks; Deep learning; Geology; Image enhancement; Image reconstruction; Optical resolving power; Remote sensing; Satellites; Image spatial resolution; Low resolution; Original images; Reconstruction accuracy; Satellite images; Satellite imaging; Super resolution reconstruction; Training data; Deep neural networks","convolutional neural networks; deep learning; satellite imaging; Super-resolution reconstruction","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85077691121"
"Zhang W.; Li W.; Zhang Y.; Zhang Y.; Huang Y.; Yang J.","Zhang, Wentao (57209270849); Li, Wenchao (55718616300); Zhang, Yongchao (56042343300); Zhang, Yin (55975581400); Huang, Yulin (23014806800); Yang, Jianyu (9239230100)","57209270849; 55718616300; 56042343300; 55975581400; 23014806800; 9239230100","Super-Resolution of Forward-Looking Scanning Radar Based on Low-Rank and Sparse Constraints","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898374","2758","2761","3","10.1109/IGARSS.2019.8898374","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077713317&doi=10.1109%2fIGARSS.2019.8898374&partnerID=40&md5=ae85c9fd247e61e738e977719066d9a3","Regularization technology can be utilized to improve the azimuth resolution for forward-looking scanning radar. In this paper, low-rank and sparse constraints as regularization norms are incorporated into the forward-looking scanning radar imaging. This method can achieve azimuth superresolution and noise suppression. Simulations are given to verify the effectiveness of the method. © 2019 IEEE.","Geology; Optical resolving power; Remote sensing; Scanning; Azimuth resolution; Forward looking; low-rank and sparse constraints; Noise suppression; Scanning radar; Super resolution; Radar","Forward-looking scanning radar; low-rank and sparse constraints; superresolution","Conference paper","Final","","Scopus","2-s2.0-85077713317"
"Zou Y.; Zhang L.; Chen Q.; Wang B.; Hu Y.; Zhang Y.","Zou, Yan (56278157500); Zhang, Linfei (57219972746); Chen, Qian (57192659447); Wang, Bowen (57204607674); Hu, Yan (56681484200); Zhang, Yuzhen (55783460800)","56278157500; 57219972746; 57192659447; 57204607674; 56681484200; 55783460800","An infrared image super-resolution imaging algorithm based on auxiliary convolution neural network","2020","Proceedings of SPIE - The International Society for Optical Engineering","11571","","115711B","","","","10.1117/12.2581217","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096360229&doi=10.1117%2f12.2581217&partnerID=40&md5=00dfbec5709d7548689d4f6bd696e32e","Convolution neural network has been successfully applied to the super-resolution method of the visible image. In this paper, we propose an infrared image super-resolution imaging algorithm based on auxiliary convolution neural network, which uses the detail information provided by the visible image under low-light conditions for super-resolution imaging of infrared image. In this algorithm, infrared image and visible image are input into the convolution neural network at the same time to obtain high resolution infrared image. The results show that the super-resolution infrared image has more detailed information. Compared with other super-resolution methods, the proposed network can obtain the high super-resolution reconstruction efficiency. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Convolution; Infrared imaging; Optical resolving power; Convolution neural network; High resolution infrared; Image super resolutions; Low light conditions; Super resolution; Super resolution imaging; Super resolution reconstruction; Superresolution methods; Neural networks","Auxiliary Convolution Neural Network.; Infrared-Image; Remote Sensing; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85096360229"
"Ciolino M.; Noever D.; Kalin J.","Ciolino, Matthew (57218126114); Noever, David (55955470100); Kalin, Josh (57218127569)","57218126114; 55955470100; 57218127569","Training set effect on super resolution for automated target recognition","2020","Proceedings of SPIE - The International Society for Optical Engineering","11394","","113940P","","","","10.1117/12.2557845","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087930621&doi=10.1117%2f12.2557845&partnerID=40&md5=82672ac17807da7720af1c8c9b1a5836","Single Image Super Resolution (SISR) is the process of mapping a low-resolution image to a high-resolution image. This inherently has applications in remote sensing as a way to increase the spatial resolution in satellite imagery. This suggests a possible improvement to automated target recognition in image classification and object detection. We explore the effect that different training sets have on SISR with the network, Super Resolution Generative Adversarial Network (SRGAN). We train 5 SRGANs on different land-use classes (e.g. agriculture, cities, ports) and test them on the same unseen dataset. We attempt to find the qualitative and quantitative differences in SISR, binary classification, and object detection performance. We find that curated training sets that contain objects in the test ontology perform better on both computer vision tasks while having a complex distribution of images allows object detection models to perform better. However, Super Resolution (SR) might not be beneficial to certain problems and will see a diminishing amount of returns for datasets that are closer to being solved. © 2020 SPIE.","Agricultural robots; Automatic target recognition; Image enhancement; Land use; Object recognition; Optical resolving power; Remote sensing; Satellite imagery; Statistical tests; Adversarial networks; Automated target recognition; Binary classification; Detection performance; High resolution image; Low resolution images; Spatial resolution; Super resolution; Object detection","Deep learning; Image classification; Object detection; Satellite imagery; Super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85087930621"
"Sharma N.; Dash P.P.; Saxena P.","Sharma, Neerav (57208001886); Dash, Praina Parimita (57220498133); Saxena, Priyank (57207991085)","57208001886; 57220498133; 57207991085","GCD Based Blind Super-Resolution for Remote Sensing Applications","2019","2nd International Conference on Energy, Power and Environment: Towards Smart Technology, ICEPE 2018","","","8658528","","","","10.1109/EPETSG.2018.8658528","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063493094&doi=10.1109%2fEPETSG.2018.8658528&partnerID=40&md5=6689b014967b43a9c702f798858b0e43","The importance of remote sensing imageries is growing day by day. Extraction of fine details of desired regions worth for further processing and decision making. Usually the data bases of remote sensing imageries are very huge that overburden the processor. Super-Resolution overcomes this problem and yields a high-quality output in less time consumption. This paper aims to give a brief idea about one of the approaches of super-resolution known as blind super-resolution reconstruction approach. In this approach, Greatest Common Divisor (GCD) algorithm is embedded into the blind reconstruction technique. The HR images obtained from this method is compared with the interpolated images. The results shows the efficacy of the proposed method. The paper tries to overcome the limitations of the super resolution approach and a conclusive discussion of the whole method has been discussed. © 2018 IEEE.","Decision making; Optical resolving power; Blind Super-resolution; Greatest common divisors; Interpolated images; Reconstruction techniques; Remote sensing applications; Remote sensing imagery; Satellite images; Super resolution; Remote sensing","Blind reconstruction; GCD; Remote sensing; Satellite image; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85063493094"
"Aykut E.; Becek K.; Cengiz B.; Ozkan S.; Akar G.B.","Aykut, Ekin (57503953700); Becek, Kadircan (57210945842); Cengiz, Baran (57210947906); Ozkan, Savas (43261670800); Akar, Gozde Bozdagi (57208572487)","57503953700; 57210945842; 57210947906; 43261670800; 57208572487","Effect of visual context information for super resolution problems; [Süper Çözünürlük problemlerinde görsel Içerik bilgisinin etkisi]","2019","27th Signal Processing and Communications Applications Conference, SIU 2019","","","8806598","","","","10.1109/SIU.2019.8806598","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071972564&doi=10.1109%2fSIU.2019.8806598&partnerID=40&md5=f92503ca1e82b5c52ec54d312f17bdbe","In this study, the effect of visual context information to the performance of learning-based techniques for the super resolution problem is analyzed. Beside the interpretation of the experimental results in detail, its theoretical reasoning is also achieved in the paper. For the experiments, two different visual datasets composed of natural and remote sensing scenes are utilized. From the experimental results, we observe that keeping visual context information in the course of parameter learning for convolutional neural networks yields better performance compared to the baselines. Moreover, we summarize that finetuning pre-trained parameters with the related context yet fewer samples improves the results. © 2019 IEEE.","Convolution; Deep learning; Deep neural networks; Neural networks; Optical resolving power; Remote sensing; Convolutional neural network; Parameter learning; Super resolution; Visual context; Signal processing","Convolutional Neural Networks; Deep learning; Super Resolution","Conference paper","Final","","Scopus","2-s2.0-85071972564"
"Tsagkatakis G.; Aidini A.; Fotiadou K.; Giannopoulos M.; Pentari A.; Tsakalides P.","Tsagkatakis, Grigorios (34870845200); Aidini, Anastasia (57203761304); Fotiadou, Konstantina (25824915900); Giannopoulos, Michalis (57205378265); Pentari, Anastasia (56442653900); Tsakalides, Panagiotis (6701848334)","34870845200; 57203761304; 25824915900; 57205378265; 56442653900; 6701848334","Survey of deep-learning approaches for remote sensing observation enhancement","2019","Sensors (Switzerland)","19","18","3929","","","","10.3390/s19183929","82","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072555757&doi=10.3390%2fs19183929&partnerID=40&md5=857b0d03e174ccd53dc03eb73ca52949","Deep Learning, and Deep Neural Networks in particular, have established themselves as the new norm in signal and data processing, achieving state-of-the-art performance in image, audio, and natural language understanding. In remote sensing, a large body of research has been devoted to the application of deep learning for typical supervised learning tasks such as classification. Less yet equally important effort has also been allocated to addressing the challenges associated with the enhancement of low-quality observations from remote sensing platforms. Addressing such channels is of paramount importance, both in itself, since high-altitude imaging, environmental conditions, and imaging systems trade-offs lead to low-quality observation, as well as to facilitate subsequent analysis, such as classification and detection. In this paper, we provide a comprehensive review of deep-learning methods for the enhancement of remote sensing observations, focusing on critical tasks including single and multi-band super-resolution, denoising, restoration, pan-sharpening, and fusion, among others. In addition to the detailed analysis and comparison of recently presented approaches, different research avenues which could be explored in the future are also discussed. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","Chemical detection; Data handling; Deep learning; Deep neural networks; Economic and social effects; Fusion reactions; Neural networks; Optical resolving power; Quality control; Adversarial networks; Convolutional neural network; De-noising; Earth observations; Pan-sharpening; Satellite imaging; Super resolution; Remote sensing","Convolutional neural networks; Deep learning; Denoising; Earth observations; Fusion; Generative adversarial networks; Pan-sharpening; Satellite imaging; Super-resolution","Review","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85072555757"
"Yi C.; Zhao Y.-Q.; Chan J.C.-W.","Yi, Chen (56421324300); Zhao, Yong-Qiang (35365726800); Chan, Jonathan Cheung-Wai (57208276698)","56421324300; 35365726800; 57208276698","Spectral Super-Resolution for Multispectral Image Based on Spectral and Spatial Strategies","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898630","851","854","3","10.1109/IGARSS.2019.8898630","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077703765&doi=10.1109%2fIGARSS.2019.8898630&partnerID=40&md5=14dda905a745ad947fba54a4d9c87dc5","A spectral super-resolution method is proposed in this paper to recover a high spectral resolution hyperspectral (HS) image from multispectral (MS) images. The proposed method involves spectral improvement strategy and spatial preservation strategy. For spectral improvement strategy, auxiliary MS/HS image pairs of different landscapes are exploited to estimate spectral response relationship so that a HS image is obtained as an intermediate result. Then, spectral dictionary learning is exploited to recover more accurate spectral reconstruction result. Spatial preservation strategy is used as spatial constraint to ensure spatial consistency. Additionally, low rank property of HS image is also introduced to make use of global spectral coherence among HS bands. Experiments are conducted on real MS/HS data (ALI and Hyperion) captured by EO-1 satellite. Experiment results demonstrate the superiority of our proposed method to other state-of-art methods. © 2019 IEEE.","Geology; Hyperspectral imaging; Remote sensing; Spectral resolution; Spectroscopy; High spectral resolution; Improvement strategies; Intermediate results; Low rank; Preservation strategies; Resolution enhancement; Spectral reconstruction; Superresolution methods; Image enhancement","Hyperspectral image; Low rank; Spectral dictionary; Spectral resolution enhancement","Conference paper","Final","","Scopus","2-s2.0-85077703765"
"Ji H.; Gao Z.; Liu X.; Zhang Y.; Mei T.","Ji, Hong (57205763449); Gao, Zhi (55256514200); Liu, Xiaodong (56420642200); Zhang, Yongjun (55577971100); Mei, Tiancan (8914886000)","57205763449; 55256514200; 56420642200; 55577971100; 8914886000","Small object detection leveraging on simultaneous super-resolution","2020","Proceedings - International Conference on Pattern Recognition","","","9413058","9054","9061","7","10.1109/ICPR48806.2021.9413058","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110485870&doi=10.1109%2fICPR48806.2021.9413058&partnerID=40&md5=f0b28d82151c3dfaf7af0c2683cd264e","Despite the impressive advancement achieved in object detection, the detection performance of small object is still far from satisfactory due to the lack of sufficient detailed appearance to distinguish it from similar objects. Inspired by the positive effects of super-resolution for object detection, we propose a framework that can be incorporated with detector networks to improve the performance of small object detection, in which the low-resolution image is super-resolved via generative adversarial network (GAN) in an unsupervised manner. In our method, the super-resolution network and the detection network are trained jointly. In particular, the detection loss is back-propagated into the super-resolution network during training to facilitate detection. Compared with available simultaneous super-resolution and detection methods which heavily rely on low-/high-resolution image pairs, our work breaks through such restriction via applying the CycleGAN strategy, achieving increased generality and applicability, while remaining an elegant structure. Extensive experiments on datasets from both computer vision and remote sensing communities demonstrate that our method obtains competitive performance on a wide range of complex scenarios. © 2020 IEEE","Image enhancement; Object recognition; Optical resolving power; Remote sensing; Adversarial networks; Competitive performance; Detection methods; Detection networks; Detection performance; Detector networks; Low resolution images; Small object detection; Object detection","","Conference paper","Final","","Scopus","2-s2.0-85110485870"
"Zhang M.; Su W.; Fu Y.; Zhu D.; Xue J.-H.; Huang J.; Wang W.; Wu J.; Yao C.","Zhang, Mingzheng (57020048200); Su, Wei (56506117700); Fu, Yuting (57210915922); Zhu, D. (8903358300); Xue, Jing-Hao (7202881908); Huang, Jianxi (8206714700); Wang, Wei (57211077340); Wu, J. (57210921790); Yao, Chan (57210915740)","57020048200; 56506117700; 57210915922; 8903358300; 7202881908; 8206714700; 57211077340; 57210921790; 57210915740","Super-resolution enhancement of Sentinel-2 image for retrieving LAI and chlorophyll content of summer corn","2019","European Journal of Agronomy","111","","125938","","","","10.1016/j.eja.2019.125938","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071854270&doi=10.1016%2fj.eja.2019.125938&partnerID=40&md5=8a608ed4631751d4db063e2e8fce440f","Sentinel-2 satellite is a new generation of multi-spectral remote sensing technique with high spatial, temporal and spectral resolution. Especially, Sentinel-2 incorporates three red-edge bands with central wavelength at 705, 740 and 783 nm, which are very sensitive to vegetation changing, heath and variations. Unfortunately, their spatial resolution is only 20 m, which is lower comparably. This spatial resolution brings difficulties for mining the potential of Sentinel-2 image in vegetation monitoring. Therefore, we focus on enhancing the spatial resolution of Sentinel-2 red edge band images to 10m using the SupReME algorithm. Furthermore, the summer corn canopy leaf area index (LAI), leaves chlorophyll content (LCC) and canopy chlorophyll content (CCC) were retrieved by the linear and physical models for the corn growth monitoring purpose. The results showed that the spatial resolution of Sentinel-2 images had been enhanced to 10m from original 20m, and the estimation accuracy (EA) was over 97% for pixels planted by summer corn. Moreover, the accuracy of summer corn canopy LAI, LCC and CCC was improved respectively using enhanced Sentinel-2 images by SupReME method. During these three parameters retrieval, the red-edge bands or SWIR bands were introduced into optimal cost function and vegetation index which the accuracy of these models was high. The SupReME algorithm provides a valuable way for Sentinel-2 images enhancement, which is of great potential to mining Sentinel-2 images and multitude its application. © 2019","Zea mays; accuracy assessment; algorithm; chlorophyll; leaf area index; maize; numerical model; radiative transfer; remote sensing; satellite imagery; Sentinel; spatial resolution; spectral resolution; summer","Chlorophyll content; LAI; Radiative transfer model; Sentinel-2 image; SupReME algorithm","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85071854270"
"Wu S.; Yang P.; Ren J.; Chen Z.; Liu C.","Wu, Shangrong (55607162400); Yang, Peng (55510452900); Ren, Jianqiang (14021882100); Chen, Zhongxin (14021042100); Liu, Changan (56420745800)","55607162400; 55510452900; 14021882100; 14021042100; 56420745800","A Novel Sub-Pixel Mapping Model Based on Pixel Aggregation Degree for Small-Sized Land-Cover","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8899769","3073","3076","3","10.1109/IGARSS.2019.8899769","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077698542&doi=10.1109%2fIGARSS.2019.8899769&partnerID=40&md5=73826dd954c035f841ffd1ad1082a452","To further improve the accuracy of remote sensing classification and land-cover recognition at sub-pixel level, a novel sub-pixel mapping (SPM) model was first proposed by introducing the concept of pixel aggregation degree (PAD) which could simulate the spatial distribution of small-sized land-cover. In the proposed novel SPM model, based on the distribution of sub-pixel random initialization, PAD algorithm was optimized sub-pixel distribution to obtain final SPM results. Using a Sentinel-2 remote sensing data, related SPM experiments were performed to verify both accuracy and effect of PAD SPM model. The experimental results indicated that the SPM accuracy based on PAD model were superior to the classification results of the K-mean and the SPM results of traditional spatial attraction model. It was shown that the PAD model had certain feasibility and applicability which provided a new idea to better break the limitations of remote sensing image spatial resolution, and was beneficial to the subsequent research and application of remote sensing image. © 2019 IEEE.","Geology; Mapping; Pixels; Classification results; Land cover; Optimization algorithms; Remote sensing classification; Remote sensing images; Research and application; Sub-pixel mapping; Super-resolution mappings; Remote sensing","optimization algorithm; pixel aggregation degree; small-sized land-cover; sub-pixel mapping; super-resolution mapping","Conference paper","Final","","Scopus","2-s2.0-85077698542"
"Jia Y.","Jia, Yanqin (57196487550)","57196487550","A super-resolution reconstruction method for remote sensing images based on Adam optimized depth convolution network","2020","Proceedings of SPIE - The International Society for Optical Engineering","11438","","1143809","","","","10.1117/12.2541485","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082617140&doi=10.1117%2f12.2541485&partnerID=40&md5=573fccb2202d644d9bbe875d3bdf8958","Super-resolution reconstructed convolution neural network (SRCNN) is widely used in image quality improvement of single image. Traditional SRCNN training uses the loss function of minimum mean square error (MSE) and the method based on stochastic gradient descent (SGD) to optimize. Its learning rate adjustment strategy is limited by pre-specified adjustment rules, and it is difficult to select the initial value. Considering the complex texture and low resolution of remote sensing images, a deconvolution layer is proposed to replace the bi-cubic interpolation enlarged image in the traditional SRCNN network to overcome the mosaic effect. At the same time, Adam optimizer is used to control the network training. After considering the first and second moment estimation of gradient comprehensively, the update step is calculated. Thus, the adaptive update of learning rate is realized and the speed of network training is greatly accelerated. The simulation results show that this method has advantages in edge reconstruction and texture details compared with the conventional super-resolution reconstruction algorithm. © 2020 SPIE.","Convolution; Deconvolution; Gradient methods; Image enhancement; Learning algorithms; Mean square error; Optical resolving power; Optical signal processing; Optimization; Remote sensing; Signal receivers; Stochastic systems; Textures; Bicubic interpolation; Convolution neural network; Image quality improvements; Minimum mean square error (mse); Optimization algorithms; Remote sensing images; Stochastic gradient descent; Super resolution reconstruction; Image reconstruction","Adam optimization algorithm; Convolution neural network; Deconvolution; Remote sensing super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85082617140"
"Fu L.; Ren C.; He X.; Wu X.; Wang Z.","Fu, Lingli (57215087021); Ren, Chao (57207076112); He, Xiaohai (9237988800); Wu, Xiaohong (56900066300); Wang, Zhengyong (55850352300)","57215087021; 57207076112; 9237988800; 56900066300; 55850352300","Single remote sensing image super-resolution with an adaptive joint constraint model","2020","Sensors (Switzerland)","20","5","1276","","","","10.3390/s20051276","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079890795&doi=10.3390%2fs20051276&partnerID=40&md5=b7dc2bf07812fdf2fe114f2d5da282fe","Remote sensing images have been widely used in many applications. However, the resolution of the obtained remote sensing images may not meet the increasing demands for some applications. In general, the sparse representation-based super-resolution (SR) method is one of the most popular methods to solve this issue. However, traditional sparse representation SR methods do not fully exploit the complementary constraints of images. Therefore, they cannot accurately reconstruct the unknown HR images. To address this issue, we propose a novel adaptive joint constraint (AJC) based on sparse representation for the single remote sensing image SR. First, we construct a nonlocal constraint by using the nonlocal self-similarity. Second, we propose a local structure filter according to the local gradient of the image and then construct a local constraint. Next, the nonlocal and local constraints are introduced into the sparse representation-based SR framework. Finally, the parameters of the joint constraint model are selected adaptively according to the level of image noise. We utilize the alternate iteration algorithm to tackle the minimization problem in AJC. Experimental results show that the proposed method achieves good SR performance in preserving image details and significantly improves the objective evaluation indices. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Image enhancement; Iterative methods; Optical resolving power; Local structure; Remote sensing images; Self-similarities; Sparse representation; Super resolution; Remote sensing","Local structure filter; Nonlocal self-similarity; Single remote sensing image; Sparse representation; Super-resolution (SR)","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85079890795"
"He H.; Chen T.; Chen M.; Li D.; Cheng P.","He, Haiqing (55214935900); Chen, Ting (56621591000); Chen, Minqiang (57210812783); Li, Dajun (27169720300); Cheng, Penggen (26661399000)","55214935900; 56621591000; 57210812783; 27169720300; 26661399000","Remote sensing image super-resolution using deep–shallow cascaded convolutional neural networks","2019","Sensor Review","39","5","","629","635","6","10.1108/SR-11-2018-0301","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071575109&doi=10.1108%2fSR-11-2018-0301&partnerID=40&md5=d4d8e1d9d456fb847ddcb4e50bb81c25","Purpose: This paper aims to present a novel approach of image super-resolution based on deep–shallow cascaded convolutional neural networks for reconstructing a clear and high-resolution (HR) remote sensing image from a low-resolution (LR) input. Design/methodology/approach: The proposed approach directly learns the residuals and mapping between simulated LR and their corresponding HR remote sensing images based on deep and shallow end-to-end convolutional networks instead of assuming any specific restored models. Extra max-pooling and up-sampling are used to achieve a multiscale space by concatenating low- and high-level feature maps, and an HR image is generated by combining LR input and the residual image. This model ensures a strong response to spatially local input patterns by using a large filter and cascaded small filters. The authors adopt a strategy based on epochs to update the learning rate for boosting convergence speed. Findings: The proposed deep network is trained to reconstruct high-quality images for low-quality inputs through a simulated dataset, which is generated with Set5, Set14, Berkeley Segmentation Data set and remote sensing images. Experimental results demonstrate that this model considerably enhances remote sensing images in terms of spatial detail and spectral fidelity and outperforms state-of-the-art SR methods in terms of peak signal-to-noise ratio, structural similarity and visual assessment. Originality/value: The proposed method can reconstruct an HR remote sensing image from an LR input and significantly improve the quality of remote sensing images in terms of spatial detail and fidelity. © 2019, Emerald Publishing Limited.","Convolution; Convolutional neural networks; Image enhancement; Image reconstruction; Image segmentation; Optical resolving power; Signal receivers; Signal to noise ratio; Space optics; Convolutional networks; Design/methodology/approach; Image super resolutions; Peak signal to noise ratio; Remote sensing images; Residual; Structural similarity; Super resolution; Remote sensing","Convolutional neural network (CNN); Residual; Super-resolution; Transmission map","Article","Final","","Scopus","2-s2.0-85071575109"
"Zhang Q.; Zhang Y.; Huang Y.; Zhang Y.","Zhang, Qiping (57207878759); Zhang, Yin (55975581400); Huang, Yulin (23014806800); Zhang, Yongchao (56042343300)","57207878759; 55975581400; 23014806800; 56042343300","Azimuth Superresolution of Forward-Looking Radar Imaging Which Relies on Linearized Bregman","2019","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","12","7","8714056","2032","2043","11","10.1109/JSTARS.2019.2912993","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070493512&doi=10.1109%2fJSTARS.2019.2912993&partnerID=40&md5=658a7d6b66fa0f05864b8e4640231a41","Forward-looking radar plays an important role in many military and civilian fields. However, the problem of low azimuth resolution has restricted its applications seriously. Although many methods have been used to achieve azimuth superresolution, the traditional methods suffer from noise amplification or limited resolution under low signal-To-noise (SNR) condition. In this paper, we proposed a Bayesian deconvolution method which relies on linearized Bregman to achieve azimuth superresolution of forward-looking radar imaging. We first used the complex Gaussian distribution and Laplace distribution to describe the distribution of noise and targets, respectively, and transformed the superresolution problem into a convex optimization problem by maximum a posteriori estimation in the Bayesian framework. Second, linearized Bregman algorithm was used to solve the convex optimization problem. The proposed method introduces the prior information of noise and target, and overcomes the ill-posedness of deconvolution. As a result, the azimuth resolution is remarkably enhanced. Besides, the proposed method has high computational efficiency by linearizing objection function, so it can take both time cost and resolution improvement into consideration. Finally, the superior performance was verified by simulation and experimental data. © 2008-2012 IEEE.","Computational efficiency; Convex optimization; Deconvolution; Gaussian noise (electronic); Linearization; Optical resolving power; Radar; Signal to noise ratio; Complex Gaussian distribution; Convex optimization problems; Deconvolution method; Forward looking radars; Laplace distributions; Maximum a posteriori estimation; Resolution improvement; Super resolution; algorithm; azimuth; Bayesian analysis; deconvolution; Gaussian method; image resolution; radar imagery; remote sensing; signal-to-noise ratio; Radar imaging","Deconvolution; maximum a posteriori estimation; radar imaging; superresolution","Article","Final","","Scopus","2-s2.0-85070493512"
"Zhu F.; Zou D.; Wang Z.; Wu H.","Zhu, Fuzhen (12780819500); Zou, Danni (57210580783); Wang, Zhifang (35231273600); Wu, Hong (55619294193)","12780819500; 57210580783; 35231273600; 55619294193","Remote sensing image super-resolution based on double parameters Beta process joint dictionary; [双参数Beta过程联合字典遥感图像超分辨]","2019","Xi Tong Gong Cheng Yu Dian Zi Ji Shu/Systems Engineering and Electronics","41","9","","1955","1960","5","10.3969/j.issn.1001-506X.2019.09.06","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075421869&doi=10.3969%2fj.issn.1001-506X.2019.09.06&partnerID=40&md5=adcbd62e71443aec16f2f21e45b09b6a","An image super-resolution reconstruction (SRR) algorithm based on the double parameters Beta process joint dictionary (BPJD) is proposed to improve the image SRR effect. Compared with those sparse representation SRR algorithms that are only applicable to single feature space, the BPJD learning dictionary is obtained in coupled feature spaces. Firstly, a training sample image is obtained according to the remote sensing image degradation model, and high and low resolution images are respectively patched and Gibbs sampled to generate the dictionary training samples. Then, a double-parameter joint dictionary is established to connect the high-low resolution image space according to the BPJD model. In the Beta process, sparse coefficients are expressed as the multiplication of coefficient weights and dictionary atoms and the joint dictionary mapping matrix is obtained by training and updating. Finally, remote sensing image super-resolution reconstruction is performed in sparse representation. Experiment results show that the proposed method can reduce the size of the dictionary adaptively, and can reconstruct the higher quality super-resolution image with the smaller sparse dictionary. The remote sensing image SRR result contains more texture details, and peak signal-to-noise ratio and structural SIMilarity are increased objectively. © 2019, Editorial Office of Systems Engineering and Electronics. All right reserved.","Image enhancement; Image reconstruction; Optical resolving power; Sampling; Signal to noise ratio; Space optics; Textures; Beta process; Dictionary learning; Image super-resolution reconstruction; Low resolution images; Peak signal to noise ratio; Remote sensing images; Sparse representation; Super resolution; Remote sensing","Beta process; Dictionary learning; Remote sensing; Super-resolution","Article","Final","","Scopus","2-s2.0-85075421869"
"DIan R.; Li S.","DIan, Renwei (57192573953); Li, Shutao (7409240361)","57192573953; 7409240361","Hyperspectral and Multispectral Image Fusion Based on Spectral Low Rank and Non-Local Spatial Similarities","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8899108","3137","3140","3","10.1109/IGARSS.2019.8899108","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077717232&doi=10.1109%2fIGARSS.2019.8899108&partnerID=40&md5=725470c0728ca50898c23b5f5074de52","Fusing a hyperspectral image (HSI) with a multispectral image (MSI) of the same scene has become a popular way to increase the spatial resolution of HSI. In this paper, we propose a novel HSI and MSI fusion method (termed as the SSS), which is based on spectral low rank and non-local spatial similarities. Firstly, to exploit the high spectral correlations of the desired high spatial resolution HSI, we formulate the fusion problem as the estimation of low-dimensional spectral subspace and coefficients. since the HSI preserves most of spectral information, the spectral subspace is estimated from HSI via singular value decomposition. With the spectral subspace known, we plug a state-of-the-art denoising algorithm, weighted nuclear norm minimization, into the alternating direction method of multipliers to estimate the coefficients, which can effectively promote the non-local similarities of desired high spatial resolution HSI. Experiments demonstrate that our method is competitive to the state-of-the-art approaches. © 2019 IEEE.","Geology; Image fusion; Image resolution; Singular value decomposition; Spectroscopy; Superpixels; Alternating direction method of multipliers; High spatial resolution; HyperSpectral; low rank; Multi-spectral image fusions; Non-local similarities; Nuclear norm minimizations; State-of-the-art approach; Remote sensing","Hyperspectral image super-resolution; low rank; superpixels","Conference paper","Final","","Scopus","2-s2.0-85077717232"
"Hu J.; Zhao M.; Li Y.","Hu, Jing (57191473546); Zhao, Minghua (55477788900); Li, Yunsong (55986546100)","57191473546; 55477788900; 55986546100","Erratum: Correction: Hyperspectral image super-resolution by deep spatial-spectral exploitation. [Remote Sensing., 11, (2019) (1229)] DOI: 10.3390/rs11101229","2019","Remote Sensing","11","24","2933","","","","10.3390/rs11242933","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077853868&doi=10.3390%2frs11242933&partnerID=40&md5=7fe26638de6722ca83e7954badbf1f12","The authors wish to make the following corrections to this paper [1]: The information for Affiliation 1 should be the School of Computer Science and Technology, Xi'an University of Technology, Xi'an 710048, China in instead of School of Computer Science, Xi'an University of Architecture and Technology, Xi'an 710048, China. © 2019 by the authors.","","","Erratum","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85077853868"
"Wang P.; Zhang G.; Leung H.","Wang, Peng (57189493188); Zhang, Gong (35241577600); Leung, Henry (7202811506)","57189493188; 35241577600; 7202811506","Improving Super-Resolution Flood Inundation Mapping for Multispectral Remote Sensing Image by Supplying More Spectral Information","2019","IEEE Geoscience and Remote Sensing Letters","16","5","8565995","771","775","4","10.1109/LGRS.2018.2882516","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058118280&doi=10.1109%2fLGRS.2018.2882516&partnerID=40&md5=45665fa0cad569cc6d0de38b92f396c9","Super-resolution mapping is an effective technique in mapping flood inundation for multispectral remote sensing image. However, the traditional super-resolution flood inundation mapping (SRFIM) is unable to fully utilize the spectral information from multispectral remote sensing image band. In order to resolve this problem, a novel SRFIM by supplying more spectral information (SRFIM-MSI) is proposed to improve mapping accuracy. In the proposed SRFIM-MSI, the spectral information from the multispectral band is calculated by the normalized difference water index (NDWI). A spectral term constituted by NDWI is added into the traditional SRFIM. The proposed method is evaluated by using two Landsat 8 OLI multispectral data from the study area in Cambodia. The obtained results demonstrate that the proposed SRFIM-MSI produces better results than the traditional SRFIM methods. © 2004-2012 IEEE.","Flood control; Floods; Image enhancement; Optical resolving power; Photomapping; Flood inundation mappings; Mapping accuracy; Multi-spectral data; Multispectral remote sensing image; Normalized difference water index; Spectral information; Super resolution; Super-resolution mappings; data assimilation; flooding; image resolution; Landsat; mapping method; multispectral image; remote sensing; Remote sensing","Multispectral remote sensing image; spectral information; super-resolution flood inundation mapping (SRFIM); super-resolution mapping (SRM)","Article","Final","","Scopus","2-s2.0-85058118280"
"Dou X.; Li C.; Shi Q.; Liu M.","Dou, Xinyu (57216671300); Li, Chenyu (57216672432); Shi, Qian (55286447700); Liu, Mengxi (57208160778)","57216671300; 57216672432; 55286447700; 57208160778","Super-resolution for hyperspectral remote sensing images based on the 3D Attention-SRGAN Network","2020","Remote Sensing","12","7","1204","","","","10.3390/rs12071204","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084251625&doi=10.3390%2frs12071204&partnerID=40&md5=371b3af26f6fab6f3ac50bce7b220ac9","Hyperspectral remote sensing images (HSIs) have a higher spectral resolution compared to multispectral remote sensing images, providing the possibility for more reasonable and effective analysis and processing of spectral data. However, rich spectral information usually comes at the expense of low spatial resolution owing to the physical limitations of sensors, which brings difficulties for identifying and analyzing targets in HSIs. In the super-resolution (SR) field, many methods have been focusing on the restoration of the spatial information while ignoring the spectral aspect. To better restore the spectral information in the HSI SR field, a novel super-resolution (SR) method was proposed in this study. Firstly, we innovatively used three-dimensional (3D) convolution based on SRGAN (Super-Resolution Generative Adversarial Network) structure to not only exploit the spatial features but also preserve spectral properties in the process of SR. Moreover, we used the attention mechanism to deal with the multiply features from the 3D convolution layers, and we enhanced the output of our model by improving the content of the generator's loss function. The experimental results indicate that the 3DASRGAN (3D Attention-based Super-Resolution Generative Adversarial Network) is both visually quantitatively better than the comparison methods, which proves that the 3DASRGAN model can reconstruct high-resolution HSIs with high efficiency. © 2020, by the authors.","Convolution; Data handling; Optical resolving power; Restoration; Three dimensional computer graphics; Adversarial networks; Attention mechanisms; Hyperspectral Remote Sensing Image; Multispectral remote sensing image; Physical limitations; Spatial informations; Spectral information; Three-dimensional (3D) convolution; Remote sensing","3D convolution; Generative adversarial networks; Hyperspectral image; Spectral angle; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85084251625"
"Zhang J.; Shamsolmoali P.; Zhang P.; Feng D.; Yang J.","Zhang, Junhao (56368684700); Shamsolmoali, Pourya (56350053200); Zhang, Pengpeng (56104492700); Feng, Deying (35219755900); Yang, Jie (15039078800)","56368684700; 56350053200; 56104492700; 35219755900; 15039078800","Multispectral image fusion using super-resolution conditional generative adversarial networks","2019","Journal of Applied Remote Sensing","13","2","022002","","","","10.1117/1.JRS.13.022002","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055792733&doi=10.1117%2f1.JRS.13.022002&partnerID=40&md5=88db0212e3ac0f09a92f60ac8917e082","In multispectral image fusion scenarios, deep learning has been widely applied. However, the fusion performance and image quality are still restricted by inflexible architecture and supervised learning mode. We proposed multispectral image fusion using super-resolution conditional generative adversarial networks (MS-cGANs) based on conditional cGANs, which produces the fused image through the flexible encode-and-decode procedure. In the proposed network, a least square model is extended to solve the gradients vanishing problem in cGANs. Then, to improve the fusion quality, the multiscale features are used to preserve the details. Furthermore, the image resolution is promoted by adding the perceptual loss in object function and injecting the super-resolution structure into a deconvolution procedure. In experimental results, MS-cGANs demonstrates a significant performance in fusing multispectral images and top-ranking image quality compared with the state-of-the-art methods. © 2018 Society of Photo-Optical Instrumentation Engineers (SPIE).","Deep learning; Fusion reactions; Image quality; Image resolution; Least squares approximations; Optical resolving power; Remote sensing; Adversarial networks; Fusion performance; Least square model; Multi-scale features; Multi-spectral image fusions; Multispectral images; State-of-the-art methods; Super resolution; Image fusion","fusion; multispectral image; multispectral-conditional generative adversarial network; remote sensing","Article","Final","","Scopus","2-s2.0-85055792733"
"Salgueiro Romero L.; Marcello J.; Vilaplana V.","Salgueiro Romero, Luis (57215564555); Marcello, Javier (6602158797); Vilaplana, Verónica (23394280500)","57215564555; 6602158797; 23394280500","Comparative study of upsampling methods for super-resolution in remote sensing","2020","Proceedings of SPIE - The International Society for Optical Engineering","11433","","114331J","","","","10.1117/12.2557357","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081169799&doi=10.1117%2f12.2557357&partnerID=40&md5=8ff4f0f2a02be012676eeca0af477bcd","Many remote sensing applications require high spatial resolution images, but the elevated cost of these images makes some studies unfeasible. Single-image super-resolution algorithms can improve the spatial resolution of a lowresolution image by recovering feature details learned from pairs of low-high resolution images. In this work, several configurations of ESRGAN, a state-of-the-art algorithm for image super-resolution, are tested. We make a comparison between several scenarios, with different modes of upsampling and channels involved. The best results are obtained training a model with RGB-IR channels and using progressive upsampling. © 2020 SPIE.","Computer vision; Deep learning; Image enhancement; Image resolution; Optical resolving power; Signal sampling; Comparative studies; High spatial resolution images; Image super resolutions; Low resolution images; Remote sensing applications; State-of-the-art algorithms; Super resolution; Worldview-2; Remote sensing","Deep Learning; Remote Sensing; Super-resolution; WorldView-2","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85081169799"
"Märtens M.; Izzo D.; Krzic A.; Cox D.","Märtens, Marcus (36938152500); Izzo, Dario (16021918800); Krzic, Andrej (57199644951); Cox, Daniël (57215652608)","36938152500; 16021918800; 57199644951; 57215652608","Super-resolution of PROBA-V images using convolutional neural networks","2019","Astrodynamics","3","4","","387","402","15","10.1007/s42064-019-0059-8","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081573720&doi=10.1007%2fs42064-019-0059-8&partnerID=40&md5=d7e98b1dab609f8e07ea71566a986583","European Space Aqency (ESA)’s PROBA-V Earth observation (EO) satellite enables us to monitor our planet at a large scale to study the interaction between vegetation and climate, and provides guidance for important decisions on our common global future. However, the interval at which high-resolution images are recorded spans over several days, in contrast to the availability of lower-resolution images which is often daily. We collect an extensive dataset of both high- and low-resolution images taken by PROBA-V instruments during monthly periods to investigate Multi Image Super-resolution, a technique to merge several low-resolution images into one image of higher quality. We propose a convolutional neural network (CNN) that is able to cope with changes in illumination, cloud coverage, and landscape features which are introduced by the fact that the different images are taken over successive satellite passages at the same region. Given a bicubic upscaling of low resolution images taken under optimal conditions, we find the Peak Signal to Noise Ratio of the reconstructed image of the network to be higher for a large majority of different scenes. This shows that applied machine learning has the potential to enhance large amounts of previously collected EO data during multiple satellite passes. © 2019, Tsinghua University Press.","Convolution; Deep learning; Earth (planet); Neural networks; Optical resolving power; Remote sensing; Satellites; Signal to noise ratio; Convolutional neural network; Deep learning; Earth observation; Earth observation satellites; Earth observations; Low resolution images; Remote-sensing; Super resolution imaging; Superresolution; Observatories","convolutional neural network (CNN); deep learning; Earth observation (EO); remote sensing; super-resolution imaging","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85081573720"
"Ma J.; Wang X.; Li F.; Yang X.","Ma, Jun (55873621900); Wang, Xiaoyong (55349792000); Li, Feng (57171116800); Yang, Xue (57204629969)","55873621900; 55349792000; 57171116800; 57204629969","An OpenMP-Based Algorithm for Multi-Nodes Computational of Super-Resolution","2019","Journal of Physics: Conference Series","1395","1","012002","","","","10.1088/1742-6596/1395/1/012002","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076708653&doi=10.1088%2f1742-6596%2f1395%2f1%2f012002&partnerID=40&md5=832b5934e906cab94c0e2a20730a30d7","A new common OpenMP based parallel programming method MPMC (multi-node paralleling model base on multiprocessor devices) is proposed and implemented for data separation based to accelerate Super-Resolution (SR) task. PanguOS, a common parallel programming system designed with MPMC, is deployed with Secure Shell (SSH) to control devices and Secure Copy (SCP) to transmit the data stream on Ubuntu 16.04, and it has a good performance for SR task with remote sensing images. Experiments with images from geostationary-orbit earth observing satellite GaoFen(GF)-4, the method proposed can achieve almost 2.95 times acceleration at PanguOS, deployed with 3 Jetson TX2s, than a single Jetson TX2. © Published under licence by IOP Publishing Ltd.","Application programming interfaces (API); Artificial intelligence; Geostationary satellites; Orbits; Parallel programming; Remote sensing; Control device; Data separation; Earth observing satellite; Geo-stationary orbits; Multiprocessor devices; Remote sensing images; Secure shell; Super resolution; Optical resolving power","","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85076708653"
"Lijing T.; Wenju W.; Sicheng G.; Taotao W.; Xiting L.","Lijing, Tang (57217908347); Wenju, Wang (37078138200); Sicheng, Gu (57219354176); Taotao, Wei (57219363971); Xiting, Liao (57219358777)","57217908347; 37078138200; 57219354176; 57219363971; 57219358777","Hyperspectral images reconstruction based on the 3D fast super-resolution convolutional neural networks","2020","WCSE 2020: 2020 10th International Workshop on Computer Science and Engineering","","","","226","232","6","10.18178/wcse.2020.06.035","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092352780&doi=10.18178%2fwcse.2020.06.035&partnerID=40&md5=eac3f1cf3c97568471c4345263bf9ec0","Hyperspectral images are widely used with the development of remote sensing technology, but its low spatial resolution greatly limits the application of hyperspectral images. Therefore, we proposed a hyperspectral image super-resolution reconstruction algorithm based on 3d FSRCNN framework model, which preprocessed the hyperspectral image data set successively, extracted features, reduced dimensions, nonlinear mapping, expanded dimensions, and deconvolution to finally realize image super-resolution reconstruction. In this algorithm, three-dimensional convolution is used to convolve both spatial dimension and spectral dimension to capture spatial spectrum characteristics. The whole convolutional network consists of 6 layers, one input layer, four convolutional layers, and one deconvolution layer. For the first five layers of convolution, PReLU was used as the activation function, which effectively prevented the phenomenon of nerve necrosis and improved the model fitting without increasing the computational cost and overfitting risk. Experimental results show that the proposed algorithm can reconstruct high spatial resolution images with less computation and reduce spectral distortion effectively. © WCSE 2020.","Cell death; Convolution; Convolutional neural networks; Deconvolution; Image resolution; Optical resolving power; Remote sensing; Spectroscopy; Three dimensional computer graphics; Activation functions; Convolutional networks; High spatial resolution images; Hyperspectral image datas; Image super-resolution reconstruction; Images reconstruction; Remote sensing technology; Spectral distortions; Image reconstruction","Convolutional Neural Network(CNN); Hyperspectral Images; Super Resolution","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85092352780"
"Fromm M.; Berrendorf M.; Faerman E.; Chen Y.; Schuss B.; Schubert M.","Fromm, Michael (57211622195); Berrendorf, Max (57207581580); Faerman, Evgeniy (57195494418); Chen, Yiyi (57219528921); Schuss, Balthasar (57214470437); Schubert, Matthias (55605776884)","57211622195; 57207581580; 57195494418; 57219528921; 57214470437; 55605776884","XD-STOD: Cross-domain superresolution for tiny object detection","2019","IEEE International Conference on Data Mining Workshops, ICDMW","2019-November","","8955582","142","148","6","10.1109/ICDMW.2019.00031","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078758026&doi=10.1109%2fICDMW.2019.00031&partnerID=40&md5=ca59fc4a89057a40a4e0d2c88d579f79","Monitoring the restoration of natural habitats after human intervention is an important task in the field of remote sensing. Currently, this requires extensive field studies entailing considerable costs. Unmanned Aerial vehicles (UAVs, a.k.a. drones) have the potential to reduce these costs, but generate immense amounts of data which have to be evaluated automatically with special techniques. Especially the automated detection of tree seedlings poses a big challenge, as their size and shape vary greatly across images. In addition, there is a tradeoff between different flying altitudes. Given the same camera equipment, a lower flying altitude achieves higher resolution images and thus, achieving high detection rates is easier. However, the imagery will only cover a limited area. On the other hand, flying at larger altitudes, allows for covering larger areas, but makes seedling detection more challenging due to the coarser images. In this paper we investigate the usability of super resolution (SR) networks for the case that we can collect a large amount of coarse imagery on higher flying altitudes, but only a small amount of high resolution images from lower flying altitudes. We use a collection of high-resolution images taken by a drone at 5m altitude. After training the SR models on these data, we evaluate their applicability to low quality images taken at 30m altitude (in-domain). In addition, we investigate and compare whether approaches trained on a highly diverse large data sets can be transferred to these data (cross-domain). We also evaluate the usability of the SR results based on their influence on the detection rate of different object detectors. We found that the features acquired from training on standard SR data sets are transferable to the drone footage. Furthermore, we demonstrate that the detection rate of common object detectors can be improved by SR techniques using both settings, in-domain and cross-domain. © 2019 IEEE.","Aircraft detection; Antennas; Data mining; Drones; Object recognition; Optical resolving power; Quality control; Remote sensing; Automated detection; Coniferous seedlings; High detection rate; High resolution image; Higher resolution images; Human intervention; Object detectors; Super resolution; Object detection","Coniferous seedlings; Drone imagery; Object detection; Remote-sensing; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85078758026"
"Yang J.; Ren C.; Zhou X.; He X.; Wang Z.","Yang, Jie (57069213800); Ren, Chao (57207076112); Zhou, Xin (57226235471); He, Xiaohai (9237988800); Wang, Zhengyong (55850352300)","57069213800; 57207076112; 57226235471; 9237988800; 55850352300","Super-resolution for remote sensing images via dual-domain network learning","2019","Journal of Electronic Imaging","28","6","063001","","","","10.1117/1.JEI.28.6.063001","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078489939&doi=10.1117%2f1.JEI.28.6.063001&partnerID=40&md5=e0156631400539504f859d7f0e3aec65","Super-resolution (SR), which aims at recovering a high-resolution (HR) image from single or sequential low-resolution (LR) images, is a widely used technology in image processing. In the field of image SR, convolutional neural networks (CNNs) have attracted increasing attention because of their high-quality performance. However, most CNN-based methods treat each channel-wise feature equally, which lacks discriminative learning ability across feature channels. Furthermore, many methods neglect to fully use information of each convolutional layer. To resolve these problems, we propose a remote sensing image SR method named dense channel attention network (DCAN). In our DCAN, a sequence of residual dense channel attention blocks (RDCABs) is cascaded with a densely connected structure. In each RDCAB, we make full use of the information from all convolution layers via densely connected convolutional layers. In addition, RDCABs utilize the channel attention mechanism to adaptively recalibrate channel-wise feature responses by explicitly modeling the interdependencies between the channels. In addition, our DCAN can make full use of the hierarchical features by densely connecting each RDCAB. Finally, to further improve the SR performance, the proposed DCAN is learned in both the pixel and wavelet domains, and a fusion layer is used to fuse the outputs of these two domains. Extensive quantitative and qualitative evaluations verify the superiority of our proposed method over several state-of-the-art methods. © 2019 SPIE and IS&T.","Convolution; Image processing; Information use; Neural networks; Optical resolving power; Attention mechanisms; Convolutional neural network; dense connection; Dual domain; Remote sensing images; Super resolution; Remote sensing","channel attention mechanism; convolutional neural networks; dense connection; dual-domain learning; remote sensing image; super resolution","Article","Final","","Scopus","2-s2.0-85078489939"
"Wagner L.; Liebel L.; Körner M.","Wagner, L. (57203101042); Liebel, L. (56938680000); Körner, M. (57190168095)","57203101042; 56938680000; 57190168095","DEEP RESIDUAL LEARNING for SINGLE-IMAGE SUPER-RESOLUTION of MULTI-SPECTRAL SATELLITE IMAGERY","2019","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","4","2/W7","","189","196","7","10.5194/isprs-annals-IV-2-W7-189-2019","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084643909&doi=10.5194%2fisprs-annals-IV-2-W7-189-2019&partnerID=40&md5=2a603b108ce7e232383eeb2009482bf8","Analyzing optical remote sensing imagery depends heavily on their spatial resolution. At the same time, this data is adversely affected by fixed sensor parameters and environmental influences. Methods for increasing the quality of such data and concomitantly optimizing its information content are, thus, in high demand. In particular, single-image super-resolution (SISR) approaches aim to achieve this goal solely by observing the individual images. We propose to adapt a generic deep residual neural network architecture for SISR to deal with the special properties of remote sensing satellite imagery, especially taking into account the different spatial resolutions of individual Sentinel-2 bands, i.e., ground sampling distances of 20 m and 10 m. As a result, this method is able to increase the perceived resolution of the 20 m channels and mesh all spectral bands. Experimental evaluation and ablation studies on large datasets have shown superior performance compared to the state-of-the-art and that the model is not bound by its capacity. © 2019 ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences. All rights reserved.","Image analysis; Large dataset; Network architecture; Optical resolving power; Remote sensing; Satellite imagery; Environmental influences; Experimental evaluation; Ground sampling distances; Information contents; Optical remote-sensing imagery; Remote sensing satellites; Spatial resolution; Special properties; Deep learning","Convolutional Neural Networks; Deep Learning; Remote Sensing; Residual Learning; Sentinel-2; Single-Image Super-Resolution","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85084643909"
"Xie W.; Jia X.; Li Y.; Lei J.","Xie, Weiying (56768656200); Jia, Xiuping (7201933692); Li, Yunsong (55986546100); Lei, Jie (36663710700)","56768656200; 7201933692; 55986546100; 36663710700","Hyperspectral Image Super-Resolution Using Deep Feature Matrix Factorization","2019","IEEE Transactions on Geoscience and Remote Sensing","57","8","8678710","6055","6067","12","10.1109/TGRS.2019.2904108","42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069787865&doi=10.1109%2fTGRS.2019.2904108&partnerID=40&md5=1fb9dfe96a46f04bf503a88bd83b3721","Hyperspectral images (HSIs) can describe the subtle differences in the spectral signatures of materials. However, they have low spatial resolution due to various hardware limitations. Improving it via postprocess without an auxiliary high-resolution (HR) image still remains a challenging problem. In this paper, we address this problem and propose a new HSI super-resolution (SR) method. Our approach, called deep feature matrix factorization (DFMF), blends feature matrix extracted by a deep neural network (DNN) with nonnegative matrix factorization strategy for super-resolving real-scene HSI. The estimation of the HR HSI is formulated as a combination of latent spatial feature matrix and spectral feature matrix. In the DFMF model, the input low-resolution (LR) HSI is first partitioned into several subsets according to the correlation matrix, and the key band is selected from each subset. Then, the key band group is super-resolved by a DNN model, and the HR key band group is then used as a guide to carry out deep spatial feature matrix. Specifically, the input LR HSI with prototype reflectance spectral vectors of the scene will be preserved when super-resolving in a spatial domain. Thus, the nonnegative spectral and spatial feature matrices are extracted simultaneously from alternately factorizing the pair of LR HSI and the HR key band group. Finally, the HR HSI is obtained by the integration of the spectral and spatial feature matrices. Experiments have been conducted on real-scene remote sensing HSI. Comparative analyses validate that the proposed DFMF method presents a superior super-resolving performance, as it preserves spectral information better. © 1980-2012 IEEE.","Deep neural networks; Factorization; Image enhancement; Optical resolving power; Remote sensing; Spectroscopy; Band selection; Comparative analysis; High resolution image; Image super resolutions; Matrix factorizations; Nonnegative matrix factorization; Spectral information; Super resolution; algorithm; artificial neural network; hardware; matrix; numerical model; remote sensing; satellite imagery; spatial resolution; spectral reflectance; Matrix algebra","Band selection; deep neural network (DNN); hyperspectral image (HSI); matrix factorization; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85069787865"
"Theran C.A.; Alvarez M.A.; Arzuaga E.; Sierra H.","Theran, Carlos A. (57213160596); Alvarez, Michael A. (57213140223); Arzuaga, Emmanuel (35781502400); Sierra, Heidy (24071959900)","57213160596; 57213140223; 35781502400; 24071959900","A Pixel Level Scaled Fusion Model to Provide High Spatial-Spectral Resolution for Satellite Images Using LSTM Networks","2019","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2019-September","","8921269","","","","10.1109/WHISPERS.2019.8921269","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077559994&doi=10.1109%2fWHISPERS.2019.8921269&partnerID=40&md5=05be7266faee713984b84933674ee973","Pixel-level fusion of satellite images coming from multiple sensors allows for an improvement in the quality of the acquired data both spatially and spectrally. In particular, multispectral and hyperspectral images have been fused to generate images with a high spatial and spectral resolution. In literature, there are several approaches for this task, nonetheless, those techniques still present a loss of relevant spatial information during the fusion process. This work presents a multi scale deep learning model to fuse multispectral and hyperspectral data, each with high-spatial-and-low-spectral resolution (HSaLS) and low-spatial-and-high-spectral resolution (LSaHS) respectively. As a result of the fusion scheme, a high-spatial-and-spectral resolution image (HSaHS) can be obtained. In order of accomplishing this result, we have developed a new scalable high spatial resolution process in which the model learns how to transition from low spatial resolution to an intermediate spatial resolution level and finally to the high spatial-spectral resolution image. This step-by-step process reduces significantly the loss of spatial information. The results of our approach show better performance in terms of both the structural similarity index and the signal to noise ratio. © 2019 IEEE.","Data fusion; Deep learning; Hyperspectral imaging; Image enhancement; Image fusion; Image resolution; Pixels; Remote sensing; Signal to noise ratio; Spectral resolution; Spectroscopy; High spatial resolution; High spectral resolution; Multispectral images; Pixel level; Spatial informations; Spatial resolution; Structural similarity indices; Super resolution; Long short-term memory","Data Fusion; hyperspectral image; Long Short Term Memory; multispectral image; Pixel level; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85077559994"
"Shin C.; Kim M.; Kim S.; Kim Y.","Shin, Changyeop (57214067386); Kim, Minbeom (57214075133); Kim, Sungho (57214086723); Kim, Youngjung (57207442949)","57214067386; 57214075133; 57214086723; 57207442949","Stacked lossless deconvolutional network for remote sensing image restoration","2020","Journal of Applied Remote Sensing","14","1","016511","","","","10.1117/1.JRS.14.016511","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083040459&doi=10.1117%2f1.JRS.14.016511&partnerID=40&md5=9e661103ccc60fc0dacfe3177c8e4b6e","Satellite image restoration from its degraded observation has a significant impact on the remote sensing industry. There are many potential applications that can directly benefit from this technique. A convolutional neural network (CNN) has been recently explored in image restoration and achieved remarkable performance. However, most deep CNN architectures in the literature do not properly handle the inherent trade-off between localization accuracy and the use of global context, which is vital for satellite images covering a ultrabroad area. We present a stacked lossless deconvolutional network (SLDN) for remote sensing image restoration. We fully exploit global context information while guaranteeing the recovery of fine details. Specifically, we design a lossless pooling by reformulating the pixel shuffle operator and incorporate it with a shallow deconvolutional network. The resulting lossless deconvolution blocks are stacked one by one to enlarge the receptive fields without any information loss. We further propose an attentive skip connection and progressive learning scheme to improve gradient flows throughout the SLDN. The SLDN can reconstruct high-quality satellite images without noticeable artifacts. An extensive ablation study is also provided to show that all the components proposed are useful for remote sensing image restoration. Experimental comparisons on various restoration tasks, including super-resolution, denoising, and compression artifact reduction, demonstrate the superiority of the proposed method over state-of-the-art methods both qualitatively and quantitatively. © 2020 Society of Photo-Optical Instrumentation Engineers (SPIE).","Convolutional neural networks; Economic and social effects; Remote sensing; Restoration; Satellites; Compression artifacts; Experimental comparison; Localization accuracy; Progressive learning; Receptive fields; Remote sensing images; Satellite images; State-of-the-art methods; Image reconstruction","compression artifact reduction; convolutional neural networks; denoising; image restoration; remote sensing; satellite imagery; super-resolution","Article","Final","","Scopus","2-s2.0-85083040459"
"Wang H.; Hu Q.; Wu C.; Chi J.; Yu X.","Wang, Huan (57208732586); Hu, Qian (57204765704); Wu, Chengdong (57208469667); Chi, Jianning (40761307100); Yu, Xiaosheng (36802973400)","57208732586; 57204765704; 57208469667; 40761307100; 36802973400","Non-locally up-down convolutional attention network for remote sensing image super-resolution","2020","IEEE Access","8","","","166304","166319","15","10.1109/ACCESS.2020.3022882","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100328257&doi=10.1109%2fACCESS.2020.3022882&partnerID=40&md5=3d1572cd8ae89dd4726dba6393622959","Recently, single image super-resolution (SISR) has been widely applied in the field of remote sensing image processing and obtained remarkable performance. However, existing CNN-based remote sens-ing image super-resolution methods are unable to exploit shallow visual characteristics at global receptive fields, which results in the limited perceptual capability of these models. Furthermore, the low-resolution inputs and features contain abundant low-frequency information, which are weighed in channels and space equally, hence limiting the representational ability of CNNs. To solve these problems, we propose a non-locally up-down convolutional attention network (NLASR) for remote sensing image super-resolution. First, a non-local features enhancement module (NLEB) is constructed to obtain the spatial context information of high-dimensional feature maps, which allows our network to utilize global information to enhance low-level similar structured texture information with effect, overcoming the defects of deficiency perceptual ability of shallow convolutional layers. Second, an enhanced up-sampling channel-wise attention (EUCA) module and enhanced down-sampling spatial-wise attention (EDSA) module are proposed to weight the features at multiple scales. By integrating the channel-wise and multi-scale spatial information, the attention modules are able to compute the response values from the multi-scale regions of each neuron and then establish the accurate mapping from low to high resolution space. Extensive experiments on NWPU-RESISC45 and UCMerced-LandUse datasets show that the proposed method can provide state-of-the-art or even better performance in both quantitative and qualitative measurements. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Convolution; Convolutional neural networks; Image processing; Optical resolving power; Scales (weighing instruments); Signal receivers; Signal sampling; Space optics; Textures; Global informations; High dimensional feature; Image super resolutions; Qualitative measurements; Remote sensing image processing; Remote sensing images; Spatial informations; Texture information; Remote sensing","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85100328257"
"Hu J.; Li Y.; Zhao M.; Zhang Y.","Hu, Jing (57191473546); Li, Yunsong (55986546100); Zhao, Minghua (55477788900); Zhang, Yaling (57213196171)","57191473546; 55986546100; 55477788900; 57213196171","Deep Spatial-Spectral Information Exploitation for Rapid Hyperspectral Image Super-Resolution","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8899111","3109","3112","3","10.1109/IGARSS.2019.8899111","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077702771&doi=10.1109%2fIGARSS.2019.8899111&partnerID=40&md5=9bd03a255a976c7fcd65de6b177a109d","limited by existing electromagnetic sensors, the hyperspectral image (HSI) is characterized by having a high spectral resolution but a low spatial resolution. The super-resolution (SR) technique, which aims at enhancing the spatial resolution of the input image, is a hot topic in computer vision. This paper presents a rapid HSI SR method based on a deep information distillation network (IDN) and an intra-fusion operation to fully utilize the spatial-spectral information. Specifically, some bands are firstly selected and super-resolved by utilizing their spatial information through IDN. Non-selected bands are super-resolved by spectral interpolation. Moreover, to take a full advantage of the information these non-selected bands conveys, intra-fusion is operated on the input HSI and the spectrally-interpolated high resolution HSI. Contrary to most existed fusion methods which require multiple observations of the same scene, this intra-fusion is more flexible, and makes further utilization of the information the input HSI conveys simultaneously. In addition, this method requires less computation and is more suitable for practical applications. Experimental data and comparative analysis have demonstrated the effectiveness this method. © 2019 IEEE.","Distillation; Geology; Hyperspectral imaging; Image enhancement; Image resolution; Spectral resolution; Spectroscopy; Comparative analysis; deep spatial-spectral exploitation; Electromagnetic sensors; High spectral resolution; Image super resolutions; Spectral information; Spectral interpolation; Super resolution; Remote sensing","deep spatial-spectral exploitation; hyperspectral image; intra-fusion; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85077702771"
"","","","3rd Chinese Conference on Pattern Recognition and Computer Vision, PRCV 2020","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12306 LNCS","","","","","1936","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093915021&partnerID=40&md5=14f9746d33306c82579ffc98fa15ec17","The proceedings contain 158 papers. The special focus in this conference is on Pattern Recognition and Computer Vision. The topics include: Underwater Image Processing by an Adversarial Network with Feedback Control; inception Parallel Attention Network for Small Object Detection in Remote Sensing Images; hyperspectral Image Denoising Based on Graph-Structured Low Rank and Non-local Constraint; multi-human Parsing with Pose and Boundary Guidance; m2E-Net: Multiscale Morphological Enhancement Network for Retinal Vessel Segmentation; DUDA: Deep Unsupervised Domain Adaptation Learning for Multi-sequence Cardiac MR Image Segmentation; learning from Rankings with Multi-level Features for No-Reference Image Quality Assessment; reversible Data Hiding Based on Prediction-Error-Ordering; aggregating Spatio-temporal Context for Video Object Segmentation; Position and Orientation Detection of Insulators in Arbitrary Direction Based on YOLOv3; R-PFN: Towards Precise Object Detection by Recurrent Pyramidal Feature Fusion; image Super-Resolution Based on Non-local Convolutional Neural Network; VH3D-LSFM: Video-Based Human 3D Pose Estimation with Long-Term and Short-Term Pose Fusion Mechanism; automatic Tooth Segmentation and 3D Reconstruction from Panoramic and Lateral Radiographs; unregistered Hyperspectral and Multispectral Image Fusion with Synchronous Nonnegative Matrix Factorization; Cloud Detection Algorithm Using Advanced Fully Convolutional Neural Networks in FY3D-MERSI Imagery; multi-layer Pointpillars: Multi-layer Feature Abstraction for Object Detection from Point Cloud; building Detection via Complementary Convolutional Features of Remote Sensing Images; hyperspectral Image Super-Resolution via Self-projected Smooth Prior; 3D Point Cloud Segmentation for Complex Structure Based on PointSIFT; completely Blind Image Quality Assessment with Visual Saliency Modulated Multi-feature Collaboration; blood Flow Velocity Detection of Nailfold Microcirculation Based on Spatiotemporal Analysis; blind Super-Resolution with Kernel-Aware Feature Refinement; preface.","","","Conference review","Final","","Scopus","2-s2.0-85093915021"
"Zheng Y.; Song H.; Sun L.; Wu Z.; Jeon B.","Zheng, Yuhui (55576235500); Song, Huihui (36572623600); Sun, Le (55493054300); Wu, Zebin (20437030300); Jeon, Byeungwoo (15136434400)","55576235500; 36572623600; 55493054300; 20437030300; 15136434400","Spatiotemporal fusion of satellite images via very deep convolutional networks","2019","Remote Sensing","11","22","2701","","","","10.3390/rs11222701","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075368174&doi=10.3390%2frs11222701&partnerID=40&md5=1dbf516ad6ac004176a337ac570fab25","Spatiotemporal fusion provides an effective way to fuse two types of remote sensing data featured by complementary spatial and temporal properties (typical representatives are Landsat and MODIS images) to generate fused data with both high spatial and temporal resolutions. This paper presents a very deep convolutional neural network (VDCN) based spatiotemporal fusion approach to effectively handle massive remote sensing data in practical applications. Compared with existing shallow learning methods, especially for the sparse representation based ones, the proposed VDCN-based model has the following merits: (1) explicitly correlating the MODIS and Landsat images by learning a non-linear mapping relationship; (2) automatically extracting effective image features; and (3) unifying the feature extraction, non-linear mapping, and image reconstruction into one optimization framework. In the training stage, we train a non-linear mapping between downsampled Landsat and MODIS data using VDCN, and then we train a multi-scale super-resolution (MSSR) VDCN between the original Landsat and downsampled Landsat data. The prediction procedure contains three layers, where each layer consists of a VDCN-based prediction and a fusion model. These layers achieve non-linear mapping from MODIS to downsampled Landsat data, the two-times SR of downsampled Landsat data, and the five-times SR of downsampled Landsat data, successively. Extensive evaluations are executed on two groups of commonly used Landsat-MODIS benchmark datasets. For the fusion results, the quantitative evaluations on all prediction dates and the visual effect on one key date demonstrate that the proposed approach achieves more accurate fusion results than sparse representation based methods. © 2019 by the authors.","Convolution; Deep neural networks; Forecasting; Image reconstruction; Mapping; Neural networks; Radiometers; Remote sensing; Convolutional networks; Convolutional neural network; Massive remote sensing datum; Nonlinear mappings; Optimization framework; Quantitative evaluation; Spatial and temporal resolutions; Spatio-temporal fusions; Image fusion","Non-linear mapping; Spatiotemporal fusion; Very deep convolutional neural network","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85075368174"
"Rifat Arefin M.; Michalski V.; St-Charles P.-L.; Kalaitzis A.; Kim S.; Kahou S.E.; Bengio Y.","Rifat Arefin, Md (57220427961); Michalski, Vincent (56736842300); St-Charles, Pierre-Luc (56071662500); Kalaitzis, Alfredo (39961644200); Kim, Sookyung (57201251082); Kahou, Samira E. (36600560600); Bengio, Yoshua (7003958245)","57220427961; 56736842300; 56071662500; 39961644200; 57201251082; 36600560600; 7003958245","Multi-image super-resolution for remote sensing using deep recurrent networks","2020","IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops","2020-June","","9150720","816","825","9","10.1109/CVPRW50498.2020.00111","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090117733&doi=10.1109%2fCVPRW50498.2020.00111&partnerID=40&md5=d84906730aa63b6c2338bd261ee32efe","High-resolution satellite imagery is critical for various earth observation applications related to environment monitoring, geoscience, forecasting, and land use analysis. However, the acquisition cost of such high-quality imagery due to the scarcity of providers and needs for high-frequency revisits restricts its accessibility in many fields. In this work, we present a data-driven, multi-image super resolution approach to alleviate these problems. Our approach is based on an end-to-end deep neural network that consists of an encoder, a fusion module, and a decoder. The encoder extracts co-registered highly efficient feature representations from low-resolution images of a scene. A Gated Re-current Unit (GRU)-based module acts as the fusion module, aggregating features into a combined representation. Finally, a decoder reconstructs the super-resolved image. The proposed model is evaluated on the PROBA-V dataset released in a recent competition held by the European Space Agency. Our results show that it performs among the top contenders and offers a new practical solution for real-world applications. © 2020 IEEE.","Computer vision; Decoding; Deep neural networks; Land use; Optical resolving power; Remote sensing; Satellite imagery; Signal encoding; Space applications; Environment monitoring; European Space Agency; Feature representation; High resolution satellite imagery; High-quality imagery; Low resolution images; Practical solutions; Recurrent networks; Recurrent neural networks","","Conference paper","Final","","Scopus","2-s2.0-85090117733"
"Nam Y.; Mun J.; Jang Y.; Kim J.","Nam, Yoojun (57205267084); Mun, Junwon (57038225200); Jang, Yunseok (57190280418); Kim, Jaeseok (15845538700)","57205267084; 57038225200; 57190280418; 15845538700","Single Image Super-resolution with Self-similarity","2019","2019 IEEE International Conference on Consumer Electronics, ICCE 2019","","","8662051","","","","10.1109/ICCE.2019.8662051","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063778540&doi=10.1109%2fICCE.2019.8662051&partnerID=40&md5=0cd9bf71b7a86a8f2af867d0c2ae4178","Degraded low-resolution (LR) images are often obtained from cameras. Resolution enhancement and image restoration are very practical in many fields such as medical imaging, surveillance system and remote sensing. Single image super-resolution is a technique which reconstruct a restored high-resolution (HR) image from a degraded LR image. In this paper, we propose single image super-resolution based on sparse coding using self-similarity prior. A sparsity constraint is used to jointly train coupled dictionaries which can generate high frequency details. Reconstructed HR output is enhanced with non-local means based on self-similarity prior. Experimental results demonstrate that our method shows higher performance than other existing algorithms. © 2019 IEEE.","Image coding; Image enhancement; Medical imaging; Optical resolving power; Remote sensing; Restoration; High frequency HF; High resolution image; Low resolution images; Non local means; Resolution enhancement; Self-similarities; Sparsity constraints; Surveillance systems; Image reconstruction","","Conference paper","Final","","Scopus","2-s2.0-85063778540"
"Chen H.; Zhang H.; Du J.; Luo B.","Chen, Hang (55778342600); Zhang, Hongyan (54954032600); Du, Juan (53663374500); Luo, Bin (57209592752)","55778342600; 54954032600; 53663374500; 57209592752","Unified framework for the joint super-resolution and registration of multiangle multi/hyperspectral remote sensing images","2020","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","13","","9091255","2369","2384","15","10.1109/JSTARS.2020.2993629","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086312216&doi=10.1109%2fJSTARS.2020.2993629&partnerID=40&md5=c7bdc21d12ed7acf1fc7456422d40373","In this article, a unified framework based on rank minimization (UFRM) is proposed for use with multiangle multi/hyperspectral remote sensing images, which simultaneously integrates image super-resolution reconstruction (SRR) and image registration. With the complementary information of different angle images and the high correlation between each band of the multi/hyperspectral images, a new image observation model is established to describe the mathematical degradation process of the observed low-resolution multiangle multi/hyperspectral images from the desired high-resolution (HR) multi/hyperspectral image. Based on the rank-one structure of the multiangle images, each observed image is decomposed into a foreground image for each angle image, and a background image, which is shared among all the multiangle images. A multichannel total variation constraint is applied to the target HR background image, with the consideration of the high correlation of different bands. Finally, an alternating minimization optimization strategy is utilized to resolve the joint cost function, which consists of the unknown image registration transformation parameters and the desired reconstruction image. As a result, the UFRM method can simultaneously achieve image registration and SRR. A number of experiments were conducted, which confirmed the superior performance of the proposed method. © 2008-2012 IEEE.","Cost functions; Image registration; Optical resolving power; Remote sensing; Alternating minimization; Degradation process; Image super-resolution reconstruction; Multi/hyperspectral images; Optimization strategy; Reconstruction image; Registration transformation; Remote sensing images; correlation; image resolution; multispectral image; numerical method; remote sensing; satellite imagery; Image reconstruction","Multi/hyperspectral; Multiangle; Rank-one; Registration; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85086312216"
"Jayanarayan A.; Sowmya V.; Soman K.P.","Jayanarayan, Abhijith (57215898504); Sowmya, V. (36096164300); Soman, K.P. (57205365723)","57215898504; 36096164300; 57205365723","Remote Sensing Image Super-Resolution Using Residual Dense Network","2020","Advances in Intelligent Systems and Computing","1118","","","721","729","8","10.1007/978-981-15-2475-2_66","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082294431&doi=10.1007%2f978-981-15-2475-2_66&partnerID=40&md5=b751e81e9d91e257762a3953bbf3cebe","Image super-resolution (SR) is a wide research topic, as it has found multiple applications in different fields. We implement image super-resolution for satellite images using a residual dense network (RDN). RDN is a CNN-based model, but unlike most CNN-based super-resolution models, it utilizes the hierarchic features from the input low resolution (LR) images and combines both the specific and general features present in the image, therefore resulting in a better performance. The novelty of our work lies in two aspects. First, we apply the residual dense network to remote sensing data to obtain higher structure similarity index metric (SSIM) and peak signal-to-noise ratio (PSNR) values than the existing models. Second, we use transfer learning due to the lack of training samples in remote sensing domain. Our RDN is first trained using an external dataset DIVerse2K (DIV2K). This model is then used to obtain high-resolution(HR) images of the remote sensing U.C Merced dataset, and the corresponding PSNR and SSIM values are computed for different scaling factors such as 2, 4 and 8. The experimental results obtained using the proposed work demonstrates the better performance of RDN for the super-resolution of remote sensing images, when compared to the existing methods like super-resolution generative adversarial network (SRGAN) and transferred generative adversarial network (TGAN). © 2020, Springer Nature Singapore Pte Ltd.","Deep learning; Optical resolving power; Signal processing; Signal to noise ratio; Soft computing; Transfer learning; High resolution image; Image; Image super resolutions; Multiple applications; Peak signal to noise ratio; Remote sensing images; Super resolution; Super-resolution models; Remote sensing","Deep learning; Image; Remote sensing; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85082294431"
"Jiang K.; Wang Z.; Yi P.; Wang G.; Lu T.; Jiang J.","Jiang, Kui (57203871718); Wang, Zhongyuan (57203515592); Yi, Peng (57203880354); Wang, Guangcheng (57209891180); Lu, Tao (56406646300); Jiang, Junjun (54902306100)","57203871718; 57203515592; 57203880354; 57209891180; 56406646300; 54902306100","Edge-Enhanced GAN for Remote Sensing Image Superresolution","2019","IEEE Transactions on Geoscience and Remote Sensing","57","8","8677274","5799","5812","13","10.1109/TGRS.2019.2902431","209","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069773369&doi=10.1109%2fTGRS.2019.2902431&partnerID=40&md5=4ce590788aca7fbb4534236883443046","The current superresolution (SR) methods based on deep learning have shown remarkable comparative advantages but remain unsatisfactory in recovering the high-frequency edge details of the images in noise-contaminated imaging conditions, e.g., remote sensing satellite imaging. In this paper, we propose a generative adversarial network (GAN)-based edge-enhancement network (EEGAN) for robust satellite image SR reconstruction along with the adversarial learning strategy that is insensitive to noise. In particular, EEGAN consists of two main subnetworks: an ultradense subnetwork (UDSN) and an edge-enhancement subnetwork (EESN). In UDSN, a group of 2-D dense blocks is assembled for feature extraction and to obtain an intermediate high-resolution result that looks sharp but is eroded with artifacts and noises as previous GAN-based methods do. Then, EESN is constructed to extract and enhance the image contours by purifying the noise-contaminated components with mask processing. The recovered intermediate image and enhanced edges can be combined to generate the result that enjoys high credibility and clear contents. Extensive experiments on Kaggle Open Source Data set, Jilin-1 video satellite images, and Digitalglobe show superior reconstruction performance compared to the state-of-the-art SR approaches. © 1980-2012 IEEE.","Deep learning; Image reconstruction; Optical resolving power; Remote sensing; Satellites; Adversarial learning; dense connection; Edge enhancements; Remote sensing imagery; Super resolution; algorithm; experimental design; image processing; reconstruction; remote sensing; satellite data; satellite imagery; Image enhancement","Adversarial learning; dense connection; edge enhancement; remote sensing imagery; superresolution","Article","Final","","Scopus","2-s2.0-85069773369"
"Kawulok M.; Benecki P.; Piechaczek S.; Hrynczenko K.; Kostrzewa D.; Nalepa J.","Kawulok, Michal (24474818300); Benecki, Pawel (55644906700); Piechaczek, Szymon (57203969234); Hrynczenko, Krzysztof (57203971746); Kostrzewa, Daniel (50661666400); Nalepa, Jakub (55441340400)","24474818300; 55644906700; 57203969234; 57203971746; 50661666400; 55441340400","Deep Learning for Multiple-Image Super-Resolution","2020","IEEE Geoscience and Remote Sensing Letters","17","6","8884136","1062","1066","4","10.1109/LGRS.2019.2940483","41","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085513402&doi=10.1109%2fLGRS.2019.2940483&partnerID=40&md5=9436b5f29b081fdc0d22e314b4dc4f55","Super-resolution (SR) reconstruction is a process aimed at enhancing the spatial resolution of images, either from a single observation, based on the learned relation between low and high resolution, or from multiple images presenting the same scene. SR is particularly important, if it is not feasible to acquire images at the desired resolution, while there are single or many observations available at lower resolution - this is inherent to a variety of remote sensing scenarios. Recently, we have witnessed substantial improvement in single-image SR attributed to the use of deep neural networks for learning the relation between low and high resolution. Importantly, deep learning has not been widely exploited for multiple-image super-resolution, which benefits from information fusion and in general allows for achieving higher reconstruction accuracy. In this letter, we introduce a new approach to combine the advantages of multiple-image fusion with learning the low-to-high resolution mapping using deep networks. The results of our extensive experiments indicate that the proposed framework outperforms the state-of-the-art SR methods. © 2019 IEEE.","Deep neural networks; Image enhancement; Image fusion; Image reconstruction; Optical resolving power; Remote sensing; High resolution; Lower resolution; Multiple image; New approaches; Reconstruction accuracy; Spatial resolution; State of the art; Super resolution reconstruction; accuracy assessment; artificial neural network; geological mapping; image processing; image resolution; reconstruction; remote sensing; satellite imagery; spatial resolution; Deep learning","Convolutional neural networks (CNNs); deep learning; image processing; super resolution (SR)","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85085513402"
"Li K.; Xie W.; Du Q.; Li Y.","Li, Kaiyan (57223151478); Xie, Weiying (56768656200); Du, Qian (7202060063); Li, Yunsong (55986546100)","57223151478; 56768656200; 7202060063; 55986546100","DDLPS: Detail-Based Deep Laplacian Pansharpening for Hyperspectral Imagery","2019","IEEE Transactions on Geoscience and Remote Sensing","57","10","8736034","8011","8025","14","10.1109/TGRS.2019.2917759","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075389681&doi=10.1109%2fTGRS.2019.2917759&partnerID=40&md5=9951a69a99084e225acfd5bf283d61aa","In this paper, we propose a new pansharpening method called detail-based deep Laplacian pansharpening (DDLPS) to improve the spatial resolution of hyperspectral imagery. This method includes three main components: upsampling, detail injection, and optimization. In particular, a deep Laplacian pyramid super-resolution network (LapSRN) improves the resolution of each band. Then, a guided image filter and a gain matrix are used to combine the spatial and spectral details with an optimization problem, which is formed to adaptively select an injection coefficient. The DDLPS method is compared with 11 state-of-the-art or traditional pansharpening approaches. The experimental results demonstrate the superiority of the DDLPS method in terms of both quantitative indices and visual appearance. In addition, the training of LapSRN is based on the data sets of traditional RGB images, which overcomes the practical difficulty of insufficient training samples for pansharpening. © 1980-2012 IEEE.","Hyperspectral imaging; Laplace transforms; Optical resolving power; Remote sensing; Spectroscopy; Guided images; HyperSpectral; Pan-sharpening; Super resolution; Sylvester equation; filter; image resolution; imaging method; matrix; network analysis; numerical method; optimization; satellite imagery; spatial resolution; Image enhancement","Guided image filter; hyperspectral (HS) imaging; Laplacian pyramid super-resolution network (LapSRN); pansharpening; super-resolution; Sylvester equation","Article","Final","","Scopus","2-s2.0-85075389681"
"Ulfarsson M.O.; Palsson F.; Dalla Mura M.; Sveinsson J.R.","Ulfarsson, Magnus O. (6507677875); Palsson, Frosti (55052918200); Dalla Mura, Mauro (36499129800); Sveinsson, Johannes R. (7003642214)","6507677875; 55052918200; 36499129800; 7003642214","Sentinel-2 sharpening using a reduced-rank method","2019","IEEE Transactions on Geoscience and Remote Sensing","57","9","8694937","6408","6420","12","10.1109/TGRS.2019.2906048","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072023379&doi=10.1109%2fTGRS.2019.2906048&partnerID=40&md5=832a78bb32913c8da1b38d41ebecc03a","Recently, the Sentinel-2 (S2) satellite constellation was deployed for mapping and monitoring the Earth environment. Images acquired by the sensors mounted on the S2 platforms have three levels of spatial resolution: 10, 20, and 60 m. In many remote sensing applications, the availability of images at the highest spatial resolution (i.e., 10 m for S2) is often desirable. This can be achieved by generating a synthetic high-resolution image through data fusion. To this end, researchers have proposed techniques exploiting the spectral/spatial correlation inherent in multispectral data to sharpen the lower resolution S2 bands to 10 m. In this paper, we propose a novel method that formulates the sharpening process as a solution to an inverse problem. We develop a cyclic descent algorithm called S2Sharp and an associated tuning parameter selection algorithm based on generalized cross validation and Bayesian optimization. The tuning parameter selection method is evaluated on a simulated data set. The effectiveness of S2Sharp is assessed experimentally by comparisons to state-of-the-art methods using both simulated and real data sets. © 1980-2012 IEEE.","Data fusion; Image fusion; Image resolution; Remote sensing; Cyclic descents; Generalized cross validation; Image sharpening; Remote sensing applications; Satellite constellations; Sentinel-2 (S2) constellation; State-of-the-art methods; Super resolution; Inverse problems","Cyclic descent (CD); data fusion; image sharpening; Sentinel-2 (S2) constellation; superresolution","Article","Final","","Scopus","2-s2.0-85072023379"
"Trinder J.; Liu Q.","Trinder, John (57203069424); Liu, Qingxiang (57190622325)","57203069424; 57190622325","Assessing environmental impacts of urban growth using remote sensing","2020","Geo-Spatial Information Science","23","1","","20","39","19","10.1080/10095020.2019.1710438","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078478146&doi=10.1080%2f10095020.2019.1710438&partnerID=40&md5=f99c09a677147c707370f336b3d9ebf6","This paper provides a study of the changes in land use in urban environments in two cities, Wuhan, China and western Sydney in Australia. Since mixed pixels are a characteristic of medium resolution images such as Landsat, when used for the classification of urban areas, due to changes in urban ground cover within a pixel, Multiple Endmember Spectral Mixture Analysis (MESMA) together with Super-Resolution Mapping (SRM) are employed to derive class fractions to generate classification maps at a higher spatial resolution using an Artificial Neural Network (ANN) predicted Wavelet method. Landsat images over the two cities for a 30-year period, are classified in terms of vegetation, buildings, soil and water. The classifications are then processed using Indifrag software to assess the levels of fragmentation caused by changes in the areas of buildings, vegetation, water and soil over the 30 years. The extents of fragmentation of vegetation, buildings, water and soil for the two cities are compared, while the percentages of vegetation are compared with recommended percentages of green space for urban areas for the benefit of health and well-being of inhabitants. Changes in Ecosystem Service Values (ESVs) resulting from the urbanization have been assessed for Wuhan and Sydney. The UN Sustainable Development Goals (SDG) for urban areas are being assessed by researchers to better understand how to achieve the sustainability of cities. © 2020, © 2020 Wuhan University. Published by Informa UK Limited, trading as Taylor & Francis Group.","Australia; China; Hubei; New South Wales; Sydney [New South Wales]; Wuhan; Ecosystems; Environmental impact; Land use; Mixtures; Neural networks; Optical resolving power; Photomapping; Pixels; Planning; Remote sensing; Soils; Sustainable development; Vegetation; Ecosystem service values; Mixture analysis; Super-resolution mappings; Urban areas; Urban classification; Urban sustainability; artificial neural network; classification; ecosystem service; environmental impact assessment; environmental values; fragmentation; image resolution; Landsat; pixel; remote sensing; Sustainable Development Goal; urban growth; Urban growth","Ecosystem Service Values (ESV); fragmentation of urban areas; Multiple Endmember Mixture Analysis (MESMA); Super-Resolution Mapping (SRM); Sustainable Development Goals (SDG); Urban classification; urban sustainability","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85078478146"
"","","","7th National Conference on Computer Vision, Pattern Recognition, Image Processing, and Graphics, NCVPRIPG 2019","2020","Communications in Computer and Information Science","1249","","","","","628","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097306523&partnerID=40&md5=5db10814e11e6467512863b6bf65fbfa","The proceedings contain 58 papers. The special focus in this conference is on Computer Vision, Pattern Recognition, Image Processing, and Graphics. The topics include: Deep Learn Bananas: A Transfer Learning for Banana Variety Classification; a Framework for Lane Prediction Based on Vehicle Detection and Tracking; detector-SegMentor Network for Skin Lesion Localization and Segmentation; choroid Disease Classification Using Convolutional Neural Network; hyper Vision Net: Kidney Tumor Segmentation Using Coordinate Convolutional Layer and Attention Unit; texture Classification by Local Rajan Transform Based Descriptor; domain Decomposition Based Preconditioned Solver for Bundle Adjustment; deep Dictionary Learning for Inpainting; A Robust Pose Transformational GAN for Pose Guided Person Image Synthesis; structure Preserving Image Inpainting Using Edge Priors with Contextual Attention; preface; fast Stereo Depth Estimation in Smartphone Devices with Narrow Baseline; exploring Temporal Differences in 3D Convolutional Neural Networks; PoshakNet: Framework for Matching Dresses from Real-Life Photos Using GAN and Siamese Network; unsupervised Domain Adaptation for Remote Sensing Images Using Metric Learning and Correlation Alignment; computationally Efficient Super-Resolution Approach for Real-World Images; Accurate Damage Dimension Estimation in AI Driven Vehicle Inspection System; a Deep Learning Based Framework for Distracted Driver Detection; RECAL: Reuse of Established CNN Classifier Apropos Unsupervised Learning Paradigm; Pose Estimation of UAVs Using Stereovision; U-RME: Underwater Refined Motion Estimation in Hazy, Cluttered and Dynamic Environments; emphasizing Similar Feature Representations to Defend Against Adversarial Attacks; single Storage Semi-Global Matching for Real Time Depth Processing; iSalGAN - An Improvised Saliency GAN; putting Jewellery and Accessories on a 3D Face Model Generated from 2D Image.","","","Conference review","Final","","Scopus","2-s2.0-85097306523"
"Borsoi R.A.; Imbiriba T.; Bermudez J.C.M.","Borsoi, Ricardo Augusto (57200515064); Imbiriba, Tales (8404434100); Bermudez, Jose Carlos Moreira (7102615510)","57200515064; 8404434100; 7102615510","Super-Resolution for Hyperspectral and Multispectral Image Fusion Accounting for Seasonal Spectral Variability","2020","IEEE Transactions on Image Processing","29","","8768351","116","127","11","10.1109/TIP.2019.2928895","54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072509104&doi=10.1109%2fTIP.2019.2928895&partnerID=40&md5=6fdcfc00988361cf9c6483012560b0a6","Image fusion combines data from different heterogeneous sources to obtain more precise information about an underlying scene. Hyperspectral-multispectral (HS-MS) image fusion is currently attracting great interest in remote sensing since it allows the generation of high spatial resolution HS images and circumventing the main limitation of this imaging modality. Existing HS-MS fusion algorithms, however, neglect the spectral variability often existing between images acquired at different time instants. This time difference causes variations in spectral signatures of the underlying constituent materials due to the different acquisition and seasonal conditions. This paper introduces a novel HS-MS image fusion strategy that combines an unmixing-based formulation with an explicit parametric model for typical spectral variability between the two images. Simulations with synthetic and real data show that the proposed strategy leads to a significant performance improvement under spectral variability and state-of-the-art performance otherwise. © 2019 IEEE.","Hyperspectral imaging; Optical resolving power; Remote sensing; Endmember variabilities; Hyperspectral Data; Multi-spectral data; Seasonal variability; Super resolution; article; neglect; simulation; Image fusion","endmember variability; Hyperspectral data; image fusion; multispectral data; seasonal variability; super-resolution","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85072509104"
"Mei S.; Liu X.; Zhang G.; Du Q.","Mei, Shaohui (25822578400); Liu, Xiao (57212229476); Zhang, Ge (57213770581); Du, Qian (7202060063)","25822578400; 57212229476; 57213770581; 7202060063","Sensor-specific Transfer Learning for Hyperspectral Image Processing","2019","2019 10th International Workshop on the Analysis of Multitemporal Remote Sensing Images, MultiTemp 2019","","","8866896","","","","10.1109/Multi-Temp.2019.8866896","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074278209&doi=10.1109%2fMulti-Temp.2019.8866896&partnerID=40&md5=038876656f1ad187bbe731e2c9292c8c","Transfer learning (TL) has shown its great advantage to solve small-Training-sample problems using knowledge learned from existing large data with deep learning techniques, which can be used for hyperspectral image intelligent processing in which labeled data is very difficult and even impossible to be obtained. However, the mismatch of hyperspectral sensors results in lots of difficulty for transfer learning to be used in hyperspectral image (HSI) processing. In this paper, sensor-specific based transfer learning is proposed for hyperspectral images acquired from same sensors, in which knowledge learn from hyperspectral images, e.g., the network structure and parameters of a deep neural network, are limited to transfer to images of the same sensor only. Specifically, the validity of sensor-specific transfer learning is evaluated using three deep learning based tasks, including feature learning, super-resolution, and image denoising. Experimental results from two benchmark datasets from the well-known ROSIS sensor, i.e., Pavia Centre and Pavia University, have demonstrated that sensor-specific based transfer learning can achieve satisfying performance even without fine-Tune by small-Training-samples on the target scene. © 2019 IEEE.","Benchmarking; Deep neural networks; Hyperspectral imaging; Image analysis; Machine learning; Neural networks; Optical resolving power; Remote sensing; Sampling; Spectroscopy; Convolutional neural network; Feature learning; Hyperspectral sensors; Intelligent processing; Learning techniques; Network structures; Super resolution; Transfer learning; Image denoising","convolutional neural network (CNN); feature learning; hyperspectral image processing; image denoising; super-resolution; transfer learning","Conference paper","Final","","Scopus","2-s2.0-85074278209"
"Wang P.; Zhang L.; Zhang G.; Bi H.; Mura M.D.; Chanussot J.","Wang, Peng (57189493188); Zhang, Lei (57218523652); Zhang, Gong (35241577600); Bi, Hui (56577412600); Mura, Mauro Dalla (36499129800); Chanussot, Jocelyn (6602159365)","57189493188; 57218523652; 35241577600; 56577412600; 36499129800; 6602159365","Superresolution Land Cover Mapping Based on Pixel-, Subpixel-, and Superpixel-Scale Spatial Dependence with Pansharpening Technique","2019","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","12","10","8844095","4082","4098","16","10.1109/JSTARS.2019.2939670","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075347281&doi=10.1109%2fJSTARS.2019.2939670&partnerID=40&md5=1ecb1bd4a3face9b335d21e59d29672e","In this article, a novel superresolution mapping (SRM) method based on pixel-, subpixel-, and superpixel-scale spatial dependence (PSSSD) with pansharpening technique is proposed. First, an original coarse resolution remote sensing image and a high-resolution panchromatic image are fused by the pansharpening technique to produce a pansharpened result. A segmentation image with numerous superpixels, which represent irregular objects, is generated by adaptively segmenting the pansharpened result. Second, the class proportions of pixels, subpixels, and superpixels are, respectively, obtained from the original image, the pansharpened image, and the segmentation image. Pixel-scale spatial dependence is obtained using a pixel spatial attraction model. Subpixel-scale spatial dependence is derived using a novel subpixel spatial attraction model. Superpixel-scale spatial dependence is obtained through an extended random walker algorithm. Third, the three-scale spatial dependence is integrated into the PSSSD. Finally, a class allocation method based on object units is used to obtain the SRM results according to the PSSSD. Experimental results for three remote sensing images show that the proposed PSSSD outperforms the existing state-of-the-art SRM methods. © 2008-2012 IEEE.","Mapping; Optical resolving power; Remote sensing; Superpixels; Allocation methods; Land cover mapping; Panchromatic images; Pansharpened images; Remote sensing images; Segmentation images; Spatial dependence; Super-resolution mappings; algorithm; image analysis; image resolution; land cover; pixel; remote sensing; satellite data; satellite imagery; spatial resolution; Image segmentation","Remote sensing image; spatial dependence; superresolution mapping (SRM)","Article","Final","","Scopus","2-s2.0-85075347281"
"Pashaei M.; Starek M.J.; Kamangir H.; Berryhill J.","Pashaei, Mohammad (57213189326); Starek, Michael J. (23494042900); Kamangir, Hamid (57196243463); Berryhill, Jacob (56542823200)","57213189326; 23494042900; 57196243463; 56542823200","Deep learning-based single image super-resolution: An investigation for dense scene reconstruction with UAS photogrammetry","2020","Remote Sensing","12","11","1757","","","","10.3390/rs12111757","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086470516&doi=10.3390%2frs12111757&partnerID=40&md5=2371fcfa424e180cf1f098715b7cd45d","The deep convolutional neural network (DCNN) has recently been applied to the highly challenging and ill-posed problem of single image super-resolution (SISR), which aims to predict high-resolution (HR) images from their corresponding low-resolution (LR) images. In many remote sensing (RS) applications, spatial resolution of the aerial or satellite imagery has a great impact on the accuracy and reliability of information extracted from the images. In this study, the potential of a DCNN-based SISR model, called enhanced super-resolution generative adversarial network (ESRGAN), to predict the spatial information degraded or lost in a hyper-spatial resolution unmanned aircraft system (UAS) RGB image set is investigated. ESRGAN model is trained over a limited number of original HR (50 out of 450 total images) and virtually-generated LR UAS images by downsampling the original HR images using a bicubic kernel with a factor x 4. Quantitative and qualitative assessments of super-resolved images using standard image quality measures (IQMs) confirm that the DCNN-based SISR approach can be successfully applied on LR UAS imagery for spatial resolution enhancement. The performance of DCNN-based SISR approach for the UAS image set closely approximates performances reported on standard SISR image sets with mean peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) index values of around 28 dB and 0.85 dB, respectively. Furthermore, by exploiting the rigorous Structure-from-Motion (SfM) photogrammetry procedure, an accurate task-based IQM for evaluating the quality of the super-resolved images is carried out. Results verify that the interior and exterior imaging geometry, which are extremely important for extracting highly accurate spatial information from UAS imagery in photogrammetric applications, can be accurately retrieved from a super-resolved image set. The number of corresponding keypoints and dense points generated from the SfM photogrammetry process are about 6 and 17 times more than those extracted from the corresponding LR image set, respectively. © 2020 by the authors.","Antennas; Convolutional neural networks; Deep learning; Deep neural networks; Image quality; Image reconstruction; Image resolution; Optical resolving power; Photogrammetry; Remote sensing; Satellite imagery; Signal to noise ratio; Unmanned aerial vehicles (UAV); High resolution image; Peak signal to noise ratio; Quantitative and qualitative assessments; Reliability of information; Spatial-resolution enhancement; Structural similarity indices (SSIM); Structure from motion; Unmanned aircraft system; Image enhancement","Convolutional neural network (CNN); Deep learning; Generative adversarial network (GAN); Photogrammetry; Remote sensing; Structure-from-motion; Super-resolution (SR); Unmanned aircraft system (UAS)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85086470516"
"Li X.; Xu F.; Lyu X.; Tong Y.; Chen Z.; Li S.; Liu D.","Li, Xin (57215779896); Xu, Feng (56401380100); Lyu, Xin (57212319266); Tong, Yao (57208420959); Chen, Ziqi (57215537468); Li, Shengyang (56438234000); Liu, Daofang (57208423917)","57215779896; 56401380100; 57212319266; 57208420959; 57215537468; 56438234000; 57208423917","A Remote-Sensing Image Pan-Sharpening Method Based on Multi-Scale Channel Attention Residual Network","2020","IEEE Access","8","","8981952","27163","27177","14","10.1109/ACCESS.2020.2971502","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081108863&doi=10.1109%2fACCESS.2020.2971502&partnerID=40&md5=6939de2a6c9b491c4bc6fc5c7c0079e7","Pan-sharpening is a significant task that aims to generate high spectral- and spatial- resolution remote-sensing image by fusing multi-spectral (MS) and panchromatic (PAN) image. The conventional approaches are insufficient to protect the fidelity both in spectral and spatial domains. Inspired by the robust capability and outstanding performance of convolutional neural networks (CNN) in natural image super-resolution tasks, CNN-based pan-sharpening methods are worthy of further exploration. In this paper, a novel pan-sharpening method is proposed by introducing a multi-scale channel attention residual network (MSCARN), which can represent features accurately and reconstruct a pan-sharpened image comprehensively. In MSCARN, the multi-scale feature extraction blocks comprehensively extract the coarse structures and high-frequency details. Moreover, the multi-residual architecture guarantees the consistency of feature learning procedure and accelerates convergence. Specifically, we introduce a channel attention mechanism to recalibrate the channel-wise features by considering interdependencies among channels adaptively. The extensive experiments are implemented on two real-datasets from GaoFen series satellites. And the results show that the proposed method performs better than the existing methods both in full-reference and no-reference metrics, meanwhile, the visual inspection displays in accordance with the quantitative metrics. Besides, in comparison with pan-sharpening by convolutional neural networks (PNN), the proposed method achieves faster convergence rate and lower loss. © 2013 IEEE.","Convolution; Deep learning; Extraction; Feature extraction; Remote sensing; Attention mechanisms; Convergence acceleration; Multi-residual learning; Multi-scale features; Pan-sharpening; Convolutional neural networks","Channel-attention mechanism; Convergence acceleration; Deep learning; Multi-residual learning; Multi-scale feature extraction; Pan-sharpening","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85081108863"
"Gargiulo M.","Gargiulo, Massimiliano (57200856555)","57200856555","Advances on CNN-Based Super-Resolution of Sentinel-2 Images","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8899186","3165","3168","3","10.1109/IGARSS.2019.8899186","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075353253&doi=10.1109%2fIGARSS.2019.8899186&partnerID=40&md5=4689d84e041d124c573ebf12a2c49023","Thanks to their temporal-spatial coverage and free access, Sentinel-2 images are very interesting for the community. However, a relatively coarse spatial resolution, compared to that of state-of-the-art commercial products, motivates the study of super-resolution techniques to mitigate such a limitation. Specifically, thirtheen bands are sensed simultaneously but at different spatial resolutions: 10, 20, and 60 meters depending on the spectral location. Here, building upon our previous convolutional neural network (CNN) based method [1], we propose an improved CNN solution to super-resolve the 20-m resolution bands benefiting spatial details conveyed by the accompanying 10-m spectral bands. © 2019 IEEE.","Convolution; Data fusion; Deep learning; Deep neural networks; Geology; Optical resolving power; Remote sensing; Commercial products; Free access; Pan-sharpening; Spatial coverage; Spatial resolution; Spectral band; State of the art; Super resolution; Convolutional neural networks","convolutional neural network; Data fusion; deep learning; pansharpening","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85075353253"
"Ling F.; Foody G.M.","Ling, Feng (56278268300); Foody, Giles M. (7007014233)","56278268300; 7007014233","Super-resolution land cover mapping by deep learning","2019","Remote Sensing Letters","10","6","","598","606","8","10.1080/2150704X.2019.1587196","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065895043&doi=10.1080%2f2150704X.2019.1587196&partnerID=40&md5=a02836ffde3fe9147cc7ea059e74a1b6","Super-resolution mapping (SRM) is a technique to estimate a fine spatial resolution land cover map from coarse spatial resolution fractional proportion images. SRM is often based explicitly on the use of a spatial pattern model that represents the land cover mosaic at the fine spatial resolution. Recently developed deep learning methods have considerable potential as an alternative approach for SRM, based on learning the spatial pattern of land cover from existing fine resolution data such as land cover maps. This letter proposes a deep learning-based SRM algorithm (DeepSRM). A deep convolutional neural network was first trained to estimate a fine resolution indicator image for each class from the coarse resolution fractional image, and all indicator maps were then combined to create the final fine resolution land cover map based on the maximal value strategy. The results of an experiment undertaken with simulated images show that DeepSRM was superior to conventional hard classification and a suite of popular SRM algorithms, yielding the most accurate land cover representation. Consequently, methods such as DeepSRM may help exploit the potential of remote sensing as a source of accurate land cover information. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Deep neural networks; Image resolution; Neural networks; Optical resolving power; Remote sensing; Convolutional neural network; Land cover informations; Land cover mapping; Learning methods; Proportion Image; Spatial resolution; Super resolution; Super-resolution mappings; algorithm; artificial neural network; classification; image analysis; land cover; machine learning; mapping method; remote sensing; spatial resolution; spectral resolution; Mapping","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85065895043"
"Liu H.; Gu Y.","Liu, Huan (57069409100); Gu, Yanfeng (7403045983)","57069409100; 7403045983","A Summary of Super-Resolution for Satellite Videos Via Learning-Based Methods","2019","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2019-September","","8920882","","","","10.1109/WHISPERS.2019.8920882","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077572399&doi=10.1109%2fWHISPERS.2019.8920882&partnerID=40&md5=541507c93cc3f4dfa64c3f00efd7d221","With the development of remote sensing techniques, remote sensing data can be obtained with higher spatial, higher spectral, and higher temporal resolution. In addition, to get higher spatial resolution, super-resolution for increasing spatial resolution is getting special attention. In this paper, we will focus on some classical learning-based superresolution methods to investigate the adaptability for satellite videos with low imaging quality. Methods include sparse representation, collaborative representation, and deep learning methods. Experiments show that learning-based methods can perform well for single-frame super-resolution for satellite videos. Methods based on deep learning show higher PSNR and SSIM. And multi-frame super-resolution will be good for moving objects. However, it may also bring negative influence for a stationary scene, which is caused by low satellite video quality, such as winkling noise, a vibration of a camera, overexposure of metals. © 2019 IEEE.","Hyperspectral imaging; Image resolution; Optical resolving power; Remote sensing; Satellites; Spectroscopy; Collaborative representations; Dictionary learning; Learning-based methods; Remote sensing techniques; Single frame super resolutions; Sparse representation; Super resolution; Superresolution methods; Deep learning","Deep Learning.; Dictionary Learning; Satellite Videos; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85077572399"
"Li J.; Chen Z.; Zhao X.; Shao L.","Li, Jingtao (57217013418); Chen, Zhanlong (26322275400); Zhao, Xiaozhen (57217013673); Shao, Lijia (57217014471)","57217013418; 26322275400; 57217013673; 57217014471","MAPGAN: An intelligent generation model for network tile maps","2020","Sensors (Switzerland)","20","11","3119","","","","10.3390/s20113119","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085729281&doi=10.3390%2fs20113119&partnerID=40&md5=11c206c75755ee4a1045444f289c8a7b","In recent years, the generative adversarial network (GAN)-based image translation model has achieved great success in image synthesis, image inpainting, image super-resolution, and other tasks. However, the images generated by these models often have problems such as insufficient details and low quality. Especially for the task of map generation, the generated electronic map cannot achieve effects comparable to industrial production in terms of accuracy and aesthetics. This paper proposes a model called Map Generative Adversarial Networks (MapGAN) for generating multitype electronic maps accurately and quickly based on both remote sensing images and render matrices. MapGAN improves the generator architecture of Pix2pixHD and adds a classifier to enhance the model, enabling it to learn the characteristics and style differences of different types of maps. Using the datasets of Google Maps, Baidu maps, and Map World maps, we compare MapGAN with some recent image translation models in the fields of one-to-one map generation and one-to-many domain map generation. The results show that the quality of the electronic maps generated by MapGAN is optimal in terms of both intuitive vision and classic evaluation indicators. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Maps; Remote sensing; Adversarial networks; Evaluation indicators; Image Inpainting; Image super resolutions; Image synthesis; Image translation; Industrial production; Remote sensing images; article; classifier; human; human experiment; remote sensing; vision; Image processing","Deep generation model; Image translation; Map generation; Network tile map","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85085729281"
"Wang B.; Zuo C.; Sun J.; Hu Y.; Zhang L.","Wang, Bowen (57204607674); Zuo, Chao (36007852700); Sun, Jiasong (56048572500); Hu, Yan (56681484200); Zhang, Linfei (57219972746)","57204607674; 36007852700; 56048572500; 56681484200; 57219972746","A computational super-resolution technique based on coded aperture imaging","2020","Proceedings of SPIE - The International Society for Optical Engineering","11396","","113960P","","","","10.1117/12.2560579","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120952107&doi=10.1117%2f12.2560579&partnerID=40&md5=019833560ce0fb2e23bf3e8e08ddd431","We report a new computational super-resolution (SR) imaging technique, termed as coded aperture super-resolution imaging (CASR), which is to modulate the point spread function (PSF) of the imaging system by rotating the aperture pattern. The pattern is designed in an anisotropic manner so that the PSF spreads across multiple pixels and contains clues about high-frequency structure. A fundamental difference between our approach and conventional multi-image superresolution is that CASR accounts for the diffraction effect explicitly with no need for relative motion between the scene and the detector. With CASR, we design and construct two sets of programmable aperture photoelectric imaging systems in the visible spectrum. The achievable equivalent Nyquist sampling frequency of the detectors is increased to 3.57×. Furthermore, it can be flexibly applied to long-distance HR detection due to its advantages of fast response, no mechanical movement, and anti-airflow disturbance. © 2020 SPIE.","Image resolution; Imaging systems; Optical transfer function; Remote sensing; Coded aperture imaging; Coded apertures; Images reconstruction; Multi-image reconstruction; Multi-images; Point-Spread function; Remote-sensing; Resolution techniques; Super resolution imaging; Superresolution; Image reconstruction","Coded Aperture; Multi-Image Reconstruction; Remote Sensing; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85120952107"
"Kasetkasem T.","Kasetkasem, Teerasit (6603233500)","6603233500","A Super-Resolution Mapping Using a Convolutional Neural Network","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898537","3077","3080","3","10.1109/IGARSS.2019.8898537","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077702630&doi=10.1109%2fIGARSS.2019.8898537&partnerID=40&md5=ea07ef92253e93ba1136f39452722844","In this paper, we propose an approach for super-resolution land cover mapping on remote sensing images based on a Convolutional Neural Network (CNN). Here, the CNN is trained to match the input subimages to the super resolution map around the training pixels. since there are so many possible configurations of super-resolution map on a given set of pixels, a large number of training samples are required. To reduce the number of training samples, we converted the super-resolution to a set of level set functions and used the minimum mean square error between the predicted and actual level set functions as the training objective. The QUICKBIRD satellite image data cover a part of Kasetsart University's Bangkhen campus was used for evaluation. Experimental results showed that the proposed method has achieved superior accuracy than both Hopfield and Pixel-Swapping methods. © 2019 IEEE.","Convolution; Geology; Mapping; Mean square error; Optical resolving power; Pixels; Remote sensing; Rotational flow; Sampling; Set theory; Land cover mapping; Level set functions; Minimum mean square errors; QuickBird satellite; Remote sensing images; Super resolution; Super-resolution mappings; Training sample; Convolutional neural networks","convolutional neural network; level set function; super-resolution mapping","Conference paper","Final","","Scopus","2-s2.0-85077702630"
"Pereira M.B.; Dos Santos J.A.","Pereira, Matheus B. (57212556072); Dos Santos, Jefersson A. (25654873000)","57212556072; 25654873000","How effective is super-resolution to improve dense labelling of coarse resolution imagery?","2019","Proceedings - 32nd Conference on Graphics, Patterns and Images, SIBGRAPI 2019","","","8919823","202","209","7","10.1109/SIBGRAPI.2019.00035","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077060392&doi=10.1109%2fSIBGRAPI.2019.00035&partnerID=40&md5=8e1e2d31ab55c6be2a70d732ea55bfc4","Coarse resolution remote sensing images, such as LANDSAT and MODIS are easily found in public open repositories and, therefore, are widely used in many studies. But their use for automatic creation of thematic maps is very restrict since most of the deep-based semantic segmentation (a.k.a dense labelling) approaches are only suitable for subdecimeter data. In this paper, we design a straightforward framework in order to evaluate the effectiveness of deep-based super-resolution in the semantic segmentation of low-resolution remote sensing images. We carried out an extensive set of experiments on three remote sensing datasets with distinct nature/properties. The results show that super-resolution is effective to improve semantic segmentation performance on low-resolution aerial imagery. It not only outperforms unsupervised interpolation but also achieves semantic segmentation results comparable to high-resolution data. © 2019 IEEE.","Aerial photography; Antennas; Image segmentation; Maps; Optical resolving power; Remote sensing; Semantics; Aerial imagery; Automatic creations; Coarse-resolution imagery; High resolution data; Open repositories; Remote sensing images; Semantic segmentation; Super resolution; Image enhancement","Remote sensing; Semantic segmentation; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85077060392"
"Yang H.; Zhao Y.; Dong J.","Yang, Hongye (57215083821); Zhao, Yindi (8359721000); Dong, Jihong (55477986400)","57215083821; 8359721000; 55477986400","Remote sensing image super-resolution of open-pit mining area based on texture transfer; [基于纹理转移的露天矿区遥感图像超分辨率重建]","2019","Meitan Xuebao/Journal of the China Coal Society","44","12","","3781","3789","8","10.13225/j.cnki.jccs.SH19.1028","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079863284&doi=10.13225%2fj.cnki.jccs.SH19.1028&partnerID=40&md5=2dad441b26e531bea660275ac29d4db1","Remote sensing image is one of the main sources in open-pit mines production. Its spatial resolution affects the identification of the boundary of each scene in mining area, the interpretation of small ground objects and the location of control points. Remote sensing images play an important role in the open-pit production management and monitoring. Aiming at the problem of high spatial resolution image that meets the restrictions, such as cost and technological constraints, it is proposed to use a super-resolution technology to improve the spatial resolution of remote sensing images in open-pit mining areas. According to the obvious texture features of each scene in the open-pit mining area, the research used a deep learning texture transfer super-resolution method. Through an end-to-end deep learning model, the processes are as follows: input low-resolution images and corresponding reference images, divide them into several image patches, extract the features of image patches using feature extraction network, and compare low-resolution feature image blocks and reference features. The image patches texture similarity adaptively transfers the texture from reference images, and fuses the plurality of ex-changed texture feature maps into the generation network in the feature layers of various scales to construct the reconstructed images with rich texture details. At the same time, the ResNet34 with deeper network depth and smaller computing capacity is used to replace the VGG19, which further improves the feature extraction effect. The research used a self-made open-pit mining area dataset for experiments. Compared with the advanced image super-resolution methods, in terms of the influence of the reference image on the results, the results show that the improved method reconstruction effect will increase with the similarity between reference images and input images. Compared with other methods, the values of peak signal-to-noise ratio and structural similarity are better than the original methods, EDSR and SRGAN, and the visual perception is better. © 2019, Editorial Office of Journal of China Coal Society. All right reserved.","Deep learning; Extraction; Feature extraction; Image coding; Image enhancement; Image reconstruction; Image resolution; Image texture; Learning systems; Optical resolving power; Remote sensing; Signal to noise ratio; Textures; Transfer learning; High spatial resolution images; Image super resolutions; Peak signal to noise ratio; Reference image; Super resolution; Superresolution methods; Technological constraints; Texture transfer; Open pit mining","Open-pit mining area; Reference images; Super-resolution; Texture transfer","Article","Final","","Scopus","2-s2.0-85079863284"
"Vala A.; Patel A.; Gosai R.; Chaudharia J.; Mewada H.; Mahant K.","Vala, Alpesh (56573960400); Patel, Amit (57222954941); Gosai, Riddhi (57204282879); Chaudharia, Jitendra (57204294506); Mewada, Hiren (35766889700); Mahant, Keyur (56878975200)","56573960400; 57222954941; 57204282879; 57204294506; 35766889700; 56878975200","A low-cost and efficient cloud monitoring camera system design for imaging satellites","2019","International Journal of Remote Sensing","40","7","","2739","2758","19","10.1080/01431161.2018.1531319","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055121345&doi=10.1080%2f01431161.2018.1531319&partnerID=40&md5=3b24b27c14accff64817aa7cb4fcd6d0","Design and development of a cloud monitoring camera (CMC) as a secondary camera for imaging/remote-sensing satellites is proposed here. It is well known that presence of clouds alters the earth-atmospheree energy budget by scattering and absorbing the shortwave radiation and absorbing and re-emitting the infrared radiation. Detection of clouds at precise positions, prior to the initiation of the imaging session of the primary (super resolution) camera can aid in saving power as well as memory storage of the satellite. Key feature of the proposed system is the implementation of an onboard cloud detection system in the visible band. The proposed system is miniature in size and cost-effective when compared to the existing integrated visible and infrared band detection system. It primarily consists of lens assembly, detector head assembly, field programmable gate array (FPGA)-based camera electronics system with supporting proximity electronics. Cloud detection algorithm for the visible band images is derived and simulated with the help of Laboratory Virtual Instrument Engineering Workbench software. The verification and hardware realization of the algorithm is achieved by implementing it on a FPGA-based system. Overall simulated and measured efficiency of more than 94% was achieved. The volume of the system is 85 mm × 85 mm × 25 mm and weighs approximately 2 kg, making it suitable for satellite mounting. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","Budget control; Cameras; Cost effectiveness; Costs; Infrared radiation; Integrated circuit design; Satellites; Cloud detection algorithms; Design and Development; Electronics system; Hardware realization; Imaging satellites; Laboratory virtual instrument engineering work-bench; Precise position; Short-wave radiation; algorithm; cloud cover; energy budget; remote sensing; satellite imagery; Field programmable gate arrays (FPGA)","","Article","Final","","Scopus","2-s2.0-85055121345"
"Moghimi M.K.; Mohanna F.","Moghimi, Mohammad Kazem (56152552300); Mohanna, Farahnaz (6603299827)","56152552300; 6603299827","A joint adaptive evolutionary model towards optical image contrast enhancement and geometrical reconstruction approach in underwater remote sensing","2019","SN Applied Sciences","1","10","1242","","","","10.1007/s42452-019-1255-0","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092040500&doi=10.1007%2fs42452-019-1255-0&partnerID=40&md5=4a5f044c4475e2e52704bfdbf27a9c4e","Nowadays, the underwater optical imaging is used by a wide range of sciences including marine scientists for studying underwater structures and organisms, oil and gas companies, telecommunications to monitor fuel transmission lines and cables, and military centers to detect the sea mines and submarines. Images with non-uniform brightness are visually limited due to low ambient light during imaging or excessive exposure, fogging, hazing, or a combination of these factors. As a result, a process of imaging improvement is highly complex with some conditions. Particularly, this issue is harmful for the underwater environments as well as its highly complexity. In this paper, we improve the underwater images from different environments by exploiting image processing techniques including elimination of fogging in the image, and improvement of contrast with combining super resolution methods which result in significant enhancement of the image quality. To remove fogging in the image enhancement method, a variational-based fusion method was proposed without increasing or decreasing image resolution to increase the adaptability of non-uniform backlight images. This approach is optimized by the bee colony algorithm. Additionally, weighting coefficient selection method is used for super resolution of image after adjusting contrast. The main reason for using hybrid contrast techniques includes the adaptive enhancement and color correction. The bee colony algorithm and weighting coefficient in super resolution due to the lack of hybrid methods in visually improved water images has been the subject of recent researches. The hybrid set has provided more effect on different images at various conditions. Having applied the algorithm set for low-quality visual image set of underwater, some analyses such as PSNR, MSE and SSIM are tested. Compared to similar solutions, the quality is significantly improved and highlighted the exhaustive operation of the algorithm. Applying the presented algorithm in the software part of underwater imaging systems is widely effective for the accurate analysis of underwater images. © 2019, Springer Nature Switzerland AG.","Fog dispersal; Gas industry; Geometrical optics; Image analysis; Image reconstruction; Image resolution; Imaging systems; Optical cables; Optical data processing; Optical resolving power; Petroleum industry; Public utilities; Remote sensing; Telecommunication industry; Underwater imaging; Bee colony algorithms; Evolutionary models; Geometrical reconstruction; Image processing technique; Oil and gas companies; Superresolution methods; Underwater environments; Weighting coefficient; Image enhancement","Adaptive contrast enhancement; Bee colony algorithm; Super resolution; Underwater images; Weighting coefficient selection","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85092040500"
"Guzmán R.; López R.; Ocerin E.; Davis S.; Hernani J.T.; Brennan-Craddock R.; Kelleman N.; Pastena M.; Melega N.; Mariani F.","Guzmán, Rafael (13703044500); López, Ricardo (57219548711); Ocerin, Eider (57219555405); Davis, Stuart (57219552939); Hernani, Juan Tomás (57219551647); Brennan-Craddock, Rob (57219555213); Kelleman, Nick (57219550769); Pastena, Massimiliano (57225077037); Melega, Nicola (53664096400); Mariani, Flavio (57211112766)","13703044500; 57219548711; 57219555405; 57219552939; 57219551647; 57219555213; 57219550769; 57225077037; 53664096400; 57211112766","A compact multispectral imager for the Mantis mission 12U Cubesat","2020","Proceedings of SPIE - The International Society for Optical Engineering","11505","","1150507","","","","10.1117/12.2568080","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093868129&doi=10.1117%2f12.2568080&partnerID=40&md5=a1c6510e555e74c1f1a83800696e7405","The requirements of the natural resources sector for remote sensing products are generally very demanding both in terms of data quality and coverage/revisit time. The MANTIS mission (Mission and Agile Nanosatellite for Terrestrial Imagery Services) is being developed to specifically fulfil those requirements using a compact and agile 12U Cubesat system. MANTIS will embark the iSIM90-12U (integrated Standard Imager for Microsatellites) an innovative high-resolution optical payload for Earth Observation missions developed by Satlantis Microsats SL. The payload consists of a compact binocular telescope specifically designed to fit within a volume of 8U, and thus ideal for 12U CubeSat standard platforms. The design relies on iSIM technology, comprised by the integration of four key technologies: a binocular diffraction-limited optical system working at visible and near-infrared wavelength; a high precision, robust and light structure; a set of innovative COTS detectors with 2D CMOS sensors; and a high-performance and reconfigurable on-board processing unit with super-resolution algorithms implemented. Open Cosmos Ltd. as Prime is responsible for the end-to-end space mission service, including the provision of a new generation 12U spacecraft platform, while Terrabotics Ltd. will analyse and provide data to the end users. The mission is funded by the European Space Agency’s InCubed (Investing in Industrial Innovation) program supporting innovative activities related to Earth Observation enabling European industry to compete commercially in the global marketplace. An overview of the development status of the mission will be presented focusing on the consolidation of the payload design and the mission end products. © 2020 SPIE.","Aerospace industry; Agile manufacturing systems; Binoculars; Earth (planet); Infrared devices; Nanosatellites; Observatories; Optical resolving power; Optical systems; Product design; Space applications; Space flight; Space optics; Binocular telescopes; European Space Agency; Industrial innovation; Innovative activities; Integrated standards; Spacecraft platforms; Super resolution algorithms; Visible and near infrared; Remote sensing","12U cubesat; Earth observation; High-resolution; InCubed; Oil and gas; Optical payload","Conference paper","Final","","Scopus","2-s2.0-85093868129"
"Shi Z.; Lei S.","Shi, Zhenwei (23398841900); Lei, Sen (57195618353)","23398841900; 57195618353","Review of Image Super-Resolution Reconstruction; [图像超分辨重建算法综述]","2020","Shuju Caiji Yu Chuli/Journal of Data Acquisition and Processing","35","1","","1","20","19","10.16337/j.1004-9037.2020.01.001","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081694839&doi=10.16337%2fj.1004-9037.2020.01.001&partnerID=40&md5=723b7ac1013842acabdee9560d64b9c2","Image super-resolution reconstruction is an image processing technology, which recovers high-resolution images from low-resolution images. While, the super-resolution problem is under-determined. In recent years, researchers have proposed learning-based methods to learn image prior information from a large amount of data, in order to constrain the super-resolution solution space. This paper introduces the mainstream image super-resolution reconstruction algorithms in the past two decades, which are divided into two categories: traditional features based methods and deep learning based methods. For the traditional super-resolution reconstruction algorithms, this paper mainly presents the methods based on neighborhood embedding, the methods based on sparse representation, and the methods based on local linear regression. For the deep learning based methods, the super-resolution model design, the up-sampling method and the loss function form are provided. In addition, this paper introduces the application of super-resolution reconstruction technology in video super-resolution, remote-sensing image super-resolution, and high-level vision tasks. Finally, the future development directions of image super-resolution reconstruction technology are provided. © 2020 by Journal of Data Acquisition and Processing.","","Deep learning; Image super-resolution reconstruction; Local linear regression; Neighborhood embedding; Sparse representation","Review","Final","","Scopus","2-s2.0-85081694839"
"Ran Q.; Xu X.; Zhao S.; Li W.; Du Q.","Ran, Qiong (24081122700); Xu, Xiaodong (57195628926); Zhao, Shizhi (57205365672); Li, Wei (56215159000); Du, Qian (7202060063)","24081122700; 57195628926; 57205365672; 56215159000; 7202060063","Remote sensing images super-resolution with deep convolution networks","2020","Multimedia Tools and Applications","79","13-14","","8985","9001","16","10.1007/s11042-018-7091-1","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059739977&doi=10.1007%2fs11042-018-7091-1&partnerID=40&md5=4c9a4c2951a00254a054abd6a6ab4a09","Remote sensing image data have been widely applied in many applications, such as agriculture, military, and land use. It is difficult to obtain remote sensing images in both high spatial and spectral resolutions due to the limitation of implements in image acquisition and the law of energy conservation. Super-resolution (SR) is a technique to improve the resolution from a low-resolution (LR) to a high-resolution (HR). In this paper, a novel deep convolution network (DCN) SR method (SRDCN) is proposed. Based on hierarchical architectures, the proposed SRDCN learns an end-to-end mapping function to reconstruct an HR image from its LR version; furthermore, extensions of SRDCN based on residual learning and multi scale version are investigated for further improvement,namely Developed SRDCN(DSRDCN) and Extensive SRDCN(ESRDCN). Experimental results using different types of remote sensing data (e.g., multispectral and hyperspectral) demonstrate that the proposed methods outperform the traditional sparse representation based methods. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Convolution; Image enhancement; Land use; Military applications; Military photography; Optical resolving power; Convolution neural network; Hierarchical architectures; Law of energy conservation; Remote sensing data; Remote sensing imagery; Remote sensing images; Sparse representation; Super resolution; Remote sensing","Convolution neural network; Remote sensing imagery; Super-resolution","Article","Final","","Scopus","2-s2.0-85059739977"
"Khademi G.; Ghassemian H.","Khademi, Ghassem (56898906800); Ghassemian, Hassan (57204122949)","56898906800; 57204122949","A Variational Pansharpening Algorithm Based on Total Variation and Primal-Dual Optimization","2019","4th International Conference on Pattern Recognition and Image Analysis, IPRIA 2019","","","8786000","64","69","5","10.1109/PRIA.2019.8786000","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071420149&doi=10.1109%2fPRIA.2019.8786000&partnerID=40&md5=27b80be81d7e33e5034dd1dcc5657b46","This paper proposes a variational framework to estimate the high-resolution (HR) multispectral (MS) image from the low-resolution (LR) MS image and the panchromatic (Pan) image. The LR MS image is modeled as a decimation of the HR MS image. Furthermore, the Pan image is considered as a linear combination of the HR MS bands. A super-resolution (SR) model is defined in accordance with the image observation model and the total variation (TV) regularization. The SR reconstruction problem is modeled as a minimization problem, which is solved by an efficient primal-dual algorithm in a Euclidean setting. The result of comparing the proposed method with some recent classical and variational pansharpening methods proves the superiority of the proposed variational pansharpening algorithm. © 2019 IEEE.","Image fusion; Pattern recognition; Remote sensing; Pan-sharpening; Panchromatic (Pan) image; Primal dual algorithms; Primal-dual; Reconstruction problems; Total variation; Total variation regularization; Variational framework; Image analysis","image fusion; pansharpening; primal-dual optimization; remote sensing; total variation","Conference paper","Final","","Scopus","2-s2.0-85071420149"
"Huo X.; Tang R.; Ma L.; Shao K.; Yang Y.","Huo, Xing (36853250800); Tang, Ronglin (35175400200); Ma, Lingling (35216102100); Shao, Kun (7006292928); Yang, YongHua (57203871304)","36853250800; 35175400200; 35216102100; 7006292928; 57203871304","A novel neural network for super-resolution remote sensing image reconstruction","2019","International Journal of Remote Sensing","40","5-6","","2375","2385","10","10.1080/01431161.2018.1516319","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053296401&doi=10.1080%2f01431161.2018.1516319&partnerID=40&md5=b59bbe198e88f3915fe2dea860445348","An accurate super-resolution image (SR image) reconstruction of remote sensing images (RSI) for preserving quality during the process of super-resolution conversion is crucial for many scientific and operational applications. Recent studies on supervised and unsupervised machine learning methodologies of SR image reconstruction have demonstrated their great potential for higher reconstruction performance in obtaining accuracy and quality. In this paper, a novel neural network with barycentric weight function (BWFNN) is proposed as a non-linear mapping function selected from the features of reference images. The whole process includes an online reconstruction phase and an offline training phase. In these phases, an edge orientation-based pre-learned kernel is introduced to describe and reference prior information, and a simple interpolation-like structure is followed to avoid any conventional iterative computation and lead to fast reconstruction. The innovation of this work is the BWFNN, which uses a non-linear barycentric weight function (BWF) to reconstruct the image details. Compared with most of the conventional reconstruction approaches, the proposed algorithm performs better in terms of peak signal-to-noise ratio (PSNR) and structural similarity (SSIM), and the model exhibits significant efficiency in reconstructing the image details. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","Iterative methods; Learning systems; Neural networks; Optical resolving power; Remote sensing; Signal to noise ratio; Iterative computation; Novel neural network; Online reconstruction; Operational applications; Peak Signal to Noise Ratio (PSNR); Remote sensing images; Structural similarity; Unsupervised machine learning; accuracy assessment; algorithm; artificial neural network; data quality; image resolution; innovation; interpolation; remote sensing; Image reconstruction","","Article","Final","","Scopus","2-s2.0-85053296401"
"Wang P.; Zhang H.; Zhou F.; Jiang Z.","Wang, Pengrui (57210155510); Zhang, Haopeng (54788751800); Zhou, Feng (57213191947); Jiang, Zhiguo (35336923600)","57210155510; 54788751800; 57213191947; 35336923600","Unsupervised Remote Sensing Image Super-Resolution Using Cycle CNN","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898648","3117","3120","3","10.1109/IGARSS.2019.8898648","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077695307&doi=10.1109%2fIGARSS.2019.8898648&partnerID=40&md5=d65d663a68d98d22adca16fa73a70420","Single image super-resolution (SISR) is a useful procedure for many remote sensing applications. However, paired high-resolution and low-resolution remote sensing images are actually hard to acquire for supervised learning SR methods. In this paper, we propose an unsupervised network named Cycle-CNN to handle this problem. Our network consists of two generative CNNs for down-sampling and super-resolution separately, and can be trained with unpaired data. Experiments on panchromatic and multi-spectral images of GaoFen-2 satellite indicate that our method achieves state-of-the-art SR results and is robust against noise and blur in the remote sensing images. © 2019 IEEE.","Geology; Optical resolving power; Spectroscopy; Unsupervised learning; High resolution; Low resolution; Multispectral images; Remote sensing applications; Remote sensing images; State of the art; Super resolution; Unsupervised network; Remote sensing","CNN; remote sensing image; super-resolution; unsupervised learning","Conference paper","Final","","Scopus","2-s2.0-85077695307"
"Lin L.; Li J.; Yuan Q.; Shen H.","Lin, Liupeng (57188711703); Li, Jie (57214207213); Yuan, Qiangqiang (36635300800); Shen, Huanfeng (8359721100)","57188711703; 57214207213; 36635300800; 8359721100","Polarimetric SAR Image Super-Resolution VIA Deep Convolutional Neural Network","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898160","3205","3208","3","10.1109/IGARSS.2019.8898160","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077691984&doi=10.1109%2fIGARSS.2019.8898160&partnerID=40&md5=e98a770372f1fe805fadf535b84c43c4","In order to solve the problem of full-polarimetric SAR image degradation, this paper proposes a full-polarimetric SAR image super-resolution reconstruction method combined with a convolutional neural network and residual compensation. Through the advantages of the deep convolutional neural network for nonlinear model fitting, this paper performs super-resolution reconstruction on low-resolution full-polarimetric SAR images, and then applies residual compensation to network reconstruction results, using low-resolution image information to the network. The super-resolution reconstruction results are corrected to obtain a high-resolution full-polarimetric SAR image. Compared with the traditional full-polarimetric SAR image super-resolution reconstruction method, the proposed method shows excellent results in both visual and quantitative evaluation indicators, especially the reconstruction of detailed information. © 2019 IEEE.","Convolution; Convolutional neural networks; Deep neural networks; Geology; Image reconstruction; Optical resolving power; Polarimeters; Remote sensing; Synthetic aperture radar; Low resolution images; Network reconstruction; Nonlinear model fitting; Polarimetric SAR; Quantitative evaluation; Residual learning; Super resolution; Super resolution reconstruction; Radar imaging","Convolutional neural network; Polarimetric SAR; Residual compensation; Residual learning; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85077691984"
"Chang Y.; Luo B.","Chang, Yunpeng (57196027422); Luo, Bin (57209592752)","57196027422; 57209592752","Bidirectional convolutional LSTM neural network for remote sensing image super-resolution","2019","Remote Sensing","11","20","2333","","","","10.3390/rs11202333","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074190624&doi=10.3390%2frs11202333&partnerID=40&md5=65c81c1e1cf6dd3bfa4e0b2ca48b6028","Single-image super-resolution (SR) is an effective approach to enhance spatial resolution for numerous applications such as object detection and classification when the resolution of sensors is limited. Although deep convolutional neural networks (CNNs) proposed for this purpose in recent years have outperformed relatively shallow models, enormous parameters bring the risk of overfitting. In addition, due to the different scale of objects in images, the hierarchical features of deepCNNcontain additional information for SR tasks, while most CNN models have not fully utilized these features. In this paper, we proposed a deep yet concise network to address these problems. Our network consists of two main structures: (1) recursive inference block based on dense connection reuse of local low-level features, and recursive learning is applied to control the model parameters while increasing the receptive fields; (2) a bidirectional convolutional LSTM (BiConvLSTM) layer is introduced to learn the correlations of features from each recursion and adaptively select the complementary information for the reconstruction layer. Experiments on multispectral satellite images, panchromatic satellite images, and nature high-resolution remote-sensing images showed that our proposed model outperformed state-of-the-art methods while utilizing fewer parameters, and ablation studies demonstrated the effectiveness of a BiConvLSTM layer for an image SR task. © 2019 by the authors.","Convolution; Deep neural networks; Image enhancement; Object detection; Object recognition; Optical resolving power; Remote sensing; BiConvLSTM; Convolutional neural network; Dense connection; High resolution remote sensing images; Multispectral satellite image; Recursive neural networks; State-of-the-art methods; Super resolution; Long short-term memory","BiConvLSTM; Dense connection; Recursive neural network; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85074190624"
"Marques A.; Rossa P.; Horota R.K.; Brum D.; De Souza E.M.; Aires A.S.; Kupssinsku L.; Veronez M.R.; Gonzaga L.; Cazarin C.L.","Marques, Ademir (57204879168); Rossa, Pedro (57191039262); Horota, Rafael Kenji (57210920444); Brum, Diego (57205768241); De Souza, Eniuce Menezes (8609297500); Aires, Alyson Soares (57210914749); Kupssinsku, Lucas (57200304800); Veronez, Mauricio Roberto (26023922300); Gonzaga, Luis (56071435800); Cazarin, Caroline Lessio (56094347300)","57204879168; 57191039262; 57210920444; 57205768241; 8609297500; 57210914749; 57200304800; 26023922300; 56071435800; 56094347300","Improving spatial resolution of LANDSAT spectral bands from a single RGB image using artificial neural network","2019","Proceedings of the International Conference on Sensing Technology, ICST","2019-December","","9047670","","","","10.1109/ICST46873.2019.9047670","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083027175&doi=10.1109%2fICST46873.2019.9047670&partnerID=40&md5=6c1cfccf12705f2d1705ba9a173d060e","Spectral information provided by multispectral and hyperspectral sensors has a great impact on remote sensing studies. These sensors are embedded in aircrafts and satellites like the Landsat, which has more data freely available but lack the spatial resolution that suborbital sensors have. To increase the spatial resolution, a series of techniques have been developed like pansharpenning data fusion and more advanced convolutional neural networks for super-resolution, however, the later requires large datasets. To overcome this requirement, this work aims to increase the spatial resolution of Landsat spectral bands using artificial neural networks that uses pixel kernels of a single high-resolution image from Google Earth. Using this method, the high-resolution spectral bands were generated with pixel size of 1m in contrast to the 15m of pansharpenned Landsat bands. The evaluate the predicted spectral bands the validation measures Universal Quality Index (UQI) and Spectral Angle Mapper (SAM) were used, showing values of 0.98 and 0.16 respectively, presenting good results. © 2019 IEEE.","Convolutional neural networks; Data fusion; Image resolution; Large dataset; Pixels; Remote sensing; High resolution; High resolution image; Hyperspectral sensors; Quality indices; Spatial resolution; Spectral angle mappers; Spectral information; Super resolution; Image enhancement","Artificial Neural Networks; High resolution; Landsat; Multispectral; Prediction; Spatial resolution","Conference paper","Final","","Scopus","2-s2.0-85083027175"
"Zhang Y.; Zhang Y.; Mao D.; Kang Y.; Zhang Y.; Yang J.","Zhang, Yongwei (57207478944); Zhang, Yongchao (56042343300); Mao, Deqing (57194656090); Kang, Yao (57211242158); Zhang, Yin (55975581400); Yang, Jianyu (9239230100)","57207478944; 56042343300; 57194656090; 57211242158; 55975581400; 9239230100","Beam-Recursive Iterative Adaptive Approach for Scanning Radar Angular Superresolution","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8899814","9145","9148","3","10.1109/IGARSS.2019.8899814","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077687364&doi=10.1109%2fIGARSS.2019.8899814&partnerID=40&md5=2aaa18a1254634b80ccded26f30861e1","Angular resolution of scanning radar is constrained by the size of antenna aperture. Such coarse resolution can not satisfy the applications of microwave remote sensing that require high resolution. Iterative adaptive approach (IAA) is a recently introduced method for scanning radar angular super-resolution, which could notably improve the angular resolution and suppress the noise amplification. In this paper, we further this development, by presenting a beam-recursive I-AA, allowing for adjusting the regularization parameter adaptively and dynamically for varying scenario. Such implementation could effectively eliminate the artifacts on background when applying the batch IAA to resolve closely spaced strong targets. Moreover, the technique offers a promising potential that deserves further attention on computationally efficient implementation and real-time imaging along antenna beam scanning. Simulations are provided to validate the effectiveness of the proposed approach. © 2019 IEEE.","Geology; Iterative methods; Optical resolving power; Radar; Radar antennas; Scanning; Scanning antennas; Angular resolution; beam-recursive; Computationally efficient; Iterative adaptive approaches (IAA); Microwave remote sensing; Noise amplification; Regularization parameters; Scanning radar; Remote sensing","angular resolution; beam-recursive; iterative adaptive approach; Scanning radar","Conference paper","Final","","Scopus","2-s2.0-85077687364"
"Gargiulo M.; Mazza A.; Gaetano R.; Ruello G.; Scarpa G.","Gargiulo, Massimiliano (57200856555); Mazza, Antonio (57200854745); Gaetano, Raffaele (23491959900); Ruello, Giuseppe (6603038881); Scarpa, Giuseppe (7004081145)","57200856555; 57200854745; 23491959900; 6603038881; 7004081145","Fast super-resolution of 20 m Sentinel-2 bands using convolutional neural networks","2019","Remote Sensing","11","22","2635","","","","10.3390/rs11222635","34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075367036&doi=10.3390%2frs11222635&partnerID=40&md5=c70e6bcf1ebf436f61ec5327ae6aacf7","Images provided by the ESA Sentinel-2 mission are rapidly becoming the main source of information for the entire remote sensing community, thanks to their unprecedented combination of spatial, spectral and temporal resolution, as well as their associated open access policy. Due to a sensor design trade-off, images are acquired (and delivered) at different spatial resolutions (10, 20 and 60 m) according to specific sets of wavelengths, with only the four visible and near infrared bands provided at the highest resolution (10 m). Although this is not a limiting factor in general, many applications seem to emerge in which the resolution enhancement of 20 m bands may be beneficial, motivating the development of specific super-resolution methods. In this work, we propose to leverage Convolutional Neural Networks (CNNs) to provide a fast, upscalable method for the single-sensor fusion of Sentinel-2 (S2) data, whose aim is to provide a 10 m super-resolution of the original 20 m bands. Experimental results demonstrate that the proposed solution can achieve better performance with respect to most of the state-of-the-art methods, including other deep learning based ones with a considerable saving of computational burden. © 2019 by the authors.","Convolution; Data fusion; Deep learning; Economic and social effects; Infrared devices; Neural networks; Optical resolving power; Remote sensing; Computational burden; Convolutional neural network; Land-cover classification; Pan-sharpening; Resolution enhancement; State-of-the-art methods; Superresolution methods; Visible and near infrared; Sensor data fusion","Convolutional neural network; Data fusion; Landcover classification; Multi-resolution analysis; Pansharpening","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85075367036"
"Mao D.; Zhang Y.; Zhang Y.; Yu C.; Yang X.; Yang J.","Mao, Deqing (57194656090); Zhang, Yin (55975581400); Zhang, Yongchao (56042343300); Yu, Chenxi (57213192775); Yang, Xiaobo (16557266900); Yang, Jianyu (9239230100)","57194656090; 55975581400; 56042343300; 57213192775; 16557266900; 9239230100","Stochastic Radiation Radar 3-D High Resolution Imaging Technique","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898816","3673","3676","3","10.1109/IGARSS.2019.8898816","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077694578&doi=10.1109%2fIGARSS.2019.8898816&partnerID=40&md5=32dacd61dcc974ee7d07048f0f3083d7","Scene surveillance radar, which generates radar stochastic radiation field with time and space to obtain more observation information, plays a significant role in disaster monitoring and environmental security. To explore its three-dimensional (3-D) imaging capabilities, in this paper, we propose an echo rearrangement super-resolution imaging method to achieve 3D high resolution imaging for SRR. Because the echo of SRR is uncorrelated along sampling time, we adjust the conventional intrapulse frequency hopping to interpulse frequency hopping. In this way, the proposed method can improve the imaging resolution by echo rearrangement utilizing the noncorrelation with time of stochastic radiation field. The 3-D image provides the scene reflectivity estimation along polar coordinate system including pitch, azimuth and space distance. Simulation results are given to illustrate the performance of the proposed method. © 2019 IEEE.","Frequency hopping; Geology; Imaging techniques; Remote sensing; Space optics; Space-based radar; Stochastic systems; Surveillance radar; 3D imaging; Environmental security; High-resolution imaging; Observation information; Polar coordinate systems; Resolution improvement; Super resolution imaging; Three dimensional (3-D) imaging; Radar imaging","3-D imaging; resolution improvement; Stochastic radiation radar","Conference paper","Final","","Scopus","2-s2.0-85077694578"
"Belov A.; Denisova A.","Belov, Alexander (35482106000); Denisova, Anna (42160925300)","35482106000; 42160925300","Super-Resolution Reconstruction of Remote Sensing Image Using Multi-Temporal Images with Partial Scene Distortions","2020","Proceedings of ITNT 2020 - 6th IEEE International Conference on Information Technology and Nanotechnology","","","9253307","","","","10.1109/ITNT49337.2020.9253307","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097632766&doi=10.1109%2fITNT49337.2020.9253307&partnerID=40&md5=323380908363aa8af1ab809356def283","Earth remote sensing data obtained by various sensors are usually different in spatial and spectral resolution and in the registration time as well. Changes in observation conditions lead to brightness distortions, some of which are compensated by atmospheric correction. Unfortunately, the distortions in the composition of the scene (scene distortions) cannot be compensated using atmospheric correction and require fusion methods to be applied. The existing superresolution methods for remote sensing data are based on the assumption that there are no scene distortions in the analyzed images. In this article, we propose an algorithm for combining Earth remote sensing data with an increase in the spectral and spatial resolution taking into account scene distortions. We found that the use of a larger dataset including images with scene distortions reduces root mean square error of 2-4% on average if the dataset contains a small number of images without scene distortions (from 2 to 6). With the larger number of images without scene distortions, the error value decreases by 1%. If all the images in the input dataset contain scene distortions, the proposed algorithm achieves super-resolution restoration of the scene image as well. © 2020 IEEE.","Mean square error; Nanotechnology; Optical resolving power; Remote sensing; Atmospheric corrections; Multi-temporal image; Observation condition; Remote sensing images; Root mean square errors; Super resolution reconstruction; Super-resolution restoration; Superresolution methods; Image reconstruction","remote sensing images; scene distortions; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85097632766"
"Shi W.; Guo C.; Tong X.; Tian Y.; Cao W.","Shi, Wenjun (57189354468); Guo, Congzhou (57126632400); Tong, Xiaochong (56270028800); Tian, Yuan (57207833726); Cao, Wen (57225815357)","57189354468; 57126632400; 56270028800; 57207833726; 57225815357","Super-resolution reconstruction of infrared remote sensing images with radiation fidelity; [辐射保真的红外遥感图像超分辨率重建]","2019","Xi'an Dianzi Keji Daxue Xuebao/Journal of Xidian University","46","2","","107","113","6","10.19665/j.issn1001-2400.2019.02.018","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067255457&doi=10.19665%2fj.issn1001-2400.2019.02.018&partnerID=40&md5=02c69850ea01161eef24f70c808bb89e","In order to overcome the contradiction between the super resolution reconstruction of an infrared remote sensing image and the fidelity of radiometric calibration, combined with the theory of regularized super-resolution reconstruction, a super resolution reconstruction model based on two-order total generalized variation is established. Through the analysis of the characteristics of the reconstruction model, the ADMM algorithm is introduced to solve the numerical solution. In the reconstruction process, the bilateral high-frequency filter is used to separate the high and low frequency information of the image, and after separation only the high frequency information image is dealt with. Finally, the low frequency information image and the reconstructed high frequency information image are fused to achieve super resolution. Experimental verification and quantitative analysis of the FY-4 meteorological satellite infrared image show that the influence of this method on radiometric calibration is less than that of conventional super resolution reconstruction. © 2019, The Editorial Board of Journal of Xidian University. All right reserved.","Calibration; Infrared imaging; Optical resolving power; Radiometry; Remote sensing; Alternating directions method of multipliers; Experimental verification; Generalized variation; High-frequency informations; Infrared remote sensing; Radiometric calibrations; Reconstruction process; Super resolution reconstruction; Image reconstruction","Alternating directions method of multipliers; High frequency information image; Radiation fidelity; Super-resolution reconstruction; Two order generalized variation","Article","Final","","Scopus","2-s2.0-85067255457"
"Zhang Y.; Zong R.; Han J.; Zhang D.; Rashid T.; Wang D.","Zhang, Yang (57191071243); Zong, Ruohan (57215609256); Han, Jun (57209633331); Zhang, Daniel (57212579276); Rashid, Tahmid (57190247003); Wang, Dong (55574213902)","57191071243; 57215609256; 57209633331; 57212579276; 57190247003; 55574213902","TransRes: A Deep Transfer Learning Approach to Migratable Image Super-Resolution in Remote Urban Sensing","2020","Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks workshops","","","9158410","","","","10.1109/SECON48991.2020.9158410","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091995745&doi=10.1109%2fSECON48991.2020.9158410&partnerID=40&md5=1375f22ac03f0f3375bb2e17e3cbcadf","Recent advances in remote sensing provide a powerful and scalable sensing paradigm to capture abundant visual information about the urban environments. We refer to such a sensing paradigm as remote urban sensing. In this paper, we focus on a migratable satellite image super-resolution problem in remote urban sensing applications. Our goal is to reconstruct satellite images of a high resolution in a target area where the high-resolution training data is not available by transferring a super-resolution model learned in a source area where such data is available. This problem is motivated by the limitation of current solutions that primarily rely on a rich set of high-resolution satellite images in the studied area that are not always available. Two important challenges exist in solving our problem: i) the target and source areas often have very different urban characteristics that prevent the direct application of a super-resolution model learned from the source area to the target area; ii) it is not a trivial task to ensure effective model migration with desirable quality without sufficient high quality training data. To address the above challenges, we develop TransRes, a deep adversarial transfer learning framework, to effectively reconstruct high-resolution satellite images without requiring any ground-truth training data from the studied area. We evaluate the TransRes framework using the real-world satellite imagery data collected from three different cities in Europe. The results show that TransRes consistently outperforms the state-of-the-art baselines by achieving the lowest perception errors under various application scenarios.  © 2020 IEEE.","Image reconstruction; Optical resolving power; Remote sensing; Satellite imagery; Transfer learning; Application scenario; High resolution satellite images; Image super resolutions; Learning frameworks; Satellite imagery data; Super-resolution models; Urban characteristics; Urban environments; Deep learning","Migratable Image Super-Resolution; Remote Sensing; Transfer Learning; Urban Sensing","Conference paper","Final","","Scopus","2-s2.0-85091995745"
"Guilloteau C.; Oberlin T.; Berne O.; Dobigeon N.","Guilloteau, Claire (57217632445); Oberlin, Thomas (55193333000); Berne, Olivier (23396135600); Dobigeon, Nicolas (12752292500)","57217632445; 55193333000; 23396135600; 12752292500","Hyperspectral and Multispectral Image Fusion under Spectrally Varying Spatial Blurs - Application to High Dimensional Infrared Astronomical Imaging","2020","IEEE Transactions on Computational Imaging","6","","9199293","1362","1374","12","10.1109/TCI.2020.3022825","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092173319&doi=10.1109%2fTCI.2020.3022825&partnerID=40&md5=f9950a407149abfa33b4b4831f221f4d","Hyperspectral imaging has become a significant source of valuable data for astronomers over the past decades. Current instrumental and observing time constraints allow direct acquisition of multispectral images, with high spatial but low spectral resolution, and hyperspectral images, with low spatial but high spectral resolution. To enhance scientific interpretation of the data, we propose a data fusion method which combines the benefits of each image to recover a high spatio-spectral resolution datacube. The proposed inverse problem accounts for the specificities of astronomical instruments, such as spectrally variant blurs. We provide a fast implementation by solving the problem in the frequency domain and in a low-dimensional subspace to efficiently handle the convolution operators as well as the high dimensionality of the data. We conduct experiments on a realistic synthetic dataset of simulated observation of the upcoming James Webb Space Telescope, and we show that our fusion algorithm outperforms state-of-the-art methods commonly used in remote sensing for Earth observation. © 2015 IEEE.","Earth (planet); Frequency domain analysis; Hyperspectral imaging; Image enhancement; Inverse problems; Remote sensing; Space optics; Space telescopes; Spectral resolution; Spectroscopy; Astronomical instrument; Convolution operators; High spectral resolution; James Webb space telescope; Low-dimensional subspace; Multi-spectral image fusions; Multispectral images; State-of-the-art methods; Image fusion","Data fusion; deconvolution; high dimensional imaging; hyperspectral imaging; infrared astronomy; super-resolution","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85092173319"
"Rohith G.; Kumar L.S.","Rohith, G. (57217188288); Kumar, Lakshmi Sutha (35778418900)","57217188288; 35778418900","Super-resolution based deep learning techniques for panchromatic satellite images in application to pansharpening","2020","IEEE Access","8","","","162099","162121","22","10.1109/ACCESS.2020.3020978","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096696559&doi=10.1109%2fACCESS.2020.3020978&partnerID=40&md5=4b39210339c9e31aaed03250b9e191bf","Pansharpening is a technique that fuses the coarser resolution of multispectral imagery (MS) with high spatial resolution panchromatic (PAN) imagery. Pansharpening is prone to spectral distortions based on the nature of the panchromatic band. If the spatial features are unclear in the panchromatic image, the pan-sharpened image will not be able to produce clear images. Super-Resolution (SR) is a technique that enhances minute details of the features in the image, thereby improving spatial information in the image. By fusing the Multispectral image with the super-resolved panchromatic image, there is a chance for producing high-quality multispectral imagery (pan-sharpened image). In this paper, ten state-of-the-art super-resolution based on deep learning techniques are tested and analyzed using ten different publicly available panchromatic datasets. On analysis, a feedback network for image super-resolution (SRFBN) technique outperforms the other algorithms in terms of sharp edges and pattern clarity, which are not visible in the input image. The proposed method is the fusion of SR applied PAN image with the MS image using a benchmarked Band Depended Spatial Detail (BDSD) pansharpening algorithm. The proposed method experiments with six datasets from different sensors. On analysis, the proposed technique outperforms the other counterpart pansharpening algorithms in terms of enhanced spatial information in addition to sharp edges and pattern clarity at reduced spectral distortion. Hence, the super-resolution based pansharpening algorithm is recommended for high spatial image applications. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Deep learning; Edge detection; Learning systems; Optical resolving power; Remote sensing; Vector quantization; High spatial resolution; Image super resolutions; Learning techniques; Multi-spectral imagery; Multispectral images; Panchromatic satellites; Spatial informations; Spectral distortions; Image enhancement","Convolution neural networks (CNN); Deep Learning (DL); Pansharpening applications","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85096696559"
"Mullah H.U.; Deka B.","Mullah, Helal Uddin (57188860954); Deka, Bhabesh (49663267700)","57188860954; 49663267700","Parallel Multispectral Image Super-resolution Based on Sparse Representations","2019","Proceedings of 2nd International Conference on Innovations in Electronics, Signal Processing and Communication, IESC 2019","","","8902436","104","109","5","10.1109/IESPC.2019.8902436","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075890258&doi=10.1109%2fIESPC.2019.8902436&partnerID=40&md5=799dfdffa17ffbdfa5478f610df23c63","Image super-resolution (SR) produces a high-resolution (HR) image using either a single or multiple low-resolution (LR) input image(s) of the same scene. Sparse representation techniques are effectively applied for image SR because of their high reconstruction accuracy. SR reconstruction is accomplished through learning of an overcomplete dictionary and then solving a series of regularization problems applied on each patch extracted from the input image. This paper demonstrates a sparse representation based coupled overcomplete dictionary training and SR procedure for LR multispectral images. The proposed work is also implemented using a multicore parallel processing technique to provide faster reconstruction. Experimental results show superiority of the proposed method over some others. © 2019 IEEE.","Optical resolving power; Remote sensing; High resolution image; Image super resolutions; Multi-core processing; Multispectral images; Over-complete dictionaries; Reconstruction accuracy; Sparse representation; Super resolution; Image reconstruction","multi-core processing; remote sensing; sparse representation; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85075890258"
"Belov A.; Denisova A.","Belov, Alexander (35482106000); Denisova, Anna (42160925300)","35482106000; 42160925300","Remote sensing classification using multi-sensor super-resolution algorithm","2020","Proceedings of the 14th IADIS International Conference Computer Graphics, Visualization, Computer Vision and Image Processing 2020, CGVCVIP 2020 and Proceedings of the 5th IADIS International Conference Big Data Analytics, Data Mining and Computational Intelligence 2020, BigDaCI 2020 and Proceedings of the 9th IADIS International Conference Theory and Practice in Modern Computing 2020, TPMC 2020 - Part of the 14th Multi Conference on Computer Science and Information Systems, MCCSIS 2020","","","","131","140","9","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101060658&partnerID=40&md5=6d3b6ea73337316fbd77cb65c0979252","Super-resolution image fusion aims to produce an image with finer spectral and spatial details than the input images. However, the super-resolution fusion is mainly applied to enhance a visual representation of the images and its potential benefits to the final thematic classification is an open question. In this paper, we present an experimental investigation of the remote sensing image classification performance in the case of the multi-sensor super-resolution image fusion. The research aims to compare classification performance obtained for the fused image and the low resolution input ones using different standard-of-the-art classifiers and feature extraction methods. Input data are supposed to be multispectral data obtained in visible and near infrared spectral ranges by the different remote sensing systems. To perform a multi-sensor super-resolution image fusion, we used a gradient-descent optimization approach with a B-TV regularization successfully adapted for remote sensing images with different spatial and spectral sampling characteristics by the authors of the paper. As for features, we applied brightness in spectral channels, attribute profiles and local feature attribute profiles. The classification was performed using support vector machines and random forest classifiers that have been proved to be very effective for remote sensing data classification. The experimental research included the multi-sensor input data simulation for four remote sensing systems, the super-resolution image fusion of all simulated images and the thematic classification of the fused image and the images obtained as an average input for each of the simulated imaging systems. The spatial resolution of the fused image was in 2, 3, 4 and 5 times better than the spatial resolution of the modeled input images. The average bandwidth of the fused image was 29 nm whereas for the input low resolution images it was in the range from 37 to 83 nm. Experimental results have shown that random forest classification is better to use with fusion, whereas support vector machines demonstrated better results without fusion. The feature extraction test showed that extended attribute profiles enhance the random forest classification accuracy of the fused image. Thus, the classification results have shown that super-resolution image fusion leads to the classification accuracy increase in the case of random forest classifier and there is no need to apply fusion in the case of support vector machines. © Proceedings of the 14th IADIS International Conference Computer Graphics, Visualization, Computer Vision and Image Processing 2020, CGVCVIP 2020 and Proceedings of the 5th IADIS International Conference Big Data Analytics, Data Mining and Computational Intelligence 2020, BigDaCI 2020 and Proceedings of the 9th IADIS International Conference Theory and Practice in Modern Computing 2020, TPMC 2020 - Part of the 14th Multi Conference on Computer Science and Information Systems, MCCSIS 2020. All rights reserved.","Advanced Analytics; Big data; Classification (of information); Computation theory; Computer vision; Data mining; Data visualization; Decision trees; Extraction; Feature extraction; Gradient methods; Image enhancement; Image fusion; Image resolution; Information systems; Information use; Infrared devices; Input output programs; Intelligent computing; Optical resolving power; Random forests; Remote sensing; Sensor data fusion; Support vector machines; Visualization; Experimental investigations; Extended attribute profiles; Gradient descent optimization; Random forest classification; Remote sensing classification; Remote sensing image classification; Remote-sensing data classification; Super resolution algorithms; Image classification","Data fusion; Image classification; RF; Super-resolution; SVM","Conference paper","Final","","Scopus","2-s2.0-85101060658"
"Bordone Molini A.; Valsesia D.; Fracastoro G.; Magli E.","Bordone Molini, Andrea (57216561661); Valsesia, Diego (55968886600); Fracastoro, Giulia (56344146600); Magli, Enrico (7003771643)","57216561661; 55968886600; 56344146600; 7003771643","DeepSUM: Deep Neural Network for Super-Resolution of Unregistered Multitemporal Images","2020","IEEE Transactions on Geoscience and Remote Sensing","58","5","8946717","3644","3656","12","10.1109/TGRS.2019.2959248","65","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081259042&doi=10.1109%2fTGRS.2019.2959248&partnerID=40&md5=89c681b99d5712d647e239708b1d17bc","Recently, convolutional neural networks (CNNs) have been successfully applied to many remote sensing problems. However, deep learning techniques for multi-image super-resolution (SR) from multitemporal unregistered imagery have received little attention so far. This article proposes a novel CNN-based technique that exploits both spatial and temporal correlations to combine multiple images. This novel framework integrates the spatial registration task directly inside the CNN, and allows one to exploit the representation learning capabilities of the network to enhance registration accuracy. The entire SR process relies on a single CNN with three main stages: shared 2-D convolutions to extract high-dimensional features from the input images; a subnetwork proposing registration filters derived from the high-dimensional feature representations; 3-D convolutions for slow fusion of the features from multiple images. The whole network can be trained end-to-end to recover a single high-resolution image from multiple unregistered low-resolution images. The method presented in this article is the winner of the PROBA-V SR challenge issued by the European Space Agency (ESA). © 1980-2012 IEEE.","Convolution; Convolutional neural networks; Deep learning; Optical resolving power; Remote sensing; European Space Agency; High dimensional feature; High resolution image; Learning capabilities; Low resolution images; Registration accuracy; Spatial and temporal correlation; Spatial registrations; accuracy assessment; artificial neural network; image resolution; remote sensing; Deep neural networks","Convolutional neural networks (CNNs); dynamic filter networks; multi-image super resolution (MISR); multitemporal images","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85081259042"
"Jia Y.; Ge Y.; Chen Y.; Li S.; Heuvelink G.B.M.; Ling F.","Jia, Yuanxin (57171309000); Ge, Yong (26655529300); Chen, Yuehong (56084228300); Li, Sanping (35113507200); Heuvelink, Gerard B.M. (6603849280); Ling, Feng (56278268300)","57171309000; 26655529300; 56084228300; 35113507200; 6603849280; 56278268300","Super-resolution land cover mapping based on the convolutional neural network","2019","Remote Sensing","11","15","1815","","","","10.3390/rs11151815","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070471922&doi=10.3390%2frs11151815&partnerID=40&md5=6a2dd07c30974b06f2f958a07ceb2c52","Super-resolution mapping (SRM) is used to obtain fine-scale land cover maps from coarse remote sensing images. Spatial attraction, geostatistics, and using prior geographic information are conventional approaches used to derive fine-scale land cover maps. As the convolutional neural network (CNN) has been shown to be effective in capturing the spatial characteristics of geographic objects and extrapolating calibrated methods to other study areas, it may be a useful approach to overcome limitations of current SRM methods. In this paper, a new SRM method based on the CNN (SRMCNN) is proposed and tested. Specifically, an encoder-decoder CNN is used to model the nonlinear relationship between coarse remote sensing images and fine-scale land cover maps. Two real-image experiments were conducted to analyze the effectiveness of the proposed method. The results demonstrate that the overall accuracy of the proposed SRMCNN method was 3% to 5% higher than that of two existing SRM methods. Moreover, the proposed SRMCNN method was validated by visualizing output features and analyzing the performance of different geographic objects. © 2019 by the authors.","Convolution; Neural networks; Optical resolving power; Remote sensing; Convolutional neural network; Geographic information; Land cover; Non-linear relationships; Remote sensing imagery; Remote sensing images; Spatial characteristics; Super-resolution mappings; Mapping","Convolutional neural network; Land cover; Remote sensing imagery; Super-resolution mapping","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85070471922"
"Qin M.; Hu L.; Du Z.; Gao Y.; Qin L.; Zhang F.; Liu R.","Qin, Mengjiao (57193907473); Hu, Linshu (57215775327); Du, Zhenhong (25929119800); Gao, Yi (57217281384); Qin, Lianjie (57195495714); Zhang, Feng (56434720200); Liu, Renyi (55809641900)","57193907473; 57215775327; 25929119800; 57217281384; 57195495714; 56434720200; 55809641900","Achieving higher resolution lake area from remote sensing images through an unsupervised deep learning super-resolution method","2020","Remote Sensing","12","12","1937","","","","10.3390/rs12121937","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086984687&doi=10.3390%2frs12121937&partnerID=40&md5=a1ca40b811fb6d11d18363594e87dd5f","Lakes have been identified as an important indicator of climate change and a finer lake area can better reflect the changes. In this paper, we propose an effective unsupervised deep gradient network (UDGN) to generate a higher resolution lake area from remote sensing images. By exploiting the power of deep learning, UDGN models the internal recurrence of information inside the single image and its corresponding gradient map to generate images with higher spatial resolution. The gradient map is derived from the input image to provide important geographical information. Since the training samples are only extracted from the input image, UDGN can adapt to different settings per image. Based on the superior adaptability of the UDGN model, two strategies are proposed for super-resolution (SR) mapping of lakes from multispectral remote sensing images. Finally, Landsat 8 and MODIS (moderate-resolution imaging spectroradiometer) images from two study areas on the Tibetan Plateau in China were used to evaluate the performance of UDGN. Compared with four unsupervised SR methods, UDGN obtained the best SR results as well as lake extraction results in terms of both quantitative and visual aspects. The experiments prove that our approach provides a promising way to break through the limitations of median-low resolution remote sensing images in lake change monitoring, and ultimately support finer lake applications. © 2020 by the authors.","Climate change; Lakes; Learning systems; Optical resolving power; Radiometers; Remote sensing; Geographical information; Gradient networks; Higher resolution; Moderate resolution imaging spectroradiometer; Multispectral remote sensing image; Remote sensing images; Spatial resolution; Superresolution methods; Deep learning","Gradient map; Lake; Remote sensing; Residual network; Unsupervised super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85086984687"
"Gu S.; Yan S.; Zhou H.; Gong J.","Gu, Sijia (57211803153); Yan, SongHua (8633609400); Zhou, Hui (56149427600); Gong, Jianya (57204201392)","57211803153; 8633609400; 56149427600; 57204201392","Super-resolution imaging based on the BeiDou B3 signal","2020","International Journal of Remote Sensing","41","6","","2339","2358","19","10.1080/01431161.2019.1688417","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075067750&doi=10.1080%2f01431161.2019.1688417&partnerID=40&md5=c36bca3545e56be7d75eca01df59c8e6","Using global navigation satellites to construct bi-static synthetic aperture radar for imaging has been a major research hotspot in passive radar. However, the low range resolution of Global Navigation Satellite signal (GNSS) limits the quality of actual scene imaging. To increase the range resolution of the imaging, a super-resolution imaging method by mixing the back-projection (BP) algorithm with truncated singular value decomposition (TSVD) is proposed. This paper first introduces the BeiDou Navigation Satellite System (BDS) signal model for ground imaging, carries out the range compression and describes the BP algorithm. Subsequently, the super-resolution method is given and some simulation results are demonstrated. Two field experimental cases, including targets of trees and ferries, are then carried out. The experimental results demonstrate the effectiveness of the proposed method. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Optical resolving power; Radar imaging; Radio navigation; Satellites; Singular value decomposition; Synthetic aperture radar; Backprojection algorithms; Beidou navigation satellite systems; Global navigation satellites; Range compression; Range resolution; Super resolution imaging; Superresolution methods; Truncated singular value decomposition; accuracy assessment; algorithm; back propagation; decomposition analysis; GNSS; numerical model; remote sensing; satellite data; satellite imagery; spatial resolution; Space-based radar","","Article","Final","","Scopus","2-s2.0-85075067750"
"Junior A.M.; de Souza E.M.; Müller M.; Brum D.; Zanotta D.C.; Horota R.K.; Kupssinskü L.S.; Veronez M.R.; Gonzaga L., Jr.; Cazarin C.L.","Junior, Ademir Marques (57204879168); de Souza, Eniuce Menezes (8609297500); Müller, Marianne (57217226864); Brum, Diego (57205768241); Zanotta, Daniel Capella (53165456900); Horota, Rafael Kenji (57210920444); Kupssinskü, Lucas Silveira (57200304800); Veronez, Maurício Roberto (26023922300); Gonzaga, Luiz (56071435800); Cazarin, Caroline Lessio (56094347300)","57204879168; 8609297500; 57217226864; 57205768241; 53165456900; 57210920444; 57200304800; 26023922300; 56071435800; 56094347300","Improving spatial resolution of multispectral rock outcrop images using rgb data and artificial neural networks","2020","Sensors (Switzerland)","20","12","3559","1","28","27","10.3390/s20123559","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086881203&doi=10.3390%2fs20123559&partnerID=40&md5=23689335281803e46ca4cbad6ad3d3c4","Spectral information provided by multispectral and hyperspectral sensors has a great impact on remote sensing studies, easing the identification of carbonate outcrops that contribute to a better understanding of petroleum reservoirs. Sensors aboard satellites like Landsat series, which have data freely available usually lack the spatial resolution that suborbital sensors have. Many techniques have been developed to improve spatial resolution through data fusion. However, most of them have serious limitations regarding application and scale. Recently Super-Resolution (SR) convolution neural networks have been tested with encouraging results. However, they require large datasets, more time and computational power for training. To overcome these limitations, this work aims to increase the spatial resolution of multispectral bands from the Landsat satellite database using a modified artificial neural network that uses pixel kernels of a single spatial high-resolution RGB image from Google Earth as input. The methodology was validated with a common dataset of indoor images as well as a specific area of Landsat 8. Different downsized scale inputs were used for training where the validation used the ground truth of the original size images, obtaining comparable results to the recent works. With the method validated, we generated high spatial resolution spectral bands based on RGB images from Google Earth on a carbonated outcrop area, which were then properly classified according to the soil spectral responses making use of the advantage of a higher spatial resolution dataset. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Data fusion; Image resolution; Large dataset; Neural networks; Petroleum reservoir engineering; Petroleum reservoirs; Remote sensing; Computational power; Convolution neural network; High spatial resolution; Hyperspectral sensors; Landsat satellite; Spatial resolution; Spectral information; Spectral response; Image enhancement","Artificial neural network; CAVE; Classification; High resolution; Landsat; Multispectral; Prediction; Super-Resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85086881203"
"Wang J.; Tong Z.; Hu C.; Xu M.; Huang Z.","Wang, Jian (57214694493); Tong, Zhishen (57202690738); Hu, Chenyu (57202688718); Xu, Mengchu (57215085067); Huang, Zengfeng (42261693300)","57214694493; 57202690738; 57202688718; 57215085067; 42261693300","Some Mathematical Problems in Ghost Imaging; [鬼成像中一些数学问题]","2020","Guangxue Xuebao/Acta Optica Sinica","40","1","0111007","","","","10.3788/AOS202040.0111007","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079846111&doi=10.3788%2fAOS202040.0111007&partnerID=40&md5=608f2b2d75ccd64016da763f3e72aea0","Ghost imaging (GI) is a novel imaging technique which is different from conventional imaging techniques, which extracts image information via high-order correlation of light-field fluctuations. In recent years, compared with conventional imaging techniques, GI has some advantages such as high sensitivity, super-resolution ability and anti-scattering, which make it widely studied in remote sensing, multi-spectral imaging, thermal X-ray diffraction imaging, and other fields. With these developments, mathematical theory and methods play a more prominent role in GI. For example, based on compressed sensing (CS) theory, we can optimize the sampling mode of GI system, design the algorithm of image reconstruction and analyze the quality of image reconstruction. In this paper, we discuss a few interesting mathematical problems in GI, including preconditioning, optimization of light fields, and phase retrieval. Studying these problems can be useful for enriching the theory of GI and promoting its practical applications. © 2020, Chinese Lasers Press. All right reserved.","Image reconstruction; Imaging systems; Remote sensing; Spectroscopy; Ghost imaging; High order correlation; Light fields; Mathematical problems; Multispectral imaging; Novel imaging techniques; Phase retrieval; Preconditioning; Imaging techniques","Ghost imaging; Imaging systems; Optimization of light fields; Phase retrieval; Preconditioning","Review","Final","","Scopus","2-s2.0-85079846111"
"Arun P.V.; Buddhiraju K.M.; Porwal A.; Chanussot J.","Arun, P.V. (57202034266); Buddhiraju, K.M. (36815713200); Porwal, A. (9738526000); Chanussot, J. (6602159365)","57202034266; 36815713200; 9738526000; 6602159365","CNN based spectral super-resolution of remote sensing images","2020","Signal Processing","169","","107394","","","","10.1016/j.sigpro.2019.107394","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075757910&doi=10.1016%2fj.sigpro.2019.107394&partnerID=40&md5=ddd75072ded69072a2cf86eb5a29074f","The spectral super-resolution techniques attempt to re-project spectrally coarse images to a set of finer wavelength bands. However, complexity of the mapping between coarser and finer scale spectra, large variability of spectral signatures, and the difficulty in simultaneously modeling spatial and spectral contexts make the problem highly ill-posed. Our main hypothesis is that the consideration of spatial as well as spectral aspects is essential for spectral enhancement of remote sensing images. In this regard, this paper proposes a framework consisting of sparse-coding-based pixel-spectra enhancement, collaborative unmixing, and spatial-spectral prior based transformation. Two sparse-coding-based architectures are proposed to project the coarser scale pixel-spectra to the target scale. These models facilitate simultaneous optimization of sparse codes and dictionaries with regard to the spectral super-resolution objective. A CNN based encoding-decoding architecture is explored to model the spatial-spectral prior for improving fidelity of the reconstructions. The endmember similarities and spectral image prior are considered while designing the proposed loss functions. The experiments, over standard as well as AVIRIS-NG and drone-derived datasets, confirm better accuracy of the proposed frameworks as compared to the prominent approaches. In addition, the proposed CNN models for spectral upscaling and spatial-spectral transformation are found to be less sensitive to the variation in network parameter values. © 2019","Image enhancement; Network architecture; Optical resolving power; Pixels; Remote sensing; Spectroscopy; HyperSpectral; Remote sensing images; Simultaneous optimization; Spectra enhancement; Spectral enhancement; Spectral signature; Spectral transformations; Super resolution; Photomapping","Hyperspectral; Remote sensing; Spectral-super-resolution","Article","Final","","Scopus","2-s2.0-85075757910"
"Pereira M.B.; Santos J.A.D.","Pereira, Matheus B. (57212556072); Santos, Jefersson A. Dos (36136174500)","57212556072; 36136174500","An End-To-End Framework for Low-Resolution Remote Sensing Semantic Segmentation","2020","2020 IEEE Latin American GRSS and ISPRS Remote Sensing Conference, LAGIRS 2020 - Proceedings","","","9165642","6","11","5","10.1109/LAGIRS48042.2020.9165642","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091663144&doi=10.1109%2fLAGIRS48042.2020.9165642&partnerID=40&md5=2a544615fcc846ed433c7835c8bf484c","High-resolution images for remote sensing applications are often not affordable or accessible, especially when in need of a wide temporal span of recordings. Given the easy access to low-resolution (LR) images from satellites, many remote sensing works rely on this type of data. The problem is that LR images are not appropriate for semantic segmentation, due to the need for high-quality data for accurate pixel prediction for this task. In this paper, we propose an end-to-end framework that unites a super-resolution and a semantic segmentation module in order to produce accurate thematic maps from LR inputs. It allows the semantic segmentation network to conduct the reconstruction process, modifying the input image with helpful textures. We evaluate the framework with three remote sensing datasets. The results show that the framework is capable of achieving a semantic segmentation performance close to native high-resolution data, while also surpassing the performance of a network trained with LR inputs.  © 2020 IEEE.","Image segmentation; Maps; Semantics; Textures; High quality data; High resolution data; High resolution image; Low resolution images; Reconstruction process; Remote sensing applications; Semantic segmentation; Super resolution; Remote sensing","end-to-end framework; remote sensing; semantic segmentation; Super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85091663144"
"Wang X.; Wu Y.; Ming Y.; Lv H.","Wang, Xinying (57215084349); Wu, Yingdan (34874341500); Ming, Yang (15754094100); Lv, Hui (35484869100)","57215084349; 34874341500; 15754094100; 35484869100","Remote sensing imagery super resolution based on adaptive multi‐scale feature fusion network","2020","Sensors (Switzerland)","20","4","1142","","","","10.3390/s20041142","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079849184&doi=10.3390%2fs20041142&partnerID=40&md5=f986c6e3ac994dd5c0d6dfd1b9a00536","Due to increasingly complex factors of image degradation, inferring high‐frequency details of remote sensing imagery is more difficult compared to ordinary digital photos. This paper proposes an adaptive multi‐scale feature fusion network (AMFFN) for remote sensing image super‐resolution. Firstly, the features are extracted from the original low‐resolution image. Then several adaptive multi‐scale feature extraction (AMFE) modules, the squeeze‐and‐excited and adaptive gating mechanisms are adopted for feature extraction and fusion. Finally, the sub‐pixel convolution method is used to reconstruct the high‐resolution image. Experiments are performed on three datasets, the key characteristics, such as the number of AMFEs and the gating connection way are studied, and super‐resolution of remote sensing imagery of different scale factors are qualitatively and quantitatively analyzed. The results show that our method outperforms the classic methods, such as Super‐Resolution Convolutional Neural Network(SRCNN), Efficient Sub‐Pixel Convolutional Network (ESPCN), and multi‐scale residual CNN(MSRN). © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Convolution; Convolutional neural networks; Extraction; Feature extraction; Pixels; Convolution methods; Convolutional networks; Feature fusion; Image degradation; Key characteristics; Remote sensing imagery; Remote sensing images; Resolution images; Remote sensing","Adaptive multi‐scale feature fusion; Remote sensing imagery; Super‐resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85079849184"
"Yu H.; Wang M.; Xu L.; Wang M.","Yu, Haixing (57197735758); Wang, Mingquan (55601062700); Xu, Lingyu (7404745474); Wang, Maohua (57202333154)","57197735758; 55601062700; 7404745474; 57202333154","Application of Bayesian super-resolution imaging algorithm to micro-nano satellite images","2019","Journal of Applied Remote Sensing","13","3","030501","","","","10.1117/1.JRS.13.030501","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072525279&doi=10.1117%2f1.JRS.13.030501&partnerID=40&md5=61044277b94a04bab6d955c1df7980ce","The need for high-resolution imaging becomes particularly important in remote sensing image applications, such as ground-object identification. We introduce a Bayesian multiframe super-resolution algorithm that efficiently improves the imaging resolution of our micro-nano carbon satellite images. We begin by presenting a theoretical overview of the algorithm, and subsequently we conduct experiments in two phases. In the first phase, we compare the performance of our algorithm with those of other similar algorithms using a set of reference images. In the second practical application phase, we apply all the algorithms considered to panchromatic images obtained from our civilian micro-nano carbon satellite. Our results indicate that the proposed algorithm significantly outperforms the other algorithms, affording higher image resolution and greater image detail. We believe that our approach can contribute to the further development of satellite imaging systems. © 2019 Society of Photo-Optical Instrumentation Engineers (SPIE).","Carbon; Image processing; Image resolution; Learning systems; Machine learning; Micro satellites; Optical resolving power; Remote sensing; Bayesian algorithms; High-resolution imaging; Imaging resolutions; Panchromatic images; Remote sensing images; Super resolution; Super resolution algorithms; Super resolution imaging; Image enhancement","Bayesian algorithm; digital image processing; machine learning; remote sensing; super-resolution","Article","Final","","Scopus","2-s2.0-85072525279"
"Zhang Y.; Wang W.","Zhang, Yongqi (57220183978); Wang, Wei (56115477500)","57220183978; 56115477500","Performance evaluation for imaging with a vortex half-wave retarder","2020","Proceedings of SPIE - The International Society for Optical Engineering","11548","","1154818","","","","10.1117/12.2573321","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097194803&doi=10.1117%2f12.2573321&partnerID=40&md5=6a3bd19865561b154c939c7a1966dc29","A vortex half-wave retarder (VHR) is a new type of polarizing element with a constant retardance across its clear aperture but its fast axis rotating continuously over the area of the optic. In polarization optics, the VHR-based polarization control method is very efficient to control the radial and azimuthal polarization states of light with a simple system configuration, ease of use, and high energy utilization efficiency. In optical manipulation, VHR can generate nondiffracting Bessel beams with an enlarged trapping region of optical tweezers. In the field of optical imaging, an imaging system with a vortex half-wave retarder has been reported to improve the resolution. Due to its many unique functions with novelty, vortex half-wave retarder has received a lot of interests in optical micro-operation, optical imaging, optical communication, optoelectronics, quantum information and remote sensing. In this paper, we study the performance evaluation for imaging with a 0-order vortex half-wave retarder by using a method referred to as Optical Transfer Matrix. After introduction of the Jones matrix for the vortex half-wave retarders as a general pupil matrix, we present the optical transfer matrix as the frequency transfer characteristics for the imaging system. As compared with a polarization imaging with a half-wave plate, the imaging system with a vortex half-wave retarder has a typical effect of apodizing by increasing a contrast for the high-frequency end.  © 2020 SPIE.","Energy utilization; Image resolution; Imaging systems; Optical communication; Optical design; Optical image storage; Polarization; Remote sensing; Transfer matrix method; Vortex flow; Azimuthal polarization; Energy utilization efficiency; Optical manipulation; Optical transfer matrix; Polarization control methods; Polarization imaging; Polarizing elements; Quantum Information; Optical tweezers","Optical Transfer Matrix; Super-resolution; Zero-order vortex half-wave retarder","Conference paper","Final","","Scopus","2-s2.0-85097194803"
"Shen H.; Lin L.; Li J.; Yuan Q.; Zhao L.","Shen, Huanfeng (8359721100); Lin, Liupeng (57188711703); Li, Jie (57214207213); Yuan, Qiangqiang (36635300800); Zhao, Lingli (55353622100)","8359721100; 57188711703; 57214207213; 36635300800; 55353622100","A residual convolutional neural network for polarimetric SAR image super-resolution","2020","ISPRS Journal of Photogrammetry and Remote Sensing","161","","","90","108","18","10.1016/j.isprsjprs.2020.01.006","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078062371&doi=10.1016%2fj.isprsjprs.2020.01.006&partnerID=40&md5=bc7d3c61c1b4fcf09f8ae3b1a7a349b4","PolSAR images provide rich polarimetric information, however, due to the limitations of the imaging system, the spatial resolution decreases while the richer polarimetric information is obtained. The lower resolution limits the application, so it is necessary to use super-resolution technology to improve the spatial resolution. In this paper, in response to the low spatial resolution of PolSAR images, a PolSAR super-resolution framework is proposed to improve the spatial resolution by the use of a residual convolutional neural network. Within this framework, deconvolution is used to up-sample the PolSAR images, PReLU is added to maintain the numerical properties. A complex structure block is also designed to accommodate the PolSAR data structure. In addition, prior information on the low-resolution image itself is used to reduce the artifacts. The proposed method shows a superior performance when compared to the traditional methods in both the quantitative evaluation and visual assessment. The proposed method improved the spatial resolution significantly, especially in terms of detail information retention, and it improves the mean PSNR by more than 12% when compared to the traditional methods. By analyzing the phase statistics and polarimetric response, it is shown that the proposed method has a good polarimetric information retention ability, and can obtain a higher classification accuracy. © 2020 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Classification (of information); Convolution; Deep learning; Deep neural networks; Image enhancement; Neural networks; Optical resolving power; Polarimeters; Radar imaging; Remote sensing; Synthetic aperture radar; Classification accuracy; Convolutional neural network; Information retention; Lower resolution limits; Polarimetric informations; Polarimetric SAR; Quantitative evaluation; Super resolution; accuracy assessment; artificial neural network; deconvolution; image resolution; learning; polarization; quantitative analysis; spatial resolution; synthetic aperture radar; Image resolution","Deep learning; Polarimetric SAR; Remote sensing; Residual convolutional neural network; Super-resolution","Article","Final","","Scopus","2-s2.0-85078062371"
"Liu X.; Feng T.; Zhao J.; Li R.","Liu, Xiaomin (57208296205); Feng, Tiantian (12782146100); Zhao, Junqiao (35115954600); Li, Rongxing (7404724327)","57208296205; 12782146100; 35115954600; 7404724327","Super Resolution Reconstruction Technique in Passive Microwave Images of Arctic Sea Ice","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898488","4234","4237","3","10.1109/IGARSS.2019.8898488","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077692177&doi=10.1109%2fIGARSS.2019.8898488&partnerID=40&md5=569c7d9c7bcdaa9b2e0cfe4ac127c5b5","Polar sea ice is one of the key parameters of cryosphere and polar environmental change, which plays an important role in the study of global climate change. High-resolution monitoring of polar sea ice relies mainly on optical satellite imagery and synthetic aperture radar (SAR) data, with limited spatial and temporal coverages for many applications. Passive microwave data is an important data source for continuous observations of polar sea ice, thanks to its working ability in all-sky conditions and its wide coverage. However, it is difficult to achieve high-resolution monitoring of polar sea ice using passive microwave data due to its coarse resolution. In order to solve this problem, super resolution (SR) reconstruction technique is adopted in this paper to improve the spatial resolution of passive microwave images. SR reconstruction technique based on both single-image and multi-image are attempted. AMSR2 level 3 (L3) Products of Brightness Temperatures (BTs) for Arctic sea ice are used as experimental data, and the reconstruction results obtained from different SR methods are compared and discussed. © 2019 IEEE.","Climate change; Geology; Image enhancement; Imaging systems; Microwaves; Optical resolving power; Radar imaging; Remote sensing; Satellite imagery; Sea ice; Synthetic aperture radar; Arctic; High-resolution monitoring; Optical satellite imagery; Passive microwaves; Reconstruction techniques; Super resolution; Super resolution reconstruction; Super-resolution reconstruction techniques; Image reconstruction","Arctic; passive microwave; sea ice; Super Resolution","Conference paper","Final","","Scopus","2-s2.0-85077692177"
"Tan Z.; Xiang L.; Lyu Q.; Sun J.; Li P.; Gao S.; Yin Z.","Tan, Zheng (57188729245); Xiang, Libin (6603552859); Lyu, Qunbo (35337326500); Sun, Jianying (56171742300); Li, Pingfu (57208272607); Gao, Shuang (57208274188); Yin, Zengshan (14627968500)","57188729245; 6603552859; 35337326500; 56171742300; 57208272607; 57208274188; 14627968500","CX-6(02) micro-nano satellite super-resolution imaging; [CX-6(02)微纳卫星超分辨率成像]","2019","Yaogan Xuebao/Journal of Remote Sensing","23","2","","196","204","8","10.11834/jrs.20198014","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064324198&doi=10.11834%2fjrs.20198014&partnerID=40&md5=e6554b90f4891410e6d651cde2f0c9a3","Micro-nano satellite is one of the developing trends of remote sensing technology with the advantages of light-weight, small size, low cost. However, because of the limitation of the volume and weight, the traditional high resolution optical imaging payload with long focal length and large aperture is difficult to apply to earth observation of micro-nano satellite. In order to solve this problem, a super-resolution imaging scheme is demonstrated in this paper. First, in the mode of images acquisition, to obtain multi frame images of the same region, the velocity of imaging relative to the ground should be controlled by satellite attitude. And because the attitude control deviation of satellite is objective, so subpixel displacement information can be generated by pitching, yaw, and rolling random deviations, without to install any other displacement generators; Secondly, In the super-resolution reconstruction algorithm, aiming at solving the problem of prior constraints on variational bayesian super-resolution reconstruction method, we propose a weighted bi-directional difference prior model to overcome the under-constraint of non-edge regions of image due to total variation prior and L1 norm prior, to further restrain the solving space of the observation equation. The above scheme is applied to the China's first super-resolution imaging micro-nano satellite:CX-6(02) micro-nano satellite. The imaging results of this satellite show that: our images acquisition method can obtain sufficient subpixel information, which is approximately uniformly distributed with 0.1 pixel magnitude; The result of super-resolution reconstruction is superior to the same variational bayesian method based on L1 norm prior model and total variation prior model, it is hardly to introduce or amplify the computational noise in the iterative process of the algorithm, effectively weakens the ill-posed property of the deconvolution operation. Make the CX-6(02) satellite's imaging resolution increased from 2.8 to 1.4 meters in the 700 km orbit altitude, and the whole satellite is only 66 kg. Except for micro-nano satellite, the design scheme of this paper can also be applied to medium or large optical imaging satellite, it may provide a certain theoretical and experimental support for high resolution earth-observing remote sensing. © 2019, Science Press. All right reserved.","Attitude control; Bayesian networks; Deconvolution; Edge detection; Image acquisition; Image reconstruction; Iterative methods; Nanosatellites; Optical image storage; Optical resolving power; Orbits; Pixels; Remote sensing; Space optics; Images acquisition; Micro-nano; Prior modeling; Reconstruction algorithms; Super resolution imaging; Variational bayes; Micro satellites","CX-6(02) micro-nano satellite; Images acquisition; Prior model; Reconstruction algorithm; Super-resolution imaging; Variational Bayes","Article","Final","","Scopus","2-s2.0-85064324198"
"Zhang N.; Wang Y.; Zhang X.; Xu D.; Wang X.","Zhang, Ning (57188816117); Wang, Yongcheng (56437944700); Zhang, Xin (57774426900); Xu, Dongdong (56299205100); Wang, Xiaodong (57208088951)","57188816117; 56437944700; 57774426900; 56299205100; 57208088951","An Unsupervised Remote Sensing Single-Image Super-Resolution Method Based on Generative Adversarial Network","2020","IEEE Access","8","","8986554","29027","29039","12","10.1109/ACCESS.2020.2972300","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079744090&doi=10.1109%2fACCESS.2020.2972300&partnerID=40&md5=e9a0ab049e0b5d66745dacf6396fc44f","Image super-resolution (SR) technique can improve the spatial resolution of images without upgrading the imaging system. As a result, SR promotes the development of high resolution (HR) remote sensing image applications. Many remote sensing image SR algorithms based on deep learning have been proposed recently, which can effectively improve the spatial resolution under the constraints of HR images. However, images acquired by remote sensing imaging devices typically have lower resolution. Hence, an insufficient number of HR remote sensing images are available for training deep neural networks. In view of this problem, we propose an unsupervised SR method that does not require HR remote sensing images. The proposed method introduces a generative adversarial network (GAN) that obtains SR images through the generator; then, the SR images are downsampled to train the discriminator with low resolution (LR) images. Our method outperformed several methods in terms of the quality of the obtained SR images as measured by 6 evaluation metrics, which proves the satisfactory performance of the proposed unsupervised method for improving the spatial resolution of remote sensing images. © 2013 IEEE.","Deep learning; Deep neural networks; Image resolution; Optical resolving power; Remote sensing; Unsupervised learning; Adversarial networks; Evaluation metrics; Image super resolutions; Low resolution images; Remote sensing images; Remote sensing imaging; Spatial resolution; Unsupervised method; Image enhancement","generative adversarial network; Image super-resolution; remote sensing; unsupervised learning","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85079744090"
"Fotiadou K.; Tsagkatakis G.; Tsakalides P.","Fotiadou, Konstantina (25824915900); Tsagkatakis, Grigorios (34870845200); Tsakalides, Panagiotis (6701848334)","25824915900; 34870845200; 6701848334","Spectral Super Resolution of Hyperspectral Images via Coupled Dictionary Learning","2019","IEEE Transactions on Geoscience and Remote Sensing","57","5","8535036","2777","2797","20","10.1109/TGRS.2018.2877124","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056563919&doi=10.1109%2fTGRS.2018.2877124&partnerID=40&md5=b7d1e812c81817d6701bbabc05524c1e","High-spectral resolution imaging systems play a critical role in the identification and characterization of objects in a scene of interest. Unfortunately, multiple factors impair spectral resolution, as in the case of modern snapshot spectral imagers that associate each hyperpixel with a specific spectral band. In this paper, we introduce a novel postacquisition computational technique aiming to enhance the spectral dimensionality of imaging systems by exploiting the mathematical frameworks of sparse representations and dictionary learning. We propose a coupled dictionary learning model which considers joint feature spaces, composed of low- and high-spectral resolution hypercubes, in order to achieve spectral superresolution performance. We formulate our spectral coupled dictionary learning optimization problem within the context of the alternating direction method of multipliers, and we manage to update the involved quantities via closed-form expressions. In addition, we consider a realistic spectral subsampling scenario, taking into account the spectral response functions of different satellites. Moreover, we apply our spectral superresolution algorithm on real satellite data acquired by Landsat-8 and Sentinel-2 sensors. Finally, we have investigated the problem of hyperspectral image unmixing using the recovered high-spectral resolution data cube, and we are able to demonstrate that the proposed scheme provides significant value in hyperspectral image understanding techniques. Experimental results demonstrate the ability of the proposed approach to synthesize high-spectral-resolution 3-D hypercubes, achieving better performance compared to state-of-the-art resolution enhancement methods. © 1980-2012 IEEE.","Geometry; Hyperspectral imaging; Image resolution; Imaging systems; Remote sensing; Spectral resolution; Spectroscopy; Alternating direction method of multipliers; Dictionary learning; Remote sensing image processing; Resolution enhancement; Sparse representation; Super resolution; algorithm; data acquisition; experimental study; image analysis; image processing; imaging method; numerical model; optimization; pixel; satellite altimetry; Sentinel; spectral analysis; spectral resolution; Image enhancement","Alternating direction method of multipliers; coupled dictionary learning; hyperspectral image enhancement; remote sensing image processing; sparse representations; spectral resolution enhancement; spectral super-resolution","Article","Final","","Scopus","2-s2.0-85056563919"
"Pan Z.; Ma W.; Guo J.; Lei B.","Pan, Zongxu (54788169800); Ma, Wen (57207877267); Guo, Jiayi (57194143247); Lei, Bin (14063767500)","54788169800; 57207877267; 57194143247; 14063767500","Super-resolution of single remote sensing image based on residual dense backprojection networks","2019","IEEE Transactions on Geoscience and Remote Sensing","57","10","8732688","7918","7933","15","10.1109/TGRS.2019.2917427","54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077813490&doi=10.1109%2fTGRS.2019.2917427&partnerID=40&md5=bc1318e20cfae0bd67fce7c2aef9811a","High-resolution (HR) images are always preferred for many remote sensing applications, which can be obtained from their low-resolution (LR) counterparts via a technique referred to as super-resolution (SR). Among SR approaches, single image SR (SISR) methods aim at reconstructing the HR image from only one LR image. In this paper, a residual dense backprojection network (RDBPN)-based SISR method is proposed to promote the resolution of RGB remote sensing images with median- and large-scale factors. The proposed network consists of several residual dense backprojection blocks that contain two kinds of modules, named the upprojection module and the downprojection module, and these modules are densely connected in one block. Different from the chain-connected backprojection structure, the proposed method applies a residual backprojection block structure, which can utilize residual learning in both global and local manners. We further simplify the network by replacing the downprojection unit with the downscaling unit to accelerate the speed of reconstruction, and this implementation is called fast RDBPN (FRDBPN). Several experiments under the UC Merced data set are conducted to validate the effectiveness of the proposed method, and the results indicate that: 1) the proposed residual block structure is superior to the chain-connected structure; 2) FRDBPN achieves a speedup of about 1.3 times with similar and even better-reconstructed performance in comparison with RDBPN; and 3) RDBPN and FRDBPN outperform several state-of-the-art methods in terms of both quantitative evaluation and visual quality. © 1980-2012 IEEE.","Neural networks; Optical resolving power; Back-projection; Convolutional neural network; Remote sensing images; residual learning; Single images; artificial neural network; data set; downscaling; image resolution; learning; reconstruction; remote sensing; Remote sensing","Convolutional neural networks (CNNs); dense backprojection blocks; remote sensing images; residual learning; single image super-resolution (SISR)","Article","Final","","Scopus","2-s2.0-85077813490"
"Ha V.K.; Ren J.-C.; Xu X.-Y.; Zhao S.; Xie G.; Masero V.; Hussain A.","Ha, Viet Khanh (57204285939); Ren, Jin-Chang (23398632100); Xu, Xin-Ying (8853613200); Zhao, Sophia (57202536196); Xie, Gang (7202981334); Masero, Valentin (6602228741); Hussain, Amir (19734290900)","57204285939; 23398632100; 8853613200; 57202536196; 7202981334; 6602228741; 19734290900","Deep Learning Based Single Image Super-resolution: A Survey","2019","International Journal of Automation and Computing","16","4","","413","426","13","10.1007/s11633-019-1183-x","45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069183006&doi=10.1007%2fs11633-019-1183-x&partnerID=40&md5=c52bfaba5585ee6e3009605124ee0e6d","Single image super-resolution has attracted increasing attention and has a wide range of applications in satellite imaging, medical imaging, computer vision, security surveillance imaging, remote sensing, objection detection, and recognition. Recently, deep learning techniques have emerged and blossomed, producing “the state-of-the-art” in many domains. Due to their capability in feature extraction and mapping, it is very helpful to predict high-frequency details lost in low-resolution images. In this paper, we give an overview of recent advances in deep learning-based models and methods that have been applied to single image super-resolution tasks. We also summarize, compare and discuss various models from the past and present for comprehensive understanding and finally provide open problems and possible directions for future research. © 2019, Institute of Automation, Chinese Academy of Sciences and Springer-Verlag GmbH Germany, part of Springer Nature.","Deep learning; Deep neural networks; Neural networks; Optical resolving power; Remote sensing; Convolutional neural network; High frequency HF; High resolution image; Image super resolutions; Learning Based Models; Learning techniques; Low resolution images; Security surveillance; Medical imaging","convolutional neural network; deep learning; high-resolution image; Image super-resolution; low-resolution image","Review","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85069183006"
"Wang L.; Bi T.; Shi Y.","Wang, Liguo (55745497100); Bi, Tianyi (57216908185); Shi, Yao (56742475000)","55745497100; 57216908185; 56742475000","A Frequency-Separated 3D-CNN for Hyperspectral Image Super-Resolution","2020","IEEE Access","8","","9087888","86367","86379","12","10.1109/ACCESS.2020.2992862","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085260527&doi=10.1109%2fACCESS.2020.2992862&partnerID=40&md5=8c050c755ee70fca276fb3798ae2780f","Considering the limitations such as cost, it is of great significance to use super-resolution methods to improve image spatial quality in the field of hyperspectral remote sensing. Due to little dependence on auxiliary information which is difficult to obtain, i.e., multispectral images and natural images, methods based on single-frame are generally considered to have good flexibility and application value. In this paper, a three-dimensional convolutional neural network with three branches combined with an analytical method is proposed, achieving better SR quality and suppressing spectral distortion as well. Firstly, the wavelet transformation is introduced to decompose the hyperspectral image into a variety frequency of components effectively and reversibly. Then, these components are fed into different three-dimensional convolutional branches respectively. Finally, hyperspectral images with high resolution are obtained by dimension amplification, detail reconstruction and inverse wavelet transformation. The presence of frequency separation and the architecture of our model having different branches designed according to frequency make it better than comparable approaches. The method proposed in this paper not only combines the high efficiency of analytical method and the flexibility of neural network, but inhibits the influence of spectral distortion as well. Compared with the state-of-art methods on real space-based hyperspectral image datasets, the effectiveness of the proposed method is demonstrated. © 2013 IEEE.","Arts computing; Convolution; Convolutional neural networks; Inverse problems; Optical resolving power; Remote sensing; Spectroscopy; Wavelet transforms; Auxiliary information; Frequency separation; Hyperspectral remote sensing; Image super resolutions; Spectral distortions; State-of-art methods; Superresolution methods; Wavelet transformations; Image enhancement","Hyperspectral remote sensing; neural network; super-resolution; wavelet transformation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85085260527"
"Choi Y.; Kim M.; Kim Y.; Han S.","Choi, Yeonju (57215967828); Kim, Minsik (57223883024); Kim, Yongwoo (57202143770); Han, Sanghyuck (37101680300)","57215967828; 57223883024; 57202143770; 37101680300","A Study of CNN-based Super-Resolution Method for Remote Sensing Image","2020","Korean Journal of Remote Sensing","36","3","","449","460","11","10.7780/kjrs.2020.36.3.5","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106324741&doi=10.7780%2fkjrs.2020.36.3.5&partnerID=40&md5=d10c8da1971505cfb3328e5823c91add","Super-resolution is a technique used to reconstruct an image with low-resolution into that of high-resolution. Recently, deep-learning based super resolution has become the mainstream, and applications of these methods are widely used in the remote sensing field. In this paper, we propose a super-resolution method based on the deep back-projection network model to improve the satellite image resolution by the factor of four. In the process, we customized the loss function with the edge loss to result in a more detailed feature of the boundary of each object and to improve the stability of the model training using generative adversarial network based on Wasserstein distance loss. Also, we have applied the detail preserving image down-scaling method to enhance the naturalness of the training output. Finally, by including the modified-residual learning with a panchromatic feature in the final step of the training process. Our proposed method is able to reconstruct fine features and high frequency information. Comparing the results of our method with that of the others, we propose that the super-resolution method improves the sharpness and the clarity of WorldView-3 and KOMPSAT-2 images. © 2020 Annals of Laparoscopic and Endoscopic Surgery. All rights reserved.","","DPID; Edge loss; Remote sensing image; SISR; Super resolution","Article","Final","","Scopus","2-s2.0-85106324741"
"Xu T.; Huang T.-Z.; Deng L.-J.; Zhao X.-L.; Huang J.","Xu, Ting (57218761958); Huang, Ting-Zhu (56193452300); Deng, Liang-Jian (55207151100); Zhao, Xi-Le (24073933900); Huang, Jie (56796935000)","57218761958; 56193452300; 55207151100; 24073933900; 56796935000","Hyperspectral Image Superresolution Using Unidirectional Total Variation with Tucker Decomposition","2020","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","13","","9151315","4381","4398","17","10.1109/JSTARS.2020.3012566","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090243226&doi=10.1109%2fJSTARS.2020.3012566&partnerID=40&md5=86b097dbcb1dadf580c06a9e9baeb266","The hyperspectral image superresolution (HSI-SR) problem aims to improve the spatial quality of a low spatial resolution HSI by fusing the LR-HSI with the corresponding high spatial resolution multispectral image. The generated HSI with high spatial quality, i.e., the target high spatial resolution hyperspectral image (HR-HSI), generally has some fundamental latent properties, e.g., the sparsity, and the piecewise smoothness along with the three modes (i.e., width, height, and spectral mode). However, limited works consider both properties in the HSI-SR problem. In this work, a novel unidirectional total variation (TV) based approach is been proposed. On the one hand, we consider that the target HR-HSI exhibits both the sparsity and the piecewise smoothness on the three modes, and they can be depicted well by the ℓ1-norm and TV, respectively. On the other hand, we utilize the classical Tucker decomposition to decompose the target HR-HSI (a three-mode tensor) as a sparse core tensor multiplied by the dictionary matrices along with the three modes. Especially, we impose the ℓ1-norm on core tensor to characterize the sparsity and the unidirectional TV on three dictionaries to characterize the piecewise smoothness. The proximal alternating optimization scheme and the alternating direction method of multipliers are used to iteratively solve the proposed model. Experiments on three common datasets illustrate that the proposed approach has better performance than some current state-of-the-art HSI-SR methods. Please find source code from: Https://liangjiandeng.github.io/. © 2020 IEEE.","Image resolution; Iterative methods; Optical resolving power; Spectroscopy; Tensors; Alternating direction method of multipliers; Alternating optimizations; High spatial resolution; High spatial resolution multispectral images; Image super-resolution; Piecewise smoothness; Spatial resolution; Tucker decompositions; decomposition analysis; optimization; remote sensing; satellite data; satellite imagery; spatial resolution; Image enhancement","Hyperspectral image superresolution (HSI-SR); image fusion; piecewise smoothness; sparsity; unidirectional total variation (TV)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85090243226"
"Zhang C.; Zhang H.; Jiang Z.","Zhang, Cong (57209818790); Zhang, Haopeng (54788751800); Jiang, Zhiguo (35336923600)","57209818790; 54788751800; 35336923600","Single infrared remote sensing image super-resolution via supervised deep learning","2020","Proceedings of SPIE - The International Society for Optical Engineering","11533","","1153314","","","","10.1117/12.2573359","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093924981&doi=10.1117%2f12.2573359&partnerID=40&md5=fa8d4b7809ee4f87f69f464c9984e97c","The infrared observation sensors aboard remote sensing satellites play an important role in the applications of crop yield estimation, environmental protection, land resources survey, disaster monitoring, etc. But infrared remote sensing data is always in low resolution due to hardware limitations. It is a high cost-effective choice to improve the spatial resolution of infrared remote sensing data through super-resolution (SR) algorithm. Deep learning methods have made great breakthroughs in super-resolution of natural images. In this paper, we comparably study five recently popular supervised-deep-learning-based single image SR models for the purpose of super-resolving infrared images, including SRGAN, ESRGAN, LapSRN, RCAN, and SRFBN. We first test the performance of models trained by natural images on infrared remote sensing images to obtain a benchmark, and then specially fine-tune the SR models using infrared images of Landsat8 in a transfer-learning manner. We evaluate the performance of all these fine-tuned models on infrared images with three indicators including PSNR, SSIM, and NIQE. The experimental results show that the SRFBN model achieves the best generalization ability and SR performance. Therefore, we suggest using SRFBN for super-resolution reconstruction of single infrared remote sensing image in applications. © SPIE. Downloading of the abstract is permitted for personal use only.","Benchmarking; Cost effectiveness; Deep learning; Infrared imaging; Learning systems; Optical resolving power; Transfer learning; Disaster monitoring; Generalization ability; Infrared observations; Infrared remote sensing; Learning methods; Remote sensing satellites; Spatial resolution; Super resolution reconstruction; Remote sensing","Deep learning; Image super-resolution; Infrared remote sensing; Supervised learning","Conference paper","Final","","Scopus","2-s2.0-85093924981"
"Ma X.; Hong Y.; Song Y.; Chen Y.","Ma, Xiaofeng (57212408403); Hong, Youtang (13002721600); Song, Yongze (57200073199); Chen, Yujia (57192703930)","57212408403; 13002721600; 57200073199; 57192703930","A Super-resolution convolutional-neural-network-based approach for subpixel mapping of hyperspectral images","2019","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","12","12","8847414","4930","4939","9","10.1109/JSTARS.2019.2941089","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079342911&doi=10.1109%2fJSTARS.2019.2941089&partnerID=40&md5=b0f582be26a8ea54f88c1897f7e11ae0","A new subpixel mapping (SPM) method based on a super-resolution convolutional neural network (SRCNN) is proposed to generate subpixel land cover maps for hyperspectral images. The SRCNN is used to restore the image spatial resolution from a coarse input image, which is equivalent to interpolation. First, an efficient subpixel convolutional neural network, which is a state-of-The-Art SRCNN, is utilized to calculate the subpixel soft class value via a transfer learning strategy. Then, a classifier is used to transform the subpixel soft class values to hard-classified land cover maps with the constraint of fraction images. Experiments on three different hyperspectral images demonstrate that the SPM accuracy of the proposed SRCNN-based method is significantly better than those of three traditional SPM methods. In addition, the SRCNN-based SPM method has a simplified calculation process, does not require training data, and is less time consuming. This article provides a new solution for SPM of hyperspectral images. © 2008-2012 IEEE.","Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Optical resolving power; Pixels; Remote sensing; Spectroscopy; Transfer learning; Fraction images; Hyperspectral Remote Sensing Image; Image spatial resolution; Land cover maps; Simplified calculations; State of the art; Sub-pixel mapping; Super resolution; artificial neural network; image resolution; land cover; machine learning; mapping method; multispectral image; pixel; remote sensing; spatial resolution; Mapping","Deep learning; hyperspectral remote sensing image; subpixel mapping (SPM); super-resolution convolutional neural network (SRCNN); transfer learning (TL)","Article","Final","","Scopus","2-s2.0-85079342911"
"Fang S.; Fang S.; Yao H.","Fang, Shuai (7402422537); Fang, Saihua (57212219173); Yao, Hongliang (15046148600)","7402422537; 57212219173; 15046148600","Pan-Sharpening Based on a Deep Pyramid Network; [基于深度金字塔网络的Pan-Sharpening算法]","2019","Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics","31","10","","1831","1837","6","10.3724/SP.J.1089.2019.17420","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076251744&doi=10.3724%2fSP.J.1089.2019.17420&partnerID=40&md5=d613d0b5ac27aa072abdfc9fca94aff0","The purpose of remote-sensing image fusion (ie, pan-sharpening) is to generate high-resolution multispectral images using high-resolution single-band panchromatic (PAN) images and low-resolution multispectral images (MS). In this paper, a pan-sharpening algorithm based on deep pyramid network is proposed, which reconstructs high-resolution multispectral images through layer-by-layer upsampling. To preserve detail information, aiming at the problem that the panchromatic image and the multispectral image differ too large in scale, this paper uses the deep pyramid network to fuse the details of the panchromatic image in a multi-scale fusion strategy. For spectral preservation, this paper uses the deconvolution layer instead of the traditional super-resolution algorithm to upsample low-resolution multispectral images. Finally, the two parts are added to obtain the fused image. The experimental results on GeoEye-1 datasets demonstrate that the proposed algorithm achieve competitive performance in comparison with BDSD, PRACS, PNN and PanNet. © 2019, Beijing China Science Journal Publishing Co. Ltd. All right reserved.","Deconvolution; Neural networks; Optical resolving power; Remote sensing; Competitive performance; Convolutional neural network; Image pyramids; Low resolution multispectral images; Pan-sharpening; Panchromatic (Pan) image; Super resolution; Super resolution algorithms; Image fusion","Convolutional neural network; Image pyramid; Pan-sharpening; Super-resolution","Article","Final","","Scopus","2-s2.0-85076251744"
"Gargiulo M.; Dell'aglio D.A.G.; Iodice A.; Riccio D.; Ruello G.","Gargiulo, M. (57200856555); Dell'aglio, D.A.G. (57202729372); Iodice, A. (7003793925); Riccio, D. (7006577607); Ruello, G. (6603038881)","57200856555; 57202729372; 7003793925; 7006577607; 6603038881","A CNN-based Super-resolution Technique for Active Fire Detection on Sentinel-2 Data","2019","Progress in Electromagnetics Research Symposium","2019-June","","9017857","418","426","8","10.1109/PIERS-Spring46901.2019.9017857","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081992611&doi=10.1109%2fPIERS-Spring46901.2019.9017857&partnerID=40&md5=12f5ad36cc40e80e72790d9e59f1963d","Remote Sensing applications can benefit from a relatively fine spatial resolution multispectral (MS) images and a high revisit frequency ensured by the twin satellites Sentinel-2. Unfortunately, only four out of thirteen bands are provided at the highest resolution of 10 meters, and the others at 20 or 60 meters. For instance the Short-Wave Infrared (SWIR) bands, provided at 20 meters, are very useful to detect active fires. Aiming to a more detailed Active Fire Detection (AFD) maps, we propose a super-resolution data fusion method based on Convolutional Neural Network (CNN) to move towards the 10-m spatial resolution the SWIR bands. The proposed CNN-based solution is compared to alternative methods in terms of some accuracy metrics. Moreover we have tested the super-resolved bands from an application point of view by monitoring active fire through classic indices. Advantages and limits of our proposed approach are validated on specific geographical area (the mount Vesuvius, close to Naples) that was damaged by widespread fires during the summer of 2017. © 2019 IEEE.","Convolutional neural networks; Data fusion; Fire detectors; Image resolution; Infrared radiation; Optical resolving power; Photonics; Piers; Remote sensing; Data fusion methods; Geographical area; Highest resolutions; Multispectral images; Remote sensing applications; Short wave infrared bands; Spatial resolution; Super resolution; Fires","","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85081992611"
"Chen L.; Jiang X.; Huang P.; Zhang Y.; Liu X.","Chen, Lin (57192609739); Jiang, Xue (55724182500); Huang, Penghui (56688948900); Zhang, Ye (57214253643); Liu, Xingzhao (35242655900)","57192609739; 55724182500; 56688948900; 57214253643; 35242655900","Efficient Nonconvex Regularization for Azimuth Resolution Enhancement of Real Beam Scanning Radar","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898637","692","695","3","10.1109/IGARSS.2019.8898637","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077703128&doi=10.1109%2fIGARSS.2019.8898637&partnerID=40&md5=518d53d4c72d4ead2ce3d4019f892c47","Azimuth superresolution for real beam scanning radar aims to recover the high-resolution image from low-resolution echo. Among superresolution techniques, regularization-based methods are widely used, but most existing methods lead to the blurring of scattering targets and thus are difficult to distinguish between close targets. In this paper, we propose to employ the nonconvex ℓp-regularization with 0 < p < 1 to achieve the sparsity-driven superresolution, which further enhances the azimuth resolution. Furthermore, the resultant optimization problem is efficiently solved using an unified framework via incorporating different proximity operators. Simulation results validate the accuracy and efficiency of the proposed algorithm. © 2019 IEEE.","Geology; Optical resolving power; Remote sensing; Scanning; Azimuth resolution; High resolution image; Optimization problems; Proximity operator; Scanning radar; Super resolution; Superresolution technique; Unified framework; Radar","azimuth super-resolution; scanning radar imaging; ℓ<sub>p</sub>-regularization","Conference paper","Final","","Scopus","2-s2.0-85077703128"
"Lei S.; Shi Z.; Zou Z.","Lei, Sen (57195618353); Shi, Zhenwei (23398841900); Zou, Zhengxia (56073977200)","57195618353; 23398841900; 56073977200","Coupled Adversarial Training for Remote Sensing Image Super-Resolution","2020","IEEE Transactions on Geoscience and Remote Sensing","58","5","8946581","3633","3643","10","10.1109/TGRS.2019.2959020","54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083899027&doi=10.1109%2fTGRS.2019.2959020&partnerID=40&md5=7215beb42d0cc9dcb4e96f78e3b6c307","Generative adversarial network (GAN) has made great progress in recent natural image super-resolution tasks. The key to its success is the integration of a discriminator which is trained to classify whether the input is a real high-resolution (HR) image or a generated one. Arguably, learning a strong discriminative prior is essential for generating high-quality images. However, in remote sensing images, we discover, through extensive statistical analysis, that there are more low-frequency components than natural images, which may lead to a 'discrimination-ambiguity' problem, i.e., the discriminator will become 'confused' to tell whether its input is real or not when dealing with those low-frequency regions, and therefore, the quality of generated HR images may be deeply affected. To address this problem, we propose a novel GAN-based super-resolution algorithm named coupled-discriminated GANs (CDGANs) for remote sensing images. Different from the previous GAN-based super-resolution models in which their discriminator takes in a single image at one time, in our model, the discriminator is specifically designed to take in a pair of images: a generated image and its HR ground truth, to make better discrimination of the inputs. We further introduce a dual pathway network architecture, a random gate, and a coupled adversarial loss to learn better correspondence between the discriminative results and the paired inputs. Experimental results on two public data sets demonstrate that our model can obtain more accurate super-resolution results in terms of both visual appearance and local details compared with other state of the arts. Our code will be made publicly available. © 1980-2012 IEEE.","Network architecture; Optical resolving power; Adversarial networks; High quality images; High resolution image; Low frequency regions; Low-frequency components; Remote sensing images; Super resolution algorithms; Super-resolution models; algorithm; data set; image resolution; remote sensing; satellite imagery; visual analysis; Remote sensing","Coupled adversarial training; deep convolutional neural networks; generative adversarial networks (GANs); remote sensing images; super-resolution","Article","Final","","Scopus","2-s2.0-85083899027"
"Li W.; Jiang J.; Guo T.; Zhou M.; Tang Y.; Wang Y.; Zhang Y.; Cheng T.; Zhu Y.; Cao W.; Yao X.","Li, Wei (57205166392); Jiang, Jiale (56289787100); Guo, Tai (57209567732); Zhou, Meng (57203944956); Tang, Yining (57208160329); Wang, Ying (57767139300); Zhang, Yu (56662268900); Cheng, Tao (56278310400); Zhu, Yan (8921604000); Cao, Weixing (55489902600); Yao, Xia (14022139100)","57205166392; 56289787100; 57209567732; 57203944956; 57208160329; 57767139300; 56662268900; 56278310400; 8921604000; 55489902600; 14022139100","Generating red-edge images at 3M spatial resolution by fusing sentinel-2 and planet satellite products","2019","Remote Sensing","11","12","1422","","","","10.3390/rs11121422","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068177402&doi=10.3390%2frs11121422&partnerID=40&md5=c29bc81d9238fbb43dba448e861a04b9","High-resolution satellite images can be used to some extent to mitigate the mixed-pixel problem caused by the lack of intensive production, farmland fragmentation, and the uneven growth of field crops in developing countries. Specifically, red-edge (RE) satellite images can be used in this context to reduce the influence of soil background at early stages as well as saturation due to crop leaf area index (LAI) at later stages. However, the availability of high-resolution RE satellite image products for research and application globally remains limited. This study uses the weight-and-unmixing algorithm as well as the SUPer-REsolution for multi-spectral Multi-resolution Estimation (Wu-SupReME) approach to combine the advantages of Sentinel-2 spectral and Planet spatial resolution and generate a high-resolution RE product. The resultant fused image is highly correlated (R2 > 0.98) with Sentinel-2 image and clearly illustrates the persistent advantages of such products. This fused image was significantly more accurate than the originals when used to predict heterogeneous wheat LAI and therefore clearly illustrated the persistence of Sentinel-2 spectral and Planet spatial advantage, which indirectly proved that the fusion methodology of generating high-resolution red-edge products from Planet and Sentinel-2 images is possible. This study provided method reference for multi-source data fusion and image product for accurate parameter inversion in quantitative remote sensing of vegetation. © 2019 by the authors.","Crops; Developing countries; Image fusion; Image resolution; Planets; Remote sensing; Fusion image; Sentinel-2; SupReME; Unmixing; Wheat LAI; Satellites","Fusion image; Planet; Sentinel-2; SupReME; Weight-and-unmixing; Wheat LAI","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85068177402"
"Nguyen T.H.; Daniel S.; Guériot D.; Sintès C.; Le Caillec J.-M.","Nguyen, Thanh Huy (57188867783); Daniel, Sylvie (7201730830); Guériot, Didier (6506733427); Sintès, Christophe (6602430428); Le Caillec, Jean-Marc (6701913312)","57188867783; 7201730830; 6506733427; 6602430428; 6701913312","Super-resolution-based snake model-an unsupervised method for large-scale building extraction using airborne lidar data and optical image","2020","Remote Sensing","12","11","1702","","","","10.3390/rs12111702","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086426138&doi=10.3390%2frs12111702&partnerID=40&md5=90a7c4de5099603cc6820a6272dbb6eb","Automatic extraction of buildings in urban and residential scenes has become a subject of growing interest in the domain of photogrammetry and remote sensing, particularly since the mid-1990s. Active contour model, colloquially known as snake model, has been studied to extract buildings from aerial and satellite imagery. However, this task is still very challenging due to the complexity of building size, shape, and its surrounding environment. This complexity leads to a major obstacle for carrying out a reliable large-scale building extraction, since the involved prior information and assumptions on building such as shape, size, and color cannot be generalized over large areas. This paper presents an efficient snake model to overcome such a challenge, called Super-Resolution-based Snake Model (SRSM). The SRSM operates on high-resolution Light Detection and Ranging (LiDAR)-based elevation images-called z-images-generated by a super-resolution process applied to LiDAR data. The involved balloon force model is also improved to shrink or inflate adaptively, instead of inflating continuously. This method is applicable for a large scale such as city scale and even larger, while having a high level of automation and not requiring any prior knowledge nor training data from the urban scenes (hence unsupervised). It achieves high overall accuracy when tested on various datasets. For instance, the proposed SRSM yields an average area-based Quality of 86.57% and object-based Quality of 81.60% on the ISPRS Vaihingen benchmark datasets. Compared to other methods using this benchmark dataset, this level of accuracy is highly desirable even for a supervised method. Similarly desirable outcomes are obtained when carrying out the proposed SRSM on the whole City of Quebec (total area of 656 km2), yielding an area-based Quality of 62.37% and an object-based Quality of 63.21%. © 2020 by the authors.","Antennas; Benchmarking; Buildings; Extraction; Geometrical optics; Image processing; Optical resolving power; Remote sensing; Satellite imagery; Active contour model; Airborne lidar data; Automatic extraction; Large scale buildings; Level of automations; Light detection and ranging; Surrounding environment; Unsupervised method; Optical radar","Active contour model; Airborne LiDAR; Building extraction; Building footprint extraction; Large scale; Optical imagery; Snake model; Super-resolution; Unsupervised approach","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85086426138"
"Zhang G.; Wang G.; Wang Z.","Zhang, Guoying (57216812800); Wang, Guoqiang (24922577900); Wang, Zhonghong (57216809637)","57216812800; 24922577900; 57216809637","Super-Resolution Based and Topological Structure for Narrow Road Extraction from Remote Sensing Image","2020","Lecture Notes in Electrical Engineering","571 LNEE","","","1402","1410","8","10.1007/978-981-13-9409-6_168","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084748717&doi=10.1007%2f978-981-13-9409-6_168&partnerID=40&md5=228d67e093d23db1f790f6b0be3e8a89","It is difficult to extract a narrow road with a width of only a few pixels from a remote sensing image. In order to solve this problem, it is proposed to process the remote sensing image with super-resolution. This paper extends the details of narrow roads by using the Deep Convolutional Neural Network (DCNN) method. Next, some noise points or roads of error extraction are processed by topological structure. To verify performance of the experimental method, experimental research on open remote sensing image data set is carried out. The experimental result is to compare the original image, super-resolution image, and topology filtering. Experimental results demonstrate that the new method has better effectiveness and superiority over the original remote sensing image. © 2020, Springer Nature Singapore Pte Ltd.","Convolutional neural networks; Deep neural networks; Extraction; Feature extraction; Optical resolving power; Remote sensing; Roads and streets; Topology; Error extractions; Experimental methods; Experimental research; Original images; Remote sensing images; Road extraction; Super resolution; Topological structure; Image processing","Narrow road extraction; Remote sensing image; Super-resolution; Topological structure","Conference paper","Final","","Scopus","2-s2.0-85084748717"
"Ghaffar M.A.A.; McKinstry A.; Maul T.; Vu T.T.","Ghaffar, M.A.A. (57188717249); McKinstry, A. (54898277600); Maul, T. (24779754500); Vu, T.T. (7102344742)","57188717249; 54898277600; 24779754500; 7102344742","DATA AUGMENTATION APPROACHES for SATELLITE IMAGE SUPER-RESOLUTION","2019","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","4","2/W7","","47","54","7","10.5194/isprs-annals-IV-2-W7-47-2019","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084668861&doi=10.5194%2fisprs-annals-IV-2-W7-47-2019&partnerID=40&md5=1042fc0c6a0dcf8cb89a572c5ded4620","Data augmentation is a well known technique that is frequently used in machine learning tasks to increase the number of training instances and hence decrease model over-fitting. In this paper we propose a data augmentation technique that can further boost the performance of satellite image super resolution tasks. A super-resolution convolutional neural network (SRCNN) was adopted as a state-of-the-art deep learning model to test the proposed data augmentation technique. Different augmentation techniques were studied to investigate their relative importance and accuracy gains. We categorized the augmentation methods into instance based and channel based augmentation methods. The former refers to the standard approach of creating new data instances through applying image transformations to the original images such as adding artificial noise, rotations and translations to training samples, while in the latter we fuse auxiliary channels (or custom bands) with each training instance, which helps the model learn useful representations. Fusing auxiliary derived channels to a satellite image RGB combination can be seen as a spectral-spatial fusion process as we explain later. Several experiments were carried out to evaluate the efficacy of the proposed fusion-based augmentation method compared with traditional data augmentation techniques such as rotation, flip and noisy training inputs. The reconstruction quality of the high resolution output was quantitatively evaluated using Peak-Signal-To-Noise-Ratio (PSNR) and qualitatively through visualisation of test samples before and after super-resolving. © 2019 ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences. All rights reserved.","Convolutional neural networks; Deep learning; Optical resolving power; Quality control; Remote sensing; Satellites; Signal to noise ratio; Augmentation methods; Augmentation techniques; Auxiliary channel; Data augmentation; High-resolution output; Image transformations; Peak signal to noise ratio; Reconstruction quality; Learning systems","Convolutional Neural Networks; Data Augmentation; Deep Learning; Landsat-8; Super Resolution","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85084668861"
"Sidorov O.; Hardeberg J.Y.","Sidorov, Oleksii (57204790438); Hardeberg, Jon Yngve (7004092442)","57204790438; 7004092442","Deep hyperspectral prior: Single-image denoising, inpainting, super-resolution","2019","Proceedings - 2019 International Conference on Computer Vision Workshop, ICCVW 2019","","","9022040","3844","3851","7","10.1109/ICCVW.2019.00477","70","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082459903&doi=10.1109%2fICCVW.2019.00477&partnerID=40&md5=520f13e0337701168dd87bd5e505539d","Deep learning algorithms have demonstrated state-of-the-art performance in various tasks of image restoration. This was made possible through the ability of CNNs to learn from large exemplar sets. However, the latter becomes an issue for hyperspectral image processing where datasets commonly consist of just a few images. In this work, we propose a new approach to denoising, inpainting, and super-resolution of hyperspectral image data using intrinsic properties of a CNN without any training. The performance of the given algorithm is shown to be comparable to the performance of trained networks, while its application is not restricted by the availability of training data. This work is an extension of original 'deep prior' algorithm to hyperspectral imaging domain and 3D-convolutional networks. © 2019 IEEE.","Computer vision; Deep learning; Hyperspectral imaging; Image reconstruction; Learning algorithms; Optical resolving power; Remote sensing; Spectroscopy; Three dimensional computer graphics; 3D CNN; De-noising; Image generations; Image priors; Inpainting; Single images; Super resolution; Image denoising","3D CNN; Deep image prior; Deep learning; Denoising; Hyperspectral imaging; Image generation; Inpainting; Remote sensing; Single image; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85082459903"
"Wu Y.; Yuan Y.; Guan J.; Yin L.; Chen J.; Zhang G.; Feng P.","Wu, Yanxia (43362038300); Yuan, Ye (57203237812); Guan, Jian (57202816841); Yin, Libo (57202788786); Chen, Jinyong (57191226304); Zhang, Ge (57861674300); Feng, Pengming (56517583500)","43362038300; 57203237812; 57202816841; 57202788786; 57191226304; 57861674300; 56517583500","Joint Convolutional Neural Network for Small-Scale Ship Classification in SAR Images","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8897831","2619","2622","3","10.1109/IGARSS.2019.8897831","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077712733&doi=10.1109%2fIGARSS.2019.8897831&partnerID=40&md5=e026258a518ac1e0ae7aaa7f494f0f85","Ship classification using synthetic aperture radar (SAR) imagery is a challenge problem in maritime surveillance. Because of the scale limitation of ship targets in SAR image, convolutional neural networks (CNNs) can not achieve similar performance as for natural image classification. In this paper, we propose a joint CNNs framework for small-scale ship targets classification in SAR image, where a generator and a classifier are jointly connected. The generator can reconstruct the small-scale low-resolution (LR) images to large-scale super-resolution (SR) images, and the classifier is used for ship classification. A novel joint loss optimization strategy is introduced to solve the problem, where an MSE-based content loss is employed to generate high quality SR images, and a classification loss is applied to enable the generator and the classifier to be trained in a joint way. Experiments are conducted to demonstrate the superior performance of our proposed method, as compared with the state-of-the-art methods. © 2019 IEEE.","Convolution; Convolutional neural networks; Geology; Image classification; Radar target recognition; Remote sensing; Ships; Synthetic aperture radar; Joint optimization; Low resolution images; Maritime surveillance; Optimization strategy; SAR image processing; Ship classification; State-of-the-art methods; Synthetic Aperture Radar Imagery; Radar imaging","convolutional neural networks; joint optimization; SAR image processing; ship classification","Conference paper","Final","","Scopus","2-s2.0-85077712733"
"Ma W.; Pan Z.; Yuan F.; Lei B.","Ma, Wen (57207877267); Pan, Zongxu (54788169800); Yuan, Feng (57214435272); Lei, Bin (14063767500)","57207877267; 54788169800; 57214435272; 14063767500","Super-resolution of remote sensing images via a dense residual generative adversarial network","2019","Remote Sensing","11","21","2578","","","","10.3390/rs11212578","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074641655&doi=10.3390%2frs11212578&partnerID=40&md5=bca7c02fd281744f4a4761f26f63a6d7","Single image super-resolution (SISR) has been widely studied in recent years as a crucial technique for remote sensing applications. In this paper, a dense residual generative adversarial network (DRGAN)-based SISR method is proposed to promote the resolution of remote sensing images. Different from previous super-resolution (SR) approaches based on generative adversarial networks (GANs), the novelty of our method mainly lies in the following factors. First, we made a breakthrough in terms of network architecture to improve performance. We designed a dense residual network as the generative network in GAN, which can make full use of the hierarchical features from low-resolution (LR) images. We also introduced a contiguous memory mechanism into the network to take advantage of the dense residual block. Second, we modified the loss function and altered the model of the discriminative network according to theWasserstein GAN with a gradient penalty (WGAN-GP) for stable training. Extensive experiments were performed using the NWPU-RESISC45 dataset, and the results demonstrated that the proposed method outperforms state-of-the-art methods in terms of both objective evaluation and subjective perspective. © 2019 by the authors.","Network architecture; Optical resolving power; Adversarial networks; Dense residual network (DRN); Remote sensing images; Single images; Wasserstein GAN with gradient penalty (WGAN-GP); Remote sensing","Dense residual network (DRN); Generative adversarial network (GAN); Remote sensing images; Single image super-resolution (SISR); Wasserstein GAN with gradient penalty (WGAN-GP)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85074641655"
"","","","PIA 2019+MRSS 2019 - Photogrammetric Image Analysis and Munich Remote Sensing Symposium","2019","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","4","2/W7","","","","242","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084647700&partnerID=40&md5=f5d8a82957694578d0f28aa5d942be3e","The proceedings contain 31 papers. The topics discussed include: a comparison between the Hadoop and spark distributed frameworks in the context of region-growing segmentation of remote sensing images; semantic change detection of river ground points in airborne lidar bathymetry data using voxel occupancies; using neural networks to detect objects in MLS point clouds based on local point neighborhoods; a many-to-many fully convolutional recurrent network for multi-temporal crop recognition; development of a high-speed videogrammetric measurement system with application in large-scale shaking table test; data augmentation approaches for satellite image super-resolution; and monocular-depth assisted semi-global matching.","","","Conference review","Final","","Scopus","2-s2.0-85084647700"
"Wang B.; Xu H.; Sun J.; Hu Y.; Zuo C.","Wang, Bowen (57204607674); Xu, Hao (57212506491); Sun, Jiasong (56048572500); Hu, Yan (56681484200); Zuo, Chao (36007852700)","57204607674; 57212506491; 56048572500; 56681484200; 36007852700","Super resolution imaging method based on the synthetic aperture system","2020","Proceedings of SPIE - The International Society for Optical Engineering","11571","","115710Q","","","","10.1117/12.2580282","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096361828&doi=10.1117%2f12.2580282&partnerID=40&md5=325bcbd5cedf683f0a6ff155267d7d23","In the long-distance imaging system, one of the main factors limiting the imaging resolution is the size of the imaging lens aperture, which determines the diffraction limit of the optical system. Therefore, we propose a non-interference synthetic aperture super-resolution imaging reconstruction and optimization method. The camera array is used to collect a series of low-resolution sub-Aperture images. Combined with Fourier ptychography imaging algorithm, the spectrum and aperture function of the current sub-Aperture diameter is updated by using the optimization algorithm based on adaptive step size.To obtain the high-resolution spectrum information of the target to be measured. Meanwhile, the high-resolution spectrum information of the target is obtained. In the reconstruction process, the simulated annealing algorithm is introduced to correct the positioning error of the sub-Aperture, and the optimization algorithm is used to update the sub-Aperture, which greatly improves the accuracy of the reconstruction results and achieves the theoretical imaging resolution. Moreover, it also has excellent imaging results for complex objects, which verifies the feasibility of the algorithm. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Diffraction; Image resolution; Lenses; Optical resolving power; Optical systems; Simulated annealing; Synthetic apertures; Diffraction limits; High-resolution spectra; Imaging resolutions; Optimization algorithms; Optimization method; Reconstruction process; Simulated annealing algorithms; Super resolution imaging; Image processing","Multi-Image Reconstruction.; Remote Sensing; Super-Resolution; Synthetic Apertures","Conference paper","Final","","Scopus","2-s2.0-85096361828"
"Cascarano P.; Corsini F.; Gandolfi S.; Piccolomini E.L.; Mandanici E.; Tavasci L.; Zama F.","Cascarano, Pasquale (57211336814); Corsini, Francesco (57208740344); Gandolfi, Stefano (7006708900); Piccolomini, Elena Loli (57221103621); Mandanici, Emanuele (35208864200); Tavasci, Luca (56610228900); Zama, Fabiana (6603081875)","57211336814; 57208740344; 7006708900; 57221103621; 35208864200; 56610228900; 6603081875","Super-resolution of thermal images using an automatic total variation based method","2020","Remote Sensing","12","10","1642","","","","10.3390/rs12101642","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085551645&doi=10.3390%2frs12101642&partnerID=40&md5=7b2012e7d7b1599ec1e10a9eea59e712","The relatively poor spatial resolution of thermal images is a limitation for many thermal remote sensing applications. A possible solution to mitigate this problem is super-resolution, which should preserve the radiometric content of the original data and should be applied to both the cases where a single image or multiple images of the target surface are available. In this perspective, we propose a new super-resolution algorithm, which can handle either single or multiple images. It is based on a total variation regularization approach and implements a fully automated choice of all the parameters, without any training dataset nor a priori information. Through simulations, the accuracy of the generated super-resolution images was assessed, in terms of both global statistical indicators and analysis of temperature errors at hot and cold spots. The algorithm was tested and applied to aerial and terrestrial thermal images. Results and comparisons with state-of-the-art methods confirmed an excellent compromise between the quality of the high-resolution images obtained and the required computational time. © 2020 by the authors.","Antennas; Remote sensing; Computational time; High resolution image; Spatial resolution; State-of-the-art methods; Statistical indicators; Super resolution algorithms; Thermal remote sensing; Total variation regularization; Optical resolving power","Automatic regularization; Regularized reconstruction; Super-resolution; Thermal images; Total variation regularization","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85085551645"
"Yang J.; Zhao Y.-Q.; Chan J.C.-W.","Yang, Jingxiang (55964111200); Zhao, Yong-Qiang (35365726800); Chan, Jonathan Cheung-Wai (57208276698)","55964111200; 35365726800; 57208276698","Hyperspectral Image Super-Resolution Based on Multi-Scale Wavelet 3D Convolutional Neural Network","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898813","2770","2773","3","10.1109/IGARSS.2019.8898813","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077681164&doi=10.1109%2fIGARSS.2019.8898813&partnerID=40&md5=a95ad8385a20dd76b91d948997973e19","Super-resolution (SR) of hyperspectral image (HSI) is of significance for its applications. Wavelet decomposition can be used to capture textures and structures in the HSI. In this study, we propose a multi-scale wavelet 3D convolutional neural network (MW-3D-CNN) for HSI SR. Instead of reconstructing the high resolution (HR) HSI directly, we predict the wavelet coefficients of HR HSI with the proposed network, which is composed of an embedding subnet and a predicting subnet. Both of them are built with 3D convolutional layers. The embedding subnet extracts deep spatial-spectral features from the low resolution (LR) HSI and represents the LR HSI as a set of feature cubes. The feature cubes are then fed to the predicting subnet. There are multiple output branches in the predicting subnet, each of which corresponds to a wavelet sub-band and predicts the wavelet coefficients of HR HSI. By applying inverse wavelet transform to the predicted wavelet coefficients, the HR HSI can be obtained. In the training stage, we propose to train MW-3D-CNN with L1 norm loss, which is more suitable than the conventional L2 norm loss for penalizing the errors in different wavelet sub-bands. In the experiment, the performance is tested on several HSI datasets. © 2019 IEEE.","Convolution; Embeddings; Forecasting; Geology; Optical resolving power; Remote sensing; Spectroscopy; Textures; Wavelet decomposition; Different wavelets; HyperSpectral; Image super resolutions; Inverse wavelet transforms; Multi-scale wavelet; Super resolution; wavelet; Wavelet coefficients; Convolutional neural networks","CNN; hyperspectral; Super-resolution; wavelet","Conference paper","Final","","Scopus","2-s2.0-85077681164"
"Zhang K.; Sumbul G.; Demir B.","Zhang, Kexin (57221087691); Sumbul, Gencer (57196192158); Demir, Begum (15131434800)","57221087691; 57196192158; 15131434800","An Approach to Super-Resolution of Sentinel-2 Images Based on Generative Adversarial Networks","2020","2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium, M2GARSS 2020 - Proceedings","","","9105165","69","72","3","10.1109/M2GARSS47143.2020.9105165","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086704517&doi=10.1109%2fM2GARSS47143.2020.9105165&partnerID=40&md5=9f39cc5fcc004c7aac1a60ab0390b2aa","This paper presents a generative adversarial network based super-resolution (SR) approach (which is called as S2GAN) to enhance the spatial resolution of Sentinel-2 spectral bands. The proposed approach consists of two main steps. The first step aims to increase the spatial resolution of the bands with 20m and 60m spatial resolutions by the scaling factors of 2 and 6, respectively. To this end, we introduce a generator network that performs SR on the lower resolution bands with the guidance of the bands associated to 10m spatial resolution by utilizing the convolutional layers with residual connections and a long skip-connection between inputs and outputs. The second step aims to distinguish SR bands from their ground truth bands. This is achieved by the proposed discriminator network, which alternately characterizes the high level features of the two sets of bands and applying binary classification on the extracted features. Then, we formulate the adversarial learning of the generator and discriminator networks as a min-max game. In this learning procedure, the generator aims to produce realistic SR bands as much as possible so that the discriminator incorrectly classifies SR bands. Experimental results obtained on different Sentinel-2 images show the effectiveness of the proposed approach compared to both conventional and deep learning based SR approaches. © 2020 IEEE.","Deep learning; Geology; Image resolution; Optical resolving power; Remote sensing; Adversarial learning; Adversarial networks; Binary classification; High-level features; Learning procedures; Lower resolution; Spatial resolution; Super resolution; Discriminators","generative adversarial network; remote sensing; Sentinel-2 images; super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85086704517"
"Liu X.; Liu Q.; Wang Y.","Liu, Xiangyu (57192693924); Liu, Qingjie (55534263100); Wang, Yunhong (34870959400)","57192693924; 55534263100; 34870959400","Remote sensing image fusion based on two-stream fusion network","2020","Information Fusion","55","","","1","15","14","10.1016/j.inffus.2019.07.010","130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070680080&doi=10.1016%2fj.inffus.2019.07.010&partnerID=40&md5=0b2e217fe3e59d3ce911b495b6de938e","Remote sensing image fusion (also known as pan-sharpening) aims at generating a high resolution multi-spectral (MS) image from inputs of a high spatial resolution single band panchromatic (PAN) image and a low spatial resolution multi-spectral image. Inspired by the astounding achievements of convolutional neural networks (CNNs) in a variety of computer vision tasks, in this paper we propose a Two-stream Fusion Network (TFNet) to address the problem of pan-sharpening. Unlike many previous CNN based methods that consider pan-sharpening as a super-resolution problem and perform pan-sharpening through mapping the stacked PAN and MS to the target high resolution MS image, the proposed TFNet aims to fuse PAN and MS images in feature domain and reconstruct the pan-sharpened image from the fused features. The TFNet mainly consists of three parts. The first part is comprised of two networks extracting features from PAN and MS images, respectively. The subsequent network fuses them together to form compact features that represent both spatial and spectral information of PAN and MS images, simultaneously. Finally, the desired high spatial resolution MS image is recovered from the fused features through an image reconstruction network. Experiments on Quickbird and GaoFen-1 images demonstrate that the proposed TFNet can fuse PAN and MS images effectively, and produce pan-sharpened images competitive with even superior to state of the arts. © 2019 Elsevier B.V.","Computer hardware description languages; Convolution; Deep learning; Deep neural networks; Image reconstruction; Image resolution; Neural networks; Remote sensing; Spectroscopy; Convolutional neural network; High spatial resolution; Multispectral images; Pan-sharpening; Panchromatic (Pan) image; Reconstruction networks; Remote sensing images; Spectral information; Image fusion","Convolutional neural networks; Deep learning; Image fusion; Pan-sharpening; Remote Sensing","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85070680080"
"Ji H.; Gao Z.; Mei T.; Ramesh B.","Ji, Hong (57205763449); Gao, Zhi (55256514200); Mei, Tiancan (8914886000); Ramesh, Bharath (56442158400)","57205763449; 55256514200; 8914886000; 56442158400","Vehicle Detection in Remote Sensing Images Leveraging on Simultaneous Super-Resolution","2020","IEEE Geoscience and Remote Sensing Letters","17","4","8792159","676","680","4","10.1109/LGRS.2019.2930308","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081677087&doi=10.1109%2fLGRS.2019.2930308&partnerID=40&md5=5a95ef4a661454d292e0a2fe01bbb40d","Owing to the relatively small size of vehicles in remote sensing images, lacking sufficient detailed appearance to distinguish vehicles from similar objects, the detection performance is still far from satisfactory compared with the detection results on everyday images. Inspired by the positive effects of super-resolution convolutional neural network (SRCNN) for object detection and the stunning success of deep CNN techniques, we apply generative adversarial network frameworks to realize simultaneous SRCNN and vehicle detection in an end-to-end manner, and the detection loss is backpropagated into the SRCNN during training to facilitate detection. In particular, our work is unsupervised and bypasses the requirement of low-/high-resolution image pairs during the training stage, achieving increased generality and applicability. Extensive experiments on representative data sets demonstrate that our method outperforms the state-of-the-art detectors. (The source code will be made available after the review process. © 2004-2012 IEEE.","Convolution; Object detection; Optical resolving power; Remote sensing; Vehicles; Feature fusion; Region-based; Remote sensing images; Super resolution; Vehicle detection; artificial neural network; detection method; image resolution; remote sensing; satellite imagery; Convolutional neural networks","Faster region-based convolutional neural network (R-CNN); feature fusion; remote sensing images; super-resolution convolutional neural network (SRCNN); vehicle detection","Article","Final","","Scopus","2-s2.0-85081677087"
"Hou Y.; Zhang J.","Hou, Yangshuan (36494442100); Zhang, Jishuai (57218298226)","36494442100; 57218298226","Unsupervised remote sensing image super-resolution method based on adaptive domain distance measurement network","2020","Proceedings - 2020 3rd International Conference on Advanced Electronic Materials, Computers and Software Engineering, AEMCSE 2020","","","9131243","256","259","3","10.1109/AEMCSE50948.2020.00062","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088658770&doi=10.1109%2fAEMCSE50948.2020.00062&partnerID=40&md5=1f3e8c001c401b0f7b410d6433581906","Compared with supervised learning, unsupervised learning is more practical; however, the associated training process is more difficult and complex. To solve the problems of unstable training and insufficient diversity of generative adversarial networks (GAN), which are widely used to realize unsupervised learning, we propose a novel unsupervised remote sensing image super-resolution method based on a reverse generating network module and the adaptive domain distance measurement network. The discriminant network of GAN is considered as a tool to measure a certain image attribute instead of the original GAN binary classification network. Furthermore, the adaptive domain distance measurement network is used to back feed the information of a high-resolution image to guide the optimization of the generating network. The results of experiments performed on various datasets demonstrate the effectiveness of the proposed method. © 2020 IEEE.","Distance measurement; Optical resolving power; Software engineering; Unsupervised learning; Adversarial networks; Binary classification; High resolution image; Image attributes; Remote sensing images; Training process; Remote sensing","Domain; GAN; Remote senseng; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85088658770"
"Shu Z.; Zong Z.; Huang L.; Huang L.","Shu, Zhaowei (57213188289); Zong, Zhulin (18435612400); Huang, Libing (57213187166); Huang, Limei (57213187159)","57213188289; 18435612400; 57213187166; 57213187159","Forward-Looking Radar Super-Resolution Imaging Combined TSVD with L1 Norm Constraint","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8897855","2559","2562","3","10.1109/IGARSS.2019.8897855","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077698579&doi=10.1109%2fIGARSS.2019.8897855&partnerID=40&md5=a80701ea3e60d1c65bb116de991977d5","This paper is devoted to the research of methods and experiments of regularization deconvolution theory on the azimuth super-resolution of forward-looking imaging radar. L1 norm is usually used as a regular term to obtain a stable solution due to its strong resolving power for sparse targets. However, deconvolution is an ill-posed problem, in the process of deconvolution iteration, using the L1 norm as a regular term is sensitive to noise and may causes a large deviation between the solution and the true value due to the influence of noise. This paper proposes the super-resolution imaging method combined truncation singular value decomposition (TSVD) with L1 norm constraint. At lower SNR, this method effectively solves the problem of noise amplification during deconvolution iteration. The effectiveness and advancement of the proposed algorithm are verified by simulation results. © 2019 IEEE.","Geology; Iterative methods; Optical resolving power; Radar; Remote sensing; Signal to noise ratio; Singular value decomposition; Forward looking; Forward looking radars; Ill posed problem; L1 norm; Noise amplification; Super resolution; Super resolution imaging; TSVD; Radar imaging","azimuth super-resolution; Forward-looking imaging; L1 norm.; TSVD","Conference paper","Final","","Scopus","2-s2.0-85077698579"
"Kanakaraj S.; Nair M.S.; Kalady S.","Kanakaraj, Sithara (55342005100); Nair, Madhu S. (24475038000); Kalady, Saidalavi (25723260000)","55342005100; 24475038000; 25723260000","Adaptive Importance Sampling Unscented Kalman Filter based SAR image super resolution","2019","Computers and Geosciences","133","","104310","","","","10.1016/j.cageo.2019.104310","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070403238&doi=10.1016%2fj.cageo.2019.104310&partnerID=40&md5=99ceae12317297acb7901260798a7967","Enhancing Synthetic Aperture Radar (SAR) images for sharp and detailed images through super-resolution (SR) is of great significance in many remote sensing applications. Due to the inherent resolution limitations and the cost incurred for further development of sensor devices, image enhancements through image processing techniques have become more popular. However, in these techniques, the soft edges present in the images are not reconstructed completely, thereby marring the clarity of the generated image. This paper presents a method to restore more details in the image by adaptively adjusting the measurement noise covariance and process noise covariance into the intensity estimation framework for SAR image super-resolution. For this, an Adaptive Importance Sampling Unscented Kalman Filter (ISUKF) framework is implemented using the covariance matching technique. Experimental results indicate that the super-resolution using ISUKF framework performs better, regarding denoising and feature preservation, when accounted for the measurement and process noise covariance. It also outperforms the other recent and standard SR techniques covered in the literature. © 2019 Elsevier Ltd","Adaptive algorithms; Image enhancement; Image reconstruction; Image sampling; Importance sampling; Kalman filters; Optical resolving power; Remote sensing; Synthetic aperture radar; Adaptive importance sampling; Feature preservation; Image processing technique; Noise covariance; Remote sensing applications; Super resolution; Synthetic aperture radar (SAR) images; Unscented Kalman Filter; covariance analysis; image processing; image resolution; Kalman filter; remote sensing; sampling; synthetic aperture radar; Radar imaging","Adaptive algorithm; Importance sampling; Noise covariance; Super resolution; Synthetic Aperture Radar image; Unscented Kalman Filter","Article","Final","","Scopus","2-s2.0-85070403238"
"Zhu F.-Z.; Liu Y.; Huang X.; Bai H.-Y.; Wu H.","Zhu, Fu-Zhen (12780819500); Liu, Yue (57200522975); Huang, Xin (57204029373); Bai, Hong-Yi (56555831200); Wu, Hong (55619294193)","12780819500; 57200522975; 57204029373; 56555831200; 55619294193","Remote sensing image super-resolution based on improved sparse representation; [改进的稀疏表示遥感图像超分辨重建]","2019","Guangxue Jingmi Gongcheng/Optics and Precision Engineering","27","3","","718","725","7","10.3788/OPE.20192703.0718","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066121388&doi=10.3788%2fOPE.20192703.0718&partnerID=40&md5=41878e66c5bf7f4daa9c01a7d40bca5a","To solve the problems of lost details and added noise in the previous sparse representation image super-resolution, an improved feature extraction algorithm was proposed to improve the image Super-Resolution Reconstruction (SRR) effect. The Gaussian filter was replaced by a symmetric nearest neighbor filter to speed up image super-resolution, and the problem of dictionary learning in the feature space was solved. First, sample training images were generated based on the remote sensing image degradation model, and high-low resolution images were divided into image patches sized 7×7. Then, a high-low resolution joint dictionary mapping matrix was generated after the dictionary was trained and updated. Finally, image super-resolution reconstruction was performed in sparse representation. Experimental results revealed that the proposed method reconstructed a higher-quality super-resolution image in less time. Simultaneously, as compared with the image obtained with the most advanced sparse representation super-resolution algorithm, the SRR resulting image contained more texture details of ground objects. In addition, the peak signal-to-noise ratio and structural similarity index measure were increased by approximately 1.7 dB and 0.016, respectively. Conclusion: The improved sparse representation SRR algorithm can effectively improve the SRR effect of remote sensing images and reduce the super-resolution reconstruction time. © 2019, Science Press. All right reserved.","Image reconstruction; Optical resolving power; Remote sensing; Signal to noise ratio; Space optics; Textures; Dictionary learning; Feature extraction algorithms; Image super-resolution reconstruction; Peak signal to noise ratio; Sparse representation; Structural similarity index measures; Super resolution algorithms; Super resolution reconstruction; Image enhancement","Dictionary learning; Image super-resolution reconstruction; Sparse representation","Article","Final","","Scopus","2-s2.0-85066121388"
"Zhu X.; Xu Y.; Wei Z.","Zhu, Xi (57213192472); Xu, Yang (57188730185); Wei, Zhihui (55761764700)","57213192472; 57188730185; 55761764700","Super-Resolution of Sentinel-2 Images Based on Deep Channel-Attention Residual Network","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8897860","628","631","3","10.1109/IGARSS.2019.8897860","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077700619&doi=10.1109%2fIGARSS.2019.8897860&partnerID=40&md5=e12019b1ad725728e503bb30266a6360","Sentinel-2 data has become an important tool for current and future earth observation due to its high quality, free availability and world-wide coverage. However, some of the spectral bands are sensed at reduced resolution due to design considerations and sensor hardware limitations. So in this paper we present a super-resolution method based on Convolutional Neural Networks (CNNs) to infer all the 20m spectral bands in the highest available resolution. This is accomplished by using an improved residual network and meanwhile we propose a channel attention mechanism to adaptively rescale the characteristics of the channels by considering the interdependencies among the channels. The proposed solution compares against several alternative methods according to different quality indexes. Our network provides the best results and a compelling visual effect on the sentinel-2 images. © 2019 IEEE.","Convolution; Geology; Optical resolving power; Remote sensing; Attention mechanisms; channel attention; Design considerations; Earth observations; Reduced resolution; Sentinel-2; Super resolution; Superresolution methods; Convolutional neural networks","channel attention; convolutional neural network; residual network; Sentinel-2; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85077700619"
"Qin M.; Mavromatis S.; Hu L.; Zhang F.; Liu R.; Sequeira J.; Du Z.","Qin, Mengjiao (57193907473); Mavromatis, Sébastien (22433774300); Hu, Linshu (57215775327); Zhang, Feng (56434720200); Liu, Renyi (55809641900); Sequeira, Jean (56231992200); Du, Zhenhong (25929119800)","57193907473; 22433774300; 57215775327; 56434720200; 55809641900; 56231992200; 25929119800","Remote sensing single-image resolution improvement using a deep gradient-aware network with image-specific enhancement","2020","Remote Sensing","12","5","758","","","","10.3390/rs12050758","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081932884&doi=10.3390%2frs12050758&partnerID=40&md5=060ec37ec6cec5168ede7403fdef9ec3","Super-resolution (SR) is able to improve the spatial resolution of remote sensing images, which is critical for many practical applications such as fine urban monitoring. In this paper, a new single-image SR method, deep gradient-aware network with image-specific enhancement (DGANet-ISE) was proposed to improve the spatial resolution of remote sensing images. First, DGANet was proposed to model the complex relationship between low-and high-resolution images. A new gradient-aware loss was designed in the training phase to preserve more gradient details in super-resolved remote sensing images. Then, the ISE approach was proposed in the testing phase to further improve the SR performance. By using the specific features of each test image, ISE can further boost the generalization capability and adaptability of our method on inexperienced datasets. Finally, three datasets were used to verify the effectiveness of our method. The results indicate that DGANet-ISE outperforms the other 14 methods in the remote sensing image SR, and the cross-database test results demonstrate that our method exhibits satisfactory generalization performance in adapting to new data. © 2020 by the authors.","Image resolution; Optical resolving power; Remote sensing; Complex relationships; Generalization capability; Generalization performance; High resolution image; Remote sensing images; Resolution improvement; Spatial resolution; Super resolution; Image enhancement","CNN; Deep gradient-aware network; Image-specific enhancement; Remote sensing; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85081932884"
"Srinath R.; Vrindavanam J.; Vasudev V.P.; Supreeth S.","Srinath, Raghunandan (57216823210); Vrindavanam, Jayavrinda (36053903900); Vasudev, V. Prathith (57216829395); Supreeth, S. (57914586900)","57216823210; 36053903900; 57216829395; 57914586900","An Iterative Approach to Super-Resolution using Multiple Low-Resolution Images","2019","2019 Global Conference for Advancement in Technology, GCAT 2019","","","8978291","","","","10.1109/GCAT47503.2019.8978291","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084801577&doi=10.1109%2fGCAT47503.2019.8978291&partnerID=40&md5=f34edb190a871c9c84fa6fa4a411cb69","Keeping in view the increasing requirements of super resolution in a wide range of applications, this paper adds to the existing literature of alternative algorithmic approach to develop a high resolution image from multiple low resolution images. The paper, after a review of the existing methods in super resolution, presents an iterative approach using multiple low-resolution images building on top of established tools like New Edge Directed Interpolation, through a novel approach. The approach tries to discover higher frequencies from a multiplicity of data samples available, and preserves these edges across iterations. The proposed method has been tested on images of a range of complexities, including on satellite images, and the results are promising. © 2019 IEEE.","Optical resolving power; Algorithmic approach; High resolution image; Higher frequencies; Iterative approach; Low resolution images; New edge-directed interpolations; Satellite images; Super resolution; Iterative methods","edge detection; Image quality; INEDI; Interpolation; Remote sensing; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85084801577"
"Jiang W.; Luo X.","Jiang, Wenjie (57210322716); Luo, Xiaoshu (7402870658)","57210322716; 7402870658","Research on super-resolution reconstruction algorithm of remote sensing image based on generative adversarial networks","2019","Proceedings of 2019 IEEE 2nd International Conference on Automation, Electronics and Electrical Engineering, AUTEEE 2019","","","9033352","438","441","3","10.1109/AUTEEE48671.2019.9033352","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083255066&doi=10.1109%2fAUTEEE48671.2019.9033352&partnerID=40&md5=41de8d3169fbce26074b67d30d347923","Due to natural conditions and hardware manufacturing processes, the resolution of remote sensing images is generally low. Obtaining high-definition remote sensing images by simply improving hardware and manufacturing processes is not only costly and technically challenging but also cannot be deployed on a large scale. Aiming at the limitations of the traditional methods, this paper studies the image super-resolution reconstruction method for improving the generated anti-network. Firstly, the generator network is optimized, and an RRDB (Residual-in-Residual Dense without BN (Batch Normalization) is used. Block) module; secondly, the related idea of relativistic GAN (relativistic generative adversarial network) is introduced, the relative value of the discriminator is not the absolute value; finally, the sensation loss is improved, and the feature is used before the function is activated. The test results show that the proposed algorithm is better than SRGAN (Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network), SRCNN (Super-Resolution Convolutional Neural Network) and FSRCNN (Fast Super-Resolution Convolutional Neural Network). The clarity of the reconstructed image is improved, and the reconstructed image quality is significantly improved. © 2019 IEEE.","Convolution; Convolutional neural networks; Image enhancement; Manufacture; Optical resolving power; Remote sensing; Adversarial networks; Image super-resolution reconstruction; Manufacturing process; Natural conditions; Reconstructed image; Remote sensing images; Super resolution; Super resolution reconstruction; Image reconstruction","Aerial image; Generative Adversarial Networks; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85083255066"
"Huang Q.; Li W.; Hu T.; Tao R.","Huang, Qian (57210124335); Li, Wei (56215159000); Hu, Ting (57212948752); Tao, Ran (7102857080)","57210124335; 56215159000; 57212948752; 7102857080","Hyperspectral Image Super-resolution Using Generative Adversarial Network and Residual Learning","2019","ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","2019-May","","8683893","3012","3016","4","10.1109/ICASSP.2019.8683893","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069455619&doi=10.1109%2fICASSP.2019.8683893&partnerID=40&md5=85cc31b6adcef332903c828fbe7093aa","Due to the limitation of image acquisition, hyperspectral remote sensing imagery is hard to reflect in both high spatial and spectral resolutions. Super-resolution (SR) is a technique which can improve the spatial resolution. Inspired by recent achievements in deep convolutional neural network (CNN) and generative adversarial network (GAN), a GAN based framework is proposed for hyperspectral image super-resolution. In the proposed method, residual learning is used to obtain a high metrics and spectral fidelity, and a shorter connection is set between the input layer and output layer. The gradient features from low-resolution (LR) image to high-resolution (HR) are utilized as auxiliary information to assist deep CNN to carry out counter training with discriminator. Experimental results demonstrate that the proposed SR algorithm achieves superior performance in spectral fidelity and spatial resolution compared with baseline methods. © 2019 IEEE.","Deep neural networks; Image resolution; Neural networks; Optical resolving power; Remote sensing; Spectroscopy; Speech communication; Adversarial networks; Auxiliary information; Convolutional neural network; Hyper-spectral imageries; Hyperspectral remote sensing; Image super resolutions; Low resolution images; Super resolution; Audio signal processing","Generative Adversarial Network; Hyperspectral Imagery; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85069455619"
"Akiyama Y.; Kidera S.","Akiyama, Yoshiki (57201894943); Kidera, Shouhei (14031687600)","57201894943; 14031687600","K-Space Decomposition Based Range Points Migration Method for Millimeter Wave Radar","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8897940","680","683","3","10.1109/IGARSS.2019.8897940","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077681576&doi=10.1109%2fIGARSS.2019.8897940&partnerID=40&md5=b539f2ac6d263c779e0b3ade129cc75c","Millimeter wave short range radar is a great potential for monitoring sensor being applicable to optically challenging environments (e.g., smog, fog or darkness). While a number of imaging algorithms have been intensively developed, the range points migration(RPM) method is regarded as one of the most promising options to achieve accurate and fast three-dimensional imaging. However, since the RPM is based on incoherent processing, it has disadvantage for angular resolution in considering millimeter wave radar with lower fractional bandwidth. To address with the above problem, this paper proposes a k-space decomposition based RPM method, where the received data is converted and decomposed into the k-space to retain the desired angular resolution. As a notable feature of the proposed method, it offers a clustered range points decomposed by k-space, which contributes to enhance an imaging accuracy by the RPM. The two-dimensional and three-dimensional numerical tests demonstrate the effectiveness of our proposed method, compared with other super resolution algorithms. © 2019 IEEE.","Bandwidth; Geology; Millimeter waves; Numerical methods; Optical resolving power; Radar imaging; Remote sensing; Space optics; K space; Millimeter wave radar; Range points migration (RPM); Range sensors; Super resolution imaging; Space-based radar","k-space decomposition; Millimeter wave radar; Range points migration (RPM); short-range sensor; Super-resolution imaging","Conference paper","Final","","Scopus","2-s2.0-85077681576"
"Li J.; Cui R.; Li B.; Li Y.; Mei S.; Du Q.","Li, Jiaojiao (55934244200); Cui, Ruxing (57211523782); Li, Bo (57188584536); Li, Yunsong (55986546100); Mei, Shaohui (25822578400); Du, Qian (7202060063)","55934244200; 57211523782; 57188584536; 55986546100; 25822578400; 7202060063","Dual 1D-2D Spatial-Spectral CNN for Hyperspectral Image Super-Resolution","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898352","3113","3116","3","10.1109/IGARSS.2019.8898352","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077683751&doi=10.1109%2fIGARSS.2019.8898352&partnerID=40&md5=13ac9ac07107208fcbb2a6cf1c19d756","Hyperspectral image (HSI) spatial super-resolution(SR) is a challenging task. Compared with a RGB images, the mapping between the low-high HSI pairs is more difficult since much more spectral bands are involved. In this paper, a novel dual 1D-2D spatial-spectral convolutional neural network (CNN) architecture is proposed for spatial SR of HSIs. Specifically, by differential treatment over redundancy in spectral and spatial domains of an HSI, the spectral and spatial context are first separately explored by 1D and 2D convolution. These two kinds of feature information are then fused using a novel hierarchical side connection, which impose the spectral information to the spatial path gradually. Experimental results over benchmark Pavia data set demonstrate that the proposed architecture clearly outperform state-of-the-art 3D CNN based works in terms of both visual quality and quantitative assessment. © 2019 IEEE.","Benchmarking; Convolution; Convolutional neural networks; Geology; Network architecture; Optical resolving power; Remote sensing; Spectroscopy; Differential treatment; Feature information; Image super resolutions; Proposed architectures; Quantitative assessments; spatial-spectral; Spectral information; Super resolution; Photomapping","dual networks; HSI; spatial-spectral; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85077683751"
"Dong X.; Xi Z.; Sun X.; Gao L.","Dong, Xiaoyu (57212387140); Xi, Zhihong (15047162700); Sun, Xu (23499533300); Gao, Lianru (14031580000)","57212387140; 15047162700; 23499533300; 14031580000","Transferred multi-perception attention networks for remote sensing image super-resolution","2019","Remote Sensing","11","23","2857","","","","10.3390/rs11232857","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076569503&doi=10.3390%2frs11232857&partnerID=40&md5=e0c2805a40857f907586d880562fb871","Image super-resolution (SR) reconstruction plays a key role in coping with the increasing demand on remote sensing imaging applications with high spatial resolution requirements. Though many SR methods have been proposed over the last few years, further research is needed to improve SR processes with regard to the complex spatial distribution of the remote sensing images and the diverse spatial scales of ground objects. In this paper, a novel multi-perception attention network (MPSR) is developed with performance exceeding those of many existing state-of-the-art models. By incorporating the proposed enhanced residual block (ERB) and residual channel attention group (RCAG), MPSR can super-resolve low-resolution remote sensing images via multi-perception learning and multi-level information adaptive weighted fusion. Moreover, a pre-train and transfer learning strategy is introduced, which improved the SR performance and stabilized the training procedure. Experimental comparisons are conducted using 13 state-of-the-art methods over a remote sensing dataset and benchmark natural image sets. The proposed model proved its excellence in both objective criterion and subjective perspective. © 2019 by the authors.","Image enhancement; Optical resolving power; Adaptive weighted fusions; Attention mechanisms; Experimental comparison; High spatial resolution; Image super resolutions; State-of-the-art methods; Super resolution; Transfer learning; Remote sensing","Attention mechanism; Remote sensing; Super-resolution; Transfer learning","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85076569503"
"Larabi M.E.A.; Karoui M.S.; Chaib S.; Bakhti K.; Tchenar M.I.","Larabi, Mohammed El Amin (57213354157); Karoui, Moussa Sofiane (15750871100); Chaib, Souleyman (57038610900); Bakhti, Khadidja (57203511701); Tchenar, Mohammed Ilyas (57217201737)","57213354157; 15750871100; 57038610900; 57203511701; 57217201737","Multibranch Cnn-Based Pansharpening with Skip Connection","2020","2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium, M2GARSS 2020 - Proceedings","","","9105231","137","140","3","10.1109/M2GARSS47143.2020.9105231","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086716829&doi=10.1109%2fM2GARSS47143.2020.9105231&partnerID=40&md5=d7a61ec599434c57c47a9dc9a824c447","Recent research on multispectral (MS) and panchromatic (PN) images fusion that known as pansharpening has progressed with the development of Convolutional Neural Networks (CNN). However, the states-of-the-arts methods are principally based on simple networks with shallow architectures that may limit their performance. Recently, residual learning (ResNet) exhibit improved performance in many application domains. At the same time, numerous upsampling methods were developed, from the classical interpolation to learning based methods. In this paper, ResNet is employed to make the full exploitation of the high nonlinearity of CNN. Moreover, an ensemble of upsampling methods were joined in the developed Multibranch Pansharpening Network (MPN) that prove good performance to reconstruct high-resolution MS images. The proposed approach is applied to QuickBird data, its efficiency is assessed with universally used performance criteria in spatial and spectral domains. Experimental results of the proposed approach show better spatial performance than classical methods and competitive spectral performance against the state-of-the-art approaches. © 2020 IEEE.","Convolutional neural networks; Geology; Signal sampling; Classical methods; High nonlinearity; Learning-based methods; Performance criterion; Recent researches; Spatial performance; Spectral performance; State-of-the-art approach; Remote sensing","CNN; Deep Learning; pansharpening; super-resolution; Transposed Convolution.","Conference paper","Final","","Scopus","2-s2.0-85086716829"
"Armanious K.; Abdulatif S.; Aziz F.; Schneider U.; Yang B.","Armanious, Karim (57208782510); Abdulatif, Sherif (57194649144); Aziz, Fady (57194650513); Schneider, Urs (55968038100); Yang, Bin (55584795030)","57208782510; 57194649144; 57194650513; 55968038100; 55584795030","An adversarial super-resolution remedy for radar design trade-offs","2019","European Signal Processing Conference","2019-September","","","","","","10.23919/EUSIPCO.2019.8902510","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075601097&doi=10.23919%2fEUSIPCO.2019.8902510&partnerID=40&md5=fb1669ec6d341145d913d5713255968b","Radar is of vital importance in many fields, such as autonomous driving, safety and surveillance applications. However, it suffers from stringent constraints on its design parametrization leading to multiple trade-offs. For example, the bandwidth in FMCW radars is inversely proportional with both the maximum unambiguous range and range resolution. In this work, we introduce a new method for circumventing radar design trade-offs. We propose the use of recent advances in computer vision, more specifically generative adversarial networks (GANs), to enhance low-resolution radar acquisitions into higher resolution counterparts while maintaining the advantages of the low-resolution parametrization. The capability of the proposed method was evaluated on the velocity resolution and range-azimuth trade-offs in micro-Doppler signatures and FMCW uniform linear array (ULA) radars, respectively. © 2019 IEEE","MIMO radar; MIMO systems; Neural networks; Optical resolving power; Radar; Radar signal processing; Remote sensing; Adversarial networks; Convolutional neural network; Micro-Doppler; Range Azimuth; Super resolution; Economic and social effects","CNN; Convolutional neural network; GAN; Generative adversarial networks; Micro-Doppler; MIMO; Radar; Range-azimuth; Remote sensing; Super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85075601097"
"Zhang Q.; Wang H.; Du T.; Yang S.; Wang Y.; Xing Z.; Bai W.; Yi Y.","Zhang, Qi (57212800057); Wang, Huafeng (36783787700); Du, Tao (56038798600); Yang, Sichen (57212138469); Wang, Yuehai (57194466632); Xing, Zhiqiang (36832316200); Bai, Wenle (16548808600); Yi, Yang (57212149988)","57212800057; 36783787700; 56038798600; 57212138469; 57194466632; 36832316200; 16548808600; 57212149988","Super-resolution reconstruction algorithms based on fusion of deep learning mechanism and wavelet","2019","ACM International Conference Proceeding Series","","","","102","107","5","10.1145/3357254.3358600","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076009305&doi=10.1145%2f3357254.3358600&partnerID=40&md5=d9950831e29011996c436064dead3789","In this paper, we consider the problem of super-resolution reconstruction. This is a hot topic because super-resolution reconstruction has a wide range of applications in the medical field, remote sensing monitoring, and criminal investigation. Compared with traditional algorithms, the current super-resolution reconstruction algorithm based on deep learning greatly improves the clarity of reconstructed pictures. Existing work like Super-Resolution Using a Generative Adversarial Network (SRGAN) can effectively restore the texture details of the image. However, experimentally verified that the texture details of the image recovered by the SRGAN are not robust. In order to get super-resolution reconstructed images with richer high-frequency details, we improve the network structure and propose a super-resolution reconstruction algorithm combining wavelet transform and Generative Adversarial Network. The proposed algorithm can efficiently reconstruct high-resolution images with rich global information and local texture details. We have trained our model by Py Torch framework and VOC2012 dataset, and tested it by Set5, Set14, BSD100 and Urban100 test datasets. © 2019 Association for Computing Machinery.","Image enhancement; Image reconstruction; Image texture; Learning algorithms; Optical resolving power; Pattern recognition; Remote sensing; Statistical tests; Textures; Wavelet transforms; Adversarial networks; Criminal investigation; Global informations; High resolution image; Learning mechanism; Reconstructed image; Remote sensing monitoring; Super resolution reconstruction; Deep learning","Deep learning; Generative Adversarial Network; Super-resolution reconstruction; Wavelet transform","Conference paper","Final","","Scopus","2-s2.0-85076009305"
"Shen D.; Liu J.; Xiao Z.; Yang J.; Xiao L.","Shen, Dunbin (57218487985); Liu, Jianjun (54787999400); Xiao, Zhiyong (55821506900); Yang, Jinlong (56927093600); Xiao, Liang (57020500800)","57218487985; 54787999400; 55821506900; 56927093600; 57020500800","A Twice Optimizing Net with Matrix Decomposition for Hyperspectral and Multispectral Image Fusion","2020","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","13","","9141409","4095","4110","15","10.1109/JSTARS.2020.3009250","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089306272&doi=10.1109%2fJSTARS.2020.3009250&partnerID=40&md5=912889f9a9fdc0a33b9c0bf577920783","Fusing a low-resolution hyperspectral (LRHS) image and a high-resolution multispectral (HRMS) image to generate a high-resolution hyperspectral (HRHS) image has grown a significant and attractive application in remote sensing fields. Recently, the popularization of deep learning has injected more possibilities into the fusion work. However, there still exists a difficulty that is how to make the best of the acquired LRHS and HRMS images. In this article, we present a twice optimizing net with matrix decomposition to fulfill the fusion task, which can be roughly divided into three stages: pre-optimization, deep prior learning, post-optimization. Specifically, we first transform this fusion problem into a spectral optimization problem and a spatial optimization problem with the help of matrix decomposition. These two optimization problems can be handled sequentially by solving a linear equation, respectively, and then we can obtain the initial HRHS image by multiplying the two solutions. Next, we establish the mapping between the initial image and the reference image through an end-to-end deep residual network based on local and nonlocal connectivity. In order to get better performance, we have customized a loss function specifically for the fusion task as well. Finally, we return the predicted result again to the optimization procedure to get the final fusion image. After the evaluation on three simulated datasets and one real dataset, it illustrates that the proposed method outperforms many state-of-the-art ones. © 2008-2012 IEEE.","Deep learning; Optimization; Remote sensing; Matrix decomposition; Multi-spectral image fusions; Optimization problems; Optimization procedures; Post optimization; Simulated datasets; Spatial optimization; Spectral optimization; data set; decomposition analysis; image analysis; image resolution; machine learning; matrix; multispectral image; optimization; remote sensing; Image fusion","Convolutional neural network (CNN); hyperspectral image; image fusion; loss function; super resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85089306272"
"Doi K.; Iwasaki A.","Doi, Kento (57208264052); Iwasaki, Akira (8073280000)","57208264052; 8073280000","SSCNET: Spectral-Spatial Consistency Optimization of CNN for Pansharpening","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8897928","3141","3144","3","10.1109/IGARSS.2019.8897928","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077678613&doi=10.1109%2fIGARSS.2019.8897928&partnerID=40&md5=25a97842de19b9c52416d3bcba004369","Recently, convolutional neural network (CNN) has achieved great results in pansharpening. Most pansharpening methods with CNN are based on PNN [1] inspired by super-resolution methods with CNN and learn the pansharpening of downsampled images. In this work, we presented a novel framework for pansharpening based on two desired property of pansharpened images: downsampled pansharpened images become low-resolution multi-spectral images (spectral consistency) and panchromatic images are approximated by weighted addition of each bands of pansharpened images (spatial consistency). Our framework train CNN to learn this spectral-spatial consistency. The advantage of our framework is that there is no scale mismatch between training and test data. We applied our method to Landsat-8 images and compared it with some previous methods. © 2019 IEEE.","Convolution; Data fusion; Deep learning; Deep neural networks; Geology; Remote sensing; Spectroscopy; Low resolution; Multispectral images; Pan-sharpening; Panchromatic images; Pansharpened images; Scale mismatches; Spatial consistency; Superresolution methods; Convolutional neural networks","convolutional neural network; data fusion; deep learning; Pansharpening","Conference paper","Final","","Scopus","2-s2.0-85077678613"
"Han X.-H.; Sun Y.Q.; Wang J.; Shi B.; Zheng Y.Q.; Chen Y.-W.","Han, Xian-Hua (24080007200); Sun, Yong Qing (56174861900); Wang, Jian (56563713200); Shi, Boxin (25423015500); Zheng, Yin Qiang (57212267581); Chen, Yen-Wei (56036268200)","24080007200; 56174861900; 56563713200; 25423015500; 57212267581; 56036268200","Spectral representation vis data-guided sparsity for hyperspectral image super-resolution","2019","Sensors (Switzerland)","19","24","5401","","","","10.3390/s19245401","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076339147&doi=10.3390%2fs19245401&partnerID=40&md5=a9f95522450b483c12e809aa7c1d0530","Hyperspectral imaging is capable of acquiring the rich spectral information of scenes and has great potential for understanding the characteristics of different materials in many applications ranging from remote sensing to medical imaging. However, due to hardware limitations, the existed hyper-/multi-spectral imaging devices usually cannot obtain high spatial resolution. This study aims to generate a high resolution hyperspectral image according to the available low resolution hyperspectral and high resolution RGB images. We propose a novel hyperspectral image superresolution method via non-negative sparse representation of reflectance spectra with a data guided sparsity constraint. The proposed method firstly learns the hyperspectral dictionary from the low resolution hyperspectral image and then transforms it into the RGB one with the camera response function, which is decided by the physical property of the RGB imaging camera. Given the RGB vector and the RGB dictionary, the sparse representation of each pixel in the high resolution image is calculated with the guidance of a sparsity map, which measures pixel material purity. The sparsity map is generated by analyzing the local content similarity of a focused pixel in the available high resolution RGB image and quantifying the spectral mixing degree motivated by the fact that the pixel spectrum of a pure material should have sparse representation of the spectral dictionary. Since the proposed method adaptively adjusts the sparsity in the spectral representation based on the local content of the available high resolution RGB image, it can produce more robust spectral representation for recovering the target high resolution hyperspectral image. Comprehensive experiments on two public hyperspectral datasets and three real remote sensing images validate that the proposed method achieves promising performances compared to the existing state-of-the-art methods. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","Cameras; Hyperspectral imaging; Medical imaging; Mixing; Optical resolving power; Pixels; Remote sensing; Spectroscopy; Data guided sparsity; Hyperspectral image superresolution; Local contents; Sparse representation; Spectral mixing; article; quantitative analysis; remote sensing; Color image processing","Data guided sparsity; Hyperspectral image superresolution; Local content similarity; Sparse representation; Spectral mixing","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85076339147"
"Lore K.G.; Reddy K.K.; Giering M.; Bernal E.A.","Lore, Kin Gwn (57190128995); Reddy, Kishore K. (55443153000); Giering, Michael (56464245300); Bernal, Edgar A. (12800366000)","57190128995; 55443153000; 56464245300; 12800366000","Generative adversarial networks for spectral super-resolution and bidirectional rgb-to-multispectral mapping","2019","IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops","2019-June","","9025450","926","933","7","10.1109/CVPRW.2019.00122","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071519076&doi=10.1109%2fCVPRW.2019.00122&partnerID=40&md5=a0acb08f88953b4bf73f88bc6b5ad48a","Acquisition of multi-and hyperspectral imagery imposes significant requirements on the hardware capabilities of the sensors involved. In order to keep costs manageable, and due to limitations in the sensing technology, tradeoffs between the spectral and the spatial resolution of hyperspectral images are usually made. Such tradeoffs are usually not necessary when considering acquisition of traditional RGB imagery. We investigate the use of statistical learning, and in particular, of conditional generative adversarial networks (cGANs) to estimate mappings from three-channel RGB to 31-band multispectral imagery. We demonstrate the application of the proposed approach to (i) RGB-to-multispectral image mapping, (ii) spectral super-resolution of image data, and (iii) recovery of RGB imagery from multispectral data. © 2019 IEEE.","Computer vision; Optical resolving power; Remote sensing; Spectroscopy; Adversarial networks; Hyper-spectral imageries; Multi-spectral data; Multi-spectral imagery; Multispectral images; Sensing technology; Spatial resolution; Statistical learning; Photomapping","","Conference paper","Final","","Scopus","2-s2.0-85071519076"
"Yang X.; Li F.; Xin L.; Lu X.; Lu M.; Zhang N.","Yang, Xue (57204629969); Li, Feng (57171116800); Xin, Lei (57183670600); Lu, Xiaotian (57189345043); Lu, Ming (56399795000); Zhang, Nan (57202033633)","57204629969; 57171116800; 57183670600; 57189345043; 56399795000; 57202033633","An improved mapping with super-resolved multispectral images for geostationary satellites","2020","Remote Sensing","12","3","466","","","","10.3390/rs12030466","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080870793&doi=10.3390%2frs12030466&partnerID=40&md5=9e187740280e14e1597713263dafd825","Super-resolution (SR) technology has shown great potential for improving the performance of the mapping and classification of multispectral satellite images. However, it is very challenging to solve ill-conditioned problems such as mapping for remote sensing images due to the presence of complicated ground features. In this paper, we address this problem by proposing a super-resolution reconstruction (SRR) mapping method called the mixed sparse representation non-convex high-order total variation (MSR-NCHOTV) method in order to accurately classify multispectral images and refine object classes. Firstly, MSR-NCHOTV is employed to reconstruct high-resolution images from low-resolution time-series images obtained from the Gaofen-4 (GF-4) geostationary orbit satellite. Secondly, a support vector machine (SVM) method was used to classify the results of SRR using the GF-4 geostationary orbit satellite images. Two sets of GF-4 satellite image data were used for experiments, and the MSR-NCHOTV SRR result obtained using these data was compared with the SRR results obtained using the bilinear interpolation (BI), projection onto convex sets (POCS), and iterative back projection (IBP) methods. The sharpness of the SRR results was evaluated using the gray-level variation between adjacent pixels, and the signal-to-noise ratio (SNR) of the SRR results was evaluated by using the measurement of high spatial resolution remote sensing images. For example, compared with the values obtained using the BI method, the average sharpness and SNR of the five bands obtained using the MSR-NCHOTV method were higher by 39.54% and 51.52%, respectively, and the overall accuracy (OA) and Kappa coefficient of the classification results obtained using the MSR-NCHOTV method were higher by 32.20% and 46.14%, respectively. These results showed that the MSR-NCHOTV method can effectively improve image clarity, enrich image texture details, enhance image quality, and improve image classification accuracy. Thus, the effectiveness and feasibility of using the proposed SRR method to improve the classification accuracy of remote sensing images was verified. © 2020 by the authors.","Geostationary satellites; Image classification; Image reconstruction; Image texture; Iterative methods; Mapping; Optical resolving power; Orbits; Remote sensing; Set theory; Signal to noise ratio; Support vector machines; Textures; Geostationary orbit satellite; Iterative back projections; Multispectral satellite image; Projection onto convex sets; Resolution enhancement; Super resolution; Super resolution reconstruction; Total variation; Image enhancement","Mapping; Remote sensing; Resolution enhancement; Super-resolution; Total variation","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85080870793"
"Belov A.M.; Denisova A.Y.","Belov, A.M. (35482106000); Denisova, A.Y. (42160925300)","35482106000; 42160925300","Spatial interpolation methods for spectral-spatial remote sensing image super-resolution algorithm based on gradient descent approach","2019","Journal of Physics: Conference Series","1368","3","032006","","","","10.1088/1742-6596/1368/3/032006","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077333226&doi=10.1088%2f1742-6596%2f1368%2f3%2f032006&partnerID=40&md5=c0a930d251cdafa9793f793ba8995924","The paper presents an investigation of the influence of spatial interpolation methods on the quality of the image obtained as a result of the spectral-spatial remote sensing image super-resolution reconstruction based on the gradient descent approach. As an example of the super-resolution method, we applied our earlier developed super-resolution image reconstruction algorithm. The algorithm provides the minimization of error of the observation model that connects the input low-resolution images with the target high-resolution image. The iterations of the gradient descent method are performed in the high-resolution spectral and spatial coordinates grid. For this reason, the spatial interpolation operator is added in the observation model. It is evident that spatial interpolation affects both the quality of the reconstructed image and the algorithm convergence rate. The objective of our research was to define the most appropriate spatial interpolation method. The paper presents the results of the spectral-spatial super-resolution image reconstruction using the following spatial interpolation methods: bilinear, bicubic, sinc, and nearest neighbour interpolation. We compare these implementations in terms of such image quality indicators as the root mean square error of the estimated high-resolution image, the algorithm convergence rate, and the presence of textural and colour artefacts as well. © Published under licence by IOP Publishing Ltd.","Gradient methods; Interpolation; Mean square error; Nanotechnology; Optical resolving power; Remote sensing; Gradient Descent method; Remote sensing images; Root mean square errors; Spatial interpolation; Spatial interpolation method; Super resolution image reconstruction algorithm; Super-resolution image reconstruction; Superresolution methods; Image reconstruction","","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85077333226"
"Rabbi J.; Ray N.; Schubert M.; Chowdhury S.; Chao D.","Rabbi, Jakaria (56606267600); Ray, Nilanjan (7102751487); Schubert, Matthias (55605776884); Chowdhury, Subir (35619919300); Chao, Dennis (55967460400)","56606267600; 7102751487; 55605776884; 35619919300; 55967460400","Small-object detection in remote sensing images with end-to-end edge-enhanced GAN and object detector network","2020","Remote Sensing","12","9","1432","","","","10.3390/RS12091432","84","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085963738&doi=10.3390%2fRS12091432&partnerID=40&md5=930f9b94ac65cd2662d76c77627aaa66","The detection performance of small objects in remote sensing images has not been satisfactory compared to large objects, especially in low-resolution and noisy images. A generative adversarial network (GAN)-based model called enhanced super-resolution GAN (ESRGAN) showed remarkable image enhancement performance, but reconstructed images usually miss high-frequency edge information. Therefore, object detection performance showed degradation for small objects on recovered noisy and low-resolution remote sensing images. Inspired by the success of edge enhanced GAN (EEGAN) and ESRGAN, we applied a new edge-enhanced super-resolution GAN (EESRGAN) to improve the quality of remote sensing images and used different detector networks in an end-to-end manner where detector loss was backpropagated into the EESRGAN to improve the detection performance. We proposed an architecture with three components: ESRGAN, EEN, and Detection network. We used residual-in-residual dense blocks (RRDB) for both the ESRGAN and EEN, and for the detector network, we used a faster region-based convolutional network (FRCNN) (two-stage detector) and a single-shot multibox detector (SSD) (one stage detector). Extensive experiments on a public (car overhead with context) dataset and another self-assembled (oil and gas storage tank) satellite dataset showed superior performance of our method compared to the standalone state-of-the-art object detectors. © 2020 by the author.","Image enhancement; Object recognition; Optical resolving power; Remote sensing; Signal receivers; Adversarial networks; Convolutional networks; Detection networks; Detection performance; High frequency HF; Reconstructed image; Remote sensing images; Small object detection; Object detection","Edge enhancement; Faster region-based convolutional neural network (FRCNN); Object detection; Remote sensing imagery; Satellites; Single-shot multibox detector (SSD); Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85085963738"
"Ishikuro S.; Yuichi O.; Hashimoto J.; Li X.","Ishikuro, Shiori (57207105902); Yuichi, Okuyama (18038436300); Hashimoto, Jun (55674648800); Li, Xiang (57192493636)","57207105902; 18038436300; 55674648800; 57192493636","Applying sparse based spatial super-resolution for himawari-8 satellite image","2019","ACM International Conference Proceeding Series","","","","40","46","6","10.1145/3357767.3357773","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073185641&doi=10.1145%2f3357767.3357773&partnerID=40&md5=958837c714145d86147e7e64facbca66","Super-resolution for meteorological satellite images is expected to improve the accuracy performance in the systems such as elucidations of meteorological, solar irradiance estimation, utilization of photovoltaic power generation, storage batteries and electric vehicles. While various super-resolution studies have been conducted for planimetric features, there seldom exists for meteorological features. In this study, we apply sparse based super-resolution for meteorological satellite images and verify the characteristics of error between original high-resolution image and super-resolution results. We confirmed super-resolution by sparse-based method which keeps the boundary feature of clouds. A sparse constraint gains an advantage for cloud image which contains boundary features from the meteorological satellite. The peak signal-to-noise ratio by the sparse based method was improved 1.43dB at the maximum compared with bicubic interpolation. On the other hand, we show that the sparse-based method still needs further studies to handle the blurry cloud and absent cloud situations. © 2019 Association for Computing Machinery..","Electric power supplies to apparatus; Optical resolving power; Photovoltaic cells; Remote sensing; Signal to noise ratio; Solar energy; Solar power generation; Solar power satellites; Weather satellites; Bicubic interpolation; High resolution image; Peak signal to noise ratio; Photovoltaic power generation; Satellite images; Solar irradiances; Sparse representation; Super resolution; Image enhancement","Meteorological satellite; Sparse representation; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85073185641"
"Molini A.B.; Valsesia D.; Fracastoro G.; Magli E.","Molini, Andrea Bordone (57213164630); Valsesia, Diego (55968886600); Fracastoro, Giulia (56344146600); Magli, Enrico (7003771643)","57213164630; 55968886600; 56344146600; 7003771643","Deep Learning for Super-Resolution of Unregistered Multi-Temporal Satellite Images","2019","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2019-September","","8920910","","","","10.1109/WHISPERS.2019.8920910","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075676262&doi=10.1109%2fWHISPERS.2019.8920910&partnerID=40&md5=d0959582745d97b432076a638e5cf77a","Recently, convolutional neural networks (CNN) have been successfully applied to many remote sensing tasks. However, deep learning for multi-image superresolution from multitemporal imagery has received little attention so far. We propose a residual CNN that exploits both spatial and temporal correlations in the low-resolution image set by using 3D convolutional layers to combine multiple images from the same scene. The experiments have been carried out using a dataset of PROBA-V satellite ground images, composed of several low-resolution and high-resolution images taken at different times from instruments on the same platform, in the context of a challenge issued by the European Space Agency. © 2019 IEEE.","Convolution; Hyperspectral imaging; Neural networks; Optical resolving power; Remote sensing; Space optics; Spectroscopy; Convolutional neural network; High resolution image; Low resolution images; Multi-images; Multi-temporal image; Multi-temporal imageries; Multi-temporal satellite images; Spatial and temporal correlation; Deep learning","convolutional neural networks; Multi-image superresolution; multi-temporal images","Conference paper","Final","","Scopus","2-s2.0-85075676262"
"Shin D.; Spittle S.","Shin, Dongjoe (57201861120); Spittle, Stephen (57191268506)","57201861120; 57191268506","LoGSRN: Deep super resolution network for digital elevation model","2019","Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics","2019-October","","8914037","3060","3065","5","10.1109/SMC.2019.8914037","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076776468&doi=10.1109%2fSMC.2019.8914037&partnerID=40&md5=21d9a9d4eb6bc3f8108c5d434f0ed762","The spatial resolution of a Digital Elevation Model (DEM) plays a crucial role in many practical remote sensing applications. However, it is normally limited by the spatial resolution of the raw input imagery, from which a DEM is derived. One solution to enhance the limited resolution of a DEM during the post-processing, is fusing previously obtained high resolution DEM data. This data-driven approach appears particularly promising, considering the recent success of a deep convolutional network in single image super resolution (SISR). In this paper, we propose a new SISR network that can recover a high resolution DEM. Instead of configuring a single network directly mapping low resolution depth values to high resolution depth values, we propose a new model consisting of 3 subnetworks, i.e. a) extracting feature maps; b) inferring the high frequency details; c) refining the result combining the low resolution input with the details from b). This is similar to LapSRN [1] in that both adopt a Laplacian image pyramid to model the scaling process in SISR. However, the proposed method implements a much deeper subnetworks efficiently with multiple recursive feedback and feedforward connections, and an additional Laplacian of Gaussian (LoG)based loss function help to produce more effective training results. In this research, we also produce a high quality DEM dataset obtained from optical and lidar sensors, from satellites and aircraft respectively, covering different scenes found in remote sensing applications. Our experiments demonstrate that the proposed model performs better than other standard deep SISR models in terms of the training convergence and the Peak Signal to Noise Ratio (PSNR) of a reconstructed DEM. © 2019 IEEE.","Digital instruments; Forestry; Geomorphology; Image resolution; Laplace transforms; Optical radar; Optical resolving power; Remote sensing; Signal to noise ratio; Training aircraft; Convolutional networks; Data-driven approach; Digital elevation model; Feedforward connections; High-resolution depth; Laplacian of Gaussian; Peak signal to noise ratio; Remote sensing applications; Surveying","","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85076776468"
"Barajas-Solano C.A.; Ramirez J.-M.; Arguello H.","Barajas-Solano, Crisostomo Alberto (57196081266); Ramirez, Juan-Marcos (57199923049); Arguello, Henry (44061135000)","57196081266; 57199923049; 44061135000","Spectral video compression using convolutional sparse coding","2020","Data Compression Conference Proceedings","2020-March","","9105867","253","262","9","10.1109/DCC47342.2020.00033","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086845462&doi=10.1109%2fDCC47342.2020.00033&partnerID=40&md5=6243b6d9d17754c0c54aa4241f34b915","Spectral Videos (SV) are datasets containing spatial-spectral-and-temporal information of a moving scene and this kind of information have been successfully used in medicine, remote sensing, and military application. However, expensive acquisition processes and difficulties in equipment manufacture lead to low-resolution datasets. Therefore, super-resolution (SR) techniques have emerged as a processing tool that recovers a high-resolution dataset by expressing the measurements as compressed versions of the desired data. Furthermore, the Convolutional Sparse Coding (CSC) has been developed as a signal model that learns a dictionary directly from the target signal, improving the reconstruction quality. This work proposes to extend the CSC formulation to consider temporal correlations in SVs, exploiting the shifting invariance property of the CSC model. The simulation results show a PSNR improvement in up to 2.5dB with respect to the state-of-the-art methods, preserving the edges and textures of the spectral video frames. © 2020 IEEE.","Convolution; Remote sensing; Textures; Video signal processing; Acquisition process; Equipment manufacture; Processing tools; Reconstruction quality; State-of-the-art methods; Super resolution; Temporal correlations; Temporal information; Image compression","Convolutional sparse coding; Data compression; Spectral video","Conference paper","Final","","Scopus","2-s2.0-85086845462"
"Klapp I.; Yafin P.; Oz N.; Brand O.; Bahat I.; Goldshtein E.; Cohen Y.; Alchanatis V.; Sochen N.","Klapp, Iftach (27567785400); Yafin, Peretz (57205183262); Oz, Navot (57211388042); Brand, Omri (57213263316); Bahat, Idan (57204394019); Goldshtein, Eitan (56964252700); Cohen, Yafit (56963379100); Alchanatis, Victor (6507904831); Sochen, Nir (7003363050)","27567785400; 57205183262; 57211388042; 57213263316; 57204394019; 56964252700; 56963379100; 6507904831; 7003363050","Computational end-to-end and super-resolution methods to improve thermal infrared remote sensing for agriculture","2020","Precision Agriculture","","","","","","","10.1007/s11119-020-09746-y","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091320916&doi=10.1007%2fs11119-020-09746-y&partnerID=40&md5=49c2d2cc8ba47be8ac27edf1be091a41","Increasing global water deficit and demand for yield improvement call for high-resolution monitoring of irrigation, crop water stress, and crops' general condition. To provide high spatial resolution with high-temperature accuracy, remote sensing is conducted at low altitudes using radiometric longwave thermal infrared cameras. However, the radiometric cameras' price, and the low altitude leading to low coverage in a given time, limit the use of radiometric aerial surveys for agricultural needs. This paper presents progress toward solving both limitations using algorithmic and computational imaging methods: stabilizing the readout of low-cost thermal cameras to obtain radiometric data, and improving the latter's low resolution by applying convolutional neural network-based super-resolution. The two methods were merged by an end-to-end algorithm pipeline, providing a large mosaicked image of the field. First, the potential capabilities of a joint estimation method to correct unknown offset and gain were simulated on remotely sensed agricultural data. Comparison to ground-truth measurements showed radiometric accuracy with a root mean square error (RMSE) of 1.3 °C to 1.8 °C. Then, the proposed super-resolution method was demonstrated on experimental and simulated remotely sensed agricultural data. Preliminary experimental results showed 50% improvement in image sharpness relative to bicubic interpolation. The performance of the algorithm was evaluated on 22 simulated cases at × 2 and × 4 magnification. Finally, image mosaicking using the proposed pipeline was demonstrated. A mosaicked image composed of sub-images pre-processed by the proposed computational methods resulted in a RMSE in temperature of 0.8 °C, as compared to 8.2 °C without the initial processing. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","","Computational imaging; Precision agriculture; Radiometry; Remote sensing and sensor; Super-resolution; Thermography","Article","Article in press","","Scopus","2-s2.0-85091320916"
"Fontana V.; Blasco J.M.D.; Cavallini A.; Lorusso N.; Scremin A.; Romeo A.","Fontana, Valerio (56684671100); Blasco, Jose Manuel Delgado (57202801719); Cavallini, Andrea (57218837302); Lorusso, Nicola (58054624800); Scremin, Alessandro (57218836468); Romeo, Antonio (57218264963)","56684671100; 57202801719; 57218837302; 58054624800; 57218836468; 57218264963","Artificial intelligence technologies for Maritime Surveillance applications","2020","Proceedings - IEEE International Conference on Mobile Data Management","2020-June","","9162203","299","303","4","10.1109/MDM48529.2020.00067","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090388370&doi=10.1109%2fMDM48529.2020.00067&partnerID=40&md5=7ea32ae2edbbb84f6373a4778a08b7bd","The use of AI methods is currently evolving tasks done in the past by image analysts. During the last years, technology had helped to jump into fully automatic methods for monitoring and surveillance tasks, such as object detection, change detection and many more. In this work we want to show some of the AI-based models which RHEA Group has been working on which can be applied to the maritime domain, such as ship detection and super-resolution of satellite data. Each of these models can be further extended and specialized into specific monitoring and surveillance tasks, from the detection of ghost ships, measure environmental damage or monitoring of critical infrastructure near harbors or protected areas. In this paper, we illustrate some examples of the status of our research activities and the developments of these prototype applications. © 2020 IEEE.","Conservation; Damage detection; Information management; Monitoring; Object detection; Ships; Software prototyping; Artificial intelligence technologies; Change detection; Environmental damage; Maritime domains; Maritime surveillance; Research activities; Super resolution; Surveillance task; Artificial intelligence","Artificial intelligence; Convolutional networks; Deep learning; Environment; Maritime survemance; Optical; Remote sensing; sAR; Security; Ship recognition","Conference paper","Final","","Scopus","2-s2.0-85090388370"
"Xue X.; Zhang X.; Li H.; Wang W.","Xue, Xiangyu (57219313682); Zhang, Xiangnan (57219320238); Li, Haibing (57219320302); Wang, Wenyong (7501758663)","57219313682; 57219320238; 57219320302; 7501758663","Research on GAN-based Image Super-Resolution Method","2020","Proceedings of 2020 IEEE International Conference on Artificial Intelligence and Computer Applications, ICAICA 2020","","","9182617","602","605","3","10.1109/ICAICA50127.2020.9182617","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092136503&doi=10.1109%2fICAICA50127.2020.9182617&partnerID=40&md5=6a7639aefe374e4024d997c3db7c0cd3","Super-Resolution (SR) refers to the reconstruction of high-resolution image from low-resolution image, which has important application value in object detection, medical imaging, satellite remote sensing and other fields. In recent years, with the rapid development of deep learning, the image super-resolution reconstruction method based on deep learning has made remarkable progress. In this paper, R-SRGAN (Residual Super-Resolution Generative Adversarial Networks) is used to build the model and realize image super-resolution. By adding residual blocks between adjacent convolutional layers of the GAN generator, more detailed information is retained. At the same time, the Wassertein distance is used as a loss function to enhance the training effect and achieve image super-resolution. © 2020 IEEE.","Deep learning; Image enhancement; Medical imaging; Object detection; Optical resolving power; Remote sensing; Adversarial networks; High resolution image; Image super resolutions; Image super-resolution reconstruction; Low resolution images; Satellite remote sensing; Super resolution; Training effects; Image reconstruction","Generative Adversarial Networks; Image Processing; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85092136503"
"Belov A.M.; Denisova A.Y.","Belov, A.M. (35482106000); Denisova, A.Y. (42160925300)","35482106000; 42160925300","Earth remote sensing imagery classification using a multi-sensor superresolution fusion algorithm","2020","Computer Optics","44","4","","627","635","8","10.18287/2412-6179-CO-735","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090274566&doi=10.18287%2f2412-6179-CO-735&partnerID=40&md5=795e2724416c748399aa6cccdae26eec","Earth remote sensing data fusion is intended to produce images of higher quality than the original ones. However, the fusion impact on further thematic processing remains an open question because fusion methods are mostly used to improve the visual data representation. This article addresses an issue of the effect of fusion with increasing spatial and spectral resolution of data on thematic classification of images using various state-of-the-art classifiers and features extraction methods. In this paper, we use our own algorithm to perform multi-frame image fusion over optical remote sensing images with different spatial and spectral resolutions. For classification, we applied support vector machines and Random Forest algorithms. For features, we used spectral channels, extended attribute profiles and local feature attribute profiles. An experimental study was carried out using model images of four imaging systems. The resulting image had a spatial resolution of 2.3.4 and 5 times better than for the original images of each imaging system, respectively. As a result of our studies, it was revealed that for the support vector machines method, fusion was inexpedient since excessive spatial details had a negative effect on the classification. For the Random Forest algorithm, the classification results of a fused image were more accurate than for the original low-resolution images in 90% of cases. For example, for images with the smallest difference in spatial resolution (2 times) from the fusion result, the classification accuracy of the fused image was on average 4% higher. In addition, the results obtained for the Random Forest algorithm with fusion were better than the results for the support vector machines method without fusion. Additionally, it was shown that the classification accuracy of a fused image using the Random Forest method could be increased by an average of 9% due to the use of extended attribute profiles as features. Thus, when using data fusion, it is better to use the Random Forest classifier, whereas using fusion with the support vector machines method is not recommended. © 2020, Institution of Russian Academy of Sciences. All rights reserved.","Classification (of information); Decision trees; Image fusion; Image resolution; Imaging systems; Random forests; Remote sensing; Spectral resolution; Support vector machines; Vectors; Classification accuracy; Classification results; Extended attribute profiles; Optical remote sensing; Random forest algorithm; Random forest classifier; Thematic classification; Visual data representation; Image classification","Data fusion; EAP; Image classification; LFAP; RF; Super-resolution; SVM","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85090274566"
"Zheng D.; Fu Y.; Zhang H.; Gao M.; Yu J.","Zheng, Dulei (57216950379); Fu, You (36729944300); Zhang, Hao (57218389096); Gao, Minghao (57217077193); Yu, Jianzhi (46061757000)","57216950379; 36729944300; 57218389096; 57217077193; 46061757000","Semantic segmentation method based on super-resolution","2020","International Journal of Performability Engineering","16","5","","711","719","8","10.23940/ijpe.20.05.p4.711719","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086073121&doi=10.23940%2fijpe.20.05.p4.711719&partnerID=40&md5=9c1d4affb065a0c3982b3de78b2c14d7","Convolutional neural network is an important method to solve most computer vision problems nowadays. Although increasing the computing cost and the scale of model will make most tasks achieve satisfactory results, the difficulty of increasing the computing cost and high-quality data also limit the increase of model scale. In this paper, when using neural network to segment the remote sensing image, aiming at the problem that the classification effect of the internal pixels of the target is not ideal, a multi-scale fusion structure about the dimension of the feature map is proposed as the classifier module of the model. In order to further improve the performance of semantic segmentation model, inspired by the Generative adversarial nets, combined with super-resolution, generative semantic segmentation architecture is proposed. In order to verify the effect of the two methods, the kappa coefficient was selected as the evaluation to conduct the semantic segmentation experiment of the remote sensing image of seaculture. With little to no increase in the scale of the model, the classification ability of the model is improved, and the effect is compared intuitively from the segmentation image. © 2020 Totem Publisher, Inc. All rights reserved.","Convolutional neural networks; Image enhancement; Optical resolving power; Remote sensing; Semantics; Classification ability; Computer vision problems; High quality data; Kappa coefficient; Multiscale fusion; Remote sensing images; Segmentation images; Semantic segmentation; Image segmentation","Generative; Remote sensing image; Semantic segmentation; Single image super-resolution","Article","Final","","Scopus","2-s2.0-85086073121"
"Gu J.; Sun X.; Zhang Y.; Fu K.; Wang L.","Gu, Jun (57217635042); Sun, Xian (34875643000); Zhang, Yue (56971657300); Fu, Kun (7202283802); Wang, Lei (57070597700)","57217635042; 34875643000; 56971657300; 7202283802; 57070597700","Deep residual squeeze and excitation network for remote sensing image super-resolution","2019","Remote Sensing","11","15","1817","","","","10.3390/rs11151817","45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070464571&doi=10.3390%2frs11151817&partnerID=40&md5=2b268ec7b73e3a8bf80488652f41b885","Recently, deep convolutional neural networks (DCNN) have obtained promising results in single image super-resolution (SISR) of remote sensing images. Due to the high complexity of remote sensing image distribution, most of the existing methods are not good enough for remote sensing image super-resolution. Enhancing the representation ability of the network is one of the critical factors to improve remote sensing image super-resolution performance. To address this problem, we propose a new SISR algorithm called a Deep Residual Squeeze and Excitation Network (DRSEN). Specifically, we propose a residual squeeze and excitation block (RSEB) as a building block in DRSEN. The RSEB fuses the input and its internal features of current block, and models the interdependencies and relationships between channels to enhance the representation power. At the same time, we improve the up-sampling module and the global residual pathway in the network to reduce the parameters of the network. Experiments on two public remote sensing datasets (UC Merced and NWPU-RESISC45) show that our DRSEN achieves better accuracy and visual improvements against most state-of-the-art methods. The DRSEN is beneficial for the progress in the remote sensing images super-resolution field. © 2019 by the authors.","Convolution; Deep neural networks; Image enhancement; Neural networks; Optical resolving power; Convolutional neural network; Internal features; Remote sensing images; Representation power; Single images; State-of-the-art methods; Super resolution; Visual improvements; Remote sensing","Convolutional neural network; Remote sensing; Single image super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85070464571"
"Heltin Genitha C.; Vani K.","Heltin Genitha, C. (56419984000); Vani, K. (57220979150)","56419984000; 57220979150","A Hybrid Approach to Super-Resolution Mapping of Remotely Sensed Multi-spectral Satellite Images Using Genetic Algorithm and Hopfield Neural Network","2019","Journal of the Indian Society of Remote Sensing","47","4","","685","692","7","10.1007/s12524-018-0905-9","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057817691&doi=10.1007%2fs12524-018-0905-9&partnerID=40&md5=1dc8a58d9843d76283c5671ea90213ee","Though super-resolution mapping of multi-spectral remote sensing satellite images is used to locate the multiple classes within a mixed pixel, it has limitations, for example, low rate of convergence leading to low accuracy and higher time consumption. This paper demonstrates a hybrid approach of genetic algorithm and Hopfield neural network which can not only speed up the process but also identify the exact global optimal solution using super-resolution mapping. The experiments are carried out for Landsat ETM + image of different dimensions (10 × 10, 25 × 25, 64 × 64, 128 × 128 and 256 × 256) and with map sizes of 2, 3, 4, 5 and 6. Map size indicates the number of all sub-pixels which are resolved from a pixel. The overall accuracy is 89.44%, 90.25%, 91.09%, 92.56%, and 93.62%, respectively, for map sizes 2, 3, 4, 5, and 6, thus showing an increase of nearly 2% accuracy for hybrid genetic algorithm. The time taken was also reduced by half of that for the genetic algorithm. Thus, the efficiency of this novel approach to map land cover classes in a coarse pixel with greater accuracy and appreciably lesser time has been demonstrated. © 2018, Indian Society of Remote Sensing.","artificial neural network; experimental study; genetic algorithm; Landsat; mapping method; pixel; remote sensing; satellite imagery; spectral analysis; spectral resolution","Genetic algorithm; Global optimal solution; Hopfield Neural Network; Super-resolution mapping","Article","Final","","Scopus","2-s2.0-85057817691"
"Aburaed N.; Panthakkan A.; Al-Saad M.; Chendeb El Rai M.; Al Mansoori S.; Al-Ahmad H.; Marshall S.","Aburaed, Nour (56943462800); Panthakkan, Alavikunhu (55812242000); Al-Saad, Mina (57207997104); Chendeb El Rai, Marwa (35107075700); Al Mansoori, Saeed (37013166900); Al-Ahmad, Hussain (57222050810); Marshall, Stephen (7401823400)","56943462800; 55812242000; 57207997104; 35107075700; 37013166900; 57222050810; 7401823400","Super-resolution of satellite imagery using a wavelet multiscale-based deep convolutional neural network model","2020","Proceedings of SPIE - The International Society for Optical Engineering","11533","","115331J","","","","10.1117/12.2573991","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093973506&doi=10.1117%2f12.2573991&partnerID=40&md5=14348f416c6c75c403c26a320e915e87","Nowadays, satellite images are used in various governmental applications, such as urbanization and monitoring the environment. Spatial resolution is an element of crucial impact on the usage of remote sensing imagery. As such, increasing the spatial resolution of an image is an important pre-processing step that can improve the performance of various image processing tasks, such as segmentation. Once a satellite is launched, the more practical solution to improve the resolution of its captured images is to use Single Image Super Resolution (SISR) techniques. In the recent years, Deep Convolutional Neural Networks (DCNNs) have been recognized as a highly effective tool to reconstruct a High Resolution (HR) image from its Low Resolution (LR) counterpart, which is an open problem due to the inherent difficulty of estimating the missing high frequency components. The aim of this research paper is to design and implement a satellite image SISR algorithm by estimating high frequency details through training Deep Convolutional Neural Network (DCNNs) with respect to wavelet analysis. The goal is to improve the spatial resolution of multispectral remote sensing images captured by DubaiSat-2 satellite. The accuracy of the proposed algorithm is assessed using several metrics such as Peak Signal-to-Noise Ratio (PSNR), Wavelet-based Signal-to-Noise Ratio (WSNR) and Structural Similarity Index Measurement (SSIM). © SPIE. Downloading of the abstract is permitted for personal use only.","Convolution; Convolutional neural networks; Deep neural networks; Image resolution; Image segmentation; Optical resolving power; Remote sensing; Satellite imagery; Signal to noise ratio; Design and implements; Governmental applications; High frequency components; High resolution image; Multispectral remote sensing image; Peak signal to noise ratio; Remote sensing imagery; Structural similarity indices; Image enhancement","Convolutional neural network; Deep learning; Remote sensing; Super resolution; Wavelet transform","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85093973506"
"Wu R.; Wai H.-T.; Ma W.-K.","Wu, Ruiyuan (57194873872); Wai, Hoi-To (47062284700); Ma, Wing-Kin (7402703846)","57194873872; 47062284700; 7402703846","Hybrid inexact bcd for coupled structured matrix factorization in hyperspectral super-resolution","2020","IEEE Transactions on Signal Processing","68","","9013083","1728","1743","15","10.1109/TSP.2020.2975910","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082384902&doi=10.1109%2fTSP.2020.2975910&partnerID=40&md5=97b0e6e65eca24f941d39cf7dfb80be3","This paper develops a first-order optimization method for coupled structured matrix factorization (CoSMF) problems that arise in the context of hyperspectral super-resolution (HSR) in remote sensing. To best leverage the problem structures for computational efficiency, we introduce a hybrid inexact block coordinate descent (HiBCD) scheme wherein one coordinate is updated via the fast proximal gradient (FPG) method, while another via the Frank-Wolfe (FW) method. The FPG-type methods are known to take less number of iterations to converge, by numerical experience, while the FW-type methods can offer lower per-iteration complexity in certain cases; and we wish to take the best of both. We show that the limit points of this HiBCD scheme are stationary. Our proof treats HiBCD as an optimization framework for a class of multi-block structured optimization problems, and our stationarity claim is applicable not only to CoSMF but also to many other problems. Previous optimization research showed the same stationarity result for inexact block coordinate descent with either FPG or FW updates only. Numerical results indicate that the proposed HiBCD scheme is computationally much more efficient than the state-of-the-art CoSMF schemes in HSR. © 1991-2012 IEEE.","Computational efficiency; Convex optimization; Factorization; Iterative methods; Numerical methods; Optical resolving power; Remote sensing; Block coordinate descents; Coupled matrix; First order optimization method; Nonconvex optimization; Number of iterations; Optimization framework; Optimization researches; Super resolution; Matrix algebra","Coupled matrix factorization; Hyperspectral super-resolution; Non-convex optimization","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85082384902"
"Rout L.; Shah S.; Moorthi S.M.; Dhar D.","Rout, Litu (57203240979); Shah, Saumyaa (57218713775); Moorthi, S Manthira (54395659100); Dhar, Debajyoti (55247789700)","57203240979; 57218713775; 54395659100; 55247789700","Monte-carlo siamese policy on actor for satellite image super resolution","2020","IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops","2020-June","","9150726","757","767","10","10.1109/CVPRW50498.2020.00105","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090116273&doi=10.1109%2fCVPRW50498.2020.00105&partnerID=40&md5=3854c233ccde45126cab2d39bab28bbf","In the past few years supervised and adversarial learning have been widely adopted in various complex computer vision tasks. It seems natural to wonder whether another branch of artificial intelligence, commonly known as Reinforcement Learning (RL) can benefit such complex vision tasks. In this study, we explore the plausible usage of RL in super resolution of remote sensing imagery. Guided by recent advances in super resolution, we propose a theoretical framework that leverages the benefits of supervised and reinforcement learning. We argue that a straightforward implementation of RL is not adequate to address ill-posed super resolution as the action variables are not fully known. To tackle this issue, we propose to parameterize action variables by matrices, and train our policy network using Monte-Carlo sampling. We study the implications of parametric action space in a model-free environment from theoretical and empirical perspective. Furthermore, we analyze the quantitative and qualitative results on both remote sensing and non-remote sensing datasets. Based on our experiments, we report considerable improvement over state-of-the-art methods by encapsulating supervised models in a reinforcement learning framework. © 2020 IEEE.","Complex networks; Computer vision; Monte Carlo methods; Optical resolving power; Reinforcement learning; Space optics; Adversarial learning; Monte Carlo sampling; Policy networks; Remote sensing imagery; Satellite images; State-of-the-art methods; Super resolution; Theoretical framework; Remote sensing","","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85090116273"
"Synthiya Vinothini D.; Sathya Bama B.; Selva N.; Kumar N.","Synthiya Vinothini, D. (57198896392); Sathya Bama, B. (36024410500); Selva, Nirmal (57220208681); Kumar, Naveen (57220211620)","57198896392; 36024410500; 57220208681; 57220211620","Super Resolution Land Cover Mapping Using Deep Multi Scale Residual Dense Network","2020","Communications in Computer and Information Science","1249","","","498","507","9","10.1007/978-981-15-8697-2_47","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097279846&doi=10.1007%2f978-981-15-8697-2_47&partnerID=40&md5=a93af4b9dd1229936d026570658595ed","Super Resolution Mapping (SRM) is a land cover mapping method that generates land surface cover maps at fine spatial resolution from a coarse spatial resolution Remote Sensing (RS) image. Recently deep networks have shown impressive performance for image super resolution and image segmentation. Inspired by this performance a deep Multi-Scale Residual Dense Network (MSRDN) is proposed for SRM application of satellite data which extracts hierarchical features that can efficiently map sub-pixels to an accurate class. A MSRDN network is trained with coarse resolution images and its corresponding fine resolution class cover patches to learn a super resolution mapping of land cover. The accuracy of the Conventional SRM techniques is restricted by the performance of soft classification methods. Hence this work utilizes the full power of deep learning to generate a fine resolution land cover map directly from a coarse resolution image neglecting the intermediate soft classification result. The results of the experiments show that MSRDN can become a best alternative to the conventional SRM techniques, to generate a precise land cover information directly from a coarse data. © 2020, Springer Nature Singapore Pte Ltd.","Computer vision; Deep learning; Image resolution; Image segmentation; Optical resolving power; Remote sensing; Hierarchical features; Image super resolutions; Land cover informations; Remote sensing images; Soft classification; Soft classification methods; Spatial resolution; Super-resolution mappings; Mapping","Class proportion image; Coarse resolution; Fine resolution; Land cover class; Super Resolution Mapping","Conference paper","Final","","Scopus","2-s2.0-85097279846"
"Garrett J.L.; Langer D.; Avagian K.; Stahl A.","Garrett, Joseph L. (56428526900); Langer, Dennis (57222665605); Avagian, Karine (57210646181); Stahl, Annette (15043301000)","56428526900; 57222665605; 57210646181; 15043301000","Accuracy of super-resolution for hyperspectral ocean observations","2019","OCEANS 2019 - Marseille, OCEANS Marseille 2019","2019-June","","8867142","","","","10.1109/OCEANSE.2019.8867142","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103684791&doi=10.1109%2fOCEANSE.2019.8867142&partnerID=40&md5=a10918c80f42d800f0434282abcf6e77","Super-resolution, a class of techniques used to reconstruct a high-resolution image from one or more low-resolution observations, is a possible route to utilize the full remote imaging capabilities of small satellites and unmanned aerial vehicles. Here, we test two frequently-used variants, Robust Super-Resolution (RSR) and Projection onto Convex Sets (POCS), to see how accurately each technique reconstructs images from a small satellite. The two techniques are chosen because each utilizes a different kind of prior knowledge. RSR utilizes knowledge about the scene, while POCS utilizes knowledge about the imaging process. The algorithms are run on three bands of two hyperspectral images: one lab-acquired image of a wooden block and one simulated image of a remote sensing ocean scene. The superresolution reconstructions of the simulated image are evaluated by calculating the brightness error and spectral angle with respect to the original scene. Both super-resolution algorithms improve both metrics relative to the raw, registered data. RSR achieves more improvement overall, but POCS operates faster. © 2019 IEEE.","Antennas; Image acquisition; Oceanography; Optical resolving power; Remote sensing; Set theory; Small satellites; Spectroscopy; Brightness error; High resolution image; Ocean observations; Projection onto convex sets; Simulated images; Super resolution; Super resolution algorithms; Super-resolution reconstruction; Image reconstruction","","Conference paper","Final","","Scopus","2-s2.0-85103684791"
"Ma W.; Pan Z.; Guo J.; Lei B.","Ma, Wen (57207877267); Pan, Zongxu (54788169800); Guo, Jiayi (57194143247); Lei, Bin (14063767500)","57207877267; 54788169800; 57194143247; 14063767500","Achieving Super-Resolution Remote Sensing Images via the Wavelet Transform Combined with the Recursive Res-Net","2019","IEEE Transactions on Geoscience and Remote Sensing","57","6","8600724","3512","3527","15","10.1109/TGRS.2018.2885506","58","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066629658&doi=10.1109%2fTGRS.2018.2885506&partnerID=40&md5=4928766409b577671c9659a3e71eb480","Deep learning (DL) has been successfully applied to single image super-resolution (SISR), which aims at reconstructing a high-resolution (HR) image from its low-resolution (LR) counterpart. Different from most current DL-based methods, which perform reconstruction in the spatial domain, we use a scheme based in the frequency domain to reconstruct the HR image at various frequency bands. Further, we propose a method that incorporates the wavelet transform (WT) and the recursive Res-Net. The WT is applied to the LR image to divide it into various frequency components. Then, an elaborately designed network with recursive residual blocks is used to predict high-frequency components. Finally, the reconstructed image is obtained via the inverse WT. This paper has three main contributions: 1) an SISR scheme based on the frequency domain is proposed under a DL framework to fully exploit the potential to depict images at different frequency bands; 2) recursive block and residual learning in global and local manners are adopted to ease the training of the deep network, and the batch normalization layer is removed to increase the flexibility of the network, save memory, and promote speed; and 3) the low-frequency wavelet component is replaced by an LR image with more details to further improve performance. To validate the effectiveness of the proposed method, extensive experiments are performed using the NWPU-RESISC45 data set, and the results demonstrate that the proposed method outperforms several state-of-the-art methods in terms of both objective evaluation and subjective perspective. © 2019 IEEE.","Deep learning; Frequency domain analysis; Image compression; Image reconstruction; Inverse problems; Optical resolving power; Remote sensing; Wavelet transforms; Frequency components; High frequency components; High resolution image; Objective evaluation; Remote sensing images; residual learning; State-of-the-art methods; Super resolution; frequency analysis; image analysis; learning; reconstruction; remote sensing; satellite imagery; wavelet analysis; Image enhancement","Recursive network; remote sensing image; residual learning; super resolution; wavelet transform (WT)","Article","Final","","Scopus","2-s2.0-85066629658"
"Ma F.; Yang F.; Wang Y.","Ma, Fei (55245276100); Yang, Feixia (57194184931); Wang, Yanwei (57213688942)","55245276100; 57194184931; 57213688942","Low-Rank Tensor Decomposition with Smooth and Sparse Regularization for Hyperspectral and Multispectral Data Fusion","2020","IEEE Access","8","","9139926","129842","129856","14","10.1109/ACCESS.2020.3009263","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089543972&doi=10.1109%2fACCESS.2020.3009263&partnerID=40&md5=8a06c12684fe2b869c9ff25318413b71","The fusion of hyperspectral and multispectral images is an effective way to obtain hyperspectral super-resolution images with high spatial resolution. A hyperspectral image is a datacube containing two spatial dimensions and a spectral dimension. The fusion methods based on non-negative matrix factorization need to reshape the three-dimensional data in matrix form, which will result in the loss of data structure information. Owing to the non-uniqueness of tensor rank and noise inference, there is a lot of redundant information in the spatial and spectral subspaces of tensor decomposition. To address the above problems, this article incorporates smooth and sparse regularization into low-rank tensor decomposition to reformulate a fusion method, in which the logarithmic sum function is adopted to eliminate the effect of redundant information and shadows in both spatial and spectral domains. Moreover, the total-variation-based regularizer is employed to vertically smooth the spectral factor matrix to suppress the noise. Then, the alternating direction multiplier method, as well as the conjugate gradient approach, is utilized to design a set of efficient algorithms by complexity reduction. The experimental results demonstrate that the proposed method can yield better performance than the state-of-the-art benchmark algorithms in most cases, which also verifies the effectiveness of incorporated regularizers in low signal-to-noise ratio environments for hyperspectral super-resolution images.  © 2013 IEEE.","Benchmarking; Computational complexity; Conjugate gradient method; Data fusion; Factorization; Optical resolving power; Signal to noise ratio; Spectroscopy; Tensors; Alternating directions; Conjugate gradient approaches; High spatial resolution; Low signal-to-noise ratio; Nonnegative matrix factorization; Sparse regularizations; Structure information; Three-dimensional data; Matrix algebra","image fusion; low-rank tensor decomposition; Remote sensing; super-resolution; total variation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85089543972"
"Li X.; Ling F.; Foody G.M.; Ge Y.; Zhang Y.; Wang L.; Shi L.; Li X.; Du Y.","Li, Xiaodong (55878368700); Ling, Feng (56278268300); Foody, Giles M. (7007014233); Ge, Yong (26655529300); Zhang, Yihang (55658053900); Wang, Lihui (57141007100); Shi, Lingfei (57193206756); Li, Xinyan (36523257300); Du, Yun (56420121700)","55878368700; 56278268300; 7007014233; 26655529300; 55658053900; 57141007100; 57193206756; 36523257300; 56420121700","Spatial-Temporal Super-Resolution Land Cover Mapping with a Local Spatial-Temporal Dependence Model","2019","IEEE Transactions on Geoscience and Remote Sensing","57","7","8677291","4951","4966","15","10.1109/TGRS.2019.2894773","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068319799&doi=10.1109%2fTGRS.2019.2894773&partnerID=40&md5=239bfdaed34e8236f8f62684d418fd24","The mixed pixel problem is common in remote sensing. A soft classification can generate land cover class fraction images that illustrate the areal proportions of the various land cover classes within pixels. The spatial distribution of land cover classes within each mixed pixel is, however, not represented. Super-resolution land cover mapping (SRM) is a technique to predict the spatial distribution of land cover classes within the mixed pixel using fraction images as input. Spatial-temporal SRM (STSRM) extends the basic SRM to include a temporal dimension by using a finer-spatial resolution land cover map that pre- or postdates the image acquisition time as ancillary data. Traditional STSRM methods often use one land cover map as the constraint, but neglect the majority of available land cover maps acquired at different dates and of the same scene in reconstructing a full state trajectory of land cover changes when applying STSRM to time-series data. In addition, the STSRM methods define the temporal dependence globally, and neglect the spatial variation of land cover temporal dependence intensity within images. A novel local STSRM (LSTSRM) is proposed in this paper. LSTSRM incorporates more than one available land cover map to constrain the solution, and develops a local temporal dependence model, in which the temporal dependence intensity may vary spatially. The results show that LSTSRM can eliminate speckle-like artifacts and reconstruct the spatial patterns of land cover patches in the resulting maps, and increase the overall accuracy compared with other STSRM methods. © 1980-2012 IEEE.","Optical resolving power; Remote sensing; Spatial distribution; Image acquisition time; Image series; Soft classification; Spatial dependence; Super-resolution mappings; Temporal dependence; Temporal dependence models; Temporal dimensions; accuracy assessment; land cover; mapping method; numerical model; pixel; remote sensing; Shuttle Radar Topography Mission; spatiotemporal analysis; spectral resolution; Pixels","Image series; spatial dependence; super-resolution mapping (SRM); temporal dependence","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85068319799"
"","","","3rd Chinese Conference on Pattern Recognition and Computer Vision, PRCV 2020","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12307 LNCS","","","","","1936","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094139686&partnerID=40&md5=870540f31eafc518d3b15989e79b4673","The proceedings contain 158 papers. The special focus in this conference is on Pattern Recognition and Computer Vision. The topics include: Underwater Image Processing by an Adversarial Network with Feedback Control; inception Parallel Attention Network for Small Object Detection in Remote Sensing Images; hyperspectral Image Denoising Based on Graph-Structured Low Rank and Non-local Constraint; multi-human Parsing with Pose and Boundary Guidance; m2E-Net: Multiscale Morphological Enhancement Network for Retinal Vessel Segmentation; DUDA: Deep Unsupervised Domain Adaptation Learning for Multi-sequence Cardiac MR Image Segmentation; learning from Rankings with Multi-level Features for No-Reference Image Quality Assessment; reversible Data Hiding Based on Prediction-Error-Ordering; aggregating Spatio-temporal Context for Video Object Segmentation; Position and Orientation Detection of Insulators in Arbitrary Direction Based on YOLOv3; R-PFN: Towards Precise Object Detection by Recurrent Pyramidal Feature Fusion; image Super-Resolution Based on Non-local Convolutional Neural Network; VH3D-LSFM: Video-Based Human 3D Pose Estimation with Long-Term and Short-Term Pose Fusion Mechanism; automatic Tooth Segmentation and 3D Reconstruction from Panoramic and Lateral Radiographs; unregistered Hyperspectral and Multispectral Image Fusion with Synchronous Nonnegative Matrix Factorization; Cloud Detection Algorithm Using Advanced Fully Convolutional Neural Networks in FY3D-MERSI Imagery; multi-layer Pointpillars: Multi-layer Feature Abstraction for Object Detection from Point Cloud; building Detection via Complementary Convolutional Features of Remote Sensing Images; hyperspectral Image Super-Resolution via Self-projected Smooth Prior; 3D Point Cloud Segmentation for Complex Structure Based on PointSIFT; completely Blind Image Quality Assessment with Visual Saliency Modulated Multi-feature Collaboration; blood Flow Velocity Detection of Nailfold Microcirculation Based on Spatiotemporal Analysis; blind Super-Resolution with Kernel-Aware Feature Refinement; preface.","","","Conference review","Final","","Scopus","2-s2.0-85094139686"
"Zhang Y.; Zhao T.; Xie B.; Mei S.","Zhang, Yifan (55265890500); Zhao, Tianqing (57213199625); Xie, Bobo (57200598098); Mei, Shaohui (25822578400)","55265890500; 57213199625; 57200598098; 25822578400","Hyperspectral Image Super-Resolution Classification with a Small Training Set Using Spectral Variation Extended Endmember Library","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898080","3001","3004","3","10.1109/IGARSS.2019.8898080","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077692240&doi=10.1109%2fIGARSS.2019.8898080&partnerID=40&md5=6cec1badf8ac99dc8ec2d0a180ea7e36","Classification has been one of the most important applications of hyperspectral images (HSIs) in the past decade, because of the outstanding discrimination among different classes ensured by abundant and detailed spectral information enclosed in HSIs. While the classification accuracy must be guaranteed by plenty of training samples, which is difficult to be satisfied in many practical cases. Meanwhile, because of its comparatively low spatial resolution, mixed pixels are widely existed in HSIs which makes subpixel level classification techniques more preferable rather than traditional pixel-level ones. A novel super-resolution classification method is proposed in this paper to deal with the two above mentioned problems in HSI classification, that is, limited number of training samples and widely existed mixed pixels. Specifically, spectral variation is considered to construct spectral variation extended endmember library, with which the abundance fractions for each class within a mixed pixel are estimated using collaborative representation. And finally, the classification result with higher spatial resolution is obtained with subpixel spatial attraction model based subpixel mapping. Simulative experiments are employed for validation and comparison. Experimental results illustrate that the newly proposed method is capable of producing super-resolution classification map of low resolution HSI with less misclassification. © 2019 IEEE.","Geology; Image classification; Image resolution; Optical resolving power; Pixels; Remote sensing; Sampling; Spectroscopy; Classification accuracy; Classification technique; Collaborative representations; HyperSpectral; Image super resolutions; Spectral variation; Sub pixels; Super resolution; Classification (of information)","Classification; hyperspectral; spectral variation; subpixel; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85077692240"
"Belov A.; Denisova A.","Belov, Alexander (35482106000); Denisova, Anna (42160925300)","35482106000; 42160925300","Remote sensing data fusion algorithm for super-resolution: Multi-temporal case","2020","Proceedings of SPIE - The International Society for Optical Engineering","11524","","115241O","","","","10.1117/12.2569653","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091242728&doi=10.1117%2f12.2569653&partnerID=40&md5=10608cb63982222f9e0e7afbf919df3b","Super-resolution remote sensing data fusion aims to compose the output image with the higher spatial and spectral resolution from the lower resolution input ones captured for the same territory. The images used for fusion are usually multi-temporal. However, existing multi-temporal image fusion methods exploit only cloud-free images that might be difficult to obtain for some territories where the weather conditions are moderately cloudy during the observation period. In this paper, the clouds and their shadows are considered as scene distortions i.e. significant local changes in brightness caused by some opaque objects or their shadows partially overlapping the scene at the moment of image registration. Here, we propose a multi-temporal remote sensing data fusion method adapted to the dataset containing images partially occupied by scene distortions. The method is based on gradient descent optimization procedure with scene distortion elimination in each iteration. The experiments with the modeled data revealed that our method provides spatial and spectral super-resolution even for datasets including images with scene distortions. In comparison with the scenedistortion free case, the proposed method reduces a root mean square error of the resulting image from 2 to 4% on average in the case of the mixed data sets with few undistorted images (from two to six). The overall research has shown that in the case of lack of the data without scene distortions, additional partially distorted images can be used to obtain better fusion results.  © 2020 SPIE.","Gradient methods; Image fusion; Mean square error; Optical resolving power; Gradient descent optimization; Multi-temporal image; Multi-temporal remote sensing; Observation Period; Remote sensing data fusion; Root mean square errors; Super resolution; Undistorted images; Remote sensing","Multi-temporal data; Remote sensing data; Root mean square error; Scene-distortion; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85091242728"
"Lu T.; Wang J.; Zhang Y.; Wang Z.; Jiang J.","Lu, Tao (56406646300); Wang, Jiaming (57206676342); Zhang, Yanduo (55993581700); Wang, Zhongyuan (57203515592); Jiang, Junjun (54902306100)","56406646300; 57206676342; 55993581700; 57203515592; 54902306100","Satellite image super-resolution via multi-scale residual deep neural network","2019","Remote Sensing","11","13","1588","","","","10.3390/rs11131588","54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068504707&doi=10.3390%2frs11131588&partnerID=40&md5=4958ed2884d2f3654a7dd51fd90d05e0","Recently, the application of satellite remote sensing images is becoming increasingly popular, but the observed images from satellite sensors are frequently in low-resolution (LR). Thus, they cannot fully meet the requirements of object identification and analysis. To utilize the multi-scale characteristics of objects fully in remote sensing images, this paper presents a multi-scale residual neural network (MRNN). MRNN adopts the multi-scale nature of satellite images to reconstruct high-frequency information accurately for super-resolution (SR) satellite imagery. Different sizes of patches from LR satellite images are initially extracted to fit different scale of objects. Large-, middle-, and small-scale deep residual neural networks are designed to simulate differently sized receptive fields for acquiring relative global, contextual, and local information for prior representation. Then, a fusion network is used to refine different scales of information. MRNN fuses the complementary high-frequency information from differently scaled networks to reconstruct the desired high-resolution satellite object image, which is in line with human visual experience (""look in multi-scale to see better""). Experimental results on the SpaceNet satellite image and NWPU-RESISC45 databases show that the proposed approach outperformed several state-of-the-art SR algorithms in terms of objective and subjective image qualities. © 2019 by the authors.","Image reconstruction; Neural networks; Optical resolving power; Remote sensing; Satellite imagery; Convolutional neural network; High resolution satellites; High-frequency informations; Multi-scale image; Object identification; Satellite remote sensing; Subjective image quality; Super resolution; Deep neural networks","Convolutional neural network; Multi-scale image; Residual network; Satellite imagery; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85068504707"
"Aidini A.; Giannopoulos M.; Pentari A.; Fotiadou K.; Tsakalides P.","Aidini, A. (57203761304); Giannopoulos, M. (57205378265); Pentari, A. (56442653900); Fotiadou, K. (25824915900); Tsakalides, P. (6701848334)","57203761304; 57205378265; 56442653900; 25824915900; 6701848334","Hyperspectral Image Compression and Super-Resolution Using Tensor Decomposition Learning","2019","Conference Record - Asilomar Conference on Signals, Systems and Computers","2019-November","","9048735","1369","1373","4","10.1109/IEEECONF44664.2019.9048735","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083324527&doi=10.1109%2fIEEECONF44664.2019.9048735&partnerID=40&md5=3caeb1d7fa266ae08d1634547223a478","As the field of remote sensing for Earth Observation is rapidly evolving, there is an increasing demand for developing suitable methods to store and transmit the massive amounts of the generated data. At the same time, as multiple sensors acquire observations with different dimensions, super-resolution methods come into play to unify the framework for upcoming statistical inference tasks. In this paper, we employ a tensor-based structuring of multi-spectral image data and we propose a low-rank tensor completion scheme for efficient image-content compression and recovery. To address the problem of low-resolution imagery, we further provide a robust algorithmic scheme for super-resolving satellite images, followed by a state-of-the-art convolutional neural network architecture serving the classification task of the employed images. Experimental analysis on real-world observations demonstrates the detrimental effects of image compression on classification, an issued successfully addressed by the proposed recovery and super-resolution schemes. © 2019 IEEE.","Computer circuits; Convolutional neural networks; Network architecture; Optical resolving power; Remote sensing; Satellite imagery; Spectroscopy; Tensors; Classification tasks; Earth observations; Experimental analysis; Low-resolution imagery; Multi-spectral image data; Statistical inference; Superresolution methods; Tensor decomposition; Image compression","Alternating Direction Method of Multipliers; Compression; Multi-Spectral Image Classification; Super Resolution; Tensor Unfoldings","Conference paper","Final","","Scopus","2-s2.0-85083324527"
"Zhang C.; Wang Q.; Li X.","Zhang, Cong (57213189690); Wang, Qi (56973045200); Li, Xuelong (55936260100)","57213189690; 56973045200; 55936260100","A Multi-Task Architecture for Remote Sensing by Joint Scene Classification and Image Quality Assessment","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898659","10055","10058","3","10.1109/IGARSS.2019.8898659","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077705053&doi=10.1109%2fIGARSS.2019.8898659&partnerID=40&md5=d711b4899eecd6cc2ba2203f73eb09c6","In this work, we propose a compact multi-task architecture based on deep learning for remote sensing scene classification and image quality assessment (IQA) simultaneously. The model can be trained in an end-to-end manner, and the robustness of classification is improved in our method. More importantly, by exploiting IQA and super-resolution, the accurate classification results can be obtained even if the images are distorted or with low quality. To the best of our knowledge, it is the first successful attempt to associate IQA with scene classification in a unified multi-task architecture. Our method is evaluated on the expanded UC Merced Land-Use dataset after data augmentation. In comparison with some other methods, the experimental results show that the proposed structure makes a great improvement on both classification and IQA. © 2019 IEEE.","Architecture; Deep learning; Geology; Image classification; Land use; Multi-task learning; Optical resolving power; Quality of service; Remote sensing; Classification results; Data augmentation; Image quality assessment; Image quality assessment (IQA); Image super resolutions; Low qualities; Scene classification; Super resolution; Image quality","deep learning; image quality assessment; image super-resolution; multi-task learning; Remote sensing; scene classification","Conference paper","Final","","Scopus","2-s2.0-85077705053"
"","","","Annual International Conference on 3D Imaging Technology, IC3DIT 2019","2020","Smart Innovation, Systems and Technologies","179","","","","","521","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084830660&partnerID=40&md5=ce895b7073bf7a21134f65766dc98aa9","The proceedings contain 60 papers. The special focus in this conference is on 3D Imaging Technology. The topics include: Loose Hand Gesture Recognition Using CNN; Multi-focus Image Fusion Method Based on NSST and BP Neural Network; classification of 3D Remote Sensing Images Through Dimensionality Reduction and Semantic Segmentation Network; research on Deep Learning Algorithm and Application Based on Convolutional Neural Network; object Attribute Recognition Based on Hard Negative Mining and Convolutional Neural Network; research on Intelligent Identification Method of Power Equipment Based on Deep Learning; chinese Color Name Identification from Images Using a Convolutional Neural Network; Research and Design of a Key Technology for Accelerating Convolution Computation for FPGA-Based CNN; Research on Voice Mark Recognition Algorithms Based on Optimized BP Neural Network; single Image Super Resolution via Deep Convolutional Dual Upscaling Branches with Different Focus; Shape Retrieval for 3D Models Based on MRF; Human Heart Model Rendering Based on BRDF Algorithm; level Set Segmentation Algorithm for Cyst Images with Intensity Inhomogeneity; a Robust and Fast Template Matching Algorithm; infrared and Visible Image Fusion Algorithm Based on Threshold Segmentation; improved K-Means Algorithm for Optimizing Initial Centers; an Improved AdaBoost Algorithm for Handwriting Digits Recognition; FCM Based on Improved Artificial Bee Colony Algorithm; airplane Trajectory Planning Using Artificial Immune Algorithm; a New Method for Removing Image Noise; sparse Impulsive Noise Corrupted Compressed Signal Recovery Using Laplace Noise Density; numerical Conformal Mapping Based on Improved Hermitian and Skew-Hermitian Splitting Method; an Improved Criminisi’s Image Inpainting Algorithm for Priority and Matching Criteria.","","","Conference review","Final","","Scopus","2-s2.0-85084830660"
"Ui Hoque M.R.; Burks R.; Kwan C.; Li J.","Ui Hoque, Md Reshad (57215223328); Burks, Roland (57215221542); Kwan, Chiman (7201421216); Li, Jiang (56226550100)","57215223328; 57215221542; 7201421216; 56226550100","Deep Learning for Remote Sensing Image Super-Resolution","2019","2019 IEEE 10th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2019","","","8993047","0286","0292","6","10.1109/UEMCON47517.2019.8993047","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080145619&doi=10.1109%2fUEMCON47517.2019.8993047&partnerID=40&md5=736354c0ac5bc10838c078f6109ef3a9","The aim of image super-Resolution (SR) is to enhance image resolution while still retain the integrity of the original image. There are many ongoing types of research on image super-resolution for natural images, but any a few on remote sensing images. In this paper, we proposed deep learning-based image super-resolution techniques, including convolutional neural network (CNN) and generative adversarial network (GAN) to enhance the resolution of remote sensing images by a factor 4. In CNN, it learns an end to end mapping from low-resolution image to high-resolution image whereas, in GAN, the model learns the mapping guided by the GAN loss and gives the sharper appearance in high-resolution images. Our experimental results show that visually GAN models perform well but are inferior to other models in terms of image quality metrics, whereas quantitatively CNN models outperform other super-resolution models. © 2019 IEEE.","Convolutional neural networks; Image enhancement; Image resolution; Learning systems; Mapping; Mobile telecommunication systems; Optical resolving power; Remote sensing; Ubiquitous computing; Adversarial networks; High resolution image; Image quality metrics; Image super resolutions; Low resolution images; Remote sensing images; Super resolution; Super-resolution models; Deep learning","CNN; Deep Learning; GAN; Machine Learning; Remote sensing image; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85080145619"
"Jiang J.; Sun H.; Liu X.; Ma J.","Jiang, Junjun (54902306100); Sun, He (57218202508); Liu, Xianming (57204313011); Ma, Jiayi (26638975600)","54902306100; 57218202508; 57204313011; 26638975600","Learning Spatial-Spectral Prior for Super-Resolution of Hyperspectral Imagery","2020","IEEE Transactions on Computational Imaging","6","","9097432","1082","1096","14","10.1109/TCI.2020.2996075","74","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088260355&doi=10.1109%2fTCI.2020.2996075&partnerID=40&md5=062572a3cc2a31be19cfa3288be749c5","Recently, single gray/RGB image super-resolution reconstruction task has been extensively studied and made significant progress by leveraging the advanced machine learning techniques based on deep convolutional neural networks (DCNNs). However, there has been limited technical development focusing on single hyperspectral image super-resolution due to the high-dimensional and complex spectral patterns in hyperspectral image. In this article, we make a step forward by investigating how to adapt state-of-the-art deep learning based single gray/RGB image super-resolution approaches for computationally efficient single hyperspectral image super-resolution, referred as SSPSR. Specifically, we introduce a spatial-spectral prior network (SSPN) to fully exploit the spatial information and the correlation between the spectra of the hyperspectral data. Considering that the hyperspectral training samples are scarce and the spectral dimension of hyperspectral image data is very high, it is nontrivial to train a stable and effective deep network. Therefore, a group convolution (with shared network parameters) and progressive upsampling framework is proposed. This will not only alleviate the difficulty in feature extraction due to high dimension of the hyperspectral data, but also make the training process more stable. To exploit the spatial and spectral prior, we design a spatial-spectral block (SSB), which consists of a spatial residual module and a spectral attention residual module. Experimental results on some hyperspectral images demonstrate that the proposed SSPSR method enhances the details of the recovered high-resolution hyperspectral images, and outperforms state-of-the-arts. The source code is available at [Online]. Available: https://github.com/junjun-jiang/SSPSR.  © 2015 IEEE.","Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Image reconstruction; Learning systems; Optical resolving power; Spectroscopy; Computationally efficient; Hyper-spectral imageries; Hyperspectral image datas; Image super resolutions; Image super-resolution reconstruction; Machine learning techniques; Spatial informations; Technical development; Image enhancement","deep convolutional neural networks (DCNNs); Hyperspectral remote sensing; image super-resolution; spatial-spectral prior","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85088260355"
"Jiang K.; Wang Z.; Yi P.; Jiang J.; Wang G.; Han Z.; Lu T.","Jiang, Kui (57203871718); Wang, Zhongyuan (57203515592); Yi, Peng (57203880354); Jiang, Junjun (54902306100); Wang, Guangcheng (57209891180); Han, Zhen (56415515700); Lu, Tao (56406646300)","57203871718; 57203515592; 57203880354; 54902306100; 57209891180; 56415515700; 56406646300","GAN-based multi-level mapping network for satellite imagery super-resolution","2019","Proceedings - IEEE International Conference on Multimedia and Expo","2019-July","","8784713","526","531","5","10.1109/ICME.2019.00097","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071032705&doi=10.1109%2fICME.2019.00097&partnerID=40&md5=50841be70ffa72c8423d321c3f30c9cc","Although many deep-learning-based image super-resolution (SR) methods have been proposed, most of them assume that all hierarchical features share the unified mapping equations. They ignore the differences between mapping equations at different feature levels, and create an average effect of mapping prediction, thus poorly building the mapping relations between low resolution (LR) and high resolution (HR) spaces. In this paper, we propose a multi-level mapping framework along with the adversarial learning strategy, namely MMGAN, for satellite imageries SR reconstruction. We also construct a feature extraction and tuning block (FETB) for fine feature expression. In particular, a novel two-dimension dense unit (DU) and a mapping attention unit (MAU) are constructed for building multi-level mappings in different stages. With our strategies, an HR image is reconstructed directly from the input image using multi-level mappings. Extensive experiments on Kaggle Open Source Dataset and Jilin-1 video satellite images exhibit superior reconstruction performance when compared with the state-of-the-art SR approaches. © 2019 IEEE.","Deep learning; Mapping; Optical resolving power; Remote sensing; Satellite imagery; Adversarial learning; Attention unit; Multi-level mapping; Remote sensing imagery; Super resolution; Image reconstruction","Adversarial learning; Attention unit; Multi-level mapping; Remote sensing imagery; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85071032705"
"Zou C.; Huang X.","Zou, Changzhong (57190284458); Huang, Xusheng (57215862334)","57190284458; 57215862334","Hyperspectral image super-resolution combining with deep learning and spectral unmixing","2020","Signal Processing: Image Communication","84","","115833","","","","10.1016/j.image.2020.115833","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082128956&doi=10.1016%2fj.image.2020.115833&partnerID=40&md5=0157832564312338f855d636f5f6d68f","In recent years, hyperspectral image super-resolution has attracted the attention of many researchers and has become a hot topic in the field of computer vision. However, it is difficult to obtain high-resolution images due to imaging hardware devices. At present, many existing hyperspectral image super-resolution methods have not achieved good results. In this paper, we propose a hyperspectral image super-resolution method combining with deep residual convolutional neural network (DRCNN) and spectral unmixing. Firstly, the spatial resolution of the image is enhanced by learning a priori knowledge of natural images. The DRCNN reconstructs high spatial resolution hyperspectral images by concatenating multiple residual blocks, each containing two convolutional layers. Secondly, the spectral features of low-resolution and high-resolution hyperspectral images are linked by spectral unmixing. This approach aims to obtain the endmember matrix and the abundance matrix. The final reconstruction result is obtained by multiplying the endmember matrix and the abundance matrix. In addition, in order to improve the visual effect of the reconstructed image, the total variation regularity is used to impose constraints on the abundance matrix to enhance the relationship between the pixels. The experimental results of remote sensing data based on ground facts show that the proposed method has good performance and preserves spatial information and spectral information without the need for auxiliary images. © 2020 Elsevier B.V.","Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Image reconstruction; Image resolution; Optical resolving power; Remote sensing; Spectroscopy; Deep residual convolutional neural network (DRCNN); High resolution image; High spatial resolution; Image super resolutions; Spatial informations; Spectral unmixing; Super resolution; Total variation; Image enhancement","Deep residual convolutional neural network (DRCNN); Hyperspectral image (HSI); Spectral unmixing; Super-resolution; Total variation (TV) regularity","Article","Final","","Scopus","2-s2.0-85082128956"
"Dell'Aglio D.A.G.; Gargiulo M.; Iodice A.; Riccio D.; Ruello G.","Dell'Aglio, D.A.G. (57202729372); Gargiulo, M. (57200856555); Iodice, A. (7003793925); Riccio, D. (7006577607); Ruello, G. (6603038881)","57202729372; 57200856555; 7003793925; 7006577607; 6603038881","Active Fire Detection in Multispectral Super-Resolved Sentinel-2 Images by Means of Sam-Based Approach","2019","5th International Forum on Research and Technologies for Society and Industry: Innovation to Shape the Future, RTSI 2019 - Proceedings","","","8895538","124","127","3","10.1109/RTSI.2019.8895538","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075638562&doi=10.1109%2fRTSI.2019.8895538&partnerID=40&md5=7217bd01b2ac64e53dd9446645b1e2c5","In the last years, Sentinel-2 data have become extensively used by the remote sensing community due to their relatively fine spatial resolution, high revisit time ensured by the twin satellites Sentinel- 2 and, of course, their free availability. However, not all the bands are provided at the highest resolution (10 meters). For instance, the Short-Wave Infrared (SWIR) bands, very useful for fires monitoring applications, are provided at 20 meters. Therefore, in order to have a more detailed Active Fire maps, we have proposed a super-resolution data fusion method based on Convolutional Neural Network (CNN), hereafter SRNN+. Then we have compared the standard Active Fire Detection (AFDs) based on indices (AFIs) [1], widely used in literature for active fires monitoring purpose, with a method based on the Spectral Angular Mapper (SAM) [2]. The proposed analysis is validated on the widespread fires that damaged the volcano Vesuvius (Italy) during the summer of 2017. © 2019 IEEE.","Convolution; Data fusion; Fire detectors; Infrared radiation; Neural networks; Optical resolving power; Remote sensing; Active fires; Convolutional neural network; Data fusion methods; Highest resolutions; Monitoring applications; Monitoring purpose; Short wave infrared bands; Super resolution; Fires","active fire indices; active fires; convolutional neural network; Data fusion; SAM; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85075638562"
"Li W.; Niu M.; Zhang Y.; Huang Y.; Yang J.","Li, Wenchao (55718616300); Niu, Meihua (57211240603); Zhang, Yongchao (56042343300); Huang, Yulin (23014806800); Yang, Jianyu (9239230100)","55718616300; 57211240603; 56042343300; 23014806800; 9239230100","Super-Resolution Imaging of Real-Beam Scanning Radar Base on Accelerated Maximum a Posteriori Algorithm","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898837","3173","3176","3","10.1109/IGARSS.2019.8898837","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077701017&doi=10.1109%2fIGARSS.2019.8898837&partnerID=40&md5=26a48f6a34ccbea277fd7b4737e56c8e","In this paper, an accelerated maximum a posteriori (AMAP) algorithm is proposed to realize fast and effective super resolution imaging of real beam scanning radar. The main idea of this algorithm is to construct a prediction vector based on the first and the second order of difference information before iteration. By using Taylor expansion series and second-order vector extrapolation technique, it aims to enhance the convergence speed of maximum a posteriori algorithm. Finally, the proposed algorithm is verified by simulations. © 2019 IEEE.","Acceleration; Deconvolution; Geology; Optical resolving power; Radar; Radar imaging; Remote sensing; Scanning; Turbo codes; Beam scanning; Convergence speed; Extrapolation techniques; Maximum a posteriori; Maximum a posteriori algorithm; Prediction vectors; Super resolution imaging; Taylor expansions; Iterative methods","acceleration; deconvolution; maximum a posteriori algorithm; Real beam scanning radar; super-resolution imaging","Conference paper","Final","","Scopus","2-s2.0-85077701017"
"","","","11th International Conference on Knowledge Science, Engineering and Management, KSEM 2018","2018","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11062 LNAI","","","","","1010","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052193794&partnerID=40&md5=c66464770f23f373c41d673b97d51710","The proceedings contain 88 papers. The special focus in this conference is on Knowledge Science, Engineering and Management. The topics include: TCMEF: A TCM entity filter using less text; two-stage object detection based on deep pruning for remote sensing image; w-shaped selection for light field super-resolution; users personalized sketch-based image retrieval using deep transfer learning; enhancing network flow for multi-target tracking with detection group analysis; combine coarse and fine cues: Multi-grained fusion network for video-based person re-identification; understand and assess people’s procrastination by mining computer usage log; group outlying aspects mining; fine-grained correlation learning with stacked co-attention networks for cross-modal information retrieval; A biomedical question answering system based on SNOMED-CT; supervised manifold-preserving graph reduction for noisy data classification; Personalize review selection using PeRView; An online GPS trajectory data compression method based on motion state change; mining temporal discriminant frames via joint matrix factorization: A case study of illegal immigration in the U.S. news media; enhancing cluster center identification in density peak clustering; An improved weighted ELM with hierarchical feature representation for imbalanced biomedical datasets; SERL: Semantic-path biased representation learning of heterogeneous information network; social Bayesian personal ranking for missing data in implicit feedback recommendation; a semantic path-based similarity measure for weighted heterogeneous information networks; cross-domain recommendation for mapping sentiment review pattern; authorship attribution for short texts with author-document topic model; fuzzy gravitational search approach to a hybrid data model based recommender system; causal discovery with Bayesian networks inductive transfer; robust detection of communities with multi-semantics in large attributed networks.","","","Conference review","Final","","Scopus","2-s2.0-85052193794"
"Wang Z.; Jin X.; Dai Q.","Wang, Zhouping (57202543657); Jin, Xin (34975078600); Dai, Qionghai (7202735131)","57202543657; 34975078600; 7202735131","Superresolution imaging through scattering media by spectrum correlation","2018","Proceedings of SPIE - The International Society for Optical Engineering","10817","","1081709","","","","10.1117/12.2500860","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059418111&doi=10.1117%2f12.2500860&partnerID=40&md5=fc8c86c40dfdb3095f3d40793f575c45","High-resolution imaging through strongly scattering media is a long-standing challenge with broad applications including biomedical imaging, remote sensing, navigation and so on. In the past decade, several techniques have been proposed to solve this problem. Among these techniques, speckle-correlation-based method can non-invasively extract the spectral amplitude of imaging target from captured scrambled image by conducting autocorrelation and Fourier transform operations. The imaging target can be reconstructed by iterative phase retrieval, while the imaging resolution is restricted by the low-pass property of scattering imaging system. Disproportionality of different frequency components of extracted imaging target spectral amplitude blurs the reconstruction results. In this paper, we propose the spectrum correlation approach to correct the proportional relations among low and medium frequency components of extracted imaging target spectral amplitude. By modeling the propagation of scattering wavefront and calculating the autocorrelation expectation of point spread function (PSF) at different depths, statistical spectral amplitude distribution of PSF is generated to be the weighting factor for imaging target spectrum correction. Nonlinear translation of speckle pattern spectrum expectation is introduced for error reduction in high-frequency components of extracted imaging target spectral amplitude. Finally, corrected spectral amplitude is utilized as the input of phase-retrieval algorithm for imaging target reconstruction. Simulated experiments are presented to demonstrate the effectiveness of the proposed method. After the spectrum correction of extracted spectral amplitude, imaging resolution of speckle-correlation-based scattering imaging system is improved, which can be applied to reconstruct target with smaller size or located deeper in the scattering media. © 2018 SPIE.","Autocorrelation; Fiber optic sensors; Image resolution; Imaging systems; Iterative methods; Medical imaging; Multimedia systems; Optical transfer function; Remote sensing; Speckle; Computational imaging; Frequency components; High frequency components; High-resolution imaging; Imaging through turbid media; Phase retrieval algorithm; Spectrum correlations; Super resolution imaging; Image processing","Computational imaging; Frequency component correction; Imaging through turbid media; Spectrum correlation","Conference paper","Final","","Scopus","2-s2.0-85059418111"
"Tan Z.; Lyu Q.; Sun J.; Wang J.; Zhao N.","Tan, Zheng (57188729245); Lyu, Qunbo (35337326500); Sun, Jianying (56171742300); Wang, Jianwei (56455377300); Zhao, Na (57202341029)","57188729245; 35337326500; 56171742300; 56455377300; 57202341029","Super-resolution imaging design for CX6-02 micro-satellite","2019","Proceedings of SPIE - The International Society for Optical Engineering","11155","","111550B","","","","10.1117/12.2532995","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078210086&doi=10.1117%2f12.2532995&partnerID=40&md5=b9672a26a03900a9c927e33dabac152b","This paper aims at a novel super-resolution imaging design scheme for CX6-02 micro-satellite. In the design of super resolution reconstruction algorithm, under the framework of the hierarchical bayesian, an improved L1 norm prior model based on gradient adaptation is proposed, to avoid the amplification of noise while deconvolution. In imaging mode and system design, the satellite attitude control deviation and ground velocity compensation are used to obtain multi-frame images with sub-pixel information, and in order to exploit the potential of the reconstruction algorithm, the parameters of the optical system are designed by means of high availability redundancy. These make the CX6-02 satellite's imaging resolution increased from 2.8 to 1.4 meters in the 700km orbit altitude, the whole satellite is 66kg. © 2019 SPIE.","Attitude control; Availability; Deconvolution; DNA sequences; Micro satellites; Optical resolving power; Optical systems; Orbits; Remote sensing; Systems analysis; Hierarchical bayesian; Imaging modes; Imaging resolutions; Reconstruction algorithms; Satellite attitude control; Sub-pixel information; Super resolution imaging; Super resolution reconstruction; Image processing","CX6-02 micro-satellite; Imaging mode and system design; Reconstruction algorithm design; Super-resolution imaging","Conference paper","Final","","Scopus","2-s2.0-85078210086"
"Joshi M.V.; Upla K.P.","Joshi, Manjunath V. (7202602032); Upla, Kishor P. (53985429600)","7202602032; 53985429600","Multi-resolution image fusion in remote sensing","2019","Multi-resolution Image Fusion in Remote Sensing","","","","1","210","209","10.1017/9781108566285","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090348571&doi=10.1017%2f9781108566285&partnerID=40&md5=5d49b302602b8eaa20da22f715078144","Written in an easy-to-follow approach, the text will help the readers to understand the techniques and applications of image fusion for remotely sensed multi-spectral images. It covers important multi-resolution fusion concepts along with the state-of-the-art methods including super resolution and multi stage guided filters. It includes in depth analysis on degradation estimation, Gabor Prior and Markov Random Field (MRF) Prior. Concepts such as guided filter and difference of Gaussian are discussed comprehensively. Novel techniques in multi-resolution fusion by making use of regularization are explained in detail. It also includes different quality assessment measures used in testing the quality of fusion. Real-life applications and plenty of multi-resolution images are provided in the text for enhanced learning. © Cambridge University Press 2019.","","","Book","Final","","Scopus","2-s2.0-85090348571"
"Gao H.; Zhang Y.; Guo H.","Gao, Han (57684597800); Zhang, Yanmei (56184948400); Guo, Haichao (54397088000)","57684597800; 56184948400; 54397088000","Multihypothesis-based compressive sensing algorithm for nonscanning three-dimensional laser imaging","2018","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","11","1","8119512","311","321","10","10.1109/JSTARS.2017.2773469","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035794725&doi=10.1109%2fJSTARS.2017.2773469&partnerID=40&md5=c5260fd87fd9984f5a562fffbf8e760d","The resolution of nonscanning three-dimensional (3-D) imaging systems is limited by the number and accuracy of the array sensors. Moreover, for space-continuous targets in practical situations, the echo pulses in time-of-flight systems overlap and traditional peak detection is no longer suitable for super-resolution applications. Hence, compressive sensing (CS) has been introduced to achieve super-resolution. However, most of the conventional CS algorithms cannot be used directly for 3-D image reconstruction. In this paper, we propose a novel super-resolution algorithm for nonscanning 3-D laser imaging based on CS reconstruction. To acquire the range information of space-continuous targets, an all-one projection is implemented in advance to estimate the spatial distribution of the targets; a range observation matrix composed of time-interval basis vectors is then constructed to obtain the peak values of each frame from overlapping echo pulses. Because of the spatial continuity of the targets, Tikhonov regularization is utilized to solve the ill-posed inverse problem. Furthermore, to enhance the reconstruction quality of the adjacent frames, multihypothesis prediction is used with displacement and diffusion models to estimate the motion of the contour line. Simulation results based on real data from the ASTER global digital elevation model demonstrate the effectiveness and high accuracy of the proposed algorithm for complex landforms. © 2017 IEEE.","Continuous time systems; Geomorphology; Image processing; Image reconstruction; Image resolution; Imaging techniques; Inverse problems; Optical radar; Optical resolving power; Sensor arrays; Vector spaces; Compressive sensing; Digital elevation model; ILL-posed inverse problem; Laser imaging; Multi-hypothesis; Super resolution; Super resolution algorithms; Three dimensional (3-D) imaging; accuracy assessment; algorithm; ASTER; digital elevation model; image analysis; image resolution; inverse problem; remote sensing; spatial distribution; three-dimensional modeling; Compressed sensing","3-D laser imaging; Compressive sensing (CS); Multihypothesis (MH) prediction; Super-resolution","Article","Final","","Scopus","2-s2.0-85035794725"
"","","","14th Asian Conference on Computer Vision, ACCV 2018","2019","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11363 LNCS","","","","","4380","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067240912&partnerID=40&md5=c9ff463e7ef36999fb318e7a10f821fc","The proceedings contain 269 papers. The special focus in this conference is on Computer Vision. The topics include: Towards Multi-class Object Detection in Unconstrained Remote Sensing Imagery; panorama from Representative Frames of Unconstrained Videos Using DiffeoMeshes; robust and Efficient Ellipse Fitting Using Tangent Chord Distance; knowledge Distillation with Feature Maps for Image Classification; bidirectional Conditional Generative Adversarial Networks; cross-Resolution Person Re-identification with Deep Antithetical Learning; a Temporally-Aware Interpolation Network for Video Frame Inpainting; linear Solution to the Minimal Absolute Pose Rolling Shutter Problem; scale Estimation of Monocular SfM for a Multi-modal Stereo Camera; geometry Meets Semantics for Semi-supervised Monocular Depth Estimation; zero-Shot Facial Expression Recognition with Multi-label Label Propagation; deep Manifold Alignment for Mid-Grain Sketch Based Image Retrieval; Visual Graphs from Motion (VGfM): Scene Understanding with Object Geometry Reasoning; deep Semantic Matching with Foreground Detection and Cycle-Consistency; hidden Two-Stream Convolutional Networks for Action Recognition; a Multi-purpose Convolutional Neural Network for Simultaneous Super-Resolution and High Dynamic Range Image Reconstruction; ITM-CNN: Learning the Inverse Tone Mapping from Low Dynamic Range Video to High Dynamic Range Displays Using Convolutional Neural Networks; Structure Aware SLAM Using Quadrics and Planes; maintaining Natural Image Statistics with the Contextual Loss; U-DADA: Unsupervised Deep Action Domain Adaptation; artistic Object Recognition by Unsupervised Style Adaptation; believe It or Not, We Know What You Are Looking At!; iPose: Instance-Aware 6D Pose Estimation of Partly Occluded Objects; multi-Attribute Probabilistic Linear Discriminant Analysis for 3D Facial Shapes; combination of Two Fully Convolutional Neural Networks for Robust Binarization; deep Depth from Focus.","","","Conference review","Final","","Scopus","2-s2.0-85067240912"
"Laurenzis M.; Bacher E.; Christnacher F.","Laurenzis, Martin (6602922462); Bacher, Emmanuel (46061790400); Christnacher, Frank (6506050618)","6602922462; 46061790400; 6506050618","Error-free coding of range gates for super-resolution three-dimensional imaging","2018","Proceedings of SPIE - The International Society for Optical Engineering","10796","","107960J","","","","10.1117/12.2320463","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057395414&doi=10.1117%2f12.2320463&partnerID=40&md5=81c23d938d98a6c5c6c119c24a1b913f","Error-free coding of range gates is a key performance for the application in super-resolution depth mapping and reliable compressed range imaging. Until now, coding of range gates suffer from a non-linear error in erroneous coding sequences. But, Gray Codes and other Hamiltonian-type coding sequences can be used to eliminate ambiguities. In this paper, different coding sequences based on 4-bit Gray Codes as well as further 4-bit Coding schemes were investigated and applied to perform three-dimensional imaging in a range of 4.2 m with super-resolution. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Compressed sensing; Errors; Hamiltonians; Imaging systems; Optical radar; Optical resolving power; Remote sensing; 3D imaging; Coding scheme; Coding sequences; Computational imaging; Non-linear error; Range imaging; Super resolution; Three dimensional imaging; Codes (symbols)","3D imaging; compressed sensing; computational imaging; Error-free coding; LADAR; LiDAR; range imaging","Conference paper","Final","","Scopus","2-s2.0-85057395414"
"Wang Z.; Zhu J.","Wang, Zelong (55910514800); Zhu, Jubo (7405689299)","55910514800; 7405689299","Single-pixel compressive imaging based on motion compensation","2018","IET Image Processing","12","12","","2283","2291","8","10.1049/iet-ipr.2018.5741","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057896385&doi=10.1049%2fiet-ipr.2018.5741&partnerID=40&md5=e3385a4f1f0d1438055458d9a4ad06b6","Compressive sensing (CS) theory enables single-pixel compressive imaging (SPCI) popular in optical remote sensing imaging, since single-pixel imager not only realises the acquisition and recovery of sparse images at the sampling rates significantly below the classical Nyquist rate, but also makes use of special detectors to improve sensitivity, dynamic range, spectral range and so on. However, its requirement of static imaging condition for the time-sequential measurements makes it difficult to apply in remote sensing, since the imaging platform is always in motion relative to the imaging scene. In this study, the authors develop a new method for SPCI on moving platform in optical remote sensing. Instead of ignoring the motion during sampling, the proposed method first builds the compressive sampling model based on motion compensation during sampling, and then reconstructs the image by frame-by-frame recovery method and joint recovery method, respectively, in the framework of CS theory, where the recovery condition is also analysed. To validate the basic principle and the physical feasibility of motion compensation, the authors implement the numerical simulations and optical experiments, where different conditions are exploited sufficiently. In addition, the proposed method for SPCI can be also extended into other applications, such as 360° annular imaging, multi-pixel compressive imaging as well as super-resolution imaging. © 2018, The Institution of Engineering and Technology.","Compressed sensing; Image enhancement; Motion compensation; Pixels; Recovery; Remote sensing; Basic principles; Compressive imaging; Compressive sampling; Compressive sensing; Optical experiments; Optical remote sensing; Physical feasibility; Super resolution imaging; Image sampling","","Article","Final","","Scopus","2-s2.0-85057896385"
"Yanovsky I.; Lambrigtsen B.","Yanovsky, Igor (16403652300); Lambrigtsen, Bjorn (6603478504)","16403652300; 6603478504","Temporal super-resolution of microwave remote sensing images","2018","15th Specialist Meeting on Microwave Radiometry and Remote Sensing of the Environment, MicroRad 2018 - Proceedings","","","8430695","110","115","5","10.1109/MICRORAD.2018.8430695","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052915526&doi=10.1109%2fMICRORAD.2018.8430695&partnerID=40&md5=3db9a2d62f7f2d12e2de7d0fde46ca4c","We develop an approach for increasing the temporal resolution of a temporally blurred sequence of observations. Super-resolution is performed in time using a variational approach. By temporal super-resolution, we mean recovering rapidly evolving events that were corrupted by the induced blur of the sensor. A blurred sequence of observations is assumed to have been generated by convolution of a physical scene with a temporal rectangular convolution kernel whose support is the sensor exposure time. We solve the deconvolution problem using the Split-Bregman method. Such methodology is based on current research in sparse optimization and compressed sensing, which lead to unprecedented efficiencies for solving image reconstruction problems. We test our method using a simulated temporally blurred and noisy temporal precipitation sequence and show that our method significantly reduces the errors in the corrupted sequence. © 2018 IEEE.","Convolution; Deconvolution; Image reconstruction; Microwaves; Optical resolving power; Radiometry; Microwave imaging; Microwave remote sensing; Precipitation sequence; Reconstruction problems; Super resolution; Temporal resolution; Temporal super resolution; Variational approaches; Remote sensing","Deconvolution; microwave imaging; remote sensing; super-resolution; temporal resolution","Conference paper","Final","","Scopus","2-s2.0-85052915526"
"Lopez-Radcenco M.; Fablet R.; Aissa-El-Bey A.; Ailliot P.","Lopez-Radcenco, Manuel (57189596029); Fablet, Ronan (6603508732); Aissa-El-Bey, Abdeldjalil (15922114000); Ailliot, Pierre (9236372700)","57189596029; 6603508732; 15922114000; 9236372700","Locally-adapted convolution-based super-resolution of irregularly-sampled ocean remote sensing data","2018","Proceedings - International Conference on Image Processing, ICIP","2017-September","","","4307","4311","4","10.1109/ICIP.2017.8297095","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045332733&doi=10.1109%2fICIP.2017.8297095&partnerID=40&md5=0842caf9d713cbd985aa5f5969b037a1","Super-resolution is a classical problem in image processing, with numerous applications to remote sensing image enhancement. Here, we address the super-resolution of irregularly-sampled remote sensing images. Using an optimal interpolation as the low-resolution reconstruction, we explore locally-adapted multimodal convolutional models and investigate different dictionary-based decompositions, namely based on principal component analysis (PCA), sparse priors and non-negativity constraints. We consider an application to the reconstruction of sea surface height (SSH) fields from two information sources, along-track altimeter data and sea surface temperature (SST) data. The reported experiments demonstrate the relevance of the proposed model, especially locally-adapted parametrizations with non-negativity constraints, to outperform optimally-interpolated reconstructions. © 2017 IEEE.","Convolution; Image enhancement; Oceanography; Optical resolving power; Principal component analysis; Surface reconstruction; Surface waters; Convolutional model; Dictionary-based; Irregular sampling; Non-negativity; Super resolution; Remote sensing","Convolutional model; Dictionary-based decomposition; Irregular sampling; Non-negativity; Super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85045332733"
"Li X.; Ling F.; Foody G.M.; Ge Y.; Zhang Y.; Du Y.","Li, Xiaodong (55878368700); Ling, Feng (56278268300); Foody, Giles M. (7007014233); Ge, Yong (26655529300); Zhang, Yihang (55658053900); Du, Yun (56420121700)","55878368700; 56278268300; 7007014233; 26655529300; 55658053900; 56420121700","Generating a series of fine spatial and temporal resolution land cover maps by fusing coarse spatial resolution remotely sensed images and fine spatial resolution land cover maps","2017","Remote Sensing of Environment","196","","","293","311","18","10.1016/j.rse.2017.05.011","79","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019386206&doi=10.1016%2fj.rse.2017.05.011&partnerID=40&md5=425dc5108d01b2facddcfb923990a0d8","Studies of land cover dynamics would benefit greatly from the generation of land cover maps at both fine spatial and temporal resolutions. Fine spatial resolution images are usually acquired relatively infrequently, whereas coarse spatial resolution images may be acquired with a high repetition rate but may not capture the spatial detail of the land cover mosaic of the region of interest. Traditional image spatial–temporal fusion methods focus on the blending of pixel spectra reflectance values and do not directly provide land cover maps or information on land cover dynamics. In this research, a novel Spatial–Temporal remotely sensed Images and land cover Maps Fusion Model (STIMFM) is proposed to produce land cover maps at both fine spatial and temporal resolutions using a series of coarse spatial resolution images together with a few fine spatial resolution land cover maps that pre- and post-date the series of coarse spatial resolution images. STIMFM integrates both the spatial and temporal dependences of fine spatial resolution pixels and outputs a series of fine spatial–temporal resolution land cover maps instead of reflectance images, which can be used directly for studies of land cover dynamics. Here, three experiments based on simulated and real remotely sensed images were undertaken to evaluate the STIMFM for studies of land cover change. These experiments included comparative assessment of methods based on single-date image such as the super-resolution approaches (e.g., pixel swapping-based super-resolution mapping) and the state-of-the-art spatial–temporal fusion approach that used the Enhanced Spatial and Temporal Adaptive Reflectance Fusion Model (ESTARFM) and the Flexible Spatiotemporal DAta Fusion model (FSDAF) to predict the fine-resolution images, in which the maximum likelihood classifier and the automated land cover updating approach based on integrated change detection and classification method were then applied to generate the fine-resolution land cover maps. Results show that the methods based on single-date image failed to predict the pixels of changed and unchanged land cover with high accuracy. The land cover maps that were obtained by classification of the reflectance images outputted from ESTARFM and FSDAF contained substantial misclassification, and the classification accuracy was lower for pixels of changed land cover than for pixels of unchanged land cover. In addition, STIMFM predicted fine spatial–temporal resolution land cover maps from a series of Landsat images and a few Google Earth images, to which ESTARFM and FSDAF that require correlation in reflectance bands in coarse and fine images cannot be applied. Notably, STIMFM generated higher accuracy for pixels of both changed and unchanged land cover in comparison with other methods. © 2017 Elsevier Inc.","Data fusion; Dynamics; Image acquisition; Image fusion; Image resolution; Image segmentation; Maximum likelihood; Optical resolving power; Pixels; Reflection; Remote sensing; Classification accuracy; Endmember extraction; Fine-resolution images; Maximum likelihood classifiers; Spatial and temporal resolutions; Spatial resolution images; Spatial temporals; Super-resolution mappings; image analysis; land cover; Landsat; map; mapping; pixel; reflectance; remote sensing; spatial resolution; spatiotemporal analysis; Mapping","Endmember extraction; Spatial temporal fusion; Super-resolution mapping","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85019386206"
"Xiu L.; Yong L.; Cui Z.; Weiqi J.","Xiu, Liu (54788183700); Yong, Liu (57215420439); Cui, Zhang (57208315695); Weiqi, Jin (24082059800)","54788183700; 57215420439; 57208315695; 24082059800","Resolution improvement and data processing of remote sensing images","2019","Laser and Optoelectronics Progress","56","8","081002","","","","10.3788/LOP56.081002","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064451782&doi=10.3788%2fLOP56.081002&partnerID=40&md5=faf9a6889715d4a8d135add9e652ed62","An electro-optical imaging system is a typical optical-discrete sampling system. Usually, the spatial resolution of the electro-optical imaging system can be improved by means of the technical routes such as the increase of objective lens focal length, the increase of detector array consumption, the size reduction of detector elements, and the increase of detector filling rate. Due to the restriction of device level, the effective data processing method can be used to improve the resolution of an imaging system. The sub-pixel imaging technique and the super-resolution image processing technique based on the discrete CCD/CMOS plane array detectors arc mainly introduced, which arc widely concerned at home and abroad. © 2019 Chinese Academy of Sciences. All rights reserved.","","Data processing; Image processing; Sub-pixel imaging; Super-resolution","Article","Final","","Scopus","2-s2.0-85064451782"
"Wang P.; Mura M.D.; Chanussot J.; Zhang G.","Wang, Peng (57189493188); Mura, Mauro Dalla (36499129800); Chanussot, Jocelyn (6602159365); Zhang, Gong (35241577600)","57189493188; 36499129800; 6602159365; 35241577600","Soft-Then-Hard Super-Resolution Mapping Based on Pansharpening Technique for Remote Sensing Image","2019","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","12","1","8584054","334","344","10","10.1109/JSTARS.2018.2885793","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058870878&doi=10.1109%2fJSTARS.2018.2885793&partnerID=40&md5=c1d57ea1c4f6326fbc318cb454178f72","Super-resolution mapping (SRM) technique can explore the spatial distribution information of land cover classes in mixed pixels for multispectral image (MSI) or hyspectral image (HSI). Soft-then-hard super-resolution mapping (STHSRM) is an important type of SRM technique. STHSRM first utilizes the subpixel sharpening to produce the high-resolution fractional images with the soft attribute values for each subpixel and then allocates the hard class labels to each subpixel. However, due to the low resolution in the original image, the fractional images are difficult to pick up the full spatial-spectral information from the original image. In this paper, pansharpening technique is utilized in STHSRM (STHSRM-PAN) to produce the fractional images with more spatial-spectral information, which improves the mapping results. First, the original low-resolution MSI or HSI and a panchromatic image (PAN) are fused by pansharpening technique to produce the improved resolution image with the high spectral resolution of MSI or HSI and the high spatial resolution of PAN. The high-resolution fractional images with more spatial-spectral information are then obtained by unmixing the improved resolution image. Finally, the class labels are assigned to each subpixel according to the soft attribute values from the high-resolution fractional images. Comparing with the state-of-the-art STHSRM algorithms, the STHSRM-PAN shows the best performance with the percentage correctly classified and Kappa coefficient (Kappa) in the three experimental results. © 2008-2012 IEEE.","Photomapping; Pixels; Remote sensing; Spectral resolution; High spatial resolution; High spectral resolution; Multispectral images; Pan-sharpening; Panchromatic (Pan) image; Remote sensing images; Spectral information; Super-resolution mappings; experimental study; image resolution; imagery; land cover; mapping method; pixel; remote sensing; spatial distribution; spectral analysis; Image enhancement","Pansharpening; remote sensing image; soft-then-hard super-resolution mapping; spatial-spectral information","Article","Final","","Scopus","2-s2.0-85058870878"
"","","","Imaging Systems and Applications, ISA 2018","2018","Optics InfoBase Conference Papers","Part F102-ISA 2018","","","","","56","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051269534&partnerID=40&md5=62b1d6e7295e981a82a71e07521fd598","This proceedings contains 27 papers. This annual topical meeting captures all the leading-edge research, engineering and systems design and innovative uses of imaging systems in microscopy, invasive and non-invasive surgery, remote sensing, astronomical observations and imaging from nearby planets to outer space, digital cinematography capture and projection, computational photography and consumer imaging. Also known as: Imaging Systems; Imaging Systems and Applications. The conference topics include: Electrically switchable large, thin, and fast optics; Achromatic Test of Pancharatnam Phase Lens for VR/AR; Non-local Control of a Metasurface Image; Towards Random Metasurface based Devices; Reflective microwave ghost imaging with dynamic metasurface apertures; The Proton Beam Imaging System Design for the Spallation Neutron Source Tungsten Target; Encoding Optical Architectures via Gene Expression Programming; Ultra-High Resolution Full-Field OCT (FFOCT) for Cornea and Retina; Rapid Full-Field Optical Coherence Tomography Using Geometric Phase Ferroelectric Liquid Crystal Technology; Automated Image Processing Algorithm for Infrared Meibography; Integrating Retinal Birefringence Scanning and Optical Coherence Tomography for Pediatric Retinal Imaging; 2-Terminal Organic FPA Pixel Design for Curved Image Sensors; Infrared Monolithic Double Diffractive Kinoform Doublet on a Planar Substrate - Coupled Design Model; Super-resolution confocal microscopy using optical nonlinearity; Improved Lateral Resolution of Continuous Wave STED Microscopy using Standing Wave in focus; Tunable structured illumination system based on a Wollaston prism; Optimal Path and Illumination Design for Multiframe Motion Deblurring; Speckle-Free Imaging with Nanosecond-Scale Acquisition Using Microlens-Stabilized Laser Arrays; Imaging and quantitating abrasion damage on transparent substrates using edge light illumination; Compressive high-speed imaging in fluorescence microscopy and 3D photography; Development of a coded exposure camera for high-speed 3D measurement using microscope; Depth of Focus Extension based on a Laser Frequency-shifted Feedback Imaging System; Temporal Study of Photonic Jet Formations under Ultrashort Laser Pulses Illumination for Different Geometries in Near-field Optical Microscopy; Measurement of Modulation Transfer Function using Digital Micromirror Devices; Bayer and demosaicking effect for imaging the stress field in digital photoelasticity; Illumination Pattern Estimation for Multiple Exposures Extraction in a Snapshot Imaging Technique; Data-Driven Non-Line-of-Sight Imaging With A Traditional Camera. The key terms of this proceedings include Biomedical Imaging, Computer Vision & Image processing, Microscopy I: Super-resolution & Illumination Techniques, Microscopy II: 3D & High Speed Techniques, Sensors & Optics, Thin Optics and Optical Design.","","","Conference review","Final","","Scopus","2-s2.0-85051269534"
"Ghosh A.; Ehrlich M.; Davis L.; Chellappa R.","Ghosh, Arthita (57189594680); Ehrlich, Max (57189682114); Davis, Larry (57203425293); Chellappa, Rama (57203078416)","57189594680; 57189682114; 57203425293; 57203078416","Unsupervised super-resolution of satellite imagery for high fidelity material label transfer","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-January","","8900639","5144","5147","3","10.1109/IGARSS.2019.8900639","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108351265&doi=10.1109%2fIGARSS.2019.8900639&partnerID=40&md5=92ad441da7c0738b541fa52b935dfb00","Urban material recognition in remote sensing imagery is a challenging problem due to the difficulty of obtaining human annotations, especially on low resolution satellite images. To this end, we propose an unsupervised domain adaptationbased approach using adversarial learning. We aim to harvest information from smaller quantities of high resolution data (source domain) and utilize the same to super-resolve low resolution imagery (target domain). This can potentially aid in semantic as well as material label transfer from a richly annotated source to a target domain.  © 2019 IEEE.","Remote sensing; Semantics; Adversarial learning; High resolution data; Human annotations; Low-resolution imagery; Remote sensing imagery; Satellite images; Super resolution; Urban materials; Satellite imagery","Adversarial learning; Label transfer; Super-resolution; Unsupervised Domain Adaptation","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85108351265"
"Wang G.; Zhu F.; Lu Z.; Yuan X.","Wang, Guangcheng (57209891180); Zhu, Feng (57201007172); Lu, Zhaolin (8579856500); Yuan, Xiaoping (55469942200)","57209891180; 57201007172; 8579856500; 55469942200","No-reference quality assessment of super-resolution reconstructed images by incorporating domain knowledge","2018","Journal of Information Hiding and Multimedia Signal Processing","9","2","","496","505","9","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042860691&partnerID=40&md5=58584f7805ea37cecfefac839f3916de","Super resolution (SR) has been extensively studied these years due to its wide applications in machine vision, medical imaging and remote sensing, etc. With a great number of SR image reconstruction algorithms proposed, an accompanying task is how to evaluate the quality of SR reconstructed images. Although a number of image quality metrics have been reported, they are not specifically designed for image super resolution, so the are usually limited for this task. Motivated by these, this paper presents a no-reference quality metric for SR reconstructed images by measuring structure degra-dations and SR-relevant domain distortions. By incorporating domain knowledge, the proposed metric is more effective than the state-of-the-art models for the quality assessment of SR reconstructed images. Experimental results based on three subjectively-rated SR image databases demonstrate the advantages of the proposed metric in terms of both prediction performance and generalization ability. © 2018, Ubiquitous International. All rights reserved.","Image processing; Image reconstruction; Image resolution; Medical imaging; Optical resolving power; Remote sensing; Blurring; Quality assessment; Ringing; Structure degradation; Super resolution; Image quality","Blurring; Quality assessment; Ringing; Structure degradation; Super resolution","Article","Final","","Scopus","2-s2.0-85042860691"
"Yang R.; Liu Z.; She W.","Yang, Rui (57196636127); Liu, Zhaohui (56482764900); She, Wenji (36538137700)","57196636127; 56482764900; 36538137700","Simultaneous super-resolution reconstruction based on plane array staring remote sensing images; [遥感面阵凝视图像并行超分辨重建方法]","2019","Hongwai yu Jiguang Gongcheng/Infrared and Laser Engineering","48","1","0126002","","","","10.3788/IRLA201948.0126002","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062681221&doi=10.3788%2fIRLA201948.0126002&partnerID=40&md5=8fd16965425187e2d7d25b63206f28d0","A group of images for one scene can be obtained by plane array staring remote sensing system. So researchers often use multi-frame image super-resolution reconstruction to produce images with higher spatial resolution. However, most of reports regard super-resolution reconstruction as an isolated part ignoring that geometric parameters of imaging system have the ability to optimize the reconstruction model. Therefore, the influence of attitude angle on resolution changes in different directions was analyzed particularly. Meanwhile, the corresponding anisotropic blur estimation was presented to improve the accuracy of discrimination model. Because of the matching parameter as a significant role in super-resolution reconstruction, for improving the accuracy of the matching parameter estimation and decreasing the global initial matching error caused by the system, the algorithm of simultaneously optimizing super-resolution image and matching parameters based on maximum a posteriori estimation was proposed. This method takes advantage of the useful information of imaging system and improve the robustness of matching parameter by synchronous optimizing. The experimental results demonstrate that the method of our paper is better than existed algorithms in detail information and definition observing by eyes. In addition, the mean square error was reduced 0.3 times, and the information entropy was increased 1.2 in average. © 2019, Editorial Board of Journal of Infrared and Laser Engineering. All right reserved.","Image enhancement; Image resolution; Imaging systems; Mean square error; Optical resolving power; Remote sensing; Discrimination model; Image super-resolution reconstruction; Maximum a posteriori estimation; Multi-frame; Remote sensing images; Remote sensing imaging; Remote sensing system; Super resolution reconstruction; Image reconstruction","Multi-frame image processing; Remote sensing imaging; Super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85062681221"
"Zhang Y.; Zhang Y.; Huang Y.; Yang J.; Yang X.","Zhang, Yongchao (56042343300); Zhang, Yin (55975581400); Huang, Yulin (23014806800); Yang, Jianyu (9239230100); Yang, Xiaobo (16557266900)","56042343300; 55975581400; 23014806800; 9239230100; 16557266900","Deterministic cramér-rao bound for scanning radar sensing","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8518677","9208","9211","3","10.1109/IGARSS.2018.8518677","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064153327&doi=10.1109%2fIGARSS.2018.8518677&partnerID=40&md5=1f6177f47b214061a2eb66eeea8ebec8","In this paper, the Cramér-Rao Bound (CRB) for scanning radar sensing is investigated, providing an algorithm-independent bound on the angular estimation error. Based on the deterministic signal model, we first derive a numerical CRB for unknown real signal parameters. Then, the approximate closed-form expression of CRBs are further provided for the single target case. Meanwhile, the potential estimation error of various classical super-resolution sensing methods are quantitatively investigated in this paper, and compared with the presented CRB. © 2018 IEEE","Geology; Optical resolving power; Remote sensing; Scanning; Closed form; Closed-form expression; Deterministic signals; Estimation errors; Potential estimation; Real signals; Scanning radar; Super resolution; Radar","Closed-form Cramér-Rao bound; Scanning radar; Super-resolution sensing","Conference paper","Final","","Scopus","2-s2.0-85064153327"
"","","","Computational Optical Sensing and Imaging, COSI 2018","2018","Optics InfoBase Conference Papers","Part F99-COSI 2018","","","","","105","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051247040&partnerID=40&md5=592bc145e4770885fa672c5161d89849","This proceedings contains 53 papers. COSI encompasses the latest advances in computational imaging research. Representative topics include compressive sensing, tomographic imaging, light-field sensing, digital holography, SAR, phase retrieval, computational spectroscopy, blind deconvolution and phase diversity, pointspread function engineering and digital/optical super resolution. The conference topics include: Non-Line-of-Sight Imaging using Superheterodyne Interferometry; Resolving Non Line-of-Sight (NLoS) motion using Speckle; Indirect Imaging Using Correlography; Micro Resolution Time-of-Flight Imaging; Passive Non-line-of-sight Source Classification from Coherence Measurements; Diffuse Time-of-flight Imaging with a Single-Photon Camera; Imaging with Phasor Fields for Non-Line-of Sight Applications; Indirect Imaging Using Virtualized Pattern Projection; Aparna Viswanath, Muralidhar M. Balaji, Prasanna Rangarajan, Duncan MacFarlane, and Marc P Christensen; Multi-layered Born scattering model for 3D phase imaging with multiple scattering objects; Depth-resolved Lensless Imaging; 3D Fluorescence Microscopy with DiffuserCam; Double-Cubic Point Spread Function for 3D Extended-Depth Localization Microscopy; Depth Sensitivity Improvement of Region-of-Interest Diffuse Optical Tomography from Superficial Signal Regression; Manob Jyoti Saikia, Rakesh Manjappa, Kunal Mankodiya, and Rajan Kanhirodan; On Block-Reference Coherent Diffraction Imaging; Deep Learning Enhances Mobile Microscopy; A Novel Optical Structure to Implement One-dimensional Fourier Transform with Spherical Lenses; Seeing through Multimode Fibers with Deep Learning; Plenoptic imaging from intensity correlations; A new method for designing highly efficient metasurface devices: Local Phase Method; Novel Optimizations for Phase Retrieval; Phase Retrieval Based on Wave Modulation; Enhanced Phase Retrieval using Quantum Illumination; Temporal Super-resolution Full Waveform LiDAR; Super-Resolution Imaging Based on Spectral Dimensional Information; Remote Sensing of Photoplethysmogram using Multi Spot Illumination; Enlarged Field of View Scattering Imaging Using Speckle Autocorrelation; Mitigating metalens aberrations via computational imaging; Shane Colburn and Arka Majumdar; Binarization threshold optimization of ghost imaging; Ghost Imaging With Gram-Schmidt Orthogonalization; Comparison between ghost imaging and traditional active optical imaging; Demonstration of computational temporal ghost imaging: detecting fast signals beyond bandwidth of detectors; Imaging the Joint Probability Distribution of Spatially Entangled Photon Pairs with a Camera; Optimization of light field fluctuation patterns in ghost imaging by mutual coherence minimization based on dictionary learning; Characterizing the optical memory effect using quantum illumination; Compressive Ultrafast Single Pixel Camera; Encrypted Single Pixel Imaging with Basis Illumination Patterns; Correlation Matrix Estimation from Compressed Measurements in a Pattern Recognition System; Exploiting Inter Voxel Correlation in Compressed Computational Imaging; Naren Viswanathan, Suresh Venkatesh, and David Schurig; Double-threshold Denoising for Single-pixel Camera; Multi-object Recognition in Turbid Water Using Compressive Sensing; Covariance Matrix Estimation from Multiple Subsets in Compressive Spectral Imaging; Compressive Spectral Polarization Imaging Using a Single Pixel Detector; Subsampling Schemes for the 2D Nuclear Magnetic Resonance Spectroscopy; Compressive coded LED and coded aperture spectral video system; Spatial Super-resolution reconstruction via SSCSI Compressive Spectral Imagers; Snapshot Compressive Spectral+Depth Imaging with Color-Coded Apertures; Spectral zooming in SSCSI Compressive Spectral Imagers; Compressive Photon-Sieve Spectral Imaging; Field-varying aberration recovery in EUV microscopy using mask roughness; Computational Cannula Microscopy: Utilizing a Simple Glass Needle for Imaging; Integral Refractive Index Imaging of Flowing Cell Nuclei; Compressive hyperspectral imaging for snapshot multi-channel fluorescence microscopy; Cell imaging by phase extraction neural network (PhENN); Quantitative Phase Maps of Live Cells Classified By Transfer Learning and Generative Adversarial Network (GAN); A Neuro-Inspired Model for Image Motion Processing; Optical Sensing and Control Based on Machine Learning; Deep Learned Phase Mask for Single Image Depth Estimation and 3D scanning; Neural Network classification for intensity imaging through multimode optical fibres; Phase Unwrapping Using Residual Neural Networks; Bending-Independent Imaging through Glass-Air Disordered Fiber Based on Deep Learning; Speckle suppression using the convolutional neural network with an exponential linear unit. The key terms of this proceedings include Compressive Sensing, Computational microscopy, Depth-resolved and turbid imaging, Imaging through aberrations, Structured illumination  and super resolution, Indirect and non-line-of-sight imaging, Machine Learning in Computational Sensing and Imaging, Phase Retrieval, Postdeadline Papers - COSI, Quantum Computational Imaging.","","","Conference review","Final","","Scopus","2-s2.0-85051247040"
"Hsu P.-H.; Kuo H.-L.","Hsu, Pai-Hui (16425859400); Kuo, Hsiang-Lin (57208242853)","16425859400; 57208242853","Pan-sharpen multispectral images using sparse representation","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8519099","5143","5146","3","10.1109/IGARSS.2018.8519099","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064228885&doi=10.1109%2fIGARSS.2018.8519099&partnerID=40&md5=5f6a27a0c3d1f4430dfe611c939e7a80","Pan-sharpening is an image fusion technique of synthesizing a high-resolution multispectral image from a low-resolution multispectral image and a high-resolution panchromatic image. In this paper, a novel pan-sharpening method for remote sensing images has been proposed with sparse representation over learned dictionaries. In the proposed method, the dictionaries are learned only from the high-resolution panchromatic image via the joint learning algorithm, instead of learning from the high-resolution multispectral image which are not available in practice. The sparse coefficients of the panchromatic image and low-resolution panchromatic image are calculated by the orthogonal matching pursuit algorithm. Then, the fused high-resolution multispectral image can be constructed by combining the obtained sparse coefficients and the high-resolution dictionary. The experiment results indicate that the proposed method not only preserve spectral and spatial details of the source images but overcoming the drawbacks of fusion distortion. © 2018 IEEE.","Geology; Learning algorithms; Remote sensing; Dictionary learning; Pan-sharpening; Regularization; Sparse representation; Super resolution; Image fusion","Dictionary learning; Pan-sharpening; Regularization; Sparse representation; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85064228885"
"Klapp I.; Brand O.; Yafin P.; Papini S.; Oz N.; Bahat I.; Cohen Y.; Alchanatis V.; Sochen N.","Klapp, I. (27567785400); Brand, O. (57213263316); Yafin, P. (57205183262); Papini, S. (57194829141); Oz, N. (57211388042); Bahat, I. (57204394019); Cohen, Y. (56963379100); Alchanatis, V. (6507904831); Sochen, N. (7003363050)","27567785400; 57213263316; 57205183262; 57194829141; 57211388042; 57204394019; 56963379100; 6507904831; 7003363050","Using computational optics for agricultural monitoring with an emphasis on irrigation management zones","2019","Precision Agriculture 2019 - Papers Presented at the 12th European Conference on Precision Agriculture, ECPA 2019","","","","665","671","6","10.3920/978-90-8686-888-9_82","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073716462&doi=10.3920%2f978-90-8686-888-9_82&partnerID=40&md5=5607b91cbbae449cd9a77eddf624ae66","The increasing global water deficit and the constant demand for yield improvement require higher imaging resolution of irrigation management zones (IMZs). Infrared radiometric remote sensing is efficient for IMZ delineation. To provide high spatial resolution, radiometric remote sensing is conducted from a relatively low altitude, raising two constraints: the radiometric camera's price, and the lower altitude that forces lower coverage in a given time. This work presents progress in using methods associated with computational optics to stabilize low-cost thermal cameras and improve the resolution of radiometric cameras. Performance results are promising. © Wageningen Academic Publishers 2019","Cameras; Irrigation; Precision agriculture; Radiometry; Agricultural monitoring; Computational imaging; High spatial resolution; Imaging resolutions; Irrigation management; Super resolution; Water deficits; Yield Improvement; Remote sensing","Computational imaging; Radiometry; Remote sensing and sensors; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85073716462"
"Göhler B.; Lutzmann P.","Göhler, Benjamin (25924375900); Lutzmann, Peter (6506045630)","25924375900; 6506045630","Extending the 3D range of a short-wave infrared laser-gated viewing system capable of correlated double sampling","2018","Proceedings of SPIE - The International Society for Optical Engineering","10796","","107960D","","","","10.1117/12.2326916","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057372786&doi=10.1117%2f12.2326916&partnerID=40&md5=b8b9dceb9037c15b77db242aa1c590fa","Primarily, a laser gated-viewing (GV) system provides range-gated 2D images without any range resolution within the range gate. By combining two GV images with appropriately overlapping range gates, 3D information within a part of these range gates can be obtained. The depth resolution is higher (super-resolution) than the minimal gate shift step size in a tomographic sequence of the scene. For a state-of-the-art system with a typical frame rate of 30 Hz, the time difference between the two required GV images is approximately 33 ms which may be too long in a dynamic scenario with fast moving objects. Therefore, in a previous work, we have applied this approach to the reset and signal level images of a short-wave infrared laser GV camera whose read-out integrated circuit is capable of correlated double sampling originally designed for the reduction of kTC noise (reset noise). This camera consists of a 640 x 512 avalanche photodiode focal plane array based on mercury cadmium telluride with a pixel pitch of 15 μm. The great advantage of this idea is the fact that these images are extracted from only one single laser pulse with a marginal time difference in between. This allows 3D imaging of fast moving objects. However, a drawback of this method is the very limited 3D range in which 3D reconstruction is possible. In this paper, we describe and discuss two measures to extend the 3D range. First, refining the algorithm for 3D reconstruction is investigated, particularly using a quadratic model instead of a linear model as in previous work. Second, we use an illumination laser with longer pulse duration than before to study the influence of laser pulse length on 3D range in real experiments. Based on these measured data, we simulate further temporal stretching of the laser pulse, to evaluate the potential of this approach to extend the 3D range. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Avalanche photodiodes; Cadmium telluride; Cameras; Electric variables measurement; II-VI semiconductors; Image reconstruction; Imaging systems; Infrared lasers; Infrared radiation; Laser pulses; Mercury compounds; Photodiodes; Remote sensing; Sampling; Active imaging; Correlated double sampling; Gated viewing; Laser range; Mercury cadmium telluride; Short wave infrared; Three dimensional imaging; Three dimensional computer graphics","active imaging; avalanche photodiode; correlated double sampling; laser gated-viewing; laser range-gating; mercury cadmium telluride; short-wave infrared; three-dimensional imaging","Conference paper","Final","","Scopus","2-s2.0-85057372786"
"Muad A.M.","Muad, Anuar M. (36681355600)","36681355600","Texture variable analysis for landscape patches represented using super-resolution mapping","2017","2017 IEEE 8th Control and System Graduate Research Colloquium, ICSGRC 2017 - Proceedings","","","8070567","51","56","5","10.1109/ICSGRC.2017.8070567","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039929582&doi=10.1109%2fICSGRC.2017.8070567&partnerID=40&md5=ca44fe7de91d907f36fecd8b4b811724","This paper presents the analyses of texture variables from the image enhanced using super-resolution mapping. Two widely known super-resolution mapping techniques, pixel swapping and Hopfield neural network are used. The texture analyses include land cover patches of varying sizes, shapes, and spatial pattern of patches. A time series coarse MODIS 250 images are used to improve the representation of land cover patches and reduce the spatial variability. Results show that using a fusion of time series images and properly setting the weights for the Hopfield neural network produce superior accuracy of representing the texture of land cover mapping. © 2017 IEEE.","Hopfield neural networks; Image enhancement; Image texture; Optical resolving power; Pixels; Remote sensing; Time series; Land cover mapping; Landscape pattern; Pixel-swapping; Spatial patterns; Spatial variability; Super-resolution mappings; Texture analysis; Variable analysis; Mapping","Hopfield neural network; Landscape pattern; Pixel swapping; Remote sensing; Texture variable","Conference paper","Final","","Scopus","2-s2.0-85039929582"
"","","","Mathematics in Imaging, MATH 2018","2018","Optics InfoBase Conference Papers","Part F105-MATH 2018","","","","","52","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051243344&partnerID=40&md5=90c209fba19815de196eae1e8571bb05","This proceedings contains 26 papers. Mathematical Imaging covers mathematical and computational methods for modeling the physics of imaging methods and for providing stable and resolved solutions to the inverse problem of image reconstruction. It captures leading edge fundamental developments in imaging science and has applications in photonics, biomedical imaging, astronomy, and remote sensing. The conference topics include: Synthetic Schlieren Tomography of Focused Ultrasound Transducers; Tomographic reconstruction of 3D atomic potentials from intensity-only TEM measurements; CNN based Sinogram Denoising for Low-Dose CT; Spectral Encoding using k-space/frequency Duality; Correlation-based imaging in random media; First Born model for reflection-mode Fourier ptychographic microscopy; Avoiding the calculation of x-ray transforms on combined ptychographic/absorption and fluorescence experiments; Seeing inside and beyond: Challenges and Trends in (low) Coherent Imaging; Simultaneous Measurement and Reconstruction Tailoring for Phase Imaging; Imaging Through Volumetric Scattering with a Single Photon Sensitive Camera; Optimizing Defect Detectability across Multiple Ultraviolet Wavelengths; Surface Estimation of Small Animals from Orbital Plenoptic Projections; On Scene Reconstruction from Spatial Coherence Measurements; Learning and Exploiting Physics of Degradations; The Pupil-Difference Probability Density as a tool for understanding OTF; Spatial intensity averaging for ghost imaging with a single-port dynamic metasurface aperture; l2 - l0 optimization for single molecule localization microscopy; Sparse Phase Retrieval Algorithm via Smoothing Function in Compressive Optical Imaging; Super-Resolution Phase Retrieval Algorithm using a Smoothing Function; The geometry of convex regularized inverse problems; Three-Dimensional Fluorophore Orientation Imaging with Multiview Polarized Microscopy; Towards Realistic Superresolution of Incoherent Point Sources; Mathematical Tools for Regularized Coherence Retrieval; Turbulent flow in coherent speckle; Consensus Equilibrium: A Framework for Model Integration; Direct inversion of intensity diffraction tomography with a computational microscope; Nonconvex Optimization for Diffractive Imaging; Incoherent Diffraction-Free Space-Time Light Sheets Produced From a Broadband LED; Time Reversal using Bianisotropic Metasurfaces. The key terms of this proceedings include Tomography, Imaging in complex media, Inverse scattering, High-dimentional imaging, Sparsity Based Priors, Application in 3D Microscopy, Model-based Imaging.","Coherent light; Coherent scattering; Computational geometry; Computerized tomography; Differential equations; Diffraction; Fast Fourier transforms; Medical imaging; Optical resolving power; Optical tomography; Particle beams; Three dimensional computer graphics; Ultrasonic applications; Biomedical imaging; Focused ultrasound; Images reconstruction; Imaging method; Metasurface; Phase retrieval algorithm; Remote-sensing; Smoothing function; Superresolution; Synthetic schlieren; Image reconstruction","","Conference review","Final","","Scopus","2-s2.0-85051243344"
"Quevedo E.; Sánchez L.; M. Callicó G.; Tobajas F.; de la Cruz J.; de Armas V.; Sarmiento R.","Quevedo, E. (55845740700); Sánchez, L. (56523973800); M. Callicó, G. (56006321500); Tobajas, F. (6602389338); de la Cruz, J. (56370423800); de Armas, V. (6603181073); Sarmiento, R. (35609452100)","55845740700; 56523973800; 56006321500; 6602389338; 56370423800; 6603181073; 35609452100","Super-resolution with selective filter based on adaptive window and variable macro-block size","2018","Journal of Real-Time Image Processing","15","2","","389","406","17","10.1007/s11554-015-0489-3","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923250155&doi=10.1007%2fs11554-015-0489-3&partnerID=40&md5=5599b907b5828fc39399660fd6814fde","Super-resolution (SR) covers a set of techniques whose objective is to improve the spatial resolution of a video sequence or a single frame. In this scope, fusion SR techniques obtain high-resolution (HR) frames taking as a reference several low-resolution (LR) frames contained in a video sequence. This paper is based on a selective filter to decide the best LR frames to be used in the super-resolution process. Additionally, each frame division into macro-blocks (MBs) is analyzed both in a fixed block size approach, which decides which MBs should be used in the process, and in a variable block size approach with an adaptive MB size, which has been developed to set an appropriate frame division into MBs with variable size. These contributions not only improve the quality of video sequences, but also reduce the computational cost of a baseline SR algorithm, avoiding the incorporation of non-correlated data. Furthermore, this paper explains the way in which the enhanced algorithm proposed in it outperforms the quality of typical SR applications, such as underwater imagery, surveillance video, or remote sensing. The results are provided in a test environment to objectively compare the image quality enhancement obtained by bilinear interpolation, by the baseline SR algorithm, and by the proposed methods, thus presenting a quantitative comparison based on peak signal-to-noise ratio (PSNR) and Structural SIMilarity (SSIM) index parameters. The comparison has also been extended to other relevant proposals of the state of the art. The proposed algorithm significantly speeds up the previous ones, allowing real-time execution under certain conditions. © 2015, Springer-Verlag Berlin Heidelberg.","Adaptive filtering; Bandpass filters; Image coding; Image quality; Optical resolving power; Remote sensing; Security systems; Signal to noise ratio; Video recording; Image quality enhancements; Peak Signal to Noise Ratio (PSNR); Quantitative comparison; Selective filters; Structural similarity indices (SSIM); Super resolution; Variable block size; Video enhancement; Image enhancement","Image enhancement; Selective filter; Super-resolution; Variable block size; Video enhancement","Article","Final","","Scopus","2-s2.0-84923250155"
"Zhu H.; Tang X.; Xie J.; Song W.; Mo F.; Gao X.","Zhu, Hong (57190032288); Tang, Xinming (8520300900); Xie, Junfeng (7402994499); Song, Weidong (56512910400); Mo, Fan (57117407600); Gao, Xiaoming (56047540600)","57190032288; 8520300900; 7402994499; 56512910400; 57117407600; 56047540600","Spatio-temporal super-resolution reconstruction of remote-sensing images based on adaptive multi-scale detail enhancement","2018","Sensors (Switzerland)","18","2","498","","","","10.3390/s18020498","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041834874&doi=10.3390%2fs18020498&partnerID=40&md5=d3633222fbccac49b9960ad2b59ca8cb","There are many problems in existing reconstruction-based super-resolution algorithms, such as the lack of texture-feature representation and of high-frequency details. Multi-scale detail enhancement can produce more texture information and high-frequency information. Therefore, super-resolution reconstruction of remote-sensing images based on adaptive multi-scale detail enhancement (AMDE-SR) is proposed in this paper. First, the information entropy of each remote-sensing image is calculated, and the image with the maximum entropy value is regarded as the reference image. Subsequently, spatio-temporal remote-sensing images are processed using phase normalization, which is to reduce the time phase difference of image data and enhance the complementarity of information. The multi-scale image information is then decomposed using the L0 gradient minimization model, and the non-redundant information is processed by difference calculation and expanding non-redundant layers and the redundant layer by the iterative back-projection (IBP) technique. The different-scale non-redundant information is adaptive-weighted and fused using cross-entropy. Finally, a nonlinear texture-detail-enhancement function is built to improve the scope of small details, and the peak signal-to-noise ratio (PSNR) is used as an iterative constraint. Ultimately, high-resolution remote-sensing images with abundant texture information are obtained by iterative optimization. Real results show an average gain in entropy of up to 0.42 dB for an up-scaling of 2 and a significant promotion gain in enhancement measure evaluation for an up-scaling of 2. The experimental results show that the performance of the AMED-SR method is better than existing super-resolution reconstruction methods in terms of visual and accuracy improvements. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Image processing; Image reconstruction; Iterative methods; Optical resolving power; Remote sensing; Scales (weighing instruments); Signal to noise ratio; Detail enhancement; High resolution remote sensing images; High-frequency informations; Iterative back projections; Multi-scale deposed; Reconstruction-based super resolutions; Remote sensing images; Super resolution reconstruction; article; calculation; decomposition; entropy; remote sensing; signal noise ratio; Image enhancement","Adaptive detail enhancement; Multi-scale deposed; Remote-sensing image; Super-resolution reconstruction","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85041834874"
"","","","2nd International Conference on Recent Trends in Image Processing and Pattern Recognition, RTIP2R 2018","2019","Communications in Computer and Information Science","1035","","","","","1993","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070237970&partnerID=40&md5=07b878e3aed7c3f45fee12cb9c7a8aab","The proceedings contain 173 papers. The special focus in this conference is on Recent Trends in Image Processing and Pattern Recognition. The topics include: Execution and Performance Evaluation of Cognitive and Expressive Event on a robotic Arm; multiple Decompositions-Based Blind Watermarking Scheme for Color Images; skeleton Joint Difference Maps for 3D Action Recognition with Convolutional Neural Networks; Novel Quality Metric for Image Super Resolution Algorithms - Super Resolution Entropy Metric (SREM); shape Descriptor Based on Centroid with Chord Lengths for Image Retrieval; learning Deep Feature Representation for Face Spoofing; ExNET: Deep Neural Network for Exercise Pose Detection; background Subtraction and Kalman Filter Algorithm for Object Tracking; A Blind Color Image Watermarking Using BRISK Features and Contourlet Transform; let Vehicles Talk with Images for Smart Vehicular Communication System; gray Level Face Recognition Using Spatial Features; application of Gabor Filter for Monitoring Wear of Single Point Cutting Tool; performance Analysis of Log-Gabor Based Multimodal Systems and Its Fusion Techniques; Temporal Super-Pixel Based Convolutional Neural Network (TS-CNN) for Human Activity Recognition in Unconstrained Videos; Content Based Video Retrieval Using SURF, BRISK and HARRIS Features for Query-by-image; An Empirical Study: ELM in Face Matching; optimal Selection of Bands for Hyperspectral Images Using Spectral Clustering; Classification of Natural Flower Videos Through Sequential Keyframe Selection Using SIFT and DCNN; Hyperspectral Remote Sensing Image Analysis with SMACC and PPI Algorithms for Endmember Extraction; real Time Hand Gesture Recognition for Differently-Abled Using Deep Learning; a Novel Foreground Segmentation Method Using Convolutional Neural Network; image Fusion Technique Using Gaussian Pyramid.","","","Conference review","Final","","Scopus","2-s2.0-85070237970"
"Vaughn I.J.; Tyo J.S.","Vaughn, Israel J. (23494071500); Tyo, J. Scott (55663513600)","23494071500; 55663513600","Spatio-temporal hybrid color-polarization channeled sensors","2019","Proceedings of SPIE - The International Society for Optical Engineering","11132","","111320K","","","","10.1117/12.2529562","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076930068&doi=10.1117%2f12.2529562&partnerID=40&md5=e053580ddd32f2e01b9fe4aa0a444bd2","Recent advancements in channeled spatio-temporal polarization sensor systems have shown potential for improved imaging performance. Lithographic processes now allow for the manufacture of pixelated focal plane arrays with both color and polarization filters applied at the per pixel level. Both Sony and Pau's group at the University of Arizona have demonstrated the manufacture of these hybrid sensors. These new sensors produce spatially channeled hybrid color/polarization systems and crowd the available channel bandwidth space in the Nyquist square. We present a new system design which utilises polarization elements to generate additional temporal carriers, allowing for the separation of color and polarization channels. This separation has the potential to improve the hybrid system performance for certain classes of scene statistics and is analogous to a kind of super-resolution effect similar to a vibrating sensor or using motion for subsampling. The separation can be achieved by varying the polarization sensitive pixels in time, e.g. a rotating half waveplate or an electro-optic polarization element. We show the system design for an existing COTS Sony sensor as well as a design with improved performance over the Sony focal plane array, along with preliminary results on possible system performance. © 2019 SPIE.","Color; Ellipsometry; Focusing; Hybrid systems; Linear systems; Manufacture; Pixels; Polarimeters; Remote sensing; Separation; Space optics; Systems analysis; Electro-optic polarization; Microanalyzers; micropolarizer array; polarimetric channels; Polarization channels; Polarization elements; Polarization sensitive; University of Arizona; Polarization","color-polarimetric hybrid; linear systems; microanalyzer array; micropolarizer array; modulated polarimetry; polarimetric channels; polarimetry","Conference paper","Final","","Scopus","2-s2.0-85076930068"
"Wang Q.; Ma L.; Xu H.; Zhou Y.; Li C.; Tang L.; Wang X.","Wang, Qi (57209560862); Ma, Lingling (35216102100); Xu, Hong (57203513843); Zhou, Yongsheng (22959334700); Li, Chuanrong (35239931100); Tang, Lingli (7402081131); Wang, Xinhong (36629779000)","57209560862; 35216102100; 57203513843; 22959334700; 35239931100; 7402081131; 36629779000","Dictionary Construction Method for Hyperspectral Remote Sensing Correlation Imaging","2019","Springer Series in Optical Sciences","223","","","239","284","45","10.1007/978-3-030-30113-2_11","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090050383&doi=10.1007%2f978-3-030-30113-2_11&partnerID=40&md5=46c17fdd87d1c633d97baf5c43d1d5b0","The correlation imaging technique is a novel imaging strategy which acquires the object image by the correlation reconstruction algorithm from the separated signal light field and reference light field, with the advantages such as super-resolution, anti-interference and high security. The hyperspectral remote sensing correlation imaging technique combined the correlation imaging and hyperspectral remote sensing has the ability to detect the spectral properties of ground objects more than the above advantages. The spatial and spectral images can be reconstructed from very few measurements acquired by hyperspectral correlation imaging systems via sparsity constraint, making it an effective approach to solve the process and transition problem in high spatial and spectral resolution. While in the hyperspectral remote sensing correlation imaging, due to the complexity and variance of the spatial and spectral properties of the target scene and lack of prior knowledge, it is difficult to construct an effective dictionary for the hyperspectral reconstruction. The fixed dictionaries such as DCT (Discrete Cosine Transform) dictionary and wavelet dictionary are mainly used in the reconstruction up to present, and these dictionaries contain fixed and limited characteristics, which is hard to present different hyperspectral scenes efficiently. This paper aims at the problem that in the hyperspectral remote sensing correlation imaging system the sparse representation of complex ground objects is difficult in image reconstruction, resulting in low quality of reconstructed images. By combining the sparse coding and dictionary learning theory of signal processing, a related research on the construction method of hyperspectral remote sensing sparse dictionaries is carried out. Through the construction of hyperspectral remote sensing sparse dictionaries, optimization in reconstruction, and application research in actual imaging systems, a set of sparse dictionary construction and usage methods in hyperspectral correlation imaging has been formed. Comparing with current methods such as the total variation constraints and the hyperspectral image kernel norm constraints, the hyperspectral remote sensing scene sparsity and hyperspectral image reconstruction quality have been effectively improved by the proposed method, which has guiding significance for the development of the correlation imaging field. © 2019, Springer Nature Switzerland AG.","","Correlation imaging hyperspectral imaging; Dictionary learning; Reconstruction algorithm; Sparse representation","Book chapter","Final","","Scopus","2-s2.0-85090050383"
"Hou B.; Zhou K.; Jiao L.","Hou, Biao (7102142690); Zhou, Kang (57200034796); Jiao, Licheng (7102491544)","7102142690; 57200034796; 7102491544","Adaptive super-resolution for remote sensing images based on sparse representation with global joint dictionary model","2018","IEEE Transactions on Geoscience and Remote Sensing","56","4","","2312","2327","15","10.1109/TGRS.2017.2778191","37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038851209&doi=10.1109%2fTGRS.2017.2778191&partnerID=40&md5=38a3536e16327067cb7dacdd24af6629","Sparse representation has been widely used in the field of remote sensing image super-resolution (SR) to restore a high-quality image from a low-resolution (LR) image, e.g., from the blurred and downsampled version of an LR image's high-resolution (HR) counterpart. It is well known that each image patch can be represented by a linear combination of the atoms of an overcomplete dictionary, and we can obtain an expression of sparse coefficients by {1} norm regularization. Owing to the lack of an inner relationship between image patches and an image's global information, the traditional methods of jointly training two overcomplete dictionaries cannot obtain good SR results. Therefore, we propose an effective approach for remote sensing image SR based on sparse representation. More specifically, a novel global joint dictionary model (GJDM) is used to explore the prior knowledge of images, including local and global characteristics. First, we train two dictionaries for detail image patches and HR patches. Second, in order to enhance the inner relationship between image patches, we introduce a global self-compatibility model for global regularization. Finally, the sparse representation and the local and nonlocal constraints are integrated to improve the performance of the model, and the fast adaptive shrinkage-thresholding algorithm is employed to solve the convex optimization problem in the GJDM. Compared with other methods, the results of the proposed method show good SR performance in preserving details and texture information and significant improvement in a peak signal-to-noise ratio. © 1980-2012 IEEE.","Convex optimization; Edge detection; Glossaries; Image reconstruction; Image resolution; Interpolation; Optical resolving power; Optimization; Remote sensing; Shrinkage; Signal to noise ratio; Adaptation models; global joint dictionary model (GJDM); Image edge detection; Remote sensing images; Sparse representation; Super resolution; Thresholding algorithms; algorithm; image resolution; numerical model; optimization; remote sensing; satellite imagery; signal-to-noise ratio; Image enhancement","Fast adaptive shrinkage-thresholding algorithm (FASTA); Global joint dictionary model (GJDM); Remote sensing images; Sparse representation; Super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85038851209"
"Yokoya N.","Yokoya, Naoto (36440631200)","36440631200","Texture-guided multisensor superresolution for remotely sensed images","2017","Remote Sensing","9","4","316","","","","10.3390/rs9040316","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017642186&doi=10.3390%2frs9040316&partnerID=40&md5=60342c8f7b9918dd906a3478db33d378","This paper presents a novel technique, namely texture-guided multisensor superresolution (TGMS), for fusing a pair of multisensor multiresolution images to enhance the spatial resolution of a lower-resolution data source. TGMS is based on multiresolution analysis, taking object structures and image textures in the higher-resolution image into consideration. TGMS is designed to be robust against misregistration and the resolution ratio and applicable to a wide variety of multisensor superresolution problems in remote sensing. The proposed methodology is applied to six different types of multisensor superresolution, which fuse the following image pairs: multispectral and panchromatic images, hyperspectral and panchromatic images, hyperspectral and multispectral images, optical and synthetic aperture radar images, thermal-hyperspectral and RGB images, and digital elevation model and multispectral images. The experimental results demonstrate the effectiveness and high general versatility of TGMS. © 2017 by the authors.","Multiresolution analysis; Optical resolving power; Radar imaging; Remote sensing; Synthetic aperture radar; Digital elevation model; Gradient descent; Higher resolution images; Multiresolution images; Multispectral images; Panchromatic images; Remotely sensed images; Super resolution; Image texture","Multiresolution analysis; Multiscale gradient descent; Multisensor superresolution; Texture guidance","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85017642186"
"Li X.; Shen H.; Wang C.; Jiang H.; Yu R.; Wang J.; Zhao M.","Li, Xuewei (36696705900); Shen, Hongqian (57205198427); Wang, Chenhan (57205199728); Jiang, Han (57205197231); Yu, Ruiguo (15051300600); Wang, Jianrong (55885983000); Zhao, Mankun (55651573800)","36696705900; 57205198427; 57205199728; 57205197231; 15051300600; 55885983000; 55651573800","Dual-convolutional enhanced residual network for single super-resolution of remote sensing images","2018","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11306 LNCS","","","363","372","9","10.1007/978-3-030-04224-0_31","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059004137&doi=10.1007%2f978-3-030-04224-0_31&partnerID=40&md5=d3deda920aa3e355773b73b32be3f3f6","The image super-resolution aims to recover a high-resolution image using a single or sequential low-resolution images. The super resolution methods based on deep learning, especially the deep convolutional neural network, have achieved good results. In this paper,we propose Dual-Convolutional Enhanced Residual Network (DCER) for remote sensing images based on residual learning, which concatenates the feature maps of different convolutional kernel sizes (3 × 3, 5 × 5). On the one hand, it can learn more high-frequency detail information by combining the local details of different scales; on the other hand, it reduces network parameters and greatly shorten the training time. The experimental results show that DCER achieves favorable performance of accuracy and visual performance against the state-of-the-art methods with the scale factor 2x, 4x and 8x. © Springer Nature Switzerland AG 2018.","Convolution; Deep neural networks; Neural networks; Optical resolving power; Remote sensing; Deep convolutional neural networks; Dual-Convolutional Enhanced Residual Network (DCER); High resolution image; Image super resolutions; Remote sensing images; State-of-the-art methods; Super resolution; Superresolution methods; Image enhancement","Dual-Convolutional Enhanced Residual Network (DCER); Remote sensing images; Single super-resolution","Conference paper","Final","","Scopus","2-s2.0-85059004137"
"Kwan C.; Choi J.H.; Chan S.; Zhou J.; Budavari B.","Kwan, Chiman (7201421216); Choi, Joon Hee (56734751700); Chan, Stanley (24824181300); Zhou, Jin (55226383100); Budavari, Bence (57191360081)","7201421216; 56734751700; 24824181300; 55226383100; 57191360081","Resolution enhancement for hyperspectral images: A super-resolution and fusion approach","2017","ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","","","7953344","6180","6184","4","10.1109/ICASSP.2017.7953344","43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021645880&doi=10.1109%2fICASSP.2017.7953344&partnerID=40&md5=19ff660f08258da24825bd3b04a45cec","Many remote sensing applications require a high-resolution hyperspectral image. However, resolutions of most hyperspectral imagers are limited to tens of meters. Existing resolution enhancement techniques either acquire additional multispectral band images or use a pan band image. The former poses hardware challenges, whereas the latter has limited performance. In this paper, we present a new resolution enhancement method that only requires a color image. Our approach integrates two newly developed techniques in the area: (1) A hybrid color mapping algorithm, and (2) A Plug-and-Play algorithm for single image super-resolution. Comprehensive experiments using real hyperspectral images are conducted to validate and evaluate the proposed method. © 2017 IEEE.","","Hybrid Color Mapping; Hyperspectral Imaging; Plug-and-Play ADMM; Remote Sensing; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85021645880"
"Bratsolis E.; Panagiotopoulou A.; Stefouli M.; Charou E.; Madamopoulos N.; Perantonis S.","Bratsolis, Emmanuel (6603338911); Panagiotopoulou, Antigoni (24479152700); Stefouli, Marianthi (6506668706); Charou, Eleni (6507509159); Madamopoulos, Nicholas (6604012410); Perantonis, Stavros (7004909153)","6603338911; 24479152700; 6506668706; 6507509159; 6604012410; 7004909153","Comparison of optimized mathematical methods in the improvement of raster data and map display resolution of sentinel-2 images","2018","Proceedings - International Conference on Image Processing, ICIP","","","8451729","2521","2525","4","10.1109/ICIP.2018.8451729","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062916418&doi=10.1109%2fICIP.2018.8451729&partnerID=40&md5=c4d6988d9ad67929b7e2d627cc4d7623","High-Resolution (HR) satellite images are a prerequisite in many applications such as astronomy, remote sensing, geoscience and geographical information systems, not only for providing better visualization but also for extracting extra information details. In the present work a comparative study of different single image resolution enhancement techniques is carried out on Sentinel-2 images of bands B2, B3, B4 and B8. The authors describe the stochastic regularized super-resolution (SR) reconstruction technique and compare with others. The techniques under comparison are stochastic regularized SR reconstruction (SRSR), spatial-wavelet SR reconstruction (SWSR) and the conventional interpolation techniques nearest neighbor (NN), bilinear (BL), bicubic (BC) and spline (SP). These techniques are tested against each other in terms of Root Mean Square Error (RMSE), Xydeas and Petrovich (XP), and Correlation Coefficient (CC). Simulated experiments of single image resolution increase take place. © 2018 IEEE.","Image reconstruction; Image resolution; Interpolation; Mean square error; Optical resolving power; Remote sensing; Stochastic systems; Wavelet transforms; Correlation coefficient; Interpolation techniques; Resolution increase; Root mean square errors; Satellite images; Simulated experiments; Stochastic regularized technique; Super resolution reconstruction; Image enhancement","Interpolation; Satellite image resolution enhancement; Spatial-wavelet transform; Stochastic regularized technique; Super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85062916418"
"Wang X.-H.; Zhao X.-Y.; Bi X.-Y.; Tao J.-Z.","Wang, Xiang-Hai (8340645000); Zhao, Xiao-Yang (57203865767); Bi, Xiao-Yun (57205207440); Tao, Jing-Zhe (55624708100)","8340645000; 57203865767; 57205207440; 55624708100","Single Image Super-resolution Reconstruction Approach Based on Multi-angle Contour Templates Variational Calculus Model in Wavelet Domain; [小波域多角度轮廓模板变分模型的单幅图像超分辨率重建]","2018","Tien Tzu Hsueh Pao/Acta Electronica Sinica","46","9","","2256","2262","6","10.3969/j.issn.0372-2112.2018.09.030","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059088767&doi=10.3969%2fj.issn.0372-2112.2018.09.030&partnerID=40&md5=97dc4388e6961464c36f32938c573988","In recent years, the study of image super-resolution reconstruction technology has been paid much attention to, because it can improve image recognition accuracy and recognition ability. One of the difficult problems is how to ensure the reconstruction quality of image edge texture area. In this paper, a single image super-resolution reconstruction approach based on wavelet domain is proposed. Firstly, the non-subsampled wavelet transform (NSWT) is applied to the input image, according to the multi-directionality of wavelet transform, three kinds of multi-angle templates are proposed, and each subband contour is estimated by total variation model (TV model) to determine its optimal direction. Then, the multi-angle templates and bicubic B-spline interpolation are used to interpolate the subbands. Finally, the non-subsampled wavelet inverse transform is implemented. This approach makes edge information and texture information of the reconstructed images more precise, and overcomes some deficiencies such as edge blurring, edge serration, as well as distortion of texture region, caused by traditional interpolation reconstruction approaches, such as bilinear interpolation and bicubic interpolation, etc. The quality of reconstructed image is improved. This approach can be used in image monitoring, remote sensing image analysis, medical image processing, and so on. A large number of simulation experiments verify the effectiveness of the proposed approach. © 2018, Chinese Institute of Electronics. All right reserved.","Calculations; Image compression; Image enhancement; Image recognition; Image texture; Interpolation; Inverse problems; Inverse transforms; Medical imaging; Optical resolving power; Remote sensing; Variational techniques; Wavelet transforms; Contour template; Directional interpolation; Edge; Multi angle; Subbands; Super resolution reconstruction; Image reconstruction","Contour template; Directional interpolation; Edge; High-frequency subbands; Multi-angle; Non-subsampled wavelet transform; Super-resolution reconstruction; Template matrix; Variational calculus model","Article","Final","","Scopus","2-s2.0-85059088767"
"Liu K.; Cheng Y.; Gao Y.; Li X.; Qin Y.; Wang H.","Liu, Kang (56071351500); Cheng, Yongqiang (56242314000); Gao, Yue (55731393400); Li, Xiang (57192491402); Qin, Yuliang (55496667400); Wang, Hongqiang (35779607700)","56071351500; 56242314000; 55731393400; 57192491402; 55496667400; 35779607700","Super-resolution radar imaging based on experimental OAM beams","2017","Applied Physics Letters","110","16","164102","","","","10.1063/1.4981253","117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018499112&doi=10.1063%2f1.4981253&partnerID=40&md5=7044d8837162a055995379853ff6a24d","A super-resolution imaging technique based on the vortex electromagnetic (EM) wave, which carries orbital angular momentum (OAM), is reported in this paper. The proof-of-concept experiment for the EM vortex imaging is conducted. An imaging processing method based on the real-world OAM radar data is proposed to obtain the target profile. Experimental results validate the effectiveness of the proposed imaging method and demonstrate that the vortex EM wave can be exploited to image targets with high-resolution beyond the limit of the array aperture. This breakthrough on the Rayleigh limit paves the way for innovative techniques in radar imaging and remote sensing. © 2017 Author(s).","Electromagnetic waves; Image reconstruction; Imaging techniques; Optical resolving power; Radar; Remote sensing; Vortex flow; High resolution; Imaging method; Imaging processing; Innovative techniques; Orbital angular momentum; Proof of concept; Super resolution; Super resolution imaging; Radar imaging","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85018499112"
"Gao J.; Deng B.; Qin Y.; Wang H.; Li X.","Gao, Jingkun (56734814600); Deng, Bin (57202950768); Qin, Yuliang (55496667400); Wang, Hongqiang (35779607700); Li, Xiang (57192491402)","56734814600; 57202950768; 55496667400; 35779607700; 57192491402","Enhanced radar imaging using a complex-valued convolutional neural network","2019","IEEE Geoscience and Remote Sensing Letters","16","1","8458209","35","39","4","10.1109/LGRS.2018.2866567","100","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053155832&doi=10.1109%2fLGRS.2018.2866567&partnerID=40&md5=9210ef413803deffc373b589c498227e","Convolutional neural networks (CNN) have successfully been employed to tackle several remote sensing tasks such as image classification and show better performance than previous techniques. For the radar imaging community, a natural question is: Can CNN be introduced to radar imaging and enhance its performance? This letter gives an affirmative answer to this question. We first propose a processing framework by which a complex-valued CNN (CV-CNN) is used to enhance radar imaging. Then we introduce two modifications to the CV-CNN to adapt it to radar imaging tasks. Subsequently, the method to generate training data is shown and some implementation details are presented. Finally, simulations and experiments are carried out, and both results show the superiority of the proposed method on imaging quality and computational efficiency. © 2004-2012 IEEE.","Complex networks; Computational efficiency; Convolution; Imaging techniques; Job analysis; Neural networks; Neurons; Personnel training; Radar; Remote sensing; Convolutional neural network; Side-lobe reduction; Super resolution; Task analysis; Training data; artificial neural network; image analysis; image classification; image processing; image resolution; radar imagery; remote sensing; technological development; Radar imaging","Complex-valued convolutional neural network (CV-CNN); radar imaging; sidelobe reduction; superresolution","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85053155832"
"Lei S.; Shi Z.; Zou Z.","Lei, Sen (57195618353); Shi, Zhenwei (23398841900); Zou, Zhengxia (56073977200)","57195618353; 23398841900; 56073977200","Super-resolution for remote sensing images via local-global combined network","2017","IEEE Geoscience and Remote Sensing Letters","14","8","7937881","1243","1247","4","10.1109/LGRS.2017.2704122","147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029315788&doi=10.1109%2fLGRS.2017.2704122&partnerID=40&md5=9c85e3b474191063c0a1dc38df6306a9","Super-resolution is an image processing technology that recovers a high-resolution image from a single or sequential low-resolution images. Recently deep convolutional neural networks (CNNs) have made a huge breakthrough in many tasks including super-resolution. In this letter, we propose a new single-image super-resolution algorithm named local-global combined networks (LGCNet) for remote sensing images based on the deep CNNs. Our LGCNet is elaborately designed with its 'multifork' structure to learn multilevel representations of remote sensing images including both local details and global environmental priors. Experimental results on a public remote sensing data set (UC Merced) demonstrate an overall improvement of both accuracy and visual performance over several state-of-the-art algorithms. © 2017 IEEE.","Convolution; Deep neural networks; Image processing; Image reconstruction; Neural networks; Optical resolving power; Convolutional neural network; High resolution image; Image processing technology; Local-global combined network (LGCNet); Low resolution images; Remote sensing images; State-of-the-art algorithms; Super resolution; Remote sensing","Convolutional neural networks (CNNs); Local-global combined network (LGCNet); Remote sensing images; Super-resolution","Article","Final","","Scopus","2-s2.0-85029315788"
"Woods M.; Katsaggelos A.","Woods, Matthew (55312741600); Katsaggelos, Aggelos (7102711302)","55312741600; 7102711302","A bayesian multi-frame image super-resolution algorithm using the Gaussian Information Filter","2017","ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","","","7952380","1368","1372","4","10.1109/ICASSP.2017.7952380","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023750208&doi=10.1109%2fICASSP.2017.7952380&partnerID=40&md5=a46bcdbef631cc52a58aa63445045c58","Multi-frame image super-resolution (SR) is an image processing technology applicable to any digital, pixilated camera that is limited, by construction, to a certain number of pixels. The objective of SR is to utilize signal processing to overcome the physical limitation and emulate the 'capabilities' of a camera with a higher-density pixel array. SR is well known to be an ill-posed problem and, consequently, state-of-the-art solutions approach it statistically, typically making use of Bayesian inference. Unfortunately, direct marginalization of the posterior distribution resulting from the Bayesian modeling is not analytically tractable. An approximation method, such as Variational Bayesian Inference (VBI), is a powerful tool that retains the advantages of statistical modeling. However, its derivation is tedious and model specific. In this paper, we propose an alternative approximate inference methodology, based upon the well-established, Gaussian Information Filter, which offers a much simpler mathematical derivation while retaining the statistical advantages of VBI. © 2017 IEEE.","","Image-Processing; Inverse Problems; Photogrammetry; Remote Sensing; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85023750208"
"Zheng C.; Jiang X.; Zhang Y.; Liu X.; Yuan B.; Li Z.","Zheng, Ce (57672921100); Jiang, Xue (55724182500); Zhang, Ye (57214253643); Liu, Xingzhao (57770107000); Yuan, Bin (36109487100); Li, Zhixin (57241049300)","57672921100; 55724182500; 57214253643; 57770107000; 36109487100; 57241049300","Self-normalizing generative adversarial network for super-resolution reconstruction of SAR images","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-July","","8900084","1911","1914","3","10.1109/IGARSS.2019.8900084","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104026398&doi=10.1109%2fIGARSS.2019.8900084&partnerID=40&md5=d8052b974df78aea9e33f718d307e7e5","High-resolution images with abundant detailed information are necessary elements for various applications of synthetic aperture radar (SAR). In this paper, a novel super-resolution image reconstruction method based on self-normalizing generative adversarial network (SNGAN) is proposed. Compared with other published GAN-based super-resolution algorithms, the proposed method reflects its superiority in two aspects. First, the scaled exponential linear units (SeLU) is introduced as the activation function of generator to give the GAN system self-normalization ability and make it more suitable for SAR images. Second, the batch normalization layers after convolution are canceled to reduce the computational requirement and model oscillation. Experiment results on the images of TerraSAR and MSTAR dataset demonstrate that the proposed method acquires satisfactory performance on the resolution enhancement and target recognition of SAR images. ©2019 IEEE","Image enhancement; Image reconstruction; Optical resolving power; Radar target recognition; Remote sensing; Synthetic aperture radar; Activation functions; Adversarial networks; Computational requirements; High resolution image; Resolution enhancement; Super resolution algorithms; Super resolution reconstruction; Super-resolution image reconstruction; Radar imaging","Generative adversarial network (GAN); Super-resolution image reconstruction; Target recognition","Conference paper","Final","","Scopus","2-s2.0-85104026398"
"Zhao X.; Yang R.; Qin Z.; Wu J.","Zhao, Xiangyu (56505752000); Yang, Ru (55836369100); Qin, Zhentao (55836134900); Wu, Jianbing (57202233424)","56505752000; 55836369100; 55836134900; 57202233424","Study on super-resolution reconstruction algorithm based on sparse representation and dictionary learning for remote sensing image","2018","Proceedings - 2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics, CISP-BMEI 2017","2018-January","","","1","4","3","10.1109/CISP-BMEI.2017.8302035","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047547770&doi=10.1109%2fCISP-BMEI.2017.8302035&partnerID=40&md5=752dd33e70fb8b7cef1fb4ace9b8b38f","Super-resolution image reconstruction plays a very important role in the interpretation of remote sensing images. Especially when the resolution of images is low, the size of the objects to be identified is close to the minimum resolution, and can be reconstructed by super-resolution better interpretation of the feature. In this paper, K-SVD algorithm is used to study the exampler of high resolution image library, and the dictionary of high resolution remote sensing image is obtained. The low resolution image is represented by high resolution dictionary, and the remote sensing reconstruction of remote sensing image is realized. Which improves the peak noise ratio and mean square error of the image, and has better performance than the interpolation algorithm. The method proposed in this paper has important significance and application prospect in remote sensing image application. © 2017 IEEE.","Biomedical engineering; Image enhancement; Mean square error; Optical resolving power; Remote sensing; Exampler; High resolution remote sensing images; Interpolation algorithms; Low resolution images; Sparse representation; Super resolution; Super resolution reconstruction; Super-resolution image reconstruction; Image reconstruction","Exampler; K-SVD; Sparse Representation; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85047547770"
"Bosch M.; Munoz Abujder R.R.R.; Gifford C.","Bosch, Marc (24398475400); Munoz Abujder, Rodrigo Rene Rai (57211071520); Gifford, Christopher (24467858000)","24398475400; 57211071520; 24467858000","Towards image and video super-resolution for improved analytics from overhead imagery","2019","Proceedings of SPIE - The International Society for Optical Engineering","10992","","1099203","","","","10.1117/12.2518179","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072569349&doi=10.1117%2f12.2518179&partnerID=40&md5=0532d54f73676e98e6b8379d5ea61274","In this work, we address the problem of losing details in the overhead remote sensing image acquisition and generation process due to sensor resolution and distance to target by leveraging state-of-the-art deep neural network architectures. The goal is to recover such details by super-resolving the images acquired by overhead imaging sensors in order for human analysts to interpret data more accurately, and consequentially, for automated visual exploitation algorithms to be applied more effectively. We have developed a super-resolution framework operating on overhead full motion video (FMV) and still imagery (e.g. satellite images). Our framework consists of a neural network capable of learning the mapping between low and high resolution images in order to produce plausible details about the scene. Our framework combines Generative Adversarial Networks (GANs) and Recurrent Neural Networks (RNNs) to process low resolution signals both spatially and, in the case of FMV, temporally. We have applied the output of our system to several visual perception tasks, including object detection, object tracking, and semantic segmentation. We have also applied our methods to data from different geographical areas, sensors, and even modalities to demonstrate broad and generalized applicability. Copyright © 2019 SPIE.","Computer vision; Deep neural networks; Image acquisition; Network architecture; Object detection; Object recognition; Optical resolving power; Recurrent neural networks; Remote sensing; Satellite imagery; Semantics; Adversarial networks; Full motion video; High resolution image; Recurrent neural network (RNNs); Remote sensing images; Semantic segmentation; Super resolution; Video super-resolution; Image enhancement","computer vision; full motion video; generative adversarial networks (GANs); object detection; satellite imagery; semantic segmentation; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85072569349"
"Jiang Z.; Yu Z.; Feng S.; Huang Z.; Peng Y.; Guo J.; Ren Q.; Lu Y.","Jiang, Zhe (57203950168); Yu, Zekuan (57218290944); Feng, Shouxin (57217725187); Huang, Zhiyu (57185934800); Peng, Yahui (35085274400); Guo, Jianxin (57203950573); Ren, Qiushi (9736022400); Lu, Yanye (55542239400)","57203950168; 57218290944; 57217725187; 57185934800; 35085274400; 57203950573; 9736022400; 55542239400","A super-resolution method-based pipeline for fundus fluorescein angiography imaging 08 Information and Computing Sciences 0801 Artificial Intelligence and Image Processing Robert Koprowski","2018","BioMedical Engineering Online","17","1","125","","","","10.1186/s12938-018-0556-7","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053714092&doi=10.1186%2fs12938-018-0556-7&partnerID=40&md5=412dedfabfc91817b6e57bf5af308ebb","Background: Fundus fluorescein angiography (FFA) imaging is a standard diagnostic tool for many retinal diseases such as age-related macular degeneration and diabetic retinopathy. High-resolution FFA images facilitate the detection of small lesions such as microaneurysms, and other landmark changes, in the early stages; this can help an ophthalmologist improve a patient's cure rate. However, only low-resolution images are available in most clinical cases. Super-resolution (SR), which is a method to improve the resolution of an image, has been successfully employed for natural and remote sensing images. To the best of our knowledge, no one has applied SR techniques to FFA imaging so far. Methods: In this work, we propose a SR method-based pipeline for FFA imaging. The aim of this pipeline is to enhance the image quality of FFA by using SR techniques. Several SR frameworks including neighborhood embedding, sparsity-based, locally-linear regression and deep learning-based approaches are investigated. Based on a clinical FFA dataset collected from Second Affiliated Hospital to Xuzhou Medical University, each SR method is implemented and evaluated for the pipeline to improve the resolution of FFA images. Results and conclusion: As shown in our results, most SR algorithms have a positive impact on the enhancement of FFA images. Super-resolution forests (SRF), a random forest-based SR method has displayed remarkable high effectiveness and outperformed other methods. Hence, SRF should be one potential way to benefit ophthalmologists by obtaining high-resolution FFA images in a clinical setting. © 2018 The Author(s).","Deep Learning; Eye; Fluorescein Angiography; Fundus Oculi; Humans; Image Processing, Computer-Assisted; Linear Models; Angiography; Artificial intelligence; Decision trees; Deep learning; Eye protection; Learning systems; Medical imaging; Ophthalmology; Optical resolving power; Pipelines; Remote sensing; Age-related macular degeneration; Convolutional networks; Fluorescein angiography; Learning-based approach; Low resolution images; Random forests; Super resolution; Superresolution methods; algorithm; Article; China; deep learning based approach; feasibility study; fluorescence angiography; fundus fluorescein angiography; image quality; image resolution; imaging and display; locally linear regression approach; machine learning; neighborhood embedding approach; priority journal; quantitative analysis; random forest; sparsity based approach; super resolution method; diagnostic imaging; eye; eye fundus; fluorescence angiography; human; image processing; procedures; statistical model; Image enhancement","Convolutional network; Fundus fluorescein angiography imaging; Machine learning; Random forest; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85053714092"
"Shen H.; Hou B.; Wen Z.; Jiao L.","Shen, Huifang (57218659671); Hou, Biao (7102142690); Wen, Zaidao (56042269100); Jiao, Licheng (7102491544)","57218659671; 7102142690; 56042269100; 7102491544","Structural-Correlated Self-Examples Based Superresolution of Single Remote Sensing Image","2018","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","11","9","8402088","3209","3223","14","10.1109/JSTARS.2018.2847450","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049488041&doi=10.1109%2fJSTARS.2018.2847450&partnerID=40&md5=551a1b406d80d761fe0ecf50ffc70ee6","Image superresolution methods are of great importance to image analysis and interpretation and have been intensively studied and widely applied. The main research works on single-image superresolution are how to construct the training image database and how to learn the mapping relationship between low-and high-resolution images. Considering only a single image, a novel super-resolution method for self-examples learning without depending on any external training images is proposed in this paper. The training self-examples are extracted from the gradually degraded versions of the testing image and their corresponding interpolated counterparts to build internal high-and low-resolution training databases. Inspired by the concept of 'coarse-to-fine,' the upscaling process is performed gradually as well. The algorithm includes two steps during each upscaling procedure. For each low-resolution patch, the first step is to find structural-correlated patches by sparse representation throughout the training database to learn global linear mapping function between low-and high-resolution image patches without any assumption on the data, and the second step takes the advantage of sparse representation as a local constraint on super-resolution result. At each upscaling procedure, iterative back projection is applied to guarantee the consistency of the estimated image. Moreover, the internal training database will be updated according to the newly generated upscaled image. Experiments show that the proposed algorithm can achieve good performance on peak signal-to-noise ratio and structural similarity index and produce excellent visual effects compared with other super-resolution methods. © 2008-2012 IEEE.","Database systems; Glossaries; Iterative methods; Mapping; Optical resolving power; Personnel training; Signal to noise ratio; Direct mapping; Image super-resolution; Signal resolution; Sparse representation; Spatial resolution; structural-correlated; correlation; database; image analysis; image resolution; mapping; remote sensing; upscaling; Remote sensing","Direct mapping (DM); image superresolution; internal database; sparse representation; structural-correlated","Article","Final","","Scopus","2-s2.0-85049488041"
"Liu T.; Qian F.; Zhang B.","Liu, Tao (56159002300); Qian, Feng (57218946056); Zhang, Bao (7406908929)","56159002300; 57218946056; 7406908929","MAP super-resolution reconstruction of remote sensing image","2018","Chinese Journal of Liquid Crystals and Displays","33","10","1007-2780(2018)10-0884-09","884","892","8","10.3788/YJYXS20183310.0884","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058614397&doi=10.3788%2fYJYXS20183310.0884&partnerID=40&md5=63ee9ce700664ba19df9b96697484339","The fundamental purpose of remote sensing is to obtain clear images with high spatial resolution, which can be further analyzed and processed. In order to obtain higher spatial resolution, higher signal-to-noise ratio and clearer images in remote sensing measurement, this paper studies the superresolution algorithm in image processing field. In the paper we set up a model fitting the real imaging system, use the theory of maximum a posteriori probability system on this model, discuss the motion blur, noise and other degrading factors, and finally improve the MAP superresolution algorithm. The experimental results show that the improved multi-frame superresolution reconstruction algorithm in the paper based on the Markov constraint field which is originated from the MAP theory, can improve the superresolution performance significantly. Using our method, PSNR is at least about 5.1 dB higher than the cubic interpolation method, and is about 0.2 dB higher than the unimproved MAP method. In our paper a dynamic prior constraint method is proposed, by adding constraints associated with the number of iterations to constraint function, the improvement innovation can accelerate convergence and more close to real images. And the experiments show that this method can fasten the convergence, and its constraint effect is good. Above all, it is more suitable for practical application. © 2018, Science Press. All rights reserved.","","Dynamic constraint; MAP principle; Markov random field; Regulation item; Remote sensing; Superresolution reconstruction","Article","Final","","Scopus","2-s2.0-85058614397"
"Song H.; Liu Q.; Wang G.; Hang R.; Huang B.","Song, Huihui (36572623600); Liu, Qingshan (36063739200); Wang, Guojie (57951093900); Hang, Renlong (56082126900); Huang, Bo (55388074800)","36572623600; 36063739200; 57951093900; 56082126900; 55388074800","Spatiotemporal Satellite Image Fusion Using Deep Convolutional Neural Networks","2018","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","11","3","","821","829","8","10.1109/JSTARS.2018.2797894","185","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042131669&doi=10.1109%2fJSTARS.2018.2797894&partnerID=40&md5=c5253a13e222c8dfbe2b19ac3ee06ff7","We propose a novel spatiotemporal fusion method based on deep convolutional neural networks (CNNs) under the application background of massive remote sensing data. In the training stage, we build two five-layer CNNs to deal with the problems of complicated correspondence and large spatial resolution gaps between MODIS and Landsat images. Specifically, we first learn a nonlinear mapping CNN between MODIS and low-spatial-resolution (LSR) Landsat images and then learn a super-resolution CNN between LSR Landsat and original Landsat images. In the prediction stage, instead of directly taking the outputs of CNNs as the fusion result, we design a fusion model consisting of high-pass modulation and a weighting strategy to make full use of the information in prior images. Specifically, we first map the input MODIS images to transitional images via the learned nonlinear mapping CNN and further improve the transitional images to LSR Landsat images via the fusion model; then, via the learned SR CNN, the LSR Landsat images are supersolved to transitional images, which are further improved to Landsat images via the fusion model. Compared with the previous learning-based fusion methods, mainly referring to the sparse-representation-based methods, our CNNs-based spatiotemporal method has the following advantages: 1) automatically extracting effective image features; 2) learning an end-to-end mapping between MODIS and LSR Landsat images; and 3) generating more favorable fusion results. To examine the performance of the proposed fusion method, we conduct experiments on two representative Landsat-MODIS datasets by comparing with the sparse-representation-based spatiotemporal fusion model. The quantitative evaluations on all possible prediction dates and the comparison of fusion results on one key date in both visual effect and quantitative evaluations demonstrate that the proposed method can generate more accurate fusion results. © 2008-2012 IEEE.","Convolution; Deep neural networks; Earth (planet); Image enhancement; Image resolution; Mapping; Neural networks; Personnel training; Radiometers; Remote sensing; Satellite imagery; Satellites; Convolutional neural network; MODIS; Nonlinear mappings; Spatial resolution; Spatiotemporal phenomena; Temporal resolution; accuracy assessment; artificial neural network; image analysis; Landsat; mapping; nonlinearity; satellite imagery; spatial resolution; spatiotemporal analysis; Image fusion","Convolutional neural network (CNN); nonlinear mapping (NLM); spatial resolution; temporal resolution","Article","Final","","Scopus","2-s2.0-85042131669"
"Lu Y.; Benedix W.-S.; Yu C.; Wang J.; Plettemeier D.","Lu, Yun (55506599500); Benedix, Wolf-Stefan (34867822800); Yu, ChunHai (57203929715); Wang, JingTao (57203928406); Plettemeier, Dirk (9741901800)","55506599500; 34867822800; 57203929715; 57203928406; 9741901800","Enhanced microwave imaging by bilinear compressed sensing","2018","Proceedings International Radar Symposium","2018-June","","8447919","","","","10.23919/IRS.2018.8447919","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053636205&doi=10.23919%2fIRS.2018.8447919&partnerID=40&md5=b5c24bc958467a73a19064021d3e6f97","Microwave imaging (migration) and spectral analysis are widely used in the remote sensing techniques. Generally, a known signal will be transmitted and the transfer function of the observed zone will then be recovered by the received signal and the transmit signal. Nevertheless, those scenes are usually available for homogeneous setting, where the transmit signal will not be modified by e. g. the medium and the wave propagation mechanism. In inhomogeneous case, however, the transmit signal is modified by the channel. Thus, the received signal can be formulated as a bilinear function over transmit signal and channel transfer function. Additionally, the measured data in practice has relative low dimension property due to some technique as well as physical limitations. Regarding e. g. a super-resolution problem, its objective vectors exist usually in the higher dimensional space. Therefore, the corresponding inverse problem can be very ill-posed. Compressed Sensing (CS), which is popular for dealing with such ill-conditioned cases, will be introduced. Particularly, the question of how to realize the bilinear CS model in our special case will be discussed. Both theory and practical tests show its promising performance. © 2018 German Institute of Navigation - DGON.","Imaging systems; Inverse problems; Radar; Remote sensing; Spectrum analysis; Transfer functions; Vector spaces; Wave propagation; Bilinear functions; Channel transfer functions; Compressive sensing; Higher-dimensional; Ill-conditioned case; Physical limitations; Propagation mechanism; Remote sensing techniques; Compressed sensing","","Conference paper","Final","","Scopus","2-s2.0-85053636205"
"Li L.; Sui L.; Kang J.; Wang X.","Li, Li (57208394808); Sui, Lichun (35173613800); Kang, Junmei (57202107365); Wang, Xue (57210452685)","57208394808; 35173613800; 57202107365; 57210452685","Super resolution reconstruction of remote sensing images based on online variational Bayesian estimation","2018","Laser and Optoelectronics Progress","55","6","062801","","","","10.3788/LOP55.062801","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062806275&doi=10.3788%2fLOP55.062801&partnerID=40&md5=1282e6b760e62e81ce6149f70d9a2251","A single remote sensing image super resolution reconstruction method based on online variational Bayes expectation maximization coupled dictionary learning is proposed in this study to improve the spatial resolution of low resolution remote sensing images. The method first establishes the probability distribution model of the dictionary atom and each parameter, divides it into local variables and global variables, and uses the Gibbs sampling method to update the current parameters with fixed other parameters to assign initial values to the variables. Then stochastic optimization method is used to optimize expectation maximization (EM) optimization for two kinds of variables. The posterior distribution of the dictionary atom is obtained by minimizing the Kullback Leibler (KL) distance, and the dictionary size is derived non-parametrically. Finally, ihe image to be reconstructed is divided into smooth and texture patches by bilateral filter during reconstruction, the sparse reconstruction method is used for the texture part while the bicubic interpolation reconstruction is applied for the smooth part. Compared with the bilinear, the bicubic interpolation and the super resolution reconstruction algorithm based on sparse representation, the average peak signal to noise ratios of the proposed method are increased by 3.85, 2. 11, 0.20 dB, respectively. And the average relative global dimensional synthesis errors (ERGASs) are decreased by 0.64, 0.28, 0.04 dB, respectively. Experimental results show that this algorithm can provide more high-frequency detail information by adding more sample and parameter prior information, which has certain universality and strong noise robustness, and the reconstruction speed is faster. © 2018 Universitat zu Koln. All rights reserved.","","Remote sensing; Remote sensing images; Sparse representation; Stochastic optimization; Super resolution reconstruction; Variational Bayesian","Article","Final","","Scopus","2-s2.0-85062806275"
"Wang A.; Wang Y.; Song X.; Iwahori Y.","Wang, Aili (55483869300); Wang, Ying (57207001725); Song, Xiaoying (57210435647); Iwahori, Yuji (7003339167)","55483869300; 57207001725; 57210435647; 7003339167","Remote Sensing Image Super-Resolution Reconstruction based on Generative Adversarial Network","2019","International Journal of Performability Engineering","15","7","","1783","1791","8","10.23940/ijpe.19.07.p4.17831791","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070709753&doi=10.23940%2fijpe.19.07.p4.17831791&partnerID=40&md5=0c36fb174d47d236fbcf8f8086646e1b","The super-resolution reconstruction algorithm based on generative adversarial network (GAN) can generate realistic texture in the super-resolution process of a single remote sensing image. In order to further improve the visual quality of the reconstructed image, this paper will improve the generation network, discrimination network, and perceptual loss of the generated confrontation network. Firstly, the batch normalization layer is removed and dense connections are used in the residual blocks, which effectively improves the performance of the generated network. Then, we use the relative discriminant network to learn more detailed texture. Finally, we obtain the perception loss before the activation function to maintain the consistency of brightness. In addition, transfer learning is used to solve the problem of insufficient remote sensing data. The experimental results show that the proposed algorithm has superiority in the super-resolution reconstruction of remote sensing images and can obtain better subjective visual effects. © 2019 Totem Publisher, Inc. All rights reserved.","Image enhancement; Optical resolving power; Remote sensing; Textures; Activation functions; Adversarial networks; Reconstructed image; Remote sensing data; Remote sensing images; Residual dense block; Super resolution reconstruction; Transfer learning; Image reconstruction","Generative adversarial network; Remote sensing image super-resolution reconstruction; Residual dense block; Transfer learning","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85070709753"
"Zhu F.; Huang X.; Liu Y.; Zhu H.","Zhu, Fuzhen (12780819500); Huang, Xin (57204029373); Liu, Yue (57200522975); Zhu, Haitao (57204846614)","12780819500; 57204029373; 57200522975; 57204846614","Improved Sparse Representation Super-Resolution algorithm for Remote Sensing Image","2018","MATEC Web of Conferences","232","","02040","","","","10.1051/matecconf/201823202040","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057483983&doi=10.1051%2fmatecconf%2f201823202040&partnerID=40&md5=a5c55fd9446d633569463a874d64f547","In order to obtain higher quality super-resolution reconstruction (SRR) of remote sensing images, an improved sparse representation remote sensing images SRR method is proposed in this paper. First, low-resolution image is processed by improved feature extract operator. The high-resolution image and low-resolution image blocks have the same sparse representation coefficient, so the SRR image with higher spatial resolution can be derived from the sparse representation coefficients which have been obtained from low-resolution image. The improved feature extraction operator is a method to get more detail and texture information from the training images. Experiment results show that more texture details can be obtained in the result of SRR remote sensing images subjectively. At the same time, the objective evaluation parameters are improved greatly. The peak PSNR is increased about 2.50dB and 0.50 dB, RMSE is decreased about 2.80 and 0.3 compared with bicubic interpolation algorithm and Ref[8] algorithm respectively. © The Authors, published by EDP Sciences, 2018.","Image texture; Optical resolving power; Personnel training; Remote sensing; Bicubic interpolation; High resolution image; Low resolution images; Objective evaluation; Remote sensing images; Sparse representation; Super resolution algorithms; Super resolution reconstruction; Image enhancement","","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85057483983"
"Wang L.; Lin Z.; Deng X.; An W.","Wang, Longguang (57193752437); Lin, Zaiping (55497588700); Deng, Xinpu (7401768928); An, Wei (7006908300)","57193752437; 55497588700; 7401768928; 7006908300","Point target detection utilizing super-resolution strategy for infrared scanning oversampling system","2017","Infrared Physics and Technology","86","","","165","175","10","10.1016/j.infrared.2017.09.009","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029715584&doi=10.1016%2fj.infrared.2017.09.009&partnerID=40&md5=aa69686560a5b6e52510f7d540a34b48","To improve the resolution of remote sensing infrared images, infrared scanning oversampling system is employed with information amount quadrupled, which contributes to the target detection. Generally the image data from double-line detector of infrared scanning oversampling system is shuffled to a whole oversampled image to be post-processed, whereas the aliasing between neighboring pixels leads to image degradation with a great impact on target detection. This paper formulates a point target detection method utilizing super-resolution (SR) strategy concerning infrared scanning oversampling system, with an accelerated SR strategy proposed to realize fast de-aliasing of the oversampled image and an adaptive MRF-based regularization designed to achieve the preserving and aggregation of target energy. Extensive experiments demonstrate the superior detection performance, robustness and efficiency of the proposed method compared with other state-of-the-art approaches. © 2017 Elsevier B.V.","Infrared imaging; Markov processes; Optical resolving power; Remote sensing; Detection performance; Image degradation; Information amount; Markov Random Fields; Over sampling; Point target detection; State-of-the-art approach; Super resolution; Scanning","Infrared scanning oversampling system; Markov random field (MRF); Point target detection; Super-resolution","Article","Final","","Scopus","2-s2.0-85029715584"
"Lagovsky B.A.; Samokhin A.B.; Shestopalov Y.V.","Lagovsky, B.A. (8228029900); Samokhin, A.B. (7005200099); Shestopalov, Y.V. (7003336210)","8228029900; 7005200099; 7003336210","Creating Two-Dimensional Images of Objects with High Angular Resolution","2018","Proceedings of the 2018 IEEE 7th Asia-Pacific Conference on Antennas and Propagation, APCAP 2018","","","8538220","114","115","1","10.1109/APCAP.2018.8538220","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059420755&doi=10.1109%2fAPCAP.2018.8538220&partnerID=40&md5=9aabcc93e56acf4a56da4979a4473525","A new method of digital radar signal processing for remote sensing is proposed. The technique allows one to obtain two-dimensional images of objects with super resolution. The method is based on solving a convolution-type two-dimensional linear integral equation of the first kind by algebraic methods. © 2018 IEEE.","Algebra; Convolution; Optical resolving power; Remote sensing; Signal processing; Algebraic method; Angular resolution; Convolution type; High angular resolutions; Linear integral equations; Rayleigh criterion; Super resolution; Two dimensional images; Integral equations","angular resolution; Rayleigh criterion; superresolution; two-dimensional linear integral equation","Conference paper","Final","","Scopus","2-s2.0-85059420755"
"Dian R.; Li S.; Fang L.; Bioucas-Dias J.","Dian, Renwei (57192573953); Li, Shutao (7409240361); Fang, Leyuan (36739090900); Bioucas-Dias, José (55901520500)","57192573953; 7409240361; 36739090900; 55901520500","Hyperspectral image super-resolution via local low-rank and sparse representations","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8519213","4003","4006","3","10.1109/IGARSS.2018.8519213","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064167409&doi=10.1109%2fIGARSS.2018.8519213&partnerID=40&md5=1eacff15ab9a16b3793b097becc4e9b4","Remotely sensed hyperspectral images (HSIs) usually have high spectral resolution but low spatial resolution. A way to increase the spatial resolution of HSIs is to solve a fusion inverse problem, which fuses a low spatial resolution HSI (LRHSI) with a high spatial resolution multispectral image (HRMSI) of the same scene. In this paper, we propose a novel HSI super-resolution approach (called LRSR), which formulates the fusion problem as the estimation of a spectral dictionary from the LR-HSI and the respective regression coefficients from both images. The regression coefficients are estimated by formulating a variational regularization problem which promotes local (in the spatial sense) low-rank and sparse regression coefficients. The local regions, where the spectral vectors are low-rank, are estimated by segmenting the HR-MSI. The formulated convex optimization is solved with SALSA. Experiments provide evidence that LRSR is competitive with respect to the state-of-the-art methods. © 2018 IEEE.","Convex optimization; Geology; Image fusion; Image resolution; Regression analysis; Remote sensing; Spectral resolution; Spectroscopy; Superpixels; High spatial resolution multispectral images; High spectral resolution; HyperSpectral; Image super resolutions; Low rank; Regression coefficient; State-of-the-art methods; Variational regularization; Inverse problems","Hyperspectral image super-resolution; Low rank; Superpixels","Conference paper","Final","","Scopus","2-s2.0-85064167409"
"Piestova I.O.; Stankevich S.A.; Kostolny J.","Piestova, Iryna O. (57195922301); Stankevich, Sergey A. (16176794100); Kostolny, Jozef (55364488000)","57195922301; 16176794100; 55364488000","Multispectral imagery super-resolution with logical reallocation of spectra","2017","Proceedings of the International Conference on Information and Digital Technologies, IDT 2017","","","8024316","322","326","4","10.1109/DT.2017.8024316","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030105477&doi=10.1109%2fDT.2017.8024316&partnerID=40&md5=d48d4d2720efde117fffcaa682d4e806","The multispectral imagery spatial resolution enhancement with logical reallocation of spectra is presented. This method includes preprocessing, subpixel resampling, subpixel neighborhood analysis and subpixel values reallocation using similar spectra spatial cross-coupling. This method intended primarily for European Sentinel-2 multispectral satellite system, but it can be adapted to other multispectral systems with non-uniform spatial resolution too. © 2017 IEEE.","Chemical reactions; Image resolution; Optical resolving power; Pixels; Remote sensing; Cross-couplings; logical reallocation; Multi-spectral imagery; Multispectral systems; Neighborhood analysis; Spatial resolution; Spatial-resolution enhancement; Super resolution; Image enhancement","logical reallocation; multispectral imagery; subpixels cross-coupling; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85030105477"
"Niu Z.; Shi J.; Sun L.; Zhu Y.; Fan J.; Zeng G.","Niu, Zhouzhou (57200164212); Shi, Jianhong (55491815200); Sun, Lei (57203714376); Zhu, Yan (49662718800); Fan, Jianping (7402795255); Zeng, Guihua (7202802740)","57200164212; 55491815200; 57203714376; 49662718800; 7402795255; 7202802740","Photon-limited face image super-resolution based on deep learning","2018","Optics Express","26","18","","22773","22782","9","10.1364/OE.26.022773","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052695171&doi=10.1364%2fOE.26.022773&partnerID=40&md5=d471410df61adb6d655578b7205d1523","With one single photon camera (SPC), imaging under ultra weak-lighting conditions may have wide-ranging applications ranging from remote sensing to night vision, but it may seriously suffer from the problem of under-sampled inherent in SPC detection. Some approaches have been proposed to solve the under-sampled problem by detecting the objects many times to generate high-resolution images and performing noise reduction to suppress the Poission noise inherent in low-flux operation. To address the under-sampled problem more effectively, a new approach is developed in this paper to reconstruct high-resolution images with lower-noise by seamlessly integrating low-light-level imaging with deep learning. In our new approach, all the objects are detected only once by SPC, where a deep network is learned to reduce noise and reconstruct high-resolution images from the detected noisy under-sampled images. In order to demonstrate our proposal is feasible, we first select a special category to verify by experiment, which are human faces. Such deep network is able to recover high-resolution and lower-noise face images from new noisy under-sampled face images and the resolution can achieve 4x up-scaling factor. Our experimental results have demonstrated that our proposed method can generate high-quality images from only ~0.2 detected signal photon per pixel. © 2018 Optical Society of America.","Image denoising; Image reconstruction; Object detection; Particle beams; Photons; Remote sensing; High quality images; High resolution; High resolution image; Low light level imaging; New approaches; Photon limiteds; Single photons; Wide-ranging applications; article; deep learning; face; human; noise; photon; Deep learning","","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85052695171"
"Jebadurai J.; Peter J.D.","Jebadurai, Jebaveerasingh (57194006295); Peter, J. Dinesh (57203535407)","57194006295; 57203535407","DeepCS: Deep convolutional neural network and SVM based single image super-resolution","2018","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11076 LNCS","","","3","13","10","10.1007/978-3-030-00807-9_1","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054865703&doi=10.1007%2f978-3-030-00807-9_1&partnerID=40&md5=76a34c29560b0259b952b532a0e8f27c","Computer based patient monitoring systems help in keeping track of the patients’ responsiveness to the treatment over the course of the treatment. Further, development of these kind of healthcare systems that require minimal or no human intervention form one of the most essential elements of smart cities. In order to make it a reality, the computer vision and machine learning techniques provide numerous ways to improve the efficiency of the automated healthcare systems. Image super-resolution (SR) has been an active area of research in the field of computer vision for the past couple of decades. The SR algorithms are offline and independent of image capturing devices making them suitable for various applications such as video surveillance, medical image analysis, remote sensing etc. This paper proposes a learning based SR algorithm for generating high resolution (HR) images from low resolution (LR) images. The proposed approach uses the fusion of deep convolutional neural network (CNN) and support vector machines (SVM) with regression for learning and reconstruction. Learning with deep neural networks exhibit better approximation and support vector machines work well in decision making. The experiments with the retinal images from RIMONE and CHASEDB have shown that the proposed approach outperforms the existing image super-resolution approaches in terms of peak signal to noise ratio (PSNR) as well as mean squared error (MSE). © Springer Nature Switzerland AG 2018.","Computer aided analysis; Computer vision; Convolution; Decision making; Deep learning; Image analysis; Image segmentation; Learning algorithms; Mean square error; Medical computing; Medical imaging; Neural networks; Optical resolving power; Patient monitoring; Patient treatment; Pediatrics; Remote sensing; Security systems; Signal to noise ratio; Support vector machines; Deep convolutional neural networks; Image capturing devices; Image super resolutions; Linear units; Low resolution images; Machine learning techniques; Patient monitoring systems; Peak Signal to Noise Ratio (PSNR); Deep neural networks","Deep learning; Deep neural networks; Image super-resolution; Rectifier linear units","Conference paper","Final","","Scopus","2-s2.0-85054865703"
"Li F.; Xin L.; Guo Y.; Gao D.; Kong X.; Jia X.","Li, Feng (57171116800); Xin, Lei (57183670600); Guo, Yi (55712471200); Gao, Dongsheng (57192410879); Kong, Xianghao (57143366600); Jia, Xiuping (7201933692)","57171116800; 57183670600; 55712471200; 57192410879; 57143366600; 7201933692","Super-resolution for GaoFen-4 remote sensing images","2018","IEEE Geoscience and Remote Sensing Letters","15","1","","28","32","4","10.1109/LGRS.2017.2768331","34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039761510&doi=10.1109%2fLGRS.2017.2768331&partnerID=40&md5=49f8cf0f64b951b8ca695c18ff29ee89","In this letter, the application of super-resolution (SR) techniques to GaoFen(GF)-4, which is the most advanced geostationary-orbit earth observing satellite in China, remote sensing images is investigated and tested. One of the shortcomings of the geostationary-orbit-based earth observing satellite is the limitation of spatial resolution. However, human beings never stop pursuing higher resolution in images. This is the first experiment of applying SR to a sequence of low-resolution (LR) images captured by GF-4 within a short time period. One of the barriers for applying SR to remote sensing images is the large time gaps between those LR image acquisition, because the reflection characteristic of the ground may change within the time period when those LR images were captured. However, GF-4 has the unique advantage of capturing a sequence of LR images of the same region in minutes, i.e., working as a staring camera from the point view of SR. The reconstructed high-resolution images of some regions in Beijing and Hainan are shown and evaluated in this letter. This letter demonstrates that the application of SR to geostationary-orbit-based earth observation data is feasible and valuable, and it has the potential to be applied to the images acquired by all other geostationary-orbit-based earth observing systems. © 2017 IEEE.","Beijing [China]; China; Hainan; Geostationary satellites; Image acquisition; Image reconstruction; Image resolution; Optical resolving power; Orbits; Satellites; Wavelet transforms; Earth observation data; Earth observing satellite; Earth observing systems; GaoFen-4 (GF-4); Maximum a posteriori; Reflection characteristics; Spatial resolution; Super resolution; EOS; geostationary satellite; image analysis; remote sensing; spatial resolution; spectral resolution; Remote sensing","GaoFen-4 (GF-4); Maximum a posteriori (MAP); Super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85039761510"
"Fablet R.; Le Sommer J.; Molines J.M.; Drumetz L.; Rousseau F.; Chapron B.","Fablet, R. (6603508732); Le Sommer, J. (6507387108); Molines, J.M. (6603285411); Drumetz, L. (56690503500); Rousseau, F. (57188780886); Chapron, B. (56209544000)","6603508732; 6507387108; 6603285411; 56690503500; 57188780886; 56209544000","Learning differential transport operators for the joint super-resolution of sea surface tracers and prediction of subgrid-scale features.","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-July","","900571","7916","7919","3","10.1109/IGARSS.2019.8900571","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113864032&doi=10.1109%2fIGARSS.2019.8900571&partnerID=40&md5=41b8b04febc1c5da706c607c985cb033","This work deals with data-driven and learning-based approaches to fill space-time sampling gaps in the observation of sea surface tracers such as Sea Surface Height (SSH), Sea Surface temperature (SST), Ocean Colour,. More precisely, we jointly address field super-resolution and the prediction of subgrid-scale features, which is novel to our knowledge. From a methodological point of view, we consider deep learning architectures with a view to learning geophysically-sound differential operators (i.e. trasnport operators). Based on an Observing System Simulation Experiment representative of SWOT fast sampling phase using NATL60 simulation data, we illustrate the relevance of the proposed methodological framework which reconstructs more than 90% of the variance of the high-resolution SSH anomaly field and above 90% of the subgrid-scale variance of this anomaly. We also illustrate significant gain w.r.t. other baseline neural network architectures and further discuss the relevance of the reported contribution for other tracer fields and case studies. © 2019 IEEE.","Deep learning; Internet protocols; Mathematical operators; Network architecture; Oceanography; Optical resolving power; Remote sensing; Tracers; Differential operators; Learning architectures; Learning-based approach; Methodological frameworks; Observing system simulation experiments; Sea surface temperature (SST); Space-time samplings; Transport operators; Surface waters","Deep learning; Differential operators; Ocean surface tracers; SSH; Subgrid-scale features; Superresolution","Conference paper","Final","","Scopus","2-s2.0-85113864032"
"Yang R.; Li H.; Li S.; Zhang P.; Tan L.; Gao X.; Kang X.","Yang, Ruliang (7403924545); Li, Haiying (57194180504); Li, Shiqiang (9238834700); Zhang, Ping (57198754127); Tan, Lulu (27568186800); Gao, Xiangwu (36848988300); Kang, Xueyan (7102354331)","7403924545; 57194180504; 9238834700; 57198754127; 27568186800; 36848988300; 7102354331","High-resolution microwave imaging","2017","High-Resolution Microwave Imaging","","","","1","552","551","10.1007/978-981-10-7138-6","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042629022&doi=10.1007%2f978-981-10-7138-6&partnerID=40&md5=0442c62338ffcbfd8435a063fc39a0f5","This book comprehensively describes high-resolution microwave imaging and super-resolution information processing technologies and discusses new theories, methods and achievements in the high-resolution microwave imaging fields. Its chapters, which include abundant research results and examples, systematically summarize the authors' main research findings in recent years. The book is intended for researchers, engineers and postgraduates in the fields of electronics systems, signal information processing and data analysis, microwave remote sensing and microwave imaging radar, as well as space technology, especially in the microwave remote sensing and airborne or space-borne microwave imaging radar fields. © National Defense Industry Press, Beijing and Springer Nature Singapore Pte Ltd. 2018. All Rights Reserved.","","","Book","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85042629022"
"Guo Z.; Wu G.; Shi X.; Sui M.; Song X.; Xu Y.; Shao X.; Shibasaki R.","Guo, Zhiling (57189517376); Wu, Guangming (57196352694); Shi, Xiaodan (57201292783); Sui, Mingzhou (57239628600); Song, Xiaoya (57205562134); Xu, Yongwei (57189516545); Shao, Xiaowei (16200316400); Shibasaki, Ryosuke (7003648498)","57189517376; 57196352694; 57201292783; 57239628600; 57205562134; 57189516545; 16200316400; 7003648498","GeOSR: A computer vision package for deep learning based single-frame remote sensing imagery super-resolution","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-July","","8900416","3376","3379","3","10.1109/IGARSS.2019.8900416","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088865636&doi=10.1109%2fIGARSS.2019.8900416&partnerID=40&md5=3b09292544297aa653f671fb57c62311","Recently, owing to the outstanding capability of deep learning in solving ill-posed problems, the single-frame super-resolution (SR) researches tend to focus on deep learning methods largely. However, related researches are implemented and evaluated through various datasets and different deep learning frameworks, which hinders the comparison of performance among different methods and heavily hampers the progress of SR techniques. In this study, we present GeoSR, an open source computer vision package for deep learning based single-frame remote sensing imagery super-resolution to facilitate the development of the SR community. As a unified, simple, and flexible package, GeoSR contains pipeline-like integrated tools from data retrieval to final result evaluation, which enables users to develop self-defined models conveniently; several state-of-the-art models trained through the same high-quality dataset are provided as the baseline in the package as well. Moreover, the proposed package could potentially serve as a viable backend for other related packages such as image segmentation with high efficiency. ©2019 IEEE","Computer vision; Image segmentation; Learning systems; Optical resolving power; Petroleum reservoir evaluation; Quality control; Remote sensing; Comparison of performance; Flexible packages; Ill posed problem; Learning frameworks; Remote sensing imagery; Result evaluation; Single frame super resolutions; State of the art; Deep learning","Computer vision; Deep learning; Open source; Remote sensing; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85088865636"
"Nan J.; Bo L.","Nan, Jing (56516351300); Bo, Lei (55956811800)","56516351300; 55956811800","Image super-resolution reconstructing based on generative adversarial network","2019","Proceedings of SPIE - The International Society for Optical Engineering","11342","","113420F","","","","10.1117/12.2547435","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077823628&doi=10.1117%2f12.2547435&partnerID=40&md5=5fa365531378a43b815a86ca39443f66","Image super-resolution refers to the technique of reconstructing a high-resolution image by processing one or more complementary low-resolution images. It is widely used in medical imaging, video surveillance, remote sensing imaging and other fields. The learning-based super-resolution algorithm obtains a mapping relationship between the highresolution image and the low-resolution image by learning, and then guides the generation of the high-resolution image according to the obtained mapping relationship. The generative adversarial network (GAN) is composed of a generative network model and a discriminator network model, and the two play each other until the Nash equilibrium is reached, and the texture information and the high-frequency details of the downsampled image can be restored based on the super-resolution method of generative adversarial network. However, super-resolution algorithms based on generative adversarial network can only be used for one kind of magnification time, and the versatility is insufficient. Despite convolutional neural networks has achieved breakthroughs in accuracy and speed of traditional single-frame superresolution reconstruction, and can achieve a higher peak signal-to-noise ratio (PSNR). Most of them use Mean Square Error (MSE) as the minimum optimization objective function, so although a higher peak signal-to-noise ratio can be achieved, when the image downsampling factors is higher, the reconstructed image will be too smooth, lack highfrequency details and perceptually unsatisfy in the sense that they fail to match the fidelity expected at the higher resolution. When dealing with complex data of real scenes, the model's representation ability is not high; and the generative adversarial network training is very unstable, seriously affecting the model training process. This paper is based on generative adversarial network, improving the network structure and optimizing the training method to improve the quality of generating images. The following improvements have been made to the generator model: the multi-level structure is used to enlarge the image step by step, so that the model can simultaneously generate multiple images with a larger scale, and also ensure that the image obtained at a larger magnification has higher quality; ResNet model is improved by recursive learning and residual learning, and the batch normalization structure in the model is removed. On the basis of ensuring the image quality, the efficiency of the model is effectively improved. The recursive and residual learning methods can effectively improve the feature expression ability of the model, and thus significantly improve the quality of the generated image. The Expand-Squeeze method is proposed to generate images. The basic idea is to expand the dimension of the last layer of the convolution layer of the model. In this way, more context information is obtained, and then the image is generated by using the 1x1 convolution kernel. The Expand-Squeeze method can effectively reduce the checkerboard effect and improve the quality of the generated image to some extent. This paper improves the discriminator network loss function. Measure the similarity between generated image and real image by introducing Wasserstein distance. The loss function proposed consists of two parts: the loss function of resistance and the loss function of content. The experimental results verify that the improved generation of the generative adversarial network can effectively improve the quality of the generated image and effectively improve the stability of the model training. © 2019 SPIE.","Convolution; Discriminators; Image quality; Image reconstruction; Image segmentation; Learning systems; Mapping; Mean square error; Medical imaging; Neural networks; Optical resolving power; Photonics; Remote sensing; Security systems; Signal to noise ratio; Textures; Adversarial networks; Convolutional neural network; Image super resolutions; Learning-based super-resolution; Optimization objective function; Reconstructing; ResNet; Super-resolution reconstruction; Image enhancement","Generative adversarial network; Image super-resolution; Reconstructing; ResNet","Conference paper","Final","","Scopus","2-s2.0-85077823628"
"Dănișor C.; Fornaro G.; Pauciullo A.; Datcu M.","Dănișor, Cosmin (56540042300); Fornaro, Gianfranco (7005348278); Pauciullo, Antonio (6506197276); Datcu, Mihai (7004523124)","56540042300; 7005348278; 6506197276; 7004523124","Statistical analysis for improvement of double persistent scatterers detection in SAR tomography","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8518752","6746","6749","3","10.1109/IGARSS.2018.8518752","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064172555&doi=10.1109%2fIGARSS.2018.8518752&partnerID=40&md5=1c5465f849379f29b05b294a9368dde2","Synthetic Aperture Radar (SAR) tomography presents the advantage of multiple stable targets detection within same pixel. Fast-sup-GLRT (generalized likelihood ratio test based on support estimation) algorithm proved to be an ideal compromise between detection capabilities and computational complexity. In this work, a multi-look version of this detector which exploits the advantages of Capon estimation is examined. Statistical analysis of estimation and detection processes are conducted to compare the performances of sequential non-linear least-squares (NLLS) search and Capon filtering of projected data for double PS identification. Main objective is to exploit the super-resolution advantages of NLLS method without the risk of multiple stable targets classification from the same scattering contribution. For the last desiderate, an additional verification is included within the detection step. © 2018 IEEE.","Geology; Remote sensing; Statistical methods; Tomography; Detection capability; Estimation and detection; Fast-sup-GLRT; Generalized Likelihood Ratio Test; Non linear; Persistent scatterers; Sar tomography (SARTom); Sequential non linear least squares; Synthetic aperture radar","Capon filtering; Fast-sup-GLRT; Non-Linear Lesast-Squares; PS detection; SAR Tomography","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85064172555"
"Khademi G.; Ghassemian H.","Khademi, Ghassem (56898906800); Ghassemian, Hassan (57204122949)","56898906800; 57204122949","Bayesian fusion of multispectral and panchromatic images","2018","Iranian Conference on Machine Vision and Image Processing, MVIP","2017-November","","","20","25","5","10.1109/IranianMVIP.2017.8342363","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047015066&doi=10.1109%2fIranianMVIP.2017.8342363&partnerID=40&md5=ee1e8977dabef7bf14b1ac9bced75f0c","In this paper, a model-based pansharpening method based on the super-resolution (SR) paradigm is developed. The spatial and spectral relationships between the desired high resolution multispectral (MS) image and the observed low resolution MS and panchromatic (Pan) images are combined with an appropriate image prior model via Bayesian theory. Maximum a posteriori (MAP) estimation is employed to convert the inverse problem of restoring the desired MS image into a constrained optimization problem. The final desired MS image is obtained by the conjugate gradient (CG) algorithm. Experimental results on two datasets show the effectiveness of the proposed method compared to the well-known pansharpening methods according to the quantitative evaluation metrics and visual inspection. © 2017 IEEE.","Computer vision; Constrained optimization; Inverse problems; Optical resolving power; Petroleum reservoir evaluation; Remote sensing; Conjugate gradient algorithms; Constrained optimi-zation problems; Maximum a posteriori estimation; Multispectral images; Pan-sharpening; Panchromatic (Pan) image; Quantitative evaluation; Super resolution; Image fusion","Image fusion; Maximum a posteriori (MAP) estimation; Pansharpening; Remote sensing; Super-resolution (SR)","Conference paper","Final","","Scopus","2-s2.0-85047015066"
"Ulfarsson M.O.; Dalla Mura M.","Ulfarsson, M.O. (6507677875); Dalla Mura, M. (36499129800)","6507677875; 36499129800","A low-rank method for sentinel-2 sharpening using cyclic descent","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8519256","8857","8860","3","10.1109/IGARSS.2018.8519256","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051675357&doi=10.1109%2fIGARSS.2018.8519256&partnerID=40&md5=aea1b6ee3cf15503ab4f169c2d911ece","Multiresolution optical remote sensing systems often have a spatial resolution that varies between bands. An example is the Sentinel-2 (S2) constellation which has three levels of spatial resolution 10m, 20m, and 60m. Recently, researchers have exploited the spectral/spatial correlation inherent in multispectral data to sharpen the lower resolution S2 bands. In this paper, we propose a low-rank method that formulates the sharpening process as a solution to a cost function. We develop an iterative algorithm based on cyclic descent and call it S2Sharp-CD. We evaluate the method on a simulated dataset and compare it to a state-of-the-art approach. © 2018 IEEE.","Cost functions; Data fusion; Geology; Image processing; Image resolution; Iterative methods; Optical data processing; Cyclic descents; Iterative algorithm; Multi-spectral data; Optical remote sensing; Sentinel-2 constellation; Spatial resolution; State-of-the-art approach; Super resolution; Remote sensing","Cyclic descent; Data fusion; Image processing; Sentinel-2 constellation; Superresolution","Conference paper","Final","","Scopus","2-s2.0-85051675357"
"Zhang Y.; Zhang D.; Wang T.","Zhang, Yifan (55265890500); Zhang, Duanguang (57200608414); Wang, Ting (57200774335)","55265890500; 57200608414; 57200774335","Super-Resolution Classification of Hyperspectral Images with a Small Training Set Using Semi-Supervised Learning","2018","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2018-September","","8747242","","","","10.1109/WHISPERS.2018.8747242","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073908391&doi=10.1109%2fWHISPERS.2018.8747242&partnerID=40&md5=902b499d76289b1f443c1d2771e7dc55","Classification has been one of the most important applications of Hyperspectral images (HSIs) in the past decade, because of the outstanding discrimination among different classes ensured by abundant and detailed spectral information enclosed in HSIs. While the classification accuracy must be guaranteed by plenty of training samples, which is difficult to be satisfied in many practical cases. Meanwhile, because of its comparatively low spatial resolution, mixed pixels are widely existed in HSIs which makes subpixel level classification techniques more preferable rather than traditional pixel-level ones. A novel super-resolution classification method is proposed in this paper to deal with the two above mentioned problems in HSI classification, that is, limited number of training samples and widely existed mixed pixels. Specifically, semi-supervised learning is emoployed for appropriate augmentation of training set, with which the abundance fractions for each class within a mixed pixel are estimated using collaborative representation. And finally, the classification result with higher spatial resolution is obtained with subpixel spatial attraction model based subpixel mapping. Simulative experimental results illustrate its outperformance over some stateof-the-art subpixel level classification methods. © 2018 IEEE.","Image classification; Image resolution; Machine learning; Optical resolving power; Pixels; Remote sensing; Sampling; Spectroscopy; Supervised learning; Classification accuracy; Classification technique; Collaborative representations; HyperSpectral; Semi- supervised learning; Semi-supervised; Sub pixels; Super resolution; Classification (of information)","Classification; hyperspectral; semi-supervised; subpixel; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85073908391"
"Bungert L.; Coomes D.A.; Ehrhardt M.J.; Rasch J.; Reisenhofer R.; Schönlieb C.-B.","Bungert, Leon (57192695224); Coomes, David A (6603900587); Ehrhardt, Matthias J. (55248138800); Rasch, Jennifer (57191161805); Reisenhofer, Rafael (57016735000); Schönlieb, Carola-Bibiane (24544878300)","57192695224; 6603900587; 55248138800; 57191161805; 57016735000; 24544878300","Blind image fusion for hyperspectral imaging with the directional total variation","2018","Inverse Problems","34","4","044003","","","","10.1088/1361-6420/aaaf63","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044241890&doi=10.1088%2f1361-6420%2faaaf63&partnerID=40&md5=54957d00b07fcc726583cbc62552eed5","Hyperspectral imaging is a cutting-edge type of remote sensing used for mapping vegetation properties, rock minerals and other materials. A major drawback of hyperspectral imaging devices is their intrinsic low spatial resolution. In this paper, we propose a method for increasing the spatial resolution of a hyperspectral image by fusing it with an image of higher spatial resolution that was obtained with a different imaging modality. This is accomplished by solving a variational problem in which the regularization functional is the directional total variation. To accommodate for possible mis-registrations between the two images, we consider a non-convex blind super-resolution problem where both a fused image and the corresponding convolution kernel are estimated. Using this approach, our model can realign the given images if needed. Our experimental results indicate that the non-convexity is negligible in practice and that reliable solutions can be computed using a variety of different optimization algorithms. Numerical results on real remote sensing data from plant sciences and urban monitoring show the potential of the proposed method and suggests that it is robust with respect to the regularization parameters, mis-registration and the shape of the kernel. © 2018 IOP Publishing Ltd.","Convolution; Image fusion; Image resolution; Numerical methods; Optical resolving power; Optimization; Remote sensing; Spectroscopy; Blind deconvolution; Blind Super-resolution; Directional total variations; Optimization algorithms; Pan-sharpening; Regularization parameters; Super resolution; Variational problems; Hyperspectral imaging","blind deconvolution; hyperspectral imaging; pansharpening; remote sensing; super-resolution","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85044241890"
"Jiang K.; Wang Z.; Yi P.; Jiang J.; Xiao J.; Yao Y.","Jiang, Kui (57203871718); Wang, Zhongyuan (57203515592); Yi, Peng (57203880354); Jiang, Junjun (54902306100); Xiao, Jing (55687498800); Yao, Yuan (56799491300)","57203871718; 57203515592; 57203880354; 54902306100; 55687498800; 56799491300","Deep distillation recursive network for remote sensing imagery super-resolution","2018","Remote Sensing","10","11","1700","","","","10.3390/rs10111700","59","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057124863&doi=10.3390%2frs10111700&partnerID=40&md5=888b204e7e03e18d7cf03890315024f6","Deep convolutional neural networks (CNNs) have been widely used and achieved state-of-the-art performance in many image or video processing and analysis tasks. In particular, for image super-resolution (SR) processing, previous CNN-based methods have led to significant improvements,when comparedwith shallowlearning-basedmethods. However, previous CNN-based algorithms with simple direct or skip connections are of poor performance when applied to remote sensing satellite images SR. In this study, a simple but effective CNN framework, namely deep distillation recursive network (DDRN), is presented for video satellite image SR. DDRN includes a group of ultra-dense residual blocks (UDB), a multi-scale purification unit (MSPU), and a reconstruction module. In particular, through the addition of rich interactive links in and between multiple-path units in each UDB, features extracted from multiple parallel convolution layers can be shared effectively. Compared with classical dense-connection-based models, DDRN possesses the following main properties. (1) DDRN contains more linking nodes with the same convolution layers. (2) A distillation and compensation mechanism, which performs feature distillation and compensation in different stages of the network, is also constructed. In particular, the high-frequency components lost during information propagation can be compensated in MSPU. (3) The final SR image can benefit from the feature maps extracted from UDB and the compensated components obtained from MSPU. Experiments on Kaggle Open Source Dataset and Jilin-1 video satellite images illustrate that DDRN outperforms the conventional CNN-based baselines and some state-of-the-art feature extraction approaches. © 2018 by the authors.","Convolution; Deep neural networks; Distillation; Image enhancement; Image resolution; Information dissemination; Neural networks; Optical resolving power; Satellite imagery; Video signal processing; Deep convolutional neural networks; High frequency components; Information propagation; Remote sensing imagery; Remote sensing satellites; State-of-the-art performance; Super resolution; Ultra-dense connection; Remote sensing","Compensation unit; Feature distillation; Remote sensing imagery; Super-resolution; Ultra-dense connection; Video satellite","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85057124863"
"Sanpayao M.; Kasetkasem T.; Isshiki T.; Rakwatin P.; Chanwimaluang T.","Sanpayao, Manatsawee (57200142215); Kasetkasem, Teerasit (6603233500); Isshiki, Tsuyoshi (35377141000); Rakwatin, Preesan (16418105400); Chanwimaluang, Thitiporn (6507915466)","57200142215; 6603233500; 35377141000; 16418105400; 6507915466","A super-resolution land cover mapping based on a random forest and Markov random field model","2017","ECTI-CON 2017 - 2017 14th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology","","","8096297","553","556","3","10.1109/ECTICon.2017.8096297","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039897433&doi=10.1109%2fECTICon.2017.8096297&partnerID=40&md5=218baf13103e59f025d63acad5a4d1e7","A mixed pixel in remote sensed images is a major problem, and the super-resolution mapping is one of the approach to deal with this problem. In this paper, we address the problem of super-resolution mapping by combining a set of random forests with a Markov random field (MRF) model. Here, a random forest is trained to estimate a class proportion of only one land cover class. Thus, there are equal number of random forests as the number of land cover class. Then, the MRF model is used to choose the mostly likely super-resolution map from all the possibility that yield the similar class portion. © 2017 IEEE.","Decision trees; Image classification; Image segmentation; Mapping; Markov processes; Pixels; Remote sensing; Land cover mapping; Markov Random Field model; Markov random field models; Markov Random Fields; Mixed pixel; Random forests; Super resolution; Super-resolution mappings; Optical resolving power","Image classification; Markov random field; Mixed pixels; Random forest; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85039897433"
"Yanovsky I.; Behrangi A.; Schreier M.; Dang V.; Wen B.; Lambrigtsen B.","Yanovsky, Igor (16403652300); Behrangi, Ali (26026749200); Schreier, Mathias (56219284300); Dang, Van (15131348300); Wen, Berry (57200601947); Lambrigtsen, Bjorn (6603478504)","16403652300; 26026749200; 56219284300; 15131348300; 57200601947; 6603478504","Fusion of microwave and infrared data for enhancing its spatial resolution","2017","International Geoscience and Remote Sensing Symposium (IGARSS)","2017-July","","8127533","2625","2628","3","10.1109/IGARSS.2017.8127533","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041807430&doi=10.1109%2fIGARSS.2017.8127533&partnerID=40&md5=19bdeb53684c9e144d8bdd338e4cbb88","The images acquired by microwave sensors are blurry and of low-resolution. On the other hand, the images obtained using infrared/visible sensors are of sufficiently high-resolution. In this paper, we develop a data fusion methodology and apply it to enhance resolution of a microwave image using the data from a collocated infrared/visible sensor. Such an approach takes advantage of the spatial resolution of the infrared instrument and the sensing accuracy of the microwave instrument. We tested our method using precipitation scenes captured with the Advanced Microwave Sounding Unit (AMSU) microwave instrument and the Advanced Very High Resolution Radiometer (AVHRR). © 2017 IEEE.","","Data fusion; inverse problems; microwave imaging; remote sensing; sparse optimization; spatial resolution; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85041807430"
"Belov A.M.; Denisova A.Y.","Belov, Aleksandr Mikhailovich (35482106000); Denisova, Anna Yurievna (42160925300)","35482106000; 42160925300","Spectral and spatial super-resolution method for earth remote sensing image fusion","2018","Computer Optics","42","5","","855","863","8","10.18287/2412-6179-2018-42-5-855-863","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059308978&doi=10.18287%2f2412-6179-2018-42-5-855-863&partnerID=40&md5=159fb1a2024300ebec557be7dfe756ea","In the article we propose a spatial and spectral super-resolution algorithm for a set of multichannel images obtained by various Earth remote sensing detectors. We regard the result of the algorithm as a model of an ideal data source, which has a better accuracy of the observed terrain representation than each of the input images having lower spatial and spectral resolution. The proposed algorithm utilizes a method of gradient descent and applies a refined model of image observation, including both spectral and spatial down-sampling and up-sampling. The article describes an experimental study of the proposed algorithm and a comparison of the quality of its work with bilinear interpolation of low-resolution images. The practical application of the proposed algorithm consists in the joint processing of remote sensing data of various levels, which makes it possible to erase the boundaries that arise from the design differences of imaging sensors. © 2018, Institution of Russian Academy of Sciences. All rights reserved.","Gradient methods; Image fusion; Optical resolving power; Signal receivers; Signal sampling; Down sampling and up samplings; Gradient Descent method; Regularization; Remote sensing data; Super resolution; Super resolution algorithms; Superresolution methods; Terrain representations; Remote sensing","Gradient descent method; Regularization; Remote sensing data; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85059308978"
"","","","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2017","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","","","","","","726","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037575965&partnerID=40&md5=c018efb2f3667ebc81ac021c4e923f53","The proceedings contain 158 papers. The topics discussed include: hyperspectral-based verses polarimetric-based anomaly detection in the LWIR; tree species classification with hyperspectral imaging and lidar; deep stacking network with coarse features for hyperspectral image classification; combining multiscale features for classification of hyperspectral images: a sequence-based kernel approach; ant colony optimization for super-resolution of hyperspectral images; estimating index of refraction, surface temperature, and downwelling radiance using polarimetric-hyperspectral imagery (P-HSI); hyperspectral image destriping using unmixing-based Kriging interpolation; mapping mangrove communities in coastal wetlands using airborne hyperspectral data; hyperspectral LWIR mapping of fumarole sulfates, Salton sea, Imperial County, California; measurement of a coastal area by a hyperspectral imager using an optical fiber bundle, a swing mirror and compact spectrometers; hyperspectral unmixing by reweighted low rank and total variation; integration of contextual knowledge in unsupervised sub-pixel classification; feature extraction using near-isometric linear embeddings for hyperspectral imagery classification; fusion of hyperspectral and lidar data using random feature selection and morphological attribute profiles; and sparse hyperspectral unmixing with spatial discontinuity preservation.","","","Conference review","Final","","Scopus","2-s2.0-85037575965"
"Dai Y.; Zhang J.; Porikli F.; He M.","Dai, Yuchao (24829251300); Zhang, Jing (56645651600); Porikli, Fatih (6603528219); He, Mingyi (7402609138)","24829251300; 56645651600; 6603528219; 7402609138","Salient Object Detection from Multi-spectral Remote Sensing Images with Deep Residual Network","2018","Cehui Xuebao/Acta Geodaetica et Cartographica Sinica","47","6","","873","881","8","10.11947/j.AGCS.2018.20170633","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050459942&doi=10.11947%2fj.AGCS.2018.20170633&partnerID=40&md5=21adac47e279d2c2a6573913bfa0fa1b","This paper focuses on intelligent photogrammetry deep learning: deep residual method. Salient object detection aims at identifying the visually interesting object regions that are consistent with human perception. Multispectral remote sensing images provide rich radiometric information in revealing the physical properties of the observed objects, therefore promise a great potential in salient object detection tasks. Conventional salient object detection methods often employ handcrafted features to predict saliency by evaluating the pixel-wise or superpixel-wise similarity. With the recent emergence of deep learning based approaches, in particular, fully convolutional neural networks, there has been profound progress in visual saliency detection. However, this success has not been extended to multispectral remote sensing images, and existing multispectral salient object detection methods are still mainly based on handcrafted features, essentially due to the difficulties in image acquisition and labeling. In this paper, we propose a novel deep residual network based on a top-down model, which is trained in an end-to-end manner to tackle the above issues in multispectral salient object detection. Our model effectively exploits the saliency cues at different levels of the deep residual network. To overcome the limited availability of remote sensing images in training of our deep residual network, we also introduce a new spectral image reconstruction model that can generate multispectral images from RGB images. Our extensive experimental evaluations using both multispectral and RGB salient object detection datasets demonstrate a significant performance improvement of more than 10% compared with the state-of-the-art methods. © 2018, Surveying and Mapping Press. All right reserved.","Deep learning; Feature extraction; Image reconstruction; Neural networks; Object recognition; Pixels; Remote sensing; Spectroscopy; Convolutional neural network; Multispectral remote sensing image; Remote sensing image processing; Salient object detection; Spectral image reconstruction; Super resolution; Top down models; Visual saliency detections; algorithm; artificial neural network; detection method; image processing; network analysis; numerical method; numerical model; photogrammetry; pixel; remote sensing; satellite imagery; Object detection","Deep residual network; Remote sensing image processing; Salient object detection; Spectral super-resolution; Top-down model","Article","Final","","Scopus","2-s2.0-85050459942"
"Yang X.; Xie Z.; Ling F.; Li X.; Zhang Y.; Zhong M.","Yang, Xiaohong (55683811800); Xie, Zhong (36164790400); Ling, Feng (56278268300); Li, Xiaodong (55878368700); Zhang, Yihang (55658053900); Zhong, Ming (47062345100)","55683811800; 36164790400; 56278268300; 55878368700; 55658053900; 47062345100","Spatio-temporal super-resolution land cover mapping based on fuzzy c-means clustering","2018","Remote Sensing","10","8","1212","","","","10.3390/rs10081212","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051664340&doi=10.3390%2frs10081212&partnerID=40&md5=d70103001b8559a6deea6d1e89d7518b","Super-resolution land cover mapping (SRM) is a method that aims to generate land cover maps with fine spatial resolutions from the original coarse spatial resolution remotely sensed image. The accuracy of the resultant land cover map produced by existing SRM methods is often limited by the errors of fraction images and the uncertainty of spatial pattern models. To address these limitations in this study, we proposed a fuzzy c-means clustering (FCM)-based spatio-temporal SRM (FCM_STSRM) model that combines the spectral, spatial, and temporal information into a single objective function. The spectral term is constructed with the FCM criterion, the spatial term is constructed with the maximal spatial dependence principle, and the temporal term is characterized by the land cover transition probabilities in the bitemporal land cover maps. The performance of the proposed FCM_STSRM method is assessed using data simulated from the National Land Cover Database dataset and real Landsat images. Results of the two experiments show that the proposed FCM_STSRM method can decrease the influence of fraction errors by directly using the original images as the input and the spatial pattern uncertainty by inheriting land cover information from the existing fine resolution land cover map. Compared with the hard classification and FCM_SRM method applied to mono-temporal images, the proposed FCM_STSRM method produced fine resolution land cover maps with high accuracy, thus showing the efficiency and potential of the novel approach for producing fine spatial resolution maps from coarse resolution remotely sensed images. © 2018 by the authors.","Fuzzy systems; Image resolution; Optical resolving power; Remote sensing; Fuzzy C means clustering; Land cover informations; Remotely sensed images; Spatial resolution; Spatio temporal; Super-resolution mappings; Temporal information; Transition probabilities; Mapping","Fuzzy c-means clustering; Spatio-temporal dependence; Super-resolution mapping","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85051664340"
"Zheng H.; Zeng K.; Guo D.; Ying J.; Yang Y.; Peng X.; Huang F.; Chen Z.; Qu X.","Zheng, Hong (57193161625); Zeng, Kun (56047736500); Guo, Di (26636947000); Ying, Jiaxi (57194712935); Yang, Yu (56208941100); Peng, Xi (36718260000); Huang, Feng (34872386600); Chen, Zhong (57034469300); Qu, Xiaobo (22958150800)","57193161625; 56047736500; 26636947000; 57194712935; 56208941100; 36718260000; 34872386600; 57034469300; 22958150800","Multi-Contrast Brain MRI Image Super-Resolution with Gradient-Guided Edge Enhancement","2018","IEEE Access","6","","8478767","57856","57867","11","10.1109/ACCESS.2018.2873484","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054521286&doi=10.1109%2fACCESS.2018.2873484&partnerID=40&md5=99181a6d9c33485a248192b96bd87590","In magnetic resonance imaging (MRI), the super-resolution technology has played a great role in improving image quality. The aim of this paper is to improve edges of brain MRI by incorporating the gradient information of another contrast high-resolution image. Multi-contrast images are assumed to possess the same gradient direction in a local pattern. We proposed to establish a relation model of gradient value between different contrast images to restore a high-resolution image from its input low-resolution version. The similarity of image patches is employed to estimate intensity parameters, leading a more accurate reconstructed image. Then, an iterative back-projection filter is applied to the reconstructed image to further increase the image quality. The new approach is verified on synthetic and real brain MRI images and achieves higher visual quality and higher objective quality criteria than the compared state-of-the-art super-resolution approaches. The gradient information of the multi-contrast MRI images is very useful. With a proper relation model, the proposed method enhances image edges in MRI image super-resolution. Improving the MRI image resolution from very low-resolution observations is challenging. We tackle this problem by first modeling the relation of gradient value in multi-contrast MRI and then performing fast supper-resolution methods. This relation model may be helpful for other MRI reconstruction problems. © 2013 IEEE.","Brain models; Edge detection; Image enhancement; Image quality; Image reconstruction; Image resolution; Interpolation; Iterative methods; Optical resolving power; Remote sensing; Gradient informations; High resolution image; Image edge detection; Intensity parameters; Iterative back projections; Magnetic Resonance Imaging (MRI); multi-contrast images; Super resolution; Magnetic resonance imaging","image reconstruction; MRI; multi-contrast images; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85054521286"
"Wu Y.; Zhang Y.; Zhang Y.; Huang Y.; Yang J.","Wu, Yang (57194652664); Zhang, Yin (55975581400); Zhang, Yongchao (56042343300); Huang, Yulin (23014806800); Yang, Jianyu (9239230100)","57194652664; 55975581400; 56042343300; 23014806800; 9239230100","Outline reconstruction for radar forward-looking imaging based on total variation functional deconvloution method","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8519584","7267","7270","3","10.1109/IGARSS.2018.8519584","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064192454&doi=10.1109%2fIGARSS.2018.8519584&partnerID=40&md5=225fd78b1afd0244f623d8dd60b4b031","It is great significant to achieve clear outline reconstruction for radar forward-looking imaging. In this paper, we apply the total variation (TV) function as the regularization term operator to obtain the forward-looking imaging with clear outline. Firstly, we establish the deconvolution model, by which the forward-looking super-resolution imaging problem is converted into inverse problem. Then, taking the TV function as regularization constraint term, we construct the objective function to solve the inverse problem. Finally, we obtain the minimum of the objective function, by which we can achieve radar forward-looking super-resolution imaging with clear outline. Simulations verify effectiveness of the proposed method in reconstructing the outline of targets. © 2018 IEEE.","Deconvolution; Geology; Image processing; Inverse problems; Optical resolving power; Problem solving; Radar; Remote sensing; Deconvolution models; Forward looking; Objective functions; Regularization; Regularization terms; Super resolution imaging; Total variation; Radar imaging","Clear outline reconstruction; Deconvolution; Forwardlooking imaging; Regularization; Total variation (TV)","Conference paper","Final","","Scopus","2-s2.0-85064192454"
"Wang P.; Zhang G.; Leung H.","Wang, Peng (57189493188); Zhang, Gong (35241577600); Leung, H. (7202811506)","57189493188; 35241577600; 7202811506","Utilizing parallel networks to produce sub-pixel shifted images with multiscale spatio-spectral information for soft-then-hard sub-pixel mapping","2018","IEEE Access","6","","8481509","57485","57496","11","10.1109/ACCESS.2018.2873813","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054496830&doi=10.1109%2fACCESS.2018.2873813&partnerID=40&md5=237bca49bb3fbd2990a5621f3e9d5d9e","The distribution information of the land-cover classes in remote sensing image can be explored by sub-pixel mapping (SPM) technique. The soft-then-hard sub-pixel mapping (STHSPM) has become an important type of SPM method. The sub-pixel shifted images (SSI) from the same area can be utilized to improve the mapping result. However, the type of information in the fine SSI is insufficient, and the SSI-based STHSPM results are affected. To solve this problem, utilizing parallel networks to produce sub-pixel shifted images with multiscale spatio-spectral information (SSI-MSSI) for STHSPM is proposed. In SSI-MSSI, the fine SSI with multi-scale information and spatio-spectral information are obtained, respectively, from parallel networks, namely the multiscale network and spatio-spectral network. The multiscale network is spectral unmixing followed by mixed spatio attraction model and the spatio-spectral network is projected onto convex sets super-resolution followed by spectral unmixing. There two different kinds of fine SSI are integrated by appropriate weight parameter to produce the fine fractional images. Class allocation method then allocates the class labels into to each sub-pixel by the predicted value from the integrated fine fractional images. Three remote sensing images are tested to show that the proposed SSI-MSSI produces more accurate mapping results than the existing SSI-based STHSPM in the literature. In the quantitative accuracy assessment, the SSI-MSSI shows the best performance with the percentage correctly classified of 99.09% and 74.07% in the experimental results. © 2013 IEEE.","Photomapping; Pixels; Remote sensing; Set theory; Allocation methods; Multi-scale informations; Quantitative accuracy; Remote sensing images; Spectral information; Sub pixels; Sub-pixel mapping; Weight parameters; Image enhancement","multiscale spatio-spectral information; Remote sensing image; soft-then-hard sub-pixel mapping; sub-pixel shifted images","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85054496830"
"Huang S.; Qian J.; Wang Y.; Yang X.; Yang L.","Huang, Shaoyin (57208839549); Qian, Jiang (55730664900); Wang, Yong (35868245400); Yang, Xiaobo (16557266900); Yang, Lei (57129295300)","57208839549; 55730664900; 35868245400; 16557266900; 57129295300","Through-the-wall radar super-resolution imaging based on cascade U-Net","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-January","","8900569","2933","2936","3","10.1109/IGARSS.2019.8900569","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113841133&doi=10.1109%2fIGARSS.2019.8900569&partnerID=40&md5=9dd0f6d245b68babda15723aa983c3e6","High-resolution radar imaging will give us detailed information of target, which becomes basic function of radar systems. Improvement of image resolution of the existing radar system is also important. Based on deep learning, a new method for super-resolution through-the-radar imaging is proposed. A network, called cascade U-net (CU-net), is proposed in this paper. The results of simulation and real data experiments demonstrate the effectiveness of our methods. © 2019 IEEE.","Deep learning; Image enhancement; Image resolution; Optical resolving power; Radar; Remote sensing; Basic functions; High resolution radar; Super resolution; Super resolution imaging; Through-the-wall radars; Radar imaging","Deep learning; Through-the-wall radar imaging","Conference paper","Final","","Scopus","2-s2.0-85113841133"
"Vitale S.; Ferraioli G.; Scarpa G.","Vitale, Sergio (57201522451); Ferraioli, Giampaolo (21933757700); Scarpa, Giuseppe (7004081145)","57201522451; 21933757700; 7004081145","A CNN-based model for pansharpening of worldview-3 images","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8519202","5108","5111","3","10.1109/IGARSS.2018.8519202","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063970763&doi=10.1109%2fIGARSS.2018.8519202&partnerID=40&md5=d036d772be75d347561d44c3eef7fef9","Fusing a multispectral image with a co-registered higher resolution single panchromatic band, provided by any multiresolution satellite systems, to rise the resolution of the former to that of the latter is known as pansharpening, and can be regarded as a guided super-resolution problem. Recently the use of convolutional neural networks (CNNs) has been extended to the pansharpening problem achieving state-of-the-art performance. Following this research line, the objective of this work was two-fold: provide a trained CNN model fitted to a specific sensor (WorldView-3) and explore a range of architectural configurations varied in both width and depth, seeking for the optimal one. Numerical and visual results show that the proposed solution compares favourably against reference methods. © 2018 IEEE.","Convolution; Data fusion; Geology; Learning systems; Neural networks; Numerical methods; Optical resolving power; Convolutional neural network; Higher resolution; Multispectral images; Panchromatic bands; Reference method; Satellite system; State-of-the-art performance; Super resolution; Remote sensing","Convolutional neural network; Data-fusion; Machine learning; Multi-resolution; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85063970763"
"Rosales-Guzmán C.; Belmonte A.; Torres J.P.","Rosales-Guzmán, Carmelo (55350783400); Belmonte, Aniceto (7005190487); Torres, Juan P. (7402798504)","55350783400; 7005190487; 7402798504","Complex light-assisted optical metrology techniques","2018","Proceedings of SPIE - The International Society for Optical Engineering","10549","","105490E","","","","10.1117/12.2292734","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050363417&doi=10.1117%2f12.2292734&partnerID=40&md5=eba278b5e2816a6bbbbb61acfc981aec","The on-demand tailoring of the properties of light, such as phase, polarization or spatial shape, has completely changed the landscape of photonic-based applications. In this way, complex light fields have become an ubiquitous tool in areas of research such as classical and quantum communications, optical tweezers and super-resolution microscopy, among many others. Here we will present some novel applications to optical metrology. First we will show how appropriate tailoring of the properties of light interacting with chiral molecules can enhance their chiral response by two orders of magnitude compared to circularly polarized light. As a second application, we will present a highly sensitive digital technique capable to measure layer thickness in the nanometer regime. This technique is interferometric in nature and contrary to others based on the same principle does not require the highly engineered construction of holders. Finally, we will describe a novel laser remote sensing technique that enables the direct measurement of the transverse component of velocity, a measure that up to now has relied in complicated techniques based on measurements of the longitudinal component of the velocity. This technique offers the possibility to also measure in a direct way the vorticity in fluids, a measure that is commonly measured through the curl of the fluid velocity. Copyright © 2018 SPIE.","Remote sensing; Stereochemistry; Thickness measurement; Circularly polarized light; Laser remote sensing; Longitudinal components; Optical chirality; Optical metrology techniques; Structured Light; Super-resolution microscopy; Transverse components; Optical tweezers","laser remote sensing; optical chirality; Structured light beams; thickness measurement","Conference paper","Final","","Scopus","2-s2.0-85050363417"
"Nie J.; Zhang L.; Wang C.; Wei W.; Zhang Y.","Nie, Jiangtao (57215969384); Zhang, Lei (56042339600); Wang, Cong (56664626200); Wei, Wei (56421092200); Zhang, Yanning (56075029000)","57215969384; 56042339600; 56664626200; 56421092200; 56075029000","Robust deep hyperspectral imagery super-resolution","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-July","","8900117","847","850","3","10.1109/IGARSS.2019.8900117","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089879453&doi=10.1109%2fIGARSS.2019.8900117&partnerID=40&md5=dd77f32bf2ad9049d10027f06e95b1e7","Fusing a low spatial resolution (LR) hyperspectral image (HSI) with a high spatial resolution (HR) multi-spectral image (MSI) is an effective way for HSI super-resolution. When the input LR HSI and the HR MSI are clean, most of existing fusion based methods can produce pleasing results. However, the input HSI and MSI are often corrupted with random noise in practice, which can greatly degrade the performance of these methods. To address this problem, we present a robust deep HSI super-resolution method in this study. In contrast to leveraging a heuristic shallow sparsity or low-rank prior in previous methods, we propose to employ a deep convolution neural network as the prior of the latent HR HSI. With such a prior, the fusion based HSI super-resolution can be formulated as an end-to-end deep learning problem, which can be effectively solved with the back-propagation algorithm. Due to the deep structure, the proposed image prior is able to capture more powerful statistics of the latent HR HSI, and thus can still produce pleasing results with noisy input images. Experimental results on two benchmark datasets demonstrate the effectiveness of the proposed method. ©2019 IEEE","Backpropagation; Deep learning; Deep neural networks; Image resolution; Optical resolving power; Remote sensing; Spectroscopy; Benchmark datasets; Convolution neural network; High spatial resolution; Hyper-spectral imageries; Multispectral images; Spatial resolution; Super resolution; Superresolution methods; Heuristic methods","Deep convolution neural networks; Hyperspectral image super-resolution; Unsupervised learning","Conference paper","Final","","Scopus","2-s2.0-85089879453"
"Xu W.; Xu G.; Wang Y.; Sun X.; Lin D.; Wu Y.","Xu, Wenjia (57192786946); Xu, Guangluan (56420820800); Wang, Yang (57208313225); Sun, Xian (34875643000); Lin, Daoyu (57196095251); Wu, Yirong (8403430500)","57192786946; 56420820800; 57208313225; 34875643000; 57196095251; 8403430500","deep memory connected neural network for optical remote sensing image restoration","2018","Remote Sensing","10","12","1893","","","","10.3390/rs10121893","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058871641&doi=10.3390%2frs10121893&partnerID=40&md5=78eebdd19fae60f76c9bf66388338d15","The spatial resolution and clarity of remote sensing images are crucial for many applications such as target detection and image classification. In the last several decades, tremendous image restoration tasks have shown great success in ordinary images. However, since remote sensing images are more complex and more blurry than ordinary images, most of the existing methods are not good enough for remote sensing image restoration. To address such problem, we propose a novel method named deep memory connected network (DMCN) based on the convolutional neural network to reconstruct high-quality images. We build local and global memory connections to combine image detail with global information. To further reduce parameters and ease time consumption, we propose Downsampling Units, shrinking the spatial size of feature maps. We verify its capability on two representative applications, Gaussian image denoising and single image super-resolution (SR). DMCN is tested on three remote sensing datasets with various spatial resolution. Experimental results indicate that our method yields promising improvements and better visual performance over the current state-of-the-art. The PSNR and SSIM improvements over the second best method are up to 0.3 dB. © 2018 by the authors.","Deep neural networks; Image denoising; Image resolution; Neural networks; Optical resolving power; Remote sensing; Restoration; Connected networks; Convolutional neural network; Global informations; High quality images; Optical remote sensing; Remote sensing images; Single images; Spatial resolution; Image reconstruction","Deep memory connected network; Image denoising; Image restoration; Remote sensing; Single image super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85058871641"
"Huang J.; Gao B.; Chen Y.; Chen Y.; Tong L.","Huang, Jin (57208261211); Gao, Bo (55707317600); Chen, Yan (55845912800); Chen, Yunping (35291533900); Tong, Ling (35785297000)","57208261211; 55707317600; 55845912800; 35291533900; 35785297000","Super-resolution reconstruction of multi-polarization SAR images based on projections onto convex sets algorithm","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8518557","8456","8459","3","10.1109/IGARSS.2018.8518557","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064278726&doi=10.1109%2fIGARSS.2018.8518557&partnerID=40&md5=2b468c53f85dd7ab3f47900d11d62043","Resolution is one of the important indices to measure the quality of SAR images. Super-resolution reconstruction is a widely adopted resolution enhancement method. Many algorithms have been developed for the super-resolution reconstruction. Among these algorithms, this paper applies projections onto convex sets algorithm to SAR image reconstruction processing. The POCS can efficiently obtain high-resolution SAR images with enhanced details. However, the POCS requires many low-resolution SAR images of the same area to gain a better result, usually 10 to 20 images. Such requirement is very difficult to achieve when only single-polarization mode is included. In this paper, we propose a novel method that utilizes all the polarimetric images of the same original SAR data for the algorithm. Thus, the number of the available images is increased exponentially. The experiment results have demonstrated the effectiveness of our proposed method: The reconstructed high-resolution SAR image based on multi-polarimetric information is more detailed and clearer than that based on single-polarization information. © 2018 IEEE.","Geology; Image enhancement; Image reconstruction; Optical resolving power; Polarimeters; Polarization; Remote sensing; Set theory; Synthetic aperture radar; High-resolution SAR; Multi-polarization; Polarimetric informations; Projections onto convex sets; Resolution enhancement; SAR Images; Single polarization; Super resolution reconstruction; Radar imaging","Multi-polarization information; POCS algorithm; SAR image; Super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85064278726"
"Arun P.V.; Buddhiraju K.M.; Porwal A.","Arun, P.V. (57202034266); Buddhiraju, Krishna Mohan (36815713200); Porwal, Alok (9738526000)","57202034266; 36815713200; 9738526000","Inversion of deep networks for modelling variations in spatial distributions of land cover classes across scales","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8518917","7129","7132","3","10.1109/IGARSS.2018.8518917","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064166412&doi=10.1109%2fIGARSS.2018.8518917&partnerID=40&md5=caa07670493f973885692bd48810ce6b","In this paper, we propose the use of network inversion for modeling the variation of class distributions with scale. Unlike the state of the art methods that predict the mapping between coarser and finer scale patches without considering the distributions at coarser scale, our approach uses coarser scale features for effective reconstruction. This is the pioneer work of using network inversion for the purpose. Analysis over the proposed framework reveals that both the computational performance and accuracy varies with the depth of the network as well as the size and number of filters in each layer. Also the performance of the approach has been found to improve with the increase in the number of input feature maps. Investigations over standard datasets indicate that the proposed approach performs much better than the recent sub-pixel classification as well as super resolution techniques. © 2018 IEEE.","Classification (of information); Geology; Class distributions; Computational performance; Convolution neural network; Network inversion; Scale; State-of-the-art methods; Sub-pixel classification; Super resolution; Remote sensing","Class distribution; Convolution Neural Network; Scale","Conference paper","Final","","Scopus","2-s2.0-85064166412"
"Han X.-H.; Wang J.; Shi B.; Zheng Y.; Chen Y.-W.","Han, Xian-Hua (24080007200); Wang, Jan (57201728015); Shi, Boxin (25423015500); Zheng, Yinqiang (57212267581); Chen, Yen-Wei (56036268200)","24080007200; 57201728015; 25423015500; 57212267581; 56036268200","Hyper-spectral image super-resolution using non-negative spectral representation with data-guided sparsity","2017","Proceedings - 2017 IEEE International Symposium on Multimedia, ISM 2017","2017-January","","","500","506","6","10.1109/ISM.2017.99","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045926383&doi=10.1109%2fISM.2017.99&partnerID=40&md5=d92455c41bd076ab820b5b37ae831785","Hyperspectral imaging has great potential for understanding the characteristics of different materials in many applications ranging from remote sensing to medical imaging. However, due to various hardware limitations, only low-resolution hyperspectral and high-resolution multi-spectral images can be available using existing imaging techniques. This study aims to generate a high-resolution hyperspectral image via fusion of the available LR-HS and HR-MS images. We propose a novel hyperspectral image superresolution method via non-negative sparse representation of reflectance spectral with adaptive sparsity constraint. By analyzing local content similarity of a focused pixel in the available high-resolution multi-spectral image, which can measure pixel material purity according to surrounding pixels, we generate a sparsity map for guiding non-negative sparse coding optimization procedure of the spectral representation called non-negative spectral representation with data-guided sparsity. Since the proposed method adaptively adjust the sparsity in the spectral representation based on the local content of the available high-resolution multi-spectral image, it can produce more robust spectral representation for recovering the target high-resolution hyper-spectral image. Comprehensive experiments on two public hyperspectral datasets validate that the proposed method achieves promising performances compared with the existing state of the art methods. © 2017 IEEE.","Hyperspectral imaging; Image coding; Optical resolving power; Pixels; Remote sensing; Spectroscopy; Hyper-spectral images; Image super-resolution; Multispectral images; Non-negative sparse coding; Optimization procedures; Sparse representation; Spectral representations; State-of-the-art methods; Medical imaging","","Conference paper","Final","","Scopus","2-s2.0-85045926383"
"Irmak H.; Akar G.B.; Yuksel S.E.","Irmak, Hasan (57189007589); Akar, Gozde Bozdagi (55662888100); Yuksel, Seniha Esen (13406053300)","57189007589; 55662888100; 13406053300","A MAP-Based Approach for Hyperspectral Imagery Super-Resolution","2018","IEEE Transactions on Image Processing","27","6","","2942","2951","9","10.1109/TIP.2018.2814210","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043478447&doi=10.1109%2fTIP.2018.2814210&partnerID=40&md5=76e088d41b6cd58a3a0a644cc032f6e0","In this paper, we propose a novel single image Bayesian super-resolution (SR) algorithm where the hyperspectral image (HSI) is the only source of information. The main contribution of the proposed approach is to convert the ill-posed SR reconstruction problem in the spectral domain to a quadratic optimization problem in the abundance map domain. In order to do so, Markov random field based energy minimization approach is proposed and proved that the solution is quadratic. The proposed approach consists of five main steps. First, the number of endmembers in the scene is determined using virtual dimensionality. Second, the endmembers and their low resolution abundance maps are computed using simplex identification via the splitted augmented Lagrangian and fully constrained least squares algorithms. Third, high resolution (HR) abundance maps are obtained using our proposed maximum a posteriori based energy function. This energy function is minimized subject to smoothness, unity, and boundary constraints. Fourth, the HR abundance maps are further enhanced with texture preserving methods. Finally, HR HSI is reconstructed using the extracted endmembers and the enhanced abundance maps. The proposed method is tested on three real HSI data sets; namely the Cave, Harvard, and Hyperspectral Remote Sensing Scenes and compared with state-of-the-art alternative methods using peak signal to noise ratio, structural similarity, spectral angle mapper, and relative dimensionless global error in synthesis metrics. It is shown that the proposed method outperforms the state of the art methods in terms of quality while preserving the spectral consistency. © 1992-2012 IEEE.","Constrained optimization; Glossaries; Hyperspectral imaging; Image segmentation; Markov processes; Optical resolving power; Optimization; Quadratic programming; Remote sensing; Signal to noise ratio; Spectroscopy; Structural frames; Bayes method; Bayesian super resolutions; Fully constrained least squares algorithms; Hyperspectral remote sensing; Peak signal to noise ratio; Quadratic optimization problems; Spatial resolution; Super resolution reconstruction; Image reconstruction","Hyperspectral image; MAP Framework; quadratic programming; super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85043478447"
"Aburaed N.; Panthakkan A.; Almansoori S.; Al-Ahmad H.","Aburaed, Nour (56943462800); Panthakkan, Alavi (55812242000); Almansoori, Saeed (57203361760); Al-Ahmad, Hussain (57222050810)","56943462800; 55812242000; 57203361760; 57222050810","Super resolution of DS-2 satellite imagery using deep convolutional neural network","2019","Proceedings of SPIE - The International Society for Optical Engineering","11155","","111551I","","","","10.1117/12.2533116","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078179533&doi=10.1117%2f12.2533116&partnerID=40&md5=2b905ccf0cac78140cfb7b3b35dcf426","Nowadays, Satellite images are used for various analysis, including building detection and road extraction, which are directly beneficial to governmental applications, such as urbanization and monitoring the environment. Spatial resolution is an element of crucial impact on the usage of remote sensing imagery. High spatial resolution means satellite images provide more detailed information. To improve the spatial resolution at the sensor level, many factors are ought to be taken into consideration, such as the manufacturing process. Moreover, once the satellite is launched, no further action can be taken from the perspective of hardware. Therefore, a more practical solution to improve the resolution of a satellite image is to use Single Image Super Resolution (SISR) techniques. This research proposal deals with the re-design, implementation, and evaluation of SISR technique using Deep Convolutional Neural Network with Skip Connections and Network in Network (DCSCN) for enlarging multispectral remote sensing images captured by DubaiSat-2 (DS-2) and estimating the missing high frequency details. The goal is to achieve high performance in terms of quality, and to test whether training the network using luminance channel only, which is extracted from YCbCr domain, can achieve high quality results. For this purpose, DCSCN is trained, evaluated, and tested using a dataset collected from DS-2. A single low resolution DS-2 image is used to construct its high resolution version by training the model from scratch and fine-tuning its hyper-parameters to produce optimal results. The performance is evaluated using various quality indices, such as Structural Similarity Index Measurement (SSIM), Peak Signal-to-Noise Ratio (PSNR), and Wavelet domain Signal-to-Noise Ratio (WSNR). The performance is compared to other state-of-the-art methods, such as Bil-inear, Bi-cubic, and Lanczos interpolation. © 2019 SPIE.","Convolution; Deep learning; Deep neural networks; Feature extraction; Image enhancement; Image reconstruction; Image resolution; Neural networks; Optical resolving power; Quality control; Remote sensing; Satellite imagery; Multi-spectral; Peak signal to noise ratio; Structure similarity; Super resolution; Wavelet domain; Signal to noise ratio","Deep Learning; Image Reconstruction; Multispectral; Peak Signal to Noise Ratio (PSNR); Structure Similarity Index Measurement (SSIM).; Super Resolution; Wavelet domain Signal to Noise Ratio (WSNR)","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85078179533"
"Li L.; Wang W.; Luo H.; Ying S.","Li, Lin (56304425300); Wang, Wei (57215072950); Luo, Heng (55515204300); Ying, Shen (15129278900)","56304425300; 57215072950; 55515204300; 15129278900","Super-resolution reconstruction of high-resolution satellite ZY-3 TLC images","2017","Sensors (Switzerland)","17","5","1062","","","","10.3390/s17051062","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019163555&doi=10.3390%2fs17051062&partnerID=40&md5=594b950570f4dc57bea22bf03ca87b45","Super-resolution (SR) image reconstruction is a technique used to recover a high-resolution image using the cumulative information provided by several low-resolution images. With the help of SR techniques, satellite remotely sensed images can be combined to achieve a higher-resolution image, which is especially useful for a two- or three-line camera satellite, e.g., the ZY-3 high-resolution Three Line Camera (TLC) satellite. In this paper, we introduce the application of the SR reconstruction method, including motion estimation and the robust super-resolution technique, to ZY-3 TLC images. The results show that SR reconstruction can significantly improve both the resolution and image quality of ZY-3 TLC images. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Cameras; Image processing; Motion estimation; Optical resolving power; Remote sensing; Satellites; High resolution satellites; Higher resolution images; Line cameras; Remotely sensed images; Super resolution; Super resolution reconstruction; Super-resolution image reconstruction; ZY-3; article; image quality; image reconstruction; motion; remote sensing; Image reconstruction","Image reconstruction; Remote sensing; Super-resolution; Three-line camera satellite; ZY-3","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85019163555"
"Sun J.; Lv Q.; Tan Z.; Liu Y.","Sun, Jianying (56171742300); Lv, Qunbo (55513035000); Tan, Zheng (57188729245); Liu, Yangyang (56415196500)","56171742300; 55513035000; 57188729245; 56415196500","An image sharpening strategy based on multiframe super resolution for multispectral data","2017","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","","","8071718","","","","10.1109/WHISPERS.2016.8071718","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037527553&doi=10.1109%2fWHISPERS.2016.8071718&partnerID=40&md5=5aa387f587abb13056b4a9d31d28c281","Spatial resolution is one of the most important assessments to evaluate an image. Enhancing spatial resolution consequently becomes a hot issue. As is all known, multispectral (MS) image, which is widely studied in remote sensing (RS) field, can be fused with the corresponding high-resolution panchromatic image to promote spatial-quality. In this paper, we consider the question regarding how to enhance the spatial resolution of multispectral image in the case that we do not have high-resolution panchromatic image. The only inputs are the MS data and the same spatial-resolution multi-frame panchromatic image. This paper addresses the application of super-resolution (SR) reconstruction technique and provides a suggestion for MS image sharpening. We generate a high-resolution panchromatic image based on SR. Then we adjust it and the low-resolution MS image into the same size. At last, we fuse them via a hybrid image sharpening technique. Experiments demonstrated an effective processing result and a good performance. © 2016 IEEE.","Image enhancement; Image resolution; Optical resolving power; Remote sensing; Signal processing; Spectroscopy; Image sharpening; Multi-spectral data; Multispectral images; Panchromatic images; Spatial quality; Spatial resolution; Super resolution; Super resolution reconstruction; Image processing","Image sharpening; Multispectral image; Spatial resolution; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85037527553"
"Fernandez-Beltran R.; Latorre-Carmona P.; Pla F.","Fernandez-Beltran, Ruben (55838551300); Latorre-Carmona, Pedro (35303034400); Pla, Filiberto (7006504936)","55838551300; 35303034400; 7006504936","Latent topic-based super-resolution for remote sensing","2017","Remote Sensing Letters","8","6","","498","507","9","10.1080/2150704X.2017.1287974","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034601887&doi=10.1080%2f2150704X.2017.1287974&partnerID=40&md5=21e2858f83fe0e6d24d91648f1b91d71","This letter presents a novel single-image Super-Resolution (SR) approach based on latent topics specially designed to remote sensing imagery. The proposed approach pursues to super-resolve topics uncovered from low-resolution images instead of super-resolving image patches themselves. An experimental comparison is conducted using nine different SR methods over four aerial image datasets. Experiments revealed the potential of latent topics in remote sensing SR by reporting that the proposed approach is able to provide a competitive advantage especially in low noise conditions. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","Competition; Optical resolving power; Aerial images; Competitive advantage; Experimental comparison; Image patches; Low resolution images; Remote sensing imagery; Single images; Super resolution; Remote sensing","","Letter","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85034601887"
"Yang H.; Li C.; Zhang Y.; Huang Y.; Yang J.","Yang, Haiguang (23971854200); Li, Changlin (57202954627); Zhang, Yin (55975581400); Huang, Yulin (23014806800); Yang, Jianyu (9239230100)","23971854200; 57202954627; 55975581400; 23014806800; 9239230100","Radar forward-looking superresolution imaging for sea-surface targets using Bayesian method","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8518993","8893","8896","3","10.1109/IGARSS.2018.8518993","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064158346&doi=10.1109%2fIGARSS.2018.8518993&partnerID=40&md5=9e4856880de1c4afdde101fc4634bd86","This paper presents an angular superresolution method based on maximum a posterior (MAP) criterion to improve the azimuthal resolution of forward-looking scanning radar in the background of sea clutter. Firstly, in consideration of the statistical property of sea clutter, the Rayleigh distribution is employed to express the likelihood function. And then, the generalized Gaussian constraint is used as prior information about targets for better property of noise suppression and positional accuracy. Finally, the iterative expression is derived to recover the scattering coefficient of original sea-surface targets. Compared to the conventional Bayesian approaches, The results of simulation experiment are given to verify the superior performance of proposed method. © 2018 IEEE.","Bayesian networks; Clutter (information theory); Geology; Iterative methods; Optical resolving power; Radar; Radar imaging; Remote sensing; Forward looking; Generalized Gaussian; Rayleigh distributions; Scanning radar; Scattering co-efficient; Statistical properties; Super resolution imaging; Superresolution methods; Surface waters","Forward-looking; Generalized Gaussian prior; Rayleigh distribution; Scanning radar imaging","Conference paper","Final","","Scopus","2-s2.0-85064158346"
"Li Q.; Ma W.-K.; Wu Q.","Li, Qiang (57216931780); Ma, Wing-Kin (7402703846); Wu, Qiong (57203976355)","57216931780; 7402703846; 57203976355","Hyperspectral Super-Resolution: Exact Recovery in Polynomial Time","2018","2018 IEEE Statistical Signal Processing Workshop, SSP 2018","","","8450697","378","382","4","10.1109/SSP.2018.8450697","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053852638&doi=10.1109%2fSSP.2018.8450697&partnerID=40&md5=cd00db059d573249b785f56819441547","In hyperspectral remote sensing, the hyperspectral super-resolution (HSR) problem has recently received growing interest. Simply speaking, the problem is to recover a super-resolution image-which has high spectral and spatial resolutions-from some lower spectral and spatial resolution measurements. Many of the current HSR studies consider matrix factorization formulations, with an emphasis on algorithms and performance in practice. On the other hand, the question of whether a factorization model is equipped with provable recovery guarantees of the true super-resolution image is much less explored. In this paper we show that unique and exact recovery of the super-resolution image is not only possible, it can also be done in polynomial time. We employ the matrix factorization model commonly used in the context of hyperspectral unmixing, and show that if certain local sparsity conditions are satisfied then the matrix factors constituting the true super-resolution image can be recovered by a simple two-step procedure. © 2018 IEEE.","Data fusion; Factorization; Hyperspectral imaging; Matrix algebra; Optical resolving power; Polynomial approximation; Recovery; Remote sensing; Spectroscopy; Algorithms and performance; Factorization model; Hyperspectral remote sensing; Hyperspectral unmixing; Matrix factorizations; Multispectral images; Super resolution; Two-step procedure; Image processing","data fusion; hyperspectral image; Hyperspectral super-resolution; multispectral image","Conference paper","Final","","Scopus","2-s2.0-85053852638"
"Belov A.M.; Denisova A.Y.","Belov, A.M. (35482106000); Denisova, A.Y. (42160925300)","35482106000; 42160925300","Algorithm for spectral-spatial remote sensing image super-resolution: Multi-sensor case","2019","Proceedings of SPIE - The International Society for Optical Engineering","11069","","110693L","","","","10.1117/12.2524143","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065775476&doi=10.1117%2f12.2524143&partnerID=40&md5=ea52000868fa3f584807f4c11547d315","Multi-sensor remote sensing image super-resolution aims to provide better characteristics for different types of resolution and compensate the limitations of the particular imaging systems. However, existing super-resolution techniques consider spectral and spatial resolution enhancement separately, i.e. only spatial or only spectral resolution can be enhanced. Among spatial super-resolution methods maximum a posteriori estimation approach with B-TV regularization stands out as one of the best method for spatial resolution enhancement. But existing implementations were designed only for RGB and grayscale photographic imagery. Unlike photographic RGB imagery, multispectral remote sensing images captured by optical sensors often contain more than three spectral channels (red, green and blue) and, moreover, different remote sensing systems produce a different spectral response for the similar spectral components. Therefore, a more complex image acquisition model should be regarded to take into account the variations in bandwidth and number of spectral channels in the case of remote sensing images. In this article, we propose an algorithm aiming to provide spectral-spatial multi-sensor remote sensing image super-resolution. We apply a joint spectral-spatial image acquisition model, that is typical for remote sensing systems, and investigate the super-resolution algorithm streaming from this model and the maximum a posteriori estimation approach with B-TV regularization. We propose a simple way to adapt B-TV regularization in the case of multiple spectral channels. Our experimental results confirm the enhancement in the spectral and spatial resolution of the output image in comparison with the input images. The results of our research demonstrate that the proposed method achieves both spectral and spatial super-resolution. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Image acquisition; Image enhancement; Image fusion; Image reconstruction; Image resolution; Optical data processing; Optical resolving power; Maximum a posteriori estimation; Multi sensor images; Multispectral remote sensing image; Red , green and blues; Spatial-resolution enhancement; Super resolution; Super resolution algorithms; Superresolution methods; Remote sensing","Image reconstruction; Multi-sensor image fusion; Remote sensing; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85065775476"
"Yanovsky I.; Behrangi A.; Wen Y.; Schreier M.; Dang V.; Lambrigtsen B.","Yanovsky, Igor (16403652300); Behrangi, Ali (26026749200); Wen, Yixin (45961585400); Schreier, Mathias (56219284300); Dang, Van (15131348300); Lambrigtsen, Bjorn (6603478504)","16403652300; 26026749200; 45961585400; 56219284300; 15131348300; 6603478504","Enhanced resolution of microwave sounder imagery through fusion with infrared sensor data","2017","Remote Sensing","9","11","1097","","","","10.3390/rs9111097","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034759236&doi=10.3390%2frs9111097&partnerID=40&md5=a590e540eedee0b9e06d5ed3318b2f02","The images acquired by microwave sensors are blurry and have low resolution. On the other hand, the images obtained using infrared/visible sensors are often of higher resolution. In this paper, we develop a data fusion methodology and apply it to enhance the resolution of a microwave image using the data from a collocated infrared/visible sensor. Such an approach takes advantage of the spatial resolution of the infrared instrument and the sensing accuracy of the microwave instrument. The model leverages sparsity in signals and is based on current research in sparse optimization and compressed sensing. We tested our method using a precipitation scene captured with the Advanced Microwave Sounding Unit (AMSU-B) microwave instrument and the Advanced Very High Resolution Radiometer (AVHRR) infrared instrument and compared the results to simultaneous radar observations. We show that the data fusion product is better than the original AMSU-B and AVHRR observations across all statistical indicators. © 2017 by the authors.","Advanced very high resolution radiometers (AVHRR); Data fusion; Image enhancement; Infrared detectors; Infrared instruments; Inverse problems; Microwave acoustic devices; Microwaves; Precipitation (chemical); Remote sensing; Satellite imagery; Sensor data fusion; Sounding apparatus; Advanced microwave sounding units; Enhanced resolutions; Fusion methodology; Microwave instruments; Sparse optimizations; Spatial resolution; Statistical indicators; Super resolution; Microwave sensors","Data fusion; Inverse problems; Precipitation; Remote sensing; Satellite imagery; Sparse optimization; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85034759236"
"Wang S.; Ren Y.-C.; Rao R.-Z.; Miao X.-K.","Wang, Shu (57195941347); Ren, Yi-Chong (55835996600); Rao, Rui-Zhong (7403069326); Miao, Xi-Kui (57210514217)","57195941347; 55835996600; 7403069326; 57210514217","Influence of atmosphere attenuation on quantum interferometric radar","2017","Wuli Xuebao/Acta Physica Sinica","66","15","150301","","","","10.7498/aps.66.150301","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031314585&doi=10.7498%2faps.66.150301&partnerID=40&md5=acb2cca2d13acd56aae464e772bd9b0f","There has been aroused much interest in quantum metrology such as quantum radar, due to its applications in subRaleigh ranging and remote sensing. For quantum radar, the atmospheric absorption and diffraction rapidly degrade any actively transmitted quantum states of light, such as N00N and M&M' states. Thus for the high-loss condition, the optimal strategy is to transmit coherent state of light, which can only provide sensitivity at the shot-noise limit but suffer no worse loss than the linear Beer's law for classical radar attenuation. In this paper, the target detection theory of quantum interferometric radar in the presence of photon loss is thoroughly investigated with the model of Mach-Zehnder interferometer, and the dynamic evolution of the quantum light field in the detecting process is also investigated. We utilize the parity operator to detect the return signal of quantum interferometric radar with coherent-state source. Then we compare the detection result of quantum radar with that of classical radar, which proves that the quantum radar scheme that employs coherent radiation sources and parity operator detection can provide an N-fold super-resolution, which is much below the Rayleigh diffraction limit; besides, the sensitivity of this scheme can also achieve the shot-noise-limit. Also, we analyze the effect of atmospheric attenuation on the performance of quantum radar, and find that the sensitivity is seriously influenced by atmospheric attenuation: only when the reference beam and the detection beam have the same transmissivity, will the sensitivity increase monotonically with increasing the photon number per pulse N, otherwise it first increases and then decreases with increasing N. Further, the sensivity is directly proportional to 1/√N for the first case. In conclusion, we investigate the effects of atmospheric absorption on the resolution and sensitivity of quantum radar, and find that one can overcome the harmful effects of atmospheric attenuation by adjusting the transmissivity of reference beam to the atmospheric transmittance. © 2017 Chinese Physical Society.","Coherent light; Diffraction; Interferometry; Optical resolving power; Photons; Quantum optics; Radar; Remote sensing; Shot noise; Solar radiation; Tracking radar; Atmosphere attenuation; Atmospheric absorption; Atmospheric attenuation; Atmospheric transmittance; Interferometric radars; Rayleigh diffraction limit; Sensitivity increase; Super resolution; Quantum theory","Atmospheric absorption; Quantum interferometric radar; Super-resolution","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85031314585"
"Lang Z.; Zhang L.; Wei W.; Nie J.; Tian C.; Zhang Y.","Lang, Zhiqiang (57215965018); Zhang, Lei (56042339600); Wei, Wei (56421092200); Nie, Jiangtao (57215969384); Tian, Chunna (12762595600); Zhang, Yanning (56075029000)","57215965018; 56042339600; 56421092200; 57215969384; 12762595600; 56075029000","Deep spectral super-resolution with noisy input","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-July","","8900510900510","624","627","3","10.1109/IGARSS.2019.8900510","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112698503&doi=10.1109%2fIGARSS.2019.8900510&partnerID=40&md5=67f81e0c3307c3bca658cf9d74bc4dea","Learning based methods, e.g., sparse coding or deep convolutional neural networks (DCNNs) have underpinned much of recent progress in increasing the spectral resolution of an RGB image for hyperspectral image (HSI) super-resolution. However, these methods suffer severe performance loss, when the test RGB image distributed differently from the training set, e.g., being corrupted with random noise. To mitigate this problem, we propose an unsupervised deep spectral superresolution method, which employs a DCNN to generate the latent HSI from an input RGB and encourages it to fit the input RGB image through down-sampling in spectral domain as well as a sparse gradient prior in spatial domain. Due to the powerful capacity of DCNN in capturing the low-level image statistics, the proposed method is able to automatically accommodate the noise corruption in the input RGB image. Experimental results shows the superior performance of the proposed method. © 2019 IEEE.","Convolutional neural networks; Deep neural networks; Optical resolving power; Remote sensing; Spectroscopy; Image statistics; Learning-based methods; Noise corruption; Performance loss; Spatial domains; Spectral domains; Super resolution; Superresolution methods; Image coding","Deep convolutional neural networks; Spectral super-resolution; Unsupervised learning","Conference paper","Final","","Scopus","2-s2.0-85112698503"
"Zhou X.; Chen X.; Zhang Y.","Zhou, Xinyu (57207880430); Chen, Xi (57188723896); Zhang, Ye (57214252416)","57207880430; 57188723896; 57214252416","Narrow road extraction from remote sensing images based on super-resolution convolutional neural network","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8517851","685","688","3","10.1109/IGARSS.2018.8517851","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063131462&doi=10.1109%2fIGARSS.2018.8517851&partnerID=40&md5=09a110af1bf9ea65ce436254b37712c9","In remote sensing images, it is usually hard to extract narrow roads with only several pixels width. To address this problem, the original remote sensing images are processed with super-resolution to enlarge the details of the narrow roads by a convolutional neural network method. Then the One-Class Support Vector Machine (OCSVM) classifier is applied after super-resolution for exact extraction of narrow roads. Experiments are conducted on an open dataset of remote sensing images to verify the performance of the new method and the results are compared with the method without image super-resolution. The experimental results demonstrate the validity and superiority of the new method. © 2018 IEEE","","Convolutional neural network; Narrow road extraction; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85063131462"
"Pendurkar S.; Banerjee B.; Saha S.; Bovolo F.","Pendurkar, Sumedh (57203391024); Banerjee, Biplab (55568183500); Saha, Sudipan (57205200597); Bovolo, Francesca (9943212600)","57203391024; 55568183500; 57205200597; 9943212600","Single image super-resolution for optical satellite scenes using deep deconvolutional network","2019","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11751 LNCS","","","410","420","10","10.1007/978-3-030-30642-7_37","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072981508&doi=10.1007%2f978-3-030-30642-7_37&partnerID=40&md5=1930830da23bfc4fa3c3531ac7476d01","In this paper, we deal with the problem of super-resolution (SR) imaging and propose a deep deconvolutional network based model for the same. In principle, the SR problem considers the construction of the high-resolution (HR) version of a scene given a number of so-called low-level image instances of the respective scene. Moreover, if there is a single low-resolution (LR) image available, the problem becomes even difficult and ill-posed. We deal with such a scenario and show how the popular deconvolutional network can effectively reconstruct the HR image by learning the functional mapping at the patch level. We evaluate the proposed model on a number of optical remote sensing (RS) images obtained from the UC-Merced dataset. Experimental results suggest that the proposed model consistently outperforms the existing deep and shallow models for single image SR for the RS images. © 2019, Springer Nature Switzerland AG.","Deep learning; Deep neural networks; Optical resolving power; Remote sensing; Functional mapping; Image super resolutions; Low resolution images; Network-based modeling; Optical remote sensing; Optical satellites; Satellite imaging; Super resolution; Image analysis","Deconvolutional neural networks; Deep learning; Image super resolution; Satellite imaging","Conference paper","Final","","Scopus","2-s2.0-85072981508"
"Kwan C.; Budavari B.; Gao F.; Zhu X.","Kwan, Chiman (7201421216); Budavari, Bence (57191360081); Gao, Feng (56486548700); Zhu, Xiaolin (55696724800)","7201421216; 57191360081; 56486548700; 55696724800","A hybrid color mapping approach to fusing MODIS and Landsat images for forward prediction","2018","Remote Sensing","10","4","520","","","","10.3390/rs10040520","45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044964188&doi=10.3390%2frs10040520&partnerID=40&md5=0d7bf18e52e28d63634cb00a6841251f","We present a simple, and efficient approach to fusing MODIS and Landsat images. It is well known that MODIS images have high temporal resolution and low spatial resolution, whereas Landsat images are just the opposite. Similar to earlier approaches, our goal is to fuse MODIS and Landsat images to yield high spatial and high temporal resolution images. Our approach consists of two steps. First, a mapping is established between two MODIS images, where one is at an earlier time, t1, and the other one is at the time of prediction, tp. Second, this mapping is applied to map a known Landsat image at t1 to generate a predicted Landsat image at tp. Similar to the Spatial and Temporal Adaptive Reflectance Fusion Model (STARFM), SpatioTemporal Image-Fusion Model (STI-FM), and the Flexible Spatiotemporal DAta Fusion (FSDAF) approaches, only one pair of MODIS and Landsat images is needed for prediction. Using seven performance metrics, experiments involving actual Landsat and MODIS images demonstrated that the proposed approach achieves comparable or better fusion performance than that of STARFM, STI-FM, and FSDAF. © 2018 by the authors.","Data fusion; Forecasting; Mapping; Radiometers; Remote sensing; Color mapping; High temporal resolution; LANDSAT; MODIS; Performance metrics; Spatio-temporal data; Spatiotemporal images; Super resolution; Image fusion","Data fusion; Hybrid color mapping; Landsat; MODIS; Remote sensing; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85044964188"
"Hao S.; Wang W.; Ye Y.; Li E.; Bruzzone L.","Hao, Siyuan (55554767400); Wang, Wei (57201865855); Ye, Yuanxin (36683803000); Li, Enyu (55347843600); Bruzzone, Lorenzo (7006892410)","55554767400; 57201865855; 36683803000; 55347843600; 7006892410","A Deep Network Architecture for Super-Resolution-Aided Hyperspectral Image Classification with Classwise Loss","2018","IEEE Transactions on Geoscience and Remote Sensing","56","8","","4650","4663","13","10.1109/TGRS.2018.2832228","54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048893491&doi=10.1109%2fTGRS.2018.2832228&partnerID=40&md5=709d7bbe627d6819aa0c875357440ac3","The supervised deep networks have shown great potential in improving the classification performance. However, training these supervised deep networks is very challenging for hyperspectral image given the fact that usually only a small amount of labeled samples are available. In order to overcome this problem and enhance the discriminative ability of the network, in this paper, we propose a deep network architecture for a super-resolution (SR)-aided hyperspectral image classification with classwise loss (SRCL). First, a three-layer SR convolutional neural network (SRCNN) is employed to reconstruct a high-resolution image from a low-resolution image. Second, an unsupervised triplet-pipeline CNN (TCNN) with an improved classwise loss is built to encourage intraclass similarity and interclass dissimilarity. Finally, SRCNN, TCNN, and a classification module are integrated to define the SRCL, which can be fine-tuned in an end-to-end manner with a small amount of training data. Experimental results on real hyperspectral images demonstrate that the proposed SRCL approach outperforms other state-of-the-art classification methods, especially for the task in which only a small amount of training data are available. © 1980-2012 IEEE.","Classification (of information); Convolution; Deep learning; Hyperspectral imaging; Image classification; Image enhancement; Independent component analysis; Neural networks; Optical resolving power; Remote sensing; Spectroscopy; Classification methods; Classification performance; Convolutional neural network; Discriminative ability; High resolution image; Low resolution images; State of the art; Super resolution; artificial neural network; experimental study; image analysis; image classification; remote sensing; spectral analysis; spectral resolution; supervised learning; Network architecture","Classwise loss; convolutional neural networks (CNNs); deep learning; hyperspectral image classification; remote sensing; super-resolution (SR)","Article","Final","","Scopus","2-s2.0-85048893491"
"Mullah H.U.; Deka B.; Barman T.; Prasad A.V.V.","Mullah, Helal Uddin (57188860954); Deka, Bhabesh (49663267700); Barman, Trishna (56100662400); Prasad, A.V.V. (56447855300)","57188860954; 49663267700; 56100662400; 56447855300","Sparsity Regularization Based Spatial-Spectral Super-Resolution of Multispectral Imagery","2019","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11941 LNCS","","","523","531","8","10.1007/978-3-030-34869-4_57","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076683156&doi=10.1007%2f978-3-030-34869-4_57&partnerID=40&md5=a5d79dad0e08e0a33c09788ec0ea6188","Multispectral (MS) remote sensing image is composed of several spectral bands of distinct wavelengths. Most earth observation satellites provide MS images consisting several low-resolution (LR) bands together with a single high-resolution (HR) image. A single image super-resolution (SISR) method tries to produce a HR MS output from the given LR MS input using digital image processing algorithms. In this work, we present a patch-wise sparse representation based MS image SR using a coupled overcomplete trained dictionary. The dictionary learning is carried out from patches extracted from the given HR panchromatic (PAN) image itself. Experiments are carried out using test MS images from QuickBird satellites and results are compared with other state-of-the-art MS image SR and pan-sharpening methods. © 2019, Springer Nature Switzerland AG.","Artificial intelligence; Optical resolving power; Pattern recognition; Remote sensing; Dictionary learning; Pan-sharpening; Sparse representation; Spectral information; Super resolution; Image processing","Dictionary learning; Pan-sharpening; Sparse representation; Spectral information; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85076683156"
"Zhang J.; Wang A.; An N.; Iwahori Y.","Zhang, Jitao (57190750416); Wang, Aili (55483869300); An, Na (57191039278); Iwahori, Yuji (7003339167)","57190750416; 55483869300; 57191039278; 7003339167","Superresolution approach of remote sensing images based on deep convolutional neural network","2018","International Journal of Performability Engineering","14","3","","463","472","9","10.23940/ijpe.18.03.p7.463472","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044441295&doi=10.23940%2fijpe.18.03.p7.463472&partnerID=40&md5=0c43efa019cebb027fd3dadc271f26c5","Nowadays, remote sensing images have been widely used in civil and military fields. But, because of the limitations of the current imaging sensors and complex atmospheric conditions, the resolution of remote sensing images is often low. In this paper, a superresolution reconstruction algorithm based on the deep convolution neural network to improve the resolution of the remote sensing image is proposed. First, this algorithm learned a series of features of the mapping between high and low resolution images in the training phase. This mapping is expressed as a kind of deep convolutional neural network; the trained network is a series of parameter optimization for super-resolution reconstruction of remote sensing image. Experimental results show that the superresolution algorithm proposed in this paper can keep the details subjectively and improve the evaluation index objectively. © 2018 Totem Publisher, Inc. All rights reserved.","Convolution; Deep neural networks; Image enhancement; Image reconstruction; Mapping; Military photography; Neural networks; Optical resolving power; Atmospheric conditions; Convolution neural network; Deep convolutional neural networks; Image super-resolution; Parameter optimization; Remote sensing images; Super resolution algorithms; Super-resolution reconstruction; Remote sensing","Deep convolutional neural network; Image superresolution; Parameter optimization; Remote sensing image","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85044441295"
"Deepak S.; Patra D.","Deepak, Shashikant (57216807543); Patra, Dipti (23985620900)","57216807543; 23985620900","Enhanced MRF based Super Resolution Method for Remote Sensing Images","2019","1st International Conference on Range Technology, ICORT 2019","","","9069619","","","","10.1109/ICORT46471.2019.9069619","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084756110&doi=10.1109%2fICORT46471.2019.9069619&partnerID=40&md5=9c81c7d16a263e938898da94bd3b764f","In this paper, a learning based enhanced Markov Random Field (MRF) based super resolution reconstruction (SRR) method for remote sensing image with embedded Image Euclidean distance (IMED) is proposed. A robust and transformation invariant similarity metric IMED is integrated for modelling compatibility functions (CF) and finding the similarity between image patches. Unlike traditional Euclidean distance, IMED takes into consideration the spatial relationships of pixels as well as the smallest deformation and therefore provides reasonable result. Further, an iterative belief propagation (BP) algorithm is used to find the optimal candidate patches and therefore high resolution (HR) patches. The experimental results demonstrate that the proposed method outperforms some of the state-of-The-Art methods. © 2019 IEEE.","Iterative methods; Magnetorheological fluids; Markov processes; Optical resolving power; Remote sensing; Belief propagation algorithm; Compatibility function; Remote sensing images; Spatial relationships; State-of-the-art methods; Super resolution reconstruction; Superresolution methods; Transformation invariants; Image enhancement","Belief propagation; IMED; MAP-MRF; remote sensing; Super-resolution reconstruction (SRR)","Conference paper","Final","","Scopus","2-s2.0-85084756110"
"Wu J.; He Z.; Zhuo L.","Wu, Jiemin (57211501464); He, Zhi (36604533800); Zhuo, Li (57239008700)","57211501464; 36604533800; 57239008700","Video satellite imagery super-resolution via a deep residual network","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-July","","8900265","2762","2765","3","10.1109/IGARSS.2019.8900265","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113422646&doi=10.1109%2fIGARSS.2019.8900265&partnerID=40&md5=a0e7c0a4397b0599f0dc0dd90879c140","Recently, as a new remote sensing system, video satellite develops rapidly for long-time observation. Thanks to its high temporal resolution, video satellite has been extensively used for environmental detection, especially for dynamic target monitoring. However, limited by the imaging device, it sacrifices some of its spatial resolution. Therefore, the super-resolution (SR) technology applied to these images is crucial. Based on deep residual learning, which has obtained a great success in the single-image SR, we propose a SR network structure which consists of two main steps. First, we use multi-scale feature extraction to exploit more contextual information on video satellite imagery, which is aimed at inferring high frequency components. Then, we utilize a series of residual blocks to learn the mapping between low resolution and high resolution images in a deeper and more stable network. In our experiment, the SR reconstruction results on Jinlin-1 satellite images greatly indicate the effectiveness of our method and the potential of the residual network for video satellite imagery SR. ©2019 IEEE","Deep learning; Optical resolving power; Remote sensing; Satellite imagery; Contextual information; Environmental detection; High frequency components; High resolution image; High temporal resolution; Multi-scale features; Network structures; Remote sensing system; Image reconstruction","Deep residual network; Multi-scale; Super-resolution (SR); Video satellite","Conference paper","Final","","Scopus","2-s2.0-85113422646"
"Yang F.; Ping Z.; Ma F.; Wang Y.","Yang, Feixia (57194184931); Ping, Ziliang (7005445426); Ma, Fei (55245276100); Wang, Yanwei (57213688942)","57194184931; 7005445426; 55245276100; 57213688942","Fusion of hyperspectral and multispectral images with sparse and proximal regularization","2019","IEEE Access","7","","8937525","186352","186363","11","10.1109/ACCESS.2019.2961240","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077956126&doi=10.1109%2fACCESS.2019.2961240&partnerID=40&md5=06e5bf4eed7434c1f91eb04be5ad538c","Fusion of hyperspectral and multispectral imagery data is utilized to reconstruct a super-resolution image with high spectral and spatial resolution, which plays a significant role in remote sensing image processing. Conversely, hyperspectral and multispectral data can be modeled as two low-dimensional subspaces by respectively spatially and spectrally degrading the desired image. A representative method is called coupled non-negative matrix factorization (CNMF) based on a Gaussian observation model, but it is an ill-posed inverse problem. In addition, from the perspective of matrix factorization, the matrixing process of hyperspectral and multispectral cube data generally results in the loss of structural information and performance degradation. To address these issues, this article proposes a proximal minimum-volume expression to regularize the convex simplex, enclosing all reconstructed image pixels instead of low-dimensional subspace data. Then, we incorporate sparse and proximal regularizers into the original CNMF to reformulate the fusion problem as a dynamical system via proximal alternating optimization. Finally, the alternating direction method of multipliers is adopted to split the variables for the closed-form solutions that are further reduced in computational complexity. The experimental results show that the proposed algorithm in this paper performs better than the state-of-the-art fusion methods in most cases, which verifies the effectiveness and efficiency of this proposed algorithm in yielding high-fidelity reconstructed images. © 2013 IEEE.","Data fusion; Dynamical systems; Factorization; Image fusion; Image reconstruction; Inverse problems; Remote sensing; Alternating direction method of multipliers; Alternating optimizations; Effectiveness and efficiencies; ILL-posed inverse problem; Minimum volumes; Nonnegative matrix factorization; Proximal regularization; Remote sensing image processing; Matrix algebra","alternating optimization; coupled non-negative matrix factorization; data fusion; minimum volume; Proximal regularization","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85077956126"
"","","","19th Pacific-Rim Conference on Multimedia, PCM 2018","2018","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11164 LNCS","","","","","2541","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057246470&partnerID=40&md5=64e6c86a5145909e8190f3f5dcb1b542","The proceedings contain 229 papers. The special focus in this conference is on Multimedia. The topics include: Video clip growth: A general algorithm for multi-view video summarization; cross-media retrieval via deep semantic canonical correlation analysis and logistic regression; 3D global trajectory and multi-view local motion combined player action recognition in volleyball analysis; underwater image enhancement by the combination of dehazing and color correction; a novel no-reference QoE assessment model for frame freezing of mobile video; saliency detection based on deep learning and graph cut; rethinking fusion baselines for multi-modal human action recognition; A DCT-JND profile for disorderly concealment effect; breast ultrasound image classification and segmentation using convolutional neural networks; mixup-based acoustic scene classification using multi-channel convolutional neural network; intra-image region context for image captioning; viewpoint quality evaluation for augmented virtual environment; A flower classification framework based on ensemble of CNNs; Image translation between high-resolution remote sensing optical and SAR data using conditional GAN; A combined strategy of hand tracking for desktop VR; super-resolution of text image based on conditional generative adversarial network; latitude-based visual attention in 360-degree video display; branched convolutional neural networks for face alignment; a robust approach for scene text detection and tracking in video; improving intra block copy with low-rank based rectification for urban building scenes; multimodal fusion for traditional chinese painting generation; assembly-based 3D modeling using graph convolutional neural networks; blur measurement for partially blurred images with saliency constrained global refinement; SCAN: Spatial and channel attention network for vehicle re-identification; Cross-modal retrieval with discriminative dual-path CNN.","","","Conference review","Final","","Scopus","2-s2.0-85057246470"
"Shin C.; Kim M.; Kim S.; Kim Y.","Shin, Changyeop (57214067386); Kim, Minbeom (57214075133); Kim, Sungho (57214086723); Kim, Youngjung (57207442949)","57214067386; 57214075133; 57214086723; 57207442949","Stacked lossless deconvolutional network for remote sensing image super-resolution","2019","Proceedings of SPIE - The International Society for Optical Engineering","11155","","1115509","","","","10.1117/12.2532229","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078182488&doi=10.1117%2f12.2532229&partnerID=40&md5=18e45d50067fa9ec0fe599ef09ddf181","Super-resolving a satellite imagery from its low-resolution one has a significant impact on the remote sensing industry. There are many potential applications that can directly benefit from this technique. A convolutional neural network (CNN) has recently achieved great success for image super-resolution (SR). However, most deep CNN architectures do not properly handle the inherent trade-off between localization accuracy and the use of global context. In this paper, we propose a stacked lossless deconvolutional network (SLDN) for remote sensing SR. We fully exploit global context information while guaranteeing the recovery of fine details. Specifically, we design a lossless pooling by reformulating the pixel shuffle operator, and incorporate it with a shallow deconvolutional network. The resulting lossless deconvolution blocks (LDBs) are stacked one by one to enlarge the receptive fields without any information loss. We further design an attentive skip connection to improve gradient flows throughout the LDB. The SLDN can reconstruct high-quality satellite images without noticeable artifacts. We also provide an extensive ablation study showing that all the components proposed in this paper are useful for the remote sensing SR. Experimental comparisons demonstrate the superiority of the proposed method over state-of-the-art methods both qualitatively and quantitatively. © 2019 SPIE.","Convolution; Economic and social effects; Image processing; Neural networks; Optical resolving power; Satellite imagery; Convolutional neural network; Experimental comparison; Image super resolutions; Information loss; Localization accuracy; Receptive fields; Remote sensing images; State-of-the-art methods; Remote sensing","Convolutional neural networks; Image super-resolution; Remote sensing; Satellite imagery","Conference paper","Final","","Scopus","2-s2.0-85078182488"
"Zhang X.; Xie J.; Li C.; Xu R.; Zhang Y.; Liu S.; Wang J.","Zhang, Xudong (57192605003); Xie, Jianan (57195837115); Li, Chunlai (8368630100); Xu, Rui (56733949100); Zhang, Yue (56971657300); Liu, Shijie (55724717500); Wang, Jianyu (56734123100)","57192605003; 57195837115; 8368630100; 56733949100; 56971657300; 55724717500; 56734123100","MEMS-based super-resolution remote sensing system using compressive sensing","2018","Optics Communications","426","","","410","417","7","10.1016/j.optcom.2018.05.046","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048778075&doi=10.1016%2fj.optcom.2018.05.046&partnerID=40&md5=765c799f13322a59b01c498c1be138dd","In this article we present a novel remote sensing system the resolution of which exceeds the image sensor's with the help of high-resolution MEMS device, which will reduce the cost of high-resolution image sensors. The super-resolution factors of 2 × 2 and 4×4 have been tested by simulation and remote sensing experiments. By applying the theory of compressive sensing, we can compress the acquisition data rate while preserving high image quality. We employ the IRLS as the super-resolution reconstruction method. A sample rate greater than 50% guarantees that our algorithm is more accurate. Through experiments we have found that the mismatch of the image sensor and MEMS device diminishes the image uniformity. Our algorithm embedded with non-uniformity correction greatly alleviates the problem visually and quantitatively. © 2018 Elsevier B.V.","Compressed sensing; Image sensors; Optical resolving power; Compressive sensing; High image quality; High resolution image; Non-uniformities; Nonuniformity correction; Remote sensing system; Super resolution; Super resolution reconstruction; Remote sensing","Compressive sensing; Non-uniformity; Remote sensing; Super resolution","Article","Final","","Scopus","2-s2.0-85048778075"
"Tao Y.; Muller J.-P.","Tao, Y. (56539197700); Muller, J.-P. (7404871794)","56539197700; 7404871794","Repeat multiview panchromatic super-resolution restoration using the UCL MAGiGAN system","2018","Proceedings of SPIE - The International Society for Optical Engineering","10789","","1078903","","","","10.1117/12.2500196","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059024601&doi=10.1117%2f12.2500196&partnerID=40&md5=eb5c8dab554c5cc6473c3417b6e63921","High spatial resolution imaging data is always considered desirable in the field of remote sensing, particularly Earth observation. However, given the physical constraints of the imaging instruments themselves, one needs to be able to trade-off spatial resolution against launch mass as well as telecommunications bandwidth for transmitting data back to the Earth. In this paper, we present a newly developed super-resolution restoration system, called MAGiGAN, based on our original GPT-SRR system combined with deep learning image networks to be able to restore up to 4x higher resolution enhancement using multi-angle repeat images as input. © 2018 SPIE.","Deep learning; Economic and social effects; Image enhancement; Image resolution; Observatories; Optical resolving power; Restoration; Adversarial networks; Earth observations; MAGiGAN; Multi angle; Super-resolution restoration; Remote sensing","Deep learning; Earth observation; Generative adversarial network; MAGiGAN; Multi-angle; Super-resolution restoration","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85059024601"
"Chen Y.; Ge Y.; Heuvelink G.B.M.; An R.; Chan Y.","Chen, Yuehong (56084228300); Ge, Yong (26655529300); Heuvelink, Gerard B.M. (6603849280); An, Ru (8584392800); Chan, Yu (57193862260)","56084228300; 26655529300; 6603849280; 8584392800; 57193862260","Object-based superresolution land-cover mapping from remotely sensed imagery","2018","IEEE Transactions on Geoscience and Remote Sensing","56","1","","328","340","12","10.1109/TGRS.2017.2747624","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030631128&doi=10.1109%2fTGRS.2017.2747624&partnerID=40&md5=007a6fad6b435a28685eccd86df48ed1","Superresolution mapping (SRM) is a widely used technique to address the mixed pixel problem in pixel-based classification. Advanced object-based classification will face a similar mixed phenomenon - A mixed object that contains different land-cover classes. Currently, most SRM approaches focus on estimating the spatial location of classes within mixed pixels in pixel-based classification. Little if any consideration has been given to predicting where classes spatially distribute within mixed objects. This paper, therefore, proposes a new object-based SRM strategy (OSRM) to deal with mixed objects in object-based classification. First, it uses the deconvolution technique to estimate the semivariograms at target subpixel scale from the class proportions of irregular objects. Then, an area-to-point kriging method is applied to predict the soft class values of subpixels within each object according to the estimated semivariograms and the class proportions of objects. Finally, a linear optimization model at object level is built to determine the optimal class labels of subpixels within each object. Two synthetic images and a real remote sensing image were used to evaluate the performance of OSRM. The experimental results demonstrated that OSRM generated more land-cover details within mixed objects than did the traditional object-based hard classification and performed better than an existing pixel-based SRM method. Hence, OSRM provides a valuable solution to mixed objects in object-based classification. © 2017 IEEE.","Deconvolution; Image segmentation; Interpolation; Linear programming; Mapping; Optical resolving power; Optimization; Remote sensing; Satellites; Area to point kriging; mixed object; Remotely sensed imagery; Spatial resolution; Super-resolution mappings; Pixels","Area-to-point kriging (ATPK); Deconvolution; Mixed object; Remotely sensed imagery; Superresolution mapping (SRM)","Article","Final","","Scopus","2-s2.0-85030631128"
"Chen Q.; Li Y.; Chai Y.","Chen, Qingjiang (9747105100); Li, Yi (57203137748); Chai, Yuzhou (56267005700)","9747105100; 57203137748; 56267005700","Remote sensing image fusion based on deep learning non-subsampled shearlet; [结合深度学习的非下采样剪切波遥感图像融合]","2018","Journal of Applied Optics","39","5","","655","666","11","10.5768/JAO201839.0502001","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058460507&doi=10.5768%2fJAO201839.0502001&partnerID=40&md5=fb15cee57f61cb1455ef60dc4ed61fae","Remote-sensing image fusion refers to the method of selectively and strategically combining image information with different observation characteristics obtained by different sensors to obtain a new image with better observation characteristics. A deep-sensing image fusion algorithm combined with non-subsampled shearlet transform (NSST) was proposed. In this algorithm, the spatial resolution of multi-spectral (MS) image is enhanced by an improved super-resolution reconstruction network. The panchromatic (PAN) image histogram-matched refers to each component of the reconstructed MS image. And the corresponding channel image is subjected to NSST transformation to obtain low-frequency sub-bands and several high-frequency direction sub-bands, respectively. To obtain low-frequency fusion coefficient, the low-frequency region uses an adaptive weighted average rule based on the gradient region, while the high-frequency sub-bands adopt the local spatial frequency maximum rule to obtain the high-frequency fusion coefficient, and finally the fused image can be obtained by inverse NSST transform reconstruction. The MS images City and Inland in different datasets were upsampled by the bicubic interpolation method. With the proposed algorithm, the general image quality index (UIQI) was 0.988 6 and 0.932 1, respectively, and the spectral angle mapping (SAM) was 1.872 1 and 2.143 2, respectively. Experimental results show that the image structure of the fusion algorithm in this paper is more clear, the saved spectral information is more complete, the fusion quality is better than the contrast algorithm, and the fusion image is more conducive to human visual observation. © 2018, Editorial Board, Journal of Applied Optics. All right reserved.","","Deep learning; NSST; Remote sensing image fusion; Super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85058460507"
"Han X.-H.; Shi B.; Zheng Y.","Han, Xian-Hua (24080007200); Shi, Boxin (25423015500); Zheng, Yinqiang (57212267581)","24080007200; 25423015500; 57212267581","Residual HSRCNN: Residual Hyper-Spectral Reconstruction CNN from an RGB Image","2018","Proceedings - International Conference on Pattern Recognition","2018-August","","8545634","2664","2669","5","10.1109/ICPR.2018.8545634","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059759354&doi=10.1109%2fICPR.2018.8545634&partnerID=40&md5=7f51c82ac415f1d415d003320a64c30c","Hyper-spectral imaging has great potential for understanding the characteristics of different materials in many applications ranging from remote sensing to medical imaging. However, due to various hardware limitations, only low-resolution hyper-spectral and high-resolution multi-spectral or RGB images can be captured at video rate. This study aims to generate a hyper-spectral image via enhancing spectral resolution of an RGB image, which might be easily obtained by a commodity camera. Motivated by the success of deep convolutional neural network (DCNN) for spatial resolution enhancement of natural images, we explore a spectral reconstruction CNN for spectral super-resolution with an available RGB image, which predicts the high-frequency content of the fine spectral wavelength in narrow band interval. Since the lost high-frequency content can not be perfectly recovered, by leveraging on the baseline CNN, we further propose a novel residual hyper-spectral reconstruction CNN framework to estimate the non-recovered high-frequency content (Residual) from the output of the baseline CNN. Experiments on benchmark hyper-spectral datasets validate that the proposed method achieves promising performances compared with the existing state-of-the-art methods. © 2018 IEEE.","Deep neural networks; Image enhancement; Medical imaging; Neural networks; Pattern recognition; Remote sensing; Spectroscopy; Commodity cameras; Deep convolutional neural networks; High frequency HF; Hyper-spectral images; Spatial-resolution enhancement; Spectral reconstruction; State-of-the-art methods; Super resolution; Image reconstruction","","Conference paper","Final","","Scopus","2-s2.0-85059759354"
"Tang S.","Tang, Shaofan (56517360600)","56517360600","A high spectral remote sensing method for hyperspectral imaging","2019","Proceedings of SPIE - The International Society for Optical Engineering","11023","","110232P","","","","10.1117/12.2521531","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063869607&doi=10.1117%2f12.2521531&partnerID=40&md5=a8b8d2bbb012c5af8d2e13f4dc4ce522","Spectral imaging technology is an optical technology that combines spatial optics imaging, spectroscopy and radiometry to produce images. The information cube data also contains the spatial information and fine spectral information of the ground scenery. Through the multi-information fusion detection method, we can effectively identify the disguised targets and false targets in the battlefield, therefor it is of great significance to the construction of national defense. However the spatial resolution of hyperspectral remote sensing remotely sensed by imaging mode is generally low, so it is difficult to meet the requirements of the modern war on the accuracy of military targets. Based on the above reasons, a high resolution hyperspectral imaging remote sensing method is proposed, which improves the spatial resolution to 2m, and effecteively solves the problem of detection complex targets in modern battlefield environment. © 2019 SPIE.","Image resolution; Iterative methods; Radar target recognition; Remote sensing; Spectroscopy; battlefield; Geo-stationary orbits; grating; HyperSpectral; Image motion; iterative back project; Micro-scanning; Super resolution reconstruction; Hyperspectral imaging","battlefield; geostationary orbit; grating; Hyperspectral; image motion; iterative back project; Micro scanning; Super-resolution reconstruction","Conference paper","Final","","Scopus","2-s2.0-85063869607"
"Wang P.; Wang L.; Wu Y.; Leung H.","Wang, Peng (57189493188); Wang, Liguo (55745497100); Wu, Yiquan (55850753800); Leung, Henry (7202811506)","57189493188; 55745497100; 55850753800; 7202811506","Utilizing pansharpening technique to produce sub-pixel resolution thematic map from coarse remote sensing image","2018","Remote Sensing","10","6","884","","","","10.3390/rs10060884","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048977412&doi=10.3390%2frs10060884&partnerID=40&md5=374995616028b5bd3eddff18cdc23e9b","Super-resolution mapping (SRM) is a technique to obtain sub-pixel resolution thematic map (SRTM). Soft-then-hard SRM (STHSRM) is an important SRM algorithm due to its simple physical meaning. The soft classification errors may affect the SRTM derived by STHSRM. To overcome this problem, the maximum a posteriori probability (MAP) super-resolution then hard classification (MTC) algorithm has been proposed. However, the prior information of the original image is difficult to utilize in MTC. To solve this issue, a novel method based on pansharpening then hard classification (PTC) is proposed to improve SRTM. The pansharpening technique is applied to the original coarse image to obtain the improved resolution image by suppling more prior information. The SRTM is then derived from the improved resolution image by hard classification. Not only does PTC inherit the advantages of MTC that avoids soft classification errors, but it can also incorporate more prior information from the original image into the process. Experiments based on real remote sensing images show that the proposed method can produce higher mapping accuracy than the STHSRM and MTC. It is shown that the PTC has the percentage correctly classified (PCC) in the range from 89.62% to 95.92% for the experimental dataset. © 2018 by the authors.","Classification (of information); Mapping; Maps; Optical resolving power; Pixels; Probability distributions; Remote sensing; Tracking radar; Maximum A posteriori probabilities; Pan-sharpening; Remote sensing images; Resolution images; Soft classification; Subpixel resolution; Super-resolution mappings; Thematic maps; Image enhancement","Pansharpening technique; Remote sensing image; Sub-pixel resolution thematic map; Super-resolution mapping","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85048977412"
"Ghaffar M.A.A.; Vu T.T.; Maul T.H.","Ghaffar, M.A.A. (57188717249); Vu, T.T. (7102344742); Maul, T.H. (24779754500)","57188717249; 7102344742; 24779754500","Multi-modal remote sensing data fusion framework","2017","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","4W2","","85","89","4","10.5194/isprs-archives-XLII-4-W2-85-2017","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027231134&doi=10.5194%2fisprs-archives-XLII-4-W2-85-2017&partnerID=40&md5=ac0b085180f3f98a095b31de679cb845","The inconsistency between the freely available remote sensing datasets and crowd-sourced data from the resolution perspective forms a big challenge in the context of data fusion. In classical classification problems, crowd-sourced data are represented as points that may or not be located within the same pixel. This discrepancy can result in having mixed pixels that could be unjustly classified. Moreover, it leads to failure in retaining sufficient level of details from data inferences. In this paper we propose a method that can preserve detailed inferences from remote sensing datasets accompanied with crowd-sourced data. We show that advanced machine learning techniques can be utilized towards this objective. The proposed method relies on two steps, firstly we enhance the spatial resolution of the satellite image using Convolutional Neural Networks and secondly we fuse the crowd-sourced data with the upscaled version of the satellite image. However, the covered scope in this paper is concerning the first step. Results show that CNN can enhance Landsat 8 scenes resolution visually and quantitatively. © Authors 2017.","Classification (of information); Convolution; Data fusion; Deep learning; Learning systems; Neural networks; Open source software; Open systems; Pixels; Software engineering; Convolutional neural network; Crowd-sourced data; Level of detail; Machine learning techniques; Remote sensing data fusion; Satellite images; Spatial resolution; Super resolution; Remote sensing","Convolutional neural networks; Crowd-sourced data; Data fusion; Deep learning; Super resolution","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85027231134"
"","","","19th Pacific-Rim Conference on Multimedia, PCM 2018","2018","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11165 LNCS","","","","","2541","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057222002&partnerID=40&md5=b43bc9db0a6c6dd8ce8e69bb3979fe1a","The proceedings contain 229 papers. The special focus in this conference is on Multimedia. The topics include: Video clip growth: A general algorithm for multi-view video summarization; cross-media retrieval via deep semantic canonical correlation analysis and logistic regression; 3D global trajectory and multi-view local motion combined player action recognition in volleyball analysis; underwater image enhancement by the combination of dehazing and color correction; a novel no-reference QoE assessment model for frame freezing of mobile video; saliency detection based on deep learning and graph cut; rethinking fusion baselines for multi-modal human action recognition; A DCT-JND profile for disorderly concealment effect; breast ultrasound image classification and segmentation using convolutional neural networks; mixup-based acoustic scene classification using multi-channel convolutional neural network; intra-image region context for image captioning; viewpoint quality evaluation for augmented virtual environment; A flower classification framework based on ensemble of CNNs; Image translation between high-resolution remote sensing optical and SAR data using conditional GAN; A combined strategy of hand tracking for desktop VR; super-resolution of text image based on conditional generative adversarial network; latitude-based visual attention in 360-degree video display; branched convolutional neural networks for face alignment; a robust approach for scene text detection and tracking in video; improving intra block copy with low-rank based rectification for urban building scenes; multimodal fusion for traditional chinese painting generation; assembly-based 3D modeling using graph convolutional neural networks; blur measurement for partially blurred images with saliency constrained global refinement; SCAN: Spatial and channel attention network for vehicle re-identification; Cross-modal retrieval with discriminative dual-path CNN.","","","Conference review","Final","","Scopus","2-s2.0-85057222002"
"Iftene M.; Arabi M.E.A.; Karoui M.S.","Iftene, Meziane (57192200878); Arabi, Mohammed El Amin (57211429776); Karoui, Moussa Sofiane (15750871100)","57192200878; 57211429776; 15750871100","Transfering Super Resolution Convolutional Neural Network for Remote Sensing Data Sharpening","2018","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2018-September","","8747223","","","","10.1109/WHISPERS.2018.8747223","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073894401&doi=10.1109%2fWHISPERS.2018.8747223&partnerID=40&md5=8f873bf4f7e3d14140cffc88170992b2","Pansharpening process aims at fusing low-spatial/high-spectral resolutions multispectral/hyperspectral (MS/HS) remote sensing data with high-spatial resolution and without spectral diversity panchromatic (PAN) ones.This paper explores different data preparation possibilities, learning strategies and architectures, used in the convolutional neural network (CNN) approaches, for improving the performance of the pansharpening process of remote sensing MS/HS data.Also, in this paper, the super resolution CNN (SRCNN) architecture is adapted by adding a normalization step in the training phase of the CNN-based pansharpening process. Then, training datasets are prepared for fitting the generalization need.Experiments based on multi-source datasets are performed to evaluate the performance of the proposed SRCNN-based pansharpening architecture. The preliminary results are promising since they show that the proposed approach is competitive with some literature methods. © 2018 IEEE.","Convolution; Deep learning; Deep neural networks; Fusion reactions; Image processing; Network architecture; Neural networks; Optical resolving power; Spectroscopy; Convolutional neural network; High spatial resolution; Multi-spectral; Pan-sharpening; Remote sensing data; Spectral diversity; Super resolution; Training data sets; Remote sensing","convolutional neural networks; deep learning; fusion; Multispectral/Hyperspectral imaging; pansharpening; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85073894401"
"Laurenzis M.","Laurenzis, Martin (6602922462)","6602922462","Computational sensing approaches for enhanced active imaging","2018","Proceedings of SPIE - The International Society for Optical Engineering","10796","","107960H","","","","10.1117/12.2325566","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057384210&doi=10.1117%2f12.2325566&partnerID=40&md5=dd6a21b8574130a2161891689f76901b","Computational Imaging is an emerging technology in the field of computer vision which enables optical sensing with new perception capacities and sensing approaches. In contrast to classical approaches, computational imaging uses a strong mathematical model on both part of the imaging process: The data acquisition and the data analysis. In this paper, we present examples where the principles of computational imaging are adapted to active imaging and laser gated viewing. While classical active imaging rely on the projection of a remote line of sight scene with a sensor system with specific resolution (sensor array size) and measures the time of flight due to a predefined sampling rate, we demonstrate the super-resolution time of flight or range measurement and spatial sampling beyond the sensor resolution. Further, we demonstrate the analysis of scattered photons to enhance the perception range and to obtain information on non-line-of-sight targets which are hidden from direct view. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Data acquisition; Range finding; Remote sensing; Classical approach; Computational imaging; Emerging technologies; Non-line-of-sight; Range imaging; Range measurements; Scattered photons; Sensor resolution; Optical radar","Compressed range imaging; LADAR; LiDAR; Non-line-of-sight; ranging","Conference paper","Final","","Scopus","2-s2.0-85057384210"
"Ling F.; Boyd D.; Ge Y.; Foody G.M.; Li X.; Wang L.; Zhang Y.; Shi L.; Shang C.; Li X.; Du Y.","Ling, Feng (56278268300); Boyd, Doreen (7202871470); Ge, Yong (26655529300); Foody, Giles M. (7007014233); Li, Xiaodong (55878368700); Wang, Lihui (57141007100); Zhang, Yihang (55658053900); Shi, Lingfei (57193206756); Shang, Cheng (57209801137); Li, Xinyan (36523257300); Du, Yun (56420121700)","56278268300; 7202871470; 26655529300; 7007014233; 55878368700; 57141007100; 55658053900; 57193206756; 57209801137; 36523257300; 56420121700","Measuring River Wetted Width From Remotely Sensed Imagery at the Subpixel Scale With a Deep Convolutional Neural Network","2019","Water Resources Research","55","7","","5631","5649","18","10.1029/2018WR024136","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068803010&doi=10.1029%2f2018WR024136&partnerID=40&md5=51095691d159c76a00b0b41005652d9e","River wetted width (RWW) is an important variable in the study of river hydrological and biogeochemical processes. Presently, RWW is often measured from remotely sensed imagery, and the accuracy of RWW estimation is typically low when coarse spatial resolution imagery is used because river boundaries often run through pixels that represent a region that is a mixture of water and land. Thus, when conventional hard classification methods are used in the estimation of RWW, the mixed pixel problem can become a large source of error. To address this problem, this paper proposes a novel approach to measure RWW at the subpixel scale. Spectral unmixing is first applied to the imagery to obtain a water fraction image that indicates the proportional coverage of water in image pixels. A fine spatial resolution river map from which RWW may be estimated is then produced from the water fraction image by superresolution mapping (SRM). In the SRM analysis, a deep convolutional neural network is used to eliminate the negative effects of water fraction errors and reconstruct the geographical distribution of water. The proposed approach is assessed in two experiments, with the results demonstrating that the convolutional neural network-based SRM model can effectively estimate subpixel scale details of rivers and that the accuracy of RWW estimation is substantially higher than that obtained from the use of a conventional hard image classification. The improvement shows that the proposed method has great potential to derive more accurate RWW values from remotely sensed imagery. ©2019. American Geophysical Union. All Rights Reserved.","Convolution; Geographical distribution; Image enhancement; Image resolution; Neural networks; Optical resolving power; Pixels; Remote sensing; Rivers; Wetting; Biogeochemical process; Classification methods; Convolutional neural network; Remotely sensed imagery; Spatial resolution; Spatial resolution imagery; Spectral unmixing; Super-resolution mappings; accuracy assessment; artificial nest; geographical distribution; image classification; image resolution; mapping method; pixel; remote sensing; satellite imagery; spatial resolution; Deep neural networks","convolutional neural networks; remote sensing; river wetted width; superresolution mapping","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85068803010"
"Lanaras C.; Bioucas-Dias J.; Baltsavias E.; Schindler K.","Lanaras, Charis (56568192000); Bioucas-Dias, Jose (55901520500); Baltsavias, Emmanuel (6603939930); Schindler, Konrad (8557497200)","56568192000; 55901520500; 6603939930; 8557497200","Super-Resolution of Multispectral Multiresolution Images from a Single Sensor","2017","IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops","2017-July","","8014928","1505","1513","8","10.1109/CVPRW.2017.194","53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030228739&doi=10.1109%2fCVPRW.2017.194&partnerID=40&md5=ed43e6e4c188debea8c56e80f96c0af1","Some remote sensing sensors, acquire multispectral images of different spatial resolutions in variable spectral ranges (e.g. Sentinel-2, MODIS). The aim of this research is to infer all the spectral bands, of multiresolution sensors, in the highest available resolution of the sensor. We formulate this problem as a minimisation of a convex objective function with an adaptive (edge-reserving) regulariser. The data-fitting term accounts for individual blur and downsampling per band, while the regulariser 'learns' the discontinuities from the higher resolution bands and transfers them to other bands. We also observed that the data can be represented in a lower-dimensional subspace, reducing the dimensionality of the problem and significantly improving its conditioning. In a series of experiments with simulated data, we obtain results that outperform state-of-the-art, while showing competitive qualitative results on real Sentinel-2 data. © 2017 IEEE.","Computer vision; Remote sensing; Convex objectives; Dimensional subspace; Higher resolution; Multiresolution images; Multispectral images; Remote sensing sensors; Spatial resolution; State of the art; Pattern recognition","","Conference paper","Final","","Scopus","2-s2.0-85030228739"
"Li Y.; Zhang L.; Tian C.; Ding C.; Zhang Y.; Wei W.","Li, Yong (57194455274); Zhang, Lei (56042339600); Tian, Chunna (12762595600); Ding, Chen (56440795300); Zhang, Yanning (56075029000); Wei, Wei (56421092200)","57194455274; 56042339600; 12762595600; 56440795300; 56075029000; 56421092200","Hyperspectral image super-resolution extending: An effective fusion based method without knowing the spatial transformation matrix","2017","Proceedings - IEEE International Conference on Multimedia and Expo","","","8019510","1117","1122","5","10.1109/ICME.2017.8019510","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030215782&doi=10.1109%2fICME.2017.8019510&partnerID=40&md5=d67e437342964c9e01c68c6299f52d7e","Hyperspectral image (HSI) super-resolution, a technique to obtain higher (often spatial) resolution image from the original image, has been extensively studied and applied to lots of fields such as computer vision, remote sensing, etc. Though fusion based method has achieved state-of-the-art result, it always assume the spatial transformation matrix is given in advance, whereas such a matrix is actually unknown in reality. An unsuitable given matrix will deteriorate the superresolution result greatly. To address this issue, we propose a novel fusion based HSI super-resolution method without knowing the spatial transformation matrix. Specifically, we incorporate super-resolution and spatial transformation matrix estimation into a unified framework. We alternately estimate the matrix and the higher spatial resolution HSI. We find that without given the spatial transformation matrix, the proposed method can obtain more accurate reconstruction result compared with other competing methods. Experimental results demonstrate the effectiveness of the proposed method. © 2017 IEEE.","Image fusion; Optical resolving power; Remote sensing; Spectroscopy; HyperSpectral; Image super resolutions; Resolution images; Spatial resolution; Spatial transformation; Super resolution; Superresolution methods; Unified framework; Linear transformations","Hyperspectral; Spatial transformation estimation; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85030215782"
"Shao Z.; Zhang X.; Ren J.; Li Y.","Shao, Zelong (57197734272); Zhang, Xiangkun (35390622700); Ren, Jiawei (57201579462); Li, Yingsong (36170735500)","57197734272; 35390622700; 57201579462; 36170735500","Short Range SAR Imaging for 2D Micro-Deformation Detection","2018","2018 IEEE Antennas and Propagation Society International Symposium and USNC/URSI National Radio Science Meeting, APSURSI 2018 - Proceedings","","","8608216","569","570","1","10.1109/APUSNCURSINRSM.2018.8608216","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061941294&doi=10.1109%2fAPUSNCURSINRSM.2018.8608216&partnerID=40&md5=a17c08dd9b94c3dd96199c9ebe3d0544","With the development of modern remote sensing techniques, high stability and super-resolution detection abilities are required to obtain an excellent performance in micro-deformation monitoring regions, such as civil architectures monitoring, disaster alarming and environment monitoring. A portable synthetic aperture radar (SAR) system based on interference technique and phase inversing technique is proposed and utilized for 2-D micro-deformation monitoring in this paper. Experiments are constructed to verify that the system can preciously and accurately get the micro-deformation in range direction and azimuth directions. © 2018 IEEE.","Deformation; Interferometry; Optical resolving power; Radar imaging; Remote sensing; Azimuth direction; Environment monitoring; Microdeformations; Remote sensing techniques; SAR imaging; Super resolution; Synthetic aperture radar","Interferometry; Micro-deformation; SAR; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85061941294"
"Liu X.; Zeng J.; Cai Y.","Liu, Xianlong (45961232200); Zeng, Jun (56893057100); Cai, Yangjian (7401750425)","45961232200; 56893057100; 7401750425","Review on vortex beams with low spatial coherence","2019","Advances in Physics: X","4","1","1626766","","","","10.1080/23746149.2019.1626766","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076142027&doi=10.1080%2f23746149.2019.1626766&partnerID=40&md5=d320e4e0d1f11a6d5ed327d395a88807","Vortex beams with helical phase, carrying phase singularity and orbital angular momentum, have attract great attention in the past decades due to their wide applications in optical communications, optical manipulation, super-resolution imaging and so on. Vortex beams with low spatial coherence, i.e. partially coherent vortex beams, carrying correlation singularity, display some unique properties during propagation, e.g. self-shaping, self-splitting and self-reconstruction. Partially coherent vortex beams exhibit some advantages over coherent vortex beams in some applications, such as remote sensing, laser radar and free-space optical communications. This review summarizes research progress on partially coherent vortex beams, including theoretical models, propagation properties, generation and topological charge determination. © 2019, © 2019 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","","correlation singularity; partially coherent; topological charge; Vortex beam","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85076142027"
"Jia J.; Ji L.; Zhao Y.; Geng X.","Jia, Jinrang (57202573620); Ji, Luyan (53881398700); Zhao, Yongchao (7406634598); Geng, Xiurui (14031598900)","57202573620; 53881398700; 7406634598; 14031598900","Hyperspectral image super-resolution with spectral–spatial network","2018","International Journal of Remote Sensing","39","22","","7806","7829","23","10.1080/01431161.2018.1471546","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048748508&doi=10.1080%2f01431161.2018.1471546&partnerID=40&md5=bff2093132c717548410f28238ab8959","The super-resolution problem for hyperspectral images is currently one of the most challenging topics in remote sensing. Increasingly effective methods have been presented to solve this ill-posed problem under certain circumstances. In this article, we propose a new approach named the spectral–spatial network (SSN), which can effectively increase spatial resolution while keeping spectral information. The SSN consists of two sections: a spatial section and a spectral section that contribute to enhancing spatial resolution and preserving spectral information, respectively. The spatial section is proposed to learn end-to-end mapping between single-band images, from low-resolution and high-resolution hyperspectral images. In this section, we enhance the traditional sub-pixel convolutional layer by adding a maximum variance principle that can realize nonlinear fitting through piecewise linearization. The spectral section aims to fine-tune spectral caves to keep the spectral signature with a spectral angle error loss function. In order to make the SSN converge quickly, we also develop a corresponding three-step training method. The experimental results on two databases, with both indoor and outdoor scenes, show that our proposed method performs better than the existing state-of-the-art methods. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","Image resolution; Independent component analysis; Optical resolving power; Remote sensing; Spectroscopy; Ill posed problem; Image super resolutions; Nonlinear fitting; Piecewise linearization; Spatial resolution; Spectral information; Spectral signature; State-of-the-art methods; database; error analysis; experimental study; image resolution; pixel; remote sensing; spatial analysis; spatial resolution; spectral resolution; Sanitary sewers","","Article","Final","","Scopus","2-s2.0-85048748508"
"Fan C.; Chen X.; Zhong L.; Zhou M.; Shi Y.; Duan Y.","Fan, Chong (36786139600); Chen, Xushuai (57193695531); Zhong, Lei (57193689704); Zhou, Min (57193696980); Shi, Yun (55349546900); Duan, Yulin (55349009200)","36786139600; 57193695531; 57193689704; 57193696980; 55349546900; 55349009200","Improved wallis dodging algorithm for large-scale super-resolution reconstruction remote sensing images","2017","Sensors (Switzerland)","17","3","623","","","","10.3390/s17030623","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015955979&doi=10.3390%2fs17030623&partnerID=40&md5=ad0e9facdca02d5879d3b5e2c05adf58","A sub-block algorithm is usually applied in the super-resolution (SR) reconstruction of images because of limitations in computer memory. However, the sub-block SR images can hardly achieve a seamless image mosaicking because of the uneven distribution of brightness and contrast among these sub-blocks. An effectively improved weighted Wallis dodging algorithm is proposed, aiming at the characteristic that SR reconstructed images are gray images with the same size and overlapping region. This algorithm can achieve consistency of image brightness and contrast. Meanwhile, a weighted adjustment sequence is presented to avoid the spatial propagation and accumulation of errors and the loss of image information caused by excessive computation. A seam line elimination method can share the partial dislocation in the seam line to the entire overlapping region with a smooth transition effect. Subsequently, the improved method is employed to remove the uneven illumination for 900 SR reconstructed images of ZY-3. Then, the overlapping image mosaic method is adopted to accomplish a seamless image mosaic based on the optimal seam line. © 2017 by the authors.","Image processing; Luminance; Optical resolving power; Remote sensing; Large-scale image; Optimal seams; Overlapping regions; Seam elimination; Super resolution reconstruction; Wallis dodging; Image reconstruction","Large-scale image; Optimal seam line; Overlapping region; Seam elimination; Super-resolution reconstruction; Wallis dodging","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85015955979"
"Collins C.B.; Beck J.M.; Bridges S.M.; Rushing J.A.; Graves S.J.","Collins, Charles B. (57200210305); Beck, John M. (57222176295); Bridges, Susan M. (7006956779); Rushing, John A. (7004376544); Graves, Sara J. (57203071280)","57200210305; 57222176295; 7006956779; 7004376544; 57203071280","Deep learning for multisensor image resolution enhancement","2017","Proceedings of the 1st Workshop on GeoAI: AI and Deep Learning for Geographic Knowledge Discovery, GeoAI 2017","","","","37","44","7","10.1145/3149808.3149815","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040242092&doi=10.1145%2f3149808.3149815&partnerID=40&md5=2ad3445b25152414e30abe77796641fb","We describe a deep learning convolutional neural network (CNN) for enhancing low resolution multispectral satellite imagery without the use of a panchromatic image. For training, low resolution images are used as input and corresponding high resolution images are used as the target output (label). The CNN learns to automatically extract hierarchical features that can be used to enhance low resolution imagery. The trained network can then be effectively used for super-resolution enhancement of low resolution multispectral images where no corresponding high resolution image is available. The CNN enhances all four spectral bands of the low resolution image simultaneously and adjusts pixel values of the low resolution to match the dynamic range of the high resolution image. The CNN yields higher quality images than standard image resampling methods. © 2017 Association for Computing Machinery.","Convolution; Deep learning; Deep neural networks; Image resolution; Neural networks; Optical resolving power; Remote sensing; Satellite imagery; Convolutional neural network; High resolution image; Low resolution images; Low resolution multispectral images; Low-resolution imagery; Multi-spectral; Multispectral satellite imagery; Super resolution; Image enhancement","Convolutional neural networks; Deep learning; Image resolution; Multispectral; Remote sensing; Super resolution","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85040242092"
"Mullah H.U.; Deka B.","Mullah, Helal Uddin (57188860954); Deka, Bhabesh (49663267700)","57188860954; 49663267700","A fast satellite image super-resolution technique using multicore processing","2018","Advances in Intelligent Systems and Computing","734","","","51","60","9","10.1007/978-3-319-76351-4_6","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044454329&doi=10.1007%2f978-3-319-76351-4_6&partnerID=40&md5=5d0d4506e2fa31f36fcb50e4a7a5aa2e","Sparse representation based single image super-resolution technique requires several regularization problems to be solved to generate the desired output. It is computationally intensive and needs a considerable time if we implement sequentially on a single core processor. Remote sensing applications generally require high resolution satellite images on a near real-time instant. Since, satellite images are of larger dimensions, so obtaining desired high resolution images within some practical time will be highly data intensive. Therefore, fast super-resolution based post-processing may be integrated into the existing system either in software or hardware for practical applications. In this paper, we implement an OpenMP based parallel processing technique for single image super-resolution of multispectral satellite images. Results not only show a promising speed up in the execution time but provide visually enhanced outputs as well, compared to some of the existing methods. © Springer International Publishing AG, part of Springer Nature 2018.","Application programming interfaces (API); Application programs; Intelligent systems; Multiprocessing systems; Optical resolving power; Remote sensing; Satellites; Multi-core processing; OpenMP; Satellite images; Sparse representation; Super resolution; Image processing","Multicore processing; OpenMP; Satellite image; Sparse representation; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85044454329"
"Haut J.M.; Fernandez-Beltran R.; Paoletti M.E.; Plaza J.; Plaza A.; Pla F.","Haut, Juan Mario (57215636081); Fernandez-Beltran, Ruben (55838551300); Paoletti, Mercedes E. (57027389000); Plaza, Javier (57195716301); Plaza, Antonio (7006613644); Pla, Filiberto (7006504936)","57215636081; 55838551300; 57027389000; 57195716301; 7006613644; 7006504936","A new deep generative network for unsupervised remote sensing single-image super-resolution","2018","IEEE Transactions on Geoscience and Remote Sensing","56","11","8400496","6792","6810","18","10.1109/TGRS.2018.2843525","114","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049321457&doi=10.1109%2fTGRS.2018.2843525&partnerID=40&md5=3d1981fc76e86780d56a9c4b8885f214","Super-resolution (SR) brings an excellent opportunity to improve a wide range of different remote sensing applications. SR techniques are concerned about increasing the image resolution while providing finer spatial details than those captured by the original acquisition instrument. Therefore, SR techniques are particularly useful to cope with the increasing demand remote sensing imaging applications requiring fine spatial resolution. Even though different machine learning paradigms have been successfully applied in SR, more research is required to improve the SR process without the need of external high-resolution (HR) training examples. This paper proposes a new convolutional generator model to super-resolve low-resolution (LR) remote sensing data from an unsupervised perspective. That is, the proposed generative network is able to initially learn relationships between the LR and HR domains throughout several convolutional, downsampling, batch normalization, and activation layers. Then, the data are symmetrically projected to the target resolution while guaranteeing a reconstruction constraint over the LR input image. An experimental comparison is conducted using 12 different unsupervised SR methods over different test images. Our experiments reveal the potential of the proposed approach to improve the resolution of remote sensing imagery. © 2018 IEEE.","Convolution; Data structures; Image enhancement; Image reconstruction; Image resolution; Image segmentation; Imaging techniques; Learning systems; Neural networks; Optical resolving power; Personnel training; Convolutional neural network; Experimental comparison; Remote sensing applications; Remote sensing data; Remote sensing imagery; Remote sensing imaging; Spatial resolution; Super resolution; artificial neural network; comparative study; data acquisition; experimental study; image analysis; image resolution; instrumentation; machine learning; remote sensing; satellite imagery; spatial resolution; spectral resolution; Remote sensing","Convolutional neural networks (CNNs); remote sensing; super-resolution (SR)","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85049321457"
"Wang P.; Zhang G.; Kong Y.Y.; Leung H.","Wang, P. (57189493188); Zhang, G. (35241577600); Kong, Y.Y. (35186206400); Leung, H. (7202811506)","57189493188; 35241577600; 35186206400; 7202811506","Superresolution mapping based on hybrid interpolation by parallel paths","2019","Remote Sensing Letters","10","2","","149","157","8","10.1080/2150704X.2018.1532126","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057077668&doi=10.1080%2f2150704X.2018.1532126&partnerID=40&md5=fd66e01deeac997f52e5d8d4b5e23248","Superresolution mapping (SRM) is a technology to handle mixed pixels in remote sensing image. In this letter, a novel hybrid interpolation-based SRM by parallel paths (HISRM-PP) is proposed. Firstly, the two different high resolution fractional images for each class are respectively derived by parallel paths. Then the two kinds of high resolution fractional images are integrated to produce the higher resolution fractional images by the appropriate weighting parameter. Finally, the higher resolution fractional images are utilized to obtain SRM result by class allocation. Due to the parallel paths in HISRM-PP, the more spatial-spectral information of the original image is utilized to improve the accuracy of SRM result. Experimental results on the two real remote sensing data show that HISRM-PP produces the better SRM result than the existing hybrid interpolation-based SRM (HISRM). © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","Interpolation; Mapping; Optical resolving power; Remote sensing; High resolution; Higher resolution; Original images; Parallel path; Remote sensing data; Remote sensing images; Spectral information; Super-resolution mappings; accuracy assessment; algorithm; image analysis; image resolution; interpolation; mapping method; parameter estimation; pixel; remote sensing; satellite data; spectral analysis; Image enhancement","","Article","Final","","Scopus","2-s2.0-85057077668"
"Keshk H.M.; Yin X.-C.","Keshk, Hatem Magdy (56410910400); Yin, Xu-Cheng (35319162100)","56410910400; 35319162100","Satellite super-resolution images depending on deep learning methods: A comparative study","2017","2017 IEEE International Conference on Signal Processing, Communications and Computing, ICSPCC 2017","2017-January","","","1","7","6","10.1109/ICSPCC.2017.8242625","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049241923&doi=10.1109%2fICSPCC.2017.8242625&partnerID=40&md5=f6a21c3541e6b462c7e876a5f4b2354e","The deep learning neural network is a recent development that has become the subject of research in the computer vision and remote sensing disciplines. Super resolution (SR) images can be obtained using deep neural network methods that achieve a higher performance than all previous traditional methods. Here, in this study, the objective is to describe existing deep learning methods for SR satellite images. Different satellite data are used to predict the performance of each deep learning model. This article presents a brief overview of most deep learning techniques and compares them to obtain a more effective and efficient model. The deep network cascade model outperforms other deep learning algorithms; this algorithm is dependable in the reconstruction process for obtaining SR images and overcomes some drawbacks found in traditional reconstruction algorithms. The sparse coding network method remains valuable, and with some enhancements, further improvement in results can be achieved. © 2017 IEEE.","Codes (symbols); Deep learning; Image coding; Learning algorithms; Network coding; Optical resolving power; Remote sensing; Satellites; Deep networks; Learning neural networks; Neural network method; Reconstruction algorithms; Reconstruction process; Satellite images; Sparse coding; Super resolution; Deep neural networks","Deep learning; Deep Network Cascade; Remote Sensing; Satellite Images; Sparse Coding Network; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85049241923"
"Jia G.; Zhao H.; Tao D.; Deng K.","Jia, Guorui (15762741500); Zhao, Huijie (15764291900); Tao, Dongxing (55496451100); Deng, Kewang (57193490383)","15762741500; 15764291900; 55496451100; 57193490383","Inversing reflectance of higher resolution from hyperspectral radiance data based on spectral super-resolution","2017","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2014-June","","8077618","","","","10.1109/WHISPERS.2014.8077618","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038564852&doi=10.1109%2fWHISPERS.2014.8077618&partnerID=40&md5=59427d4fdbe6891998a711cd6934017a","To promote cross-calibration or information extraction involving hyperspectral reflectance data from different sources, a method for restoring reflectance of a higher spectral resolution from hyperspectral radiance data is proposed. It involves three steps: spectral super-resolution of radiance data, transformation to the higher resolution of interest, and radiative-transfer-model-based atmospheric correction. The spectral resolution of the super-resolved radiance and the spectral response model of the restored reflectance were analyzed. The restored reflectance matches the library spectrum better than the directly inversed and the interpolated reflectance spectra in the validation experiment based on HyMap data and USGS spectral library. This method is theoretically applicable to get reflectance of a relative lower spectral resolution as well. © 2014 IEEE.","Image processing; Metadata; Optical resolving power; Radiative transfer; Reflection; Remote sensing; Restoration; Signal processing; Spectral resolution; Spectroscopy; Atmospheric corrections; Cross calibration; HyperSpectral; Hyperspectral reflectance; Radiative transfer model; Reflectance spectrum; Spectral libraries; Spectral response model; Data mining","atmospheric correction; hyperspectral; radiative transfer; spectral resolution","Conference paper","Final","","Scopus","2-s2.0-85038564852"
"Chen B.; Huang B.; Xu B.","Chen, Bin (57210117458); Huang, Bo (55388074800); Xu, Bing (7404589013)","57210117458; 55388074800; 7404589013","A hierarchical spatiotemporal adaptive fusion model using one image pair","2017","International Journal of Digital Earth","10","6","","639","655","16","10.1080/17538947.2016.1235621","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994132727&doi=10.1080%2f17538947.2016.1235621&partnerID=40&md5=88812ac5ccb6910fa973f74999ca9c26","Image fusion techniques that blend multi-sensor characteristics to generate synthetic data with fine resolutions have generated great interest within the remote sensing community. Over the past decade, although many advances have been made in the spatiotemporal fusion models, there still remain several shortcomings in existing methods. In this article, a hierarchical spatiotemporal adaptive fusion model (HSTAFM) is proposed for producing daily synthetic fine-resolution fusions. The suggested model uses only one prior or posterior image pair, especially with the aim being to predict arbitrary temporal changes. The proposed model is implemented in two stages. First, the coarse-resolution image is enhanced through super-resolution based on sparse representation; second, a pre-selection of temporal change is performed. It then adopts a two-level strategy to select similar pixels, and blends multi-sensor features adaptively to generate the final synthetic data. The results of tests using both simulated and actual observed data show that the model can accurately capture both seasonal phenology change and land-cover-type change. Comparisons between HSTAFM and other developed models also demonstrate our proposed model produces consistently lower biases. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","Image enhancement; Remote sensing; Sensor data fusion; Conversion coefficients; Image fusion techniques; Land-cover types; Resolution images; Sparse representation; Spatio-temporal fusions; Temporal change; Two-level strategies; adaptive management; analytical hierarchy process; image analysis; phenology; remote sensing; satellite data; satellite imagery; Image fusion","conversion coefficients; pre-selection of temporal change; Sparse representation; spatiotemporal fusion","Article","Final","","Scopus","2-s2.0-84994132727"
"Paris C.; Bioucas-Dias J.; Bruzzone L.","Paris, Claudia (56042202900); Bioucas-Dias, Jose (55901520500); Bruzzone, Lorenzo (7006892410)","56042202900; 55901520500; 7006892410","A Novel Sharpening Approach for Superresolving Multiresolution Optical Images","2019","IEEE Transactions on Geoscience and Remote Sensing","57","3","8472286","1545","1546","1","10.1109/TGRS.2018.2867284","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054202902&doi=10.1109%2fTGRS.2018.2867284&partnerID=40&md5=392443fc778db05349fcecb407255124","This paper aims to provide a compact superresolution formulation specific for multispectral (MS) multiresolution optical data, i.e., images characterized by different scales across different spectral bands. The proposed method, named multiresolution sharpening approach (MuSA), relies on the solution of an optimization problem tailored to the properties of those images. The superresolution problem is formulated as the minimization of an objective function containing a data-fitting term that models the blurs and downsamplings of the different bands and a patch-based regularizer that promotes image self-similarity guided by the geometric details provided by the high-resolution bands. By exploiting the approximately low-rank property of the MS data, the ill-posedness of the inverse problem in hand is strongly reduced, thus sharply improving its conditioning. The state-of-the-art color block-matching and 3D filtering (C-BM3D) image denoiser is used as a patch-based regularizer by leveraging the 'plug-and-play' framework: the denoiser is plugged into the iterations of the alternating direction method of multipliers. The main novelties of the proposed method are: 1) the introduction of an observation model tailored to the specific properties of (MS) multiresolution images and 2) the exploitation of the high-spatial-resolution bands to guide the grouping step in the color block-matching and 3D filtering (C-BM3D) denoiser, which constitutes a form of regularization learned from the high-resolution channels. The results obtained on the real and synthetic Sentinel 2 data sets give an evidence of the effectiveness of the proposed approach. © 1980-2012 IEEE.","Musa; Color; Color matching; Geometrical optics; Image denoising; Image resolution; Motion compensation; Optical resolving power; Remote sensing; Satellite imagery; Alternating direction method of multiplier (ADMM); Bayes method; Block matching and 3d filtering; Dimensionality reduction; Image color analysis; MODIS; Multiresolution images; Optical imaging; Plug and play; Self-similarities; Signal resolution; Spatial resolution; Super resolution; data set; geometry; image analysis; inverse problem; numerical model; optical method; optimization; remote sensing; spectral resolution; three-dimensional modeling; Inverse problems","Alternating direction method of multipliers (ADMM); color block-matching and 3D filtering (C-BM3D); dimensionality reduction; multispectral (MS) multiresolution images; plug-and-play; remote sensing; self-similarity; superresolution","Article","Final","","Scopus","2-s2.0-85054202902"
"Mareboyana M.; Le Moigne J.","Mareboyana, Manohar (7007068388); Le Moigne, Jaqueline (55664867700)","7007068388; 55664867700","Super-resolution of remote sensing images using edge-directed radial basis functions","2018","Proceedings of SPIE - The International Society for Optical Engineering","10646","","1064610","","","","10.1117/12.2303732","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049159073&doi=10.1117%2f12.2303732&partnerID=40&md5=4110f0d1bc6c8ed4d6414ed66635172b","Edge-Directed Radial Basis Functions (EDRBF) are used to compute super resolution(SR) image from a given set of low resolution (LR) images differing in subpixel shifts. The algorithm is tested on remote sensing images and compared for accuracy with other well-known algorithms such as Iterative Back Projection (IBP), Maximum Likelihood (ML) algorithm, interpolation of scattered points using Nearest Neighbor (NN) and Inversed Distance Weighted (IDW) interpolation, and Radial Basis Functin(RBF). The accuracy of SR depends on various factors besides the algorithm (i) number of subpixel shifted LR images (ii) accuracy with which the LR shifts are estimated by registration algorithms (iii) and the targeted spatial resolution of SR. In our studies, the accuracy of EDRBF is compared with other algorithms keeping these factors constant. The algorithm has two steps: i) registration of low resolution images and (ii) estimating the pixels in High Resolution (HR) grid using EDRBF. Experiments are conducted by simulating LR images from a input HR image with different sub-pixel shifts. The reconstructed SR image is compared with input HR image to measure the accuracy of the algorithm using sum of squared errors (SSE). The algorithm has outperformed all of the algorithms mentioned above. The algorithm is robust and is not overly sensitive to the registration inaccuracies. © 2018 SPIE.","Functions; Interpolation; Maximum likelihood; Optical resolving power; Pixels; Radial basis function networks; Remote sensing; Signal processing; Iterative back projections; Low resolution images; Maximum likelihood algorithm; Radial basis functions; Registration algorithms; Remote sensing images; Sum of squared errors; Super resolution; Iterative methods","Edge-Directeed Radial Basis Functions; Radial Basis Functions; Super Resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85049159073"
"Qin J.; Yanovsky I.","Qin, Jing (53980312700); Yanovsky, Igor (16403652300)","53980312700; 16403652300","Robust super-resolution image reconstruction method for geometrically deformed remote sensing images","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8518056","8050","8053","3","10.1109/IGARSS.2018.8518056","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063138583&doi=10.1109%2fIGARSS.2018.8518056&partnerID=40&md5=a2779f344a52bfcfc88928774277e812","Due to the limitations of imaging sensors, remote sensing images often have limited resolution. To address this issue, various super-resolution (SR) image reconstruction techniques have been developed to reconstruct a high-resolution image from a sequence of low-resolution, noisy and blurry observations. In this paper, we propose an efficient super-resolution image reconstruction method for geometrically deformed remote sensing images, based on the nonlocal total variation (NLTV) regularization. The proposed minimization problem is solved by a fast primal-dual algorithm. Numerical experiments demonstrate the performance of the proposed method. © 2018 IEEE","","Primal-dual algorithm; Remote sensing images; Super-resolution image reconstruction","Conference paper","Final","","Scopus","2-s2.0-85063138583"
"Qin X.; Gao X.; Yue K.","Qin, Xing (8305782400); Gao, Xiaoqi (57215861251); Yue, Keqiang (35786745000)","8305782400; 57215861251; 35786745000","Remote Sensing Image Super-Resolution using Multi-Scale Convolutional Neural Network","2018","11th UK-Europe-China Workshop on Millimeter Waves and Terahertz Technologies, UCMMT 2018 - Proceedings","","","9015801","","","","10.1109/UCMMT45316.2018.9015801","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082131511&doi=10.1109%2fUCMMT45316.2018.9015801&partnerID=40&md5=776b512048330c47615174be34b49eda","Remote sensing images have advantages in large-area imaging and macroscopic integrity. However, in most commercial applications, further recognition and processing becomes difficult due to the low spatial resolution of the acquired images. Therefore, improving the resolution of remote sensing images has important practical significance. To solve this problem, we propose a remote sensing image super-resolution method based on deep learning technology. In order to obtain more detailed image information, we introduce multi-scale convolution to implement feature extraction and deconvolution be used to achieve the final 3× image reconstruction without bicubic interpolation. Experimental results show that our network achieves better performance than prior art methods and visual improvement of our results is easily noticeable. © 2018 IEEE.","Arts computing; Convolution; Convolutional neural networks; Deep learning; Image enhancement; Image reconstruction; Millimeter waves; Optical resolving power; Terahertz waves; Bicubic interpolation; Commercial applications; Detailed images; Learning technology; Prior arts; Remote sensing images; Spatial resolution; Visual improvements; Remote sensing","","Conference paper","Final","","Scopus","2-s2.0-85082131511"
"Li W.; Lv Q.; Liu Y.; Zhang D.; Zhao N.; Fang Y.","Li, Weiyan (55232640100); Lv, Qunbo (55513035000); Liu, Yangyang (56415196500); Zhang, Dandan (57191521441); Zhao, Na (57202341029); Fang, Yu (55617605200)","55232640100; 55513035000; 56415196500; 57191521441; 57202341029; 55617605200","Structure system design of super-resolution space camera","2019","Proceedings of SPIE - The International Society for Optical Engineering","11032","","110320O","","","","10.1117/12.2523245","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068321034&doi=10.1117%2f12.2523245&partnerID=40&md5=8203868185b7e5bfee7ee78a7bab9ef0","With the rapid development of microelectronics, nanotechnology and integrated design concept, the trend of satellite miniaturization is becoming more and more obvious, and the high resolution of small satellites is enhanced, and the capability of remote sensing is the forward position to promote space exploration and technological innovation. For the telephoto optical system, the influence of the spatial thermal environment changes and the change of the gravity field before and after the launch will change the focal length of the optical system, resulting in blurred image, so the need for focusing the focus parts to focus. According to the overall technical requirements of the satellite, a small-scale super-resolution spatial camera system based on the traditional Cass-grain optical system is designed. The modal, sinusoidal vibration and random vibration of the system are simulated by mechanical simulation software. The results shows that the mechanical properties of the system are good. The load has been successfully launched and a good image effect has been achieved. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Cameras; Computer software; Microelectronics; Optical resolving power; Optical systems; Remote sensing; Small satellites; Space research; X ray optics; Integrated designs; Mechanical simulations; Sinusoidal vibration; Space explorations; Super resolution; Technical requirement; Technological innovation; Thermal environment; Vibrations (mechanical)","Structure system; super-resolution space camera; mechanical simulation analysis","Conference paper","Final","","Scopus","2-s2.0-85068321034"
"Zaitseva E.; Piestova I.; Rabcan J.; Rusnak P.","Zaitseva, Elena (16481714700); Piestova, Iryna (57195922301); Rabcan, Jan (57057844100); Rusnak, Patrik (57195920975)","16481714700; 57195922301; 57057844100; 57195920975","Multiple-Valued and Fuzzy Logics Application to Remote Sensing Data Analysis","2018","2018 26th Telecommunications Forum, TELFOR 2018 - Proceedings","","","8612109","","","","10.1109/TELFOR.2018.8612109","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062093296&doi=10.1109%2fTELFOR.2018.8612109&partnerID=40&md5=97995440dcf451a7a69f73f17355e4d7","The main goal of this paper is to justify the use of multiple-valued and fuzzy logics for the problem of increasing the spatial resolution of multi-spectral satellite images. Additionally, we present our solution based on the fuzzy clastering of the image by spectral signatures and the subpixel's values reallocating. In our solution, we are taking into account spatial topology relationships for each study type of land cover. © 2018 IEEE.","Fuzzy clustering; Fuzzy logic; Pixels; Remote sensing; Multiple-valued; Multispectral satellite image; Remote sensing data; Spatial resolution; Spatial topologies; Spectral signature; Sub pixels; Super resolution; Many valued logics","Fuzzy clustering; Multispectral imagery superresolution; Multivalued logic; Subpixel reallocating","Conference paper","Final","","Scopus","2-s2.0-85062093296"
"Nikonorov A.; Petrov M.; Bibikov S.; Kutikova V.; Yakimov P.; Morozov A.; Skidanov R.; Kazanskiy N.","Nikonorov, Artem (36810443400); Petrov, Maksim (55746564400); Bibikov, Sergey (36809179400); Kutikova, Viktoria (57031823700); Yakimov, Pavel (40462885200); Morozov, Andrey (57198055418); Skidanov, Roman (6603643112); Kazanskiy, Nikolay (35581405600)","36810443400; 55746564400; 36809179400; 57031823700; 40462885200; 57198055418; 6603643112; 35581405600","Deep learning-based enhancement of hyperspectral images using simulated ground truth","2018","2018 10th IAPR Workshop on Pattern Recognition in Remote Sensing, PRRS 2018","","","8486408","","","","10.1109/PRRS.2018.8486408","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056493043&doi=10.1109%2fPRRS.2018.8486408&partnerID=40&md5=1afef7afa6d2e341cb9545ae0e545dbc","The paper addresses the problem of imaging quality enhancement for the Offner hyperspectrometer using a convolutional neural network. We use a deep convolutional neural network with residual training and PReLU activation, inspired by the super-resolution task for RGB images. In the case of hyperspectral imaging, it is often a problem to find a large enough ground truth dataset for training a neural network from scratch. Transfer learning using the network pretrained for RGB images with some pre- and postprocessing is one of the possible workarounds. In this paper, we propose to simulate the necessary ground truth data using non-imaging spectrometer. The obtained dataset with partially simulated ground truth is then used to train the convolutional neural network directly for hyperspectral image quality enhancement. The proposed training approach also allows to incorporate distortions specific for hyperspectral images into the enhancement procedure. It allows to successfully remove the striping distortions inherent to the Offner scheme of image acquisition. The experimental results of the proposed approach show a significant quality gain. © 2018 IEEE.","Convolution; Deep neural networks; Hyperspectral imaging; Image quality; Independent component analysis; Neural networks; Pattern recognition; Quality control; Remote sensing; Spectroscopy; Convolutional neural network; Deep convolutional neural networks; Ground truth data; Ground-truth dataset; Imaging quality; Offner scheme; Super resolution; Transfer learning; Image enhancement","Convolutional neural networks; Hyperspectral image enhancement; Imaging hyperspectrometer; Offner scheme; Training from scratch","Conference paper","Final","","Scopus","2-s2.0-85056493043"
"Tao Y.; Muller J.-P.","Tao, Y. (56539197700); Muller, J.-P. (7404871794)","56539197700; 7404871794","Super-resolution restoration of spaceborne HD videos using the UCL MAGiGAN system","2019","Proceedings of SPIE - The International Society for Optical Engineering","11155","","1115508","","","","10.1117/12.2532889","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078198191&doi=10.1117%2f12.2532889&partnerID=40&md5=828817e6907aad33d8482ac8726058cf","We developed a novel SRR system, called Multi-Angle Gotcha image restoration with Generative Adversarial Network (MAGiGAN), to produce resolution enhancement of 3-5 times from multi-pass EO images. The MAGiGAN SRR system uses a combination of photogrammetric and machine vision approaches including image segmentation and shadow labelling, feature matching and densification, estimation of an image degradation model, and deep learning approaches, to retrieve image information from distorted features and training networks. We have tested the MAGiGAN SRR using the NVIDIA® Jetson TX-2 GPU card for onboard processing within a smart-satellite capturing high definition satellite videos, which will enable many innovative remote-sensing applications to be implemented in the future. In this paper, we show SRR processing results from a Planet® SkySat HD 70cm spaceborne video using a GPU version of the MAGiGAN system. Image quality and effective resolution enhancement are measured and discussed. © 2019 SPIE.","Deep learning; Digital television; Earth (planet); Graphics processing unit; Image enhancement; Image segmentation; Optical resolving power; Remote sensing; Restoration; Video signal processing; Adversarial networks; Earth observations; HD videos; MAGiGAN; Multi angle; Super-resolution restoration; Image reconstruction","Earth Observation; Generative Adversarial Network; MAGiGAN; Multi-angle; Planet® SkySat® HD Video; Super-Resolution Restoration","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85078198191"
"Guo Z.; Wu G.; Song X.; Yuan W.; Chen Q.; Zhang H.; Shi X.; Xu M.; Xu Y.; Shibasaki R.; Shao X.","Guo, Zhiling (57189517376); Wu, Guangming (57196352694); Song, Xiaoya (57205562134); Yuan, Wei (55197962500); Chen, Qi (56900142500); Zhang, Haoran (57204578013); Shi, Xiaodan (57201292783); Xu, Mingzhou (57218689200); Xu, Yongwei (57189516545); Shibasaki, Ryosuke (7003648498); Shao, Xiaowei (16200316400)","57189517376; 57196352694; 57205562134; 55197962500; 56900142500; 57204578013; 57201292783; 57218689200; 57189516545; 7003648498; 16200316400","Super-resolution integrated building semantic segmentation for multi-source remote sensing imagery","2019","IEEE Access","7","","2928646","99381","99397","16","10.1109/ACCESS.2019.2928646","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085255602&doi=10.1109%2fACCESS.2019.2928646&partnerID=40&md5=ebbc2dd10ed5ce8990e2580a4b1c2896","Multi-source remote sensing imagery has become widely accessible owing to the development of data acquisition systems. In this paper, we address the challenging task of the semantic segmentation of buildings via multi-source remote sensing imagery with different spatial resolutions. Unlike previous works that mainly focused on optimizing the segmentation model, which did not enable the severe problems caused by the unaligned resolution between the training and testing data to be fundamentally solved, we propose to integrate SR techniques with the existing framework to enhance the segmentation performance. The feasibility of the proposed method was evaluated by utilizing representative multi-source study materials: high-resolution (HR) aerial and low-resolution (LR) panchromatic satellite imagery as the training and testing data, respectively. Instead of directly conducting building segmentation from the LR imagery by using the model trained using the HR imagery, the deep learning-based super-resolution (SR) model was first adopted to super-resolved LR imagery into SR space, which could mitigate the influence of the difference in resolution between the training and testing data. The experimental results obtained from the test area in Tokyo, Japan, demonstrate that the proposed SR-integrated method significantly outperforms that without SR, improving the Jaccard index and kappa by approximately 19.01% and 19.10%, respectively. The results confirmed that the proposed method is a viable tool for building semantic segmentation, especially when the resolution is unaligned. © 2020 Lippincott Williams and Wilkins. All rights reserved.","Antennas; Data acquisition; Deep learning; Optical resolving power; Satellite imagery; Semantics; Space optics; Data acquisition system; Integrated buildings; Learning-based super-resolution; Panchromatic satellites; Remote sensing imagery; Segmentation performance; Semantic segmentation; Training and testing; Remote sensing","Building segmentation; Deep learning; Remote sensing; Super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85085255602"
"Shi S.; Gong X.; Mu Y.; Finch K.; Gamez G.","Shi, Songyue (57193746671); Gong, Xiaoxia (57193743385); Mu, Yan (57204113396); Finch, Kevin (57202680089); Gamez, Gerardo (6602094248)","57193746671; 57193743385; 57204113396; 57202680089; 6602094248","Geometric super-resolution on push-broom hyperspectral imaging for plasma optical emission spectroscopy","2018","Journal of Analytical Atomic Spectrometry","33","10","","1745","1752","7","10.1039/c8ja00235e","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054503681&doi=10.1039%2fc8ja00235e&partnerID=40&md5=e1296b37027c9bdee15c032ffecb2657","Push-broom hyperspectral imaging (Pb-HSI) is a powerful technique for obtaining the spectral information along with the spatial information simultaneously for various applications, from remote sensing to chemical imaging. Spatial resolution improvement is beneficial in many instances; however, typical solutions suffer from the limitation of geometric extent, lowered light throughput, or reduced field-of-view (FOV). Sub-pixel shifting (SPS) acquires higher-resolution images, compared to typical imaging approaches, from the deconvolution of low-resolution images acquired with a higher sampling rate. Furthermore, SPS is particularly suited for Pb-HSI due to its scanning nature. In this study, an SPS approach is developed and implemented on a Pb-HSI system for plasma optical emission spectroscopy. The preliminary results showed that a periodic deconvolution error was generated in the final SPS Pb-HSI images. The periodic error was traced back to random noise present in the raw/convoluted SPS data and its frequency displays an inverse relationship with the number of sub-pixel samples acquired. Computer modelled data allows studying the effect of varying the relative standard deviation (RSD) in the raw/convoluted SPS data on the final reconstructed SPS images and optimization of noise filtering. The optimized SPS Pb-HSI technique was used to acquire the line-of-sight integrated optical emission maps from an atmospheric pressure micro-capillary dielectric barrier discharge (μDBD). The selected plasma species of interest (He, I, N2, N2                             +, and O) yield some insight into the underlying mechanisms. The SPS Pb-HSI technique developed here will allow implementing geometric super-resolution in many applications, for example, it will be used for extracting radially resolved information from Abel's inversion protocols, where improved fitting is expected due to the increase in resolution/data points. © The Royal Society of Chemistry.","Atmospheric pressure; Dielectric materials; Electric discharges; Geometry; Hyperspectral imaging; Image acquisition; Light emission; Optical emission spectroscopy; Optical resolving power; Pixels; Remote sensing; Dielectric barrier discharges; Higher resolution images; Inverse relationship; Low resolution images; Plasma optical emission spectroscopy; Relative standard deviations; Spatial informations; Spectral information; Lead compounds","","Article","Final","","Scopus","2-s2.0-85054503681"
"Petrou Z.I.; Xian Y.; Tian Y.","Petrou, Zisis I. (54405740400); Xian, Yang (57033722600); Tian, YingLi (16556710700)","54405740400; 57033722600; 16556710700","Towards breaking the spatial resolution barriers: An optical flow and super-resolution approach for sea ice motion estimation","2018","ISPRS Journal of Photogrammetry and Remote Sensing","138","","","164","175","11","10.1016/j.isprsjprs.2018.01.020","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042365899&doi=10.1016%2fj.isprsjprs.2018.01.020&partnerID=40&md5=b9bcd838ffb8ea4a6a19068a04a3f1e1","Estimation of sea ice motion at fine scales is important for a number of regional and local level applications, including modeling of sea ice distribution, ocean-atmosphere and climate dynamics, as well as safe navigation and sea operations. In this study, we propose an optical flow and super-resolution approach to accurately estimate motion from remote sensing images at a higher spatial resolution than the original data. First, an external example learning-based super-resolution method is applied on the original images to generate higher resolution versions. Then, an optical flow approach is applied on the higher resolution images, identifying sparse correspondences and interpolating them to extract a dense motion vector field with continuous values and subpixel accuracies. Our proposed approach is successfully evaluated on passive microwave, optical, and Synthetic Aperture Radar data, proving appropriate for multi-sensor applications and different spatial resolutions. The approach estimates motion with similar or higher accuracy than the original data, while increasing the spatial resolution of up to eight times. In addition, the adopted optical flow component outperforms a state-of-the-art pattern matching method. Overall, the proposed approach results in accurate motion vectors with unprecedented spatial resolutions of up to 1.5 km for passive microwave data covering the entire Arctic and 20 m for radar data, and proves promising for numerous scientific and operational applications. © 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Ice; Image resolution; Microwave sensors; Optical correlation; Optical flows; Optical resolving power; Pattern matching; Radar; Remote sensing; Sea ice; Synthetic aperture radar; Arctic sea ice; Drift estimations; Maximum cross correlations; Motion tracking; Super resolution; Motion estimation","Arctic sea ice; Drift estimation; Maximum cross-correlation; Motion tracking; Optical flow; Super-resolution","Article","Final","","Scopus","2-s2.0-85042365899"
"Zhang Q.; Zhang Y.; Zhang Y.; Huang Y.; Li W.; Wu J.; Yang J.","Zhang, Qiping (57207878759); Zhang, Yin (55975581400); Zhang, Yongchao (56042343300); Huang, Yulin (23014806800); Li, Wenchao (55718616300); Wu, Junjie (55713990900); Yang, Jianyu (9239230100)","57207878759; 55975581400; 56042343300; 23014806800; 55718616300; 55713990900; 9239230100","Azimuth superresolution of forward-looking radar imaging based on improved total variation","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-July","","8900485","4276","4279","3","10.1109/IGARSS.2019.8900485","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113899499&doi=10.1109%2fIGARSS.2019.8900485&partnerID=40&md5=eb3017f7c046d6ba2ad66bf6c8125f7f","The clear contour is required when realize azimuth superresolution of forward-looking radar imaging in many applications. Traditional deconvolution methods achieve the azimuth superresolution but are limited in contour recovery. Although the total variation (TV) method can be used to keep the contour information, it’s sensitive to noise because of derivation. In this paper, we propose an improved total variation (ITV) method to realize azimuth superresolution of forward-looking radar imaging and recover the contour information. Firstly, the TV norm and L2 norm are combined as the penalties under regularization framework. Then the regularization problem is solved by split Bregman algorithm. The proposed ITV method achieves higher azimuth resolution and better contour recovery performance than traditional methods, and the super performance is verified by simulations lastly. ©2019 IEEE","Optical resolving power; Radar; Recovery; Remote sensing; Azimuth resolution; Contour information; Contour recoveries; Deconvolution method; Forward looking radars; Regularization framework; Split bregman algorithms; Super resolution; Radar imaging","Contour recovery; Radar imaging; Superresolution; Total variation","Conference paper","Final","","Scopus","2-s2.0-85113899499"
"Ren Y.-C.; Wang S.; Rao R.-Z.; Miao X.-K.","Ren, Yi-Chong (55835996600); Wang, Shu (57195941347); Rao, Rui-Zhong (7403069326); Miao, Xi-Kui (57210514217)","55835996600; 57195941347; 7403069326; 57210514217","Influence of atmospheric scintillation on entangled coherent states quantum interferometric radar; [大气闪烁对纠缠相干态量子干涉雷达影响机理]","2018","Wuli Xuebao/Acta Physica Sinica","67","14","","140301","","","10.7498/aps.67.20172401","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055640514&doi=10.7498%2faps.67.20172401&partnerID=40&md5=2ce2c23254a125091885a9dece69c825","Much interest has been aroused in quantum metrology such as quantum interferometric radar, due to its application in sub-Raleigh ranging and remote sensing. Generally, the quantum signal emitted by quantum radar will be affected by atmosphere medium. For instance, both atmospheric loss and atmospheric scintillation seriously affect the sensitivity and resolution of quantum radar. In fact, the effects of atmospheric loss on the sensitivity and resolution of quantum interferometric radar have been investigated thoroughly and completely in the past decades. However, the investigation about the influence of atmospheric scintillation is lacking until now. To realize practical quantum interferometric radar, the perturbation coming from turbulent atmosphere must be considered, thus it is necessary to investigate how the atmospheric scintillation affects the performance of quantum radar. In this paper, the influence of intensity fluctuation which is caused by atmospheric scintillation on the performance of quantum interferometric radar with entangled coherent states (ECS) is thoroughly investigated. We first introduce the physical model of quantum interferometric radar, and the dynamic evolution of quantum light field in atmosphere is obtained by solving the master equation of dissipation channel. Considering the dissipation and fluctuation caused by atmospheric scintillation, we regard the turbulent atmosphere as so-called dissipation-fluctuation channel. Moreover, according to classical statistical theory of turbulence, we derive the explicit expression of probability distribution of transmission coefficient P(T), this probability distribution of transmission cofficient, which is determined by average transmission coefficient TD and scintillation index βD                             2 plays a crucial role in the studying of atmospheric scintillation. The results of investigation show that atmospheric scintillation leads to the degradation of the sensitivity and resolution of ECS quantum interferometric radar at lower atmospheric loss. Under the higher lossy condition of atmosphere, atmospheric scintillation can greatly enhance the performance of quantum interferometric radar. Furthermore, the critical atmospheric transmission coefficient which determines the lower and higher loss of atmosphere keeps increasing with the increase of average photon number per pulse. Increasing the atmospheric scintillation, rather than introducing noise and degrading the performance of quantum radar, can improve the sensitivity and resolution. This anomalous phenomenon can be explained only by quantum decoherence theory. As is well known, the supersensitivity and super-resolution of quantum radar are based on the nonlocal characteristic of quantum light field, while the dissipation process will induce decoherence that leads to the loss of nonlocal characteristic, and finally degrades the performance of quantum radar. However, there have been several researches indicating that the dissipation-fluctuation channel can alleviate the decoherence effect and maintain the nonlocal characteristic of quantum light field compared with pure dissipation channel. For the evolution of quantum light field in dissipation medium, the loss of amplitude plays a crucial role at a lower loss, while the decoherence will play a dominant role at a higher loss. Consequently, the fluctuation may induce extra noise and degrade the performance of quantum radar at lower loss. For higher loss, the fluctuation can prevent the decoherence process and maintain the quantum characteristic of light field, thus the atmospheric scintillation finally improves the sensitivity and resolution of quantum radar. © 2018 Chinese Physical Society.","Atmospheric thermodynamics; Atmospheric turbulence; Coherent light; Interferometry; Probability distributions; Radar; Remote sensing; Scintillation; Atmospheric scintillation; Atmospheric transmissions; Entangled coherent state; Intensity fluctuations; Interferometric radars; Supersensitivity; Transmission coefficients; Turbulent atmosphere; Quantum entanglement","Atmospheric scintillation; Entangled coherent state; Quantum interferometric radar; Supersensitivity","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85055640514"
"Lu X.; Wang D.; Shi W.","Lu, Xuan (57190565423); Wang, Dingwen (23468078000); Shi, Wenxuan (37104951800)","57190565423; 23468078000; 37104951800","Image Super-resolution with On-line Dictionary Learning","2018","Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University","43","5","","719","725","6","10.13203/j.whugis20150753","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050502047&doi=10.13203%2fj.whugis20150753&partnerID=40&md5=ea8dfe8b2559a27cd8808c116ed7304b","Image super-resolution reconstruction is the method that uses one or several low-resolution images to reconstruct a high-resolution image. Sparse representation has been widely used in single image super-resolution reconstruction. However, the contents can vary significantly across different patches in a single image, and the fixed dictionaries, which common super-resolution algorithms based on sparse representation often used, cannot suit for every patch. This paper presents a novel approach for single image super-resolution based on sparse representation, which trains the dictionary with external database and the input low-resolution image itself. With the nonlocal similar patches extracted from the input image, the dictionary is updated by on-line dictionary learning method to ensure that the new dictionary is suitable for every patch in the image. Extensive experiments on natural images and remote sensing images show that the method with on-line dictionary learning achieves better results than those of the state-of-the-art algorithms in terms of both objective and visual evaluations. © 2018, Research and Development Office of Wuhan University. All right reserved.","E-learning; Optical resolving power; Remote sensing; Dictionary learning; Image super-resolution reconstruction; Non-local similarities; Single-image super-resolution reconstruction; Sparse representation; State-of-the-art algorithms; Super resolution; Super resolution algorithms; algorithm; database; experimental study; image resolution; learning; reconstruction; remote sensing; visualization; Image reconstruction","Non-local similarity; On-line dictionary learning; Sparse representation; Super-resolution","Article","Final","","Scopus","2-s2.0-85050502047"
"Zhang Y.; Foody G.M.; Ling F.; Li X.; Ge Y.; Du Y.; Atkinson P.M.","Zhang, Yihang (55658053900); Foody, Giles M. (7007014233); Ling, Feng (56278268300); Li, Xiaodong (55878368700); Ge, Yong (26655529300); Du, Yun (56420121700); Atkinson, Peter M. (7201906181)","55658053900; 7007014233; 56278268300; 55878368700; 26655529300; 56420121700; 7201906181","Spatial-temporal fraction map fusion with multi-scale remotely sensed images","2018","Remote Sensing of Environment","213","","","162","181","19","10.1016/j.rse.2018.05.010","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047057538&doi=10.1016%2fj.rse.2018.05.010&partnerID=40&md5=f79120e0d8f0ee5cbc0f2ec3e93b8e3f","Given the common trade-off between the spatial and temporal resolutions of current satellite sensors, spatial-temporal data fusion methods could be applied to produce fused remotely sensed data with synthetic fine spatial resolution (FR) and high repeat frequency. Such fused data are required to provide a comprehensive understanding of Earth's surface land cover dynamics. In this research, a novel Spatial-Temporal Fraction Map Fusion (STFMF) model is proposed to produce a series of fine-spatial-temporal-resolution land cover fraction maps by fusing coarse-spatial-fine-temporal and fine-spatial-coarse-temporal fraction maps, which may be generated from multi-scale remotely sensed images. The STFMF has two main stages. First, FR fraction change maps are generated using kernel ridge regression. Second, a FR fraction map for the date of prediction is predicted using a temporal-weighted fusion model. In comparison to two established spatial-temporal fusion methods of spatial-temporal super-resolution land cover mapping model and spatial-temporal image reflectance fusion model, STFMF holds the following characteristics and advantages: (1) it takes account of the mixed pixel problem in FR remotely sensed images; (2) it directly uses the fraction maps as input, which could be generated from a range of satellite images or other suitable data sources; (3) it focuses on the estimation of fraction changes happened through time and can predict the land cover change more accurately. Experiments using synthetic multi-scale fraction maps simulated from Google Earth images, as well as synthetic and real MODIS-Landsat images were undertaken to test the performance of the proposed STFMF approach against two benchmark spatial-temporal reflectance fusion methods: the Enhanced Spatial and Temporal Adaptive Reflectance Fusion Model (ESTARFM) and the Flexible Spatiotemporal Data Fusion (FSDAF) model. In both visual and quantitative evaluations, STFMF was able to generate more accurate FR fraction maps and provide more spatial detail than ESTARFM and FSDAF, particularly in areas with substantial land cover changes. STFMF has great potential to produce accurate time-series fraction maps with fine-spatial-temporal-resolution that can support studies of land cover dynamics at the sub-pixel scale. © 2018 Elsevier Inc.","Benchmarking; Economic and social effects; Image enhancement; Optical resolving power; Photomapping; Pixels; Reflection; Regression analysis; Remote sensing; Satellite imagery; Kernel ridge regressions; Land cover; Quantitative evaluation; Remotely sensed images; Spatial and temporal resolutions; Spatial temporals; Spectral unmixing; Super-resolution mappings; benchmarking; land cover; Landsat; mapping; MODIS; prediction; regression analysis; remote sensing; research work; satellite data; satellite imagery; sensor; spatial resolution; spatiotemporal analysis; Image fusion","Fraction maps; Land cover; Spatial-temporal fusion; Spectral unmixing; Super-resolution mapping","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85047057538"
"Lei S.; Shi Z.; Wu X.; Pan B.; Xu X.; Hao H.","Lei, Sen (57195618353); Shi, Zhenwei (23398841900); Wu, Xi (57202075685); Pan, Bin (56421342100); Xu, Xia (57192694193); Hao, Hongxun (57237953900)","57195618353; 23398841900; 57202075685; 56421342100; 57192694193; 57237953900","Simultaneous super-resolution and segmentation for remote sensing images","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-July","","8900402","3121","3124","3","10.1109/IGARSS.2019.8900402","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095072123&doi=10.1109%2fIGARSS.2019.8900402&partnerID=40&md5=7cb56ba234786659b15b496bccd6e301","In this paper, we present an algorithm to simultaneously obtain high-resolution images and segmentation maps from low-resolution inputs. Super-resolution and segmentation both are challenging task, but they may have certain relationship. Super-resolution will provide images with more details that may help to improve the segmentation accuracy, while label maps in segmentation dataset may contribute to finer edges during super-resolution process. Therefore, we aim to combine these two tasks and explore the influence for each other. For this end, we proposed a new deep neural network to simultaneously address the super-resolution and segmentation tasks for remote sensing images, which is named S2Net. The S2Net is an integrated network composed of a super-resolution sub-network and a segmentation sub-network, which is trained in an end-to-end manner. Experimental results demonstrate that this combination can enhance the performance on these two tasks. ©2019 IEEE","Deep neural networks; Image enhancement; Optical resolving power; Remote sensing; High resolution image; Integrated networks; Low resolution; Remote sensing images; Segmentation accuracy; Segmentation map; Sub-network; Super resolution; Image segmentation","Remote sensing images; S<sup>2</sup>Net; Segmentation; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85095072123"
"Mei S.; Yuan X.; Ji J.; Wan S.; Hou J.; Du Q.","Mei, Shaohui (25822578400); Yuan, Xin (57188549342); Ji, Jingyu (57188828176); Wan, Shuai (8335632500); Hou, Junhui (36989331100); Du, Qian (7202060063)","25822578400; 57188549342; 57188828176; 8335632500; 36989331100; 7202060063","Hyperspectral image super-resolution via convolutional neural network","2018","Proceedings - International Conference on Image Processing, ICIP","2017-September","","","4297","4301","4","10.1109/ICIP.2017.8297093","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045329596&doi=10.1109%2fICIP.2017.8297093&partnerID=40&md5=f159a54ceeab80210cfc0f90d2bca5be","Due to the tradeoff between spatial and spectral resolution in remote sensing imaging, hyperspectral images are often acquired with a relative low spatial resolution, which limits their applications in many areas. Inspired by recent achievements in convolutional neural network (CNN) based super resolution (SR), a novel CNN based framework is constructed for SR of hyperspectral images by considering both spatial context and spectral correlation. As a result, the spectral distortion incurred by directly applying traditional SR algorithms to hyperspectral images is alleviated. Experimental results on several benchmark hyperspectral datasets have demonstrated that higher quality of reconstruction and spectral fidelity can be achieved, compared to band-wise manner based algorithms. © 2017 IEEE.","Benchmarking; Convolution; Deep learning; Hyperspectral imaging; Independent component analysis; Neural networks; Optical resolving power; Remote sensing; Spectroscopy; Convolutional neural network; Convolutional Neural Networks (CNN); HyperSpectral; Image super resolutions; Remote sensing imaging; Spectral correlation; Spectral distortions; Super resolution; Image processing","Convolutional neural network; Deep learning; Hyperspectral; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85045329596"
"Zareapoor M.; Jain D.K.; Yang J.","Zareapoor, Masoumeh (56349635100); Jain, Deepak Kumar (56206778300); Yang, Jie (15039078800)","56349635100; 56206778300; 15039078800","Local spatial information for image super-resolution","2018","Cognitive Systems Research","52","","","49","57","8","10.1016/j.cogsys.2018.06.007","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048965882&doi=10.1016%2fj.cogsys.2018.06.007&partnerID=40&md5=928d9c81729386d68dd10a3f405c2c1f","Image Super resolution plays a crucial role in many applications, such as medical imaging, remote sensing, and security surveillance. Recently convolutional neural network are becoming mainstream in computer vision. Most CNN based super resolution methods cannot fully exploit the entire feature from the original image, and thus the corresponding results will appear low resolution. In this paper, we propose a new network which can reconstruct a high resolution images by upscaling the low resolution images layer by layer with a small scale factor. This strategy helps network to possibly avoid of losing information. The existing CNN models involved bicubic interpolation for preprocessing, which leads to large feature maps and high computational loads. To settle of this problem, the proposed network directly extracts features from the input images, without using preprocessing. In addition, the proposed network investigates the spatial information which is represented by dissimilarities between a low resolution image and its corresponding high resolution by adopting a global residual learning. This differentiable strategy is inserted into the proposed network, to dynamically extract the feature maps. The proposed model not only achieves a compatible performance with the existing prominent methods but also, efficiently reduce the computational expenses. © 2018 Elsevier B.V.","Convolution; Deep neural networks; Medical imaging; Neural networks; Optical resolving power; Remote sensing; Computational expense; Convolutional neural network; Deep convolutional neural networks; Image super resolutions; Low resolution images; Spatial features; Super resolution; Superresolution methods; Article; artificial neural network; controlled study; image enhancement; image processing; image quality; image reconstruction; intermethod comparison; measurement accuracy; priority journal; Image processing","Deep convolutional neural network; Image processing; Spatial features; Super-resolution","Article","Final","","Scopus","2-s2.0-85048965882"
"Kwan C.; Choi J.H.; Chan S.H.; Zhou J.; Budavari B.","Kwan, Chiman (7201421216); Choi, Joon Hee (56734751700); Chan, Stanley H. (24824181300); Zhou, Jin (55226383100); Budavari, Bence (57191360081)","7201421216; 56734751700; 24824181300; 55226383100; 57191360081","A super-resolution and fusion approach to enhancing hyperspectral images","2018","Remote Sensing","10","9","1416","","","","10.3390/rs10091416","56","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053619709&doi=10.3390%2frs10091416&partnerID=40&md5=d2169c6e946856e7d4d98d7a3a361995","High resolution (HR) hyperspectral (HS) images have found widespread applications in terrestrial remote sensing applications, including vegetation monitoring, military surveillance and reconnaissance, fire damage assessment, and many others. They also find applications in planetary missions such as Mars surface characterization. However, resolutions of most HS imagers are limited to tens of meters. Existing resolution enhancement techniques either require additional multispectral (MS) band images or use a panchromatic (pan) band image. The former poses hardware challenges, whereas the latter may have limited performance. In this paper, we present a new resolution enhancement algorithm for HS images that only requires an HR color image and a low resolution (LR) HS image cube. Our approach integrates two newly developed techniques: (1) A hybrid color mapping (HCM) algorithm, and (2) A Plug-and-Play algorithm for single image super-resolution. Comprehensive experiments (objective (five performance metrics), subjective (synthesized fused images in multiple spectral ranges), and pixel clustering) using real HS images and comparative studies with 20 representative algorithms in the literature were conducted to validate and evaluate the proposed method. Results demonstrated that the new algorithm is very promising. © 2018 by the authors.","Clustering algorithms; Color; Damage detection; Hyperspectral imaging; Mapping; Military applications; Military photography; Optical resolving power; Remote sensing; Spectroscopy; Alternating direction method of multipliers; Color mapping; Military surveillance; Remote sensing applications; Resolution enhancement; Resolution enhancement technique; Super resolution; Vegetation monitoring; Image enhancement","Hybrid color mapping; Hyperspectral imaging; Plug-and-Play Alternating Direction Method of Multipliers (PAP-ADMM); Remote sensing; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85053619709"
"Wu H.; Zhao S.; Zhang J.; Lu C.","Wu, Honglin (56734647000); Zhao, Shuzhen (57208422823); Zhang, Jianming (56970028600); Lu, Chaoquan (57208332569)","56734647000; 57208422823; 56970028600; 57208332569","Remote Sensing Image Sharpening by Integrating Multispectral Image Super-Resolution and Convolutional Sparse Representation Fusion","2019","IEEE Access","7","","6287639","46562","46574","12","10.1109/ACCESS.2019.2908968","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064763887&doi=10.1109%2fACCESS.2019.2908968&partnerID=40&md5=b4d187f9a662cdc03f8be9d7d70b4b40","In remote sensing, it is quite necessary to fuse spectral information of low-resolution multispectral (LRMS) images and spatial information of panchromatic (PAN) images for obtaining high-resolution multispectral (HRMS) images. In this paper, an effective fusion method integrating multispectral (MS) image super-resolution and convolutional sparse representation (CSR) fusion is proposed to make full use of the spatial information of remote sensing images. First, for enhancing the spatial information of LRMS images with suitable sizes, a fast iterative image super-resolution algorithm based on the learned iterative shrinkage and thresholding algorithm (LISTA) is exploited in the first stage. It employs a feed-forward neural network to simplify the solution of sparse coefficients in the process of super-resolution. In the fusion stage, we propose a CSR-based image fusion framework, in which each MS super-resolution image and PAN image is decomposed into a basic layer and a detail layer, then we fuse the basic layers and the detail layers of the images, respectively. This hierarchical fusion strategy guarantees great performance in detail preservation. The experimental results on QuickBird, WorldView-2, and Landsat ETM+ datasets demonstrate that the proposed method outperforms other methods in terms of both objective evaluation and visual effect. © 2013 IEEE.","Convolution; Image enhancement; Iterative methods; Optical resolving power; Remote sensing; Shrinkage; Image super resolutions; Objective evaluation; Panchromatic (Pan) image; Remote sensing fusion; Remote sensing images; Sparse representation; Super resolution; Thresholding algorithms; Image fusion","convolutional sparse representation (CSR); learned iterative shrinkage and thresholding algorithm (LISTA); Remote sensing fusion; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85064763887"
"","","","11th International Conference on Knowledge Science, Engineering and Management, KSEM 2018","2018","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11061 LNAI","","","","","1010","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052234700&partnerID=40&md5=a94b055b275233caa660545bbe434a01","The proceedings contain 88 papers. The special focus in this conference is on Knowledge Science, Engineering and Management. The topics include: TCMEF: A TCM entity filter using less text; two-stage object detection based on deep pruning for remote sensing image; w-shaped selection for light field super-resolution; users personalized sketch-based image retrieval using deep transfer learning; enhancing network flow for multi-target tracking with detection group analysis; combine coarse and fine cues: Multi-grained fusion network for video-based person re-identification; understand and assess people’s procrastination by mining computer usage log; group outlying aspects mining; fine-grained correlation learning with stacked co-attention networks for cross-modal information retrieval; A biomedical question answering system based on SNOMED-CT; supervised manifold-preserving graph reduction for noisy data classification; Personalize review selection using PeRView; An online GPS trajectory data compression method based on motion state change; mining temporal discriminant frames via joint matrix factorization: A case study of illegal immigration in the U.S. news media; enhancing cluster center identification in density peak clustering; An improved weighted ELM with hierarchical feature representation for imbalanced biomedical datasets; SERL: Semantic-path biased representation learning of heterogeneous information network; social Bayesian personal ranking for missing data in implicit feedback recommendation; a semantic path-based similarity measure for weighted heterogeneous information networks; cross-domain recommendation for mapping sentiment review pattern; authorship attribution for short texts with author-document topic model; fuzzy gravitational search approach to a hybrid data model based recommender system; causal discovery with Bayesian networks inductive transfer; robust detection of communities with multi-semantics in large attributed networks.","","","Conference review","Final","","Scopus","2-s2.0-85052234700"
"Ren R.; Gu L.; Fu H.; Sun C.","Ren, Ruizhi (15835523400); Gu, Lingjia (15834718400); Fu, Haoyang (56727208100); Sun, Chenglin (35216653800)","15835523400; 15834718400; 56727208100; 35216653800","Super-resolution algorithm based on sparse representation and wavelet preprocessing for remote sensing imagery","2017","Journal of Applied Remote Sensing","11","2","026014","","","","10.1117/1.JRS.11.026014","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021652863&doi=10.1117%2f1.JRS.11.026014&partnerID=40&md5=d88902d678b61c4edcba4994255a96f3","An effective super-resolution (SR) algorithm is proposed for actual spectral remote sensing images based on sparse representation and wavelet preprocessing. The proposed SR algorithm mainly consists of dictionary training and image reconstruction. Wavelet preprocessing is used to establish four subbands, i.e., low frequency, horizontal, vertical, and diagonal high frequency, for an input image. As compared to the traditional approaches involving the direct training of image patches, the proposed approach focuses on the training of features derived from these four subbands. The proposed algorithm is verified using different spectral remote sensing images, e.g., moderate-resolution imaging spectroradiometer (MODIS) images with different bands, and the latest Chinese Jilin-1 satellite images with high spatial resolution. According to the visual experimental results obtained from the MODIS remote sensing data, the SR images using the proposed SR algorithm are superior to those using a conventional bicubic interpolation algorithm or traditional SR algorithms without preprocessing. Fusion algorithms, e.g., standard intensity-hue-saturation, principal component analysis, wavelet transform, and the proposed SR algorithms are utilized to merge the multispectral and panchromatic images acquired by the Jilin-1 satellite. The effectiveness of the proposed SR algorithm is assessed by parameters such as peak signal-to-noise ratio, structural similarity index, correlation coefficient, root-mean-square error, relative dimensionless global error in synthesis, relative average spectral error, spectral angle mapper, and the quality index Q4, and its performance is better than that of the standard image fusion algorithms. © 2017 Society of Photo-Optical Instrumentation Engineers (SPIE).","Errors; Image fusion; Image reconstruction; Image segmentation; Mean square error; Optical resolving power; Principal component analysis; Radiometers; Satellite imagery; Signal to noise ratio; Spectrometers; Wavelet transforms; Intensity hue saturations; Moderate resolution imaging spectroradiometer; Peak signal to noise ratio; Sparse representation; Structural similarity indices; Super resolution; Super resolution algorithms; Wavelet transformations; Remote sensing","Chinese Jilin-1 satellite imagery; image fusion; moderate-resolution imaging spectroradiometer; sparse representation; super-resolution; wavelet transformation","Article","Final","","Scopus","2-s2.0-85021652863"
"Zhao C.; Yang H.; Liu W.; Zhu H.; Wan X.","Zhao, Chunhui (7403563984); Yang, Huaijuan (57202612332); Liu, Wu (56050834300); Zhu, Haifeng (55717966500); Wan, Xiaoqing (57193524947)","7403563984; 57202612332; 56050834300; 55717966500; 57193524947","Super-resolution mapping of remote sensing image based on joint dictionary sparse representation; [基于联合字典稀疏表示的遥感图像超分辨率制图]","2018","Harbin Gongcheng Daxue Xuebao/Journal of Harbin Engineering University","39","8","","1400","1408","8","10.11990/jheu.201706002","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056816600&doi=10.11990%2fjheu.201706002&partnerID=40&md5=fd2083334296ce0bc423b86203c46e6f","Super-resolution mapping (SRM) is a technique for generating fine-spatial-resolution land cover maps from coarse-spatial-resolution fraction images. In this paper, we propose a new SRM method that uses a joint dictionary-based sparse representation to overcome one problem: in practice, the spatial dependence principle is not sufficient for describing complex patterns. We use a transfer learning mechanism and natural images to jointly train a high- and low-resolution image patch dictionary, and according to the similarity of the sparse representations of the low- and high-resolution image patch pairs with their corresponding dictionaries, high-resolution soft-classified images are generated by combining the sparse representation of low-resolution abundance images with the high-resolution image patch dictionary. Finally, we perform class allocation to obtain a high-resolution land cover map. Using a synthetic Landsat multispectral image and a subset image of the National Land Cover Database 2001, we tested and compared the performance of the proposed method against those of several existing typical SRM methods. The results show that the proposed method has the highest SRM accuracy of the SRM algorithms tested. © 2018, Editorial Department of Journal of HEU. All right reserved.","Image resolution; Optical resolving power; Remote sensing; High resolution image; Landsat multispectral images; Low resolution images; Remote sensing images; Sparse representation; Spatial resolution; Super-resolution mappings; Transfer learning; Mapping","Joint dictionary; Remote-sensing images; Sparse representation; Super-resolution mapping; Transfer learning","Article","Final","","Scopus","2-s2.0-85056816600"
"Shao Z.; Zhang X.; Ren J.; Li Y.","Shao, Zelong (57197734272); Zhang, Xiangkun (35390622700); Ren, Jiawei (57201579462); Li, Yingsong (36170735500)","57197734272; 35390622700; 57201579462; 36170735500","High-speed railway bridge vibration measurement and analysis based on radar interferometry","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8518902","4099","4102","3","10.1109/IGARSS.2018.8518902","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064158652&doi=10.1109%2fIGARSS.2018.8518902&partnerID=40&md5=794de0be02ae5be0e927ff657e1a111b","A newly designed radar based on interferometry is proposed and well designed in the paper. The designed radar can detect the vibration of the railway bridge with a super-resolution and a high precision, which also has remote sensing ability. The general bridge monitoring methods are expensive and time-consuming since it is difficult to install sensors that should be directly contact with the bridge, such as accelerometer and dynamometer. Based on the designed radar, experiments are constructed on a Beijing-Tianjin Inter-City high-speed railway bridge to prove that the radar interferometry can be used to preciously and accurately monitor the railway bridge’s vibration. © 2018 IEEE.","Geology; Interferometry; Radar; Railroad bridges; Railroad transportation; Railroads; Remote sensing; Vibration analysis; Bridge monitoring; High-precision; High-speed railway bridges; Measurement and analysis; Radar interferometry; Railway bridges; Super resolution; Vibration; Radar measurement","Interferometry; Railway bridge; Vibration","Conference paper","Final","","Scopus","2-s2.0-85064158652"
"Joshi S.; Kulkarni R.K.","Joshi, Shilpa (57210408313); Kulkarni, R.K. (16239497100)","57210408313; 16239497100","Combining diffusion filter algorithms with super—resolution for abnormality detection in medical images","2018","Lecture Notes in Computational Vision and Biomechanics","28","","","1108","1116","8","10.1007/978-3-319-71767-8_95","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042445730&doi=10.1007%2f978-3-319-71767-8_95&partnerID=40&md5=96de12629be6acb5cd7e76ecbbd429df","One of the most significant areas of image research is Image Enhancement. The main aspect of image enhancement involves the improvisation of the visual manifestation of an image. Poor contrast and noise affect many kinds of images today, such as satellite images, remote sensing images, medical images, real-life images and electron microscope images. Therefore, noise removal and resolution increment are important as well as necessary to ensure and enhance the quality of images. There are many imaging modalities and each of them performs different functions ranging from the provision of information about human anatomy/structure to the provision of location statistics about specific activities and tasks. Physical constraints of system detectors—which are tuned to signal-to-noise and timing considerations are used to determine the resolution of imaging systems. The hybrid techniques designed n this paper uses algorithms are mostly based on standard diffusion filters and SR algorithms. Results demonstrate the potential in introducing SR techniques into practical medical applications. © 2018, Springer International Publishing AG.","","Diffusion filters; Image enhancement; Image modalities; Malignancy detection; Medical image analysis; Super-resolution","Book chapter","Final","","Scopus","2-s2.0-85042445730"
"Xu Y.; Li J.; Bai C.; Liu J.; Zong Y.; Duan M.","Xu, Yixuan (57195487196); Li, Jianxin (57204508800); Bai, Caixun (56865304800); Liu, Jie (57195399184); Zong, Yi (57210420361); Duan, Mingliang (57210415571)","57195487196; 57204508800; 56865304800; 57195399184; 57210420361; 57210415571","A high-precision wavelength calibration method based on Fourier transform imaging spectrometer","2019","Proceedings of SPIE - The International Society for Optical Engineering","11337","","1133708","","","","10.1117/12.2541545","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077973459&doi=10.1117%2f12.2541545&partnerID=40&md5=dc8f280efb01b4fa5b3fa65e0be7543a","Fourier Transform Imaging Spectrometer(FTIS) is an instrument cable of acquiring two-dimensional spatial information and one-dimensional spectral information. The FTIS has attracted much attention and is widely applied in the fields like military reconnaissance, remote sensing, biomedicine, environmental monitoring, etc. The FTIS acquires the spectral intensity in different wavelengths by performing Fourier transform on the white light interference signal of the target generated by the FTIS. The spectral curve obtained directly by Fourier transform reflects the relationship between the wavenumber order and the spectral intensity. So wavelength calibration is required to convert the above relationship into the relationship between the wavelength and the spectral intensity, which makes it more intuitive. Therefore, wavelength calibration is a necessary step for FTIS to recovery spectrum. The traditional wavelength calibration method can only get the wavenumber order in the range of integer because of the picket fence effect in Fourier transform. It will definitely ignore the fractional part which results in the inaccurate wavenumber order, which will directly affect the precision of the wavelength calibration result. In order to solve this problem, a high-precision wavelength calibration method based on Fourier transform imaging spectrometer is proposed according to the principle of FTIS and Fourier transform. This method can calculate the wavenumber order with the precision of percentile, which will reduce the error of wavelength calibration effectively. As a result, the precision of spectral calibration can be increased eventually. This method realizes high-precision wavelength calibration by the way of adding zero to the interference fringe in the spatial domain. The core of the method is getting a more precise wavenumber order. The brief process of obtaining wavenumber order is as follows: First, the FTIS acquires the interference fringe of a monochromatic laser. Second, the original interference fringe is extrapolated with zero. Third, the subtle spectrum can be obtained by performing Fourier transform on the extrapolated interference fringe. Finally, the precise wavenumber order is calculated by dividing the abscissa of the peak value by the extrapolation multiple. The principle of this method is investigated and related simulations are then carried out. The simulation results indicate that the wavenumber order calculated by the method have the same precision with the preset parameters, which illustrates that the method can calculate the wavenumber order more accurately. Therefore, the method can improve the precision of the spectral calibration. Besides, related experiments are also performed. The laser interference fringes of different wavelengths generated by the actual FTIS all apply the method to get the wavenumber orders in the frequency domain. Then a curve which is the wavelength calibration function is fitted using the discrete relation between the wavelengths and the wavenumber orders. A laser whose wavelength is known is measured by the FTIS with the wavelength calibration function got by the proposed method. The error of the wavelength measurement result is one-fifth of the traditional method. The simulations and the experiment results indicate that the proposed method can improve the precision of the wavelength calibration, which provides the theory and technology support for spectral measurement using FTIS. It also provides a possibility for the development of FTIS towards the super resolution direction. © 2019 SPIE.","Calibration; Extrapolation; Fourier transforms; Frequency domain analysis; Plasma diagnostics; Remote sensing; Spectrometers; Environmental Monitoring; Fourier transform imaging spectrometers; Imaging spectroscopy; Military reconnaissance; Spectral refinement; Wavelength calibration; Wavelength measurement; White light interference; Image processing","Fourier transform; Imaging spectroscopy; Spectral refinement; Wavelength calibration","Conference paper","Final","","Scopus","2-s2.0-85077973459"
"Li X.; Zhang L.; You J.","Li, Xiaoyan (56134032900); Zhang, Lefei (48663190100); You, Jane (57195578392)","56134032900; 48663190100; 57195578392","Domain transfer learning for hyperspectral image super-resolution","2019","Remote Sensing","11","6","694","","","","10.3390/rs11060694","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064626734&doi=10.3390%2frs11060694&partnerID=40&md5=497580db2cbbba9b36c47249288edcb0","A Hyperspectral Image (HSI) contains a great number of spectral bands for each pixel; however, the spatial resolution of HSI is low. Hyperspectral image super-resolution is effective to enhance the spatial resolution while preserving the high-spectral-resolution by software techniques. Recently, the existing methods have been presented to fuse HSI and Multispectral Images (MSI) by assuming that the MSI of the same scene is required with the observed HSI, which limits the super-resolution reconstruction quality. In this paper, a new framework based on domain transfer learning for HSI super-resolution is proposed to enhance the spatial resolution of HSI by learning the knowledge from the general purpose optical images (natural scene images) and exploiting the cross-correlation between the observed low-resolution HSI and high-resolution MSI. First, the relationship between low- and high-resolution images is learned by a single convolutional super-resolution network and then is transferred to HSI by the idea of transfer learning. Second, the obtained Pre-high-resolution HSI (pre-HSI), the observed low-resolution HSI, and high-resolution MSI are simultaneously considered to estimate the endmember matrix and the abundance code for learning the spectral characteristic. Experimental results on ground-based and remote sensing datasets demonstrate that the proposed method achieves comparable performance and outperforms the existing HSI super-resolution methods. © 2019 by the authors.","Convolution; Geometrical optics; Image fusion; Image resolution; Optical correlation; Remote sensing; Spectral resolution; Spectroscopy; Domain transfers; High resolution image; High spectral resolution; Image super resolutions; Spectral characteristics; Super resolution; Super resolution reconstruction; Superresolution methods; Image enhancement","Convolutional super-resolution network; Domain transfer learning; Hyperspectral Image (HSI) super-resolution; Image fusion","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85064626734"
"Bupphawat W.; Kasetkasem T.; Kumazawa I.; Rakwatin P.; Chanwimaluang T.","Bupphawat, Watsana (57200138076); Kasetkasem, Teerasit (6603233500); Kumazawa, Itsuo (55943452700); Rakwatin, Preesan (16418105400); Chanwimaluang, Thitiporn (6507915466)","57200138076; 6603233500; 55943452700; 16418105400; 6507915466","Super-resolution land cover mapping based on deep learning and level set method","2017","ECTI-CON 2017 - 2017 14th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology","","","8096298","557","560","3","10.1109/ECTICon.2017.8096298","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039907576&doi=10.1109%2fECTICon.2017.8096298&partnerID=40&md5=b4df69cd37d630f0cee327e3d03d6178","In this paper, we proposed an approach for super-resolution land cover mapping on remote sensing images based on the deep learning technique, namely Convolutional Neural Network (CNN) by combining with the level set method (LSM). Here, the CNN is used to find the probabilities that a subpixel belonging to a land cover class, and the LSM is employed to fine tune the boundaries among land cover classes. The QUICKBIBD satellite image data cover a part of Kasetsart University was used for evaluation. Experimental result showed that the proposed method has achieved superior accuracy than both Hopfield and Pixel-Swapping methods. © 2017 IEEE.","Deep learning; Drop breakup; Level measurement; Neural networks; Numerical methods; Optical resolving power; Pixels; Remote sensing; Convolutional neural network; Land cover mapping; Learning techniques; Level Set method; Remote sensing images; Satellite image datas; Super resolution; Supper resolutions; Mapping","Deep Learning; Level set method; Supper-resolution mapping","Conference paper","Final","","Scopus","2-s2.0-85039907576"
"Wu W.; Liu W.","Wu, Wei (57198678845); Liu, Wei (57835020200)","57198678845; 57835020200","Remote sensing recognition of residential areas based on GF-4 satellite image","2018","5th International Workshop on Earth Observation and Remote Sensing Applications, EORSA 2018 - Proceedings","","","8598622","","","","10.1109/EORSA.2018.8598622","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061817473&doi=10.1109%2fEORSA.2018.8598622&partnerID=40&md5=10fd5649cc5988e92bff27c7684d6162","Residential area is an important place for human habitation and life. Using remote sensing technology to identify residential areas is of great value for land resources planning and utilization, disaster prevention and relief and other fields. As the world's first high resolution optical remote sensing satellite for geosynchronous orbit, GF-4 satellite has high time resolution, medium spatial resolution and multispectral land detection capability, which provides a new data resource for residential monitoring. Closely combining with the detection characteristics of the GF-4 satellite, this paper proposes a remote sensing identification method based on GF-4 satellite, and the recognition ability of the GF-4 satellite to the residential area is analyzed. The remote sensing recognition of residential areas is mainly divided into four steps. First, Super-resolution image enhancement technology is used to improve the spatial resolution of GF-4 satellite PMS image. Then, the resolution enhanced image is processed by geometric correction, radiometric calibration and atmospheric correction. Third, the existing land use and land cover data are selected as prior knowledge to select typical sample areas. Based on the spectral characteristics and spectral relationship of different objects in GF-4 satellite image, decision tree classification method is used to eliminate the obvious non-residential areas such as cloud, vegetation, water and shadow, so as to reduce the subsequent data processing and reduce the false recognition rate in residential area. Finally, SVM classifier is selected for the classification of residential areas. Taking GF-4 satellite data in Jiashan county as experiment, the result shows that the user accuracy of resident recognition by this method is 89.96%, which is significantly higher than that without resolution enhancement in the same method. Besides, the spatial scope of the county and township residents can be effectively identified in GF-4 enhanced image. © 2018 IEEE.","Data handling; Data mining; Decision trees; Disaster prevention; Housing; Image enhancement; Image resolution; Land use; Observatories; Optical resolving power; Orbits; Satellites; Trees (mathematics); Decision tree classification; Detection characteristics; GF-4; Radiometric calibrations; Remote sensing information; Remote sensing technology; Residential areas; Spectral characteristics; Remote sensing","GF-4; Remote sensing information extraction; Residential area recognition","Conference paper","Final","","Scopus","2-s2.0-85061817473"
"Wang P.; Wang L.","Wang, Peng (57189493188); Wang, Liguo (55745497100)","57189493188; 55745497100","Soft-then-hard super-resolution mapping based on a spatial attraction model with multiscale subpixel shifted images","2017","International Journal of Remote Sensing","38","15","","4303","4326","23","10.1080/01431161.2017.1317937","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026579162&doi=10.1080%2f01431161.2017.1317937&partnerID=40&md5=47370664a88752fe0fae8719e65c5ed5","Super-resolution mapping (SRM) is a technique for exploring spatial distribution information of the land-cover classes at finer spatial resolution. The soft-then-hard super-resolution mapping (STHSRM) algorithm is a type of SRM algorithm that first estimates the soft class values for sub-pixels at the target fine spatial resolution and then predicts the hard class labels for sub-pixels. The sub-pixel shifted images from the same area can be incorporated to improve the accuracy of STHSRM algorithm. In this article, multi-scale sub-pixel shifted images (MSSI) based on the fine-scale model and the coarse-scale model are utilized to increase the accuracy of STHSRM. First, class fraction images are derived from multiple sub-pixel shifted coarse spatial resolution images by soft classification. Then using the sub-pixel/sub-pixel spatial attraction model as fine-scale and the sub-pixel/pixel spatial attraction model as coarse scale, all MSSI can be derived from fraction images. The MSSI for each class are then integrated to obtain the desired fine spatial resolution images. Finally, the integrated fine spatial resolution images are used to allocate classes for sub-pixel. Experiments on two synthetic remote sensing images and a real hyperspectral remote sensing imagery show that the proposed method produces higher mapping accuracy result. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","Image resolution; Mapping; Optical resolving power; Pixels; Remote sensing; Coarse-scale models; Hyperspectral remote sensing; Mapping accuracy; Remote sensing images; Soft classification; Spatial resolution; Spatial resolution images; Super-resolution mappings; algorithm; image analysis; pixel; remote sensing; smoothing; spatial analysis; spatial resolution; Image enhancement","","Article","Final","","Scopus","2-s2.0-85026579162"
"Xu J.; Liang Y.; Liu J.; Huang Z.","Xu, Jieping (56460486700); Liang, Yonghui (16836733200); Liu, Jin (56591555000); Huang, Zongfu (38961448500)","56460486700; 16836733200; 56591555000; 38961448500","Multi-frame super-resolution of gaofen-4 remote sensing images","2017","Sensors (Switzerland)","17","9","2142","","","","10.3390/s17092142","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029791215&doi=10.3390%2fs17092142&partnerID=40&md5=e06a7a2a1deb40133dc6c3934b93db4f","Gaofen-4 is China’s first geosynchronous orbit high-definition optical imaging satellite with extremely high temporal resolution. The features of staring imaging and high temporal resolution enable the super-resolution of multiple images of the same scene. In this paper, we propose a super-resolution (SR) technique to reconstruct a higher-resolution image from multiple low-resolution (LR) satellite images. The method first performs image registration in both the spatial and range domains. Then the point spread function (PSF) of LR images is parameterized by a Gaussian function and estimated by a blind deconvolution algorithm based on the maximum a posteriori (MAP). Finally, the high-resolution (HR) image is reconstructed by a MAP-based SR algorithm. The MAP cost function includes a data fidelity term and a regularized term. The data fidelity term is in the L2 norm, and the regularized term employs the Huber-Markov prior which can reduce the noise and artifacts while preserving the image edges. Experiments with real Gaofen-4 images show that the reconstructed images are sharper and contain more details than Google Earth ones. © 2017 by the authors.","Blind source separation; Convolution; Cost functions; Deconvolution; Image processing; Maps; Optical resolving power; Optical transfer function; Orbits; Remote sensing; Blind deconvolution; Blind deconvolution algorithms; High resolution image; High temporal resolution; Higher resolution images; Remote sensing images; Staring imaging; Super resolution; article; artifact; deconvolution algorithm; image registration; noise; point spread function; satellite imagery; Image reconstruction","Blind deconvolution; MAP; Remote sensing; Staring imaging; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85029791215"
"Xu W.; Xu G.; Wang Y.; Sun X.; Lin D.; Wu Y.","Xu, Wenjia (57192786946); Xu, Guangluan (56420820800); Wang, Yang (57821937600); Sun, Xian (34875643000); Lin, Daoyu (57196095251); Wu, Yirong (8403430500)","57192786946; 56420820800; 57821937600; 34875643000; 57196095251; 8403430500","High quality remote sensing image super-resolution using deep memory connected network","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8518855","8889","8892","3","10.1109/IGARSS.2018.8518855","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064151450&doi=10.1109%2fIGARSS.2018.8518855&partnerID=40&md5=1fbaf4dbe806a65946053bd719640a99","Single image super-resolution is an effective way to enhance the spatial resolution of remote sensing image, which is crucial for many applications such as target detection and image classification. However, existing methods based on the neural network usually have small receptive fields and ignore the image detail. We propose a novel method named deep memory connected network (DMCN) based on a convolutional neural network to reconstruct high-quality super-resolution images. We build local and global memory connections to combine image detail with environmental information. To further reduce parameters and ease time-consuming, we propose downsampling units, shrinking the spatial size of feature maps. We test DMCN on three remote sensing datasets with different spatial resolution. Experimental results indicate that our method yields promising improvements in both accuracy and visual performance over the current state-of-the-art. © 2018 IEEE","Convolution; Geology; Image enhancement; Image fusion; Image resolution; Neural networks; Optical resolving power; Connected networks; Convolutional neural network; Environmental information; Receptive fields; Remote sensing images; Spatial resolution; Super resolution; Visual performance; Remote sensing","Convolutional neural network; Image fusion; Remote sensing image; Super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85064151450"
"Yuan Y.; Zheng X.; Lu X.","Yuan, Yuan (57203237779); Zheng, Xiangtao (56022876500); Lu, Xiaoqiang (35180125200)","57203237779; 56022876500; 35180125200","Hyperspectral Image Superresolution by Transfer Learning","2017","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","10","5","7855724","1963","1974","11","10.1109/JSTARS.2017.2655112","154","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012981972&doi=10.1109%2fJSTARS.2017.2655112&partnerID=40&md5=5361ab25a83106398d41540f82a6012a","Hyperspectral image superresolution is a highly attractive topic in computer vision and has attracted many researchers' attention. However, nearly all the existing methods assume that multiple observations of the same scene are required with the observed low-resolution hyperspectral image. This limits the application of superresolution. In this paper, we propose a new framework to enhance the resolution of hyperspectral images by exploiting the knowledge from natural images: The relationship between low/high-resolution images is the same as that between low/high-resolution hyperspectral images. In the proposed framework, the mapping between low- A nd high-resolution images can be learned by deep convolutional neural network and be transferred to hyperspectral image by borrowing the idea of transfer learning. In addition, to study the spectral characteristic between low- A nd high-resolution hyperspectral image, collaborative nonnegative matrix factorization (CNMF) is proposed to enforce collaborations between the low- A nd high-resolution hyperspectral images, which encourages the estimated solution to extract the same endmembers with low-resolution hyperspectral image. The experimental results on ground based and remote sensing data suggest that the proposed method achieves comparable performance without requiring any auxiliary images of the same scene. © 2016 IEEE.","Deep learning; Deep neural networks; Factorization; Independent component analysis; Matrix algebra; Neural networks; Optical resolving power; Remote sensing; Convolutional neural network; High resolution image; Image super-resolution; Nonnegative matrix factorization; Remote sensing data; Spectral characteristics; Super resolution; Transfer learning; artificial neural network; computer vision; image resolution; imaging method; mapping; remote sensing; Spectroscopy","Collaborative nonnegative matrix factorization (CNMF); convolutional neural network (CNN); hyperspectral image (HSI) superresolution","Article","Final","","Scopus","2-s2.0-85012981972"
"Amala Dhason H.G.C.; Muthaia I.","Amala Dhason, Heltin Genitha Cyril (56419984000); Muthaia, Indhumathi (57216844565)","56419984000; 57216844565","A hybrid approach to super resolution mapping for water-spread area and capacity estimation of reservoir using satellite image (India)","2019","Advances in Science, Technology and Innovation","","","","65","68","3","10.1007/978-3-030-01440-7_16","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108094564&doi=10.1007%2f978-3-030-01440-7_16&partnerID=40&md5=ba76ce536c6c53d2070c6eb2e83fc0a4","For proper monitoring and scheduling of the supply of drinking water in reservoirs, it is necessary to carry out the capacity surveys. Remote sensing techniques can be used to estimate the capacity of the reservoirs in an inexpensive and less laborious way. In this paper, a super resolution mapping based on hybrid approach was developed and applied to Landsat OLI image of the Puzhal reservoir, Chennai city, southern India and the reservoir water-spread area was estimated. The estimated water-spread was used to find the capacity of the reservoir using Trapezoidal formula. The hybrid approach uses New Fuzzy Cluster Centroid (NFCC) algorithm for sub-pixel mapping and multi-objective genetic algorithm for super resolution mapping. The super resolution mapping is an advanced classification technique which accurately maps the location of classes within a pixel. The capacity determined from the image processing technique is compared with that estimated from the field survey data with a meagre 1.35% error. Hence, it is observed that the super resolution mapping is a prominent methodology to estimate the water-spread area of the reservoir which in turn increases the accuracy of the estimation capacity of the reservoir. © Springer Nature Switzerland AG 2019.","","Satellite image; Sub-pixel mapping; Super resolution mapping; Water-spread area","Book chapter","Final","","Scopus","2-s2.0-85108094564"
"Vishnukumar S.; Wilscy M.","Vishnukumar, S. (35175430100); Wilscy, M. (17436378300)","35175430100; 17436378300","Single image super-resolution based on compressive sensing and improved TV minimization sparse recovery","2017","Optics Communications","404","","","80","93","13","10.1016/j.optcom.2017.05.074","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021653160&doi=10.1016%2fj.optcom.2017.05.074&partnerID=40&md5=a3b7d6c54e5171b53fa558cea75ed6da","In this paper, we propose a single image Super-Resolution (SR) method based on Compressive Sensing (CS) and Improved Total Variation (TV) Minimization Sparse Recovery. In the CS framework, low-resolution (LR) image is treated as the compressed version of high-resolution (HR) image. Dictionary Training and Sparse Recovery are the two phases of the method. K-Singular Value Decomposition (K-SVD) method is used for dictionary training and the dictionary represents HR image patches in a sparse manner. Here, only the interpolated version of the LR image is used for training purpose and thereby the structural self similarity inherent in the LR image is exploited. In the sparse recovery phase the sparse representation coefficients with respect to the trained dictionary for LR image patches are derived using Improved TV Minimization method. HR image can be reconstructed by the linear combination of the dictionary and the sparse coefficients. The experimental results show that the proposed method gives better results quantitatively as well as qualitatively on both natural and remote sensing images. The reconstructed images have better visual quality since edges and other sharp details are preserved. © 2017 Elsevier B.V.","Compressed sensing; Image reconstruction; Optical resolving power; Recovery; Signal reconstruction; Singular value decomposition; Compressive sensing; Dictionary trainings; High resolution image; Low resolution images; Minimization methods; Remote sensing images; Sparse representation; Super resolution; Image processing","Compressive sensing (CS); K-singular value decomposition (K-SVD); Super-resolution; TV minimization","Article","Final","","Scopus","2-s2.0-85021653160"
"Zheng K.; Gao L.; Zhang B.; Cui X.","Zheng, Ke (57203106376); Gao, Lianru (14031580000); Zhang, Bing (8835983800); Cui, Ximin (24833089600)","57203106376; 14031580000; 8835983800; 24833089600","Multi-Losses Function Based Convolution Neural Network for Single Hyperspectral Image Super-Resolution","2018","5th International Workshop on Earth Observation and Remote Sensing Applications, EORSA 2018 - Proceedings","","","8598551","","","","10.1109/EORSA.2018.8598551","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061774012&doi=10.1109%2fEORSA.2018.8598551&partnerID=40&md5=3dc503ea8f303fdaa42ea1c6040c710b","Recently deep convolutional neural network (CNN) has made significant achievement in Single Image Super-Resolution (SISR). Most CNN-based SISR methods used the default L2 norm of the error. However, for Hyperspectral Image (HSI), this loss function may bring spectral inconsistencies. The main reason is that most methods did not pay much attention to spectral loss. To HSI, the loss function should capture not only spatial information but also spectral consistency. In this paper, a Multi-Losses Function Network (MLFN) simultaneously considering spatial and spectral information is proposed, and is composed of two parts: one is Concatenate Dense Residual Network (CDRN), and the other is Loss Network (LN). CDRN is an image reconstruction network which can utilize the hierarchical features extracted from the low-resolution image. LN includes pixel-wise spatial loss and spectral loss which drive the learning of the entire reconstruction model. The experimental results prove that the proposed MLFN can enhance spatial resolution with the consistency of the spectrum of HSI preserved. © 2018 IEEE.","Convolution; Deep learning; Deep neural networks; Hyperspectral imaging; Neural networks; Observatories; Optical resolving power; Remote sensing; Spectroscopy; Convolution neural network; Convolutional neural network; Hierarchical features; Image super resolutions; Low resolution images; Reconstruction networks; Spectral Consistency; Super resolution; Image reconstruction","Deep Learning; Hyperspectral Image; Spectral Consistency; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85061774012"
"Irmak H.; Akar G.B.; Uksel S.E.Y.","Irmak, Hasan (57189007589); Akar, Gozde Bozdagi (57208572487); Uksel, Seniha Esen Y (57211429518)","57189007589; 57208572487; 57211429518","Image Fusion for Hyperspectral Image Super-Resolution","2018","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2018-September","","8747231","","","","10.1109/WHISPERS.2018.8747231","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073909998&doi=10.1109%2fWHISPERS.2018.8747231&partnerID=40&md5=7cef1aa730551548129d796ed424d609","Hyperspectral sensors have high spectral resolution by capturing images in hundreds of bands. Despite the high spectral resolution, low spatial resolution of these sensors restricts the performance of the hyperspectral imaging applications such as target tracking and image classification. Fusing the hyper-spectral image (HSI) with higher spatial resolution RGB or multispectral image (MSI) data is a commonly used method in the resolution enhancement of the HSIs. In this paper, we propose a new fusion technique for the HSI super-resolution. The main contribution of this study is formulating the fusion problem in a quadratic manner and also regularizing the solution quadratically using smoothness prior. Moreover, another contribution of the proposed method is converting the fusion problem from spectral domain to the abundance map domain which gives more robust and spectrally consistent results. In the proposed method, first, abundance maps are obtained using linear spectral unmixing and then a quadratic energy function is obtained using these maps and high resolution (HR) RGB image. In addition, quadratic function is regularized using additional constraints. Solving the regularized quadratic function gives the HR abundance maps and these maps are used to reconstruct HR HSI. Experiments show that proposed method yields better performance as compared to state of the art methods in different performance metrics. © 2018 IEEE.","Hyperspectral imaging; Image enhancement; Image resolution; Quadratic programming; Remote sensing; Spectral resolution; Spectroscopy; Target tracking; High spectral resolution; HyperSpectral; Image super resolutions; Linear spectral unmixing; Quadratic optimization; Resolution enhancement; State-of-the-art methods; Super resolution; Image fusion","Abundance Maps; Hyperspectral; Image Fusion; Quadratic optimization; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85073909998"
"","","","20th International Conference on Image Analysis and Processing, ICIAP 2019","2019","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11751 LNCS","","","","","1318","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072955985&partnerID=40&md5=5b3decc96092fb86105a948c42c78256","The proceedings contain 117 papers. The special focus in this conference is on Image Analysis and Processing. The topics include: 3D shape segmentation with geometric deep learning; Multiple organs segmentation in abdomen CT scans using a cascade of CNNs; performance evaluation of learned 3D features; variational autoencoder inspired by brain’s convergence–divergence zones for autonomous driving application; hyperspectral image classification via convolutional neural network based on dilation layers; estimation of speed and distance of surrounding vehicles from a single camera; a convolutional neural network for virtual screening of molecular fingerprints; Evaluation of continuous image features learned by ODE nets; deep motion model for pedestrian tracking in 360 degrees videos; within-network ensemble for face attributes classification; visual and textual sentiment analysis of daily news social media images by deep learning; 3DMM for accurate reconstruction of depth data; The effects of data sources: A baseline evaluation of the MoCA dataset; take a ramble into solution spaces for classification problems in neural networks; supervised two-stage transfer learning on imbalanced dataset for sport classification; single image super-resolution for optical satellite scenes using deep deconvolutional network; genuine personality recognition from highly constrained face images; Deep compact person re-identification with distractor synthesis via guided DC-GANs; dimensionality reduction using discriminative autoencoders for remote sensing image retrieval; video-based convolutional attention for person re-identification; a low-cost computer vision system for real-time tennis analysis; Virtual crowds: An LSTM-based framework for crowd simulation; worldly eyes on video: Learnt vs. reactive deployment of attention to dynamic stimuli; low-complexity scene understanding network; preface.","","","Conference review","Final","","Scopus","2-s2.0-85072955985"
"Zhu F.; Liu Y.; Huang X.; Zhu H.","Zhu, Fuzhen (12780819500); Liu, Yue (57200522975); Huang, Xin (57204029373); Zhu, Haitao (57204846614)","12780819500; 57200522975; 57204029373; 57204846614","Remote Sensing Image Super-resolution Based on Sparse Representation","2018","MATEC Web of Conferences","232","","02037","","","","10.1051/matecconf/201823202037","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057450558&doi=10.1051%2fmatecconf%2f201823202037&partnerID=40&md5=6bb90b83f2ceec62898b786713050a7e","In order to obtain higher resolution remote sensing images with more details, an improved sparse representation remote sensing image super-resolution reconstruction(SRR) algorithm is proposed. First, remote sensing image is preprocessed to obtain the required training sample image; then, the KSVD algorithm is used for dictionary training to obtain the high-low resolution dictionary pairs; finally, the image feature extraction block is represented, which is improved by using adaptive filtering method. At the same time, the mean value filtering method is used to improve the super-resolution reconstruction iterative calculation. Experiment results show that, compared with the most advanced sparse representation super-resolution algorithm, the improved sparse representation super-resolution method can effectively avoid the loss of edge information of SRR image and obtain a better super-resolution reconstruction effect. The texture details are more abundant in subjective vision, the PSNR is increased about 1 dB, and the structure similarity (SSIM) is increased about 0.01. © The Authors, published by EDP Sciences, 2018.","Adaptive filtering; Adaptive filters; Edge detection; Image enhancement; Image reconstruction; Iterative methods; Optical resolving power; Image feature extractions; Iterative calculation; Mean value filtering; Remote sensing images; Sparse representation; Super resolution algorithms; Super resolution reconstruction; Superresolution methods; Remote sensing","","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85057450558"
"Zhou C.; Zhou J.","Zhou, Cui (55578922200); Zhou, Jinghong (56242343500)","55578922200; 56242343500","Single-Frame Remote Sensing Image Super-Resolution Reconstruction Algorithm Based on Two-Dimensional Wavelet","2018","2018 3rd IEEE International Conference on Image, Vision and Computing, ICIVC 2018","","","8492778","360","363","3","10.1109/ICIVC.2018.8492778","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056507721&doi=10.1109%2fICIVC.2018.8492778&partnerID=40&md5=fc543862b8df08bb8a2f56f444a5c4c5","The obtained precisely high frequency information is the key of single-frame image super-resolution reconstruction by using two-dimensional wavelet. Because the bicubic interpolation of high frequency components decomposed by wavelet will introduce noise, it will affect reconstruction effect. An improved algorithm using Fourier transform and zero-padding resampling instead of bicubic interpolation is proposed in this paper. The advantage of frequency domain interpolation is obtained by using Fourier transform and zero-padding resampling. And high frequency components obtained by wavelet decomposition of the original image can be interpolated optimally without introducing noise, which makes the high frequency details more precise in the reconstruction process. The experimental results show that the improved algorithm is superior to the traditional two-dimensional wavelet reconstruction algorithm, which can be applied to the single-frame remote sensing image super-resolution reconstruction. © 2018 IEEE.","Frequency domain analysis; Image enhancement; Interpolation; Optical resolving power; Remote sensing; Two dimensional; Wavelet decomposition; Bicubic interpolation; Frequency domain interpolation; High frequency components; High-frequency informations; Reconstruction process; Resampling; Single frame image; Wavelet reconstruction; Image reconstruction","Bicubic interpolation; Single-frame image super-resolution reconstruction; Two-dimensional wavelet transform; Zero-padding resampling","Conference paper","Final","","Scopus","2-s2.0-85056507721"
"Kwan C.","Kwan, Chiman (7201421216)","7201421216","Remote sensing performance enhancement in hyperspectral images","2018","Sensors (Switzerland)","18","11","3598","","","","10.3390/s18113598","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055613104&doi=10.3390%2fs18113598&partnerID=40&md5=dc5a65d849b49ce18dadba62a99cb63f","Hyperspectral images with hundreds of spectral bands have been proven to yield high performance in material classification. However, despite intensive advancement in hardware, the spatial resolution is still somewhat low, as compared to that of color and multispectral (MS) imagers. In this paper, we aim at presenting some ideas that may further enhance the performance of some remote sensing applications such as border monitoring and Mars exploration using hyperspectral images. One popular approach to enhancing the spatial resolution of hyperspectral images is pansharpening. We present a brief review of recent image resolution enhancement algorithms, including single super-resolution and multi-image fusion algorithms, for hyperspectral images. Advantages and limitations of the enhancement algorithms are highlighted. Some limitations in the pansharpening process include the availability of high resolution (HR) panchromatic (pan) and/or MS images, the registration of images from multiple sources, the availability of point spread function (PSF), and reliable and consistent image quality assessment. We suggest some proactive ideas to alleviate the above issues in practice. In the event where hyperspectral images are not available, we suggest the use of band synthesis techniques to generate HR hyperspectral images from low resolution (LR) MS images. Several recent interesting applications in border monitoring and Mars exploration using hyperspectral images are presented. Finally, some future directions in this research area are highlighted. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Hyperspectral imaging; Image fusion; Image resolution; Martian surface analysis; Optical transfer function; Remote sensing; Spectral resolution; Spectroscopy; Enhancement algorithms; Image quality assessment; Image resolution enhancements; Material classification; Pan-sharpening; Remote sensing applications; Resolution enhancement; Synthesis techniques; Image enhancement","Band synthesis; Hyperspectral images; Pansharpening; Remote sensing; Resolution enhancement; Spectral resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85055613104"
"Zhu H.; Gao X.; Tang X.; Xie J.; Song W.; Mo F.; Jia D.","Zhu, Hong (57190032288); Gao, Xiaoming (56047540600); Tang, Xinming (8520300900); Xie, Junfeng (7402994499); Song, Weidong (56512910400); Mo, Fan (57117407600); Jia, Di (36840119400)","57190032288; 56047540600; 8520300900; 7402994499; 56512910400; 57117407600; 36840119400","Super-resolution reconstruction and its application based on multilevel main structure and detail boosting","2018","Remote Sensing","10","12","2065","","","","10.3390/rs10122065","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058891755&doi=10.3390%2frs10122065&partnerID=40&md5=d67e2809486d80f7f9b83bd1681faec4","Vivid main structure and rich texture detail are important factors with which to determine the quality of high-resolution images after super-resolution (SR) reconstruction. Owing to the loss of high-frequency information in the process of SR reconstruction and the limitation of the accurate estimation of the unknown information in the inversion process, a gap still exists between the high-resolution image and the real image. The main structure can better preserve the edge structure of the image, and detail boosting can compensate for the missing high-frequency information in the reconstruction process. Therefore, a novel single remote-sensing image SR reconstruction method based on multilevel main structure and detail boosting (MMSDB-SR) is put forward in this paper. First, the multilevel main structure was obtained based on the decomposition of the remote-sensing image through use of the relative total variation model. Subsequently, multilevel texture detail information was obtained by a difference process. Second, the multilevel main structure and texture detail were reconstructed separately. The detail-boosting function was used to compensate for the missing high-frequency details in the reconstruction process. Finally, the high-resolution remote-sensing image with clear edge and rich texture detail can be obtained by fusing the multilevel main structure and texture-detail information. The experimental results show that the reconstructed high-resolution image has high clarity, high fidelity, and multi-detail visual effects, and the objective evaluation index exhibits significant improvement. Actual results show an average gain in entropy of up to 0.34 dB for an up-scaling of 2. Real results show an average gain in enhancement measure evaluation of up to 2.42 for an up-scaling of 2. The robustness and universality of the proposed SR method are verified. © 2018 by the authors.","Frequency estimation; Image enhancement; Image reconstruction; Optical resolving power; Remote sensing; Detail boosting; Main structure; Multilevel decomposition; Remote sensing images; Super resolution reconstruction; Image texture","Detail boosting; Main structure; Multilevel decomposition; Remote-sensing image; Super-resolution reconstruction","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85058891755"
"Morera-Delfín L.; Pinto-Elías R.; Ochoa-Domínguez H.-J.","Morera-Delfín, Leandro (57204354148); Pinto-Elías, Raúl (7006549214); Ochoa-Domínguez, Humberto-de-Jesús (55939609300)","57204354148; 7006549214; 55939609300","Overview of super-resolution techniques","2018","Advanced Topics on Computer Vision, Control and Robotics in Mechatronics","","","","101","127","26","10.1007/978-3-319-77770-2_5","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060434518&doi=10.1007%2f978-3-319-77770-2_5&partnerID=40&md5=12a23121bd4747c529834e8edeb2cded","In the last three decades, multi-frame and single-frame super-resolution and reconstruction techniques have been receiving increasing attention because of the large number of applications that many areas have found when increasing the resolution of their images. For example, in high-definition television, high-definition displays have reached a new level and resolution enhancement cannot be ignored; in some remote sensing applications, the pixel size is a limitation; and in medical imaging, the details are important for a more accurate diagnostic or acquiring high-resolution images while reducing the time of radiation to a patient. Some of the problems faced in this area, that in the future require dealing more effectively, are the inadequate representation of edges, inaccurate motion estimation between images, sub-pixel registration, and computational complexity among others. In this chapter, an overview of the most important methods classified into two taxonomies, multiple- and single-image super-resolution, is given. Moreover, two new techniques for single-image SR are proposed. © Springer International Publishing AG, part of Springer Nature 2018. All rights reserved.","Diagnosis; Digital television; Frequency domain analysis; High definition television; Medical imaging; Motion estimation; Optical resolving power; Pixels; Remote sensing; Television applications; Frequency domains; High definition display; Reconstruction techniques; Remote sensing applications; Single frame super resolutions; Sub-pixel registrations; Super resolution; Total variation; Image enhancement","Frequency domain; Spatial domain Total variation; Super-resolution","Book chapter","Final","","Scopus","2-s2.0-85060434518"
"","","","19th Pacific-Rim Conference on Multimedia, PCM 2018","2018","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11166 LNCS","","","","","2541","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054544658&partnerID=40&md5=78422fb46096c60049b42c102cf40f2e","The proceedings contain 229 papers. The special focus in this conference is on Multimedia. The topics include: Video clip growth: A general algorithm for multi-view video summarization; cross-media retrieval via deep semantic canonical correlation analysis and logistic regression; 3D global trajectory and multi-view local motion combined player action recognition in volleyball analysis; underwater image enhancement by the combination of dehazing and color correction; a novel no-reference QoE assessment model for frame freezing of mobile video; saliency detection based on deep learning and graph cut; rethinking fusion baselines for multi-modal human action recognition; A DCT-JND profile for disorderly concealment effect; breast ultrasound image classification and segmentation using convolutional neural networks; mixup-based acoustic scene classification using multi-channel convolutional neural network; intra-image region context for image captioning; viewpoint quality evaluation for augmented virtual environment; A flower classification framework based on ensemble of CNNs; Image translation between high-resolution remote sensing optical and SAR data using conditional GAN; A combined strategy of hand tracking for desktop VR; super-resolution of text image based on conditional generative adversarial network; latitude-based visual attention in 360-degree video display; branched convolutional neural networks for face alignment; a robust approach for scene text detection and tracking in video; improving intra block copy with low-rank based rectification for urban building scenes; multimodal fusion for traditional chinese painting generation; assembly-based 3D modeling using graph convolutional neural networks; blur measurement for partially blurred images with saliency constrained global refinement; SCAN: Spatial and channel attention network for vehicle re-identification; Cross-modal retrieval with discriminative dual-path CNN.","","","Conference review","Final","","Scopus","2-s2.0-85054544658"
"Fu J.; Liu Y.; Li F.","Fu, Jie (57199749988); Liu, Yuhong (57206819491); Li, Feng (57171116800)","57199749988; 57206819491; 57171116800","Single frame super resolution with convolutional neural network for remote sensing imagery","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8518584","8014","8017","3","10.1109/IGARSS.2018.8518584","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064248950&doi=10.1109%2fIGARSS.2018.8518584&partnerID=40&md5=b405e37f7be713d6ad99f6c47523ebd8","In this paper, a new convolutional neural networks based super resolution(SR) is proposed. SR has been a hot research area for decades, and it includes two types: single frame based SR and multi-frame based SR. The focus of the paper is to reconstruct the corresponding high resolution image from a given low resolution image. The popular end-to-end learning architecture is improved and no preprocessing and image aggregation are needed. Our network model(RSCNN) uses different convolution kernels for a set of feature maps in the feature mapping step, which ensures the accuracy of reconstruction results under the premise of improving the reconstruction quality. The method is applied to Jilin-1 which is the first self-developed commercial remote sensing satellite group in China. The results show the superiority of our method both visually and numerically by comparing with other excellent image super resolution algorithms. © 2018 IEEE.","Convolution; Geology; Image enhancement; Neural networks; Optical resolving power; Convolutional neural network; Image super resolutions; Learning architectures; Reconstruction quality; Remote sensing imagery; Remote sensing satellites; Single frame super resolutions; Single images; Remote sensing","Convolutional neural network; Jinlin-1 satellite; Single image super resolution","Conference paper","Final","","Scopus","2-s2.0-85064248950"
"Li C.; Zhang Y.; Zhang Y.; Huang Y.; Yang J.","Li, Changlin (57202954627); Zhang, Yongchao (56042343300); Zhang, Yin (55975581400); Huang, Yulin (23014806800); Yang, Jianyu (9239230100)","57202954627; 56042343300; 55975581400; 23014806800; 9239230100","Airborne radar forward-looking super-resolution imaging using an iterative adaptive approach","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8517547","7910","7913","3","10.1109/IGARSS.2018.8517547","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063145344&doi=10.1109%2fIGARSS.2018.8517547&partnerID=40&md5=38c12ea3caa4d4613b91daa20554db11","Airborne radar forward-looking imaging is of great significance in many remote sensing applications. However, the existing synthetic aperture radar (SAR) and Doppler beam sharpening (DBS) imaging techniques are incapable of forward-looking imaging. The real aperture radar (RAR) using a scanning antenna can provide forward-looking images, but suffers from coarse azimuth resolution. In this paper, we extend the iterative adaptive approach (IAA) to forward-looking super-resolution imaging. Different from the conventional forward-looking convolution model, both the Doppler phase and antenna convolution are considered in the new model, allowing for more accurate reconstruction of the forward-looking imaging scenario when applying the IAA. Simulation results demonstrate that the IAA-based super-resolution imaging can overcome the deficiencies of the SAR and DBS techniques in forward-looking imaging direction. © 2018 IEEE","","Airborne radar; Antenna convolution; Doppler phase; Forward-looking; Iterative adaptive approach","Conference paper","Final","","Scopus","2-s2.0-85063145344"
"Aydin V.A.; Foroosh H.","Aydin, Vildan Atalay (57208952190); Foroosh, Hassan (57207549389)","57208952190; 57207549389","In-band sub-pixel registration of wavelet-encoded images from sparse coefficients","2017","Signal, Image and Video Processing","11","8","","1527","1535","8","10.1007/s11760-017-1116-5","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019724354&doi=10.1007%2fs11760-017-1116-5&partnerID=40&md5=fbb717911a23520b3e297ee932c1d315","Sub-pixel registration is a crucial step for applications such as super-resolution in remote sensing, motion compensation in magnetic resonance imaging, and nondestructive testing in manufacturing, to name a few. Recently, these technologies have been trending towards wavelet-encoded imaging and sparse/compressive sensing. The former plays a crucial role in reducing imaging artifacts, while the latter significantly increases the acquisition speed. In view of these new emerging needs for applications of wavelet-encoded imaging, we propose a sub-pixel registration method that can achieve direct wavelet domain registration from a sparse set of coefficients. We make the following contributions: (i) We devise a method of decoupling scale, rotation, and translation parameters in the Haar wavelet domain, (ii) we derive explicit mathematical expressions that define in-band sub-pixel registration in terms of wavelet coefficients, (iii) using the derived expressions, we propose an approach to achieve in-band sub-pixel registration, avoiding back and forth transformations. (iv) Our solution remains highly accurate even when a sparse set of coefficients are used, which is due to localization of signals in a sparse set of wavelet coefficients. We demonstrate the accuracy of our method, and show that it outperforms the state of the art on simulated and real data, even when the data are sparse. © 2017, Springer-Verlag London.","Magnetic resonance imaging; Mathematical transformations; Motion compensation; Nondestructive examination; Pixels; Remote sensing; Wavelet transforms; Haar wavelets; Image pyramids; Imaging artifacts; Mathematical expressions; Sub-pixel registrations; Super resolution; Translation parameters; Wavelet coefficients; Wavelet decomposition","Haar wavelets; Image pyramids; Sub-pixel registration; Wavelet decomposition","Article","Final","","Scopus","2-s2.0-85019724354"
"Xu X.; Tong X.; Plaza A.; Li J.; Zhong Y.; Xie H.; Zhang L.","Xu, Xiong (55520591300); Tong, Xiaohua (55500134600); Plaza, Antonio (7006613644); Li, Jun (24481713500); Zhong, Yanfei (12039673900); Xie, Huan (36117406500); Zhang, Liangpei (8359720900)","55520591300; 55500134600; 7006613644; 24481713500; 12039673900; 36117406500; 8359720900","A new spectral-spatial sub-pixel mapping model for remotely sensed hyperspectral imagery","2018","IEEE Transactions on Geoscience and Remote Sensing","56","11","8410597","6763","6778","15","10.1109/TGRS.2018.2842748","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049961475&doi=10.1109%2fTGRS.2018.2842748&partnerID=40&md5=bd791833c0112bcbe9aed5eb835cbdfa","In this paper, a new joint spectral-spatial subpixel mapping model is proposed for hyperspectral remotely sensed imagery. Conventional approaches generally use an intermediate step based on the derivation of fractional abundance maps obtained after a spectral unmixing process, and thus the rich spectral information contained in the original hyperspectral data set may not be utilized fully. In this paper, a concept of subpixel abundance map, which calculates the abundance fraction of each subpixel to belong to a given class, was introduced. This allows us to directly connect the original (coarser) hyperspectral image with the final subpixel result. Furthermore, the proposed approach incorporates the spectral information contained in the original hyperspectral imagery and the concept of spatial dependence to generate a final subpixel mapping result. The proposed approach has been experimentally evaluated using both synthetic and real hyperspectral images, and the obtained results demonstrate that the method achieves better results when compared to other seven subpixel mapping methods. The numerical comparisons are based on different indexes such as the overall accuracy and the CPU time. Moreover, the obtained results are statistically significant at 95% confidence. © 2018 IEEE.","Genetic algorithms; Image resolution; Independent component analysis; Linear programming; Neural networks; Photomapping; Pixels; Remote sensing; Spectroscopy; Conventional approach; Hyper-spectral imageries; Numerical comparison; Remotely sensed imagery; Spectral information; Spectral unmixing; Sub-pixel mapping; Super-resolution mappings; data set; image analysis; multispectral image; numerical method; pixel; remote sensing; resolution; Hyperspectral imaging","Hyperspectral imaging; spectral unmixing; subpixel mapping; super-resolution mapping","Article","Final","","Scopus","2-s2.0-85049961475"
"Wang P.; Zhang G.; Hao S.; Wang L.","Wang, Peng (57189493188); Zhang, Gong (35241577600); Hao, Siyuan (55554767400); Wang, Liguo (55745497100)","57189493188; 35241577600; 55554767400; 55745497100","Improving remote sensing image super-resolution mapping based on the spatial attraction model by utilizing the pansharpening technique","2019","Remote Sensing","11","3","247","","","","10.3390/rs11030247","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061404911&doi=10.3390%2frs11030247&partnerID=40&md5=46ae1acbc41af24dcbc8fbf255e166d9","The spatial distribution information of remote sensing images can be derived by the super-resolution mapping (SRM) technique. Super-resolution mapping, based on the spatial attraction model (SRMSAM), has been an important SRM method, due to its simplicity and explicit physical meanings. However, the resolution of the original remote sensing image is coarse, and the existing SRMSAM cannot take full advantage of the spatial-spectral information from the original image. To utilize more spatial-spectral information, improving remote sensing image super-resolution mapping based on the spatial attraction model by utilizing the pansharpening technique (SRMSAM-PAN) is proposed. In SRMSAM-PAN, a novel processing path, named the pansharpening path, is added to the existing SRMSAM. The original coarse remote sensing image is first fused with the high-resolution panchromatic image from the same area by the pansharpening technique in the novel pansharpening path, and the improved image is unmixed to obtain the novel fine-fraction images. The novel fine-fraction images from the pansharpening path and the existing fine-fraction images from the existing path are then integrated to produce finer-fraction images with more spatial-spectral information. Finally, the values predicted from the finer-fraction images are utilized to allocate class labels to all subpixels, to achieve the final mapping result. Experimental results show that the proposed SRMSAM-PAN can obtain a higher mapping accuracy than the existing SRMSAM methods. © 2019 by the authors.","Optical resolving power; Photomapping; Remote sensing; Mapping accuracy; Novel processing; Pan-sharpening; Panchromatic images; Physical meanings; Remote sensing images; Spectral information; Super-resolution mappings; Image enhancement","Pansharpening technique; Remote sensing image; Spatial attraction model; Super-resolution mapping","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85061404911"
"Mishra S.K.; Sharma M.; Ung B.","Mishra, Satyendra K. (55279344600); Sharma, Manish (57200423141); Ung, Bora (16240384500)","55279344600; 57200423141; 16240384500","OAM beam propagation in hollow core capillary fiber for the study of chiral light matter interactions","2019","Proceedings of SPIE - The International Society for Optical Engineering","11083","","1108330","","","","10.1117/12.2528855","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073784794&doi=10.1117%2f12.2528855&partnerID=40&md5=5bc0b5aa4e85f7f0250455132f2047ec","Beams carrying orbital angular momentum (OAM) are attractive as they offer a theoretically unbounded number of discrete states and have therefore been a subject of great interest for a variety of fundamental and applied research including optical communications, optical trapping, super-resolution microscopy, remote sensing and quantum information. In this work, we present a study on the use of fused silica capillary optical fibers for OAM beam propagation by means of antiresonant reflecting waveguiding. In particular, we propose the application of these simple and commercially available fibers for probing the light-matter interactions within the hollow core. We show that OAM beams (topological charge |L| = 1) of high mode purity (>90%) can be achieved in such capillary fibers. The stability of the OAM beam propagation was theoretically and experimentally demonstrated in the visible range. A numerical study based on full-vector finite-element method is conducted to characterize the change of OAM mode purity and loss as a function of the refractive index (RI) of the material filling the core. The propagation loss remains in the range of a few dB/m throughout the range of RI values varying from 1 to 1.39 that encompasses many analytes in the vapor or liquid phase. Finally, we propose that the simple capillary fiber can be used as a cost-effective optofluidic platform to study OAM light-matter interactions and new optical phenomena involving biochemical analytes. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Cost effectiveness; Micromanipulators; Numerical methods; Optical communication; Optical fibers; Quantum optics; Refractive index; Remote sensing; Capillary fibers; Hollow core fiber; Light-matter interactions; OAM beams; Opto-fluidics; Fused silica","Capillary fiber; Hollow core fiber; Light-matter interactions; OAM beams; Optofluidics","Conference paper","Final","","Scopus","2-s2.0-85073784794"
"Zhang T.; Du Y.; Lu F.","Zhang, Ting (56999385700); Du, Yi (35731460300); Lu, Fangfang (35173394600)","56999385700; 35731460300; 35173394600","Super-resolution reconstruction of remote sensing images using multiple-point statistics and isometric mapping","2017","Remote Sensing","9","7","724","","","","10.3390/RS9070724","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057025771&doi=10.3390%2fRS9070724&partnerID=40&md5=b9dc6a6dde7c75767a79c785079884ff","When using coarse-resolution remote sensing images, super-resolution reconstruction is widely desired, and can be realized by reproducing the intrinsic features from a set of coarse-resolution fraction data to fine-resolution remote sensing images that are consistent with the coarse fraction information. Prior models of spatial structures that encode the expected features at the fine (target) resolution are helpful to constrain the spatial patterns of remote sensing images to be generated at that resolution. These prior models can be used properly by multiple-point statistics (MPS), capable of extracting the intrinsic features of patterns from prior models such as training images, and copying them to the simulated regions using hard and soft conditional data, or even without any conditional data. However, because traditional MPS methods based on linear dimensionality reduction are not suitable to deal with nonlinear data, and isometric mapping (ISOMAP) can reduce the dimensionality of nonlinear data effectively, this paper presents a sequential simulation framework for generating super-resolution remote sensing images using ISOMAP and MPS. Using four different examples, it is demonstrated that the structural characteristics of super-resolution reconstruction of remote sensing images using this method, are similar to those of training images. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Data reduction; Image reconstruction; Mapping; Remote sensing; Coarser resolution; Dimensionality reduction; Intrinsic features; Isometric mapping; Multiple-point statistics; Prior modeling; Remote sensing images; Soft data; Super-resolution reconstruction; Training image; Optical resolving power","Dimensionality reduction; Remote sensing images; Soft data; Super-resolution reconstruction; Training image","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85057025771"
"Amiri M.; Ahmadyfard A.; Abolghasemi V.","Amiri, Mahmood (57193790581); Ahmadyfard, Alireza (23003581100); Abolghasemi, Vahid (23466416200)","57193790581; 23003581100; 23466416200","A fast video super resolution for facial image","2019","Signal Processing: Image Communication","70","","","259","270","11","10.1016/j.image.2018.10.008","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056244814&doi=10.1016%2fj.image.2018.10.008&partnerID=40&md5=bfb5d632448e9536184dae59326febb9","Multi-frame super resolution has found various applications in different domains of machine vision such as remote sensing, object recognition, and security applications for the last two decades. Classic super resolution methods are not able to handle real word videos where different parts of scene undergo different motions. Most of recent methods in the literature address this problem but they suffer from time complexity. In this paper, we propose a fast method for super resolution of facial videos. Our proposed method provides less computational complexity in addition to handling videos having general motion patterns. These two benefits make the proposed method suitable for security purposes. In the proposed method, first we extract a number of key points from face in each video frame. Then, for each pixel in the reference frame the corresponding pixels in other frames are determined using triangular patches. Subsequently, the obtained solution is improved by minimizing an energy function considering both appearance and pixel displacements. Super resolved facial image is finally obtained by using information available in a small window around approximated location of the low resolution frames. The effectiveness of the proposed method has been demonstrated for real video sequences. © 2018 Elsevier B.V.","Object recognition; Pixels; Remote sensing; Dense registration; Different domains; Facial images; Pixel displacement; Real video sequences; Security application; Superresolution methods; Video super-resolution; Optical resolving power","Dense registration; Facial image; Video super resolution","Article","Final","","Scopus","2-s2.0-85056244814"
"Shi Y.; Zhu X.X.; Yin W.; Bamler R.","Shi, Yilei (55495784300); Zhu, Xiao Xiang (55696622200); Yin, Wotao (8729349300); Bamler, Richard (7004572990)","55495784300; 55696622200; 8729349300; 7004572990","A fast and accurate basis pursuit denoising algorithm with application to super-resolving tomographic SAR","2018","IEEE Transactions on Geoscience and Remote Sensing","56","10","8412239","6148","6158","10","10.1109/TGRS.2018.2832721","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053603100&doi=10.1109%2fTGRS.2018.2832721&partnerID=40&md5=d8284361f446052d88f81e6acf25167e","L1 regularization is used for finding sparse solutions to an underdetermined linear system. As sparse signals are widely expected in remote sensing, this type of regularization scheme and its extensions have been widely employed in many remote sensing problems, such as image fusion, target detection, image super-resolution, and others, and have led to promising results. However, solving such sparse reconstruction problems is computationally expensive and has limitations in its practical use. In this paper, we proposed a novel efficient algorithm for solving the complex-valued L1 regularized least squares problem. Taking the high-dimensional tomographic synthetic aperture radar (TomoSAR) as a practical example, we carried out extensive experiments, both with the simulation data and the real data, to demonstrate that the proposed approach can retain the accuracy of the second-order methods while dramatically speeding up the processing by one or two orders. Although we have chosen TomoSAR as the example, the proposed method can be generally applied to any spectral estimation problems. © 2018 IEEE.","","Basis pursuit denoising (BPDN); L<sub>1</sub> regularization; proximal gradient (PG); second-order cone programming (SOCP); TomoSAR","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85053603100"
"Logofătu P.C.; Damian V.; Vasile T.; Pascu M.L.","Logofătu, P.C. (27867768900); Damian, V. (6701532728); Vasile, T. (55209049600); Pascu, M.L. (7005283583)","27867768900; 6701532728; 55209049600; 7005283583","Two instances of image super-resolution using sensor raster scanning and deconvolution","2019","Romanian Reports in Physics","71","1","401","","","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063596278&partnerID=40&md5=beb1d5b7f860f1398e741c0bfad25536","Super-resolution reconstructs a high-resolution image from one or more low-resolution recorded images. It uses a variety of hardware techniques, such as sensor raster scanning, or software techniques, such as interpolation, iterative backprojection, and the regularized methods, and it is useful in a variety of applications, such as video surveillance, medical diagnosis and remote sensing. Two applications based on the same technique are presented here in some detail: first, the hyperspectral characterization of a THz beam generated by a Time Domain Spectroscopy device and second, the resolution-enhanced photography. In both cases, images recorded by the sensor during a subpixel raster scan were interwoven in a high-resolution image, subsequently deconvoluted with a constant square kernel of the size of the sensor pixel. For hyperspectral characterization, regularization was necessary, whereas for resolutionenhanced photography, simple deconvolution sufficed. Magee’s approach to superresolution, which does not use convolution, was analyzed and rejected. © 2019, Editura Academiei Romane. All rights reserved.","","Deconvolution; Hyperspectroscopy; Super-resolution","Article","Final","","Scopus","2-s2.0-85063596278"
"Tuna C.; Unal G.; Sertel E.","Tuna, Caglayan (57191850673); Unal, Gozde (57220534209); Sertel, Elif (21934838300)","57191850673; 57220534209; 21934838300","Single-frame super resolution of remote-sensing images by convolutional neural networks","2018","International Journal of Remote Sensing","39","8","","2463","2479","16","10.1080/01431161.2018.1425561","35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041435269&doi=10.1080%2f01431161.2018.1425561&partnerID=40&md5=92ef93afd8e287d8e3d6491aaac77722","Super resolution (SR) refers to generation of a high-resolution (HR) image from a decimated, blurred, low-resolution (LR) image set, which can be either a single-frame or multi-frame that contains a collection of images acquired from slightly different views of the same observation area. In this study, two convolutional neural network (CNN)-based deep learning techniques are adapted in single-frame SR to increase the resolution of remote sensing (RS) images by a factor of 2, 3, and 4. In order to both preserve the colour information and speed up the algorithm, first an intensity hue saturation (IHS) transform is utilized and the SR techniques are only applied to the intensity channel of the images. Colour information is then restored with an inverse IHS transformation. We demonstrate the results of the proposed method on RS images acquired from Satellites Pour l’Observation de la Terre (SPOT) or Earth-observing satellites and Pleiades satellites with different spatial resolution. First synthetic LR images are created by downsampling, then structural similarity (SSIM) Index, peak signal-to-noise ratio (PSNR), Spectral Angle Mapper (SAM) and Erreur Relative Globale Adimensionnelle de Synthese (ERGAS) values are calculated for a quantitative evaluation of the methods. Finally, the method, with better performance results, is tested within a real scenario, that is, with original LR images as the input. The obtained HR images demonstrated visible qualitative enhancements. © 2018 Informa UK Limited, trading as Taylor & Francis Group.","Convolution; Deep learning; Image acquisition; Image segmentation; Inverse problems; Neural networks; Optical resolving power; Remote sensing; Satellites; Signal to noise ratio; Convolutional neural network; Convolutional Neural Networks (CNN); Earth observing satellite; Intensity hue saturations; Peak Signal to Noise Ratio (PSNR); Quantitative evaluation; Single frame super resolutions; Structural similarity indices (SSIM); algorithm; artificial neural network; image resolution; remote sensing; spatial resolution; Image enhancement","","Article","Final","","Scopus","2-s2.0-85041435269"
"Muad A.M.","Muad, Anuar M. (36681355600)","36681355600","Shape characterization of land covers using super-resolution mapping","2017","2017 IEEE 8th Control and System Graduate Research Colloquium, ICSGRC 2017 - Proceedings","","","8070568","57","61","4","10.1109/ICSGRC.2017.8070568","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039972526&doi=10.1109%2fICSGRC.2017.8070568&partnerID=40&md5=bb4c8ae34ddd60522e0264a00cfd109c","This paper presents a representation of land cover from a popular low spatial resolution of remote sensing image, MODIS 250 m. The spatial resolution of the MODIS image is enhanced using super-resolution mapping to a resolution that is equal to resolution of Landsat ETM+, which is 30 m. Two super-resolution mapping techniques, Hopfleld neural network and pixel swapping are used to represent the land covers as patch objects. Parameters for both techniques are varies to investigate their impact towards the characterization of the object in a single MODIS image and also in a time-series MODIS images. © 2017 IEEE.","Hopfield neural networks; Image enhancement; Image resolution; Optical resolving power; Pixels; Radiometers; Remote sensing; LANDSAT; MODIS; Object based; Pixel-swapping; Remote sensing images; Shape characterization; Spatial resolution; Super-resolution mappings; Mapping","Hopfield neural network; Landsat; MODIS; Object based remote sensing; Pixel swapping; Remote sensing","Conference paper","Final","","Scopus","2-s2.0-85039972526"
"Matongera T.N.; Mutanga O.; Dube T.; Lottering R.T.","Matongera, Trylee Nyasha (57195959448); Mutanga, Onisimo (55912148400); Dube, Timothy (55629520500); Lottering, Romano Trent (55520837100)","57195959448; 55912148400; 55629520500; 55520837100","Detection and mapping of bracken fern weeds using multispectral remotely sensed data: a review of progress and challenges","2018","Geocarto International","33","3","","209","224","15","10.1080/10106049.2016.1240719","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041214156&doi=10.1080%2f10106049.2016.1240719&partnerID=40&md5=46b077bf3ee728f016603ff4e789b7c8","Bracken fern is one of the major invasive plants distributed all over the world currently threatening socio-economic and ecological systems due to its ability to swiftly colonize landscapes. The study aimed at reviewing the progress and challenges in detecting and mapping of bracken fern weeds using different remote sensing techniques. Evidence from literature have revealed that traditional methods such as field surveys and modelling have been insufficient in detecting and mapping the spatial distribution of bracken fern at a regional scale. The applications of medium spatial resolution sensors have been constrained by their limited spatial, spectral and radiometric capabilities in detecting and mapping bracken fern. On the other hand, the availability of most of these data-sets free of charge, large swath width and their high temporal resolution have significantly improved remote sensing of bracken fern. The use of commercial satellite data with high resolution have also proven useful in providing fine spectral and spatial resolution capabilities that are primarily essential to offer precise and reliable data on the spatial distribution of invasive species. However, the application of these data-sets is largely restricted to smaller areas, due to high costs and huge data volumes. Studies on bracken fern classification have extensively adopted traditional classification methods such as supervised maximum likelihood classifier. In studies where traditional methods performed poorly, the combination of soft classifiers such as super resolution analysis and traditional methods of classification have shown an improvement in bracken fern classification. Finally, since high spatial resolution sensors are expensive to acquire and have small swath width, the current study recommends that future research can also consider investigating the utility of the freely available recently launched sensors with a global footprint that has the potential to provide invaluable information for repeated measurement of invasive species over time and space. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","Pteridium aquilinum; detection method; fern; mapping; remote sensing; satellite data; satellite imagery; sensor; spatial analysis; spatial resolution; weed","Bracken fern; classification; encroachment; global distribution; mapping; satellite imagery; spatial configuration","Review","Final","","Scopus","2-s2.0-85041214156"
"Sun Y.; Zhang W.; Gu H.; Liu C.; Hong S.; Xu W.; Yang J.; Gui G.","Sun, Yingyi (57207933852); Zhang, Wei (57192222344); Gu, Hao (57208473553); Liu, Chao (57215725572); Hong, Sheng (57200651045); Xu, Wenhua (57207932142); Yang, Jie (57192104836); Gui, Guan (24168616700)","57207933852; 57192222344; 57208473553; 57215725572; 57200651045; 57207932142; 57192104836; 24168616700","Convolutional Neural Network Based Models for Improving Super-Resolution Imaging","2019","IEEE Access","7","","6287639","43042","43051","9","10.1109/ACCESS.2019.2908501","24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064869864&doi=10.1109%2fACCESS.2019.2908501&partnerID=40&md5=46419bf4674ab8c29943290a9a2cacf3","Many fields, such as remote sensing, medical imaging, and biological detection, pose a technical challenge for achieving super-resolution imaging. Convolutional neural networks (CNNs) are considered one of the potential solutions to realize the super-resolution. In this paper three-layer, CNN-based models are proposed to reconstruct the super-resolution images using four optimization algorithms, i.e., stochastic gradient descent, adaptive gradient (AdaGrad), root mean square prop (RMSprop), and adaptive moment estimation (ADAM). Among these four optimizations, ADAM is considered to have the best performance. To further verify the impact of the number of convolution layers on performance, a selection of CNN-based models with four convolutional layers is then proposed, each of which is named with the convolution parameters. All the four-layer models are optimized with ADAM, and the experimental results indicate that the 9-3-3-5 model achieves the best performance in the super-resolution reconstruction task. © 2013 IEEE.","Convolution; Deep learning; Neural networks; Optical resolving power; Optimization; Remote sensing; Stochastic models; Stochastic systems; Biological detection; Convolutional neural network; Moment estimation; Optimization algorithms; Stochastic gradient descent; Super resolution imaging; Super resolution reconstruction; Technical challenges; Medical imaging","adaptive moment estimation; convolutional neural networks; deep learning; Super-resolution imaging","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85064869864"
"Yanovsky I.; Wen Y.; Behrangi A.; Schreier M.; Lambrigtsen B.","Yanovsky, Igor (16403652300); Wen, Yixin (45961585400); Behrangi, Ali (26026749200); Schreier, Mathias (56219284300); Lambrigtsen, Bjorn (6603478504)","16403652300; 45961585400; 26026749200; 56219284300; 6603478504","Validating enhanced resolution of microwave sounder imagery through fusion with infrared sensor data","2018","15th Specialist Meeting on Microwave Radiometry and Remote Sensing of the Environment, MicroRad 2018 - Proceedings","","","8430703","86","90","4","10.1109/MICRORAD.2018.8430703","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052962494&doi=10.1109%2fMICRORAD.2018.8430703&partnerID=40&md5=94648cde731f35b2c37354aa434c8231","In this paper, we describe and validate a data fusion methodology and apply it to enhance the resolution of a microwave image using the data from a collocated infrared/visible sensor. Such an approach takes advantage of the spatial resolution of the infrared instrument and the sensing accuracy of the microwave instrument. We test our method using a precipitation scene captured with the Advanced Microwave Sounding Unit (AMSU-B) microwave instrument and the Advanced Very High Resolution Radiometer (AVHRR) infrared instrument and compare the results to simultaneous radar observations. We show that the data fusion product is better than the original AMSU-Band AVHRR observations across all statistical indicators. © 2018 IEEE.","Advanced very high resolution radiometers (AVHRR); Data fusion; Image enhancement; Infrared detectors; Infrared instruments; Microwave acoustic devices; Microwaves; Precipitation (chemical); Radiometry; Remote sensing; Sensor data fusion; Sounding apparatus; Advanced microwave sounding units; Enhanced resolutions; Fusion methodology; Microwave instruments; Sparse optimizations; Spatial resolution; Statistical indicators; Super resolution; Microwave sensors","Data fusion; precipitation; remote sensing; sparse optimization; super-resolution","Conference paper","Final","","Scopus","2-s2.0-85052962494"
"Chen Y.; Ge Y.; An R.; Chen Y.","Chen, Yuehong (56084228300); Ge, Yong (26655529300); An, Ru (8584392800); Chen, Yu (57193862260)","56084228300; 26655529300; 8584392800; 57193862260","Super-resolution mapping of impervious surfaces from remotely sensed imagery with points-of-interest","2018","Remote Sensing","10","2","242","","","","10.3390/rs10020242","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042527042&doi=10.3390%2frs10020242&partnerID=40&md5=33e4604734f163651cdd921f346447c4","The accurate mapping of impervious surfaces is of key significance for various urban applications. Usually, traditional methods extract the proportion image of impervious surfaces from remote sensing images; however, the proportion image cannot specify where the impervious surfaces spatially distribute within a pixel. Meanwhile, impervious surfaces often locate urban areas and have a strong correlation with the relatively new big (geo)data points of interest (POIs). This study, therefore, proposed a novel impervious surfaces mapping method (super-resolution mapping of impervious surfaces, SRMIS) by combining a super-resolution mapping technique and POIs to increase the spatial resolution of impervious surfaces in proportion images and determine the accurate spatial location of impervious surfaces within each pixel. SRMIS was evaluated using a 10-m Sentinel-2 image and a 30-m Landsat 8 Operational Land Imager (OLI) image of Nanjing city, China. The experimental results show that SRMIS generated satisfactory impervious surface maps with better-classified image quality and greater accuracy than a traditional hard classifier, the two existing super-resolution mapping (SRM) methods of the subpixel-swapping algorithm, or the method using both pixel-level and subpixel-level spatial dependence. The experimental results show that the overall accuracy increase of SRMIS was from 2.34% to 5.59% compared with the hard classification method and the two SRM methods in the first experiment, while the overall accuracy of SRMIS was 1.34-3.09% greater than that of the compared methods in the second experiment. Hence, this study provides a useful solution to combining SRM techniques and the relatively new big (geo)data (i.e., POIs) to extract impervious surface maps with a higher spatial resolution than that of the input remote sensing images, and thereby supports urban research. © 2018 by the authors.","Image resolution; Mapping; Optical resolving power; Pixels; Remote sensing; Impervious surface; Points of interest; Spatial dependence; Super-resolution mappings; Urban remote sensing; Image processing","Impervious surfaces; Points of interest; Spatial dependence; Super-resolution mapping; Urban remote sensing","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85042527042"
"Liu H.; Fu Z.; Han J.; Shao L.; Liu H.","Liu, Heng (57022065500); Fu, Zilin (57201062491); Han, Jungong (14522692900); Shao, Ling (55643855000); Liu, Hongshen (12805845100)","57022065500; 57201062491; 14522692900; 55643855000; 12805845100","Single satellite imagery simultaneous super-resolution and colorization using multi-task deep neural networks","2018","Journal of Visual Communication and Image Representation","53","","","20","30","10","10.1016/j.jvcir.2018.02.016","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043229610&doi=10.1016%2fj.jvcir.2018.02.016&partnerID=40&md5=45ff504eadf171a2896b41df3ed4ec7f","Satellite imagery is a kind of typical remote sensing data, which holds preponderance in large area imaging and strong macro integrity. However, for most commercial space usages, such as virtual display of urban traffic flow, virtual interaction of environmental resources, one drawback of satellite imagery is its low spatial resolution, failing to provide the clear image details. Moreover, in recent years, synthesizing the color for grayscale satellite imagery or recovering the original color of camouflage sensitive regions becomes an urgent requirement for large spatial objects virtual reality interaction. In this work, unlike existing works which solve these two problems separately, we focus on achieving image super-resolution (SR) and image colorization synchronously. Based on multi-task learning, we provide a novel deep neural network model to fulfill single satellite imagery SR and colorization simultaneously. By feeding back the color feature representations into the SR network and jointly optimizing such two tasks, our deep model successfully achieves the mutual cooperation between imagery reconstruction and image colorization. To avoid color bias, we not only adopt the non-satellite imagery to enrich the color diversity of satellite image, but also recalculate the prior color distribution and the valid color range based on the mixed data. We evaluate the proposed model on satellite images from different data sets, such as RSSCN7 and AID. Both the evaluations and comparisons reveal that the proposed multi-task deep learning approach is superior to the state-of-the-art methods, where image SR and colorization can be accomplished simultaneously and efficiently. © 2018 Elsevier Inc.","Color; Deep learning; Deep neural networks; Learning systems; Optical resolving power; Remote sensing; Satellites; Virtual reality; Environmental resources; Image super resolutions; Multitask learning; Neural network model; Satellite images; State-of-the-art methods; Virtual interactions; Virtual reality interactions; Satellite imagery","Deep neural networks; Image super-resolution; Multi-task learning; Satellite image colorization","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85043229610"
"Zhao X.; Cao J.; Zhou Z.; Huang J.","Zhao, Xiaodong (55705116900); Cao, Jianzhong (8243343200); Zhou, Zuofeng (15835945100); Huang, Jijiang (55840631500)","55705116900; 8243343200; 15835945100; 55840631500","A novel PDE-based single image super-resolution reconstruction method","2017","International Journal of Pattern Recognition and Artificial Intelligence","31","6","1754010","","","","10.1142/S0218001417540106","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011843817&doi=10.1142%2fS0218001417540106&partnerID=40&md5=2915e1aff8f640eb72c95d3bbb8ee924","For applications such as remote sensing imaging and medical imaging, high-resolution (HR) images are urgently required. Image Super-Resolution (SR) reconstruction has great application prospects in optical imaging. In this paper, we propose a novel unified Partial Differential Equation (PDE)-based method to single image SR reconstruction. Firstly, two directional diffusion terms calculated by Anisotropic Nonlinear Structure Tensor (ANLST) are constructed, combing information of all channels to prevent singular results, making full use of its directional diffusion feature. Secondly, by introducing multiple orientations estimation using high order matrix-valued tensor instead of gradient, orientations can be estimated more precisely for junctions or corners. As a unique descriptor of orientations, mixed orientation parameter (MOP) is separated into two orientations by finding roots of a second-order polynomial in the nonlinear part. Then, we synthesize a Gradient Vector Flow (GVF) shock filter to balance edge enhancement and de-noising process. Experimental results confirm the validity of the method and show that the method enhances image edges, restores corners or junctions, and suppresses noise robustness, which is competitive with the existing methods. © 2017 World Scientific Publishing Company.","Anisotropy; Image reconstruction; Medical imaging; Nonlinear equations; Optical resolving power; Partial differential equations; Remote sensing; Tensors; Image super resolutions; Multiple orientations; Nonlinear structure tensor; Partial differential equations (PDE); Remote sensing imaging; Second-order polynomial; Single-image super-resolution reconstruction; Super resolution; Image processing","Anisotropic nonlinear structure tensor; GVF; orientations estimation; partial differential equation; super-resolution","Article","Final","","Scopus","2-s2.0-85011843817"
"Wang W.; Li M.; Wang W.; Qi J.; Liu J.; Tang W.; Yi W.; Guo Y.; Zhu M.; Zhu J.; Li X.","Wang, Wei (56948645300); Li, Mengzhu (57208192648); Wang, Weizheng (46261700200); Qi, Junli (54392109200); Liu, Jiying (55199488700); Tang, Wusheng (55612050800); Yi, Wenjun (56517572400); Guo, Yanfang (57206256083); Zhu, Mengjun (57200258270); Zhu, Jubo (7405689299); Li, Xiujian (55542118600)","56948645300; 57208192648; 46261700200; 54392109200; 55199488700; 55612050800; 56517572400; 57206256083; 57200258270; 7405689299; 55542118600","Super-resolution hyperspectral compressed sampling imaging by push-broom coded aperture","2019","Proceedings of SPIE - The International Society for Optical Engineering","11186","","1118613","","","","10.1117/12.2537503","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077800384&doi=10.1117%2f12.2537503&partnerID=40&md5=beb5cd6bdb72c9576eff26a6e694e05c","Super-resolution hyperspectral imaging is a key technology for many applications, especially in the fields of remote sensing, military, agriculture, and geological exploration. Recovering a high resolution image needs enormous data, which puts forward very high requirements on image system hardware. Compressed sampling spectral imaging technology could well solve this problem and achieve high-resolution objects with low-resolution compressed data. In this paper, the method of a compressed sampling spectral imaging based on push-broom coded aperture and dispersion prism is proposed. A spectral aliasing image is formed when the object passing through the dispersive prism. According to the prism dispersion condition and the CCD pixel size, the visible spectrum can be divided into N spectral bands, and the measurement matrix of the coded aperture is respectively calibrated for the center wavelength of each spectral band. By controlling a stepper to implement the push broom of the coded aperture to change the measurement matrix, multiple spectral aliasing images can be obtained. The pixel size of the coded aperture becomes half of the CCD by a relay lens, which means the pixel of CCD is low-resolution for the coded aperture. The super-resolution hyperspectral image of the object is obtained by the improved LS reconstruction algorithm. Simulation results show that, the recovered hyperspectral image has twice resolution compared with the low-resolution CCD image, and the peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) increase with the increasing compressed sampling hyperspectral images. For N=31, the average PSNR and SSIM recovered from six aliasing images is 22.019 and 0.235, respectively. The average PSNR and SSIM of the recovered 31 bands are also increasing with increasing aliasing images. While the aliasing imaging is 156, The average PSNR and SSIM exceeds 38 and 0.9. This method proves that super-resolution hyperspectral imaging can be achieved by capturing less low-resolution object images. © 2019 SPIE.","Dispersion (waves); Image enhancement; Matrix algebra; Military applications; Optical image storage; Optical resolving power; Pixels; Prisms; Recovery; Remote sensing; Signal to noise ratio; Spectroscopy; Coded apertures; Compressed samplings; Computational imaging; Push-broom; Super resolution; Hyperspectral imaging","Coded aperture; Compressed sampling; Computational imaging; Hyperspectral imaging; Push-broom; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85077800384"
"Ma W.; Pan Z.; Guo J.; Lei B.","Ma, Wen (57207877267); Pan, Zongxu (54788169800); Guo, Jiayi (57194143247); Lei, Bin (14063767500)","57207877267; 54788169800; 57194143247; 14063767500","Super-resolution of remote sensing images based on transferred generative adversarial network","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8517442","1148","1151","3","10.1109/IGARSS.2018.8517442","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063138028&doi=10.1109%2fIGARSS.2018.8517442&partnerID=40&md5=39673883be5d097f6a3bd4bf2fe8f3fc","Single image super-resolution (SR) has been widely studied in recent years as a crucial technique for remote sensing applications. This paper proposes a SR method for remote sensing images based on a transferred generative adversarial network (TGAN). Different from the previous GAN-based SR approaches, the novelty of our method mainly reflects from two aspects. First, the batch normalization layers are removed to reduce the memory consumption and the computational burden, as well as raising the accuracy. Second, our model is trained in a transfer-learning fashion to cope with the insufficiency of training data, which is the crux of applying deep learning methods to remote sensing applications. The model is firstly trained on an external dataset DIV2K and further fine-tuned with the remote sensing dataset. Our experimental results demonstrate that the proposed method is superior to SRCNN and SRGAN in terms of both the objective evaluation and the subjective perspective. © 2018 IEEE","","Generative adversarial network; Remote sensing images; Super-resolution; Transfer learning","Conference paper","Final","","Scopus","2-s2.0-85063138028"
"Wu S.; Ren J.; Chen Z.; Jin W.; Liu X.; Li H.; Pan H.; Guo W.","Wu, Shangrong (55607162400); Ren, Jianqiang (14021882100); Chen, Zhongxin (14021042100); Jin, Wujun (57171366600); Liu, Xingren (55868805300); Li, He (55023481400); Pan, Haizhu (57201362978); Guo, Wenqian (57201356202)","55607162400; 14021882100; 14021042100; 57171366600; 55868805300; 55023481400; 57201362978; 57201356202","Influence of reconstruction scale, spatial resolution and pixel spatial relationships on the sub-pixel mapping accuracy of a double-calculated spatial attraction model","2018","Remote Sensing of Environment","210","","","345","361","16","10.1016/j.rse.2018.03.015","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044466727&doi=10.1016%2fj.rse.2018.03.015&partnerID=40&md5=350aa7ce1a3b0884ccf7f186a957ce58","Mixed pixels universally exist in remote sensing images, and they are one of the main obstacles for further improving the accuracy of land cover recognition and classification. Since the concept of sub-pixel mapping (SPM) is proposed, SPM technology has rapidly become an important method to solve the problem of mixed pixels. To further improve SPM accuracy, this paper first proposes a double-calculated spatial attraction model (DSAM) combining the advantages of the spatial attraction model (SAM) and the pixel swap model (PSM). Then, based on the full validation of the proposed DSAM, how multiple factors affect the SPM accuracy is analyzed using the multispectral remote sensing (MRS) images. Finally, by analyzing the maximum variations in the ranges of the overall accuracy and the kappa coefficient under different multiple factors, the order of factors influencing SPM accuracy is determined as follows: reconstruction scale > image spatial resolution > pixel spatial relationships. The results can serve as a reference for other scholars in setting model parameters and selecting the appropriate remote sensing data, thereby helping them achieve more accurate SPM results. © 2018 Elsevier Inc.","Image analysis; Image enhancement; Image resolution; Mapping; Remote sensing; Scale Factor; Spatial relationships; Spatial resolution; Sub-pixel mapping; Super-resolution mappings; accuracy assessment; image classification; land cover; mapping method; model validation; numerical method; numerical model; pixel; satellite data; satellite imagery; scale effect; spatial resolution; Pixels","Double-calculated spatial attraction model; Pixel spatial relationships; Scale factor; Spatial resolution; Sub-pixel mapping; Super-resolution mapping","Article","Final","","Scopus","2-s2.0-85044466727"
"Vitale S.","Vitale, Sergio (57201522451)","57201522451","A CNN-based pansharpening method with perceptual loss","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-July","","8900390","3105","3108","3","10.1109/IGARSS.2019.8900390","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077856020&doi=10.1109%2fIGARSS.2019.8900390&partnerID=40&md5=2cfef72d3c7352fde748d6c01325a0d6","Pansharpening is a classical data fusion task that is often necessary when dealing with data sensed through multiresolution acquisition systems. These systems, in fact, provide a single panchromatic band at full spatial resolution coupled with a multispectral lower resolution image of the same scene, which must be fused (pansharpened) to generate a full spatial-spectral resolution datacube. In the last few years, there has been a methodological shift in pansharpening towards the deep learning (DL) paradigm. Most DL solutions proposed thus far use self-supervised learning. Training is carried out on data at downgraded resolution, where ground truth data are also available. Then, the trained network is applied to perform pansharpening on native resolution data. As a consequence, such solutions show good results on low-resolution datasets, but less convincing results on full-resolution data, due to limited generalization ability. In this work, to address this problem, we enrich the training loss function with a perceptual term computed on full-resolution data, obtaining promising experimental results. © 2019 IEEE.","Convolutional neural networks; Data fusion; Deep neural networks; Remote sensing; Full resolution datum; Generalization ability; Ground truth data; Lower resolution; Multiresolution acquisitions; Panchromatic bands; Spatial resolution; Super resolution; Deep learning","Convolutional neural network; Data fusion; Deep learning; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85077856020"
"Qiu Y.; Bi Y.; Li Y.; Wang H.","Qiu, Yuwei (57200599573); Bi, Yuda (57200794610); Li, Yang (57246347100); Wang, Haoxiang (56178830400)","57200599573; 57200794610; 57246347100; 56178830400","High resolution remote sensing image denoising algorithm based on sparse representation and adaptive dictionary learning","2018","Lecture Notes in Computational Vision and Biomechanics","28","","","892","901","9","10.1007/978-3-319-71767-8_76","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042413593&doi=10.1007%2f978-3-319-71767-8_76&partnerID=40&md5=0b6f47f72dae280e92e99be494e147fc","Aiming at the denoising algorithm of high resolution remote sensing images, in this paper, we propose a novel method based on sparse representation and adaptive dictionary learning. The proposed algorithm uses the strong correlation between the bands of high resolution remote sensing images, which combines the non local self similarity of the image with the local sparsity to improve the denoising performance. By means of sparse representation of image noise, we extract texture information from image noise so as to improve the quality of image denoising. A learning based super-resolution algorithm learns a dictionary through a set of training examples, and combines the missing high-frequency information from the low resolution image, and finally obtains the corresponding high-resolution image. The traditional denoising algorithm still has noise residue after noise removal, and the image denoising effect is not obvious when the noise is large. Experimental results show that the peak signal-to-noise ratio of the proposed method is higher than the existing similar algorithms, and it can better preserve the details and texture information of the image, and improve the visual effect. © 2018, Springer International Publishing AG.","","Adaptive dictionary; Algorithm; Denoising; High resolution; Learning method; Remote sensing image; Sparse representation","Book chapter","Final","","Scopus","2-s2.0-85042413593"
"Junaidi A.; Lin C.-H.; Tseng Y.-H.; Chang L.-H.; Peng S.-C.","Junaidi, Achmad (57240727400); Lin, Chao-Hung (14054277800); Tseng, Yi-Hsing (7202711022); Chang, Li-Hsueh (57656573300); Peng, Shin-Chia (57241158800)","57240727400; 14054277800; 7202711022; 57656573300; 57241158800","Gradient-based adaptive image super resolution","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-July","","8900578","2774","2777","3","10.1109/IGARSS.2019.8900578","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114045155&doi=10.1109%2fIGARSS.2019.8900578&partnerID=40&md5=e62a30fbac3fa9dda105288a2116ff5f","Super-resolution (SR) has been used in the realm of remote sensing to improve the resolution of an image and get more detailed spatial information than the original image captured by the sensor on the acquisition device. Several SR methods with different approaches, only focusing on sharpening the edges and forgetting non-edge areas. One of the SR methods that utilize prior gradients, can produce high resolution (HR) images in a short time and produce sharp images for non-homogeneous areas. But for areas that tend to be homogeneous, a lot of noise appears. This problem will affect the remote sensing process due to the amount of noise that arises. This paper offers to use dynamic weighting on the gradient prior that will reduce the noise on the homogeneous area, while still able to maintains to produce the sharp edges in non-homogeneous areas. An experimental comparison is conducted on both homogeneous and non-homogeneous area using the previous method and the proposed method. © 2019 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Optical resolving power; Remote sensing; Acquisition device; Adaptive images; Experimental comparison; High resolution image; Non-homogeneous; Original images; Spatial informations; Super resolution; Image enhancement","Dynamic weighting; Gradient prior; Gradient-based; Image reconstruction; Image super-resolution","Conference paper","Final","","Scopus","2-s2.0-85114045155"
"","","","Image and Signal Processing for Remote Sensing XXV","2019","Proceedings of SPIE - The International Society for Optical Engineering","11155","","","","","690","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078131307&partnerID=40&md5=7428f396d9a4ad45df142449eb2997e3","The proceedings contain 70 papers. The topics discussed include: finer scale mapping with super resolved GF-4 satellite images; super-resolution imaging design for CX6-02 micro-satellite; optimization of unsupervised affinity propagation clustering method; road and railway detection in SAR images using deep learning; remote sensing and machine learning for tree detection and classi?cation in forestry applications; on-line learning tracking-by-segmentation of spacecraft observed by satellite-based imaging system; and GWENN-SS: a simple semi-supervised nearest-neighbor density-based classi?cation method with application to hyperspectral images.","","","Conference review","Final","","Scopus","2-s2.0-85078131307"
"Wang Z.-Z.; Zhang Q.-J.; Han X.-L.","Wang, Zhi-Zhong (57192241218); Zhang, Qing-Jun (55092505400); Han, Xiao-Lei (57225865157)","57192241218; 55092505400; 57225865157","Satellite remote sensing image super resolution based on markov random fields","2016","International Geoscience and Remote Sensing Symposium (IGARSS)","2016-November","","7730892","7256","7259","3","10.1109/IGARSS.2016.7730892","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007482450&doi=10.1109%2fIGARSS.2016.7730892&partnerID=40&md5=9f94befcbd0d557952dc089ceee4cb85","This paper studies satellite remote sensing image super resolution that employs image processing techniques to reconstruct the high-resolution image from a set of low-resolution observations of the same scene. A heuristic approach for maximum a posteriori (MAP) estimate of desired high-resolution image based on markov random fields (MRF) is presented. Under the posteriori distribution deduced by Bayesian criterion, the reconstruction image is derived by finding the global optimized estimation with the simulated annealing (SA) optimization mechanism. In the experiments, the proposed method is evaluated in a simulated framework that the estimate images are compared with the reference one using Normalized Mean Square Error (NMSE) criterion. The results quantitatively indicate the super performance of super resolution reconstruction and noise robustness obtained by our approach in comparison with the Cubic interpolation. © 2016 IEEE.","","Markov random field; Maximum a posteriori probability; Satellite remote sensing; Simulated annealing; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85007482450"
"Wang S.; Zhang Z.; Wu Y.","Wang, Suyu (55714507500); Zhang, Zongxiang (56834737500); Wu, Ying (57195469569)","55714507500; 56834737500; 57195469569","Spatial and spectral coordinate super resolution of hyperspectral imagery based on redundant dictionary","2015","Proceedings of SPIE - The International Society for Optical Engineering","9817","","98170E","","","","10.1117/12.2228374","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028319980&doi=10.1117%2f12.2228374&partnerID=40&md5=522570d7e8bead02e5c4272974f6e221","Hyperspectral imagery has been widely used in various fields for its rich amount of feature information. The quality of hyperspectral imagery has been set higher requirements. As a result of the limitation of imaging semiconductor technology, hyperspectral image resolution needs to be improved by a signal processing method. This paper presents a recovery algorithm of spatial and spectral coordinate super-resolution of hyperspectral image based on redundant dictionary. Compared with the traditional image super-resolution restoration algorithm, the super-resolution restoration in the spectral of hyperspectral image was added on the basis of spatial resolution improvement. The original constraint was added in the algorithm and edges of reconstructed image were sharpened with the Maximum a Posterior. The results show this algorithm can effectively improve spatial and spectral resolution of the hyperspectral imagery. © 2015 SPIE.","Edge detection; Hyperspectral imaging; Image resolution; Optical resolving power; Processing; Remote sensing; Restoration; Semiconductor device manufacture; Signal processing; Spectroscopy; Hyper-spectral imageries; Image super resolutions; Maximum a posteriori; Maximum a posteriors; Reconstructed image; Redundant dictionaries; Semiconductor technology; Super-resolution restoration; Image processing","Hyperspectral imagery; Maximum a posteriori; Redundant dictionary; Super-resolution restoration","Conference paper","Final","","Scopus","2-s2.0-85028319980"
"Ishimaru A.; Zhang C.; Kuga Y.","Ishimaru, Akira (7005122046); Zhang, Ce (55703849700); Kuga, Yasuo (57205930653)","7005122046; 55703849700; 57205930653","Statistical electromagnetic theories and applications: A review of recent advances","2015","2015 1st URSI Atlantic Radio Science Conference, URSI AT-RASC 2015","","","7302918","","","","10.1109/URSI-AT-RASC.2015.7302918","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959468072&doi=10.1109%2fURSI-AT-RASC.2015.7302918&partnerID=40&md5=472b91f137be3558964d22ee8eb13804","Statistical Electromagnetic Theories have been developed over many years and applied to a wide range of practical problems in remote sensing of geophysical media, biological media, medical optics, ultrasound imaging and object detection and communication in clutter. This paper gives a review of recent developments in applications of statistical wave theories. The super resolution of images occurs in random media due to the multiple scattering and the increase of apparent aperture size of the transmitter. Another interesting effect is that the scattered wave from multiple scattering remembers the direction of the incident wave and strong correlations can be observed under certain conditions. This is called the 'Memory Effect'. Recent study shows that under certain conditions, the angular and frequency correlations of the scattered wave can be enhanced or reduced and this effect can be used to reduce the clutter from the rough surface. It is also noted that the coherence in multiple scattering causes the increase of radar cross sections in turbulence due to the interference between the forward and backward waves, called the 'double passage effect'. This is related to the Anderson localization and the coherent backscattering. © 2015 International Union of Radio Science (URSI).","Clutter (information theory); Coherent scattering; Electric fields; Medical imaging; Medical problems; Multiple scattering; Radar cross section; Remote sensing; Ultrasonic applications; Ultrasonic imaging; Anderson localization; Coherent backscattering; Electromagnetic theories; Forward-and-backward; Frequency correlation; Practical problems; Strong correlation; Ultrasound imaging; Forward scattering","","Conference paper","Final","","Scopus","2-s2.0-84959468072"
"Wei Y.; Yuan Q.; Shen H.; Zhang L.","Wei, Yancong (57192696450); Yuan, Qiangqiang (36635300800); Shen, Huanfeng (8359721100); Zhang, Liangpei (8359720900)","57192696450; 36635300800; 8359721100; 8359720900","A universal remote sensing image quality improvement method with deep learning","2016","International Geoscience and Remote Sensing Symposium (IGARSS)","2016-November","","7730813","6950","6953","3","10.1109/IGARSS.2016.7730813","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007417752&doi=10.1109%2fIGARSS.2016.7730813&partnerID=40&md5=56066dec204dce6ae3696e6019d7b8f4","In this paper, we introduced a deep learning model: Convolutional neural network(CNN) from the field of natural image classification and restoration, to solve general quality improving tasks for remote sensing images, including super-resolution, denoising and haze removal. To take advantage of the content similarity among aerial images and the learning ability of deep learning models, we proposed the idea of training CNN on datasets collected from aerial images with specific degenerating factors, then apply the model to matched tasks. Experiments showed that our network achieved superior performance in quantified results, and visually reconstructed a satisfying majority of missing details from low-quality observations. © 2016 IEEE.","","blind denoising; Convolutional neural network; image restoration; non-uniform haze removal; single image super-resolution","Conference paper","Final","","Scopus","2-s2.0-85007417752"
"Sundar K.J.A.; Divyalakhsmi K.; Ifjaz Ahmed M.; Sivagami R.; Sangeetha V.; Vaithiyanathan V.","Sundar, K. Joseph Abraham (56783941200); Divyalakhsmi, K. (57188676994); Ifjaz Ahmed, M. (55808708400); Sivagami, R. (57188678371); Sangeetha, V. (57210551454); Vaithiyanathan, V. (35173624000)","56783941200; 57188676994; 55808708400; 57188678371; 57210551454; 35173624000","Super resolution image reconstruction using frequency spectrum","2015","Indian Journal of Science and Technology","8","35","","","","3","10.17485/ijst/2015/v8i35/86632","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962245770&doi=10.17485%2fijst%2f2015%2fv8i35%2f86632&partnerID=40&md5=617dc962f9ea11e4b71108b91f0df720","Super resolution image reconstruction is defined as generating a high resolution image from a low resolution image or sequence of low resolution images captured from identical scene apparently a video. An algorithm for reconstructing a high resolution image from a low resolution image by altering the frequency components is discussed in this paper. In this method the high frequency components of the zoomed low resolution image is modified so as to increase the resolution of the low resolution image. The evaluation for the experiments is based on the performance measure matrix peak signal to noise ratio. The experimental results shown proves that the algorithm is highly advantageous and computationally fast compared to the other interpolation methods. The algorithm will be helpful in practical applications of medical imaging diagnosis, remote sensing and military applications.","","Filters; Frequency spectrum; Image reconstruction; Interpolation; Super resolution","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-84962245770"
"Wang X.; Cao Y.; Lu D.; Liu X.; Fan S.; Zhou Y.; Li Y.","Wang, Xinwei (57193115364); Cao, Yinan (55644480400); Lu, Dezhen (56512966300); Liu, Xiaoquan (55937163000); Fan, Songtao (8592655600); Zhou, Yan (57188685533); Li, Youfu (8589964900)","57193115364; 55644480400; 56512966300; 55937163000; 8592655600; 57188685533; 8589964900","Spatial difference shaping to improve range resolution in 3D super resolution range gated imaging","2015","Proceedings of SPIE - The International Society for Optical Engineering","9622","","962202","","","","10.1117/12.2184677","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943551804&doi=10.1117%2f12.2184677&partnerID=40&md5=b98c6ce3d2d6fcd0a86b4bbbb21da0fc","Three-dimensional super-resolution range-gated imaging has been developed for high-resolution 3D remote sensing with two range-intensity correlation algorithms under specific shapes of range-intensity profiles (RIP). However, pulsed lasers have a minimum pulse width which limits range resolution improvement. Here a spatial difference shaping method is proposed to break the resolution limitation. This method establishes a shaping filter, and the pre-reshaping gate images are reshaped by spatial difference and yield new gate images with the laser pulse width equivalently narrowed as half value which improves the range resolution. Furthermore, the boundary blurring caused by non-rectangular laser pulses are also eliminated. © 2015 SPIE.","Image processing; Laser pulses; Optical instruments; Optical resolving power; Pulsed lasers; Remote sensing; Intensity profiles; Range-gated imaging; Shaping filters; Spatial differences; Super resolution; Pulse shaping","range-intensity profile; shaping filter; spatial difference shaping; super-resolution; three-dimensional range-gated imaging","Conference paper","Final","","Scopus","2-s2.0-84943551804"
"Zhang H.; Casaseca-De-La-Higuera P.; Luo C.; Wang Q.; Kitchin M.; Parmley A.; Monge-Alvarez J.","Zhang, Huaizhong (15924212700); Casaseca-De-La-Higuera, Pablo (9744429500); Luo, Chunbo (55637616900); Wang, Qi (57091061800); Kitchin, Matthew (6601997724); Parmley, Andrew (35100687900); Monge-Alvarez, Jesus (57039022700)","15924212700; 9744429500; 55637616900; 57091061800; 6601997724; 35100687900; 57039022700","Systematic infrared image quality improvement using deep learning based techniques","2016","Proceedings of SPIE - The International Society for Optical Engineering","10008","","100080P","","","","10.1117/12.2242036","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010888144&doi=10.1117%2f12.2242036&partnerID=40&md5=b251dfc7626ebb42cdf87602a4f179dd","Infrared thermography (IRT, or thermal video) uses thermographic cameras to detect and record radiation in the longwavelength infrared range of the electromagnetic spectrum. It allows sensing environments beyond the visual perception limitations, and thus has been widely used in many civilian and military applications. Even though current thermal cameras are able to provide high resolution and bit-depth images, there are significant challenges to be addressed in specific applications such as poor contrast, low target signature resolution, etc. This paper addresses quality improvement in IRT images for object recognition. A systematic approach based on image bias correction and deep learning is proposed to increase target signature resolution and optimise the baseline quality of inputs for object recognition. Our main objective is to maximise the useful information on the object to be detected even when the number of pixels on target is adversely small. The experimental results show that our approach can significantly improve target resolution and thus helps making object recognition more efficient in automatic target detection/recognition systems (ATD/R). © 2016 SPIE.","Cameras; Infrared devices; Infrared imaging; Military applications; Neural networks; Optical resolving power; Remote sensing; Urban planning; ADT/R; Automatic target detection; Convolutional neural network; Electromagnetic spectra; Image quality improvements; Long-wavelength infrared ranges; Super resolution; Thermographic cameras; Object recognition","ADT/R; IRT; super-resolution; Super-Resolution Convolutional Neural Network (SRCNN)","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85010888144"
"Weiss M.; Fornaro G.; Reale D.","Weiss, Matthias (55451934900); Fornaro, Gianfranco (7005348278); Reale, DIego (25651870200)","55451934900; 7005348278; 25651870200","Multi scatterer detection within tomographic SAR using a compressive sensing approach","2015","2015 3rd International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar, and Remote Sensing, CoSeRa 2015","","","7330254","11","15","4","10.1109/CoSeRa.2015.7330254","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962856902&doi=10.1109%2fCoSeRa.2015.7330254&partnerID=40&md5=4ceda0bee2eb3e28e5e1dd8a65de9545","Synthetic Aperture Radar (SAR) tomography has seen a strong evolution in the past years as it has shown to be a worthwhile tool for analysing data obtained with high range resolution interferometric SAR sensors at pixel size. In particular by transforming them into a 3-D, 4-D, and in general Multi-Dimensional SAR image. The resolution in the higher dimensions, for instance in elevation and time, depends on the size of the elevation aperture and on the temporal separation which will be spanned by the different repeat paths. However, for more recent space-borne SAR systems which has sub-meter range resolution, like COSMO-Skymed or TerraSAR-X, the orbital tracks are tightly controlled so that they show only a small variation. According to this, the tomographic resolution in elevation is an order of magnitude lower than in range or azimuth. This is normally not a problem as only the strongest reflector is of interest. However, for urban scenes or man made objects one can expect that each azimuth-range cell consists of a few point-like scatterers in the elevation direction. To resolve these scatterers super-resolution algorithms are required to improve the performance of tomographic tools. Due to the present of only a few scatterers we can use compressive sensing (CS) techniques for reconstructing the elevation for tomographic images. This paper presents an adapted CS method for 4-D tomographic SAR and compares it with classical matched filter. Super-resolution properties of the proposed CS is proven by results obtained from simulations and from real TerraSAR-X data. © 2015 IEEE.","Matched filters; Optical resolving power; Radar; Radar imaging; Remote sensing; Satellites; Signal reconstruction; Sonar; Space optics; Synthetic aperture radar; Tomography; Classical matched filters; Compressive sensing; D-inSAR; High range resolution; Sar tomography (SARTom); Super resolution; Super resolution algorithms; Tomographic resolution; Compressed sensing","Compressive Sensing (CS); Differential SAR Tomography; DInSAR; SAR Tomography; Super-Resolution; Synthetic Aperture Radar (SAR)","Conference paper","Final","","Scopus","2-s2.0-84962856902"
"Wang L.; Wang P.; Zhao C.","Wang, Liguo (55745497100); Wang, Peng (57189493188); Zhao, Chunhui (7403563984)","55745497100; 57189493188; 7403563984","Producing Subpixel Resolution Thematic Map from Coarse Imagery: MAP Algorithm-Based Super-Resolution Recovery","2016","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","9","6","7480345","2290","2304","14","10.1109/JSTARS.2016.2552224","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971467486&doi=10.1109%2fJSTARS.2016.2552224&partnerID=40&md5=4b8b63fee47c307706c3c302c7837c14","Subpixel mapping (SPM) of hyperspectral remote sensing imagery is a promising technique for deriving fine mapping result by classification at fine spatial resolution. There is a type of algorithm for SPM, namely, the soft-Then-hard SPM (STHSPM) algorithm that first estimates soft attribute values for land cover classes at subpixel level and then allocates classes for subpixel according to the soft attribute values. However, the fraction images derived from spectral unmixing are of less prior information of original hyperspectral remote sensing imagery and there are lots of errors in SPM result due to the limitation of spectral unmixing technology currently available. In this paper, a framework based on subpixel resolution thematic map, namely, super-resolution then classification (STC) is proposed to improve mapping result. In the proposed framework, a maximum a posteriori (MAP) model associated with the endmembers of interest (EOI), namely, T-MAP-SR is applied to the original coarse imagery to derive a high-resolution imagery with generous prior information. Then fine mapping result can be derived from the high-spatial resolution imagery by the available classification methods. Experiments show that the proposed framework can produce higher mapping accuracy result and protect the classes of interest (COI). © 2016 IEEE.","Algorithms; Fits and tolerances; Image resolution; Mapping; Maps; Optical resolving power; Pixels; Classification methods; High resolution imagery; High spatial resolution imagery; Hyperspectral remote sensing; Maximum a posteriori models; Spatial resolution; Spectral unmixing; Subpixel resolution; algorithm; image classification; imagery; pixel; remote sensing; spatial resolution; thematic mapping; Remote sensing","Endmembers of interest (EOI); Hyperspectral imagery (HSI); Maximum a posteriori (MAP); Subpixel mapping (SPM); Super-resolution","Article","Final","","Scopus","2-s2.0-84971467486"
"Bacci A.; Giusti E.; Cataldo D.; Tomei S.; Martorella M.","Bacci, A. (50961022100); Giusti, E. (55388839300); Cataldo, D. (55869058300); Tomei, S. (57112169700); Martorella, M. (6603185380)","50961022100; 55388839300; 55869058300; 57112169700; 6603185380","ISAR resolution enhancement via compressive sensing: A comparison with state of the art SR techniques","2016","2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing, CoSeRa 2016","","","7745734","227","231","4","10.1109/CoSeRa.2016.7745734","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002776967&doi=10.1109%2fCoSeRa.2016.7745734&partnerID=40&md5=f21ef100f1dfaa9bc3241a43b431e8e7","The applicability of Compressing Sensing (CS) to Inverse Synthetic Aperture Radar has been widely treated in the last few years. In particular, CS based image reconstruction algorithms have been developed and their effectiveness has been proven when dealing with data that are incomplete in slow time and/or frequency domain. Resolution enhancement has been identified as a case in which CS can be exploited to obtain good results even compared with state of the art super resolution techniques. In this paper an exhaustive performance analysis is performed and a numerical comparison among CS and conventional super resolution techniques is provided. Some performance indicators are defined and results are provided using real dataset. © 2016 IEEE.","Frequency domain analysis; Image reconstruction; Inverse synthetic aperture radar; Optical resolving power; Radar; Remote sensing; Signal reconstruction; Sonar; Synthetic aperture radar; Compressive sensing; Frequency domains; Image reconstruction algorithm; Numerical comparison; Performance analysis; Performance indicators; Resolution enhancement; State of the art; Compressed sensing","","Conference paper","Final","","Scopus","2-s2.0-85002776967"
"Biondi F.","Biondi, Filippo (55949088500)","55949088500","Super resolution of synthetic aperture radar data by convex optimization","2016","2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing, CoSeRa 2016","","","7745693","28","32","4","10.1109/CoSeRa.2016.7745693","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002832478&doi=10.1109%2fCoSeRa.2016.7745693&partnerID=40&md5=86c2c422b2de8fc0ba3dfe02d35f75ce","The problem of chirped Synthetic Aperture Radar (SAR) is the high vulnerability of the received information, under Electromagnetic (EM) Corruption. This paper proposes a valid recovery solution of SAR Single Look Complex (SLC)1 images observed with low band signals. The recovery of high resolution images is made by Super-Resolution (SR) Signal Processing (SP), based on Spectrum Extrapolation (SE), implemented by Convex Programming (CP). © 2016 IEEE.","Compressed sensing; Convex optimization; Extrapolation; Image processing; Jamming; Optical resolving power; Radar; Radar imaging; Remote sensing; Signal processing; Signal reconstruction; Sonar; Compressive sensing; High resolution image; Single-look complexes; Spectrum extrapolation; Super resolution; Synthetic aperture radar","Compressed Sensing (CS); Jamming; Spectrum Extrapolation (SE); Super-Resolution (SR); Synthetic Aperture Radar (SAR)","Conference paper","Final","","Scopus","2-s2.0-85002832478"
"Şimşek M.; Polat E.","Şimşek, Murat (57198315114); Polat, Ediz (6602452700)","57198315114; 6602452700","Sparse representation-based dictionary learning methods for hyperspectral super-resolution; [Hiperspektral Süper-Çözünürlük için Seyrek Temsil Tabanli Sözlük Öǧrenme Yöntemleri]","2016","2016 24th Signal Processing and Communication Application Conference, SIU 2016 - Proceedings","","","7495849","753","756","3","10.1109/SIU.2016.7495849","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982793246&doi=10.1109%2fSIU.2016.7495849&partnerID=40&md5=5f885b7e172b43dc3fe61869bc0c2435","Due to hardware limitations, hyperspectral imagery has low spatial resolution. It can be obtained super- resolution hyperspectral imagery by means of sparse representation-based methods that are designed for improving spatial resolution. In this paper, the effect of sparse representation-based dictionary learning algorithms including K-SVD, ODL and Bayes on obtaining super-resolution images with low error and high quality has been investigated. The method with best results has been identified. © 2016 IEEE.","Image resolution; Learning algorithms; Optical resolving power; Remote sensing; Spectroscopy; Dictionary learning; Dictionary learning algorithms; Hyper-spectral imageries; Hyper-spectral images; HyperSpectral; Sparse representation; Spatial resolution; Super resolution; Signal processing","dictionary learning; hyperspectral images; sparse representation; super resolution","Conference paper","Final","","Scopus","2-s2.0-84982793246"
"Amrita A.; Tiwari K.C.","Amrita, A. (57192575761); Tiwari, K.C. (57214612594)","57192575761; 57214612594","A comparative assessment of various super-resolution techniques in target detection and enhancement using hyperspectral data","2016","Proceedings of SPIE - The International Society for Optical Engineering","9880","","98801V","","","","10.1117/12.2223539","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006940235&doi=10.1117%2f12.2223539&partnerID=40&md5=11c728ba2c6cec44de9bbbda4b463feb","Algorithms for target detection in hyperspectral data successfully detect full pixel targets; but, they fail to simultaneously detect part of target which may be lying partially in surrounding pixels. This requires development of algorithms which can simultaneously detect the sub pixel targets in surrounding pixels so that shape of the target can be recovered for identification. Super resolution mapping is one such method for target identification and enhancement. Aim of this paper is to perform a comparative assessment of various existing super resolution mapping techniques and to present a super resolution mapping technique which can preferably work on non - random allocation of sub-pixels and non recursive optimization. © 2016 SPIE.","Hyperspectral imaging; Image processing; Optical resolving power; Photomapping; Pixels; Remote sensing; Spectroscopy; Mixed pixel; Spectral unmixing; Sub-pixel mapping; Super-resolution mappings; Target identification; Radar target recognition","Hyperspectral imaging; Mixed pixel; Spectral unmixing; Subpixel mapping; Super resolution mapping; Target enhancement; Target identification","Conference paper","Final","","Scopus","2-s2.0-85006940235"
"Chen Z.; Wang X.; Xu Z.; Hou W.","Chen, Zixuan (56955915100); Wang, Xuewen (55917995000); Xu, Zekai (56606439400); Hou, Wenguang (8697574000)","56955915100; 55917995000; 56606439400; 8697574000","Convolutional neural network based dem super resolution","2016","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","41","","","247","250","3","10.5194/isprsarchives-XLI-B3-247-2016","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978039220&doi=10.5194%2fisprsarchives-XLI-B3-247-2016&partnerID=40&md5=b21380405183633b38a5e9e8f1f27302","DEM super resolution is proposed in our previous publication to improve the resolution for a DEM on basis of some learning examples. Meanwhile, the nonlocal algorithm is introduced to deal with it and lots of experiments show that the strategy is feasible. In our publication, the learning examples are defined as the partial original DEM and their related high measurements due to this way can avoid the incompatibility between the data to be processed and the learning examples. To further extent the applications of this new strategy, the learning examples should be diverse and easy to obtain. Yet, it may cause the problem of incompatibility and unrobustness. To overcome it, we intend to investigate a convolutional neural network based method. The input of the convolutional neural network is a low resolution DEM and the output is expected to be its high resolution one. A three layers model will be adopted. The first layer is used to detect some features from the input, the second integrates the detected features to some compressed ones and the final step transforms the compressed features as a new DEM. According to this designed structure, some learning DEMs will be taken to train it. Specifically, the designed network will be optimized by minimizing the error of the output and its expected high resolution DEM. In practical applications, a testing DEM will be input to the convolutional neural network and a super resolution will be obtained. Many experiments show that the CNN based method can obtain better reconstructions than many classic interpolation methods.","Image reconstruction; Neural networks; Optical resolving power; Remote sensing; Convolutional neural network; High resolution; High-resolution DEM; Interpolation method; Low resolution; Step transforms; Super resolution; Three-layer; Convolution","Convolutional Neural Network; DEM Super Resolution; Reconstruction","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-84978039220"
"Wang Q.; Atkinson P.M.; Shi W.","Wang, Qunming (55649569623); Atkinson, Peter M. (7201906181); Shi, Wenzhong (7402664815)","55649569623; 7201906181; 7402664815","Fast subpixel mapping algorithms for subpixel resolution change detection","2015","IEEE Transactions on Geoscience and Remote Sensing","53","4","6883154","1692","1706","14","10.1109/TGRS.2014.2346535","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027940287&doi=10.1109%2fTGRS.2014.2346535&partnerID=40&md5=14751c68b11a33942d953589334debdf","Due to rapid changes on the Earth's surface, it is important to perform land cover change detection (CD) at a fine spatial and fine temporal resolution. However, remote sensing images with both fine spatial and temporal resolutions are commonly not available or, where available, may be expensive to obtain. This paper attempts to achieve fine spatial and temporal resolution land cover CD with a new computer technology based on subpixel mapping (SPM): The fine spatial resolution land cover maps (FRMs) are first predicted through SPM of the coarse spatial but fine temporal resolution images, and then, subpixel resolution CD is performed by comparison of class labels in the SPM results. For the first time, five fast SPM algorithms, including bilinear interpolation, bicubic interpolation, subpixel/pixel spatial attraction model, Kriging, and radial basis function interpolation methods, are proposed for subpixel resolution CD. The auxiliary information from the known FRM on one date is incorporated in SPM of coarse images on other dates to increase the CD accuracy. Based on the five fast SPM algorithms and the availability of the FRM, subpixels for each class are predicted by comparison of the estimated soft class values at the target fine spatial resolution and borrowing information from the FRM. Experiments demonstrate the feasibility of the five SPM algorithms using FRM in subpixel resolution CD. They are fast methods to achieve subpixel resolution CD. © 2014 IEEE.","Conformal mapping; Image resolution; Interpolation; Radial basis function networks; Remote sensing; Auxiliary information; Bilinear interpolation; Change detection; Radial basis function interpolation; Spatial and temporal resolutions; Sub-pixel mapping; Super-resolution mappings; Temporal resolution images; algorithm; image resolution; interpolation; kriging; land cover; pixel; remote sensing; spatial resolution; spatiotemporal analysis; Pixels","Change detection (CD); remote sensing; subpixel mapping (SPM); superresolution mapping","Article","Final","","Scopus","2-s2.0-85027940287"
"Fornaro G.; Pauciullo A.; Reale D.; Weis M.; Budillon A.; Schirinzi G.","Fornaro, Gianfranco (7005348278); Pauciullo, Antonio (6506197276); Reale, Diego (25651870200); Weis, Matthias (55451934900); Budillon, Alessandra (8275243900); Schirinzi, Gilda (7003330705)","7005348278; 6506197276; 25651870200; 55451934900; 8275243900; 7003330705","Compressive sensing and generalized likelihood ratio test in SAR tomography","2016","2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing, CoSeRa 2016","","","7745706","90","94","4","10.1109/CoSeRa.2016.7745706","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002734663&doi=10.1109%2fCoSeRa.2016.7745706&partnerID=40&md5=8bc928b3ba2700f15c49842335a59d2e","Synthetic Aperture Radar (SAR) interferometry has been the subject of an intensive development in the last years thanks to crucial applications in the area of risk monitoring. The emergence of very high resolution X-Band sensors has increased the interest in application to urban area. Advances of SAR interferometry has been provided by the extension toward SAR tomography. By transforming classical 2-D SAR imaging into higher dimensional (space-time) imaging, it offers the possibility to reconstruct the 3-D/4-D scattering distribution and to detect point clouds for reconstructing single buildings and infrastructures and for the monitoring of their long term deformation. The resolution provided by classical SAR tomographic methods may show limitations in the detection of point clouds. To improve the performance of the tomographic tools super-resolution Compressive Sensing (CS) algorithms have been recently proposed. The literature, however, lacks of an assessment of the improvement of CS over classical point could detection schemes based on classical matched filter as well as of possible indications about the development of a CS algorithm able to guarantee a fixed false alarm probability. This work aims to provide a contribution along this line. © 2016 IEEE.","Interferometry; Matched filters; Patient monitoring; Radar; Radar imaging; Remote sensing; Signal receivers; Signal reconstruction; Sonar; Space optics; Synthetic aperture radar; Tomography; Classical matched filters; False alarm probability; Generalized Likelihood Ratio Test; Long-term deformation; Sar tomography (SARTom); Scattering distributions; Synthetic aperture radar interferometry; Very high resolution; Compressed sensing","","Conference paper","Final","","Scopus","2-s2.0-85002734663"
"Li F.; Xin L.; Guo Y.; Gao J.; Jia X.","Li, Feng (57171116800); Xin, Lei (57183670600); Guo, Yi (55712471200); Gao, Junbin (7404475180); Jia, Xiuping (7201933692)","57171116800; 57183670600; 55712471200; 7404475180; 7201933692","A Framework of Mixed Sparse Representations for Remote Sensing Images","2017","IEEE Transactions on Geoscience and Remote Sensing","55","2","7745953","1210","1221","11","10.1109/TGRS.2016.2621123","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996928544&doi=10.1109%2fTGRS.2016.2621123&partnerID=40&md5=46bb6ef429d277a9243e491e89b7e9e1","In this paper, a new framework of mixed sparse representations (MSRs) is proposed for solving ill-conditioned problems with remote sensing images. In general, it is very difficult to find a common sparse representation for remote sensing images because of complicated ground features. Here we regard a remote sensing image as a combination of subimage of smooth, edges, and point-like components, respectively. Since each domain transformation method is capable of representing only a particular kind of ground object or texture, a group of domain transformations are used to sparsely represent each subimage. To demonstrate the effect of the framework of MSR for remote sensing images, MSR is regarded as a prior for maximum a posteriori when solving ill-conditioned problems such as classification and super resolution (SR), respectively. The experimental results show that not only the new framework of MSR can improve classification accuracy but also it can construct a much better high-resolution image than other common SR methods. The proposed framework MSR is a competitive candidate for solving other remote sensing images-related ill-conditioned problems. © 1980-2012 IEEE.","Classification (of information); Image enhancement; Optical resolving power; Problem solving; Classification accuracy; Compressive sensing; Domain transformation; High resolution image; Ill conditioned problems; Remote sensing images; Sparse representation; Super resolution; analytical framework; image analysis; image classification; image resolution; numerical method; remote sensing; Remote sensing","Classification; compressive sensing (CS); mixed sparse representations (MSRs); super-resolution (SR)","Article","Final","","Scopus","2-s2.0-84996928544"
"Moustafa M.; Ebeid H.M.; Helmy A.; Nazmy T.M.; Tolba M.F.","Moustafa, Marwa (57239502500); Ebeid, Hala M. (25640793000); Helmy, Ashraf (35793517700); Nazmy, Taymoor M. (6504376853); Tolba, Mohamed F. (24541714400)","57239502500; 25640793000; 35793517700; 6504376853; 24541714400","Rapid real-time generation of super-resolution hyperspectral images through compressive sensing and GPU","2016","International Journal of Remote Sensing","37","18","","4201","4224","23","10.1080/01431161.2016.1209314","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979920407&doi=10.1080%2f01431161.2016.1209314&partnerID=40&md5=7704a78b101d23be03e6f678587cfbc1","Recently, compressive sensing (CS) has offered a new framework whereby a signal can be recovered from a small number of noisy non-adaptive samples. This is now an active area of research in many image-processing applications, especially super-resolution. CS algorithms are widely known to be computationally expensive. This paper studies a real time super-resolution reconstruction method based on the compressive sampling matching pursuit (CoSaMP) algorithm for hyperspectral images. CoSaMP is an iterative compressive sensing method based on the orthogonal matching pursuit (OMP). Multi-spectral images record enormous volumes of data that are required in practical modern remote-sensing applications. A proposed implementation based on the graphical processing unit (GPU) has been developed for CoSaMP using computed unified device architecture (CUDA) and the cuBLAS library. The CoSaMP algorithm is divided into interdependent parts with respect to complexity and potential for parallelization. The proposed implementation is evaluated in terms of reconstruction error for different state-of-the-art super-resolution methods. Various experiments were conducted using real hyperspectral images collected by Earth Observing-1 (EO-1), and experimental results demonstrate the speeding up of the proposed GPU implementation and compare it to the sequential CPU implementation and state-of-the-art techniques. The speeding up of the GPU-based implementation is up to approximately 70 times faster than the corresponding optimized CPU. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","Compressed sensing; Image processing; Iterative methods; Optical resolving power; Remote sensing; Spectroscopy; Compressive sampling matching pursuits; Graphical processing units; Image processing applications; Orthogonal matching pursuit; Remote sensing applications; State-of-the-art techniques; Super resolution reconstruction; Superresolution methods; algorithm; graphical method; image processing; image resolution; multispectral image; real time; remote sensing; spectral resolution; Graphics processing unit","","Article","Final","","Scopus","2-s2.0-84979920407"
"Loncan L.; Chanussot J.; Fabre S.; Briottet X.","Loncan, Laetitia (56899045500); Chanussot, Jocelyn (6602159365); Fabre, Sophie (7006429292); Briottet, Xavier (56060845000)","56899045500; 6602159365; 7006429292; 56060845000","Hyperspectral pansharpening based on unmixing techniques","2015","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2015-June","","8075419","","","","10.1109/WHISPERS.2015.8075419","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039154778&doi=10.1109%2fWHISPERS.2015.8075419&partnerID=40&md5=2ee622ad9cba9fe4c548c5d5e4511b13","Pansharpening first aims at fusing a panchromatic image with a multispectral image to generate an image with the high spatial resolution of the former and the spectral resolution of the latter. In the last decade many pansharpening algorithms have been presented in the literature using multispectral data. With the increasing availability of hyperspectral systems these methods are now extenDing to hyperspectral images. But the problem of the mixed pixel is generally ignored by the existing methods since their goal is to preserve the spectral information and add spatial information. In this work we compare different approaches to deal with mixed pixels as a pre-processing step before doing the fusion. This should improved the result by adDing missing spectral information available in the reference image because of the mixed pixel. © 2015 IEEE.","Independent component analysis; Pixels; Remote sensing; Spectroscopy; HyperSpectral; Pan-sharpening; Panchromatique; Super resolution; Unmixing; Image enhancement","Hyperspectral; Panchromatique; Pansharpening; Super-resolution; Unmixing","Conference paper","Final","","Scopus","2-s2.0-85039154778"
"Sezer O.G.; Altunbasak Y.","Sezer, Osman G. (13005399600); Altunbasak, Yucel (7006244815)","13005399600; 7006244815","Super-resolution reconstruction of multichannel images","2017","Super-Resolution Imaging","","","","355","381","26","10.1201/9781439819319","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052454899&doi=10.1201%2f9781439819319&partnerID=40&md5=a738f00d12491df550a9b34693fca403","This chapter describes how super-resolution techniques can be applied to improve both spatial and spectral resolution of the multichannel images. The digital cameras that become a part of the daily life captures color images that have three channels (i.e., red, green, and blue), however the number of frequency channels can go up to hundreds for some multichannel data such as hyperspectral images. The multichannel data in remote sensing applications addresses the need to resolve not only the shape of a particular object but also its compositional features (e.g., concrete, asphalt, brick, etc.) With the advent of analysis tools, the multichannel imagery makes it possible to identify, recognize, detect, or classify objects or regions of interest for commercial, civilian and military reconnaissance purposes. © 2011 by Taylor and Francis Group, LLC.","Image reconstruction; Military applications; Object detection; Optical resolving power; Remote sensing; Spectroscopy; Compositional features; Frequency channels; Military reconnaissance; Multichannel data; Multichannel images; Regions of interest; Remote sensing applications; Super resolution reconstruction; Image enhancement","","Book chapter","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85052454899"
"Zhang L.; Li J.","Zhang, Liangpei (8359720900); Li, Jiayi (55986562900)","8359720900; 55986562900","Development and prospect of sparse representation-based hyperspectral image processing and analysis","2016","Yaogan Xuebao/Journal of Remote Sensing","20","5","","1091","1101","10","10.11834/jrs.20166050","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992426887&doi=10.11834%2fjrs.20166050&partnerID=40&md5=657ebc95ecd308ded90a516c71e9cc56","Hyperspectral images, which span the visible to infrared spectrum with hundreds of contiguous and narrow spectral bands, are advantageous because of their subtle discriminative spectral characteristics. Owing to the fine spectral differences between various materials of interest, hyperspectral images support improved interpretation capabilities, and they perform important functions in various fields, such as the military, precision agriculture, and mineralogy. The sparsity of signals is a powerful and promising statistical signal modeling tool for hyperspectral image processing and analysis because signals can be compactly represented by only a few coefficients that carry the most important information in a certain basis or dictionary. A full diagram of Sparse Representation (SR) consists of sparse coding (regression) and dictionary learning. A brief review about this basic theory from the perspective of hyperspectral remote sensing is presented in the second section. With various forms of complex degradation and the demand for resolution enhancement considered, basic theories as well as recent studies in the area of hyperspectral image processing, including denoising, unmixing, super-resolution, and spectral-spatial image fusion in an SR manner, are presented in the third section. Dimensional reduction, classification, target detection, and anomaly detection, which are aimed at mining subtle diagnostic information on hyperspectral images in an SR manner, are also reviewed in the hyperspectral image analysis section. This review is followed by some suggestions and remarks on SR-based hyperspectral image processing and analysis. Processing literature considers denoising as the most fundamental task, single image super-resolution as problematic, and hyperspectral unmixing and spectral-spatial fusion as necessary subjects. In the hyperspectral analysis area, classification and detection are the most important tasks, and feature extraction/dimensional reduction works as a meaningful pre-processing step. The research on SR-based hyperspectral processing and analysis has recently attained some achievements. However, the obstacles mentioned in this paper still require further study. This review also presents several important remarks and outlines the future directions in this field. First, despite the increasing research on hyperspectral signal recovery and reconstruction, single image super-resolution and multi-resolution image fusion remain a problem area, mainly because of the limited availability of prior information within the remote sensing data and because of unstable sparse inverse optimization. Thus, the method for qualified over-completed dictionary design for specific hyperspectral image processing and delicate inverse optimization is an important study area. Second, the most important issue for hyperspectral image information extraction comes in the form of a discriminative dictionary. Most research ideas on hyperspectral target detection involve multiple sparse representation classification-based model simplification, whereas the anomaly detection method relies on the quality of the local ambient dictionary. Thus, the detection area should be studied further. In addition, reasonable approximated sparse coding combined with specific dictionary learning and some unique characteristics of hyperspectral images, such as manifold structure, multi-modality, and low rank property, should be regarded as useful tools for future research. © 2016, Science Press. All right reserved.","Classification (of information); Codes (symbols); Data fusion; Data mining; Feature extraction; Image analysis; Image coding; Image denoising; Image fusion; Independent component analysis; Inverse problems; Military photography; Minerals; Optical resolving power; Quality control; Radar target recognition; Remote sensing; Signal detection; Spectroscopy; Target tracking; Discriminative dictionaries; High dimensions; Hyperspectral image analysis; Hyperspectral image processing; Hyperspectral remote sensing; Hyperspectral target detection; Improving the quality of image; Sparse representation; Image processing","Disposal of high dimension; Hyperspectral image processing and analysis; Improving the quality of image; Sparse representation","Review","Final","","Scopus","2-s2.0-84992426887"
"Zhu H.; Song W.; Tan H.; Wang J.; Jia D.","Zhu, Hong (57190032288); Song, Weidong (56512910400); Tan, Hai (36976217000); Wang, Jingxue (55349285400); Jia, Di (36840119400)","57190032288; 56512910400; 36976217000; 55349285400; 36840119400","SUPER RESOLUTION RECONSTRUCTION BASED on ADAPTIVE DETAIL ENHANCEMENT for ZY-3 SATELLITE IMAGES","2016","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","3","","","213","217","4","10.5194/isprs-annals-III-7-213-2016","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043252013&doi=10.5194%2fisprs-annals-III-7-213-2016&partnerID=40&md5=ccaa1a1e0ba4cb487a9c7e12debf818c","Super-resolution reconstruction of sequence remote sensing image is a technology which handles multiple low-resolution satellite remote sensing images with complementary information and obtains one or more high resolution images. The cores of the technology are high precision matching between images and high detail information extraction and fusion. In this paper puts forward a new image super resolution model frame which can adaptive multi-scale enhance the details of reconstructed image. First, the sequence images were decomposed into a detail layer containing the detail information and a smooth layer containing the large scale edge information by bilateral filter. Then, a texture detail enhancement function was constructed to promote the magnitude of the medium and small details. Next, the non-redundant information of the super reconstruction was obtained by differential processing of the detail layer, and the initial super resolution construction result was achieved by interpolating fusion of non-redundant information and the smooth layer. At last, the final reconstruction image was acquired by executing a local optimization model on the initial constructed image. Experiments on ZY-3 satellite images of same phase and different phase show that the proposed method can both improve the information entropy and the image details evaluation standard comparing with the interpolation method, traditional TV algorithm and MAP algorithm, which indicate that our method can obviously highlight image details and contains more ground texture information. A large number of experiment results reveal that the proposed method is robust and universal for different kinds of ZY-3 satellite images.","","adaptive detail enhancement; image fusion; multi-scale decomposition; super resolution","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85043252013"
"Sharma S.; Sharma S.; Buddhiraju K.M.","Sharma, Shreya (57198535245); Sharma, Shakti (57193503231); Buddhiraju, Krishna M. (36815713200)","57198535245; 57193503231; 36815713200","Sub-pixel mapping of hyperspectral imagery using super-resolution","2016","Proceedings of SPIE - The International Society for Optical Engineering","9880","","98801Y","","","","10.1117/12.2223598","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006944150&doi=10.1117%2f12.2223598&partnerID=40&md5=328c6f93b8f8749dd368cb30da0ef162","With the development of remote sensing technologies, it has become possible to obtain an overview of landscape elements which helps in studying the changes on earth's surface due to climate, geological, geomorphological and human activities. Remote sensing measures the electromagnetic radiations from the earth's surface and match the spectral similarity between the observed signature and the known standard signatures of the various targets. However, problem lies when image classification techniques assume pixels to be pure. In hyperspectral imagery, images have high spectral resolution but poor spatial resolution. Therefore, the spectra obtained is often contaminated due to the presence of mixed pixels and causes misclassification. To utilise this high spectral information, spatial resolution has to be enhanced. Many factors make the spatial resolution one of the most expensive and hardest to improve in imaging systems. To solve this problem, post-processing of hyperspectral images is done to retrieve more information from the already acquired images. The algorithm to enhance spatial resolution of the images by dividing them into sub-pixels is known as super-resolution and several researches have been done in this domain.In this paper, we propose a new method for super-resolution based on ant colony optimization and review the popular methods of sub-pixel mapping of hyperspectral images along with their comparative analysis. © 2016 SPIE.","Ant colony optimization; Earth (planet); Image matching; Image resolution; Mapping; Optical resolving power; Remote sensing; Spectral resolution; Spectroscopy; Classication; Hyperspectral Data; Mixed pixel; Optmization; Spatial optimization; Sub-pixel mapping; Super resolution; Pixels","Ant colony optmization; Hyperspectral data; Mixed pixel; Soft-classication; Spatial optimization; Sub-pixel mapping; Superresolution","Conference paper","Final","","Scopus","2-s2.0-85006944150"
"Yanovsky I.; Lambrigtsen B.","Yanovsky, Igor (16403652300); Lambrigtsen, Bjorn (6603478504)","16403652300; 6603478504","Sparsity-based approaches for multispectral super-resolution of tropical cyclone imagery","2016","14th Specialist Meeting on Microwave Radiometry and Remote Sensing of the Environment, MicroRad 2016 - Proceedings","","","7530522","139","144","5","10.1109/MICRORAD.2016.7530522","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992200180&doi=10.1109%2fMICRORAD.2016.7530522&partnerID=40&md5=fffb615f84fe915fce61ef4cdc921054","An aperture synthesis system produces ringing at sharp edges and other transitions in the observed field. In this paper, we have developed an efficient multispectral deconvolution method, based on Split Bregman total variation minimization technique, and showed it to reduce image ringing, blurring, and distortion, while sharpening the image and preserving information content. We also present a multispectral multiframe super-resolution method that is robust to image noise and noise in the point spread function and leads to additional improvements in spatial resolution. The methodologies are based on current research in sparse optimization and compressed sensing, which lead to unprecedented efficiencies for solving image reconstruction problems. © 2016 IEEE.","Compressed sensing; Image reconstruction; Image resolution; Inverse problems; Microwaves; Optical resolving power; Optical transfer function; Radiometry; Remote sensing; Storms; Aperture synthesis; Microwave imaging; Multi-spectral image analysis; Spatial resolution; Super resolution; Image processing","Aperture synthesis system; inverse problems; microwave imaging; multispectral image analysis; remote sensing; spatial resolution; super-resolution","Conference paper","Final","","Scopus","2-s2.0-84992200180"
"Zhao C.; Chen Z.; Zeng G.; Zhang L.","Zhao, Chen (56518631600); Chen, Zezong (56099283200); Zeng, Gengfei (56574655900); Zhang, Longgang (56574767900)","56518631600; 56099283200; 56574655900; 56574767900","Evaluating two array autocalibration methods with multifrequency HF radar current measurements","2015","Journal of Atmospheric and Oceanic Technology","32","5","","1088","1097","9","10.1175/JTECH-D-14-00130.1","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980413824&doi=10.1175%2fJTECH-D-14-00130.1&partnerID=40&md5=0901af4167e44500bcb1d8fe2a18c3a7","One pivotal factor affecting the accuracy of HF radar current measurements is the direction of arrival (DOA) estimation performance of the current signal. The beamforming technology or superresolution algorithm cannot always perform best in practical applications because of the phase errors existing in array channels. These phase errors, which cause uncertain estimation of DOA, lead to confused values in radial current maps. To solve this problem, this paper is focused on discussing the performances of two autocalibration methods using sea echoes for multifrequency high-frequency (MHF) radar current measurements. These two array calibration methods, based on maximum likelihood (ML) and multiple signal classification (MU), first seek single-DOA sea echoes and then gather them for array calibration using different cost functions. The ML and MU methods provide approximate mean phases, while the standard phase errors of the MU method are smaller. After array calibration using these two methods, the results show significant improvements in current retrievals. Comparisons between the MHF radar and ADCPs reveal that array calibration using the ML and MU methods also improves the estimation of radial currents clearly, with correlation coefficients over 0.93 and rms differences of 0.09-0.18 m s-1 at different operating frequencies and sampling locations. The performance of the bearing offset is also improved. Only small bearing offsets less than 10° exist in radial current measurements. Therefore, this paper demonstrates that array calibration is a crucial part for current measurements, especially for direction-finding HF radar. © 2015 American Meteorological Society.","Calibration; Cost functions; Data handling; Data processing; Electric current measurement; Errors; Frequency estimation; Maximum likelihood; Maximum likelihood estimation; Radar; Radar measurement; Radar signal processing; Remote sensing; Wavelet analysis; Auto-calibration method; Correlation coefficient; Direction of arrivalestimation(DOA); Multiple signal classification; Operating frequency; Radars/radar observations; Super resolution algorithms; Surface observation; algorithm; automation; calibration; data processing; marine technology; maximum likelihood analysis; measurement method; oceanic current; remote sensing; Direction of arrival","Data processing; Radars/Radar observations; Remote sensing; Surface observations","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-84980413824"
"Jin G.; Song M.-Z.; Zhang G.-X.; Qu H.-S.; Tao S.-P.","Jin, Guang (26434758300); Song, Ming-Zhu (57195512909); Zhang, Gui-Xiang (55505933600); Qu, Hong-Song (15060363800); Tao, Shu-Ping (55025161500)","26434758300; 57195512909; 55505933600; 15060363800; 55025161500","Digital domain tilting model time delayed and integration technology","2017","Chinese Journal of Liquid Crystals and Displays","32","8","1007-2780(2017)08-0628-07","628","634","6","10.3788/YJYXS20173208.0628","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028571948&doi=10.3788%2fYJYXS20173208.0628&partnerID=40&md5=b5b17af7fb5cf567664e609c1650ff94","In order to realize super-resolution of remote sensing picture, an digital domain tilting model time delayed and integration(DT-TDI) technology is proposed, and its relevant technologies such as digital domain TDI technology, tilting sampling imaging theory, DT-TDI technology and etc are analysed and investigated. First, we establish general digital TDI model; then establish DT-TDI model applied to different tilt angle by utilizing tilting sampling imaging theory, then we choose tilt angle of 45° and prove the accuracy of DT-TDI by experiment, and obtain a series of low resolution images of a certain attitude and orbit in this angle. Finally, we reconstruct the low resolution images of subpixel shifting via super-resolution algorithm and obtain high resolution image. Experimental results indicate that the DT-TDI technology has a stable imaging capability, and the subpixel shifting error of low resolution images is about 15% in 45°, and the DT-TDI technology is satisfied with the demand of superresolution. The resolution ratio of image is raised obviously after reconstruction. © 2017, Science Press. All rights reserved.","","Digital domain TDI; Subpixel; Tilting model","Article","Final","","Scopus","2-s2.0-85028571948"
"Veganzones M.A.; Simões M.; Licciardi G.; Yokoya N.; Bioucas-Dias J.M.; Chanussot J.","Veganzones, Miguel A. (24825298300); Simões, Miguel (56376643900); Licciardi, Giorgio (23493098400); Yokoya, Naoto (36440631200); Bioucas-Dias, José M. (55901520500); Chanussot, Jocelyn (6602159365)","24825298300; 56376643900; 23493098400; 36440631200; 55901520500; 6602159365","Hyperspectral super-resolution of locally low rank images from complementary multisource data","2016","IEEE Transactions on Image Processing","25","1","7312998","274","288","14","10.1109/TIP.2015.2496263","122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009259853&doi=10.1109%2fTIP.2015.2496263&partnerID=40&md5=d66828832939a472c4416325df0fc479","Remote sensing hyperspectral images (HSIs) are quite often low rank, in the sense that the data belong to a low dimensional subspace/manifold. This has been recently exploited for the fusion of low spatial resolution HSI with high spatial resolution multispectral images in order to obtain super-resolution HSI. Most approaches adopt an unmixing or a matrix factorization perspective. The derived methods have led to state-of-the-art results when the spectral information lies in a low-dimensional subspace/manifold. However, if the subspace/manifold dimensionality spanned by the complete data set is large, i.e., larger than the number of multispectral bands, the performance of these methods mainly decreases because the underlying sparse regression problem is severely ill-posed. In this paper, we propose a local approach to cope with this difficulty. Fundamentally, we exploit the fact that real world HSIs are locally low rank, that is, pixels acquired from a given spatial neighborhood span a very low-dimensional subspace/manifold, i.e., lower or equal than the number of multispectral bands. Thus, we propose to partition the image into patches and solve the data fusion problem independently for each patch. This way, in each patch the subspace/manifold dimensionality is low enough, such that the problem is not ill-posed anymore. We propose two alternative approaches to define the hyperspectral superresolution through local dictionary learning using endmember induction algorithms. We also explore two alternatives to define the local regions, using sliding windows and binary partition trees. The effectiveness of the proposed approaches is illustrated with synthetic and semi real data. © 2015 IEEE.","Binary trees; Data fusion; Factorization; Forestry; Image fusion; Image resolution; Object recognition; Optical resolving power; Remote sensing; Spectroscopy; Binary partition Tree; Dictionary learning; Hyper-spectral imageries; Multi-spectral imagery; Spectral unmixing; Super resolution; Trees (mathematics)","Binary partition tree; Data fusion; Dictionary learning; Hyperspectral imagery; Multispectral imagery; Spectral unmixing; Super-resolution","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85009259853"
"Zhou J.; Zhou C.; Zhu J.; Fan D.","Zhou, Jinghong (56242343500); Zhou, Cui (55578922200); Zhu, Jianjun (6602928296); Fan, Donghao (56241669700)","56242343500; 55578922200; 6602928296; 56241669700","A method of super-resolution reconstruction for remote sensing image based on non-subsampled contourlet transform","2015","Guangxue Xuebao/Acta Optica Sinica","35","1","0110001","","","9","10.3788/AOS201535.0110001","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922671627&doi=10.3788%2fAOS201535.0110001&partnerID=40&md5=40d42db3200b711ab8540e600d375bb0","An improved method is proposed to solve the existing problem that the fusion process is too simple in non- subsampled contourlet transform (NSCT) super- resolution reconstruction. The magnitude of the spatial frequency reflects the degree of image detail richness, and the improved method uses this magnitude of regional window as the standard of the weight, so the adaptive weighted fusion method is applied to the obtained high frequency by NSCT decomposition of image. The adaptive weighted fusion method and NSCT analysis are assembled to achieve image super- resolution reconstruction, in this process, each corresponding high-frequency image is fused by adaptive weighted fusion method, and the low-frequency image is processed to get a mean. The super- resolution image is acquired by inverse NSCT to both the low frequency images and high frequency images. Through simulation and engineering practice, the improved method proves to be feasible and effective. ©, 2015, Chinese Optical Society. All right reserved.","Image fusion; Image processing; Image reconstruction; Inverse problems; Optical resolving power; Remote sensing; Two dimensional; Wavelet transforms; Adaptive fusion; Adaptive weighted fusions; Bicubic interpolation; Image super-resolution reconstruction; Non subsampled contourlet transform (NSCT); Non-sub-sampled contourlet transforms; Remote sensing images; Super resolution reconstruction; Image enhancement","Bicubic interpolation; Image processing; Non-subsampled contourlet transform; Regional adaptive fusion; Super-resolution reconstruction; Two-dimensional wavelet transform","Article","Final","","Scopus","2-s2.0-84922671627"
"Dong S.; Nanda P.; Guo K.; Liao J.; Zheng G.","Dong, Siyuan (55990219900); Nanda, Pariksheet (56342347500); Guo, Kaikai (56193607100); Liao, Jun (56824887200); Zheng, Guoan (57202554945)","55990219900; 56342347500; 56193607100; 56824887200; 57202554945","Incoherent Fourier ptychographic photography using structured light","2015","Photonics Research","3","1","","19","23","4","10.1364/PRJ.3.000019","48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941124186&doi=10.1364%2fPRJ.3.000019&partnerID=40&md5=3628054ca45e7f21916d0954e48daac4","Controlling photographic illumination in a structured fashion is a common practice in computational photography and image-based rendering. Here we introduce an incoherent photographic imaging approach, termed Fourier ptychographic photography, that uses nonuniform structured light for super-resolution imaging. In this approach, frequency mixing between the object and the structured light shifts the high-frequency object information to the passband of the photographic lens. Therefore, the recorded intensity images contain object information that is beyond the cutoff frequency of the collection optics. Based on multiple images acquired under different structured light patterns, we used the Fourier ptychographic algorithm to recover the super-resolution object image and the unknown illumination pattern. We demonstrated the reported approach by imaging various objects, including a resolution target, a quick response code, a dollar bill, an insect, and a color leaf. The reported approach may find applications in photographic imaging settings, remote sensing, and imaging radar. It may also provide new insights for high-resolution imaging by shifting the focus from the collection optics to the generation of structured light. © 2015 Chinese Laser Press.","Color photography; Cutoff frequency; Fourier transforms; Imaging systems; Microscopic examination; Mixer circuits; Optical resolving power; Photography; Remote sensing; Computational imaging; Computational photography; Digital holography; High-resolution imaging; Image based rendering; Structured light patterns; Super resolution imaging; Unknown illuminations; Light","Computational imaging; Digital holography; Imaging systems; Microscopy","Article","Final","","Scopus","2-s2.0-84941124186"
"Mayossa P.C.K.; Gadal S.; Roda J.-M.","Mayossa, Prune Christobelle Komba (57191524165); Gadal, Sébastien (6504148942); Roda, Jean-Marc (7005768217)","57191524165; 6504148942; 7005768217","Remote sensing of industrial palm groves in Cameroon","2017","ASM Science Journal","2017","Specialissue1","","16","20","4","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026513859&partnerID=40&md5=e54c1dc9a376cc116449a4f3a9124d18","The measurement of biomass can be obtainedfrom remote sensing analysis and modelling, the impacts of which are related to oil palm cultivation in industrial plantations. Our study aims at producing a spatial model for oil palm biomass estimation, at different scales of spatial analysis. The study was carried out in the industrial plantations of the Cameroonian Society of Palm Groves (SOCAPALM). The developed methodology combined: (i) the mapping of palm groves (Kumar, 2015), (ii) the characterisationof palm groves (Gadal, 2013), (iii) biomass estimation, and (iv) the comparison of the obtained results with Spot6, Landsat 7 ETM+ and Landsat 8 OLI images from 2001 to 2015. The first results were obtained for the mapping of the SOCAPALM industrial palm groves between 2001 and 2015. The obtained maps were highly correlated (Kappa of 0.91 for Spot 6, 0.92 for Landsat 7 and 0.82 for Lansat8), however, because of the presence of mixed pixels, some confusion between oil palm and other classes were observed. One of the factors affecting biomass estimation is spatial accuracy. Several improvements have been suggested: (1) mapping palm groves at a subpixel scale using super-resolution mapping; (2) developing a classification system of cartographic products. The use of satellites images with different spatial resolutions may also help to generate new data taking into account the level of spatial analysis.","","Biomass; Energy; Modelling; Palm groves; Remote sensing; Spatial accuracy","Article","Final","","Scopus","2-s2.0-85026513859"
"Wang L.; Zhao C.","Wang, Liguo (55745497100); Zhao, Chunhui (7403563984)","55745497100; 7403563984","Hyperspectral image processing","2015","Hyperspectral Image Processing","","","","1","315","314","10.1007/978-3-662-47456-3","42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945351798&doi=10.1007%2f978-3-662-47456-3&partnerID=40&md5=4651093e3fd7f4585a30cca482f1fa94","Based on the authors' research, this book introduces the main processing techniques in hyperspectral imaging. In this context, SVM-based classification, distance comparison-based endmember extraction, SVM-based spectral unmixing, spatial attraction model-based sub-pixel mapping and MAP/POCS-based super-resolution reconstruction are discussed in depth. Readers will gain a comprehensive understanding of these cutting-edge hyperspectral imaging techniques. Researchers and graduate students in fields such as remote sensing, surveying and mapping, geosciences and information systems will benefit from this valuable resource. © National Defense Industry Press, Beijing and Springer-Verlag Berlin Heidelberg 2016.","Hyperspectral imaging; Imaging techniques; Mapping; Photomapping; Spectroscopy; Students; Cutting edges; Endmember extraction; Graduate students; Model-based OPC; Processing technique; Spectral unmixing; Sub-pixel mapping; Super resolution reconstruction; Image processing","","Book","Final","","Scopus","2-s2.0-84945351798"
"Sun T.; Zhang Z.C.; Song B.; Tang X.J.; Liu S.B.","Sun, T. (57220544728); Zhang, Z.C. (57192635798); Song, B. (15521496400); Tang, X.J. (7404101522); Liu, S.B. (36554383500)","57220544728; 57192635798; 15521496400; 7404101522; 36554383500","Subsurface fine structures survey by GPR B-scan image based on signal subspace method","2016","Proceedings of 2016 16th International Conference of Ground Penetrating Radar, GPR 2016","","","7572593","","","","10.1109/ICGPR.2016.7572593","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992035780&doi=10.1109%2fICGPR.2016.7572593&partnerID=40&md5=3f4b0ce90488515e9f983c012caaee72","Ground Penetrating Radar (GPR) is an efficient remote sensing tool for geophysical subsurface survey. These structure characteristics are recorded in radar signal profiles by means of echo detection, amplitude and phase estimation. Besides the energy attenuation and absorption of GPR EM pulse during its propagating downward direction into the ground from a transmitting antenna, the strong interferences, clutters, multiples and random noise, often make the fine-structures hardly distinguishable. This paper develops a signal subspace method to detect fine fractures, leading to water intrusion at the Dazu Rock Carving site. With field surveying data, this method is validated to detect sub-surface fine structure with sparse representation and yields discriminative fracture signature for geological interpretation. © 2016 IEEE.","Atomic physics; Electromagnetic pulse; Fracture; Geological surveys; Radar; Radar imaging; Remote sensing; Signal analysis; Signal detection; Surveys; Dazu Rock Carving; Ground Penetrating Radar; MUSIC; Signal sub-space; Super resolution; Ground penetrating radar systems","Dazu Rock Carving; Ground penetrating radar; MUSIC; Signal subspace; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-84992035780"
"Li W.; Zhang X.; Ling F.; Zheng D.","Li, Wenbo (57207126023); Zhang, Xiuhua (57173288700); Ling, Feng (56278268300); Zheng, Dongbo (57191199900)","57207126023; 57173288700; 56278268300; 57191199900","Locally adaptive super-resolution waterline mapping with MODIS imagery","2016","Remote Sensing Letters","7","12","","1121","1130","9","10.1080/2150704X.2016.1219460","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987875558&doi=10.1080%2f2150704X.2016.1219460&partnerID=40&md5=698f552ee02a6a49194c1b9d5782ab46","Mapping inland water bodies is important for relevant research fields and water resource management. Satellite remote sensing is a routine approach, and various remotely sensed images have been applied to map waterlines. MODerate-resolution Imaging Spectroradiometer (MODIS) images have advantages for waterline mapping in large areas, thanks to its wide scan width and high frequent revisiting period; however, the spatial resolution of MODIS images is too coarse to map waterlines accurately. In this article, a super-resolution mapping (SRM) model was proposed for fine spatial resolution waterline mapping with MODIS images. The proposed SRM model was directly applied in the MODIS band 2 images, which have a fine spatial resolution and a high spectral separability between water and land. In order to further take account of the spatial heterogeneity of endmembers, the reflectance values of water and land were locally calculated for each coarse resolution pixel. The proposed SRM model was assessed in two study areas located in the Tibetan Plateau, China and Wisconsin, United States, including water bodies with different areas and boundary shapes. The results showed that the accuracy values of the proposed SRM model using local endmembers were higher than those of hard classification and the SRM model using average endmembers, showing the effectiveness of the proposed model in fine spatial resolution waterline mapping with MODIS imagery. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","China; Qinghai-Xizang Plateau; United States; Wisconsin; Image resolution; Mapping; Optical resolving power; Reflection; Remote sensing; Satellite imagery; Water management; Moderate resolution imaging spectroradiometer; Remotely sensed images; Satellite remote sensing; Spatial heterogeneity; Spatial resolution; Spectral separability; Super-resolution mappings; Waterresource management; hydrological modeling; image classification; mapping method; MODIS; pixel; reflectance; remote sensing; resource management; satellite imagery; spatial resolution; water resource; Radiometers","","Article","Final","","Scopus","2-s2.0-84987875558"
"Dwivedi M.; Kumar V.","Dwivedi, Manish (57192585923); Kumar, Vinay (57212901158)","57192585923; 57212901158","Super-resolution mapping using multi-viewing CHRIS/PROBA data","2016","Proceedings of SPIE - The International Society for Optical Engineering","9880","","98800Y","","","","10.1117/12.2227665","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006905612&doi=10.1117%2f12.2227665&partnerID=40&md5=1325feb441309455660dbba8940e2ca6","High-spatial resolution Remote Sensing (RS) data provides detailed information which ensures high-definition visual image analysis of earth surface features. These data sets also support improved information extraction capabilities at a fine scale. In order to improve the spatial resolution of coarser resolution RS data, the Super Resolution Reconstruction (SRR) technique has become widely acknowledged which focused on multi-angular image sequences. In this study multi-angle CHRIS/PROBA data of Kutch area is used for SR image reconstruction to enhance the spatial resolution from 18 m to 6m in the hope to obtain a better land cover classification. Various SR approaches like Projection onto Convex Sets (POCS), Robust, Iterative Back Projection (IBP), Non-Uniform Interpolation and Structure-Adaptive Normalized Convolution (SANC) chosen for this study. Subjective assessment through visual interpretation shows substantial improvement in land cover details. Quantitative measures including peak signal to noise ratio and structural similarity are used for the evaluation of the image quality. It was observed that SANC SR technique using Vandewalle algorithm for the low resolution image registration outperformed the other techniques. After that SVM based classifier is used for the classification of SRR and data resampled to 6m spatial resolution using bi-cubic interpolation. A comparative analysis is carried out between classified data of bicubic interpolated and SR derived images of CHRIS/PROBA and SR derived classified data have shown a significant improvement of 10-12% in the overall accuracy. The results demonstrated that SR methods is able to improve spatial detail of multi-angle images as well as the classification accuracy. © 2016 SPIE.","Image analysis; Image processing; Image quality; Image reconstruction; Image resolution; Image segmentation; Interpolation; Iterative methods; Mapping; Optical resolving power; Quality control; Remote sensing; Set theory; Signal to noise ratio; Bicubic interpolation; CHRIS/PROBA; Multi-Viewing Hypersectral data; POCS; SANC; Spatial; Super-resolution mappings; Data mining","Bicubic Interpolation; CHRIS/PROBA; IBP; Multi-Viewing Hypersectral data; POCS; SANC; Spatial; Super Resolution Mapping; SVM","Conference paper","Final","","Scopus","2-s2.0-85006905612"
"Tao Y.; Muller J.-P.","Tao, Y. (56539197700); Muller, J.-P. (7404871794)","56539197700; 7404871794","Quantitative assessment of a novel super-resolution restoration technique using hirise with navcam images: How much resolution enhancement is possible from repeat-pass observations","2016","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","41","","","503","509","6","10.5194/isprsarchives-XLI-B4-503-2016","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978044416&doi=10.5194%2fisprsarchives-XLI-B4-503-2016&partnerID=40&md5=eaf2103a9aabacb8d610a9608bddcffa","Higher spatial resolution imaging data is always desirable to the international community of planetary scientists interested in improving understanding of surface formation processes. We have previously developed a novel Super-resolution restoration (SRR) technique (Tao & Muller, 2016) using Gotcha sub-pixel matching, orthorectification, and segmented 4th order PDE-TV, called GPT SRR, which is able to restore 5cm-12.5cm near rover scale images (equivalent to Navcam projected FoV at a range of ≥5m) from multiple 25cm resolution NASA MRO HiRISE images. The SRR technique has been successfully applied to the rover traverses for the MER and MSL missions within the EU FP-7 PRoViDE project. These SRR results have revealed new surface information including the imaging of individual rocks (diameter ≥ 25cm) by comparison of the original HiRISE image and rover Navcam orthorectified image mosaics. In this work, we seek evidence from processing a very large number of stereo reconstruction results from all Navcam stereo images within PRoViDE, registration and comparison with the corresponding SRR image, in order to derive a quantitative assessment on key features including rocks (diameter < 150cm) and rover track wheel spacing. We summarise statistics from SRR-Navcam measurements and demonstrate that our unique SRR datasets will greatly support the geological and morphological analysis and monitoring of Martian surface and can also be applied to landing site selection, in order to avoid unsuitable terrain, for any future lander/rover as well as help to define future rover paths.","Image processing; Image reconstruction; Image registration; Landing; Martian surface analysis; NASA; Optical resolving power; Remote sensing; Restoration; Site selection; Assessment; HiRISE; Landing site; Navcam; Orthorectified image; Repeat pass; Resolution enhancement; Rover track; Super-resolution restoration; Stereo image processing","Assessment; GPT; HiRISE; Landing site selection; MSL; Navcam; Orthorectified image; Repeat-pass; Resolution enhancement; Rock size; Rover track; Super-resolution restoration","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84978044416"
"Amiri M.; Ahmadifard A.; Abolghasemi V.","Amiri, Mahmood (57193790581); Ahmadifard, Alireza (23003581100); Abolghasemi, Vahid (23466416200)","57193790581; 23003581100; 23466416200","A probabilistic framework for dense image registration using relaxation labelling","2017","Proceedings - 2016 2nd International Conference of Signal Processing and Intelligent Systems, ICSPIS 2016","","","7869876","","","","10.1109/ICSPIS.2016.7869876","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016546299&doi=10.1109%2fICSPIS.2016.7869876&partnerID=40&md5=77833beae50bd2d46341450ef9692f94","Image Registration has investigated in many researches in recent years. It is an important preprocessing step in a variety of applications such as medical images, super resolution and remote sensing. Generally, dense image registration requires several transformations and deformations such as contrast changing, scaling, rotation and displacement. However, in most recent proposed methods, only some of these transforms are considered, which results in incorrect output. In this paper we propose a new method for dense image registration based on relaxation labelling. For each pixel of a test image, we want to find the best match in a reference image, considering the intensity and geometric constraints. We use blocks of reference image as features, then we look for the closest candidate in the test image. In next step, a relaxation labelling procedure is applied to these candidates for selecting the best match between candidate pixels. Experimental results show that the proposed method achieves satisfactory performance in terms of visual quality, PSNR values and Bad pixel evaluation criteria. © 2016 IEEE.","Image registration; Intelligent systems; Medical imaging; Pixels; Remote sensing; Signal processing; Stereo image processing; Dense image registrations; Dense registration; Evaluation criteria; Feature matching; Geometric constraint; Pre-processing step; Probabilistic framework; Stereo matching; Image processing","Dense registration; Feature matching; Relaxation labelling; Stereo matching","Conference paper","Final","","Scopus","2-s2.0-85016546299"
"Li L.; Xu T.; Chen Y.","Li, Linyi (12781706800); Xu, Tingbao (24304468000); Chen, Yun (55721092200)","12781706800; 24304468000; 55721092200","Improved urban flooding mapping from remote sensing images using generalized regression neural network-based super-resolution algorithm","2016","Remote Sensing","8","8","625","","","","10.3390/rs8080625","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983800181&doi=10.3390%2frs8080625&partnerID=40&md5=293d34a4a32d6462c2342a6dd92f5289","Urban flooding is a serious natural hazard to many cities all over the world, which has dramatic impacts on the urban environment and human life. Urban flooding mapping has practical significance for the prevention and management of urban flood disasters. Remote sensing images with high temporal resolutions are widely used for urban flooding mapping, but have a limitation of relatively low spatial resolutions. In this study, a new method based on a generalized regression neural network (GRNN) is proposed to achieve improved accuracy in super-resolution mapping of urban flooding (SMUF) from remote sensing images. The GRNN-SMUF algorithm was proposed and then assessed using Landsat 5 and Landsat 8 images of Brisbane city in Australia and Wuhan city in China. Compared to three traditional methods, GRNN-SMUF mapped urban flooding more accurately according to both visual and quantitative assessments. The results of this study will improve the accuracy of urban flooding mapping using easily-available remote sensing images with medium-low spatial resolutions and will be propitious to the prevention and management of urban flood disasters. © 2016 by the authors.","Algorithms; Disaster prevention; Disasters; Floods; Image reconstruction; Mapping; Neural networks; Optical resolving power; Regression analysis; Generalized Regression Neural Network(GRNN); Generalized regression neural networks; High temporal resolution; Quantitative assessments; Remote sensing images; Super resolution algorithms; Super-resolution mappings; Urban flooding; Remote sensing","Generalized regression neural network; Remote sensing images; Super-resolution mapping; Urban flooding","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84983800181"
"Kanaev A.V.","Kanaev, A.V. (35515080100)","35515080100","Compact full-motion video hyperspectral cameras: Development, image processing, and applications","2015","Proceedings of SPIE - The International Society for Optical Engineering","9649","","96490R","","","","10.1117/12.2196718","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961589264&doi=10.1117%2f12.2196718&partnerID=40&md5=24d54ae9b8f41387e6f9fd92802cd803","Emergence of spectral pixel-level color filters has enabled development of hyper-spectral Full Motion Video (FMV) sensors operating in visible (EO) and infrared (IR) wavelengths. The new class of hyper-spectral cameras opens broad possibilities of its utilization for military and industry purposes. Indeed, such cameras are able to classify materials as well as detect and track spectral signatures continuously in real time while simultaneously providing an operator the benefit of enhanced-discrimination-color video. Supporting these extensive capabilities requires significant computational processing of the collected spectral data. In general, two processing streams are envisioned for mosaic array cameras. The first is spectral computation that provides essential spectral content analysis e.g. detection or classification. The second is presentation of the video to an operator that can offer the best display of the content depending on the performed task e.g. providing spatial resolution enhancement or color coding of the spectral analysis. These processing streams can be executed in parallel or they can utilize each other's results. The spectral analysis algorithms have been developed extensively, however demosaicking of more than three equally-sampled spectral bands has been explored scarcely. We present unique approach to demosaicking based on multi-band super-resolution and show the trade-off between spatial resolution and spectral content. Using imagery collected with developed 9-band SWIR camera we demonstrate several of its concepts of operation including detection and tracking. We also compare the demosaicking results to the results of multi-frame super-resolution as well as to the combined multi-frame and multiband processing. © 2015 SPIE.","Cameras; Color; Economic and social effects; Image processing; Image resolution; Infrared radiation; Motion analysis; Optical data processing; Optical resolving power; Remote sensing; Spectrum analysis; Computational processing; Concepts of operations; Demosaicking; Detection and tracking; Hyper-spectral cameras; Mosaic arrays; Spatial-resolution enhancement; Super resolution; Video signal processing","demosaicking; mosaic-array cameras; super-resolution","Conference paper","Final","","Scopus","2-s2.0-84961589264"
"Fernandez-Beltran R.; Latorre-Carmona P.; Pla F.","Fernandez-Beltran, Ruben (55838551300); Latorre-Carmona, Pedro (35303034400); Pla, Filiberto (7006504936)","55838551300; 35303034400; 7006504936","Single-frame super-resolution in remote sensing: a practical overview","2017","International Journal of Remote Sensing","38","1","","314","354","40","10.1080/01431161.2016.1264027","62","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003837202&doi=10.1080%2f01431161.2016.1264027&partnerID=40&md5=4846e9bfd0a60fe88fd6e47f3d7506c3","Image acquisition technology is improving very fast from a performance point of view. However, there are physical restrictions that can only be solved using software processing strategies. This is particularly true in the case of super resolution (SR) methodologies. SR techniques have found a fertile application field in airborne and space optical acquisition platforms. Single-frame SR methods may be advantageous for some remote-sensing platforms and acquisition time conditions. The contributions of this article are basically two: (1) to present an overview of single-frame SR methods, making a comparative analysis of their performance in different and challenging remote-sensing scenarios, and (2) to propose a new single-frame SR taxonomy, and a common validation strategy. Finally, we should emphasize that, on the one hand, this is the first time, to the best of our knowledge, that such a review and analysis of single SR methods is made in the framework of remote sensing, and, on the other hand, that the new single-frame SR taxonomy is aimed at shedding some light when classifying some types of single-frame SR methods. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","Image enhancement; Optical resolving power; Space optics; Space platforms; Taxonomies; Technology transfer; Application fields; Comparative analysis; Performance points; Physical restriction; Remote sensing platforms; Single frame super resolutions; Software processing; Validation strategies; comparative study; data acquisition; image classification; image resolution; performance assessment; remote sensing; software; Remote sensing","","Review","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85003837202"
"Xinlei W.; Naifeng L.","Xinlei, Wang (55821520400); Naifeng, Liu (57225227139)","55821520400; 57225227139","Super-resolution of remote sensing images via sparse structural manifold embedding","2016","Neurocomputing","173","","","1402","1411","9","10.1016/j.neucom.2015.09.012","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959363195&doi=10.1016%2fj.neucom.2015.09.012&partnerID=40&md5=1381174d20f3f591515e6ebbbf359e5d","Exploring signal processing technologies to enhance the resolution of remote sensing images has received increasing interests in the last decade. In order to well preserve the structural details such as edges, contours and textures in the recovered high-resolution images, we advance a new Sparse Structural Manifold Embedding (SSME) approach in this paper. By incorporating the geometric regularities of images along singularity of edges or contours into neighbors' selection, SSME can well recover structural information of images. Moreover, considering that outliers are often included into embedding to generate inaccurate structures, a robust and sparse embedding is used to exclude outliers in synthesizing high-resolution images, where normalized weights are employed to acquire more accurate neighbors and coding coefficients. Experiments are taken on realizing a 3× amplification of remote sensing images, and the results indicated that SSME has an improvement of about 0.1-0.3. dB over the state-of-the-art results in peak signal to noise ratio. © 2015 Elsevier B.V.","Image enhancement; Image processing; Image reconstruction; Optical resolving power; Remote sensing; Signal processing; Signal to noise ratio; Statistics; Image super resolutions; Non-sub-sampled contourlet transforms; Normalized weights; Sparse coding; Sparse structural manifold embedding; Article; image analysis; image processing; image quality; image reconstruction; mathematical analysis; priority journal; remote sensing; signal noise ratio; signal processing; Image coding","Image super-resolution; Nonsubsampled Contourlet transform; Normalized weights; Sparse coding; Sparse structural manifold embedding","Article","Final","","Scopus","2-s2.0-84959363195"
"Zhang Z.; Liu A.; Lei Q.","Zhang, Zhaohui (57104099000); Liu, Anran (57104194500); Lei, Qian (57104567500)","57104099000; 57104194500; 57104567500","Image super-resolution reconstruction via RBM-based joint dictionary learning and sparse representation","2015","Proceedings of SPIE - The International Society for Optical Engineering","9815","","981528","","","","10.1117/12.2214097","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957642927&doi=10.1117%2f12.2214097&partnerID=40&md5=e1670c96dd6380b417d61a30ae5f46ea","In this paper, we propose a method for single image super-resolution(SR). Given the training set produced from large amount of high-low resolution image patches, an over-complete joint dictionary is firstly learned from a pair of high-low resolution image feature space based on Restricted Boltzmann Machines (RBM). Then for each low resolution image patch densely extracted from an up-scaled low resolution input image, its high resolution image patch can be reconstructed based on sparse representation. Finally, the reconstructed image patches are overlapped to form a large image, and a high resolution image can be achieved by means of iterated residual image compensation. Experimental results verify the effectiveness of the proposed method. © 2015 SPIE.","Geographic information systems; Image reconstruction; Information systems; Optical resolving power; Pattern recognition; Pattern recognition systems; Remote sensing; Space optics; Dictionary learning; High resolution image; Image super resolutions; Image super-resolution reconstruction; Low resolution images; Reconstructed image; Restricted boltzmann machine; Sparse representation; Image processing","Image Super-Resolution; Joint Dictionary Learning; Restricted Boltzmann Machine(RBM); Sparse Representation","Conference paper","Final","","Scopus","2-s2.0-84957642927"
"Zhao Y.; Huang B.","Zhao, Yongquan (57192575717); Huang, Bo (55388074800)","57192575717; 55388074800","A Two-step Spatio-Temporal satellite image Fusion Model for temporal changes of various LULC under one-pair prior images scenario","2016","ICSPCC 2016 - IEEE International Conference on Signal Processing, Communications and Computing, Conference Proceedings","","","7753699","","","","10.1109/ICSPCC.2016.7753699","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006850810&doi=10.1109%2fICSPCC.2016.7753699&partnerID=40&md5=7135e31dd0f56e3cae61881af8a440b6","This paper proposes a two-step spatio-temporal fusion model (TSTFM) for generating synthetic satellite remote sensing images with high-spatial and high-temporal resolution (HSaHTeR) based on one pair of prior images, which contain one low-spatial but high-temporal resolution (LSaHTeR) image and one high-spatial but low-temporal resolution (HSaLTeR) image. Considering both phenology and type surface temporal changes, the two steps in TSTFM are adopted to handle these two kinds of changes respectively, which are based on weighted mean and example-based image super-resolution approaches accordingly. In addition, a relative radiometric normalization process is conducted before performing the two-step spatio-temporal fusion (STF) process, which aims to calibrate radiometric differences of different kinds of satellite sensors. The proposed method was tested on two sets of test data: surface with mainly LULC phenology changes and surface with primarily LULC type changes. Experimental results show that TSTFM can capture both phenology and type changes efficiently and precisely even with one-pair prior images, and it can also maintain its robustness when facing extremely complex LULC. © 2016 IEEE.","Biology; Image reconstruction; Optical resolving power; Radiometry; Remote sensing; Satellites; Signal processing; Image super resolutions; phenology change; Spatio-temporal fusions; type change; various LULC; Weighted mean; Image fusion","image super-resolution; phenology change; Spatio-temporal fusion; type change; various LULC; weighted mean","Conference paper","Final","","Scopus","2-s2.0-85006850810"
"Zaki S.K.M.; Muad A.M.","Zaki, Siti Khadijah Mohd (56594484500); Muad, Anuar M. (36681355600)","56594484500; 36681355600","Estimating location of land cover patch in super-resolution mapping by hopfield neural network","2015","ISCAIE 2015 - 2015 IEEE Symposium on Computer Applications and Industrial Electronics","","","7298325","42","47","5","10.1109/ISCAIE.2015.7298325","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959057369&doi=10.1109%2fISCAIE.2015.7298325&partnerID=40&md5=4a702df414ada20231eef7713fa44897","Super-resolution mapping (SRM) aims to locate subpixel class fractions geographically in the area represented by a mixed pixel. The accuracy of small sub-pixel class patches are represented by the popular SRM method is explored. It is shown that the accuracy of predicted patch location from the Hopfield Neural of SRM is a function of patch size. Specifically, the accuracy with which patch location is predicted varies inversely with patch size, with very small patches subject to large mis-location errors. A means to reduce the magnitude of mis-location error through the use of multiple sub-pixel shifted imagery is illustrated and the implications to popular site-specific accuracy assessment discussed. The use of multiple subpixel shifted images was able to reduce the error in patch location by more than half for very small patches and represents a simple but effective enhancement to SRM applications. © 2015 IEEE.","Errors; Hopfield neural networks; Industrial electronics; Location; Optical resolving power; Pixels; Remote sensing; Accuracy assessment; Land cover; Location errors; Mixed pixel; Site-specific; Small patches; Sub pixels; Super-resolution mappings; Mapping","mixed pixel; multiple sub-pixel shifted; remote sensing","Conference paper","Final","","Scopus","2-s2.0-84959057369"
"Frazier A.E.","Frazier, Amy E. (38661165700)","38661165700","Landscape heterogeneity and scale considerations for super-resolution mapping","2015","International Journal of Remote Sensing","36","9","","2395","2408","13","10.1080/2150704X.2015.1040130","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928923325&doi=10.1080%2f2150704X.2015.1040130&partnerID=40&md5=da155bb982a88fc0da6fcedb2204abe4","Super-resolution mapping (SRM) is a rapidly emerging field of remote sensing that seeks to map the spatial distribution of land cover proportions resulting from soft classification techniques. Many methods have been proposed, but there has been little impetus to converge these efforts or compare the results. One reason for this lack of comparison is the issue of landscape heterogeneity and the range of scaling issues it embodies. Landscape heterogeneity refers to the complex distribution of land cover types across the landscape and the spatial patterns or spatial frequency of those land cover types. Landscape heterogeneity and the spatial patterns it produces are inherently scale-dependent while SRM is fundamentally an inverse scaling challenge being applied to real landscapes. The result is that SRM techniques developed for a particular landscape or scaling factor may not translate well when applied to other landscapes with different heterogeneity or computed for a different scaling factor. This lack of transferability due to landscape heterogeneity has largely been ignored in the literature. Heterogeneity is rarely reported in SRM studies and its behaviour across resolutions rarely integrated into SRM techniques. This article discusses the importance of heterogeneity in SRM, demonstrates how heterogeneity impacts SRM results, proposes several solutions for reporting landscape heterogeneity, and discusses the difficulties associated with incorporating heterogeneity into SRM. By highlighting the interrelatedness between landscape heterogeneity and SRM, the aim is for studies to begin reporting heterogeneity to facilitate inter-comparisons and ultimately incorporate the scale-dependency of landscape heterogeneity into SRM techniques to improve accuracy and applicability. © 2015, © 2015 Taylor & Francis.","Optical resolving power; Remote sensing; Intercomparisons; Land-cover types; Landscape heterogeneities; Scale dependency; Soft classification; Spatial frequency; Spatial patterns; Super-resolution mappings; classification; land cover; landscape; mapping; remote sensing; spatial distribution; Spatial distribution","","Article","Final","","Scopus","2-s2.0-84928923325"
"","","","14th Specialist Meeting on Microwave Radiometry and Remote Sensing of the Environment, MicroRad 2016 - Proceedings","2016","14th Specialist Meeting on Microwave Radiometry and Remote Sensing of the Environment, MicroRad 2016 - Proceedings","","","","","","203","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992197954&partnerID=40&md5=ebb21d0652692796dd8b2ce13981f9e9","The proceedings contain 41 papers. The topics discussed include: status of aquarius and the salinity retrieval; microwave scanner-sounder MTVZA-GY on new Russian meteorological satellite meteor-m no. 2: modeling, calibration and measurements; SMOS payload status after six years in orbit: operational and thermal performance, calibration strategy and RFI management; faraday rotation with the SMAP radiometer; microwave imager instrument for METOP second generation: design and verification; requirements for a robust precipitation constellation; analysis and design of mm-wave detectors in SiGe SoC radiometers for spaceborne observations of solar flares; development of compact high altitude imager and sounding radiometer (CHAISR); comparison of time-frequency RFI mitigation techniques in microwave radiometry; performance analysis of a hardware implemented complex signal kurtosis radio-frequency interference detector; corruption of the TRMM microwave imager cold sky mirror due to RFI; evaluation of modeled high resolution virtual brightness temperatures compared to space-borne observations for the Neckar catchment; an assessment of SMOS version 6.20 products through triple and quadruple collocation techniques considering ASCAT, era/interim land, ISMN and SMAP soil moisture data; SMOS salinity retrievals enhancement in coastal areas by joint application of nodal sampling and corrected correlator efficiency; and sparsity-based approaches for multispectral super-resolution of tropical cyclone imagery.","","","Conference review","Final","","Scopus","2-s2.0-84992197954"
"Xuan V.N.; Hartmann K.; Weihs W.; Loffeld O.","Xuan, Vinh Nguyen (57188806690); Hartmann, Klaus (36170781100); Weihs, Wolfgang (24287276300); Loffeld, Otmar (7003978381)","57188806690; 36170781100; 24287276300; 7003978381","Combined based on minimum distance orthogonal matching pursuit method for support recovery improvement in super-resolution compressed sensing","2016","2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing, CoSeRa 2016","","","7745740","257","261","4","10.1109/CoSeRa.2016.7745740","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002938967&doi=10.1109%2fCoSeRa.2016.7745740&partnerID=40&md5=63e883b0bb915e48ee9e0b832e38a242","This paper introduces a new scenario, named combined based on minimum distance orthogonal matching pursuit (CMD-OMP) which utilizes the strength of two available recovery methods at different ranges of minimum distance. Particularly, OMP with a global optimization and non-negative constrained least square algorithm (a MATLAB function implemented as OMP with a modification step) will be studied comparatively and then interacted together to improve signal support recovery performance in super-resolution compressed sensing. © 2016 IEEE.","Compressed sensing; Constrained optimization; Global optimization; Optical resolving power; Radar; Recovery; Signal reconstruction; Sonar; Constrained least squares; Matlab functions; Minimum distance; Orthogonal matching pursuit; Recovery methods; Signal support; Super resolution; Support recoveries; Remote sensing","","Conference paper","Final","","Scopus","2-s2.0-85002938967"
"Irmak H.; Akar G.B.; Yuksel S.E.","Irmak, Hasan (57189007589); Akar, Gozde B. (55662888100); Yuksel, Seniha Esen (13406053300)","57189007589; 55662888100; 13406053300","A map-based approach to resolution enhancement of hyperspectral images","2015","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2015-June","","8075492","","","","10.1109/WHISPERS.2015.8075492","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007450710&doi=10.1109%2fWHISPERS.2015.8075492&partnerID=40&md5=7fe8c45568f576f5d158c02828b7d421","Hyperspectral imaging is widely used in many fields such as geology, medicine, meteorology, and so on. Despite the high spectral resolution, the spatial resolution of the hyperspectral sensors is severely limited. In this paper, we propose a novel maximum a posteriori (MAP)-based approach based on the joint superresolution of the abundance maps, to enhance the resolution of hyperspectral images. In the proposed approach, first, the endmembers and their abundance maps are estimated using Vertex Component Analysis (VCA) and Fully Constrained Least Squares (FCLS), respectively. Second, a high resolution (HR) abundance map is reconstructed for each low resolution (LR) abundance map using a MAP-based approach. In the MAP-formulation data, smoothness and edge preservation constraints are extended to include a unity constraint term specific to abundances. Finally, HR hyperspectral images are reconstructed using the HR abundance maps. The proposed algorithm is tested on both synthetic images and real image sequences. The experimental results and comparative analysis verify the effectiveness of the proposed algorithm. © 2015 IEEE.","Graphic methods; Hyperspectral imaging; Independent component analysis; Markov processes; Remote sensing; Spectral resolution; Spectroscopy; Energy minimization; HyperSpectral; Markov Random Fields; Spectral unmixing; Super resolution; Image enhancement","Graph Cut Energy Minimization; Hyperspectral; Markov Random Field; Spectral Unmixing; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85007450710"
"Joseph Abraham Sundar K.; Divyalakhsmi K.; Ifjaz Ahmed M.; Sivagami R.; Sangeetha V.; Vaithiyanathan V.","Joseph Abraham Sundar, K. (56783941200); Divyalakhsmi, K. (57188676994); Ifjaz Ahmed, M. (55808708400); Sivagami, R. (57188678371); Sangeetha, V. (57210551454); Vaithiyanathan, V. (35173624000)","56783941200; 57188676994; 55808708400; 57188678371; 57210551454; 35173624000","Super resolution image reconstruction using frequency spectrum","2015","Indian Journal of Science and Technology","8","35","","","","3","10.17485/ijst/2015/v8i35/IPL0991","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962231306&doi=10.17485%2fijst%2f2015%2fv8i35%2fIPL0991&partnerID=40&md5=c71d4a43103e074c16d4885cefa36131","Super resolution image reconstruction is defined as generating a high resolution image from a low resolution image or sequence of low resolution images captured from identical scene apparently a video. An algorithm for reconstructing a high resolution image from a low resolution image by altering the frequency components is discussed in this paper. In this method the high frequency components of the zoomed low resolution image is modified so as to increase the resolution of the low resolution image. The evaluation for the experiments is based on the performance measure matrix peak signal to noise ratio. The experimental results shown proves that the algorithm is highly advantageous and computationally fast compared to the other interpolation methods. The algorithm will be helpful in practical applications of medical imaging diagnosis, remote sensing and military applications.","","Filters; Frequency spectrum; Image reconstruction; Interpolation; Super resolution","Article","Final","","Scopus","2-s2.0-84962231306"
"Göhler B.; Lutzmann P.","Göhler, Benjamin (25924375900); Lutzmann, Peter (6506045630)","25924375900; 6506045630","Super-resolution depth information from a short-wave infrared laser gated-viewing system by using correlated double sampling","2017","Proceedings of SPIE - The International Society for Optical Engineering","10434","","104340M","","","","10.1117/12.2278431","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041442388&doi=10.1117%2f12.2278431&partnerID=40&md5=172c015271e7c2f15fb599374e096a3d","Primarily, a laser gated-viewing (GV) system provides range-gated 2D images without any range resolution within the range gate. By combining two GV images with slightly different gate positions, 3D information within a part of the range gate can be obtained. The depth resolution is higher (super-resolution) than the minimal gate shift step size in a tomographic sequence of the scene. For a state-of-the-art system with a typical frame rate of 20 Hz, the time difference between the two required GV images is 50 ms which may be too long in a dynamic scenario with moving objects. Therefore, we have applied this approach to the reset and signal level images of a new short-wave infrared (SWIR) GV camera whose read-out integrated circuit supports correlated double sampling (CDS) actually intended for the reduction of kTC noise (reset noise). These images are extracted from only one single laser pulse with a marginal time difference in between. The SWIR GV camera consists of 640 x 512 avalanche photodiodes based on mercury cadmium telluride with a pixel pitch of 15 μm. A Q-switched, flash lamp pumped solid-state laser with 1.57 μm wavelength (OPO), 52 mJ pulse energy after beam shaping, 7 ns pulse length and 20 Hz pulse repetition frequency is used for flash illumination. In this paper, the experimental set-up is described and the operating principle of CDS is explained. The method of deriving super-resolution depth information from a GV system by using CDS is introduced and optimized. Further, the range accuracy is estimated from measured image data. © 2017 SPIE.","Avalanche photodiodes; Cadmium; Cadmium telluride; Cameras; Electric variables measurement; Mercury (metal); Mercury compounds; Optical pumping; Optical resolving power; Photodiodes; Pumping (laser); Remote sensing; Sampling; Solid state lasers; Active imaging; Correlated double sampling; Gated viewing; Laser range; Mercury cadmium telluride; Short wave infrared; Three dimensional imaging; Infrared radiation","active imaging; avalanche photodiode; correlated double sampling; laser gated-viewing; laser range-gating; mercury cadmium telluride; short-wave infrared; three-dimensional imaging","Conference paper","Final","","Scopus","2-s2.0-85041442388"
"Seibel H.; Goldenstein S.; Rocha A.","Seibel, Hilario (57147403300); Goldenstein, Siome (6602436600); Rocha, Anderson (16643616700)","57147403300; 6602436600; 16643616700","Fast and Effective Geometric K-Nearest Neighbors Multi-frame Super-Resolution","2015","Brazilian Symposium of Computer Graphic and Image Processing","2015-October","","7314552","103","110","7","10.1109/SIBGRAPI.2015.47","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959362546&doi=10.1109%2fSIBGRAPI.2015.47&partnerID=40&md5=565822adf6ec02dc72093b40b3fc81a9","Multi-frame super-resolution is possible when there is motion and non-redundant information from a sequence of low-resolution input images. Remote sensors, surveillance videos and modern mobile phones are examples of devices able to easily gather multiple images of a same scene. However, combining a large number of frames into a higher resolution image may not be computationally feasible by complex super-resolution techniques. We discuss herein a set of simple and effective high-performance algorithms to fastly super-resolve several low-resolution images in an always-on low-power environment, with possible applications in mobile computing, forensics, and biometrics. The algorithms rely on geometric k-nearest neighbors to decide which information to consider in each high-resolution pixel, have a low memory footprint and run in linear time as we increase the number of low-resolution input images. Finally, we suggest a minimum number of input images for multi-frame super-resolution, considering that we expect a good response as fast as possible. © 2015 IEEE.","Geometry; Mobile devices; Motion analysis; Motion compensation; Nearest neighbor search; Remote sensing; Security systems; burst; geometric k-NN; High performance algorithms; Higher resolution images; K-nearest neighbors; Low resolution images; Multi-frame; Super resolution; Optical resolving power","burst; geometric k-NN; mobile devices; multi-frame; super-resolution","Conference paper","Final","","Scopus","2-s2.0-84959362546"
"Heltin Genitha C.; Indhumathi M.","Heltin Genitha, C. (56419984000); Indhumathi, M. (57191610328)","56419984000; 57191610328","Super resolution mapping of satellite images to estimate the capacity of reservoirs around Chennai City","2016","37th Asian Conference on Remote Sensing, ACRS 2016","1","","","610","618","8","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018249287&partnerID=40&md5=d4c53cf52e742e3e7a0f519f5eeaa188","Reservoir capacity estimation is often carried out by field surveys, which is a time consuming and tedious process that cannot be performed periodically. To overcome this issue, satellite images are used, where the area estimation is made by the conventional per-pixel classification algorithms. These techniques, however, result in inaccurate estimation of reservoir capacity because the per-pixel classification techniques assume one class per pixel and classify the remotely sensed images. This paper presents a super resolution mapping technique, which predicts and maps the location of several land cover classes within the pixels of the images of Poondi and Chembarambakkam reservoirs of Chennai city. The Hopfield Neural Network algorithm was developed and applied Landsat OLI image of the reservoirs. The fraction images of the reservoir sites, obtained by sub-pixel classification, were subjected to super resolution mapping to accurately estimate the water-spread area and the capacity of the reservoirs. Thus, the pixels with mixed land cover classes along the periphery of the reservoirs were accurately classified in terms of the abundance of water. The water-spread area estimated using super resolution mapping approach can be used as an input in the volume estimation equation to estimate the volume at different water levels of the reservoirs. Super-resolution Mapping approach gives minimum error when compared to sub-pixel approach which inturn gives less erroneous result when comparing per-pixel approach.","Classification (of information); Hopfield neural networks; Optical resolving power; Pixels; Remote sensing; Reservoirs (water); Satellites; Water levels; Neural network algorithm; Pixel-classification techniques; Remotely sensed images; Reservoir capacity; Satellite images; Spread areas; Sub-pixel classification; Super-resolution mappings; Mapping","Classification; Hopfield Neural Network; Reservoir capacity; Satellite image; Super resolution mapping; Water-spread area","Conference paper","Final","","Scopus","2-s2.0-85018249287"
"Lanaras C.; Baltsavias E.; Schindler K.","Lanaras, Charis (56568192000); Baltsavias, Emmanuel (6603939930); Schindler, Konrad (8557497200)","56568192000; 6603939930; 8557497200","Hyperspectral image fusion","2015","ACRS 2015 - 36th Asian Conference on Remote Sensing: Fostering Resilient Growth in Asia, Proceedings","","","","","","","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964034558&partnerID=40&md5=2129ea1b7085e9e51b54d7fe03fa95cb","In this research, we jointly process high spectral and high geometric resolution images, exploiting their synergies, with aims to (a) generate a fused image of high spectral and geometric resolution, and (b) to improve spectral unmixing level of hyperspectral images at subpixel regarding the estimation of endmembers and fractional abundances. The potential of this methodological improvement lies in a more accurate and detailed semantic interpretation of objects and their properties in hyperspectral and multispectral images, with applications often in environmental mapping, monitoring and change detection. To incorporate the case of real data the spectral response of the one sensor with respect to the other must be known. To estimate the relative spectral response the two images must be co-registered and the point spread function must be taken into account. In this paper, we degrade the images spectrally and geometrically so that they have the same dimensions and we solve a least-squares problem with two constraints. The results using synthetic data confirm this approach, while with real data results are in principle promising, but in some cases the reconstructed spectral response is noisy.","Independent component analysis; Optical transfer function; Remote sensing; Semantics; Spectroscopy; Environmental mapping; HyperSpectral; Hyperspectral image fusions; Least squares problems; Relative spectral response; Semantic interpretation; Spectral unmixing; Super resolution; Image fusion","Hyperspectral; Image fusion; Relative spectral response; Spectral unmixing; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-84964034558"
"","","","2016 9th IAPR Workshop on Pattern Recognition in Remote Sensing, PRRS 2016","2017","2016 9th IAPR Workshop on Pattern Recognition in Remote Sensing, PRRS 2016","","","","","","82","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017011087&partnerID=40&md5=510c5451499a6db52db070ce560d8e32","The proceedings contain 14 papers. The topics discussed include: improving semantic orthophotos by a fast method based on harmonic inpainting; segmentation of 3D outdoor scenes using hierarchical clustering structure and perceptual grouping laws; river sediment yield classification using remote sensing imagery; reflectance-based 3D shape refinement of surfaces with spatially varying BRDF properties; 4d change detection based on persistent scatterer interferometry; robust alignment for UAV images based on adaptive adjustment; a comprehensive study on object proposals methods for vehicle detection in aerial images; deep learning for ocean remote sensing: an application of convolutional neural networks for super-resolution on satellite-derived SST data; evaluating imaging quality of the Offner hyperspectrometer; fast extraction of dominant planes in MLS-data of urban areas; discriminative archetypal self-taught learning for multispectral landcover classification; semisupervised classification of hyperspectral remote sensing images with spatial majority voting; towards vegetation species discrimination by using data-driven descriptors; and point cloud registration by combining shape and intensity contexts.","","","Conference review","Final","","Scopus","2-s2.0-85017011087"
"Garzelli A.","Garzelli, Andrea (7004594292)","7004594292","A Review of Image Fusion Algorithms Based on the Super-Resolution Paradigm","2016","Remote Sensing","8","10","797","1","","","10.3390/rs8100797","68","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990041955&doi=10.3390%2frs8100797&partnerID=40&md5=bec41ff3d94b5282b236dcb5b1b702ab","A critical analysis of remote sensing image fusion methods based on the super-resolution (SR) paradigm is presented in this paper. Very recent algorithms have been selected among the pioneering studies adopting a new methodology and the most promising solutions. After introducing the concept of super-resolution and modeling the approach as a constrained optimization problem, different SR solutions for spatio-temporal fusion and pan-sharpening are reviewed and critically discussed. Concerning pan-sharpening, the well-known, simple, yet effective, proportional additive wavelet in the luminance component (AWLP) is adopted as a benchmark to assess the performance of the new SR-based pan-sharpening methods. The widespread quality indexes computed at degraded resolution, with the original multispectral image used as the reference, i.e., SAM (Spectral Angle Mapper) and ERGAS (Erreur Relative Globale Adimensionnelle de Synthèse), are finally presented. Considering these results, sparse representation and Bayesian approaches seem far from being mature to be adopted in operational pan-sharpening scenarios. © 2016 by the author; licensee MDPI, Basel, Switzerland.","Bayesian networks; Benchmarking; Constrained optimization; Image reconstruction; Optical resolving power; Optimization; Remote sensing; Constrained optimi-zation problems; Image fusion algorithms; Pan-sharpening; Remote sensing images; Sparse representation; Spatio-temporal fusions; Spectral angle mappers; Super resolution; Image fusion","Image fusion; Pan-sharpening; Sparse representations; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84990041955"
"Liebel L.; Körner M.","Liebel, L. (56938680000); Körner, M. (57190168095)","56938680000; 57190168095","Single-image super resolution for multispectral remote sensing data using convolutional neural networks","2016","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","41","","","883","890","7","10.5194/isprsarchives-XLI-B3-883-2016","91","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978081674&doi=10.5194%2fisprsarchives-XLI-B3-883-2016&partnerID=40&md5=dadf2c4296fb6012db985cae90e14967","In optical remote sensing, spatial resolution of images is crucial for numerous applications. Space-borne systems are most likely to be affected by a lack of spatial resolution, due to their natural disadvantage of a large distance between the sensor and the sensed object. Thus, methods for single-image super resolution are desirable to exceed the limits of the sensor. Apart from assisting visual inspection of datasets, post-processing operations-e.g., segmentation or feature extraction-can benefit from detailed and distinguishable structures. In this paper, we show that recently introduced state-of-The-Art approaches for single-image super resolution of conventional photographs, making use of deep learning techniques, such as convolutional neural networks (CNN), can successfully be applied to remote sensing data. With a huge amount of training data available, end-To-end learning is reasonably easy to apply and can achieve results unattainable using conventional handcrafted algorithms. We trained our CNN on a specifically designed, domain-specific dataset, in order to take into account the special characteristics of multispectral remote sensing data. This dataset consists of publicly available SENTINEL-2 images featuring 13 spectral bands, a ground resolution of up to 10m, and a high radiometric resolution and thus satisfying our requirements in terms of quality and quantity. In experiments, we obtained results superior compared to competing approaches trained on generic image sets, which failed to reasonably scale satellite images with a high radiometric resolution, as well as conventional interpolation methods.","Convolution; Feature extraction; Image resolution; Neural networks; Optical resolving power; Radiometry; Space optics; Convolutional neural network; Deep learning; Multispectral remote sensing; Optical remote sensing; Radiometric resolution; Sentinel-2; Single images; State-of-the-art approach; Remote sensing","Convolutional Neural Networks; Deep Learning; Sentinel-2; Single-Image Super Resolution","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-84978081674"
"Wang S.; Song Z.-Q.; Zhang L.; Li X.; Wang Z.","Wang, Senhua (7410346732); Song, Zhi-Qiang (56166399200); Zhang, Li (55235351500); Li, Xiangzhong (55560350200); Wang, Zhaoxia (57212120242)","7410346732; 56166399200; 55235351500; 55560350200; 57212120242","The study of super-resolution reconstruction based on visual attention and wavelet analysis","2016","2015 12th International Computer Conference on Wavelet Active Media Technology and Information Processing, ICCWAMTIP 2015","","","7493995","295","298","3","10.1109/ICCWAMTIP.2015.7493995","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978878067&doi=10.1109%2fICCWAMTIP.2015.7493995&partnerID=40&md5=074475235090a898bb8b9774577f8a5c","The super-resolution reconstruction is an important method for improving the image quality, which possesses widely application in the fields of video monitoring, remote sensing imaging, medical image processing, etc. In this paper, firstly, the salient edges and the boundaries of salient objects were obtained by using the salient characteristics of visual attention based on computer visual model and wavelet analysis; secondly, the super-resolution image was synthetically acquired by adopting the bilinear interpolation in the contour's internal region and the adaptive interpolation in the boundaries' external region respectively. The simulation results showed that the visual effect of the reconstructed model was more according with human visual characteristics. In addition, the subjective judgment and objective evaluation is better than traditional reconstruction algorithm. The algorithm in this paper achieves good effects and reaches good feasibility and validity. © 2015 IEEE.","Behavioral research; Image processing; Information science; Interpolation; Medical imaging; Optical resolving power; Quality control; Remote sensing; Video signal processing; Wavelet analysis; Adaptive interpolation; Bilinear interpolation; Human visual characteristics; Reconstruction algorithms; Salient Edges; Super resolution; Super resolution reconstruction; Visual Attention; Medical image processing","Adaptive Interpolation; Salient Edges; Super-Resolution; Visual Attention; Wavelet Analysis","Conference paper","Final","","Scopus","2-s2.0-84978878067"
"Mayossa P.C.K.; Gadal S.","Mayossa, Prune Christobelle Komba (57191524165); Gadal, Sébastien (6504148942)","57191524165; 6504148942","Monitoring spatial accuracy of oil palm cultivation mapping in southern Cameroon from Landsat series images","2016","Proceedings of Spatial Accuracy 2016","","","","358","365","7","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991311739&partnerID=40&md5=af73a99d1184ca6044346770c05b71d0","Studying and mapping palm grove evolution allow understanding the impact related to its cultivation. Our study aims to map industrial palm grove using Landsat series images and measures the accuracy of the produced maps. It was carried out in SOCAPALM industrial plantation, located in southern of Cameroon. For the mapping and assessment of accuracy, perpixel classification and confusion matrix method were used, respectively. We obtained high correlated maps (Kappa =0.92 in 2001 vs 0.86 in 2015). However, some confusions were observed between vegetation and oil palm classes for the two periods, affecting the maps accuracy. These confusions are caused by the presence of mixed pixels resulting from the spatial and spectral characteristics of palm groves, the method used to map and validate the map, and uncertainty related to dada. To increase the accuracy, we suggest (1) to use another mapping method such as super-resolution mapping, (2) develop a classification system of cartographic products.","Mapping; Monitoring; Remote sensing; Classification system; Confusion matrices; Elaeis Guineensis.Jaq; Industrial plantations; Oil palm; Spatial accuracy; Spectral characteristics; Super-resolution mappings; Palm oil","Elaeis Guineensis.Jaq; Monitoring; Oil palm; Remote sensing; Spatial accuracy","Conference paper","Final","","Scopus","2-s2.0-84991311739"
"Zhang Y.; Atkinson P.M.; Li X.; Ling F.; Wang Q.; Du Y.","Zhang, Yihang (55658053900); Atkinson, Peter M. (7201906181); Li, Xiaodong (55878368700); Ling, Feng (56278268300); Wang, Qunming (55649569623); Du, Yun (56420121700)","55658053900; 7201906181; 55878368700; 56278268300; 55649569623; 56420121700","Learning-Based Spatial-Temporal Superresolution Mapping of Forest Cover with MODIS Images","2017","IEEE Transactions on Geoscience and Remote Sensing","55","1","7586093","600","614","14","10.1109/TGRS.2016.2613140","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991030117&doi=10.1109%2fTGRS.2016.2613140&partnerID=40&md5=335af0d1e5a6f0cd64a8ac0900d35051","Forest mapping from satellite sensor imagery provides important information for the timely monitoring of forest growth and deforestation, bioenergy potential assessment, and modeling of carbon flux, among others. Due to the daily global revisit rate and wide swath width, MODerate-resolution Imaging Spectroradiometer (MODIS) images are used commonly for satellite-derived forest mapping at both regional and global scales. However, the spatial resolution of MODIS images is too coarse to observe fine spatial variation in forest cover. The last few decades have seen the production of several fine-spatial-resolution satellite-derived global forest cover maps, such as Hansen's global tree canopy cover map of 2000, which includes abundant spectral, temporal, and spatial prior information about forest cover at a fine spatial resolution. In this paper, a novel learning-based spatial-temporal superresolution mapping approach is proposed to integrate both current MODIS images and prior maps of Hansen's tree canopy cover, to map present forest cover with a fine spatial resolution. The novel approach is composed of three main stages: 1) automatic generation of 240-m forest proportion images from both 240-and 480-m MODIS images using a nonlinear learning-based spectral unmixing method; 2) downscaling the 240-m forest proportion images to 30 m to predict the class possibilities at the subpixel scale using a temporal-example learning-based downscaling method; and 3) final production of the fine-spatial-resolution forest map by solving a regularization-based optimization problem. The novel approach produced more accurate fine-spatial-resolution forest cover maps in terms of both visual and quantitative evaluation than traditional pixel-based classification and the latest subpixel based superresolution mapping methods. The results show the great efficiency and potential of the novel approach for producing fine-spatial-resolution forest maps from MODIS images. © 2016 IEEE.","Deforestation; Image resolution; Optical resolving power; Photomapping; Pixels; Radiometers; Remote sensing; Spectrometers; Down-scaling; Moderate resolution imaging spectroradiometer; Spatial temporals; Spectral unmixing; Super-resolution mappings; Tree cover; carbon flux; downscaling; forest cover; forest ecosystem; image classification; image resolution; mapping method; MODIS; pixel; remote sensing; satellite imagery; spatial resolution; spatiotemporal analysis; spectral resolution; vegetation cover; Satellite imagery","Downscaling; forest map; MODerate-resolution Imaging Spectroradiometer (MODIS); nonlinear spectral unmixing; remote sensing; spatial temporal; superresolution mapping; Tree cover","Article","Final","","Scopus","2-s2.0-84991030117"
"Zhang G.","Zhang, Guo (35774842600)","35774842600","Satellite video processing and applications","2016","Yingyong Kexue Xuebao/Journal of Applied Sciences","34","4","","361","370","9","10.3969/j.issn.0255-8297.2016.04.001","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980028153&doi=10.3969%2fj.issn.0255-8297.2016.04.001&partnerID=40&md5=c11ea2ed5998f367948818f287a089a5","Video satellites acquire continuous images of targets in a certain time period to dynamically monitor areas of interest in real time. They have become a hot spot in remote sensing satellite development in recent years. In this paper, a survey is given on the development of video satellites and application perspectives of satellite video data. Major challenges facing satellite video are analyzed, focusing on geometric calibration, radiometric calibration, video stabilization, super resolution reconstruction, moving target detection and tracking, 3D reconstruction, and the development trend. Major application fields of satellite video and the future perspectives are discussed. © 2016, Editorial Office of Journal of Applied Sciences. All right reserved.","","3D reconstruction; Calibration; Moving target detection; Satellite video; Stabilization","Article","Final","","Scopus","2-s2.0-84980028153"
"Su Y.-F.","Su, Yuan-Fong (23975067600)","23975067600","Spatial continuity and self-similarity in super-resolution mapping: Self-similar pixel swapping","2016","Remote Sensing Letters","7","4","","338","347","9","10.1080/2150704X.2015.1137988","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964430209&doi=10.1080%2f2150704X.2015.1137988&partnerID=40&md5=9cb48663e707570f42dc032b3d7f73d6","Self-similarity of fractal geometry refers to that a part of an object is similar to the whole. This scale-invariant feature has a certain role to play in super-resolution mapping which is a mapping technique across scale aiming at enhancing spatial resolution of remote-sensing imagery. Unlike other super-resolution mapping methods depending solely on spatial continuity, a self-similar pixel swapping (SSPS) method combining spatial continuity and self-similarity of fractal geometry into original pixel swapping (PS) algorithm is presented here. A self-similar weight function defined from the composition information at pixel scale within a predetermined window is added to the calculation of attractiveness in the standard PS method. The self-similar weight function guides the subpixels within a pixel to arrange spatially similar to the appearance of the composition information at pixel scale. Evaluating with synthetic images and satellite image, the performance of the SSPS is particularly obvious in reproducing objects with sharp corners, linear features and adjacent small objects. © 2016 Taylor & Francis.","Fractals; Mapping; Optical resolving power; Remote sensing; Scales (weighing instruments); Mapping techniques; Remote sensing imagery; Scale invariant features; Self-similarities; Spatial continuity; Spatial resolution; Super-resolution mappings; Weight functions; Pixels","","Article","Final","","Scopus","2-s2.0-84964430209"
"Zhao Y.; Yi C.; Yang J.; Chan J.C.-W.","Zhao, Yongqiang (35365726800); Yi, Chen (56421324300); Yang, Jingxiang (55964111200); Chan, Jonathan Cheung-Wai (8840429000)","35365726800; 56421324300; 55964111200; 8840429000","Spectral super-resolution based on matrix factorization and spectral dictionary","2016","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","0","","8071766","","","","10.1109/WHISPERS.2016.8071766","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037543545&doi=10.1109%2fWHISPERS.2016.8071766&partnerID=40&md5=b912869f8be409390ca498ec0f118240","Spectral information in hyperspectral imagery (HSI) directly acquired by sensors, commonly with surplus bands and redundant information, takes high memory and transmission costs, resulting in reduced spatial resolution and aggravated spectral mixture. Therefore, the desired high spectral resolution HSI can be obtained via spectral super-resolution after acquiring original HSI with lower spectral resolution but relatively higher spatial resolution. In this paper, we proposed a spectral super-resolution method based on spectral matrix factorization and dictionary learning. High and low spectral resolution HSIs are assumed to have the same spatial resolution and share the same spectral signatures. So abundances of low spectral resolution imagery can provide high spatial information, while its endmembers can supply accurate spectral characteristics. Then several high spectral resolution HSIs in 2-D forms are utilized to train a spectral dictionary which contains both high spatial resolution information and high spectral resolution information. Finally, the desired spectral enhancement results are achieved through the use of spatial fidelity constraint. Experiments on Sandigo dataset indicated the superiority of our proposed method. © 2016 IEEE.","Factorization; Image processing; Image resolution; Matrix algebra; Remote sensing; Spectroscopy; Dictionary learning; High spatial resolution; High spectral resolution; Hyper-spectral imageries; Matrix factorizations; Spectral characteristics; Super resolution; Superresolution methods; Spectral resolution","Dictionary learning; Hyperspectral imagery; Matrix factorization; Spectral super-resolution","Conference paper","Final","","Scopus","2-s2.0-85037543545"
"Zhu F.-Z.; Wang X.-F.; Ding Q.; He H.-C.","Zhu, Fu-Zhen (12780819500); Wang, Xiao-Fei (36667500400); Ding, Qun (37043420200); He, Hong-Chang (56512861900)","12780819500; 36667500400; 37043420200; 56512861900","Super-resolution reconstruction of remote images based on three level training BP neural network","2015","Guangxue Jingmi Gongcheng/Optics and Precision Engineering","23","","","723","730","7","10.3788/OPE.20152313.0723","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950312324&doi=10.3788%2fOPE.20152313.0723&partnerID=40&md5=600a69b5b9c12ef5982b37c97e29bba2","To further improve the effect of the super-resolution reconstruction (SRR) of remote sensing images and reduce its time-consuming, a three level training BP Neural Network (BPNN) was established. The research was focused on the acquisition of training samples, selections of input-output training samples, and the design of BPNN structure and training algorithm. A remote sensing image degradation model was set up. Then, training sample images were got by undersampled and subpixel-shifted method. The input-output training sample images were selected by variance comparison. Finally, three groups remote sensing images with different super-resolution mapping modes were used as the input-output training samples for the same BPNN. The net was continuously trained and learned three cycles, and image size and spatial resolution were improved three times. Experimental results indicate that the three level training BPNN for the SRR of remote sensing image can obtain better SRR effect and higher spatial resolution in the process of fitting remote sensing image SRR mapping, and the Peak Signal to Noise Ratio (PSNR) is improved about 6 dB than that of other ordinary super-resolution algorithm. For preserving more image details and reducing reconstructing time, it is more suitable for practical applications of remote sensing images. © 2015, Chinese Academy of Sciences. All right reserved.","Image processing; Image resolution; Mapping; Neural networks; Optical resolving power; Remote sensing; Sampling; Signal to noise ratio; BP neural networks; Input-output training; Peak signal to noise ratio; Remote sensing images; Super resolution; Super resolution algorithms; Super resolution reconstruction; Super-resolution mappings; Image reconstruction","Remote sensing image, image reconstruction; Super-resolution; Three level training BP neural network","Article","Final","","Scopus","2-s2.0-84950312324"
"Lanaras C.; Baltsavias E.; Schindler K.","Lanaras, C. (56568192000); Baltsavias, E. (6603939930); Schindler, K. (8557497200)","56568192000; 6603939930; 8557497200","Advances in hyperspectral and multispectral image fusion and spectral unmixing","2015","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","40","3W3","","451","458","7","10.5194/isprsarchives-XL-3-W3-451-2015","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959344585&doi=10.5194%2fisprsarchives-XL-3-W3-451-2015&partnerID=40&md5=e85e4011f1abbfe10386d7d661cde998","In this work, we jointly process high spectral and high geometric resolution images and exploit their synergies to (a) generate a fused image of high spectral and geometric resolution; and (b) improve (linear) spectral unmixing of hyperspectral endmembers at subpixel level w.r.t. the pixel size of the hyperspectral image. We assume that the two images are radiometrically corrected and geometrically co-registered. The scientific contributions of this work are (a) a simultaneous approach to image fusion and hyperspectral unmixing, (b) enforcing several physically plausible constraints during unmixing that are all well-known, but typically not used in combination, and (c) the use of efficient, state-of-the-art mathematical optimization tools to implement the processing. The results of our joint fusion and unmixing has the potential to enable more accurate and detailed semantic interpretation of objects and their properties in hyperspectral and multispectral images, with applications in environmental mapping, monitoring and change detection. In our experiments, the proposed method always improves the fusion compared to competing methods, reducing RMSE between 4% and 53%.","Image processing; Information science; Optimization; Photogrammetry; Pixels; Remote sensing; Semantics; Spectroscopy; Endmembers; HyperSpectral; Processing technique; Spectral unmixing; Super resolution; Image fusion","Endmembers; Hyperspectral; Image fusion; Processing techniques; Spectral unmixing; Super-resolution","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84959344585"
"Cao J.; Li C.; Jin J.; Ji H.; Zhang X.; Wang J.","Cao, Jiahao (57192578002); Li, Chunlai (8368630100); Jin, Jian (56415479300); Ji, Hongzhen (56564619000); Zhang, Xudong (57192605003); Wang, Jianyu (56734123100)","57192578002; 8368630100; 56415479300; 56564619000; 57192605003; 56734123100","Enhancing spatial resolution of infrared imagery using overlap of sequence images","2016","Proceedings of SPIE - The International Society for Optical Engineering","9880","","98802B","","","","10.1117/12.2228024","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006850822&doi=10.1117%2f12.2228024&partnerID=40&md5=db207e537d5ce3572d32a6ca0dc99fd7","The high-resolution thermal infrared image, by which the information of a scene can be described in details, is extensively used in many fields including computer vision process, medicine, and remote sensing, etc. This paper introduces a super-resolution reconstruction algorithm in combination of phase related motion estimating algorithm and iterative back-projecting algorithm. Continuous frames of the thermal infrared image aerially shot are extracted, the subpixel displacement of each frame of image relative to the reference image is estimated with the phase related motion estimating algorithm, and then the subpixel displacement data acquired is combined with the iterative back-projecting algorithm to actualize the super-resolution reconstruction of thermal infrared image aerially shot. The thermal infrared images were aerially shot above Zhoushan. The experimental result has proven the image spatial resolution can be effectively improved by this algorithm. © 2016 SPIE.","Computer vision; Image reconstruction; Image resolution; Infrared imaging; Infrared radiation; Iterative methods; Optical resolving power; Pixels; Remote sensing; Computer vision process; Continuous frames; Image registering; Image spatial resolution; Spatial resolution; Sub-pixel displacements; Super resolution reconstruction; Thermal infrared images; Image processing","Image registering; Iterative back-projecting algorithm; Spatial resolution; Thermal infrared image","Conference paper","Final","","Scopus","2-s2.0-85006850822"
"Luo Q.; Shao X.; Peng L.; Wang Y.; Wang L.","Luo, Qiuhua (56333495800); Shao, Xiaopeng (7202920421); Peng, Ligen (56333126800); Wang, Yi (57204548320); Wang, Lin (56769098400)","56333495800; 7202920421; 56333126800; 57204548320; 56769098400","Super-resolution imaging in remote sensing","2015","Proceedings of SPIE - The International Society for Optical Engineering","9501","","950108","","","","10.1117/12.2176172","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938866872&doi=10.1117%2f12.2176172&partnerID=40&md5=aff7ee84d3a976b0b51d24347ddf94e5","A new effective image super resolution (SR) algorithm which is a hybrid of multiple frame Variational Bayesian (VB) reconstruction and single frame Dictionary Learning (DL) reconstruction method is developed to reconstruct a high resolution (HR) satellite image in this article. Firstly, by employing a variational Bayesian analysis, the unknown high resolution image, the acquisition process, the motion parameters and the unknown model parameters are built together in a single mathematical model with a Bayesian formula, and then the distributions of all unknowns are jointly estimated. Without any parameter adjustment, an HR image is adaptively reconstructed from multiple frame low resolution (LR) images. Secondly, by taking the above HR image as input, a higher resolution image can be rebuilt utilizing the statistical correlation between the HR and LR images which is obtained via the DL method. The VB method effectively uses non-redundant information between LR images to recover HR satellite images. Benefit from the dictionary training of magnanimity image, the DL algorithm is able to provide more high-frequency image details, which means this hybrid of VB and DL method combines the above advantages. The experiments show that this proposed algorithm can effectively increase the image resolution of remote sensing images by 0.5times at least comparing with low resolution image. © 2015 SPIE.","Algorithms; Data compression; Data handling; Image reconstruction; Image resolution; Optical resolving power; Remote sensing; Satellites; Target tracking; Dictionary learning; Multiple-frame; Single frames; Super resolution reconstruction; Variational bayesian; Image processing","Dictionary Learning (DL); multiple frame; single frame; Super Resolution Reconstruction; Variational Bayesian (VB)","Conference paper","Final","","Scopus","2-s2.0-84938866872"
"Sun J.; Tan Z.; Lv Q.; Pei L.","Sun, Jianying (56171742300); Tan, Zheng (57188729245); Lv, Qunbo (55513035000); Pei, Linlin (55607401400)","56171742300; 57188729245; 55513035000; 55607401400","Multispectral image enhancement processing for microsat-borne imager","2017","Proceedings of SPIE - The International Society for Optical Engineering","10427","","2280556","","","","10.1117/12.2280556","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041054496&doi=10.1117%2f12.2280556&partnerID=40&md5=490a49c22aa561c8a6e63dee4e398651","With the rapid development of remote sensing imaging technology, the micro satellite, one kind of tiny spacecraft, appears during the past few years. A good many studies contribute to dwarfing satellites for imaging purpose. Generally speaking, micro satellites weigh less than 100 kilograms, even less than 50 kilograms, which are slightly larger or smaller than the common miniature refrigerators. However, the optical system design is hard to be perfect due to the satellite room and weight limitation. In most cases, the unprocessed data captured by the imager on the microsatellite cannot meet the application need. Spatial resolution is the key problem. As for remote sensing applications, the higher spatial resolution of images we gain, the wider fields we can apply them. Consequently, how to utilize super resolution (SR) and image fusion to enhance the quality of imagery deserves studying. Our team, the Key Laboratory of Computational Optical Imaging Technology, Academy Opto-Electronics, is devoted to designing high-performance microsat-borne imagers and high-efficiency image processing algorithms. This paper addresses a multispectral image enhancement framework for space-borne imagery, jointing the pan-sharpening and super resolution techniques to deal with the spatial resolution shortcoming of microsatellites. We test the remote sensing images acquired by CX6-02 satellite and give the SR performance. The experiments illustrate the proposed approach provides high-quality images. © 2017 SPIE.","Computational efficiency; DNA sequences; Image fusion; Image processing; Image resolution; Imaging techniques; Optical data processing; Optical resolving power; Optical systems; Remote sensing; Satellites; Signal processing; Space optics; Enhancement framework; Image processing algorithm; Micro satellite; Optical imaging technology; Pan-sharpening; Remote sensing applications; Remote sensing imaging; Super resolution; Image enhancement","Image enhancement; Microsatellite-borne imager; Pan-sharpening; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85041054496"
"Tang Y.; Atkinson P.M.; Zhang J.","Tang, Yunwei (35197211600); Atkinson, Peter M. (7201906181); Zhang, Jingxiong (55943804700)","35197211600; 7201906181; 55943804700","Downscaling remotely sensed imagery using area-to-point cokriging and multiple-point geostatistical simulation","2015","ISPRS Journal of Photogrammetry and Remote Sensing","101","","","174","185","11","10.1016/j.isprsjprs.2014.12.016","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920916706&doi=10.1016%2fj.isprsjprs.2014.12.016&partnerID=40&md5=05b9fcd8ecc6aaa22a821511c956969c","A cross-scale data integration method was developed and tested based on the theory of geostatistics and multiple-point geostatistics (MPG). The goal was to downscale remotely sensed images while retaining spatial structure by integrating images at different spatial resolutions. During the process of downscaling, a rich spatial correlation model in the form of a training image was incorporated to facilitate reproduction of similar local patterns in the simulated images. Area-to-point cokriging (ATPCK) was used as locally varying mean (LVM) (i.e., soft data) to deal with the change of support problem (COSP) for cross-scale integration, which MPG cannot achieve alone. Several pairs of spectral bands of remotely sensed images were tested for integration within different cross-scale case studies. The experiment shows that MPG can restore the spatial structure of the image at a fine spatial resolution given the training image and conditioning data. The super-resolution image can be predicted using the proposed method, which cannot be realised using most data integration methods. The results show that ATPCK-MPG approach can achieve greater accuracy than methods which do not account for the change of support issue. © 2014 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).","Optical resolving power; Remote sensing; Co-Kriging; Conditional simulations; Down-scaling; Multiple-point geostatistics; Super resolution; accuracy assessment; downscaling; geostatistics; kriging; remote sensing; satellite imagery; spatial resolution; Data integration","Area-to-point cokriging; Conditional simulation; Data integration; Downscaling; Multiple-point geostatistics; Super-resolution","Article","Final","","Scopus","2-s2.0-84920916706"
"Fan C.; Wu C.; Li G.; Ma J.","Fan, Chong (36786139600); Wu, Chaoyun (56995406100); Li, Grand (57193322169); Ma, Jun (57193322429)","36786139600; 56995406100; 57193322169; 57193322429","Projections onto convex sets super-resolution reconstruction based on point spread function estimation of low-resolution remote sensing images","2017","Sensors (Switzerland)","17","2","362","","","","10.3390/s17020362","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012970219&doi=10.3390%2fs17020362&partnerID=40&md5=c8f022bb0f6b91164432f5cfe0daa971","To solve the problem on inaccuracy when estimating the point spread function (PSF) of the ideal original image in traditional projection onto convex set (POCS) super-resolution (SR) reconstruction, this paper presents an improved POCS SR algorithm based on PSF estimation of low-resolution (LR) remote sensing images. The proposed algorithm can improve the spatial resolution of the image and benefit agricultural crop visual interpolation. The PSF of the high-resolution (HR) image is unknown in reality. Therefore, analysis of the relationship between the PSF of the HR image and the PSF of the LR image is important to estimate the PSF of the HR image by using multiple LR images. In this study, the linear relationship between the PSFs of the HR and LR images can be proven. In addition, the novel slant knife-edge method is employed, which can improve the accuracy of the PSF estimation of LR images. Finally, the proposed method is applied to reconstruct airborne digital sensor 40 (ADS40) three-line array images and the overlapped areas of two adjacent GF-2 images by embedding the estimated PSF of the HR image to the original POCS SR algorithm. Experimental results show that the proposed method yields higher quality of reconstructed images than that produced by the blind SR method and the bicubic interpolation method. © 2017 by the authors; licensee MDPI, Basel, Switzerland.","Crops; Image processing; Interpolation; Optical resolving power; Optical transfer function; Remote sensing; Set theory; Bicubic interpolation; High resolution image; Projection onto convex sets; Projections onto convex sets; Quality of reconstructed images; Remote sensing images; Super resolution; Super resolution reconstruction; Image reconstruction","Point spread function (PSF); Projections onto convex sets (POCS); Remote sensing; Super resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85012970219"
"","","","18th International Conference on Intelligent Data Engineering and Automated Learning, IDEAL 2017","2017","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10585 LNCS","","","","","606","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034239653&partnerID=40&md5=66f82d426703fb4e7808a0f67e9f2c5f","The proceedings contain 65 papers. The special focus in this conference is on Intelligent Data Engineering and Automated Learning. The topics include: Cross-media retrieval of tourism big data based on deep features and topic semantics; information retrieval with implicitly temporal queries; on the relations of theoretical foundations of different causal inference algorithms; SibStCNN and TBCNN + kNN-TED: New models over tree structures for source code classification; a community detection algorithm based on local double rings and fireworks algorithm; cost sensitive matrix factorization for face recognition; Research of dengue fever prediction in san juan, puerto rico based on a KNN regression model; identification of nonlinear system based on complex-valued flexible neural network; research on the method of splitting large class diagram based on multilevel partitioning; dynamic community detection algorithm based on automatic parameter adjustment; ford motorcar identification from single-camera side-view image based on convolutional neural network; predicting personality traits of users in social networks; face anti-spoofing algorithm based on gray level co-occurrence matrix and dual tree complex wavelet transform; high-accuracy deep convolution neural network for image super-resolution; an improved density peak clustering algorithm; consensus-based parallel algorithm for robust convex optimization with scenario approach in colored network; heterogeneous context-aware recommendation algorithm with semi-supervised tensor factorization; object detection with proposals in high-resolution optical remote sensing images; towards spectral-texture approach to hyperspectral image analysis for plant classification; face attributes retrieval by multi-label contractive hashing; an ant colony random walk algorithm for overlapping community detection; trajectory similarity-based prediction with information fusion for remaining useful life.","","","Conference review","Final","","Scopus","2-s2.0-85034239653"
"Mareboyana M.; Le Moigne J.; Bennett J.","Mareboyana, Manohar (7007068388); Le Moigne, Jacqueline (55664867700); Bennett, Jerome (57191538497)","7007068388; 55664867700; 57191538497","High resolution image reconstruction from projection of low resolution images differing in subpixel shifts","2016","Proceedings of SPIE - The International Society for Optical Engineering","9870","","98700F","","","","10.1117/12.2223936","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991497507&doi=10.1117%2f12.2223936&partnerID=40&md5=cfdc3d78e6a95c3bbea154d444d353d7","In this paper, we demonstrate simple algorithms that project low resolution (LR) images differing in subpixel shifts on a high resolution (HR) also called super resolution (SR) grid. The algorithms are very effective in accuracy as well as time efficiency. A number of spatial interpolation techniques using nearest neighbor, inverse-distance weighted averages, Radial Basis Functions (RBF) etc. are used in projection. For best accuracy of reconstructing SR image by a factor of two requires four LR images differing in four independent subpixel shifts. The algorithm has two steps: i) registration of low resolution images and (ii) shifting the low resolution images to align with reference image and projecting them on high resolution grid based on the shifts of each low resolution image using different interpolation techniques. Experiments are conducted by simulating low resolution images by subpixel shifts and subsampling of original high resolution image and the reconstructing the high resolution images from the simulated low resolution images. The results of accuracy of reconstruction are compared by using mean squared error measure between original high resolution image and reconstructed image. The algorithm was tested on remote sensing images and found to outperform previously proposed techniques such as Iterative Back Projection algorithm (IBP), Maximum Likelihood (ML) algorithms. The algorithms are robust and are not overly sensitive to the registration inaccuracies. © 2016 SPIE.","Image processing; Interpolation; Iterative methods; Maximum likelihood; Mean square error; Optical resolving power; Pixels; Radial basis function networks; Remote sensing; High resolution image reconstruction; High spatial resolution; Inverse distance weighted; Iterative back projections; Maximum likelihood algorithm; Radial Basis Function(RBF); Remote sensing data; Super resolution; Image reconstruction","High spatial resolution; Remote sensing Data; Super Resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84991497507"
"Liu S.; Zhu Y.; Xue L.","Liu, Shuai (57196071725); Zhu, Yajie (55799696600); Xue, Lei (55368549400)","57196071725; 55799696600; 55368549400","Remote sensing image super-resolution method using sparse representation and classified texture patches","2015","Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University","40","5","","578","582","4","10.13203/j.whugis20130385","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929721238&doi=10.13203%2fj.whugis20130385&partnerID=40&md5=dc215c1c7468d382c0c6cfd75e83f3d8","A super-resolution method based on sparse representation and classified texture patches was proposed, mainly using the priori knowledge and texture to reconstruct remote sensing images. First, extract image blocks for dictionary learning, the over-complete dictionary was learned from the high and low resolution remote sensing image blocks. Orthogonal match pursuit was used to calculate the sparse conefficients, then the coefficients were fixed, iterative method was used to update the dictionary until the algorithm converges. Then, the training dictionary was used to reconstruct the remote sensing images. In this step, the image was divided into smooth patches and non-smooth patches, bicubic interpolation was used for smooth patches while sparse conefficients and over-complete dictionary were used for non-smooth patches. Experiment shows that this method has a faster reconstruction speed and can achieve satisfied super-resolution results in the visual effects and objective evaluation indicators. ©, 2015, Wuhan University. All right reserved.","Image classification; Image reconstruction; Iterative methods; Optical resolving power; Remote sensing; Textures; Classified texture patches; Dictionary learning; Remote sensing images; Sparse representation; Super resolution; algorithm; image resolution; imaging method; interpolation; learning; remote sensing; Image texture","Classified texture patches; Dictionary learning; Remote sensing image; Sparse representation; Super-resolution","Article","Final","","Scopus","2-s2.0-84929721238"
"Abraham Sundar K.J.; Vaithiyanathan V.","Abraham Sundar, K. Joseph (56783941200); Vaithiyanathan, V. (35173624000)","56783941200; 35173624000","Multi-frame super-resolution using adaptive normalized convolution","2017","Signal, Image and Video Processing","11","2","","357","362","5","10.1007/s11760-016-0952-z","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982867188&doi=10.1007%2fs11760-016-0952-z&partnerID=40&md5=a37d6e2a3a26b2b230722d1d968f6bc8","An enhanced fusion algorithm for generating a super-resolution image from a sequence of low-resolution images captured from identical scene apparently a video based on adaptive normalized convolution has been designed and analyzed. The algorithm for fusing the images is based on the supporting structure of normalized convolution. Here the idea is projection of local signals onto a subspace. The adaptive nature of the window function in adaptive normalized convolution helps to gather more samples for processing and increases signal-to-noise ratio, decreases diffusion through discontinuities. The validation of proposed method is done using simulated experiments and real-time experiments. These experimental results are compared with various latest techniques using performance measures like peak signal-to-noise ratio, sharpness index and blind image quality index. In both the cases of experiments, the proposed adaptive normalized convolution-based super-resolution image reconstruction has proved to be highly efficient which is needed for satellite imaging, medical imaging diagnosis, military surveillance, remote sensing, etc. © 2016, Springer-Verlag London.","Algorithms; Convolution; Diagnosis; Image fusion; Image quality; Image reconstruction; Image segmentation; Medical imaging; Military photography; Optical resolving power; Remote sensing; Low resolution images; Military surveillance; Normalized convolution; Peak signal to noise ratio; Real-time experiment; Simulated experiments; Super resolution; Super-resolution image reconstruction; Signal to noise ratio","Adaptive normalized convolution; Applicability function; Image fusion; Normalized convolution; Super-resolution","Article","Final","","Scopus","2-s2.0-84982867188"
"","","","Proceedings - International Conference on Machine Learning and Cybernetics","2015","Proceedings - International Conference on Machine Learning and Cybernetics","2","","","","","932","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020724668&partnerID=40&md5=190966ee1349142fe76ae5e2f154f867","The proceedings contain 153 papers. The topics discussed include: prediction of protein structural classes by decreasing nearest neighbor error rate; parameter learning for ant colony optimization to minimal time cost reduction; graph k-means with lost cluster approach for nonlinear manifold clustering; a matroidal structure for formal context and its applications on epidemiological study; morphological component analysis and least squares support vector machine for image super-resolution; selection of initial parameters of k-means clustering algorithm for MRI brain image segmentation; classification on Tiangong-1 hyperspectral remote sensing image via contextual sparse coding; information fusion in multi-source fuzzy information system with same structure; an effective and efficient grid-based data clustering algorithm using intuitive neighbor relationship for data mining; a study of hand gesture recognition with wireless channel modeling by using wearable devices; biclustering analysis of gene expression data using multi-objective evolutionary algorithms; fusion based approach to discovering social circles in ego networks; a new adaptive fuzzy neural force controller for robots manipulator interacting with environments; image segmentation with texture clustering based JSEG; and automatic Chinese dialog acts recognition with multiple kernel learning.","","","Conference review","Final","","Scopus","2-s2.0-85020724668"
"Sundar K.J.A.; Vaithiyanathan V.; Thangadurai G.R.S.; Namdeo N.","Sundar, K. Joseph Abraham (56783941200); Vaithiyanathan, V. (35173624000); Thangadurai, G. Raja Singh (6506804521); Namdeo, Naveen (56784210200)","56783941200; 35173624000; 6506804521; 56784210200","Design and analysis of fusion algorithm for multi-frame super-resolution image reconstruction using framelet","2015","Defence Science Journal","65","4","","292","299","7","10.14429/dsj.65.8265","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939459042&doi=10.14429%2fdsj.65.8265&partnerID=40&md5=8458928321f19ad35267d69360ba8f79","A enhanced fusion algorithm for generating a super resolution image from a sequence of low-resolution images captured from identical scene apparently a video, based on framelet have been designed and analyzed. In this paper an improved analytical method of image registration is used which integrates nearest neighbor method and gradient method. Comparing to Discrete Wavelet Transform (DWT) the Framelet Transform (FrT) have tight frame filter bank that offers symmetry and permits shift in invariance. Therefore using framelet this paper also present a framelet based enhanced fusion for choosing the fused framelet co-efficient that provides detailed edges and good spatial information with adequate de-noising. The proposed algorithm also has high advantage and computationally fast which are most needed for satellite imaging, medical imaging diagnosis, military surveillance, remote sensing etc. © 2015, DESIDOC.","Diagnosis; Discrete wavelet transforms; Gradient methods; Image analysis; Image enhancement; Image fusion; Image registration; Medical imaging; Optical resolving power; Remote sensing; Framelet; Improved analytical methods; Low resolution images; Military surveillance; Nearest neighbor method; Super resolution; Super-resolution image reconstruction; Tight frame; Image reconstruction","Framelet; Image registration; Super resolution; Tight frames","Article","Final","","Scopus","2-s2.0-84939459042"
"Chen Y.; Ge Y.; Jia Y.","Chen, Yuehong (56084228300); Ge, Yong (26655529300); Jia, Yuanxin (57171309000)","56084228300; 26655529300; 57171309000","Integrating object boundary in super-resolution land-cover mapping","2017","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","10","1","7433947","219","230","11","10.1109/JSTARS.2016.2533571","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960976921&doi=10.1109%2fJSTARS.2016.2533571&partnerID=40&md5=f42bc8eeae5abe272a1157b11391baa7","This paper proposes a novel class allocation strategy in units of object (UOO) for soft-then-hard super-resolution mapping (STHSRM). STHSRM involves two processes: 1) subpixel sharpening and 2) class allocation. The UOO is implemented in the second process by integrating the object boundaries as an additional structural constraint. First, UOO obtains the object boundaries from remote-sensing images by image segmentation. The number of subpixels within an object is then calculated for each class to meet the coherence constraint of fractional images imposed by soft classification. Finally, a linear optimization model is built for each object to obtain the optimal hard class labels of subpixels. A synthetic image and two real remote-sensing images are used to evaluate the effectiveness of UOO. The results are compared visually and quantitatively with two existing class allocation methods: 1) the highest attribute values first (HAVF) and 2) units of class (UOC). The experimental results show that UOO performs better than these two methods. UOO can better reduce the salt and pepper effect in resultant maps than both HAVF and UOC when dealing with real remote-sensing images. Moreover, UOO can better maintain the structure of land-cover patches, with smoother boundaries as compared with the two methods. © 2008-2012 IEEE.","Image reconstruction; Image segmentation; Linear programming; Mapping; Optical resolving power; Optimization; Pixels; Allocation strategy; Coherence constraints; Land cover mapping; Linear optimization model; Remote sensing images; Soft classification; Structural constraints; Super-resolution mappings; image resolution; land cover; mapping; pixel; remote sensing; satellite imagery; Remote sensing","Land cover; object boundary; remotely sensed imagery; super-resolution mapping (SRM)","Article","Final","","Scopus","2-s2.0-84960976921"
"Vishnukumar S.; Wilscy M.","Vishnukumar, S. (35175430100); Wilscy, M. (17436378300)","35175430100; 17436378300","Super-resolution for remote sensing images using content adaptive detail enhanced self examples","2016","Proceedings of IEEE International Conference on Circuit, Power and Computing Technologies, ICCPCT 2016","","","7530375","","","","10.1109/ICCPCT.2016.7530375","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992018129&doi=10.1109%2fICCPCT.2016.7530375&partnerID=40&md5=57626e9398ce1889a84b7a5b1c8aa048","This paper proposes a single image super-resolution (SR) technique for remote sensing images using content adaptive detail enhanced self examples. This method exploits large number of similar patches exists in the remote sensing images by using self examples. A high frequency layer is extracted from the input low resolution image and details of the high frequency layer are enhanced using content adaptive method to form the self examples. The root mean square difference of feature vectors extracted from self examples is given to a Gaussian function to find the weight. Weighted average of pixel computed using weights predicts the pixels of the high resolution high frequency layer. The reconstructed high resolution high frequency layer is combined with the linearly interpolated high resolution image to form the final high resolution image. Qualitative and Quantitative experimental analysis show that the proposed method gives better results than other existing methods. The results have better visual quality since image details are well preserved. © 2016 IEEE.","Computer circuits; Image processing; Image reconstruction; Optical resolving power; Pixels; Reconfigurable hardware; Content-adaptive; Example based; Experimental analysis; High resolution image; Low resolution images; Remote sensing images; Root mean square differences; Super resolution; Remote sensing","Content Adaptive; Remote Sensing Image; Self example based; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-84992018129"
"Sakthivel S.P.; Shanmugam S.","Sakthivel, Shanmuga Priyaa (57508446000); Shanmugam, Sanjeevi (6507719504)","57508446000; 6507719504","Improved road network extraction by super-resolution mapping of hyperion image data","2016","37th Asian Conference on Remote Sensing, ACRS 2016","2","","","1284","1290","6","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018372804&partnerID=40&md5=7814c01cde85641c76ff230a75ba5087","This paper is concerned with the development of super resolution mapping approaches to extract the road network from a moderate resolution hyperspectral (Hyperion) image data. Super-resolution mapping is a technique which allows classification and mapping from coarse resolution images at the sub-pixel scale. In this work, the potential of Linear Spectral Unmixing and Support Vector Machine as inputs for Hopfield Neural Network based super resolution mapping. Further, integration of SVM as a soft-classified input to the SRM proved to be better than linear spectral unmixing (LSU) as soft classification input. The probability image obtained from support vector machine is used as an input for super resolution mapping designed on Hopfield Neural Network (HNN). For the evaluation of the technique, road segments are mapped using the Hyperion image (30m resolution and 242 bands) of Pondicherry city, south India. Producer's accuracy of the road class is 97.26% and user's accuracy is 91.03%. SRM with SVM as an input has achieved completeness of 0.594 and correctness of 0.863. The results proved that SVM as a soft classified input to the HNN based SRM is efficient and it results in overall accuracy of 92.97% for road network extraction from 30 m resolution image.","Extraction; Hopfield neural networks; Mapping; Optical resolving power; Photomapping; Remote sensing; Roads and streets; Support vector machines; Transportation; Hopfield neural networks (HNN); Hyperspectral Data; Linear spectral unmixing; Moderate resolution; Overall accuracies; Road network extraction; Soft classification; Super-resolution mappings; Image processing","Hopfield Neural Network; Hyperspectral data; Support Vector Machine","Conference paper","Final","","Scopus","2-s2.0-85018372804"
"","","","Proceedings of SPIE - The International Society for Optical Engineering","2017","Proceedings of SPIE - The International Society for Optical Engineering","10434","","","","","245","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041589365&partnerID=40&md5=0b5c781e7aa0a4ff1cc8df1ca44f1396","The proceedings contain 23 papers. The topics discussed include: new microwave modulation LIDAR scheme for naval mine detection; UTOFIA: an underwater time-of-flight image acquisition system; experimental evaluation of penetration capabilities of a Geiger-mode APD array laser radar system; laser SRS tracker for reverse prototyping tasks; characterization and performance of a LWIR polarimetric imager; single vs. dual color fire detection systems: operational tradeoffs; a method of recognition of maritime objects based on FLIR (forward looking infra-red) sensor images using dynamic time warping; fine-grained visual marine vessel classification for coastal surveillance and defense applications; real-time moving objects detection and tracking from airborne infrared camera; active multispectral reflection fingerprinting of persistent chemical agents; simultaneous remote measurement of CO2 concentration, humidity and temperature with a matrix of optical fiber sensors; new optical scheme of the intensity control for a remote gas analyzer; passive fiber optic temperature sensor for safety applications; dual-core optical fiber based strain sensor for remote sensing in hard-to-reach areas; super-resolution depth information from a short-wave infrared laser gated-viewing system by using correlated double sampling; robust eye-safe pulsed fiber laser source for 3D ladar applications; multimodal UAV detection: study of various intrusion scenarios; open architecture of smart sensor suites; and infrared small target detection in a wide field imaging system.","","","Conference review","Final","","Scopus","2-s2.0-85041589365"
"Wu W.; Yang X.; Liu K.; Liu Y.; Yan B.; Hua H.","Wu, Wei (56386371900); Yang, Xiaomin (9237988500); Liu, Kai (57223776901); Liu, Yiguang (56462033100); Yan, Binyu (45961752600); Hua, Hua (55166201400)","56386371900; 9237988500; 57223776901; 56462033100; 45961752600; 55166201400","A new framework for remote sensing image super-resolution: Sparse representation-based method by processing dictionaries with multi-type features","2016","Journal of Systems Architecture","64","","","63","75","12","10.1016/j.sysarc.2015.11.005","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961310713&doi=10.1016%2fj.sysarc.2015.11.005&partnerID=40&md5=b8edeb5ceeac76e253e3fe3f5a6dad57","Remote sensing images play an important role in many practical applications, however, due to the physical limitations of remote sensing devices, it is difficult to obtain images at an expecting high resolution level. Acquiring high-resolution(HR) images from the original low-resolution(LR) ones with super-resolution(SR) methods has always been an attractive proposition in embedded systems including various kinds of tablet PC and smart phone. SR methods based on sparse representation have been successfully used in processing remote sensing images, however, they have two major problems in common. First, they use only one type of image features to represent the low resolution(LR) images. However, one single type of features cannot accurately represent an image due to the diverse structures of the image, as a result, artifacts would be produced simultaneously. Second, many dictionary learning methods try to build a universal dictionary with only one single type of features. However, apparently, a dictionary with a single type of features is not enough to capture the different structures of a remote sensing image, without any doubt, the resultant image would turn out to be a poor one. To overcome the problems above, we propose a new framework for remote sensing image super resolution: sparse representation-based SR method by processing dictionaries with multi-type features. First, in order to represent the remote sensing image more accurately, different types of features are extracted from images. Second, to achieve a better performance, various dictionaries with multi-type features are learned to capture the essential structures of the image. Then, it's proposed to adaptively control the weights of the high resolution(HR) patches obtained by different dictionaries. Numerous experiments validate that this proposed framework brings better results in terms of both objective quantitation and visual perception than other compared algorithms. © 2015 Elsevier B.V. All rights reserved.","Embedded systems; Image processing; Image reconstruction; Optical resolving power; Personal computers; Smartphones; Dictionary learning; Different structure; High resolution image; Low resolution images; Physical limitations; Remote sensing images; Sparse representation; Super resolution; Remote sensing","Dictionary interpreting; Remote sensing images; Sparse representation; Super-resolution","Article","Final","","Scopus","2-s2.0-84961310713"
"Xu X.; Tong X.; Plaza A.; Zhong Y.; Xie H.; Zhang L.","Xu, Xiong (55520591300); Tong, Xiaohua (55500134600); Plaza, Antonio (7006613644); Zhong, Yanfei (12039673900); Xie, Huan (36117406500); Zhang, Liangpei (8359720900)","55520591300; 55500134600; 7006613644; 12039673900; 36117406500; 8359720900","Joint sparse sub-pixel mapping model with endmember variability for remotely sensed imagery","2017","Remote Sensing","9","1","15","","","","10.3390/rs9010015","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010657700&doi=10.3390%2frs9010015&partnerID=40&md5=aacd62a4d968fec1f3f178a4247e15cd","Spectral unmixing and sub-pixel mapping have been used to estimate the proportion and spatial distribution of the different land-cover classes in mixed pixels at a sub-pixel scale. In the past decades, several algorithms were proposed in both categories; however, these two techniques are generally regarded as independent procedures, with most sub-pixel mapping methods using abundance maps generated by spectral unmixing techniques. It should be noted that the utilized abundance map has a strong impact on the performance of the subsequent sub-pixel mapping process. Recently, we built a novel sub-pixel mapping model in combination with the linear spectral mixture model. Therefore, a joint sub-pixel mapping model was established that connects an original (coarser resolution) remotely sensed image with the final sub-pixel result directly. However, this approach focuses on incorporating the spectral information contained in the original image without addressing the spectral endmember variability resulting from variable illumination and environmental conditions. To address this important issue, in this paper we designed a new joint sparse sub-pixel mapping method under the assumption that various representative spectra for each endmember are known a priori and available in a library. In addition, the total variation (TV) regularization was also adopted to exploit the spatial information. The proposed approach was experimentally evaluated using both synthetic and real hyperspectral images, and the obtained results demonstrate that the method can achieve better results by considering the impact of endmember variability when compared with other sub-pixel mapping methods. © 2016 by the authors; licensee MDPI, Basel, Switzerland.","Edge detection; Photomapping; Pixels; Remote sensing; Spectroscopy; Endmember variabilities; Hyperspectral Imaging; Sparse regression; Spectral unmixing; Sub-pixel mapping; Super-resolution mappings; Mapping","Endmember variability; Hyperspectral imaging; Sparse regression; Spectral unmixing; Sub-pixel mapping; Super-resolution mapping","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85010657700"
"Li L.; Chen Y.; Xu T.; Liu R.; Shi K.; Huang C.","Li, Linyi (12781706800); Chen, Yun (55721092200); Xu, Tingbao (24304468000); Liu, Rui (56412259000); Shi, Kaifang (55235145300); Huang, Chang (56460475700)","12781706800; 55721092200; 24304468000; 56412259000; 55235145300; 56460475700","Super-resolution mapping of wetland inundation from remote sensing imagery based on integration of back-propagation neural network and genetic algorithm","2015","Remote Sensing of Environment","164","","","142","154","12","10.1016/j.rse.2015.04.009","91","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928653893&doi=10.1016%2fj.rse.2015.04.009&partnerID=40&md5=8a1462d5322ac9ccd2f44e9b43700c07","Mapping the spatio-temporal characteristics of wetland inundation has an important significance to the study of wetland environment and associated flora and fauna. High temporal remote sensing imagery is widely used for this purpose with the limitations of relatively low spatial resolutions. In this study, a novel method based on integration of back-propagation neural network (BP) and genetic algorithm (GA), so-called IBPGA, is proposed for super-resolution mapping of wetland inundation (SMWI) from multispectral remote sensing imagery. The IBPGA-SMWI algorithm is developed, including the fitness function and integration search strategy. IBPGA-SMWI was evaluated using Landsat TM/ETM. + imagery from the Poyanghu wetland in China and the Macquarie Marshes in Australia. Compared with traditional SMWI methods, IBPGA-SMWI consistently achieved more accurate super-resolution mapping results in terms of visual and quantitative evaluations. In comparison with GA-SMWI, IBPGA-SMWI not only improved the accuracy of SMWI, but also accelerated the convergence speed of the algorithm. The sensitivity analysis of IBPGA-SMWI in relation to standard crossover rate, BP crossover rate and mutation rate was also carried out to discuss the algorithm performance. It is hoped that the results of this study will enhance the application of median-low resolution remote sensing imagery in wetland inundation mapping and monitoring, and ultimately support the studies of wetland environment. © 2015 Elsevier Inc.","Australia; China; Macquarie Marshes; New South Wales; Backpropagation; Floods; Genetic algorithms; Image enhancement; Integration; Mapping; Neural networks; Optical resolving power; Sensitivity analysis; Torsional stress; Wetlands; Algorithm performance; Back propagation neural networks; Intelligent Algorithms; Multispectral remote sensing imagery; Quantitative evaluation; Remote sensing imagery; Spatiotemporal characteristics; Super-resolution mappings; accuracy assessment; artificial neural network; back propagation; genetic algorithm; image resolution; Landsat thematic mapper; remote sensing; satellite imagery; Remote sensing","Intelligent algorithm integration; Remote sensing imagery; Super-resolution mapping; Wetland inundation","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84928653893"
"Eskandari A.; Karami A.","Eskandari, Armin (57200386214); Karami, Azam (56597709000)","57200386214; 56597709000","The effect of denoising on superresolution of hyperspectral imaging","2017","Proceedings of SPIE - The International Society for Optical Engineering","10427","","2278503","","","","10.1117/12.2278503","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041046387&doi=10.1117%2f12.2278503&partnerID=40&md5=3dd9b5d531e183b95b5b1cb7ca734b26","Hyperspectral Images (HSI) are usually affected by different type of noises such as Gaussian and non-Gaussian. The existing noise can directly affect the classification, unmixing and superresolution analyses. In this paper, the effect of denoising on superresolution of HSI is investigated. First a denoising method based on shearlet transform is applied to the low-resolution HSI in order to reduce the effect of noise, then the superresolution method based on Bayesian sparse representation is used. The proposed method is applied to real HSI dataset. The obtained results of the proposed method in comparison with some of the state-of-The-Art superresolution methods show that the proposed method significantly increases the spatial resolution and decreases the noise effects efficiently. © 2017 SPIE.","Hyperspectral imaging; Image processing; Optical resolving power; Remote sensing; Spectroscopy; Denoising methods; Effect of noise; Shearlet transforms; Sparse representation; Spatial resolution; State of the art; Super resolution; Superresolution methods; Signal processing","Shearlet transform; Sparse representation; Superresolution","Conference paper","Final","","Scopus","2-s2.0-85041046387"
"","","","Proceedings of SPIE - The International Society for Optical Engineering","2017","Proceedings of SPIE - The International Society for Optical Engineering","10609","","","","","431","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045550764&partnerID=40&md5=4c3e3d0cc47349eeca208ea78616ec34","The proceedings contain 59 papers. The topics discussed include: static facial expression recognition with convolution neural networks; affine invariant feature extraction based on the shape of local support region; hog pedestrian detection based on edge symmetry and trilinear interpolation; a multi-view face recognition system based on cascade face detector and improved Dlib; the method for froth floatation condition recognition based on adaptive feature weighted; robust image matching via orb feature and VFC for mismatch removal; dual-threshold segmentation using Arimoto entropy based on chaotic bee colony optimization; a novel approach for fire recognition using hybrid features and manifold learning-based classifier; research on three-dimensional reconstruction method based on binocular vision; scene text detection by leveraging multi-channel information and local context; single image super-resolution based on convolutional neural networks; supervised guiding long-short term memory for image caption generation based on object classes; a method of non-contact reading code based on computer vision; automated railroad reconstruction from remote sensing image based on texture filter; environmentally adaptive crop extraction for agricultural automation using super-pixel and LAB Gaussian model; improved dense trajectories for action recognition based on random projection and fisher vectors; and collaborative identification method for sea battlefield target based on deep convolutional neural networks.","","","Conference review","Final","","Scopus","2-s2.0-85045550764"
"Masi G.; Cozzolino D.; Verdoliva L.; Scarpa G.","Masi, Giuseppe (36721555500); Cozzolino, Davide (55440439700); Verdoliva, Luisa (6506573720); Scarpa, Giuseppe (7004081145)","36721555500; 55440439700; 6506573720; 7004081145","Pansharpening by convolutional neural networks","2016","Remote Sensing","8","7","594","","","","10.3390/rs8070594","580","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84993982662&doi=10.3390%2frs8070594&partnerID=40&md5=2b7f50119ee23909675e767465921a73","A new pansharpening method is proposed, based on convolutional neural networks. We adapt a simple and effective three-layer architecture recently proposed for super-resolution to the pansharpening problem. Moreover, to improve performance without increasing complexity, we augment the input by including several maps of nonlinear radiometric indices typical of remote sensing. Experiments on three representative datasets show the proposed method to provide very promising results, largely competitive with the current state of the art in terms of both full-reference and no-reference metrics, and also at a visual inspection. © 2016 by the authors; licensee MDPI, Basel, Switzerland.","Artificial intelligence; Convolution; Image enhancement; Image segmentation; Learning systems; Neural networks; Optical resolving power; Remote sensing; Convolutional neural network; Improve performance; Multiresolution; No-reference metrics; Radiometric indices; Super resolution; Threelayer architecture; Visual inspection; Complex networks; Convolution","Convolutional neural networks; Enhancement; Machine learning; Multiresolution; Segmentation; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84993982662"
"Tuna C.; Akoguz A.; Unal G.; Sertel E.","Tuna, Caglayan (57191850673); Akoguz, Alper (55853943100); Unal, Gozde (57220534209); Sertel, Elif (21934838300)","57191850673; 55853943100; 57220534209; 21934838300","Resolution enhancement of tri-stereo remote sensing images by super resolution methods","2016","Proceedings of SPIE - The International Society for Optical Engineering","10004","","1000409","","","","10.1117/12.2241176","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011347375&doi=10.1117%2f12.2241176&partnerID=40&md5=224f9324ce0110ee3dd2f1832b96377d","Super resolution (SR) refers to generation of a High Resolution (HR) image from a decimated, blurred, low-resolution (LR) image set, which can be either a single frame or multi-frame that contains a collection of several images acquired from slightly different views of the same observation area. In this study, we propose a novel application of tri-stereo Remote Sensing (RS) satellite images to the super resolution problem. Since the tri-stereo RS images of the same observation area are acquired from three different viewing angles along the flight path of the satellite, these RS images are properly suited to a SR application. We first estimate registration between the chosen reference LR image and other LR images to calculate the sub pixel shifts among the LR images. Then, the warping, blurring and down sampling matrix operators are created as sparse matrices to avoid high memory and computational requirements, which would otherwise make the RS-SR solution impractical. Finally, the overall system matrix, which is constructed based on the obtained operator matrices is used to obtain the estimate HR image in one step in each iteration of the SR algorithm. Both the Laplacian and total variation regularizers are incorporated separately into our algorithm and the results are presented to demonstrate an improved quantitative performance against the standard interpolation method as well as improved qualitative results due expert evaluations. © 2016 SPIE..","Image processing; Image reconstruction; Iterative methods; Optical resolving power; Remote sensing; Signal processing; Bilateral total variations; Multi-frame; Regularization; SPOT; Stereo-image; Super resolution; Stereo image processing","Bilateral Total Variation; Multi-frame; Pléiades; Regularization; SPOT; Super Resolution; Tri-stereo Images","Conference paper","Final","","Scopus","2-s2.0-85011347375"
"Dalmiya C.P.; Dharun V.S.","Dalmiya, C.P. (55823809800); Dharun, V.S. (55823607900)","55823809800; 55823607900","A survey of registration techniques in remote sensing images","2015","Indian Journal of Science and Technology","8","26","IPL0505","","","","10.17485/ijst/2015/v8i26/81048","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949973019&doi=10.17485%2fijst%2f2015%2fv8i26%2f81048&partnerID=40&md5=c615dd34245f26c5b88e1f281f029944","Background: Image registration is one of the challenging issues in remote sensing applications. In last few years a wide variety of image registration techniques have been proposed. This paper reviews various registration techniques of satellite images. The approach discussed in this paper includes feature extraction and selection, feature matching, transform model estimation, transformation and resampling. Methods: The methods of registrations which are applicable to multi temporal, multi spectral, multi angle and multisensory are discussed. Automatic registration of remote sensing images deals with various problems such as intensity variations, illumination changes, geometric distortions, noise etc. For solving all the registration problems various techniques are presented for various applications. There are two types of registration involved, one type is intensity based and other one is feature based. Literature evaluation of various techniques describes the methods applicable for each application. Results: The findings shown that SIFT is the best suitable method for feature extraction. This survey helps researchers for attain information about registration of remote sensing images. Application: Image registration can be applied in various applications such as Multispectral classification, Environmental monitoring, Change detection, Image mosaicking, Weather forecasting, creating super-resolution images etc.","","Feature extraction; Feature matching; Image registration; Image resampling; Remote sensing; Transformation model","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-84949973019"
"Zhang J.; Wang Y.-J.; Wang S.","Zhang, Jian (56688227100); Wang, Yiju (57193618011); Wang, Shengchao (57193617706)","56688227100; 57193618011; 57193617706","Super resolution sparse reconstruction with a high and low resolution dictionary for single remote sensing image","2016","International Journal of Simulation: Systems, Science and Technology","17","40","","4.1","4.7","","10.5013/IJSSST.a.17.40.04","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015184992&doi=10.5013%2fIJSSST.a.17.40.04&partnerID=40&md5=8604319c4d7670fba4810529e1892b2c","Super resolution remote sensing image is important for the improvement of the target recognition rate, but there is a large demand of training sample in the super resolution reconstruction process, which result in the problem of low computing efficiency and poor reconstruction resolution, so here proposed Super resolution sparse reconstruction with the high and low resolution dictionary for single remote sensing image. Firstly, the training set of samples with high and low resolution is obtained from the high resolution remote sensing image based on the existing high resolution remote sensing image; Secondly, here designed the sparse dictionary joint training method, and deal with the high and low resolution feature of the sample training set, which could get the dictionary with high and low resolution; Finally, the high resolution remote sensing image is reconstructed based on the acquired high and low resolution dictionary, and then the complexity of the algorithm is analyzed. The simulation results show that the algorithm has less requirements on the dictionary training sample, and can achieve a good result. © 2016, UK Simulation Society. All rights reserved.","Computational complexity; Image processing; Image reconstruction; Optical resolving power; Sampling; Dictionary trainings; High resolution remote sensing images; Low resolution; Remote sensing images; Sparse reconstruction; Sparse representation; Super resolution; Super resolution reconstruction; Remote sensing","High and low resolution dictionary; Reconstruction; Remote sensing image; Sparse representation; Super resolution","Article","Final","","Scopus","2-s2.0-85015184992"
"Zhang H.; Wang C.; Chen Y.; Jia F.; Li J.","Zhang, Hairong (57190809753); Wang, Cheng (36990982800); Chen, Yiping (56233739200); Jia, Fukai (56335115800); Li, Jonathan (57235557700)","57190809753; 36990982800; 56233739200; 56335115800; 57235557700","Benchmark on outdoor scenes","2016","Proceedings of SPIE - The International Society for Optical Engineering","9901","","99010U","","","","10.1117/12.2234860","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983365284&doi=10.1117%2f12.2234860&partnerID=40&md5=443f20353483ea30c71d6ac7caf149da","Depth super-resolution is becoming popular in computer vision, and most of test data is based on indoor data sets with ground-truth measurements such as Middlebury. However, indoor data sets mainly are acquired from structured light techniques under ideal conditions, which cannot represent the objective world with nature light. Unlike indoor scenes, the uncontrolled outdoor environment is much more complicated and is rich both in visual and depth texture. For that reason, we develop a more challenging and meaningful outdoor benchmark for depth super-resolution using the state-of-the-art active laser scanning system. © 2016 SPIE.","Benchmarking; Laser applications; Optical resolving power; Remote sensing; Surface analysis; Depth; Depth super resolutions; Laser scanning; Laser scanning systems; outdoor; Outdoor environment; State of the art; Super resolution; Computer vision","benchmark; Depth; laser scanning; outdoor; super-resolution","Conference paper","Final","","Scopus","2-s2.0-84983365284"
"Chen Y.; Ge Y.; Song D.","Chen, Yuehong (56084228300); Ge, Yong (26655529300); Song, Dunjiang (16176403100)","56084228300; 26655529300; 16176403100","Superresolution Land-Cover Mapping Based on High-Accuracy Surface Modeling","2015","IEEE Geoscience and Remote Sensing Letters","12","12","7312427","2516","2520","4","10.1109/LGRS.2015.2489683","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947868712&doi=10.1109%2fLGRS.2015.2489683&partnerID=40&md5=e8ee0830c381f472e5a6a34aca42e1e8","A new superresolution mapping (SRM) method based on high-accuracy surface modeling (HASM) is proposed to generate land-cover maps at the subpixel scale. HASM uses the fundamental theorem of surfaces to uniquely define a land surface, which can produce less errors in interpolation results than classic methods, and thus, the proposed SRM method first uses it to estimate the soft class values of subpixels according to the fraction images of soft classification. Then, it transforms the soft class values into a hard-classified land-cover map using class allocation under the constraints of fraction images. Experiments on a synthetic image and a real remote sensing image show that the proposed method produces more accurate SRM maps than four existing SRM methods. Hence, the proposed method provides a new option for superresolution land-cover mapping. © 2004-2012 IEEE.","Image classification; Image reconstruction; Optical resolving power; Pixels; Remote sensing; Fundamental theorems; Land cover mapping; Remote sensing images; Soft classification; Super resolution; Super-resolution mappings; Surface modeling; Synthetic images; Mapping","Accuracy; Interpolation; Land surface; Remote sensing; Spatial resolution; Yttrium","Article","Final","","Scopus","2-s2.0-84947868712"
"Zhu H.; Song W.; Tan H.; Wang J.","Zhu, Hong (57190032288); Song, Weidong (56512910400); Tan, Hai (36976217000); Wang, Jingxue (55349285400)","57190032288; 56512910400; 36976217000; 55349285400","Remote sensing images super resolution reconstruction based on multi-scale detail enhancement","2016","Cehui Xuebao/Acta Geodaetica et Cartographica Sinica","45","9","","1081","1088","7","10.11947/j.AGCS.2016.20150451","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990059420&doi=10.11947%2fj.AGCS.2016.20150451&partnerID=40&md5=0c0a95f152d38fd17d8e52bba0803418","The existing methods are hard to highlight the details after super resolution reconstruction, so it is proposed a super-resolution model frame to enhance the multi-scale details. Firstly, the sequence images are multi-scale deposed to keep the edge structure and the deposed multi-scale image information are differenced. Then, the smoothing information and detail information are interpolated, and a texture detail enhancement function is built to improve the scope of small details. Finally, the coarse-scale image information and small-medium-scale information are confused to get the premier super-resolution reconstruction result, and a local optimizing model is built to further promote the premier image quality. The experiments on the same period and different period remote sensing images show that the objective evaluation index are both largely improved comparing with the interpolation method, traditional total variation (TV) method, and maximum a posterior (MAP) method. The details of the reconstruction image are improved distinctly. The reconstruction image produced using the proposed method provides more high frequency details, and the method proves to be robust and universal for different kinds of satellite remote sensing images. © 2016, Surveying and Mapping Press. All right reserved.","Image fusion; Image reconstruction; Optical resolving power; Remote sensing; Detail enhancement; Interpolation method; Maximum a posteriors; Multi-scale Decomposition; Remote sensing images; Satellite remote sensing; Super resolution reconstruction; Super-resolution models; data quality; decomposition analysis; image resolution; optimization; reconstruction; remote sensing; satellite imagery; Image enhancement","Detail enhancement; Image fusion; Multi-scale decomposition; Super resolution reconstruction","Article","Final","","Scopus","2-s2.0-84990059420"
"Morton K.; Weisberg A.","Morton, Kenneth (56320101800); Weisberg, Arel (15039024600)","56320101800; 15039024600","Compact high performance spectrometers using computational imaging","2016","Proceedings of SPIE - The International Society for Optical Engineering","9874","","98740C","","","","10.1117/12.2224159","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991486760&doi=10.1117%2f12.2224159&partnerID=40&md5=aaa9d7fd4d77c4b6277877d3bc103eda","Compressive sensing technology can theoretically be used to develop low cost compact spectrometers with the performance of larger and more expensive systems. Indeed, compressive sensing for spectroscopic systems has been previously demonstrated using coded aperture techniques, wherein a mask is placed between the grating and a charge coupled device (CCD) and multiple measurements are collected with different masks. Although proven effective for some spectroscopic sensing paradigms (e.g. Raman), this approach requires that the signal being measured is static between shots (low noise and minimal signal fluctuation). Many spectroscopic techniques applicable to remote sensing are inherently noisy and thus coded aperture compressed sensing will likely not be effective. This work explores an alternative approach to compressed sensing that allows for reconstruction of a high resolution spectrum in sensing paradigms featuring significant signal fluctuations between measurements. This is accomplished through relatively minor changes to the spectrometer hardware together with custom super-resolution algorithms. Current results indicate that a potential overall reduction in CCD size of up to a factor of 4 can be attained without a loss of resolution. This reduction can result in significant improvements in cost, size, and weight of spectrometers incorporating the technology. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Charge coupled devices; Compressed sensing; Data compression; Image reconstruction; Remote sensing; Signal reconstruction; Spectroscopy; Computational imaging; High-resolution spectra; LIBS; Multiple measurements; Spectroscopic sensing; Spectroscopic systems; Spectroscopic technique; Super resolution algorithms; Spectrometers","Compressed Sensing; LIBS; Reconstruction; Spectroscopy","Conference paper","Final","","Scopus","2-s2.0-84991486760"
"Lanaras C.; Baltsavias E.; Schindler K.","Lanaras, Charis (56568192000); Baltsavias, Emmanuel (6603939930); Schindler, Konrad (8557497200)","56568192000; 6603939930; 8557497200","Estimation of relative sensor characteristics for hyperspectral super-resolution","2016","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","0","","8071757","","","","10.1109/WHISPERS.2016.8071757","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037545873&doi=10.1109%2fWHISPERS.2016.8071757&partnerID=40&md5=116ec5f50579a79a349ca2828f058a16","To enhance the spatial resolution of hyperspectral data, additional multispectral images of higher resolution can be used. However, to combine the two data sources information about the sensors is needed. In this paper we derive a model to estimate the relative spatial and spectral response of the two sensors. The proposed formulation includes non-negativity, recovers remaining registration (shift) errors, and uses prior information to adjust to the shape of the spectral response with either l1 or l2 norm regularization. The framework is tested both with real data and with simulated data where the ground truth is known. © 2016 IEEE.","Image enhancement; Optical resolving power; Spectroscopy; Hyperspectral Data; Multispectral images; Relative spatial; Relative spectral response; Response; Sensor characteristics; Spatial resolution; Super resolution; Remote sensing","Hyperspectral super-resolution; Relative spatial; Relative spectral response; Response","Conference paper","Final","","Scopus","2-s2.0-85037545873"
"Chen Y.; Ge Y.; Heuvelink G.B.M.; Hu J.; Jiang Y.","Chen, Yuehong (56084228300); Ge, Yong (26655529300); Heuvelink, Gerard B. M. (6603849280); Hu, Jianlong (55499498100); Jiang, Yu (56083252200)","56084228300; 26655529300; 6603849280; 55499498100; 56083252200","Hybrid Constraints of Pure and Mixed Pixels for Soft-Then-Hard Super-Resolution Mapping with Multiple Shifted Images","2015","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","8","5","7086001","2040","2052","12","10.1109/JSTARS.2015.2417191","39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027930562&doi=10.1109%2fJSTARS.2015.2417191&partnerID=40&md5=584f3139061c34dd42f0ea2a80ff0564","Multiple shifted images (MSIs) have been widely applied to many super-resolution mapping (SRM) approaches to improve the accuracy of fine-scale land-cover maps. Most SRM methods with MSIs involve two processes: subpixel sharpening and class allocation. Complementary information from the MSIs has been successfully adopted to produce soft attribute values of subpixels during the subpixel sharpening process. Such information, however, is not used in the second process of class allocation. In this paper, a new class-allocation algorithm, named 'hybrid constraints of pure and mixed pixels' (HCPMP), is proposed to allocate land-cover classes to subpixels using MSIs. HCPMP first determines the classes of subpixels that overlap with the pure pixels of auxiliary images in MSIs, after which the remaining subpixels are classified using information derived from the mixed pixels of the base image in MSIs. An artificial image and two remote sensing images were used to evaluate the performance of the proposed HCPMP algorithm. The experimental results demonstrate that HCPMP successfully applied MSIs to produce SRM maps that are visually closer to the reference images and that have greater accuracy than five existing class-allocation algorithms. Especially, it can produce more accurate SRM maps for high-resolution land-cover classes than low-resolution cases. The algorithm takes slightly less runtime than class allocation using linear optimization techniques. Hence, HCPMP provides a valuable new solution for class allocation in SRM using auxiliary data from MSIs. © 2015 IEEE.","Algorithms; Image reconstruction; Linear programming; Optical resolving power; Pixels; Remote sensing; Allocation algorithm; Attribute values; Hybrid constraints; Linear optimization; multiple shifted images (MSIs); Remote sensing images; Remotely sensed imagery; Super-resolution mappings; algorithm; image resolution; land cover; mapping; optimization; pixel; remote sensing; Mapping","Hybrid constraints; multiple shifted images (MSIs); remotely sensed imagery; super-resolution mapping (SRM)","Article","Final","","Scopus","2-s2.0-85027930562"
"Qifang X.; Guoqing Y.; Pin L.","Qifang, Xie (57195603464); Guoqing, Yao (55335044100); Pin, Liu (57195607459)","57195603464; 55335044100; 57195607459","Super-resolution Reconstruction of Satellite Video Images Based on Interpolation Method","2017","Procedia Computer Science","107","","","454","459","5","10.1016/j.procs.2017.03.089","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029142004&doi=10.1016%2fj.procs.2017.03.089&partnerID=40&md5=0ff9201ac3c0a92cebf282cef95a0385","At present, super-resolution reconstruction technology is widely used in remote sensing as an effective means to improve the resolution. The super-resolution reconstruction technique reconstructs a series of low-resolution images into one high-resolution image by using complementary information provided by images pixel displacements. In this paper, the satellite video comes from Durango Mexico is used as experimental data. The Vandewalle motion estimation method and Interpolation reconstruction method are used to reconstruct the satellite video images, and the quality evaluation combines subjective evaluation with objective evaluation to appraise the results comprehensively and effectively. Experimental results show that static feature edges reconstructed by Interpolation reconstruction method are even more smooth and clear, and the detail information is more abundant, which can effectively improve the resolution of satellite video images. © 2017 The Authors.","Image quality; Image reconstruction; Interpolation; Motion estimation; Optical resolving power; Quality control; Remote sensing; Satellites; High resolution image; Low resolution images; Quality evaluation; Reconstruction method; Subjective evaluations; Super resolution reconstruction; Super-resolution reconstruction techniques; Video image; Image processing","quality evaluation; satellite video image; super-resolution reconstruction","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85029142004"
"Milanfar P.","Milanfar, Peyman (7004264375)","7004264375","Super-resolution imaging","2017","Super-Resolution Imaging","","","","1","472","471","10.1201/9781439819319","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052468849&doi=10.1201%2f9781439819319&partnerID=40&md5=4bbc6aad4ba05030775d4faf5896830f","With the exponential increase in computing power and broad proliferation of digital cameras, super-resolution imaging is poised to become the next “killer app.” The growing interest in this technology has manifested itself in an explosion of literature on the subject. Super-Resolution Imaging consolidates key recent research contributions from eminent scholars and practitioners in this area and serves as a starting point for exploration into the state of the art in the field. It describes the latest in both theoretical and practical aspects of direct relevance to academia and industry, providing a base of understanding for future progress. Features downloadable tools to supplement material found in the book Recent advances in camera sensor technology have led to an increasingly larger number of pixels being crammed into ever-smaller spaces. This has resulted in an overall decline in the visual quality of recorded content, necessitating improvement of images through the use of post-processing. Providing a snapshot of the cutting edge in super-resolution imaging, this book focuses on methods and techniques to improve images and video beyond the capabilities of the sensors that acquired them. It covers: History and future directions of super-resolution imaging Locally adaptive processing methods versus globally optimal methods Modern techniques for motion estimation How to integrate robustness Bayesian statistical approaches Learning-based methods Applications in remote sensing and medicine Practical implementations and commercial products based on super-resolution The book concludes by concentrating on multidisciplinary applications of super-resolution for a variety of fields. It covers a wide range of super-resolution imaging implementation techniques, including variational, feature-based, multi-channel, learning-based, locally adaptive, and nonparametric methods. This versatile book can be used as the basis for short courses for engineers and scientists, or as part of graduate-level courses in image processing. © 2011 by Taylor and Francis Group, LLC.","Image enhancement; Motion estimation; Processing; Remote sensing; Variational techniques; Bayesian statistical approach; Commercial products; Exponential increase; Graduate level course; Implementation techniques; Learning-based methods; Nonparametric methods; Super resolution imaging; Optical resolving power","","Book","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85052468849"
"","","","2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing, CoSeRa 2016","2016","2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing, CoSeRa 2016","","","","","","262","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002763060&partnerID=40&md5=9a44bee61501deef0e00ad0ccbda8057","The proceedings contain 54 papers. The topics discussed include: a dual-deconvolution algorithm for radar and communication black-space spectrum sharing; off the grid time delay estimation for sparse translation-invariant signals; a non-convex blind calibration method for randomized sensing strategies; generalized line spectral estimation for radar and localization; blind deconvolution and compressed sensing; super resolution of synthetic aperture radar data by convex optimization; a procedure for optimal pulse selection strategy in radar imaging systems; and multi-circular synthetic aperture radar imaging processing procedure based on compressive sensing.","","","Conference review","Final","","Scopus","2-s2.0-85002763060"
"Li Z.; Li C.; Deng C.; Li J.","Li, Zeyu (57192706525); Li, Chao (57192580834); Deng, Cheng (57208019993); Li, Jie (7410068291)","57192706525; 57192580834; 57208019993; 7410068291","Hyperspectral image super-resolution using sparse spectral unmixing and low-rank constraints","2016","International Geoscience and Remote Sensing Symposium (IGARSS)","2016-November","","7730884","7224","7227","3","10.1109/IGARSS.2016.7730884","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007427991&doi=10.1109%2fIGARSS.2016.7730884&partnerID=40&md5=121bca2cdf36130504a83172fd072155","Hyperspectral images play an important role in real-world applications, such as recognition and remote sensing, etc. How to enhance the spatial resolution of hyperspectral image is still a challenging problem in this field. In this paper, we propose a novel hyperspectral image super-resolution approach by jointly incorporating the sparse, low-rank constraints and spectral mixture priori into a linear unmixing framework, which will make the unmixing framework more consistent with the real-world scenarios of the spectral mixture. Experiments on two public databases show that our proposed approach achieves much lower average reconstruction errors than other state-of-the-art methods. © 2016 IEEE.","","Hyperspectral image; image fusion; joint constraints; super-resolution; unmixing","Conference paper","Final","","Scopus","2-s2.0-85007427991"
"Regan D.; Srivatsa S.K.","Regan, D. (56316597400); Srivatsa, S.K. (7003518102)","56316597400; 7003518102","Adaptive artificial bee colony based parameter selection for subpixel mapping multiagent system in remote-sensing imagery","2015","ICIIECS 2015 - 2015 IEEE International Conference on Innovations in Information, Embedded and Communication Systems","","","7193224","","","","10.1109/ICIIECS.2015.7193224","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956979491&doi=10.1109%2fICIIECS.2015.7193224&partnerID=40&md5=96246d0c285a773719637e4f2677169c","Remote sensing has become an important source of land use/cover information at a range of spatial and temporal scales. The existence of mixed pixels is a major problem in remote-sensing image classification. Although the soft classification and spectral unmixing techniques can obtain an abundance of different classes in a pixel to solve the mixed pixel problem, the subpixel spatial attribution of the pixel will still be unknown. The subpixel mapping technique can effectively solve this problem by providing a fine-resolution map of class labels from coarser spectrally unmixed fraction images. However, most traditional subpixel mapping algorithms treat all mixed pixels as an identical type, either boundary-mixed pixel or linear subpixel, leading to incomplete and inaccurate results. To improve the subpixel mapping accuracy, this paper proposes an adaptive subpixel mapping framework based on a multiagent system for remote sensing imagery. In the proposed multiagent subpixel mapping framework, three kinds of agents, namely, feature detection agents, subpixel mapping agents and decision agents, are designed to solve the subpixel mapping problem. This confirms that MASSM is appropriate for the subpixel mapping of remote-sensing images. But the major problem is that the selection of the parameters becomes assumption in order to overcome these problems proposed work focus on adaptive selection of parameters based on the optimization methods, it automatically selects the parameters value in the classification, and it improves the classification results in the remote-sensing imagery. Experiments with artificial images and synthetic remote-sensing images were performed to evaluate the performance of the proposed artificial bee colony based optimization subpixel mapping algorithm in comparison with the hard classification method and other subpixel mapping algorithms: Subpixel mapping based on a back-propagation neural network and the spatial attraction model. The experimental results indicate that the proposed algorithm outperforms the other two subpixel mapping algorithms in reconstructing the different structures in mixed pixels. © 2015 IEEE.","Algorithms; Backpropagation; Backpropagation algorithms; Conformal mapping; Embedded systems; Image classification; Image enhancement; Image reconstruction; Land use; Mapping; Multi agent systems; Neural networks; Optical resolving power; Optimization; Problem solving; Remote sensing; Spectroscopy; Artificial bee colonies; Back propagation neural networks; Classification methods; Classification results; Remote sensing image classification; Spatial and temporal scale; Sub-pixel mapping; Super-resolution mappings; Pixels","Artificial Bee Colony; Enhancement; Hyperspectral Image Sub-Pixel Mapping; Remote Sensing; Resolution; Subpixel Mapping; Super-Resolution Mapping","Conference paper","Final","","Scopus","2-s2.0-84956979491"
"Wang X.; Sun L.; Lei P.; Ren P.; Fan S.; Zhou Y.","Wang, Xinwei (57193115364); Sun, Liang (56945893500); Lei, Pingshun (42461813700); Ren, Pengdao (57191621799); Fan, Songtao (8592655600); Zhou, Yan (57188685533)","57193115364; 56945893500; 42461813700; 57191621799; 8592655600; 57188685533","Range intensity coding under triangular and trapezoidal correlation algorithms for 3D super-resolution range-gated imaging","2016","Proceedings of SPIE - The International Society for Optical Engineering","9988","","99880U","","","","10.1117/12.2241638","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011102725&doi=10.1117%2f12.2241638&partnerID=40&md5=a43f311bed1478bb2ecef2b367947e08","Three-dimensional super-resolution range-gated imaging (3D SRGI) is a new technique for high-resolution 3D sensing. Up to now, 3D SRGI has been developed with two range-intensity correlation algorithms, including trapezoidal algorithm and triangular algorithm. To obtain high depth-to-resolution ratio of 3D imaging, coding method was developed for 3D SRGI based on the trapezoidal algorithm in 2011. In this paper, we propose the range-intensity coding based on the triangular algorithm and the hybrid range-intensity coding based on the triangular and trapezoidal algorithms. The theoretical models to predict the maximum coding bin number are developed for different coding methods. In the models, the maximum coding bin number is 7 for three coding gate images under the triangular algorithm, and the maximum is extended to 16 under the hybrid algorithm. The coding examples of 7 bins and 16 bins mentioned above are also given in this paper. The comparison among the three coding methods is performed by the depth-to-resolution ratio defined as the ratio between the 3D imaging depth and the product of the range resolution and raw gate image number, and the hybrid coding method has the highest depth-to-resolution ratio. Higher depth-to-resolution ratio means better 3D imaging capability of 3D SRGI. © 2016 SPIE.","Bins; Codes (symbols); Imaging systems; Optical resolving power; Remote sensing; Correlation algorithm; Hybrid algorithms; Intensity coding; Intensity correlation; Intensity profiles; Range-gated imaging; Resolution ratios; Supper resolutions; Image coding","range-intensity coding; supper-resolution; three-dimensional range-gated imaging; trapezoidal range-intensity profile; triangular range-intensity profile","Conference paper","Final","","Scopus","2-s2.0-85011102725"
"Czaja W.; Murphy J.M.; Weinberg D.","Czaja, Wojciech (6603938615); Murphy, James M. (56330281800); Weinberg, Daniel (56825242700)","6603938615; 56330281800; 56825242700","Superresolution of remotely sensed images with anisotropic features","2015","2015 International Conference on Sampling Theory and Applications, SampTA 2015","","","7148904","317","321","4","10.1109/SAMPTA.2015.7148904","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941105574&doi=10.1109%2fSAMPTA.2015.7148904&partnerID=40&md5=3de917f4841d92977c35bd3304bb2532","We consider the problem of superresolution for remotely sensed images. Our ambition is to develop an algorithm that efficiently increases the resolution of an image without introducing artifacts or blurring, and without using any additional information, such as images of the same scene in different modalities or sub-pixel shifts of the same image at lower resolutions. The approach developed in this article is based on analysis of the directional features present in the image that is to be superesolved. The harmonic analytic technique of shearlets is employed in order to efficiently capture the directional information present in the image, which is then used to provide smooth, accurate images at higher resolutions. Our algorithm is compared to the standard superresolution method of bicubic interpolation. We test our algorithm on a remotely sensed image of Gulfport, Mississippi. Our results indicate the superior performance of shearlet-based superresolution algorithms, compared to bicubic interpolation. © 2015 IEEE.","Anisotropy; Image processing; Interpolation; Optical resolving power; Anisotropic features; Bicubic interpolation; Directional information; Remotely sensed images; Shearlets; Super resolution; Super resolution algorithms; Superresolution methods; Remote sensing","anisotropic dictionaries; Image processing; remote sensing; shearlets; superresolution","Conference paper","Final","","Scopus","2-s2.0-84941105574"
"Hu J.; Ge Y.; Chen Y.; Li D.","Hu, Jianlong (55499498100); Ge, Yong (26655529300); Chen, Yuehong (56084228300); Li, Deyu (55704079400)","55499498100; 26655529300; 56084228300; 55704079400","Super-Resolution Land Cover Mapping Based on Multiscale Spatial Regularization","2015","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","8","5","7045474","2031","2039","8","10.1109/JSTARS.2015.2399509","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027948404&doi=10.1109%2fJSTARS.2015.2399509&partnerID=40&md5=6258f9462d3b0dd3c90ee607aff879b1","Super-resolution mapping (SRM) is a method for allocating land cover classes at a fine scale according to coarse fraction images. Based on a spatial regularization framework, this paper proposes a new regularization method for SRM that integrates multiscale spatial information from the fine scale as a smooth term and from the coarse scale as a penalty term. The smooth term is considered a homogeneity constraint, and the penalty term is used to characterize the heterogeneity constraint. Specifically, the smooth term depends on the local fine scale spatial consistency, and is used to smooth edges and eliminate speckle points. The penalty term depends on the coarse scale local spatial differences, and suppresses the over-smoothing effect from the fine scale information while preserving more details (e.g., connectivity and aggregation of linear land cover patterns). We validated our method using simulated and synthetic images, and compared the results to four representative SRM algorithms. Our numerical experiments demonstrated that the proposed method can produce more accurate maps, reduce differences in the number of patches, visually preserve smoother edges and more details, reject speckle points, and suppress over-smoothing. © 2015 IEEE.","Numerical methods; Optical resolving power; Remote sensing; Speckle; Fraction images; heterogeneity; homogeneity; multiscale; regularization; Spatial dependence; Super-resolution mappings; algorithm; heterogeneity; homogeneity; image analysis; land cover; mapping; regulatory framework; remote sensing; speckle; Mapping","Fraction images; heterogeneity; homogeneity; multiscale; regularization; remote sensing; spatial dependence; super-resolution mapping (SRM)","Article","Final","","Scopus","2-s2.0-85027948404"
"Patel R.C.; Joshi M.V.","Patel, Rakesh C. (56334985000); Joshi, Manjunath V. (7202602032)","56334985000; 7202602032","Super-resolution of hyperspectral images using sparse representation and Gabor prior","2016","Journal of Applied Remote Sensing","10","2","026019","","","","10.1117/1.JRS.10.026019","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977652756&doi=10.1117%2f1.JRS.10.026019&partnerID=40&md5=99811d8a9fd6855d1122f6fe38d2a0b0","Super-resolution (SR) as a postprocessing technique is quite useful in enhancing the spatial resolution of hyperspectral (HS) images without affecting its spectral resolution. We present an approach to increase the spatial resolution of HS images by making use of sparse representation and Gabor prior. The low-resolution HS observations consisting of large number of bands are represented as a linear combination of a small number of basis images using principal component analysis (PCA), and the significant components are used in our work. We first obtain initial estimates of SR on this reduced dimension by using compressive sensing-based method. Since SR is an ill-posed problem, the final solution is obtained by using a regularization framework. The novelty of our approach lies in: (1) estimation of optimal point spread function in the form of decimation matrix, and (2) using a new prior called ""Gabor prior"" to super-resolve the significant PCA components. Experiments are conducted on two different HS datasets namely, 31-band natural HS image set collected under controlled laboratory environment and a set of 224-band real HS images collected by airborne visible/infrared imaging spectrometer remote sensing sensor. Visual inspections and quantitative comparison confirm that our method enhances spatial information without introducing significant spectral distortion. Our conclusions include: (1) incorporate the sensor characteristics in the form of estimated decimation matrix for SR, and (2) preserve various frequencies in super-resolved image by making use of Gabor prior. © 2016 Society of Photo-Optical Instrumentation Engineers (SPIE).","Compressed sensing; Image resolution; Matrix algebra; Optical resolving power; Optical transfer function; Principal component analysis; Remote sensing; Spectroscopy; Airborne visible/infrared imaging spectrometers; HyperSpectral; Post-processing techniques; Quantitative comparison; Regularization framework; Spatial; Spectral; Super resolution; Image enhancement","Compressed sensing; Hyperspectral; Remote sensing; Spatial; Spectral; Super-resolution","Article","Final","","Scopus","2-s2.0-84977652756"
"Azam K.; Nezhad Zahra H.","Azam, Karami (56597709000); Nezhad Zahra, Hashemi (57188871697)","56597709000; 57188871697","Superresolution of hyperspectral images using linear spectral unmixing and sparse coding","2015","ACRS 2015 - 36th Asian Conference on Remote Sensing: Fostering Resilient Growth in Asia, Proceedings","","","","","","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964059080&partnerID=40&md5=c0de5dc5ced34274f20994519a72fd35","HSI usually have high spectral and low spatial resolutions. However, multispectral images (MSI) and panchromatic images (PAN) usually have low spectral and high spatial resolutions (because of sensor limitations). In various applications, HSI with high spectral and spatial resolutions are required. In this paper, a new method for superresolution of hyperspectral images using linear spectral unmixing and sparse coding (LSUSC) is introduced. In the proposed method, high spectral resolution features of HSI and high spatial resolution features of MSI and PAN are fused. In this case, the sparse representation of PAN and linear spectral unmixing (LSU) model of HSI and MSI is used in order to construct high resolution HSI (HRHSI). The fusion process of HSI, MSI and PAN are formulated as an ill-posed inverse problem which requires a regularization term or prior information in order to convert into well-posed problem. Briefly in the proposed method, first the LSU algorithm is applied. Second, the sparse representation is considered as a regularization term in an ill-posed inverse problem by constructing proper dictionary. The proposed algorithm is applied to real datasets. Compared with the other state-of-the-art algorithms such as pansharpening methods (component substitution and multiresolution analysis), the proposed method achieves smaller Spectral Angle Mapper (SAM), smaller Error Relative Global Dimensional Synthesis (ERGAS) and higher Peak Signal to Noise Ratio (PSNR).","Codes (symbols); Image coding; Optical resolving power; Remote sensing; Satellite imagery; Signal to noise ratio; Spectral resolution; Spectroscopy; Hyper-spectral images; Linear spectral unmixing; Panchromatic images; Sparse coding; Super resolution; Inverse problems","Hyperspectral images; Linear spectral unmixing; Panchromatic images; Sparse coding; Superresolution","Conference paper","Final","","Scopus","2-s2.0-84964059080"
"Wu W.; Zhao D.; Zhang H.","Wu, Wei (57209634017); Zhao, Dewei (57104105100); Zhang, Huan (57105127500)","57209634017; 57104105100; 57105127500","A novel algorithm of super-resolution image reconstruction based on multi-class dictionaries for natural scene","2015","Proceedings of SPIE - The International Society for Optical Engineering","9815","","981515","","","","10.1117/12.2204775","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957610844&doi=10.1117%2f12.2204775&partnerID=40&md5=c50d228ce70cd6fc7f4d8a32e46d49ae","Super-resolution image reconstruction is an effective method to improve the image quality. It has important research significance in the field of image processing. However, the choice of the dictionary directly affects the efficiency of image reconstruction. A sparse representation theory is introduced into the problem of the nearest neighbor selection. Based on the sparse representation of super-resolution image reconstruction method, a super-resolution image reconstruction algorithm based on multi-class dictionary is analyzed. This method avoids the redundancy problem of only training a hyper complete dictionary, and makes the sub-dictionary more representatives, and then replaces the traditional Euclidean distance computing method to improve the quality of the whole image reconstruction. In addition, the ill-posed problem is introduced into non-local self-similarity regularization. Experimental results show that the algorithm is much better results than state-of-the-art algorithm in terms of both PSNR and visual perception. © 2015 SPIE.","Algorithms; Computation theory; Geographic information systems; Image reconstruction; Information systems; Nearest neighbor search; Optical resolving power; Pattern recognition; Pattern recognition systems; Remote sensing; Ill posed problem; Research significances; sparse learning; Sparse representation; State-of-the-art algorithms; Super resolution; Super resolution image reconstruction algorithm; Super-resolution image reconstruction; Image processing","ill-posed problem; multi-class dictionary; sparse learning; super-resolution","Conference paper","Final","","Scopus","2-s2.0-84957610844"
"Zha G.; Wang H.; Yang Z.; Cheng Y.; Qin Y.","Zha, Guofeng (56369170200); Wang, Hongqiang (35779607700); Yang, Zhaocheng (36995630400); Cheng, Yongqiang (56242314000); Qin, Yuliang (55496667400)","56369170200; 35779607700; 36995630400; 56242314000; 55496667400","Effect analysis and design on array geometry for coincidence imaging radar based on effective rank theory","2016","Proceedings of SPIE - The International Society for Optical Engineering","9901","","99010D","","","","10.1117/12.2234799","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983242825&doi=10.1117%2f12.2234799&partnerID=40&md5=58a66015ea26052099f55aaa351d20d5","As a complementary imaging technology, coincidence imaging radar (CIR) achieves super-resolution in real aperture staring radar imagery via employing the temporal-spatial independent array detecting (TSIAD) signals. The characters of TSIAD signals are impacted by the array geometry and the imaging performance are influenced by the relative imaging position with respect to antennas array. In this paper, the effect of array geometry on CIR system is investigated in detail based on the judgment criteria of the effective rank theory. In course of analyzing of these influences, useful system design guidance about the array geometry is remarked for the CIR system. With the design guidance, the target images are reconstructed based on the Tikhonov regularization algorithm. Simulation results are presented to validate the whole analysis and the efficiency of the design guidance. © 2016 SPIE.","Antenna arrays; Computer vision; Curricula; Design; Geometry; Imaging techniques; Radar; Remote sensing; Tracking radar; Array geometries; Coincidence imaging; Effective rank theory; Imaging performance; Imaging positions; Imaging technology; Super resolution; Tikhonov regularization; Radar imaging","Array geometry design; Coincidence imaging radar; Effective rank theory; Tikhonov regularization algorithm","Conference paper","Final","","Scopus","2-s2.0-84983242825"
"Prudyus I.; Tkachenko V.; Lazko L.; Fabirovskyy S.","Prudyus, Ivan (55920578700); Tkachenko, Viktor (24483931200); Lazko, Leonid (55976471700); Fabirovskyy, Sergiy (55975814000)","55920578700; 24483931200; 55976471700; 55975814000","Sub-pixel based forming of high-resolution images; [Formowanie obrazu wysokiej rozdzielczości przy przetwarzaniu subpikseli]","2015","Przeglad Elektrotechniczny","91","7","","45","48","3","10.15199/48.2015.07.15","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933567763&doi=10.15199%2f48.2015.07.15&partnerID=40&md5=ea4b07fe71e040b9759297c221f8428a","The paper deals with considering the possibility of improving the image forming quality of the objects and scenes in remote sensing systems that works in visible range of waves. The analysis of the influence of the pixel shape aperture on the image formation quality and the ability to improve resolution by sub-pixel processing using inverse filtering and Tikhonov regularization, to enhance high spatial frequencies are conducted. © 2015, Wydawnictwo SIGMA - N O T Sp. z o.o. All rights reserved.","","Image restoration; Inverse problems; Sub-pixel image processing; Super-resolution","Article","Final","","Scopus","2-s2.0-84933567763"
"Sundar K.J.A.; Vaithiyanathan V.; Manickavasagam M.; Sarkar A.K.","Sundar, K. Joseph Abraham (56783941200); Vaithiyanathan, V. (35173624000); Manickavasagam, M. (56955181600); Sarkar, A.K. (56046036800)","56783941200; 35173624000; 56955181600; 56046036800","Enhanced singular value decomposition based fusion for super resolution image reconstruction","2015","Defence Science Journal","65","6","","459","465","6","10.14429/dsj.65.8336","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946718805&doi=10.14429%2fdsj.65.8336&partnerID=40&md5=7bce68adf4ecece247e65b97840fa996","The singular value decomposition (SVD) plays a very important role in the field of image processing for applications such as feature extraction, image compression, etc. The main objective is to enhance the resolution of the image based on Singular Value Decomposition. The original image and the subsequent sub-pixel shifted image, subjected to image registration is transferred to SVD domain. An enhanced method of choosing the singular values from the SVD domain images to reconstruct a high resolution image using fusion techniques is proposesed. This technique is called as enhanced SVD based fusion. Significant improvement in the performance is observed by applying enhanced SVD method preceding the various interpolation methods which are incorporated. The technique has high advantage and computationally fast which is most needed for satellite imaging, high definition television broadcasting, medical imaging diagnosis, military surveillance, remote sensing etc. © 2015, DESIDOC.","Diagnosis; Digital television; High definition television; Image compression; Image enhancement; Image fusion; Image reconstruction; Image registration; Interpolation; Medical imaging; Optical resolving power; Remote sensing; Television broadcasting; Fusion techniques; High resolution image; Interpolation method; Military surveillance; Satellite imaging; Singular values; Super resolution; Super-resolution image reconstruction; Singular value decomposition","Image fusion; Image registration; Interpolation; Singular value decomposition; Super resolution","Article","Final","","Scopus","2-s2.0-84946718805"
"Babacan S.D.; Molina R.; Katsaggelos A.K.","Babacan, S. Derin (18041993800); Molina, Rafael (34870201500); Katsaggelos, Aggelos K. (7102711302)","18041993800; 34870201500; 7102711302","Variational bayesian super-resolution reconstruction","2017","Super-Resolution Imaging","","","","285","314","29","10.1201/9781439819319","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023766132&doi=10.1201%2f9781439819319&partnerID=40&md5=56beb8521ecf5445d45fcda9fd039ae2","In many imaging applications, acquiring an image of a scene with high spatial resolution is not possible due to a number of theoretical and practical limitations. These limitations include for instance the sensor resolution, the Rayleigh resolution limit, the increased cost, data transfer rate, and the amount of shot noise due to the size of the digital sensor, among others. In these cases, super-resolution (SR) methods can be utilized to process one or more low-resolution (LR) images of the scene together to obtain a high-resolution (HR) image. The basic principle of super-resolution is that changes in the LR images caused by the blur and the (camera or scene) motion provide additional data that can be utilized to reconstruct the HR image from the set of LR observations. Super-resolution methods are widely utilized in a number of imaging fields, such as surveillance, remote sensing, medical and nano-imaging. © 2011 by Taylor and Francis Group, LLC.","Data transfer; Data transfer rates; Medical imaging; Optical resolving power; Remote sensing; Shot noise; High resolution image; High spatial resolution; Imaging applications; Low resolution images; Resolution limits; Sensor resolution; Superresolution methods; Variational bayesian; Image processing","","Book chapter","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85023766132"
"Huang W.; Xiao L.; Liu H.; Wei Z.","Huang, Wei (56637310000); Xiao, Liang (9733464300); Liu, Hongyi (54903598800); Wei, Zhihui (55761764700)","56637310000; 9733464300; 54903598800; 55761764700","Hyperspectral imagery super-resolution by compressive sensing inspired dictionary learning and spatial-spectral regularization","2015","Sensors (Switzerland)","15","1","","2041","2058","17","10.3390/s150102041","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921503476&doi=10.3390%2fs150102041&partnerID=40&md5=0e8db0239326a38f3a0207ded3faeadc","Due to the instrumental and imaging optics limitations, it is difficult to acquire high spatial resolution hyperspectral imagery (HSI). Super-resolution (SR) imagery aims at inferring high quality images of a given scene from degraded versions of the same scene. This paper proposes a novel hyperspectral imagery super-resolution (HSI-SR) method via dictionary learning and spatial-spectral regularization. The main contributions of this paper are twofold. First, inspired by the compressive sensing (CS) framework, for learning the high resolution dictionary, we encourage stronger sparsity on image patches and promote smaller coherence between the learned dictionary and sensing matrix. Thus, a sparsity and incoherence restricted dictionary learning method is proposed to achieve higher efficiency sparse representation. Second, a variational regularization model combing a spatial sparsity regularization term and a new local spectral similarity preserving term is proposed to integrate the spectral and spatial-contextual information of the HSI. Experimental results show that the proposed method can effectively recover spatial information and better preserve spectral information. The high spatial resolution HSI reconstructed by the proposed method outperforms reconstructed results by other well-known methods in terms of both objective measurements and visual evaluation. © 2015 by the authors; licensee MDPI, Basel, Switzerland.","Image resolution; Optical resolving power; Remote sensing; Signal reconstruction; Spectroscopy; Compressive sensing; Dictionary learning; Hyper-spectral images; Sparse representation; Spectral similarity; Super resolution; Compressed sensing","Compressive sensing; Dictionary learning; Hyperspectral image; Sparse representation; Spectral similarity; Super-resolution","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84921503476"
"Sharma S.; Sharma S.; Buddhiraju K.M.","Sharma, Shakti (57193503231); Sharma, Shreya (57198535245); Buddhiraju, Krishna Mohan (36815713200)","57193503231; 57198535245; 36815713200","Ant colony optimization for super-resolution of hyperspectral images","2016","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","0","","8071672","","","","10.1109/WHISPERS.2016.8071672","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037526694&doi=10.1109%2fWHISPERS.2016.8071672&partnerID=40&md5=4917ed7b741504e17874e8febf908bad","Remotely sensed images provide synaptic view of the earth's surface to study about the landscape elements. Classification of the ground surface into several classes facilitate in understanding the changes caused by climate, natural and human activities. For this purpose, hyperspectral images provide high spectral information. Due to poor spatial resolution the IFOV of the sensor contains many classes and the spectra obtained are often mixture of two classes. This results in misclassification. In this paper, sub-pixel analysis of hyperspectral images is carried out to deal with the mixed pixel problem. We propose a technique based on Ant Colony Optimization(ACO) which utilizes the spectral information to generate spatially high resolution images. Sub-pixel mapping implies division of mixed pixels into sub-pixels and allocating classes to them based on spatial contiguity and abundance fractions. To solve this spatial optimization problem, ACO has been applied which has shown significant improvement in the classification results. © 2016 IEEE.","Artificial intelligence; Image processing; Independent component analysis; Mapping; Optical resolving power; Pixels; Remote sensing; Spectroscopy; Ant Colony Optimization (ACO); Classification results; High resolution image; Hyperspectral Data; Mixed pixel; Remotely sensed images; Sub-pixel mapping; Super resolution; Ant colony optimization","Ant colony optimization; Hyperspectral data; Mixed pixel; Sub-pixel mapping; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85037526694"
"Yang X.; Wu W.; Gan Z.; Yan B.; Zhang Y.","Yang, Xiaomin (9237988500); Wu, Wei (56386371900); Gan, Zhongliang (15119109300); Yan, Binyu (45961752600); Zhang, Yingying (57196197536)","9237988500; 56386371900; 15119109300; 45961752600; 57196197536","Remote sensing image super-resolution by using sparse dictionary and residual dictionary","2015","Sichuan Daxue Xuebao (Gongcheng Kexue Ban)/Journal of Sichuan University (Engineering Science Edition)","47","3","","71","76","5","10.15961/j.jsuese.2015.03.010","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930069195&doi=10.15961%2fj.jsuese.2015.03.010&partnerID=40&md5=02df9618feacb766dc5f7d90ef4b34d2","A super resolution (SR) method for remote sensing images based on sparse dictionary and structural self-similarity was proposed. Furthermore, compared with correspondence between LR and HR image patches from a conventional SR methods, two dictionary pairs, i. e. primitive sparse dictionary pair and residual sparse dictionary pair, are raining database. The primitive sparse dictionary pair is learned to reconstruct initial high-resolution (HR) remote sensing image from a single low-resolution (LR) input. However, the initial HR remote sensing image loses some details compare with the corresponding original HR image completely. Therefore, residual sparse dictionary pair is learned to reconstruct residual information. Finally, self-similarity structural widely exist in remote sensing images and this feature can be used to correct the reconstructed image by nonlocal means (NLM) method. Experimental results showed that the proposed algorithm provides better subjective and objective quality, when compared to the conventional algorithms and its PSNR is 24.690 5, SSIM is 0.736 3. ©, 2015, Editorial Department of Journal of Sichuan University. All right reserved.","Image denoising; Image reconstruction; Optical resolving power; Conventional algorithms; Dictionary learning; Non local means (NLM); Objective qualities; Reconstructed image; Remote sensing images; Sparse representation; Super resolution; Remote sensing","Dictionary learning; Remote sensing images; Sparse representation; Super-resolution","Article","Final","","Scopus","2-s2.0-84930069195"
"Shin D.; Shapiro J.H.; Goyal V.K.","Shin, Dongeek (55938475500); Shapiro, Jeffrey H. (7402728029); Goyal, Vivek K. (7005469803)","55938475500; 7402728029; 7005469803","Photon-efficient super-resolution laser radar","2017","Proceedings of SPIE - The International Society for Optical Engineering","10394","","1039409","","","","10.1117/12.2273208","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033588173&doi=10.1117%2f12.2273208&partnerID=40&md5=127e13b482472a15d60b0ff714c1a380","The resolution achieved in photon-efficient active optical range imaging systems can be low due to non-idealities such as propagation through a diffuse scattering medium. We propose a constrained optimization-based frame- work to address extremes in scarcity of photons and blurring by a forward imaging kernel. We provide two algorithms for the resulting inverse problem: a greedy algorithm, inspired by sparse pursuit algorithms; and a convex optimization heuristic that incorporates image total variation regularization. We demonstrate that our framework outperforms existing deconvolution imaging techniques in terms of peak signal-to-noise ratio. Since our proposed method is able to super-resolve depth features using small numbers of photon counts, it can be useful for observing fine-scale phenomena in remote sensing through a scattering medium and through-the-skin biomedical imaging applications. © 2017 SPIE.","Constrained optimization; Convex optimization; Deconvolution; Heuristic algorithms; Image resolution; Image segmentation; Imaging techniques; Inverse problems; Medical imaging; Photons; Radar imaging; Remote sensing; Signal to noise ratio; Biomedical imaging applications; Diffuse scattering; Greedy algorithms; Peak signal to noise ratio; Pursuit algorithms; Scattering medium; Super resolution; Total variation regularization; Optimization","","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85033588173"
"Hu S.; Zhang S.; Zhang A.; Chai S.","Hu, Shaoxing (55779602800); Zhang, Shuyu (57193263639); Zhang, Aiwu (7402772582); Chai, Shatuo (55430230200)","55779602800; 57193263639; 7402772582; 55430230200","Hyperspectral imagery super-resolution by adaptive pocs and blur metric","2017","Sensors (Switzerland)","17","1","82","","","","10.3390/s17010082","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012113150&doi=10.3390%2fs17010082&partnerID=40&md5=64ff14d3e429253b66d310ba2be9ece1","The spatial resolution of a hyperspectral image is often coarse as the limitations on the imaging hardware. A novel super-resolution reconstruction algorithm for hyperspectral imagery (HSI) via adaptive projection onto convex sets and image blur metric (APOCS-BM) is proposed in this paper to solve these problems. Firstly, a no-reference image blur metric assessment method based on Gabor wavelet transform is utilized to obtain the blur metric of the low-resolution (LR) image. Then, the bound used in the APOCS is automatically calculated via LR image blur metric. Finally, the high-resolution (HR) image is reconstructed by the APOCS method. With the contribution of APOCS and image blur metric, the fixed bound problem in POCS is solved, and the image blur information is utilized during the reconstruction of HR image, which effectively enhances the spatial-spectral information and improves the reconstruction accuracy. The experimental results for the PaviaU, PaviaC and Jinyin Tan datasets indicate that the proposed method not only enhances the spatial resolution, but also preserves HSI spectral information well. © 2017 by the authors; licensee MDPI, Basel, Switzerland.","Hyperspectral imaging; Image processing; Image reconstruction; Image resolution; Optical resolving power; Remote sensing; Set theory; Spectroscopy; Wavelet transforms; Gabor wavelet transforms; Hyper-spectral imageries; Image blur; Super resolution; Weighted POCS; article; diagnostic test accuracy study; human; human experiment; imagery; reconstruction algorithm; wavelet transform; Image compression","Gabor wavelet transform; Hyperspectral imagery; Image blur metric; Super-resolution; Weighted POCS","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85012113150"
"Shkvarko Y.V.; Yanez J.I.; Martin Del Campo G.D.","Shkvarko, Y.V. (6701493067); Yanez, J.I. (55810827500); Martin Del Campo, G.D. (55811052100)","6701493067; 55810827500; 55811052100","Multiframe resolution recovery of radar imagery: Towards super-resolution sensing","2015","International Geoscience and Remote Sensing Symposium (IGARSS)","2015-November","","7326824","4487","4490","3","10.1109/IGARSS.2015.7326824","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962505202&doi=10.1109%2fIGARSS.2015.7326824&partnerID=40&md5=b25ed819cf813fe9e04f93b15f69102c","The aim of this study is to address a new approach and develop the relevant technique for super-resolution (SR) feature-enhanced recovery of microwave remote sensing (RS) imagery. The challenging proposition is twofold. First, we adapt the SR multi-scale iterative reconstructive (MSIR) image post-processing method for solving the inverse problem of recovery of the speckle corrupted low resolution RS images employing iterative projections onto the nested refined resolution frames. Second, we unify the modified RS-adapted MSIR method with the Descriptive Experiment Design Regularization (DEDR) high-resolution RS image enhancement technique for attaining the overall SR recovery with considerably enhanced resolution performances. Algorithmically, the MSIR processing loop is performed via the Fourier transform (FT) or wavelet transform (WT) of the input image. Different wavelet dictionaries were examined in order to approach the most speeded-up WT-based iterative MSIR-level image recovery. © 2015 IEEE.","","Fourier/wavelet transform; multi-scale iterative image recovery; remote sensing; super-resolution","Conference paper","Final","","Scopus","2-s2.0-84962505202"
"Iyanda C.A.; Yaakob S.N.B.; Nawir M.","Iyanda, Comfort Abiodun (57193140227); Yaakob, Shahrul Nizam Bin (55394447500); Nawir, Mukrimah (57193134132)","57193140227; 55394447500; 57193134132","Uniqueness of iterative back projection in super resolution techniques","2017","2016 3rd International Conference on Electronic Design, ICED 2016","","","7804696","501","506","5","10.1109/ICED.2016.7804696","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011017706&doi=10.1109%2fICED.2016.7804696&partnerID=40&md5=0a12bcbe8b3d691f24a0e1c7566d5a9b","Despite the recent plethora of empirical attempt at improving image quality in the emerging image processing field, image resolution is pressingly fraught with dire challenges today. Image enhancement research remained progressive because of the advancement in contemporary globalization that mandates an improvement in image quality and it becomes essential to run the best quality of image in some applications such as in forensic unit where in order to obtain the best information, image has to be enlarged in terms of size. Degraded image, often occasioned by motion blur, inaccurate focusing and sensor noise aggregate during the process of acquiring image through an image acquisition device (Camera). The improvisational capacity of super resolution imaging algorithm compensates this degradations by reconstructing a high resolution image from honing and harnessing single or multiple low resolution image to facilitate and foster enhanced visual contents and scene recognitions. High quality images are required in applications of different fields, such as remote sensing, satellite imaging, surveillance, medical imaging, etc. This paper attempts a conceptual enquiry and presents an overview of the conventional techniques of super resolution, how the techniques works along with their pros and cons accordingly, recent improvements carried out by different researchers are dutifully delineated. The Iterative back projection (IBP) method is hereby suggested a promising super resolution method due to its unique features highlighted. © 2016 IEEE.","Image acquisition; Image enhancement; Image quality; Image reconstruction; Image resolution; Iterative methods; Medical imaging; Optical resolving power; Remote sensing; Conventional techniques; High resolution; Iterative back projections; Low resolution; Low resolution images; Super resolution; Super resolution imaging; Superresolution methods; Image processing","High resolution; Image enhancement; Iterative back projection; Low resolution; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85011017706"
"Khateri M.; Ghassemian H.","Khateri, Mohammad (57191841088); Ghassemian, Hassan (57204122949)","57191841088; 57204122949","A self-learning approach for pan-sharpening of multispectral images","2017","Proceedings of the 2017 IEEE International Conference on Signal and Image Processing Applications, ICSIPA 2017","","","","199","204","5","10.1109/ICSIPA.2017.8120606","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041385878&doi=10.1109%2fICSIPA.2017.8120606&partnerID=40&md5=bcebf9863f711462e763f5332118d85c","Due to the importance of high-resolution multi-spectral (HRM) images in many remote sensing applications, pan-sharpening techniques have been proposed to increase the spatial resolution of a low-resolution multi-spectral (LRM) image using a high-resolution panchromatic (HRP) image. In this paper, we propose a self-learning approach to pan-sharpen the LRM images. Many structures in a natural image redundantly tend to repeat in the same scale as well as different scales. These similar structures in different levels can be used to reconstruct the HRM bands with more details; in this perspective, we can construct the HRM data from the available HRP and LRM data by using self-similarity in a multi-scale procedure. The proposed method has been applied on GeoEye-1 data and DEIMOS-2 data, and then fused images compared with some popular and state-of-The-Art methods in terms of several assessment indexes. The experimental results demonstrate that the proposed method can retain spectral and spatial information of the source images efficiently. © 2017 IEEE.","Data fusion; Image fusion; Remote sensing; multi-scale; Multi-spectral data; Pan-sharpening; Panchromatic data; Self-learning; Super resolution; Image processing","image fusion; multi-scale; multi-spectral data; Pan-sharpening; panchromatic data; self-learning; superresolution","Conference paper","Final","","Scopus","2-s2.0-85041385878"
"Zhao Y.; Yi C.; Yang J.","Zhao, Yongqiang (35365726800); Yi, Chen (56421324300); Yang, Jingxiang (55964111200)","35365726800; 56421324300; 55964111200","Jointly spatial-spectral resolution enhancement of hyperspectral imagery","2015","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2015-June","","8075455","","","","10.1109/WHISPERS.2015.8075455","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039154455&doi=10.1109%2fWHISPERS.2015.8075455&partnerID=40&md5=6b44af20075971ecb0f88061d711cdaa","For hyperspectral image, low spatial and spectral resolution will cause inaccurate object detection and classification. In this paper, a novel jointly spatial-spectral resolution enhancement algorithm is proposed to promote the spatial resolution and spectral resolution simultaneously, high spatial resolution information from panchromatic image is used as constraint in spectral enhancement while the high spectral resolution details are benefited for spatial enhancement, which makes spatial SR and spectral SR promote each other. The experiments prove that our algorithm can provide joint spatial-spectral enhanced results, which can outperform the state-of-art methods both in spatial and spectral domains. © 2015 IEEE.","Hyperspectral imaging; Image resolution; Object detection; Remote sensing; Spectral resolution; Spectroscopy; High spatial resolution; High spectral resolution; Hyper-spectral imageries; Resolution enhancement; Sparse representation; Spectral enhancement; Super resolution; Unmixing; Image enhancement","Hyperspectral image; sparse representation; spatial-spectral super resolution; unmixing","Conference paper","Final","","Scopus","2-s2.0-85039154455"
"Simoes M.; Bioucas-Dias J.; Almeida L.B.; Chanussot J.","Simoes, Miguel (56376643900); Bioucas-Dias, Jose (55901520500); Almeida, Luis B. (35915994300); Chanussot, Jocelyn (6602159365)","56376643900; 55901520500; 35915994300; 6602159365","A convex formulation for hyperspectral image superresolution via subspace-based regularization","2015","IEEE Transactions on Geoscience and Remote Sensing","53","6","7000523","3373","3388","15","10.1109/TGRS.2014.2375320","438","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027944334&doi=10.1109%2fTGRS.2014.2375320&partnerID=40&md5=4c2f6b99ab412eb77e2d5fa0e80dd218","Hyperspectral remote sensing images (HSIs) usually have high spectral resolution and low spatial resolution. Conversely, multispectral images (MSIs) usually have low spectral and high spatial resolutions. The problem of inferring images that combine the high spectral and high spatial resolutions of HSIs and MSIs, respectively, is a data fusion problem that has been the focus of recent active research due to the increasing availability of HSIs and MSIs retrieved from the same geographical area. We formulate this problem as the minimization of a convex objective function containing two quadratic data-fitting terms and an edge-preserving regularizer. The data-fitting terms account for blur, different resolutions, and additive noise. The regularizer, a form of vector total variation, promotes piecewise-smooth solutions with discontinuities aligned across the hyperspectral bands. The downsampling operator accounting for the different spatial resolutions, the nonquadratic and nonsmooth nature of the regularizer, and the very large size of the HSI to be estimated lead to a hard optimization problem. We deal with these difficulties by exploiting the fact that HSIs generally 'live' in a low-dimensional subspace and by tailoring the split augmented Lagrangian shrinkage algorithm (SALSA), which is an instance of the alternating direction method of multipliers (ADMM), to this optimization problem, by means of a convenient variable splitting. The spatial blur and the spectral linear operators linked, respectively, with the HSI and MSI acquisition processes are also estimated, and we obtain an effective algorithm that outperforms the state of the art, as illustrated in a series of experiments with simulated and real-life data. © 1980-2012 IEEE.","Additive noise; Constrained optimization; Data fusion; Data handling; Image reconstruction; Mathematical operators; Optical resolving power; Optimization; Remote sensing; Spectral resolution; Spectroscopy; Alternating direction method of multipliers; Hyperspectral Imaging; Nonsmooth optimization; Super resolution; Total variation; algorithm; data acquisition; geographical region; optimization; remote sensing; spectral resolution; Vectors","Alternating direction method of multipliers (ADMM); convex nonsmooth optimization; data fusion; hyperspectral imaging; superresolution; Vector total variation (VTV)","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85027944334"
"Merugu S.; Jain K.","Merugu, Suresh (56658583800); Jain, Kamal (56658294100)","56658583800; 56658294100","A New Super Resolution Mapping Algorithm by Combining Pixel and Subpixel-Level Spatial Dependences With Colorimetry","2015","Journal of the Indian Society of Remote Sensing","43","2","411","259","268","9","10.1007/s12524-014-0412-6","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929993156&doi=10.1007%2fs12524-014-0412-6&partnerID=40&md5=9d3b96e6f4b8432274da2ff503d1a837","Super resolution mapping is a continuously growing area of remote sensing. Satellite images coupled with a very high spectral resolution, and are suitable for detection and classification of surfaces and different elements in the observed image. The main problem with high resolution data for these applications is the (relatively) low spatial resolution, which can vary from a few to tens of meters. In the case of classification purposes, the major problem caused by low spatial resolution is related to subpixels, i.e., pixels in the image where more than one land cover class is within the same pixel. In such a case, the pixel cannot be considered as belonging to just one class, and the assignment of the pixel to a single class will inevitably lead to a loss of information, no matter what class is chosen. A new super resolution mapping (SRM) algorithm by combining pixel and subpixel-level spatial dependences with colorimetry is proposed in this paper. The pixel-level dependence is measured by the spatial attraction model with either surrounding or quadrant neighborhood, while the subpixel-level dependence is characterized by either the mean filter or the exponential weighting function. Both pixel-level and subpixel-level dependences are then fused as the weighted dependence for quickly obtaining the optimal spatial distribution of subpixels by employing the colorimetric algorithm. Synthetic imagery and a QuickBird image are tested for validation of the proposed method. The results demonstrate that the proposed method can achieve results with greater accuracy than two traditional subpixel mapping (SPM) methods and the mixed spatial attraction model method. Meanwhile, the proposed method needs considerably less computation time than the conventional mixed spatial attraction model method, and hence it provides a new solution to subpixel land cover mapping. © 2014, Indian Society of Remote Sensing.","algorithm; colorimetry; land cover; mapping method; pixel; QuickBird; satellite imagery; spatial distribution; spatial resolution","Colorimetry; Spatial dependences and satellite imagery; Subpixel classification; Super resolution mapping","Article","Final","","Scopus","2-s2.0-84929993156"
"","","","Proceedings of SPIE - The International Society for Optical Engineering","2016","Proceedings of SPIE - The International Society for Optical Engineering","10004","","","","","700","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011347790&partnerID=40&md5=20f635c647e0589fb673a8a7fe21be9e","The proceedings contain 64 papers. The topics discussed include: geocoding uncertainty analysis for the automated processing of Sentinel-1 data using Sentinel-1 toolbox software; evaluation of georeferencing methods with respect to their suitability to address unsimilarity between the image to be referenced and the reference image; pansharpening remotely sensed data by using nonnegative matrix factorization and spectral-spatial degradation models; resolution enhancement of tri-stereo remote sensing images by super resolution methods; a novel feature extraction methodology for region classification in lidar data; a novel approach to internal crown characterization for coniferous tree species classification; domain adaptation based on deep denoising auto-encoders for classification of remote sensing images; regions-of-interest extraction from remote sensing imageries using visual attention modelling; accuracy assessment of blind and semi-blind restoration methods for hyperspectral images; unsupervised component reduction of hyperspectral images and clustering without performance loss: application to marine algae identification; an end-user-oriented framework for RGB representation of multitemporal SAR images and visual data mining; estimation of ice sheet attenuation by using radar sounder and ice core data; and analysis of the electronic crosstalk effect in terra MODIS long-wave infrared photovoltaic bands using lunar images.","","","Conference review","Final","","Scopus","2-s2.0-85011347790"
"Xuan V.N.; Hartmann K.; Weihs W.; Loffeld O.","Xuan, Vinh Nguyen (57188806690); Hartmann, Klaus (36170781100); Weihs, Wolfgang (24287276300); Loffeld, Otmar (7003978381)","57188806690; 36170781100; 24287276300; 7003978381","Multi-target super-resolution using compressive sensing arguments for multipath interference recovery","2016","2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing, CoSeRa 2016","","","7745718","148","152","4","10.1109/CoSeRa.2016.7745718","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002730872&doi=10.1109%2fCoSeRa.2016.7745718&partnerID=40&md5=89e8c292b71d9d44951d77eae2074514","The multipath interference (MPI) adds noises to the time-of-flight (TOF) measurements and then causes depth estimation inaccuracy. This paper combines multi-frequency TOF (MFT) acquisition and compressive sensing (CS) approaches to reconstruct the multipath reflections. Mismatch model and depth resolution problems will be analyzed to achieve a good measurement accuracy with a high probability. © 2016 IEEE.","Multipath propagation; Optical resolving power; Radar; Remote sensing; Signal interference; Signal reconstruction; Sonar; Measurement accuracy; Multi frequency; Multi-path interference; Multipath; Multipath interferences; Multipath reflections; Super resolution; Time of flight measurements; Compressed sensing","compressed sensing; multi-frequency; multipath; super-resolution; time-of-light","Conference paper","Final","","Scopus","2-s2.0-85002730872"
"Yang D.; Li Z.; Xia Y.; Chen Z.","Yang, Daiqin (56151910900); Li, Zimeng (57885024500); Xia, Yatong (56377152600); Chen, Zhenzhong (55737671700)","56151910900; 57885024500; 56377152600; 55737671700","Remote sensing image super-resolution: Challenges and approaches","2015","International Conference on Digital Signal Processing, DSP","2015-September","","7251858","196","200","4","10.1109/ICDSP.2015.7251858","43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961333327&doi=10.1109%2fICDSP.2015.7251858&partnerID=40&md5=35019a35097302201954a03cd806a2a0","Remote sensing has a growing relevance in the modern society with the development of image processing of satellite imagery. However, due to the limitations of the current imaging sensors and the complex atmospheric conditions, we are facing great challenges in the remote sensing applications due to the limited spatial, spectral, radiometric and temporal resolutions. Therefore, super-resolution techniques have attracted much attention by which the low quality low resolution remote sensing images are enhanced. In this paper, we discuss the challenges in remote sensing image super-resolution and thereafter review the relevant approaches. More specifically, the different categories of remote sensing techniques, i.e., the learning-based, interpolation based, frequency domain based, and probability based methods, are reviewed and discussed. Furthermore, the super-resolution applications are discussed and insightful comments on future research directions are provided. © 2015 IEEE.","Digital signal processing; Frequency domain analysis; Image processing; Image reconstruction; Optical resolving power; Satellite imagery; Signal processing; Atmospheric conditions; Future research directions; Observation model; Remote sensing applications; Remote sensing images; Remote sensing techniques; Super resolution; Temporal resolution; Remote sensing","observation model; remote sensing; Super resolution","Conference paper","Final","","Scopus","2-s2.0-84961333327"
"Karachevtseva I.P.; Kokhanov A.A.; Rodionova J.F.; Zharkova A.Yu.; Lazareva M.S.","Karachevtseva, I.P. (55794052200); Kokhanov, A.A. (56059616000); Rodionova, J.F. (56502281300); Zharkova, A.Yu. (57190177585); Lazareva, M.S. (57214375299)","55794052200; 56059616000; 56502281300; 57190177585; 57214375299","Mapping of inner and outer celestial bodies using new global and local topographic data derived from photogrammetric image processing","2016","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","41","","","411","415","4","10.5194/isprsarchives-XLI-B4-411-2016","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978079823&doi=10.5194%2fisprsarchives-XLI-B4-411-2016&partnerID=40&md5=ea2c36a939f6a9d0c3de4a2c8597d80e","New estimation of fundamental geodetic parameters and global and local topography of planets and satellites provide basic coordinate systems for mapping as well as opportunities for studies of processes on their surfaces. The main targets of our study are Europa, Ganymede, Calisto and Io (satellites of Jupiter), Enceladus (a satellite of Saturn), terrestrial planetary bodies, including Mercury, the Moon and Phobos, one of the Martian satellites. In particular, based on new global shape models derived from three-dimensional control point networks and processing of high-resolution stereo images, we have carried out studies of topography and morphology. As a visual representation of the results, various planetary maps with different scale and thematic direction were created. For example, for Phobos we have produced a new atlas with 43 maps, as well as various wall maps (different from the maps in the atlas by their format and design): basemap, topography and geomorphological maps. In addition, we compiled geomorphologic maps of Ganymede on local level, and a global hypsometric Enceladus map. Mercury's topography was represented as a hypsometric globe for the first time. Mapping of the Moon was carried out using new images with super resolution (0.5-1 m/pixel) for activity regions of the first Soviet planetary rovers (Lunokhod-1 and -2). New results of planetary mapping have been demonstrated to the scientific community at planetary map exhibitions (Planetary Maps Exhibitions, 2015), organized by MExLab team in frame of the International Map Year, which is celebrated in 2015-2016. Cartographic products have multipurpose applications: for example, the Mercury globe is popular for teaching and public outreach, the maps like those for the Moon and Phobos provide cartographic support for Solar system exploration.","Geodetic satellites; Geomorphology; Image processing; Interplanetary flight; Mapping; Maps; Mercury (metal); Moon; Photogrammetry; Planets; Remote sensing; Solar system; Stereo image processing; Topography; Enceladus; Geodetic parameters; High resolution stereo; Phobos; Planets and satellites; Scientific community; Solar system exploration; Visual representations; Satellites","DEM; Ganymede and enceladus; Geomorphology study; Mercury; Phobos; Planetary cartography; The moon","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-84978079823"
"Li X.; Du Y.; Ling F.; Li W.","Li, Xiaodong (55878368700); Du, Yun (56420121700); Ling, Feng (56278268300); Li, Wenbo (57207126023)","55878368700; 56420121700; 56278268300; 57207126023","Locally adaptive linear mixture model-based super-resolution land-cover mapping based on a structure tensor","2016","International Journal of Remote Sensing","37","24","","5802","5825","23","10.1080/01431161.2016.1249305","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997428731&doi=10.1080%2f01431161.2016.1249305&partnerID=40&md5=919d3f21e25d4c4ef3313be964bcfdfd","Super-resolution land-cover mapping (SRM) is a technique for generating land-cover thematic maps with a finer spatial resolution than the input image. Linear mixture model-based SRM (LSRM) is applied directly to a remotely sensed image and is composed of a spatial term that integrates the land-cover spatial pattern prior information, a spectral term that assumes that the spectral signature of each mixed pixel is composed of a weighted linear sum of endmember spectral signatures within that pixel and a balance parameter that defines the weight of the spatial term. The traditional LSRM adopts an isotropic spatial autocorrelation model in the land-cover spatial term for different classes and a fixed balance parameter for the entire image, and ignores the image local properties. The class boundaries are at risk of oversmoothing and may be imprecise, and the homogeneous regions may be unsmoothed and contain speckle-like artefacts in the result. This study proposes a locally adaptive LSRM (LA-LSRM) that integrates image local properties to predict fine spatial resolution pixel labels. The structure tensor is applied to detect the image local information. The LA-LSRM spatial term is locally adaptive and is composed of an anisotropic spatial autocorrelation model in which the spatial autocorrelation orientations of different classes may vary. The LA-LSRM balance parameter is locally adaptive to the different regions of the image. Such parameter obtains a relatively large value when the fine-resolution pixel is located in the homogeneous region to remove speckle-like artefacts and a relatively small value when the fine-resolution pixel is at the class boundary to preserve the edge. The LA-LSRM performance was assessed using a simulated multi-spectral image, an IKONOS multi-spectral image, a hyperspectral image produced by Airborne Visible/Infrared Imaging Spectrometer and a hyperspectral image produced by reflective optics system imaging spectrometer. Results show that the homogeneous regions were smoothed, the boundaries were better preserved and the overall accuracies were increased by LA-LSRM compared with traditional LSRM in all experiments. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","Autocorrelation; Hyperspectral imaging; Image processing; Image resolution; Maps; Mixtures; Optical resolving power; Pixels; Speckle; Spectrometers; Spectroscopy; Tensors; Airborne visible/infrared imaging spectrometers; Homogeneous regions; Imaging spectrometers; Land cover mapping; Linear mixture modeling; Multispectral images; Remotely sensed images; Spatial autocorrelations; autocorrelation; land cover; numerical model; pixel; remote sensing; spatial resolution; thematic mapping; Mapping","","Article","Final","","Scopus","2-s2.0-84997428731"
"","","","Proceedings - International Conference on Machine Learning and Cybernetics","2015","Proceedings - International Conference on Machine Learning and Cybernetics","1","","","","","932","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020743645&partnerID=40&md5=74a51362e0b0b3044ee26b389efe3acc","The proceedings contain 153 papers. The topics discussed include: prediction of protein structural classes by decreasing nearest neighbor error rate; parameter learning for ant colony optimization to minimal time cost reduction; graph k-means with lost cluster approach for nonlinear manifold clustering; a matroidal structure for formal context and its applications on epidemiological study; morphological component analysis and least squares support vector machine for image super-resolution; selection of initial parameters of k-means clustering algorithm for MRI brain image segmentation; classification on Tiangong-1 hyperspectral remote sensing image via contextual sparse coding; information fusion in multi-source fuzzy information system with same structure; an effective and efficient grid-based data clustering algorithm using intuitive neighbor relationship for data mining; a study of hand gesture recognition with wireless channel modeling by using wearable devices; biclustering analysis of gene expression data using multi-objective evolutionary algorithms; fusion based approach to discovering social circles in ego networks; a new adaptive fuzzy neural force controller for robots manipulator interacting with environments; image segmentation with texture clustering based JSEG; and automatic Chinese dialog acts recognition with multiple kernel learning.","","","Conference review","Final","","Scopus","2-s2.0-85020743645"
"Aghighi H.; Trinder J.; Lim S.; Tarabalka Y.","Aghighi, H. (25227285900); Trinder, J. (57203069424); Lim, S. (14827020900); Tarabalka, Y. (24512498300)","25227285900; 57203069424; 14827020900; 24512498300","Fully spatially adaptive smoothing parameter estimation for Markov random field super-resolution mapping of remotely sensed images","2015","International Journal of Remote Sensing","36","11","","2851","2879","28","10.1080/01431161.2015.1049381","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934300957&doi=10.1080%2f01431161.2015.1049381&partnerID=40&md5=d2e7190e1f4caad23bd5cbcc66301a7b","This article presents a fully spatially adaptive Markov random field (MRF)-based super-resolution mapping (SRM) technique to produce land-cover maps at a finer spatial resolution than the original coarse-resolution image. MRF combines the spectral and spatial energies; hence, an MRF-SRM technique requires a smoothing parameter to manage the contributions of these energies. The main aim of this article is to introduce a new method called fully spatially adaptive MRF-SRM to automatically determine the smoothing parameter, overcoming limitations of the previously proposed approaches. This method estimates the number of endmembers in each image and uses them to assess the proportions of classes within each coarse pixel by a linear spectral unmixing method. Then, the real pixel intensity vectors and the local properties of each coarse pixel are used to compute the local spectral energy change matrix and the local spatial energy change matrix for each coarse pixel. Each pair of matrices represents all possible situations in spatial and spectral energy change for each coarse pixel and can be used to examine the balance between spatial and spectral energies, and hence to estimate a smoothing parameter for each coarse pixel. Thus, the estimated smoothing parameter is fully spatially adaptive with respect to real pixel spectral vectors and their local properties. The performance of this method is evaluated using two synthetic images and an EO1-ALI (The Advanced Land Imager instrument on Earth Observing-1 satellite) multispectral remotely sensed image. Our experiments show that the proposed method outperforms the state-of-the-art techniques. © 2015 Taylor & Francis.","Markov processes; Matrix algebra; Optical resolving power; Parameter estimation; Pixels; Remote sensing; Advanced land imagers; Linear spectral unmixing; Markov Random Fields; Remotely sensed images; Smoothing parameter; Spatially adaptive; State-of-the-art techniques; Super-resolution mappings; Mapping","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84934300957"
"","","","Proceedings of SPIE - The International Society for Optical Engineering","2016","Proceedings of SPIE - The International Society for Optical Engineering","9988","","","","","304","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011103121&partnerID=40&md5=5d85b5106dbf5424ac6e43f75ec8b323","The proceedings contain 30 papers. The topics discussed include: automated object detection and tracking with a flash LiDAR system; penetration of pyrotechnic effects with SWIR laser gated viewing in comparison to VIS and thermal IR bands; image enhancement and color constancy for a vehicle-mounted change detection system; reconstruction method of compressed sensing for remote sensing images cooperating with energy compensation; effect of optical turbulence along a downward slant path on probability of laser hazard; noncontact thermoacoustic detection of targets embedded in dispersive media; optimization design and evaluation specifications analysis for the optical remote system with a high spatial resolution; high sensitivity InAs photodiodes for mid-infrared detection; real-time detection of small and dim moving objects in IR video sequences using a robust background estimator and a noise-adaptive double thresholding; compressed sensing for super-resolution spatial and temporal laser detection and ranging; evaluating automatic registration of UAV imagery using multi-temporal ortho images; importance of using field spectroscopy to support the satellite remote sensing for underground structures intended for security reasons in the eastern Mediterranean region; and range intensity coding under triangular and trapezoidal correlation algorithms for 3D super-resolution range gated imaging.","","","Conference review","Final","","Scopus","2-s2.0-85011103121"
"Huang N.; Yang Y.; Liu J.; Gu X.; Cai H.","Huang, Ningbo (57193711665); Yang, Yong (57197835686); Liu, Junjie (57197825848); Gu, Xinchao (57193710683); Cai, Hua (56195429500)","57193711665; 57197835686; 57197825848; 57193710683; 56195429500","Single-Image Super-Resolution for Remote Sensing Data Using Deep Residual-Learning Neural Network","2017","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10635 LNCS","","","622","630","8","10.1007/978-3-319-70096-0_64","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035090889&doi=10.1007%2f978-3-319-70096-0_64&partnerID=40&md5=105c9596f036ca649b9abab26886c1a5","Single image super-resolution (SISR) plays an important role in remote sensing image processing. In recent years, deep convolutional neural networks have achieved state-of-the-art performance in the SISR field of common camera images. Although the SISR method based on deep learning is effective on general camera images, it is not necessarily effective on remote sensing images because of the significant difference between remote sensing images and common camera images. In this paper, the VDSR network (proposed by Kim et al. in 2016) was found to be invalid for Sentinel-2A remote sensing images; we then proposed our own neural network, which is called the remote sensing deep residual-learning (RS-DRL) network. Our network achieved better performance than VDSR on Sentinel-2A remote sensing images. © 2017, Springer International Publishing AG.","Cameras; Convolution; Deep neural networks; Image processing; Neural networks; Optical resolving power; Convolution neural network; Convolutional neural network; Learning neural networks; Remote sensing image processing; Residual-Learning; Sentinel-2A; Single images; State-of-the-art performance; Remote sensing","Deep convolution neural network; Residual-Learning; Sentinel-2A; Single-Image Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85035090889"
"Yanovsky I.; Lambrigtsen B.H.; Tanner A.B.; Vese L.A.","Yanovsky, Igor (16403652300); Lambrigtsen, Bjorn H. (6603478504); Tanner, Alan B. (7103174511); Vese, Luminita A. (6602096082)","16403652300; 6603478504; 7103174511; 6602096082","Efficient Deconvolution and Super-Resolution Methods in Microwave Imagery","2015","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","8","9","7109125","4273","4283","10","10.1109/JSTARS.2015.2424451","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929598461&doi=10.1109%2fJSTARS.2015.2424451&partnerID=40&md5=b9f285a94710ea4f88f76fe707b1aed1","In this paper, we develop efficient deconvolution and super-resolution methodologies, and apply these techniques to reduce image blurring and distortion inherent in an aperture synthesis system. Such a system produces ringing at sharp edges and other transitions in the observed field. The conventional approach to suppressing sidelobes is to apply linear apodization, which has the undesirable side effect of degrading spatial resolution. We have developed an efficient total variation minimization technique based on Split Bregman deconvolution that reduces image ringing while sharpening the image and preserving information content. The model was generalized to include upsampling of deconvolved images to a higher resolution grid. Furthermore, a proposed multiframe super-resolution method is presented that is robust to image noise and noise in the point spread function, and leads to additional improvements in spatial resolution. Our super-resolution methodologies are based on current research in sparse optimization and compressed sensing, which lead to unprecedented efficiencies for solving image reconstruction problems. © 2015 IEEE.","Compressed sensing; Deconvolution; Image reconstruction; Image resolution; Optical resolving power; Optical transfer function; Conventional approach; Information contents; Reconstruction problems; Sparse optimizations; Spatial resolution; Superresolution methods; Suppressing side-lobes; Total variation minimization; deconvolution; image resolution; microwave imagery; noise; optimization; remote sensing; spatial resolution; Image processing","Aperture synthesis system; inverse problems; microwave imaging; remote sensing; sparse optimization; spatial resolution; super-resolution","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-84929598461"
"Lanaras C.; Baltsavias E.; Schindler K.","Lanaras, Charis (56568192000); Baltsavias, Emmanuel (6603939930); Schindler, Konrad (8557497200)","56568192000; 6603939930; 8557497200","Estimating the relative spatial and spectral sensor response for hyperspectral and multispectral image fusion","2016","37th Asian Conference on Remote Sensing, ACRS 2016","1","","","455","463","8","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018299301&partnerID=40&md5=02e40050b356eefe4cb253cc158de105","In the framework of our research, we process jointly high spectral (hyperspectral) and high geometric (multispectral) resolution images with lower and higher spatial resolution respectively, exploiting their synergies, with aims to (a) generate a fused image of high spectral and geometric resolution, and (b) to improve spectral unmixing at sub-pixel level of hyperspectral images regarding estimation of endmembers and fractional abundances. To relate the two images much of the existing research work assumes that the spatial and spectral characteristics (responses) of the two sensors are known in advance. This assumption is true only for simulated data. When moving to real data, however, it is not obvious that the exact spatial and spectral sensor characteristics are accessible. The aim of this concrete work is to derive the relative sensor responses from the data, given (approximately) co-registered images. Recovering the relative spatial response amounts to reconstructing the 2D spatial blur kernel that integrates multispectral pixels into hyperspectral pixels. Conversely, to recover the relative spectral response we estimate the shapes and sizes of the 1D kernels that integrate hyperspectral bands into multispectral bands. The spectral and spatial response functions are coupled, in the sense that one must be known in order to directly solve for the other. In practice, we find that estimating them in two consecutive steps is sufficient. The proposed formulation includes non-negativity and other constraints, recovers remaining registration (translation) errors between the two images, and uses prior information to adjust to the shape of the spectral response (rectangular or ramp shaped) with either l1 or l2 norm regularization. The proposed method is tested with both real and simulated data, aerial, close-range and satellite, in the second case with ground truth. The results show that, also under real-world imaging conditions, it appears possible to compute the relative spatial and spectral responses in a data-driven manner.","Image processing; Pixels; Remote sensing; Spectroscopy; Geometric resolution; HyperSpectral; Multi-spectral image fusions; Relative spectral response; Sensor response; Spatial response functions; Spectral characteristics; Super resolution; Image fusion","Hyperspectral; Image fusion; Relative sensor response; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85018299301"
"Saika Y.","Saika, Yohei (16644029800)","16644029800","Monte Carlo simulation for phase unwrapping using super-resolution for remote sensing using synthetic aperture radar interferometry","2015","ICCAS 2015 - 2015 15th International Conference on Control, Automation and Systems, Proceedings","","","7364999","651","656","5","10.1109/ICCAS.2015.7364999","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966394789&doi=10.1109%2fICCAS.2015.7364999&partnerID=40&md5=357d2a3edc587205287a5a207f2714e2","We investigate the problem of phase unwrapping using multiple interferograms on the basis of Bayesian inference using the maximizer of the posterior marginal (MPM) estimate by making use of Monte Carlo simulation for several artificial wave-fronts in remote sensing via the synthetic aperture radar (SAR) interferometry. The simulations find that there is a phase where phase unwrapping is realized under the constraint of the surface-consistency in the hyper-parameter space, and that the upper phase boundary of the phase is steady along the parameter tuning fluctuations around the MAP solution. Also, we clarify that the MPM estimate succeeds in reconstruct the wave-front similar to the original one under the constraint of the surface-consistency condition, if the interferograms are corrupted by the Gaussian noises. Then, we find that the MPM estimate accurately reconstructs original wave-fronts using multiple interferograms, even if the interferograms are corrupted by Gaussian noises whose standard deviation is not so small. © 2015 Institute of Control, Robotics and Systems - ICROS.","Bayesian networks; Gaussian noise (electronic); Inference engines; Intelligent systems; Interferometry; Phase diagrams; Radar; Remote sensing; Space optics; Synthetic aperture radar; Wavefronts; Artificial waves; Bayesian inference; Consistency conditions; Hyper-parameter space; MPM estimate; Phase unwrapping; Standard deviation; Synthetic aperture radar interferometry; Monte Carlo methods","Bayesian inference; Monte Carlo simulation; MPM estimate; Phase diagram; Phase unwrapping","Conference paper","Final","","Scopus","2-s2.0-84966394789"
"Sargent G.C.; Ratliff B.M.; Asari V.K.","Sargent, Garrett C. (57193162199); Ratliff, Bradley M. (6603879539); Asari, Vijayan K. (6701420692)","57193162199; 6603879539; 6701420692","Single image super-resolution via regularized extreme learning regression for imagery from microgrid polarimeters","2017","Proceedings of SPIE - The International Society for Optical Engineering","10407","","104070C","","","","10.1117/12.2273945","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039057302&doi=10.1117%2f12.2273945&partnerID=40&md5=bb154d6a4e7ce0e332a6871128d43380","The advantage of division of focal plane imaging polarimeters is their ability to obtain temporally synchronized intensity measurements across a scene; however, they sacrifice spatial resolution in doing so due to their spatially modulated arrangement of the pixel-To-pixel polarizers and often result in aliased imagery. Here, we propose a super-resolution method based upon two previously trained extreme learning machines (ELM) that attempt to recover missing high frequency and low frequency content beyond the spatial resolution of the sensor. This method yields a computationally fast and simple way of recovering lost high and low frequency content from demosaicing raw microgrid polarimetric imagery. The proposed method outperforms other state-of-The-Art single-image super-resolution algorithms in terms of structural similarity and peak signal-To-noise ratio. © 2017 SPIE.","Image quality; Image resolution; Knowledge acquisition; Learning systems; Optical resolving power; Pixels; Polarimeters; Polarization; Remote sensing; Extreme learning machine; Intensity measurements; Micro grid; Peak signal to noise ratio; Polarimetric imagery; Single images; Structural similarity; Superresolution methods; Signal to noise ratio","Extreme learning machine; Machine learning; Microgrid polarimeter; Single-image super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85039057302"
"Laurenzis M.; Schertzer S.; Christnacher F.","Laurenzis, Martin (6602922462); Schertzer, Stephane (54413044400); Christnacher, Frank (6506050618)","6602922462; 54413044400; 6506050618","Compressed sensing for super-resolution spatial and temporal laser detection and ranging","2016","Proceedings of SPIE - The International Society for Optical Engineering","9988","","99880O","","","","10.1117/12.2240758","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011020000&doi=10.1117%2f12.2240758&partnerID=40&md5=c106480a96a76c17446f7ec1a12d6b0b","In the past decades, laser aided electro-optical sensing has reached high maturity and several commercial systems are available at the market for various but specific applications. These systems can be used for detection i.e. imaging as well as ranging. They cover laser scanning devices like LiDAR and staring full frame imaging systems like laser gated viewing or LADAR. The sensing capabilities of these systems is limited by physical parameter (like FPA array size, temporal band width, scanning rate, sampling rate) and is adapted to specific applications. Change of system parameter like an increase of spatial resolution implies the setup of a new sensing device with high development cost or the purchase and installation of a complete new sensor unit. Computational imaging approaches can help to setup sensor devices with flexible or adaptable sensing capabilities. Especially, compressed sensing is an emerging computational method which is a promising candidate to realize super-resolution sensing with the possibility to adapt its performance to various sensing tasks. It is possible to increase sensing capabilities with compressed sensing to gain either higher spatial and/or temporal resolution. Then, the sensing capabilities depend no longer only on the physical performance of the device but also on the computational effort and can be adapted to the application. In this paper, we demonstrate and discuss laser aided imaging using CS for super-resolution tempo-spatial imaging and ranging. © 2016 SPIE.","Compressed sensing; Optical resolving power; Remote sensing; Signal reconstruction; Computational effort; Computational imaging; Laser detection and ranging; Laser scanning device; Physical parameters; Physical performance; Single-pixel cameras; Temporal resolution; Optical radar","compressed sensing; Laser detection and ranging; single pixel camera","Conference paper","Final","","Scopus","2-s2.0-85011020000"
"Wang L.; Shao Z.; Liu J.; Nie Q.; Jia H.; Dai S.; Wang X.; Zhu J.; Li X.","Wang, Lei (57268071200); Shao, Zhengzheng (16064649100); Liu, Jiying (55199488700); Nie, Qianwen (57193745198); Jia, Hui (35332041000); Dai, Suian (35368214600); Wang, Xiaofeng (56016207000); Zhu, Jubo (7405689299); Li, Xiujian (55542118600)","57268071200; 16064649100; 55199488700; 57193745198; 35332041000; 35368214600; 56016207000; 7405689299; 55542118600","A push-broom compressive imaging system with situ calibration function for encoding mask","2017","Proceedings of SPIE - The International Society for Optical Engineering","10255","","1025508","","","","10.1117/12.2267747","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016259228&doi=10.1117%2f12.2267747&partnerID=40&md5=1c682d473d2cd9265401f1397c4fb591","Compressive imaging(CI)can offer a versatile improvements for imaging systems, such as smaller compressed data volume and super-resolution. Among various methods to realize Compressive imaging, pushing encoding mask has attracted the most attention with its compatibility to the space remote sensing. However, complex pre-calibrations are usually needed for calibrating the encoding mask to achieve the measurement matrix for the image reconstruction. Herein, we design a pushing compressive imaging system which fixed with the function of situ calibration of the encoding mask. The pushing compressive imaging system was constructed, and the experimental results confirmed that the system had the ability for data compression and super-resolution. And above all, the system can avoid the complex pre-calibration, which makes the on-orbit calibration feasible. In the simulations, twice, three times and four times resolutions higher than the captured image's resolution are performed respectively, which confirm that the method can improve the target image resolution based on the relative low resolution raw captured target images. Furthermore, by pushing the mask precisely which can be considered equivalent to the real pushing imaging, we have reconstructed the true super-resolution target image accurately based on the mask calibration and 6 captured pushing imaging frames. © 2017 SPIE.","Calibration; Encoding (symbols); Image processing; Image resolution; Imaging systems; Matrix algebra; Optical resolving power; Remote sensing; Calibration functions; Compressive imaging; Encoding masks; Measurement matrix; On-orbit calibration; Pre calibrations; Space remote sensing; Super resolution; Image reconstruction","Encoding mask; Measurement matrix; Push-broom compressive imaging; Situ calibration","Conference paper","Final","","Scopus","2-s2.0-85016259228"
"Zhong J.; Yang B.; Huang G.; Zhong F.; Chen Z.","Zhong, Jinying (57189874799); Yang, Bin (55584794814); Huang, Guoyu (57189874697); Zhong, Fei (57225726168); Chen, Zhongze (17433732700)","57189874799; 55584794814; 57189874697; 57225726168; 17433732700","Remote Sensing Image Fusion with Convolutional Neural Network","2016","Sensing and Imaging","17","1","10","","","","10.1007/s11220-016-0135-6","111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975475015&doi=10.1007%2fs11220-016-0135-6&partnerID=40&md5=b918453c7b8fc2ff3223358ca5cb586a","Remote sensing image fusion (RSIF) is referenced as restoring the high-resolution multispectral image from its corresponding low-resolution multispectral (LMS) image aided by the panchromatic (PAN) image. Most RSIF methods assume that the missing spatial details of the LMS image can be obtained from the high resolution PAN image. However, the distortions would be produced due to the much difference between the structural component of LMS image and that of PAN image. Actually, the LMS image can fully utilize its spatial details to improve the resolution. In this paper, a novel two-stage RSIF algorithm is proposed, which makes full use of both spatial details and spectral information of the LMS image itself. In the first stage, the convolutional neural network based super-resolution is used to increase the spatial resolution of the LMS image. In the second stage, Gram–Schmidt transform is employed to fuse the enhanced MS and the PAN images for further improvement the resolution of MS image. Since the spatial resolution enhancement in the first stage, the spectral distortions in the fused image would be decreased in evidence. Moreover, the spatial details can be preserved to construct the fused images. The QuickBird satellite source images are used to test the performances of the proposed method. The experimental results demonstrate that the proposed method can achieve better spatial details and spectral information simultaneously compared with other well-known methods. © 2016, Springer Science+Business Media New York.","Convolution; Image reconstruction; Image resolution; Neural networks; Optical resolving power; Remote sensing; Convolutional neural network; Multispectral images; Panchromatic (Pan) image; Remote sensing images; Schmidt; Spatial-resolution enhancement; Structural component; Super resolution; Image fusion","Convolutional neural network; Gram–Schmidt transform; Remote sensing image fusion; Super-resolution","Article","Final","","Scopus","2-s2.0-84975475015"
"Cao L.; Wang C.; Li J.","Cao, Liujuan (35749499000); Wang, Cheng (36990982800); Li, Jonathan (57235557700)","35749499000; 36990982800; 57235557700","Vehicle detection from highway satellite images via transfer learning","2016","Information Sciences","366","","","177","187","10","10.1016/j.ins.2016.01.004","42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977951505&doi=10.1016%2fj.ins.2016.01.004&partnerID=40&md5=f2c50a227f59c7ed66bad28dedcc333b","Coming with the era of highway satellites, nowadays there is a massive amount of remote sensing images captured. Therefore, it is now feasible to detect vehicles directly from these satellite images, which has attracted extensive research attentions for both academic and industrial applications. However, it is not an easy task at all, mainly due to the difficulty to obtain training data to train vehicle detectors. On the contrary, there has been sufficient amount of labeled information regarding vehicle regions in the domain of aerial images. In this paper, we study the problem of detecting vehicles on highway satellite images, without the time-consuming step of collecting sufficient training data in this domain. Our key idea is to adopt a novel transfer learning technology that transfers vehicle detectors trained in the aerial image domain to the satellite image domain. In doing so, several cutting-edge vehicle detection algorithms can be directly applied. More specifically, our transfer learning scheme is based on a supervised super-resolution algorithm, which learns mutually correlative sparse coefficients between high and low resolution image patches. Then, a linear SVM based detector is trained, the loss function of which is integrated into the sparse coding operation above. Experimental results have shown that the proposed framework can achieve significant improvement over several alternative and state-of-the-art schemes, with high precision and low false alarms. © 2016 Elsevier Inc.","Classification (of information); Codes (symbols); Image reconstruction; Industrial research; Object detection; Remote sensing; Satellites; Transportation; Vehicles; Low resolution images; Remote sensing images; Satellite images; Sparse coding; State-of-the-art scheme; Super resolution algorithms; Transfer learning; Vehicle detection; Image coding","Classification; Satellite images; Sparse coding; Transfer learning","Article","Final","","Scopus","2-s2.0-84977951505"
"Du Y.; Zhang T.","Du, Yi (35731460300); Zhang, Ting (56999385700)","35731460300; 56999385700","A super-resolution reconstruction method for land cover maps using multiple-point statistics","2016","Tien Tzu Hsueh Pao/Acta Electronica Sinica","44","11","","2576","2582","6","10.3969/j.issn.0372-2112.2016.11.003","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012301051&doi=10.3969%2fj.issn.0372-2112.2016.11.003&partnerID=40&md5=2cad84e01dfd0b636e71b26bf9b48464","When using remote sensing for land cover mapping, super-resolution reconstruction is widely used. Prior models containing the features of land cover maps can constrain the uncertainty of reconstruction. These prior models can be used properly by multiple-point statistics (MPS) by extracting the intrinsic features from them, and copying these features to the simulated regions. However, because traditional MPS methods based on linear dimensionality reduction are not suitable to deal with nonlinear data, isometric mapping (ISOMAP) is introduced in MPS to reduce the dimensionality reduction of nonlinear data and then these lower-dimensional data are classified. Current data event and the average of every classified class are compared so that a pattern can be extracted from the class that is closest to the current data event. Besides, the low-resolution original image is viewed as soft data for generating super-resolution land cover maps. Tests show that the super-resolution reconstructions of land cover maps have the similar structural features with those of reference images. © 2016, Chinese Institute of Electronics. All right reserved.","Mapping; Optical resolving power; Remote sensing; Dimensionality reduction; Isometric mapping; Land cover; Land cover mapping; Linear dimensionality reduction; Multiple-point statistics; Structural feature; Super resolution reconstruction; Data reduction","Isometric mapping; Land cover; Multiple-point statistics; Remote sensing; Super-resolution reconstruction","Article","Final","","Scopus","2-s2.0-85012301051"
"Marquez M.A.; Vargas C.A.; Arguello H.","Marquez, Miguel A. (57190760886); Vargas, Cesar A. (56423559600); Arguello, H. (44061135000)","57190760886; 56423559600; 44061135000","Compact spatio-spectral algorithm for single image super-resolution in hyperspectral imaging; [Superresolución basado en una única imagen para imágenes hiperespectrales]","2016","Ingenieria e Investigacion","36","3","","117","124","7","10.15446/ing.investig.v36n3.54267","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006795637&doi=10.15446%2fing.investig.v36n3.54267&partnerID=40&md5=d1de026d343cb53b58a8002af5667d83","Hyperspectral imaging (HSI) is used in a wide range of applications such as remote sensing, space imagery, mineral detection, and exploration. Unfortunately, it is difficult to acquire hyperspectral images with high spatial and spectral resolution due to instrument limitations. The super-resolution techniques are used to reconstruct low-resolution hyperspectral images. However, traditional super-resolution (SR) approaches do not allow direct use of both spatial and spectral information, which is a decisive for an optimal reconstruction. This paper proposes a single image SR algorithm for HSI. The algorithm uses the fact that the spatial and spectral information can be integrated to make an accurate estimate of the high-resolution HSI. To achieve this, two types of spatio-spectral downsampling, and a three-dimensional interpolation are proposed in order to increase coherence between the spatial and spectral information. The resulting reconstructions using the proposed method are up to 2 dB better than traditional SR approaches. © 2016, Revista Ingenieria e Investigacion - Editorial Board. All rights reserved.","","Hyperspectral downsampling; Hyperspectral imaging; Spatio-spectral dimension; Three-dimensional interpolation","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85006795637"
"Wang M.; Yu W.; Wang R.; Guo L.; Luo X.","Wang, Mingjiang (55811304400); Yu, Weidong (55570004000); Wang, Robert (7405336715); Guo, Lei (56602014600); Luo, Xiulian (55869611500)","55811304400; 55570004000; 7405336715; 56602014600; 55869611500","Digital beamforming synthetic aperture radar imaging on received signals based on compressed sensing","2015","Journal of Applied Remote Sensing","9","1","096060","","","","10.1117/1.JRS.9.096060","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928712585&doi=10.1117%2f1.JRS.9.096060&partnerID=40&md5=1c525ff700cc6a33160f4e419fc898ff","Digital beamforming synthetic aperture radar (SAR) in elevation is a promising technique to realize the increasing requirements of high-resolution and wide-swath imaging in remote sensing, although it suffers from a dense sampling rate and heavy data volume. This poses serious challenges to onboard transmission and storage of satellites. Additionally, the traditional beamforming technique suffers degraded imaging capacities caused by the incoherence between the received signals of different channels. To overcome these deficiencies, this paper proposes an improved method for the focusing of multichannel SAR raw data based on the framework of compressed sensing (CS). Through adaptive measurement matrix construction for each subchannel, the proposed approach can take the misregistration information of all received signals into account, providing an accurate imagery recovery of sparse reflectivity. Compared with conventional processing, the suggested technique not only provides a more efficient data acquisition scheme for orbital configurations, but also carries the potential to eliminate the migration effects of imaging amplitude and resolution. Furthermore, it is demonstrated that the proposed implementation is equipped with additional imaging benefits, such as superresolution and lower sidelobes. Numerical and experimental results have validated these favorable performances of the suggested strategy. © 2015 Society of Photo-Optical Instrumentation Engineers.","Beamforming; Compressed sensing; Data acquisition; Digital storage; Optical resolving power; Radar imaging; Radar signal processing; Remote sensing; Adaptive measurements; Beamforming technique; Compressive sensing; Conventional processing; Digital beam forming; Migration effects; Orbital configuration; Super resolution; Synthetic aperture radar","compressed sensing; digital beamforming; super resolution; synthetic aperture radar","Article","Final","","Scopus","2-s2.0-84928712585"
"Fablet R.; Rousseau F.","Fablet, R. (6603508732); Rousseau, F. (57188780886)","6603508732; 57188780886","Missing data super-resolution using non-local and statistical priors","2015","Proceedings - International Conference on Image Processing, ICIP","2015-December","","7350884","676","680","4","10.1109/ICIP.2015.7350884","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956675173&doi=10.1109%2fICIP.2015.7350884&partnerID=40&md5=8def8bb2e2e9f632be84bdc17695237c","We here address the super-resolution of a high-resolution image involving missing data given that a low-resolution image of the same scene is available. This is a typical issue in the remote sensing of geophysical parameters from different spaceborne sensors. Such super-resolution application involves large downscaling factor (typically from 10 to 20) and the super-resolution model should account for both texture patterns and specific statistical features, especially the spectral and non-Gaussian features. In this context, we propose a novel non-local approach and formally states the solution as the joint minimization of several projection constraints. We illustrate the relevance of the proposed model on real ocean remote sensing data, namely sea surface temperature fields, as well on visual textures. © 2015 IEEE.","","geophysical fields; inpainting; non-Gaussian fields; non-local regularisation; ocean remote sensing; spectral properties; super-resolution","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84956675173"
"Ishimaru A.; Zhang C.; Kuga Y.","Ishimaru, Akira (7005122046); Zhang, Ce (55703849700); Kuga, Yasuo (7005071830)","7005122046; 55703849700; 7005071830","Statistical maxwell’s electromagnetic theories applied to imaging of objects in geophysical and biological media","2015","Progress in Electromagnetics Research","151","","","17","31","14","10.2528/PIER14123103","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948683834&doi=10.2528%2fPIER14123103&partnerID=40&md5=b9377935cd7942b1be9b91d244c32d26","Statistical Maxwell’s Electromagnetic Theories have been developed over many years and applied to a wide range of practical problems in remote sensing of geographical media, imaging in biological media, medical optics, ultrasound imaging, and object detection and imaging and communications in clutter environment. This paper gives a review of recent advances, development and applications of statistical wave theory. Many important problems on imaging in geophysical and biological media have been treated often as separate problems. This paper attempts to present unified theoretical work and viewpoints under the statistical theories which may help further advance and understanding of theories and applications. The statistical electromagnetic theories encompass most advanced mathematical and theoretical work and most practical applications. This includes timereversal imaging through multiple scattering media, super resolution, communication channel capacity in clutter, space-time vector radiative transfer, bio-electromagnetics and ultrasound in tissues, coherence in multiple scattering, memory effects, the use of transformation electromagnetics, seismic coda, and the fundamental multiple scattering theories. Statistical Electromagnetics Theories are one of the most challenging theoretical problems today involving many applications in geographical and biological media. © 2015, Electromagnetics Academy. All rights reserved.","Clutter (information theory); Coherent scattering; Electric fields; Geophysics; Medical problems; Multiple scattering; Remote sensing; Statistics; Ultrasonic applications; Ultrasonic imaging; Vector spaces; Bio-electromagnetics; Development and applications; Electromagnetic theories; Multiple-scattering media; Multiple-scattering theory; Statistical electromagnetics; Time reversal imaging; Vector radiative transfer; Medical imaging","","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-84948683834"
"Jia W.; Xu X.; Xu G.","Jia, Weiwei (57206669714); Xu, Xiaojian (16320137600); Xu, Guangyao (57095230000)","57206669714; 16320137600; 57095230000","APES-based procedure for super-resolution SAR imagery with GPU parallel computing","2015","Proceedings of SPIE - The International Society for Optical Engineering","9646","","96460C","","","","10.1117/12.2194408","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957062546&doi=10.1117%2f12.2194408&partnerID=40&md5=6c1c16dbeb1b240e35e11d590a8f6ceb","The amplitude and phase estimation (APES) algorithm is widely used in modern spectral analysis. Compared with conventional Fourier transform (FFT), APES results in lower sidelobes and narrower spectral peaks. However, in synthetic aperture radar (SAR) imaging with large scene, without parallel computation, it is difficult to apply APES directly to super-resolution radar image processing due to its great amount of calculation. In this paper, a procedure is proposed to achieve target extraction and parallel computing of APES for super-resolution SAR imaging. Numerical experimental are carried out on Tesla K40C with 745 MHz GPU clock rate and 2880 CUDA cores. Results of SAR image with GPU parallel computing show that the parallel APES is remarkably more efficient than that of CPU-based with the same super-resolution. © 2015 SPIE.","Algorithms; Extraction; Image processing; Optical resolving power; Parallel processing systems; Program processors; Radar; Remote sensing; Spectrum analysis; Synthetic aperture radar; APES; Graphics processor units; SAR Images; Super resolution; Target extraction; Radar imaging","APES; graphics processor unit (GPU); parallel computing; SAR image; super-resolution; target extraction","Conference paper","Final","","Scopus","2-s2.0-84957062546"
"Li F.; Fu J.; Xin L.; Liu Y.; Liu Z.","Li, Feng (57171116800); Fu, Jie (57199749988); Xin, Lei (57183670600); Liu, Yuhong (57206819491); Liu, Zhijia (56101731400)","57171116800; 57199749988; 57183670600; 57206819491; 56101731400","New developments in super resolution for GaoFen-4","2017","Proceedings of SPIE - The International Society for Optical Engineering","10427","","2278158","","","","10.1117/12.2278158","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041022923&doi=10.1117%2f12.2278158&partnerID=40&md5=f72fe6c628c9c9a401191df35a79e81f","In this paper, the application of super resolution (SR, restoring a high spatial resolution image from a series of low resolution images of the same scene) techniques to GaoFen(GF)-4, which is the most advanced geostationary- orbit earth observing satellite in China, remote sensing images is investigated and tested. SR has been a hot research area for decades, but one of the barriers of applying SR in remote sensing community is the time slot between those low resolution (LR) images acquisition. In general, the longer the time slot, the less reliable the reconstruction. GF-4 has the unique advantage of capturing a sequence of LR of the same region in minutes, i.e. working as a staring camera from the point view of SR. This is the first experiment of applying super resolution to a sequence of low resolution images captured by GF-4 within a short time period. In this paper, we use Maximum a Posteriori (MAP) to solve the ill-conditioned problem of SR. Both the wavelet transform and the curvelet transform are used to setup a sparse prior for remote sensing images. By combining several images of both the Beijing and DunHuang regions captured by GF-4 our method can improve spatial resolution both visually and numerically. Experimental tests show that lots of detail cannot be observed in the captured LR images, but can be seen in the super resolved high resolution (HR) images. To help the evaluation, Google Earth image can also be referenced. Moreover, our experimental tests also show that the higher the temporal resolution, the better the HR images can be resolved. The study illustrates that the application for SR to geostationary-orbit based earth observation data is very feasible and worthwhile, and it holds the potential application for all other geostationary-orbit based earth observing systems. © 2017 SPIE.","Geostationary satellites; Image processing; Image resolution; Optical resolving power; Orbits; Remote sensing; Signal processing; Wavelet transforms; Earth observation data; Earth observing satellite; Earth observing systems; Gf-4; High spatial resolution images; Ill conditioned problems; Maximum a posteriori; Super resolution; Image enhancement","Gf-4; Maximum a posteriori; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85041022923"
"Bosch E.H.; Czaja W.; Murphy J.M.; Weinberg D.","Bosch, Edward H. (7103323348); Czaja, Wojciech (6603938615); Murphy, James M. (56330281800); Weinberg, Daniel (56825242700)","7103323348; 6603938615; 56330281800; 56825242700","Anisotropic representations for superresolution of hyperspectral data","2015","Proceedings of SPIE - The International Society for Optical Engineering","9472","","947213","","","","10.1117/12.2180523","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946069722&doi=10.1117%2f12.2180523&partnerID=40&md5=889648234033b78666e26dc9bc7bb16d","We develop a method for superresolution based on anisotropic harmonic analysis. Our ambition is to effciently increase the resolution of an image without blurring or introducing artifacts, and without integrating additional information, such as sub-pixel shifts of the same image at lower resolutions or multimodal images of the same scene. The approach developed in this article is based on analysis of the directional features present in the image that is to be superesolved. The harmonic analytic technique of shearlets is implemented in order to effciently capture the directional information present in the image, which is then used to provide smooth, accurate images at higher resolutions. Our algorithm is compared to both a recent anisotropic technique based on frame theory and circulant matrices,1 as well as to the standard superresolution method of bicubic interpolation. We evaluate our algorithm on synthetic test images, as well as a hyperspectral image. Our results indicate the superior performance of anisotropic methods, when compared to standard bicubic interpolation. © 2015 SPIE.","Algorithms; Image processing; Independent component analysis; Interpolation; Optical resolving power; Remote sensing; Spectroscopy; Bicubic interpolation; Directional feature; Directional information; Hyper-spectral images; Shearlets; Super resolution; Superresolution methods; Synthetic test images; Anisotropy","Anisotropic dictionaries; Hyperspectral images; Image processing; Remote sensing; Shearlets; Superresolution","Conference paper","Final","","Scopus","2-s2.0-84946069722"
"Moro A.; Shang F.; Kidera S.; Kirimoto T.","Moro, Akira (57094652200); Shang, Fang (55575500900); Kidera, Shouhei (14031687600); Kirimoto, Tetsuo (7003883695)","57094652200; 55575500900; 14031687600; 7003883695","Noise robust time of arrival estimation method using hierarchical Bayesian based compressed sensing algorithm","2017","ISAP 2016 - International Symposium on Antennas and Propagation","","","7821535","862","863","1","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013196822&partnerID=40&md5=0f1a1f6df71da9e812c1d8cbcb7deab0","A microwave radar system is a useful tool for all-weather type remote sensing, such as terrain surface measurement. It is well known fact that a resolution of time-of-arrival (TOA) is strictly determined by the frequency bandwidth of transmitted signal. As super-resolution technique beyond such limitation, a compressed sensing (CS) algorithm has come under spotlight because a sparse assumption is well established in typical radar situations. However, the original CS method suffers from lower TOA resolution in insufficient SNR level. To address with such problem, this paper introduces a hierarchical Bayesian based CS algorithm. This method introduces the stochastic model derived from cross-correlation response as a priori information for CS reconstruction as hyper-prior distribution. The results of numerical simulation show that the proposed method enhances an accuracy for signal reconstruction, even in lower SNR situations. © 2016 IEICE.","Bayesian networks; Compressed sensing; Numerical methods; Radar; Radar measurement; Radar signal processing; Radar systems; Remote sensing; Signal processing; Signal reconstruction; Signal to noise ratio; Stochastic models; Stochastic systems; Surface measurement; Compressive sensing; Cross correlations; Frequency band width; Hierarchical bayesian; Hierarchical Bayesian modeling; Time of arrival (TOA); Time of arrival estimation; TOA estimation; Time of arrival","Compressed sensing; Hierarchical Bayesian model; Radar signal processing; TOA estimation","Conference paper","Final","","Scopus","2-s2.0-85013196822"
"Tiwari L.K.; Sinha S.K.; Saran S.; Tolpekin V.A.; Raju P.L.N.","Tiwari, L.K. (57225820963); Sinha, S.K. (23101384400); Saran, S. (7003795359); Tolpekin, V.A. (16418092800); Raju, P.L.N. (56448256400)","57225820963; 23101384400; 7003795359; 16418092800; 56448256400","Markov random field-based method for super-resolution mapping of forest encroachment from remotely sensed ASTER image","2016","Geocarto International","31","4","","428","445","17","10.1080/10106049.2015.1054441","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955208354&doi=10.1080%2f10106049.2015.1054441&partnerID=40&md5=805556579b502bed9d3b3053534fed6f","Forest encroachment (FE) is a problem in Andaman and Nicobar Islands (ANI) in India for environment and planning. Small gaps created in the forest slowly expand its periphery disturbing the biodiversity. Therefore, intrusion of poachers, slash and burn and other factors causing FE must be carefully detected and monitored. Remote sensing offers a great opportunity to accomplish this task because of its synoptic view. Conventional classification methods with remotely sensed images are problematic because of small size of FE and mixed landcover composition. This study presents an application of super-resolution mapping (SRM) based on Markov random field for detection of FE using ASTER (15 m) images. The SRM results were validated using multispectral IRS LISS-IV (5.8 m) image. Non-contiguous FE patches of various sizes and shapes are characterized using the spatial contextual information. The novelty of this approach lies in the identification and separability of small FE pockets which could not be achieved with pixel-based maximum likelihood classifier (MLC). The SRM parameters were optimized and found comparable to previous studies. Classification accuracy obtained with SRM at scale factor 3 is κ = 0.62 that is superior to accuracy of MLC (κ = 0.51). SRM is a promising tool for detection and monitoring of FE at Rutland Island in ANI, India. © 2015 Taylor & Francis.","Andamans and Nicobars; India; Agonidae; ASTER; deforestation; image classification; image resolution; mapping; Markov chain; multispectral image; remote sensing; satellite imagery","forest encroachment; Markov random field; maximum likelihood classifier; super-resolution mapping","Article","Final","","Scopus","2-s2.0-84955208354"
"Ducournau A.; Fablet R.","Ducournau, Aurelien (36166421600); Fablet, Ronan (6603508732)","36166421600; 6603508732","Deep learning for ocean remote sensing: An application of convolutional neural networks for super-resolution on satellite-derived SST data","2017","2016 9th IAPR Workshop on Pattern Recognition in Remote Sensing, PRRS 2016","","","7867019","","","","10.1109/PRRS.2016.7867019","59","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016967048&doi=10.1109%2fPRRS.2016.7867019&partnerID=40&md5=aa5bb17305fe1ca49863e291ddb84a59","In this paper, we propose to address the downscaling of ocean remote sensing data using image super-resolution models based on deep learning, and more particularly Convolutional Neural Networks (CNNs). The goal of this study, for which we focus on satellite-derived Sea Surface Temperature (SST) data, is to evaluate the efficiency and the relevance of deep learning architectures applied to oceanographic remote sensing data. By using a CNN architecture, namely SRCNN (Super Resolution CNN), on a large-scale dataset of SST fields, we show that it allows a considerable gain in terms of PSNR compared to classical downscaling techniques. These results point out the relevance of deep learning models specifically trained for ocean remote sensing data and advocate for other applications to the reconstruction of high-resolution sea surface geophysical fields from multi-sensor satellite observations. © 2016 IEEE.","Atmospheric temperature; Convolution; Deep learning; Network architecture; Neural networks; Oceanography; Optical resolving power; Pattern recognition; Satellites; Surface waters; Convolutional neural network; Image super resolutions; Large-scale dataset; Learning architectures; Ocean remote sensing; Remote sensing data; Sea surface temperature (SST); Super resolution; Remote sensing","Convolutional Neural Networks; Deep Learning; Ocean Remote Sensing Data; Super-Resolution","Conference paper","Final","","Scopus","2-s2.0-85016967048"
"Synthiya Vinothini D.; Sathyabama B.; Karthikeyan S.","Synthiya Vinothini, D. (57198896392); Sathyabama, B. (36024410500); Karthikeyan, S. (57217707616)","57198896392; 36024410500; 57217707616","Super resolution mapping of trees for urban forest monitoring in Madurai city using remote sensing","2016","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10481 LNCS","","","88","96","8","10.1007/978-3-319-68124-5_8","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057858998&doi=10.1007%2f978-3-319-68124-5_8&partnerID=40&md5=c8689202b7312eae368d64dded58a943","This paper proposes a super resolution mapping of trees pixel swapping method in Madurai city. Identifying and mapping the vegetation specifically trees is a significant issue in remote sensing applications where the lack of height information becomes a hard monocular recognition task. The density and shape of the trees gets affected by other man-made objects which gives rise to an erroneous recognition. The quality of recognition may be affected by various terms like resolution, visibility, sizes or scale. Predicting trees when they are partially blocked from view is also a challenging task. A common problem associated with the application of satellite images is the frequent occurrence of mixed pixels. The motivation of this work is to extract trees using pixel swapping method. Pixel-swapping algorithm is a simple and efficient technique for super resolution mapping to change the spatial arrangement of sub-pixels in such a way that the spatial correlation between neighboring sub-pixels would be maximized. Soft classification techniques were introduced to avoid the loss of information by assigning a pixel to multiple land-use/land-cover classes according to the area represented within the pixel. This soft classification technique generates a number of fractional images equal to the number of classes. Super resolution mapping was then used to know where each class is located within the pixel, in order to obtain detailed spatial patterns. The aim of supper resolution mapping is to determine a fine resolution map of the trees from the soft classification result. The experiment is conducted with images of Madurai city obtained from WorldView2 satellite. The accuracy of the pixel swapping algorithm was 98.74%. © Springer International Publishing AG 2017.","Classification (of information); Computer vision; Forestry; Land use; Optical resolving power; Pixels; Remote sensing; Fuzzy C mean; Low resolution multispectral images; Panchromatic images; Pixel-swapping; Super-resolution mappings; Urban forests; Mapping","Fuzzy C Means; High resolution panchromatic image; Low resolution multispectral image; Pixel swapping; Remote sensing; Super resolution mapping; Urban forest","Conference paper","Final","","Scopus","2-s2.0-85057858998"
"Ziyong Z.","Ziyong, Zhou (35436521900)","35436521900","Super-resolution reconstruction of hyperspectral images using empirical mode decomposition and compressed sensing","2016","Journal of Applied Remote Sensing","10","4","042011","","","","10.1117/1.JRS.10.042011","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998865669&doi=10.1117%2f1.JRS.10.042011&partnerID=40&md5=151394c549505e78d3f4e4ef4d14e2fa","Hyperspectral remote sensing provides the possibility of direct detection of material information; however, coarse spatial resolution can restrict the scope of its application. The super-resolution (SR) technique can overcome this problem, but the separate application of SR reconstruction to each spectral band is computationally intensive. We proposed an approach that combines empirical mode decomposition (EMD), single-image SR reconstruction using compressed sensing (CS), and principal component analysis (PCA). EMD was used to extract details from within the images, whereas PCA was implemented to reduce the spectral dimensions of the hyperspectral image cube and to retain meaningful spectral information. The CS-based single-image SR reconstruction involved the use of both the K-SVD algorithm for learning and obtaining an over-complete dictionary, and the orthogonal matching pursuit algorithm for the image reconstruction. Experimental results obtained using an EO-1 hyperion image were used to validate the proposed approach. © 2016 Society of Photo-Optical Instrumentation Engineers (SPIE).","Compressed sensing; Hyperspectral imaging; Image compression; Optical resolving power; Principal component analysis; Remote sensing; Spectroscopy; Empirical Mode Decomposition; Hyperspectral image cubes; Hyperspectral remote sensing; Orthogonal matching pursuit; Over-complete dictionaries; Spectral information; Super resolution; Super resolution reconstruction; Image reconstruction","compressed sensing; empirical mode decomposition; hyperspectral image; super-resolution","Article","Final","","Scopus","2-s2.0-84998865669"
