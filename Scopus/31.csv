"Authors","Author full names","Author(s) ID","Titles","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","DOI","Cited by","Link","Abstract","Indexed Keywords","Author Keywords","Document Type","Publication Stage","Open Access","Source","EID"
"Chen S.; Chen M.; Zhao B.; Mao T.; Wu J.; Bao W.","Chen, Shuaiqiang (57869452400); Chen, Meng (57221682011); Zhao, Bingyu (57200651458); Mao, Ting (56654878500); Wu, Jianjun (56840894700); Bao, Wenxuan (57394246900)","57869452400; 57221682011; 57200651458; 56654878500; 56840894700; 57394246900","Urban Tree Canopy Mapping Based on Double-Branch Convolutional Neural Network and Multi-Temporal High Spatial Resolution Satellite Imagery","2023","Remote Sensing","15","3","765","","","","10.3390/rs15030765","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147934630&doi=10.3390%2frs15030765&partnerID=40&md5=cdf50656bad56d972d9177773cd1e241","Accurate knowledge of urban forest patterns contributes to well-managed urbanization, but accurate urban tree canopy mapping is still a challenging task because of the complexity of the urban structure. In this paper, a new method that combines double-branch U-NET with multi-temporal satellite images containing phenological information is introduced to accurately map urban tree canopies. Based on the constructed GF-2 image dataset, we developed a double-branch U-NET based on the feature fusion strategy using multi-temporal images to obtain an accuracy improvement with an IOU (intersection over union) of 2.3% and an F1-Score of 1.3% at the pixel level compared to the U-NET using mono-temporal images which performs best in existing studies for urban tree canopy mapping. We also found that the double-branch U-NET based on the feature fusion strategy has better accuracy than the early fusion strategy and decision fusion strategy in processing multi-temporal images for urban tree canopy mapping. We compared the impact of image combinations of different seasons on the urban tree canopy mapping task and found that the combination of summer and autumn images had the highest accuracy in the study area. Our research not only provides a high-precision urban tree canopy mapping method but also provides a direction to improve the accuracy both from the model structure and data potential when using deep learning for urban tree canopy mapping. © 2023 by the authors.","Convolutional neural networks; Deep learning; Forestry; Image enhancement; Image fusion; Mapping; Satellite imagery; Convolutional neural network; Deep learning; Features fusions; Fusion strategies; High spatial resolution satellite imagery; Multi-temporal; Multi-temporal image; Remote-sensing; Urban forests; Urban tree canopies; Remote sensing","data fusion; deep learning; multi-temporal; remote sensing; urban forest","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85147934630"
"Maillet W.; Ouhami M.; Hafiane A.","Maillet, William (57889286300); Ouhami, Maryam (57218310382); Hafiane, Adel (23396705600)","57889286300; 57218310382; 23396705600","Fusion of Satellite Images and Weather Data with Transformer Networks for Downy Mildew Disease Detection","2023","IEEE Access","11","","","5406","5416","10","10.1109/ACCESS.2023.3237082","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147268432&doi=10.1109%2fACCESS.2023.3237082&partnerID=40&md5=5371bc31481acdfee05126cb503aee1a","Crop diseases significantly affect the quantity and quality of agricultural production. In a context where the goal of precision agriculture is to minimize or even avoid the use of pesticides, weather and remote sensing data with deep learning can play a pivotal role in detecting crop diseases, allowing localized treatment of crops. However, combining heterogeneous data such as weather and images remains a hot topic and challenging task. Recent developments in transformer architectures have shown the possibility of fusion of data from different domains, such as text-image. The current trend is to custom only one transformer to create a multimodal fusion model. Conversely, we propose a new approach to realize data fusion using three transformers. In this paper, we first solved the missing satellite images problem, by interpolating them with a ConvLSTM model. Then, we proposed a multimodal fusion architecture that jointly learns to process visual and weather information. The architecture is built from three main components, a Vision Transformer and two transformer-encoders, allowing to fuse both image and weather modalities. The results of the proposed method are promising achieving an overall accuracy of 97%. © 2013 IEEE.","Computer architecture; Deep learning; Image fusion; Image processing; Meteorology; Network architecture; Remote sensing; Satellites; Vegetation; Crop monitoring; Deep learning; Features extraction; Images processing; Index; Remote-sensing; Transformer; Vegetation index; Vegetation mapping; Crops","agriculture; crop monitoring; data fusion; deep learning; image processing; Remote sensing; vegetation indices","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85147268432"
"Cao Z.; Chen S.; Gao F.; Li X.","Cao, Ziyang (57215722368); Chen, Shaohui (36815612100); Gao, Feng (56486548700); Li, Xueke (56400693500)","57215722368; 36815612100; 56486548700; 56400693500","Improving phenological monitoring of winter wheat by considering sensor spectral response in spatiotemporal image fusion","2020","Physics and Chemistry of the Earth","116","","102859","","","","10.1016/j.pce.2020.102859","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081726268&doi=10.1016%2fj.pce.2020.102859&partnerID=40&md5=0201387853e9652f0c2fe4e82aa711f9","Multisensor image fusion results may deviate from accurately reflecting the phenological stages of winter wheat because different responses of satellite sensors to the spectrum lead to the radiometric inconsistency between different remote sensing images. To reduce the effect of the difference in the physical electromagnetic spectrum responses between sensors on monitoring the phenological stages of winter wheat by fusion results, Sensor Spectral Response (SSR) should be considered in spatiotemporal fusion methods. This paper proposes a novel image fusion model by introducing SSR into the Spatial and Temporal Adaptive Reflectance Fusion Model (STARFM). The contribution of SSR in minimizing the effect of the system difference between sensors on image fusion products is parameterized as a calibration factor by matrixing operation, which is able to offset the systematic inconsistency between different sensor images. Linear regression equation for different land cover type and spectral band is established to calculate the weights needed in STARFM for improving the selection of neighboring spectrally similar pixels. This proposed method is evaluated using one satellite datasets including four ZY-3 (5.8 m) and Landsat 8 OLI (30 m) scenes which are acquired during the growth stages of winter wheat from seedling to harvest. Qualitative and quantitative evaluation shows that the proposed method can better monitor the phenology of winter wheat with an improved spatial and temporal consistency with the observations than STARFM. © 2020","Triticum aestivum; Crops; Image enhancement; Reflection; Remote sensing; Satellites; Satellite images; Spectral response; System difference; TOA reflectance; Winter wheat; Landsat; monitoring; phenology; pixel; regression analysis; sensor; spatiotemporal analysis; spectral reflectance; wheat; Image fusion","Phenological monitoring of winter wheat; Sensor spectral response; Spatiotemporal satellite image fusion; System difference; TOA reflectance Prediction","Article","Final","","Scopus","2-s2.0-85081726268"
"Fang S.; Yao Z.; Cao F.","Fang, Shuai (7402422537); Yao, Zhenji (57213268834); Cao, Fengyun (55639620000)","7402422537; 57213268834; 55639620000","Spatio-temporal method of satellite image fusion based on linear model; [线性模型的遥感图像时空融合]","2020","Journal of Image and Graphics","25","3","","579","592","13","10.11834/jig.190279","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091007938&doi=10.11834%2fjig.190279&partnerID=40&md5=30a2a89af62bc5027fa938cb48972aea","Objective: Fine resolution images with high acquisition frequency play a key role in earth surface observation. However, due to technical and budget limitations, current satellite sensors have a tradeoff between spatial and temporal resolutions. No single sensor can simultaneously achieve a fine spatial resolution and a frequent revisit cycle although a large number of remote sensing instruments with different spatial and temporal characteristics have been launched. For example, Landsat sensors have fine spatial resolutions (1560 m) but long revisit frequencies (16 days). By contrast, a moderate resolution imaging spectro-radiometer (MODIS) instrument has a frequent revisit cycle (1 day) but a coarse spatial resolution (2501 000 m). In addition, optical satellite images are frequently contaminated by clouds, cloud shadows, and other atmospheric conditions. These factors limit applications that require data with both high spatial resolution and high temporal resolution. Spatio-temporal satellite image fusion is an effective way to solve this problem. Many spatio-temporal fusion methods have been proposed recently. Existing spatio-temporal data fusion methods are mainly divided into the following three categories: weight function-based methods, unmixing-based methods, and dictionary learning-based methods. All of these methods require at least one pair of observed coarse- and fine-resolution images for training and a coarse-resolution image at prediction date as input data. The output of spatio-temporal fusion methods is a synthetic fine-resolution image at prediction date. All spatio-temporal fusion methods use spatial information from the input fine-resolution images and temporal information from the coarse-resolution images. Unfortunately, existing spatio-temporal fusion methods cannot achieve satisfactory results in accurately predicting land-cover type change with only one pair of fine-coarse prior images. Thus, spatio-temporal satellite image-fusion method based on linear model is proposed to improve the prediction capacity and accuracy, especially for complex changed landscapes. Method: The temporal model is assumed to be independent of sensors, and a linear relationship is used to represent the temporal model between images acquired on different dates. Therefore, the spatio-temporal fusion is transformed into estimating parameters of the temporal model. To accurately capture earth surface change during the period between the input and prediction dates, we carefully analyzed the reasons for the temporal change, and then the temporal change was divided into two types: phonological and land cover type. The former is mainly caused by differences in atmospheric condition, solar angle at different dates, and is global and flat. The latter is mainly caused by the change on the surface, and is local and abrupt. Therefore, parameters of the model from global and local perspectives were estimated. To accurately estimate the parameters, we need to search for similar pixels in the local window to ensure that the pixels used for parameter estimation satisfies spectral consistency. Moreover, considering that the land-cover type may change during the period, we find that the spatial distribution of similar pixels may change at different dates. Therefore, a multi-temporal search strategy is introduced to flexibly select appropriate neighboring pixels. Only pixels that have similar spectral information to the target pixel at both base date and prediction date are considered to be similar pixels, which eliminate the block effect of traditional algorithms. After searching similar pixels and solving the temporal model, the input fine resolution image was combined with the temporal model to predict fine image at target date. The aforementioned strategies make our method achieve good prediction results even if the earth surface changed drastically. Result: We compared our model with two popular spatio-temporal fusion models: spatial and temporal adaptive reflectance fusion model (STARFM) and flexible spatiotemporal data fusion (FSDAF) method on two datasets. The experiment results show that our model outperforms all other methods in both datasets. In the first experiment, the dataset constitutes primarily phenological change. Therefore, all three methods achieve satisfactory results and our method achieves the best result. Quantitative comparisons show that our method achieves high correlation coefficient (CC), peak signal-to-noise ratio (PSNR), structural similarity (SSIM), and lower root mean square error (RMSE). Compared with STARFM and FSDAF, our method increases CC by 0.25% and 0.28%, PSNR by 0.153 1 dB and 1.379 dB, SSIM by 0.79% and 2.3%, and decreases RMSE by 0.05% and 0.69%. In the second experiment, the dataset has undergone dramatic land-cover type change. Therefore, both STARFM and FSDAF have block effects at different levels visually. In quantitative assessment, compared with STARFM and FSDAF, our method increases CC by 6.64% and 3.26%, PSNR by 2.086 dB and 2.510 7 dB, SSIM by 11.76% and 11.2%, and decreases RMSE by 1.45% and 2.08%. Conclusion: In this study, a spatio-temporal satellite image-fusion method based on linear model is proposed. This method uses a linear model to represent the temporal change. By analyzing the characteristics of the temporal change, the temporal model is constrained from local and global perspectives, and the solved model can represent the temporal change accurately. In addition, the method uses a multi-temporal similar pixel search strategy to search for similar pixels more flexibly, thereby eliminating the block effect of previous methods, fully utilizing spectral information in neighboring similar pixels, and improving the accuracy of prediction results. The experimental results show that in terms of visual comparison, compared with two popular spatiotemporal fusion methods, the proposed method can predict land-cover type change more accurately, and our findings are close to the true image. In the quantitative evaluation, our method improves CC, PSNR, RMSE, SSIM, and other indicators to varying degrees in each band. © 2020, Editorial and Publishing Board of Journal of Image and Graphics. All right reserved.","","Linear model; Parameter estimation; Remote sensing; Spatio-temporal fusion; Weight function-based method","Article","Final","","Scopus","2-s2.0-85091007938"
"Sigurdsson J.; Ulfarsson M.O.; Sveinsson J.R.","Sigurdsson, Jakob (7006736374); Ulfarsson, Magnus O. (6507677875); Sveinsson, Johannes R. (7003642214)","7006736374; 6507677875; 7003642214","FUSING SENTINEL-2 SATELLITE IMAGES AND AERIAL RGB IMAGES","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","4444","4447","3","10.1109/IGARSS47720.2021.9554406","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130050774&doi=10.1109%2fIGARSS47720.2021.9554406&partnerID=40&md5=a9f6932471da61c30ed82c7847d60469","Sentinel-2 (S2) is a constellation of two satellites that frequently acquire optical imagery over land and coastal waters. The S2 sensors have three spatial resolutions: 10, 20, and 60 m. Many remote sensing applications require the spatial resolution to be at the highest resolution, i.e., 10 m for S2. To address this demand, researchers have proposed various methods that exploit the spectral and spatial correlation in multispectral data to sharpen the S2 bands to 10 m. In this paper, we fuse S2 data with high-resolution aerial RGB images. A method called S2Sharp is modified to include the red, green, and blue bands of the aerial image and sharpen S2 data to the resolution of the RGB image. The method, termed S2PF, is evaluated using an S2 image and aerial photographs of Reykjavik, Iceland. © 2021 IEEE","Image fusion; Remote sensing; Satellite imagery; Coastal waters; High resolution; Image sharpening; Optical imagery; Remote sensing applications; RGB images; Satellite images; Sentinel-2  constellation; Spatial resolution; Superresolution; Antennas","Data fusion; Image sharpening; RGB images; Sentinel-2 (S2) constellation; Superresolution","Conference paper","Final","","Scopus","2-s2.0-85130050774"
"Rumora L.; Gašparović M.; Miler M.; Medak D.","Rumora, Luka (57211063553); Gašparović, Mateo (36987936900); Miler, Mario (57086384000); Medak, Damir (26642614700)","57211063553; 36987936900; 57086384000; 26642614700","Quality assessment of fusing Sentinel-2 and WorldView-4 imagery on Sentinel-2 spectral band values: a case study of Zagreb, Croatia","2020","International Journal of Image and Data Fusion","11","1","","77","96","19","10.1080/19479832.2019.1683624","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074924779&doi=10.1080%2f19479832.2019.1683624&partnerID=40&md5=aa7d4be24f8ba3650cd094a2600f96c6","Image fusion methods aim at fusing low resolution and high-resolution image to obtain a new image that provides new information for the specific application. The main goal of this article is multitemporal Sentinel-2 image fusion using single WorldView-4 satellite image for urban area monitoring. Fusing those images should provide Sentinel-2 image with similar radiometric band value as original Sentinel-2 image, but with a spatial resolution of WorldView-4. Ehlers, Brovey Transform, Modified Intensity-Hue-Saturation, High-Pass Filtering, Hyperspherical Colour Space and Wavelet resolution merge fusion techniques were used for spatial enhancement of Sentinel-2 images. Original and fused images were first compared using standard statistical parameters, mean, median and standard deviation. Image quality analysis was conducted with different objective image quality measures like root mean square error, peak signal to noise ratio, universal image quality index, structural similarity index, relative dimensionless global error, spatial correlation coefficient, relative average spectral error, spectral angle mapper, multi-scale structural similarity index. Using these quality measures helped in determining the spectral and spatial preservation of fused images. Hyperspherical colour space method was selected as the best method for image fusion of Sentinel-2 and WorldView-4 image-based on standard statistical parameters and quality measures. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Croatia; Zagreb; Color; Errors; High pass filters; Image enhancement; Image fusion; Mean square error; Signal to noise ratio; Colour spaces; Intensity hue saturations; Peak signal to noise ratio; Sentinel-2; Spatial correlation coefficients; Spectral value; Structural similarity indices; WorldView-4; data quality; image processing; qualitative analysis; satellite imagery; Sentinel; signal-to-noise ratio; spectral resolution; WorldView; Image quality","hyperspherical colour space; Image fusion; Sentinel-2; spectral values; WorldView-4","Article","Final","","Scopus","2-s2.0-85074924779"
"Zhu X.; Zhan W.; Zhou J.; Chen X.; Liang Z.; Xu S.; Chen J.","Zhu, Xiaolin (55696724800); Zhan, Wenfeng (57221408739); Zhou, Junxiong (57219625237); Chen, Xuehong (35733584200); Liang, Zicong (57218659923); Xu, Shuai (57218659636); Chen, Jin (55717837500)","55696724800; 57221408739; 57219625237; 35733584200; 57218659923; 57218659636; 55717837500","A novel framework to assess all-round performances of spatiotemporal fusion models","2022","Remote Sensing of Environment","274","","113002","","","","10.1016/j.rse.2022.113002","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126832742&doi=10.1016%2fj.rse.2022.113002&partnerID=40&md5=b28b65a1724863d70c5deb2dc9d81561","Spatiotemporal data fusion, as a feasible and low-cost solution for producing time-series satellite images with both high spatial and temporal resolution, has undergone rapid development over the past two decades with more than one hundred spatiotemporal fusion methods developed. Accuracy assessment of fused images is crucial for users to select appropriate methods for real-world applications. However, commonly used assessment metrics do not comprehensively cover multiple aspects of spatiotemporal fused image quality, contain redundant information, and are not comparable across different study areas. To address these problems, this study proposed a novel framework to assess all-round performances of spatiotemporal fusion methods. Four accuracy metrics, including RMSE, AD, Edge, and local binary patterns (LBP), were selected as the optimal set of assessment metrics according to the assessment criteria. These metrics not only quantify the spectral and spatial information in the fused images but also greatly alleviate information redundancy and feature computational simplicity. Furthermore, inspired by Taylor diagrams, we designed an all-round performance assessment (APA) diagram to provide a visual tool for a comprehensive assessment of the performance of spatiotemporal fusion methods, supporting cross-comparison of different spatiotemporal fusion methods by considering the effects of input data and land surface characteristics. The case study in three typical sites demonstrated that the proposed framework can better differentiate the performances of six spatiotemporal fusion methods. This new framework can promote the cross-comparison of different spatiotemporal fusion methods and guide users to select suitable methods for real-world applications, as well as facilitate the establishment of a standard accuracy assessment procedure for spatiotemporal fusion methods. © 2022 The Authors","Accuracy assessment; Assessment metric; Fused images; Fusion methods; Intercomparisons; Modeling performance; Performance; Real-world; Spatio-temporal fusions; Taylor diagrams; accuracy assessment; assessment method; land surface; performance assessment; satellite data; time series analysis; Image fusion","Accuracy assessment; Inter-comparison; Model performance; Spatiotemporal fusion; Taylor diagram","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85126832742"
"Li W.; Yang C.; Peng Y.; Du J.","Li, Weisheng (36067507500); Yang, Chao (57263586100); Peng, Yidong (57192995836); Du, Jiao (55416429400)","36067507500; 57263586100; 57192995836; 55416429400","A Pseudo-Siamese Deep Convolutional Neural Network for Spatiotemporal Satellite Image Fusion","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","1205","1220","15","10.1109/JSTARS.2022.3143464","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123345120&doi=10.1109%2fJSTARS.2022.3143464&partnerID=40&md5=97ac49fc1d4ed777a94531d0b2bae43f","Due to technology and cost limitations, it is challenging to obtain high temporal and spatial resolution images from a single satellite spectrometer, which significantly limits the specific application of such remote sensing images in earth science. To solve the problem that the existing algorithms cannot effectively balance the spatial detail preservation and spectral change reconstruction, a pseudo-Siamese deep convolutional neural network (PDCNN) for spatiotemporal fusion is proposed in this article. The method proposes a pseudo-Siamese network framework model for fusion. This framework has two independent and equal feature extraction streams, but the weights are not shared. The two feature extraction streams process the image information at the previous and later moments and reconstruct the fine image of the corresponding time to fully extract the image information at different times. In the feature extraction stream, the multiscale mechanism and dilated convolution of flexible perception are designed, which can flexibly obtain feature image information and improve the model reconstruction accuracy. In addition, an attention mechanism is introduced to improve the weight of the crucial information for the remote sensing images. Adding a residual connection enhances the reuse of the initial feature information in shallow networks and reduces the loss of feature information in deep networks. Finally, the fine images obtained from the two feature extraction streams are weighted and fused to obtain the final predicted image. The subjective and objective results demonstrate that the PDCNN can effectively reconstruct the fusion image with higher quality. © 2022 Institute of Electrical and Electronics Engineers. All rights reserved.","Convolution; Deep neural networks; Extraction; Image enhancement; Image fusion; Image reconstruction; Image resolution; Media streaming; Object detection; Remote sensing; Convolutional neural network; Features extraction; Images reconstruction; Multiscale mechanisms; Pseudo-siamese network; Remote-sensing; Spatial resolution; Spatio-temporal fusions; Spatiotemporal phenomenon; Streaming medium; artificial neural network; image analysis; remote sensing; satellite data; satellite imagery; spatiotemporal analysis; Feature extraction","Convolutional neural networks; Feature extraction; Image reconstruction; Remote sensing; Spatial resolution; Spatiotemporal phenomena; Streaming media","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85123345120"
"Wang F.; Zhang J.; Zou B.","Wang, Feifei (57218564557); Zhang, Junping (55961672900); Zou, Bin (55684454000)","57218564557; 55961672900; 55684454000","Multispectral and panchromatic images fusion based on nsct and gs transform","2020","Proceedings of SPIE - The International Society for Optical Engineering","11392","","113921A","","","","10.1117/12.2558052","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088163961&doi=10.1117%2f12.2558052&partnerID=40&md5=b6435cbac8e84bc622df54adf8dff053","The spatial and spectral resolution of remote sensing images are mutually restricted due to the limitation of sensor technology. Multispectral (MS) image has high spectral resolution, but low spatial resolution. While, panchromatic (PAN) image can provide high spatial resolution. Fusion of MS and PAN images is to get MS image with high resolution, which is a hot research in the field of remote sensing image processing. In this paper, a fusion algorithm of MS and PAN images is presented based on non-subsampled contourlet transform (NSCT) and Gram-Schmidt (GS) transform. Firstly, the low-resolution PAN image is synthesized by weighing each band of MS image whose weight coefficients are obtained by least squares estimation. MS image is decomposed by GS transform with the first GS component of the synthetic low-resolution PAN image. Secondly, one-level and three-level NSCT decomposition is performed on the synthetic low-resolution PAN image and PAN image, respectively. Low-frequency coefficients of low-resolution PAN image are as ones of the generated PAN image. High-frequency coefficients of first level decomposition of lowresolution PAN image and PAN image are fused according to region energy. The other level high-frequency coefficients of PAN image are as ones of the generated PAN image. Thirdly, the generated PAN image is reconstructed by the inverse NSCT with these coefficients. Lastly, inverse GS transform is performed to gain improved MS image by replacing the first GS component with the generated PAN image. The experiments conducted on Quickbird satellite images show that the proposed method is superior to the other typical methods, which improves the spatial resolution and has smaller spectral distortion. © 2020 SPIE.","Image fusion; Image resolution; Inverse problems; Remote sensing; Spectral resolution; Spectroscopy; High spatial resolution; High spectral resolution; Least squares estimation; Multispectral images; Non subsampled contourlet transform (NSCT); Panchromatic (Pan) image; Remote sensing image processing; Remote sensing images; Image enhancement","Gram-schmidt (gs) transform; Image fusion; Multispectral image; Non-subsampled contourlet transform (NSCT)","Conference paper","Final","","Scopus","2-s2.0-85088163961"
"Xu Y.; Li J.; Du C.; Chen H.","Xu, Yingxiao (57205201007); Li, Jun (56023443800); Du, Chun (50061333500); Chen, Hao (57056710000)","57205201007; 56023443800; 50061333500; 57056710000","NBR-Net: A Nonrigid Bidirectional Registration Network for Multitemporal Remote Sensing Images","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5620715","","","","10.1109/TGRS.2022.3162094","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128803124&doi=10.1109%2fTGRS.2022.3162094&partnerID=40&md5=5f674dc63ed4d37ef2629f76fd635f14","Remote sensing image registration is the basis of change detection, environmental monitoring, and image fusion. Under severe appearance differences, feature-based methods have difficulty in finding sufficient feature matches to solve the global transformation and tackling the local deformation caused by height undulations and building shadows. By contrast, nonrigid registration methods are more flexible than feature-based matching methods, while often ignoring the reversibility between images, resulting in misalignment and inconsistency. To this end, this article proposes a nonrigid bidirectional registration network (NBR-Net) to estimate the flow-based dense correspondence for remote sensing images. We first propose an external cyclic registration network to strengthen the registration reversibility and geometric consistency by registering Image A to Image B and then reversely registering back to Image A. Second, we design an internal iterative refinement strategy to optimize the rough predicted flow caused by large distortion and viewpoint difference. Extensive experiments demonstrate that our method shows a performance superior to the state-of-the-art models on the multitemporal satellite image dataset. Furthermore, we attempt to extend our method to heterogeneous remote sensing image registration, which is more common in the real world. Therefore, we test our pretrained model in a satellite and unmanned aerial vehicle (UAV) image registration task. Due to the cyclic registration mechanism and coarse-to-fine refinement strategy, the proposed approach obtains the best performance on two GPS-denied UAV image datasets. Our code will be released at https://github.com/xuyingxiao/ NBR-Net.  © 1980-2012 IEEE.","Antennas; Image fusion; Image registration; Iterative methods; Remote sensing; Cycle consistency; Images registration; Iterative refinement; Nonrigid; Remote sensing image registration; Remote sensing images; Reversibility; Unmanned aerial vehicle  image registration; Vehicle images; artificial neural network; data set; image analysis; remote sensing; satellite imagery; unmanned vehicle; Unmanned aerial vehicles (UAV)","Cycle consistency; iterative refinement; nonrigid; remote sensing image registration; reversibility; unmanned aerial vehicle (UAV) image registration","Article","Final","","Scopus","2-s2.0-85128803124"
"Bose R.; Banerjee A.S.B.; Chaudhuri S.","Bose, Rupak (57226749299); Banerjee, Anshul Shrivastava Biplab (57413367600); Chaudhuri, Subhasis (7402977965)","57226749299; 57413367600; 7402977965","DARK: Few-shot remote sensing colorization using label conditioned color injection.","2022","IEEE Geoscience and Remote Sensing Letters","","","","","","","10.1109/LGRS.2022.3141465","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122859857&doi=10.1109%2fLGRS.2022.3141465&partnerID=40&md5=1ee9bb27478c2a99d1099eb5fb79c285","Satellite image colorization is a broad challenging problem in the domain of remote sensing (RS) having huge potential applications. The problem becomes even more complicated under the few-shot setting yet it has barely been studied to date. In this paper, we propose a colorization framework for the RS scene for synthesizing optical images from their panchromatic (PAN) counterparts using color injection and attention fusion mechanism. Our proposed model ensures that the synthesized optical images are coherent with the structural variability of panchromatic images while constraining the realistic appearance in the optical domain from a few training image pairs. To accomplish the same, we introduce a novel Dual Attention fusion of Receptive Kernels (DARK) which considers the spatial nuances along with color injection conditioned on prior label allocation. DARK is a multi spectral-spatial feature generator that selectively accentuates important cross-spatial features based on attention fusion. We also employ a prior distribution constraint on color embedding generation for introducing vibrant yet diverse variance in a color generation. Our approach achieves state-of-the-art results on the publicly available EuroSAT and PatternNet datasets while demonstrating significant speedups. We showcase our results quantitatively by comparing the PSNR, mean squared error(MSE), and cosine similarity of generated images and qualitatively via visual perception. IEEE","Color; Geometrical optics; Image fusion; Image processing; Mean square error; Attention; Few-shot; Fusion mechanism; Image colorizations; Optical image; Optical-; Panchromatic; Remote-sensing; Satellite images; Spatial features; Remote sensing","Attention; Data Fusion; Few-shot; Image colorization; Optical; Panchromatic; Remote Sensing","Article","Article in press","","Scopus","2-s2.0-85122859857"
"Yi W.; Zeng Y.; Wang Y.; Deng J.; Su W.; Yuan Z.","Yi, Wei (57206484579); Zeng, Yong (36624647900); Wang, Yuhao (57224960821); Deng, Jianan (57225126398); Su, Wenbo (57225129618); Yuan, Zheng (57206482317)","57206484579; 36624647900; 57224960821; 57225126398; 57225129618; 57206482317","An improved IHS fusion method of GF-2 remote sensing images","2021","Proceedings of SPIE - The International Society for Optical Engineering","11848","","118480Y","","","","10.1117/12.2600387","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109215527&doi=10.1117%2f12.2600387&partnerID=40&md5=4d25c9cd127ec1a8592d1d39328b832e","The IHS transform fusion is one of the most widely used techniques for image fusion. However, the IHS transform fusion brings spectral distortion. In order to develop new image fusion methods, it is necessary to investigate the spectral features of the original images from different sensors. In this study, high-resolution panchromatic images were reconstructed to improve IHS transform based on GF-2 satellite images. The NSCT transform was used in order to separate details and spectral information. A synthetic index (SI) for assessing fidelity was proposed with consideration of average gradient, entropy, correlation coefficient and spectral distortion. Results show that, in urban areas, the SI of improved IHS method increases from 2.75 to 4.30, and the SI of the hybrid method (improved IHS + NSCT method) increases from 6.68 to 6.93. In addition, the proposed method helps to improve the SI from 1.10 to 3.80 and the NSCT from 6.00 to 7.46 for vegetation covered areas. Thus, the improved IHS transform would maintain spectral fidelity and significantly improve the vegetation spectral information.  © 2021 SPIE.","Image fusion; Remote sensing; Vegetation; Average gradient; Correlation coefficient; Image fusion methods; Panchromatic images; Remote sensing images; Spectral distortions; Spectral fidelity; Spectral information; Image enhancement","Evaluation; IHS; Image fusion; Non-subsampled contourlet","Conference paper","Final","","Scopus","2-s2.0-85109215527"
"Fan X.; Liu Y.; Wu G.; Zhao X.","Fan, Xingwang (36171497700); Liu, Yuanbo (56140027500); Wu, Guiping (55617651300); Zhao, Xiaosong (9244111200)","36171497700; 56140027500; 55617651300; 9244111200","Compositing the minimum NDVI for daily water surface mapping","2020","Remote Sensing","12","4","700","","","","10.3390/rs12040700","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080886778&doi=10.3390%2frs12040700&partnerID=40&md5=e6e449a982ec097f058f399be6ce8678","Capturing high frequency water surface dynamics via optical remote sensing is important for understanding hydro-ecological processes over seasonally flooded wetlands. However, it is a difficult task due to the presence of clouds on satellite images. This study proposed the MODerate-resolution Imaging Spectroradiometer (MODIS) Normalized Difference Vegetation Index (NDVI) Minimum Value Composite (MinVC) algorithm to generate daily water surface data at a 250-m resolution. The algorithm selected pixelwise minimum values from the combined daily Terra and Aqua MODIS NDVIdata within a 15-day moving window. Consisting mainly of cloud and water surface information, the MinVC NDVI data were segmented for water surfaces over the Poyang Lake, China (2000-2017) by using an edge detection model. The water surface mapping result was strongly correlated with the Landsat based result (R2 = 0.914, root mean square error, RMSE = 223.7 km2), the cloud free MODIS image based result (R2 = 0.824, RMSE = 356.7 km2), the recent Landsat-MODIS image fusion based result (R2 = 0.765, RMSE = 403 km2), and the hydrodynamic modeling result (R2 = 0.799). Compared to the equivalent eight-day MOD13 NDVI based on the Constraint View-Angle Maximum Value Composite (CV-MVC) algorithm, the daily MinVC NDVI highlighted water bodies by generating spatially homogenous water surface information. Consequently, the algorithm provided spatially and temporally continuous data for calculating water submersion times and trends in water surface area, which contribute to a better understanding of hydro-ecological processes over seasonally flooded wetlands. Within the framework of sensor intercalibration, the algorithm can be extended to incorporate multiple sensor data for improved water surface mapping. © 2020 by the author.","Ecology; Floods; Image fusion; Lakes; Mapping; Mean square error; Remote sensing; Wetlands; Compositing; MODIS; NDVI; Po-yang lakes; Water surface; Radiometers","Compositing; MODIS; NDVI; Poyang Lake; Water surface area","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85080886778"
"Tan Z.; Di L.; Zhang M.; Guo L.; Gao M.","Tan, Zhenyu (56421169400); Di, Liping (7006684098); Zhang, Mingda (55675164800); Guo, Liying (8721117700); Gao, Meiling (57191226894)","56421169400; 7006684098; 55675164800; 8721117700; 57191226894","An enhanced deep convolutional model for spatiotemporal image fusion","2019","Remote Sensing","11","24","2898","","","","10.3390/rs11242898","47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077888518&doi=10.3390%2frs11242898&partnerID=40&md5=cb2cdcf1e245da6e9279708d24112302","Earth observation data with high spatiotemporal resolution are critical for dynamic monitoring and prediction in geoscience applications, however, due to some technique and budget limitations, it is not easy to acquire satellite images with both high spatial and high temporal resolutions. Spatiotemporal image fusion techniques provide a feasible and economical solution for generating dense-time data with high spatial resolution, pushing the limits of current satellite observation systems. Among existing various fusion algorithms, deep-learning-based models reveal a promising prospect with higher accuracy and robustness. This paper refined and improved the existing deep convolutional spatiotemporal fusion network (DCSTFN) to further boost model prediction accuracy and enhance image quality. The contributions of this paper are twofold. First, the fusion result is improved considerably with brand-new network architecture and a novel compound loss function. Experiments conducted in two different areas demonstrate these improvements by comparing them with existing algorithms. The enhanced DCSTFN model shows superior performance with higher accuracy, vision quality, and robustness. Second, the advantages and disadvantages of existing deep-learning-based spatiotemporal fusion models are comparatively discussed and a network design guide for spatiotemporal fusion is provided as a reference for future research. Those comparisons and guidelines are summarized based on numbers of actual experiments and have promising potentials to be applied for other image sources with customized spatiotemporal fusion networks. © 2019 by the authors.","Budget control; Convolution; Deep learning; Image enhancement; Network architecture; Remote sensing; EDCSTFN; High spatial resolution; High temporal resolution; LANDSAT; MODIS; Satellite observation systems; Spatio-temporal resolution; Spatiotemporal; Image fusion","CNN; Deep learning; EDCSTFN; Image fusion; Landsat; MODIS; Remote sensing; Spatiotemporal","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85077888518"
"Horváth J.; Xiang Z.; Cannas E.D.; Bestagini P.; Tubaro S.; Delp E.J.","Horváth, János (57218707036); Xiang, Ziyue (57224548383); Cannas, Edoardo Daniele (57219686714); Bestagini, Paolo (21638596100); Tubaro, Stefano (7003411765); Delp, Edward J. (7005252700)","57218707036; 57224548383; 57219686714; 21638596100; 7003411765; 7005252700","Sat U-Net: A Fusion Based Method for Forensic Splicing Localization in Satellite Images","2022","Proceedings of SPIE - The International Society for Optical Engineering","12100","","1210002","","","","10.1117/12.2616150","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135909634&doi=10.1117%2f12.2616150&partnerID=40&md5=90b50581facac8f0b10679fb4f78aef5","Satellite images are widely available to the public. These satellite images are used in various elds including natural disaster analysis, meteorology and agriculture. As with any type of images, satellite images can be altered using image manipulation tools. A common manipulation is splicing, i.e., pasting on top of an image a region coming from a di erent source image. Most manipulation detection methods designed for images captured by ""consumer cameras""tend to fail when used with satellite images. In this paper we propose a machine learning approach, Sat U-Net, to fuse the results of two exiting forensic splicing localization methods to increase their overall accuracy and robustness. Sat U-Net is a U-Net based architecture exploiting several Transformers to enhance the performance. Sat U-Net fuses the outputs of two unsupervised splicing detection methods, Gated PixelCNN Ensemble and Vision Transformer, to produce a heatmap highlighting the manipulated image region. We show that our fusion approach trained on images from one satellite can be lightly retrained on few images from another satellite to detect spliced regions. We compare our approach to well-known splicing detection methods (i.e., Noiseprint) and segmentation techniques (i.e., U-Net and Nested Attention U-Net). We conducted our experiments on two large datasets: one dataset contains images from Sentinel 2 satellites and the other one contains images from Worldview 3 satellite. Our experiments show that our proposed fusion method performs well when compared to other techniques in localizing spliced areas using Jaccard Index and Dice Score as metrics on both datasets.  © 2022 SPIE.","Deep learning; Disasters; Image fusion; Large dataset; Remote sensing; Deep learning; Detection methods; Disaster analysis; Forensic; Image manipulation; Manipulation tools; Natural disasters; Satellite images; Splicing detections; Splicing localizations; Satellites","Deep Learning; Forensic; Fusion; Satellite Images","Conference paper","Final","","Scopus","2-s2.0-85135909634"
"Luo X.; Tong X.; Hu Z.","Luo, Xin (56316646000); Tong, Xiaohua (55500134600); Hu, Zhongwen (55630272400)","56316646000; 55500134600; 55630272400","Improving Satellite Image Fusion via Generative Adversarial Training","2021","IEEE Transactions on Geoscience and Remote Sensing","59","8","9212572","6969","6982","13","10.1109/TGRS.2020.3025821","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111155134&doi=10.1109%2fTGRS.2020.3025821&partnerID=40&md5=52efcfa7eaddf11c1f7bf0d58f09c968","The optical images acquired from satellite platforms are commonly multiresolution images, and converting multiresolution satellite images into full higher-resolution (HR) images has been a critical technique for improving the image quality. In this study, we introduced the generative adversarial network (GAN) and proposed a new fusion GAN (FusGAN) approach for solving the remote sensing image fusion problem. Specifically, we developed a new adversarial training strategy: 1) downscaled multiresolution images are adopted for generative network (G-Net) training, and 2) the discriminative network (D-Net) is used to adversarially train the G-Net by discriminating whether the original multiresolution images have been fused well enough. To further improve the capability of the network, we structured our G-Net with residual dense blocks by combining state-of-the-art residual and dense connection ideas. Our proposed FusGAN approach is evaluated both visually and quantitatively on Sentinel-2 and Landsat Operational Land Imager (OLI) multiresolution images. As demonstrated by the results, the proposed FusGAN approach outperforms the selected benchmark methods and both perfectly preserves spectral information and reconstructs spatial information in image fusion. Considering the common resolution disparities among intra- and intersatellite images, the proposed FusGAN approach can contribute to the quality improvement of satellite images and thus improve remote sensing applications. © 1980-2012 IEEE.","Geometrical optics; Image fusion; Remote sensing; Satellites; Adversarial networks; Discriminative networks; Multiresolution images; Operational land imager; Remote sensing applications; Remote sensing images; Spatial informations; Spectral information; artificial neural network; optical method; satellite data; Image enhancement","Deep learning; generative adversarial networks (GANs); Landsat 8; remote sensing image fusion; residual dense blocks; Sentinel-2","Article","Final","","Scopus","2-s2.0-85111155134"
"Tambe R.G.; Talbar S.N.; Chavan S.S.","Tambe, Rishikesh G. (56711882100); Talbar, Sanjay N. (12800615100); Chavan, Satishkumar S. (57203944586)","56711882100; 12800615100; 57203944586","Fusion of Multispectral and Panchromatic Images by Integrating Standard PCA with Rotated Wavelet Transform","2021","Journal of the Indian Society of Remote Sensing","49","9","","2033","2055","22","10.1007/s12524-021-01373-y","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105386893&doi=10.1007%2fs12524-021-01373-y&partnerID=40&md5=1fe878b69bd7ec051af22f6e4b392217","Many pansharpening algorithms are based on the principle of extracting spatial details from panchromatic (PAN) images and injecting them into multispectral (MS) images. In this paper, we present two fusion approach based on same principle by integrating standard principle component analysis (PCA) with decimated and undecimated rotated wavelet transform. When decimated/subsampled rotated wavelet transform (SSRWT) is used for fusion of MS and PAN images, three visual artifacts get introduced in the fused image namely color distortion, shifting effect and shift distortion. To eliminate color distortion, SSRWT is integrated with standard PCA, i.e., PCA–SSRWT. Color distortion is significantly mitigated, but shifting effect and shift distortion persist in the fused image of PCA–SSRWT. After employing undecimated/nonsubsampled rotated wavelet transform (NSRWT), shifting effect and shift distortion get eliminated with minimum color distortion. However, fused image as a result of NSRWT is spectrally high but spatially low. In order to improve spatial quality and remove visual artifacts observed in SSRWT and PCA–SSRWT, NSRWT is integrated with standard PCA, i.e., PCA–NSRWT. Visual and quantitative analysis is carried out to validate the quality of fused image for all the algorithms. Visual interpretation suggests that fused image obtained using PCA–NSRWT is superior to fused images of SSRWT, PCA and NSRWT. The overall quantitative analysis manifests that the PCA–NSRWT is consistent with visual interpretation and performs better than state-of-the-art methods. PCA–NSRWT not only removes visual artifacts but also improves spectral and spatial quality of the fused image compared to individual PCA, SSRWT, NSRWT and PCA–SSRWT. Based on visual and quantitative analysis, it is observed that PCA works better with undecimated compared to decimated rotated wavelet transform for fusion. © 2021, Indian Society of Remote Sensing.","algorithm; image analysis; multispectral image; panchromatic image; principal component analysis; wavelet analysis","Nonsubsampled rotated wavelet transform (NSRWT); Principal component analysis (PCA); Satellite image fusion; Shift distortion; Shifting effect; Subsampled rotated wavelet transform (SSRWT)","Article","Final","","Scopus","2-s2.0-85105386893"
"Florez Zuluaga J.A.; David Ortega Pabon J.; Vargas Bonilla J.F.; Quintero Montova O.L.","Florez Zuluaga, Jimmy Anderson (56395438100); David Ortega Pabon, Jose (57213353575); Vargas Bonilla, Jesus Francisco (37862227500); Quintero Montova, Olga Lucia (26326549600)","56395438100; 57213353575; 37862227500; 26326549600","Meteorological Risk Early Warning System for Air Operations","2019","International Symposium on Technology and Society, Proceedings","2019-November","","8938012","","","","10.1109/ISTAS48451.2019.8938012","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077772328&doi=10.1109%2fISTAS48451.2019.8938012&partnerID=40&md5=af75fa3d160a70926716ebcbd26c80b8","Today, airspace control has the challenge of merging information from independent and heterogeneous systems in order to minimize air safety risks and facilitate the decision-making process. One of the main risks for air operations is meteorology because convective formations like Torre cumulus or cumulonimbus could generate several dangerous phenomena such as icing, wind gusts, and thunderstorms, among others, that can affect the air operation safety. Based on previous works that allow the automatic identification of convective phenomena through the fusion of multispectral satellite images and other sources as winds and Meteorological Aerodrome Report (METAR), and establishing a common georeferenced coordinates system like WGS-84, for all sources, it can generate a system that could calculate early alerts about hazardous weather conditions in the aircrafts proximality for air traffic control system. For this, a meteorological analysis system can generate information about convective clouds calculating area, heights, temperatures, risk level and position of the meteorological formation. Parallelly the convective cloud is surrounded by optimal elliptical forms centered on the convective formation, generating a meteorological object. On the other hand, there is a system responsible for monitoring the information of the surveillance sensors. This system fused the air traffic sensors available like primary and secondary radar signals and ADS-B sensors in a unique WGS-84 coordinates system. Finally, in a georeferenced raster-Type graphing system or in a Geographic Information System (GIS), the meteorological and surveillance information is correlated projecting the track routes generates by air traffic system and traces generated by meteorological objects in order to establish times and high-risk areas, early. With this information, the Air Traffic Controller (ATC) system users, could minimize risk areas and reorganize the air traffic flow. This methodology then, would contribute to the decision-making process of ATC, facilitating the air flow reorganization and minimizing meteorological risks. For the development of this project a cooperative experimental methodology by subsystems was used. It was based on an operational knowledge and normal operating procedures of the Colombian Air Force, integrated with radar tracking technologies that implement decision trees. These alerts allow the air traffic controller to assess the risk and in accordance with the evaluation, if necessary, reorganize the air traffic flow for a specific area before the aircraft enter areas of bad weather mitigating the risks. © 2019 IEEE.","Air navigation; Air transportation; Aircraft; Automation; Aviation; Clouds; Control system analysis; Controllers; Decision making; Decision trees; Flight control systems; Image fusion; Image processing; Information management; Meteorological problems; Meteorological radar; Monitoring; Radar tracking; Risk assessment; Risk management; Safety engineering; Sensor data fusion; Space-based radar; Tracking radar; Traffic surveys; Air control systems; Air Traffic Management Systems; GOES-R; Meteorological analysis; Radar data; Satellite image processing; Surveillance sensors; Air traffic control","ADS-B; Air control systems; air fusion data; Air traffic management system; GOES-R; meteorological analysis; radar data; radar fusion; radar tracking; risk management; satellite image processing; surveillance sensor","Conference paper","Final","","Scopus","2-s2.0-85077772328"
"Ruiz-Morales T.; Melo C.E.; Medina J.","Ruiz-Morales, Tania (57219661387); Melo, Carlos Eduardo (56090783200); Medina, Javier (57197825929)","57219661387; 56090783200; 57197825929","Thematic map of the Simón Bolivar metropolitan park from an image transformed by the combination of image fusion methods: High pass filter (hpf) and Á trous; [Mapa temático turístico del parque metropolitano Simón Bolívar a partir de una imagen transformada por la combinación de los métodos de fusión de imágenes: Filtro paso alto (HPF) y á trous]","2020","RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao","2020","E36","","217","228","11","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094594627&partnerID=40&md5=9e1f421f9a0a28d80a87d5240815ef80","This article presents the generation of a synthetic image with better spatial detail, which allows to recognize, identify and promote emblematic sites to visually attract tourists; specifically used as a case study, the Simon Bolivar Metropolitan Park of the city of Bogota. For the development a method of fusion of satellite images is proposed, which consists of a combination between the High Pass Filter and the “Á trous” algorithm. The objective is to expose through digital image processing techniques where the final result, corresponds to a thematic tourist map that allows to distinguish the coverage of the soil, the different structures and the places of interest, like the sports complexes that compose it, the green areas where they develop. © 2020, Associacao Iberica de Sistemas e Tecnologias de Informacao. All rights reserved.","","HPF; Image fusion; Thematic map; Tourism; Á trous","Article","Final","","Scopus","2-s2.0-85094594627"
"Ya Y.; Pan H.; Jing Z.; Ren X.; Qiao L.","Ya, Ying (57219238527); Pan, Han (37013877800); Jing, Zhongliang (7102250485); Ren, Xuanguang (57204636736); Qiao, Lingfeng (56479926200)","57219238527; 37013877800; 7102250485; 57204636736; 56479926200","Fusion object detection of satellite imagery with arbitrary-oriented region convolutional neural network","2019","Aerospace Systems","2","2","","163","174","11","10.1007/s42401-019-00033-x","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091854058&doi=10.1007%2fs42401-019-00033-x&partnerID=40&md5=92fcb249151bdf37ab1f61139c4bbc3c","Object detection on multi-source images from satellite platforms is difficult due to the characteristics of imaging sensors. Multi-model image fusion provides a possibility to improve the performance of object detection. This paper proposes a fusion object detection framework with arbitrary-oriented region convolutional neural network. First, nine kinds of pansharpening methods are utilized to fuse multi-source images. Second, a novel object detection framework based on Faster Region-based Convolutional Neural Network structure is used, which is suitable for large-scale satellite images. Region Proposal Network is adopted to generate axially aligned bounding boxes enclosing object sin different orientations, and then extract features by pooling layers with different sizes. These features are used to classify the proposals, adjust the bounding boxes, and predict the inclined boxes and the objectness/non-objectness score. Smaller anchors for small objects are considered. Finally, inclined non-maximum suppression method is utilized to get the detection results. Experimental results showed that the proposed method performs better than some state-of-the-art object detection techniques, such as YOLO-v2, YOLO-v3, etc. Some numerical tests validate the efficiency and effectiveness of the proposed method. © 2019, Shanghai Jiao Tong University.","","CNN; Image fusion; Object detection; Satellite imagery","Article","Final","","Scopus","2-s2.0-85091854058"
"Khosravi V.; Gholizadeh A.; Saberioon M.","Khosravi, Vahid (57202034112); Gholizadeh, Asa (35322496100); Saberioon, Mohammadmehdi (55795699000)","57202034112; 35322496100; 55795699000","Soil toxic elements determination using integration of Sentinel-2 and Landsat-8 images: Effect of fusion techniques on model performance","2022","Environmental Pollution","310","","119828","","","","10.1016/j.envpol.2022.119828","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135829086&doi=10.1016%2fj.envpol.2022.119828&partnerID=40&md5=8181ac08fc885834fd3e41d04980c564","Finding an appropriate satellite image as simultaneous as possible with the sampling time campaigns is challenging. Fusion can be considered as a method of integrating images and obtaining more pixels with higher spatial, spectral and temporal resolutions. This paper investigated the impact of Landsat 8-OLI and Sentinel-2A data fusion on prediction of several toxic elements at a mine waste dump. The 30 m spatial resolution Landsat 8-OLI bands were fused with the 10 m Sentinel-2A bands using various fusion techniques namely hue-saturation-value (HSV), Brovey, principal component analysis (PCA), Gram-Schmidt (GS), wavelet, and area-to-point regression kriging (ATPRK). ATPRK was the best method preserving both spectral and spatial features of Landsat 8-OLI and Sentinel-2A after fusion. Furthermore, the partial least squares regression (PLSR) model developed on genetic algorithm (GA)-selected laboratory visible-near infrared-shortwave infrared (VNIR–SWIR) spectra yielded more accurate prediction results compared to the PLSR model calibrated on the entire spectra. It was hence, applied to both individual sensors and their ATPRK-fused image. In case of the individual sensors, except for As, Sentinel-2A provided more robust prediction models than Landsat 8-OLI. However, the best performances were obtained using the fused images, highlighting the potential of data fusion to enhance the toxic elements’ prediction models. © 2022 Elsevier Ltd","Least-Squares Analysis; Principal Component Analysis; Soil; Data integration; Forecasting; Genetic algorithms; Image enhancement; Image fusion; Infrared devices; Infrared radiation; Least squares approximations; Principal component analysis; arsenic; chromium; lead; zinc; Earth observations; Fused images; Fusion techniques; LANDSAT; Partial least squares regression models; Prediction modelling; Regression-kriging; Satellite images; Soil contamination; Toxic elements; data processing; genetic algorithm; Landsat; numerical model; performance assessment; prediction; satellite imagery; Sentinel; soil pollution; area to point regression kriging; Article; Brovey method; controlled study; data accuracy; data processing; genetic algorithm; Gram Schmidt method; hue saturation value; image processing; infrared spectroscopy; mine waste; partial least squares regression; prediction; principal component analysis; satellite imagery; soil analysis; soil pollution; statistical analysis; visible near infrared shortwave infrared spectroscopy; wavelet analysis; least square analysis; soil; Landsat","Data fusion; Earth observation; Genetic algorithm; Satellite image; Soil contamination","Article","Final","","Scopus","2-s2.0-85135829086"
"Rangzan K.; Kabolizadeh M.; Karimi D.","Rangzan, Kazem (7801505713); Kabolizadeh, Mostafa (36080758400); Karimi, Danya (57193122143)","7801505713; 36080758400; 57193122143","Optimized water depth retrieval using satellite imageries based on novel algorithms","2022","Earth Science Informatics","15","1","","37","55","18","10.1007/s12145-021-00698-z","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115605309&doi=10.1007%2fs12145-021-00698-z&partnerID=40&md5=0a570909272461c8c8d5ee43e2555ca4","Bathymetry is a knowledge of water depth calculation, which is of great importance in many environmental management applications. The objective of this study is to improve the accuracy of the traditional ratio model as a widely used experimental bathymetry method. Therefore, firstly hybrid methods were proposed, which combined principal component analysis (PCA) and image fusion methods, to obtain more informative inputs for the Nayband bay bathymetry mapping under conditions of high turbidity. The results showed that the proposed hybrid bathymetry methods highly improved the accuracy of the depth maps. Then, two new algorithms, namely HybF_PSO and HybF_GA, have been introduced based on combining the proposed hybrid methods and the particle swarm optimization (PSO) or the genetic algorithm (GA) optimization methods. PSO and GA optimization methods were utilized to calculate the constant parameters of the depth model optimally. Compared to the traditional ratio model, the HybF_GA algorithm improved the bathymetry accuracy of depths shallower than − 2 m from 2.93 to 2.53, depths between − 2 and − 4 m from 3.2 to 1.56, depths between − 4 and − 8 m from 2.4 to 1.88, and areas deeper that − 8 m from 5.24 to 2.93. The HybF_PSO algorithm improved the accuracy of mapping areas deeper than − 8 m even more than the HybF_GA algorithm. Compared to the traditional ratio model, the HybF_PSO algorithm also highly improved the bathymetry accuracy in all the depth classes. Therefore, it can be concluded that the proposed bathymetry algorithms are very applicable and helpful. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","accuracy assessment; algorithm; bathymetry; detection method; optimization; satellite imagery; turbidity","Bathymetry; Image fusion; Optimization methods; PCA; Satellite images","Article","Final","","Scopus","2-s2.0-85115605309"
"Gialampoukidis I.; Moumtzidou A.; Bakratsas M.; Vrochidis S.; Kompatsiaris I.","Gialampoukidis, Ilias (55863740200); Moumtzidou, Anastasia (25924031500); Bakratsas, Marios (57191885398); Vrochidis, Stefanos (23052810300); Kompatsiaris, Ioannis (7004756014)","55863740200; 25924031500; 57191885398; 23052810300; 7004756014","A Multimodal Tensor-Based Late Fusion Approach for Satellite Image Search in Sentinel 2 Images","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12573 LNCS","","","294","306","12","10.1007/978-3-030-67835-7_25","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101636096&doi=10.1007%2f978-3-030-67835-7_25&partnerID=40&md5=9d06b3fc79f34dad159feac3ddf8e571","Earth Observation (EO) Big Data Collections are acquired at large volumes and variety, due to their high heterogeneous nature. The multimodal character of EO Big Data requires effective combination of multiple modalities for similarity search. We propose a late fusion mechanism of multiple rankings to combine the results from several uni-modal searches in Sentinel 2 image collections. We fist create a K-order tensor from the results of separate searches by visual features, concepts, spatial and temporal information. Visual concepts and features are based on a vector representation from Deep Convolutional Neural Networks. 2D-surfaces of the K-order tensor initially provide candidate retrieved results per ranking position and are merged to obtain the final list of retrieved results. Satellite image patches are used as queries in order to retrieve the most relevant image patches in Sentinel 2 images. Quantitative and qualitative results show that the proposed method outperforms search by a single modality and other late fusion methods. © 2021, Springer Nature Switzerland AG.","Big data; Convolutional neural networks; Deep neural networks; Tensors; Data collection; Earth observations; Image collections; Multiple modalities; Satellite images; Similarity search; Temporal information; Vector representations; Image fusion","Late fusion; Multimodal search; Sentinel 2 images","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85101636096"
"Kaimaris D.; Patias P.; Mallinis G.; Georgiadis C.","Kaimaris, Dimitris (36544749400); Patias, Petros (55979802800); Mallinis, Giorgos (6507765711); Georgiadis, Charalampos (7003272359)","36544749400; 55979802800; 6507765711; 7003272359","Data Fusion of Scanned Black and White Aerial Photographs with Multispectral Satellite Images","2020","Sci","2","2","29","","","","10.3390/sci2020029","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097543648&doi=10.3390%2fsci2020029&partnerID=40&md5=5d26165b17efd765f067bf1b43f29a81","To date, countless satellite image fusions have been made, mainly with panchromatic spatial resolution to a multispectral image ratio of 1/4, fewer fusions with lower ratios, and relatively recently fusions with much higher spatial resolution ratios have been published. Apart from this, there is a small number of publications studying the fusion of aerial photographs with satellite images, with the year of image acquisition varying and the dates of acquisition not mentioned. In addition, in these publications, either no quantitative controls are performed on the composite images produced, or the aerial photographs are recent and colorful and only the RGB bands of the satellite images are used for data fusion purposes. The objective of this paper is the study of the addition of multispectral information from satellite images to black and white aerial photographs of the 80s decade (1980–1990) with small difference (just a few days) in their image acquisition date, the same year and season. Quantitative tests are performed in two case studies and the results are encouraging, as the accuracy of the classification of the features and objects of the Earth’s surface is improved and the automatic digital extraction of their form and shape from the archived aerial photographs is now allowed. This opens up a new field of use for the black and white aerial photographs and archived multispectral satellite images of the same period in a variety of applications, such as the temporal changes of cities, forests and archaeological sites. © 2020 by the authors.","","black and white aerial photographs; classification; correlation tables; data fusion; multispectral satellite images","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85097543648"
"Chu G.; Li M.; Wang X.","Chu, Guozhong (57411460600); Li, Mengmeng (48761446900); Wang, Xiaoqin (55736763000)","57411460600; 48761446900; 55736763000","Integrating Height Features for Multi-scale Urban Building Type Classification from High- Resolution Remote Sensing Images; [融合高度特征的高分遥感影像多尺度城市建筑类型分类]","2021","Journal of Geo-Information Science","23","11","","2073","2085","12","10.12082/dqxxkx.2021.210365","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122790760&doi=10.12082%2fdqxxkx.2021.210365&partnerID=40&md5=d4fb6a7d0208d5e916e2a48ba9d1338e","Urban building type information is crucial to many urban applications such as the identification of urban functional areas and estimation of urban environmental variables. This paper presents a new method to extract urban building types using multi-scale features and integrating height features derived from high resolution remote sensing images. We first conduct an image semantic segmentation to extract building and shadow objects from remote sensing images, and then estimate the height of buildings based upon the directional relationship of a building object and its shadow information. Following multi-scale image analysis concept, we extract a series of multi-scale features regarding the height, geometry, and spatial structure of building objects. Last, we use a machine learning method based upon random forest to classify building types. We also analyze the impact of different spatial units of building types on classification results. Experiments were conducted in Fuzhou, Fujian province, China, using a Chinese GF-2 satellite images acquired on February 18, 2020. Our results show that: (1) The overall accuracy of building type classification combined with multi-scale features reached 82.98%, and the kappa coefficient was 0.77, which was better than other conventional methods, namely a Multi-scale Classification Without Height Features (MCNH), a Single-scale Classification Incorporating Height Features (SC), and a Single-scale Classification Without Height Features (SCNH) in this paper; (2) The classification accuracy of middle-low residential buildings and high-rise commercial and residential buildings was improved by adding height features. Compared with classification results without using height features, the overall accuracy was improved by 11.28%; (3) The fusion of image features at multiple scales can reduce the misclassification of adjacent buildings into dense buildings. Compared with a single-scale classification method, the proposed method improved overall accuracy by 2.77%. We conclude that the use of high-resolution remote sensing images provides an effective strategy to estimate building heights based upon shadow information and improves the classification accuracy of urban building types, particularly when detailed digital surface model data are absent. In addition, the fusion of multi-scale image features can improve the characterization of complex building types in urban areas and the subsequent classification accuracy accordingly. Nevertheless, we also observed that the results of classified building types were affected by the initial extraction of building information from high resolution remote sensing images, implying that a further improvement of building type classification can be done by improving the extraction methods, e.g., using a more advanced semantic segmentation model. 2021, Science Press. All right reserved.","China; Fujian; Fujian; Fuzhou; Classification (of information); Feature extraction; Housing; Image analysis; Image classification; Image enhancement; Image fusion; Image segmentation; Learning systems; Remote sensing; Semantics; Building extraction; Building height; Building type classification; Building types; Height estimation; High-resolution remote sensing images; Morphological features; Multi scale analysis; Semantic segmentation; Shadow information；building height estimation; Type classifications; building; experimental study; height determination; image analysis; remote sensing; urban area; Decision trees","Building extraction; Building type classification; High-resolution remote sensing images; Morphological features; Multi-scale analysis; Semantic segmentation; Shadow information；Building height estimation","Article","Final","","Scopus","2-s2.0-85122790760"
"Teo T.-A.; Fu Y.-J.","Teo, Tee-Ann (7005909918); Fu, Yu-Ju (57210930564)","7005909918; 57210930564","Spatiotemporal fusion of formosat-2 and landsat-8 satellite images: A comparison of “super resolution-then-blend” and “blend-then-super resolution” approaches","2021","Remote Sensing","13","4","606","1","20","19","10.3390/rs13040606","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100937279&doi=10.3390%2frs13040606&partnerID=40&md5=fab3f163f429eba556d99e56d295f81f","The spatiotemporal fusion technique has the advantages of generating time-series images with high-spatial and high-temporal resolution from coarse-resolution to fine-resolution images. A hybrid fusion method that integrates image blending (i.e., spatial and temporal adaptive reflectance fusion model, STARFM) and super-resolution (i.e., very deep super resolution, VDSR) techniques for the spatiotemporal fusion of 8 m Formosat-2 and 30 m Landsat-8 satellite images is proposed. Two different fusion approaches, namely Blend-then-Super-Resolution and Super-Resolution (SR)-then-Blend, were developed to improve the results of spatiotemporal fusion. The SR-then-Blend approach performs SR before image blending. The SR refines the image resampling stage on generating the same pixel-size of coarse-and fine-resolution images. The Blend-then-SR approach is aimed at refining the spatial details after image blending. Several quality indices were used to analyze the quality of the different fusion approaches. Experimental results showed that the performance of the hybrid method is slightly better than the traditional approach. Images obtained using SR-then-Blend are more similar to the real observed images compared with images acquired using Blend-then-SR. The overall mean bias of SR-then-Blend was 4% lower than Blend-then-SR, and nearly 3% improvement for overall standard deviation in SR-B. The VDSR technique reduces the systematic deviation in spectral band between Formosat-2 and Landsat-8 satellite images. The integration of STARFM and the VDSR model is useful for improving the quality of spatiotemporal fusion. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Image acquisition; Optical resolving power; Satellites; Fine-resolution images; High temporal resolution; Image resampling; Spatio-temporal fusions; Standard deviation; Systematic deviation; Temporal adaptive; Traditional approaches; Image fusion","Deep learning; Image fusion; STARFM; Time-series satellite images; VDSR","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85100937279"
"Nuthammachot N.; Askar A.; Stratoulias D.; Wicaksono P.","Nuthammachot, Narissara (57204889352); Askar, Askar (57211992632); Stratoulias, Dimitris (56270527600); Wicaksono, Pramaditya (54279699900)","57204889352; 57211992632; 56270527600; 54279699900","Combined use of Sentinel-1 and Sentinel-2 data for improving above-ground biomass estimation","2022","Geocarto International","37","2","","366","376","10","10.1080/10106049.2020.1726507","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079697733&doi=10.1080%2f10106049.2020.1726507&partnerID=40&md5=516de63a505e61bd8e10ee9342d8961c","Above-ground Biomass (AGB) represents the largest amount of biomass found on earth. Passive and active remote sensors have been a useful tool in estimating AGB for this purpose; nevertheless, both data sources suffer from saturation problems in dense vegetation. A combination of optical and radar data could potentially increase the accuracy of AGB estimation. In this study we evaluate the synergistic use of Sentinel-1 and Sentinel-2 for assessing AGB in a private forest in Yogyakarta, Indonesia. Forty five sample plots of 20 m x 20 m were used as ground truth data. AGB correlated with Sentinel-1 backscatter and Sentinel-2 derived variables with R2 = 0.34 and R2 = 0.82, respectively; nevertheless, the synergistic use of Sentinel-1 and Sentinel-2 yielded the highest accuracy (i.e., R2 = 0.84). The results indicate that AGB in Yogyakarta is most accurately estimated based on the synergy of optical and radar satellite images. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","Indonesia; Yogyakarta; aboveground biomass; backscatter; forest; image analysis; satellite data; Sentinel","Above-ground biomass; image fusion; private forest; Sentinel-1; Sentinel-2","Article","Final","","Scopus","2-s2.0-85079697733"
"Heidarian Dehkordi R.; Pelgrum H.; Meersmans J.","Heidarian Dehkordi, Ramin (57218627173); Pelgrum, Henk (6603073020); Meersmans, Jeroen (24399409600)","57218627173; 6603073020; 24399409600","High spatio-temporal monitoring of century-old biochar effects on evapotranspiration through the ETLook model: a case study with UAV and satellite image fusion based on additive wavelet transform (AWT)","2022","GIScience and Remote Sensing","59","1","","111","141","30","10.1080/15481603.2021.2016262","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121728046&doi=10.1080%2f15481603.2021.2016262&partnerID=40&md5=2a4add7c2152754ed0e8491582fa5b5a","It can be challenging to fuse remotely-sensed images with large differences in spatial resolutions. In this paper, we used additive wavelet transform (AWT) to fuse Landsat-8 (30 m) and unmanned aerial vehicle (UAV) images (7 cm and 3.7 cm for thermal and multispectral images, respectively) as one of the primary studies. AWT image fusion generated sharpened Landsat-8 (L-8) images which were significantly correlated with coarse resolution images, while also well preserving the spatial details. Surface albedo (α0), normalized difference vegetation index (NDVI), and surface temperature (ST) were computed from multispectral and thermal sensors on board of UAV and L-8 platforms. High-resolution UAV and AWT sharpened L-8 images were then used in ETLook model to estimate evapotranspiration (ET) across an agricultural farm enriched with century-old biochar. High spatio-temporal analysis demonstrated a significant decrease in α0 across the biochar patches during the early development stages of winter wheat. Moreover, biochar significantly stimulated the development of wheat canopies towards the middle of the cropping season. There were however no impacts at the end of the season due to dense wheat canopies covering the aggravated dark colour soil across the biochar patches. ST was not affected by biochar either at the beginning or towards the end of the season. Neither was there any impact of biochar on actual ET over the season. Our approach can help to develop robust techniques for fusion of UAV and satellite images in light of climate-smart agriculture, and is also applicable to other farms with any specific precision agricultural treatments. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","agriculture; albedo; biochar; evapotranspiration; Landsat; NDVI; satellite imagery; spatiotemporal analysis; surface temperature; transform; unmanned vehicle; wavelet analysis","Evapotranspiration; image fusion; Landsat-8; surface albedo; surface temperature; UAV","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85121728046"
"Arefin R.; Meshram S.G.; Santos C.A.G.; da Silva R.M.; Pushparaj J.","Arefin, Riad (57202254195); Meshram, Sarita Gajbhiye (57190754999); Santos, Celso Augusto Guimarães (7201458646); da Silva, Richarde Marques (56208649100); Pushparaj, Jagalingam (57193551482)","57202254195; 57190754999; 7201458646; 56208649100; 57193551482","Hybrid modelling approach for water body change detection at Chalan Beel area in northern Bangladesh","2020","Environmental Earth Sciences","79","19","442","","","","10.1007/s12665-020-09185-y","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091315842&doi=10.1007%2fs12665-020-09185-y&partnerID=40&md5=47a08c233669a3328a7aecbfee0b2673","Water is a strategic resource for both socio-economic development and human life. The current study has been carried out for spatio-temporal change detection of surface water bodies during winter period using hybrid modelling approach. The study area has fallen in the northern part of Bangladesh and is locally called Chalan Beel with 5 million of in habitants, a prominent intensive crop production, surface and groundwater irrigation, high evapotranspiration, and water scarcity. For the detection of water body changes, satellite images of 1999 and 2011 were used, and the following image fusion techniques were applied: (a) Gram-Schmidt (GS), (b) modified intensity hue saturation (IHS), (c) high-pass filter (HPF), and (d) wavelet. Landsat 7/ETM + panchromatic (PAN) band of 15 m × 15 m resolution in 1999 and Landsat 5/TM multispectral (MS) bands of 30 m × 30 m resolution in 2011 were allied each other to generate high-resolution image that contains information of two different years. The fused images were classified to extract the water bodies using four classification methods: (a) artificial neural network (ANN), (b) support vector machine (SVM) and (c) maximum likelihood (ML). To analyze the quality of the fused images, statistical calculation (quantitatively) and Laplacian edge detection (qualitatively) were used. To validate the fused image classification results, the multispectral images from 1999 and 2011 were again individually classified using principal component analysis (PCA), normalized difference water index (NDWI), and image differencing (ID) processes and compared with the previous classification. Surprisingly, the results showed that two-third of the areas dried up in 10 years. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Bangladesh; Cultivation; Economics; Edge detection; Groundwater; High pass filters; Image analysis; Image fusion; Maximum likelihood; Support vector machines; Surface waters; Classification methods; Groundwater irrigation; Image fusion techniques; Intensity hue saturations; Normalized difference water index; Socio-economic development; Spatio-temporal changes; Statistical calculations; artificial neural network; groundwater resource; groundwater-surface water interaction; hydrological regime; image analysis; image classification; image resolution; Landsat; support vector machine; water quality; Image classification","Bangladesh; Chalan beel; Change detection; Image fusion; Landsat image; Remote sensing; Surface water","Article","Final","","Scopus","2-s2.0-85091315842"
"Ablin R.; Sulochana C.; Prabin G.","Ablin, R. (57199742245); Sulochana, C.Helen (35520397900); Prabin, G. (52464313900)","57199742245; 35520397900; 52464313900","An investigation in satellite images based on image enhancement techniques","2020","European Journal of Remote Sensing","53","sup2","","86","94","8","10.1080/22797254.2019.1673216","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074054784&doi=10.1080%2f22797254.2019.1673216&partnerID=40&md5=ebb17b157584996b931b07d5db4de75d","In Satellite Images, enhancement plays a dynamic research topic in image processing. The aim of enhancement is to process an image so that the result is more suitable than original image for specific remote sensing application. Satellite image enhancement techniques provide a lot of choices for improving the visual quality of remotely sensed images. In this research review, image fusion plays an important role, since it effectively combines auxiliary image content to enhance information contained in the individual datasets. This article provides an overview of the existing enhancement techniques. There are many techniques which have been proposed for enhancing the digital images which may be used for enhancing Satellite images. Here, a survey on various Satellite image enhancement techniques has been performed which recommends fusion-based enhancement performs superior while comparing with non-fusion-based enhancement techniques. © 2019 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Flow visualization; Image fusion; Image processing; Remote sensing; Satellites; Dynamic researches; Image content; Original images; Remote sensing applications; Remotely sensed images; Research review; Satellite images; Visual qualities; data interpretation; data quality; data set; digital mapping; image analysis; image resolution; satellite data; satellite imagery; Image enhancement","Image fusion; image processing; remote sensing; satellite image enhancement; visualization","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85074054784"
"Li W.; Yang C.; Peng Y.; Zhang X.","Li, Weisheng (36067507500); Yang, Chao (57263586100); Peng, Yidong (57192995836); Zhang, Xiayan (57219233195)","36067507500; 57263586100; 57192995836; 57219233195","A Multi-Cooperative Deep Convolutional Neural Network for Spatiotemporal Satellite Image Fusion","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","","10174","10188","14","10.1109/JSTARS.2021.3113163","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115163134&doi=10.1109%2fJSTARS.2021.3113163&partnerID=40&md5=fe8b2ef65e762a1ee49abf3181490716","Remote sensing satellite images with high temporal and high spatial resolution play a critical role in earth science applications. However, it is difficult for a single satellite to obtain such images due to technical and cost constraints. Therefore, spatiotemporal image fusion based on deep learning has received extensive attention in recent years. This article proposes a multicooperative deep convolutional neural network (MCDNet) for spatiotemporal satellite image fusion. This method is a new multinetwork model in which multiple networks work together to reconstruct the predicted image. The multinetwork model consists of a super-resolution network, a difference reconstruction network, and a collaborative training network. First, the super-resolution network uses the combination of a novel multiscale mechanism and dilated convolutions to make full use of the spectral information of the coarse image and upgrade it to a transitional image that matches the fine image. The difference reconstruction network uses structural relevance to complete the reconstruction of the fine difference image. The collaborative training network extracts the hidden information from the fine image and uses the time relevance to restrict the training of the difference reconstruction network. Finally, the fine difference image and the known fine image are combined to complete the image fusion. The new compound loss function can help multinetwork models better complete cooperative training. Through experiments on two datasets and comparison with existing fusion algorithms, the subjective and objective results prove that MCDNet can effectively reconstruct higher-quality prediction images. © 2008-2012 IEEE.","Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Image reconstruction; Optical resolving power; Remote sensing; Satellites; Collaborative training; High spatial resolution; Multiscale mechanisms; Reconstruction networks; Remote sensing satellites; Science applications; Spatiotemporal images; Spectral information; algorithm; artificial neural network; data set; remote sensing; satellite imagery; spatiotemporal analysis; training; Image fusion","Convolutional neural network (CNN); dilated convolution; multiscale mechanism; spatiotemporal fusion","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85115163134"
"Toro Garay G.H.; Median Daza J.","Toro Garay, Giselle Helena (57199146070); Median Daza, Javier (57215487307)","57199146070; 57215487307","Implementation of a scaling wavelet plane used during the ikonos image fusion process, from decomposition à troús; [Implementación de un plano wavelet de escalamiento utilizado durante el proceso de fusión de imágenes ikonos, a partir de la descomposición à troús]","2020","RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao","2020","E28","","230","243","13","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081000566&partnerID=40&md5=115a2a688cecd2f10989f461f62c0470","The fusion of satellite images represents one of the most efficient techniques to obtain images with high spatial or spectral quality according to the user’s needs. However, these modifications act in inverse form, when obtaining high quality in a spectral resolution, there is a loss of quality than the other. Several algorithms and modifications have been presented to try to decrease this proportion or keep it at similar levels. In this work, image fusion is used with the discrete wavelet transform; applying the à troús algorithm. In this algorithm the decomposition is rectangular and the spatial filter spatial filter b3 spline is generally used. during the process this filter is expanded, as proposed, this expansion is modified, keeping the symmetry conditions, which alllows us to find a fused image that assess with different quality indices (Entropy, Universal Quality, Divergence, Bias, Correlation coefficient, RASE, RMSE, ERGAS, RASE) it has a greater spectral richness and largely maintains spatial richness. © 2020, Associacao Iberica de Sistemas e Tecnologias de Informacao. All rights reserved.","","B3 spline; Image fusion; Spatial filter; Wavelet Transform; À troús","Article","Final","","Scopus","2-s2.0-85081000566"
"Kong J.; Ryu Y.; Huang Y.; Dechant B.; Houborg R.; Guan K.; Zhu X.","Kong, Juwon (57221054115); Ryu, Youngryel (24399902600); Huang, Yan (57201395501); Dechant, Benjamin (57194380653); Houborg, Rasmus (55887377500); Guan, Kaiyu (56382070400); Zhu, Xiaolin (55696724800)","57221054115; 24399902600; 57201395501; 57194380653; 55887377500; 56382070400; 55696724800","Evaluation of four image fusion NDVI products against in-situ spectral-measurements over a heterogeneous rice paddy landscape","2021","Agricultural and Forest Meteorology","297","","108255","","","","10.1016/j.agrformet.2020.108255","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098084686&doi=10.1016%2fj.agrformet.2020.108255&partnerID=40&md5=3788c41d9d1ce04a91c1b57a97c0c919","Satellite image fusion methods that improve spatial and temporal resolution have significant potential to advance understanding of ecosystem dynamics in space and time. However, systematic evaluations of image fusion methods against in situ spectral data are lacking. Here, we used a suite of in situ spectral data collected at 60 elementary sampling units (10 × 10 m) covering 15 Landsat pixel (30 × 30 m) plots and one Moderate Resolution Imaging Spectroradiometer (MODIS) pixel (250 × 250 m) throughout the entire growing season in a heterogeneous rice paddy landscape to evaluate four state-of-the-art image fusion NDVI products. They include the Enhanced Spatial and Temporal Adaptive Reflectance Fusion Model (ESTARFM), Flexible Spatiotemporal DAta Fusion (FSDAF), SaTellite dAta IntegRation (STAIR), and the CubeSat Enabled Spatio-Temporal Enhancement Method (CESTEM); the former three blended Landsat and MODIS data, whereas the latter combined CubeSats, Landsat, and MODIS observations. All fusion products showed strong linear relationships against in situ data when combining all spatial and temporal observations (R2: 0.73 to 0.93) although there were partly negative biases (–1% to –9%). These biases resulted from forcing data to image fusion algorithms, such as Landsat (–4%) and MODIS (–7%). Performance difference between fusion methods were considerably larger for spatial than for temporal variation. Furthermore, Landsat NDVI explained only 17–22% of spatial variation against in situ spectral data, which can be translated into weak performance of image fusion products to predict spatial variability in NDVI. Image fusion products that relied on spatial interpolation showed large biases (–15% to –30%) for a vegetation plot surrounded by mixed land cover plots. Our results highlight key sources of uncertainty and will be instrumental in improving satellite image fusion methods to monitor land surface phenology in space and time. © 2020 Elsevier B.V.","Varanidae; ecosystem dynamics; growing season; image analysis; in situ measurement; land cover; Landsat; landscape ecology; measurement method; MODIS; NDVI; paddy field; rice; satellite altimetry; satellite data; satellite imagery; spectral analysis","","Article","Final","","Scopus","2-s2.0-85098084686"
"Chi X.-H.; Wang R.; Yu X.-C.; Zeng L.-S.; Wu Y.-B.","Chi, Xing-hua (57216270916); Wang, Rui (57216273260); Yu, Xing-chao (57007394500); Zeng, Ling-sha (57216270913); Wu, Yun-bi li ge (57216273233)","57216270916; 57216273260; 57007394500; 57216270913; 57216273233","A Brief Discussion on the Method and Key Technology of Using ZY-3","2020","Advances in Intelligent Systems and Computing","1146 AISC","","","397","402","5","10.1007/978-3-030-43306-2_56","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082992221&doi=10.1007%2f978-3-030-43306-2_56&partnerID=40&md5=cd1f145aadd03b352efd66bdf65135f4","Digital orthography (DOM) is an important 4D mapping product. In this paper, according to the characteristics of ZY-3 satellite image, the technical process of making orthophoto image based on ZY-3 satellite image is designed, the key technology of orthophoto image making and the quality inspection method are introduced, and the useful exploration of making orthophoto image of the area without measurement control points is carried out. © Springer Nature Switzerland AG 2020.","Computer programming; Computer science; Image mosaic; Key technologies; Measurement control; Orthophoto images; Quality inspection methods; Technical process; The DOM; ZY-3; Image fusion","Image fusion; Image Mosaic; The DOM; The key technology; ZY-3","Conference paper","Final","","Scopus","2-s2.0-85082992221"
"Moghimi A.; Mohammadzadeh A.; Celik T.; Amani M.","Moghimi, Armin (57194760236); Mohammadzadeh, Ali (16070064500); Celik, Turgay (35101499300); Amani, Meisam (56684747900)","57194760236; 16070064500; 35101499300; 56684747900","A Novel Radiometric Control Set Sample Selection Strategy for Relative Radiometric Normalization of Multitemporal Satellite Images","2021","IEEE Transactions on Geoscience and Remote Sensing","59","3","9133139","2503","2519","16","10.1109/TGRS.2020.2995394","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094805754&doi=10.1109%2fTGRS.2020.2995394&partnerID=40&md5=888cdbd449f3c383cb1b04e19a4f3b30","This article presents a new relative radiometric normalization (RRN) method for multitemporal satellite images based on the automatic selection and multistep optimization of the radiometric control set samples (RCSS). A novel image-fusion strategy based on the fast local Laplacian filter is employed to generate a difference index using the complementary information extracted from the change vector analysis and absolute gradient difference of the bitemporal satellite images. The difference index is then segmented into changed and unchanged pixels using a fast level-set method. A novel local outlier method is then applied to the unchanged pixels of the bitemporal images to identify the initial RCSS, which are then scored by a novel unchanged purity index, and the histogram of the scores is used to produce the final RCSS. The RRN between the bitemporal images is achieved by adjusting the subject image to the reference image using orthogonal linear regression on the final RCSS. The proposed method is applied to seven different data sets comprised of bitemporal images acquired by various satellites, including Landsat TM/ETM+, Sentinel 2B, Worldview 2/3, and Aster. The experimental results show that the method outperforms the state-of-the-art RRN methods. It reduces the average root-mean-square error (RMSE) of the best baseline method (IR-MAD) by up to 32% considering all data sets. © 1980-2012 IEEE.","Satellites; Image fusion; Mean square error; Pixels; Radiometry; Satellites; Automatic selection; Change vector analysis; Fast level set methods; Fusion strategies; Laplacian filters; Multi-temporal satellite images; Relative radiometric normalization; Root mean square errors; histogram; Landsat; optimization; remote sensing; satellite imagery; Sentinel; temporal analysis; Numerical methods","Change vector analysis (CVA); multitemporal satellite images; radiometric control set samples (RCSS); relative radiometric normalization (RRN)","Article","Final","","Scopus","2-s2.0-85094805754"
"Tuesta-Monteza V.; Vásquez Y.P.; Mejía-Cabrera H.I.; Forero M.G.","Tuesta-Monteza, Victor (57193776107); Vásquez, Yelsin Pérez (57219421678); Mejía-Cabrera, Heber I. (57193775165); Forero, Manuel G. (15831912100)","57193776107; 57219421678; 57193775165; 15831912100","Evaluation of panchromatic and multispectral fusion methods","2020","Proceedings of SPIE - The International Society for Optical Engineering","11510","","115101U","","","","10.1117/12.2567829","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092630866&doi=10.1117%2f12.2567829&partnerID=40&md5=26250baa33e0a7fcd6cbd3ccbfe17cd3","Earth observation satellites provide multispectral images that are characterized by good spectral quality but low spatial quality. They also provide panchromatic images that, on the contrary, are characterized by good spatial quality but low spectral quality. Therefore, it is important to merge both images to obtain a single one that contains complementary information and can be used in land resource studies, surface geology, water management, forests, urban development, agriculture, and others. For this reason, it is important to evaluate the techniques used for the fusion of multispectral and panchromatic images: EIHS, Brovey and Averaging. Therefore, in this work these three techniques are evaluated, using the quantitative indices: spectral ERGAS and spatial ERGAS. In this way, the quality of the resulting fused images can be measured. Natural images were used to make the evaluation. The results show, on the one hand, that the best spectral quality is obtained with the Averaging algorithm, followed by the Brovey and, thirdly, by the EIHS. On the other hand, the best spatial quality was obtained with the EIHS algorithm, followed by the Brovey and then by the Averaging algorithm. It was also found that by averaging the values obtained in both evaluations that the best quality of fusion is obtained with the Averaging algorithm, followed by the Brovey and finally by the EIHS. © 2020 SPIE.","Agricultural robots; Image processing; Information management; Urban growth; Water management; Earth observation satellites; Multispectral fusion; Multispectral images; Panchromatic images; Quantitative indices; Spatial quality; Spectral quality; Urban development; Quality control","Averaging; Brovey; EIHS; ERGAS; Image fusion; Multispectral images; Panchromatic images; Satellite images","Conference paper","Final","","Scopus","2-s2.0-85092630866"
"Lim H.; Park H.","Lim, Heechang (57220103889); Park, Honglyun (57195485987)","57220103889; 57195485987","Supervised classification for greenhouse detection by using sharpened SWIR bands of Sentinel-2A satellite imagery","2020","Journal of the Korean Society of Surveying, Geodesy, Photogrammetry and Cartography","38","5","","435","441","6","10.7848/ksgpc.2020.38.5.435","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096932560&doi=10.7848%2fksgpc.2020.38.5.435&partnerID=40&md5=68c3212540e9e323885b31fefb376601","Sentinel-2A satellite imagery provides VNIR (Visible Near InfraRed) and SWIR (ShortWave InfraRed) wavelength bands, and it is known to be effective for land cover classification, cloud detection, and environmental monitoring. Greenhouse is one of the middle classification classes for land cover map provided by the Ministry of Environment of the Republic of Korea. Since greenhouse is a class that has a lot of changes due to natural disasters such as storm and flood damage, there is a limit to updating the greenhouse at a rapid cycle in the land cover map. In the present study, we utilized Sentinel-2A satellite images that provide both VNIR and SWIR bands for the detection of greenhouse. To utilize Sentinel-2A satellite images for the detection of greenhouse, we produced high-resolution SWIR bands applying to the fusion technique performed in two stages and carried out the detection of greenhouse using SVM (Support Vector Machine) supervised classification technique. In order to analyze the applicability of SWIR bands to greenhouse detection, comparative evaluation was performed using the detection results applying only VNIR bands. As a results of quantitative and qualitative evaluation, the result of detection by additionally applying SWIR bands was found to be superior to the result of applying only VNIR bands. © 2020 Korean Society of Surveying. All rights reserved.","South Korea; carbon emission; detection method; greenhouse effect; image processing; land cover; natural disaster; satellite imagery; Sentinel; supervised classification; support vector machine","Image Fusion; Sentinel-2A; Supervised Classification; SVM (Support Vector Machine); SWIR (ShortWave InfraRed)","Article","Final","","Scopus","2-s2.0-85096932560"
"Park S.; Park N.-W.; Na S.-I.","Park, Soyeon (57215420514); Park, No-Wook (7202111787); Na, Sang-Il (57217287093)","57215420514; 7202111787; 57217287093","An Object-Based Weighting Approach to Spatiotemporal Fusion of High Spatial Resolution Satellite Images for Small-Scale Cropland Monitoring","2022","Agronomy","12","10","2572","","","","10.3390/agronomy12102572","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140433373&doi=10.3390%2fagronomy12102572&partnerID=40&md5=554b6813ed37b7f5497a6b0c2ae8f41b","Continuous crop monitoring often requires a time-series set of satellite images. Since satellite images have a trade-off in spatial and temporal resolution, spatiotemporal image fusion (STIF) has been applied to construct time-series images at a consistent scale. With the increased availability of high spatial resolution images, it is necessary to develop a new STIF model that can effectively reflect the properties of high spatial resolution satellite images for small-scale crop field monitoring. This paper proposes an advanced STIF model using a single image pair, called high spatial resolution image fusion using object-based weighting (HIFOW), for blending high spatial resolution satellite images. The four-step weighted-function approach of HIFOW includes (1) temporal relationship modeling, (2) object extraction using image segmentation, (3) weighting based on object information, and (4) residual correction to quantify temporal variability between the base and prediction dates and also represent both spectral patterns at the prediction date and spatial details of fine-scale images. The specific procedures tailored for blending fine-scale images are the extraction of object-based change and structural information and their application to weight determination. The potential of HIFOW was evaluated from the experiments on agricultural sites using Sentinel-2 and RapidEye images. HIFOW was compared with three existing STIF models, including the spatial and temporal adaptive reflectance fusion model (STARFM), flexible spatiotemporal data fusion (FSDAF), and Fit-FC. Experimental results revealed that the HIFOW prediction could restore detailed spatial patterns within crop fields and clear crop boundaries with less spectral distortion, which was not represented in the prediction results of the other three models. Consequently, HIFOW achieved the best prediction performance in terms of accuracy and structural similarity for all the spectral bands. Other than the reflectance prediction, HIFOW also yielded superior prediction performance for blending normalized difference vegetation index images. These findings indicate that HIFOW could be a potential solution for constructing high spatial resolution time-series images in small-scale croplands. © 2022 by the authors.","","crop monitoring; image segmentation; multi-sensor images; resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85140433373"
"Medina J.; Vera N.; Upegui E.","Medina, Javier (57197825929); Vera, Nelson (56743087900); Upegui, Erika (36459015100)","57197825929; 56743087900; 36459015100","A comparative study for the assessment of Ikonos satellite image-fusion techniques","2022","Indonesian Journal of Electrical Engineering and Computer Science","25","1","","256","264","8","10.11591/ijeecs.v25.i1.pp256-264","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122064070&doi=10.11591%2fijeecs.v25.i1.pp256-264&partnerID=40&md5=7c67d371c9879291e99f073f7309624e","Image-fusion provide users with detailed information about the urban and rural environment, which is useful for applications such as urban planning and management when higher spatial resolution images are not available. There are different image fusion methods. This paper implements, evaluates, and compares six satellite image-fusion methods, namely wavelet 2D-M transform, gram schmidt, high-frequency modulation, high pass filter (HPF) transform, simple mean value, and PCA. An Ikonos image (Panchromatic-PAN and multispectral-MULTI) showing the northwest of Bogotá (Colombia) is used to generate six fused images: MULTIWavelet 2D-M, MULTIG-S, MULTIMHF, MULTIHPF, MULTISMV, and MULTIPCA. In order to assess the efficiency of the six image-fusion methods, the resulting images were evaluated in terms of both spatial quality and spectral quality. To this end, four metrics were applied, namely the correlation index, erreur relative globale adimensionnelle de synthese (ERGAS), relative average spectral error (RASE) and the Q index. The best results were obtained for the MULTISMV image, which exhibited spectral correlation higher than 0.85, a Q index of 0.84, and the highest scores in spectral assessment according to ERGAS and RASE, 4.36% and 17.39% respectively. © 2022 Institute of Advanced Engineering and Science. All rights reserved.","","Fusion Gram schmidt High frequency modulation PCA Satellite images Simple mean value Wavelet 2D-M","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85122064070"
"Medina-Daza R.J.; Vera-Parra N.E.; Restrepo-Rodriguez A.O.","Medina-Daza, Ruben Javier (57199150874); Vera-Parra, Nelson Enrique (56809301400); Restrepo-Rodriguez, Andres Ovidio (57208672336)","57199150874; 56809301400; 57208672336","Sallfus, library for satellite images fusion on homogeneous and heterogeneous computing architectures","2020","IEEE Latin America Transactions","18","12","9400441","2130","2137","7","10.1109/TLA.2020.9400441","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104305529&doi=10.1109%2fTLA.2020.9400441&partnerID=40&md5=0fcc587487dc4eacdf984e513765ef5a","Fusion of satellite images consists of improving the quality of a multispectral image by combining data from a high spatial resolution panchromatic image with a high spectral resolution multispectral image. To carry out this, different techniques are available, which perform various operations at the pixel level, which leads to generating a dependency between the computational requirement and the image size. Currently, there are some libraries that implement these fusion methods, however, none of them allow this fusion process to be carried out on heterogeneous architectures, which enable the integration of acceleration platforms that reduce execution time through massive parallelization. For this reason, this document presents a library called Sallfus, which allows executing and evaluating the quality and performance of image fusion methods such as the Brovey transform, Multiplicative method, Principal Component Analysis (PCA) and Wavelet A trous, on homogeneous and heterogeneous architectures. Likewise, an evaluation of the library is made from an analysis of execution times and image quality using mathematical-statistical indices such as the correlation coefficient (CC), BIAS coefficient and Root of the Root Mean Square Error (RMSE). The results of the library evaluation showed that the merging process with images of 8192 pixels, presents a speed-up of approximately 591x for Brovey, 309x for Multiplicative, 18x for PCA and 6x for A trous. Additionally, it was observed that the methods that presented the best performance both computationally and in the quality of the merged image were Brovey and Wavelet A trous. Availability and implementation: https://github.com/Parall-UD/sallfus. © 2003-2012 IEEE.","Computer architecture; Image analysis; Image enhancement; Image fusion; Mean square error; Pixels; Quality control; Spectral resolution; Computational requirements; Correlation coefficient; Heterogeneous architectures; Heterogeneous computing; High spatial resolution; High spectral resolution; Image fusion methods; Root mean square errors; Image quality","Brovey transform; Heterogenous Computing; Multiplicative transform; Principal Component Analysis; Satellite-image fusion; Wavelet À trous","Article","Final","","Scopus","2-s2.0-85104305529"
"Wang J.; Chen J.; Wang Q.","Wang, Jian (57221359948); Chen, Jiaqi (48160919100); Wang, Qingwei (57210324380)","57221359948; 48160919100; 57210324380","Fusion of POLSAR and Multispectral Satellite Images: A New Insight for Image Fusion","2020","Proceedings of the 2020 IEEE International Conference on Computational Electromagnetics, ICCEM 2020","","","9219457","83","84","1","10.1109/ICCEM47450.2020.9219457","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095584450&doi=10.1109%2fICCEM47450.2020.9219457&partnerID=40&md5=9ef6dede6b475205025cce468d6654d4","Polarized synthetic aperture radar (POLSAR) and multispectral images have great complementarity in information volume. That is to say, POLSAR have high resolution but poor color information. Multispectral images have rich spectral channel information, but the resolution is low. Therefore, this work has explored the fusion problem of the two data source. A framework was proposed, which merged polarized channel fusion data and multispectral images based on the Sentinel-2 and GF-3 data. The experimental results showed that the fusion results greatly integrated the characteristics of each channel of POLSAR and optical image. Therefore, our work has great application potential in improving the accuracy of feature recognition.  © 2020 IEEE.","Computational electromagnetics; Geometrical optics; Synthetic aperture radar; Color information; Data-source; Feature recognition; High resolution; Multispectral images; Multispectral satellite image; Optical image; Spectral channels; Image fusion","Feature recognition; Fusion; GF-3; Polarized synthetic aperture radar (POL-SAR); Sentinel-2","Conference paper","Final","","Scopus","2-s2.0-85095584450"
"Pastorino M.; Montaldo A.; Fronda L.; Hedhli I.; Moser G.; Serpico S.B.; Zerubia J.","Pastorino, Martina (57222463026); Montaldo, Alessandro (57212479880); Fronda, Luca (57212479749); Hedhli, Ihsen (56422415400); Moser, Gabriele (7101795745); Serpico, Sebastiano B. (7005306316); Zerubia, Josiane (56211628500)","57222463026; 57212479880; 57212479749; 56422415400; 7101795745; 7005306316; 56211628500","Multisensor and multiresolution remote sensing image classification through a causal hierarchical markov framework and decision tree ensembles","2021","Remote Sensing","13","5","849","1","25","24","10.3390/rs13050849","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102777777&doi=10.3390%2frs13050849&partnerID=40&md5=9d44023ed349a581d572e0df4c5a87ee","In this paper, a hierarchical probabilistic graphical model is proposed to tackle joint classification of multiresolution and multisensor remote sensing images of the same scene. This problem is crucial in the study of satellite imagery and jointly involves multiresolution and multisensor image fusion. The proposed framework consists of a hierarchical Markov model with a quadtree structure to model information contained in different spatial scales, a planar Markov model to account for contextual spatial information at each resolution, and decision tree ensembles for pixelwise modeling. This probabilistic graphical model and its topology are especially fit for application to very high resolution (VHR) image data. The theoretical properties of the proposed model are analyzed: the causality of the whole framework is mathematically proved, granting the use of time-efficient inference algorithms such as the marginal posterior mode criterion, which is non-iterative when applied to quadtree structures. This is mostly advantageous for classification methods linked to multiresolution tasks formulated on hierarchical Markov models. Within the proposed framework, two multimodal classification algorithms are developed, that incorporate Markov mesh and spatial Markov chain concepts. The results obtained in the experimental validation conducted with two datasets containing VHR multispectral, panchromatic, and radar satellite images, verify the effectiveness of the proposed framework. The proposed approach is also compared to previous methods that are based on alternate strategies for multimodal fusion. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Decision trees; Graphic methods; Image classification; Image fusion; Inference engines; Iterative methods; Remote sensing; Satellite imagery; Topology; Classification algorithm; Contextual spatial information; Experimental validations; Marginal posterior modes; Multi-resolution remote sensing; Multisensor remote sensing; Probabilistic graphical models; Very high resolution (VHR) image; Markov chains","Causal Markov model; Decision tree ensemble; Hierarchical Markov random field; Markov chain; Markov mesh random field; Multimodal data fusion; Multiresolution and multisensor fusion; Remote sensing; Semantic image segmentation","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85102777777"
"Jovhari N.; Farhadi N.; Sedaghat A.; Mohammadi N.","Jovhari, N. (58080647700); Farhadi, N. (58080647800); Sedaghat, A. (54279304900); Mohammadi, N. (57198154105)","58080647700; 58080647800; 54279304900; 57198154105","PERFORMANCE EVALUATION OF LEARNING-BASED METHODS FOR MULTISPECTRAL SATELLITE IMAGE MATCHING","2023","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","10","4/W1-2022","","335","341","6","10.5194/isprs-annals-X-4-W1-2022-335-2023","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146937142&doi=10.5194%2fisprs-annals-X-4-W1-2022-335-2023&partnerID=40&md5=7a0cdd0e557e67ead334ddf73467eb67","Multispectral image registration is one of the most critical requirements to achieve reliable remote sensing goals such as change detection, image fusion, etc., due to providing complementary knowledge of the scene. On the one hand, this issue has always been a hot topic of research according to significant appearance differences, including geometric and nonlinear radiometric distortions. On the other hand, developing deep learning methods promises precise results in image processing and, in particular, image registration. It is no longer limited to low-level information structures, such as intensity and gradients. However, it is possible to provide more reliable results by extracting various high-level features and removing feature engineering. Therefore, we need extensive experiments in multispectral image registration to determine an efficient and robust method. To this end, this paper evaluates six well-known recently proposed learning-based feature descriptors, including LOFTR, TFeat, HardNet8, HardNet, SosNet, and HyNet, against geometric distortions within real multispectral images. Evaluations demonstrate the general superiority of the HardNet8 descriptor due to extracting high-level features within eight convolution layers. © Author(s) 2023. CC BY 4.0 License.","Deep learning; Geometry; Image fusion; Learning systems; Remote sensing; Deep learning; Feature descriptors; Geometric difference; High-level features; Illumination variation; Images registration; Learning-based methods; Multispectral images; Multispectral satellite image; Performances evaluation; Image registration","Deep Learning; Feature Descriptors; Geometric Differences; Illumination Variations; Image Registration; Multispectral Images","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85146937142"
"Huang B.; Li Z.; Yang C.; Sun F.; Song Y.","Huang, Binghui (57216946822); Li, Zhi (57208551292); Yang, Chao (57195032153); Sun, Fuchun (57204699218); Song, Yixu (15124457200)","57216946822; 57208551292; 57195032153; 57204699218; 15124457200","Single satellite optical imagery dehazing using SAR image prior based on conditional generative adversarial networks","2020","Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV 2020","","","9093471","1795","1802","7","10.1109/WACV45572.2020.9093471","14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085521974&doi=10.1109%2fWACV45572.2020.9093471&partnerID=40&md5=4ebab6919c32b079b180d91c1193b85f","Satellite image dehazing aims at precisely retrieving the real situations of the obscured parts from the hazy remote sensing (RS) images, which is a challenging task since the hazy regions contain both ground features and haze components. Many approaches of removing haze focus on processing multi-spectral or RGB images, whereas few of them utilize multi-sensor data. The multi-sensor data fusion is significant to provide auxiliary information since RGB images are sensitive to atmospheric conditions. In this paper, a dataset called SateHaze1k is established and composed of 1200 pairs clear Synthetic Aperture Radar (SAR), hazy RGB, and corresponding ground truth images, which are divided into three degrees of the haze, i.e. thin, moderate, and thick fog. Moreover, we propose a novel fusion dehazing method to directly restore the haze-free RS images by using an end-to-end conditional generative adversarial network(cGAN). The proposed network combines the information of both RGB and SAR images to eliminate the image blurring. Besides, the dilated residual blocks of the generator can also sufficiently improve the dehazing effects. Our experiments demonstrate that the proposed method, which fuses the information of different sensors applied to the cloudy conditions, can achieve more precise results than other baseline models. © 2020 IEEE.","Computer vision; Demulsification; Image fusion; Remote sensing; Satellite imagery; Sensor data fusion; Space-based radar; Synthetic aperture radar; Adversarial networks; Atmospheric conditions; Auxiliary information; Cloudy conditions; Multi-sensor data; Multisensor data fusion; Remote sensing images; Satellite optical imagery; Radar imaging","","Conference paper","Final","","Scopus","2-s2.0-85085521974"
"Wang Y.; Xie D.; Zhan Y.; Li H.; Yan G.; Chen Y.","Wang, Yiting (55931500000); Xie, Donghui (7202588306); Zhan, Yinggang (57221789648); Li, Huan (57221776832); Yan, Guangjian (7202089880); Chen, Yuanyuan (57221789502)","55931500000; 7202588306; 57221789648; 57221776832; 7202089880; 57221789502","Assessing the accuracy of landsat-modis ndvi fusion with limited input data: A strategy for base data selection","2021","Remote Sensing","13","2","266","1","21","20","10.3390/rs13020266","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100169820&doi=10.3390%2frs13020266&partnerID=40&md5=ad0e63a649ac5d45891323e8cf4a7be5","Despite its wide applications, the spatiotemporal fusion of coarse-and fine-resolution satellite images is limited primarily to the availability of clear-sky fine-resolution images, which are commonly scarce due to unfavorable weather, and such a limitation might cause errors in spatiotemporal fusion. Thus, the effective use of limited fine-resolution images, while critical, remains challenging. To address this issue, in this paper we propose a new phenological similarity strategy (PSS) to select the optimal combination of image pairs for a prediction date. The PSS considers the temporal proximity and phenological similarity between the base and prediction images and computes a weight for identifying the optimal combination of image pairs. Using the PSS, we further evaluate the influence of input data on the fusion accuracy by varying the number and temporal distribution of input images. The results show that the PSS (mean R = 0.827 and 0.760) outperforms the nearest date (mean R = 0.786 and 0.742) and highest correlation (mean R = 0.821 and 0.727) strategies in both the enhanced spatial and temporal adaptive reflectance fusion model (ESTARFM) and the linear mixing growth model (LMGM), respectively, for fusing Landsat 8 OLI and MODIS NDVI datasets. Furthermore, base images adequately covering different growth stages yield better predictability than simply increasing the number of base images. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Image processing; Input output programs; Different growth stages; Fine-resolution images; Growth modeling; Optimal combination; Satellite images; Spatio-temporal fusions; Temporal adaptive; Temporal distribution; Image fusion","Base data selection; ESTARFM; Landsat; LMGM; MODIS; NDVI; Spatiotemporal data fusion","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85100169820"
"Gite K.R.; Gupta P.","Gite, K.R. (58041608600); Gupta, Praveen (57199836986)","58041608600; 57199836986","GAN-FuzzyNN: Optimization Based Generative Adversarial Network and Fuzzy Neural Network Classification for Change Detection in Satellite Images","2023","Sensing and Imaging","24","1","1","","","","10.1007/s11220-022-00404-3","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145509453&doi=10.1007%2fs11220-022-00404-3&partnerID=40&md5=a54308bc84a02004b70f77d8e42b2329","Nowadays, change detection with satellite images plays an essential role in urban planning, resources survey, and understanding global environmental changes. However, numerous satellite images are persistently acquired each and every second and they possess a significant source of data for the assessment of the spatiotemporal case. Moreover, obtaining reference data associated with satellite images dealing with land cover changes still remains a major challenging issue. Besides, traditional techniques for change detection are not valuable because of complex texture features. To cope up with such limitations, an effective mechanism is proposed for change detection by exploiting Fuzzy Neural Network (FNN) classification, which is an integration of the Fuzzy concept with Neural Network (NN), and also segmentation is done using Taylor Shuffled Shepherd Optimization (TSSO)-based Generative Adversarial Network (GAN). The proposed TSSO is obtained by incorporating the Taylor series and Shuffled shepherd Optimization (SSO) and the proposed approach achieved a maximum overall accuracy of 0.932, minimum overall error of 0.0704, and maximum kappa coefficient of 0.911. The accuracy of the devised TSSO-based GAN + Fuzzy NN is 2.28%, 4.78%, 0.33%, and 13.26% improved than the Kernel Principal Component Analysis Convolutional Mapping Network (KPCA-MNet), Multiclass Support Vector Machine (MSVM), Patchlevel and pixel-level change detection network (PPCNET), and Image Fusion Network (IFN), respectively, for Image-1. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Change detection; Convolutional neural networks; Feedforward neural networks; Fuzzy inference; Generative adversarial networks; Image classification; Image enhancement; Image fusion; Image segmentation; Principal component analysis; Satellites; Support vector machines; Textures; Change detection; Fuzzy-neural-networks; Global environmental change; Neural network classification; Optimisations; Optimization algorithms; Reference data; Satellite images; Shuffled shepherd optimization algorithm; Taylor-series; Fuzzy neural networks","Change detection; Fuzzy neural network; Generative adversarial network; Shuffled shepherd optimization algorithm; Taylor series","Article","Final","","Scopus","2-s2.0-85145509453"
"","","","International Conference on Computational Methods and Data Engineering, ICMDE 2020","2021","Advances in Intelligent Systems and Computing","1227","","","","","621","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090086657&partnerID=40&md5=c412acba7fd780842cbca2513bf77ad9","The proceedings contain 50 papers. The special focus in this conference is on Computational Methods and Data Engineering. The topics include: On roman domination of graphs using a genetic algorithm; general variable neighborhood search for the minimum stretch spanning tree problem; tabu-embedded simulated annealing algorithm for profile minimization problem; deep learning-based asset prognostics; evaluation of two feature extraction techniques for age-invariant face recognition; XGBoost: 2D-object recognition using shape descriptors and extreme gradient boosting classifier; Comparison of principle component analysis and stacked autoencoder on NSL-KDD dataset; maintainability configuration for component-based systems using fuzzy approach; development of petri net-based design model for energy efficiency in wireless sensor networks; Hybrid ANFIS-GA and ANFIS-PSO based models for prediction of type 2 diabetes mellitus; lifting wavelet and discrete cosine transform-based super-resolution for satellite image fusion; biologically inspired intelligent machine and its correlation to free will; weather status prediction of Dhaka City using machine learning; image processing: What, how and future; a study of efficient methods for selecting quasi-identifier for privacy-preserving data mining; day-ahead wind power forecasting using machine learning algorithms; query relational databases in Punjabi language; machine learning algorithms for big data analytics; fault classification using support vectors for unmanned helicopters; EEG signal analysis and emotion classification using bispectrum; social network analysis of youtube: A case study on content diversity and genre recommendation; Slack feedback analyzer (SFbA); a review of tools and techniques for preprocessing of textual data; A U-shaped printed UWB antenna with three band rejection; model for predicting academic performance through artificial intelligence.","","","Conference review","Final","","Scopus","2-s2.0-85090086657"
"Joshi K.; Shah D.D.; Deshpande A.A.","Joshi, Kavita (56903765500); Shah, Dilip D. (55576264100); Deshpande, Anupama A. (57209251507)","56903765500; 55576264100; 57209251507","Improvement in Satellite Images by Amalgam of Brovey and PCA Algorithm with Artificial Neural Network","2020","Lecture Notes in Electrical Engineering","570","","","251","259","8","10.1007/978-981-13-8715-9_30","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070610594&doi=10.1007%2f978-981-13-8715-9_30&partnerID=40&md5=cf9a647546ec26e7f26dc5ed56e4d3d8","Image processing is playing a major role in almost all the field to renovate the original images. Image processing includes image capturing, then pre-processing, segmenting, extraction of features and classification. Authors are proposing a method of fusion of the panchromatic and hyperspectral images and then classification using ANN. After pre-processing of satellite image, Segmentation of image have been carried out using fusion techniques incorporating brovey and Principal component analysis which is proven to present best results in terms of enhancement. Authors have achieved accuracy of 95.1% with processing delay of 43.79 ms for 1600 blocks training in NN. © 2020, Springer Nature Singapore Pte Ltd.","Classification (of information); Fusion reactions; Image analysis; Image fusion; Image segmentation; Neural networks; Principal component analysis; Satellites; Spectroscopy; Brovey; Fusion techniques; Image capturing; Original images; PCA algorithms; Pre-processing; Processing delay; Satellite images; Image enhancement","Brovey; Classification; Fusion; Neural network; Principal component analysis; Satellite image","Conference paper","Final","","Scopus","2-s2.0-85070610594"
"Cheng F.; Fu Z.; Niu B.; Huang L.; Ji X.; Sun Y.","Cheng, Feifei (57354791400); Fu, Zhitao (57199314812); Niu, Baosheng (57781413300); Huang, Liang (55571335200); Ji, Xinran (57777325300); Sun, Yu (57612765900)","57354791400; 57199314812; 57781413300; 55571335200; 57777325300; 57612765900","Fusion of Domestic High Resolution Remote Sensing Images Based on the Non-Subsampled Shearlet Transform; [基于非下采样剪切波变换的国产高分遥感影像融合]","2022","Laser and Optoelectronics Progress","59","12","1228001","","","","10.3788/LOP202259.1228001","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133448650&doi=10.3788%2fLOP202259.1228001&partnerID=40&md5=36762f63ad0274ec782cbdb8df87a1f6","To address the problems of poor inter-image correlation and obvious differences in fused brightness in high resolution remote sensing image fusion, this paper proposes a method for fusing domestic high-resolution panchromatic and multispectral remote sensing using the non-subsampled shearlet transform. Remote sensing images of GF-1, GF-2, and GF-7 are selected as the experimental data. The intensity-hue-saturation (IHS) algorithm is used to extract the luminance component of the multispectral image; the non-subsampled shearlet transform (NSST) algorithm is used to extract the high frequency and low frequency information from the luminance component and the panchromatic image; and the relationship between high frequency and low frequency is fully considered when designing an effective image fusion strategy. Finally, the fused image is obtained by the IHS and NSST algorithms. By comparing the proposed method to Brovey, Gram-Schmidt (GS)、 Hue-saturation-value (HSV), and Co-occurrence filtering (COF) algorithms, it is determined that the proposed method is a feasible remote sensing image fusion method with the combination of subjective and objective evaluation for the fused images. © 2022 Universitat zu Koln. All rights reserved.","","GF satellite image; image fusion; non-subsampled shearlet transform; remote sensing","Article","Final","","Scopus","2-s2.0-85133448650"
"Medina Daza R.J.; Upegui E.","Medina Daza, Rubén Javier (57199150874); Upegui, Erika (36459015100)","57199150874; 36459015100","Implementation and evaluation of the High Pass Filter and Wavelet À Trous transforms in Matlab to fusion Landsat 8 OLI/TIRS Satellite Images; [Implementación y evaluación de las transformadas Filtro Paso Alto y Wavelet À Trous, en Matlab, para fusionar Imágenes Satelitales Landsat 8 OLI/TIRS]","2022","Iberian Conference on Information Systems and Technologies, CISTI","2022-June","","","","","","10.23919/CISTI54924.2022.9820476","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134845229&doi=10.23919%2fCISTI54924.2022.9820476&partnerID=40&md5=f8b7ccc8ca6ef8e8d1a2d2a803ddba51","In this article, the High Pass Filter-HPF, and Wavelet À trous transforms are developed mathematically, to later implement them in Matlab. The fusion of satellite images is performed with each one of the implemented transforms, with a proposed methodology. A Landsat 8 OLI/TIRS image (Panchromatic - PAN and multispectral - MULTI) of a northwestern sector of Peru -where sugar cane crops are evident-is used to generate two fused images, namely: MULTIHPF and MULTITWA. The fused images were evaluated both in spatial and spectral quality through four indices, specifically: correlation index, ERGAS, RASE and Q index, in order to determine the efficiency of the proposed methods. Best results of the spectral evaluation were obtained with the MULTITWA image, achieving correlations higher than 0.95, a Q index of 0.96 and a RASE value of 9.2%, while spatially higher values than 0.96. Regarding spatial richness, the best results were obtained with MULTIHPF with an ERGAS of 14.6, a RASE of 29.3% and a Q of 0.7. © 2022 IEEE Computer Society. All rights reserved.","High pass filters; Image fusion; Quality control; Sugar cane; Wavelet transforms; Correlation index; Fused images; High-pass filter; LANDSAT; Landsat 8; Multi-spectral; Satellite images; Spatial quality; Spectral quality; À trous; Landsat","fusion; High pass filter; Landsat 8; Satellite images; À trous","Conference paper","Final","","Scopus","2-s2.0-85134845229"
"Zhao F.; Wu X.; Wang S.","Zhao, Fuchao (57395239300); Wu, Xiaoming (55715032000); Wang, Shuai (57196155579)","57395239300; 55715032000; 57196155579","Object-oriented Vegetation Classification Method based on UAV and Satellite Image Fusion","2020","Procedia Computer Science","174","","","609","615","6","10.1016/j.procs.2020.06.132","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099917554&doi=10.1016%2fj.procs.2020.06.132&partnerID=40&md5=369e8534125765f7ed2606058eb281a5","Nowadays, space remote sensing technology has become one of the most important means for people to obtain geographic information and environmental information. Satellite multi-spectral data contains rich spectral information in multiple bands. The method of remote sensing monitoring of ground vegetation classification and identification represented by satellite is widely used. Because the Unmanned Aerial Vehicle (UAV) has obvious advantages such as small size, strong timeliness, flexible operation and low cost, it is widely used as a remote sensing platform for disaster monitoring, environmental detection, vegetation distribution information monitoring, etc. And it quickly becomes an important way to get the vegetation type of the study area. Compared with satellite multi-spectral images, UAV images have high resolution and rich spatial information, but lack spectral information for vegetation identification. So this article is based on satellite images, in order to improve the precision of ground vegetation in the area of classification and recognition, the UAV images and satellite multi-spectral images data pixel level fusion, combined with object-oriented supervised classification method, the integration of data with random forests (RF), support vector machine (SVM) and maximum likelihood estimation (MLE) method for vegetation classification identification precision and validation. Compared with the data before fusion, the statistical results of the confusion matrix output show that the accuracy of vegetation classification recognition under the combination of object-oriented supervised classification method has been significantly improved. © 2020 The Authors. Published by Elsevier B.V.","Antennas; Decision trees; Image classification; Image enhancement; Image fusion; Maximum likelihood estimation; Pixels; Remote sensing; Space optics; Spectroscopy; Support vector machines; Unmanned aerial vehicles (UAV); Vegetation; Classification and identifications; Classification methods; Ground vegetation; Object oriented; Pixel level fusion; Satellite images; Spectral information; Vegetation classification; Vegetation classification and identification; Vehicle images; Satellites","Object-oriented; Pixel-level fusion; Satellite; UAV; Vegetation classification and identification","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85099917554"
"Qin R.; Ling X.; Farella E.M.; Remondino F.","Qin, Rongjun (55790585000); Ling, Xiao (57226238069); Farella, Elisa Mariarosaria (57195268084); Remondino, Fabio (6507122674)","55790585000; 57226238069; 57195268084; 6507122674","Uncertainty-Guided Depth Fusion from Multi-View Satellite Images to Improve the Accuracy in Large-Scale DSM Generation","2022","Remote Sensing","14","6","1309","","","","10.3390/rs14061309","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126287863&doi=10.3390%2frs14061309&partnerID=40&md5=514c46a932b3f3b37f09f1f5b636ebce","The generation of digital surface models (DSMs) from multi-view high-resolution (VHR) satellite imagery has recently received a great attention due to the increasing availability of such space-based datasets. Existing production-level pipelines primarily adopt a multi-view stereo (MVS) paradigm, which exploit the statistical depth fusion of multiple DSMs generated from individual stereo pairs. To make this process scalable, these depth fusion methods often adopt simple approaches such as the median filter or its variants, which are efficient in computation but lack the flexibility to adapt to heterogenous information of individual pixels. These simple fusion approaches generally discard ancillary information produced by MVS algorithms (such as measurement con-fidence/uncertainty) that is otherwise extremely useful to enable adaptive fusion. To make use of such information, this paper proposes an efficient and scalable approach that incorporates the matching uncertainty to adaptively guide the fusion process. This seemingly straightforward idea has a higher-level advantage: first, the uncertainty information is obtained from global/semiglobal matching methods, which inherently populate global information of the scene, making the fusion process nonlocal. Secondly, these globally determined uncertainties are operated locally to achieve efficiency for processing large-sized images, making the method extremely practical to implement. The proposed method can exploit results from stereo pairs with small intersection angles to recover details for areas where dense buildings and narrow streets exist, but also to benefit from highly accurate 3D points generated in flat regions under large intersection angles. The proposed method was applied to DSMs generated from Worldview, GeoEye, and Pleiades stereo pairs covering a large area (400 km2). Experiments showed that we achieved an RMSE (root-mean-squared error) improvement of approximately 0.1–0.2 m over a typical Median Filter approach for fusion (equivalent to 5–10% of relative accuracy improvement). © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Image enhancement; Image fusion; Mean square error; Satellite imagery; Stereo image processing; Dense image matching; Depth fusion; Digital surface models; Fusion process; Median-Filter; Multi-view stereo; Multi-views; Satellite photogrammetry; Stereo pair; Uncertainty; Median filters","Dense image matching; Depth fusion; Digital surface models; Multi-view stereo; Satellite photogrammetry; Uncertainty","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85126287863"
"Kurganovich K.A.; Kochev D.V.; Bosov M.A.","Kurganovich, Konstantin A. (57191967376); Kochev, Denis V. (58001325100); Bosov, Maxim A. (57269927600)","57191967376; 58001325100; 57269927600","THE HYBRID METHOD OF WATER LEVELS AND VOLUMES RECONSTRUCTING IN THE ARAKHLEY LAKE (TRANS-BAIKAL TERRITORY) ACCORDING TO LANDSAT REMOTE SENSING DATA WITH UNMANNED AERIAL VEHICLES IMAGES FUSION; [ИСПОЛЬЗОВАНИЕ ГИБРИДНОГО МЕТОДА СОВМЕСТНОГО АНАЛИЗА ДАННЫХ СПУТНИКОВОГО ЗОНДИРОВАНИЯ LANDSAT И БЕСПИЛОТНЫХ ЛЕТАТЕЛЬНЫХ АППАРАТОВ ДЛЯ РЕКОНСТРУКЦИИ УРОВНЕЙ ВОДЫ И ОБЪЕМОВ ВОДНОЙ МАССЫ В ВОДОЕМАХ (НА ПРИМЕРЕ ОЗ. АРАХЛЕЙ ЗАБАЙКАЛЬСКОГО КРАЯ)]","2022","InterCarto, InterGIS","28","","","368","382","14","10.35595/2414-9179-2022-1-28-368-382","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143812945&doi=10.35595%2f2414-9179-2022-1-28-368-382&partnerID=40&md5=ecd0674ca5f5e96f0f98dcb573858da6","The use of a hybrid method for reconstructing water levels and volumes of water mass in a reservoir is considered on the example of the Arakhley Lake of the Trans-Baikal Territory. The method makes it possible to obtain high spatial resolution cuts of water levels on the relief based on satellite images of the Landsat system of different time intervals and images from unmanned aerial vehicles (UAVs) as a source of a highly detailed digital elevation model. As a result of processing the Landsat satellite data, the values of the Arakhley Lake surface areas for the period 1987–2018 were obtained. Based on the results of the UAV survey, the water levels in the lake were extracted according to the survey dates corresponding to the areas. The root mean square error of water level determination (RMSE) was 0.23 m, which is lower than the horizontal resolution of the elevation model (0.3 m) obtained from the UAV data. Also, the characteristics of the water mass volume were obtained for the variable part of the lake volume for the period 1987–2018. The use of the hybrid method considered in the article will solve the problem of insufficient or complete absence of data on the long-term water regime of unexplored lakes and reservoirs. Evaluation of the possibilities of using this technology by comparing with the instrumental characteristics of water levels at the regime point of hydrological observations, shows the boundaries of its use, advantages and disadvantages. At the same time, the main advantage can be recognized as the possibility of obtaining time series of changes in levels and volumes over the past years in those lakes and reservoirs where there have never been ground observations and are unlikely to be. In the case of establishing the dependences of the water mass volume on the areas of the water surface, it becomes possible to perform operational hydrological monitoring of water bodies using only Landsat satellite images. © 2022 Lomonosov Moscow State University. All rights reserved.","","digital terrain model; morphometric characteristics of lakes; spectral water indices; unmanned aerial vehicles","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85143812945"
"Dong M.; Li W.; Liang X.; Zhang X.","Dong, Meilin (57219224960); Li, Weisheng (36067507500); Liang, Xuesong (57222732776); Zhang, Xiayan (57219233195)","57219224960; 36067507500; 57222732776; 57219233195","MDCNN: Multispectral pansharpening based on a multiscale dilated convolutional neural network","2021","Journal of Applied Remote Sensing","15","3","036516","","","","10.1117/1.JRS.15.036516","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116391570&doi=10.1117%2f1.JRS.15.036516&partnerID=40&md5=4e8678788e7202fc6fe4e5553ff38279","Convolutional neural networks (CNNs) have achieved remarkable results in multispectral (MS) and panchromatic (PAN) image fusion (pansharpening) because of their strong image feature extraction ability. However, previous CNN-based pansharpening methods mostly use an ordinary convolution, which has a small receptive field in the convolution layer, has insufficient contextual information, and can only extract shallow features, which is not conducive to learning the complex nonlinear mapping relationship between the input image and the fused image. Therefore, this study proposes a pansharpening algorithm based on a multiscale densely convolutional neural network (MDCNN). First, a two-stream network is used for feature extraction, with two convolution layers to extract spectral information from MS images. The multiscale convolutional feature extraction module is designed to extract the spatial detail features of the PAN images. Second, the proposed multiscale densely connected modules and residual modules are used as the backbone of the fusion network. Finally, the deep features generated are reconstructed, and spectral mapping is used to retain spectral information to obtain a high-resolution fusion image. Experimental results using three satellite image datasets show that the proposed algorithm generates high-quality fusion images, and it outperforms most advanced pansharpening methods in subjective visual and objective evaluation indexes.  © 2021 Society of Photo-Optical Instrumentation Engineers (SPIE).","Convolution; Convolutional neural networks; Extraction; Image fusion; Photomapping; Convolutional neural network; Dense module; Features extraction; Fusion image; Image feature extractions; Multi-spectral; Network-based; Pan-sharpening; Receptive fields; Spectral information; Feature extraction","convolutional neural network; dense module; feature extraction; image fusion; pansharpening","Article","Final","","Scopus","2-s2.0-85116391570"
"Gautam R.; Chandran S.; Hormese J.","Gautam, Ritik (57219318525); Chandran, Saravanan (55880135100); Hormese, Jose (57205126682)","57219318525; 55880135100; 57205126682","Classification of Buildings and Vehicles in Google Map Satellite Images Using Random Forest Classifier","2020","Lecture Notes in Electrical Engineering","686","","","1073","1082","9","10.1007/978-981-15-7031-5_102","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092152488&doi=10.1007%2f978-981-15-7031-5_102&partnerID=40&md5=5f09972769d124909bf4c920965856e5","The Google Map provides an additional feature for observing various places of the landscapes as bird’s eye view with the help of the satellite images. Google Map satellite images are developed with the help of geographical information systems (GIS) data, aerial images, drone images, and satellite images with the help of image fusion methods to produce a bird’s eye view of a landscape. This proposed research work is intended to classify the buildings and vehicles from the Google Map satellite images that are captured at a zoom level of 20 m. This research work carried out to survey an area for various applications which require number of buildings and number of vehicles. The random forest classifier is used for the pixel classification, and this technique is also referred as pixel segmentation. The random forest classifier produces a result of 87% accuracy. © 2020, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Antennas; Automobile electronic equipment; Birds; Decision trees; Image classification; Image fusion; Pixels; Random forests; Satellites; Aerial images; Google maps; Image fusion methods; Number of vehicles; Pixel classification; Random forest classifier; Satellite images; Intelligent computing","Building segmentation; Google map; Random forest classifier; Satellite images; Vehicle segmentation","Conference paper","Final","","Scopus","2-s2.0-85092152488"
"Wang S.; Yang X.; Li G.; Jin Y.; Tian C.","Wang, Shengbo (57889670100); Yang, Xiufeng (57396526000); Li, Guohong (55714233200); Jin, YongTao (57193738879); Tian, Chuanzhao (57889571800)","57889670100; 57396526000; 55714233200; 57193738879; 57889571800","Research on spatio-temporal fusion algorithm of remote sensing image based on GF-1 WFV and Sentinel-2 satellite data","2022","2022 3rd International Conference on Geology, Mapping and Remote Sensing, ICGMRS 2022","","","","667","678","11","10.1109/ICGMRS55602.2022.9849377","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137974963&doi=10.1109%2fICGMRS55602.2022.9849377&partnerID=40&md5=e264da05e12c5cdae3622809a77c953a","The remote sensing data set with high spatial and temporal resolution is of great significance for monitoring surface change. However, the earth observation satellites at domestic and international cannot obtain high spatial resolution and high temporal resolution images at the same time. Remote sensing data spatio-temporal fusion technology is an effective means to solve this problem. In this paper, the multi-period GaoFen-1 WideField-View (GF-1 WFV) satellite images and Sentinel-2 satellite images of Beijing-Tianjin-Hebei region in 2020 are used to perform fusion simulation for the three spatio-temporal fusion algorithms of Spatial and Temporal Adaptive Reflectance Fusion Model (STARFM), Enhanced-STARFM (ESTARFM) and Enhanced Flexible Spatiotemporal Data Fusion Model (EFSDAF) and these simulation degree of the results are quantitatively evaluated. The results show that ESTARFM algorithm is more suitable for the construction of high spatio-temporal fusion data of GF-1 WFV and Sentinel-2 satellites in Beijing-Tianjin-Hebei region.  © 2022 IEEE.","Image fusion; Remote sensing; Satellites; Enhanced flexible spatiotemporal data fusion model; Enhanced-STARFM; Fusion model; Gaofen-1 widefield-view image; Spatial and temporal adaptive reflectance fusion model; Spatio-temporal data; Temporal adaptive; Temporal and spatial; Temporal and spatial fusion; Wide-field view; Image enhancement","EFSDAF; ESTARFM; GF-1 WFV images; STARFM; Temporal and spatial fusion","Conference paper","Final","","Scopus","2-s2.0-85137974963"
"Lei C.; Meng X.; Shao F.","Lei, Chenyang (57223265991); Meng, Xiangchao (56158755000); Shao, Feng (7006717672)","57223265991; 56158755000; 7006717672","Spatio-temporal fusion quality evaluation based on ""Point""-""Line""-""Plane"" aspects; [遥感影像时-空融合的""点""-""线""-""面""质量评价]","2021","National Remote Sensing Bulletin","25","3","","791","802","11","10.11834/jrs.20219334","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105408441&doi=10.11834%2fjrs.20219334&partnerID=40&md5=a45034006d7d9372d8147000f00722e5","Remote sensing images with both high spatial and high temporal resolutions are highly desirable in various applications. However, due to technical limitations of remote sensing imaging system and other factors, the acquired remote sensing images have to make a fundamental trade-off between high spatial and temporal resolutions. For example, the MODIS images have high temporal resolution, its spatial resolution is low; On the contrary, the Landsat images have high spatial resolution with relatively lower temporal resolution. Spatio-temporal fusion can integrate the complementary advantages of high spatial resolution and high spectral resolution, respectively, of multi-source remote sensing images, to generate time-continuous images with high spatial resolution. This has important application value in remote sensing image dynamic monitoring, time-series analysis, and other aspects. To the best of our knowledge, at present, most of studies generally evaluated the spatio-temporal fused images based on a single type of remote sensing data, such as the surface reflectance data or the Normalized Difference Vegetation Index (NDVI) remote sensing product, etc. However, how well a spatio-temporal fusion method performs in practical applications? This should be comprehensively assessed from different aspects based on different types of remote sensing data products. In addition, most of studies performed the evaluation of a spatio-temporal fusion method based on the fused image at a single phase. However, for spatio-temporal fusion, the final target is actually to obtain time-series fused images, the quality evaluation of the fused images from the temporal dimension should be also taken into account. Whereas, to the best of our knowledge, the quality evaluation for time-series fused images is not comprehensively considered in the existing studies. In this paper, we proposed to evaluate the spatio-temporal fusion methods from the comprehensive perspective of single time point, time series, and multiple different remote sensing data products. In this paper, spatio-temporal fusion data sets, including surface reflectance data set, NDVI data set, and the Land Surface Temperature (LST) data set were established based on Landsat and MODIS remote sensing satellite images. In addition, some typical spatio-temporal fusion methods were reviewed, and the performance of four spatio-temporal fusion algorithms, including the Spatial and Temporal Adaptive Reflectance Fusion Model (STARFM), Enhanced STARFM (ESTARFM), Flexible Spatio-Temporal Data Fusion (FSDAF), and the Spatial and Temporal Nonlocal Filter-based Fusion Model (STNLFFM), were qualitatively and quantitatively evaluated based on the proposed data sets of different kinds of remote sensing data products, i.e., the surface reflectance, NDVI, and LST. In addition, the quality evaluation from the perspective of both single-time-point and time-series dimensions were performed. The experimental results show that the performance of spatio-temporal fusion algorithms can be more comprehensively verified based on different type of data sets, and the evaluation combined with single time point and time-series data set is more objective. © 2021, Science Press. All right reserved.","Economic and social effects; Image fusion; Image quality; Image resolution; Land surface temperature; Quality control; Radiometers; Reflection; Spectral resolution; Time series analysis; High spatial resolution; High spectral resolution; High temporal resolution; Normalized difference vegetation index; Remote sensing imaging; Remote sensing satellites; Spatial and temporal resolutions; Spatio-temporal fusions; Remote sensing","Land Surface Temperature(LST); Normalized Difference Vegetation Index(NDVI); Quality evaluation; Reflectance; Spatio-temporal fusion","Article","Final","","Scopus","2-s2.0-85105408441"
"","","","1st International Conference on Advances in Electrical and Computer Technologies, ICAECT 2019","2020","Lecture Notes in Electrical Engineering","672","","","","","1439","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091319583&partnerID=40&md5=9d3d832b5e34543a4a8aaa442dbe6d63","The proceedings contain 119 papers. The special focus in this conference is on Advances in Electrical and Computer Technologies. The topics include: Sum modified laplacian-based image fusion in dct domain with super resolution; a supplement to “pre: A simple, pragmatic, and provably correct algorithm”; effective compression of digital images using spiht coding with selective decomposition bands; reconfigurable lut-based dynamic obfuscation for hardware security; detection and control of phishing attack in electronic medical record application; smart apron using embroidered textile fractal antenna for e-health monitoring system; design of modified wideband log periodic microstrip antenna with slot for navigational application; machine learning approach to condition monitoring of an automotive radiator cooling fan system; sensors network for temperature measurement in a cocoa fermentator; communication-aware virtual machine placement in cloud; migration from silicon to gallium nitride devices—a review; high-speed modified da architecture for dwt computation in secure image encoding; satellite image classification with data augmentation and convolutional neural network; design and randomness evaluation of a chaotic neural encryption and decryption network for trng; circuit modelling of graphene and carbon nanotube-based multilayer structures for high-frequency absorption; pi and sliding mode control of quanser qnet 2.0 hvac system; robust control of position and speed for a dc servomotor system using various control techniques; mpc-based temperature control of cstr process and its comparison with pid; microgrid integration in kerala power grid—a case study; design of control system for autonomous harvester based on navigation inputs; design and optimization of microgrid as ev charging source; preface.","","","Conference review","Final","","Scopus","2-s2.0-85091319583"
"Tong Y.; Quan Y.; Feng W.; Xing M.","Tong, Yingping (57220011021); Quan, Yinghui (35181982300); Feng, Wei (57089587500); Xing, Mengdao (7005922869)","57220011021; 35181982300; 57089587500; 7005922869","Multi-source remote sensing image fusion method based on spatial-spectrum information collaboration and Gram-Schmidt transform; [基于空谱信息协同与Gram-Schmidt变换的多源遥感图像融合方法]","2022","Xi Tong Gong Cheng Yu Dian Zi Ji Shu/Systems Engineering and Electronics","44","7","","2074","2083","9","10.12305/j.issn.1001-506X.2022.07.02","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132523965&doi=10.12305%2fj.issn.1001-506X.2022.07.02&partnerID=40&md5=29eab6b032f2e79b467f873c1fd9733b","The fusion of multispectral and synthetic aperture radar (SAR) images can retain the advantages of each data and improve the accuracy of land cover classification. However, some current image fusion methods cannot fully utilize the spectral information and texture details of the original data. In order to overcome these problems, a fusion method based on space-spectrum information collaboration and Gram-Schmidt transform is proposed. In the proposed method, Sentinel-2A images and GaoFen-3 (GF-3) images are preprocessed by different methods. Since the gray co-occurrence matrix can effectively extract the texture information of the image, it is applied to the Sentinel-2A image to extract the structural features, and the multispectral image coordinated by the space-spectrum information is fused with GF-3 image by the Gram-Schmidt transform. Principal component analysis (PCA) and the traditional Gram-Schmidt transform are used as the comparison methods in this experiment. In order to determine the effectiveness of the fusion algorithm, this paper uses five evaluation indicators including average gradient, spatial frequency, mean, standard deviation and correlation coefficient to measure the quality of the fusion image. In addition, due to its excellent training speed and excellent classification performance, random forest is used for land cover classification. The classification accuracy of random forest, Kappa coefficient and classification result graph are used as the evaluation criteria of the fusion method. Experimental results show that, compared with the original Sentinel-2A alone, the proposed fusion method can improve the overall accuracy by up to 5%, and has the potential to improve the accuracy of land cover classification in remote sensing satellite images. © 2022, Editorial Office of Systems Engineering and Electronics. All right reserved.","Classification (of information); Decision trees; Image classification; Image enhancement; Image fusion; Principal component analysis; Quality control; Synthetic aperture radar; Textures; Fusion methods; Gram-Schmidt transform; Image fusion methods; Information collaborations; Land cover classification; Multi-spectral; Random forests; Remote-sensing; Space spectrum; Spectrum information; Remote sensing","Classification; Image fusion; Multispectral; Remote sensing","Article","Final","","Scopus","2-s2.0-85132523965"
"Ezimand K.; Chahardoli M.; Azadbakht M.; Matkan A.A.","Ezimand, Keyvan (57202853151); Chahardoli, Manouchehr (57219200485); Azadbakht, Mohsen (57023624300); Matkan, Ali Akbar (36243866100)","57202853151; 57219200485; 57023624300; 36243866100","Spatiotemporal analysis of land surface temperature using multi-temporal and multi-sensor image fusion techniques","2021","Sustainable Cities and Society","64","","102508","","","","10.1016/j.scs.2020.102508","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091672366&doi=10.1016%2fj.scs.2020.102508&partnerID=40&md5=53fc0edaef39911b25e268347b4be4a8","Urban Heat Island (UHI) is a major challenge in urban environments that affects human activities. This phenomenon is caused and changed by various factors in urban environments, in which identification of such parameters requires fine-scale satellite images. This study, therefore, aimed at investigating spatiotemporal changes of UHIs as well as identification of important factors using remote sensing image fusion techniques in Rasht. The image dataset comprises of Landsat 5, 7, 8 and MODIS images from 2001 to 2018. After pre-processing, multi-temporal and multi-sensor image fusion techniques were used to retrieve Landsat 7 images as well as Landsat-like medium spatial resolution images. The effects of built-up areas and surface biophysical characteristics such as brightness, greenness and wetness were also examined on LST changes through time. The results showed that multi-temporal and multi-sensor image fusion methods provide appropriate accuracies and the multi-temporal fusion method performs better than the multi-sensor fusion method. The results also showed that retrieval of sensor products is of higher accuracy than that of the spectral bands. The spatiotemporal changes of UHIs were indicative of an increasing trend over time. Of the surface biophysical parameters, the normalized difference built-up index exhibited the highest correlation with changes of normalized LST. © 2020 Elsevier Ltd","Gilan; Iran; Rasht; Atmospheric temperature; Image processing; Land surface temperature; Remote sensing; Urban planning; Biophysical characteristics; Biophysical parameters; Multi-sensor fusion method; Normalized differences; Remote sensing images; Spatial resolution images; Spatio-temporal changes; Spatiotemporal analysis; biophysics; heat island; image processing; land surface; Landsat; remote sensing; sensor; spatiotemporal analysis; surface temperature; Image fusion","Land surface temperature; Multi-sensor fusion; Multi-temporal fusion; Surface biophysical parameters; Urban heat island","Article","Final","","Scopus","2-s2.0-85091672366"
"Singh S.; Mittal N.; Singh H.","Singh, Simrandeep (57223097851); Mittal, Nitin (56640907600); Singh, Harbinder (56423891600)","57223097851; 56640907600; 56423891600","Classification of various image fusion algorithms and their performance evaluation metrics","2020","Computational Intelligence for Machine Learning and Healthcare Informatics","","","","179","198","19","10.1515/9783110648195-009","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092120780&doi=10.1515%2f9783110648195-009&partnerID=40&md5=277ce3ff9e6fd4c5551eff43a280ccca","Image fusion is the process of enhancing the perception of a vision by combining substantial information captured by different sensors, different exposure values, and at different focus points. Several images captured from different sensors like infrared region and visible region, positron emission tomography scan, and computed tomography, Multifocus images with different focal points, and images taken by static camera at different exposure values. Most promising area of image processing nowadays is image fusion. The picture fusion method seeks to incorporate two or more pictures into one picture that contains better data than each source picture without adding any artifacts. In distinct apps, it plays an essential role, namely medical diagnostics, pattern detection and identification, navigation, army, civilian surveillance, robotics, and remote sensing satellite images. Three elements are taken into consideration in this review document: spatial domain fusion methodology, different transformation domain techniques, and image fusion performance metrics like entropy, mean, standard deviation, average gradient, peak signal-to-noise ratio, and structural similarity index (SSIM). Many image fusion applications are explored in this chapter. © 2020 Walter de Gruyter GmbH, Berlin/Boston. All rights reserved.","","Image fusion; Multiexposure image fusion; Multifocus image fusion; Multimodal image fusion","Book chapter","Final","","Scopus","2-s2.0-85092120780"
"Swathi R.; Srinivas A.","Swathi, R. (57685847200); Srinivas, Alluri (57195287292)","57685847200; 57195287292","An Improved Image Registration Method Using E-SIFT Feature Descriptor with Hybrid Optimization Algorithm","2020","Journal of the Indian Society of Remote Sensing","48","2","","215","226","11","10.1007/s12524-019-01063-w","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075474726&doi=10.1007%2fs12524-019-01063-w&partnerID=40&md5=7288a452cb456d0a7c737c3280e4a55f","Automatic image registration of the satellite images aids in the field of the computer-aided research. In the recent years, image registration is useful in the environment monitoring and the agriculture purpose. In this work, the automatic image registration model has been developed through the novel hybrid optimization algorithm. This work mainly concentrates in image registration of the hyperspectral images arriving from the satellite. The proposed automatic image registration model uses the input image and the reference image for the registration purpose. From both the images, the E-SIFT features are extracted and given to the point matching algorithm for the keypoint detection. Then, the similarity transformation model gets the keypoints and makes the input images to the original position. Here, the weighted average model is developed for the image fusion, and the weight score for the image fusion is selected optimally through the proposed salp swarm-crow search algorithm (SS-CSA). For the experimentation, the proposed scheme uses the standard database having the hyperspectral satellite images. The simulation results reveal that the proposed image registration scheme with the SS-CSA algorithm has progressed better than the existing techniques with 0.711788 and 0.993602 for the RMSE and NCC, respectively. © 2019, Indian Society of Remote Sensing.","algorithm; detection method; image analysis; numerical model; optimization; satellite imagery; simulation","E-SIFT features; Hyperspectral images; Image registration; Optimization; Weighted average model","Article","Final","","Scopus","2-s2.0-85075474726"
"Shutao W.; Wang K.; Deming K.; Tiezhu W.; Ruixiang L.","Shutao, Wang (57205708522); Wang, Kang (57767781100); Deming, Kong (57767539400); Tiezhu, Wang (57767046000); Ruixiang, Li (57768755300)","57205708522; 57767781100; 57767539400; 57767046000; 57768755300","GF-1 Image Fusion Based on Regression Kriging; [基于回归克里金的高分-1 影像融合]","2022","Laser and Optoelectronics Progress","59","8","0828005","","","","10.3788/LOP202259.0828005","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133020517&doi=10.3788%2fLOP202259.0828005&partnerID=40&md5=113a03056406962996ed49cecabf6652","Aiming at the problem that it is difficult for remote sensing data to achieve both high spatial and spectral resolution, a quadtree-based adaptive block area-to-point regression Kriging method (QAATPRK) is proposed to fuse the panchromatic (PAN) and multispectral (MS) data of GF-1. The proposed method is based on the area to point regression Kriging method, where the whole image is segmented into several independent fusion units and fused, splicing the results. For each individual fusion unit, spatial information of high-resolution PAN images were used for regression modeling and the residuals were treated by the regression Kriging method. The proposed method is compared with the Principal Component Analysis (PCA) method, wavelet transform method, Intensity-Hue-Saturation and Gram-Schmidt (IGS) method, and DenseNet. Root mean square error (RMSE), structure similarity (SSIM), universal image quality index (UIQI), relative global-dimensional synthesis error (ERGAS), and spectral angle mapper (SAM) demonstrate that the fusion image quality of the proposed method is the best and the spectral properties of the MS image are maintained. © 2022 Universitat zu Koln. All rights reserved.","","GF satellite image; image fusion; image processing; regression Kriging; remote sensing","Article","Final","","Scopus","2-s2.0-85133020517"
"Zhou W.; Wang F.; Wang X.; Tang F.; Li J.","Zhou, Weifeng (55475996100); Wang, Fei (57853299900); Wang, Xi (57425145800); Tang, Fenghua (36773921700); Li, Jiasheng (57191969252)","55475996100; 57853299900; 57425145800; 36773921700; 57191969252","Evaluation of Multi-Source High-Resolution Remote Sensing Image Fusion in Aquaculture Areas","2022","Applied Sciences (Switzerland)","12","3","1170","","","","10.3390/app12031170","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123447079&doi=10.3390%2fapp12031170&partnerID=40&md5=5a7ecf352449bc746b9ec1604eb84ccb","Image fusion of satellite sensors can generate a high-resolution multi-spectral image from inputs of a high spatial resolution panchromatic image and a low spatial resolution multi-spectral image for feature extraction and target recognition, such as enclosure seines and floating rafts. However, there is currently no clear and definite method of image fusion for different aquaculture areas distribution extraction from high-resolution satellite images. This study uses three types of high-resolution remote sensing images, GF-1 (Gaofen-1), GF-2 (Gaofen-2), and WV-2 (WorldView-2), covering the raft and enclosure seines aquacultures in the Xiangshan Bay, China, to evaluate panchromatic and multispectral image fusion techniques to determine which is the best. This study applied PCA (principal component analysis), GS (Gram-Schmidt), and NNDiffuse (nearest neighbor diffusion) algorithms to panchromatic and multispectral images fusion of GF-1, GF-2, and WV-2. Two quantitative methods are used to evaluate the fusion effect. The first used seven statistical parameters, including gray mean value, standard deviation, information entropy, average gradient, correlation coefficient, deviation index, and spectral distortion. The second is the CQmax index. Comparing the evaluation results by these seven common statistical indicators with the results of the image fusion evaluation by index CQmax, the results prove that the CQmax index can be applied to the evaluation of image fusion effects in different aquaculture areas. For the floating raft cultured area, the conclusion is consentaneous; NNDiffuse was also optimal for GF-1 and GF-2 data, and PCA was optimal for WV-2 data. For the enclosure seines culture area, the conclusion of quantitative evaluations is not consistent and it shows that there is no definite good method that can be applied to all areas; therefore, careful evaluation and selection of the best applicable image fusion method are required according to the study area and sensor images. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","","Aquaculture area; CQ<sub>max</sub>; High-resolution satellite images; Image fusion; Quantitative evaluation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85123447079"
"Wang M.; Meng X.; Shao F.; Fu R.","Wang, Mengyao (57210968797); Meng, Xiangchao (56158755000); Shao, Feng (7006717672); Fu, Randi (14821950200)","57210968797; 56158755000; 7006717672; 14821950200","SAR-Assisted Optical Remote Sensing Image Cloud Removal Method Based on Deep Learning; [基于深度学习的SAR辅助下光学遥感图像去云方法]","2021","Guangxue Xuebao/Acta Optica Sinica","41","12","1228002","","","","10.3788/AOS202141.1228002","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113278742&doi=10.3788%2fAOS202141.1228002&partnerID=40&md5=9b89574ba859279c7a4f3fd7c4491b52","The existing deep learning based SAR-assisted cloud removal methods do not take full into account the texture and spectral information of the optical images, which results in blurring and spectral loss. In this paper, we constructed a data set for SAR-assisted cloud removal based on the Sentinel-1 and Sentinel-2 satellite images in Yuhang District of Hangzhou. In addition, we established a conditional generative adversarial network (cGAN) based model by fully considering the details, texture, and color information of optical remote sensing images, achieving information recovery and reconstruction in the case of optical images covered by thin clouds, fog, and thick clouds. The results show that the proposed method outperforms other methods in SAR-assisted cloud removal. © 2021, Chinese Lasers Press. All right reserved.","Geometrical optics; Image texture; Learning systems; Radar imaging; Remote sensing; Textures; Adversarial networks; Cloud removal; Color information; Information recovery; Optical image; Optical remote sensing; Satellite images; Spectral information; Deep learning","Cloud removal; Conditional generative adversarial network (cGAN); Image fusion; Optical image; Remote sensing; Synthetic aperture radar (SAR) image","Article","Final","","Scopus","2-s2.0-85113278742"
"Kurban T.","Kurban, Tuba (35077012700)","35077012700","Fusion of remotely sensed infrared and visible images using Shearlet transform and backtracking search algorithm","2021","International Journal of Remote Sensing","42","13","","5091","5108","17","10.1080/01431161.2021.1910370","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104572531&doi=10.1080%2f01431161.2021.1910370&partnerID=40&md5=8b2989f6394fadba18a49db433d87cb3","Information provided from a single spectral band of a satellite image, may not be sufficient in most cases for classification, recognition and change detection applications. Therefore, bands with different spectral and spatial characteristics are combined to obtain a single fused image that contains complementary information. This study introduces a novel hybrid fusion method for remotely sensed infrared and visible images based on backtracking search algorithm (BSA) and Shearlet transform. Shearlet is an efficient processing method to transform spatial information and BSA is a powerful metaheuristic optimization method. Combining these techniques offers an efficient way to fuse low-resolution infrared and high-resolution panchromatic bands of satellite images. Extensive experiments proved that proposed method outperforms well-known multi-scale transforms based fusion methods in terms of both numerical and visual evaluations. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","Classification (of information); Learning algorithms; Numerical methods; Remote sensing; Backtracking search algorithms; Infrared and visible image; Meta-heuristic optimizations; Multi-scale transforms; Panchromatic bands; Shearlet transforms; Spatial informations; Spectral and spatial characteristics; algorithm; computer simulation; detection method; efficiency measurement; image analysis; numerical model; remote sensing; satellite data; satellite imagery; spatial resolution; Image fusion","","Article","Final","","Scopus","2-s2.0-85104572531"
"Hamouda M.; Bouhlel M.S.","Hamouda, Maissa (57202891783); Bouhlel, Med Salim (6507076729)","57202891783; 6507076729","Modified Convolutional Neural Networks Architecture for Hyperspectral Image Classification (Extra-Convolutional Neural Networks)","2021","IET Image Processing","","","","","","","10.1049/ipr2.12169","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102472468&doi=10.1049%2fipr2.12169&partnerID=40&md5=9867ce10b31a305f671c5dbe41da103a","Classification of Hyperspectral Satellite Images (HSI) is a very important technology for object detection and cartography. Several problems can be detected, which make classification difficult (large size of the images, fusion between the classes, small amount of samples, etc.). Recently, several Convolutional Neural Networks (CNN-HSI) have been proposed for the classification of hyperspectral images. In this article, an improvement to CNN-HSI is proposed, aiming to reduce the number of erroneous pixels during classification (due to the limited number of samples). Thus, an extra-convolution technique (ExCNN) is proposed, where we add layers of global convolutions on the classified images, outgoing from classical CNN. The addition of 1 to 10 layers, on three real hyperspectral images, is tested. The results obtained are compared with other similar methods of the state of art, and show the effectiveness of the proposed method. © 2021 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology","","","Article","Article in press","All Open Access; Gold Open Access","Scopus","2-s2.0-85102472468"
"Zheng Y.; Song H.; Sun L.; Wu Z.; Jeon B.","Zheng, Yuhui (55576235500); Song, Huihui (36572623600); Sun, Le (55493054300); Wu, Zebin (20437030300); Jeon, Byeungwoo (15136434400)","55576235500; 36572623600; 55493054300; 20437030300; 15136434400","Spatiotemporal fusion of satellite images via very deep convolutional networks","2019","Remote Sensing","11","22","2701","","","","10.3390/rs11222701","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075368174&doi=10.3390%2frs11222701&partnerID=40&md5=1dbf516ad6ac004176a337ac570fab25","Spatiotemporal fusion provides an effective way to fuse two types of remote sensing data featured by complementary spatial and temporal properties (typical representatives are Landsat and MODIS images) to generate fused data with both high spatial and temporal resolutions. This paper presents a very deep convolutional neural network (VDCN) based spatiotemporal fusion approach to effectively handle massive remote sensing data in practical applications. Compared with existing shallow learning methods, especially for the sparse representation based ones, the proposed VDCN-based model has the following merits: (1) explicitly correlating the MODIS and Landsat images by learning a non-linear mapping relationship; (2) automatically extracting effective image features; and (3) unifying the feature extraction, non-linear mapping, and image reconstruction into one optimization framework. In the training stage, we train a non-linear mapping between downsampled Landsat and MODIS data using VDCN, and then we train a multi-scale super-resolution (MSSR) VDCN between the original Landsat and downsampled Landsat data. The prediction procedure contains three layers, where each layer consists of a VDCN-based prediction and a fusion model. These layers achieve non-linear mapping from MODIS to downsampled Landsat data, the two-times SR of downsampled Landsat data, and the five-times SR of downsampled Landsat data, successively. Extensive evaluations are executed on two groups of commonly used Landsat-MODIS benchmark datasets. For the fusion results, the quantitative evaluations on all prediction dates and the visual effect on one key date demonstrate that the proposed approach achieves more accurate fusion results than sparse representation based methods. © 2019 by the authors.","Convolution; Deep neural networks; Forecasting; Image reconstruction; Mapping; Neural networks; Radiometers; Remote sensing; Convolutional networks; Convolutional neural network; Massive remote sensing datum; Nonlinear mappings; Optimization framework; Quantitative evaluation; Spatial and temporal resolutions; Spatio-temporal fusions; Image fusion","Non-linear mapping; Spatiotemporal fusion; Very deep convolutional neural network","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85075368174"
"El Abidi Z.; Minaoui K.; El Aouni A.; Tamim A.; Laanaya H.","El Abidi, Zineb (57202460591); Minaoui, Khalid (55312226700); El Aouni, Anass (57190492008); Tamim, Ayoub (56178185800); Laanaya, Hicham (14058152800)","57202460591; 55312226700; 57190492008; 56178185800; 14058152800","An Efficient Detection of Moroccan Coastal Upwelling Based on Fusion of Chlorophyll-a and Sea Surface Temperature Images with a New Validation Index","2021","IEEE Geoscience and Remote Sensing Letters","18","8","9127830","1322","1326","4","10.1109/LGRS.2020.3002473","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111280412&doi=10.1109%2fLGRS.2020.3002473&partnerID=40&md5=f161b7acd6449c7a3849f3b216228331","This research deals with the problem of identifying and extracting effectively the main Moroccan upwelling front. The proposed methodology, based on the image-fusion concept, comes to benefit from the information available in both sea-surface temperature (SST) and chlorophyll-a satellite images. Moreover, a new validation index is proposed by computing a simple gradient along the extracted upwelling limit. The developed procedure is applied over a database of 366 SST and 366 chlorophyll-a images from 2007 to 2014, covering the Moroccan Atlantic coast. The final results are validated qualitatively by an oceanographer and quantitatively by our innovative index. The findings of validation demonstrate the performance of our fusion approach. © 2004-2012 IEEE.","Atlantic Ocean; Atmospheric temperature; Chlorophyll; Image fusion; Submarine geophysics; Surface properties; Surface waters; Atlantic coasts; Coastal upwelling; Efficient detection; Fusion concept; Moroccan upwelling; Satellite images; Sea surface temperature (SST); Validation index; chlorophyll a; database; detection method; innovation; model validation; remote sensing; sea surface temperature; upwelling; Oceanography","Chlorophyll-a; image fusion; main Moroccan upwelling front; sea-surface temperature (SST); validation index","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85111280412"
"Mejia-Cabrera H.I.; Sanchez S.; Monja F.; Cabrejos L.A.; Tuesta-Monteza V.; Forero M.G.","Mejia-Cabrera, Heber I. (57193775165); Sanchez, Samuel (57325502800); Monja, Fernando (57325502900); Cabrejos, Luz A. (57325878800); Tuesta-Monteza, Victor (57193776107); Forero, Manuel G. (15831912100)","57193775165; 57325502800; 57325502900; 57325878800; 57193776107; 15831912100","Evaluation of panchromatic and multispectral image fusion methods using natural images","2021","Proceedings of SPIE - The International Society for Optical Engineering","11842","","118421I","","","","10.1117/12.2594623","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118633631&doi=10.1117%2f12.2594623&partnerID=40&md5=cf869cfb3d6c2df5a5661bc407ac88d9","Images provided by various remote sensing satellites are multispectral, low resolution, and panchromatic, high resolution, which are fused, enlarging the low resolution images to make them the same size as the panchromatic ones. Panchromatic images have good spatial resolution but only one spectral band and multispectral images typically have four or eight bands but are four times lower in spatial resolution than a panchromatic image. Image fusion of this type seeks to combine the best feature of the high spatial panchromatic image with the low spatial multispectral image to obtain an image with high spatial and spectral resolution. Several techniques have been developed to perform this fusion however the techniques with low computational resource consumption are EIHS Algorithm, Brovey Algorithm, Averaging Algorithm. To compare them, in this work, natural color photographs are taken, from which high resolution monochromatic and lower resolution chromatic images are obtained to emulate the real situation. The low resolution color images obtained were interpolated using three satellite image interpolation techniques. The fusion techniques were evaluated, obtaining the quantitative spectral and spatial ERGAS indices and the RMSE. The EIHS and Brovey techniques were found to produce artifacts because the color component values can fall above or below the representation interval [0,255]. After correcting this issue, it was found that the EIHS and Brovey methods, in that order, produced the lowest RMSE, followed by the averaging method. Since this result proved to be inconsistent with that obtained with the mean ERGAS, a new normalized mean ERGAS that gives a better indication of fusion quality, matching the result given by the RMSE, was proposed to be used instead.  © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Color; Image resolution; Remote sensing; Averaging algorithm; Brovey algorithm; EIHS algorithm; High resolution; Lower resolution; Multiespectral; Panchromatic; RMSE; Spatial resolution; Standardized ERGAS; Image fusion","Averaging Algorithm; Brovey Algorithm; EIHS Algorithm; Image fusion; Multiespectral; Panchromatic; RMSE; Standardised ERGAS","Conference paper","Final","","Scopus","2-s2.0-85118633631"
"Mehmood A.","Mehmood, Asif (36133731600)","36133731600","Late fusion of pre-trained networks for satellite image classification","2022","Proceedings of SPIE - The International Society for Optical Engineering","12101","","1210106","","","","10.1117/12.2615030","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136089455&doi=10.1117%2f12.2615030&partnerID=40&md5=7417c14be31f9bca313effec1f7742ba","This paper presents a deep learning approach to image classification in satellite imagery based on late fusion in conjunction with pre-trained networks. The pre-trained models are especially useful for image classification and can be used as the backbone for transfer learning. The intuition behind transfer learning is that these pre-trained models will effectively serve as a generic model of the visual world. This paper addresses the problem of object classification in representative data limited environment and exploits the pre-trained networks in conjunction with late fusion to perform classification on satellite images. Interestingly, the pre-trained networks namely ResNet50 and VGG16 trained on ImageNet (a large collection of photographs), and yet yield results with high accuracy on satellite images. The experimental results show that the late fusion method outperforms the other competing approaches buy a considerable margin of over 10 percentage points.  © 2022 SPIE.","Deep learning; Image classification; Image fusion; Learning systems; Transfer learning; Imagenet; Images classification; Late fusion; Learning approach; Pretrained; Resnet; Satellite image classification; Satellite images; Transfer learning; VGG; Satellite imagery","ImageNet; Late fusion; Pretrained; ResNet; Satellite Imagery; Transfer Learning; VGG","Conference paper","Final","","Scopus","2-s2.0-85136089455"
"Li X.; Xu F.; Lyu X.; Gao H.; Tong Y.; Cai S.; Li S.; Liu D.","Li, Xin (57215779896); Xu, Feng (56401380100); Lyu, Xin (57212319266); Gao, Hongmin (34770690700); Tong, Yao (57208420959); Cai, Sujin (56472251400); Li, Shengyang (56438234000); Liu, Daofang (57208423917)","57215779896; 56401380100; 57212319266; 34770690700; 57208420959; 56472251400; 56438234000; 57208423917","Dual attention deep fusion semantic segmentation networks of large-scale satellite remote-sensing images","2021","International Journal of Remote Sensing","42","9","","3583","3610","27","10.1080/01431161.2021.1876272","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101476043&doi=10.1080%2f01431161.2021.1876272&partnerID=40&md5=8a0e263eed85c28efe04004b4b36080b","Since DCNNs (deep convolutional neural networks) have been successfully applied to various academic and industrial fields, semantic segmentation methods, based on DCNNs, are increasingly explored for remote-sensing image interpreting and information extracting. It is still highly challenging due to the presence of irregular target shapes, and similarities of inter–and intra-class objects in large-scale high-resolution satellite images. A majority of existing methods fuse the multi-scale features that always fail to provide satisfactory results. In this paper, a dual attention deep fusion semantic segmentation network of large-scale satellite remote-sensing images is proposed (DASSN_RSI). The framework consists of novel encoder-decoder architecture, and a weight-adaptive loss function based on focal loss. To refine high-level semantic and low-level spatial feature maps, the deep layer channel attention module (DLCAM) and shallow layer spatial attention module (SLSAM) are designed and appended with specific blocks. Then the DUpsampling is incorporated to fuse feature maps in a lossless way. Peculiarly, the weight-adaptive focal loss (W-AFL) is inferred and embedded successfully, alleviating the class-imbalanced issue as much as possible. The extensive experiments are conducted on Gaofen image dataset (GID) datasets (Gaofen-2 satellite images, coarse set with five categories and refined set with fifteen categories). And the results show that our approach achieves state-of-the-art performance compared to other typical variants of encoder-decoder networks in the numerical evaluation and visual inspection. Besides, the necessary ablation studies are carried out for a comprehensive evaluation. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Convolutional neural networks; Decoding; Deep neural networks; Image fusion; Image segmentation; Satellites; Semantic Web; Semantics; Signal encoding; Adaptive loss functions; Comprehensive evaluation; Encoder-decoder architecture; High resolution satellite images; Information extracting; Large-scale satellites; Remote sensing images; State-of-the-art performance; artificial neural network; image processing; remote sensing; satellite data; satellite imagery; Remote sensing","","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85101476043"
"Chen R.; Wang X.","Chen, Runyu (57224512790); Wang, Xiaoqing (56048910600)","57224512790; 56048910600","An Effective Cloud Removal Algorithm Based on Sparse Expression","2021","ACM International Conference Proceeding Series","","","","194","199","5","10.1145/3447587.3447616","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107758080&doi=10.1145%2f3447587.3447616&partnerID=40&md5=f7a9e8ae5f536520c7f499df0abc3605","In order to remove the clouds cover in remote sensing images, this paper proposes a clouds removal algorithm based on spatiotemporal fusion and sparse expression. In this paper we select two images in the same area with a short time difference, one of them is covered by clouds, the other clear image is basically not. First, we use some indicators [1] to distinguish clouds and clear ground to get classified images, such as NDVI(Normalized Difference Vegetation Index), and EVI(Enhanced Vegetation Index). Then we select the cloudless regions in both images to train sparse expression dictionary. For the cloudy regions, we find the corresponding area in the cloudless area in the other image, in which we perform dictionary decomposition and get a sparse representation [2], [3]. We utilize the dictionary of cloudy image to map the sparse representation to the corresponding area in cloudy image, and replace the original cloudy area. The fusion image retains the original real information and predicts the type of ground surface under the clouds. The experimental results show that the algorithm has an excellent effect on the removal of thick clouds, and solves the problem of image distortion and grayscale mutations that may be caused by traditional clouds removal algorithms. Sentinel-2 satellite images were used to evaluate the proposed method, and it was compared with other related algorithms, for example, homomorphic filtering and LRMR(low-rank matrix recovery), the experimental results confirm that the proposed method is effective in correcting clouds contaminated images while preserving the true spectral information.  © 2021 ACM.","Genetic algorithms; Image fusion; Information filtering; Remote sensing; Vegetation; Cloud removal algorithms; Enhanced vegetation index; Homomorphic filtering; Low-rank matrix recoveries; Normalized difference vegetation index; Remote sensing images; Sparse representation; Spatio-temporal fusions; Image enhancement","Clouds removal; image algorithm; image fusion; sparse expression","Conference paper","Final","","Scopus","2-s2.0-85107758080"
"Moghimi A.; Mohammadzadeh A.; Celik T.; Brisco B.; Amani M.","Moghimi, Armin (57194760236); Mohammadzadeh, Ali (16070064500); Celik, Turgay (35101499300); Brisco, Brian (7003505161); Amani, Meisam (56684747900)","57194760236; 16070064500; 35101499300; 7003505161; 56684747900","Automatic Relative Radiometric Normalization of Bi-Temporal Satellite Images Using a Coarse-to-Fine Pseudo-Invariant Features Selection and Fuzzy Integral Fusion Strategies","2022","Remote Sensing","14","8","1777","","","","10.3390/rs14081777","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128852062&doi=10.3390%2frs14081777&partnerID=40&md5=ed1785c3261fe65e37b9f16a35de89bf","Relative radiometric normalization (RRN) is important for pre-processing and analyzing multitemporal remote sensing (RS) images. Multitemporal RS images usually include different land use/land cover (LULC) types; therefore, considering an identical linear relationship during RRN modeling may result in potential errors in the RRN results. To resolve this issue, we proposed a new automatic RRN technique that efficiently selects the clustered pseudo-invariant features (PIFs) through a coarse-to-fine strategy and uses them in a fusion-based RRN modeling approach. In the coarse stage, an efficient difference index was first generated from the down-sampled reference and target images by combining the spectral correlation, spectral angle mapper (SAM), and Chebyshev distance. This index was then categorized into three groups of changed, unchanged, and uncertain classes using a fast multiple thresholding technique. In the fine stage, the subject image was first segmented into different clusters by the histogram-based fuzzy c-means (HFCM) algorithm. The optimal PIFs were then selected from unchanged and uncertain regions using each cluster’s bivariate joint distribution analysis. In the RRN modeling step, two normalized subject images were first produced using the robust linear regression (RLR) and cluster-wise-RLR (CRLR) methods based on the clustered PIFs. Finally, the normalized images were fused using the Choquet fuzzy integral fusion strategy for overwhelming the discontinuity between clusters in the final results and keeping the radiometric rectification optimal. Several experiments were implemented on four different bi-temporal satellite images and a simulated dataset to demonstrate the efficiency of the proposed method. The results showed that the proposed method yielded superior RRN results and outperformed other considered well-known RRN algorithms in terms of both accuracy level and execution time. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Clustering algorithms; Integral equations; Land use; Radiometry; Remote sensing; Satellites; Change detection; Fusion strategies; Multi-temporal remote sensing; Multi-temporal satellite images; Pseudo-invariant feature; Pseudo-invariant features; Relative radiometric normalization; Remote sensing images; Satellite images; Image fusion","change detection; image fusion; multi-temporal satellite images; pseudo-invariant features (PIFs); relative radiometric normalization (RRN)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85128852062"
"Zheng Y.; Liu S.; Du Q.; Zhao H.; Tong X.; Dalponte M.","Zheng, Yongjie (57215334734); Liu, Sicong (38662862600); Du, Qian (7202060063); Zhao, Hui (57274670600); Tong, Xiaohua (55500134600); Dalponte, Michele (24075297800)","57215334734; 38662862600; 7202060063; 57274670600; 55500134600; 24075297800","A Novel Multitemporal Deep Fusion Network (MDFN) for Short-Term Multitemporal HR Images Classification","2021","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14","","","10691","10704","13","10.1109/JSTARS.2021.3119942","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117822737&doi=10.1109%2fJSTARS.2021.3119942&partnerID=40&md5=4a9680ad0ae36cb7dacedb21cf7dcee0","High-resolution (HR) satellite images, due to the technical constraints on spectral and spatial resolutions, usually contain only several broad spectral bands but with a very high spatial resolution. This provides rich spatial details of the objects on the Earth surface, while their spectral discrimination is relatively low. Recently, the increase of the satellite revisit times made it possible to acquire more frequent data coverage for finer classification. In this article, we proposed a novel multitemporal deep fusion network (MDFN) for short-term multitemporal HR images classification. Specifically, a two-branch structure of MDFN is designed, which includes a long short-term memory (LSTM) and a convolutional neural network (CNN). The LSTM branch is mainly used to learn the joint expression of different temporal-spectral features. For the CNN branch, the three-dimensional (3-D) convolution is firstly applied along the temporal and spectral dimensions to jointly learn the temporal-spatial and spectral-spatial information, respectively, and then the 2-D convolution is performed along the spatial dimension to further extract the spatial context information. Finally, features generated from the two different branches are fused to obtain the discriminative high-level semantic information for classification. Experimental results carried on two real multitemporal HR remote sensing datasets demonstrate that the proposed MDFN provides better classification performance over the state-of-the-art methods, and it also shows the potentiality to use short-term multitemporal HR images for more accurate land use/land cover mapping. © 2008-2012 IEEE.","Brain; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Feature extraction; Image classification; Image fusion; Land use; Long short-term memory; Remote sensing; Satellites; Semantics; Convolutional neural network; Deep feature fusion; Features extraction; Features fusions; Images classification; Land cover classification; Land use/land cover; Land use/land cover  classification; Long short term memory; Multi-temporal image; Spatial resolution; artificial neural network; image classification; image resolution; land cover; land use change; satellite imagery; spatial resolution; Image resolution","Convolutional neural network (CNN); deep feature fusion; land use/land cover (LULC) classification; long short term memory (LSTM); multitemporal images","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85117822737"
"Fang S.; Guo Q.; Cao Y.","Fang, Shuai (7402422537); Guo, Qing (57796600400); Cao, Yang (57022583200)","7402422537; 57796600400; 57022583200","WDBSTF: A Weighted Dual-Branch Spatiotemporal Fusion Network Based on Complementarity between Super-Resolution and Change Prediction","2022","Remote Sensing","14","22","5883","","","","10.3390/rs14225883","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142722791&doi=10.3390%2frs14225883&partnerID=40&md5=6a93d0d75ece432938b591460771eea6","Spatiotemporal fusion (STF) is a solution to generate satellite images with both high-spatial and high-temporal resolutions. The deep learning-based STF algorithms focus on spatial dimensions to build a super-resolution (SR) model or the temporal dimensions to build a change prediction (CP) model, or the task itself to build a data-driven end-to-end model. The multi-source images used for STF usually have large spatial scale gaps and temporal spans. The large spatial scale gaps lead to poor spatial details based on a SR model; the large temporal spans make it difficult to accurately reconstruct changing areas based on a CP model. We propose a weighted dual-branch spatiotemporal fusion network based on complementarity between super-resolution and change prediction (WDBSTF), which includes the SR branch and CP branch, and a weight module representing the complementarity of the two branches. The SR branch makes full use of edge information and high-resolution reference images to obtain high-quality spatial features for image reconstruction. The CP branch decomposes complex problems via a two-layer cascaded network, changes features from the difference image, and selects high-quality spatial features through the attention mechanism. The fusion result of the CP branch has rich image details, but the fusion accuracy in the changing area is low due to the lack of detail. The SR branch has consistent and excellent fusion performances in the changing and no-changing areas, but the image details are not rich enough compared with the CP branch due to the large amplification factor. Next, a weighted network was designed to combine the advantages of the two branches to produce improved fusion results. We evaluated the performance of the WDBSTF in three representative scenarios, and both visual and quantitative evaluations demonstrate the state-of-the-art performance of our algorithm. (On the LGC dataset, our method outperforms the suboptimal method by 2.577% on SSIM. On the AHB dataset, our method outperforms the suboptimal method by 1.684% on SSIM. On the CIA dataset, our method outperforms the suboptimal method by 5.55% on SAM). © 2022 by the authors.","Deep learning; Forecasting; Image enhancement; Image fusion; Network layers; Optical resolving power; Remote sensing; Attention mechanisms; Change prediction; Edge enhancements; Image super resolutions; Remote sensing image super-resolution; Remote sensing images; Spatio-temporal fusions; Sub-optimal method; Superresolution; Weighted networks; Image reconstruction","attention mechanism; CNNs; edge enhancement; remote sensing images super-resolution; spatiotemporal fusion; weighted network","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85142722791"
"Kim G.","Kim, Gibak (15925492200)","15925492200","Pixel-wise weighted composition of wavelet planes for satellite image fusion","2020","Transactions of the Korean Institute of Electrical Engineers","69","1","","152","157","5","10.5370/KIEE.2020.69.1.152","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081972318&doi=10.5370%2fKIEE.2020.69.1.152&partnerID=40&md5=75ee1f3d4b631d09f137638b242bc190","We propose a wavelet-based method for fusing satellite images. The proposed scheme is based on the wavelet decomposition. A linear combination of wavelet planes is presented, which includes terms for avoiding overlapping high frequency component and enhancing details. To consider the local characteristics of image, weights are imposed on each pixel of the image and the high resolution image is synthesized in a pixel-wise fusion. The weights are estimated by least squares method with lowered resolution images and multiplied by a proper scaling factor. In the experiments, using IKONOS and QuickBird satellite image data, we demonstrated that the proposed method outperforms conventional methods in terms of various objective quality measures. © 2020 Korean Institute of Electrical Engineers. All rights reserved.","Least squares approximations; Pixels; Satellite imagery; Wavelet decomposition; Conventional methods; High frequency components; High resolution image; Least squares methods; Local characteristics; Objective quality measures; Wavelet planes; Wavelet-based methods; Image fusion","Image fusion; Satellite imagery; Wavelet plane","Article","Final","","Scopus","2-s2.0-85081972318"
"Zhao Y.; Liu D.","Zhao, Yongquan (57192575717); Liu, Desheng (55577793400)","57192575717; 55577793400","A robust and adaptive spatial-spectral fusion model for PlanetScope and Sentinel-2 imagery","2022","GIScience and Remote Sensing","59","1","","520","546","26","10.1080/15481603.2022.2036054","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127040354&doi=10.1080%2f15481603.2022.2036054&partnerID=40&md5=adaedef06006886c69888dce4b2b86cc","Satellite sensors usually compromise between their spatial and spectral resolutions due to the limitations of data volume and signal-to-noise ratio, such as the Very High spatial Resolution (VHR) PlanetScope (PS, four or five 3-m bands) and medium spatial resolution (med-resolution) Sentinel-2 (S2, ten 10-m or 20-m bands) constellations. Concomitant with the growing demand for satellite images with ample spatial details and spectral signatures, Spatial-Spectral image Fusion (SSF) is important for blending the spatial resolution of PS and the spectral resolution of S2 to produce synthetic 3-m image products in the ten bands for different applications. However, the existing studies conducted for fusing PS and S2 data present limited spatial and spectral fidelities to original PS and S2 bands. Hence, this study presents a new SSF method named Robust and Adaptive Spatial-Spectral image Fusion Model (RASSFM) for that purpose. RASSFM improves the spatial and spectral fidelities of the results through: (1) combining the spectral mapping and the spectral correlation to obtain the high-quality spatial information sources for the S2 bands, (2) utilizing the neighborhood information considering both spatial and spectral constraints to improve the spectral fidelities of the fused bands. We conducted the SSF tests at the degraded and original spatial resolutions to comprehensively evaluate the proposed RASSFM method. Furthermore, we examined the performance of RASSFM in four study sites with highly mixed regular or desert urban, heterogeneous agricultural, and vegetation-dominated landscapes. Moreover, we compared our method with twenty representative SSF methods developed for similar purposes. The results demonstrate that RASSFM not only outperforms the other methods but has robust performance in different landscapes and comparable accuracies in different bands, thereby advancing the fusion of VHR and med-resolution images from PS and S2, respectively. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","image resolution; multispectral image; numerical model; satellite imagery; satellite sensor; Sentinel; spatial analysis; spectral analysis","medium resolution (med-resolution); multispectral; PlanetScope; sentinel-2; Spatial-spectral image fusion; very high resolution (VHR)","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85127040354"
"Gasmi A.; Gomez C.; Chehbouni A.; Dhiba D.; Elfil H.","Gasmi, Anis (57192316697); Gomez, Cécile (55485047400); Chehbouni, Abdelghani (7006296776); Dhiba, Driss (12787043500); Elfil, Hamza (6507567383)","57192316697; 55485047400; 7006296776; 12787043500; 6507567383","Satellite Multi-Sensor Data Fusion for Soil Clay Mapping Based on the Spectral Index and Spectral Bands Approaches","2022","Remote Sensing","14","5","1103","","","","10.3390/rs14051103","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125660094&doi=10.3390%2frs14051103&partnerID=40&md5=b5ee709322f9323a3284d481030c5f2f","Integrating satellite data at different resolutions (i.e., spatial, spectral, and temporal) can be a helpful technique for acquiring soil information from a synoptic point of view. This study aimed to evaluate the advantage of using satellite mono-and multi-sensor image fusion based on either spectral indices or entire spectra to predict the topsoil clay content. To this end, multispectral satellite images acquired by various sensors (i.e., Landsat-5 Thematic Mapper (TM), Landsat-8 Operational Land Imager (OLI), Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER), and Sentinel2-MultiSpectral Instrument (S2-MSI)) have been used to assess their potential in identifying bare soil pixels over an area in northeastern Tunisia, the Lebna and Chiba catchments. A spectral index image and a spectral bands image are generated for each satellite sensor (i.e., TM, OLI, ASTER, and S2-MSI). Then, two multi-sensor satellite image fusions are generated, one from the spectral index images and the other from spectral bands. The resulting spectral index and spectral band images based on mono-and multi-sensor satellites are compared through their spectral patterns and ability to predict the topsoil clay content using the Multilayer Perceptron with backpropagation learning algorithm (MLP-BP) method. The results suggest that for clay content prediction: (i) the spectral bands’ images outperformed the spectral index images regardless of the used satellite sensor; (ii) the fused images derived from the spectral index or bands provided the best performances, with a 10% increase in the prediction accuracy; and (iii) the bare soil images obtained by the fusion of many multispectral sensor satellite images can be more beneficial than using mono-sensor images. Soil maps elaborated via satellite multi-sensor data fusion might become a valuable tool for soil survey, land planning, management, and precision agriculture. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Catchments; Image fusion; Photomapping; Remote sensing; Satellites; Soil surveys; Soils; Clay content; Digital soil mappings; Index image; Multi sensors data fusion; Multispectral remote sensing; Operational land imager; Spectral band; Spectral indices; Thematic mappers; Topsoil; Forecasting","Clay content; Digital soil mapping; Multi-sensors data fusion; Multispectral remote sensing; Spectral band; Spectral index","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85125660094"
"Dai J.; Zhu T.; Zhang Y.; Wang Y.; Fang X.","Dai, Jiguang (36677171900); Zhu, Tingting (57209399870); Zhang, Yilei (57211923516); Wang, Yang (57244937000); Fang, Xinxin (57194102233)","36677171900; 57209399870; 57211923516; 57244937000; 57194102233","Line segment fusion method for high-resolution optical satellite image; [高分辨率光学卫星影像线段融合方法]","2020","Cehui Xuebao/Acta Geodaetica et Cartographica Sinica","49","4","","489","498","9","10.11947/j.AGCS.2020.20190109","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083693851&doi=10.11947%2fj.AGCS.2020.20190109&partnerID=40&md5=acb1bfa80dae5a692ee2017a48a42b90","To solve the problem of line segment breakage in high resolution optical satellite images, a simple line segment fusion method is proposed based on the idea of complementary advantages of line segment extraction results from different methods. Firstly, this paper starts with edge extraction and edge tracking, compares and analyses the experimental results of different methods to verify the necessity of line segment fusion. Secondly, two line segment extraction methods, which are different in edge extraction and edge tracking, are selected as the fusion elements, and Dai method is improved. Thirdly, Phase grouping, endpoint constraints and topological constraints are used to construct line segment matching models of different methods. Finally, a line segment fusion decision-making model is established according to the principle of line segment length priority. Through the analysis of experimental results of several high resolution optical satellite images with different types, sizes and coverage areas, compared with other methods, the proposed method has the advantages of high completeness. © 2020, Surveying and Mapping Press. All right reserved.","Decision making; Extraction; Image fusion; Optical resolving power; Satellites; Edge extraction; End-point constraint; Fusion decision makings; Fusion element; High-resolution optical satellite images; Line segment extraction; Matching models; Topological constraints; breakage; decision making; extraction method; image resolution; satellite imagery; topology; tracking; Image segmentation","Fusion; High resolution; Line segment; Optical; Satellite image","Article","Final","","Scopus","2-s2.0-85083693851"
"Ghadjati M.; Benazza-Benyahia A.; Moussaoui A.","Ghadjati, Mohamed (56077225600); Benazza-Benyahia, Amel (55967964100); Moussaoui, Abdelkrim (15081385600)","56077225600; 55967964100; 15081385600","Satellite Image Fusion Using an Iterative IHS-Based Approach","2020","2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium, M2GARSS 2020 - Proceedings","","","9105197","133","136","3","10.1109/M2GARSS47143.2020.9105197","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086720479&doi=10.1109%2fM2GARSS47143.2020.9105197&partnerID=40&md5=884d49b717ae8d64ab4a7d0e0758aee3","Intensity-Hue-Saturation (IHS) method is a pansharpening method belonging to the spectral class methods. In this class of methods, the multispectral image undergoes a spectral transformation and then one of the resulting components is totally replaced by the panchromatic image, hence leading to a significant color distortion. To alleviate this shortcoming, in the literature, the wavelet transform is often integrated to the spectral methods in order to transfer only the spatial details of the panchromatic image. Furthermore, the spatial information quantity transferred during the fusion is usually defined by the resolution ratio between the multispectral and panchromatic images. However, this is not necessarily the optimal way to generate the best fused image. In this paper, we propose an iterative IHS-based method (called IIHS), to continuously transfer the spatial information from the panchromatic image to the multispectral image while controling the perceptual quality of the fused image. Experiments on remote sensing images show that the proposed method presents the best visual and objective performances comparatively to the state-of-art IHS methods. © 2020 IEEE.","Geology; Iterative methods; Remote sensing; Wavelet transforms; Intensity hue saturations; Multispectral images; Panchromatic images; Perceptual quality; Remote sensing images; Resolution ratios; Spatial informations; Spectral transformations; Image fusion","IHS method; iterative IHS; Pansharpening; quality with no reference index; spatial information","Conference paper","Final","","Scopus","2-s2.0-85086720479"
"Fu X.; Wang W.; Huang Y.; Ding X.; Paisley J.","Fu, Xueyang (55647967200); Wang, Wu (57215771956); Huang, Yue (57204367647); Ding, Xinghao (57204367131); Paisley, John (35810949000)","55647967200; 57215771956; 57204367647; 57204367131; 35810949000","Deep Multiscale Detail Networks for Multiband Spectral Image Sharpening","2021","IEEE Transactions on Neural Networks and Learning Systems","32","5","9106801","2090","2104","14","10.1109/TNNLS.2020.2996498","57","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105600826&doi=10.1109%2fTNNLS.2020.2996498&partnerID=40&md5=b2dac35b672f7c70fd6f9eab2bd8ef84","We introduce a new deep detail network architecture with grouped multiscale dilated convolutions to sharpen images contain multiband spectral information. Specifically, our end-to-end network directly fuses low-resolution multispectral and panchromatic inputs to produce high-resolution multispectral results, which is the same goal of the pansharpening in remote sensing. The proposed network architecture is designed by utilizing our domain knowledge and considering the two aims of the pansharpening: spectral and spatial preservations. For spectral preservation, the up-sampled multispectral images are directly added to the output for lossless spectral information propagation. For spatial preservation, we train the proposed network in the high-frequency domain instead of the commonly used image domain. Different from conventional network structures, we remove pooling and batch normalization layers to preserve spatial information and improve generalization to new satellites, respectively. To effectively and efficiently obtain multiscale contextual features at a fine-grained level, we propose a grouped multiscale dilated network structure to enlarge the receptive fields for each network layer. This structure allows the network to capture multiscale representations without increasing the parameter burden and network complexity. These representations are finally utilized to reconstruct the residual images which contain spatial details of PAN. Our trained network is able to generalize different satellite images without the need for parameter tuning. Moreover, our model is a general framework, which can be directly used for other kinds of multiband spectral image sharpening, e.g., hyperspectral image sharpening. Experiments show that our model performs favorably against compared methods in terms of both qualitative and quantitative qualities.  © 2012 IEEE.","Frequency domain analysis; Information dissemination; Network layers; Remote sensing; Spectroscopy; Conventional network structures; End-to-end network; High frequency domain; Multiscale representations; Multispectral images; Network complexity; Spatial informations; Spectral information; article; quantitative analysis; receptive field; satellite imagery; Network architecture","Deep learning; hyperspectral image (HSI) sharpening; image fusion; pansharpening; superresolution","Article","Final","","Scopus","2-s2.0-85105600826"
"Talal T.M.; Attiya G.; Metwalli M.R.; Abd El-Samie F.E.; Dessouky M.I.","Talal, Tamer M. (15766387800); Attiya, Gamal (56001046200); Metwalli, Mohamed R. (35776990600); Abd El-Samie, Fathi E. (12785222000); Dessouky, Moawad I. (7005350912)","15766387800; 56001046200; 35776990600; 12785222000; 7005350912","Satellite image fusion based on modified central force optimization","2020","Multimedia Tools and Applications","79","29-30","","21129","21154","25","10.1007/s11042-019-08471-7","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085088124&doi=10.1007%2fs11042-019-08471-7&partnerID=40&md5=371c510f2779fe9dfc95904e86aaa3bb","Nowadays, optimization has become a brand methodology for different applications. One of the most promising fields for application of optimization is the image processing field, especially image fusion. A new effective deterministic optimization technique is the modified central force optimization (MCFO) that overcomes the low convergence rate drawback of the central force optimization (CFO). In this paper, the MCFO is applied with standard image fusion methods as a novel brand to improve the fusion efficiency either qualitatively or quantitatively. Intensity-hue-saturation (IHS), high-pass filtering (HPF), and discrete wavelet transform (DWT) are powerful standard techniques for satellite image fusion that are implemented with MCFO optimization in this paper. They are performed on satellite panchromatic (PAN) and multispectral (MS) images. The target of using the MCFO is to reduce some spectral and spatial distortions that may occur without optimization. Different qualitative indices have been used to validate the proposed approach comprising optimization for satellite image fusion. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Discrete wavelet transforms; High pass filters; Image enhancement; Optimization; Satellites; Central force optimizations; Convergence rates; Deterministic optimization; High-pass filtering; Intensity hue saturations; Multispectral images; Qualitative indices; Spatial distortion; Image fusion","DWT; HPF; IHS; Image fusion; Landsat; MCFO; PAN-sharpening; Quickbird; Spot","Article","Final","","Scopus","2-s2.0-85085088124"
"Pal S.; Bhattacharyya S.; Doss S.; Akila D.; Suseendran G.","Pal, Souvik (57223907316); Bhattacharyya, Sonali (57216484257); Doss, Srinath (57216485360); Akila, D. (56472833800); Suseendran, G. (56910235600)","57223907316; 57216484257; 57216485360; 56472833800; 56910235600","Hyperspectral and multispectral image fusion using NSCT and FDCT methods","2020","Journal of Critical Reviews","7","5","","635","642","7","10.31838/jcr.07.05.131","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083677801&doi=10.31838%2fjcr.07.05.131&partnerID=40&md5=842c5a34f48aa2fa02d1bf95fce45e99","Image fusion plays an important role in computer vision, medical imaging, robotics, remote sensing and satellite imagery. Image fusion is a method or a process in which it produce all relevant information in a single image by combining two or more input images. The final image or final output contains more information than a single image. Hyperspectral image known as HIS and Multispectral image fusion known as MSI are used in wide array of application although it originally developed for geology and mining because of high spectral-resolution but it has low spatial-resolution. Non-Subsampled Contour let Transform known as NSCT. Hyperspectral and multispectral Image Fusion using NSCT and FDCT methods are used in this paper and it can be used in various fields like medical imaging, Satellite images, space research and remote sensing. © 2019 by Advance Scientific Research. This is an open-access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/)","","Fast discrete curvelet transform(FDCT); Hyperspectral image (HSI); Multispectral image (MSI); Non-Subsampled Contour let Transform(NSCT)","Review","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85083677801"
"Gao F.; Li Y.; Zhang P.; Zhai Y.; Zhang Y.; Yang Y.; An Y.","Gao, Fang (56856320000); Li, Yihui (57222075470); Zhang, Peng (57222078612); Zhai, Yuwei (57226675353); Zhang, Yan (57211359187); Yang, Yongshuai (57915719400); An, Yuan (57222076419)","56856320000; 57222075470; 57222078612; 57226675353; 57211359187; 57915719400; 57222076419","A high-resolution panchromatic-multispectral satellite image fusion method assisted with building segmentation","2022","Computers and Geosciences","168","","105219","","","","10.1016/j.cageo.2022.105219","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139228390&doi=10.1016%2fj.cageo.2022.105219&partnerID=40&md5=d59aa0adf7c4505ec62b48f6e39e105a","The main difficulty of panchromatic-multispectral image fusion is to balance the quality of spatial information and the spectral fidelity. Most of the practical fusion methods determine the optimal parameters based on the spatial and spectral characteristics of all original panchromatic and multispectral bands. However, for built-up and non-built-up areas (like cropland, forest) in one image, there may be large differences in their spatial and spectral characteristics, so their fused results are not optimal respectively with same parameters. To address above issues, this paper presents a high-resolution satellite image fusion method assisted with building segmentation. First, the proposed approach computes the average gradient and Gaussian filtering parameters of built-up and non-built-up areas separately according to the building segmentation results, on the basis of smoothing filter-based intensity modulation (SFIM). Then the intermediate data of two types of areas are computed in parallel and they are composited to obtain the final fused image, weighted by the pixel-wise “building factors” derived from the building segmentation results. Moreover, to better simulate the spatial characteristics of the multispectral image, we perform the “gradient simulation” operation to extract the gradient values in the multispectral image. Experimental results on Jilin-1 satellite images show that the proposed method provides competitive performance in spatial resolution, multispectral fidelity and quantity of information, as compared to the state-of-the-art methods in mainstream commercial software. © 2022 Chang Guang Satellite Technology Co., Ltd.","Image fusion; Image segmentation; Modulation; Satellites; Building segmentation; High resolution satellite images; High-resolution satellite image fusion; Image fusion methods; Multi-spectral image fusions; Panchromatic-multispectral image fusion; Panchromatic/multispectral; Smoothing filter based intensity modulation; Spatial characteristics; Spectral characteristics; computer simulation; Gaussian method; image resolution; satellite imagery; spatial resolution; Buildings","Building segmentation; High-resolution satellite images fusion; Panchromatic-multispectral image fusion; Smoothing filter-based intensity modulation","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85139228390"
"Naragonahalli ShambuGowda A.; Dasanapura Nanjundaiah C.","Naragonahalli ShambuGowda, Anil (57907371800); Dasanapura Nanjundaiah, Chandrappa (57907030900)","57907371800; 57907030900","Dynamic Gradient Sparsity Based Image Registration and Fusion Technique for Satellite Images","2022","Lecture Notes in Electrical Engineering","903","","","399","409","10","10.1007/978-981-19-2281-7_38","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138803226&doi=10.1007%2f978-981-19-2281-7_38&partnerID=40&md5=65cd39824a0f695ded4209350aa97907","Image registration (IR) is the basic preprocessing step that is widely used for performing different operations such as digital surface modelling, satellite image fusion, image mosaicking and so on, where pixel information from multiple images is merged into a single image for better representation. Existing image registration and fusion techniques achieve good spectral quality, but the spatial quality of the fused image is poor. This paper presents a Dynamic Gradient Sparsity based Image Registration and Fusion (DGS-IRF) technique which can retain good spectral and spatial features. The DGS-IRF technique performs a registration and fusion operation at the same time, which includes an inherent correlation of different pixels to improve registration accuracies under extreme intensity variations/distortions. Different qualitative measurement metrics such as correlation coefficient, standard deviation and root mean square error are used for validation of the DGS-IRF technique. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Image registration; Mean square error; Pixels; Correlation coefficient; Digital surface models; Fusion image; Image fusion techniques; Image mosaicking; Image registration techniques; Images registration; Intensity variations; Pre-processing step; Satellite images; Image fusion","Correlation coefficient; Image fusion; Image mosaicking; Image registration; Intensity variations","Conference paper","Final","","Scopus","2-s2.0-85138803226"
"Fang S.; Guo Q.; Cao Y.; Zhang J.","Fang, Shuai (7402422537); Guo, Qing (57938173300); Cao, Yang (57022583200); Zhang, Jing (57211055913)","7402422537; 57938173300; 57022583200; 57211055913","A Two-Layers Super-Resolution Based Generation Adversarial Spatiotemporal Fusion Model","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","891","894","3","10.1109/IGARSS46834.2022.9883547","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140364937&doi=10.1109%2fIGARSS46834.2022.9883547&partnerID=40&md5=ca6a8cca3ffe4be9f310ce7f1b26e2b0","Remote sensing image spatiotemporal fusion (STF) algorism plays an important role by supplementing the lack of original high-resolution remote sensing satellite images in the study scenarios of dense time-series data. In recent years, the deep-learning-based STF algorithm has become a research hotspot with comparatively higher accuracy and robustness. However, due to the lack of sufficient high-quality images for training and the huge resolution gap between low-resolution images and high-resolution images, it is difficult to recover detailed information, especially for areas of land-cover change. In this paper, we propose a two-layers super-resolution based generation adversarial spatiotemporal fusion model(TLSRSTF) using smaller inputs to reduce pressure on data requirements and a mutual affine convolution to reduce model parameters. Specifically, we only use a pair of high-resolution and low-resolution images and a high-resolution image at any time. A spatial degradation consistency is constructed to adaptively determine the ratio of two layers of the super-resolution STF model. The quantitative and qualitative experimental results on public spatiotemporal fusion datasets demonstrate our superiority over the state-of-the-art methods. © 2022 IEEE.","Convolution; Deep learning; Image fusion; Optical resolving power; Remote sensing; Fusion model; High resolution remote sensing; High-resolution images; Low resolution images; Mutual affine convolution; Remote sensing images; Remote sensing satellites; Spatio-temporal fusions; Superresolution; Two-layer; Generative adversarial networks","Generative Adversarial Networks(GAN); Mutual Affine Convolution; Spatiotemporal Fusion","Conference paper","Final","","Scopus","2-s2.0-85140364937"
"Dutta S.; Banerjee A.","Dutta, Sayantan (57216762703); Banerjee, Ayan (57191896840)","57216762703; 57191896840","Optimal Image Fusion Algorithm using Modified Whale Optimization Algorithm Amalgamed with Local Search and BAT Algorithm","2020","Proceedings of the 4th International Conference on Computing Methodologies and Communication, ICCMC 2020","","","9076434","709","715","6","10.1109/ICCMC48092.2020.ICCMC-000132","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084675513&doi=10.1109%2fICCMC48092.2020.ICCMC-000132&partnerID=40&md5=55808c5cf413bb40cd7c18629ad1726d","Image fusion has an extensive application in the area of medical and satellite image analysis. Having such large applicability, the uses of image fusion is restricted because of the lack of precise algorithm and dedicated hardware. Researchers have tried to use the metaheuristic algorithm in the image processing field. The WOA (whale optimization algorithm) is one of the most popular metaheuristic algorithms used in recent days, but any such straight forward metaheuristic algorithm has some drawbacks. To overcome this drawback, a MWOA (modified WOA) has been proposed in this paper. This modified WOA is incorporated with LSA and BA algorithm. LSA makes this WOA more accurate, and BA makes this system faster. The problem of premature convergence and trapping of local minima is also shorted by using this MWOA. This Modified WOA have greater accuracy for identifying the object which has been compared with other heuristic and metaheuristic algorithm. The optimization algorithm is tasted by using MATLAB R2018b. The proposed design is synthesized using Xilinx Vivado 18.2 synthesis tool and simulated using ModelSim. The outcomes of the synthesis report and simulation of the circuit outshine other metaheuristic optimization approach. This MWOA is performed by using our own designed algorithm. © 2020 IEEE.","Local search (optimization); MATLAB; Medical imaging; Bat algorithms; Dedicated hardware; Meta heuristic algorithm; Meta-heuristic optimizations; Optimization algorithms; Pre-mature convergences; Satellite image analysis; Synthesis reports; Image fusion","BA; camera and sound probe; heuristic optimization; LSS; metaheuristic optimization; Modified WOA; prey; WOA","Conference paper","Final","","Scopus","2-s2.0-85084675513"
"Apostolopoulos D.N.; Nikolakopoulos K.G.","Apostolopoulos, Dionysios N. (57216331020); Nikolakopoulos, Konstantinos G. (6602629539)","57216331020; 6602629539","SPOT vs Landsat satellite images for the evolution of the north Peloponnese coastline, Greece","2022","Regional Studies in Marine Science","56","","102691","","","","10.1016/j.rsma.2022.102691","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140614190&doi=10.1016%2fj.rsma.2022.102691&partnerID=40&md5=5c7a341f73f05ee55602fee3bf141624","The littoral zone of Achaia prefecture, located in northwestern Peloponnese of Greece, is an area which has experienced significant modification the last two decades. It is a linear and sandy coast with limited curves and infrastructures, suitable for the comparison of the shoreline derived from SPOT and Landsat satellite images. Nowadays, the application of the remote sensing has overshadowed the traditional methods of shoreline mapping, such as ground survey along with transects and airborne stereophotogrammetry, as low-cost repeatable observations can be made, providing reliable results. The normalized difference water index (NDWI), which is computed from multispectral satellite data, have been successfully applied to shoreline discrimination. Consequently, the current manuscript applies to the specific index on Landsat and SPOT data for the 1987–2008 period in order to detect the shoreline position. Moreover, shorelines were generated from the Landsat and SPOT satellite images of medium spatial resolution, 30 m and 20 m respectively, for the years of 1987, 1996, and 2008, and their accuracy was compared to respective data derived from air photos with high spatial resolution (0.50 m to 1 m). The analysis revealed that the Landsat TM 5 data provide more accurate vectorized shorelines than the SPOT 1 to 4 series with 20 m spatial resolution via the NDWI. Both are not suitable for high-scale​ accurate diachronic shoreline monitoring, even if image fusion techniques were used, as they emerged bad overlapping ratio following significant distortions on the two axes in relation to the respective high-resolution reference data. Moreover, they provided quite different results regarding the shoreline evolution in relation to the respective high-resolution data. © 2022 Elsevier B.V.","","GIS; Remote sensing; Satellite; Shoreline; Statistics","Article","Final","","Scopus","2-s2.0-85140614190"
"Oliveira D.; Martins L.; Mora A.; Damásio C.; Caetano M.; Fonseca J.; Ribeiro R.A.","Oliveira, Diogo (57200895435); Martins, Leonardo (56964737200); Mora, André (15728256600); Damásio, Carlos (6603410864); Caetano, Mário (35567666900); Fonseca, José (34769664200); Ribeiro, Rita A. (56527722100)","57200895435; 56964737200; 15728256600; 6603410864; 35567666900; 34769664200; 56527722100","Data fusion approach for eucalyptus trees identification","2021","International Journal of Remote Sensing","42","11","","4087","4109","22","10.1080/01431161.2021.1883198","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102178265&doi=10.1080%2f01431161.2021.1883198&partnerID=40&md5=ba6938e2516cfd8fa7b30546138f46f2","Remote sensing is based on the extraction of data, acquired by satellites or aircrafts, through multispectral images, that allow their remote analysis and classification. Analysing those images with data fusion techniques is a promising approach for identification and classification of forest types. Fusion techniques can aggregate various sources of heterogeneous information to generate value-added maps, facilitating forest-type classification. This work applies a data fusion algorithm, denoted FIF (Fuzzy Information Fusion), which combines computational intelligence techniques with multicriteria concepts and techniques, to automatically distinguish Eucalyptus trees from satellite images. The algorithm customization was performed with a Portuguese area planted with Eucalyptus. After customizing and validating the approach with several representative scenarios to assess its suitability for automatic classification of Eucalyptus, we tested on a large tile obtaining a sensitivity of 69.61%, with a specificity of 99.43%, and an overall accuracy of 98.19%. This work demonstrates the potential of our approach to automatically classify specific forest types from satellite images, since this is a novel approach dedicated to the identification of eucalyptus trees. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","Portugal; Eucalyptus; Satellites; Forestry; Image analysis; Image fusion; Intelligent computing; Remote sensing; Satellites; Automatic classification; Computational intelligence techniques; Data fusion algorithm; Data fusion technique; Fuzzy information fusion; Heterogeneous information; Multispectral images; Overall accuracies; algorithm; evergreen forest; evergreen tree; image classification; multispectral image; remote sensing; satellite data; Classification (of information)","","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85102178265"
"Gialampoukidis I.; Andreadis S.; Vrochidis S.; Kompatsiaris I.","Gialampoukidis, Ilias (55863740200); Andreadis, Stelios (57188709545); Vrochidis, Stefanos (23052810300); Kompatsiaris, Ioannis (7004756014)","55863740200; 57188709545; 23052810300; 7004756014","MULTIMODAL DATA FUSION OF SOCIAL MEDIA AND SATELLITE IMAGES FOR EMERGENCY RESPONSE AND DECISION-MAKING","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","228","231","3","10.1109/IGARSS47720.2021.9554176","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129806526&doi=10.1109%2fIGARSS47720.2021.9554176&partnerID=40&md5=57025baa1c92103de1efc48fc8b74480","Artificial Intelligence (AI) is already part of our lives and is extensively entering the space sector to offer value-added Earth Observation (EO) products and services. The Copernicus programme provides data on a free, full and open basis, while the recently launched Data and Information Access Service (DIAS) providers index, store and exchange tremendous amounts of data and cloud infrastructure computational resources. Copernicus data and other georeferenced data sources are often highly heterogeneous, distributed and semantically fragmented. One example is the massively generated social media data from citizen observations, including visual, textual and spatiotemporal information. Social media information offers reliable, timely and very prescriptive information about a crisis event. In this work we present the multimodal fusion aspects for combining satellite images and social media for emergency response, such as flood monitoring and extreme weather conditions in polar regions. © 2021 IEEE","Deep learning; Earth (planet); Emergency services; Image fusion; Social networking (online); Decisions makings; Deep learning; Earth observation products; Emergency response; Media images; Multimodal data fusion; Product and services; Satellite images; Social media; Space sectors; Decision making","Decision-making; Deep Learning; Emergency response; Multimodal data fusion; Social Media","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85129806526"
"Rai A.K.; Mandal N.; Singh A.; Singh K.K.","Rai, Amit Kumar (57204950845); Mandal, Nirupama (26436005000); Singh, Akansha (54899131000); Singh, Krishna Kant (55265360800)","57204950845; 26436005000; 54899131000; 55265360800","Landsat 8 OLI Satellite Image Classification using Convolutional Neural Network","2020","Procedia Computer Science","167","","","987","993","6","10.1016/j.procs.2020.03.398","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084412485&doi=10.1016%2fj.procs.2020.03.398&partnerID=40&md5=421ec1450fcfbc742645d3f5790bf208","An automated method for classification of multispectral satellite images using image fusion is presented in this paper. Principal Component Analysis(PCA),and convolutional neural network (CNN).This proposed method first take multispectral satellite image and apply Brovey transform method for fusion of three RGB bands with panchromatic band shaving spatial resolution of 30m and 15m respectively. Then Principal Component Analysis is applied on fused images for reducing dimension. After that Convolutional Neural Network has been applied for classification purpose. Classification outcomes of the proposed method are matched with FCM, GIFP-FCM,and FKLICM. © 2020 The Authors. Published by Elsevier B.V.","Convolution; Image analysis; Image classification; Image fusion; Principal component analysis; Satellites; Automated methods; Brovey transforms; Fused images; Multispectral satellite image; Panchromatic bands; RGB bands; Satellite image classification; Spatial resolution; Convolutional neural networks","Brovey Transform; CNN; PCA","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85084412485"
"Yilmaz V.","Yilmaz, Volkan (57004516700)","57004516700","A comprehensive investigation of image fusion methods for spatial enhancement of hyperspectral images","2022","International Journal of Remote Sensing","43","11","","4151","4186","35","10.1080/01431161.2022.2109223","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136524797&doi=10.1080%2f01431161.2022.2109223&partnerID=40&md5=e404254c5bc27a8bb027e0e7b3cc1c60","The coarse spatial resolutions of hyperspectral (HS) satellite images limit their use in many applications. The spatial structure quality of HS images can be improved by fusing them either with higher-resolution panchromatic (PAN) images, or with higher-resolution multispectral (MS) images. Fusion of HS images can be done with fusion methods that are designed to fuse MS and PAN images, and the fusion methods developed for the fusion of HS and MS images. A wide variety of HS-MS and MS-PAN image fusion techniques can be used for the fusion of HS images, which leads the users to a hesitation as to which method(s) should be used for optimal fusion performance. Hence, the current study aimed to qualitatively and quantitatively assess the HS image fusion performances of a total of 15 MS-PAN image fusion methods and 17 state-of-the-art HS-MS image fusion techniques within four experiments, with the hope to give some clues on the performances of the fusion techniques used. Experiments showed that the HS-MS fusion methods exhibited much better HS image fusion performance, compared to the MS-PAN fusion methods used. It was also concluded that the coupled nonnegative matrix factorization (CNMF), convolutional neural network (CNN) denoiser-based method (CNN-D), HS super-resolution (HySure) and fast fusion based on Sylvester equation with naive Gaussian prior (FUSE-G) techniques provided the most robust fusion results. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Hyperspectral imaging; Image fusion; Matrix algebra; Matrix factorization; Neural networks; Remote sensing; Spectroscopy; Fusion methods; Fusion performance; High resolution; HyperSpectral; Hyperspectral image fusions; Image fusion methods; Image fusion techniques; Multi-spectral; Multispectral images; Remote-sensing; image analysis; image classification; image resolution; remote sensing; spatiotemporal analysis; spectral analysis; Image enhancement","hyperspectral imaging; image enhancement; Image fusion; remote sensing","Article","Final","","Scopus","2-s2.0-85136524797"
"Li Y.; Li J.; Plaza A.","Li, Yunfei (57218424664); Li, Jun (24481713500); Plaza, Antonio (7006613644)","57218424664; 24481713500; 7006613644","A Noise Proof Strategy for Spatio-Temporal Fusion of Remote Sensing Imagery","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","895","898","3","10.1109/IGARSS46834.2022.9884821","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141897960&doi=10.1109%2fIGARSS46834.2022.9884821&partnerID=40&md5=d1139ac9cfb27595e282547475c85b77","Spatio-temporal fusion is a feasible way to generating the synthetic remote sensing data with high spatial resolution and high temporal resolution simultaneously by blending the fine and coarse resolution satellite images. To date, dozens of spatio-temporal fusion approaches have been developed. A basic rule of these approaches is the bands of coarse and fine images must be corresponding, which means the quality of fused images depends on that of both fine and coarse images. In the literature, the MODIS images are the most wildly used coarse images in spatio-temporal fusion. However, the MODIS images may suffer from serious stripe noises in the short-wave infrared-1 and short-wave infrared-2 bands, which will lead to undesired results of spatio-temporal fusion. To address this problem, we develop a noise proof strategy in this paper, which takes advantage of the spectral correlation of base fine image to remove the stripe noises of the base MODIS image, then the spatial correlation of base MODIS image is exploited to restore the MODIS image of the predicted time. Finally, the reconstructed MODIS images are fused with the base fine image to predict the missing fine images. The strategy is tested via real Landsat and MODIS images, and the experimental result demonstrates it is not only effective in removing the stripe noises of MDOIS short-wave infrared-1 and short-wave infrared-2 bands, but also able to improve the fusion accuracy. © 2022 IEEE.","Image enhancement; Image fusion; Image reconstruction; Infrared radiation; Radiometers; Remote sensing; Fine images; High spatial resolution; MODIS; Noise proof; Proof strategy; Remote sensing data; Remote sensing imagery; Short wave infrared; Spatio-temporal fusions; Stripe noise; Landsat","MODIS; noise proof; Spatio-temporal fusion","Conference paper","Final","","Scopus","2-s2.0-85141897960"
"Richa; Kaur K.; singh P.","Richa (57488362500); Kaur, Karamjit (57192780781); singh, Priti (57188967313)","57488362500; 57192780781; 57188967313","An Effective Algorithm of Remote Sensing Image Fusion Based on Discrete Wavelet Transform","2022","Lecture Notes in Networks and Systems","339","","","313","330","17","10.1007/978-981-16-7018-3_24","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126372341&doi=10.1007%2f978-981-16-7018-3_24&partnerID=40&md5=3cc59fd8f8c5443dbfcf2696d145eefa","Image fusion is a combination of two different images into one image. Image integration has a huge application field, from medical to satellite imaging, as this approach plays an important role. There are various methods available for image merging, and in particular, there are two categories in which image merging is subdivided, modified, and integrated with the domain. A newly created image compilation would be more accurate and informed than the original image. This paper introduces a single image integration process called DWT discrete wavelet transform (DWT). We will be comparing various combinations such as MIN MIN and MAX MIN. The final picture is compared by multiple criteria, and the best approach is inferred in this article. Panchromatic satellite images are the data used for this paper. For these pictures, this algorithm needs to be used, as satellite pictures demand high spectral and spatial modification. Techniques to share photographs are included in this situation. The merged image would have both local and optical characteristics in a single image through image fusion. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","","Discrete; DWT; FIR; Fusion; Hilbert; MAX; MIN; Spatial; Spectral; Wavelet","Conference paper","Final","","Scopus","2-s2.0-85126372341"
"Cao B.; Fang Y.; Gao L.; Hu H.; Jiang Z.; Sun B.; Lou L.","Cao, Bincai (55886626700); Fang, Yong (57190179174); Gao, Li (57200600241); Hu, Haiyan (55740750000); Jiang, Zhengzhi (36543796700); Sun, Bijiao (57189267149); Lou, Lele (57221463615)","55886626700; 57190179174; 57200600241; 55740750000; 36543796700; 57189267149; 57221463615","An active-passive fusion strategy and accuracy evaluation for shallow water bathymetry based on ICESat-2 ATLAS laser point cloud and satellite remote sensing imagery","2021","International Journal of Remote Sensing","42","8","","2783","2806","23","10.1080/01431161.2020.1862441","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099254370&doi=10.1080%2f01431161.2020.1862441&partnerID=40&md5=7ec64ea9beb3cabe4900631eb85996bc","The Advanced Topographic Laser Altimeter System (ATLAS) on ICESat-2 (Ice, Cloud, and Land Elevation Satellite-2) uses a 532 nm band photon-counting LiDAR (Light Detection and Ranging), which has certain penetrability to water bodies, and the measured data show that the bathymetric ability reaches nearly one Secchi depth. ATLAS has a limited number of beams and a fixed ground track, and only collects section elevation along the track direction. The fusion of active laser point cloud and passive optical remote sensing satellite image can fill the gap of shallow water depth data in a large range. This paper takes ATLAS as the research object, with the aim of exploring the effective algorithm flow of spaceborne active laser and passive optical fusion processing, and systematically evaluating the bathymetric accuracy of the fusion algorithm. An adaptive Gauss filtering technology based on the density of point cloud was firstly improved to achieve accurate denoising under the condition of uneven surface/underwater density. Subsequently, the depth of underwater points was calculated automatically through steps of water surface modelling, refraction correction, etc. Finally, the control points and check points were randomly extracted to solve the parameters of multispectral inversion model and verify the internal accuracy of the model. In this paper, the accuracy of ATLAS bathymetry was verified by Airborne LiDAR Bathymetry (ALB) data in Oahu Island, Hawaii, and the results indicate that the vertical root mean square error (RMSE) ranges from 0.56 m to 1.11 m. In Yongle islands and Qilianyu area of the South China Sea, WorldView-2 (WV2) 4 bands multispectral images and ATLAS data were used to carry out the active-passive fusion bathymetry, and the ALB and sonar data were used to evaluate the accuracy. Experimental results show that the internal compliance accuracy of the fusion model is better than 1.25 m (RMSE), and the real bathymetry accuracy is better than 1.42 m (RMSE). The above results reveal the great potential of active-passive fusion bathymetry based on ICESat-2 and other high-resolution remote sensing satellites, which can provide strong technical support for filling the blank of shallow water depth information. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","Satellites; Aneroid altimeters; Bathymetry; Communication satellites; Image fusion; Landforms; Mean square error; Optical radar; Radio altimeters; Satellite imagery; Surface waters; Underwater acoustics; High resolution remote sensing; Land elevation satellites; LIDAR (light detection and ranging); Optical remote sensing; Root mean square errors; Satellite remote sensing; Shallow water bathymetry; Water surface modelling; accuracy assessment; bathymetry; data set; image analysis; lidar; remote sensing; satellite imagery; shallow water; Remote sensing","accuracy evaluation; active-passive fusion; ICESat-2,ATLAS; photon-counting LiDAR; shallow bathymetry","Article","Final","","Scopus","2-s2.0-85099254370"
"Liu G.; Wang Y.; Guo L.; Ma C.","Liu, Guo (57216282623); Wang, Yizhe (57216283988); Guo, Li (57209791997); Ma, Cuifeng (57216279355)","57216282623; 57216283988; 57209791997; 57216279355","Research on fusion of GF-6 imagery and quality evaluation","2020","E3S Web of Conferences","165","","03016","","","","10.1051/e3sconf/202016503016","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085252376&doi=10.1051%2fe3sconf%2f202016503016&partnerID=40&md5=e16a9af5de7daf1934a3d674e8f58ebc","Gaofen-6 (GF-6) has the advantages of wide coverage, multiple resolutions, and multiple bands. Image fusion method is the key process in high resolution remote sensing application. Beijing Daxing International Airport was selected as the experiment area and four image fusion methods of HPF, NND, Gram-Schmidt and Pansharp were employed to process panchromatic and multispectral imaging. The results demonstrated that Pansharp was the best algorithm for image information and spectral fidelity of GF-6, taking into account the preservation of color effects of images and enhancement of spatial details, which can meet most fusion needs. HPF's color retention is not as good as Pansharp algorithm. The contrast of the NND algorithm result is relatively high, which may cause the local image to be too bright and the texture to be lost. The GS algorithm has lower information entropy and average gradient. Compared with the other three algorithms, it has a worse effect on spatial details and texture expression. This conclusion can provide key reference for scientific research and engineering application using GF-6 satellite image. © The Authors, published by EDP Sciences, 2020.","Image enhancement; Remote sensing; Textures; Engineering applications; High resolution remote sensing; Image fusion methods; Information entropy; International airport; Multiple resolutions; Multispectral imaging; Scientific researches; Image fusion","","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85085252376"
"Huertas K.A.; Medina J.","Huertas, Karen Andrea (57219657324); Medina, Javier (57197825929)","57219657324; 57197825929","Generation of the thematic map for the identification of areas of historical and scenic interest in the tourist and cultural district of Cartagena de Indias-Colombia through the fusion of satellite images using the two-dimensional discrete wavelet (DWT) transform; [Generación del mapa temático para la identificación de zonas de interés histórico y paisajístico en el distrito turístico y cultural de Cartagena de Indias-Colombia mediante la fusión de imágenes satelitales usando la transformada wavelet discreta bidimensional (DWT)]","2020","RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao","2020","E36","","203","216","13","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094579994&partnerID=40&md5=0cad8dc695063c185237199b6c04ec87","Cartagena de Indias is considered the tourist capital of Colombia, declared a World Heritage Site in 1984 by UNESCO. In addition, it is one of the five walled metropolises with the most scenic beauty in the world according to the BBC in London. The tourist population attracted concurrently has resorted to the use of thematic cartography extracted from high-resolution satellite images. Thanks to the technological advance in digital image processing, the use of fusion techniques has been incorporated with the aim of injecting greater spatial detail into less detailed images. This article presents the image fusion technique by implementing algorithms based on the Discrete Wavelet Transform (DWT) to identify areas of interest that are in the tourist and cultural district of Cartagena de Indias, a port city on the coast of the Caribbean and tourist, cultural and historical epicenter of Colombia. © 2020, Associacao Iberica de Sistemas e Tecnologias de Informacao. All rights reserved.","","Cartagena; Coiflet 2; Fusion of satellite images; Wavelet transform; À trous","Article","Final","","Scopus","2-s2.0-85094579994"
"Guo Y.; Fu Y.H.; Chen S.; Robin Bryant C.; Li X.; Senthilnath J.; Sun H.; Wang S.; Wu Z.; de Beurs K.","Guo, Yahui (57206187965); Fu, Yongshuo H. (36918071700); Chen, Shouzhi (57218847836); Robin Bryant, Christopher (7103310182); Li, Xinxi (57217592279); Senthilnath, J. (35183910200); Sun, Hongyong (13005632300); Wang, Shuxin (57218763437); Wu, Zhaofei (57218761357); de Beurs, Kirsten (6506889738)","57206187965; 36918071700; 57218847836; 7103310182; 57217592279; 35183910200; 13005632300; 57218763437; 57218761357; 6506889738","Integrating spectral and textural information for identifying the tasseling date of summer maize using UAV based RGB images","2021","International Journal of Applied Earth Observation and Geoinformation","102","","102435","","","","10.1016/j.jag.2021.102435","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115158940&doi=10.1016%2fj.jag.2021.102435&partnerID=40&md5=50007cfe9f2c357a690aff0025d5c59c","The extraction of phenological events in forest and agriculture commonly relies on Vegetation Indices (VI) composed by visible and near infrared bands from satellite images. However, the textural information playing an important role in image fusion, image classification and change detection is commonly ignored. In this study, high-throughput images collected from an Unmanned Aerial Vehicle (UAV) platform during the growth stages of summer maize were used to identify the Tasseling Date (TD) based on both spectral and textural information. The spectral and textural information were extracted using various VI and the Gray Level Co-occurrence Matrix (GLCM), respectively. The results showed that the Normalized Green Blue Difference Index (NGBDI), and the Green Blue Difference Index (GBDI) of VI and the Contrast Information (Contrast) of GLCM performed better than other variables. A new index was generated by integrating spectral and textural information using the Improved Adaptive Feature Weighting Method (IAFWM), and then the TDs were identified for each plot. The Root Mean Square Error (RMSE) of new index was 5.77 days and it was the lowest among all variables. The potential ability of more advanced machine learning and deep learning in integrating the spectral and textural information should be investigated. © 2021 The Authors","image classification; machine learning; maize; phenology; spectral analysis; unmanned vehicle; vegetation index","Phenology extraction; Spectral information; Textural information; UAV","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85115158940"
"Hoque M.R.U.; Wu J.; Kwan C.; Koperski K.; Li J.","Hoque, Md Reshad Ul (57215344852); Wu, Jian (57193141747); Kwan, Chiman (7201421216); Koperski, Krzysztof (6603540174); Li, Jiang (56226550100)","57215344852; 57193141747; 7201421216; 6603540174; 56226550100","ArithFusion: An Arithmetic Deep Model for Temporal Remote Sensing Image Fusion","2022","Remote Sensing","14","23","6160","","","","10.3390/rs14236160","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143761796&doi=10.3390%2frs14236160&partnerID=40&md5=6d162c4fc285294f57b7c7e89e83f5f4","Different satellite images may consist of variable numbers of channels which have different resolutions, and each satellite has a unique revisit period. For example, the Landsat-8 satellite images have 30 m resolution in their multispectral channels, the Sentinel-2 satellite images have 10 m resolution in the pan-sharp channel, and the National Agriculture Imagery Program (NAIP) aerial images have 1 m resolution. In this study, we propose a simple yet effective arithmetic deep model for multimodal temporal remote sensing image fusion. The proposed model takes both low- and high-resolution remote sensing images at (Formula presented.) together with low-resolution images at a future time (Formula presented.) from the same location as inputs and fuses them to generate high-resolution images for the same location at (Formula presented.). We propose an arithmetic operation applied to the low-resolution images at the two time points in feature space to take care of temporal changes. We evaluated the proposed model on three modality pairs for multimodal temporal image fusion, including downsampled WorldView-2/original WorldView-2, Landsat-8/Sentinel-2, and Sentinel-2/NAIP. Experimental results show that our model outperforms traditional algorithms and recent deep learning-based models by large margins in most scenarios, achieving sharp fused images while appropriately addressing temporal changes. © 2022 by the authors.","Antennas; Deep learning; Generative adversarial networks; Image fusion; Satellite imagery; Space optics; Deep learning; Generative adversarial network; HRNet; LANDSAT; Neural-networks; Remote sensing images; Remote-sensing; Satellite images; Superresolution; U-net; Remote sensing","deep learning; generative adversarial network (GAN); HRNet; image fusion; neural networks; remote sensing; super-resolution; U-Net","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85143761796"
"Kurban T.","Kurban, Tuba (35077012700)","35077012700","Region based multi-spectral fusion method for remote sensing images using differential search algorithm and IHS transform","2022","Expert Systems with Applications","189","","116135","","","","10.1016/j.eswa.2021.116135","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118488013&doi=10.1016%2fj.eswa.2021.116135&partnerID=40&md5=738ee2f83c6ca2d76e09ea0816628338","Remote sensing applications such as clustering, classification, feature extraction, measurement and change detection need fused high-resolution images that contain complementary information coming from multi-spectral bands. To transfer as much information as possible from source images to the fused image, image fusion can be considered as an optimization problem. In this paper, a new, two-stage, multi-spectral, region based, optimal fusion method is proposed. Panchromatic and infrared bands of Landsat 8 satellite images are fused with K-medoids segmentation and Differential Search Algorithm (DSA). The fused image is combined with the red, green, and blue (RGB) bands of the same area with intensity-hue-saturation (IHS) transform. Experiments carried out on test images indicate that developed method performed better than most of the state-of-the-art fusion techniques in terms of both visual and numerical evaluations. © 2021 Elsevier Ltd","Classification (of information); Clustering algorithms; Feature extraction; Image fusion; Image segmentation; Learning algorithms; Numerical methods; Spectroscopy; Differential search algorithm; Fused images; Fusion methods; Intensity-hue-saturation transforms; Multi-spectral; Multispectral imaging; Optimisations; Region-based; Remote-sensing; Search Algorithms; Remote sensing","Differential search algorithm; Image fusion; Multi-spectral imaging; Optimization; Remote sensing","Article","Final","","Scopus","2-s2.0-85118488013"
"Hashim F.; Dibs H.; Jaber H.S.","Hashim, Fatima (57226717655); Dibs, Hayder (56568428200); Jaber, Hussein Sabah (57188830123)","57226717655; 56568428200; 57188830123","Adopting Gram-Schmidt and Brovey Methods for Estimating Land Use and Land Cover Using Remote Sensing and Satellite Images","2022","Nature Environment and Pollution Technology","21","2","","867","881","14","10.46488/NEPT.2022.v21i02.050","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133339358&doi=10.46488%2fNEPT.2022.v21i02.050&partnerID=40&md5=649510614b3c97fb230d140bc0df38ca","The production of Land Use and Land Cover thematic maps using remote sensing data is one of the things that must be dealt with carefully to obtain accurate results, data is obtained from sensors of different characteristics. It is not possible to obtain high spatial and spectral accuracy in one image, so we used a fusion image (multispectral image with a low spatial resolution with a panchromatic image with high spatial resolution), which achieved high efficiency in improving the methods of producing Land Use and Land Cover maps. In this study, we used Landsat-8 multispectral and panchromatic images. The study aims to investigate the effectiveness of panchromatic images in improving the methods of producing Land Use and Land Cover maps for the city of Karbala, Iraq. The Support Vector Machine was used to classify the fusion images using the Brovey method and Gram-Schmidt sharpening algorithms. The appropriate methodology for producing Land Use and Land Cover maps was suggested by comparing classifying results and the classification accuracy was evaluated through the confusion matrix. Where the results showed that the method of classifying the fused image by Gram-Schmidt and classified by Support Vector Machine is the best way to produce Land use and Land cover maps for the study area and achieved the highest results for overall accuracy and kappa coefficient of 97.81% and 0.95, respectively. © 2022 Technoscience Publications. All rights reserved.","Iraq; Karbala; accuracy assessment; algorithm; image classification; land cover; land use change; Landsat; methodology; numerical method; panchromatic image; remote sensing; satellite imagery; spatial resolution; support vector machine","Brovey method; Gram-Schmidt method; Image fusion; Support vector machine","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85133339358"
"Manocha A.; Afaq Y.; Bhatia M.","Manocha, Ankush (57207915903); Afaq, Yasir (57223431081); Bhatia, Munish (57190168274)","57207915903; 57223431081; 57190168274","Mapping of water bodies from sentinel-2 images using deep learning-based feature fusion approach","2022","Neural Computing and Applications","","","","","","","10.1007/s00521-022-08177-2","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144654184&doi=10.1007%2fs00521-022-08177-2&partnerID=40&md5=fba5c2933b716bc884b9629df6848604","As water is considered one of the essential assets of nature, the recognition of the availability of water at a specific location can help government bodies to take necessary action toward water conservation. Monitoring water from satellite images is considered one of the most difficult areas of pattern recognition. In this manner, a novel multi-level feature fusion approach is proposed to predict the pattern of water concerning a specific location to analyze the scale and availability. The proposed framework can access the spatial features from sentinel-2 images by utilizing the concept of structural learning. For evaluating the prediction performance, the calculated outcomes are compared with the traditional and modern pattern recognition approaches. It has been observed that the proposed approach is more robust in terms of pattern analysis as compared to the state-of-the-art approaches. Moreover, the performance of the proposed approach is evaluated on different training and testing ratios such as 70:30, 75:25, and 80:20. In this manner, the calculated outcomes define the pattern recognition efficiency of the proposed approach over the state-of-the-art approaches by achieving 94.51% of accuracy. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Deep learning; Image fusion; Water conservation; Water resources; Deep learning; Features fusions; Multi-level feature fusion approach; Multilevels; Pattern analysis; Sentinel-2 image; Specific location; State-of-the-art approach; Waterbodies; Waters resources; Pattern recognition","Deep learning; Multi-level feature fusion approach (MFFA); Pattern analysis; Sentinel-2 images; Water resource","Article","Article in press","","Scopus","2-s2.0-85144654184"
"Sun W.; Zhou R.; Nie C.; Wang L.; Sun J.","Sun, Wei (57317673600); Zhou, Rong (57220825435); Nie, Congchong (57210218918); Wang, Liuan (56104494100); Sun, Jun (57603813100)","57317673600; 57220825435; 57210218918; 56104494100; 57603813100","Farmland segmentation from remote sensing images using deep learning methods","2020","Proceedings of SPIE - The International Society for Optical Engineering","11528","","1152809","","","","10.1117/12.2573244","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094592950&doi=10.1117%2f12.2573244&partnerID=40&md5=00307662f72cd326286d4e44be373eea","Farmland segmentation is crucial and getting increasingly important role in the field of agricultural insurance and digital agriculture. To accurately achieve insured crop area and disaster loss assessment, precision smallholders' farmland segmentation and mapping are necessary. Deep learning technology has demonstrated its strength and has out-performed state-of-the-art alternatives in many fields. In this study, we aim to explore the effectiveness of five classic deep semantic segmentation models on the smallholder-wise farmland segmentation from remote sensing images. Five FCN-based segmentation models were selected including U-Net, PSPNet, DeepLabV3+, DANet, and CCNet, which were originally proposed for natural or medical image segmentation. The study area locates in Jiaxiang County in the north China. We used GF-1 at 2m spatial resolution with 4-band multispectral images (red, green, blue, and near-infrared) acquired based on image fusion. Comparative experiment results showed that DeepLabv3+ achieved the best mIoU of 89.82%. PSPNet, DANet, CCNet and U-Net obtained lower but similar mIoU with: 89.63%, 89.66%, 89.59%, and 89.15%. The OA metric of the all the five models were above 94.8%. The results indicate that the FCN-based deep semantic segmentation networks are effective for larger-scale smallholder-wise farmland segmentation with high spatial resolution multispectral satellite images.  © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Agricultural robots; Ecosystems; Farms; Hydrology; Image fusion; Image resolution; Image segmentation; Infrared devices; Learning systems; Medical imaging; Remote sensing; Semantics; Comparative experiments; Digital agriculture; High spatial resolution; Learning technology; Multispectral images; Multispectral satellite image; Remote sensing images; Semantic segmentation; Deep learning","Agriculture insurance; Deep semantic segmentation; Farmland segmentation; Remote sensing; Satellite imagery","Conference paper","Final","","Scopus","2-s2.0-85094592950"
"Karnjana J.; Keerativittayanun S.; Sangrit K.; Dillon P.; Tanatipuknon A.; Aimmanee P.; Murata K.T.","Karnjana, Jessada (57190762441); Keerativittayanun, Suthum (35304784000); Sangrit, Kittikom (57208549908); Dillon, Pitisit (57204500802); Tanatipuknon, Asadang (57204501752); Aimmanee, Pakinee (25654530400); Murata, Ken T. (41861922300)","57190762441; 35304784000; 57208549908; 57204500802; 57204501752; 25654530400; 41861922300","Real-Time Monitoring System Based on Wireless Sensor Networks and Remote Sensing Techniques for Landslide-Prone Areas in the Northern Region of Thailand","2022","Springer Tracts in Civil Engineering","","","","169","180","11","10.1007/978-981-16-5312-4_12","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119688019&doi=10.1007%2f978-981-16-5312-4_12&partnerID=40&md5=076afd0f635063bc6aa73cbbb0a4ec04","Many areas in the northern region of Thailand are mountainous and subject to landslides. A landslide causes local damage to a particular area; in addition, it induces nearby prone areas trans-regionally. Therefore, monitoring landslide-prone areas can help in risk assesment and management to efficiently handle a situation. This paper reports collaborative research activities and results of projects endorsed by ASEAN COSTI and e-Asia JRP. It aims to investigate potential landslides’ environmental parameters and conditions using real-time monitoring based on wireless sensors networks (WSN) and remote sensing techniques. The WSN, equipped with a camera, is designed based on low-power technologies (i.e., ZigBee and LoRa), and the performance is evaluated and compared in terms of communication packet losses. Also, remote sensing techniques are used to detect changes in satellite imagery and 3D point clouds. For example, k-means clustering and structural patch decomposition are applied to generate a binary map that locates change between two satellite images of different times. A deep-learning approach based on CNN is used to identify locations of landslides. The density-based spatial clustering and a clutter-removal method are used to detect rockfall events from two 3D point clouds. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","","change detection; image fusion; landslide detection; rockfall detection; WSN-based landslide monitoring system","Book chapter","Final","","Scopus","2-s2.0-85119688019"
"Cheng L.; Zang H.; Wei Z.; Sun G.","Cheng, Lilin (57203687765); Zang, Haixiang (56870889000); Wei, Zhinong (7402258961); Sun, Guoqiang (9236400000)","57203687765; 56870889000; 7402258961; 9236400000","Ultra-short-term Forecasting of Regional Photovoltaic Power Generation Considering Multispectral Satellite Remote Sensing Data; [考虑多光谱卫星遥感的区域级超短期光伏功率预测]","2022","Zhongguo Dianji Gongcheng Xuebao/Proceedings of the Chinese Society of Electrical Engineering","42","20","","7451","7464","13","10.13334/j.0258-8013.pcsee.212843","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140906484&doi=10.13334%2fj.0258-8013.pcsee.212843&partnerID=40&md5=708bec3282980892cfcc7896fe06b274","It is vital to achieve carbon emission peak and carbon neutrality in China by building new power systems with high renewable energy penetration. Photovoltaic (PV) power will occupy a high proportion due to its broadly distributed nature. Because of the PV randomness, highly integrated renewable energy power grids will require strong abilities of area coordination and interaction, depending on accurate regional predictions. Compared to single forecast, regional forecast should track cloud motion within large areas and study weather variations among PV power sites. It should also avoid repeated modeling for each power plant. Thus, the ultra-short-term forecast method for regional up-scaling PV power was proposed based on satellite remote sensing data. It contains multispectral image fusion, image prediction and two-level generative PV forecasting. The method can take full merits of multispectral satellite images, and can reduce the impacts on PV power predictions caused by image forecast errors. Based on open cases from European weather satellite and Belgium provincial PV regions, it can be proved that the method increases the accuracy under horizons of 1.5 hours and above, meeting requirements of real-time dispatch between regional power grids. ©2022 Chin.Soc.for Elec.Eng.","Carbon; Electric power transmission networks; Remote sensing; Satellites; Solar power generation; Weather forecasting; Generative model; Image fusion and prediction; Photovoltaic power; Photovoltaics; Power forecasting; Regional solar photovoltaic; Satellite remote sensing; Satellite remote sensing data; Solar photovoltaics; Ultra-short-term photovoltaic power forecasting; Image fusion","generative model; image fusion and prediction; regional solar photovoltaic (PV); satellite remote sensing; ultra-short-term PV power forecasting","Article","Final","","Scopus","2-s2.0-85140906484"
"Chen G.; Jiao P.; Hu Q.; Xiao L.; Ye Z.","Chen, Guanyu (57791777300); Jiao, Peng (57791443900); Hu, Qing (57158171000); Xiao, Linjie (57792440900); Ye, Zijian (57790451600)","57791777300; 57791443900; 57158171000; 57792440900; 57790451600","SwinSTFM: Remote Sensing Spatiotemporal Fusion Using Swin Transformer","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5410618","","","","10.1109/TGRS.2022.3182809","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133763923&doi=10.1109%2fTGRS.2022.3182809&partnerID=40&md5=aa79c25302845ef9524b5deb94583832","Remote sensing images with high temporal and spatial resolutions have broad market demands and various application scenarios. This article aims to generate high-quality remote sensing image time series for feature mining of the growth quality of traditional Chinese medicine. Spatiotemporal fusion is a flexible method that combines two types of satellite images with high temporal resolution or high spatial resolution to generate high-quality remote sensing images. In recent years, many spatiotemporal fusion algorithms have been proposed, and deep learning-based methods show extraordinary talents in this field. However, the current deep learning-based methods have three problems: 1) most algorithms do not support models with large-scale learnable parameters; 2) the model structure based on convolutional neural networks will bring the noise to the image fusion process; and 3) current deep learning-based methods ignore some excellent modules in traditional spatiotemporal fusion algorithms. For the above problems and challenges, this article creatively proposes a new algorithm based on the Swin transformer and the linear spectral mixing theory. The algorithm makes full use of the advantages of the Swin transformer in feature extraction and integrates the unmixing theories into the model based on the self-attention mechanism, which greatly improves the quality of generated images. In the experimental part, the proposed algorithm achieves state-of-the-art results on three well-known public datasets and has been proven effective and reasonable in ablation studies. © 1980-2012 IEEE.","Deep learning; Image enhancement; Learning algorithms; Medicine; Neural networks; Remote sensing; Deep learning; High quality; High spatial resolution; High temporal resolution; Learning-based methods; Remote sensing images; Remote-sensing; Spatio-temporal fusions; Swin transformer; Unmixing; algorithm; remote sensing; Image fusion","Deep learning; remote sensing; spatiotemporal fusion; Swin transformer; unmixing","Article","Final","","Scopus","2-s2.0-85133763923"
"Asokan A.; Anitha J.","Asokan, Anju (57190950323); Anitha, J. (57204786853)","57190950323; 57204786853","Artificial Bee Colony-Optimized Contrast Enhancement for Satellite Image Fusion","2020","Remote Sensing and Digital Image Processing","24","","","83","105","22","10.1007/978-3-030-24178-0_5","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075497641&doi=10.1007%2f978-3-030-24178-0_5&partnerID=40&md5=8527b213e5d249bac035e85a5f944052","Image fusion combines two or more images to a single image to extract all the necessary information from the source images. It minimizes the redundant information present in the source images. Fused images find wide applications in medical imaging, computer vision, remote sensing, change detection, and military applications. The success of the fusion technique is limited by the noise present in the source images. In order to overcome this limitations, an artificial bee colony (ABC)-optimized contrast enhancement for satellite image fusion is proposed to fuse two multitemporal satellite images. The ABC-optimized source images are given as input to the fusion stage. A hybrid contrast enhancement technique combining the histogram equalization and gamma correction techniques is used for the contrast enhancement of the source images. The contrast-enhanced images are fused using Discrete Wavelet Transform (DWT), Principle Component Analysis (PCA), and Intensity, Hue, Saturation Transform (IHS) individually. The proposed work further compares these conventional fusion techniques by computing performance measures for image fusion such as Mean Square Error (MSE), Peak Signal-to-Noise Ratio (PSNR), entropy, Structural Similarity Index (SSIM), and Feature Similarity Index (FSIM). The experimental results show that the IHS-based image fusion technique outperforms the PCA- and DWT-based fusion techniques. Also, this method is computationally effective and simple in its implementation. © 2020, Springer Nature Switzerland AG.","","Gamma correction; Histogram equalization; IHS; Image fusion; Multitemporal; PCA; Remote sensing","Book chapter","Final","","Scopus","2-s2.0-85075497641"
"Vaithiyanathan D.; Sudalaimuthu K.","Vaithiyanathan, Dhayalan (57932535400); Sudalaimuthu, Karuppasamy (57209618364)","57932535400; 57209618364","Area-to-point regression Kriging approach fusion of Landsat 8 OLI and Sentinel 2 data for assessment of soil macronutrients at Anaimalai, Coimbatore","2022","Environmental Monitoring and Assessment","194","12","916","","","","10.1007/s10661-022-10571-1","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140080862&doi=10.1007%2fs10661-022-10571-1&partnerID=40&md5=fb5b98e7c54dff6d7a037615679e0034","Spectral indices-based soil prediction models derived from multispectral datasets are too intricate in terms of accuracy as well as resolution. Complications arise while incorporating multispectral datasets for regional-scale spatial assessment of soil macronutrients. Sporadically satellite image fusion techniques have been used for soil nutrient interpolation to circumvent the complications. The fusion of multispectral bands encompasses precise soil information that cannot be observed as accurate with single satellite dataset. In this study, fusion of near infrared regions of Landsat 8 Operational Land Imager and Sentinel 2 has been observed for its contribution on soil macronutrient assessments. Area-to-point regression Kriging (ATPRK) approach is followed in fusing the two satellite imagery and in situ soil spectral have used for the validation of the resultant. Comparative statistical analysis on Landsat 8 OLI band 5 (wavelength: 845–885 nm), Sentine-2 band 8,8A (wavelength: 785–900 nm) datasets and fused satellite bands provides R2 values of 0.8209, 0.8436, and 0.8763 respectively. Regression models y = (0.25006 ± 0.00754) + (0.0000313)x, y = (0.25252 ± 0.0062) + (0.0000810)x, and y = (0.23715 ± 0.0062) + (0.0001210)x for nitrogen, phosphorus, and potassium respectively aids for soil macronutrient interpolation and assessments. Computations reveals the ranges of nitrogen, phosphorus and potassium that floats from 48 to 295 kg/ha, 5.0 to 37 kg/ha, and 32 to 455 kg/ha in the study area. Fusion of satellite imagery by ATPRK approaches in soil macronutrient study at regional scale brings the novelty of the study. © 2022, The Author(s), under exclusive licence to Springer Nature Switzerland AG.","Environmental Monitoring; Nitrogen; Nutrients; Phosphorus; Potassium; Soil; Spatial Analysis; Anaimalai Hills; India; Tamil Nadu; Western Ghats; Image fusion; Infrared devices; Interpolation; Nitrogen; Phosphorus; Potassium; Regression analysis; Soils; nitrogen; phosphorus; potassium; phosphorus; Kriging approach; LANDSAT; Landsat 8 OLI; Multi-spectral; Multispectral datasets; Regression-kriging; Satellite image fusion; Satellite images; Sentine-2; Soil macronutrient study; data set; kriging; Landsat; Sentinel; spatiotemporal analysis; spectral analysis; agriculture; area to point regression Kriging approach; Article; controlled study; electric conductivity; image processing; India; mathematical model; satellite imagery; soil acidity; soil analysis; soil chemistry; soil moisture; environmental monitoring; procedures; soil; spatial analysis; Landsat","Landsat 8 OLI; Multispectral; Satellite image fusion; Sentine-2; Soil macronutrient study","Article","Final","","Scopus","2-s2.0-85140080862"
"Günen M.A.","Günen, Mehmet Akif (57190371587)","57190371587","Weighted differential evolution algorithm based pansharpening","2021","International Journal of Remote Sensing","42","22","","8468","8491","23","10.1080/01431161.2021.1976874","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117145380&doi=10.1080%2f01431161.2021.1976874&partnerID=40&md5=15d9ded9769a2c12d946e13e0d550127","Imaging Satellites acquire multispectral images, MIs, in low resolution, LR, and panchromatic images, PANs, in high resolution, HR, due to some advantages provided in satellite design. The pansharpening, PS, is a super resolution image synthesis method that is used to generate the pansharpened image, PI, by fusion of PAN and MI. The use of PS process is unavoidable in applications such as efficient use of communication-bandwidth of imaging satellites and fusion of images derived from various image sensors. The PS process is a multi-step process consisting of various complex image processing stages, such as registration, resampling, synthesis, and fusion. The Weighted Differential Evolution Algorithm-based PS method, WDEPS, has been proposed in this paper. The WDEPS uses WDE to synthesize the intensity image, which is the blended-image of MI -bands. WDE has been used to compute the relevant image-blending weights, efficiently. In the experiments, several satellite images (QuickBird-2, Ikonos-2, and GeoEye-1) with different spatial resolutions were used. The WDEPS’s experimental results have been compared with 17 well-known PS methods by using 9 full-reference and 3 blind image quality assessment metrics. The experimental results exposed that WDEPS generates high-quality PIs than traditional PS methods used in the experimental aspect of qualitative and quantitative assessment. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","Satellites; Evolutionary algorithms; Image processing; Optimization; Satellite communication systems; Satellites; Differential evolution algorithms; High resolution; Images synthesis; Imaging satellites; Lower resolution; Multispectral images; Pan-sharpening; Resolution images; Satellites design; Superresolution; algorithm; GeoEye; IKONOS; image resolution; multispectral image; panchromatic image; QuickBird; satellite imagery; Image fusion","","Article","Final","","Scopus","2-s2.0-85117145380"
"Vibhute A.D.; Kale K.V.; Gaikwad S.V.; Dhumal R.K.; Nagne A.D.; Varpe A.B.; Nalawade D.B.; Mehrotra S.C.","Vibhute, Amol D. (55811504600); Kale, Karbhari V. (6701566257); Gaikwad, Sandeep V. (57189381643); Dhumal, Rajesh K. (56448892100); Nagne, Ajay D. (56449298200); Varpe, Amarsinh B. (56392893900); Nalawade, Dhananjay B. (57200073514); Mehrotra, Suresh C. (7102264286)","55811504600; 6701566257; 57189381643; 56448892100; 56449298200; 56392893900; 57200073514; 7102264286","Classification of complex environments using pixel level fusion of satellite data","2020","Multimedia Tools and Applications","79","47-48","","34737","34769","32","10.1007/s11042-020-08978-4","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085306289&doi=10.1007%2fs11042-020-08978-4&partnerID=40&md5=abeb1812cd18f8fe91c4b00511d13900","The present study reports classification and analysis of composite land features using fusion images obtained by fusing two original hyperspectral and multispectral datasets. The high spatial-spectral resolution, multi-instrument and multi-period satellite images were used for fusion. Three pixel level fusion based techniques, Color Normalized Spectral Sharpening (CNSS), Principal Component Spectral Sharpening Transform (PCSST) and Gram-Schmidt Transform (GST), were implemented on the datasets. Performance evaluations of three fusion algorithms were done using classification results. The Support Vector Machine (SVM) and Gaussian Maximum Likelihood Classification (MLC) were used for classification using five types of images, viz. hyperspectral, multispectral and three fused images. Number of classes considered was eight. Sufficient number of ground field data for each class has also been acquired which was needed for supervise based classification. The accuracy was improved from 74.44 to 97.65% when the fused images were considered with SVM classifier. Similarly, the results were improved from 69.25 to 94.61% with original and fused data using MLC classifier. The fusion image technique was found to be superior to the single original image and the SVM is better than the MLC method. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Image enhancement; Image fusion; Maximum likelihood; Pixels; Support vector machines; Classification results; Complex environments; Gaussian maximum likelihood; Gram-Schmidt transform; Multispectral datasets; Pixel level fusion; Principal Components; Spectral sharpening; Classification (of information)","Color normalized spectral sharpening (CNSS); Dimensionality reduction; Maximum likelihood classifier; Minimum noise fraction; Pixel level fusion; Supervised classification","Article","Final","","Scopus","2-s2.0-85085306289"
"Mallick J.; Talukdar S.; Shahfahad; Pal S.; Rahman A.","Mallick, Javed (35269521700); Talukdar, Swapan (57194545588); Shahfahad (57214364016); Pal, Swades (55469273900); Rahman, Atiqur (7402940471)","35269521700; 57194545588; 57214364016; 55469273900; 7402940471","A novel classifier for improving wetland mapping by integrating image fusion techniques and ensemble machine learning classifiers","2021","Ecological Informatics","65","","101426","","","","10.1016/j.ecoinf.2021.101426","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115295519&doi=10.1016%2fj.ecoinf.2021.101426&partnerID=40&md5=4a8a39eeec4e6f80a7dfdfa51cedfa0c","Among all the natural features, wetlands are the most difficult to map and monitor because of their complicated morphology, i.e., their diverse shapes and sizes, ranging from open waterlogged regions with sparse vegetation to thickly wooded areas with a distant distribution pattern. Wetland mapping has been performed with optical remote sensing data for a long time; but the accuracy varies with time and space owing to the complexity of wetland systems. Therefore, the objective of this work is to examine the efficacy of a novel and unique approach to automated complex wetland mapping in Bangladesh's Sunamganj District, using combined image fusion with machine learning techniques. The image fusion technique was used to fuse the multispectral bands (MS) of Landsat 8 OLI (bands 5, 4, 3) with the panchromatic band of Landsat 8, (band 8). The quality of the fused images was determined by calculating the correlation between the spectral values of the original multispectral and fused images, as well as through edge detection techniques. In addition to this, four advanced machine learning classifiers, i.e. random forest (RF), support vector machine (SVM), k-nearest neighbor (KNN), and decision tree (DT), were used to classify the complex wetland image. Furthermore, a hybrid classifier was created by applying an artificial neural network (ANN) to previously identified models and spectral bands of satellite images. To validate the identified wetland maps, the Kappa coefficient and root mean square error (RMSE) have been used. The result shows that in wetland mapping, the Brovey image fusion approach surpassed the Gram-Schmidt image fusion technique. In addition, the accuracy of all four machine learning classifiers was higher on the fused images than on the MS image. The proposed fused ANN-based hybrid model outperformed all fused and MS classification models in terms of accuracy (kappa: 89.4% and RMSE: 0.13). According to the findings of this study, image-fusion based machine learning classifiers could be used for wetland mapping in other regions of the world, as well as for mapping river dynamics, forest cover, urban growth, and croplands. © 2021","Bangladesh; Sunamganj; Sylhet; Varanidae; agricultural land; artificial neural network; Landsat; machine learning; mapping method; remote sensing; support vector machine; wet season; wetland","Artificial neural network; Edge detection; Image fusion; Machine learning algorithms; Wetland mapping","Article","Final","","Scopus","2-s2.0-85115295519"
"","","","Proceedings - 2022 2nd International Conference of Smart Systems and Emerging Technologies, SMARTTECH 2022","2022","Proceedings - 2022 2nd International Conference of Smart Systems and Emerging Technologies, SMARTTECH 2022","","","","","","266","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136819767&partnerID=40&md5=b07183c37c5892022b8f104ed57c2d2c","The proceedings contain 43 papers. The topics discussed include: automated grading of diabetic macular edema using color retinal photographs; medical image fusion based on hybrid intelligence and local energy in the nonsubsampled shearlet domain; diagnosis of COVID-19 through transfer learning techniques on CT scans: a comparison of deep learning models; ensemble-based effective diagnosis of thyroid disorder with various feature selection techniques; assessment of students performance and e-learning experience using online social networks; managing temporal uncertainty - a short review; towards a spatio-temporal query language for the interrogation of graph-based satellite image time series models; are formal methods applicable to machine learning and artificial intelligence?; fabric weave pattern recognition and classification by machine learning; a comprehensive assistive solution for visually impaired persons; and hiding privacy data in visual surveillance video based on wavelet and flexible function.","","","Conference review","Final","","Scopus","2-s2.0-85136819767"
"Asefpour Vakilian A.; Saradjian M.R.","Asefpour Vakilian, Afshin (57324349100); Saradjian, Mohammad Reza (8397399100)","57324349100; 8397399100","An object-based sparse representation model for spatiotemporal image fusion","2022","Scientific Reports","12","1","5021","","","","10.1038/s41598-022-08728-6","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126868532&doi=10.1038%2fs41598-022-08728-6&partnerID=40&md5=6efe597a4c13568435e152565b83297d","Many algorithms have been proposed for spatiotemporal image fusion on simulated data, yet only a few deal with spectral changes in real satellite images. An innovative spatiotemporal sparse representation (STSR) image fusion approach is introduced in this study to generate global dense high spatial and temporal resolution images from real satellite images. It aimed to minimize the data gap, especially when fine spatial resolution images are unavailable for a specific period. The proposed approach uses a set of real coarse- and fine-spatial resolution satellite images acquired simultaneously and another coarse image acquired at a different time to predict the corresponding unknown fine image. During the fusion process, pixels located between object classes with different spectral responses are more vulnerable to spectral distortion. Therefore, firstly, a rule-based fuzzy classification algorithm is used in STSR to classify input data and extract accurate edge candidates. Then, an object-based estimation of physical constraints and brightness shift between input data is utilized to construct the proposed sparse representation (SR) model that can deal with real input satellite images. Initial rules to adjust spatial covariance and equalize spectral response of object classes between input images are introduced as prior information to the model, followed by an optimization step to improve the STSR approach. The proposed method is applied to real fine Sentinel-2 and coarse Landsat-8 satellite data. The results showed that introducing objects in the fusion process improved spatial detail, especially over the edge candidates, and eliminated spectral distortion by preserving the spectral continuity of extracted objects. Experiments revealed the promising performance of the proposed object-based STSR image fusion approach based on its quantitative results, where it preserved almost 96.9% and 93.8% of the spectral detail over the smooth and urban areas, respectively. © 2022, The Author(s).","Algorithms; algorithm","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85126868532"
"Sarmadian A.; Moghimi A.; Amani M.; Mahdavi S.","Sarmadian, Amin (57222432800); Moghimi, Armin (57194760236); Amani, Meisam (56684747900); Mahdavi, Sahel (57190089926)","57222432800; 57194760236; 56684747900; 57190089926","Optimizing the Snake Model Using Honey-Bee Mating Algorithm for Road Extraction from Very High-Resolution Satellite Images","2022","2022 10th International Conference on Agro-Geoinformatics, Agro-Geoinformatics 2022","","","","","","","10.1109/Agro-Geoinformatics55649.2022.9859090","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137890738&doi=10.1109%2fAgro-Geoinformatics55649.2022.9859090&partnerID=40&md5=51d0b0709a1b22373d9d8f8253fbd3f5","Many geospatial applications rely on the extraction of spatial features, including road networks, from very high-resolution (VHR) satellite images. Researchers have developed many algorithms to achieve this goal, the majority of which are based on image fusion, fuzzy logic, and active contour models. The snake model is among the most widely used methods for road extraction by active contours. In most studies, an initial curve close to available roads is manually defined or based on prior knowledge. These methods also require manual adjustment of the snake model parameters, which is time-consuming. In order to address these limitations, this study proposes an algorithm for extracting roads from VHR satellite images in a semi-urban area that optimizes snake models by Honey-Bee Mating Optimization (HBMO). Based on a support vector machine and some image processing analysis, the presented method can extract an accurate initial curve, as well. According to the results of the experiments, the proposed approach not only eliminates the shortcomings of the snake model but also increases the accuracy of road extraction by 10% in all three study areas compared to the traditional snake method.  © 2022 IEEE.","Edge detection; Extraction; Feature extraction; Food products; Fuzzy logic; Image fusion; Image segmentation; Roads and streets; Support vector machines; Honey bee; Honey bees mating optimizations; Honey-bee mating optimization algorithm; Initial curve; Matings; Optimization algorithms; Remote-sensing; Road extraction; Snake model; Very high resolution satellite images; Remote sensing","Edge Detection; HBMO Algorithm; Remote Sensing; Road Extraction; Snake Model","Conference paper","Final","","Scopus","2-s2.0-85137890738"
"Huang L.; Hu Z.; Luo X.; Zhang Q.; Wang J.; Wu G.","Huang, Leping (57221165982); Hu, Zhongwen (55630272400); Luo, Xin (56316646000); Zhang, Qian (57831105800); Wang, Jingzhe (57191893435); Wu, Guofeng (7404975854)","57221165982; 55630272400; 56316646000; 57831105800; 57191893435; 7404975854","Stepwise Fusion of Hyperspectral, Multispectral and Panchromatic Images with Spectral Grouping Strategy: A Comparative Study Using GF5 and GF1 Images","2022","Remote Sensing","14","4","1021","","","","10.3390/rs14041021","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125007934&doi=10.3390%2frs14041021&partnerID=40&md5=4e032efd13930c5a3478adb8de46673d","Since hyperspectral satellite images (HSIs) usually hold low spatial resolution, improving the spatial resolution of hyperspectral imaging (HSI) is an effective solution to explore its potential for remote sensing applications, such as land cover mapping over urban and coastal areas. The fusion of HSIs with high spatial resolution multispectral images (MSIs) and panchromatic (PAN) images could be a solution. To address the challenging work of fusing HSIs, MSIs and PAN images, a novel easy-to-implement stepwise fusion approach was proposed in this study. The fusion of HSIs and MSIs was decomposed into a set of simple image fusion tasks through spectral grouping strategy. HSI, MSI and PAN images were fused step by step using existing image fusion algorithms. According to different fusion order, two strategies ((HSI+MSI)+PAN and HSI+(MSI+PAN)) were proposed. Using simulated and real Gaofen-5 (GF-5) HSI, MSI and PAN images from the Gaofen-1 (GF-1) PMS sensor as experi-mental data, we compared the proposed stepwise fusion strategies with the traditional fusion strategy (HSI+PAN), and compared the performances of six fusion algorithms under three fusion strategies. We comprehensively evaluated the fused results through three aspects: spectral fidelity, spatial fidelity and computation efficiency evaluation. The results showed that (1) the spectral fidelity of the fused images obtained by stepwise fusion strategies was better than that of the traditional strategy; (2) the proposed stepwise strategies performed better or comparable spatial fidelity than traditional strategy; (3) the stepwise strategy did not significantly increase the time complexity compared to the traditional strategy; and (4) we also provide suggestions for selecting image fusion algorithms using the proposed strategy. The study provided us with a reference for the selection of fusion strategies and algorithms in different application scenarios, and also provided an easy-to-implement solution and useful refer-ences for fusing HSI, MSI and PAN images. © 2022 by the authors. Li-censee MDPI, Basel, Switzerland.","Hyperspectral imaging; Image enhancement; Image fusion; Image resolution; Remote sensing; Fusion strategies; Gaofen-1; Gaofen-5; Hyperspectral image; Hyperspectral satellite; Multispectral image; Multispectral images; Panchromatic  image; Spectral grouping; Stepwise image fusion; Spectroscopy","Gaofen-1 (GF-1); Gaofen-5 (GF-5); Hyperspectral image (HSI); Multispectral image (MSI); Panchromatic (PAN) image; Spectral grouping; Stepwise image fusion","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85125007934"
"Verma A.; Kumar A.; Lal K.","Verma, Abhinav (57210809234); Kumar, Amit (9244865300); Lal, Kanhaiya (57541263500)","57210809234; 9244865300; 57541263500","Kharif crop characterization using combination of SAR and MSI Optical Sentinel Satellite datasets","2019","Journal of Earth System Science","128","8","230","","","","10.1007/s12040-019-1260-0","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071442100&doi=10.1007%2fs12040-019-1260-0&partnerID=40&md5=f195206b8978afa6c2d81f31fd0c7f1c","In the present study, the differences in the kharif crop reflectance at varied wavelength regions and temporal SAR backscatter (at VV and VH polarizations) during different crop stages were analyzed to classify crop types in parts of Ranchi district, East India using random forest classifier. The spectral signature of crops was generated during various growth stages using temporal Sentinel-2 MSI (optical) satellite images. The temporal backscatter profile that depends on the geometric and di-electric properties of crops were studied using Sentinel-1 SAR data. The spectral profile exhibited distinctive reflectance at the NIR (0.842 µm) and SWIR (1.610 µm) wavelength regions for paddy (Oryza sativa; ~0.25 at NIR, ~0.27 at SWIR), maize (Zea mays; ~0.24 at NIR, ~0.29 at SWIR) and finger millet (Eleusine coracana, ~0.26 NIR, ~0.31 at SWIR) during pre-sowing season (mid-June). Similar variations in crop’s reflectance at their different growth stages (vegetative to harvesting) were observed at various wavelength ranges. Further, the variations in the backscatter coefficient of different crops were observed at various growth stages depending upon the differences in sowing–harvesting periods, field conditions, geometry, and water presence in the crop field, etc. The Sentinel-1 SAR based study indicated difference in the backscatter of crops (i.e., ~−18.5 dB (VH) and ~−10 dB (VV) for paddy, ~−14 dB (VH) and ~−7.5 dB (VV) for maize, ~−14.5 dB and ~−8 dB (VV) for finger millet) during late-July (transplantation for paddy; early vegetative for maize and finger millet). These variations in the reflectance and backscatter values during various stages were used to deduce the best combination of the optical and SAR layers in order to classify each crop precisely. The GLCM texture analysis was performed on SAR for better classification of crop fields with higher accuracies. The SAR-MSI based kharif crop assessment (2017) indicated that the total cropped area under paddy, maize and finger millet was 24,544.55, 1468.28 and 632.48 ha, respectively. The result was validated with ground observations, which indicated an overall accuracy of 83.87% and kappa coefficient of 0.78. The high temporal, spatial spectral agility of Sentinel satellite are highly suitable for kharif crop monitoring. The study signifies the role of combined SAR–MSI technology for accurate mapping and monitoring of kharif crops. © 2019, Indian Academy of Sciences.","India; Jharkhand; Ranchi; Eleusine coracana; Oryza sativa; Zea mays; crop; data set; image classification; machine learning; monitoring; satellite data; Sentinel; synthetic aperture radar","Crop monitoring; crop spectral profile; random forest classification; SAR texture; SAR–MSI image fusion","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85071442100"
"Xu S.; Ehlers M.","Xu, S. (57190172711); Ehlers, M. (7102012167)","57190172711; 7102012167","CRITICAL REFLECTION ON QUANTITATIVE ASSESSMENT OF IMAGE FUSION QUALITY","2022","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","43","B3-2022","","551","557","6","10.5194/isprs-archives-XLIII-B3-2022-551-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131950554&doi=10.5194%2fisprs-archives-XLIII-B3-2022-551-2022&partnerID=40&md5=a94acd8d4afbbb7020077906a60c61fd","Image fusion technique has been extended its development from multi-sensor fusion, multi-model fusion to multi-focus fusion. More and more advanced techniques such as deep learning have been integrated into the development of image fusion algorithms. However, as an important aspect, fusion quality assessment has been received less attention. This paper intends to reflect on the commonly used indices for quantitative assessment and investigate how they can represent the fusion quality regarding spectral preservation and spatial improvement. We found that image dissimilarities are unavoidable due to the spectral coverage of different image sensors. Image fusion should integrate these dissimilarities when they are representing spatial improvement. Such integration will naturally change the pixel values. However, as the quality indices for the assessment of spectral preservation are measuring image dissimilarities, the integration of spatial information will lead to a low fusion quality assessment. For the evaluation of spatial improvement, the quality indices only work if the spatial details have been lost; however, in the case of spatial details gain, these indices do not reflect them as spatial improvements. Moreover, this paper raises attention to image processing procedures involved in image fusion, including image geo-registration, image clipping and image resampling, which will change image statistics and thereby influence the quality assessment when statistical indices are used.  © Authors 2022","Deep learning; Image enhancement; Image quality; Remote sensing; Critical reflections; Fusion quality; Image fusion techniques; Multi-model fusion; Multi-sensor fusion; Quality assessment; Quality indices; Quantitative assessments; Remote-sensing; Satellite images; Image fusion","Fusion quality; Image fusion; Quantitative assessment; Remote sensing; Satellite image","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85131950554"
"Januar T.W.; Lin T.-H.; Huang C.-Y.; Chang K.-E.","Januar, Tri Wandi (57215417950); Lin, Tang-Huang (7404861364); Huang, Chih-Yuan (50261888100); Chang, Kuo-En (56237209700)","57215417950; 7404861364; 50261888100; 56237209700","Modifying an image fusion approach for high spatiotemporal LST retrieval in surface dryness and evapotranspiration estimations","2020","Remote Sensing","12","3","498","","","","10.3390/rs12030498","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080962555&doi=10.3390%2frs12030498&partnerID=40&md5=6d0b4a8c9445fb024e2c5c6cade09cef","Thermal infrared (TIR) satellite images are generally employed to retrieve land surface temperature (LST) data in remote sensing. LST data have been widely used in evapotranspiration (ET) estimation based on satellite observations over broad regions, as well as the surface dryness associated with vegetation index. Landsat-8 Operational Land Imager (OLI) and Thermal Infrared Sensor (TIRS) can provide LST data with a 30-m spatial resolution. However, rapid changes in environmental factors, such as temperature, humidity, wind speed, and soil moisture, will affect the dynamics of ET. Therefore, ET estimation needs a high temporal resolution as well as a high spatial resolution for daily, diurnal, or even hourly analysis. A challenge with satellite observations is that higher-spatial-resolution sensors have a lower temporal resolution, and vice versa. Previous studies solved this limitation by developing a spatial and temporal adaptive reflectance fusion model (STARFM) for visible images. In this study, with the primary mechanism (thermal emission) of TIRS, surface emissivity is used in the proposed spatial and temporal adaptive emissivity fusion model (STAEFM) as a modification of the original STARFM for fusing TIR images instead of reflectance. For high a temporal resolution, the advanced Himawari imager (AHI) onboard the Himawari-8 satellite is explored. Thus, Landsat-like TIR images with a 10-minute temporal resolution can be synthesized by fusing TIR images of Himawari-8 AHI and Landsat-8 TIRS. The performance of the STAEFM to retrieve LST was compared with the STARFM and enhanced STARFM (ESTARFM) based on the similarity to the observed Landsat image and differences with air temperature. The peak signal-to-noise ratio (PSNR) value of the STAEFM image is more than 42 dB, while the values for STARFM and ESTARFM images are around 31 and 38 dB, respectively. The differences of LST and air temperature data collected from five meteorological stations are 1.53 °C to 4.93 °C, which are smaller compared with STARFM's and ESATRFM's. The examination of the case study showed reasonable results of hourly LST, dryness index, and ET retrieval, indicating significant potential for the proposed STAEFM to provide very-high-spatiotemporal-resolution (30 m every 10 min) TIR images for surface dryness and ET monitoring. © 2020 by the authors.","Atmospheric temperature; Electromagnetic wave emission; Evapotranspiration; Image fusion; Image resolution; Infrared detectors; Infrared radiation; Land surface temperature; Reflection; Remote sensing; Satellites; Signal to noise ratio; Soil moisture; Wind; High spatiotemporal retrieval; High temporal resolution; LANDSAT; Operational land imager; Peak signal to noise ratio; Spatio-temporal resolution; Thermal emissions; Thermal infrared sensors; Image enhancement","High spatiotemporal retrieval; Landsat-8 OLI and Himawari-8 AHI; LST; Surface dryness and evapotranspiration; Thermal emission; TIR image fusion","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85080962555"
"Metrikaityte G.; Visockiene J.S.; Papsys K.","Metrikaityte, Guste (57798962200); Visockiene, Jurate Suziedelyte (56548798600); Papsys, Kestutis (55383221400)","57798962200; 56548798600; 55383221400","Digital Mapping of Land Cover Changes Using the Fusion of SAR and MSI Satellite Data","2022","Land","11","7","1023","","","","10.3390/land11071023","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134038608&doi=10.3390%2fland11071023&partnerID=40&md5=325ae20ec3924f318c441f6d108ef2f8","The aim of this article is to choose the most appropriate method for identifying and managing land cover changes over time. These processes intensify due to human activities such as agriculture, urbanisation and deforestation. The study is based in the remote sensing field. The authors used four different methods of satellite image segmentation with different data: Synthetic Aperture Radar (SAR) Sentinel-1 data, Multispectral Imagery (MSI) Sentinel-2 images and a fusion of these data. The images were preprocessed under segmentation by special algorithms and the European Space Agency Sentinel Application Platform (ESA SNAP) toolbox. The analysis was performed in the western part of Lithuania, which is characterised by diverse land use. The techniques applied during the study were: the coherence of two SAR images; the method when SAR and MSI images are segmented separately and the results of segmentation are fused; the method when SAR and MSI data are fused before land cover segmentation; and an upgraded method of SAR and MSI data fusion by adding additional formulas and index images. The 2018 and 2019 results obtained for SAR image segmentation differ from the MSI segmentation results. Urban areas are poorly identified because of the similarity of spectre signatures, where urban areas overlap with classes such as nonvegetation and/or sandy territories. Therefore, it is necessary to include the field surveys in the calculations in order to improve the reliability and accuracy of the results. The authors are of the opinion that the calculation of the additional indexes may help to enhance the visibility of vegetation and urban area classes. These indexes, calculated based on two or more different bands of multispectral images, would help to improve the accuracy of the segmentation results. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","","coherence; image fusion; land cover changes; LULC; MSI RGB; SAR; segmentation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85134038608"
"Jeong D.; Kim Y.","Jeong, Doyoung (57215428848); Kim, Yongil (7410213546)","57215428848; 7410213546","Deep learning based pansharpening using a Laplacian pyramid","2020","40th Asian Conference on Remote Sensing, ACRS 2019: Progress of Remote Sensing Technology for Smart Future","","","","","","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105832389&partnerID=40&md5=6bb018f898eea63ca6c84334ac04517e","Pansharpening is an image fusion technique aimed at acquiring high-resolution multispectral images by fusing a multispectral (MS) image and high-resolution panchromatic (PAN) images. Various types of pansharpening algorithm have been developed for the last decades, and in recent years, with remarkable growth in the field of deep learning, deep learning based methods have been presented. Because the scale of MS and PAN is different, MS needs to be interpolated with the scale of PAN as inputs for most pansharpening networks. The interpolated MS has the same information as the original MS, but has a limitation in that the computation cost and the inherent error in the satellite image can be overestimated during the deep learning process. We propose a learning based approach to synthesize high-resolution MS based on convolutional neural networks. The proposed network consists of extracting and synthesizing high spatial frequency features through a separate network, rather than interpolated MS and PAN in an integrated network. The proposed method showed good performance in preserving the spatial characteristics but limited in preserving the spectral characteristics. © 2020 40th Asian Conference on Remote Sensing, ACRS 2019: ""Progress of Remote Sensing Technology for Smart Future"". All rights reserved.","Convolutional neural networks; Image fusion; Learning systems; Remote sensing; High spatial frequency; Image fusion techniques; Learning-based approach; Pan-sharpening; Panchromatic (Pan) image; Spatial characteristics; Spectral characteristics; Very high spatial resolutions; Deep learning","Deep learning; Pansharpening; Remote sensing; Very high spatial resolution imagery","Conference paper","Final","","Scopus","2-s2.0-85105832389"
"Medina J.; Carrillo I.; Upegui E.","Medina, Javier (57197825929); Carrillo, Iván (57201589455); Upegui, Erika (36459015100)","57197825929; 57201589455; 36459015100","Implementation and assessment of the wavelet 2d À trous transform: Using intensity, luminance and value in matlab for fusion of satellite images; [Implementación y evaluación de la transformada wavelet 2d à trous: Usando intensidad, luminancia y value en matlab para fusión de imágenes satelitales]","2021","RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao","2021","E41","","396","409","13","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105461101&partnerID=40&md5=893775e450aa9bf7e4ba1470708e6e58","This article develops mathematically the IHS, HSL, and HSV color models, to which the undecided Wavelet 2D Transform (Trous Algorithm) is applied using Matlab in order to establish the best color model for image fusion purposes. This implementation is performed for fusing of satellite images with a proposed five-step methodology. An Ikonos image (Panchromatic-PAN and multispectral-MULTI) of a sector of the city of Bogota (Colombia) is used to generate three fused images, specifically: MULTIINT, MULTILUM and MULTIVAL. In order to determine the efficiency of the Wavelet Transform, the fused images were evaluated in both spatial and spectral quality across four indexes, namely correlation index, ERGAS, RASE and Q index. The best evaluation results were obtained by the MULTIVAL image that used the Value component of the HSV color model achieved spectral correlations greater than 0.94, a Q index value of 0.94 and the best values of ERGAS and RASE spectral. MULTVA L image preserves spectral richness by improving its spatial quality. © 2021, Associacao Iberica de Sistemas e Tecnologias de Informacao. All rights reserved.","","Fusion; HIS; HSL; HSV; Intensity, Luminance; Satellite-Image; Value; Àtrous","Article","Final","","Scopus","2-s2.0-85105461101"
"Shi W.; Guo D.; Zhang H.","Shi, Wenzhong (57221530932); Guo, Dizhou (57218161768); Zhang, Hua (36995174200)","57221530932; 57218161768; 36995174200","A reliable and adaptive spatiotemporal data fusion method for blending multi-spatiotemporal-resolution satellite images","2022","Remote Sensing of Environment","268","","112770","","","","10.1016/j.rse.2021.112770","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118487066&doi=10.1016%2fj.rse.2021.112770&partnerID=40&md5=85c983a96689f97ee6bb5eee3480ffa4","Spatiotemporal image fusion is a potential way to resolve the constraint between the spatial and temporal resolutions of satellite images and has been developed rapidly in recent years. However, two key challenges related to fusion accuracy remain: a) reducing the uncertainty of image fusion caused by sensor differences and b) addressing strong temporal changes. To solve the above two issues, this paper presents the newly proposed Reliable and Adaptive Spatiotemporal Data Fusion (RASDF) method. In RASDF, the effects of four kinds of sensor differences on fusion are analyzed systematically. A reliability index is therefore proposed to describe the spatial distribution of the reliability in input data for image fusion. An optimization strategy based on the spatial distribution of the reliability quantified by the index is developed to improve the robustness of the fusion. In addition, an adaptive global unmixing model and an adaptive local unmixing model are constructed and utilized collaboratively to enhance the ability to retrieve strong temporal changes. The performance and robustness of RASDF were compared with six representative fusion methods for both real and simulated datasets covering both homogeneous and heterogeneous sites. Experimental results indicated that RASDF achieves a better performance and provides a more reliable image fusion solution in terms of reducing the impact of sensor differences on image fusion and retrieving strong temporal changes. © 2021 Elsevier Inc.","Reliability; Satellites; Sensor data fusion; Spatial distribution; Data fusion methods; Local unmixing; Performance; Reliability Index; Satellite images; Spatio-temporal data; Spatio-temporal fusions; Spatio-temporal resolution; Temporal change; Unmixing; data acquisition; detection method; image resolution; satellite imagery; spatial distribution; temporal variation; Image fusion","Local unmixing; Reliability index; Satellite images; Spatiotemporal fusion; Temporal change","Article","Final","","Scopus","2-s2.0-85118487066"
"Scheffler D.; Frantz D.","Scheffler, Daniel (57188984457); Frantz, David (56428816500)","57188984457; 56428816500","Improved burn severity estimation by using Land Surface Phenology metrics and red edge information estimated from Landsat","2022","International Journal of Applied Earth Observation and Geoinformation","115","","103126","","","","10.1016/j.jag.2022.103126","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142522786&doi=10.1016%2fj.jag.2022.103126&partnerID=40&md5=adc26bbec733947f4b440aa358d3d194","Global wildfire activities are expected to increase substantially in the near future. Existing techniques for spaceborne burn severity estimation often rely on bi-temporal spectral indices, which are related to in-situ burn severity data. However, due to cloud coverage and limited revisit frequency, in combination with the date of field surveys, it is a challenge to find suitable and phenologically comparable pre- and -post-fire images. To overcome these issues and to improve the accuracy of burn severity estimations by incorporating ecologically relevant spectral information, we investigated the capability of using Land Surface Phenology (LSP) metrics and incorporating red edge spectral information. We examined the well-researched Jasper fire (September 2000, Black Hills, USA) with a dense time series of Landsat-5 and -7 data. We generated synthesized red edge spectral bands through a recently proposed spectral harmonization technique and computed several bi-temporal vegetation indices. Additionally, we derived various bi-annual LSP metrics from the same indices. We used linear regression between composite burn index (CBI) ground truth data and the various indices to measure the performance of each approach, and intercompared estimated burn severity maps. We found added value of both incorporating red edge spectral information into bi-temporal indices and into LSP metrics. Among the indices, NDVI and NDVIre1n performed best, with the latter being the overall winner. This was observed for both the bi-temporal indices and the bi-annual LSP metrics, wherein best estimation performance was found with Value of Peak of Season and Value of Green Mean metrics. Although the correlation between CBI point measurements and bi-temporal index data is similar to the LSP approach, the LSP-based burn severity maps show more robustness with regard to clouds and cloud shadows, altitude gradients and pre-processing uncertainty. The results are not only relevant for sensors with native red edge bands like Sentinel-2 but also suggest that back-casting the red edge spectral information to the Landsat archive combined with an LSP based estimation approach may improve existing burn severity maps, especially in more frequently clouded regions. © 2022","Black Hills; United States; burning; estimation method; Landsat; NDVI; phenology; regression analysis; satellite imagery; spectral analysis","Burn severity; Land Surface Phenology; Red edge; Satellite image fusion; Spectral harmonization","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85142522786"
"Li H.; Wu G.; Wang X.","Li, Hengkai (36617514300); Wu, Guanhua (57221636380); Wang, Xiuli (57203580331)","36617514300; 57221636380; 57203580331","Land Surface Temperature Downscaling Method in Ion-type Rare Earth Mining Area Oriented to Mining Disturbance; [面向开采扰动的离子型稀土矿区地表温度降尺度方法]","2021","Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University","46","1","","133","142","9","10.13203/j.whugis20190022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099650923&doi=10.13203%2fj.whugis20190022&partnerID=40&md5=cf382b153f3c966a4167ff73268523d8","The mining activities of ion-type rare earth have caused extremely ecological disturbances on the surface of the mining area and caused local ecological and environmental problems. The variation of surface thermal environment in the mining area can better reflect the ecological disturbance characteristics of the mining area, and is an important parameter to identify surface ecological disturbances. The ion-type rare earth area has the characteristics of scattered ore and small single-site area, thus obtaining the surface temperature data with strong practicability and higher spatial resolution is valuable to the monitoring of the ecological environment of the rare earth mining area.We constructed a temperature downscale model with image fusion and spectral unmixing. The Lingbei ion-type rare earth district in Dingnan County of Ganzhou City is selected as the study area. The Landsat 8 satellite image is used as main data source. Firstly, we select data of two seasons in the same year, and combine the integrated image fusion algorithm and linear spectral mixture model. The surface temperature resolution of the surface is downscaled to 15 m.Then, the land surface temperature results after downscaling are qualitatively and quantitatively analyzed and tested for accuracy.The results show that the spatial distribution of the surface temperature and the overall trend of the mining area before and after the decomposition are consistent. The surface temperature after the downscaling can reflect the surface features and spatial differences of the mining area in more details. The overall root mean square error(RMSE)of the two seasonal phases in the study area are respectively for 1.459 K and 1.196 K, the mean absolute error(MAE) are 1.128 K and 0.952 K respectively with high accuracy.Our proposed method has high applicability for improving the spatial resolution of the surface temperature of the ionic rare earth. © 2021, Editorial Board of Geomatics and Information Science of Wuhan University. All right reserved.","China; Ganzhou; Jiangxi; Atmospheric temperature; Ecology; Image fusion; Image resolution; Ions; Mean square error; Rare earths; Surface measurement; Surface properties; Ecological disturbance; Ecological environments; Environmental problems; Linear spectral mixture model; Mining disturbances; Root mean square errors; Surface temperatures; Thermal environment; algorithm; downscaling; ion; land surface; Landsat; mining; rare earth element; satellite imagery; surface temperature; Land surface temperature","Downscaling; Ion-type rare earth; Land surface temperature; Linear spectral mixture model; Mining disturbance","Article","Final","","Scopus","2-s2.0-85099650923"
"Lomelí-Huerta R.; Avila-George H.; Rivera-Caicedo J.P.; De-La-Torre M.","Lomelí-Huerta, Roberto (57678512600); Avila-George, Himer (36607394000); Rivera-Caicedo, Juan Pablo (54684821900); De-La-Torre, Miguel (22333630400)","57678512600; 36607394000; 54684821900; 22333630400","WATER POLLUTION DETECTION IN ACAPULCO COASTS USING MERGED DATA FROM THE SENTINEL-2 AND SENTINEL-3 SATELLITES","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","1518","1521","3","10.1109/IGARSS47720.2021.9553929","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129902247&doi=10.1109%2fIGARSS47720.2021.9553929&partnerID=40&md5=f0fb826b3db5da16c03577752facbfc2","Acapulco coasts are occasionally contaminated by illegal discharges originated by temporary or permanent floods that disembogue to the pacific ocean. Plumes formed by contaminated water running through the ocean can be distinguished in satellite imagery, and their reflectance is related to the polluting elements. Although some spacial agencies provide data from diverse multispectral sensors, application-specific requirements are fulfilled by merging heterogeneous imagery (differences in spatial, temporal, and spectral resolutions). This paper proposes a continuous monitoring strategy to detect pollution in water discharges by combining data from Sentinel-2 and Sentinel-3 platforms. First, the region of interest to be monitored is detected using the bands with high spatial resolution. Then, distance-based supervised machine learning is employed to detect pixel-wise pollution in water. Finally, the historic detections over time are presented to detect recurrent discharges. ©2021 IEEE","Image fusion; Image segmentation; Monitoring; Oil spills; Pollution detection; Remote sensing; Satellite imagery; Supervised learning; Contaminated water; Illegal discharges; Monitoring system; Pacific ocean; Remote-sensing; Satellite image fusion; Satellite images; Sentinel; Water pollution detections; Water running; Water pollution","contaminated water; monitoring system; remote sensing; satellite image fusion; Sentinel","Conference paper","Final","","Scopus","2-s2.0-85129902247"
"Zhao L.; Shi Y.; Liu B.; Hovis C.; Duan Y.; Shi Z.","Zhao, Licheng (57213600651); Shi, Yun (55349546900); Liu, Bin (57209810247); Hovis, Ciara (57197783515); Duan, Yulin (55349009200); Shi, Zhongchao (55349453700)","57213600651; 55349546900; 57209810247; 57197783515; 55349009200; 55349453700","Finer classification of crops by fusing UAV images and sentinel-2A data","2019","Remote Sensing","11","24","3012","","","","10.3390/rs11243012","34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077881059&doi=10.3390%2frs11243012&partnerID=40&md5=e40cf68278849f4c15d0eba94f57596c","Accurate crop distribution maps provide important information for crop censuses, yield monitoring and agricultural insurance assessments. Most existing studies apply low spatial resolution satellite images for crop distribution mapping, even in areas with a fragmented landscape. Unmanned aerial vehicle (UAV) imagery provides an alternative imagery source for crop mapping, yet its spectral resolution is usually lower than satellite images. In order to produce more accurate maps without losing any spatial heterogeneity (e.g., the physical boundary of land parcel), this study fuses Sentinel-2A and UAV images to map crop distribution at a finer spatial scale (i.e., land parcel scale) in an experimental site with various cropping patterns in Heilongjiang Province, Northeast China. Using a random forest algorithm, the original, as well as the fused images, are classified into 10 categories: rice, corn, soybean, buckwheat, other vegetations, greenhouses, bare land, water, roads and houses. In addition, we test the effect of UAV image choice by fusing Sentinel-2A with different UAV images at multiples spatial resolutions: 0.03 m, 0.10 m, 0.50 m, 1.00 m and 3.00 m. Overall, the fused images achieved higher classification accuracies, ranging between 10.58% and 16.39%, than the original images. However, the fused image based on the finest UAV image (i.e., 0.03 m) does not result in the highest accuracy. Instead, the 0.10 m spatial resolution UAV image produced the most accurate map. When the spatial resolution is less than 0.10 m, accuracy decreases gradually as spatial resolution decreases. The results of this paper not only indicate the possibility of combining satellite images and UAV images for land parcel level crop mapping for fragmented landscapes, but it also implies a potential scheme to exploit optimal choice of spatial resolution in fusing UAV images and Sentinel-2A, with little to no adverse side-effects. © 2019 by the authors.","Antennas; Classification (of information); Crops; Decision trees; Image fusion; Image resolution; Optical resolving power; Photomapping; Satellite imagery; Unmanned aerial vehicles (UAV); Adverse side effects; Classification accuracy; Fragmented landscapes; Random forest algorithm; Random forests; Sentinel-2A; Spatial heterogeneity; Spatial resolution; Image classification","Classification; Image fusion; Random forests; Resolution; Sentinel-2A; UAV","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85077881059"
"Yunyu Z.; Yingying C.; Ming W.; Mingqiong H.; Jing T.","Yunyu, Zhang (57217826879); Yingying, Chen (57208965806); Ming, Wang (57219974186); Mingqiong, He (57219971556); Jing, Tan (57219971064)","57217826879; 57208965806; 57219974186; 57219971556; 57219971064","FY-3D/MERSI-II Meteorological Satellite Image Fusion Method and its Application","2020","Proceedings of 2020 IEEE 3rd International Conference on Information Systems and Computer Aided Education, ICISCAE 2020","","","9236890","237","240","3","10.1109/ICISCAE51034.2020.9236890","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096362130&doi=10.1109%2fICISCAE51034.2020.9236890&partnerID=40&md5=86994b0c53958bfff4ca6b3038050b06","In order to solve the problem that the spatial resolution of some channels of the FY-3D satellite medium-resolution spectral imager (MERSI-II) is not high enough, 19 channel images with a spatial resolution of 1000 meters are merged and enhanced. Based on the geometric correction of the original data, the Gram-Schimidt Transform remote sensing fusion algorithm is selected, and the panchromatic image extracted from the MERSI-II 250-meter spatial resolution image is used. Then selected the WMO 'natural color' synthesis scheme is to display RGB three-color synthesis on the fused image. The result of FY-3D satellite image data fusion shows that the fused image has clear colors, which not only retains the multi-spectral characteristics of 1000-meter channel data, but also has the high-resolution advantage of 250-meter channel data. The comparison experiment found that compared with the original image, the fused image has greatly improved the ability to recognize the topography of rivers, lakes, land and sea boundaries, and mountain range trends. And the ability to recognize snow, vegetation cover, and structural features of cloud has also been significantly enhanced. The fusion algorithm can greatly improve the remote sensing fine analysis capability of FY-3D / MERSI - II images in the fields of disaster prevention and mitigation and ecological civilization construction. © 2020 IEEE.","Color; Computer aided instruction; Disaster prevention; Image fusion; Image resolution; Information systems; Information use; Mathematical transformations; Remote sensing; Satellites; Spectroscopy; Topography; Disaster prevention and mitigations; Geometric correction; Medium resolution spectral imager; Panchromatic images; Remote sensing fusion; Satellite image datas; Spatial resolution images; Structural feature; Image enhancement","FY-3D; Image fusion; remote sensing; spatial resolution","Conference paper","Final","","Scopus","2-s2.0-85096362130"
"Tang F.; Shen C.; An A.; Wan Y.","Tang, Feifei (57203686345); Shen, Cheng (57219988314); An, Aobo (57965724600); Wan, Yun (57965601200)","57203686345; 57219988314; 57965724600; 57965601200","Research on Fusion and Registration Method for High-Resolution Satellite Image and Vehicle Lidar Data","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","3303","3306","3","10.1109/IGARSS46834.2022.9884791","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141898284&doi=10.1109%2fIGARSS46834.2022.9884791&partnerID=40&md5=693b18c4b0d50207de8981819be2b372","In this paper, to solve the problem of lacking of road information caused by ground object occlusion, a registration and fusion method of high-resolution satellite image and vehicle point cloud data is proposed. Firstly, the road surface and crash barrier are extracted by using the filtering algorithm of joint gradient and elevation. Secondly, the Canny algorithm is used to extract road boundary on satellite images, and the plane is selected to extract linear points according to the elevation features of crash barrier and road boundary. Thirdly, the nearest neighbor point cloud iteration method is used to realize the matching of linear points with the same name. Finally, the high-resolution image and DEM are combined to generate a 3D model, and the vehicle point cloud data is registered with the three-dimensional model according to a rotation matrix, so as to improve the efficiency of high-precision map construction. The experimental results show that this method can effectively realize the registration of high resolution image and vehicle lidar data, combine the complementary advantages of high resolution image and point cloud data, improving the integrity of vehicle point cloud data, and alleviate the problem of high-precision map construction caused by occlusion to a certain extent. © 2022 IEEE.","3D modeling; Image enhancement; Image fusion; Image registration; Optical radar; Roads and streets; Satellites; Fusion methods; High resolution satellite images; High-resolution images; Iterative algorithm; Laser point; Near neighbor iterative algorithm; Nearest-neighbour; Point cloud data; Registration; Vehicle-based laser point cloud data; Iterative methods","High-resolution satellite image; Nearest neighbor iterative algorithm; Registration; Vehicle-based laser point cloud data","Conference paper","Final","","Scopus","2-s2.0-85141898284"
"Mishra D.; Hadar O.","Mishra, Divya (57485985200); Hadar, Ofer (7004643957)","57485985200; 7004643957","Self-FuseNet: Data Free Unsupervised Remote Sensing Image Super-Resolution","2023","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","","","1","18","17","10.1109/JSTARS.2023.3239758","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147265423&doi=10.1109%2fJSTARS.2023.3239758&partnerID=40&md5=a7c1e77a3941292c5e9835cc38db60de","Real-world degradations deviate from ideal degradations, as most deep learning-based scenarios involve the ideal synthesis of low-resolution counterpart images by popularly used bicubic interpolation. Moreover, supervised learning approaches rely on many high-resolution and low-resolution image pairings to reconstruct missing information based on their association, developed by complex long hours of deep neural network training. Additionally, the trained model&#x0027;s generalizability on various image datasets with various distributions is not guaranteed. To overcome this challenge, we proposed our novel Self-FuseNet, particularly for extremely poor-resolution satellite images. Also, the network exhibits strong generalization performance on additional datasets (both &#x201C;Ideal&#x201D; and &#x201C;Non-Ideal&#x201D; scenarios). The network is especially for those image datasets suffering from two significant limitations: (1) non-availability of ground truth high-resolution images and (2) limitation of a large count of the unpaired dataset for deep neural network training. The benefit of the proposed model is threefold: First, it does not require any significant extensive training data, either paired or unpaired but only a single low-resolution image without prior knowledge of its distribution. Secondly, it is a simple and effective model for super-resolving very poor-resolution images, saving computational resources and time. Third, using UNet, the processing of data is accelerated by the network&#x0027;s wide skip connections, allows image reconstruction with fewer parameters. Rather than using an inverse approach, as common in most deep learning scenarios, we introduced a forward approach to super-resolve exceptionally low-resolution remote sensing images. This demonstrates its supremacy over recently proposed state-of-the-art methods for unsupervised single real-world image blind super-resolution. Author","Data handling; Deep neural networks; Image fusion; Inverse problems; Optical resolving power; Remote sensing; Blind image super-resolution; Deep learning; Features extraction; Image super resolutions; Images reconstruction; Self-fusion; Spatial resolution; Superresolution; Unsupervised image super-resolution; Image reconstruction","Blind image super-resolution; data fusion; Deep learning; deep learning; Feature extraction; Image reconstruction; Satellites; self-fusion; Spatial resolution; Superresolution; Training; unsupervised image super-resolution","Article","Article in press","All Open Access; Gold Open Access","Scopus","2-s2.0-85147265423"
"Mateen S.; Nuthammachot N.; Techato K.; Ullah N.","Mateen, Shabnam (58075050600); Nuthammachot, Narissara (57204889352); Techato, Kuaanan (25321184300); Ullah, Nasim (54380714500)","58075050600; 57204889352; 25321184300; 54380714500","Billion Tree Tsunami Forests Classification Using Image Fusion Technique and Random Forest Classifier Applied to Sentinel-2 and Landsat-8 Images: A Case Study of Garhi Chandan Pakistan","2023","ISPRS International Journal of Geo-Information","12","1","9","","","","10.3390/ijgi12010009","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146717923&doi=10.3390%2fijgi12010009&partnerID=40&md5=e22dd6be87621fd32f0aca641d2e6a32","In order to address the challenges of global warming, the Billion Tree plantation drive was initiated by the government of Khyber Pakhtunkhwa, Pakistan, in 2014. The land cover changes as a result of Billion Tree Tsunami project are relatively unexplored. In particular, the utilization of remote sensing techniques and satellite image classification has not yet been done. Recently, the Sentinel-2 (S2) satellite has found much utilization in remote sensing and land cover classification. Sentinel-2 (S2) sensors provide freely available images with a spatial resolution of 10, 20 and 60 m. The higher classification accuracy is directly dependent on the higher spatial resolution of the images. This research aims to classify the land cover changes as a result of the Billion Tree plantation drive in the areas of our interest using Random Forest Classifier (RFA) and image fusion techniques applied to Sentinel-2 and Landsat-8 satellite images. A state-of-the-art, model-based image-sharpening technique was used to sharpen the lower resolution Sentinel-2 bands to 10 m. Then the RFA classifier was used to classify the sharpened images and an accuracy assessment was performed for the classified images of the years 2016, 2018, 2020 and 2022. Finally, ground data samples were collected using an unmanned aerial vehicle (UAV) drone and the classified image samples were compared with the real data collected for the year 2022. The real data ground samples were matched by more than 90% with the classified image samples. The overall classification accuracies [%] for the classified images were recorded as 92.87%, 90.79%, 90.27% and 93.02% for the sample data of the years 2016, 2018, 2020 and 2022, respectively. Similarly, an overall Kappa hat classification was calculated as 0.87, 0.86, 0.83 and 0.84 for the sample data of the years 2016, 2018, 2020 and 2022, respectively. © 2022 by the authors.","","Billion Tree Tsunami project; image classification; image fusion and sharpening; Random Forest Classifier","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85146717923"
"Tambe R.G.; Talbar S.N.; Chavan S.S.","Tambe, Rishikesh G. (56711882100); Talbar, Sanjay N. (12800615100); Chavan, Satishkumar S. (57203944586)","56711882100; 12800615100; 57203944586","Satellite image fusion using undecimated rotated wavelet transform","2021","International Journal of Computational Science and Engineering","24","2","","171","184","13","10.1504/IJCSE.2021.115103","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106169684&doi=10.1504%2fIJCSE.2021.115103&partnerID=40&md5=04691fb6946f038c9bc9bb3635a7904b","This paper presents two satellite image fusion algorithms namely decimated/ subsampled rotated wavelet transform (SSRWT) and undecimated/non-subsampled rotated wavelet transform (NSRWT) using 2D rotated wavelet filters for extracting relevant and pragmatic information from MS and PAN images. Three major visual artefacts such as colour distortion, shifting effects and shift distortion are identified in the fused images obtained using SSRWT which are addressed by using NSRWT. The proposed NSRWT algorithm preserves spatial and spectral features of the source MS and PAN images resulting fused image with better fusion performance. The final fused image provides richer information (in terms of spatial and spectral quality) than that of the original input images. The experimental results strongly reveal that undecimated fusion algorithm (NSRWT) not only performs better than decimated fusion algorithm (SSRWT) but also improves spatial and spectral quality of the fused images. Copyright © 2021 Inderscience Enterprises Ltd.","Image compression; Image enhancement; Rotation; Wavelet transforms; Fused images; Fusion algorithms; Fusion performance; Pragmatic informations; Satellite images; Spectral feature; Spectral quality; Wavelet filters; Image fusion","Feature extraction; Fusion metrics; MS images; Non-subsampled rotated wavelet transform; NSRWT; PAN images; Rotated wavelet filters; RWF; Satellite image fusion; Shift distortion; Shifting effect; SSRWT; Subsampled rotated wavelet transform","Article","Final","","Scopus","2-s2.0-85106169684"
"Ravikanth G.; Sunitha K.V.N.; Eswara Reddy B.","Ravikanth, G. (57218775536); Sunitha, K.V.N. (12789729100); Eswara Reddy, B. (25923111700)","57218775536; 12789729100; 25923111700","Location Related Signals with Satellite Image Fusion Method Using Visual Image Integration Method","2020","Computer Systems Science and Engineering","35","5","","385","393","8","10.32604/CSSE.2020.35.385","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104505706&doi=10.32604%2fCSSE.2020.35.385&partnerID=40&md5=a74c96799966fce0f635f8582f2416a2","Investigations were performed on a group utilizing (General Purpose Unit) GPU and executions were evaluated for the utilization of the created parallel usages to process satellite pictures from satellite Landsat7.The usage on a realistic group gives execution change from 2 to 18 times. The nature of the considered techniques was assessed by relative dimensionless global error in synthesis (ERGAS) and Quality Without Reference (QNR) measurements. The outcomes demonstrate execution picks ups and holding of value with the bunch of GPU contrasted with the outcomes and different analysts for a CPU and single GPU. The errand of upgrading the view of a scene by combining data caught from various picture sensors is usually known as multisensor picture combination. This paper displays a territory based picture combination calculation to consolidate SAR (Synthetic Aperture Radar) and optical pictures. The co-enlistment of the two images is first led utilizing the proposed enrollment method prior to picture combination. The paper displays a parallel execution of existing picture combination techniques on a graphical group. Parallel executions of techniques in view of discrete wavelet changes are created. Division into dynamic and motionless regions is then executed on the SAR surface picture for particular injection of the SAR picture into panchromatic (PAN) picture. An integrated image in view of these two pictures is produced by the novel region based combination plot, which forces diverse combination rules for each fragmented region. At long last, this picture is melded into a multispectral(MS) picture through the half breed skillet honing technique proposed in past research. Exploratory outcomes exhibit that the proposed strategy demonstrates preferred execution over different fusion algorithms and can possibly be connected to the multisensory combination of SAR and optical pictures. © 2020 CRL Publishing. All rights reserved.","Graphics processing unit; Image fusion; Radar imaging; Satellites; Synthetic aperture radar; Combination rules; Discrete wavelets; Fusion algorithms; Integrated images; Parallel executions; SAR(synthetic aperture radar); Satellite images; Satellite pictures; Space-based radar","Area-based combination conspire; Cluster; co-enlistment; GPU; hybrid sharpening; Image combination; multisensor picture combination; Satellite.; Wavelet; wavelet change","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85104505706"
"Mahmud H.B.; Katiyar V.; Nagai M.","Mahmud, Husniyah Binti (57215431801); Katiyar, Vaibhav (55349816200); Nagai, Masahiko (36148030600)","57215431801; 55349816200; 36148030600","Improved Consistency of an Automated Multisatellite Method for Extracting Temporal Changes in Flood Extent","2021","Mathematical Problems in Engineering","2021","","6164161","","","","10.1155/2021/6164161","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122996712&doi=10.1155%2f2021%2f6164161&partnerID=40&md5=1dca99a2c399f12a259c9364d5027274","Malaysia is affected by floods almost every year. In this situation, high-frequency flood monitoring is crucial so that timely measures can be taken. However, the low revisit time of the satellites, as well as occlusion cast by clouds in optical images, limits the frequency of flood observation of the focused area. Therefore, this study proposes utilising multisatellite data from optical satellites such as Landsat 7, Landsat 8, and Moderate Resolution Imaging Spectroradiometer (MODIS), as well as Synthetic Aperture Radar (SAR) images from Advanced Land Observation Satellite (ALOS-2) and Sentinel-1, to increase observation of flood. The main objective was to utilize Otsu image segmentation over both optical and SAR satellite images to distinguish water and nonwater areas in each image separately. For this, modified normalized difference water index (MNDWI) for the optical satellite and total dual-polarization backscatter for SAR satellite images were estimated. The focused area has been divided into Universal Transverse Mercator (UTM) square-size grids of 30 pixels, and each satellite image was reprojected and resampled with a pixel size of 0.001° to standardize the flood map resolution. The second objective was to assess the potential of image fusion for increasing the consistency of water area extraction. Two pairs of satellite images with the same observation period covering a flood event in September 2017 in Perlis, Malaysia, were processed using 2D wavelet transform. Lastly, the temporal changes of the integrated surface water extent were evaluated by comparing the output from both multisatellite and fused images with the observed water level data from the Department of Drainage and Irrigation. The results showed that the proposed model can be used to estimate flood duration as well as to estimate the flood-related losses, especially in ungauged or data-poor regions. Copyright © 2021 Husniyah Binti Mahmud et al.","Geometrical optics; Image fusion; Image segmentation; Pixels; Radar imaging; Satellite imagery; Surface waters; Synthetic aperture radar; Water levels; Wavelet transforms; Flood monitoring; High frequency HF; LANDSAT; LandSat 7; Malaysia; Optical image; Optical satellites; Radar satellites; Satellite images; Temporal change; Floods","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85122996712"
"Asokan A.; Anitha J.","Asokan, Anju (57190950323); Anitha, J. (57204786853)","57190950323; 57204786853","Lifting wavelet and discrete cosine transform-based super-resolution for satellite image fusion","2021","Advances in Intelligent Systems and Computing","1227","","","273","283","10","10.1007/978-981-15-6876-3_20","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090098917&doi=10.1007%2f978-981-15-6876-3_20&partnerID=40&md5=b4264554f733479ef4511ddda4ec7b6d","Super-resolution creates a high-resolution image from an input low-resolution image. The availability of low-resolution images for analysis has degraded the quality of image processing. We propose a lifting wavelet and discrete cosine transform-based super-resolution technique for satellite image enhancement. Here, the low-resolution images are decomposed using Lifting Wavelet Transform (LWT) and Discrete Cosine Transform (DCT). The high-frequency components and the source image are interpolated and all these images are combined to generate the high-resolution image using Inverse Lifting Wavelet Transform (ILWT). The enhanced source images are further fused using curvelet transform. The proposed work is assessed on a set of multispectral images and the results indicate that the proposed framework generates better quality high-resolution satellite images and further enhances the image fusion results compared to the traditional wavelet-based transforms and spatial domain interpolation schemes. © Springer Nature Singapore Pte Ltd. 2021.","Computational methods; Discrete cosine transforms; Image coding; Image compression; Image fusion; Inverse problems; Optical resolving power; Satellites; Wavelet transforms; Discrete Cosine Transform(DCT); High frequency components; High resolution image; High resolution satellite images; Lifting wavelet transforms; Low resolution images; Multispectral images; Spatial domain interpolation; Image enhancement","Curvelet transform; Image fusion; Lifting scheme; Lifting Wavelet Transform; Multispectral; Satellite image; Super-resolution","Conference paper","Final","","Scopus","2-s2.0-85090098917"
"Abbas H.K.; Faris F.; Sami S.; Fadel A.Z.","Abbas, Heba Khudhair (57209497100); Faris, Farah (57222424021); Sami, Sale (57222724374); Fadel, Al Zahraa (57223914831)","57209497100; 57222424021; 57222724374; 57223914831","Adopting image integration techniques to simulate satellite images","2020","Iraqi Journal of Science","61","12","","3446","3456","10","10.24996/ijs.2020.61.12.32","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106417507&doi=10.24996%2fijs.2020.61.12.32&partnerID=40&md5=e0fb32a08e909e06288398972f33afbd","Mathematical integration techniques rely on mathematical relationships such as addition, subtraction, division, and subtraction to merge images with different resolutions to achieve the best effect of the merger. In this study, a simulation is adopted to correct the geometric and radiometric distortion of satellite images based on mathematical integration techniques, including Brovey Transform (BT), Color Normalization Transform (CNT), and Multiplicative Model (MM). Also, interpolation methods, namely the nearest neighborhood, Bi-linear, and Bi-cubic were adapted to the images captured by an optical camera. The evaluation of images resulting from the integration process was performed using several types of measures; the first type depends on the determination of quality in the regions of the edges using a contrast measure as well as the number of edges and threshold. The second type is the global one that is based on the parameters of the image region, including the Mean (µ), Standard Deviation (SD), and Signal to Noise Ratio (SNR). The parameters also included the Amount of Information Added (AIA) to the original image, such as those for the total (AIAt), edges (AIAe), and homogenous (AIAh) regions. The results showed the efficiency of the integration process in the image fusion with different resolutions in one image integrated resolution. The quality measures used were also capable in evaluating the most efficient techniques and determining the accurate information of the resulting image. © 2020 University of Baghdad-College of Science. All rights reserved.","","Geometric distortion; Interpolation method; Mathematical integration techniques; Statistical measures","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85106417507"
"Vohra R.; Tiwari K.C.","Vohra, Rubeena (57195635472); Tiwari, K.C. (57214612594)","57195635472; 57214612594","Land cover classification using multi-fusion based dense transpose convolution in fully convolutional network with feature alignment for remote sensing images","2022","Earth Science Informatics","","","","","","","10.1007/s12145-022-00891-8","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141692844&doi=10.1007%2fs12145-022-00891-8&partnerID=40&md5=2b17f3fdab35c9f91487c529815c7b51","With advances in social development and economic growth, remote sensing technology has been attracted greater attention in monitoring the earth data using radar and optical sensors on satellite platforms for a wide range of applications in different fields such as coastal, hazard and natural resources. Satellite images could play a greater role in improving classification accuracy with high spatial resolution and rich spectral information for land cover classification. However, existing image fusion methods achieves low accuracy due to large-scale feature space. To focus on these issues, a deep learning network structure needs to classify different classes with high spatial resolution and rich spectral information to obtain higher accuracy. In this paper, a feature-based classification approach is proposed namely Multi-Fusion based Dense Transpose Convolutional layer in Fully Convolutional Network with Feature Alignment framework (MF-DTCFCN) to label and categorizes the label region in Remote Sensing Images (RSI). Initially, a multi-fusion feature framework is designed by adding a point-wise addition structure to handle large-scale feature space for high-resolution images. Secondly, the optimized features are pre-trained to classify the labels comprised of the most discriminative features in the pre-training network. The density of output label maps are improved by introducing dense transpose convolution in the network. Then combine the output to the feature alignment with point-wise addition is employed to balance the different features and similarities to achieve additional performance for classification. Here, the Land Use/land Cover (LULC) satellite image dataset namely, Sentinel-2 were used to classify the urban areas of Hyderabad city, India. Experimental results depict that the MF-DTCFCN approach outperforms an accurate improvement in classification accuracy than existing methods. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","","Deep Learning(DL); Fully Convolutional Network (FCN); Land cover classification; Multi-sensor data; Remote Sensing Images (RSI)","Article","Article in press","","Scopus","2-s2.0-85141692844"
"Huang W.; Zhou J.; Zhang D.","Huang, Wei (57218084573); Zhou, Jianzhong (57218363180); Zhang, Dongying (56529797700)","57218084573; 57218363180; 56529797700","On‐the‐fly fusion of remotely‐sensed big data using an elastic computing paradigm with a containerized spark engine on kubernetes","2021","Sensors","21","9","2971","","","","10.3390/s21092971","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104515500&doi=10.3390%2fs21092971&partnerID=40&md5=b0e0cde4a9a23225b726d40bd1e8ce78","Remotely‐sensed satellite image fusion is indispensable for the generation of long‐term gap‐free Earth observation data. While cloud computing (CC) provides the big picture for RS big data (RSBD), the fundamental question of the efficient fusion of RSBD on CC platforms has not yet been settled. To this end, we propose a lightweight cloud‐native framework for the elastic processing of RSBD in this study. With the scaling mechanisms provided by both the Infrastructure as a Service (IaaS) and Platform as a Services (PaaS) of CC, the Spark‐on‐Kubernetes operator model running in the framework can enhance the efficiency of Spark‐based algorithms without considering bottlenecks such as task latency caused by an unbalanced workload, and can ease the burden to tune the performance parameters for their parallel algorithms. Internally, we propose a task scheduling mechanism (TSM) to dynamically change the Spark executor pods’ affinities to the computing hosts. The TSM learns the workload of a computing host. Learning from the ratio between the number of completed and failed tasks on a computing host, the TSM dispatches Spark executor pods to newer and less‐overwhelmed computing hosts. In order to illustrate the advantage, we implement a parallel enhanced spatial and temporal adaptive reflectance fusion model (PESTARFM) to enable the efficient fusion of big RS images with a Spark aggregation function. We construct an OpenStack cloud computing environment to test the usability of the framework. According to the experiments, TSM can improve the performance of the PESTARFM using only PaaS scaling to about 11.7%. When using both the IaaS and PaaS scaling, the maximum performance gain with the TSM can be even greater than 13.6%. The fusion of such big Sentinel and PlanetScope images requires less than 4 min in the experimental environment. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Big data; Image enhancement; Image fusion; Platform as a Service (PaaS); Aggregation functions; Cloud computing environments; Earth observation data; Elastic computing; Experimental environment; Performance parameters; Scaling mechanism; Temporal adaptive; algorithm; article; big data; cloud computing; human; learning; running; usability; workload; Infrastructure as a service (IaaS)","Big data; Cloud computing; Fusion algorithm; Kubernetes; Parallel computing","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85104515500"
"Ebel P.; Xu Y.; Schmitt M.; Zhu X.X.","Ebel, Patrick (57409415200); Xu, Yajin (57431339600); Schmitt, Michael (7401931279); Zhu, Xiao Xiang (55696622200)","57409415200; 57431339600; 7401931279; 55696622200","Multi-Sensor Time Series Cloud Removal Fusing Optical and SAR Satellite Information","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","5381","5384","3","10.1109/IGARSS46834.2022.9883238","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140366516&doi=10.1109%2fIGARSS46834.2022.9883238&partnerID=40&md5=e91242160b9cb5f6990eef332f102787","On average, about half of all optical satellite data observing Earth is covered by haze or clouds. These atmospheric disturbances hinder the ongoing observation of our planet and prevent the seamless application of established remote sensing methods. Accordingly, to allow for an ongoing monitoring of Earth, approaches to reconstruct optical space-borne observations are required. This work introduces a new data set, SEN12MS-CR-TS, for the purpose of multi-sensor time series cloud removal. SEN12MS-CR-TS consists of co-registered radar and optical satellite data, featuring a se-quence of bi-weekly observations throughout an entire year. Finally, we demonstrate the usability of our novel data set by developing a new multi-sensor time-series cloud removal ar-chitecture. We are positive that our curated data set as well as the proposed model will advance future research in satellite image reconstruction and benefit the expanding adaptation of global and all-weather remote sensing applications. © 2022 IEEE.","Earth (planet); Image fusion; Image reconstruction; Optical remote sensing; Radar imaging; Satellites; Space optics; Space-based radar; Time series; Cloud removal; Data set; Images reconstruction; Multi sensor; Optical imagery; Optical satellites; Optical-; Satellite data; Satellite information; Times series; Synthetic aperture radar","data fusion; image reconstruction; optical imagery; synthetic aperture radar; time series","Conference paper","Final","","Scopus","2-s2.0-85140366516"
"Hurtado E.; Vera-Parra N.E.; Medina J.","Hurtado, Edwin (57223309981); Vera-Parra, Nelson Enrique (56809301400); Medina, Javier (57197825929)","57223309981; 56809301400; 57197825929","Implementation and assessement of image fusion using google earth engine and matlab with landsat 8 images; [Implementación y evaluación de la fusión de imágenes usando google earth engine y matlab con imágenes landsat 8]","2021","RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao","2021","E41","","604","617","13","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105515039&partnerID=40&md5=ec8e65bf05200fd7cd3f59d5da988f8a","This article develops the mathematical algorithm of the RGB-HSV Transform for merging satellite images. Three important topics are addressed; the first topic corresponds to a mathematical introduction to implement image fusion using the RGB-HSV transform. The second theme corresponds to the implementation of the algorithmic development of the transform using Google Earth Engine and Matlab, using a Landsat 8 OLI TIRS satellite image. The third topic is dedicated to the evaluation in order to determine the efficiency of the RGB-HSV Transform. The two resulting merged images were evaluated for both spatial and spectral quality through four indices, namely: the correlation coefficient, the RASE index, the ERGAS index, and the universal quality index Qu. The best results of the evaluation were obtained with the image fused with the RGB-HSV algorithm, implemented in Matlab, which preserves the spectral richness and improves its spatial quality. © 2021, Associacao Iberica de Sistemas e Tecnologias de Informacao. All rights reserved.","","Fusion; GEE; RGB-HSV; Satellite images","Article","Final","","Scopus","2-s2.0-85105515039"
"Sun H.; Xiao W.","Sun, Haoxuan (57209326277); Xiao, Wu (36620043400)","57209326277; 36620043400","Similarity Weight Learning: A New Spatial and Temporal Satellite Image Fusion Framework","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5408617","","","","10.1109/TGRS.2022.3161070","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127054430&doi=10.1109%2fTGRS.2022.3161070&partnerID=40&md5=88ea8dadb9813ebc514cb00dc5f1fd8f","Spatiotemporal fusion is a topical framework for solving the mutual restricted problem between the spatial and temporal resolution of satellite images. We pioneer an approach to replace similarity measurement steps in spatiotemporal fusion algorithms with convolutional neural networks (CNNs), building a bridge between weight function-based models and the learning-based models. Specifically, we propose a nonlocal form that separates the relational computation part from the value representation part, and construct the CNN-based similarity weight learning block for learning normalized weights. The block can be inserted into spatial and temporal adaptive reflectance fusion model (STARFM) to replace the manually designed weight calculation rules common in weight function-based methods, or into the CNN model StfNet to better utilize neighboring high-resolution images. The trained model outputs a high-resolution prediction from each base date image pair. The final result is a combination of the two predictions. In this regard, we propose the standard deviation-based weights to combine two prediction results. Four experiments are performed on Landsat-Moderate-resolution Imaging Spectroradiometer (MODIS) image pairs to determine the following: 1) the performance of the model at the target training date; 2) the generalization of the model in the target training time period; and 3) the generalization of the model at different dates and different geographical locations, each considering the different cases of giving one and two pairs of known images. Experimental results demonstrate the superiority of the similarity weight learning block and standard deviation-based weights. Among them, STARFM with the similarity weight learning block exhibits strong generalization, which testifies to the practical value of our model. © 1980-2012 IEEE.","Biological systems; Convolution; Forecasting; Image fusion; Neural networks; Remote sensing; Satellite imagery; Statistics; Attention; Biological system modeling; Generalization capability; Non-local module; Nonlocal; Remote-sensing; Satellite image fusion; Satellite images; Similarity measure; Spatial resolution; Spatio-temporal fusions; Spatiotemporal phenomenon; algorithm; data acquisition; measurement method; prediction; satellite imagery; Image resolution","Attention; generalization capability; nonlocal module; satellite image fusion; similarity measure; spatiotemporal fusion","Article","Final","","Scopus","2-s2.0-85127054430"
"Yin Y.; Tran A.; Zhang Y.; Hu W.; Wang G.; Varadarajan J.; Zimmermann R.; Ng S.-K.","Yin, Yifang (55925782200); Tran, An (23135524900); Zhang, Ying (56013501000); Hu, Wenmiao (57340316400); Wang, Guanfeng (36722905100); Varadarajan, Jagannadan (25925503600); Zimmermann, Roger (55423994500); Ng, See-Kiong (7403358862)","55925782200; 23135524900; 56013501000; 57340316400; 36722905100; 25925503600; 55423994500; 7403358862","Multimodal Fusion of Satellite Images and Crowdsourced GPS Traces for Robust Road Attribute Detection","2021","GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems","","","","107","116","9","10.1145/3474717.3483917","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119178230&doi=10.1145%2f3474717.3483917&partnerID=40&md5=aa2cefe788b7403c4a409493c68e535b","Automatic inference of missing road attributes (e.g., road type and speed limit) for enriching digital maps has attracted significant research attention in recent years. A number of machine learning based approaches have been proposed to detect road attributes from GPS traces, dash-cam videos, or satellite images. However, existing solutions mostly focus on a single modality without modeling the correlations among multiple data sources. To bridge the gap, we present a multimodal road attribute detection method, which improves the robustness by performing pixel-level fusion of crowdsourced GPS traces and satellite images. A GPS trace is usually given by a sequence of location, bearing, and speed. To align it with satellite imagery in the spatial domain, we render GPS traces into a sequence of multi-channel images that simultaneously capture the global distribution of the GPS points, the local distribution of vehicles' moving directions and speeds, and their temporal changes over time, at each pixel. Unlike previous GPS based road feature extraction methods, our proposed GPS rendering does not require map matching in the data preprocessing step. Moreover, our multimodal solution addresses single-modal challenges such as occlusions in satellite images and data sparsity in GPS traces by learning the pixel-wise correspondences among different data sources. Extensive experiments have been conducted on two real-world datasets in Singapore and Jakarta. Compared with previous work, our method is able to improve the detection accuracy on road attributes by a large margin. © 2021 Owner/Author.","Crowdsourcing; Global positioning system; Image enhancement; Image fusion; Rendering (computer graphics); Roads and streets; Satellite imagery; Attribute detections; Automatic inference; Digital map; GPS traces; GPS trajectory; Multi-modal; Multi-modal fusion; Road attribute; Satellite images; Speed limit; Pixels","digital maps; GPS trajectories; Road attributes; satellite images","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85119178230"
"Azarang A.; Kehtarnavaz N.","Azarang, Arian (57191341532); Kehtarnavaz, Nasser (7006470206)","57191341532; 7006470206","Image fusion in remote sensing conventional and deep learning approaches","2021","Synthesis Lectures on Image, Video, and Multimedia Processing","10","1","","","","","10.2200/S01074ED1V01Y202101IVM021","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101259428&doi=10.2200%2fS01074ED1V01Y202101IVM021&partnerID=40&md5=0d5213bacbf6846fa6897f0dcabe03ac","Image fusion in remote sensing or pansharpening involves fusing spatial (panchromatic) and spectral (multispectral) images that are captured by different sensors on satellites. This book addresses image fusion approaches for remote sensing applications. Both conventional and deep learning approaches are covered. First, the conventional approaches to image fusion in remote sensing are discussed. These approaches include component substitution, multi-resolution, and model-based algorithms. Then, the recently developed deep learning approaches involving single-objective and multi-objective loss functions are discussed. Experimental results are provided comparing conventional and deep learning approaches in terms of both low-resolution and full-resolution objective metrics that are commonly used in remote sensing. The book is concluded by stating anticipated future trends in pansharpening or image fusion in remote sensing. © 2021 Association for Computing Machinery. All rights reserved.","Image fusion; Remote sensing; Component substitution; Conventional approach; Image fusion approach; Learning approach; Model-based algorithms; Objective metrics; Remote sensing applications; Single objective; Deep learning","Deep learning-based image fusion; Fusion of spatial and spectral satellite images; Image fusion in remote sensing; Pansharpening","Article","Final","","Scopus","2-s2.0-85101259428"
"Jenice Aroma R.; Raimond K.","Jenice Aroma, R. (55811488900); Raimond, Kumudha (24776550700)","55811488900; 24776550700","Application of Image Fusion Approaches for Image Differencing in Satellite Images","2020","Advances in Intelligent Systems and Computing","766","","","283","292","9","10.1007/978-981-13-9683-0_31","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079827581&doi=10.1007%2f978-981-13-9683-0_31&partnerID=40&md5=b3de06a8e165da9b7c3db71029c287f2","The increasing thwart for the environment has lead to a revolutionary change in protective measures. The surveillance of the complete ecosystem was a laborious effort during the days of field sensors based assessment practices for spatial object monitoring. After the rise of satellite image based applications for observing the spatiotemporal changes in both coastal regions and urban ecosystems, environmental sustainability has got a balance. In order to implement such applications with more accurate assessment, the spatial image interpretation methods are in need to be improved. This paper proposes a significant approach for water body change visualization by applying feature-level image fusion methods for tracing the extent of change occurred within a water body over the chosen time period. The Image Quality Assessment (IQA) metrics have been applied for quantitative assessment. The results achieved on superimposing the various point descriptors, wavelet descriptors, and other reduced features could highly portray the effective change visualization of the chosen water body. © 2020, Springer Nature Singapore Pte Ltd.","Ecosystems; Image enhancement; Sustainable development; Visualization; Clustering; Environmental sustainability; Image quality assessment (IQA); LANDSAT; Quantitative assessments; Spatio-temporal changes; Spectral indices; Waterbodies; Image fusion","Change map; Clustering; Image fusion; Landsat 8; Spectral indices; Water body","Conference paper","Final","","Scopus","2-s2.0-85079827581"
"Ma Y.; Chen H.; Zhao G.; Wang Z.; Wang D.","Ma, Ying (57210170643); Chen, Hongyan (35785773800); Zhao, Gengxing (57223727867); Wang, Zhuoran (56660491000); Wang, Danyang (57209326552)","57210170643; 35785773800; 57223727867; 56660491000; 57209326552","Spectral Index Fusion for Salinized Soil Salinity Inversion Using Sentinel-2A and UAV Images in a Coastal Area","2020","IEEE Access","8","","9180282","159595","159608","13","10.1109/ACCESS.2020.3020325","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091298494&doi=10.1109%2fACCESS.2020.3020325&partnerID=40&md5=f438c677d4196d965fdaa1c56b939480","The accurate and rapid inversion of soil salinity in regions based on the fusion of multisource remote sensing is not only practical for the treatment and utilization of saline soil but also the main trend in the development of quantitative soil salinization remote sensing. In this paper, the use of a numerical regression method to fuse spectral indexes based on high-spatial-resolution unmanned aerial vehicle (UAV) images and low-spatial-resolution satellite images was proposed to deeply assess the internal relationships between different types of remote sensing data. An inversion model of soil salt content (SSC) was constructed based on high-spatial-resolution UAV images, and the spectral indexes involved in the fusion were selected from the model. Then, a quadratic polynomial fusion function describing the relationship between the spectral indexes based on the two images was established to correct the spectral indexes based on the low-spatial-resolution satellite image (from Sentinel-2A). Then, scenario 1 (the best model based on Sentinel-2A used for the unfused Sentinel-2A spectral index), scenario 2 (the best inversion model based on UAV used for the unfused Sentinel-2A-based spectral index), and scenario 3 (the best inversion model based on UAV used for the fused Sentinel-2A-based spectral index) were compared and analyzed, and the SSC distribution map was obtained through scenario 3. The results indicate that the scenario 3 had highest accuracy, with the calibration R2 improving by 0.078-0.111, the root mean square error (RMSE) decreasing by 0.338-1.048, the validation R2 improving by 0.019-0.079, the RMSE decreasing by 0.517-1.030, and the ratio of performance to deviation (RPD) improving by 0.185-0.423. Therefore, this method can improve the accuracy of SSC remote sensing inversion, which is conducive to the accurate and rapid monitoring of SSC. © 2013 IEEE.","Antennas; Image fusion; Image resolution; Mean square error; Numerical methods; Regression analysis; Soils; Unmanned aerial vehicles (UAV); Distribution maps; High spatial resolution; Internal relationships; Quadratic polynomial; Remote sensing data; Root mean square errors; Soil salinization; Spatial resolution; Remote sensing","numerical regression; Soil salinization; spectral index fusion; unmanned aerial vehicle","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85091298494"
"Kabolizadeh M.; Rangzan K.; Mousavi S.S.; Azhdari E.","Kabolizadeh, Mostafa (36080758400); Rangzan, Kazem (7801505713); Mousavi, Seyyed Sajedin (57772503500); Azhdari, Ehsan (57772851700)","36080758400; 7801505713; 57772503500; 57772851700","Applying optimum fusion method to improve lithological mapping of sedimentary rocks using sentinel-2 and ASTER satellite images","2022","Earth Science Informatics","15","3","","1765","1778","13","10.1007/s12145-022-00836-1","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133192561&doi=10.1007%2fs12145-022-00836-1&partnerID=40&md5=43865186b609e0d62166084776f25cde","This study was set the yield a precise map of geological formations appliying satellite image fusion techniques. Geologic maps are one of the most valuable sources for understanding the geological conditions of a region used to show the spread of different rock and soil outcrops. In the present research, the fusion of ASTER and Sentinel-2 images were applied using Brovey Transform (BT), Gram-Schmidt (GS), Color Normalized (CN), Smoothing Filter-based Intensity Modulation (SFIM) and Discrete Wavelet Transform (DWT) methods to prepare the lithological map. Based on the results of the employed methods, DWT and BT methods are good in terms of providing spectral and spatial information, respectively. The results also showed that the SFIM method has appropriate spectral and spatial accuracy. At the classification stage, all fused images were processed through supervised classification algorithm of Support Vector Machine (SVM) to identify and separate the geological formations of the study area. The evaluation of the classifications results demonstrated that the SVM method used in the fused images by SFIM method, with 83.16 overall accuracy and 0.82 kappa coefficient has evidential results for lithological mapping. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","ASTER; lithology; mapping method; numerical method; satellite imagery; sedimentary rock; Sentinel; supervised classification","ASTER; Image fusion; Lithological mapping; Sentinel-2","Article","Final","","Scopus","2-s2.0-85133192561"
"Chhabra V.; Kiran R.U.; Xiao J.; Reddy P.K.; Avtar R.","Chhabra, Vipul (57680044700); Kiran, R. Uday (57821373600); Xiao, Juan (57224571896); Reddy, P. Krishna (34877780100); Avtar, Ram (35885220000)","57680044700; 57821373600; 57224571896; 34877780100; 35885220000","A Spatiotemporal Image Fusion Method for Predicting High-Resolution Satellite Images","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13343 LNAI","","","470","481","11","10.1007/978-3-031-08530-7_40","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137972794&doi=10.1007%2f978-3-031-08530-7_40&partnerID=40&md5=3ec9fdcc8b1004fffbb50df6d958beef","Given a coarse satellite image and a fine satellite image of a particular location taken at the same time, the high-resolution spatiotemporal image fusion technique involves understanding the spatial correlation between the pixels of both images and using it to generate a finer image for a given coarse (or test) image taken at a later time. This technique is extensively used for monitoring agricultural land cover, forest cover, etc. The two key issues in this technique are: (i) handling missing pixel data and (ii) improving the prediction accuracy of the fine image generated from the given test coarse image. This paper tackles these two issues by proposing an efficient method consisting of the following three basic steps: (i) imputation of missing pixels using neighborhood information, (ii) cross-scale matching to adjust both the Point Spread Functions Effect (PSF) and geo-registration errors between the course and high-resolution images, and (iii) error-based modulation, which uses pixel-based multiplicative factors and residuals to fix the error caused due to modulation of temporal changes. The experimental results on the real-world satellite imagery datasets demonstrate that the proposed model outperforms the state-of-art by accurately producing the high-resolution satellite images closer to the ground truth. © 2022, Springer Nature Switzerland AG.","Data handling; Errors; Image enhancement; Image fusion; Modulation; Optical transfer function; Satellite imagery; Fine images; High resolution; High resolution satellite images; Image fusion methods; Image fusion techniques; Land cover; Satellite images; Spatial correlations; Spatiotemporal images; Test images; Pixels","Image fusion; Land cover; Monitoring; Satellite images","Conference paper","Final","","Scopus","2-s2.0-85137972794"
"Wang S.-T.; Cui K.; Kong D.-M.; Liu S.-Y.; Wu X.","Wang, Shu-Tao (55714642300); Cui, Kai (57216916554); Kong, De-Ming (55513769000); Liu, Shi-Yu (57209286687); Wu, Xing (57210164510)","55714642300; 57216916554; 55513769000; 57209286687; 57210164510","Application of densely connected network in SAR and multispectral image fusion; [密集连接网络在SAR与多光谱影像融合中的应用]","2021","Guangxue Jingmi Gongcheng/Optics and Precision Engineering","29","5","","1145","1153","8","10.37188/OPE.20212905.1145","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108662401&doi=10.37188%2fOPE.20212905.1145&partnerID=40&md5=f7290d3cd617b5a8743151c6fa0cc1a7","To overcome the shortcomings of single satellite sensor imaging, a fusion algorithm for synthetic aperture radar (SAR) and multispectral images based on densely connected networks is proposed herein. Firstly, the SAR and multispectral images are preprocessed separately, and the bicubic interpolation method is used to resample the same spatial resolution. Then, the densely connected network is used to extract the feature maps of the image separately, and the fusion strategy with the largest regional energy is used to combine the depth features. The fused image is input to a pre-trained decoder for reconstruction to obtain the final fused image. The experiment uses Sentinel-1 SAR images, Landsat-8 images, and Gaofen-1 satellite images for verification and draws comparisons with methods based on component substitution, those based on multiscale decomposition, and those based on deep learning. Experimental results indicate that the accuracy of the fusion algorithm based on densely connected networks in terms of the multiscale structural similarity index is as high as 0.9307, and it is better than other fusion algorithms in terms of other evaluation indexes. Detailed information of SAR images and multispectral images are well preserved.","Deep learning; Image fusion; Image processing; Space-based radar; Synthetic aperture radar; Bicubic interpolation; Component substitution; Densely connected networks; Multi-scale Decomposition; Multi-spectral image fusions; Multispectral images; Spatial resolution; Structural similarity indices; Radar imaging","Densely connected network; Image fusion; Multispectral; Synthetic aperture radar","Article","Final","","Scopus","2-s2.0-85108662401"
"Adeniran I.A.; Zhu R.; Yang J.; Zhu X.; Wong M.S.","Adeniran, Ibrahim Ademola (57907674100); Zhu, Rui (57784827700); Yang, Jinxin (56009762200); Zhu, Xiaolin (55696724800); Wong, Man Sing (57419402600)","57907674100; 57784827700; 56009762200; 55696724800; 57419402600","Cross-Comparison between Sun-Synchronized and Geostationary Satellite-Derived Land Surface Temperature: A Case Study in Hong Kong","2022","Remote Sensing","14","18","4444","","","","10.3390/rs14184444","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138814022&doi=10.3390%2frs14184444&partnerID=40&md5=9fc5c6b4171f7f025f426bc5509ad23b","Harmonization of satellite imagery provides a good opportunity for studying land surface temperature (LST) as well as the urban heat island effect. However, it is challenging to use the harmonized data for the study of LST due to the systematic bias between the LSTs from different satellites, which is highly influenced by sensor differences and the compatibility of LST retrieval algorithms. To fill this research gap, this study proposes the comparison of different LST images retrieved from various satellites that focus on Hong Kong, China, by applying diverse retrieval algorithms. LST images generated from Landsat-8 using the mono-window algorithm (MWAL8) and split-window algorithm (SWAL8) would be compared with the LST estimations from Sentinel-3 SLSTR and Himawari-8 using the split-window algorithm (SWAS3 and SWAH8). Intercomparison will also be performed through segregated groups of different land use classes both during the daytime and nighttime. Results indicate that there is a significant difference among the quantitative distribution of the LST data generated from these three satellites, with average bias of up to −1.80 K when SWAH8 was compared with MWAL8, despite having similar spatial patterns of the LST images. The findings also suggest that retrieval algorithms and the dominant land use class in the study area would affect the accuracy of image-fusion techniques. The results from the day and nighttime comparisons revealed that there is a significant difference between day and nighttime LSTs, with nighttime LSTs from different satellite sensors more consistent than the daytime LSTs. This emphasizes the need to incorporate as much night-time LST data as available when predicting or optimizing fine-scale LSTs in the nighttime, so as to minimize the bias. The framework designed by this study will serve as a guideline towards efficient spatial optimization and harmonized use of LSTs when utilizing different satellite images associated with an array of land covers and at different times of the day. © 2022 by the authors.","Atmospheric temperature; Geostationary satellites; Image fusion; Land surface temperature; Land use; Surface measurement; Surface properties; Himawari-8; Hong-kong; Land surface temperature; Land use class; LANDSAT; Landsat-8; Mono-window algorithms; Retrieval algorithms; Split window algorithms; Temperature data; Landsat","Himawari-8; land surface temperature; Landsat-8; mono-window algorithm; split-window algorithm","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85138814022"
"Medina J.; Ardila O.; Upegui E.","Medina, Javier (57197825929); Ardila, Oscar (57212555178); Upegui, Erika (36459015100)","57197825929; 57212555178; 36459015100","Implementation and evaluation of the wavelet 2-D À trous transform using phyton and matlab for the fusion of worldview-2 satellite images; [Implementación y evaluación de la transformada wavelet 2-D à trous usando phyton y matlab para la fusión de imágenes satelitales worldview-2]","2020","RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao","2020","E27","","704","717","13","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081036844&partnerID=40&md5=2450e181355d9b4339f6a7b1fc83bd2d","This article develops the mathematical algorithm of the Wavelet 2-D Transform not decimated (À trous algorithm) for the fusion of satellite images. Throughout the article three important themes are addressed, the first theme corresponds to the mathematical detail to implement the fusion of images using the Wavelet À trous transform; and the second theme to the implementation of the mathematical development of the Wavelet 2-D Transform using free and proprietary Python and Matlab software respectively, using a WorldView-2 satellite image. And the third in order to determine the efficiency of the Wavelet À trous Transform. The two resulting images were evaluated in both spatial and spectral quality through four indices. The best results of the evaluation were obtained with the image fused with the À trous algorithm implemented in Matlab which preserves the spectral richness and improves its spatial quality. © 2020, Associacao Iberica de Sistemas e Tecnologias de Informacao. All rights reserved.","","Satellite-Image Fusion; Wavelet Transforms; WorldView-2; À trous","Article","Final","","Scopus","2-s2.0-85081036844"
"Uma Maheswari K.; Rajesh S.","Uma Maheswari, K. (57212793944); Rajesh, S. (55649569737)","57212793944; 55649569737","A novel QIM-DCT based fusion approach for classification of remote sensing images via PSO and SVM models","2020","Soft Computing","24","20","","15561","15576","15","10.1007/s00500-020-04884-x","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082977358&doi=10.1007%2fs00500-020-04884-x&partnerID=40&md5=5f518d162bc94bb359295a2e78617282","Fusion of panchromatic and multispectral images has become a research interest for the classification of remote sensing images. The spectral and spatial resolutions of different images give better information with the aid of image classification. However, fusing pixels for various satellite images is difficult due to the nature of original image consists of complex information. Similarly, most of the existing fusion algorithms implement a unified processing over the whole part of the image, thereby leaving certain important needs out of consideration. The main aim of our proposed approach is to fuse the images by gathering all important information from multiple images with minimum errors. In this paper, we propose a novel quantization index modulation with discrete contourlet transform-based fusion approach for classification of remote sensing images (LISS IV sensor). In order to improve the image fusion performance, we eliminate certain noises (salt, pepper, and Gaussian) using Bayesian filter with Adaptive Type-2 Fuzzy System. After image fusion, we make image classification by two steps of processes including deep multi-feature extraction and feature selection. Multiple features such as spectral, shape, global and local features are extracted using Affine Transformation (0°, 90°, 180°, and 270°), and then the best set of features are chosen by mutual information and maximal information coefficients. Finally, the image is classified into seven classes using PSO and SVM namely Urban, Vegetation, Wetland, Tank, Water Area, Bare Land, and Roadways. MATLAB R2017b has been used for evaluation of the LISS IV images. Experimental results revealed that our proposed approach is very effective in terms of their classification accuracy. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Adaptive filtering; Classification (of information); Feature extraction; Fuzzy filters; Image enhancement; Image fusion; Modulation; Particle swarm optimization (PSO); Remote sensing; Support vector machines; Vector quantization; Affine transformations; Classification accuracy; Classification of remote sensing image; Complex information; Contourlet transform; Multispectral images; Quantization index modulation; Type-2 fuzzy systems; Image classification","Bayesian filter with adaptive type-2 fuzzy system; Image classification and particle swarm optimization with support vector machine; Image fusion; Quantization index modulation with discrete contourlet transform","Article","Final","","Scopus","2-s2.0-85082977358"
"Shuangao W.; Padmanaban R.; Mbanze A.A.; Silva J.M.N.; Shamsudeen M.; Cabral P.; Campos F.S.","Shuangao, Wang (57222466743); Padmanaban, Rajchandar (57191844026); Mbanze, Aires A. (56912336500); Silva, João M. N. (55447844200); Shamsudeen, Mohamed (57219196731); Cabral, Pedro (56221630400); Campos, Felipe S. (48361058100)","57222466743; 57191844026; 56912336500; 55447844200; 57219196731; 56221630400; 48361058100","Using satellite image fusion to evaluate the impact of land use changes on ecosystem services and their economic values","2021","Remote Sensing","13","5","851","1","21","20","10.3390/rs13050851","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102768558&doi=10.3390%2frs13050851&partnerID=40&md5=ee5108eee0275b055f0fd381e3ca5464","Accelerated land use change is a current challenge for environmental management world-wide. Given the urgent need to incorporate economic and ecological goals in landscape planning, cost-effective conservation strategies are required. In this study, we validated the benefit of fusing imagery from multiple sensors to assess the impact of landscape changes on ecosystem services (ES) and their economic values in the Long County, Shaanxi Province, China. We applied several landscape metrics to assess the local spatial configuration over 15 years (2004–2019) from fused image-ries. Using Landsat-7 Enhanced Thematic Mapper Plus (ETM+), Landsat-8 Operational Land Im-ager (OLI) and Indian Remote Sensing Satellite System Linear Imaging Self Scanning Sensor 3 (IRS LISS 3) imageries fused for 2004, 2009, 2014 and 2019, we reclassified land use/land cover (LULC) changes, through the rotation forest (RF) machine-learning algorithm. We proposed an equivalent monetary metric for estimating the ES values, which also could be used in the whole China. Results showed that agriculture farmland and unused land decreased their spatial distribution over time, with an observed increase on woodland, grassland, water bodies and built-up area. Our findings suggested that the patterns of landscape uniformity and connectivity improved, while the distribution of landscape types stabilized, while the landscape diversity had a slight improvement. The overall ES values increased (4.34%) under a benefit transfer approach, mainly concerning woodland and grassland. A sensitivity analysis showed the selected economic value (EV) was relevant and suitable for the study area associated with our ES for LULC changes. We suggested that changes in landscape patterns affected the ESV trends, while the increases on some LULC classes slightly improved the landscape diversity. Using an interdisciplinary approach, we recommend that local au-thorities and environmental practitioners should balance the economic benefits and ecological gains in different landscapes to achieve a sustainable development from local to regional scales. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Agricultural robots; Communication satellites; Cost effectiveness; Ecosystems; Environmental management; Image enhancement; Image fusion; Land use; Learning algorithms; Machine learning; Remote sensing; Sensitivity analysis; Sustainable development; Urban planning; Conservation strategies; Ecosystem services; Indian remote sensing satellite; Land use/land cover; Landsat-7 (L7) Enhanced Thematic mapper plus (ETM+); Landscape diversity; Landscape planning; Spatial configuration; Economic analysis","Environmental monitoring; Image fusion; Landscape patterns; Remote sens-ing; Urban ecosystem services","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85102768558"
"Shunying W.; Ya'nan Z.; Xianzeng Y.; Li F.; Tianjun W.; Jiancheng L.","Shunying, Wang (58091004600); Ya'nan, Zhou (58033341100); Xianzeng, Yang (58091795500); Li, Feng (58091342300); Tianjun, Wu (57223986312); Jiancheng, Luo (8251026800)","58091004600; 58033341100; 58091795500; 58091342300; 57223986312; 8251026800","BSNet: Boundary-semantic-fusion network for farmland parcel mapping in high-resolution satellite images","2023","Computers and Electronics in Agriculture","206","","107683","","","","10.1016/j.compag.2023.107683","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147424676&doi=10.1016%2fj.compag.2023.107683&partnerID=40&md5=c627d74c63a60862e218ae2f906f78d5","Mapping farmland parcels using satellite images is essential for agricultural remote sensing applications. Loss of spatial details and positioning of parcel boundaries are the main challenges in available deep convolution network (DCN) models. This study developed a boundary-semantic-fusion DCN (BSNet) model for delineating farmland parcels from high-resolution satellite images. Central to this method is the combination between shallow-level boundary features with accurate spatial positioning and deep-level semantic features for category identification. First, a general deep convolution framework consisting of boundary, semantic and fusion blocks was implemented for farmland parcel mapping. Second, a particular serial structure with a detaching operation for linking the boundary and semantic blocks was explored to maintain the spatial details and fine-scale boundaries in feature learning. Third, an encoder-decoder fusion block was developed to integrate the boundary and semantic features to produce the final parcel maps. We validated the proposed model with different high-resolution satellite images in two study areas. The experimental results, with improvements greater than 4% in the F1 score and 6% in the IoU score relative to other comparative methods, illustrate the effectiveness of the proposed model for fine-scale farmland parcel mapping. © 2023 Elsevier B.V.","Farms; Image fusion; Mapping; Remote sensing; Satellites; Semantic Segmentation; Semantic Web; Semantics; Boundary extraction; Farmland parcel; Fine-scale; Fusion network; High resolution satellite images; High-resolution images; Satellite images; Semantic features; Semantic fusion; Semantic segmentation; agricultural land; artificial neural network; image resolution; mapping method; remote sensing; satellite imagery; Convolution","Boundary extraction; Farmland parcel; Fusion networks; High-resolution images; Semantic segmentation","Article","Final","","Scopus","2-s2.0-85147424676"
"Datta U.","Datta, U. (7007098861)","7007098861","Multimodal change monitoring using multitemporal satellite images","2021","Proceedings of SPIE - The International Society for Optical Engineering","11862","","118620M","","","","10.1117/12.2600099","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118562976&doi=10.1117%2f12.2600099&partnerID=40&md5=b8701ca19db314f013b32048a2075cc9","The main objective of this study is to monitor the land infrastructure growth over a period of time using multimodality of remote sensing satellite images. In this project unsupervised change detection analysis using ITPCA (Iterated Principal Component Analysis) is presented to indicate the continuous change occurring over a long period of time. The change monitoring is pixel based and multitemporal. Co-registration is an important criteria in pixel based multitemporal image analysis. The minimization of co-registration error is addressed considering 8-neighborhood pixels. Comparison of results of ITPCA analysis with LRT (likelihood ratio test) and GLRT (generalized likelihood ratio test) methods used for SAR and MS (Multispectral) images respectively in earlier publications are also presented in this paper. The datasets of Sentinel-2 around 0-3 days of the acquisition of Sentinel-1 are used for multimodal image fusion. SAR and MS both have inherent advantages and disadvantages. SAR images have the advantage of being insensitive to atmospheric and light conditions, but it suffers the presence of speckle phenomenon. In case of multispectral, challenge is to get quite a large number of datasets without cloud coverage in region of interest for multivariate distribution modelling.  © 2021 SPIE.","Image analysis; Image fusion; Image segmentation; Large dataset; Pixels; Radar imaging; Remote sensing; Synthetic aperture radar; Change detection; Coregistration; Generalized Likelihood Ratio Test; Iterated principal component analyse; Likelihood ratio tests; Multi-modal; Multi-spectral; Principal-component analysis; SAR; SAR Images; Principal component analysis","Change detection; GLRT; ITPCA; LRT; Multimodal; Multispectral; SAR","Conference paper","Final","","Scopus","2-s2.0-85118562976"
"Vakilian A.A.; Saradjian M.R.","Vakilian, A. Asefpour (58080930700); Saradjian, M.R. (8397399100)","58080930700; 8397399100","OPTIMIZATION OF THE SPARSE REPRESENTATION PARAMETERS FOR THE FUSION OF REMOTELY SENSED SATELLITE IMAGES","2023","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","10","4/W1-2022","","71","77","6","10.5194/isprs-annals-X-4-W1-2022-71-2023","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146920676&doi=10.5194%2fisprs-annals-X-4-W1-2022-71-2023&partnerID=40&md5=904f437bdf8e381d162ab1ceadc31f47","Image fusion methods are widely used in remote sensing applications to obtain more information about the features in the study area. One of the recent satellite image fusion techniques that can deal with noise and reduce computational cost and deal with geometric misregistration is sparse representation model. The important part of creating a generalized sparse representation model for satellite image fusion problems is defining initial constraints and adjusting the corresponding regularization coefficients. Regularization coefficients play an essential role in the performance of the sparse representation model and convergence of the optimization solution. Also, the number and size of sub-images extracted from the dictionary matrix in the sparse representation model, and the number of iterations of the optimization step are important in building a sparse representation model. Therefore, in this research, the four parameters that affect the performance of the sparse representation model were investigated: the number of sub-images, the size of sub-images, regularization coefficients, and the number of iterations. Results obtained from pan-sharpening of OLI-8 images showed that optimal values for the number and size of sub-images, regularization coefficients, and the number of iterations were equal to 150, 9×9 pixels, 10-4, and 4 respectively. Results from this study can be generalized to other satellite image fusion problems using sparse representation models. © Author(s) 2023. CC BY 4.0 License.","Remote sensing; Satellites; Constraint; Number of iterations; Optimisations; Performance; Regularisation; Regularization coefficients; Representation model; Satellite images; Sparse representation; Subimages; Image fusion","Constraints; Fusion; Optimization; Regularization; Satellite Image; Sparse Representation","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85146920676"
"","","","6th International Conference on Advanced Computing, Networking, and Informatics, ICACNI 2018","2020","Advances in Intelligent Systems and Computing","766","","","","","317","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079766014&partnerID=40&md5=df464e123adbcdd105b6847f5259ba20","The proceedings contain 27 papers. The special focus in this conference is on Advanced Computing, Networking, and Informatics. The topics include: Hash Code Based Image Authentication Using Rotation Invariant Local Phase Quantization; novel Competitive Swarm Optimizer for Sampling-Based Image Matting Problem; note Transcription from Carnatic Music; sentence-Based Dialect Identification System Using Extreme Gradient Boosting Algorithm; characterization of Consonant Sounds Using Features Related to Place of Articulation; named Entity Recognition Using Part-of-Speech Rules for Telugu; objective Assessment of Pitch Accuracy in Equal-Tempered Vocal Music Using Signal Processing Approaches; gibbs Sampled Hierarchical Dirichlet Mixture Model Based Approach for Clustering Scientific Articles; experimental Evaluation of Dynamic Typing Mechanism: A Case Study; A Robust and Blind Watermarking for Color Videos Using Redundant Wavelet Domain and SVD; integrating Digital Forensics and Digital Discovery to Improve E-mail Communication Analysis in Organisations; speaker Verification Systems: A Comprehensive Review; A Fast Method for Segmenting ECG Waveforms; Removal of Eye-Blink Artifact from EEG Using LDA and Pre-trained RBF Neural Network; skin Cancer Detection Using Advanced Imaging Techniques; auto-associative Neural Network Based Concrete Crack Detection; image Filter Selection, Denoising and Enhancement Based on Statistical Attributes of Pixel Array; Enhanced Security Credentials for Image Steganography Using QR Code; Clustering-Based Melanoma Detection in Dermoscopy Images Using ABCD Parameters; optimized Object Detection Technique in Video Surveillance System Using Depth Images; automated Histogram-Based Seed Selection for the Segmentation of Natural Scene; application of Image Fusion Approaches for Image Differencing in Satellite Images; a Novel Method for Detecting Bone Contours in Hand Radiographic Images.","","","Conference review","Final","","Scopus","2-s2.0-85079766014"
"Naik S.K.; Ramesh H.","Naik, Sushmita K. (57456969600); Ramesh, H. (56494595300)","57456969600; 56494595300","Satellite Image Fusion using FDCT for Land Cover Classification","2021","2021 IEEE 6th International Conference on Computing, Communication and Automation, ICCCA 2021","","","","81","86","5","10.1109/ICCCA52192.2021.9666283","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124803009&doi=10.1109%2fICCCA52192.2021.9666283&partnerID=40&md5=183f5fc0906c1e896a6e3112335505bb","Remote sensing is a fast developing field of science involving repetitive collection of data from earth observing satellites. However each satellite system has one or more limitations, giving rise to the need of data collection from multiple sources and their fusion. Landsat 8 collects images in a broad spectrum but at a coarser spatial resolution of 30m. Cartosat-1 collects images at a high spatial resolution of 2.5m but lacks color details. Good visually interpretable images are indispensable for land cover classification. In this paper, the Landsat 8 and Cartosat-1 images are fused by using the Fast Discrete Curvelet Transform (FDCT) method. Supervised classification using the Random Forest (RF) classifier is performed on the Landsat 8 multispectral image and the fused image. The results showed high quality of image fusion based on the entropy, RMSE and CC values obtained for the given dataset. The fusion process also improved the overall accuracy of the land cover classification.  © 2021 IEEE.","Data acquisition; Decision trees; Image classification; Image resolution; Remote sensing; Satellites; Cartosat-1; Curvelet transforms; Data collection; Earth observing satellite; Land cover classification; LANDSAT; Remote-sensing; Satellite image fusion; Satellite images; Satellite system; Image fusion","Land cover classification; Satellite image fusion","Conference paper","Final","","Scopus","2-s2.0-85124803009"
"Xia Z.; Liu J.; Chen X.; Li X.; Chen P.","Xia, Zhiwei (57997828400); Liu, Jun (57196294334); Chen, Xiao (57221569086); Li, Xin (57541575400); Chen, Peng (57226026284)","57997828400; 57196294334; 57221569086; 57541575400; 57226026284","Airplane Object Detection in Satellite Images Based on Attention Mechanism and Multi-scale Feature Fusion","2022","2022 4th International Conference on Robotics and Computer Vision, ICRCV 2022","","","","142","147","5","10.1109/ICRCV55858.2022.9953228","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143623823&doi=10.1109%2fICRCV55858.2022.9953228&partnerID=40&md5=49f3906b3b291c4f1324069a3931e629","The order of magnitude of object detection instances in satellite images is larger than that in conventional images, and many small object instances are clustered together in satellite images. Most objects in conventional object detection datasets are perpendicular to the ground, while objects in satellite images are parallel to the ground and their orientation varies greatly. Conventional detection with horizontal bounding box, a horizontal bounding box may contain multiple dense instances and may contain a lot of background information, resulting in a disproportionate proportion of the background in the detection box. The oriented bounding box helps to locate the object more accurately and obtain the azimuth information of the object more easily. Therefore, in this work, we used oriented bounding boxes to detect airplane objects in satellite images. In order to target the detection of airplane objects, we produced a high-resolution dataset containing only airplane objects and more small instances. We use ResNet as backbone and FPN as Neck. By adding an SE Block module after each stage of ResNet to pay attention to important features, and connecting a pyramid convolution (PConv) module after FPN to enhance feature fusion. Cropping the input image to 1024*1024 using a sliding window allowed detection accuracy improved on DOTA v1.0(90.53 mAP) and our own dataset Satellite-Airplane2309(83.48 mAP) on the GTX TITAN X.  © 2022 IEEE.","Aircraft; Aircraft detection; Convolution; Image enhancement; Image fusion; Image segmentation; Object recognition; Satellites; Airplane objects; Attention mechanisms; Bounding-box; Features fusions; Image-based; Objects detection; Oriented bounding box; Pyramid convolution; Satellite images; SE block; Object detection","oriented bounding box; pyramid convolution; satellite images; SE Block","Conference paper","Final","","Scopus","2-s2.0-85143623823"
"Xie H.; Hu X.; Jiang H.; Zhang J.","Xie, Haofeng (57561987100); Hu, Xiangyun (7404709263); Jiang, Huiwei (57215435747); Zhang, Jinming (57218508349)","57561987100; 7404709263; 57215435747; 57218508349","BSSNet: Building Subclass Segmentation From Satellite Images Using Boundary Guidance and Contrastive Learning","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","7700","7711","11","10.1109/JSTARS.2022.3202524","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137876616&doi=10.1109%2fJSTARS.2022.3202524&partnerID=40&md5=c5f8234d122ee5f049ea2d49330ac106","Building subclass segmentation, aimed at predicting classes of buildings (high-rise zone, low-rise zone, single high-rise, and single low-rise) from satellite images, is beneficial in numerous applications, including human geography, urban planning, and humanitarian aid. However, problems, such as complex scenes and similar characteristics of different building categories make it difficult for general models to balance the accuracy of localization and classification in building subclass segmentation. Therefore, this article proposes a novel network for building subclass segmentation called building subclass segmentation network (BSSNet), which uses two subnetworks to divide and conquer the problem. The first network guides the building locations through binary building segmentation, called localization network. The spatial gradient fusion module in the localization network improves the binary segmentation result by supervising the spatial gradient map of prediction. The second network is a classification network, which predicts building subclasses. Intermediate features of the second network are optimized by contrastive learning loss to improve feature consistency. Finally, predictions of the two networks are combined to obtain the final result. The experimental results demonstrate that our BSSNet can perform significant improvements on the Hainan dataset we produced and the xBD dataset. In particular, the BSSNet achieves the best performance compared to current methods on the Hainan dataset.  © 2008-2012 IEEE.","China; Hainan; Buildings; Forecasting; Image fusion; Image segmentation; Job analysis; Neural networks; Remote sensing; Satellites; Building subclass segmentation; Contrastive learning loss; Convolutional neural network; Features fusions; Head; Images segmentations; Location awareness; Remote-sensing; Satellite images; Spatial gradient fusion; Spatial gradients; Task analysis; artificial neural network; classification; data set; experimental study; remote sensing; satellite imagery; segmentation; spatial analysis; Semantics","Building subclass segmentation; contrastive learning loss; convolutional neural network (CNN); feature fusion; satellite image; spatial gradient fusion (SGF)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85137876616"
"Asokan A.; Anitha J.","Asokan, Anju (57190950323); Anitha, J. (57204786853)","57190950323; 57204786853","Satellite Image Enhancement Using Hybrid Denoising Method for Fusion Application","2020","Advances in Intelligent Systems and Computing","1119","","","115","123","8","10.1007/978-981-15-2414-1_12","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083337360&doi=10.1007%2f978-981-15-2414-1_12&partnerID=40&md5=891943d2ffd740c9b6e2afbd76dececa","Image fusion involves combining useful details from input images into a single image and the image can convey the complete particulars. Image fusion finds wide application in remote sensing, change detection, and medical imaging. The presence of noise in the input images limits the accuracy of fusion. To overcome this limitation, a hybrid filtering technique using gradient and guided filter is proposed to fuse satellite data. Source images are denoised using a hybrid filtering framework comprising of a gradient filter followed by an edge-preserving guided filter. The denoised images are fused using the traditional discrete wavelet transform. The results are compared against the fused outputs for traditional filters like median filter, Wiener filter, and guided filter by computing performance metrics such as entropy, Peak Signal-to-Noise Ratio(PSNR), Structural Similarity Index (SSIM), Feature Similarity Index (FSIM), gradient-based quality index (QAB/F), and CPU time. The results show that the hybrid filtering based fusion outperforms other filtering-based fusion techniques. © 2020, Springer Nature Singapore Pte Ltd.","Discrete wavelet transforms; Image denoising; Image fusion; Image segmentation; Median filters; Medical imaging; Remote sensing; Signal to noise ratio; Computing performance; Denoising methods; Feature similarities; Fusion applications; Fusion techniques; Peak signal to noise ratio; Structural similarity indices (SSIM); Traditional filter; Image enhancement","Gradient filter; Guided filter; Image fusion; Multitemporal; Remote sensing; Wiener filter","Conference paper","Final","","Scopus","2-s2.0-85083337360"
"Swathika R.; Sharmila T.S.","Swathika, R. (55823315000); Sharmila, T. Sree (55337283900)","55823315000; 55337283900","Multi-model fusion based satellite image classification using versatile unsupervised vector zone (VUVZ) fusion and intensive pragmatic blossoms (IPB) technique","2020","Multimedia Tools and Applications","79","5-6","","4239","4260","21","10.1007/s11042-019-07872-y","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071041527&doi=10.1007%2fs11042-019-07872-y&partnerID=40&md5=6c9bc28f9ab9ee09f9deb45f56aed8bb","To get the result if satellite image classification in precisely the image fusion method is widely used. The satellite images at different spectral and spatial resolutions with the guide of image handling strategies can improve the idea of data. For the most part image fusion is important to expel the spatial data from two images of different spatial, spectral and worldly images of a comparable zone. A task of image examination, for instance, image order on fused images gives better results in contrast with one of a kind data. In this work versatile unsupervised vector zone (VUVZ) method have been used for image fusion. The resultant images have been classified using the supervised classification with Intensive Pragmatic Blossoms (IPB) rule for information extraction and comparison between them regarding their accuracy. In This work describes a case study of micro seepage signals detection in the land, using multi-sensor satellite time series based on linear iterative segmentation (LIS) and Intensive Pragmatic Blossoms (IPB). Results show that the spectral anomalies identified from a satellite are closely correlated to the known oilfields and that the micro seepage maps can produce new high-quality data to reduce exploration risk. The simulation work classification accuracy of 94.12% which is much better than past outcomes in this engaged field of research. The execution of the usage is analyzed, an examination is likewise influenced concerning the clustering precision, time complexity, and false proportion are introduced. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Classification (of information); Fusion reactions; Image classification; Image enhancement; Iterative methods; Micro satellites; Petroleum prospecting; Seepage; Classification accuracy; Image fusion methods; Intensive pragmatic blossoms; Iterative clustering; Iterative segmentation; Satellite image classification; Supervised classification; Temporal filters; Image fusion","Fusion; Intensive pragmatic blossoms; Linear iterative clustering; Temporal filter","Article","Final","","Scopus","2-s2.0-85071041527"
"Darbari P.; Kumar M.","Darbari, Priyanka (57697976300); Kumar, Manoj (57226488915)","57697976300; 57226488915","Satellite Image Enhancement Techniques: A Comprehensive Review","2022","Lecture Notes in Networks and Systems","435","","","431","447","16","10.1007/978-981-19-0976-4_36","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130305155&doi=10.1007%2f978-981-19-0976-4_36&partnerID=40&md5=e41c946097afd7181f7a0b940041f972","Satellite images are useful in various domain areas. In satellite images resolution is the major challenging issue because of huge distance, atmospheric changes, clouds, different air devices (drones, aeroplanes). Image enhancement is a technique of image processing for better image visualization, noise removing, other air facts. Image enhancement is applied after image acquisition using different sensors. In this paper, an introduction about satellite image acquisition, image enhancement techniques, survey of different techniques of satellite image enhancement is discussed with their advantages and disadvantages. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","","Image enhancement; Image fusion; Satellite image acquisition; Satellite image enhancement","Conference paper","Final","","Scopus","2-s2.0-85130305155"
"Samadzadegan F.; Toosi A.; Javan F.D.; Stein A.","Samadzadegan, F. (55898340800); Toosi, A. (57216339698); Javan, F. Dadrass (58080784400); Stein, A. (7401758587)","55898340800; 57216339698; 58080784400; 7401758587","DECISION-BASED FUSION OF PANSHARPENED VHR SATELLITE IMAGES USING TWO-LEVEL ROLLING SELF-GUIDANCE FILTERING AND EDGE INFORMATION","2023","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","10","4/W1-2022","","691","698","7","10.5194/isprs-annals-X-4-W1-2022-691-2023","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146926321&doi=10.5194%2fisprs-annals-X-4-W1-2022-691-2023&partnerID=40&md5=17d28a9ab35ccda2727ceaf8a2a3cb0e","Pan-sharpening (PS) fuses low-resolution multispectral (LR MS) images with high-resolution panchromatic (HR PAN) bands to produce HR MS data. Current PS methods either better maintain the spectral information of MS images, or better transfer the PAN spatial details to the MS bands. In this study, we propose a decision-based fusion method that integrates two basic pan-sharpened very-high-resolution (VHR) satellite imageries taking advantage of both images simultaneously. It uses two-level rolling self-guidance filtering (RSGF) and Canny edge detection. The method is tested on Worldview (WV)-2 and WV-4 VHR satellite images on the San Fransisco and New York areas, using four PS algorithms. Results indicate that the proposed method increased the overall spectral-spatial quality of the base pan-sharpened images by 7.2% and 9.8% for the San Fransisco and New York areas, respectively. Our method therefore effectively addresses decision-level fusion of different base pan-sharpened images. © Author(s) 2023. CC BY 4.0 License.","Edge detection; Information filtering; Satellite imagery; Canny edge detectors; Decision-based; Guided filters; High resolution imagery; Pan-sharpened; Pan-sharpening; Self guidances; Very high resolution; Very high resolution satellite images; Very-high-resolution imagery; Image fusion","Canny Edge Detector; Guided Filter; Image Fusion; Pansharpening; Very-high-resolution Imagery","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85146926321"
"Al-Jasim A.A.N.; Naji T.A.; Shaban A.H.","Al-Jasim, Ali Adnan N. (57210174445); Naji, Taghreed Abdulhameed (57202456578); Shaban, Auday H. (57195675596)","57210174445; 57202456578; 57195675596","The Effect of Using the Different Satellite Spatial Resolution on the Fusion Technique; [تأثير استخدام الدقة المكانية المختلفة للقمر الصناعي على تقانة الاندماج]","2022","Iraqi Journal of Science","63","9","","4131","4141","10","10.24996/ijs.2022.63.9.40","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139567980&doi=10.24996%2fijs.2022.63.9.40&partnerID=40&md5=6cb022d2e66cab425c4d97f126435a65","Bilinear interpolation and use of perceptual color spaces (HSL, HSV, LAB, and LUV) fusion techniques are presented to improve spatial and spectral characteristics of the multispectral image that has a low resolution to match the high spatial resolution of a panchromatic image for different satellites image data (Orbview-3 and Landsat-7) for the same region. The Signal-to-Noise Ratio (SNR) fidelity criterion for achromatic information has been calculated, as well as the mean color-shifting parameters that computed the ratio of chromatic information loss of the RGB compound inside each pixel to evaluate the quality of the fused images. The results showed the superiority of HSL color space to fuse images over the rest of the spaces, as it recorded the highest SNR and the lowest mean color-shifting. The quality of the fused images using Lab color space was not affected by the type of intermediate algorithm used for XYZ space, unlike LUV color space. The XYZ algorithm type affected the fused image results, which recorded the worst consequences. It is noted that the computational time taken increased exponentially with the difference in spatial resolution between the fused images. © 2022 University of Baghdad-College of Science. All rights reserved.","","bilinear interpolation technique; HSL; HSV; Image fusion; Lab; LUV perceptual color spaces; Orbview-3 image data; RGB color space; up-sampling process","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85139567980"
"Verma H.C.; Ahmed T.; Rajan S.; Hasan M.K.; Khan A.; Gohel H.; Adam A.","Verma, Harish Chandra (56604746900); Ahmed, Tasneem (55549594300); Rajan, Shailendra (55249900000); Hasan, Mohammad Kamrul (55057479600); Khan, Asif (56602074400); Gohel, Hardik (57195539048); Adam, Afzan (57188569603)","56604746900; 55549594300; 55249900000; 55057479600; 56602074400; 57195539048; 57188569603","Development of LR-PCA Based Fusion Approach to Detect the Changes in Mango Fruit Crop by Using Landsat 8 OLI Images","2022","IEEE Access","10","","","85764","85776","12","10.1109/ACCESS.2022.3194000","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135758692&doi=10.1109%2fACCESS.2022.3194000&partnerID=40&md5=230a651aa55745a7fcaf1f3a99795738","Change detection (CD) is the process of detecting changes from multi-temporal satellite images that have undergone spatial changes due to natural phenomena and/or human-induced activities. Mango is a major fruit crop in India, but detection of changes in mango crops remains a challenging task because the reason that many perennial crops have similar reflectance profiles. Therefore, a potent change detection technique is required for different applications such as the rate of deforestation, urban developments, damage evaluation, and resource monitoring. Compared to annual and seasonal crops, relatively few studies have been conducted on change detection in perennial fruit crops. In this study, a novel log ratio change detection technique (i.e., LR-PCA) is developed using the fusion of log-ratio (LR) and principal component analysis (PCA) images derived from bi-temporal soil adjusted vegetation index (SAVI) images to extract meaningful information and detect temporal changes in the mango fruit crop areas with high change detection accuracy. The proposed approach comprised two steps: (1) SAVI images from 2015 and 2019 were used to retrieve the log-ratio (LR) and principal component (PC) images, respectively, and both the images were fused by applying the pixel-by-pixel fusion approach. (2) Fused images were classified into three classes: 'positive change', 'no change', and 'negative change' using a derived threshold value. The results show that the LR-PCA method of change detection yields a high change detection accuracy of 92% in comparison with the other change detection methods viz. vegetation image differencing, image ratioing, PCA, and log-ratio. To validate the adaptability of the proposed algorithm, experiments with two sets of bi-temporal SAVI indices images belonging to the Sitapur district of Uttar Pradesh State determine that the proposed change detection method performs well as compared to the existing individual methods for detection of changes in mango fruit crop. The proposed method is expected to be useful for detecting changes in the area of perennial crops. In the future, an accurate and efficient change detection analysis may be helpful for developing a real-time mango fruit crop monitoring system at the national level.  © 2013 IEEE.","Change detection; Crops; Damage detection; Deforestation; Fruits; Image analysis; Image fusion; Pixels; Principal component analysis; Remote sensing; Urban growth; Vegetation mapping; Change detection; LANDSAT; Landsat 8 OLI; Log ratio; Mango crop; Principal-component analysis; Remote-sensing; Satellite broadcasting; Vegetation mapping; Landsat","Change detection; Landsat 8 OLI; Log ratio; Mango crop; Principal component analysis","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85135758692"
"Shen K.; Yang X.; Li Z.; Jiang J.; Jiang F.; Ren H.; Li Y.","Shen, Kangqing (57219194394); Yang, Xiaoyuan (35217321600); Li, Zhengze (57207913633); Jiang, Jin (57211559925); Jiang, Fazhen (57218705046); Ren, Huwei (57241368000); Li, Yixiao (57246930500)","57219194394; 35217321600; 57207913633; 57211559925; 57218705046; 57241368000; 57246930500","DOCSNet: a dual-output and cross-scale strategy for pan-sharpening","2022","International Journal of Remote Sensing","43","5","","1609","1629","20","10.1080/01431161.2022.2042618","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127080978&doi=10.1080%2f01431161.2022.2042618&partnerID=40&md5=f16dab8823e05ac70807348baf45d298","Pan-sharpening aims to obtain a multi-spectral image of high resolution from inputs of a high spatial resolution panchromatic image and a low spatial resolution multi-spectral image. In recent years, pan-sharpening methods based on supervised learning have achieved superior performance over traditional methods. However, all these supervised pan-sharpening methods rest upon the assumption that performance of model trained on a coarse scale can generalize well on a finer one, which is not always the case. To address this problem, we propose a novel dual-output and cross-scale learning strategy DOCSNet for pan-sharpening. DOCSNet consists of two sub-networks, ReducedNet1 and FullNet2, which are both adapted from simple three convolutional layers and progressively cascaded. ReducedNet1 is first trained on the reduced-scale training set, its parameters are frozen, and then the whole network (fixed ReducedNet1 cascaded with FullNet2) adopts a cross-scale training strategy which involves simultaneously reduced and full resolution training samples. Each sub-network has an output terminal for reduced-scale and target-scale results, respectively. To the best of our knowledge, this is the first attempt to introduce a dual-output architecture to pan-sharpening framework. Extensive experiments on GaoFen-2 and WorldView-3 satellite images demonstrate that DOCSNet outperforms other state-of-the-art pan-sharpening methods in terms of qualitative visual effects and quantitative metrics evaluations. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Convolution; Deep neural networks; Image fusion; Image resolution; Spectroscopy; Convolutional neural network; Deep learning; Dual outputs; High resolution; Multispectral images; Pan-sharpening; Performance; Reduced scale; Remote-sensing; Subnetworks; artificial neural network; image resolution; machine learning; remote sensing; spatial resolution; Remote sensing","convolutional neural network; deep learning; image fusion; Pan-sharpening; remote sensing","Article","Final","","Scopus","2-s2.0-85127080978"
"Sulaiman A.G.; Elashmawi W.H.; Eltaweel G.","Sulaiman, Asmaa G. (57212140146); Elashmawi, Walaa H. (55350799600); Eltaweel, Gh.S. (57215425539)","57212140146; 55350799600; 57215425539","IHS-based pan-sharpening technique for visual quality improvement using KPCA and enhanced SML in the NSCT domain","2021","International Journal of Remote Sensing","42","2","","537","566","29","10.1080/01431161.2020.1811913","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096695788&doi=10.1080%2f01431161.2020.1811913&partnerID=40&md5=e5f3b999f67cee2423ff064524bd6126","Due to the different characteristics of satellite imagery, pan-sharpening has become an important field of remote sensing science. It is a reliable method to fuse the high-resolution panchromatic (Pan) image with the low-resolution multispectral (MS) images to generate a composite high-resolution MS (pan-sharpened) image. In this paper, we propose a robust pan-sharpening technique which combines the nonsubsampled contourlet transform (NSCT) with kernel principal component analysis (KPCA). An enhancement method is executed on the source MS image to retain the maximum spatial information present in the MS bands based on the intensity hue saturation (IHS) colour space transform. The proposed pan-sharpening technique is performed as follows: first, the source Pan and MS images are divided into high and low-pass coefficients by NSCT. Second, KPCA is used to propose an effective fusion rule for choosing appropriate low-pass NSCT coefficients for fusion. The high-pass coefficients are fused by proposing an enhanced sum modified Laplacian method (SML). Finally, the final pan-sharpened image is obtained by performing an inverse NSCT and inverse IHS transform on the fused low and high-pass coefficients. Four different groups of satellite image datasets are utilized in the experiments, which show that the proposed technique can both preserve the spatial details of the source images well and avoid spectral distortion. In addition, different image fusion quality metrics are adopted to evaluate the spectral and spatial qualities of the pan-sharpened image. Compared to the state-of-the-art pan-sharpening methods, the proposed technique achieved better performance in balancing spectral and spatial information and improved pan-sharpening results in terms of both visual quality and objective measurements. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","Image fusion; Inverse problems; Quality control; Remote sensing; Satellite imagery; Colour space transform; Intensity hue saturations; Kernel principal component analyses (KPCA); Non subsampled contourlet transform (NSCT); Objective measurement; Panchromatic (Pan) image; Spectral distortions; Sum-Modified-Laplacian; data set; Laplace transform; principal component analysis; qualitative analysis; remote sensing; satellite imagery; spatial data; visual analysis; Image enhancement","","Article","Final","","Scopus","2-s2.0-85096695788"
"Dao P.D.; Mong N.T.; Chan H.-P.","Dao, Phuong D. (56659285100); Mong, Ngoc Thi (57188881249); Chan, Hai-Po (56071008700)","56659285100; 57188881249; 56071008700","Landsat-MODIS image fusion and object-based image analysis for observing flood inundation in a heterogeneous vegetated scene","2019","GIScience and Remote Sensing","56","8","","1148","1169","21","10.1080/15481603.2019.1627062","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067578032&doi=10.1080%2f15481603.2019.1627062&partnerID=40&md5=acc1f0ed9ec3298dac693f015a256922","Typhoon flooding normally occurs suddenly with short duration, and the thick cloud cover limits the ability of one single satellite to timely capture the inundation extent. Landsat satellite data with a spatial resolution of 30 m is spatially applicable for flooding research; however, its 16-day observation frequency is typically insufficient to observe short-term typhoon inundation. Alternatively, despite the coarse spatial resolutions, the Moderate Resolution Imaging Spectroradiometer (MODIS) sensor provide daily data, which is well suited for flood-related investigations. Accordingly, the idea of combining these two sources of data to generate a high spatial and temporal image would be useful. In this study, the Enhanced Spatial and Temporal Adaptive Reflectance Fusion Model (ESTARFM) was applied to generate cloud-free Landsat/MODIS synthesized data with a spatial resolution of 30 m for the delineation of the inundated areas during a flood event. This approach produces a Landsat-scale image for fine-scale flood mapping of areas where there are no observed cloud-free Landsat or similar resolution satellite images. The fusion model was implemented on atmospherically corrected surface reflectance, and the resultant reflectance values were validated by comparing with observed Landsat reflectance before further data interpretation. The blending results indicate that the synthetic Landsat-scaled image is highly correlated with Landsat surface reflectance, captured a day after the synthetic image acquisition date, over cloud-free areas. For image interpretation, an object-based image analysis (OBIA) approach with an optimal-scale segmentation and the support vector machine (SVM) classifier was applied for flood classification. The flood mapping result was validated by comparing with a reference flood map derived from an observed Landsat image. This study demonstrates that the techniques of image fusion and object-based image analysis are useful for observing flood inundation in the heterogeneous vegetated area. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","flooding; image analysis; Landsat; MODIS; satellite data; satellite imagery; spatiotemporal analysis; support vector machine; vegetation cover","ESTARFM image fusion; flood mapping; Landsat; MODIS; OBIA","Article","Final","","Scopus","2-s2.0-85067578032"
"Suarez P.; Medina J.","Suarez, Paola (57219662309); Medina, Javier (57197825929)","57219662309; 57197825929","Location of tourist areas: Green areas and natural parks in the city of Bucaramanga and the metropolitan area from the fusion of sentinel2b and landsat-8 satellite images; [Localización de zonas turísticas: Zonas verdes y parques naturales en la ciudad de bucaramanga y área metropolitana a partir de fusión de imágenes satelitales sentinel-2b y landsat-8]","2020","RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao","2020","E36","","270","281","11","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094614082&partnerID=40&md5=7da47b9df5b935fc2f872aadb076adc6","In this article, a thematic map is generated with the location of green areas and natural parks in the city of Bucaramanga and its metropolitan area of Girón from satellite images of free use from fusion methods and the wavelet haar transform in order to enhance the benefits of the spatial and spectral characteristics of these and obtain a thematic map that allows locating green areas and natural parks in the city of Bucaramanga and its metropolitan area of Girón in order to promote ecotourism in the city and show the advantages of this type of free access images. The city of Bucaramanga has always been recognized as the beautiful city of parks, with a large number of green areas of great attraction for tourists who often do not know where these areas are located, which is why with this map thematic it is very easy to locate the parks in order to structure a tourist trip to these areas. To carry out this thematic map, a mathematical introduction to implement the image fusion using the wavelet transform will first be addressed. The second theme corresponds to the implementation of the mathematical development of the wavelet transform using Matlab software and Sentinel-2 and Landsat-8 satellite images. The third theme corresponds to the analysis and evaluation of the transformations to determine their efficiency and the generation of the final map. Obtaining an updated map, with free access images, ideal to locate the green areas of the city of Bucaramanga and Giron and encourage tourism to these points of great interest. © 2020, Associacao Iberica de Sistemas e Tecnologias de Informacao. All rights reserved.","","Green areas; Image fusion; Parks; Tourism; Wavelet Transformation","Article","Final","","Scopus","2-s2.0-85094614082"
"Yuan Y.; Sun B.; Liu G.","Yuan, Yuan (57203237779); Sun, Bo (57199831810); Liu, Ganchao (55857516300)","57203237779; 57199831810; 55857516300","Dual attention and dual fusion: An accurate way of image-based geo-localization","2022","Neurocomputing","500","","","965","977","12","10.1016/j.neucom.2022.05.013","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131720157&doi=10.1016%2fj.neucom.2022.05.013&partnerID=40&md5=e654110c900452b89e4b72b5a83861a7","When GPS signal is interfered or lost, the visual geo-localization method is particularly important for Unmanned Aerial Vehicle (UAV). Since matching UAV images with satellite maps is a multi-source and multi-view problem, visual geo-localization is very challenging. Most existing methods use Convolutional Neural Network (CNN), which extract the final output of the backbone Network to predict the similarity between UAV images and satellite maps. Due to continuous stacked convolution and pooling, rich local information is gradually lost while semantic information is acquired. To solve this problem, a dual attention and dual fusion (DADF) scene matching algorithm is proposed. The contributions of this paper are as follows: 1) In order to achieve accurate matching between UAV and satellite images, a visual geo-localization algorithm based on siamese network is designed. 2) In order to improve the ability of semantic feature extraction, a dual-attention model is constructed. The network pays more attention to the parts that are useful for similarity metric. 3) A dual fusion model is established. According to the feature fusion method and multi-level matching result fusion algorithm, the confidence of matching is improved. To verify the performance of the proposed approach, LA850 and NWPU-ChangAn datasets were collected and enhanced. The experimental results show that the proposed algorithm is more efficient than comparison algorithms. © 2022","Antennas; Convolution; Image fusion; Satellites; Semantics; Attentional mechanism; Decisions fusion; Geo-localisation; GPS signals; Image-based; Localization method; Matchings; Multi-Sources; Scene matching; Vehicle images; algorithm; article; attention; feature extraction; satellite imagery; unmanned aerial vehicle; Unmanned aerial vehicles (UAV)","Attentional mechanism; Decision fusion; Geo-localization; Scene matching","Article","Final","","Scopus","2-s2.0-85131720157"
"Reza Ghafarian Malamiri H.; Arabi Aliabad F.; Shojaei S.; Morad M.; Band S.S.","Reza Ghafarian Malamiri, Hamid (18535346900); Arabi Aliabad, Fahime (57202335135); Shojaei, Saeed (56074126600); Morad, Mortaz (57222515560); Band, Shahab S. (57221738247)","18535346900; 57202335135; 56074126600; 57222515560; 57221738247","A study on the use of UAV images to improve the separation accuracy of agricultural land areas","2021","Computers and Electronics in Agriculture","184","","106079","","","","10.1016/j.compag.2021.106079","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102976213&doi=10.1016%2fj.compag.2021.106079&partnerID=40&md5=232ee3ad01e8e89cc59c1576fdbf94d4","Classifying satellite images with medium spatial resolution such as Landsat, it is usually difficult to distinguish between plant species, and it is impossible to determine the area covered with weeds. In this study, a Landsat 8 image along with UAV images utilized to separate pistachio cultivars and separate weed from trees. To use the high spatial resolution of UAV images, image fusion was carried out through the high-pass filter, wavelet, principal component transformation, BROVEY, IHS, and Gram Schmidt methods. ERGAS, RMSE, and correlation criteria were applied to assess their accuracy. The results represented that the wavelet method with R2, RMSE, and ERGAS 0.91, 12.22 cm, and 2.05 respectively had the highest accuracy in combining these images. Then, images obtained by this method were chosen with a spatial resolution of 20 cm for classification. Different classification methods including unsupervised method, maximum likelihood, minimum distance, fuzzy artmap, perceptron, and tree methods were evaluated. Moreover, six soil classes, Ahmad Aghaei, Akbari, Kalleh Ghoochi, Fandoghi, and a mixing class of Kalleh Ghoochi and Fandoghi were applied, and also three classes of soil, pistachio tree and weeds were extracted from the trees. The results demonstrated that the fuzzy artmap method had the highest accuracy in separating weeds from trees, differentiating various pistachio cultivars with Landsat image and also classification with combined image and had 0.87, 0.79, and 0.87 kappa coefficients respectively. The comparison between pistachio cultivars through Landsat image and the combined image showed that the validation accuracy obtained from harvest has raised by 17% because of the combination of images. The results of this study indicated that the combination of UAV and Landsat 8 images affects well to separate pistachio cultivars and determine the area covered with weeds. © 2021 Elsevier B.V.","Pistacia vera; Forestry; High pass filters; Image classification; Image enhancement; Image fusion; Image resolution; Maximum likelihood; Unmanned aerial vehicles (UAV); Combined images; Fuzzy ARTMAP; High-accuracy; Image fusion methods; LANDSAT; Landsat 8; Landsat images; Pistachio; Spatial resolution; UAV image; accuracy assessment; aerial survey; agricultural land; cultivar; image analysis; image classification; Landsat; satellite imagery; spatial resolution; unmanned vehicle; unsupervised classification; weed control; Land use","Image fusion methods; Land use; Landsat 8; Pistachio; UAV image","Article","Final","","Scopus","2-s2.0-85102976213"
"Benzenati T.; Kessentini Y.; Kallel A.","Benzenati, Tayeb (57216240538); Kessentini, Yousri (16052461400); Kallel, Abdelaziz (22233967900)","57216240538; 16052461400; 22233967900","Spectral-Temporal Fusion of Satellite Images via an End-to-End Two-Stream Attention With an Effective Reconstruction Network","2023","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","16","","","1308","1320","12","10.1109/JSTARS.2023.3234722","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147306147&doi=10.1109%2fJSTARS.2023.3234722&partnerID=40&md5=fc0194dea6d3188caaa258f671d7efe9","Due to technical and budget constraints on current optical satellites, the acquisition of satellite images with the best resolutions is not practicable. In this article, aiming to produce products with high spectral (HS) and temporal resolutions, we introduced a two-stream spectral-temporal fusion technique based on attention mechanism called STA-Net. STA-Net aims to combine high spectral and low temporal (HSLT) resolution images with low spectral and high temporal (LSHT) resolution images to generate products with the best characteristics. The proposed technique involves two stages. In the first one, two fused images are generated by a two-stream architecture based on residual attention blocks. The temporal difference estimator stream estimates the temporal difference between HS images at desired and neighboring dates. The reflectance difference estimator is the second stream. It predicts the reflectance difference between the input images (HS-LS) to map LS images into HS products. In the second stage, a reconstruction network combines the latter two-stream outputs via an effective learnable weighted-sum strategy. The two-stage model is trained in an end-to-end fashion using an effective loss function to ensure the best fusion quality. To the best of our knowledge, this work represents the first attempt to address the spectral-temporal fusion using an end-to-end deep neural network model. Experimental results conducted on two actual datasets of Sentinel-2 (HSLT:10 spectral bands and long revisit period) and Planetscope (LSHT: four spectral bands and daily images) images, which proved the effectiveness of the proposed technique with respect to baseline technique. © 2008-2012 IEEE.","Budget control; Deep neural networks; Image fusion; Image reconstruction; Optical remote sensing; Reflection; Satellite imagery; Attention mechanisms; Images reconstruction; Multi sensor images; Multi-sensor image fusion; Planetscope; Remote-sensing; Sensor image fusion; Sentinel-2; Spatial resolution; Spectral-temporal fusion; artificial neural network; image analysis; image resolution; satellite imagery; Sentinel; spectral analysis; Image resolution","Attention mechanism; convolutional neural network (CNN); image fusion; multisensor image fusion; Planetscope; Sentinel-2; spectral-temporal fusion","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85147306147"
"Nagamani K.; Divya K.; Sujatha K.; Bonagiri K.R.; Kande G.B.; Kumar P.S.S.","Nagamani, Khambampati (57558761900); Divya, Kurapati (57220353468); Sujatha, Kaipa (56460159000); Bonagiri, Koteswar Rao (57558247900); Kande, Giri Babu (24824467100); Kumar, P.S. Shijin (57188825939)","57558761900; 57220353468; 56460159000; 57558247900; 24824467100; 57188825939","Adaptive histogram equalization of wavelet sub bands for the enhancement of contrast in aerial images","2022","Materials Today: Proceedings","52","","","898","901","3","10.1016/j.matpr.2021.10.297","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127390847&doi=10.1016%2fj.matpr.2021.10.297&partnerID=40&md5=f2eb229d43c57c6bd6484d5803182194","Remote sensing images, like satellite images, have played a key role in various sectors of human life. Enhancement of contrast is critical for improved color vision and reproduction. Discrete Wavelet Transform (DWT) and adaptive histogram equalization (AHE) are used in this work to propose a unique method. For images considered for remote sensing, the current methods employ dominant illumination level reasoning and adaptive brightness translation. Using the low-frequency illumination element in wavelets, this technique calculates luminance strength transfer functions and converts pixel intensity as per the transfer function. We use the log-average brightness to divide the sub band (LL) into low, medium, and high frequency layers after performing a discrete wavelet transform on the input images. The gamma adjustment function and knee transfer function are incorporated to adaptively estimate intensity transfer functions depending on the prevailing illumination within each layer. The inverse DWT is used to produce the improved picture after the intensity translation. To increase the image's overall quality, the suggested technique employs adaptive histogram equalization. The current method favours LL sub bands over other bands, necessitating boundary softening and image fusion. This may induce a drop in overall quality. AHE is used in the suggested technique to solve this problem. The suggested method outperforms current methodologies in terms of overall contrast and visibility of local features, according to the findings of the experiments. The suggested approach outperforms the current systems in terms of performance. © 2022 Elsevier Ltd. All rights reserved.","Antennas; Cell proliferation; Graphic methods; Image enhancement; Image fusion; Inverse problems; Luminance; Remote sensing; Signal reconstruction; 'current; Adaptive histograms; Contrast; Discrete-wavelet-transform; Enhancement; Histogram equalizations; Overall quality; Remote-sensing; Subbands; Wavelet; Discrete wavelet transforms","Contrast; Discrete wavelet transform; Enhancement; Remote sensing; Transfer function; Wavelets","Conference paper","Final","","Scopus","2-s2.0-85127390847"
"Islam M.D.S.; Sun X.; Wang Z.; Cheng I.","Islam, MD Samiul (57369268400); Sun, Xinyao (57959394700); Wang, Zheng (57959838300); Cheng, Irene (54790535600)","57369268400; 57959394700; 57959838300; 54790535600","FAPNET: Feature Fusion with Adaptive Patch for Flood-Water Detection and Monitoring †","2022","Sensors","22","21","8245","","","","10.3390/s22218245","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141631320&doi=10.3390%2fs22218245&partnerID=40&md5=4b5e73e6b888bb81e9b98d7e95e4aa71","In satellite remote sensing applications, waterbody segmentation plays an essential role in mapping and monitoring the dynamics of surface water. Satellite image segmentation—examining a relevant sensor data spectrum and identifying the regions of interests to obtain improved performance—is a fundamental step in satellite data analytics. Satellite image segmentation is challenging for a number of reasons, which include cloud interference, inadequate label data, low lighting and the presence of terrain. In recent years, Convolutional Neural Networks (CNNs), combined with (satellite captured) multispectral image segmentation techniques, have led to promising advances in related research. However, ensuring sufficient image resolution, maintaining class balance to achieve prediction quality and reducing the computational overhead of the deep neural architecture are still open to research due to the sophisticated CNN hierarchical architectures. To address these issues, we propose a number of methods: a multi-channel Data-Fusion Module (DFM), Neural Adaptive Patch (NAP) augmentation algorithm and re-weight class balancing (implemented in our PHR-CB experimental setup). We integrated these techniques into our novel Fusion Adaptive Patch Network (FAPNET). Our dataset is the Sentinel-1 SAR microwave signal, used in the Microsoft Artificial Intelligence for Earth competition, so that we can compare our results with the top scores in the competition. In order to validate our approach, we designed four experimental setups and in each setup, we compared our results with the popular image segmentation models UNET, VNET, DNCNN, UNET++, U2NET, ATTUNET, FPN and LINKNET. The comparisons demonstrate that our PHR-CB setup, with class balance, generates the best performance for all models in general and our FAPNET approach outperforms relative works. FAPNET successfully detected the salient features from the satellite images. FAPNET with a MeanIoU score of 87.06% outperforms the state-of-the-art UNET, which has a score of 79.54%. In addition, FAPNET has a shorter training time than other models, comparable to that of UNET (6.77 min for 5 epochs). Qualitative analysis also reveals that our FAPNET model successfully distinguishes micro waterbodies better than existing models. FAPNET is more robust to low lighting, cloud and weather fluctuations and can also be used in RGB images. Our proposed method is lightweight, computationally inexpensive, robust and simple to deploy in industrial applications. Our research findings show that flood-water mapping is more accurate when using SAR signals than RGB images. Our FAPNET architecture, having less parameters than UNET, can distinguish micro waterbodies accurately with shorter training time. © 2022 by the authors.","Algorithms; Artificial Intelligence; Floods; Image Processing, Computer-Assisted; Neural Networks, Computer; Water; Convolutional neural networks; Cost effectiveness; Data Analytics; Deep neural networks; Feature extraction; Floods; Image enhancement; Image fusion; Image resolution; Mapping; Network architecture; Radar imaging; Remote sensing; Satellite imagery; Surface waters; Synthetic aperture radar; water; Flood waters; Flood-water mapping; Images segmentations; Performance; SAR imagery; Satellite image analysis; Satellite images; Water mapping; Waterbodies; Waterbody detection; algorithm; artificial intelligence; flooding; image processing; procedures; Image segmentation","flood-water mapping; image segmentation; SAR imagery; satellite image analysis; waterbody detection","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85141631320"
"Ghoniemy T.M.; Hammad M.M.; Amein A.S.; Mahmoud T.A.","Ghoniemy, Tarek M. (57207793796); Hammad, Mahmoud M. (57344722300); Amein, A.S. (55892252700); Mahmoud, Tarek A. (7004694196)","57207793796; 57344722300; 55892252700; 7004694196","Multi-stage guided-filter for SAR and optical satellites images fusion using Curvelet and Gram Schmidt transforms for maritime surveillance","2021","International Journal of Image and Data Fusion","","","","","","","10.1080/19479832.2021.2003446","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119374374&doi=10.1080%2f19479832.2021.2003446&partnerID=40&md5=51447702bea91678ccc910b3e4abce15","Synthetic aperture radar (SAR) images depend on the dielectric properties of objects with certain incident angles. Thus, vessels and other metallic objects appear clear in SAR images however, they are difficult to be distinguished in optical images. Synergy of these two types of images leads to not only high spatial and spectral resolutions but also good explanation of the image scene. In this paper, a hybrid pixel-level image fusion method is proposed for integrating panchromatic (PAN), multispectral (MS) and SAR images. The fusion method is performed using Multi-stage guided filter (MGF) for optical images pansharpening, to get high preserving spatial details and nested Gram-Schmidt (GS) and Curvelet-Transform (CVT) methods for SAR and optical images,to increase the quality of the final fused image and benefit from the SAR image properties. The accuracy and performance of the proposed method are appraised using Landsat-8 Operational-Land-Imager (OLI) and Sentinel-1 images subjectively as well as objectively using different quality metrics. Moreover, the proposed method is compared to a number of state-of-the-art fusion techniques. The results show significant improvements in both visual quality and the spatial and spectral evaluation metrics. Consequently, the proposed method is capable of highlighting maritime activity for further processing. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","Dielectric properties; Geometrical optics; Radar imaging; Synthetic aperture radar; Curvelet transforms; Curvelets; Gram-Schmidt transform; Guided filters; Maritime-surveillance; Multi-stages; Optical image; Optical satellite images; Radar satellites; Synthetic aperture radar images; Image fusion","curvelet transform; Gram-Schmidt transform; image fusion; maritime surveillance; SAR image","Article","Article in press","","Scopus","2-s2.0-85119374374"
"Singh M.; Tyagi K.D.; Singh A.; Singh K.K.","Singh, Mohan (57216741657); Tyagi, Kapil Dev (56039142500); Singh, Akansha (54899131000); Singh, Krishna Kant (55265360800)","57216741657; 56039142500; 54899131000; 55265360800","Detection of changes in Landsat Images using Hybrid PSO-FCM","2020","Procedia Computer Science","167","","","423","430","7","10.1016/j.procs.2020.03.251","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084511736&doi=10.1016%2fj.procs.2020.03.251&partnerID=40&md5=a900fdcc3bc2391c5f716dc295cd33a4","Image fusion using image normalization and radiometric calibration and Particle Swarm Optimization Fuzzy-c means (PSOFCM) based unsupervised change observation technique is proposed in this paper. To obtain a change of an image, principle component analysis (PCA) & absolute difference log ratio images are fused using radiometric calibration and followed by PSOFCM classifier. Further PSOFCM classifier is used for classifying the satellite image segments into change & unchanged blocks. Better performance is obtained from the simulation of proposed method as compare to other states of art methods. © 2020 The Authors. Published by Elsevier B.V.","Artificial intelligence; Calibration; Image fusion; Principal component analysis; Radiometry; Absolute difference; Detection of changes; Image normalization; Log-ratio images; Observation techniques; Principle component analysis; Radiometric calibrations; Satellite images; Particle swarm optimization (PSO)","CNN; DWT; SCD","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85084511736"
"Asokan A.; Anitha J.","Asokan, Anju (57190950323); Anitha, J. (57204786853)","57190950323; 57204786853","Guided filtering based real time flood area identification on bitemporal satellite images","2021","2021 4th International Conference on Electrical, Computer and Communication Technologies, ICECCT 2021","","","","","","","10.1109/ICECCT52121.2021.9616955","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123415634&doi=10.1109%2fICECCT52121.2021.9616955&partnerID=40&md5=c342252fd1980577d04b72a4a85b8b9c","Satellite images are considered as the most reliable source of information concerning disaster affected areas. The ease of satellite image acquisition in extreme weather and frequent availability with wider coverage makes it effective for proper disaster response. This paper focuses on change detection in flood areas in bitemporal satellite imagery. The proposed method is based on three stages: guided filter for image enhancement and spatial feature extraction, difference image creation and classification. The difference image is classified to identify the changes in pre-event and post-event images to form a binary change map. The performance of the proposed method is assessed by applying on image sets acquired before and after the floods. Experiments show that the proposed method gives promising results over existing methods.  © 2021 IEEE.","Disasters; Extraction; Floods; Image acquisition; Image enhancement; Image fusion; Satellite imagery; Bitemporal; Change map; Difference images; Features extraction; Flood areas; Guided filtering; Multi-spectral; Real- time; Satellite images; Sources of informations; Feature extraction","bitemporal; change map; feature extraction; image fusion; multispectral","Conference paper","Final","","Scopus","2-s2.0-85123415634"
"Ramírez M.; Martínez L.; Montilla M.; Sarmiento O.; Lasso J.; Diaz S.","Ramírez, M. (57220994474); Martínez, L. (57214231932); Montilla, M. (57220187808); Sarmiento, O. (57220190162); Lasso, J. (57220176809); Diaz, S. (57197656091)","57220994474; 57214231932; 57220187808; 57220190162; 57220176809; 57197656091","Obtaining agricultural land cover in sentinel-2 satellite images with drone image injection using random forest in google earth engine; [Obtención de coberturas del suelo agropecuarias en imágenes satelitales sentinel-2 con la inyección de imágenes de dron usando random forest en google earth engine]","2020","Revista de Teledeteccion","2020","56","","49","68","19","10.4995/raet.2020.14102","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097188346&doi=10.4995%2fraet.2020.14102&partnerID=40&md5=21bf9dd9240706827f2925c8397f9e73","To obtain accurate information on land cover changes in the agricultural sector, we propose a supervised classification method that integrates Sentinel-2 satellite imagery with images surveyed from Remote Piloted Aircraft Systems (RPAS). The methodology was implemented on the Google Earth Engine platform. Initially, the Sentinel-2 imagery collection was integrated into a single image through a median reduction process. Subsequently, the high-pass filter (HPF) pansharpening image fusion method was applied to the thermal spectral bands to obtain a final spatial resolution of 10 m. To perform the integration of the two image sources, the RPAS image was normalized by using a 5X5 gaussian texture filter and the pixel was resampled to five times its original size. This procedure was performed iteratively until reaching the spatial resolution of the Sentinel-2 imagery. Besides, the following inputs were added to the classification: the spectral indices, calculated from the Sentinel-2 and RPAS bands (e.g. NDVI, NDWI, SIPI, GARI), altimetric information and slopes of the zone derived from the SRTM DEM. The supervised classification was done by using the Random Forest technique (Machine Learning). The land cover seed reference to perform the classification was manually captured by a thematic expert, then, this reference was distributed in 70% for the training of the Random Forest algorithm and in 30% to validate the classification. The results show that the incorporation of the RPAS image improves thematic accuracy indicators by an average of 3% compared to a classification made exclusively with Sentinel-2 imagery. © 2020, Universidad Politecnica de Valencia.. All rights reserved.","","Google Earth Engine; Random Forest; RPAS; Sentinel-2; Supervised classification","Note","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85097188346"
"Rao D.R.; Noorjahan S.; Fathima S.A.","Rao, Duvvada Rajeswara (57201479001); Noorjahan, Shaik (57645668900); Fathima, Shaik Ayesha (57647144700)","57201479001; 57645668900; 57647144700","Classification of Land Cover Usage from Satellite Images using Deep Learning Algorithms","2022","Proceedings of the International Conference on Electronics and Renewable Systems, ICEARS 2022","","","","1302","1308","6","10.1109/ICEARS53579.2022.9752282","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128935677&doi=10.1109%2fICEARS53579.2022.9752282&partnerID=40&md5=ec96bdf4ac4e2dfb1b3f73168d332a33","Earth's environment and its evolution can be seen through satellite images in near real time. Through satellite imagery, remote sensing data provides crucial information that can be used for a variety of applications, including image fusion, change detection, land cover classification, agriculture, mining, disaster mitigation, and monitoring climate change. The objective of this project is to propose a method for classifying satellite images according to multiple predefined land cover classes. The proposed approach involves collecting data in image format. The data is then preprocessed using data preprocessing techniques. The processed data is fed into the proposed algorithm and the obtained result is analyzed. Some of the algorithms used in satellite imagery classification are U-Net, Random Forest, Deep Labv3, CNN (Convolutional Neural Network), ANN(Artificial neural network), Resnet etc. In this project, DeepLabv3 (Atrous convolution) algorithm is used for land cover classification. The dataset used is the deep globe land cover classification dataset. DeepLabv3 is a semantic segmentation system that uses atrous convolution to capture multi-scale context by adopting multiple atrous rates in cascade or in parallel to determine the scale of segments. © 2022 IEEE.","Classification (of information); Climate change; Decision trees; Deep learning; Image classification; Image fusion; Neural networks; Remote sensing; Satellite imagery; Semantic Segmentation; Semantics; Area calculation; Atrous convolution; Deep globe land cover classification; Deeplabv3; Earth environment; Land cover; Land cover classification; Resnet 50.; Satellite images; Convolution","Area Calculation; Atrous convolution; Deep globe land cover classification; DeepLabv3; Land cover classification; Resnet 50.","Conference paper","Final","","Scopus","2-s2.0-85128935677"
"Li J.-J.; Fu Q.-Y.; Jiang T.","Li, Jun-Jie (57219708000); Fu, Qiao-Yang (57219697971); Jiang, Tao (56564606100)","57219708000; 57219697971; 56564606100","Remote Sensing Image Fusion Based on Spectral Response Function and Global Variance Matching; [结合光谱响应函数和全局方差匹配的遥感图像融合]","2020","Guangzi Xuebao/Acta Photonica Sinica","49","10","1010001","","","","10.3788/gzxb20204910.1010001","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094859372&doi=10.3788%2fgzxb20204910.1010001&partnerID=40&md5=6f0cbe96caa749767e3be562df3a2ccc","In order to keep the spatial details and reduce the spectral distortion, and to solve the problem that the coefficients of the improved component replacement fusion method are often negative or too small when building the intensity components, a remote sensing image fusion method combining spectral response function and global variance matching is proposed. Based on the general component replacement fusion framework, the intensity component is constructed by using the proportional relationship of the radiation energy response reflected by the spectral response function of panchromatic and multispectral sensors. The physical meaning is explicit, and the mathematical form is simple and clear. At the same time, the spatial detail modulation parameters are determined by using the ratio of global covariance to variance to reduce the spectral distortion and meet the constraints of the general component replacement fusion framework. The proposed method is compared with many mature fusion methods on two groups of different satellite image data, the results show that the fusion image spatial and spectral quality are better. © 2020, Science Press. All right reserved.","Image enhancement; Remote sensing; Component replacement; Modulation parameters; Multispectral sensors; Proportional relationships; Remote sensing images; Satellite image datas; Spectral distortions; Spectral response functions; Image fusion","Component substitution pansharpening; Global variance matching; Multispectral image; Remote sensing image fusion; Spectral response function","Article","Final","","Scopus","2-s2.0-85094859372"
"Cai J.; Huang B.; Fung T.","Cai, Jiajun (57193551962); Huang, Bo (55388074800); Fung, Tung (7102715957)","57193551962; 55388074800; 7102715957","Progressive spatiotemporal image fusion with deep neural networks","2022","International Journal of Applied Earth Observation and Geoinformation","108","","102745","","","","10.1016/j.jag.2022.102745","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126629629&doi=10.1016%2fj.jag.2022.102745&partnerID=40&md5=d72fb02ac7691bf4a899fa75415bb094","Spatiotemporal image fusion (STIF) provides a feasible and effective solution for generating satellite images with high spatial and temporal resolution. As deep learning-based fusion algorithms show great potential in generating high-quality images, we propose a novel deep learning model, namely a deep progressive spatiotemporal fusion network (DPSTFN), which is coupled with pansharpening and super-resolution learning processes to satisfy requirements of STIF based on Moderate Resolution Imaging Spectroradiometer (MODIS) and Landsat data. First, a pansharpening process is adopted to make full use of two MODIS bands with 250 m spatial resolution. Second, a super-resolution process enhances the spatial information that existed in coarse-resolution images to alleviate the enormous spatial resolution gap between MODIS and Landsat images. Third, combining the aforementioned two auxiliary processes, a progressive spatiotemporal fusion framework is proposed to generate deliberate and robust fusion results. Experiments are conducted using two MODIS-Landsat datasets of distinctive landforms to evaluate the performance of DPSTFN. The results of the subjective and objective evaluation show that our proposed network performs better than the state-of-the-art traditional STIF algorithms Fit-FC and RASTFM, and the deep learning-based algorithms EDCSTFN and StfNet. © 2022 The Author(s)","algorithm; artificial neural network; landform; Landsat; MODIS; numerical model; satellite imagery; spatial resolution; spatiotemporal analysis","Convolutional neural network; Deep learning; Landsat; MODIS; Spatiotemporal fusion","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85126629629"
"Sigurdsson J.; Armannsson S.E.; Ulfarsson M.O.; Sveinsson J.R.","Sigurdsson, Jakob (7006736374); Armannsson, Sveinn E. (57224686207); Ulfarsson, Magnus O. (6507677875); Sveinsson, Johannes R. (7003642214)","7006736374; 57224686207; 6507677875; 7003642214","Fusing Sentinel-2 and Landsat 8 Satellite Images Using a Model-Based Method","2022","Remote Sensing","14","13","3224","","","","10.3390/rs14133224","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133860643&doi=10.3390%2frs14133224&partnerID=40&md5=36a359caa11fe4e2c3c864be45cbb3cc","The Copernicus Sentinel-2 (S2) constellation comprises of two satellites in a sun-synchronous orbit. The S2 sensors have three spatial resolutions: 10, 20, and 60 m. The Landsat 8 (L8) satellite has sensors that provide seasonal coverage at spatial resolutions of 15, 30, and 60 m. Many remote sensing applications require the spatial resolutions of all data to be at the highest resolution possible, i.e., 10 m for S2. To address this demand, researchers have proposed various methods that exploit the spectral and spatial correlations within multispectral data to sharpen the S2 bands to 10 m. In this study, we combined S2 and L8 data. An S2 sharpening method called Sentinel-2 Sharpening (S2Sharp) was modified to include the 30 m and 15 m spectral bands from L8 and to sharpen all bands (S2 and L8) to the highest resolution of the data, which was 10 m. The method was evaluated using both real and simulated data. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Image fusion; Orbits; Remote sensing; High resolution; Image sharpening; LANDSAT; Landsat 8; Multi-spectral; Multiresolution images; Multispectral  multiresolution image; Sentinel-2; Spatial resolution; Superresolution; Landsat","data fusion; image sharpening; Landsat 8; multispectral (MS) multiresolution images; Sentinel-2; super-resolution","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85133860643"
"Sahu M.; Dash R.","Sahu, Madhusmita (57677789400); Dash, Rasmita (42560897800)","57677789400; 42560897800","A fusion based land cover classification model using remote sensed images","2022","Intelligent Decision Technologies","16","1","","37","49","12","10.3233/IDT-210037","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129310389&doi=10.3233%2fIDT-210037&partnerID=40&md5=29082bdcbbebb65c101be3c56578f109","Classification of land cover from remote sensed image is quite challenging task. Since the satellite images preserve spatial and spectral information, thus it is essential to identify the land cover classes and classify them to generate the thematic map. The remote sensed images and thus produced thematic maps are useful for extracting the esteemed information in diagnosing, supervising, and management of earth's surface. In this paper, a multiclass land cover classification model is proposed that comprise of pre-processing method, a multiclass classifier and performance evaluation strategy. The land cover-based satellite images are applied to this model to generate a land cover map labelled with seven land cover classes. The morphological opening, closing, and a fusion technique are involved in pre-processing stage to extract the spatial information as well as reduce the incurred noise from the input image. Then a supervised classification methodology is introduced to classify the image into 7 number of land cover classes based on the spectral values of each pixel of the image. The overall achievement of the proposed model is compared with some existing multiclass supervised and unsupervised classification techniques such as Naïve Bayes classifier (NBC), Decision tree (DT), K-nearest neighbour (KNN), Convolution Neural Network (CNN).  © 2022 - IOS Press. All rights reserved.","Classification (of information); Classifiers; Decision trees; Image classification; Image fusion; Maps; Processing; Classification models; Cover-image; Land cover; Land cover classification; Land cover image; Morphological closing; Morphological opening; Satellite images; Sensed image; Spatial informations; Remote sensing","image fusion; land cover classification; Land cover image; morphological closing; morphological opening","Article","Final","","Scopus","2-s2.0-85129310389"
"Kucuk S.; Abaci B.; Dede M.; Yuksel S.E.; Yilmaz M.","Kucuk, Sefa (56246617500); Abaci, Bahri (56005473700); Dede, Murat (57783654200); Yuksel, Seniha Esen (13406053300); Yilmaz, Mete (24726215700)","56246617500; 56005473700; 57783654200; 13406053300; 24726215700","Analysis and Detection of Mucilage Bloom from Multispectral Satellite Images; [Multispektral Uydu Görüntülerinden Müsilaj Oluşumlarinin Analizi ve Tespiti]","2022","2022 30th Signal Processing and Communications Applications Conference, SIU 2022","","","","","","","10.1109/SIU55565.2022.9864988","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138755267&doi=10.1109%2fSIU55565.2022.9864988&partnerID=40&md5=a46b03e65badc283f6ccd6dfc53f1b75","In this paper, we aim to detect and observe the mucilage formations in the Sea of Marmara by means of Sentinel-2A satellite data. For this purpose, we produce mucilage index maps by utilizing the relationship between the spectral bands of Sentinel-2A. Sentinel-2A has four 10m fine bands and six 20m coarse bands. To compute the mucilage index, the spectral bands must have the same spatial resolution. Although the Sentinel-2A does not have a panchromatic band, the spatial resolution of the 20m bands can be increased to 10m thanks to its four fine bands. Based on the results of this analysis, we utilize seven of the existing image fusion approaches to enhance the spatial resolution of 20m bands to 10m. We monitor changes in mucilage formations over time with the mucilage maps acquired by using fused images through the mucilage index. © 2022 IEEE.","Image enhancement; Image fusion; Image resolution; Maps; Index maps; Mucilage; Mucilage formation; Multispectral satellite image; Remote-sensing; Satellite data; Sea of Marmara; Sentinel-2a; Spatial resolution; Spectral band; Remote sensing","Fusion; mucilage; remote sensing; Sentinel-2A","Conference paper","Final","","Scopus","2-s2.0-85138755267"
"Guo A.; Wu Y.; Li S.","Guo, Anjing (57200751372); Wu, Yue (57757462800); Li, Shutao (7409240361)","57200751372; 57757462800; 7409240361","JOINT IMAGE REGISTRATION AND BLUR KERNEL LEARNING FOR PANSHARPENING","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","2636","2639","3","10.1109/IGARSS47720.2021.9554618","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129866063&doi=10.1109%2fIGARSS47720.2021.9554618&partnerID=40&md5=bdecef190b18b29cecf6e816262a566f","Image registration and the estimation of spatial and spectral blur kernels are essential steps before fusing panchromatic image (PAN) and multispectral image (MSI). Usually, these basic steps are performed separately, which will lead to error accumulation and ultimately affect the fusion performance. In this paper, we propose a novel deep learning (DL) based framework which can jointly register images and learn the blur kernels of original PAN and MSI. Specifically, we first construct a convolutional neural network (CNN) to learn the offsets between PAN and MSI, and the offsets are utilized to align the two images. Then, we analyze the relationship between the registered PAN and MSI, and design a tiny network for blur kernel learning. After solving the gradient derivation problems, we can combine the two networks and train them end-to-end. Experimental results on GF-2 satellite images demonstrate that the proposed method can significantly improve the fusion performance of some popular pansharpening methods. © 2021 IEEE.","Convolutional neural networks; Deep learning; Image enhancement; Image fusion; Blur kernel learning; Deep learning; Error accumulation; Fusion performance; Image blur; Images registration; Kernel learning; Learn+; Multispectral images; Pan-sharpening; Image registration","blur kernel learning; deep learning; image registration; Pansharpening","Conference paper","Final","","Scopus","2-s2.0-85129866063"
"Lohi S.A.; Bhatt C.","Lohi, Snehal A. (56208994600); Bhatt, Chinmay (57983817700)","56208994600; 57983817700","Empirical Analysis of Crop Yield Prediction and Disease Detection Systems: A Statistical Perspective","2023","Lecture Notes in Networks and Systems","520","","","49","57","8","10.1007/978-981-19-5331-6_6","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142731308&doi=10.1007%2f978-981-19-5331-6_6&partnerID=40&md5=631b9d32e62de6020402ae4ab5ad1242","Crop-imagery is categorized into three different types, which are near-field images, satellite images and drone-based images. All these image types can be processed in order to determine crop growth, crop diseases and finally crop yield. Different algorithms have been proposed over the years which determine one or more of these parameters using a series of image segmentation, feature extraction, feature selection, classification and post-processing steps. Each of these steps requires a specialized set of algorithms to be employed in order to design an effective crop-image processing system. Due to the wide variety of algorithms present in the given field of work, selection of the most optimum algorithm set for a given application is often ambiguous. For instance, if an application is trying to process satellite imagery, then identification of best image-fusion methods for effective classification requires a lot of research, and thus increases delay for designing the system. In order to reduce this ambiguity, this paper reviews these algorithm sets which identify the best techniques in terms of statistical parameters for a given application. Accuracy and error rate have been compared between different algorithms in order to give a clear idea about the performance of these algorithms. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","","Classification; Crop; Disease; Growth; Machine learning; Prediction; Yield","Conference paper","Final","","Scopus","2-s2.0-85142731308"
"Goshehgir A.S.; Golabi M.; Naseri A.A.","Goshehgir, A.S. (57222134854); Golabi, M. (26666639600); Naseri, A.A. (23095231300)","57222134854; 26666639600; 23095231300","Estimation and Comparison Actual Evapotranspiration of Sugarcane Using Separate and Fusion Satellite Images and Lysimeteric Data with Approach of Determining Water Use Efficiency","2021","Journal of the Indian Society of Remote Sensing","49","6","","1461","1474","13","10.1007/s12524-021-01326-5","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101612574&doi=10.1007%2fs12524-021-01326-5&partnerID=40&md5=45f32bfc1c62f0d4f1e7735c6d7d2194","Estimating evapotranspiration is an essential step towards the calculation of crops irrigation needs. One of the most widely used methods for this estimation is Surface Energy Balance Algorithm (SEBAL), a method based on remote sensing imagery. In the current study, fusion images of Landsat 8 and MODIS satellites using Gram-Schmidt algorithm were employed to calculate actual evapotranspiration of the Amir Kabir sugarcane argo-industry company, Khuzestan, Iran. Furthermore, the amount of sugarcane evapotranspiration was estimated using Landsat 8 images and SEBAL algorithm, and finally, the results were compared with lysimeteric data. The comparison of evapotranspiration from Landsat 8 and lysimeteric data showed a correlation higher than 0.96, as well as a comparison of evapotranspiration from the Landsat-MODIS fusion images having a suitable correlation equal to 0.88 with the lysimeteric data. In this research, the amount of dry matter produced in farming year 2016–2017 was calculated by using the Monteith model and satellite images. The average dry matter produced (biomass) of sugarcane in this period estimated using Landsat 8 images was 52.51ton/ha and 42.45ton/ha with fusion images. The average water use efficiency from the dry matter ratio produced by the actual evapotranspiration estimated from satellite data for Landsat 8 images and Landsat-MODIS fusion images was 5.98 and 5.95 kg/m3, respectively. Also, the relationship between age and sugarcane varieties with yield and evapotranspiration rates calculated by the Monteith and SEBAL model indicated that the effect of the age of the sugarcane and varieties on its evapotranspiration rate is negligible. Finally, the relationship between the estimated evapotranspiration by Landsat 8 images and NDVI revealed that the extraction of NDVI values from images could be achieved with the proper accuracy of evapotranspiration. © 2021, Indian Society of Remote Sensing.","Iran; Khuzestan; Satellites; estimation method; evapotranspiration; MODIS; NDVI; remote sensing; satellite data; sugar cane; water use efficiency","Evapotranspiration; Image fusion; SEBAL; Sugarcane","Article","Final","","Scopus","2-s2.0-85101612574"
"Jia D.; Cheng C.; Song C.; Shen S.; Ning L.; Zhang T.","Jia, Duo (57194393773); Cheng, Changxiu (15839192900); Song, Changqing (57195903224); Shen, Shi (56991897300); Ning, Lixin (57186245900); Zhang, Tianyuan (57221110107)","57194393773; 15839192900; 57195903224; 56991897300; 57186245900; 57221110107","A hybrid deep learning-based spatiotemporal fusion method for combining satellite images with different resolutions","2021","Remote Sensing","13","4","645","1","33","32","10.3390/rs13040645","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100920238&doi=10.3390%2frs13040645&partnerID=40&md5=5c57e750787641e5f8388c136349430f","Spatiotemporal fusion (STF) is considered a feasible and cost-effective way to deal with the trade-off between the spatial and temporal resolution of satellite sensors, and to generate satellite images with high spatial and high temporal resolutions. This is achieved by fusing two types of satellite images, i.e., images with fine temporal but rough spatial resolution, and images with fine spatial but rough temporal resolution. Numerous STF methods have been proposed, however, it is still a challenge to predict both abrupt landcover change, and phenological change, accurately. Meanwhile, robustness to radiation differences between multi-source satellite images is crucial for the effective application of STF methods. Aiming to solve the abovementioned problems, in this paper we propose a hybrid deep learning-based STF method (HDLSFM). The method formulates a hybrid framework for robust fusion with phenological and landcover change information with min-imal input requirements, and in which a nonlinear deep learning-based relative radiometric nor-malization, a deep learning-based superresolution, and a linear-based fusion are combined to ad-dress radiation differences between different types of satellite images, landcover, and phenological change prediction. Four comparative experiments using three popular STF methods, i.e., spatial and temporal adaptive reflectance fusion model (STARFM), flexible spatiotemporal data fusion (FSDAF), and Fit-FC, as benchmarks demonstrated the effectiveness of the HDLSFM in predicting phenological and landcover change. Meanwhile, HDLSFM is robust for radiation differences between different types of satellite images and the time interval between the prediction and base dates, which ensures its effectiveness in the generation of fused time-series data. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Cost effectiveness; Economic and social effects; Forecasting; Image fusion; Learning systems; Satellites; Comparative experiments; Different resolutions; High temporal resolution; Phenological changes; Spatial and temporal resolutions; Spatio-temporal data; Spatio-temporal fusions; Temporal resolution; Deep learning","Landcover change; Phenological change; Radiation difference; Spatiotemporal fusion","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85100920238"
"Agapiou A.","Agapiou, Athos (35188628700)","35188628700","Evaluation of Landsat 8 OLI/TIRS level-2 and sentinel 2 level-1C fusion techniques intended for image segmentation of archaeological landscapes and proxies","2020","Remote Sensing","12","3","579","","","","10.3390/rs12030579","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080882418&doi=10.3390%2frs12030579&partnerID=40&md5=1382c221b471daf10e82fa271f8dd410","The use of medium resolution, open access, and freely distributed satellite images, such as those of Landsat, is still understudied in the domain of archaeological research, mainly due to restrictions of spatial resolution. This investigation aims to showcase how the synergistic use of Landsat and Sentinel optical sensors can efficiently support archaeological research through object-based image analysis (OBIA), a relatively new scientific trend, as highlighted in the relevant literature, in the domain of remote sensing archaeology. Initially, the fusion of a 30mspatial resolution Landsat 8 OLI/TIRS Level-2 and a 10 m spatial resolution Sentinel 2 Level-1C optical images, over the archaeological site of ""Nea Paphos"" in Cyprus, are evaluated in order to improve the spatial resolution of the Landsat image. At this step, various known fusion models are implemented and evaluated, namely Gram-Schmidt, Brovey, principal component analysis (PCA), and hue-saturation-value (HSV) algorithms. In addition, all four 10mavailable spectral bands of the Sentinel 2 sensor, namely the blue, green, red, and near-infrared bands (Bands 2 to 4 and Band 8, respectively) were assessed for each of the different fusion models. On the basis of these findings, the next step of the study, focused on the image segmentation process, through the evaluation of different scale factors. The segmentation process is an important step moving from pixel-based to object-based image analysis. The overall results show that the Gram-Schmidt fusion method based on the near-infrared band of the Sentinel 2 (Band 8) at a range of scale factor segmentation to 70 are the optimum parameters for the detection of standing visible monuments, monitoring excavated areas, and detecting buried archaeological remains, without any significant spectral distortion of the original Landsat image. The new 10 m fused Landsat 8 image provides further spatial details of the archaeological site and depicts, through the segmentation process, important details within the landscape under examination. © 2020 by the authors.","Architecture; Fusion reactions; Geometrical optics; Image analysis; Image enhancement; Image fusion; Image resolution; Infrared devices; Principal component analysis; Remote sensing; Archaeological landscapes; Archaeological proxies; LANDSAT; Object based image analysis (OBIA); Sentinel 2; Image segmentation","Archaeological landscapes; Archaeological proxies; Fusion; Image segmentation; Landsat 8; Object-based image analysis (OBIA); Sentinel 2","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85080882418"
"Li W.; Zhang H.; Li W.; Ma T.","Li, Weiguo (26664080400); Zhang, Hong (58046133500); Li, Wei (57406526100); Ma, Tinghuai (57406526000)","26664080400; 58046133500; 57406526100; 57406526000","Extraction of Winter Wheat Planting Area Based on Multi-Scale Fusion","2023","Remote Sensing","15","1","164","","","","10.3390/rs15010164","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145883464&doi=10.3390%2frs15010164&partnerID=40&md5=ea2bf44875a9e3ae5728e37a24a11b86","It is difficult to accurately identify the winter wheat acreage in the Jianghuai region of China, and the fusion of high-resolution images and medium-resolution image data can improve the image quality and facilitate the identification and acreage extraction of winter wheat. Therefore, the objective of this study is to improve the accuracy of China’s medium-spatial resolution image data (environment and disaster monitoring and forecasting satellite data, HJ-1/CCD) in extracting the large area of winter wheat planted. The fusion and object-oriented classification of the 30 m × 30 m HJ-1/CCD multispectral image and 2 m × 2 m GF-1 panchromatic image (GF-1/PMS) of winter wheat at the jointing stage in the study area were studied. The GF-1/PMS panchromatic images were resampled at 8 m, 16 m and 24 m to produce panchromatic images with four spatial resolutions, including 2 m. They were fused with HJ-1/CCD multispectral images by Gram Schmidt (GS). The quality of the fused images was evaluated to pick adequate scale images for the field pattern of winter wheat cultivation in the study area. The HJ-1/CCD multispectral image was resampled to obtain an image with the same scale as the suitable scale fused image. In the two images, the training samples SFI (samples of fused image) and SRI (samples of resampled image) containing spectral and texture information were selected. The fused image (FI) and resampled image (RI) were used for winter wheat acreage extraction using an object-oriented classification method. The results indicated that the fusion effect of 16 m × 16 m fused image was better than 2 m × 2 m, 8 m × 8 m and 24 m × 24 m fused images, with mean, standard deviation, average gradient and correlation coefficient values of 161.15, 83.01, 4.55 and 0.97, respectively. After object-oriented classification, the overall accuracy of SFI for the classification of resampled image RI16m was 92.22%, and the Kappa coefficient was 0.90. The overall accuracy of SFI for the classification of fused image FI16m was 94.44%, and the Kappa coefficient was 0.93. The overall accuracy of SRI for the classification of resampled image RI16m was 84.44%, and the Kappa coefficient was 0.80. The classification effect of SFI for the fused image FI16m was the best, indicating that the object-oriented classification method combined with the fused image and the extraction samples of the fused image (SFI) could extract the winter wheat planting area with precision. In addition, the object-oriented classification method combining resampled images and the extraction samples of fused images (SFI) could extract the winter wheat planting area more effectively. These results indicated that the combination of medium spatial resolution HJ-1/CCD images and high spatial resolution GF-1 satellite images could effectively extract the planting area information of winter wheat in large regions. © 2022 by the authors.","Classification (of information); Crops; Data mining; Image classification; Image enhancement; Image fusion; Image quality; Satellites; Textures; Extraction of winter wheat planting area; Fused images; GF-1/PMS satellite image; HJ-1/CCD satellite image; Multispectral images; Object oriented classification; Planting areas; Satellite images; Winter wheat; Extraction","extraction of winter wheat planting area; GF-1/PMS satellite image; HJ-1/CCD satellite image; image fusion; object-oriented classification","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85145883464"
"Zhao Y.; Liu D.; Wei X.","Zhao, Yongquan (57192575717); Liu, Desheng (55577793400); Wei, Xiaofang (57695072500)","57192575717; 55577793400; 57695072500","Monitoring cyanobacterial harmful algal blooms at high spatiotemporal resolution by fusing Landsat and MODIS imagery","2020","Environmental Advances","2","","100008","","","","10.1016/j.envadv.2020.100008","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107186475&doi=10.1016%2fj.envadv.2020.100008&partnerID=40&md5=0b673d02b81aba3a6f77c0721c5e327e","Toxic Cyanobacteria-rich Harmful Algal Blooms (CyanoHABs) are severe environmental issues impacting water environment, aquatic life populations, and surrounding wild and human lives. Given their fast-changing variations in space and time, frequent monitoring of CyanoHABs with sufficient spatial details and coverage is needed to understand their impacts. However, current monitoring activities based on in situ or satellite data do not meet this requirement due to the limited spatial coverages of buoy measurements and the compromise between spatial resolution and temporal frequency of satellite observations. In this study, we develop a Spatial-Temporal Image Fusion (STIF) approach to enable high spatial-temporal resolution monitoring of CyanoHABs. The proposed approach consists of two steps: (1) a new CyanoHAB spectral index called Broad Wavelength Algae Index (BWAI) is developed for fine-but-sparse (Landsat) and coarse-but-frequent (MODIS) satellite images, and (2) the Landsat and MODIS derived BWAI images are fused by the Robust Adaptive Spatial and Temporal Fusion Model (RASTFM) to generate fine-and-frequent Landsat-like BWAI images. Our results show that the proposed BWAI index is with higher similarity and correlation with the reference Cyanobacteria Index (CI) images and in situ observations than the comparative algae indices devised for broad wavelength sensors. Moreover, the 30-m Landsat-like BWAI image series provide more accurate and detailed results than their 500-m MODIS counterparts and greatly improve the temporal frequency over Landsat-based algae indices, demonstrating the contribution of the improved spatial-temporal resolution achieved by the proposed STIF approach. Consequently, this research fills the gap of high spatiotemporal resolution monitoring of CyanoHABs and paves a new way of assessing water environment in a timely and detailed manner. © 2020 The Authors","","Broad wavelength algae index (BWAI); Cyanobacteria-rich harmful algal blooms (CyanoHABs); Landsat; MODIS; Spatial-temporal image fusion (STIF)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85107186475"
"Niu L.; Xu G.; Kaufmann H.; Li X.","Niu, Lifeng (57235220000); Xu, Guochang (57325040700); Kaufmann, Hermann (55657538300); Li, Xiaojun (55927844400)","57235220000; 57325040700; 55657538300; 55927844400","An advanced algorithm for fusing Gaofen multispectral satellite data with drone imagery","2022","International Journal of Remote Sensing","43","9","","3163","3189","26","10.1080/01431161.2022.2088257","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133085066&doi=10.1080%2f01431161.2022.2088257&partnerID=40&md5=49958d6cac4efcdf61c7ca92baa0b86f","Common image fusion methods used to merge remotely sensed data of varying spatial and spectral information as provided by different air-, and space-borne sensors often do not provide the optimal reachable information. This paper proposes a novel fusion method for pansharpening using a multi-resolution analysis (MRA) based on Chinese Gaofen (GF-1/2) satellite data and corresponding drone data as an example. The novel fusion method is named droesharpening fusion method, which addresses common poor spatial and spectral feature issues of fusion results. The droesharpening fusion method designed several separate computing steps based on wavelets and a pulse-coupled neural network (PCNN) to calculate low-resolution drone (LDRO) images and an injection weight (gk) for significantly improved results. The droesharpening fusion method includes a new algorithm for reducing the MDRO image dimensions (RDA). The proposed new algorithm calculated image feature (IFA), and the proposed algorithm of calculating the gk (IWA). ARD is used to reduce the dimensionalities of a drone (MDRO) image to a new single-band drone (SDRO) image. Then, we applied an improved ‘à trous’ Wavelet Transform (ATWT) to SDRO images to extract LDRO images and an improved PCNN for the multispectral (MS) images. Additionally, edge processing is deployed to the PCNN segmented images. The IFA is then used to calculate the spatial characteristics of the SDRO images based on the ATWT decomposed image and the spectral features of the MS images based on the PCNN segmented images. In the next step, the IMA calculates the gk based on the spatial and spectral characteristics. The detailed spatial information of the MDRO images is then injected into the MS images by using the gk to obtain the fused drone/multispectral satellite imagery. Additional experimental results using several drone/multispectral satellite images proved that the proposed method achieves high spectral fidelity and simultaneously improves the spatial resolution of fused images. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Drones; Image enhancement; Neural networks; Satellite imagery; Wavelet transforms; 'A trous' wavelet transform; An improved ‘a trous’ wavelet transform; Fusion methods; Injection weight; Multispectral images; Pan-sharpening; Pulse coupled neural network; Single band; Spatial informations; Spectral feature; algorithm; artificial neural network; image processing; image resolution; multispectral image; remote sensing; satellite data; satellite imagery; Image fusion","ATWT; image fusion; injection weight; pansharpening; PCNN","Article","Final","","Scopus","2-s2.0-85133085066"
"Rahman A.N.; Tripathiy V.; Gupta A.D.; Paul B.; Kurian M.T.; Vijayan V.P.","Rahman, A Nisam (57751694600); Tripathiy, Vikas (58028541100); Gupta, Ayan Das (57575881200); Paul, Biju (36452304300); Kurian, Manju T (58028459900); Vijayan, Vinodh P (56406165300)","57751694600; 58028541100; 57575881200; 36452304300; 58028459900; 56406165300","Satellite Image Fusion for Obtaining High Resolution Images Using Deep Neural Network","2022","Proceedings of 2022 International Conference on Intelligent Innovations in Engineering and Technology, ICIIET 2022","","","","301","306","5","10.1109/ICIIET55458.2022.9967537","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144607104&doi=10.1109%2fICIIET55458.2022.9967537&partnerID=40&md5=7c4d646075b8514db2465ce6074b53b7","Due to its critical function in a wide range of applications, scene categorization of high-resolution remote sensing (RS) photos has drawn increasing attention. A technique for spatiotemporal fusion using deep neural networks (DNNs) with a large amount of remote sensing data as the application background. An innovative multispectral image fusion architecture is proposed in this paper. The proposed method for fusing satellite images entails two phases, each using two neural networks. In the first stage, an adaptively weighted injection-based joints detailed approach to remotely sensed image fusion is discussed. Multispectral (MS) and panchromatic (PAN) images are used to extract spatial features using a wavelet transform. In contrast to the conventional detail injection technique, dictionary learning from the sub-images themselves is used to construct the primary joint details by sparsely representing the extracted features. To minimize spectrum distortions in the fused images while keeping spatial information, we implemented a unique loss function for this DNN. This network is known as the 'Spectral Reimbursement Network (SRN).' Finally, using three datasets, full-reference, and limited-reference criterion, the proposed strategy is compared against several state-of-The-Art methods. Experiment findings demonstrate that the suggested technique can compete in both spatial and spectral parameters. © 2022 IEEE.","Image fusion; Remote sensing; Satellites; Wavelet transforms; Critical functions; Fused multispectral image; High resolution remote sensing; High-resolution images; Large amounts; Multispectral images; Satellite images; Scene categorization; Spatio-temporal fusions; Spectral reimbursement network; Deep neural networks","Deep neural network; fused MS image; Satellite image; Spectral reimbursement network","Conference paper","Final","","Scopus","2-s2.0-85144607104"
"Niu X.; Zeng Q.; Luo X.; Chen L.","Niu, Xuerui (57395879800); Zeng, Qiaolin (57190367130); Luo, Xiaobo (36562124600); Chen, Liangfu (8437626600)","57395879800; 57190367130; 36562124600; 8437626600","FCAU-Net for the Semantic Segmentation of Fine-Resolution Remotely Sensed Images","2022","Remote Sensing","14","1","215","","","","10.3390/rs14010215","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122211554&doi=10.3390%2frs14010215&partnerID=40&md5=c2c73a3b45d87a8a303d9a7377942727","The semantic segmentation of fine-resolution remotely sensed images is an urgent issue in satellite image processing. Solving this problem can help overcome various obstacles in urban planning, land cover classification, and environmental protection, paving the way for scene-level landscape pattern analysis and decision making. Encoder-decoder structures based on attention mechanisms have been frequently used for fine-resolution image segmentation. In this paper, we incorporate a coordinate attention (CA) mechanism, adopt an asymmetric convolution block (ACB), and design a refinement fusion block (RFB), forming a network named the fusion coordinate and asymmetry-based U-Net (FCAU-Net). Furthermore, we propose novel convolutional neural network (CNN) architecture to fully capture long-term dependencies and fine-grained details in fine-resolution remotely sensed imagery. This approach has the following advantages: (1) the CA mechanism embeds position information into a channel attention mechanism to enhance the feature representations produced by the network while effectively capturing position information and channel relationships; (2) the ACB enhances the feature representation ability of the standard convolution layer and captures and refines the feature information in each layer of the encoder; and (3) the RFB effectively integrates low-level spatial information and high-level abstract features to eliminate background noise when extracting feature information, reduces the fitting residuals of the fused features, and improves the ability of the network to capture information flows. Extensive experiments conducted on two public datasets (ZY-3 and DeepGlobe) demonstrate the effectiveness of the FCAU-Net. The proposed FCAU-Net transcends U-Net, Attention U-Net, the pyramid scene parsing network (PSPNet), DeepLab v3+, the multistage attention residual U-Net (MAResU-Net), MACU-Net, and the Transformer U-Net (TransUNet). Specifically, the FCAU-Net achieves a 97.97% (95.05%) pixel accuracy (PA), a 98.53% (91.27%) mean PA (mPA), a 95.17% (85.54%) mean intersection over union (mIoU), and a 96.07% (90.74%) frequency-weighted IoU (FWIoU) on the ZY-3 (DeepGlobe) dataset. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Decision making; Image coding; Image enhancement; Image fusion; Remote sensing; Satellite imagery; Semantic Segmentation; Semantics; Signal encoding; Asymmetric convolution block; Attention mechanisms; Feature information; Feature representation; Fine resolution; Fine-resolution remotely sensed image; Position information; Refinement fusion block; Remotely sensed images; Semantic segmentation; Convolution","Asymmetric convolution block; Attention mechanism; Fine-resolution remotely sensed images; Refinement fusion block; Semantic segmentation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85122211554"
"Ma C.; Gao H.","Ma, Conghui (56562155900); Gao, Hongchao (57471481400)","56562155900; 57471481400","A GAN based method for SAR and optical images fusion","2022","Proceedings of SPIE - The International Society for Optical Engineering","12166","","121664F","","","","10.1117/12.2617316","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125474916&doi=10.1117%2f12.2617316&partnerID=40&md5=04c5d0df6dd2dfd1a20109005ebc35dd","With the development of the remote sensing technology, the availability of satellite images has been dramatically increased with high quantity and quality. Diverse information can be obtained from these multiple imaging sources. For example, synthetic aperture radar (SAR) imagery measures physical properties of the observed scene in all-weather and full-time situation and follows a range-based imaging geometry, while optical imagery measures chemical characteristics of the scene and follows a perspective imaging geometry and needs both daylight and a cloudless sky. These multisource remote sensing images, once fused together, provide a more comprehensive interpretation of remote sensing scenes. Recent advances in Generative adversarial networks (GANs) have shown great promise in translating imagery between modalities, as well in the generation of high resolution and realistic imagery. In this paper, a GAN architecture is used to solve the task of fusing SAR and optical remote sensing imagery. The network learns the mapping between input and output image, and learns a loss function to train this mapping. Specifically, the generated network is divided into two parts, encoding and decoding. The fused image including SAR intensity and texture information is generated by the generator. Other details of the optical image are added to the fusion image gradually by the discriminator. The structural similarity loss function of GAN is to make the training of GAN model more accurate on the whole structure. Experiments on Sentinel-1and Sentinel-2 imagery confirm the effectiveness and efficiency of the proposed method.  © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Generative adversarial networks; Geometrical optics; Image fusion; Mapping; Radar imaging; Remote sensing; Textures; Imaging geometry; Learn+; Loss functions; Multiple imaging; Network-based; Optical image; Optical imagery; Remote sensing technology; Satellite images; Synthetic aperture radar images; Synthetic aperture radar","Generative adversarial network; Image fusion; Optical imagery; SAR","Conference paper","Final","","Scopus","2-s2.0-85125474916"
"Li Y.; Cai R.; Li J.; Liu Z.; Meng L.; He L.","Li, Yunfei (57218424664); Cai, Runlin (57283915000); Li, Jun (24481713500); Liu, Zhenjie (57215772908); Meng, Liangli (57608633700); He, Lin (57192205017)","57218424664; 57283915000; 24481713500; 57215772908; 57608633700; 57192205017","Pansharpening-Based Spatio-Temporal Fusion for Predicting Intense Surface Changes","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","5624114","","","","10.1109/TGRS.2022.3169494","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128636030&doi=10.1109%2fTGRS.2022.3169494&partnerID=40&md5=9564deb67ad2100ae03c795866e47533","Spatio-temporal fusion is a feasible way to provide synthetic satellite images with high spatial and high temporal resolution simultaneously. Due to its practicability, spatio-temporal fusion has gotten increasing attention, for which many spatio-temporal fusion approaches have been developed. Most spatio-temporal fusion methods follow the 'base fine image guided' (BFIG) fusion mode, resulting in the fact that their fusion results are similar to the base fine images. Therefore, these methods can perform well in areas with limited surface changes due to high similarity between the base and the predicted fine images. However, they might not be applicable in areas with intense surface changes. In this article, we develop a pansharpening-based spatio-temporal fusion model (PSTFM) by introducing the pansharpening fusion mode, which is 'coarse image guided' (CIG), into spatio-temporal fusion. PSTFM first trains a pansharpening convolutional neural network (CNN), which then fuses the coarse images and reconstructed panchromatic (Pan) images of the predicted time to recover the missing fine images. The newly proposed PSTFM is compared with three representative BFIG spatio-temporal fusion methods on two Landsat-Moderate Resolution Imaging Spectroradiometer (MODIS) datasets, both of which contain intense surface changes. After that, the experimental results are analyzed and discussed in detail. The experiments and the analysis demonstrate that the newly proposed PSTFM has remarkably qualitative and quantitative performance in predicting the intense surface changes while it is mediocre in areas with low surface change intensity.  © 1980-2012 IEEE.","Convolution; Image fusion; Neural networks; Base fine image guided; Coarse image guided; Convolutional neural network; Fine images; Image-guided; Land surface; Pan-sharpening; Remote-sensing; Spatial resolution; Spatio-temporal fusions; artificial neural network; Landsat; satellite data; spatiotemporal analysis; Remote sensing","Base fine image guided (BFIG); coarse image guided (CIG); convolutional neural network (CNN); pansharpening; spatio-temporal fusion","Article","Final","","Scopus","2-s2.0-85128636030"
"Issaoui W.; Alexakis D.D.; Nasr I.H.; Argyriou A.V.; Alevizos E.; Papadopoulos N.; Inoubli M.H.","Issaoui, Wissal (57223179966); Alexakis, Dimitrios D. (55901750800); Nasr, Imen Hamdi (24721723900); Argyriou, Athanasios V. (55848342500); Alevizos, Evangelos (56915984900); Papadopoulos, Nikos (55327516400); Inoubli, Mohamed Hédi (24721052000)","57223179966; 55901750800; 24721723900; 55848342500; 56915984900; 55327516400; 24721052000","Monitoring Olive Oil Mill Wastewater Disposal Sites Using Sentinel-2 and PlanetScopeSatellite Images: Case Studies in Tunisia and Greece","2022","Agronomy","12","1","90","","","","10.3390/agronomy12010090","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122194375&doi=10.3390%2fagronomy12010090&partnerID=40&md5=48d73759c235f02a520fb695636c9db8","Mediterranean countries are known worldwide for their significant contribution to olive oil production, which generates large amounts of olive mill wastewater (OMW) that degrades land and water environments near the disposal sites. OMW consists of organic substances with high concentrations of phenolic compounds along with inorganic particles. The aim of this study is to assess the effectiveness of satellite image analysis techniques using multispectral satellite data with high (PlanetScope, 3 × 3 m) and medium (Sentinel-2, 10 × 10 m) spatial resolution to detect Olive Mill Wastewater (OMW) disposal sites, both in the SidiBouzid region (Tunisia) and in the broader Rethymno region on the island of Crete, (Greece). Documentation of the sites was carried out by collecting spectral signatures of OMW at temporal periods. The study integrates the application of a variety of spectral vegetation indices (VIs), such as the Normalized Difference Vegetation Index (NDVI), in order to evaluate their efficiency in detecting OMW disposal areas. Furthermore, a set of image-processing methods was applied on satellite images to improve the monitoring of OMW ponds including the false-color composites (FCC), the Principal Component Analysis (PCA), and image fusion. Finally, different classification algorithms, such as the ISODATA, the maximum likelihood (ML), and the Support Vector Machine (SVM) were applied to both satellite images in order to assist in the overall approach to effectively detect the sites. The results obtained from different approaches were compared, evaluating the efficiency of Sentinel-2 and PlanetScope images to detect and monitor OMW disposal areas under different morphological environments. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","","Classification; Disposal sites; Indices; Olive mill wastewater (OMW); Remote sensing; Spectral signature","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85122194375"
"Ozcelik F.; Alganci U.; Sertel E.; Unal G.","Ozcelik, Furkan (57208564493); Alganci, Ugur (24281315400); Sertel, Elif (21934838300); Unal, Gozde (57220534209)","57208564493; 24281315400; 21934838300; 57220534209","Rethinking CNN-Based Pansharpening: Guided Colorization of Panchromatic Images via GANs","2021","IEEE Transactions on Geoscience and Remote Sensing","59","4","9153037","3486","3501","15","10.1109/TGRS.2020.3010441","31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103340930&doi=10.1109%2fTGRS.2020.3010441&partnerID=40&md5=4547984f760413e2dede1e82f04b7766","Convolutional neural network (CNN)-based approaches have shown promising results in the pansharpening of the satellite images in recent years. However, they still exhibit limitations in producing high-quality pansharpening outputs. To that end, we propose a new self-supervised learning framework, where we treat pansharpening as a colorization problem, which brings an entirely novel perspective and solution to the problem compared with the existing methods that base their solution solely on producing a super-resolution version of the multispectral image. Whereas the CNN-based methods provide a reduced-resolution panchromatic image as the input to their model along with the reduced-resolution multispectral images and, hence, learn to increase their resolution together, we instead provide the grayscale transformed multispectral image as the input and train our model to learn the colorization of the grayscale input. We further address the fixed downscale ratio assumption during training, which does not generalize well to the full-resolution scenario. We introduce a noise injection into the training by randomly varying the downsampling ratios. Those two critical changes, along with the addition of adversarial training in the proposed PanColorization generative adversarial network (PanColorGAN) framework, help overcome the spatial-detail loss and blur problems that are observed in CNN-based pansharpening. The proposed approach outperforms the previous CNN-based and traditional methods, as demonstrated in our experiments. © 1980-2012 IEEE.","Electrical engineering; Geology; Adversarial networks; Full resolutions; Multispectral images; Noise injection; Panchromatic images; Reduced resolution; Satellite images; Super resolution; data set; image analysis; image resolution; multispectral image; panchromatic image; satellite imagery; Convolutional neural networks","AI; colorization; convolutional neural networks (CNNs); deep learning; generative adversarial networks (GANs); image fusion; PanColorization generative adversarial network (PanColorGAN); pansharpening; self-supervised learning; super-resolution (SR)","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85103340930"
"Li Y.; Li J.; He L.","Li, Yunfei (57218424664); Li, Jun (24481713500); He, Lin (57192205017)","57218424664; 24481713500; 57192205017","A Single Image Pair-Based Convolutional Neural Network method for Spatio-Temporal Fusion; [单样本对卷积神经网络遥感图像时空融合]","2022","National Remote Sensing Bulletin","26","8","","1614","1623","9","10.11834/jrs.20219348","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141720665&doi=10.11834%2fjrs.20219348&partnerID=40&md5=c23381618123115600a9df9f317b5743","Due to the limitations of hardware technology and launching cost, there is a tradeoff between the spatial resolution and temporal resolution of satellite images. In order to access to the data with both high spatial and high temporal resolution, spatio-temporal fusion (STF) of remotely sensed images came into being. In recent years, convolutional neural networks (CNNs) have been successfully adopted in this field and some efficient STF methods based on CNNs were developed. However, these methods require a significant number of training image pairs, where each pair generally consists of a high spatial resolution image and a low spatial resolution image. Such a requirement limits the applicability of STF methods to real scenarios, as in many cases there is no wide availability of image pairs for training. To overcome this important limitation, in this paper we introduce a single image pair-based method (based on CNNs) for STF of remotely sensed images. Our method, called SS-CNN, uses the spatial information provided by the average image (obtained across the available spectral bands) of the high spatial resolution image to perform CNN-based super-resolution mapping (SRM) between the low and high spatial resolution images. Three experiments, including two simulated and one real ones, were used to evaluate the STF accuracy of SS-CNN. The obtained experimental results clearly demonstrate the effectiveness of our newly proposed method. © 2022 Science Press. All rights reserved.","Convolutional neural networks; Image fusion; Photomapping; Remote sensing; Convolutional neural network; Fusion methods; Hardware technology; High spatial resolution images; Image pairs; Neural network method; Remotely sensed images; Single image pair; Single images; Spatio-temporal fusions; Image resolution","CNN; remotely sensed images; single image pair; spatio-temporal fusion","Article","Final","","Scopus","2-s2.0-85141720665"
"An T.; Zhang X.; Huo C.; Xue B.; Wang L.; Pan C.","An, Tai (57424018000); Zhang, Xin (55792938900); Huo, Chunlei (24080315500); Xue, Bin (57220896004); Wang, Lingfeng (55721448100); Pan, Chunhong (8558023500)","57424018000; 55792938900; 24080315500; 57220896004; 55721448100; 8558023500","TR-MISR: Multiimage Super-Resolution Based on Feature Fusion With Transformers","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","1373","1388","15","10.1109/JSTARS.2022.3143532","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123378888&doi=10.1109%2fJSTARS.2022.3143532&partnerID=40&md5=95dff27ba2f421ed53ecd66bf736106d","Multiimage super-resolution (MISR), as one of the most promising directions in remote sensing, has become a needy technique in the satellite market. A sequence of images collected by satellites often has plenty of views and a long time span, so integrating multiple low-resolution views into a high-resolution image with details emerges as a challenging problem. However, most MISR methods based on deep learning cannot make full use of multiple images. Their fusion modules are incapable of adapting to an image sequence with weak temporal correlations well. To cope with these problems, we propose a novel end-to-end framework called TR-MISR. It consists of three parts: An encoder based on residual blocks, a transformer-based fusion module, and a decoder based on subpixel convolution. Specifically, by rearranging multiple feature maps into vectors, the fusion module can assign dynamic attention to the same area of different satellite images simultaneously. In addition, TR-MISR adopts an additional learnable embedding vector that fuses these vectors to restore the details to the greatest extent. TR-MISR has successfully applied the transformer to MISR tasks for the first time, notably reducing the difficulty of training the transformer by ignoring the spatial relations of image patches. Extensive experiments performed on the PROBA-V Kelvin dataset demonstrate the superiority of the proposed model that provides an effective method for transformers in other low-level vision tasks.  © 2008-2012 IEEE.","Deep learning; Image fusion; Job analysis; Remote sensing; Satellites; Deep learning; End-to-end network; Features extraction; Features fusions; Image super resolutions; Multi-image super-resolution; Multi-images; Remote-sensing; Superresolution; Task analysis; Transformer; digital mapping; machine learning; remote sensing; satellite data; satellite imagery; spatial resolution; Image resolution","Deep learning; end-to-end networks; feature extraction and fusion; multiimage super-resolution (MISR); remote sensing; transformers","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85123378888"
"Gacem A.; Berrached N.; Boudia S.M.","Gacem, A. (57151178600); Berrached, N. (56636254200); Boudia, S. Merad (57151063000)","57151178600; 56636254200; 57151063000","Improve road extraction by bayesian data fusion and mean shift segmentation in urban area","2015","International Review on Computers and Software","10","12","","1179","1185","6","10.15866/irecos.v10i12.7675","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959544705&doi=10.15866%2firecos.v10i12.7675&partnerID=40&md5=e99481d755ad0c779d9bd1c2abe1a26a","Automatic road extraction is a critical aspect for an effective use of remote-sensing imagery in most contexts. This paper proposes a robust approach based on an existing road extraction method, to provide a better result in urban road extraction. In this contribution, we integrate spectral information from the multispectral image with spatial information from the panchromatic image, to benefit from the spatial properties of high resolution satellite images, using Bayesian data fusion. The pan-sharpened image is then segmented with mean shift technique to weaken the appearance of objects and artifacts on the fused images, while keeping a good image quality to improve road extraction. The quality assessments in the studied urban area show that the completeness and correctness of the extracted major roads in the sense of their lengths were increased by more than 50%, using the Bayesian data fusion method and mean shift filtering. The results of the road extraction are vectorized for GIS integration and for a better interaction with experts. © 2015 Praise Worthy Prize S.r.l. - All rights reserved.","","Bayesian data fusion; Image smoothing; Mean shift; Multi-source image fusion; Road extraction; Urban area","Article","Final","","Scopus","2-s2.0-84959544705"
"Jenerowicz A.; Woroszkiewicz M.","Jenerowicz, Agnieszka (56539966900); Woroszkiewicz, Malgorzata (57193134667)","56539966900; 57193134667","The pan-sharpening of satellite and UAV imagery for agricultural applications","2016","Proceedings of SPIE - The International Society for Optical Engineering","9998","","99981S","","","","10.1117/12.2241645","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011114757&doi=10.1117%2f12.2241645&partnerID=40&md5=59ca11035c7fb10a20022830fc22bfb0","Remote sensing techniques are widely used in many different areas of interest, i.e. urban studies, environmental studies, agriculture, etc., due to fact that they provide rapid, accurate and information over large areas with optimal time, spatial and spectral resolutions. Agricultural management is one of the most common application of remote sensing methods nowadays. Monitoring of agricultural sites and creating information regarding spatial distribution and characteristics of crops are important tasks to provide data for precision agriculture, crop management and registries of agricultural lands. For monitoring of cultivated areas many different types of remote sensing data can be used-most popular are multispectral satellites imagery. Such data allow for generating land use and land cover maps, based on various methods of image processing and remote sensing methods. This paper presents fusion of satellite and unnamed aerial vehicle (UAV) imagery for agricultural applications, especially for distinguishing crop types. Authors in their article presented chosen data fusion methods for satellite images and data obtained from low altitudes. Moreover the authors described pan-sharpening approaches and applied chosen pan-sharpening methods for multiresolution image fusion of satellite and UAV imagery. For such purpose, satellite images from Landsat-8 OLI sensor and data collected within various UAV flights (with mounted RGB camera) were used. In this article, the authors not only had shown the potential of fusion of satellite and UAV images, but also presented the application of pan-sharpening in crop identification and management. © 2016 SPIE.","Agriculture; Crops; Data fusion; Ecology; Ecosystems; Hydrology; Image fusion; Image processing; Land use; Satellite imagery; Satellites; Unmanned aerial vehicles (UAV); Agricultural management; Land use and land cover; LANDSAT; Multiresolution images; Multispectral images; Pan-sharpening; Remote sensing techniques; Unnamed aerial vehicles; Remote sensing","Agriculture; Data Fusion; Image Processing; Landsat 8; Multispectral Image; Pan-Sharpening; UAV","Conference paper","Final","","Scopus","2-s2.0-85011114757"
"Batur E.; Maktav D.","Batur, Ersan (57195941906); Maktav, Derya (6601954343)","57195941906; 6601954343","Assessment of Surface Water Quality by Using Satellite Images Fusion Based on PCA Method in the Lake Gala, Turkey","2019","IEEE Transactions on Geoscience and Remote Sensing","57","5","8541109","2983","2989","6","10.1109/TGRS.2018.2879024","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057173840&doi=10.1109%2fTGRS.2018.2879024&partnerID=40&md5=b303d027cde9eba97f24bb7f806a6d44","Monitoring water quality with classical methods is not an easy task. Remote sensing with wide coverage and multiple temporal monitoring is the best solution for surface water quality monitoring. This paper demonstrates the determination of surface water quality parameters by using principal component analysis (PCA) data fusion and mining techniques with the aid of Landsat 8 OLI (L8 OLI), Sentinel 2A (S2A), and Göktürk-2 (GK2) satellite sensors. Chlorophyll-a, dissolved oxygen, total suspended solids, Secchi disk depth, total dissolved substance, and pH were the parameters selected for surface water quality analysis. High spectral resolution of L8 OLI/S2A images and the high spatial resolution of GK2 images were fused and analyzed by a suite of data mining models to provide more reliable images with both high spatial and temporal resolutions. Surface water quality parameters calculated by PCA-based response surface regression (RSR) method were compared with results obtained from multiple linear regression (MLR), artificial neural network (ANN), and support vector machines (SVMs) data mining methods. The performance of the data mining models derived using only multispectral band data and PCA fused data were quantified using four statistical indices; such as mean-square error (MSE), root MSE, mean absolute error, and coefficient of determination (R2). The analysis confirmed that the PCA-based RSR method is superior to MLR, ANN, and SVM data mining models to accurately estimate water quality parameters in lakes. © 1980-2012 IEEE.","Lake Gala; Turkey; Biochemical oxygen demand; Data mining; Dissolved oxygen; Image analysis; Image fusion; Image resolution; Lakes; Linear regression; Mean square error; Neural networks; Quality control; Remote sensing; Satellites; Sensors; Spectral resolution; Support vector machines; Surface properties; Water quality; Coefficient of determination; LANDSAT; Multiple linear regressions; Response surface methodology; Sentinel 2A (S2A); Spatial and temporal resolutions; Spatial resolution; Support vector machine (SVMs); artificial neural network; assessment method; data mining; image analysis; lake water; Landsat; numerical method; principal component analysis; remote sensing; satellite imagery; satellite sensor; Sentinel; spatial resolution; spectral resolution; surface water; water quality; Principal component analysis","Göktürk-2 (GK2); image fusion; Landsat 8 OLI (L8 OLI); principal component analysis (PCA); remote sensing; Sentinel 2A (S2A); water quality","Article","Final","","Scopus","2-s2.0-85057173840"
"Pour T.; Burian J.; Miřijovský J.","Pour, T. (57190172675); Burian, J. (35112842600); Miřijovský, J. (56483246400)","57190172675; 35112842600; 56483246400","Advanced extraction of spatial information from high resolution satellite data","2016","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","41","","","905","907","2","10.5194/isprsarchives-XLI-B3-905-2016","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978148870&doi=10.5194%2fisprsarchives-XLI-B3-905-2016&partnerID=40&md5=4174fb243cc2068cb375d2926e7ff861","In this paper authors processed five satellite image of five different Middle-European cities taken by five different sensors. The aim of the paper was to find methods and approaches leading to evaluation and spatial data extraction from areas of interest. For this reason, data were firstly pre-processed using image fusion, mosaicking and segmentation processes. Results going into the next step were two polygon layers; first one representing single objects and the second one representing city blocks. In the second step, polygon layers were classified and exported into Esri shapefile format. Classification was partly hierarchical expert based and partly based on the tool SEaTH used for separability distinction and thresholding. Final results along with visual previews were attached to the original thesis. Results are evaluated visually and statistically in the last part of the paper. In the discussion author described difficulties of working with data of large size, taken by different sensors and different also thematically.","Data fusion; Extraction; Image analysis; Image fusion; Image segmentation; Remote sensing; Satellite imagery; Satellites; European cities; High resolution satellite data; Obia; Satellite images; Seath; Segmentation process; Spatial informations; Urban areas; Image processing","Image Analysis; Obia; Satellite Imagery; Seath; Urban Areas","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-84978148870"
"Kwan C.; Yang J.; Chou B.","Kwan, Chiman (7201421216); Yang, Jerry (57211120044); Chou, Bryan (57197859877)","7201421216; 57211120044; 57197859877","Change Detection Using Original and Fused Landsat and Worldview Images","2019","2019 IEEE 10th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2019","","","8993020","0449","0454","5","10.1109/UEMCON47517.2019.8993020","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074212698&doi=10.1109%2fUEMCON47517.2019.8993020&partnerID=40&md5=900d31a174cc96271f7efe27dd2670e1","In this paper, we present some preliminary results on change detection using satellite images. We first present a change detection framework that incorporates multiple change detection algorithms. A number of change detection maps, including normalized difference of vegetation index (NDVI), nonhomogeneous feature difference (NFHD), global Reed-Xiaoli (GRX), chronochrome (CC), etc. are integrated to generate the final change map. We then present an algorithm to fuse low spatial resolution but high temporal Landsat and high spatial resolution but low temporal resolution Worldview images. Finally, we compare change detection results using pure Landsat images, pure Worldview images, and fused images. Our results indicate that there is definitely some advantages in using fused images for change detection. It was observed that change maps based on the fused images are slightly better than that of using the pure Landsat images and are worse than the pure Worldview images maps. Consequently, more research is needed in generating high quality fused images so that change detection using fused images can be further improved. © 2019 IEEE.","Image fusion; Image resolution; Mobile telecommunication systems; Ubiquitous computing; Change detection; Change detection maps; Color mapping; High spatial resolution; LANDSAT; Normalized differences; Temporal resolution; Worldview; Image enhancement","change detection; hybrid color mapping; image fusion; Landsat; Worldview","Conference paper","Final","","Scopus","2-s2.0-85074212698"
"Wang B.; Choi J.; Choi S.; Lee S.; Wu P.; Gao Y.","Wang, Biao (56498129900); Choi, Jaewan (9045393200); Choi, Seokeun (55635397100); Lee, Soungki (56195745300); Wu, Penghai (55644317800); Gao, Yan (57195473211)","56498129900; 9045393200; 55635397100; 56195745300; 55644317800; 57195473211","Image fusion-based land cover change detection using multi-temporal high-resolution satellite images","2017","Remote Sensing","9","8","804","","","","10.3390/rs9080804","25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028327092&doi=10.3390%2frs9080804&partnerID=40&md5=59c2884581f075486a50287fcaafbc46","Change detection is usually treated as a problem of explicitly detecting land cover transitions in satellite images obtained at different times, and helps with emergency response and government management. This study presents an unsupervised change detection method based on the image fusion of multi-temporal images. The main objective of this study is to improve the accuracy of unsupervised change detection from high-resolution multi-temporal images. Our method effectively reduces change detection errors, since spatial displacement and spectral differences between multi-temporal images are evaluated. To this end, a total of four cross-fused images are generated with multi-temporal images, and the iteratively reweighted multivariate alteration detection (IR-MAD) method-a measure for the spectral distortion of change information-is applied to the fused images. In this experiment, the land cover change maps were extracted using multi-temporal IKONOS-2,WorldView-3, and GF-1 satellite images. The effectiveness of the proposed method compared with other unsupervised change detection methods is demonstrated through experimentation. The proposed method achieved an overall accuracy of 80.51% and 97.87% for cases 1 and 2, respectively. Moreover, the proposed method performed better when differentiating the water area from the vegetation area compared to the existing change detection methods. Although the water area beneath moderate and sparse vegetation canopy was captured, vegetation cover and paved regions of the water body were the main sources of omission error, and commission errors occurred primarily in pixels of mixed land use and along the water body edge. Nevertheless, the proposed method, in conjunction with high-resolution satellite imagery, offers a robust and flexible approach to land cover change mapping that requires no ancillary data for rapid implementation. © 2017 by the authors.","Errors; Image analysis; Image fusion; Iterative methods; Land use; Satellite imagery; Satellites; Vegetation; Alteration detections; Change detection; Government management; High resolution image; High resolution satellite imagery; High resolution satellite images; Land cover; Unsupervised change detection; Mapping","Change detection; High resolution image; Image analysis; Image fusion; Land cover","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85028327092"
"Mora A.; Santos T.M.A.; Lukasik S.; Silva J.M.N.; Falcão A.J.; Fonseca J.M.; Ribeiro R.A.","Mora, André (15728256600); Santos, Tiago M.A. (55364476400); Lukasik, Szymon (24385431300); Silva, João M.N. (55447844200); Falcão, António J. (23033931600); Fonseca, José M. (34769664200); Ribeiro, Rita A. (56527722100)","15728256600; 55364476400; 24385431300; 55447844200; 23033931600; 34769664200; 56527722100","Land cover classification from multispectral data using computational intelligence tools: A comparative study","2017","Information (Switzerland)","8","4","147","","","","10.3390/info8040147","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85036460977&doi=10.3390%2finfo8040147&partnerID=40&md5=18fa59783662cd4249dfebd21f5382a1","This article discusses how computational intelligence techniques are applied to fuse spectral images into a higher level image of land cover distribution for remote sensing, specifically for satellite image classification. We compare a fuzzy-inference method with two other computational intelligence methods, decision trees and neural networks, using a case study of land cover classification from satellite images. Further, an unsupervised approach based on k-means clustering has been also taken into consideration for comparison. The fuzzy-inference method includes training the classifier with a fuzzy-fusion technique and then performing land cover classification using reinforcement aggregation operators. To assess the robustness of the four methods, a comparative study including three years of land cover maps for the district of Mandimba, Niassa province, Mozambique, was undertaken. Our results show that the fuzzy-fusion method performs similarly to decision trees, achieving reliable classifications; neural networks suffer from overfitting; while k-means clustering constitutes a promising technique to identify land cover types from unknown areas. © 2017 by the authors.","Artificial intelligence; Decision trees; Fuzzy inference; Fuzzy neural networks; Image fusion; Intelligent control; Mathematical operators; Personnel training; Remote sensing; Satellite imagery; Spectroscopy; Aggregation operator; Comparative studies; Computational intelligence methods; Computational intelligence techniques; Fuzzy inference method; Land cover classification; Satellite image classification; Unsupervised approaches; Image classification","Aggregation operators; Image fusion; Land cover classification; Remote sensing","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85036460977"
"Anandhi D.; Valli S.","Anandhi, D. (57200875841); Valli, S. (13409224400)","57200875841; 13409224400","An algorithm for multi-sensor image fusion using maximum a posteriori and nonsubsampled contourlet transform","2018","Computers and Electrical Engineering","65","","","139","152","13","10.1016/j.compeleceng.2017.04.002","28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017445666&doi=10.1016%2fj.compeleceng.2017.04.002&partnerID=40&md5=fdb262ebf2b03713ddfd0dea7e8875ef","Multi-sensor image fusion draws an inference based on the information obtained from different sensors. Recently, wavelet and contourlet transforms have been widely used in multi-sensor image fusion. But these transforms have been inadequate in the representation of images due to their subsampling. Hence, a fusion algorithm based on Synthetic Aperture Radar (SAR) and Panchromatic (PAN) images in Nonsubsampled Contourlet Transform (NSCT) domain is proposed. NSCT gives flexible multiscale, multidirectional expansion for images. A high fusion accuracy is achieved by ‘Maximum A Posteriori (MAP)’ estimation based on Rayleigh and Laplacian probabilities for despeckling of SAR higher frequency coefficients. Subsequently, the despeckled SAR coefficient is directly fused with PAN coefficients using the newly developed Edge-based fusion rule. The combination of NSCT, MAP and Edge-fusion rule facilitates maximum preservation of the edge and the texture information. The performance of the proposed fusion algorithm is evaluated using reference and non-reference quality metrics. The results prove that the proposed method outperforms the existing NSCT methods by preserving maximum features. © 2017 Elsevier Ltd","Frequency estimation; Image enhancement; Radar; Radar imaging; Synthetic aperture radar; De-speckling; Maximum a posteriori; Maximum a posteriori estimation; Non subsampled contourlet transform (NSCT); Non-sub-sampled contourlet transforms; Panchromatic (Pan) image; Satellite images; Wavelet and contourlet transform; Image fusion","Despeckling; Maximum a posteriori estimation; Nonsubsampled Contourlet Transform; Satellite image fusion; Synthetic Aperture Radar","Article","Final","","Scopus","2-s2.0-85017445666"
"Xue G.; Ding Y.; Chu W.","Xue, Guangyin (57207732986); Ding, Yuxue (57211228836); Chu, Weiyu (57211229392)","57207732986; 57211228836; 57211229392","Analysis of the remote sensing image processing method of the mine monitoring","2019","ACM International Conference Proceeding Series","","","","478","481","3","10.1145/3349341.3349454","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073077427&doi=10.1145%2f3349341.3349454&partnerID=40&md5=09042b3b9fa61acee6fe6c2c0cbf9753","In Mine Remote Sensing monitoring, remote sensing data, as a basic data source of monitoring has replaced traditional aerial photographs, and high resolution satellite data is the most widely used nowadays. Based on this, the characteristics of high resolution satellite remote sensing data are introduced, and the image fusion method of high resolution satellite image data is discussed according to the requirements of mine remote sensing monitoring. © 2019 Association for Computing Machinery.","Antennas; Artificial intelligence; Image fusion; Image processing; Monitoring; Processing; Satellites; Aerial Photographs; High resolution satellite data; High resolution satellite images; High resolution satellites; Image fusion methods; Remote sensing data; Remote sensing image processing; Remote sensing monitoring; Remote sensing","Image fusion; Image processing; Mine monitoring; Remote sensing","Conference paper","Final","","Scopus","2-s2.0-85073077427"
"Li S.; Zhang W.; Yang S.","Li, Shengyang (14031768000); Zhang, Wanfeng (55674650200); Yang, Song (57191892271)","14031768000; 55674650200; 57191892271","Intelligence fusion method research of multisource high-resolution remote sensing images","2017","Yaogan Xuebao/Journal of Remote Sensing","21","3","","415","424","9","10.11834/jrs.20176386","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027270468&doi=10.11834%2fjrs.20176386&partnerID=40&md5=8680521c6c9499b4991e0956a67e6588","Intelligent fusion of multi-source high resolution remote sensing images is attracting more attention due to its extensive applications. To satisfy application requirements of multi-source high resolution remote sensing image fusion, this paper studies ""on-demand"" intelligent fusion of multi-source remote sensing images. Particularly, this study focuses on intelligent fusion of different temporal high-resolution remote sensing images at different resolutions. This paper presents a novel intelligent fusion approach to achieve automatic image source selection as well as fusion method recommendation. This research applies the decision tree algorithm to high resolution remote sensing image fusion. The decision tree is trained to build the knowledge base of fusion rules, which is off-line updated. Each training sample consists of remote sensing images, fusion methods, and the evaluation results. Besides, to solve the problem of spectral distortion cause by hyperspherical color space transform, this paper proposes a fusion method renamed as Curvelet-HCS based on the second generation Curvelet transform and hyperspherical color space transform. The main idea of Curvelet-HCS is as follows. Curvelet-HCS decompose the image into low and high frequency components and employ different fusion rules for these two components. In detail, for the low frequency component, low frequency coefficients are computed as a weighted sum of low frequency coefficients of two fusing images, where weights are defined as functions of regional standard deviation and the local direction information entropy. Similarly, for the high frequency component, the high frequency coefficients are determined by the maximum. This research experiment the Curvelet-HCS method with different sources of satellite images, including the GF-1 and GF-2 satellite multispectral and panchromatic images. To evaluate the fusion performance of the proposed approach objectively, the fused images are quantitatively analyzed based on the mean, the standard deviation, the correlation coefficient, the information entropy and the average gradient. The results show that the image has a better visual effect after fusion, and the proposed fusion method achieves better performance compared to other fusion methods including Principal Component Analysis, Gramm-Schmidt, and Hyperspherical Color Sharpening. This thesis presents an intelligent fusion method by studying the relationship among the remote sensing images, the fusion methods and the evaluation results. This fusion approach improves the level of automation and intelligence of multi-resource high resolution remote sensing image fusion. It is a beneficial exploration for researching the intelligent on-demand service pattern. Also, this paper proposes a Curvelet-HCS fusion method which can fuse more than three bands of MS image at one time. The experimental results demonstrate that the proposed method is an effective method for fusing multispectral image and panchromatic image, and obtains good fused images. © 2017, Science Press. All right reserved.","Color; Data mining; Decision trees; Image analysis; Image enhancement; Image reconstruction; Knowledge based systems; Principal component analysis; Remote sensing; Space optics; Statistics; Trees (mathematics); Fusion methods; Fusion rule; High resolution; Intelligent fusion; Remote sensing images; Image fusion","Decision tree; Fusion method; Fusion rules; High resolution; Intelligent fusion; Remote sensing image","Article","Final","","Scopus","2-s2.0-85027270468"
"Mangalraj P.; Agrawal R.A.","Mangalraj, P. (56901364700); Agrawal, Rajuraykar Anupam (56900480800)","56901364700; 56900480800","An efficient method based on wavelet for fusion of multi-sensor satellite images","2015","Proceedings of 2015 IEEE International Conference on Electrical, Computer and Communication Technologies, ICECCT 2015","","","7226108","","","","10.1109/ICECCT.2015.7226108","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954129976&doi=10.1109%2fICECCT.2015.7226108&partnerID=40&md5=4643e1fa51b93173d13ecbb530f7cb4a","In this paper an efficient fusion algorithm for remotely sensed images has proposed. The wavelet tool is used for the decomposition of the images at different resolutions. By applying the fusion rules at different components (Approximated and Detailed) the desired output was obtained. The results of the proposed fusion algorithm are compared with the conventional Principal Component Analysis method. It is proved by the quantitative analysis, the proposed one outperforms the existing conventional fusion technique. © 2015 IEEE.","Algorithms; Chemical analysis; Fusion reactions; Principal component analysis; Wavelet decomposition; Different resolutions; Fusion algorithms; Fusion rule; Fusion techniques; Multi-sensor satellite images; Principal component analysis method; Remotely sensed images; Wavelet; Image fusion","Fusion; Quantitative Analysis; Wavelet","Conference paper","Final","","Scopus","2-s2.0-84954129976"
"Millán S.; Bolaños J.A.; García-Valencia C.; Gómez-López D.I.","Millán, Santiago (57189634785); Bolaños, Jiner Antonio (57192997819); García-Valencia, Carolina (57192995960); Gómez-López, Diana Isabel (36704693500)","57189634785; 57192997819; 57192995960; 36704693500","Remote sensing applied to recognition of seagrass meadows in low visibilities environments: La Guajira, Colombia; [Teledetección aplicada al reconocimiento de praderas de pastos marinos en ambientes de baja visibilidad: La Guajira, Colombia]","2016","Boletin de Investigaciones Marinas y Costeras","45","2","","289","315","26","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009887787&partnerID=40&md5=64cf92bb357d05a677ed160e805acafc","Seagrass meadows are important ecosystems due to their high productivity and ecological value among tropical ecosystems, because of their high species diversity. In Colombia seagrasses are located around some islands, oceanic coral banks and along the Caribbean shelf, mainly in La Guajira Department, where more than 80% of the seagrass meadows of the country are present. In the world, the delimitation of this ecosystem has been successfully mapped during years, with assistance of remote sensing, using satellite image of different spatial scales. Nevertheless, the specific environmental conditions in La Guajira, such as high water turbidity and reduced light penetration restrict the use of traditional satellite images employed for those seascapes. With the aim of delimiting and establishing the extension of seagrass meadows in La Guajira, based on analyses between July 2013 and February 2014, a methodology of massive image interpretation that included fieldwork fast verification was applied, generating as a result one layer of seagrass habitats in Cabo de La Vela - Dibulla area at 1:100000 scale. Methodology included geometric correction, image fusion, fieldwork information, definition of thematic classes, determining of criteria for spatial delimitation, visual interpretation of images, thematic uncertainty qualification, and final cartography production. The process of cartographic production showed that Landsat 8 OLI satellite sensor images made easier the identification of seagrass meadows in deep areas (>10m). In total, 53621 ha of seagrass meadows were identified, and the largest meadows of Colombia were delimitated, which reach dimensions of up to 6018 ha.","","La Guajira; Remote sensing; Satellite images; Seagrasses meadows","Article","Final","","Scopus","2-s2.0-85009887787"
"Ye B.; Liu L.","Ye, Baoying (23971837800); Liu, Ling (57221211961)","23971837800; 57221211961","Remote sensing monitoring land use change in Donglutian coal mine, Shuozhou City","2017","IOP Conference Series: Earth and Environmental Science","52","1","012110","","","","10.1088/1742-6596/52/1/012110","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014666798&doi=10.1088%2f1742-6596%2f52%2f1%2f012110&partnerID=40&md5=e4bf2552cdc3be77e6f0f8fd27337af8","This paper monitored the coal mine exploitation in Donglutian coal mine, Shuozhou city, Shanxi Province. Landsat satellite images from 2008 to 2016 were selected, and then 15m color composite images were obtained through data processing and image fusion. On this basis, the land use map from 2008 to 2016 was obtained using visual interpretation method. Results showed that the main land use type in this area was cropland, unused land and coalmine. Area of cropland and unused land kept decreasing year by year, while coal mine expanded rapidly. The expansion of coal mine concentrated on two time periods: from 2009 to 2010 and from 2012 to 2013. During these two time periods, topsoil stripping was the main exploitation type, while deep mining was the main type for other times. Results also presented that the exploitation number of small coals kept increasing year by year, from the initial number of 26 at 2008 to 42 at 2016. © Published under licence by IOP Publishing Ltd.","Coal; Data fusion; Data handling; Environmental protection; Image fusion; Land use; Remote sensing; Satellite imagery; Color composite image; Land use maps; Land use type; Land-use change; LANDSAT satellite images; Remote sensing monitoring; Time-periods; Visual interpretation; Coal mines","","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85014666798"
"Maharnisha G.; Veerasundari R.; Kumar G.R.; Arunraj","Maharnisha, Gandla (57202899817); Veerasundari, R. (57215911932); Kumar, Gandla Roopesh (57215913272); Arunraj (57224284051)","57202899817; 57215911932; 57215913272; 57224284051","Improving the spatial resolution of real time satellite image fusion using 2D curvelet transform","2018","International Journal of Engineering and Technology(UAE)","7","2.19 Special issue  19","","55","60","5","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082343339&partnerID=40&md5=7e9722ef3fb7c99bf97bc3250f63efa8","The fused image will have structural details of the higher spatial resolution panchromatic images as well as rich spectral information from the multispectral images. Before fusion, Mean adjustment algorithm of Adaptive Median Filter (AMF) and Hybrid Enhancer (combination of AMF and Contrast Limited Adaptive Histogram Equalization (CLAHE)) are used in the preprocessing. Here, conventional Principal Component image fusion method will be compared with newly modified Curvelet transform image fusion method. Principal Component fusion technique will improve the spatial resolution but it may produce spectral degradation in the output image. To over-come the spectral degradation, Curvelet transform fusion methods can be used. Curvelet transform uses curve which represents edges and extraction of the detailed information from the image. Curvelet Transform of individual acquired low-frequency approximate component of PAN image and high-frequency detail components from PAN and MS image is used. Peak Signal to Noise Ratio (PSNR) and Root Mean Square Error (RMSE) are measured to evaluate the image fusion accuracy. © 2016 Authors.","","Cloud computing; Edge computing; Fog computing; IoT","Article","Final","","Scopus","2-s2.0-85082343339"
"Chaithra C.C.; Taranath N.L.; Darshan L.M.; Subbaraya C.K.","Chaithra, C.C. (57205632104); Taranath, N.L. (56538645800); Darshan, L.M. (57205625530); Subbaraya, C.K. (55298457800)","57205632104; 56538645800; 57205625530; 55298457800","A Survey on Image Fusion Techniques and Performance Metrics","2018","Proceedings of the 2nd International Conference on Electronics, Communication and Aerospace Technology, ICECA 2018","","","8474818","995","999","4","10.1109/ICECA.2018.8474818","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060894932&doi=10.1109%2fICECA.2018.8474818&partnerID=40&md5=9172addb4d2d99e854ba384d6c9b5f60","Image fusion is the process of merging two or more relevant information into one image. The resulted image will have more explanatory than original images. Multispectral image (MS) is obtained from satellite, multispectral image having rich spectral information and low spatial resolution. MS have less information which is not suitable for remote sensor application. Panchromatic (PAN) image is one of the types of satellite images. PAN images have more spectral information but low spatial information. In remote sensing application more spatial and spectral information is required, so merging MS and PAN will result in rich spatial and spectral image. Many fusion algorithms are supported to fuse MS and PAN. Some techniques are principal component analysis, discrete wavelet transform, pixel-level image fusion and multisensor image fusion. Qualitative analysis determines the performance of fused image by comparison between original image and resulted fused image. Some qualitative metrics are evaluated using Root mean square error (RMSE), Relative global dimensional synthesis error (ERGAS), Quality factor (Q4), Cross correlation (CC) and Spectral angle mapper (SAM). This paper reviews about various fusion techniques in remote sensor and quality metrics. © 2018 IEEE.","Discrete wavelet transforms; Fighter aircraft; Image analysis; Image compression; Mean square error; Merging; Principal component analysis; Quality control; Remote sensing; Spectroscopy; Image fusion techniques; Intensity hue saturations; Multisensor image fusion; Panchromatic (Pan) image; Pixel-level image fusion; Quality metrics; Remote sensing applications; Root mean square errors; Image fusion","Intensity-Hue-Saturation; Principal component analysis (PCA); wavelets transform and quality metrics","Conference paper","Final","","Scopus","2-s2.0-85060894932"
"Zhang D.-D.; Xie F.; Zhang L.","Zhang, Dong-Dong (57208124753); Xie, Feng (57200331120); Zhang, Lei (55961752800)","57208124753; 57200331120; 55961752800","Preprocessing and fusion analysis of GF-2 satellite Remote-sensed spatial data","2019","Proceedings of 2018 International Conference on Information Systems and Computer Aided Education, ICISCAE 2018","","","8666873","24","29","5","10.1109/ICISCAE.2018.8666873","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063860635&doi=10.1109%2fICISCAE.2018.8666873&partnerID=40&md5=edbcf5be2c2d0199d0ac965f53b90e0c","There is no pansharpening method that can be applied to all kinds of images at present due to the principle of fusion processing and the characteristics of sensors that acquire images. In order to explore the suitable fusion method for the » Gaofen-2 » satellite image, PCA, HPF, Gram-Schmidt and NNDiffuse four kinds of fusion methods were selected to merge the panchromatic and multi spectral data of Gaofen-2 satellite images, the fusion results of the image were synthetically compared and evaluated with subjective evaluation and quantitative analysis. The test results show that the NNDiffuse transform method has the best combination effect and is very prominent in the fusion effect of the visible light band; And in the fusion of near-infrared band, Gram-Schmidt method can be considered. The research results of this paper can provide reference for the fusion processing and application of Gaofen-2 satellite image data. © 2018 IEEE.","Chemical analysis; Computer aided instruction; Image processing; Information systems; Information use; Infrared devices; Remote sensing; Satellites; Combination effects; Gaofen-2; Multi-spectral data; NNDiffuse; Pan-sharpening; Satellite image datas; Subjective evaluations; Visible light bands; Image fusion","Gaofen-2; NNDiffuse; Pansharpening; quantitative analysis; subjective evaluation","Conference paper","Final","","Scopus","2-s2.0-85063860635"
"Sojasi S.; Maldague X.","Sojasi, Saeed (57190260932); Maldague, Xavier (7003528304)","57190260932; 7003528304","Satellite image fusion by using a combination of IHS and HPM methods","2017","Proceedings of SPIE - The International Society for Optical Engineering","10214","","102141L","","","","10.1117/12.2266038","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023605449&doi=10.1117%2f12.2266038&partnerID=40&md5=757943d37e6cf2df13885665f25eb88e","There are numerous image fusion techniques such as intensity-hue-saturation (IHS) transform and principal component analysis (PCA). These methods are offering promising performance but the drawback with them is that they are not necessarily optimal in newer applications such as Ikonos and QuickBird. Color distortion is of vital importance in fusion image processing. The main result of this paper is the development of a fast HPM-enhanced version of the IHS method for application in fusion image processing in high-resolution satellite images. Combining these two methods makes it possible to benefit from the advantages of both methods. To evaluate the HPM-enhanced version of IHS method we used QuickBird data. The HPM-enhanced version of IHS and HPM-enhanced IHS are used interchangeably. The simulation results of this method show that it is capable of providing a significant improvement in preserving spectral and spatial information. © 2017 SPIE.","Image processing; Infrared devices; Infrared radiation; Principal component analysis; Color distortions; High resolution satellite images; Ikonos; Image fusion techniques; Intensity hue saturations; Quickbird datum; Satellite images; Spatial informations; Image fusion","HPM; IHS; Ikonos; Image Fusion","Conference paper","Final","","Scopus","2-s2.0-85023605449"
"Padmanaban R.; Bhowmik A.K.; Cabral P.","Padmanaban, Rajchandar (57191844026); Bhowmik, Avit K. (42961032900); Cabral, Pedro (56221630400)","57191844026; 42961032900; 56221630400","Satellite image fusion to detect changing surface permeability and emerging urban heat islands in a fast-growing city","2019","PLoS ONE","14","1","e0208949","","","","10.1371/journal.pone.0208949","26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059423931&doi=10.1371%2fjournal.pone.0208949&partnerID=40&md5=456ab97b133a095e4d82c8b44c2d7038","Rapid and extensive urbanization has adversely impacted humans and ecological entities in the recent decades through a decrease in surface permeability and the emergence of Urban Heat Islands (UHI). While detailed and continuous assessments of surface permeability and UHI are crucial for urban planning and management of landuse zones, they mostly involve time consuming and expensive field studies and single sensor derived large scale aerial and satellite imageries. We demonstrated the advantage of fusing imageries from multiple sensors for landuse and landcover (LULC) change assessments as well as for assessing surface permeability and temperature and UHI emergence in a fast growing city, i.e. Tirunelveli, Tamilnadu, India. IRS-LISSIII and Landsat-7 ETM+ imageries were fused for 2007 and 2017, and classified using a Rotation Forest (RF) algorithm. Surface permeability and temperature were then quantified using Soil-Adjusted Vegetation Index (SAVI) and Land Surface Temperature (LST) index, respectively. Finally, we assessed the relationship between SAVI and LST for entire Tirunelveli as well as for each LULC zone, and also detected UHI emergence hot spots using a SAVI-LST combined metric. Our fused images exhibited higher classification accuracies, i.e. overall kappa coefficient values, than non-fused images. We observed an overall increase in the coverage of urban (dry, real estate plots and built-up) areas, while a decrease for vegetated (cropland and forest) areas in Tirunelveli between 2007 and 2017. The SAVI values indicated an extensive decrease in surface permeability for Tirunelveli overall and also for almost all LULC zones. The LST values showed an overall increase of surface temperature in Tirunelveli with the highest increase for urban built-up areas between 2007 and 2017. LST also exhibited a strong negative association with SAVI. Southeastern built-up areas in Tirunelveli were depicted as a potential UHI hotspot, with a caution for the Western riparian zone for UHI emergence in 2017. Our results provide important metrics for surface permeability, temperature and UHI monitoring, and inform urban and zonal planning authorities about the advantages of satellite image fusion. © 2019 Padmanaban et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","Environmental Monitoring; Humans; India; Satellite Imagery; Temperature; Urbanization; Article; city; environmental temperature; forest; geographic and geological phenomena; land biome; land use; permeability; satellite imagery; scrub; urban area; urban heat island; wetland; environmental monitoring; human; India; procedures; satellite imagery; temperature; urbanization","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85059423931"
"Vibhute A.D.; Gaikwad S.V.; Dhumal R.K.; Nagne A.D.; Varpe A.B.; Nalawade D.B.; Kale K.V.; Mehrotra S.C.","Vibhute, Amol D. (55811504600); Gaikwad, Sandeep V. (57189381643); Dhumal, Rajesh K. (56448892100); Nagne, Ajay D. (56449298200); Varpe, Amarsinh B. (56392893900); Nalawade, Dhananjay B. (57200073514); Kale, Karbhari V. (6701566257); Mehrotra, Suresh C. (7102264286)","55811504600; 57189381643; 56448892100; 56449298200; 56392893900; 57200073514; 6701566257; 7102264286","Hyperspectral and Multispectral Remote Sensing Data Fusion for Classification of Complex-Mixed Land Features Using SVM","2019","Communications in Computer and Information Science","1035","","","345","362","17","10.1007/978-981-13-9181-1_31","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070228679&doi=10.1007%2f978-981-13-9181-1_31&partnerID=40&md5=5a17b43593357c1753689a202726d4b2","In the present paper, classification and analysis of complex land features on the combined outcome of the high spectral resolution Hyperion-Hyperspectral Remote Sensing (HRS) data and high spatial resolution Resourcesat-II Linear Imaging Self-Scanning System IV (LISS-IV) multispectral data were investigated. The traditional way of satellite image fusion is based on high spatial resolution panchromatic image and low spatial-spectral resolution multispectral image. However, in the current study, a novel approach via considering HRS and LISS-IV multispectral data is proposed for classification of complex features of earth surface. The used multi-date, multi-sensor and multi-resolution satellite imagery was acquired on$$20^{th}$$ March, 2015 and$$28^{th}$$ February, 2014 of HRS and LISS-IV data having spatial resolution 30 m and 5.8 m respectively. Three pixel level image fusion algorithms were computed such as Gram-Schmidt Transform (GST), Principal Component Spectral Sharpening Transform (PCSST) and Color Normalized Spectral Sharpening (CNSS) for fusion of datasets. The quality of the fusion algorithms has been estimated on the classification accuracy of mixed features. Moreover, the performance of three fusion algorithms was compared with the classification results. The assessment results of fused data using all the methods were acceptable in view of spatial-spectral accuracy of data. The Support Vector Machine (SVM) approach with its Gaussian Radial Basis Function (GRBF) kernel was implemented for classification of original and fused data. In conclusion, the SVM algorithm resulted accurate with 97.65, 97.47, 96.30, 86.20 and 74.44% accuracy for CNSS fused, PCSST fused, GST fused, and original multispectral and original hyperspectral data respectively and proved very robust method for mixed feature classification. © 2019, Springer Nature Singapore Pte Ltd.","Hyperspectral imaging; Image fusion; Image resolution; Pattern recognition; Radial basis function networks; Remote sensing; Satellite imagery; Spectral resolution; Support vector machines; Gram-Schmidt transform; Hyperspectral Data; Satellite images; Spectral classification; Spectral sharpening; Classification (of information)","Gram-Schmidt Transform; Hyperspectral data; Principal Component Spectral Sharpening; Satellite image fusion; Spatial-spectral classification; Support vector machine","Conference paper","Final","","Scopus","2-s2.0-85070228679"
"Synthiya Vinothini D.; Sathya Bama B.","Synthiya Vinothini, D. (57198896392); Sathya Bama, B. (36024410500)","57198896392; 36024410500","Quaternion-Based Sparse Model for Pan-Sharpening of IRS Satellite Images","2018","Journal of the Indian Society of Remote Sensing","46","12","","2069","2079","10","10.1007/s12524-018-0878-8","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055878079&doi=10.1007%2fs12524-018-0878-8&partnerID=40&md5=64c6854f1a17891f4e14b780783c60bc","This paper considers the pan-sharpening problem of the IRS satellite images from the perspective of vector sparse representation model using quaternion matrix analysis. It selects the sparse basis in quaternion space, which uniformly transforms the color channels into an orthogonal color space. Moreover, the proposed quaternion model for pan-sharpening is more efficient than the conventional sparse model as the hyper-complex representation of color channels conserves the interrelationship among the chromatic channels. This paper also proposes a quaternion forward–backward pursuit algorithm that preserves the inherent chromatic structures in terms of spatial and spectral details during the vector reconstruction. The experimental result validates the efficacy of the proposed quaternion model and shows its potential as a powerful pan-sharpening tool for IRS data even for cloudy multispectral data. © 2018, Indian Society of Remote Sensing.","algorithm; image analysis; multispectral image; numerical model; panchromatic image; remote sensing; satellite data; satellite imagery","Image fusion; Indian remote sensing satellite; Multispectral image; Pan-sharpening; Panchromatic image; Quaternions; Remote sensing; Sparse representation","Article","Final","","Scopus","2-s2.0-85055878079"
"Ahrari A.H.; Kiavarz M.; Hasanlou M.; Marofi M.","Ahrari, A.H. (57216691167); Kiavarz, M. (57194688190); Hasanlou, M. (55178361600); Marofi, M. (57196237941)","57216691167; 57194688190; 55178361600; 57196237941","Thermal and visible satellite image fusion using wavelet in remote sensing and satellite image processing","2017","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","4W4","","11","15","4","10.5194/isprs-archives-XLII-4-W4-11-2017","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032383744&doi=10.5194%2fisprs-archives-XLII-4-W4-11-2017&partnerID=40&md5=0a117416347edcc29a363bb118a40ef8","Multimodal remote sensing approach is based on merging different data in different portions of electromagnetic radiation that improves the accuracy in satellite image processing and interpretations. Remote Sensing Visible and thermal infrared bands independently contain valuable spatial and spectral information. Visible bands make enough information spatially and thermal makes more different radiometric and spectral information than visible. However low spatial resolution is the most important limitation in thermal infrared bands. Using satellite image fusion, it is possible to merge them as a single thermal image that contains high spectral and spatial information at the same time. The aim of this study is a performance assessment of thermal and visible image fusion quantitatively and qualitatively with wavelet transform and different filters. In this research, wavelet algorithm (Haar) and different decomposition filters (mean.linear, ma, min and rand) for thermal and panchromatic bands of Landast8 Satellite were applied as shortwave and longwave fusion method. Finally, quality assessment has been done with quantitative and qualitative approaches. Quantitative parameters such as Entropy, Standard Deviation, Cross Correlation, Q Factor and Mutual Information were used. For thermal and visible image fusion accuracy assessment, all parameters (quantitative and qualitative) must be analysed with respect to each other. Among all relevant statistical factors, correlation has the most meaningful result and similarity to the qualitative assessment. Results showed that mean and linear filters make better fused images against the other filters in Haar algorithm. Linear and mean filters have same performance and there is not any difference between their qualitative and quantitative results.","Electromagnetic waves; Image enhancement; Image processing; Infrared radiation; Q factor measurement; Remote sensing; Satellite imagery; Satellites; Space optics; Wavelet decomposition; Wavelet transforms; Multi-modal; Performance assessment; Qualitative assessments; Quantitative parameters; Remote sensing approaches; Satellite image processing; Thermal infrared bands; Visible image; Image fusion","Multimodal remote sensing; Thermal and visible image fusion; Wavelets algorithms","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85032383744"
"Wei J.; Huang Y.","Wei, Jingbo (55711392500); Huang, Yukun (56242862100)","55711392500; 56242862100","NMPE: A normalized metric for measuring generalized spatial distortion of multispectral panshapening fusion","2017","Multimedia Tools and Applications","76","21","","23099","23116","17","10.1007/s11042-017-4518-z","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014518991&doi=10.1007%2fs11042-017-4518-z&partnerID=40&md5=aa1d18e9494d2f54300b64fd7a4f1c33","Adaptivity is important in remote sensing image fusion because of the data-intensive and mass-driven processing platforms that call for reliable evaluation metrics to assess the runtime fusion procedure. Spatial distortion, including poor detail, visual disorder, or over-injection, has not been measured as effectively as in the spectral domain. A new metric, namely normalized mean potential energy (NMPE), is proposed in this paper to check the generalized spatial distortion of fused images by calculating the potential energy of marginal filtering distributions using information of high-order Markov random fields. NMPE is defined based on the GFoE model, which is a new high-order model that we built for remote sensing image applications. To incorporate the evaluation experience of human vision system into the GFoE model, the real zero-mean Gabor filters with multiple directions and scales are used as feature extractors, and the Gaussian scale mixture model as the expert function. The model parameters are trained from 200 images of the Berkeley segmentation dataset. Poor detail in a fused image tends to result in small NMPE evaluation with respect to small Gabor scales. Our observation shows that scale invariance exists only for “good” details, so we use large scales of Gabor functions to detect visual disorder. Over-injection is checked when the fused NMPE is much higher than 1. In the experimental procedure, satellite images from Quickbird, LandSat-7, and SPOT-5 were put to fusion with five popular methods to produce different images for visual and digital comparison. It can be concluded from the experiment that NMPE is in line with our subjective judgment to measure the pansharpening quality in terms of enhanced detail, visual distortion, and over-injection. © 2017, Springer Science+Business Media New York.","Data fusion; Function evaluation; Gabor filters; Image reconstruction; Image segmentation; Information filtering; Markov processes; Molecular physics; Potential energy; Remote sensing; Berkeley segmentation dataset; Experimental procedure; Gaussian scale mixture models; Human vision systems; Markov Random Fields; Pansharpen; Processing platform; Remote sensing images; Image fusion","Human vision system; Image fusion; Markov random fields; Pansharpen; Remote sensing","Article","Final","","Scopus","2-s2.0-85014518991"
"Belgiu M.; Stein A.","Belgiu, Mariana (55962329600); Stein, Alfred (7401758587)","55962329600; 7401758587","Spatiotemporal image fusion in remote sensing","2019","Remote Sensing","11","7","818","","","","10.3390/rs11070818","92","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064013012&doi=10.3390%2frs11070818&partnerID=40&md5=c4df3791067b16bc307801fabf663b67","In this paper, we discuss spatiotemporal data fusion methods in remote sensing. These methods fuse temporally sparse fine-resolution images with temporally dense coarse-resolution images. This review reveals that existing spatiotemporal data fusion methods are mainly dedicated to blending optical images. There is a limited number of studies focusing on fusing microwave data, or on fusing microwave and optical images in order to address the problem of gaps in the optical data caused by the presence of clouds. Therefore, future efforts are required to develop spatiotemporal data fusion methods flexible enough to accomplish different data fusion tasks under different environmental conditions and using different sensors data as input. The review shows that additional investigations are required to account for temporal changes occurring during the observation period when predicting spectral reflectance values at a fine scale in space and time. More sophisticated machine learning methods such as convolutional neural network (CNN) represent a promising solution for spatiotemporal fusion, especially due to their capability to fuse images with different spectral values. © 2019 by the authors.","Data fusion; Geometrical optics; Learning systems; Neural networks; Reflection; Remote sensing; Space optics; Convolutional neural network; Environmental conditions; Fine-resolution images; Satellite images; Sophisticated machines; Spatio-temporal fusions; Spatiotemporal images; Spectral reflectance value; Image fusion","Data fusion; Time series satellite images","Review","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85064013012"
"Talal T.M.; Metwalli M.R.; Attiya G.; Abd El-Samie F.E.; Dessouky M.I.","Talal, Tamer M. (15766387800); Metwalli, Mohamed R. (35776990600); Attiya, Gamal (56001046200); Abd El-Samie, Fathi E. (12785222000); Dessouky, M.I. (7005350912)","15766387800; 35776990600; 56001046200; 12785222000; 7005350912","Fusion-based resolution enhancement of satellite images: Comparative study and performance evaluation","2019","ICENCO 2018 - 14th International Computer Engineering Conference: Secure Smart Societies","","","8636137","1","6","5","10.1109/ICENCO.2018.8636137","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063032488&doi=10.1109%2fICENCO.2018.8636137&partnerID=40&md5=17442018e1037fa555a244107d40b5a8","Fusion becomes an important technique for improving resolution of satellite images. This importance is established from the ability of such technique to combine relevant information from several images, of a scene, into a single image. The constructed image is more informative than any one of the original images. This paper first presents a literature survey of the most recent fusion techniques concerned with satellite images. Then, it gives a performance evaluation of such techniques for enhancing resolution of color images considering full scene images of different regions with resolutions taken by Spot-4 and Landsat-8 satellites. Finally, it presents a comparison among the fusion techniques using different evaluation criteria. © 2018 IEEE.","Image fusion; Satellites; Spectral resolution; Comparative studies; Evaluation criteria; Fusion techniques; Literature survey; Original images; Resolution enhancement; Satellite images; Spatial resolution; Image enhancement","Image fusion; Satellite images; Spatial resolution; Spectral resolution","Conference paper","Final","","Scopus","2-s2.0-85063032488"
"Bergado J.R.; Persello C.; Stein A.","Bergado, John Ray (57192703116); Persello, Claudio (23493587700); Stein, Alfred (7401758587)","57192703116; 23493587700; 7401758587","Recurrent Multiresolution Convolutional Networks for VHR Image Classification","2018","IEEE Transactions on Geoscience and Remote Sensing","56","11","8388225","6361","6374","13","10.1109/TGRS.2018.2837357","49","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048883766&doi=10.1109%2fTGRS.2018.2837357&partnerID=40&md5=7c073fd1731112cf2ce27874f0f5987d","Classification of very high-resolution (VHR) satellite images has three major challenges: 1) inherent low intraclass and high interclass spectral similarities; 2) mismatching resolution of available bands; and 3) the need to regularize noisy classification maps. Conventional methods have addressed these challenges by adopting separate stages of image fusion, feature extraction, and postclassification map regularization. These processing stages, however, are not jointly optimizing the classification task at hand. In this paper, we propose a single-stage framework embedding the processing stages in a recurrent multiresolution convolutional network trained in an end-to-end manner. The feedforward version of the network, called FuseNet, aims to match the resolution of the panchromatic and multispectral bands in a VHR image using convolutional layers with corresponding downsampling and upsampling operations. Contextual label information is incorporated into FuseNet by means of a recurrent version called ReuseNet. We compared FuseNet and ReuseNet against the use of separate processing steps for both image fusions, e.g., pansharpening and resampling through interpolation and map regularization such as conditional random fields. We carried out our experiments on a land-cover classification task using a Worldview-03 image of Quezon City, Philippines, and the International Society for Photogrammetry and Remote Sensing 2-D semantic labeling benchmark data set of Vaihingen, Germany. FuseNet and ReuseNet surpass the baseline approaches in both the quantitative and qualitative results. © 2018 IEEE.","Baden-Wurttemberg; Germany; National Capital Region; Philippines; Quezon City; Vaihingen an der Enz; Classification (of information); Convolution; Deep learning; Extraction; Feature extraction; Image classification; Image segmentation; Job analysis; Labeling; Remote sensing; Semantics; Signal sampling; Convolutional networks; Kernel; Land cover classification; Recurrent networks; Spatial resolution; Task analysis; Very high resolution (VHR) image; benchmarking; image classification; image resolution; interpolation; land cover; photogrammetry; remote sensing; satellite imagery; WorldView; Image fusion","Convolutional networks; deep learning; land cover classification; recurrent networks; very high-resolution (VHR) image","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85048883766"
"Ghasemian N.; Akhoondzadeh M.","Ghasemian, Nafiseh (57196243510); Akhoondzadeh, Mehdi (35363587600)","57196243510; 35363587600","Fusion of non-thermal and thermal satellite images by boosted SVM classifiers for cloud detection","2017","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","4W4","","83","89","6","10.5194/isprs-archives-XLII-4-W4-83-2017","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032375312&doi=10.5194%2fisprs-archives-XLII-4-W4-83-2017&partnerID=40&md5=de3383d135a0f3522abeb1becef91f06","The goal of ensemble learning methods like Bagging and Boosting is to improve the classification results of some weak classifiers gradually. Usually, Boosting algorithms show better results than Bagging. In this article, we have examined the possibility of fusion of non-thermal and thermal bands of Landsat 8 satellite images for cloud detection by using the boosting method. We used SVM as a base learner and the performance of two kinds of Boosting methods including AdaBoost.M1 and s Boost was compared on remote sensing images of Landsat 8 satellite. We first extracted the co-occurrence matrix features of non-thermal and thermal bands separately and then used PCA method for feature selection. In the next step AdaBoost.M1 and s Boost algorithms were applied on non-thermal and thermal bands and finally, the classifiers were fused using majority voting. Also, we showed that by changing the regularization parameter (C) the result of s Boost algorithm can significantly change and achieve overall accuracy and cloud producer accuracy of 74%, and 0.53 kappa coefficient that shows better results in comparison to AdaBoost.M1.","Image classification; Learning systems; Remote sensing; Satellites; Boosted SVM; Classification results; Cloud detection; Co-occurrence-matrix; LANDSAT; Majority vote; Regularization parameters; Remote sensing images; Image fusion","Boosted SVM; Cloud detection; Landsat; Majority vote","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85032375312"
"Santos T.M.A.; Mora A.; Ribeiro R.A.; Silva J.M.N.","Santos, Tiago M. A. (55364476400); Mora, Andre (15728256600); Ribeiro, Rita A. (56527722100); Silva, Joao M. N. (55447844200)","55364476400; 15728256600; 56527722100; 55447844200","Fuzzy-fusion approach for land cover classification","2016","INES 2016 - 20th Jubilee IEEE International Conference on Intelligent Engineering Systems, Proceedings","","","7555116","177","182","5","10.1109/INES.2016.7555116","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988009593&doi=10.1109%2fINES.2016.7555116&partnerID=40&md5=66f0e104b8d190a118e181a6d8e9f3fe","The use of computational intelligent techniques for feature extraction and classification from earth observation satellite images, like Landsat multispectral images, can contribute to improve remote sensing analysis. Image fusion techniques are applied to fuse the spectral images into a higher-level image of the land cover distribution. In this paper we propose a fuzzy-fusion inference approach for satellite image classification based on a fuzzy process, which uses both a hybrid method to train the classifier and reinforcement aggregation operators in the inference scheme. The approach was tested with land cover maps for the district of Mandimba of the Niassa province, Mozambique and was validated against an expert classification and then with Decision trees and Artificial Neural Networks. © 2016 IEEE.","Decision trees; Feature extraction; Image fusion; Image processing; Mathematical operators; Neural networks; Remote sensing; Satellite imagery; Spectroscopy; Computational intelligent techniques; Earth observation satellites; Feature extraction and classification; Image fusion techniques; Land cover classification; Landsat multispectral images; Remote sensing analysis; Satellite image classification; Image classification","","Conference paper","Final","","Scopus","2-s2.0-84988009593"
"Daza R.J.M.; Angulo V.D.; Galvis J.L.R.","Daza, Ruben Javer Medina (57193828334); Angulo, Victor Daniel (57193159709); Galvis, Jorge Luis Rodriguez (57195313700)","57193828334; 57193159709; 57195313700","Improving the spatial resolution of the images Ikonos beginning with Unmanned Aerial Vehicle (UAV): An application of image fusion with wavelet transform; [Mejoramiento de la resolución espacial de las imágenes Ikonos a partir de Vehículo aéreo no tripulado (VANT): una aplicación de la fusión de imágenes con la Transformada Wavelet]","2017","Iberian Conference on Information Systems and Technologies, CISTI","","","7975729","","","","10.23919/CISTI.2017.7975729","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027057200&doi=10.23919%2fCISTI.2017.7975729&partnerID=40&md5=930286db46d5b97901ba696ec9dcea5c","This article aims to develop and evaluate two methodologies for improving the spatial resolution without significant loss of the spectral resolution of a multi-spectral Ikonos image using an image acquired with an UAV. In the first method from multi-spectral image and image acquired with the UAV get the intensity of the multispectral image (Im) and the intensity of UAV (Iv), using the RGB-IHS transformation respectively. Then applying fusion to the intensity components of Im and Iv using Wavelet transform together with ARSIS' technique to genere a new intensity (n-Imv). This n-Imv together with hue and saturation obtained from Ikonos image are transformed inversely to generate a new multispectral image (N-MULT-I). In the second process a new panchromatic is created through of average of three RGB bands of UAV's image (fpan), then fusion is applied using wavelet transform to Im and fpan to generate a new intensity (n-Ifpm). Using n-Ifpm and hue and saturation components of IKonos image a new image multispectral is generated (N-MULT-fpan). Finally, results are shown and there are evaluated with Correlation Coefficient, ERGAS, RASE and Qu. Finding that better results are obtained with the second process. © 2017 AISTI.","Fusion reactions; Genes; Image acquisition; Image compression; Image fusion; Image resolution; Information systems; Spectroscopy; Unmanned aerial vehicles (UAV); Wavelet transforms; Correlation coefficient; IHS transformation; IKONOS images; Multi-spectral; Multispectral images; Satellite images; Spatial resolution; Wavelet; Color image processing","Fusion; Multispectral; Satellite images; UAV; Wavelet","Conference paper","Final","","Scopus","2-s2.0-85027057200"
"Rao D.S.; Seetha M.; Krishna Prasad M.H.M.","Rao, D. Srinivasa (57226537415); Seetha, M. (54795736200); Krishna Prasad, M.H.M. (54795323700)","57226537415; 54795736200; 54795323700","Quality assessment of pixel-based image classification of fused satellite images","2015","Advanced Science Letters","21","11","","3453","3457","4","10.1166/asl.2015.6576","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960464193&doi=10.1166%2fasl.2015.6576&partnerID=40&md5=f8a88d6945fc96e44c4a3460397b4b01","Image Classification possess supreme role in great many applications like image analysis, remote sensing, image recognition, medical imaging, image interpretation and pattern recognition etc., In given occurrences, the classification process alone can shape the object of the examination. Original images acquired from satellites are unlike at spiritual and structural intentions. Utilization of image processing approaches can refine the grade of image content. Image fusion is a method to converge input images and to compute fused image with more spectral and spatial information furthermore. Image classification using K-Means on fused images produces better results when contrast to image classification of original images. In this paper fused images obtain from different techniques (Principal Component Analysis (PCA), image fusion using Wavelet Transform, Fuzzy logic and image fusion using Neuro fuzzy logic) are classified and assessed using accuracy assessment parameters for the image classification. LISS III multispectral and panchromatic images have been used in this experiment to show the quality enhancement and improved accuracy assessment of fused image over the original images using MATLAB. Due to potentiality of the fusion approach, fused output images generated from fuzzy, neuro fuzzy, iterative fuzzy and iterative neuro fuzzy logic obtained the better classification accuracy and Kappa coefficient compared to classification of original images and classification of PCA based and wavelet based fused images. © 2015, American Scientific Publishers. All rights reserved.","","Accuracy; Classification; Fusion; Fuzzy logic; K-Means; Kappa coefficient; Neuro fuzzy logic; PCA; Wavelet","Article","Final","","Scopus","2-s2.0-84960464193"
"Yang S.; Li S.; Chen C.; Zheng H.","Yang, Song (57191892271); Li, Shengyang (14031768000); Chen, Chenxin (55914019000); Zheng, He (57208254960)","57191892271; 14031768000; 55914019000; 57208254960","High resolution remote sensing image fusion method based on curvelet and HCS","2016","Proceedings of 2016 8th IEEE International Conference on Communication Software and Networks, ICCSN 2016","","","7586609","677","680","3","10.1109/ICCSN.2016.7586609","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994509831&doi=10.1109%2fICCSN.2016.7586609&partnerID=40&md5=d6479dcec5c95b90ca02d42ee1c0dffe","To obtain high spatial and spectral resolution image, we propose a novel method of high resolution remote sensing image fusion based on the second generation curvelet transform and hyperspherical color space transform which can fuse n-band multispectral and panchromatic images. The GF-1 satellite images are used as experimental data, and the fused image are quantitatively analyzed according to the mean, the standard deviation, the correlation coefficient, the information entropy and the average gradient. The results show that the proposed method has better performance than other fusion methods such as Principal Component Analysis, Gramm-Schmidt, and Hyperspherical Color Sharpening. © 2016 IEEE.","Color; Image enhancement; Image reconstruction; Principal component analysis; Remote sensing; Space optics; Color space transform; Correlation coefficient; Curvelet transforms; High resolution; High resolution remote sensing images; Hyperspherical; Information entropy; Panchromatic images; Image fusion","curvelet transform; high resolution; hyperspherical color sharpening; image fusion; remote sensing","Conference paper","Final","","Scopus","2-s2.0-84994509831"
"Teo T.-A.; Shih P.T.Y.; Chen B.","Teo, Tee-Ann (7005909918); Shih, Peter T.Y. (35204080800); Chen, Bo (55723078200)","7005909918; 35204080800; 55723078200","Automatic georeferencing framework for timeseries formosat-2 satellite imagery using open source software","2017","38th Asian Conference on Remote Sensing - Space Applications: Touching Human Lives, ACRS 2017","2017-October","","","","","","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047426884&partnerID=40&md5=f8f3e01a626094f12bc0d35d2865d80f","Georeferencing is to assign mapping coordinate system and to produce a geo-rectified image for satellite image. It is an important preprocessing for multi-temporal images analysis as well as multi-source data fusion. Orthorectification and co-registration are two different methods in geometric correction. The orthorectification establishes mapping function between 2D image space and 3D object space while the co-registration adopts a global or a local image-to-image transformation. This two methods can be integrated sequentially for precise mapping. Due to the development of geospatial big data analysis, the growing satellite image archive requires automatic and precise georeferencing framework to handle time-series satellite images. This study aims to develop an automatic georeferencing framework using open geospatial data and open source software for Formosat-2 satellite image archive. The input Formosat-2 satellite images are level 1A panchromatic and multispectral images while the output data are registrated pan-sharpening images. The sensor model of Formosat-2 in used is rational function model (RFM) for orthorectification. The georeferencing framework utilizes an orthoimage as a reference image. The open geospatial data for correction of terrain relief are 30m Shuttle Radar Topography Mission (SRTM) elevation data and EGM96 Geoid data. In order to perform automatic georeferencing, a predefined orthoimage is selected as a reference image to find corresponding points between reference orthoimage and Formosat-2 satellite image. The geospatial open source software in used includes OpenCV (http://opencv.org/), Orfeo ToolBox (https://www.orfeotoolbox.org/) (Christophe et al., 2008), and Arosics (https://pypi.python.org/pypi/arosics) (Scheffler et al., 2017). The main idea is to refine the satellite image using different approaches in different stages. The proposed framework includes four major stages: preprocessing, coarse-registration, fine-registration and color fusion. The preprocessing stage uses OpenCV Library to construct an image pyramid-matching scheme in refinement of rational polynomial coefficients (RPCs). This stage effectively refines the metadata of input Formosat-2 image (i.e. RPCs) from pyramid images. A Speeded-up-robust-features (SURF) matching (Bay et al., 2008) is applied to extract registration points between orthoimage and Formosat-2 image. The height of registration points can be obtained from digital elevation model (DEM). Then, the extracted registration points is applied to improve the positioning accuracy of RPCs (Teo, 2011). The second stage is coarse-registration by refined RPCs and reference orthoimage. Several tools from Orfeo Toolbox are composed to build up an iterative refinement scheme in automatic coarse-registration. The automatic coarse-registration divides input image into different blocks and each block preforms SURF matching to find registration points. So, the registration points are equally distributed to cover the whole scene. The RFM is refined by additional parameters with outlier detection. This stage resamples the Formosat-2 level 1A image into initial geocoded image based on RFM, registration points and DEM. This coarse-registration might include geometrical discrepancy between initial geocoded image and reference orthoimage. Therefore, fine-registration is needed. The third stage is an image-to-image registration using local transformation. The Arosics is selected to do the fine-registration between initial geocoded image and reference orthoimage. As the initial geocoded image is similar to reference orthoimage, the phase-shift image matching method is applied in fine-registration. The fine-registration also divides input image into different blocks and perform image matching iteratively. Finally, a high pass filter (HPF) color fusion method (Gangkofner et al., 2008) is applied to generate pan-sharping image from panchromatic and multispectral images. The challenges of the proposed automatic scheme are cloud and terrain effects. Therefore, this study select a mountain area in different cloud conditions. The experiment utilized a set of Formosat-2 level 1A satellite images (28 panchromatic images and 28 multispectral image) with different cloud coverages (e.g. 0% to 40%) in year 2014. The reference orthoimage was also a 2m Formosat-2 image in year 2014. The proposed georeferencing framework automatically rectified satellite images and fused the panchromatic and corresponding multispectral images into timeseries pan-sharping images. This study selected 14 cloud free panchromatic images in accuracy analysis. The geometric accuracies before registration were ranged from -169.29m to 267.28m. After co-registration, the geometric accuracies improved to -4.17m to 3.13m. In summary, the geolocation accuracy of proposed scheme was improved from hundred meters to 5 meters level accuracy. One of the limitation for the proposed scheme is image quality (e.g. the percentage of homogeneous area). The future study will focus on excluding homogeneous area to improve the quality of georeferencing image. © 2017 ACRS. All rights reserved.","Big data; Data handling; Geometry; High pass filters; HTTP; Image analysis; Image fusion; Image matching; Image registration; Iterative methods; Landforms; Mapping; Open source software; Open systems; Rational functions; Remote sensing; Satellite imagery; Space applications; Space optics; Surveying; Time series analysis; Tracking radar; Arosics; Formosat-2; Georeferencing; OpenCV; Orfeo toolbox; Satellite images; Image enhancement","Arosics; Formosat-2; Georeferencing; OpenCV; Orfeo toolbox; Satellite image","Conference paper","Final","","Scopus","2-s2.0-85047426884"
"Rajathurai A.; Chellakkon H.S.","Rajathurai, Ablin (57199742245); Chellakkon, Helen Sulochana (57194722029)","57199742245; 57194722029","Improved Visualization Using a Fusion Technique Based on KNN Matting of Remotely Sensed Images","2018","Journal of the Indian Society of Remote Sensing","46","2","","179","187","8","10.1007/s12524-017-0693-7","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021787562&doi=10.1007%2fs12524-017-0693-7&partnerID=40&md5=eeb0526be31da7e39cd0a0b820f2a823","Hyperspectral image fusion is an important task in remote sensing as it could strengthen hyperspectral bands for visualization and analysis of satellite images. Many fusion techniques have been developed in the recent years to obtain an accurate and complete description of visualization. Since the existing works could hardly produce the desired results, the proposed method attempts to design a novel fusion framework based on K Nearest Neighbours (KNN) matting model. Image matting aims at finding the probability that each pixel in a band belongs to a specified class. This model capitalizes on the natural principle of matching non-local neighbourhoods by using KNN and contributes a fast and simple algorithm that produces competitive results, provided an input of sparse mark-ups in the form of scribbles. KNN matting has a closed form solution that leverages the existing approaches by producing efficient results. After determining the value of alpha, the solution can be generalized to solve the multilayer extraction problem with reduced computational complexity. Experimental evaluation on benchmark data sets indicates that the proposed model is better than the state-of-the-art methods. © 2017, Indian Society of Remote Sensing.","","Hyperspectral image; Image fusion; KNN matting; Visualization","Article","Final","","Scopus","2-s2.0-85021787562"
"Kim Y.-H.; Oh J.-H.; Kim Y.-I.","Kim, Yong-Hyun (56195702200); Oh, Jae-Hong (36140723100); Kim, Yong-Il (7410213546)","56195702200; 36140723100; 7410213546","Fast and efficient satellite imagery fusion using DT-CWT proportional and wavelet Zero-Padding","2015","Journal of the Korean Society of Surveying, Geodesy, Photogrammetry and Cartography","33","6","","517","525","8","10.7848/ksgpc.2015.33.6.517","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963972002&doi=10.7848%2fksgpc.2015.33.6.517&partnerID=40&md5=af27dae3e9f7a2009d60376a8f708710","Among the various image fusion or pan-sharpening methods, those wavelet-based methods provide superior radiometric quality. However, the fusion processing is not only simple but also flexible, since many low- and high-frequency sub-bands are often produced in the wavelet domain. To address this issue, a novel DT-CWT (Dual-Tree Complex Wavelet Transform) proportional to the fusion method by a WZP (Wavelet Zero-Padding) is proposed. The proposed method produces a single high-frequency image in the spatial domain that is injected into the LRM (Low-Resolution Multispectral) image. Thus, a wavelet domain fusion can be simplified to spatial domain fusion. In addition, in the proposed DT-CWTP (DT-CWT Proportional) fusion method, it is unnecessary to decompose the LRM image by adopting WZP. The comparison indicates that the proposed fusion method is nearly five times faster than the DT-CWT with SW (Substitute-Wavelet) fusion method, meanwhile simultaneously maintaining the radiometric quality. The conducted experiments with WorldView-2 satellite images demonstrated promising results with the computation efficiency and fused image quality.","image analysis; image processing; image resolution; imaging method; satellite imagery; transform","Dual-Tree Complex Wavelet; Image fusion; Pan-sharpening; Wavelet Zero-Padding","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-84963972002"
"Vakalopoulou M.; Christodoulidis S.; Sahasrabudhe M.; Mougiakakou S.; Paragios N.","Vakalopoulou, Maria (57024178400); Christodoulidis, Stergios (56648066500); Sahasrabudhe, Mihir (56126225800); Mougiakakou, Stavroula (6603242680); Paragios, Nikos (22235200200)","57024178400; 56648066500; 56126225800; 6603242680; 22235200200","Image Registration of Satellite Imagery with Deep Convolutional Neural Networks","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898220","4939","4942","3","10.1109/IGARSS.2019.8898220","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077677867&doi=10.1109%2fIGARSS.2019.8898220&partnerID=40&md5=27edbb02278536fdcf83a297c9d62c6b","Image registration in multimodal, multitemporal satellite imagery is one of the most important problems in remote sensing and essential for a number of other tasks such as change detection and image fusion. In this paper, inspired by the recent success of deep learning approaches we propose a novel convolutional neural network architecture that couples linear and deformable approaches for accurate alignment of remote sensing imagery. The proposed method is completely unsupervised, ensures smooth displacement fields and provides real time registration on a pair of images. We evaluate the performance of our method using a challenging multitemporal dataset of very high resolution satellite images and compare its performance with a state of the art elastic registration method based on graphical models. Both quantitative and qualitative results prove the high potentials of our method. © 2019 IEEE.","Convolution; Deep learning; Deep neural networks; Deformation; Geology; Image fusion; Image registration; Network architecture; Remote sensing; Satellite imagery; Displacement field; Elastic registration; Learning approach; Linear registration; Multitemporal satellite imagery; Real-time registration; Remote sensing imagery; Very high resolution satellite images; Convolutional neural networks","Convolutional Neural Networks (CNN); Deep Learning; Deformable and Linear Registration; Very High Resolution Satellite Images","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85077677867"
"Bouakache A.; Tahraoui A.; Kheddam R.; Belhadj-Aissa A.","Bouakache, Abdenour (24528506200); Tahraoui, Ahmed (57197859837); Kheddam, Radja (56495252000); Belhadj-Aissa, Aichouche (6506430028)","24528506200; 57197859837; 56495252000; 6506430028","Change detection approach using evidential fusion of change indices","2017","Proceedings - 3rd International Conference on Advanced Technologies for Signal and Image Processing, ATSIP 2017","","","8075574","","","","10.1109/ATSIP.2017.8075574","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035347349&doi=10.1109%2fATSIP.2017.8075574&partnerID=40&md5=ad81954f7a89626f9eda33db943545ed","In this paper, we present fusion and classification process of change indices using multitemporal satellites images in the aim to detect the change of surface states after a flood. This process is performed in the framework of Dempster Shafer Theory (DST), which takes into account the imprecision and the ignorance related to data. We apply this process to a study site located at south west of England, traversed by Severn river, which have undergone in October 2000 an important flood. For the detection of the flood damage, we have used two change indices: difference values and texture evolution. We find that change index fusion overcomes the limits of change mono-index classification. © 2017 IEEE.","Classification (of information); Damage detection; Floods; Formal logic; Image fusion; Change detection; change indices; Classification process; cluster shade; Dempster-Shafer theory; Evidential fusions; Multitemporal satellites; SAVI; Image processing","change detection; change indices; classification; cluster shade; DST; image fusion; SAVI","Conference paper","Final","","Scopus","2-s2.0-85035347349"
"Gašparović M.; Rumora L.; Miler M.; Medak D.","Gašparović, Mateo (36987936900); Rumora, Luka (57211063553); Miler, Mario (57086384000); Medak, Damir (26642614700)","36987936900; 57211063553; 57086384000; 26642614700","Effect of fusing Sentinel-2 and WorldView-4 imagery on the various vegetation indices","2019","Journal of Applied Remote Sensing","13","3","036503","","","","10.1117/1.JRS.13.036503","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072518110&doi=10.1117%2f1.JRS.13.036503&partnerID=40&md5=208c404c271a4618fa31c545877ec9a3","Satellite image fusion techniques have been used for more than two decades. Development of satellite sensors for very high-resolution satellite imagery monitoring contributed to the development of new image fusion techniques. We examine the quality of Ehlers, Brovey transform, modified intensity-hue-saturation (M-IHS), and high-filter resolution merge fusion methods on vegetation indices values combining high-resolution WorldView-4 and low-resolution Sentinel-2 imagery. For image fusion, four bands-blue, green, red, and near-infrared-were used. The effect of fusing Sentinel-2 and WorldView-4 imagery is tested on the various vegetation indices [normalized difference vegetation index (NDVI), blue normalized difference vegetation index (BNDVI), and green normalized difference vegetation index (GNDVI)]. M-IHS fusion showed the best result, with the least difference between indices calculated based on the original Sentinel-2 and fused bands. Difference between vegetation indices calculated using original Sentinel-2 and M-IHS fused bands for 30.08.2015, 30.09.2016, and 30.09.2017 is between-0.041 to 0.037. The second part of this research is an evaluation of three different vegetation classes (grassland, mixed vegetation, and forest) on three different years and three different months within a year. Difference between NDVI, GNDVI, and BNDVI calculated based on the original Sentinel-2, and M-IHS fused bands are ranging from-0.043 to 0.103,-0.041 to 0.050, and-0.052 to 0.030 for grassland, mixed vegetation, and forest, respectively. On the other hand, the difference between vegetation indices for grassland, mixed vegetation, and forest are from-0.110 to 0.050,-0.041 to 0.038, and-0.052 to 0.038, when observing August, September, and October of 2017, respectively. © 2019 Society of Photo-Optical Instrumentation Engineers (SPIE).","Forestry; Infrared devices; Remote sensing; Satellite imagery; Vegetation; Green normalized difference vegetation index; Image fusion techniques; Intensity hue saturations; Normalized difference vegetation index; Sentinel-2; Vegetation index; Very high resolution satellite imagery; WorldView-4; Image fusion","image fusion; remote sensing; Sentinel-2; vegetation indices; WorldView-4","Article","Final","","Scopus","2-s2.0-85072518110"
"Ezimand K.; Kakroodi A.A.; Kiavarz M.","Ezimand, Keyvan (57202853151); Kakroodi, A.A. (54882459700); Kiavarz, Majid (57194688190)","57202853151; 54882459700; 57194688190","The development of spectral indices for detecting built-up land areas and their relationship with land-surface temperature","2018","International Journal of Remote Sensing","39","23","","8428","8449","21","10.1080/01431161.2018.1488282","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049593168&doi=10.1080%2f01431161.2018.1488282&partnerID=40&md5=36eef35f08e21d7dde57b1975942a3cb","Different spectral indices were provided for the classification of built-up lands using satellite images, but the importance of the blue band in the classification, fusion, and image enhancement prior to the calculation of spectral indices has received less attention so far. This study introduces a new index based on blue band and run it along with six other spectral indices. The method of study is as follows, after the selection of Landsat 7 and Landsat 8 images, the initial pre-processing was done on the images and in the second stage, the enhancement and the fusion were performed. In the third stage, the built-up lands were classified using spectral indices. Otsu’s thresholding method was used on all indices to separate built-up and non-built-up lands. To assess the accuracy, 3500 reference points were used. The results showed that when fusion and image enhancement were performed, overall accuracy (OA) increased by 3% to 6.71% for Landsat 7 images, and 2.14% to 6.71% for Landsat 8 images. The results also showed that after fusion and image enhancement, the visible blue band and first shortwave infrared index (VbSWIR1-BI) with an OA of 92.88% (Landsat 7) and 91.68% (Landsat 8) indicate the highest OA. The percentage of built-up lands changes according to spectral indices ranges from 6.38% to 25.76% and the largest and lowest amount of built-up land on the basis of the VbSWIR1-BI index belonging to districts 12 and 22, respectively. The results of the spectral indicator show dispread growth during the 14 year period for Tehran. Finally, a significant relationship was observed between surface temperature and built-up land classified by spectral indices. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","Iran; Tehran [Iran]; Atmospheric temperature; Image fusion; Surface properties; Land surface temperature; Overall accuracies; Reference points; Satellite images; Short wave infrared; Spectral indices; Surface temperatures; Thresholding methods; image analysis; land classification; land surface; satellite imagery; spectral analysis; surface temperature; Image enhancement","","Article","Final","","Scopus","2-s2.0-85049593168"
"Wendl C.; Bris A.L.; Chehata N.; Puissant A.; Postadjian T.","Wendl, Cyril (57204814998); Bris, Arnaud Le (22135725700); Chehata, Nesrine (8598290000); Puissant, Anne (7102002323); Postadjian, Tristan (57201383948)","57204814998; 22135725700; 8598290000; 7102002323; 57201383948","Late fusion SPOT 6/7 images and multitemporal Sentinel-2 data for the detection of the urban area; [Fusion tardive d'lmages spot 6/7 et de donnees multitemporelles sentinel-2 pour la detection de la tache urbaine]","2018","Revue Francaise de Photogrammetrie et de Teledetection","2018-September","217-218","","87","97","10","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057313899&partnerID=40&md5=a79e1d29c4c3efdbd3d0a249234fd887","Fusion of very high spatial resolution multispectral (VHR) images with time series of lower spatial resolution images with more spectral bands can improve land cover classification, combining geometric and semantic advantages of both sources, respectively. This study presents a strategy to extract the urban footprint using decision-level fusion of individual classifications on Sentinel-2 and SPOT 6/7 satellite images. First, both sources are classified separately in five classes, using state-of-the-art supervised Random Forest classification and Convolutional Neural Networks. The two results are then merged in order to extract individual buildings with the highest spatial precision conceivable. Secondly, detected buildings are merged again with the Sentinel-2 classification so as to extract the artificialized areas; the building labels from the regularization step are dilated in order to connect the building objects; a binary classification is derived from the original Sentinel-2 classification before being reintroduced in a fusion and contrast sensitive regularization process so as to eventually retrieve the urban footprint. Results show well the complementary between both data sources as well as the relevance of the late fusion stategy. © 2018 Soc. Francaise de Photogrammetrie et de Teledetection.","Classification (of information); Decision trees; Image enhancement; Image resolution; Image segmentation; Neural networks; Semantics; Artificialized Area; Decision fusion; Late fusion; Multi-spectral; Regularization; Urban areas; Image fusion","Artificialized Area; Classification; Decision Fusion; Late Fusion; Multispectral; Regularization; Segmentation; Urban Area","Article","Final","","Scopus","2-s2.0-85057313899"
"Hu Y.; Li L.","Hu, Yawen (57215525219); Li, Li (57216234151)","57215525219; 57216234151","Remote sensing mapping of cyanobacteria blooms in chaohu based on spatio-temporal-spectrum fusion: Improvement on spatial scales","2019","Journal of Engineering Science and Technology Review","12","6","","182","194","12","10.25103/jestr.126.23","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081068339&doi=10.25103%2fjestr.126.23&partnerID=40&md5=8ca32a737367964859be421f5158e962","Occurrence and relevant risks of cyanobacteria blooms have been increasing continuously in the world wide. Monitoring on spatial and temporal distribution changes of cyanobacteria blooms has been the key of environmental monitoring. In particular, spatio-temporal distribution of cyanobacteria blooms in complicated small inland water areas changes so frequently and a more accurate inversion monitoring method and product was required with the fact that quality of inversion results of existing major optical remote sensing monitoring means is determined by the source images. Due to mutual restraints of temporal, spatial and spectral resolution of satellite images, common multispectral images cannot realize high-accuracy monitoring in complicated small inland water areas. A method to improve inversion accuracy and spatial resolution of inversion products was carried out in this study. Based on multisource image data, inversion models of chlorophyll a (Chl-a) and cyanobacterial biomarker pigment phycocyanin (PC) concentration in Lake Chaohu were constructed with the image fusion algorithm and machine learning algorithm. Effects of increasing spatial scale of source image on inversion accuracy were verified by comparing accuracy of the inversion models based on fusion image and original moderate-resolution imaging spectroradiometer (MODIS) images in the same period under the same conditions. Moreover, inversion mapping with high accuracy and high spatial scale was accomplished for several days successively. Results demonstrate that accuracy of the inversion model be increased with improving spatial resolution of source images, which further increased spatial scale of inversion products significantly. This study provides a feasible and effective method to realize high-accuracy monitoring of cyanobacteria blooms in small-scaled but complicated inland water environment. © 2019 School of Science, IHU.","Decision trees; Image fusion; Image resolution; Machine learning; Mapping; Monitoring; Personal computers; Radiometers; Random forests; Remote sensing; Small satellites; Chl-a; Environmental Monitoring; Image fusion algorithms; Moderate resolution imaging spectroradiometer; Optical remote sensing; Spatial and temporal distribution; Spatio-temporal spectrum; Spatiotemporal distributions; Image enhancement","Chl-a; Image fusion; PC; Random forest; Remote sensing","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85081068339"
"Wendl C.; Le Bris A.; Chehata N.; Puissant A.; Postadjian T.","Wendl, Cyril (57204814998); Le Bris, Arnaud (22135725700); Chehata, Nesrine (8598290000); Puissant, Anne (7102002323); Postadjian, Tristan (57201383948)","57204814998; 22135725700; 8598290000; 7102002323; 57201383948","Late fusion of SPOT-6/7 images and Sentinel-2 multi-temporal data for urban area detection; [FUSION TARDIVE D'IMAGES SPOT 6/7 ET DE DONNÉES MULTITEMPORELLES SENTINEL-2 POUR LA DÉTECTION DE LA TACHE URBAINE]","2018","Revue Francaise de Photogrammetrie et de Teledetection","","217-218","","","","","10.52638/rfpt.2018.415","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142401136&doi=10.52638%2frfpt.2018.415&partnerID=40&md5=223b3f8df02723d6702ff7849db70b5d","Fusion of very high spatial resolution multispectral (VHR) images with time series of lower spatial resolution images with more spectral bands can improve land cover classification, combining geometric and semantic advantages of both sources, respectively. This study presents a strategy to extract the urban footprint using decision-level fusion of individual classifications on Sentinel-2 and SPOT 6/7 satellite images. First, both sources are classified separately in five classes, using state-of-the-art supervised Random Forest classification and Convolutional Neural Networks. The two results are then merged in order to extract individual buildings with the highest spatial precision conceivable. Secondly, detected buildings are merged again with the Sentinel-2 classification so as to extract the artificialized areas; the building labels from the regularization step are dilated in order to connect the building objects; a binary classification is derived from the original Sentinel-2 classification before being reintroduced in a fusion and contrast sensitive regularization process so as to eventually retrieve the urban footprint. Results show well the complementary between both data sources as well as the relevance of the late fusion stategy. © 2022 Authors. All rights reserved.","Convolutional neural networks; Image classification; Image enhancement; Image fusion; Image resolution; Satellite imagery; Semantic Segmentation; Semantics; Area detection; Artificialized area; Decisions fusion; Late fusion; Multi-spectral; Multi-temporal data; Regularisation; Segmentation; Urban areas; Very-high spatial resolutions; Decision trees","Artificialized area; Classification; Decision fusion; Late fusion; Multispectral; Regularization; Segmentation; Urban area","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85142401136"
"Teo T.-A.; Fu Y.-J.","Teo, Tee-Ann (7005909918); Fu, Yu-Ju (57210930564)","7005909918; 57210930564","Time series image fusion for formosat-2 and landsat-8 images","2018","Proceedings - 39th Asian Conference on Remote Sensing: Remote Sensing Enabling Prosperity, ACRS 2018","5","","","3007","3010","3","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071949917&partnerID=40&md5=3d8e3a02279e67d2baae977a239d09d0","The aim of this study is to construct time series images from multi-sensor images. This study compares different time series image fusion techniques for Formosat-2 (FS-2) and Landsat-8 (LS-8) images. Three different image fusion approaches are included to generate time series images from Formosat-2 and Landsat-8 images, including bi-cubic image resampling, high pass filter pan-sharpening and spatial and temporal adaptive reflectance fusion model (STARFM). The goal is to integrate satellite images from different sensors with different spatial and temporal characteristics. In order to assess the quality of simulated images, this study calculates the biases between the observed and the synthetic reflectance for Formosat-2 image. Also, this study demonstrates the simulation of Formosat-2 image from Landsat-8 image through different approaches. In qualitative analysis, the STARFM approach provides better results than other approaches. The quantitative results also indicated that the difference between simulated and real image via STARFM has the lowest bias. In summary, the time series satellite images can be constructed from multi-sensor satellite images successfully. © 2018 Asian Association on Remote Sensing. All Rights Reserved.","High pass filters; Reflection; Remote sensing; Satellites; Time series; Image; Image fusion approach; Image fusion techniques; Multi sensor images; Multi-sensor satellite images; Qualitative analysis; Quantitative result; Temporal characteristics; Image fusion","Image; Image fusion; Satellite; Time-series","Conference paper","Final","","Scopus","2-s2.0-85071949917"
"Santhi P.; Thirugnanam G.; Mangaiyarkarasi P.","Santhi, P. (57195480795); Thirugnanam, G. (34267841300); Mangaiyarkarasi, P. (34969191500)","57195480795; 34267841300; 34969191500","Directional contourlet based multi-resolution image fusion method for INSAT images","2017","Communications in Computer and Information Science","721","","","369","376","7","10.1007/978-981-10-5427-3_39","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028301335&doi=10.1007%2f978-981-10-5427-3_39&partnerID=40&md5=053542375123b711f77047974f1ef02a","Among the accessibility of multi-detector information in numerous fields, image fusion has received growing consideration in the researchers for a extensive spectrum of applications. Image fusion is the procedure to merges statistics from various images of the identical view. These pictures perhaps taken from various detectors, obtained at dissimilar times. In this paper, an image fusion technique rely on Directional Contourlet transform is proposed to improve the quality of image and meet the needs of application of vision. Two or more images to be fused should be decomposed using Contourlet with multi-resolution frequencies. The resulting sub-images are fused using Directive Contrast rule to obtain the combined image. As the wavelet transform has several special features in evaluation with scalar wavelets on image processing, but it flushes it to keep the inherent information. The efficacy of the proposed scheme has been explained using various image sets such as the multi-focus pictures, multi-detector satellite image. The proposed Directional Contourlet transform based fusion method has compared with wavelet transform image fusion method qualitatively and quantitatively. Experimental results concluded that the proposed scheme performs superior for image fusion in comparison with wavelet transform. © Springer Nature Singapore Pte Ltd. 2017.","Image compression; Image enhancement; Image processing; Wavelet transforms; Combined images; Contourlet transform; Fusion methods; Image fusion methods; Image fusion techniques; INSAT images; Multi-detectors; Multiresolution images; Image fusion","Directional contourlet transform; Image fusion; INSAT images; Wavelet transform","Conference paper","Final","","Scopus","2-s2.0-85028301335"
"Song H.; Liu Q.; Wang G.; Hang R.; Huang B.","Song, Huihui (36572623600); Liu, Qingshan (36063739200); Wang, Guojie (57951093900); Hang, Renlong (56082126900); Huang, Bo (55388074800)","36572623600; 36063739200; 57951093900; 56082126900; 55388074800","Spatiotemporal Satellite Image Fusion Using Deep Convolutional Neural Networks","2018","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","11","3","","821","829","8","10.1109/JSTARS.2018.2797894","185","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042131669&doi=10.1109%2fJSTARS.2018.2797894&partnerID=40&md5=c5253a13e222c8dfbe2b19ac3ee06ff7","We propose a novel spatiotemporal fusion method based on deep convolutional neural networks (CNNs) under the application background of massive remote sensing data. In the training stage, we build two five-layer CNNs to deal with the problems of complicated correspondence and large spatial resolution gaps between MODIS and Landsat images. Specifically, we first learn a nonlinear mapping CNN between MODIS and low-spatial-resolution (LSR) Landsat images and then learn a super-resolution CNN between LSR Landsat and original Landsat images. In the prediction stage, instead of directly taking the outputs of CNNs as the fusion result, we design a fusion model consisting of high-pass modulation and a weighting strategy to make full use of the information in prior images. Specifically, we first map the input MODIS images to transitional images via the learned nonlinear mapping CNN and further improve the transitional images to LSR Landsat images via the fusion model; then, via the learned SR CNN, the LSR Landsat images are supersolved to transitional images, which are further improved to Landsat images via the fusion model. Compared with the previous learning-based fusion methods, mainly referring to the sparse-representation-based methods, our CNNs-based spatiotemporal method has the following advantages: 1) automatically extracting effective image features; 2) learning an end-to-end mapping between MODIS and LSR Landsat images; and 3) generating more favorable fusion results. To examine the performance of the proposed fusion method, we conduct experiments on two representative Landsat-MODIS datasets by comparing with the sparse-representation-based spatiotemporal fusion model. The quantitative evaluations on all possible prediction dates and the comparison of fusion results on one key date in both visual effect and quantitative evaluations demonstrate that the proposed method can generate more accurate fusion results. © 2008-2012 IEEE.","Convolution; Deep neural networks; Earth (planet); Image enhancement; Image resolution; Mapping; Neural networks; Personnel training; Radiometers; Remote sensing; Satellite imagery; Satellites; Convolutional neural network; MODIS; Nonlinear mappings; Spatial resolution; Spatiotemporal phenomena; Temporal resolution; accuracy assessment; artificial neural network; image analysis; Landsat; mapping; nonlinearity; satellite imagery; spatial resolution; spatiotemporal analysis; Image fusion","Convolutional neural network (CNN); nonlinear mapping (NLM); spatial resolution; temporal resolution","Article","Final","","Scopus","2-s2.0-85042131669"
"Tian H.; Huang S.; Zhou S.; Bi P.; Yang Z.; Li X.; Chen L.; Cazelles B.; Yang J.; Luo L.; Jing Q.; Yuan W.; Pei Y.; Sun Z.; Yue T.; Kwan M.-P.; Liu Q.; Wang M.; Tong S.; Brownstein J.S.; Xu B.","Tian, Huaiyu (57603675900); Huang, Shanqian (56333817500); Zhou, Sen (55765753800); Bi, Peng (57202072544); Yang, Zhicong (56565728400); Li, Xiujun (55910536800); Chen, Lifan (55766425800); Cazelles, Bernard (57194820701); Yang, Jing (57839424700); Luo, Lei (55181381600); Jing, Qinlong (55181888800); Yuan, Wenping (8562505600); Pei, Yao (56333645400); Sun, Zhe (57189991383); Yue, Tianxiang (7101867316); Kwan, Mei-Po (7005364475); Liu, Qiyong (55616174300); Wang, Ming (53265130500); Tong, Shilu (7201486841); Brownstein, John S. (8872411400); Xu, Bing (7404589013)","57603675900; 56333817500; 55765753800; 57202072544; 56565728400; 55910536800; 55766425800; 57194820701; 57839424700; 55181381600; 55181888800; 8562505600; 56333645400; 57189991383; 7101867316; 7005364475; 55616174300; 53265130500; 7201486841; 8872411400; 7404589013","Surface water areas significantly impacted 2014 dengue outbreaks in Guangzhou, China","2016","Environmental Research","150","","","299","305","6","10.1016/j.envres.2016.05.039","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976276969&doi=10.1016%2fj.envres.2016.05.039&partnerID=40&md5=15de630429ed70beb102241bbfec3295","Dengue transmission in urban areas is strongly influenced by a range of biological and environmental factors, yet the key drivers still need further exploration. To better understand mechanisms of environment–mosquito–urban dengue transmission, we propose an empirical model parameterized and cross-validated from a unique dataset including viral gene sequences, vector dynamics and human dengue cases in Guangzhou, China, together with a 36-year urban environmental change maps investigated by spatiotemporal satellite image fusion. The dengue epidemics in Guangzhou are highly episodic and were not associated with annual rainfall over time. Our results indicate that urban environmental changes, especially variations in surface area covered by water in urban areas, can substantially alter the virus population and dengue transmission. The recent severe dengue outbreaks in Guangzhou may be due to the surge in an artificial lake construction, which could increase infection force between vector (mainly Aedes albopictus) and host when urban water area significantly increased. Impacts of urban environmental change on dengue dynamics may not have been thoroughly investigated in the past studies and more work needs to be done to better understand the consequences of urbanization processes in our changing world. © 2016 The Authors","Aedes; Animals; China; Dengue; Disease Outbreaks; Fresh Water; Insect Vectors; Urbanization; China; Guangdong; Guangzhou; Aedes albopictus; rain; water; fresh water; disease transmission; disease vector; empirical analysis; environmental change; epidemic; genetic analysis; remote sensing; surface water; urban area; urbanization; Aedes albopictus; Article; China; dengue; disease transmission; environmental change; epidemic; gene sequence; lake; priority journal; remote sensing; surface area; urban area; Aedes; animal; dengue; insect vector; physiology; transmission; urbanization; virology","Climate; Guangzhou; Remote sensing; Urban dengue outbreak; Water surface area","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-84976276969"
"Kuchma T.","Kuchma, Tetyana (57191273209)","57191273209","Combined use of SAR and optical satellite images for landscape diversity assessment","2016","European Space Agency, (Special Publication) ESA SP","SP-740","","","","","","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988514162&partnerID=40&md5=24ac28c5ef505e3c9cfb47645c8a5faa","Land cover change analysis is essential for effective land use management and biodiversity conservation. The advantages of Sentinel-1 and Landsat-8 image fusion for land cover classification and landscape diversity maps development were studied. The methodology of landscape metrics interpretation for sustainable land use planning is developed and tested on agricultural landscapes in Ukraine.","Biodiversity; Conservation; Image fusion; Radar imaging; Agricultural landscapes; Biodiversity conservation; Land cover classification; Land-use management; Landscape diversity; Landscape metrics; Optical satellite images; Sustainable land use; Land use","","Conference paper","Final","","Scopus","2-s2.0-84988514162"
"Wang J.; Huang B.","Wang, Jing (56278839600); Huang, Bo (55388074800)","56278839600; 55388074800","A spatiotemporal satellite image fusion model with autoregressive error correction (AREC)","2018","International Journal of Remote Sensing","39","20","","6731","6756","25","10.1080/01431161.2018.1466073","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046036871&doi=10.1080%2f01431161.2018.1466073&partnerID=40&md5=5f484000d9ab0749cb204a7996149f21","To overcome the trade-off between spatial and temporal resolutions of satellite sensors, various spatiotemporal image fusion methods have been developed to generate synthetic imagery with both fine spatial and temporal resolutions. While such methods have achieved different levels of success, they have not considered spatiotemporal autocorrelation in the fusion process. Herein, we propose a novel spatiotemporal model incorporating autoregressive error correction (AREC) for fusing Moderate Resolution Imaging Spectroradiometer (MODIS) and Landsat Enhanced Thematic Mapper Plus (ETM+) images. This AREC model minimizes autoregressive errors when fitting a relationship between coarse- and fine-resolution pixels in an existing MODIS–Landsat image pair (on a base date (Formula presented.)). The derived relationship is then applied to the corresponding pixel in the prediction pair (on a prediction date (Formula presented.)). This method enables the relationship to be optimized and the phenological and land-cover changes to be treated in a unified manner. The AREC model was tested using a simulated data set and two actual data sets from Shenzhen, China, and Saskatchewan, Canada. The model was compared with the spatial and temporal adaptive reflectance fusion model (STARFM) and the flexible spatiotemporal data fusion (FSDAF) method in terms of changed and unchanged regions, and whole data sets, using visual analysis and quantitative indices. The results show that the AREC model can effectively predict phenological and land-cover changes with higher accuracies than other algorithms as a result of AREC. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","Canada; China; Guangdong; Saskatchewan; Shenzhen; Economic and social effects; Error correction; Forecasting; Image enhancement; Pixels; Radiometers; Satellite imagery; Autoregressive error correction; Autoregressive errors; Landsat enhanced Thematic Mapper Plus (ETM+) image; Moderate resolution imaging spectroradiometer; Saskatchewan , Canada; Spatial and temporal resolutions; Spatio-temporal models; Spatiotemporal images; error correction; image analysis; land cover; Landsat thematic mapper; MODIS; numerical model; phenology; pixel; satellite imagery; spatiotemporal analysis; Image fusion","","Article","Final","","Scopus","2-s2.0-85046036871"
"Guo L.; Zhao D.; Zhang R.; Du M.; Li Z.; Wang X.; Wang Y.","Guo, Lei (56401341400); Zhao, Dongling (55475660100); Zhang, Rui (57226040755); Du, Meng (57188837552); Li, Zhixiao (56945894900); Wang, Xiang (57151551000); Wang, Yaru (57192109336)","56401341400; 55475660100; 57226040755; 57188837552; 56945894900; 57151551000; 57192109336","Study on methods of extracting new construction land information based on SPOT6","2016","IFIP Advances in Information and Communication Technology","478","","","94","106","12","10.1007/978-3-319-48357-3_10","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997496842&doi=10.1007%2f978-3-319-48357-3_10&partnerID=40&md5=69bad5216aad3466a25da4d4f9cb7d7d","SPOT6 is a new remote sensing satellite launched in 2012, with high spatial resolution and strong data acquisition ability. However, a complete data preprocessing technology for the regulation of land resources has not yet been formed. According to the characteristics of SPOT6 satellite images, four different image fusion methods – Gram-Schmidt, HPF, PanSharpand PanSharpening were selected to conduct the comparison experiment by using the software platforms of ENVI, ERDAS and PCI. We evaluate the results’ performances from 3 different aspects. First, evaluating the image quality of experiment results qualitatively, then assessed quantitatively by establishing evaluation indexes including mean, standard deviation, information entropy, average gradient and correlation coefficient. Finally, evaluating the applicative effect of fused images based on the classification accuracy. The analysis results shows that the method of PanSharp is best to extract construction land information. Based on the PanSharp fusion image, in order to obtain the texture information under different scales, the authors screened the texture features according to Shannon entropy, and then used distance-based approach J-M to calculate the separation for choosing the optimal texture window. Once got the texture information, combining it with the original image to participate in the multi-scale image classification. The research result showed that multi-window texture participation in classification can improve separation of objects. Finally we extract construction land information with the method of SVM. This study may provide the technical support for application of SPOT6 image in the land resources management. © IFIP International Federation for Information Processing 2016.","Agriculture; Classification (of information); Data acquisition; Image fusion; Image texture; Natural resources; Quality control; Remote sensing; Satellite imagery; Classification accuracy; Correlation coefficient; High spatial resolution; Image fusion methods; Multi-Windows; New constructions; Remote sensing satellites; SPOT6; Image classification","Image fusion; Multi-window texture; New construction land; SPOT6; SVM","Conference paper","Final","","Scopus","2-s2.0-84997496842"
"Ban Y.J.; Kim H.S.; Park C.J.","Ban, Yun Ji (15128584200); Kim, Hye Sun (55655063600); Park, Chang Joon (56140934000)","15128584200; 55655063600; 56140934000","Fusion pipeline of 3D terrain data from different input images","2019","ICTC 2019 - 10th International Conference on ICT Convergence: ICT Convergence Leading the Autonomous Future","","","8939798","1096","1098","2","10.1109/ICTC46691.2019.8939798","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078290076&doi=10.1109%2fICTC46691.2019.8939798&partnerID=40&md5=6b7036240c1d1959f1072c4b5cf9063d","Nowadays, researches for reconstructing 3D terrain from images are being widely carried out. The result of reconstruction according to the kind of the input image is different. In this paper, we propose a 3D terrain fusion method of textured mesh models reconstructed from different altitude images or generated by hand. We merged 3D models depending on the priority and connected edges seamlessly. © 2019 IEEE.","Fusion reactions; Image fusion; Landforms; Merging; Mesh generation; Textures; Three dimensional computer graphics; 3-d terrains; 3D meshes; Aerial images; Fusion methods; Input image; Mesh model; Satellite images; Image reconstruction","3D mesh; aerial image; fusion; merge; reconstruction; satellite image","Conference paper","Final","","Scopus","2-s2.0-85078290076"
"Lal A.M.; Anouncia S.M.","Lal, Anisha M. (56808822200); Anouncia, S. Margret (25822351600)","56808822200; 25822351600","Enhanced dictionary based sparse representation fusion for multi-temporal remote sensing images","2016","European Journal of Remote Sensing","49","","","317","336","19","10.5721/EuJRS20164918","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981343226&doi=10.5721%2fEuJRS20164918&partnerID=40&md5=b8ebe68f7eafea99aaa2517cbbd6c9c4","In remote sensing, image fusion is the process of blending two images to obtain finer details of the fused image. In this paper, an enhanced dictionary-based sparse representation (EDSR) is proposed for multitemporal image fusion. Multitemporal remote satellite images acquired on the same geographical area at different acquisition dates are merged to obtain a fused image for further analysis. Sparse representation of the image is employed in the approximation and representation of the target image. In order to improve the performance of the fusion process, a locally adaptive dictionary is created such that the dictionary contains patches extracted from both source images. The reconstruction of the image is performed using maximum absolute coefficients through the learned dictionary. The proposed EDSR technique has been compared quantitatively and qualitatively with the existing techniques, such as PCA, DWT, SWT, Ehlers, and sparse representation (SR), to evaluate its performance. The EDSR performs well in mutual information (MI) with 3.4742 and feature mutual information (FMI) with 0.4790 and provides better results in the case of degree of distortion, UIQI, and ERGAS for dataset 1 than the existing fusion methods. Experimental results on LANDSAT images revealed that the proposed technique is more effective in terms of preservation of spectral information, errors, color, and visual quality of the fused product. © 2016 by the authors; licensee Italian Society of Remote Sensing (AIT).","Image fusion; Remote sensing; Degree of distortion; Learned dictionaries; Multi-temporal; Multi-temporal image; Multi-temporal remote sensing; Mutual informations; Sparse representation; Spectral information; data quality; image resolution; Landsat; reconstruction; remote sensing; satellite data; satellite imagery; spectral analysis; temporal analysis; Image enhancement","Image fusion; Multitemporal; Remote sensing; Sparse representation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-84981343226"
"","","","ACM International Conference Proceeding Series","2018","ACM International Conference Proceeding Series","","","","","","248","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064485525&partnerID=40&md5=a4b29f7688ccbe8d113f7773f487b02c","The proceedings contain 45 papers. The topics discussed include: additive margin softmax with center loss for face recognition; a new method for stroke order recognition of handwritten Chinese characters; real-time face attendance marking system in non-cooperative environments; top view person detection and counting for low compute embedded platforms; image edge detection using fractional order differential calculus; a natural scene edge detection algorithm based on image fusion; optimization of feature space for people detection from topview on light embedded platform; 3D face reconstruction from low-resolution images with convolutional neural networks; planetary marching cubes: a marching cubes algorithm for spherical space; an efficient non-convex mixture method for low-rank tensor completion; and analysis of chromatic characteristics, in satellite images for the classification of vegetation covers and deforested areas.","","","Conference review","Final","","Scopus","2-s2.0-85064485525"
"Sonnad S.","Sonnad, Shashidhar (57191613269)","57191613269","A survey on fusion of multispectral and panchromatic images for high spatial and spectral information","2016","Proceedings of the 2016 IEEE International Conference on Wireless Communications, Signal Processing and Networking, WiSPNET 2016","","","7566115","177","180","3","10.1109/WiSPNET.2016.7566115","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992018178&doi=10.1109%2fWiSPNET.2016.7566115&partnerID=40&md5=3a1b21af9a33f7ad6059a034854ae7cb","The purpose of satellite image fusion of multispectral and panchromatic images is a method to combine the desirable characteristic of high spatial panchromatic (PAN) image and low spatial multispectral (MS) image to obtain single multispectral image with high spatial resolution and high spectral resolution. This paper furnish a survey on various image fusion algorithms of MS and PAN images such as, Brovey transform, Intensity-Hue-Saturation(IHS) transform, Principal Component Analysis (PCA), Highpass Filtering, Wavelet transform, Integration of different transform methods with IHS, fusion method based on PCA and feature product of Wavelet transform, Fourier transform, General Intensity- Hue-Saturation (GIHS) transform, Optimal Filter design, modified Wavelet Averaging Merging method and modified Bi-cubic Interpolation method in non Subsampled Contourlet transform, improved IHS and PCA merges based on Wavelet decomposition, etc. © 2016 IEEE.","Fusion reactions; High pass filters; Image enhancement; Principal component analysis; Product design; Satellite imagery; Signal processing; Spectral resolution; Surveys; Wavelet decomposition; Wavelet transforms; Wireless telecommunication systems; High spectral resolution; Image fusion algorithms; Intensity hue saturations; Multi-spectral; Non-sub-sampled contourlet transforms; Panchromatic; Panchromatic (Pan) image; Wavelet; Image fusion","Fusion; IHS; Multispectral; Panchromatic; PCA; Wavelet","Conference paper","Final","","Scopus","2-s2.0-84992018178"
"Theran C.A.; Alvarez M.A.; Arzuaga E.; Sierra H.","Theran, Carlos A. (57213160596); Alvarez, Michael A. (57213140223); Arzuaga, Emmanuel (35781502400); Sierra, Heidy (24071959900)","57213160596; 57213140223; 35781502400; 24071959900","A Pixel Level Scaled Fusion Model to Provide High Spatial-Spectral Resolution for Satellite Images Using LSTM Networks","2019","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2019-September","","8921269","","","","10.1109/WHISPERS.2019.8921269","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077559994&doi=10.1109%2fWHISPERS.2019.8921269&partnerID=40&md5=05be7266faee713984b84933674ee973","Pixel-level fusion of satellite images coming from multiple sensors allows for an improvement in the quality of the acquired data both spatially and spectrally. In particular, multispectral and hyperspectral images have been fused to generate images with a high spatial and spectral resolution. In literature, there are several approaches for this task, nonetheless, those techniques still present a loss of relevant spatial information during the fusion process. This work presents a multi scale deep learning model to fuse multispectral and hyperspectral data, each with high-spatial-and-low-spectral resolution (HSaLS) and low-spatial-and-high-spectral resolution (LSaHS) respectively. As a result of the fusion scheme, a high-spatial-and-spectral resolution image (HSaHS) can be obtained. In order of accomplishing this result, we have developed a new scalable high spatial resolution process in which the model learns how to transition from low spatial resolution to an intermediate spatial resolution level and finally to the high spatial-spectral resolution image. This step-by-step process reduces significantly the loss of spatial information. The results of our approach show better performance in terms of both the structural similarity index and the signal to noise ratio. © 2019 IEEE.","Data fusion; Deep learning; Hyperspectral imaging; Image enhancement; Image fusion; Image resolution; Pixels; Remote sensing; Signal to noise ratio; Spectral resolution; Spectroscopy; High spatial resolution; High spectral resolution; Multispectral images; Pixel level; Spatial informations; Spatial resolution; Structural similarity indices; Super resolution; Long short-term memory","Data Fusion; hyperspectral image; Long Short Term Memory; multispectral image; Pixel level; Super resolution","Conference paper","Final","","Scopus","2-s2.0-85077559994"
"Satapathy L.M.; Dalai A.; Satapathy S.; Jena A.","Satapathy, Lalit Mohan (57205394328); Dalai, Abhisek (57205393398); Satapathy, Soubhagya (57205389716); Jena, Anwesha (57210385325)","57205394328; 57205393398; 57205389716; 57210385325","Satellite image enhancement based on multi-technology fusion","2018","Proceedings of the International Conference on Inventive Communication and Computational Technologies, ICICCT 2018","","","8473070","1677","1680","3","10.1109/ICICCT.2018.8473070","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059851037&doi=10.1109%2fICICCT.2018.8473070&partnerID=40&md5=22d6cae397e465202f504c022145d56b","In this paper, a novel contrast enhancement technique based on bi-dimensional empirical mode decomposition (BEMD) and principal component analysis (PCA) is proposed for low contrast satellite image. The proposed method first decomposes the image into various intrinsic mode functions (IMF). The edge information is obtained by applying a weighted method between the residue and the gradient of the original image. The resultant image is calculated by applying PCA based fusion to the original image and the reconstructed image. Experiments are conducted on various satellite images to compare and analyze the performance of the proposed algorithm. The effectiveness of the presented approach is quantified in terms of entropy ratio (ER), peak signal to noise ratio (PSNR), the absolute mean brightness error (AMBE), image quality index(IQI) and structural similarity index measure (SSIM). © 2018 IEEE.","Image analysis; Image fusion; Image quality; Principal component analysis; Satellites; Signal to noise ratio; BEMD; Bi dimensional empirical mode decomposition (BEMD); Compare and analyze; Contrast Enhancement; Intrinsic Mode functions; Morphological gradient; Peak Signal to Noise Ratio (PSNR); Structural similarity index measures (SSIM); Image enhancement","BEMD; enhancement; image fusion; morphological gradient; PCA","Conference paper","Final","","Scopus","2-s2.0-85059851037"
"Devi M.B.; Devanathan R.","Devi, Mutum Bidyarani (57204634103); Devanathan, R. (7005067176)","57204634103; 7005067176","Pansharpening Using Data Driven Model Based on Linear Regression","2018","2018 IEEE International Conference on Electronics, Computing and Communication Technologies, CONECCT 2018","","","8482388","","","","10.1109/CONECCT.2018.8482388","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056466986&doi=10.1109%2fCONECCT.2018.8482388&partnerID=40&md5=965c2cd2f84bf5a57c69826e35ce1667","With the launching of many earth's observation satellites, the amount of data capturing the Earth's surface has been increasing to a great extent. In this paper, we emphasize the need for analyzing the satellite image data particularly in the context of data fusion applied to data taken from sensors of different resolution. The problem lies in maintaining the spectral characteristics of the multispectral images when panchromatic image is used to estimate the high spatial multispectral image. We take a wholesome approach based on the reflectance data irrespective of the sensor physics. The approach aims to produce an enhanced spatial resolution multispectral image having the same resolution as that of the panchromatic data while still preserving the spectral characteristics of the multispectral image. Using a linear regression model between multispectral and panchromatic data, an optimal solution in terms of Lagrange multiplier is provided and validated to maximize the spectral consistency of the fused image. The chi-square test is used to check the 'goodness of fitd' of the data. The experimental results are discussed and presented using IKONOS satellite data. © 2018 IEEE.","Data fusion; Image enhancement; Lagrange multipliers; Linear regression; Satellites; Statistical tests; Different resolutions; Linear regression models; Multispectral images; Observation satellites; Panchromatic images; Satellite image datas; Spectral characteristics; spectral consistency; Image fusion","data fusion; image fusion; Lagrange multiplier; spectral consistency","Conference paper","Final","","Scopus","2-s2.0-85056466986"
"","","","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","2017","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","4W4","","","","536","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032375242&partnerID=40&md5=7e586b59444678ba970f2b86a4d9a8ef","The proceedings contain 82 papers. The topics discussed include: a comparison of close-range photogrammetry using a non-professional camera with field surveying for volume estimation; investigating and modeling effects of climatically and hydrologically indicators on the Urmia lake coastline changes using time series analysis; thermal and visible satellite image fusion using wavelet in remote sensing and satellite image processing; monitoring spatiotemporal changes of heat island in Babol city due to land use changes; and statistical method to overcome overfitting issue in rational function models.","","","Conference review","Final","","Scopus","2-s2.0-85032375242"
"Liu M.; Ke Y.; Yin Q.; Chen X.; Im J.","Liu, Maolin (57201456951); Ke, Yinghai (35784422100); Yin, Qi (57210813556); Chen, Xiuwan (8505956600); Im, Jungho (9036557400)","57201456951; 35784422100; 57210813556; 8505956600; 9036557400","Comparison of five spatio-temporal satellite image fusion models over landscapes with various spatial heterogeneity and temporal variation","2019","Remote Sensing","11","22","2612","","","","10.3390/rs11222612","29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075337132&doi=10.3390%2frs11222612&partnerID=40&md5=f68a1dddf3291e25909b345209478a06","In recent years, many spatial and temporal satellite image fusion (STIF) methods have been developed to solve the problems of trade-off between spatial and temporal resolution of satellite sensors. This study, for the first time, conducted both scene-level and local-level comparison of five state-of-art STIF methods from four categories over landscapes with various spatial heterogeneity and temporal variation. The five STIF methods include the spatial and temporal adaptive reflectance fusion model (STARFM) and Fit-FC model from the weight function-based category, an unmixing-based data fusion (UBDF) method from the unmixing-based category, the one-pair learning method from the learning-based category, and the Flexible Spatiotemporal DAta Fusion (FSDAF) method from hybrid category. The relationship between the performances of the STIF methods and scene-level and local-level landscape heterogeneity index (LHI) and temporal variation index (TVI) were analyzed. Our results showed that (1) the FSDAF model was most robust regardless of variations in LHI and TVI at both scene level and local level, while it was less computationally efficient than the other models except for one-pair learning; (2) Fit-FC had the highest computing efficiency. It was accurate in predicting reflectance but less accurate than FSDAF and one-pair learning in capturing image structures; (3) One-pair learning had advantages in prediction of large-area land cover change with the capability of preserving image structures. However, it was the least computational efficient model; (4) STARFM was good at predicting phenological change, while it was not suitable for applications of land cover type change; (5) UBDF is not recommended for cases with strong temporal changes or abrupt changes. These findings could provide guidelines for users to select appropriate STIF method for their own applications. © 2019 by the authors.","Economic and social effects; Forecasting; Image analysis; Image fusion; Reflection; Satellites; Fit-FC; FSDAF; One-pair learning; Satellite images; Spatial heterogeneity; STARFM; Temporal variation; UBDF; Learning systems","Fit-FC; FSDAF; One-pair learning; Spatial and temporal satellite image fusion; Spatial heterogeneity; STARFM; Temporal variation; UBDF","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85075337132"
"Joshi K.; Shah D.D.; Deshpande A.A.","Joshi, Kavita (57215550958); Shah, Dilip D. (55576264100); Deshpande, Anupama A. (57209251507)","57215550958; 55576264100; 57209251507","Improving satellite image processing via hybridization of fusion, feature extraction & neural nets","2019","International Journal of Recent Technology and Engineering","7","6","","1773","1778","5","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067015636&partnerID=40&md5=ad707ffe452b8a409a08fea0eba11189","Satellite image classification is useful for many applications including but not limited to, crop classification, military equipment identification, movement tracking and forest cover detection. These applications involve image segmentation, feature extraction and application of a classifier to perform the final categorization task. This texts presents a hybrid approach which uses multispectral image fusion using brovey and principal component analysis methods, with the purpose of boosting the eminence of the image segmentation method, this when combined with hybrid feature extraction and classification process, tends to produce highly accurate classification results. We compare the classification accuracy of a standard support vector machine (SVM) with cascaded neural networks and observe that the neural network performs 20% better than SVM when applied to crop identification application © BEIESP.","","Brovey; Fusion; Hybrid; Neural network; PCA; Satellite image classification","Article","Final","","Scopus","2-s2.0-85067015636"
"Yu L.; Zhang Y.; Sun M.; Zhu X.","Yu, Lei (56364548300); Zhang, Yongjun (55577971100); Sun, Mingwei (12782541800); Zhu, Xinyu (57190835793)","56364548300; 55577971100; 12782541800; 57190835793","Fusion of cloudy opical satellite imagery by cloud detection and HPF pass filtering","2016","Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University","41","9","","1160","1167","7","10.13203/j.whugis20140505","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983439960&doi=10.13203%2fj.whugis20140505&partnerID=40&md5=01545e848f2b391486954637230df1fb","Noise from clouds is a common problem in optical satellite image processing. The high pass filter (HPF) fusion method is analyzed as a way to estimate the influence of cloud noise during image fusion. An approach combining cloud detection with HPF is introduced that refines the results of image fusion containing clouds. A, NIR/R-OTSU cloud detection approach is employed for real-time cloud detection, thus areas covered by clouds can be identified. A local optimization strategy is adopted in image fusion with HPF in cloudless blocks to get the fused image. Merged multispectral and panchromatic iZY-3 satellite image results show that the algorithm discussed in this paper performs better than HPF, IHS transform and Pansharp methods for merging images with clouds. © 2016, Research and Development Office of Wuhan University. All right reserved.","Fusion reactions; High pass filters; Image processing; Optical data processing; Satellite imagery; Satellites; Cloud detection; Fused images; Fusion methods; IHS transforms; Local optimization strategies; Multi-spectral; Optical satellite images; Satellite images; cloud; detection method; image processing; optical method; satellite imagery; ZiYuan; Image fusion","Cloud detection; Fusion; High pass filter; Satellite image; ZY-3 Satellite","Article","Final","","Scopus","2-s2.0-84983439960"
"Cepeda-Velastegui M.V.; Lopez Estevez M.C.; Padilla-Almeida O.; Toulkeridis T.","Cepeda-Velastegui, Marilyn V. (57209652496); Lopez Estevez, Maria Cristina (57209657340); Padilla-Almeida, Oswaldo (57023591200); Toulkeridis, Theofilos (6701738123)","57209652496; 57209657340; 57023591200; 6701738123","Determination of open pit mining zones through digital processing of multi-spectral images and ppi method - A case study of southern Ecuador","2019","2019 6th International Conference on eDemocracy and eGovernment, ICEDEG 2019","","","8734455","188","193","5","10.1109/ICEDEG.2019.8734455","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068409007&doi=10.1109%2fICEDEG.2019.8734455&partnerID=40&md5=74e07efffcbce89ff47df1181ae296ed","In the current study, the identification of open pit mining areas has been conducted using multispectral satellite images of medium (Landsat 8)and high (Sentinel 2B)spatial resolution of the province of Zamora Chinchipe in southern Ecuador. Such research involved several digital processes such as atmospheric correction, image fusion through the Brovey algorithm, noise elimination among others. We worked simultaneously with spatial and spectral patterns through the application of algorithms in order to increase spatial resolution., and spectral indices that enhance variables of interest. In addition, the Pixel Purity Index (PPI)methodology has been applied in order to obtain the classes involved in the study area based on the pure pixels and the results were compared between the two methodologies. The zones considered open-pit mining have been obtained in both cases. © 2019 IEEE.","Image fusion; Image resolution; Pixels; Spectroscopy; Application of algorithms; Atmospheric corrections; Endmembers; Multispectral images; Multispectral satellite image; Pixel purity index; Spatial resolution; Spectral indices; Open pit mining","Brovey algorithm; Endmembers; Open pit mining; PPI; Spectral indexes","Conference paper","Final","","Scopus","2-s2.0-85068409007"
"","","","2017 IEEE 2nd International Conference on Signal and Image Processing, ICSIP 2017","2017","2017 IEEE 2nd International Conference on Signal and Image Processing, ICSIP 2017","2017-January","","","","","499","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043708891&partnerID=40&md5=9af8a46cfd0bf7691cd3c53b57b7a55d","The proceedings contain 97 papers. The topics discussed include: improved k-d tree-segmented block truncation coding for color image compression; an error detection and recovery technique for images compressed with the CCSDS compression algorithm; adaptive compressive-sensing of 3D point clouds; compressed sensing MRI with total variation and frame balanced regularization; medical image fusion based on GPU accelerated nonsubsampled shearlet transform and 2D principal component analysis; a novel approach on classification of infant activity post surgery based on motion vector; automatic localization of optic disc based on deep learning in fundus images; a novel compensation algorithm of aerial image registration; three-dimensional positioning using ALOS/prism triple linear-array satellite images; digital anthropometry for human body measurement on android platform; stacked hidden Markov model for motion intention recognition; image processing algorithm for extracting the phase map from structured lights; supervised 3D graph-based automated epidermal thickness estimation; optimizing cognitive analysis sensitivity of photospheres using cube maps; detecting AMD caused vision scotoma through eye tracking; and learning visual odometry for unmanned aerial vehicles.","","","Conference review","Final","","Scopus","2-s2.0-85043708891"
"Medina J.; González L.B.; Upegui E.","Medina, Javier (57197825929); González, Laura Becerra (57210264490); Upegui, Erika (36459015100)","57197825929; 57210264490; 36459015100","Spectral and spatial assessment of the Ikonos images fusion, using the Principal Components, Brovey Transform and Multiplicative; [Evaluación espectral y espacial de la fusión de imágenes Ikonos, usando métodos tradicionales: Componentes Principales, Transformada de Brovey y Multiplicación]","2019","Iberian Conference on Information Systems and Technologies, CISTI","2019-June","","8760873","","","","10.23919/CISTI.2019.8760873","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070105082&doi=10.23919%2fCISTI.2019.8760873&partnerID=40&md5=1b4a001acf7bd23c07597a5aa1a0903d","This article presents the assessment of the fusion of Ikonos satellite images using three methods, the first corresponds, Principal Component second Brovey Transform and the Multiplication method implemented in the Matlab Software, with the objective of identifying which of the three methods improves the special resolution without significant loss of spectral richness. Assessment of two implemented methods were performed using the following indices: ERGAS (spectral and spatial), RASE, Universal Quality Index Qu, and Correlation Index, where the best results on spatially and spectrally richness were obtained with first method called transform Brovey. © 2019 AISTI.","Fusion reactions; Image fusion; Information systems; Information use; MATLAB; Brovey transforms; Correlation index; Ikonos; Ikonos satellite image; Multiplication method; Principal Components; Satellite images; Spatial assessment; Image enhancement","Fusion; Ikonos; Multiplication method; Principal Component; Satellite images; Transform Brovey","Conference paper","Final","","Scopus","2-s2.0-85070105082"
"Wang X.; Feng X.; Su F.; Wang W.; Zhang Y.; Jiang H.","Wang, Xuefeng (57202646959); Feng, Xue (57668714800); Su, Fenzhen (57210948280); Wang, Wuxia (57668714700); Zhang, Yu (56158245500); Jiang, Huiping (57202254261)","57202646959; 57668714800; 57210948280; 57668714700; 56158245500; 57202254261","Extraction of Coastal Aquaculture Land from Medium Resolution Image based on Texture and Spatial Features; [基于纹理和空间特征的中分辨率影像滨海水产养殖用地提取研究]","2018","Journal of Geo-Information Science","20","5","","694","702","8","10.12082/dqxxkx.2018.180040","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087161668&doi=10.12082%2fdqxxkx.2018.180040&partnerID=40&md5=324481138976805e108c3bc43e555976","Aquaculture land has become widely distributed in recent years. It's difficult to extract aquaculture land for its complexity and inhomogeneity, especially from the medium spatial resolution satellite images. In this paper, we present an automated method containing three main steps to extract aquaculture land from medium spatial resolution images. First, the texture entropy and Normalized Difference Water Index(NDWI) were used to extracted aquaculture land initially. Then, the interrelations of neighboring objects were utilized to merge objects. Finally, a relative new feature called relative width was proposed, and the NDWI was used again to separate the aquaculture land accurately. This method was applied to Van fong Bay, Vietnam using Landsat-8 images whith pixel size of 15m after image fusion. Manual interpretation was conducted in the same region to support and validate our results of the minimum distance method. The result shows that the precision of the proposed method is 91.13%, which is far higher than the traditional object-oriented method. And the missing rate and false rate of the proposed method are 0.09% and 8.87%, respectively, indicating that the proposed method is reliable. This method provides an accurate and efficient means for fast land use mapping from medium resolution imagery. © 2018, Science Press. All right reserved.","","Aquaculture land; Middle resolution; Object-oriented; Texture","Article","Final","","Scopus","2-s2.0-85087161668"
"Zhong D.; Zhou F.","Zhong, Detang (7102032532); Zhou, Fuqun (57216519289)","7102032532; 57216519289","Improvement of clustering methods for modelling abrupt land surface changes in satellite image fusions","2019","Remote Sensing","11","15","1759","","","","10.3390/rs11151759","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070436836&doi=10.3390%2frs11151759&partnerID=40&md5=02f6bae009cde900bf6a2680a841cc22","A key challenge in developing models for the fusion of surface reflectance data across multiple satellite sensors is ensuring that they apply to both gradual vegetation phenological dynamics and abrupt land surface changes. To better model land cover spatial and temporal changes, we proposed previously a Prediction Smooth Reflectance Fusion Model (PSRFM) that combines a dynamic prediction model based on the linear spectral mixing model with a smoothing filter corresponding to the weighted average of forward and backward temporal predictions. One of the significant advantages of PSRFM is that PSRFM can model abrupt land surface changes either through optimized clusters or the residuals of the predicted gradual changes. In this paper, we expanded our approach and developed more efficient methods for clustering. We applied the new methods for dramatic land surface changes caused by a flood and a forest fire. Comparison of the model outputs showed that the new methods can capture the land surface changes more effectively. We also compared the improved PSRFM to two most popular reflectance fusion algorithms: Spatial and Temporal Adaptive Reflectance Fusion Model (STARFM) and Enhanced version of STARFM (ESTARFM). The results showed that the improved PSRFM is more effective and outperforms STARFM and ESTARFM both visually and quantitatively. © 2019 by the authors.","Deforestation; Forecasting; Image fusion; Reflection; Remote sensing; Surface measurement; Forward-and-backward; LANDSAT; Linear spectral mixing models; MODIS; Multiple satellites; Sentinel; Spatial and temporal changes; Spatio-temporal interpolations; Image enhancement","Image fusion; Landsat; MODIS; Remote sensing; Sentinel; Spatiotemporal interpolation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85070436836"
"Kaynak S.; Kumlu D.; Erer I.","Kaynak, Soner (57201856274); Kumlu, Deniz (55744570400); Erer, Isin (6603348002)","57201856274; 55744570400; 6603348002","Multiscale directional bilateral filter based fusion of satellite images","2018","2017 10th International Conference on Electrical and Electronics Engineering, ELECO 2017","2018-January","","","1161","1165","4","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046299921&partnerID=40&md5=d15749cf989aa3b58b533790ad3f951b","The fusion of multispectral and panchromatic satellite images is widely used in remote sensing community to obtain high resolution images both in spatial and spectral domains. One approach is to obtain Panchromatic (PAN) image details through a multiresolution analysis (MRA) based decomposition such as wavelet transform and inject them to the low resolution Multispectral (MS) image. However, this process may lead to redundant detail injection, resulting to artifacts and overenhancement in the fusion results. In this paper, we propose a new fusion scheme based on the decomposition of the PAN image using a multidirectional bilateral filter. Obtained detail layers contain both resolution and direction information. By appropriate selection of these layers, it is possible to perform a proper detail injection. Visual and quantitative results for Quickbird images are presented to validate the proposed method. © 2017 EMO (Turkish Chamber of Electrical Enginners).","Bandpass filters; Nonlinear filtering; Remote sensing; Wavelet decomposition; Bilateral filters; High resolution image; Multispectral images; Panchromatic (Pan) image; Panchromatic satellites; Quantitative result; QuickBird images; Satellite images; Image fusion","","Conference paper","Final","","Scopus","2-s2.0-85046299921"
"Manaf S.A.; Mustapha N.; Sulaiman M.N.; Husin N.A.; Hamid M.R.A.","Manaf, Syaifulnizam Abd (55185057700); Mustapha, Norwati (24802568600); Sulaiman, Md Nasir (22434244300); Husin, Nor Azura (25825147600); Hamid, Mohd Radzi Abdul (57190281942)","55185057700; 24802568600; 22434244300; 25825147600; 57190281942","Comparison of classification techniques on fused optical and SAR images for shoreline extraction: A case study at Northeast Coast of Peninsular Malaysia","2016","Journal of Computer Science","12","8","","399","411","12","10.3844/jcssp.2016.399.411","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006504138&doi=10.3844%2fjcssp.2016.399.411&partnerID=40&md5=ecafdb44839d3984c599df6ef7c770d9","Shoreline is a very important element to identify exact boundary at the coastal areas of a country. However, in order to identify land-water boundary for a large region using traditional ground survey technique is very time consuming. Alternatively, shoreline can be extracted by using satellite images that minimizes the mapping errors. The trend of extracting shoreline has been shifted from image processing to machine learning and data mining techniques. By using machine learning technique, the satellite images could be classified into land and water classes in order to extract shoreline. However, the result is meaningless if it has cloud and shadow on the water-land boundary. In this study, we compare the accuracy and Kappa Coefficient of six machine learning techniques namely Maximum Likelihood, Minimum Distance, Mahalanobis Distance, Parallelepiped, Neural Network and Support Vector Machines on three type of images; single optical multispectral, single SAR and fused image. A case study for this research is done alongside Tumpat beach, located at the Northeast Coast of Peninsular Malaysia. All the machine learning techniques have been tested on the three types of images. The experimental results show that classification using SVM on single multispectral image has the highest accuracy among all. However, the classified of fused image using SVM is considered much more accurate because it can cater the cloud and shadow problem. Additionally, the classification on 5 and 10 m fused images also tested and the result shows that with the increase of spatial resolution of fused image, the classification accuracy also increases. © 2016 Syaifulnizam Abd Manaf, Norwati Mustapha, Md Nasir Sulaiman, Nor Azura Husin and Mohd Radzi Abdul Hamid.","","Image classification; Image fusion; Machine learning; Satellite images; Shoreline extraction","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85006504138"
"Zexing Z.; Qizhi X.; Haibo W.; Wenyong Y.","Zexing, Zhao (57202311139); Qizhi, Xu (50562407300); Haibo, Wang (57681846600); Wenyong, Yu (57202309456)","57202311139; 50562407300; 57681846600; 57202309456","High-reflectivity objects distributed optical satellite image fusion based on NDVI classification","2017","Proceedings of 2017 2nd International Conference on Frontiers of Sensors Technologies, ICFST 2017","2017-January","","","231","235","4","10.1109/ICFST.2017.8210509","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047793500&doi=10.1109%2fICFST.2017.8210509&partnerID=40&md5=eccca03a328a30ceba7bc11aea7a449a","Ratioing method is one type of the most famous fusion methods in remote sensing image fusion domain. Generally, the ratioing method synthesizes a low-resolution panchromatic (Pan) image by adaptive weighted summation of a multispectral (MS) image. Consequently, the accuracy of the weights for low-resolution Pan image synthesis is of great importance. However, in most cases, the optical satellite images contain lots of high-reflectivity objects, such as clouds covered regions, and high-reflectivity buildings. These objects are saturate due to their strong reflectance. The distortion of saturated objects results in the failure of weights calculation, so that causes the color distortion of fused images. To solve the problem, this paper proposes a high-reflectivity objects distributed optical satellite image fusion method based on NDVI classification. First, the NDVI index is employed to classify the pixels of a MS image into high-reflectivity group and normal group, then the pixels in normal group is used to calculate the weighted coefficients, finally the fused image is obtained by ratioing transform. Experimental results on a large number of test images show that the proposed method has good performance on reducing color distortion. © 2017 IEEE.","Adaptive optics; Image classification; Pixels; Reflection; Remote sensing; Satellites; Multispectral images; NDVI index; Optical satellite images; Pan-sharpening; Panchromatic (Pan) image; Remote sensing images; Weighted coefficients; Weights calculation; Image fusion","Image fusion; NDVI index; Pan-sharpening; Remote sensing image","Conference paper","Final","","Scopus","2-s2.0-85047793500"
"Sghaier M.O.; Hadzagic M.; Patera J.","Sghaier, Moslem Ouled (56421930900); Hadzagic, Melita (8120789600); Patera, Jiri (22972569300)","56421930900; 8120789600; 22972569300","Fusion of SAR and Multispectral Satellite Images Using Multiscale Analysis and Dempster-Shafer Theory for Flood Extent Extraction","2019","FUSION 2019 - 22nd International Conference on Information Fusion","","","9011209","","","","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081788259&partnerID=40&md5=f1a0063e1de2d2f60ff7f5d9f9b7894a","Monitoring flood extent by means of Synthetic Aperture Radar (SAR) images has become a very common practice among decision makers and planners in disaster management as these images provide wide area coverage in extreme weather conditions. However, due to the satellite revisit time, their availability hinders their efficient use in disaster management. To capitalize on SAR images characteristics, this work considers both SAR and optical multispectral (MS) images, and proposes a novel method for SAR and optical image fusion in application to flood extent monitoring, which is based on two main steps: 1-Extraction of water pixels from the pre-and post-flooding images using a Modified Water Index (MWI) for water bodies identification from optical MS images and the Structural Feature Set (SFS) texture measurement for homogeneous areas extraction from SAR images, and 2-Applying the Max-Tree structure to estimate mass functions based on the multiscale and the multishape analysis of the input features map which are subsequently incorporated into the fusion module using Dempster-Shafer theory (DST). The results obtained in the evaluation of the proposed fusion method for three flood events characterized by different satellite image scenarios demonstrate the benefits of the multiscale DST fusion strategy in terms of chosen metrics in the classification of water body and monitoring of flood extent. © 2019 ISIF-International Society of Information Fusion.","Decision making; Disaster prevention; Disasters; Extraction; Extreme weather; Floods; Geometrical optics; Image analysis; Image fusion; Information fusion; Probabilistic logics; Satellites; Space-based radar; Synthetic aperture radar; Textures; Trees (mathematics); Dempster-Shafer fusion; Dempster-Shafer theory; Extreme weather conditions; Multi scale analysis; Multiscale image analysis; Multispectral images; Multispectral satellite image; Synthetic aperture radar (SAR) images; Radar imaging","Dempster-Shafer fusion; flood extent extraction; multiscale image analysis; multispectral satellite images; SAR","Conference paper","Final","","Scopus","2-s2.0-85081788259"
"Shanthini C.; Anitha J.","Shanthini, C. (57191608237); Anitha, J. (57204786853)","57191608237; 57204786853","Satellite image registration using hybrid salient region detection method","2016","Proceedings of IEEE International Conference on Circuit, Power and Computing Technologies, ICCPCT 2016","","","7530356","","","","10.1109/ICCPCT.2016.7530356","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992121775&doi=10.1109%2fICCPCT.2016.7530356&partnerID=40&md5=cfe484a679568c747d815b207b6671d0","In remote sensing multisensor image fusion or registration is the process of combining relevant information from two or more images into a single image. The resulting image will be more informative than any of the input images. In order to transform the remote sensing images to retrieve more information, this paper proposes a hybrid method that consists of image segmentation, salient region detection and image fusion. First of all, the paper presents the superpixel segmentation method in order to divide the image into subareas and for the feature extraction we implemented the difference of Gaussian and local binary pattern from the salient regions. This proposed method is tested on remote sensing images. Software results shows that the method is fast and gives less error compared to other existing methods. © 2016 IEEE.","Binary images; Bins; Computer circuits; Feature extraction; Image fusion; Image processing; Image reconstruction; Reconfigurable hardware; Remote sensing; Hybrid method; Local binary patterns; Multisensor image fusion; Remote sensing images; Salient region detections; Salient regions; Single images; Superpixel segmentations; Image segmentation","Image segmentation; Local binary pattern; Remote sensing images; Salient region detection","Conference paper","Final","","Scopus","2-s2.0-84992121775"
"Myna A.N.","Myna, A.N. (23985617900)","23985617900","Image Registration and Fusion","2016","Mobile Intelligent Autonomous Systems","","","","53","82","29","10.1201/b12690-4","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137428804&doi=10.1201%2fb12690-4&partnerID=40&md5=1784fd3e8259b1ca2534ef3a01b7ea82","Image registration and image fusion processes are important operations in remote sensing applications, robotics, target tracking/identification and medical imaging. The aim of registration is to geometrically align the two images-the source and the target images. Image registration is usually followed by generation of large panoramic images for viewing and analysis. The aim of satellite image registration is to align the satellite images obtained at different points of time so that changes such as movement of clouds, growth of vegetation and so on can be detected. The increased volume of satellite images has reinforced the need for automatic image registration methods. Image fusion of multisource images will have effects of denoising, resolution improvement, definition improvement and compensation for loss or failure from one sensor. The most important issue concerning image fusion is to determine how to combine the different sensor images. © 2013 by Taylor and Francis Group, LLC.","","","Book chapter","Final","","Scopus","2-s2.0-85137428804"
"Tian Y.-X.; Wu J.-L.; Tian X.-L.","Tian, Yun-Xiang (57008525200); Wu, Jiang-Long (35101055400); Tian, Xiao-Lin (7202380154)","57008525200; 35101055400; 7202380154","Satellite image fusion using RPCA combined IHS transform","2015","Guangxue Jingmi Gongcheng/Optics and Precision Engineering","23","","","504","508","4","10.3788/OPE.20152313.0504","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950325968&doi=10.3788%2fOPE.20152313.0504&partnerID=40&md5=6db4ba9a96ec6b514849d731ba7cd468","The traditional Principal Component Analysis (PCA) and IHS satellite image fusion technology may have spectral losing and feature detail distortion. A fusion method using Robust PCA (RPCA) combined with IHS transform was proposed to solve the problem. First, multi-spectral images were converted from a RGB model into an IHS model. The 'I' component of IHS was converted into low-rank matrix L0 and sparse matrix S0 by RPCA transform. Then, the histogram of panchromatic images was matched with the histogram of the L0 component, and the L0 component was replaced by the panchromatic image. Finally, the fused multi-spectral image was converted back to the RGB space. Testing results show that of the information entropies preserved by RPCA combined IHS method are 7.5275 and 7.4772, which means that the method proposed in the paper gives better results than conventional methods, such as PCA and IHS transform. © 2015, Chinese Academy of Sciences. All right reserved.","Graphic methods; Image analysis; Image fusion; Satellites; Spectroscopy; Conventional methods; IHS transforms; Information entropy; Low-rank matrices; Multispectral images; Panchromatic images; Principal component analysis transforms; Satellite images; Principal component analysis","IHS transform; Image fusion; PCA transform; Principal Component Analysis (PCA) transform; Satellite image","Article","Final","","Scopus","2-s2.0-84950325968"
"Hou L.; Zhang X.","Hou, Likun (55815478400); Zhang, Xiaoqun (13410919700)","55815478400; 13410919700","Pansharpening Image Fusion Using Cross-Channel Correlation: A Framelet-Based Approach","2016","Journal of Mathematical Imaging and Vision","55","1","","36","49","13","10.1007/s10851-015-0612-x","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960795545&doi=10.1007%2fs10851-015-0612-x&partnerID=40&md5=aaf8b90dc6f0207eb028f6879a8689e3","This paper aims at developing a variational model for pansharpening image fusion. To resolve the ill-posedness of image fusion, we propose a new regularization technique that explores the cross-channel correlation of different spectral channels in wavelet tight frame (or framelet) domain. Besides using a regular cross-channel sparsity prior (Inverse Probl Imaging 7(3):777–794, 2013), the proposed model also makes efficient use of the panchromatic image as a guidance for image feature alignment. An ADMM-based iterative scheme is derived for solving the proposed model, and its performance is tested on several datasets including natural images, aerial images, and real multispectral satellite images. Numerical results suggest that the proposed approach works well on the testing datasets and outperforms some state-of-the-art algorithms in comparison. © 2015, Springer Science+Business Media New York.","Iterative methods; ADMM; Channel correlation; Multi-spectral; Pan-sharpening; Wavelet frame; Image fusion","ADMM; Cross-channel correlation; Multispectral; Pansharpening image fusion; Wavelet frames","Article","Final","","Scopus","2-s2.0-84960795545"
"Talal T.M.; Attiya G.; Metwalli M.R.; Abd El-Samie F.E.; Dessouky M.I.","Talal, Tamer M. (15766387800); Attiya, Gamal (56001046200); Metwalli, Mohamed R. (35776990600); Abd El-Samie, Fathi E. (12785222000); Dessouky, M.I. (7005350912)","15766387800; 56001046200; 35776990600; 12785222000; 7005350912","Two Efficient Hybrid Methods for Enhancing Pan-Sharpening of Multi-spectral Images Transmitted from Satellite to Ground Stations","2019","Journal of the Indian Society of Remote Sensing","47","7","","1245","1255","10","10.1007/s12524-019-00970-2","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065256945&doi=10.1007%2fs12524-019-00970-2&partnerID=40&md5=e6850452f0e37b4ddbf26df397c446ff","Pan-sharpening is one of the most important tasks performed on satellite images as it enhances spectral and spatial information of the images. Empirical mode decomposition (EMD) is one of the powerful methods for pan-sharpening. It first decomposes the image into a set of intrinsic mode functions and a residual component. These panchromatic and multi-spectral components are then fused to create an enhanced pan-sharpened image. This paper presents two efficient hybrid methods to enhance pan-sharpening of multi-spectral images. The new proposals combine the EMD with the two pan-sharpening methods: high-pass filtering and discrete wavelet transform to maximize the pan-sharpened image quality. The two methods are evaluated using satellite images of Cairo and Suez Canal region, Egypt, captured by Spot-4 and Landsat-8 satellites, respectively. The results imply that the proposed hybrid methods provide better qualitative and quantitative results compared to the individual and the common pan-sharpening methods. © 2019, Indian Society of Remote Sensing.","Egypt; Suez Canal; decomposition analysis; image analysis; multispectral image; numerical method; satellite imagery; SPOT; wavelet analysis","DWT; EMD; HPF; Image fusion; Landsat-8; Pan-sharpening; Spot-4","Article","Final","","Scopus","2-s2.0-85065256945"
"Ulabhaje K.S.; Arya M.S.","Ulabhaje, Kalyani S. (57211137662); Arya, Meenakshi S. (57189231080)","57211137662; 57189231080","A proposed methodology for the fusion of microwave and optical remote sensing data","2019","Proceedings of the 3rd International Conference on Computing Methodologies and Communication, ICCMC 2019","","","8819731","731","736","5","10.1109/ICCMC.2019.8819731","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072758690&doi=10.1109%2fICCMC.2019.8819731&partnerID=40&md5=3c1e573cef246fc54b53f50d5bc3cbb1","The merging of images obtained by satellites through remote sensing has evolved into an established protocol. In popular parlance such blending is known as image fusion. This is done chiefly because it gives myriad advantages. Image fusion comes in extremely useful in the observation, study and analysis of diverse fields, including environment, agriculture and other related areas. In essence, what happens in image fusion is that the needed data or information is gleaned from numerous images. These images then are coalesced to form fewer pictures. The ideal, of course, is the blending of them into a lone picture. This is highly sought-after because the image thus intermingledis said to contain all relevant data and, moreover, is more suitable and error-free than an image secured from one single source. Needless to say, it also incorporates all the information that is needed. Besides this, there are other benefits. For one, it curtails the volume of data. For another, it produces images that are pertinent and apt. This paper's chief objective is to proffer a suggested methodolog y on the fusion between the capabilities of optical and microwave satellite images and to improve the visible quality of Landsat image. © 2019 IEEE","Image enhancement; Image processing; Image quality; Optical data processing; Remote sensing; Satellites; Wavelet transforms; Estimated parameter; LANDSAT; PSNR; Satellite images; Sentinel; Image fusion","Estimated Parameters; Image Fusion; Image Processing; Landsat; PSNR; Quality; Remote Sensing; Satellite Images; Sentinel; Wavelet Transforms","Conference paper","Final","","Scopus","2-s2.0-85072758690"
"Radhika K.S.R.; Rao C.V.; Kamakshi Prasad V.","Radhika, K.S.R. (57210658243); Rao, C.V. (15840393400); Kamakshi Prasad, V. (6507684291)","57210658243; 15840393400; 6507684291","Improving the spatial resolution of AWiFS sensor data using LISS III and AWiFS datapair with contourlet transform learning","2018","Advances in Intelligent Systems and Computing","712","","","105","119","14","10.1007/978-981-10-8228-3_11","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051144706&doi=10.1007%2f978-981-10-8228-3_11&partnerID=40&md5=c7182caa4d72cee72e13b079a3492238","Acquiring satellite images having high spectral, spatial, temporal, and radiometric resolutions simultaneously is very difficult. In this work, data from two sensors, viz., LISS III and AWiFS (DataPair) of Resourcesat-1 satellite (ISRO), are fusioned for improving the spatial resolution of AWiFS data. Best temporal resolution available from Resourcesat-1 is at 5-day repetivity by AWiFS. Using high spatial temporal resolution images, more information can be extracted from the images. Non-subsampled contourlet transform (NSCT) is used for the fusion of LISS III and AWiFS data. Through this fusion, even fine details can be extracted from the surface of the earth. Fusion of one or more images can be used, to determine the information content more accurately in our unambiguous manner. Image fusion process deals with two images with different characteristics and combines the merits of both. Here, an image with high spatial resolution (HSR) is used for a corresponding low spatial resolution (LSR) image. The quality of the output data are checked with the quality of the original image. The results of the desired high-resolution image through this current method are found to be satisfactory. © 2018, Springer Nature Singapore Pte Ltd.","Artificial intelligence; Image enhancement; Image resolution; Satellite imagery; AWiFS data; High resolution image; High spatial resolution; LISS-III; Non subsampled contourlet transform (NSCT); NSCT; Quality assessment; Radiometric resolution; Image fusion","AWiFS data; HSR quality assessment; LISS III data; LSR; NSCT","Conference paper","Final","","Scopus","2-s2.0-85051144706"
"Li Q.; Ding F.; Wu W.; Chen J.","Li, Qinsheng (57191224597); Ding, Feng (34970994600); Wu, Wenfeng (56428171900); Chen, Jieyu (57191225179)","57191224597; 34970994600; 56428171900; 57191225179","Improvement of ESTARFM and its application to fusion of Landsat-8 and MODIS Land Surface Temperature images","2016","4th International Workshop on Earth Observation and Remote Sensing Applications, EORSA 2016 - Proceedings","","","7552761","33","37","4","10.1109/EORSA.2016.7552761","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988025239&doi=10.1109%2fEORSA.2016.7552761&partnerID=40&md5=8f15e9e96f71f30c5baf77e569b6fab4","Land Surface Temperature (LST) is an important parameter to study the earth's surface thermal environment and the exchange process of matter and energy of earth's various systems, etc. In many studies, thermal infrared (TIR) images with both high spatial and frequent coverage were highly required to obtain LSTs. However, at current stage, there is no such kind of satellite sensor can completely meet the requirements. If a satellite sensor has high spatial resolution, then its temporal resolution is low, and vice versa. Therefore, in recent years, in order to enhance the spatial resolution and time coverage of the satellite images simultaneously, a variety of spatial and temporal fusion models or algorithms have been proposed. In this paper, we using the Enhanced Spatial and Temporal Adaptive Reflectance Fusion Model (ESTARFM), proposed by Zhu et al. (2010), taking Yanping District, Nanping City, Fujian Province, China as the study area, the original ESTARFM was improved by taking the following measures: considering the characteristics of the thermal images of the study area, we only used the Landsat and MODIS TIR radiance images to select the thermal similar neighbor pixels, calculate the conversion coefficients and the spectral, temporal weights. The improved ESTARFM was implemented by IDL (Interactive Data Language) programming, using three pairs of Landsat-8 and MODIS images acquired on December 1st, 2013, January 2nd, 2014 and February 3rd, 2014, respectively. The resultant fusion image was assessed and was applied to retrieve LST by using the newly revised Generalized Single-channel Method proposed by Jiménez-Muñoz and Sobrino et al. (2014), after that, the predicted LST was compared with the actually observed LST which retrieved from the actually observed Landsat-8 image not only from the qualitative but also from the quantitative perspectives. The research results showed that, by using the Landsat-8 and MYD11A1 LST images with the improved ESTARFM proposed by this study, strong agreements between the actual and synthetic LST images were achieved, thus the temporal coverage of the Landsat-8 LST data over the study area was successfully increased. © 2016 IEEE.","Atmospheric temperature; Data fusion; Image resolution; Observatories; Radiometers; Remote sensing; Satellite imagery; Satellites; Surface measurement; Surface properties; improved ESTARFM; Land surface temperature; LANDSAT; MODIS; Temporal Data; Image fusion","improved ESTARFM; land surface temperature; Landsat-8; MODIS; spatial and temporal data fusion","Conference paper","Final","","Scopus","2-s2.0-84988025239"
"Miao Z.; Shi W.; Samat A.; Lisini G.; Gamba P.","Miao, Zelang (55388064200); Shi, Wenzhong (7402664815); Samat, Alim (7005626086); Lisini, Gianni (6602456693); Gamba, Paolo (7007165803)","55388064200; 7402664815; 7005626086; 6602456693; 7007165803","Information Fusion for Urban Road Extraction From VHR Optical Satellite Images","2016","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","9","5","7337372","1817","1829","12","10.1109/JSTARS.2015.2498663","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949883440&doi=10.1109%2fJSTARS.2015.2498663&partnerID=40&md5=fff264df80029e9218bd35f1b0a98b1b","This paper presents a novel method exploiting fusion at the information level for urban road extraction from very high resolution (VHR) optical satellite images. Given a satellite image, we explore spectral and shape features computed at the pixel level, and use them to select road segments using two different methods (i.e., expectation maximization clustering and linearness filtering). A road centerline extraction method, which is relying on the outlier robust regression, is subsequently applied to extract accurate centerlines from road segments. After that, three different sets of information fusion rules are applied to jointly exploit results from these methods, which offer ways to address their own limitations. Two VHR optical satellite images are used to validate the proposed method. Quantitative results prove that information fusion following centerline extraction by multiple techniques is able to produce the best accuracy values for automatic urban road extraction from VHR optical satellite images. © 2008-2012 IEEE.","Extraction; Feature extraction; Image fusion; Information fusion; Maximum principle; Roads and streets; Satellites; Transportation; Centerline extraction; Expectation - maximizations; Information levels; Optical satellite images; Quantitative result; Robust regressions; Satellite images; Very high resolution; Image processing","Centerline; expectation maximization (EM); information fusion; linearness filter; RANdom SAmple Consensus (RANSAC)","Article","Final","","Scopus","2-s2.0-84949883440"
"Kwan C.; Ayhan B.; Budavari B.","Kwan, C. (7201421216); Ayhan, B. (14037070200); Budavari, B. (57191360081)","7201421216; 14037070200; 57191360081","Fusion of themis and TES for accurate Mars surface characterization","2017","International Geoscience and Remote Sensing Symposium (IGARSS)","2017-July","","8127723","3381","3384","3","10.1109/IGARSS.2017.8127723","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032155324&doi=10.1109%2fIGARSS.2017.8127723&partnerID=40&md5=9458d10443e8ecf588924ca0fae26e19","This paper presents a novel approach to fusing Thermal Emission Imaging System (THEMIS) and Thermal Emission Spectrometer (TES) satellite images, aiming to improve Mars surface characterization performance from orbit. Our approach includes proven registration and advanced pansharpening algorithms developed by us and others. Preliminary experiments show that the fusion approach is highly promising despite the extremely high resolution difference of THEMIS and TES (30 to 1). We also observed some potential issues that require further research. © 2017 IEEE.","","image fusion; pansharpening; registration; TES; THEMIS","Conference paper","Final","","Scopus","2-s2.0-85032155324"
"Saxena N.; Sharma K.K.","Saxena, Nidhi (56516227500); Sharma, Kamalesh K. (55645022100)","56516227500; 55645022100","Pansharpening scheme using filtering in twodimensional discrete fractional Fourier transform","2018","IET Image Processing","12","6","","1013","1019","6","10.1049/iet-ipr.2017.0961","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047248931&doi=10.1049%2fiet-ipr.2017.0961&partnerID=40&md5=3c9204fe2715a95d6ca9a2b3fdf1972f","The aim of the pansharpening scheme is to improve the spatial information of multispectral images using the panchromatic (PAN) image. In this study, a novel pansharpening scheme based on two-dimensional discrete fractional Fourier transform (2D-DFRFT) is proposed. In the proposed scheme, PAN and intensity images are transformed using 2D-DFRFT and filtered by highpass filters, respectively. The filtered images are inverse transformed and further used to generate the pansharpened image using appropriate fusion rule. The additional degree of freedom in terms of its angle parameters associated with the 2D-DFRFT is exploited for obtaining better results in the proposed pansharpening scheme. Simulation results of the proposed technique carried out in MATLAB are presented for IKONOS and GeoEye-1 satellite images and compared with existing fusion methods in terms of both visual observation and quality metrics. It is seen that the proposed pansharpening scheme has improved spectral and spatial resolution as compared to the existing schemes. © The Institution of Engineering and Technology 2018.","Degrees of freedom (mechanics); High pass filters; Image fusion; Inverse problems; MATLAB; Degree of freedom; Discrete fractional Fourier transforms; Multispectral images; Panchromatic (Pan) image; Pansharpened images; Spatial informations; Spatial resolution; Visual observations; Image enhancement","","Article","Final","","Scopus","2-s2.0-85047248931"
"Carcellar B.G.; Lisniana D.M.","Carcellar, Bienvenido G. (57190385551); Lisniana, Diona Mae (57194032748)","57190385551; 57194032748","Automation of multiple image fusion algorithms and assessment of fused products using statistical methods","2016","37th Asian Conference on Remote Sensing, ACRS 2016","3","","","2024","2031","7","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018417062&partnerID=40&md5=be0f90df3710ea791d14f6ca1bd552f6","The continuous technological advancement in the field of remote sensing due to the numerous satellites emerging bring us variety in data. Satellite images have different characteristics in terms of temporal, spatial, radiometric and spectral resolutions. To integrate numerous sources of satellite images, the technique called image fusion is soon done to different satellite images. Image fusion or pansharpening is the process of creating a new image which is a combination of information from two source images - one that has a high resolution and another which will be the source of spectral characteristics. There are numerous algorithms to fuse a panchromatic image with its multispectral counterpart. With the increase in the developments of pansharpening algorithms, it is a need now to determine which technique is most suitable for the intended application. The main objective of this research is to automate five existing pansharpening techniques, namely: IHS, Wavelet, IHS-Wavelet, RVS, and Ehlers. After automating these fusion algorithms, the researchers also automated different spectral and spatial statistical tests to release the quality metrics of the produced pansharpened image. For comparing the different fusion methods, we employ different statistical tests to quantify both the spatial and the spectral quality of the fused images. For spectral quality metrics, we compare spectral characteristics of images obtained from the different pansharpening methods with the spectral characteristics of the original multispectral images. While in spatial quality metrics, we are comparing the pansharpened image with the panchromatic band specifically the spatial characteristics. In measuring the spectral quality, we used three indices to measure their quality, namely: Deviation Index, Correlation Coefficient, and Signal to Noise Ratio. For measuring the spatial quality of the images, the only metric used is the high pass deviation index (HPDI).","Remote sensing; Satellites; Signal to noise ratio; Statistical tests; Correlation coefficient; LANDSAT; Multispectral images; Pan-sharpening; Python; Spatial characteristics; Spectral characteristics; Technological advancement; Image fusion","Landsat; Pansharpening; Python; Remote sensing","Conference paper","Final","","Scopus","2-s2.0-85018417062"
"Patel M.I.; Thakar V.K.","Patel, Manish I. (57188760171); Thakar, Vishvjit K. (8418004000)","57188760171; 8418004000","Application of radon transform for fast image registration","2015","ICACCS 2015 - Proceedings of the 2nd International Conference on Advanced Computing and Communication Systems","","","7324141","","","","10.1109/ICACCS.2015.7324141","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962920536&doi=10.1109%2fICACCS.2015.7324141&partnerID=40&md5=032172e655f4e5da433ebb3b8c5f6570","One of the important steps in image fusion is image registration. The process of determining the spatial transformation that maps the points in the target image to the points in the source image is known as image registration. Various image registration approaches can be classified as area, feature and transform domain based. Choice of approach depends on image contents and application. Area based approach requires more computation time, specially for large images such as satellite images, while feature based approach may not be accurate if significant features are not available in the images. In this paper authors have used the rotation and translation invariant properties of radon transform to find the amount of rotation and translation required to perform registration, i.e.To align the images. Simulation results are shown for different images, with different amount of rotation and translations, to show the accuracy and reliability of the method. Again noise level is also varied, to observe the robustness of the method to noise. The required average computation time is in seconds, depending on the size of images. © 2015 IEEE.","Image fusion; Mathematical transformations; Fast image registration; Feature based approaches; Radon Transform; rotational property; Satellite images; Spatial transformation; Translation invariant properties; translational property; Image registration","image registration; radon transform; rotational property; translational property","Conference paper","Final","","Scopus","2-s2.0-84962920536"
"Prabhakara Rao T.; Rama Rao B.","Prabhakara Rao, T. (57210578360); Rama Rao, B. (7403489734)","57210578360; 7403489734","A methodical block based feature level image fusion technique with wavelet transform using neural network for satellite images","2019","International Journal of Engineering and Advanced Technology","8","6 Special Issue","","465","474","9","10.35940/ijeat.F1097.0886S19","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073340778&doi=10.35940%2fijeat.F1097.0886S19&partnerID=40&md5=cbc1cd3d3dc01b54bc4b6ddcf3ed0c63","This paper describe about the feature extraction or detection machine learning application which one is wavelet transform integrated with neural network. It has obtained an effective block based feature level with wavelet transform using neural network (BFWN) model for image fusion. In the projected BFWN model, the discrete wavelet transform (DWT) and neural network (NN) are considered for fusing IRS-1D images using LISS-III scanner about the location different areas in India. Also Quick Bird image data and Landsat 7 image data are used to carry out on the proposed BFWN method. The characteristics like contrast visibility, energy of gradient, spatial frequency, variance and edge information are under study. A Feed forward back propagation neural network is trained and tested for categorization since the learning capability of neural network makes it feasible to customize the image fusion process. The trained neural network is used to fuse the two source images. The proposed BFWN model is distinguish, with DWT alone to assess the quality of the fused image. The results obviously show that the proposed BFWN model is a capable and feasible algorithm for image fusion. © BEIESP.","","Block Based Features; Discrete Wavelet Transform; DWT; Image Fusion; Neural Network; Neural Network; Performance Measures","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85073340778"
"Li Y.; Liu C.; Yan L.; Li J.; Plaza A.; Li B.","Li, Yunfei (57218424664); Liu, Chenying (57192703264); Yan, Lin (56895452500); Li, Jun (57216664202); Plaza, Antonio (7006613644); Li, Bo (56092633500)","57218424664; 57192703264; 56895452500; 57216664202; 7006613644; 56092633500","A New Spatio-Temporal Fusion Method for Remotely Sensed Data Based on Convolutional Neural Networks","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898524","835","838","3","10.1109/IGARSS.2019.8898524","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077717429&doi=10.1109%2fIGARSS.2019.8898524&partnerID=40&md5=60021a14a16c663f2fe4465e8851fa1e","In some remote sensing applications such as change detection, satellite images with both high spatial and high temporal resolution are required. However, no single satellite sensor can currently provide such images due to technical specifications. To solve this problem, spatio-temporal fusion provides a cost-effective solution. In this paper, we propose a new spatio-temporal fusion approach, based on convolutional neural networks (CNNs), for Landsat and MODIS image fusion. Specifically, the proposed approach utilizes CNNs to model the heterogeneity of fine pixels from the coarse MODIS images. Here, the heterogeneity of fine pixels is defined as the difference between the reflectance changes obtained from the two types of images. After that, two transition-predicted images can be obtained using the trained CNNs, which are then fused in order to obtain a fi-nal prediction. In our newly proposed approach, CNNs are only used to learn the heterogeneity of fine pixels rather than the whole images, thus providing a more stable and less time-consuming strategy as compared to other available approaches. We evaluated the proposed approach on a public spatio-temporal fusion dataset and the obtained results suggest that our newly developed method achieves state-of-the-art performance. © 2019 IEEE.","Convolution; Cost effectiveness; Geology; Image fusion; Pixels; Radiometers; Remote sensing; Cost-effective solutions; heterogeneity; High temporal resolution; Remote sensing applications; Remotely sensed data; Spatio-temporal fusions; State-of-the-art performance; Technical specifications; Convolutional neural networks","convolutional neural networks (CNNs); heterogeneity; Spatio-temporal fusion","Conference paper","Final","","Scopus","2-s2.0-85077717429"
"Fung C.H.; Wong M.S.; Chan P.W.","Fung, Che Heng (57188670292); Wong, Man Sing (57210337677); Chan, P.W. (35756335100)","57188670292; 57210337677; 35756335100","Spatio-temporal data fusion for satellite images using hopfield neural network","2019","Remote Sensing","11","18","2077","","","","10.3390/rs11182077","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072647584&doi=10.3390%2frs11182077&partnerID=40&md5=9c21a1731ca28ad8feccd2045e04599f","Spatio-temporal data fusion refers to the technique of combining high temporal resolution from coarse satellite images and high spatial resolution from fine satellite images. However, data availability remains a major limitation in algorithm development. Existing spatio-temporal data fusion algorithms require at least one known image pair between the fine and coarse resolution image. However, data which come from two different satellite platforms do not necessarily have an overlap in their overpass times, hence restricting the application of spatio-temporal data fusion. In this paper, a new algorithm named Hopfield Neural Network SPatio-tempOral daTa fusion model (HNN-SPOT) is developed by utilizing the optimization concept in the Hopfield neural network (HNN) for spatio-temporal image fusion. The algorithm derives a synthesized fine resolution image from a coarse spatial resolution satellite image (similar to downscaling), with the use of one fine resolution image taken on an arbitrary date and one coarse image taken on a predicted date. The HNN-SPOT particularly addresses the problem when the fine resolution and coarse resolution images are acquired from different satellite overpass times over the same geographic extent. Both simulated datasets and real datasets over Hong Kong and Australia have been used in the evaluation of HNN-SPOT. Results showed that HNN-SPOT was comparable with an existing fusion algorithm, the spatial and temporal adaptive reflectance fusion model (STARFM). HNN-SPOT assumes consistent spatial structure for the target area between the date of data acquisition and the prediction date. Therefore, it is more applicable to geographical areas with little or no land cover change. It is shown that HNN-SPOT can produce accurate fusion results with > 90% of correlation coefficient over consistent land covers. For areas that have undergone land cover changes, HNN-SPOT can still produce a prediction about the outlines and the tone of the features, if they are large enough to be recorded in the coarse resolution image at the prediction date. HNN-SPOT provides a relatively new approach in spatio-temporal data fusion, and further improvements can be made by modifying or adding new goals and constraints in its HNN architecture. Owing to its lower demand for data prerequisites, HNN-SPOT is expected to increase the applicability of fine-scale applications in remote sensing, such as environmental modeling and monitoring. © 2019 by the authors.","Data acquisition; Forecasting; Hopfield neural networks; Image resolution; Overpasses; Remote sensing; Satellites; Algorithm development; Correlation coefficient; Fine-resolution images; High spatial resolution; High temporal resolution; Hopfield neural networks (HNN); Satellite images; Spatio-temporal data; Image fusion","Hopfield neural network; Satellite images; Spatio-temporal data fusion","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85072647584"
"Asokan A.; Anitha J.","Asokan, Anju (57190950323); Anitha, J. (57204786853)","57190950323; 57204786853","2D Discrete Cosine Transform for Fusion of Multitemporal Satellite Images","2019","Proceedings of the 2nd International Conference on Intelligent Computing and Control Systems, ICICCS 2018","","","8662832","5","10","5","10.1109/ICCONS.2018.8662832","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063774169&doi=10.1109%2fICCONS.2018.8662832&partnerID=40&md5=bb0f3b33558a94e066bf57f0d830bcd1","This paper analyses the quantitative performance metrics on applying image fusion method on satellite images and compares it with the fusion methods when applied to filtered images. The satellite images are obtained from over long distances and are immensely huge in size. During transmission, the satellite images get distorted by the presence of different noise components in the atmosphere. In this paper, satellite image fusion is done using Discrete Cosine Transform and compared with the image fusion after filtering operation on satellite images. The results are compared by calculating the Peak Signal-to-N oise Ratio, Mean Square Error and Entropy. From the results, it can be inferred that the image fusion on filtered images gives improved results in comparison to fusion on unfiltered images. © 2018 IEEE.","Control systems; Discrete cosine transforms; Image enhancement; Intelligent computing; Mean square error; Satellites; 2D discrete cosine transform; Change detection; Filtering operations; Image fusion methods; LANDSAT; Laplacians; Multi-temporal; Multi-temporal satellite images; Image fusion","change detection; image fusion; Landsat; Laplacian; Multitemporal","Conference paper","Final","","Scopus","2-s2.0-85063774169"
"Ho H.-C.; Huang C.-Y.","Ho, Hsuan-Chi (57194032518); Huang, Chih-Yuan (50261888100)","57194032518; 50261888100","Spatio-Temporal image fusion using landsat-8 and himawari-8 satellite imagery","2016","37th Asian Conference on Remote Sensing, ACRS 2016","3","","","2237","2242","5","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018388341&partnerID=40&md5=668d6b6595f2a2affa283184c33a71c6","Satellite remote sensing images provide periodical and multispectral information about the ground surface, which empowers various monitoring applications. Among the applications, some of them requires high spatial and temporal resolution, including disaster management, crop phenology monitoring, land cover change detection, etc. In order to provide high spatial and temporal information, image fusion techniques were proposed to integrate high-spatial-resolution satellite imagery with high-Temporal-resolution imagery, such as the spatial and temporal adaptive reflectance fusion model (STARFM). Previous studies applied the STARFM method on Landsat and Moderate-resolution Imaging Spectroradiometer (MODIS) satellite images to provide high spatial and high temporal images. With the advance of satellite technology, a new satellite, Himawari-8, has a 10-minute temporal resolution, which is much higher than that of MODIS, and its spatial resolution is similar to MODIS. This research tries to fuse the Landsat-8 and Himawari-8 images to provide images with high spatial resolution and very high temporal resolution. On the preprocessing step, we use affine transformation for geometric correction. Then we use the STARFM method to fuse Landsat-8 images with Himawari-8 images to produce 30-meter-spatial-resolution and 10-minute-Temporal-resolution images. Finally, in order to verify the result of this research, we apply the fused images to estimate aerosol optical depth (AOD) and compare with in-situ observations. Overall, this research uses Himawari- 8 and Landsat-8 image to produce images with high spatial and temporal resolutions. The fused images could provide timely information to assist various monitoring applications.","Adaptive optics; Atmospheric aerosols; Disaster prevention; Disasters; Image fusion; Image reconstruction; Image resolution; Information management; Mathematical transformations; Radiometers; Remote sensing; Satellites; High spatial resolution satellite imagery; High temporal resolution; Himawari-8; LANDSAT; Moderate resolution imaging spectroradiometer satellites; Satellite remote sensing; Spatial and temporal resolutions; STARFM; Satellite imagery","Himawari-8; Image fusion; Landsat-8; STARFM","Conference paper","Final","","Scopus","2-s2.0-85018388341"
"Bai B.; Tan Y.; Guo D.; Xu B.","Bai, Bingxin (57205687503); Tan, Yumin (14064055300); Guo, Dong (57225947007); Xu, Bo (55117475200)","57205687503; 14064055300; 57225947007; 55117475200","Dynamic monitoring of forest land in fuling district based on multi-source time series remote sensing images","2019","ISPRS International Journal of Geo-Information","8","1","36","","","","10.3390/ijgi8010036","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061140516&doi=10.3390%2fijgi8010036&partnerID=40&md5=8e42f7a3e0f3a1080eb0dafb3b5cce8f","Time series remote sensing images can be used to monitor the dynamic changes of forest lands. Due to consistent cloud cover and fog, a single sensor typically provides limited data for dynamic monitoring. This problem is solved by combining observations from multiple sensors to form a time series (a satellite image time series). In this paper, the pixel-based multi-source remote sensing image fusion (MulTiFuse) method is applied to combine the Landsat time series and Huanjing-1 A/B (HJ-1 A/B) data in the Fuling district of Chongqing, China. The fusion results are further corrected and improved with spatial features. Dynamic monitoring and analysis of the study area are subsequently performed on the improved time series data using the combination of Mann-Kendall trend detection method and Theil Sen Slope analysis. The monitoring results show that a majority of the forest land (60.08%) has experienced strong growth during the 1999-2013 period. Accuracy assessment indicates that the dynamic monitoring using the fused image time series produces results with relatively high accuracies. © 2019 by the authors.","","Dynamic monitoring; HJ-1 A/B; Image fusion; Landsat; Time series","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85061140516"
"Van Ha P.; Truong N.X.; Laffly D.; Jourdan A.; Nhat Thanh N.T.","Van Ha, Pham (15021177200); Truong, Ngo Xuan (57215356232); Laffly, Dominique (6507821975); Jourdan, Astrid (7006696305); Nhat Thanh, Nguyen Thi (57215355522)","15021177200; 57215356232; 6507821975; 7006696305; 57215355522","Evaluation of maximum likelihood estimation and regression methods for fusion of multiple satellite aerosol optical depth data over Vietnam","2019","Proceedings of 2019 11th International Conference on Knowledge and Systems Engineering, KSE 2019","","","8919417","","","","10.1109/KSE.2019.8919417","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077034213&doi=10.1109%2fKSE.2019.8919417&partnerID=40&md5=e2ed712410d328ce2bfe8f10aaa07aa7","This paper applied different data fusion methods including Maximum Likelihood Estimation (MLE) and Linear Regression methods on satellite images over Vietnam areas from Moderate Resolution Imaging Spectroradiometer (MODIS) and Visible Infrared Imaging Radiometer Suite (VIIRS) sensors. In comparison with ground station Aerosol Robotic Network (AERONET), the regression method is better than Maximum Likelihood Estimator (MLE). Our results show that the fusion methods can improve both data coverage and quality of satellite aerosol optical depth (AOD). Strong correlations were observed between fused AOD and AERONET AOD (R2 = 0.8118, 0.7511 for Terra regression and MLE method, respectively). This paper presented the evaluation of data fusion algorithm and highlighted its importance on the satellite AOD data coverage and quality methods from multiple sensors. © 2019 IEEE.","Aerosols; Data fusion; Image fusion; Optical properties; Quality control; Radiometers; Regression analysis; Satellites; Systems engineering; Thermography (imaging); Aerosol robotic networks; Linear regression methods; Maximum likelihood estimators (MLE); Moderate resolution imaging spectroradiometer; Regression; Satellite images; Viet Nam; Visible infrared imaging radiometer suites; Maximum likelihood estimation","Data fusion; Maximum Likelihood Estimation; Regression; Satellite images; Vietnam","Conference paper","Final","","Scopus","2-s2.0-85077034213"
"Sulochana S.; Vidhya R.; Mohanraj K.; Vijayasekaran D.","Sulochana, S. (55830733500); Vidhya, R. (37102966200); Mohanraj, K. (56825665600); Vijayasekaran, D. (57192719353)","55830733500; 37102966200; 56825665600; 57192719353","Effect of wavelet based image fusion techniques with principal component analysis (PCA) and singular value decomposition (SVD) in supervised classification","2017","Indian Journal of Geo-Marine Sciences","46","2","","338","348","10","","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015413610&partnerID=40&md5=e87f02abb60d34c1258ca7fd26a172d9","With more promotion in satellite image processing techniques and the accessibility of various resolution images, fusion is necessary to combine panchromatic and multispectral images for further applications. Recent researches show that wavelet based image fusion algorithms provide high spectral quality in the fused images, but less spatial information in fused images due to critical down sampling. To increase spatial and spectral resolution, we have implemented wavelet based image fusion algorithms along with singular value decomposition(SVD) and principal component analysis (PCA) and its influences on supervised classification. The quality of the fused images is evaluated by quantitative and qualitative measurements. Qualitative evaluation is confirmed by edge detection methods. Quantitative results proved in terms of with reference and no reference image quality metrics. Supervised classification is used to check whether the spectral distortion caused by wavelet based fusion methods and the classification accuracy is measured by Kappa index (K). Results shows wavelet based image fusion combined with Eigen value methods such as SVD and PCA improves the classification accuracy as compared to actual multispectral images. Best classification results are achieved by framelet transform with SVD based fusion. © 2017, National Institute of Science Communication and Information Resources (NISCAIR). All rights reserved.","algorithm; decomposition analysis; image classification; image processing; principal component analysis; support vector machine; transform; wavelet analysis","Discrete wavelet transform (DWT); Principal component analysis (PCA); Singular value decomposition (SVD); Support vector machine (SVM)","Article","Final","","Scopus","2-s2.0-85015413610"
"Ling C.; Ju H.; Liu H.; Zhang H.; Sun H.","Ling, Chengxing (35189160000); Ju, Hongbo (7102390649); Liu, Hua (55272664000); Zhang, Huaiqing (7409199128); Sun, Hua (55729314700)","35189160000; 7102390649; 55272664000; 7409199128; 55729314700","Comparison and evaluation of fusion methods used for GF-2 satellite image in coastal mangrove area","2018","Proceedings of SPIE - The International Society for Optical Engineering","10615","","1061531","","","","10.1117/12.2304499","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046476086&doi=10.1117%2f12.2304499&partnerID=40&md5=b8f6ad88d8236f3c4837e5bdf3e4a525","GF-2 satellite is the highest spatial resolution Remote Sensing Satellite of the development history of China's satellite. In this study, three traditional fusion methods including Brovey, Gram-Schmidt and Color Normalized (CN) were used to compare with the other new fusion method NNDiffuse, which used the qualitative assessment and quantitative fusion quality index, including information entropy, variance, mean gradient, deviation index, spectral correlation coefficient. Analysis results show that NNDiffuse method presented the optimum in qualitative and quantitative analysis. It had more effective for the follow up of remote sensing information extraction and forest, wetland resources monitoring applications. © 2018 SPIE.","Image processing; Remote sensing; Satellites; Coastal Mangrove; Evaluating indicators; NNDiffuse; Qualitative and quantitative analysis; Qualitative assessments; Remote sensing information; Remote sensing satellites; Spectral correlation; Image fusion","Coastal Mangrove; Evaluating Indicator; GF-2 Satellite; Image Fusion; NNDiffuse","Conference paper","Final","","Scopus","2-s2.0-85046476086"
"Liu J.; Ma Y.; Wu Y.; Chen F.","Liu, Jianbo (56055157000); Ma, Yong (57189519597); Wu, Yitian (56711467600); Chen, Fu (56172930500)","56055157000; 57189519597; 56711467600; 56172930500","Review of methods and applications of high spatiotemporal fusion of remote sensing data","2016","Yaogan Xuebao/Journal of Remote Sensing","20","5","","1038","1049","11","10.11834/jrs.20166218","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992345420&doi=10.11834%2fjrs.20166218&partnerID=40&md5=e38697fca9878b1d51ce28417719de16","Remote sensing images can provide important and abundant information about the Earth at a global or local scale. Thus, many applications often require remote sensing data with high acquisition frequency and high spatial resolution. However, meeting this requirement is a considerable challenge given satellite limitations. The spatiotemporal fusion method provides a feasible way to solve these ""spatialtemporal"" contradictions. In the last 10 years, spatiotemporal fusion has elicited wide interest in various applications because it integrates the superiority of multisource satellite data in fine spatial resolution or frequent temporal coverage and it can generate fused images with high spatial and temporal resolution. In this study, we reviewed the advantages and limitations of three types of method for spatiotemporal fusion, namely, transformation- based, reconstruction-based, and learning-based methods. First, the transformation-based method consistently filters and processes transformed data and then accesses high-spatiotemporal resolution data via inverse transform. It mainly focuses on the spatial and spectral information of multi-source satellite image enhancement or fusion. The spatial resolution of the results obtained with this method remains low, and the accuracy is relatively poor because the temporal change information is not used in this method. Second, the reconstruction-based method has elicited much attention since the proposal of a semi-physical fusion model and STARFM. This method integrates the information of temporal change, spatial change, and spectral change among multi-source satellite images acquired in different times and generates high-spatiotemporal resolution data by calculating the weight of different changes. This method provides an excellent fusion approach for spatiotemporal fusion because the results show high accuracy. However, the results would be poor when the type of land cover changes or the cover area is heterogeneous. Third, the learning-based method is based on the development of compressed sensing and sparse representation technology. This method represents a recent development that relies on learning the relationship and difference of multi-source satellite images by training samples and constructing an image dictionary. Although the learning-based method could obtain good results, the processing efficiency is lower than that of other methods, and it requires the training of sample selection. Recently, the result of spatiotemporal fusion has been used in various applications, especially in the reconstruction-based method. This method is mainly used in time series data analysis as well as in retrieval and regional data set generation. For time series data analysis and retrieval, many researchers have used the results in developing the missing images of time series, detecting phenology, inversing urban environment parameters, estimating gross primary production, evaluating biomass, calculating land surface temperature, and so on. Given that the covered area of a low spatial resolution is large and the spectrum continuity of spatiotemporal fusion results is high, these results could be applied to the generation of regional data sets. Although the spatiotemporal fusion method has seen considerable development, certain problems remain. The uncertainties are attributed to the complexity of land cover change, the errors of sensor calibration, and the data pretreatment process. The five potential aspects of the spatiotemporal fusion method that require further study are the consistency of data from different sensors, introduction of nonlinear mixed models, addition of prior knowledge, introduction of deep learning theory, and expansion into other satellites. © 2016, Science Press. All right reserved.","Atmospheric temperature; Data handling; Deep learning; Image enhancement; Image fusion; Image resolution; Information analysis; Inverse transforms; Metadata; Models; Remote sensing; Satellite imagery; Time series; Time series analysis; Gross primary production; Land surface temperature; Multisource data; Spatial and temporal resolutions; Spatial temporals; Spatio-temporal fusions; Spatio-temporal resolution; Time series data analysis; Inverse problems","High spatiotemporal fusion; Model; Multi-source data; Remote sensing; Spatial-temporal contradictions","Review","Final","","Scopus","2-s2.0-84992345420"
"Castagno J.; Atkins E.","Castagno, Jeremy (57203415935); Atkins, Ella (7102202806)","57203415935; 7102202806","Roof shape classification from LiDAR and satellite image data fusion using supervised learning","2018","Sensors (Switzerland)","18","11","3960","","","","10.3390/s18113960","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056694123&doi=10.3390%2fs18113960&partnerID=40&md5=763d67f358e96423e848d8797d595529","Geographic information systems (GIS) provide accurate maps of terrain, roads, waterways, and building footprints and heights. Aircraft, particularly small unmanned aircraft systems (UAS), can exploit this and additional information such as building roof structure to improve navigation accuracy and safely perform contingency landings particularly in urban regions. However, building roof structure is not fully provided in maps. This paper proposes a method to automatically label building roof shape from publicly available GIS data. Satellite imagery and airborne LiDAR data are processed and manually labeled to create a diverse annotated roof image dataset for small to large urban cities. Multiple convolutional neural network (CNN) architectures are trained and tested, with the best performing networks providing a condensed feature set for support vector machine and decision tree classifiers. Satellite image and LiDAR data fusion is shown to provide greater classification accuracy than using either data type alone. Model confidence thresholds are adjusted leading to significant increases in models precision. Networks trained from roof data in Witten, Germany and Manhattan (New York City) are evaluated on independent data from these cities and Ann Arbor, Michigan. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Accident prevention; Air navigation; Computer vision; Decision trees; Drones; Geographic information systems; Image classification; Image fusion; Information systems; Information use; Large dataset; Learning systems; Machine learning; Maps; Neural networks; Optical radar; Roof coverings; Satellite imagery; Small satellites; Support vector machines; Unmanned aerial vehicles (UAV); Airborne lidar data; Classification accuracy; Confidence threshold; Convolutional neural network; Decision tree classifiers; Satellite image datas; Small unmanned aircrafts; Unmanned aircraft system; Classification (of information)","Drones; Geographical information system (GIS); LiDAR; Machine learning; Machine vision; Maps; Safety; Unmanned aircraft systems (UAS)","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85056694123"
"","","","3rd International Conference on Intelligent Computing and Applications, ICICA 2016","2018","Advances in Intelligent Systems and Computing","632","","","","","676","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040227903&partnerID=40&md5=203900dc6dbba04f313021097edcd158","The proceedings contain 59 papers. The special focus in this conference is on Intelligent Computing and Applications. The topics include: Parallel palm print identification using fractional coefficients of palm edge transformed images on GPU; a secure spatial domain image steganography using genetic algorithm and linear congruential generator; Three-dimensional MRI brain image analysis on hadoop platform; performance evaluation of fingerprint trait authentication system; graphical password using an intuitive approach; a model of legal and procedural framework for cybercrime investigation in India using digital image forensics; comparative study of android-based M-Apps for farmers; Feature extraction of DICOM images using canny edge detection algorithm; design of 2-bit parallel asynchronous self-timed adder and 2-bit parallel adder using radix adder; block compressive sampling and wiener curvelet denoising approach for satellite images; efficient image secret sharing using parallel processing for row-wise encoding and decoding; TXGR: A reverse engineering tool to convert design patterns and application software into graph; Comparative analysis of image fusion using DCT, DST, DWT, walsh transform and kekre’s wavelet transform; ioT-based smart garbage management system; Event-driven SOA-based IoT architecture; FPGA implementation of AES algorithm for image, audio, and video signal; power extraction from small hydropower plant; enhancement of digital distance protection scheme with novel transducer; A hierarchical underwater wireless sensor network design for tracking ships approaching harbors using an aerial mobile sink (AMS) node; development of single and multi-jet conical nozzle based open jet facility for cold jet simulation; Neural deployment algorithm for WSN: A concept; energy-aware multi-objective differential evolution in cloud computing.","","","Conference review","Final","","Scopus","2-s2.0-85040227903"
"Bharathidasan B.; Thirugnanam G.","Bharathidasan, B. (57210282750); Thirugnanam, G. (34267841300)","57210282750; 34267841300","Multiresolution Satellite Fusion Method for INSAT Images","2019","Communications in Computer and Information Science","1046","","","263","271","8","10.1007/978-981-13-9942-8_25","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070214677&doi=10.1007%2f978-981-13-9942-8_25&partnerID=40&md5=79586d5ae2932d27c0cccbe5c92db29a","Image fusion is the procedure in which two input images are fused so as to develop the image quality. The input images have to be the images of the comparable prospect with assorted superiority measures. The superiority of the output image will be superior to any of the input images. In this paper, satellite image fusion performance based on Wavelet Packet Transform (WPT) is proposed. Two level decomposition WPT is done on two images to obtain sub-images. The ensuing coefficients are fused by new fusion rule to acquire the fused image. The worth of this method has explained by different images such as the INSAT 3D, INSAT 3A, LANDSAT and PAN images. In this paper the proposed WPT based fusion technique is compared with Discrete Wavelet Transform (DWT) based image fusion. Simulation results accomplished that the proposed method performs finer for image fusion when compared with DWT. Image fusion methods made a comparison against DWT and WPT quality and quantity. Investigational output ended that the proposed WPT design carry out finer for image fusion in association with DWT. © 2019, Springer Nature Singapore Pte Ltd.","Discrete wavelet transforms; Image compression; Signal reconstruction; Wavelet analysis; Wavelet transforms; Fusion performance; Fusion techniques; Image fusion methods; INSAT images; Satellite images; Two-level decomposition; Wavelet Packet; Wavelet packet transform(WPT); Image fusion","Image fusion; INSAT images; Wavelet packet; Wavelet transform","Conference paper","Final","","Scopus","2-s2.0-85070214677"
"Xie S.; Zhao T.; Wang W.; Shi J.","Xie, Shiqin (57188721888); Zhao, Tianzhong (55453818600); Wang, Wei (57785246700); Shi, Jingjing (26637556600)","57188721888; 55453818600; 57785246700; 26637556600","Study on Fusion Algorithms of GF-2 Satellite Image; [高分二号卫星影像融合方法比较研究]","2017","Xitong Fangzhen Xuebao / Journal of System Simulation","29","11","","2742","2746and2752","27460010","10.16182/j.issn1004731x.joss.201711020","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055825828&doi=10.16182%2fj.issn1004731x.joss.201711020&partnerID=40&md5=c939fe5438407ec6996d9110de97e4c2","This paper compared 4 kinds of image fusion methods through the GF-2 panchromatic and multispectral data fusion test. The subjective qualitative evaluation and objective quantitative evaluation were applied to analyze the quality of the fusion images, which were classified by the maximum likelihood method to select the suitable fusion method for GF-2 image. Test results showed that, among the four fusion methods, Pansharp transform achieved better fusion effect. It had the best subjective and objective qualitative evaluation; It had the highest overall classification accuracy in the maximum likelihood classification test. The experiment results indicated that the Pansharp transform had better fusion effect than other fusion algorithms, and it was suitable for the application of GF-2 in forestry industry. The research aimed to provide reference for the application of image fusion in the forestry sector. © 2017, The Editorial Board of Journal of System Simulation. All right reserved.","","Evaluating indicator; GF-2 satellite image; Image classification; Image fusion; Image quality","Article","Final","","Scopus","2-s2.0-85055825828"
"HemaLatha M.; Varadarajan S.","HemaLatha, M. (57209518510); Varadarajan, S. (12140219400)","57209518510; 12140219400","Feature enhancement of multispectral images using vegetation, water, and soil indices image fusion","2019","Lecture Notes in Computational Vision and Biomechanics","30","","","329","337","8","10.1007/978-3-030-00665-5_34","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060204903&doi=10.1007%2f978-3-030-00665-5_34&partnerID=40&md5=36e9e718c477d92da528ebaafe8e8b39","Land cover characteristics of satellite images are analyzed in this research paper. Remote sensing indices are calculated for multispectral image. In the proposed method, satellite image indices, i.e., NDVI (Normalized difference vegetation index), NDWI (Normalized difference water index), and BSI (Bare soil index), are calculated for various classes such as land, vegetation, water, and in land cover categories. All these remote sensing indices are fused to get composite bands and to enhance all features in multispectral image. This technique increases visual perception of human eye for multispectral images. Fusion plays vital role in remote sensing and medical images interpretation. In case of remote sensing, we cannot get entire information in one spectral band. So multispectral bands are combined, which leads to feature enhancement. This method depends on green (G), infrared (IR), near infrared (NIR), and short wave infrared (SWIR) bands and their fusion. Finally, error matrix is generated with reference data and classified data. The main application is to calculate vegetation, bare soil, and water indices in three land covers and to get better feature enhancement. Producer’s accuracy, consumer’s accuracy, commission, omission, kappa coefficient, F1score, over all accuracy, and over all kappa coefficients are calculated. © Springer Nature Switzerland AG 2019.","","BSI; Error matrix; Land cover; NDVI; NDWI","Book chapter","Final","","Scopus","2-s2.0-85060204903"
"Snehmani; Gore A.; Ganju A.; Kumar S.; Srivastava P.K.; Hari Ram R.P.","Snehmani (55938288400); Gore, Akshay (56595501600); Ganju, Ashwagosh (57225430881); Kumar, Satish (57201873515); Srivastava, P.K. (57194335076); Hari Ram, R.P. (57056328900)","55938288400; 56595501600; 57225430881; 57201873515; 57194335076; 57056328900","A comparative analysis of pansharpening techniques on quickbird and WorldView-3 images","2017","Geocarto International","32","11","","1268","1284","16","10.1080/10106049.2016.1206627","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978701861&doi=10.1080%2f10106049.2016.1206627&partnerID=40&md5=9783e5624b13065709e78b0f30d521d5","Nowadays, different image pansharpening methods are available, which combine the strengths of different satellite images that have different spectral and spatial resolutions. These different image fusion methods, however, add spectral and spatial distortions to the resultant images depending on the required context. Therefore, a careful selection of the fusion method is required. Simultaneously, it is also essential that the fusion technique should be efficient to cope with the large data. In this paper, we investigated how different pansharpening algorithms perform, when applied to very high-resolution WorldView-3 and QuickBird satellite images effectively and efficiently. We compared these 27 pansharpening techniques in terms of quantitative analysis, visual inspection and computational complexity, which has not previously been formally tested. In addition, 12 different image quality metrics available in literature are used for quantitative analysis purpose. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","algorithm; comparative study; data quality; QuickBird; remote sensing; satellite imagery; spatial resolution; spectral analysis; WorldView","Fusion; Pansharpening; Remote sensing; WorldView-3","Article","Final","","Scopus","2-s2.0-84978701861"
"Subramanian P.; Leerar K.F.; Ahammed K.P.H.; Sarun K.; Mohammed Z.","Subramanian, P. (57200000221); Leerar, K.Faizal (57192871545); Ahammed, K.P.Hafiz (57192870748); Sarun, K. (57192871443); Mohammed, Ziyad (57225306312)","57200000221; 57192871545; 57192870748; 57192871443; 57225306312","Image registration methods","2016","International Journal of Chemical Sciences","14","","","825","828","3","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008457863&partnerID=40&md5=2723b23ce4ac1f56424c6063618f4080","Image registration, an important preprocess in image fusion, is the process of geometrically aligning two or more images. The image registration can be applied for fusion of medical images, satellite images or images obtained by different sensors at the same time or by same sensor at different times. Image registration involves selection of a control point, which can be done manually or automatically. Manual selection of control point, though simple, is time consuming and can be inaccurate. Automatic image registration does not involve human intervention and many algorithms are available in the literature. Though one algorithm cannot be applied to all applications, algorithms should not be very much application specific. In this paper we study different methods for image registration of different types of images.","","Automatic registration; Evalaution; Image registration","Article","Final","","Scopus","2-s2.0-85008457863"
"Ahlawat N.","Ahlawat, Neha (57210786913)","57210786913","Exploring fusion techniques for satellite image","2019","International Journal of Innovative Technology and Exploring Engineering","8","6 Special Issue 4","","1438","1444","6","10.35940/ijitee.F1293.0486S419","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071514381&doi=10.35940%2fijitee.F1293.0486S419&partnerID=40&md5=9dcb971a25e842483e652ba2159ef0f8","With the advance in multispectral imaging, the use of image fusion has become a new and important research area. A solitary caught picture of a certifiable scene is generally deficient to uncover every one of the points of interest due to under-or over-uncovered areas. Amid the most recent twenty years, numerous strategies, for example, Multiplicative Change, Brovey Transform, Principal Component Analysis (PCA), and IHS Transform have been grown great quality melded pictures. Inspite of the very great visual outcomes, numerous analysts have announced the restrictions of the above combination procedures. The most huge issue is twisting of shading,Another basic issue is that the combination quality frequently depend upon the administrator's combination encounter and upon the informational collection being melded. The goal of this paper is to examine different combination systems utilized for satellite pictures and dissect these methodologies intently for different situations. Likewise talk about the progressions which have been made while creating different combination methods their constraints and so forth. Combination methods on satellite pictures empower us to break down various sorts of information like climate estimate, Forest Area, Identify Roads for Maps, Water Bodies and so on altogether. © BEIESP.","","Ground Sample Distance(GSD); High Pass Filtering (HPF); Multispectral image(MS); Panchromatic image(PAN); SVR(Synthetic Variable Ratio","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85071514381"
"Zhang G.; Ghamisi P.; Zhu X.X.","Zhang, Guichen (57213144851); Ghamisi, Pedram (53663404300); Zhu, Xiao Xiang (55696622200)","57213144851; 53663404300; 55696622200","Fusion of Heterogeneous Earth Observation Data for the Classification of Local Climate Zones","2019","IEEE Transactions on Geoscience and Remote Sensing","57","10","8765334","7623","7642","19","10.1109/TGRS.2019.2914967","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067230834&doi=10.1109%2fTGRS.2019.2914967&partnerID=40&md5=227855ff54e9f1943fe0093c7f726fa3","This paper proposes a novel framework for fusing multi-temporal, multispectral satellite images and OpenStreetMap (OSM) data for the classification of local climate zones (LCZs). Feature stacking is the most commonly used method of data fusion but does not consider the heterogeneity of multimodal optical images and OSM data, which becomes its main drawback. The proposed framework processes two data sources separately and then combines them at the model level through two fusion models (the landuse fusion model and building fusion model) that aim to fuse optical images with landuse and buildings layers of OSM data, respectively. In addition, a new approach to detecting building incompleteness of OSM data is proposed. The proposed framework was trained and tested using the data from the 2017 IEEE GRSS Data Fusion Contest and further validated on one additional test (AT) set containing test samples that are manually labeled in Munich and New York. The experimental results have indicated that compared with the feature stacking-based baseline framework, the proposed framework is effective in fusing optical images with OSM data for the classification of LCZs with high generalization capability on a large scale. The classification accuracy of the proposed framework outperforms the baseline framework by more than 6% and 2% while testing on the test set of 2017 IEEE GRSS Data Fusion Contest and the AT set, respectively. In addition, the proposed framework is less sensitive to spectral diversities of optical satellite images and thus achieves more stable classification performance than the state-of-the-art frameworks. © 1980-2012 IEEE.","Bavaria; Germany; Munich; New York [United States]; United States; Computer software maintenance; Earth (planet); Geometrical optics; Image fusion; Satellites; Canonical correlations; Heterogeneous data; Local climate; OpenStreetMap (OSM); Satellite images; baseline survey; building; canonical analysis; correlation; EOS; heterogeneity; satellite imagery; software; Classification (of information)","Canonical correlation forest (CCF); heterogeneous data fusion; local climate zones (LCZs); OpenStreetMap (OSM); satellite images","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85067230834"
"Miura H.","Miura, Hiroyuki (36842132600)","36842132600","Fusion analysis of optical satellite images and digital elevation model for quantifying volume in debris flow disaster","2019","Remote Sensing","11","9","1096","","","","10.3390/rs11091096","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065720493&doi=10.3390%2frs11091096&partnerID=40&md5=b85dd2dd148118129234ca7570d272e6","Rapid identification of affected areas and volumes in a large-scale debris flow disaster is important for early-stage recovery and debris management planning. This study introduces a methodology for fusion analysis of optical satellite images and digital elevation model (DEM) for simplified quantification of volumes in a debris flow event. The LiDAR data, the pre- and post-event Sentinel-2 images and the pre-event DEM in Hiroshima, Japan affected by the debris flow disaster on July 2018 are analyzed in this study. Erosion depth by the debris flows is empirically modeled from the pre- and post-event LiDAR-derived DEMs. Erosion areas are detected from the change detection of the satellite images and the DEM-based debris flow propagation analysis by providing predefined sources. The volumes and their pattern are estimated from the detected erosion areas by multiplying the empirical erosion depth. The result of the volume estimations show good agreement with the LiDAR-derived volumes. © 2019 by the authors.","Debris; Digital instruments; Disasters; Erosion; Geomorphology; Image analysis; Image fusion; Optical radar; Satellites; Change detection; Debris flows; Debris-flow propagation; Erosion depth; Volume; Surveying","Change detection; Debris flow; Debris flow propagation analysis; Erosion depth; Volume","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85065720493"
"Zhang N.; Zhao J.; Zhang L.","Zhang, Ningyu (7401648122); Zhao, Junqing (36095200800); Zhang, Ling (54379325100)","7401648122; 36095200800; 54379325100","Comparison and evaluation on image fusion methods for GaoFen-1 imagery","2016","Proceedings of SPIE - The International Society for Optical Engineering","10157","","101571V","","","","10.1117/12.2246695","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010902648&doi=10.1117%2f12.2246695&partnerID=40&md5=adf611a73fc9c15946f51078df52e532","Currently, there are many research works focusing on the best fusion method suitable for satellite images of SPOT, QuickBird, Landsat and so on, but only a few of them discuss the application of GaoFen-1 satellite images. This paper proposes a novel idea by using four fusion methods, such as principal component analysis transform, Brovey transform, hue-saturation-value transform, and Gram-Schmidt transform, from the perspective of keeping the original image spectral information. The experimental results showed that the transformed images by the four fusion methods not only retain high spatial resolution on panchromatic band but also have the abundant spectral information. Through comparison and evaluation, the integration of Brovey transform is better, but the color fidelity is not the premium. The brightness and color distortion in hue saturation-value transformed image is the largest. Principal component analysis transform did a good job in color fidelity, but its clarity still need improvement. Gram-Schmidt transform works best in color fidelity, and the edge of the vegetation is the most obvious, the fused image sharpness is higher than that of principal component analysis. Brovey transform, is suitable for distinguishing the Gram-Schmidt transform, and the most appropriate for GaoFen-1 satellite image in vegetation and non-vegetation area. In brief, different fusion methods have different advantages in image quality and class extraction, and should be used according to the actual application information and image fusion algorithm. © 2016 SPIE.","Color; Data processing; Image analysis; Image processing; Infrared radiation; Principal component analysis; Satellite imagery; Satellites; Vegetation; GaoFen-1; Gram-Schmidt transform; High spatial resolution; Hue saturation values; Image fusion algorithms; Image fusion methods; Principal component analysis transforms; Spectral information; Image fusion","GaoFen-1; image fusion; information processing","Conference paper","Final","","Scopus","2-s2.0-85010902648"
"Toro-Garay G.H.; Medina-Daza R.J.","Toro-Garay, Giselle Helena (57199146070); Medina-Daza, Rubén Javier (57199150874)","57199146070; 57199150874","Fusion of WorldView2 images using Contourlet, Curvelet and Ridgelet transforms for edge enhancement","2017","Revista Facultad de Ingenieria","","85","","8","17","9","10.17533/udea.redin.n85a02","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037638989&doi=10.17533%2fudea.redin.n85a02&partnerID=40&md5=8445e20756f7906fcd04a69313bb96bd","This article discusses the implementation of three transforms, namely Contourlet, Curvelet and Ridgelet, which are intended for image edge enhancement. These transforms were applied to fused Worldview 2 satellite images. The fusion was performed over the WorldView 2 satellite images applying various types of wavelet transforms, such as Daubechies, Bior, rbior, Coiflet and Symlet 5, with different levels of decomposition. The best results were obtained for the case of Symlet 5, level 5. Wavelet fused images and the generated images (using Contourlet, Curvelet and transformed Ridgelet) were evaluated and analyzed quantitatively. Quantitative methods in the present analysis include ERGAS, RASE, Universal Quality (Qu) and correlation coefficient (CC). Image merging and the implementation of transforms were performed with MatLab®, which supplies the following tools: Wavelet toolbox, Image processing toolbox, Contourlet toolbox, and Curvelet and Ridgelet source code. The results show that the Curvelet and Ridgelet transforms yield better results in terms of edge enhancement for both the merged image and the original image.","","Contourlet; Curvelet; Image fusion; Ridgelet; Wavelet","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85037638989"
"Bergado J.R.; Persello C.; Stein A.","Bergado, John Ray (57192703116); Persello, Claudio (23493587700); Stein, Alfred (7401758587)","57192703116; 23493587700; 7401758587","FuseNet: End-to-end multispectral VHR image fusion and classification","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8519214","2091","2094","3","10.1109/IGARSS.2018.8519214","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064275120&doi=10.1109%2fIGARSS.2018.8519214&partnerID=40&md5=097fbbb92e1838340643ce3d3e60c81d","Classification of very high resolution (VHR) satellite images faces two major challenges: 1) inherent low intra-class and high inter-class spectral similarities and 2) mismatching resolution of available bands. Conventional methods have addressed these challenges by adopting separate stages of image fusion and spatial feature extraction steps. These steps, however, are not jointly optimizing the classification task at hand. We propose a single-stage framework embedding these processing stages in a multiresolution convolutional network. The network, called FuseNet, aims to match the resolution of the panchromatic and multispectral bands in a VHR image using convolutional layers with corresponding downsampling and upsampling operations. We compared FuseNet against the use of separate processing steps for image fusion, such as pansharpening and resampling through interpolation. We also analyzed the sensitivity of the classification performance of FuseNet to a selected number of its hyperparameters. Results show that FuseNet surpasses conventional methods. © 2018 IEEE.","Convolution; Deep learning; Geology; Image fusion; Remote sensing; Signal sampling; Classification performance; Classification tasks; Conventional methods; Convolutional networks; Land cover classification; Spectral similarity; Very high resolution; VHR images; Image classification","Convolutional networks; Deep learning; Image fusion; Land cover classification; VHR image","Conference paper","Final","","Scopus","2-s2.0-85064275120"
"Rupnik E.; Pierrot-Deseilligny M.; Delorme A.","Rupnik, Ewelina (55798823500); Pierrot-Deseilligny, Marc (23036301900); Delorme, Arthur (35319768200)","55798823500; 23036301900; 35319768200","3D reconstruction from multi-view VHR-satellite images in MicMac","2018","ISPRS Journal of Photogrammetry and Remote Sensing","139","","","201","211","10","10.1016/j.isprsjprs.2018.03.016","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044138675&doi=10.1016%2fj.isprsjprs.2018.03.016&partnerID=40&md5=936f69125a7315e0e2d9c7caca18cfa0","This work addresses the generation of high quality digital surface models by fusing multiple depths maps calculated with the dense image matching method. The algorithm is adapted to very high resolution multi-view satellite images, and the main contributions of this work are in the multi-view fusion. The algorithm is insensitive to outliers, takes into account the matching quality indicators, handles non-correlated zones (e.g. occlusions), and is solved with a multi-directional dynamic programming approach. No geometric constraints (e.g. surface planarity) or auxiliary data in form of ground control points are required for its operation. Prior to the fusion procedures, the RPC geolocation parameters of all images are improved in a bundle block adjustment routine. The performance of the algorithm is evaluated on two VHR (Very High Resolution)-satellite image datasets (Pléiades, WorldView-3) revealing its good performance in reconstructing non-textured areas, repetitive patterns, and surface discontinuities. © 2018 The Authors","Dynamic programming; Image enhancement; Image fusion; Image matching; Image processing; Rock mechanics; Satellite imagery; Satellites; Bundle block adjustments; Depth Map; Digital surface models; Geometric constraint; Ground control points; Multi-views; Surface discontinuities; Very high resolution; algorithm; data set; depth; digital terrain model; image processing; map; reconstruction; satellite imagery; satellite sensor; Image reconstruction","Bundle block adjustment; Dense image matching; Depth map fusion; Multi-view; VHR-satellite imagery","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85044138675"
"Biswas B.; Dey A.; Dey K.N.","Biswas, Biswajit (7103207978); Dey, Abhishek (56603703100); Dey, Kashi Nath (7005770173)","7103207978; 56603703100; 7005770173","Remote sensing image fusion using Hausdorff fractal dimension in shearlet domain","2015","2015 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2015","","","7275939","2180","2185","5","10.1109/ICACCI.2015.7275939","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946219040&doi=10.1109%2fICACCI.2015.7275939&partnerID=40&md5=d3a04f3b8cf23ba5f412228a900a3928","Preservation of spectral information and enhancement of spatial resolution is the most important issue in remote sensing image fusion. In this paper, a new remote sensing satellite image fusion method using shearlet transform (ST) with Hausdorff fractal dimension(HFD) estimation method is proposed. Firstly, ST is used in each high-spatial-resolution panchromatic (PAN) image and multi-spectral image (MS). Then, the low frequency sub-band coefficients from different images are combined according to the HFD method which estimates and selects the modified low-pass band automatically. The composition of different high-pass sub-band coefficients achieved by the ST decomposition is discussed in detail. Finally, we achieve fusion results from the inverse transformation of ST. Experimental results show that the proposed method outperforms many state-of-the-art techniques in both subjective and objective evaluation measures. © 2015 IEEE.","Fractal dimension; Image enhancement; Image resolution; Inverse problems; Remote sensing; Spectroscopy; Hausdorff; Mutual informations; Panchromatic (Pan) image; Remote sensing images; Remote sensing satellites; Shearlet transforms; State-of-the-art techniques; Subjective and objective evaluations; Image fusion","Hausdorff fractal dimension; mutual information; Remote sensing image fusion; Shearlet Transform","Conference paper","Final","","Scopus","2-s2.0-84946219040"
"Dwivedi A.K.; Kumar A.; Chaturvedi A.K.","Dwivedi, A.K. (35733635800); Kumar, Abhinav (37085915400); Chaturvedi, A.K. (7101745256)","35733635800; 37085915400; 7101745256","High resolution multispectral satellite data interpretation and limited ground checking: A proxy for geological mapping and uranium exploration in Mahakoshal Fold Belt of Son valley area, Madhya Pradesh","2016","Journal of the Geological Society of India","88","2","","159","172","13","10.1007/s12594-016-0475-9","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981275531&doi=10.1007%2fs12594-016-0475-9&partnerID=40&md5=5a73be2ac2bd00ae8fb5400e831fe82f","This research aims at integrating remote sensing data and field studies to prospect for uranium mineralisation in the Palaeoproterozoic Mahakoshal Group of rocks in the Son valley area, Central India. In present work, a revised geological map of Mahakoshal Fold Belt (MFB) bounded by Son-Narmada north fault (SNNF) and Son-Narmada south fault (SNSF) along Chorhut-Sidhi-Chitrangi sector falling in Sidhi, Rewa and Shahdol districts of Madhya Pradesh has been prepared based on interpretation of digitally enhanced satellite images. The satellite image interpretation is supported by limited field works, radioelemental measurements (eU, eTh and % K) of in-situ rocks by four channel Portable Gamma Ray Spectrometer (PGRS) and existing published geological maps of Geological Survey of India. In search for mineral potential areas, accurate and up-to-date geological maps are essential as it represent the most basic information for carrying out further exploration activities. However, available geological maps of MFB and sedimentary formations ofVindhayan Supergroup along SNNF and Chhotanagpur Granite Gneissic Complex (CGGC) and Gondwana Supergroup along SNSF available in public domain are discontinuous and multi-scaled. Optical bands of Landsat Enhanced Thematic Mapper Plus (ETM+) and Indian Remote Sensing (IRS) PAN of the study area were used in mapping lithological units, structural features and small intrusive bodies. Principal Component Analysis (PCA), Image Fusion, Linear Contrast Stretch, Histogram Equalisation and False Color Composite (FCC) of various band combination and ratio maps were performed in the digital image processing of geo-rectified satellite imageries. In analyzing and interpreting high resolution multi-spectral images, certain standard norms were employed to acquire information about litho-structural features such as topographic, geomorphic and tectonic facets. The main criteria are colour and tones, geomorphology, drainage patterns and vegetation anomalies. The processed Landsat ETM+ images were interpreted and classified to delineate detailed lithological units and structural features in order to update existing geological maps. To validate the prepared litho-structural map, ground survey was carried out along critical geological sections for checking the geological features like rocks, folds, faults, fractures and foliations. While comparing with the ground geological data to that obtained from the satellite imagery, it is observed that remote sensing interpreted litho-structural map is in a class with the ground observations. Various data sets such as unconformable geological contacts, fault breccias zone, lineaments and gamma ray spectrometric data (eU, eTh and % K) based on PGRS study were integrated and modelled using Geographical Information System (GIS) for identifying important prospective horizons for uranium mineralisation in the MFB of Son valley area. It is concluded that the revised large scale geological map is of practical use for not only for mapping of litho-structural architecture, but also in identifying potential areas for ‘vein–type’ uranium mineralisation along the structurally deformed zones of the SNNF, Asmi-Jiawan fault (AJF) and SNSF; and ‘unconformity- type’ of uranium mineralisation in the outliers of Jungel Group. The revised map and radiometric data acquired are useful in formulating exploration strategy for the ongoing uranium exploration in this area © 2016, Geological Society of India.","India; Madhya Pradesh; Mahakoshal; Son Valley; data interpretation; fold belt; geological mapping; GIS; mineral exploration; multispectral image; remote sensing; satellite data; uranium","GIS; Madhya Pradesh; Mahakoshal Fold Belt; Remote Sensing; Son Valley; Uranium Exploration","Article","Final","","Scopus","2-s2.0-84981275531"
"Hsu C.-B.; Lee J.-C.; Tu T.-M.","Hsu, Chih-Bin (54395466100); Lee, Jen-Chun (23397074400); Tu, Te-Ming (7005133164)","54395466100; 23397074400; 7005133164","Generalized IHS-BT framework for the pansharpening of high-resolution satellite imagery","2018","Journal of Applied Remote Sensing","12","4","046008","","","","10.1117/1.JRS.12.046008","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055516809&doi=10.1117%2f1.JRS.12.046008&partnerID=40&md5=43f2a4d96ad9fb19abb8e2cf01a04cda","Image fusion is an important technique for enhancing the spatial resolution of multispectral imagery by merging with a corresponding high-resolution panchromatic image. Many algorithms have been developed to obtain a better trade-off between spectral fidelity and spatial resolution enhancement. The recently developed techniques use sophisticated algorithms; however, three issues are often ignored. The first involves the progressively increasing amount of high-resolution satellite image data. Second, the designed method needs to be versatile to process a variety of complex terrain and surface features. The third is that the proposed method must satisfy the requirements of both visual inspection and classification. Based on the previous studies, this work proposes a generalized intensity-hue-saturation and Brovey transform framework (GF) to tackle these three problems. Eight modules are integrated into this GF: Four modules are designed for classification with a new intensity matching technique to improve the spectral quality; the other four modules are the spatial-enhancement version for visual inspection by adding more native spatial details. To verify the proposed technique, the experiments are conducted for QuickBird and WorldView-2 images. The results show that the GF modules can offer the maximal spatial information content while preserving good spectral information quality. © 2018 Society of Photo-Optical Instrumentation Engineers (SPIE).","Economic and social effects; Image fusion; Image resolution; Satellite imagery; Brovey transforms; High resolution satellite imagery; High resolution satellite images; Intensity hue saturations; Multi-spectral imagery; Pan-sharpening; Spatial informations; Spatial-resolution enhancement; Image enhancement","Brovey transform; image fusion; intensity-hue-saturation; pansharpening","Article","Final","","Scopus","2-s2.0-85055516809"
"Aswin Kumer S.V.; Srivatsa S.K.","Aswin Kumer, S.V. (57199650952); Srivatsa, S.K. (7003518102)","57199650952; 7003518102","An implementation of futuristic deep learning neural network in satellite images for hybrid image fusion","2019","International Journal of Recent Technology and Engineering","8","1","","484","487","3","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067860981&partnerID=40&md5=2752b55513485962d5d1e1e7e6c2e4fb","Image fusion is the process of registering two different images of same scene to combine the individual image quality details to single image. This work is going to reduce the complexities while implementing image fusion by applying the Deep Neural Network (DNN) to analyse the input images to get the resultant output image. At first, the DNN checks whether the input images are in same size by checking the dimensions of the input images. Then, the DNN checks the resolution of the input images and it resize the low resolution image corresponds to the high resolution image for better image quality output, if the input images are in different sizes. Then it performs image rectification using the left side and right side images. After rectification, the DNN executes the image registration by matching the coordinates of the input images. Finally, the image fusion is performed with the input images and the resultant image is enhanced to improve the quality of an image and it can be evaluated by Mean Square Error (MSE), Peak Signal to Noise Ratio (PSNR), Correlation Coefficient (CC), Maximum Squared Error (MAXERR), Structured Similarity Index Measurement (SSIM) and Ratio of Squared Norms (L2RAT). © BEIESP.","","Deep Neural Network (DNN); Hybrid image fusion; Image enhancement; Image rectification","Article","Final","","Scopus","2-s2.0-85067860981"
"Zhu H.; Song W.; Tan H.; Wang J.; Jia D.","Zhu, Hong (57190032288); Song, Weidong (56512910400); Tan, Hai (36976217000); Wang, Jingxue (55349285400); Jia, Di (36840119400)","57190032288; 56512910400; 36976217000; 55349285400; 36840119400","SUPER RESOLUTION RECONSTRUCTION BASED on ADAPTIVE DETAIL ENHANCEMENT for ZY-3 SATELLITE IMAGES","2016","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","3","","","213","217","4","10.5194/isprs-annals-III-7-213-2016","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043252013&doi=10.5194%2fisprs-annals-III-7-213-2016&partnerID=40&md5=ccaa1a1e0ba4cb487a9c7e12debf818c","Super-resolution reconstruction of sequence remote sensing image is a technology which handles multiple low-resolution satellite remote sensing images with complementary information and obtains one or more high resolution images. The cores of the technology are high precision matching between images and high detail information extraction and fusion. In this paper puts forward a new image super resolution model frame which can adaptive multi-scale enhance the details of reconstructed image. First, the sequence images were decomposed into a detail layer containing the detail information and a smooth layer containing the large scale edge information by bilateral filter. Then, a texture detail enhancement function was constructed to promote the magnitude of the medium and small details. Next, the non-redundant information of the super reconstruction was obtained by differential processing of the detail layer, and the initial super resolution construction result was achieved by interpolating fusion of non-redundant information and the smooth layer. At last, the final reconstruction image was acquired by executing a local optimization model on the initial constructed image. Experiments on ZY-3 satellite images of same phase and different phase show that the proposed method can both improve the information entropy and the image details evaluation standard comparing with the interpolation method, traditional TV algorithm and MAP algorithm, which indicate that our method can obviously highlight image details and contains more ground texture information. A large number of experiment results reveal that the proposed method is robust and universal for different kinds of ZY-3 satellite images.","","adaptive detail enhancement; image fusion; multi-scale decomposition; super resolution","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85043252013"
"Purushotham Reddy M.; Srinivasa Reddy K.; Lakshmi L.; Mallikarjuna Reddy A.","Purushotham Reddy, M. (57201349406); Srinivasa Reddy, K. (57202347382); Lakshmi, L. (57194719393); Mallikarjuna Reddy, A. (57204426868)","57201349406; 57202347382; 57194719393; 57204426868","Effective technique based on intensity huge saturation and standard variation for image fusion of satellite images","2019","International Journal of Engineering and Advanced Technology","8","5","","291","295","4","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069962033&partnerID=40&md5=1394d8b6e78b07eba82164f03790aa81","Image fusion is combining the images for the benefit of information obtained from multiple domains. The purpose of image fusion is to extract the necessary data from multiple images to create composite images. The fused images are to occupy less space for storage, less bandwidth for transmission and less time for transmission of images. The Multi-Spectral satellite images contain several groups of the low resolution and the limited data. These groups’ images and Panchromatic images merge into a fused image that has common data for all the groups, but existing image fusion techniques are influenced by the colour degradation. The purpose of the study is to enhance the spectral and the spatial data of the satellite images using IHS and standard variation method. In this paper, we investigated groupings of the estimations that are used to calculate the execution of the entwined image things. The proposed technique shows the superior performance than the existing image fusion methods. ©BEIESP.","","Image fusion; Multi-Spectral images; Panchromatic images; Satellite images; Standard variation","Article","Final","","Scopus","2-s2.0-85069962033"
"Jemseera K.; Noufal P.","Jemseera, K. (57189091224); Noufal, P. (57189099533)","57189091224; 57189099533","Satellite Image Fusion Based on Improved Fast Discrete Curvelet Transforms","2016","Proceedings - 2015 5th International Conference on Advances in Computing and Communications, ICACC 2015","","","7433897","430","433","3","10.1109/ICACC.2015.30","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965095503&doi=10.1109%2fICACC.2015.30&partnerID=40&md5=20300fa2eec6cd0d83182c005cd91b44","Image fusion is the process of merging two or more images into a more informative single image. Satellite image fusion uses high resolution panchromatic image and low resolution multispectral image. IHS, Brovery, PCA, Wavelet, Curvelet etc are the existing techniques available for image fusion. But simultaneous retention of spatial and spectral resolution is an important concern in remote sensing applications. In this paper we proposed an improved Satellite image fusion method based on Fast Discrete curvelet Transform (FDCT) via wrapping. The method uses an improved fusion rule, were the maximum FDCT coefficients from each cell of the Intensity component of the MS image and histogram matched PAN image are taken. The resulting image is then undergone a comparative analysis with the outcomes of existing methodologies. The comparative analysis proves that the proposed method retains more spatial and spectral details than other methods. © 2015 IEEE.","Discrete wavelet transforms; Remote sensing; Satellites; Wavelet transforms; Comparative analysis; Fast discrete curvelet transform (FDCT); Fast discrete curvelet transforms; High resolution; Low resolution multispectral images; Panchromatic images; Remote sensing applications; Satellite images; Image fusion","Fast Discrete Curvelet Transforms; Image Fusion; Intensity-Hue-Transforms; wavelet transforms","Conference paper","Final","","Scopus","2-s2.0-84965095503"
"Zhang Y.","Zhang, Yun (35365712500)","35365712500","Smart Photogrammetric and Remote Sensing Image Processing for Optical Very High Resolution Images-Examples from the CRC-AGIP Lab at UNB","2018","Cehui Xuebao/Acta Geodaetica et Cartographica Sinica","47","6","","722","729","7","10.11947/j.AGCS.2018.20180011","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050477113&doi=10.11947%2fj.AGCS.2018.20180011&partnerID=40&md5=8c36eaeece0cf1a5bda8035a895ffc02","This paper introduces some of the image processing techniques developed in the Canada Research Chair in Advanced Geomatics Image Processing Laboratory (CRC-AGIP Lab) and in the Department of Geodesy and Geomatics Engineering (GGE) at the University of New Brunswick (UNB), Canada. The techniques were developed by innovatively utilizing the characteristics of the available very high resolution remote sensing optical images to solve important problems or create new applications in photogrammetry and remote sensing. The techniques to be introduced are: automated image fusion (UNB-PanSharp), satellite image online mapping, street view technology, moving vehicle detection using single set satellite imagery, supervised image segmentation, image matching in smooth areas, and change detection using images from different viewing angles. © 2018, Surveying and Mapping Press. All right reserved.","Canada; New Brunswick; Geodetic satellites; Geometrical optics; Image fusion; Image matching; Mapping; Optical data processing; Photogrammetry; Remote sensing; Satellite imagery; Surveying; Change detection; High resolution; Moving informations; Online mapping; Optical image; Pan-sharpening; detection method; image processing; image resolution; mapping method; photogrammetry; remote sensing; satellite imagery; segmentation; smoothing; Image segmentation","Change detection; High resolution; Image matching; Image segmentation; Moving information detection; Online mapping; Optical image; Pan-sharpening; Remote sensing; Street view","Article","Final","","Scopus","2-s2.0-85050477113"
"Zhou W.-Z.; Li J.-Z.","Zhou, Wan-Zhen (35197570300); Li, Jia-Ze (57204980983)","35197570300; 57204980983","Comparison and Analysis of Image Fusion Algorithms for GF-2 Satellite","2018","10th International Conference on Modelling, Identification and Control, ICMIC 2018","","","8529899","","","","10.1109/ICMIC.2018.8529899","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058234448&doi=10.1109%2fICMIC.2018.8529899&partnerID=40&md5=091a08fb9f225dcf75c039c186e84a03","Image fusion is an indispensable step in the technology of satellite image processing. After orthorectification and registration can image fusion, the image fusion can effectively increase the utilization rate of the image and improve the discrimination of objects in the image. Firstly, this article introduces the background and significance of image fusion technology nowadays, and then introduced the related algorithms of image fusion in detail. Finally, the algorithm is implemented through experiments. The experiment adopts 'GF-2' satellite to acquire the image data. The Xiongan New Area divided by Hebei Province was chosen as the experimental area. Comparing and analyzing the Baiyangdian Wharf in Anxin County, which is rich in features, high contrast, and low cloudiness. Several fusion algorithms were compared and analyzed by visual observation and quantitative analysis. The experimental results in this paper can be used to provide a reference for the fusion and application of 'GF-2' satellite image data. © 2018 IEEE.","Image enhancement; Satellite imagery; Compared; Comparison and analysis; Image fusion algorithms; Image fusion technology; Ortho-rectification; Satellite image datas; Satellite image processing; Visual observations; Image fusion","Compared; Image fusion; Satellite imagery","Conference paper","Final","","Scopus","2-s2.0-85058234448"
"Liu S.; Li H.; Wang X.; Guo L.; Wang R.","Liu, Shuhan (56200368800); Li, Hongzhou (57202048390); Wang, Xia (55243905600); Guo, Li (57209791997); Wang, Rui (57202045865)","56200368800; 57202048390; 55243905600; 57209791997; 57202045865","Study on mosaic and uniform color method of satellite image fusion in Large srea","2018","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","3","","1099","1102","3","10.5194/isprs-archives-XLII-3-1099-2018","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046949561&doi=10.5194%2fisprs-archives-XLII-3-1099-2018&partnerID=40&md5=6e7fd9f9ed0a87e8190654e0dbff4311","Due to the improvement of satellite radiometric resolution and the color difference for multi-temporal satellite remote sensing images and the large amount of satellite image data, how to complete the mosaic and uniform color process of satellite images is always an important problem in image processing. First of all using the bundle uniform color method and least squares mosaic method of GXL and the dodging function, the uniform transition of color and brightness can be realized in large area and multi-temporal satellite images. Secondly, using Color Mapping software to color mosaic images of 16bit to mosaic images of 8bit based on uniform color method with low resolution reference images. At last, qualitative and quantitative analytical methods are used respectively to analyse and evaluate satellite image after mosaic and uniformity coloring. The test reflects the correlation of mosaic images before and after coloring is higher than 95% and image information entropy increases, texture features are enhanced which have been proved by calculation of quantitative indexes such as correlation coefficient and information entropy. Satellite image mosaic and color processing in large area has been well implemented. © Authors 2018. CC BY 4.0 License.","Color; Colorimetry; Image enhancement; Image fusion; Least squares approximations; Remote sensing; Satellites; Correlation coefficient; Image information entropy; Large area; Multi-temporal; Multi-temporal satellite images; Radiometric resolution; Satellite images; Satellite remote sensing; Color image processing","Automatic uniform color; Large area; Multi-temporal; Satellite image mosaic","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85046949561"
"Tardy B.; Inglada J.; Michel J.","Tardy, Benjamin (56875284600); Inglada, Jordi (55996140200); Michel, Julien (15520146800)","56875284600; 55996140200; 15520146800","Fusion approaches for land cover map production using high resolution image time series without reference data of the corresponding period","2017","Remote Sensing","9","11","1151","","","","10.3390/rs9111151","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034767190&doi=10.3390%2frs9111151&partnerID=40&md5=b43075b560068d75e69969a38f5e0138","Optical sensor time series images allow one to produce land cover maps at a large scale. The supervised classification algorithms have been shown to be the best to produce maps automatically with good accuracy. The main drawback of these methods is the need for reference data, the collection of which can introduce important production delays. Therefore, the maps are often available too late for some applications. Domain adaptation methods seem to be efficient for using past data for land cover map production. According to this idea, the main goal of this study is to propose several simple past data fusion schemes to override the current land cover map production delays. A single classifier approach and three voting rules are considered to produce maps without reference data of the corresponding period. These four approaches reach an overall accuracy of around 80% with a 17-class nomenclature using Formosat-2 image time series. A study of the impact of the number of past periods used is also done. It shows that the overall accuracy increases with the number of periods used. The proposed methods require at least two or three previous years to be used. © 2017 by the authors.","Data fusion; Decision trees; Time series; Classification fusion; Domain adaptation; Land cover; Random forests; Satellite images; Image fusion","Classification fusion; Domain adaptation; Land cover; Random forests; Satellite image time series","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85034767190"
"Kim Y.","Kim, Yongmin (42961682300)","42961682300","Generation of land cover maps through the fusion of aerial images and airborne LiDAR data in urban areas","2016","Remote Sensing","8","6","521","","","","10.3390/rs8060521","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019962659&doi=10.3390%2frs8060521&partnerID=40&md5=6502c26d9d999e74fc4f8f760a4e15c3","Satellite images and aerial images with high spatial resolution have improved visual interpretation capabilities. The use of high-resolution images has rapidly grown and has been extended to various fields, such as military surveillance, disaster monitoring, and cartography. However, many problems were encountered in which one object has a variety of spectral properties and different objects have similar spectral characteristics in terms of land cover. The problems are quite noticeable, especially for building objects in urban environments. In the land cover classification process, these issues directly decrease the classification accuracy by causing misclassification of single objects as well as between objects. This study proposes a method of increasing the accuracy of land cover classification by addressing the problem of misclassifying building objects through the output-level fusion of aerial images and airborne Light Detection and Ranging (LiDAR) data. The new method consists of the following three steps: (1) generation of the segmented image via a process that performs adaptive dynamic range linear stretching and modified seeded region growth algorithms; (2) extraction of building information from airborne LiDAR data using a planar filter and binary supervised classification; and (3) generation of a land cover map using the output-level fusion of two results and object-based classification. The new method was tested at four experimental sites with the Min-Max method and the SSI-nDSM method followed by a visual assessment and a quantitative accuracy assessment through comparison with reference data. In the accuracy assessment, the new method exhibits various advantages, including reduced noise and more precise classification results. Additionally, the new method improved the overall accuracy by more than 5% over the comparative evaluation methods. The high and low patterns between the overall and building accuracies were similar. Thus, the new method is judged to have successfully solved the inaccuracy problem of classification that is often produced by high-resolution images of urban environments through an output-level fusion technique. © 2016 by the author.","Buildings; Classification (of information); Data mining; Maps; Military photography; Optical radar; Satellite imagery; Urban planning; Aerial images; Land cover; Land cover classification; Light detection and ranging; Object-based classifications; Output levels; Supervised classification; Urban environments; Image fusion","Aerial images; Building; Land cover; LiDAR; Output-level fusion; Urban environment","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85019962659"
"Chen C.; Li Y.; Liu W.; Huang J.","Chen, Chen (55707834700); Li, Yeqing (55892220100); Liu, Wei (56303625400); Huang, Junzhou (55570947600)","55707834700; 55892220100; 56303625400; 55570947600","SIRF: Simultaneous Satellite Image Registration and Fusion in a Unified Framework","2015","IEEE Transactions on Image Processing","24","11","7156141","4213","4224","11","10.1109/TIP.2015.2456415","102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939503568&doi=10.1109%2fTIP.2015.2456415&partnerID=40&md5=563c2691c51a54aa3bd10535f86f39b8","In this paper, we propose a novel method for image fusion with a high-resolution panchromatic image and a low-resolution multispectral (Ms) image at the same geographical location. The fusion is formulated as a convex optimization problem which minimizes a linear combination of a least-squares fitting term and a dynamic gradient sparsity regularizer. The former is to preserve accurate spectral information of the Ms image, while the latter is to keep sharp edges of the high-resolution panchromatic image. We further propose to simultaneously register the two images during the fusing process, which is naturally achieved by virtue of the dynamic gradient sparsity property. An efficient algorithm is then devised to solve the optimization problem, accomplishing a linear computational complexity in the size of the output image in each iteration. We compare our method against six state-of-the-art image fusion methods on Ms image data sets from four satellites. Extensive experimental results demonstrate that the proposed method substantially outperforms the others in terms of both spatial and spectral qualities. We also show that our method can provide high-quality products from coarsely registered real-world IKONOS data sets. Finally, a MATLAB implementation is provided to facilitate future research. © 2015 IEEE.","Algorithms; Computational efficiency; Convex optimization; Data fusion; Image registration; Iterative methods; Optimization; Convex optimization problems; Geographical locations; Group sparsities; High-quality products; Least squares fitting; Optimization problems; Pan-sharpening; Spectral information; Image fusion","dynamic gradient sparsity; group sparsity; Image fusion; image registration; joint fusion; pan-sharpening","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84939503568"
"Qiu C.; Wei J.; Dong Q.","Qiu, Chunxia (57195331246); Wei, Jingyi (56514381000); Dong, Qiankun (57195598643)","57195331246; 56514381000; 57195598643","Research of Image Fusion Method about ZY-3 Panchromatic Image and Multispectral Image","2018","5th International Workshop on Earth Observation and Remote Sensing Applications, EORSA 2018 - Proceedings","","","8598582","","","","10.1109/EORSA.2018.8598582","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061821135&doi=10.1109%2fEORSA.2018.8598582&partnerID=40&md5=a130e61555dd6c720f39b27cf8eccf8b","At present, there are few researches on the fusion method of ZY-3 satellite. The paper takes the ZY-3 image of Xi'an as an example, the image fusion experiments were mainly performed using the Brovey transform and Gram-schmidt transform method. Then qualitative analysis from the following three aspects: sharpness, texture features, and hue. Quantitative evaluation from four aspects including standard deviation, information entropy, mean value and correlation coefficient. Combined with the results of qualitative and quantitative analysis above, it shows that Gram-schmidt transform is the most suitable fusion method for panchromatic image and multispectral image of ZY-3 satellite in the existing fusion method. © 2018 IEEE.","Observatories; Remote sensing; Satellites; Textures; Accuracy evaluation; Brovey transforms; Gram-Schmidt transform; Remote sensing images; Satellite images; Image fusion","Accuracy evaluation; Brovey transform; Gram-schmidt transform; Remote Sensing Image Fusion; ZY-3 satellite image","Conference paper","Final","","Scopus","2-s2.0-85061821135"
"Devabalan; Saravanan R.","Devabalan (57192715904); Saravanan, R. (55161916600)","57192715904; 55161916600","Tbann: Tree bagger algorithm with neural network-based hyperspectral images classification","2016","Asian Journal of Information Technology","15","16","","3125","3133","8","10.3923/ajit.2016.3125.3133","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007583413&doi=10.3923%2fajit.2016.3125.3133&partnerID=40&md5=4ce480009c05d5e5edb8aa77e1fc0683","Geological information prediction and Earth monitoring by the satellite images are the recent research area to preserve the vegetation, weather forecast, and the disaster management. The employment of Hyper Spectral Image (HSI) by capturing the electromechanical energy variations from the Earth's surface in the various spectral bands offers the significant contribution to the remote sensing applications. The clear image analysis depends on the spectral response. The capture of response in HSI in narrow bandwidth causes the less performance. Hence, the number of bands over the various time periods are the important requirement in clear image analysis. The multi-temporal images contain more information than RGB image since more bands are available in it. The absence of frames update leads to accuracy degradation. This study focuses on multi-temporal images for better isolation of normal and noise region and provides the clear image analysis compared to HSI. This study proposes the cellular automata-based noise filtering technique with the changes in noise prediction structure to eradicate the noise components, thereby better isolation is achieved. This study overcomes the update and accuracy limitations by an employment of image fusion to each band to eliminate the cloud and provide the necessary updated frames. The classification of normalized images from the fused images by using Tree Bagger algorithm with Neural Network (NN) formation (TBANN) predicts the cluster label for the color features of specific band results in the reduction of the atmospheric and signal dependent noise. The comparative analysis between the proposed TBANN with the existing methods regarding the accuracy, Kappa coefficient and the number of pixels count assures the effectiveness of TBANN in remote sensing applications. © Medwell Journals, 2016.","","Cloud elimination; Hyper spectral image (HSI); Image fusion; Neural network (NN); Preprocessing; Tree bagger algorithm","Article","Final","","Scopus","2-s2.0-85007583413"
"Pereira O.J.R.; Melfi A.J.; Montes C.R.","Pereira, Osvaldo José Ribeiro (36628953000); Melfi, Adolpho José (7003918479); Montes, Célia Regina (7005310646)","36628953000; 7003918479; 7005310646","Image fusion of Sentinel-2 and CBERS-4 satellites for mapping soil cover in the Wetlands of Pantanal","2017","International Journal of Image and Data Fusion","8","2","","148","172","24","10.1080/19479832.2016.1261946","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008682047&doi=10.1080%2f19479832.2016.1261946&partnerID=40&md5=72e4a2c326f13b2cce0018c52a8b299a","Advances in remote-sensing technology and the release of new sensor systems have been providing a wide range of optical and radar satellite images. The availability of such images gives new options for mapping relatively remote and sparsely settled territories. Given this, the main goal of this research was to perform a quantitative assessment of the quality of a set of fused images obtained by China–Brazil Earth Resources Satellite (CBERS-4) and Sentinel-2 satellites over the region of the Brazilian Pantanal, considering a zonal quantitative approach. Through the applied methods, we combined the spectral resolution of Sentinel-2 images with the spatial resolution of the CBERS-4 panchromatic band. The quantitative evaluation of the spectral and spatial quality of the fused products based on a regionalised approach was essential in order to understand the spatial variability of the fusion quality, according to each fusion method. Based on the obtained results, we observed that CBERS-4 panchromatic band could be satisfactorily applied for refining the spatial resolution of Sentinel-2 multispectral (MS) images according to À trous wavelet transform and downscaling cokriging image fusion methods, allowing the generation of MS fused images with a 5-m spatial resolution. The resulting fused images were used to map the spatial distribution of saline and crystalline lakes at high spatial resolution and with unprecedented spectral and spatial accuracies, according to a semiautomatic classification approach. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","Pantanal; Image compression; Image enhancement; Image resolution; Mapping; Remote sensing; Satellite imagery; Satellites; Soils; Wavelet transforms; ATWT; Classification approach; Earth resources satellites; High spatial resolution; Quantitative approach; Quantitative assessments; Quantitative evaluation; Remote sensing technology; image analysis; mapping; quantitative analysis; remote sensing; satellite imagery; Sentinel; soil cover; wetland; Image fusion","ATWT; DCK; image enhancement; Image fusion","Article","Final","","Scopus","2-s2.0-85008682047"
"Jenerowicz A.; Siok K.; Woroszkiewicz M.; Orych A.","Jenerowicz, Agnieszka (56539966900); Siok, Katarzyna (23981507400); Woroszkiewicz, Malgorzata (57193134667); Orych, Agata (56539971700)","56539966900; 23981507400; 57193134667; 56539971700","The fusion of satellite and UAV data: Simulation of high spatial resolution band","2017","Proceedings of SPIE - The International Society for Optical Engineering","10421","","104211Z","","","","10.1117/12.2278669","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034764913&doi=10.1117%2f12.2278669&partnerID=40&md5=bb7174094e1aae4319bcc69e4b302361","Remote sensing techniques used in the precision agriculture and farming that apply imagery data obtained with sensors mounted on UAV platforms became more popular in the last few years due to the availability of low-cost UAV platforms and low-cost sensors. Data obtained from low altitudes with low-cost sensors can be characterised by high spatial and radiometric resolution but quite low spectral resolution, therefore the application of imagery data obtained with such technology is quite limited and can be used only for the basic land cover classification. To enrich the spectral resolution of imagery data acquired with low-cost sensors from low altitudes, the authors proposed the fusion of RGB data obtained with UAV platform with multispectral satellite imagery. The fusion is based on the pansharpening process, that aims to integrate the spatial details of the high-resolution panchromatic image with the spectral information of lower resolution multispectral or hyperspectral imagery to obtain multispectral or hyperspectral images with high spatial resolution. The key of pansharpening is to properly estimate the missing spatial details of multispectral images while preserving their spectral properties. In the research, the authors presented the fusion of RGB images (with high spatial resolution) obtained with sensors mounted on low-cost UAV platforms and multispectral satellite imagery with satellite sensors, i.e. Landsat 8 OLI. To perform the fusion of UAV data with satellite imagery, the simulation of the panchromatic bands from RGB data based on the spectral channels linear combination, was conducted. Next, for simulated bands and multispectral satellite images, the Gram-Schmidt pansharpening method was applied. As a result of the fusion, the authors obtained several multispectral images with very high spatial resolution and then analysed the spatial and spectral accuracies of processed images. © 2017 SPIE.","Agriculture; Costs; Data fusion; Ecology; Ecosystems; Hydrology; Image fusion; Image processing; Image resolution; Remote sensing; Satellites; Spectral resolution; Spectroscopy; Unmanned aerial vehicles (UAV); Data simulation; Land cover classification; LANDSAT; Multispectral satellite image; Multispectral satellite imagery; Pan-sharpening; Remote sensing techniques; Very high spatial resolutions; Satellite imagery","data fusion; data simulation; Landsat; pansharpening; satellite imagery; UAV","Conference paper","Final","","Scopus","2-s2.0-85034764913"
"Singh R.; Gupta R.","Singh, Rajesh (57211196512); Gupta, Rajiv (55705310800)","57211196512; 55705310800","Improvement of classification accuracy using image fusion techniques","2016","Proceedings - 2016 International Conference on Computational Intelligence and Applications, ICCIA 2016","","","7600311","36","40","4","10.1109/ICCIA.2016.21","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994841549&doi=10.1109%2fICCIA.2016.21&partnerID=40&md5=ef6ae49ce03bc5051c6f9cfc3fd303ea","Remote sensing techniques have been widely used for identification of land use and land cover features. Land information can be easily collected by classification of satellite images in the context of their use. In this paper study area has been classified into three classes i.e. settlement, trees and agricultural by classification of an image which has been enhanced using fusion of two images. The spatial and spectral resolutions of different satellite images provide better information with the aid of initial processing of image and fusion of both images. The satellite images fused together are multispectral IRS-P6 also called Resourcesat-1 satellite, on board LISS-III sensor provide image with spatial resolution of 23.5 m and an IRS-P5 also called Cartosat-1 satellite provides single band panchromatic image with spatial resolution of 2.5 m. Erdas Imagine 9.1 software has been used for image processing, fusion and supervised classification of the images. The Brovery, Multiplicative and Principal Component Analysis (PCA) method have been used for image fusion. The resultant images have been classified using the supervised classification with maximum likelihood parametric rule for information extraction and comparison between them in terms of their accuracy. © 2016 IEEE.","Artificial intelligence; Classification (of information); Image fusion; Image processing; Image resolution; Land use; Maximum likelihood; Principal component analysis; Remote sensing; Satellites; Supervised learning; Accuracy assessment; Classification accuracy; Image fusion techniques; Land use and land cover; Panchromatic images; Remote sensing techniques; Spatial resolution; Supervised classification; Image classification","Accuracy Assessment; Image Classification; Image Fusion Techniques","Conference paper","Final","","Scopus","2-s2.0-84994841549"
"","","","3rd International Conference on Advanced Informatics for Computing Research, ICAICR 2019","2019","Communications in Computer and Information Science","1076","","","","","879","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075241050&partnerID=40&md5=4e24873f1f3fa784bdae3dc44de75c92","The proceedings contain 78 papers. The special focus in this conference is on Advanced Informatics for Computing Research. The topics include: Quantum Cryptography Protocols for IOE Security: A Perspective; low-Profile Patch Antenna with Parasitic Elements for CubeSat Applications; Analysis and Optimization of a Very Compact MPA with Parasitic Elements for Inter-swarm of CubeSats Communications; multi-sensor Image Fusion Using Intensity Hue Saturation Technique; analysis of Novel Hybrid Encryption Algorithm for Providing Security in Big Data; Image Encryption Technique Based on Hybridized DNA Cryptography and Compressive Sensing Algorithm; data Obfuscation Using Secret Sharing; a Centrality Measure for Influence Maximization Across Multiple Social Networks; performance Analysis and Comparison of Modulation and Congestion Techniques in Cognitive Radio Networks; design of Microstrip Patch Antenna Using E-Shaped Slots for Multiband Applications; optimizing Routing Performance in P2P Networks Using Machine Learning; Performance Analysis of Various Congestion Control Schemes in VANET; Predicting Protein-Protein Interaction in Multi-layer Blood Cell PPI Networks; anchor Placement Techniques for Effective Positioning of Wireless Sensors; Detection of DDoS Attacks Using Machine Learning in Cloud Computing; hybrid Approach for Network Intrusion Detection System Using Random Forest Classifier and Rough Set Theory for Rules Generation; MDRAA: A Multi-decisive Resource Allocation Approach to Enhance Energy Efficiency in a Cloud Computing Environment; trust-Aware Clustering Approach Using Type-2 Fuzzy Logic for Mobile Wireless Sensor Networks; high Resolution Satellite Image Based Seagrass Detection Using Generalized Regression Neural Network; an Efficient Design of Staircase Circular Slot Shaped Antenna for Wireless Application; S-Band CPW-Fed Slot Antenna with 2D Metamaterials for CubeSat Communications.","","","Conference review","Final","","Scopus","2-s2.0-85075241050"
"Singh H.; Verma P.A.; Saran S.","Singh, Harpreet (57213857895); Verma, Prabhakar Alok (57189896345); Saran, Sameer (7003795359)","57213857895; 57189896345; 7003795359","Qualitative assessment of geostatistical and non-geostatistical fusion techniques: a case study on landsat 8 images","2019","Spatial Information Research","27","3","","275","283","8","10.1007/s41324-018-00235-z","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091835849&doi=10.1007%2fs41324-018-00235-z&partnerID=40&md5=39dcb8e7f11d5ed68b315b90ad2b24a7","Broadly satellite images are available in two categories (1) high spectral resolution but less spatial resolution (2) high spatial resolution but less spectral resolution. But in certain applications, images with high spatial as well as high spectral resolution are required. To meet such kind of requirement, Image fusion is widely accepted and increasingly being used. In this study satellite image fusion is done using geostatistical methods (cokriging, regression kriging) and non-geostatistical methods (intensity hue saturation, principal component analysis). The study is focused on performing qualitative assessment of selected image fusion techniques. In this study, the primary variable is RGB bands of Landsat 8 Operational Land Imager (OLI) and the panchromatic band is chosen as the second variable. The output of these selected methods is compared to access spectral and spatial quality. Spectral quality is accessed by finding the correlation between the primary variable and the output, however spatial quality is accessed via texture analysis method named entropy. Overall assessment of loss of correlation, luminance distortion, and contrast distortion is done using Image quality index. Correlation index of regression kriging and PCA are comparable whereas entropy and image quality index of fused output is highest in case of regression kriging. Hence regression kriging can be concluded as the best fusion technique out of the compared techniques. © 2019, Korean Spatial Information Society.","","Cokriging; Geostatistical; IHS; Kriging; Landsat; OLI; PCA; Regression kriging","Article","Final","","Scopus","2-s2.0-85091835849"
"Fu B.; Wang Y.; Campbell A.; Li Y.; Zhang B.; Yin S.; Xing Z.; Jin X.","Fu, Bolin (57218665909); Wang, Yeqiao (57200374534); Campbell, Anthony (57191292668); Li, Ying (57208286533); Zhang, Bai (8453127200); Yin, Shubai (13610744300); Xing, Zefeng (56814273000); Jin, Xiaomin (57191291999)","57218665909; 57200374534; 57191292668; 57208286533; 8453127200; 13610744300; 56814273000; 57191291999","Comparison of object-based and pixel-based Random Forest algorithm for wetland vegetation mapping using high spatial resolution GF-1 and SAR data","2017","Ecological Indicators","73","","","105","117","12","10.1016/j.ecolind.2016.09.029","124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988703621&doi=10.1016%2fj.ecolind.2016.09.029&partnerID=40&md5=cf9e838e0396e01852e810b889cb2ea3","Vegetation is an integral component of wetland ecosystems. Mapping distribution, quality and quantity of wetland vegetation is important for wetland protection, management and restoration. This study evaluated the performance of object-based and pixel-based Random Forest (RF) algorithms for mapping wetland vegetation using a new Chinese high spatial resolution Gaofen-1 (GF-1) satellite image, L-band PALSAR and C-band Radarsat-2 data. This research utilized the wavelet-principal component analysis (PCA) image fusion technique to integrate multispectral GF-1 and synthetic aperture radar (SAR) images. Comparison of six classification scenarios indicates that the use of additional multi-source datasets achieved higher classification accuracy. The specific conclusions of this study include the followings:(1) the classification of GF-1, Radarsat-2 and PALSAR images found statistically significant difference between pixel-based and object-based methods; (2) object-based and pixel-based RF classifications both achieved greater 80% overall accuracy for both GF-1 and GF-1 fused with SAR images; (3) object-based classifications improved overall accuracy between 3%-10% in all scenarios when compared to pixel-based classifications; (4) object-based classifications produced by the integration of GF-1, Radarsat-2 and PALSAR images outperformed any of the lone datasets, and achieved 89.64% overall accuracy. © 2016 Elsevier Ltd","China; C (programming language); Classification (of information); Decision trees; Image fusion; Image resolution; Pixels; Principal component analysis; Radar imaging; Satellite imagery; Synthetic aperture radar; Vegetation; Wetlands; GF-1; Northeast China; Object-based classifications; Pixel based classifications; Random forest classifier; Statistically significant difference; Synthetic aperture radar (SAR) images; Wetland vegetation; accuracy assessment; algorithm; data set; forest ecosystem; image classification; PALSAR; pixel; RADARSAT; satellite imagery; spatial resolution; synthetic aperture radar; vegetation mapping; wetland; Mapping","GF-1; Image fusion; Northeast China; Random Forest classifier; SAR; Wetland vegetation mapping","Article","Final","","Scopus","2-s2.0-84988703621"
"Hasanlou M.; Saradjian M.R.","Hasanlou, Mahdi (55178361600); Saradjian, Mohammad Reza (8397399100)","55178361600; 8397399100","Quality assessment of pan-sharpening methods in high-resolution satellite images using radiometric and geometric index","2016","Arabian Journal of Geosciences","9","1","45","1","10","9","10.1007/s12517-015-2015-0","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949545339&doi=10.1007%2fs12517-015-2015-0&partnerID=40&md5=ed08081faf5a4f8c62da0d821ff95591","This paper focuses on quality assessment of fusion of multispectral (MS) images with high-resolution panchromatic (Pan) images. Since most existing quality assessments take the entire image into account simultaneously and generate some uncertainties, a novel and rather objective quality index has been proposed for image fusion. The index is comprised of geometric and radiometric parts. Both geometric and radiometric measurements are calculated using morphological algorithm applied on an edge image to create a mask which is used to separate high-frequency regions from low-frequency ones. The accuracy assessment is made using common existing criteria on geometric and radiometric segments, and then a weighted sum is calculated to generate radiometric and geometric index (RG index). Several commonly used fusion algorithms such as IHS, modified IHS, PCA, Gram-Schmidt, Brovey Transform, Ehlers, High-Pass Modulation, Schowengerdt and UNB were applied on a very high-resolution GeoEye-1 and WorldView-2 images. In order to perform quality assessment, methods of Spectral Angle Mapper, Structural SIMilarity, correlation coefficients and universal quality index for which the normalization were possible (for comparison purposes) were used. The utilized RG index showed that by separating spectral and spatial component quality measurement, the quality assessment is made on fused images in a more distinct, explicit, accurate and objective manner. © 2015, Saudi Society for Geosciences.","accuracy assessment; data quality; GeoEye; geometry; image resolution; multispectral image; panchromatic image; satellite imagery; WorldView","Geometric distortion; Geometric quality; Image fusion; Multispectral imagery; Quality assessment; Radiometric quality","Article","Final","","Scopus","2-s2.0-84949545339"
"Prema R.; Sumithra M.G.","Prema, R. (57213111939); Sumithra, M.G. (37091512500)","57213111939; 37091512500","Comparative assessment of image fusion methods for land cover/ land use monitoring","2018","International Journal of Engineering and Advanced Technology","8","2C2","","105","110","5","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070099802&partnerID=40&md5=0cd0f1c34d7d222a61ba2cf81f89ff6c","Land Cover/Land Use (LCLU) applications includes rural/urban change detection, biomass mapping and natural resource management. The high spatial and high spectral resolution are necessary for efficient class discrimination of LCLU monitoring and mapping. The multispectral (MS) images acquired from land observation satellites like Landsat, MODIS and IRS etc. are able to provide only coarse spatial resolution. The Panchromatic (PAN) band in satellite images have high spatial but coarse spectral resolution. The process of combining PAN and MS band images to produce high spatial and spectral resolution is called Image Fusion. Classical image fusion algorithms are Brovey, Intensity Hue and Saturation (IHS), Principal Component Analysis (PCA), High Pass Filtering (HPF), Atrous Wavelet Transform (ATWT) and Generalized Laplacian Pyramid (GLP). These benchmarking methods are coming under pixel level fusion. In this paper, we are going to analyze the performance quantitatively using evaluation parameters Spectral Angle Mapper (SAM), Universal Image Quality Index (UIQI) and Relative Global-dimensional Synthesis Error (ERGAS). The experiment is performed using datasets Landsat and QuikBird. All the simulations were carried out in MATLAB R2014a. Comparison of all the methods concludes the better approach for future research. © BEIESP.","","Image Fusion; Land Cover/Land Use; Pixel level fusion; Spatial resolution and Spectral Resolution","Article","Final","","Scopus","2-s2.0-85070099802"
"Zhu X.; Cai F.; Tian J.; Williams T.K.-A.","Zhu, Xiaolin (55696724800); Cai, Fangyi (57201734879); Tian, Jiaqi (57201734900); Williams, Trecia Kay-Ann (57201734213)","55696724800; 57201734879; 57201734900; 57201734213","Spatiotemporal fusion of multisource remote sensing data: Literature survey, taxonomy, principles, applications, and future directions","2018","Remote Sensing","10","4","527","","","","10.3390/rs10040527","224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045984906&doi=10.3390%2frs10040527&partnerID=40&md5=04700e126f04fea5ae3fd428f4e9c891","Satellite time series with high spatial resolution is critical for monitoring land surface dynamics in heterogeneous landscapes. Although remote sensing technologies have experienced rapid development in recent years, data acquired from a single satellite sensor are often unable to satisfy our demand. As a result, integrated use of data from different sensors has become increasingly popular in the past decade. Many spatiotemporal data fusion methods have been developed to produce synthesized images with both high spatial and temporal resolutions from two types of satellite images, frequent coarse-resolution images, and sparse fine-resolution images. These methods were designed based on different principles and strategies, and therefore show different strengths and limitations. This diversity brings difficulties for users to choose an appropriate method for their specific applications and data sets. To this end, this review paper investigates literature on current spatiotemporal data fusion methods, categorizes existing methods, discusses the principal laws underlying these methods, summarizes their potential applications, and proposes possible directions for future studies in this field. © 2018 by the authors.","Image resolution; Remote sensing; Satellite imagery; Heterogeneous landscapes; Multisource remote sensing data; Remote sensing technology; Satellite images; Spatial and temporal resolutions; Spatial resolution; Spatio-temporal data; Temporal resolution; Image fusion","Data blending; Satellite images; Spatial resolution; Spatiotemporal data fusion; Temporal resolution","Review","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85045984906"
"Zhao Y.; Huang B.","Zhao, Yongquan (57192575717); Huang, Bo (55388074800)","57192575717; 55388074800","A Two-step Spatio-Temporal satellite image Fusion Model for temporal changes of various LULC under one-pair prior images scenario","2016","ICSPCC 2016 - IEEE International Conference on Signal Processing, Communications and Computing, Conference Proceedings","","","7753699","","","","10.1109/ICSPCC.2016.7753699","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006850810&doi=10.1109%2fICSPCC.2016.7753699&partnerID=40&md5=7135e31dd0f56e3cae61881af8a440b6","This paper proposes a two-step spatio-temporal fusion model (TSTFM) for generating synthetic satellite remote sensing images with high-spatial and high-temporal resolution (HSaHTeR) based on one pair of prior images, which contain one low-spatial but high-temporal resolution (LSaHTeR) image and one high-spatial but low-temporal resolution (HSaLTeR) image. Considering both phenology and type surface temporal changes, the two steps in TSTFM are adopted to handle these two kinds of changes respectively, which are based on weighted mean and example-based image super-resolution approaches accordingly. In addition, a relative radiometric normalization process is conducted before performing the two-step spatio-temporal fusion (STF) process, which aims to calibrate radiometric differences of different kinds of satellite sensors. The proposed method was tested on two sets of test data: surface with mainly LULC phenology changes and surface with primarily LULC type changes. Experimental results show that TSTFM can capture both phenology and type changes efficiently and precisely even with one-pair prior images, and it can also maintain its robustness when facing extremely complex LULC. © 2016 IEEE.","Biology; Image reconstruction; Optical resolving power; Radiometry; Remote sensing; Satellites; Signal processing; Image super resolutions; phenology change; Spatio-temporal fusions; type change; various LULC; Weighted mean; Image fusion","image super-resolution; phenology change; Spatio-temporal fusion; type change; various LULC; weighted mean","Conference paper","Final","","Scopus","2-s2.0-85006850810"
"Khateri M.; Ghassemian H.","Khateri, Mohammad (57191841088); Ghassemian, Hassan (57204122949)","57191841088; 57204122949","A compressed-sensing-based approach for remote sensing image fusion","2016","2016 24th Iranian Conference on Electrical Engineering, ICEE 2016","","","7585815","1809","1814","5","10.1109/IranianCEE.2016.7585815","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994140720&doi=10.1109%2fIranianCEE.2016.7585815&partnerID=40&md5=67dd8c7660c0a67f1869e138c1a73147","Remote sensing image pan-sharpening is an image fusion process which fuses a low-resolution multi-spectral (LRMS) image with its corresponding high-resolution panchromatic (HRP) image to create a high-resolution multi-spectral (HRMS) image. In this paper, pan-sharpening methods based on compressed sensing (CS) theory are proposed. In the proposed methods, the HRP and LRMS dictionaries are learned from the input images (HRP, LRMS). Moreover, this paper proposes a new algorithm to reconstruct the unknown HRMS image by considering remote sensing physics. The proposed algorithm extracts non-overlapping patches from input images and provides an initial estimation of HRMS dictionary. Then, the initial HRMS dictionary and LRMS image are used to reconstruct unknown HRMS image. The algorithm neither needs to extract overlapping patches, nor training dataset. So, it makes the proposed methods fast and practical. Furthermore a high-pass filter is used to preserve more details in the fusion process. The proposed methods are tested on WorldView-2 and QuickBird satellite images and these results are compared with several popular and state-of-the-art methods quantitatively and visually. © 2016 IEEE.","Compressed sensing; High pass filters; Image processing; Image reconstruction; Remote sensing; Signal reconstruction; Compressive sensing; Dictionary learning; Initial estimation; Pan-sharpening; QuickBird satellite; Remote sensing images; State-of-the-art methods; Training dataset; Image fusion","compressed sensing (CS); dictionary learning; image fusion; pan-sharpening; Remote sensing","Conference paper","Final","","Scopus","2-s2.0-84994140720"
"Maniraj Kumar P.; Thirumurugan P.; Karthikeyan P.; Saravanan S.; Kumarnath J.","Maniraj Kumar, P. (56006722000); Thirumurugan, P. (56087871100); Karthikeyan, P. (57211774744); Saravanan, S. (57968968500); Kumarnath, J. (57211803990)","56006722000; 56087871100; 57211774744; 57968968500; 57211803990","Image synthesis M/2D/HWT in VLSI technology","2019","International Journal of Innovative Technology and Exploring Engineering","9","1","","2976","2982","6","10.35940/ijitee.A9119.119119","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075072229&doi=10.35940%2fijitee.A9119.119119&partnerID=40&md5=923c3d3348862a80d52d06535a71a0dd","Image synthesis is grouping of valid information from a group of images in to unique image. The ensuing image is an improved quality than any other images. The spectral deformation major con in standard method. The different multiscale transforms are proposed the overcome the issue. The image is affected by impulse noise because of satellite images, are filtered the impulse noise in the image syntehesis. In this paper we studied the architecture of Edge preserve algorithm which good in PSNR and MSE. The proposed technique using wavelet decomposition is implemented in Matlab for low resolution images are multispectral image and high resolution image are panchromatic image and then we combined the synthesized image in Altera Cyclone. The result shows the significant area and power. The synthesis image has a colour combination which is effective than any other in set of images. © BEIESP.","","Edge preserving Filter; Haar Wavelet; Image Fusion; Impulse Noise","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85075072229"
"Jinju J.; Santhi N.; Ramar K.; Sathya Bama B.","Jinju, Joy (55839411800); Santhi, N. (55258030500); Ramar, K. (7004225698); Sathya Bama, B. (36024410500)","55839411800; 55258030500; 7004225698; 36024410500","Spatial frequency discrete wavelet transform image fusion technique for remote sensing applications","2019","Engineering Science and Technology, an International Journal","22","3","","715","726","11","10.1016/j.jestch.2019.01.004","43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060086324&doi=10.1016%2fj.jestch.2019.01.004&partnerID=40&md5=cb75c59db33eeae563792c8d84e5d672","In Remote Sensing, fusion of Panchromatic (PAN) image and Multispectral (MS) image is an important technique. This paper incorporates a multiresolution image fusion algorithm based on the proposed Spatial Frequency DWT (SFDWT – Spatial Frequency Discrete Wavelet Transform) technique. In SFDWT technique, the low resolution MS image is resampled to the high resolution PAN image and fusion is done by injecting the spectral and spatial information's present in PAN and MS images onto each other using their corresponding DWT coefficients by evaluating the spatial frequency (SF – Spatial Frequency). Evaluation is carried out using Pléiades Satellite images having a resolution ratio of 1:4. Fusion simulation is done in which pan sharpened reference images are available, indicate that the proposed SFDWT technique performs better than standard DWT methods and the IHS method in terms of different evaluation indexes including Structural similarity measure (SSIM), Errur Relative Globale Adimensionnelle de Synthese (ERGAS) etc. SFDWT produces high spectral and spatial quality fused images for remote sensing applications. © 2019 Karabuk University","","MS image; PAN image; SFDWT; Spatial frequency","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85060086324"
"Solanky V.; Katiyar S.K.","Solanky, Vijay (57217203068); Katiyar, S.K. (36786708800)","57217203068; 36786708800","Pixel-level image fusion techniques in remote sensing: a review","2016","Spatial Information Research","24","4","","475","483","8","10.1007/s41324-016-0046-6","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029444748&doi=10.1007%2fs41324-016-0046-6&partnerID=40&md5=fb71cdad8e18db59c15e082676b84e28","In the recent years remote sensing image fusion of satellite images has become a popular tool for analyzing different features presented on satellite images. We have analyzed only pixel-level image fusion techniques in this paper, which integrates a low-resolution multispectral (MS) image and high-resolution panchromatic (PAN) image to produce a more informative image than any of the single image. Generally, a PAN image is having a better spatial resolution, while the MS image is having a better spectral resolution than PAN image, due to this trade-off between MS and PAN image resolutions, it could be difficult to preserve spectral and spatial resolution in a single image without a fusion technique. In this paper, we have reviewed most popular and recent image fusion techniques and implemented them on Cartosat-1, RESOURCESAT-2, LANDSAT-8 data set. Results obtained from each method by visual analysis and quantitative measures indicated that UNB fusion algorithm outperforms other techniques used in this paper. © 2016, Korean Spatial Information Society.","","Image fusion; LANDSAT-8; Pixel-level fusion; RESOURCESAT-2","Review","Final","","Scopus","2-s2.0-85029444748"
"Peschoud C.; Minghelli A.; Mathieu S.; Lei M.; Pairaud I.; Pinazo C.","Peschoud, Cecile (57189630285); Minghelli, Audrey (6507427005); Mathieu, Sandrine (57204744545); Lei, Manchun (35868077200); Pairaud, Ivane (8869977400); Pinazo, Christel (6602655361)","57189630285; 6507427005; 57204744545; 35868077200; 8869977400; 6602655361","Fusion of Sun-Synchronous and Geostationary Images for Coastal and Ocean Color Survey Application to OLCI (Sentinel-3) and FCI (MTG)","2017","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","10","1","7487007","45","56","11","10.1109/JSTARS.2016.2558819","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973519387&doi=10.1109%2fJSTARS.2016.2558819&partnerID=40&md5=08fb8dcd4a7a78e81c48c9f613355d10","Open ocean and coastal area monitoring requires multispectral satellite images with a middle spatial resolution ({\sim 300\ {\text{m}}}) and a high temporal repeatability ({\sim 1\ {\text{h}}}). As no current satellite sensors have such features, the aim of this study is to propose a fusion method to merge images delivered by a low earth orbit (LEO) sensor with images delivered by a geostationary earth orbit (GEO) sensor. This fusion method, called spatial spectral temporal fusion (SSTF), is applied to the future sensors-Ocean and Land Color Instrument (OLCI) (on Sentinel-3) and Flexible Combined Imager (FCI) (on Meteosat Third Generation) whose images were simulated. The OLCI bands, acquired at t0, are divided by the oversampled corresponding FCI band acquired at t0 and multiplied by the FCI bands acquired at t1. The fusion product is used for the next fusion at t1 and so on. The high temporal resolution of FCI allows its signal-To-noise ratio (SNR) to be enhanced by the means of temporal filtering. The fusion quality indicator ERGAS computed between SSTF fusion products and reference images is around 0.75, once the FCI images are filtered from the noise and 1.08 before filtering. We also compared the estimation of chlorophyll (Chl), suspended particulate matter (SPM), and colored dissolved organic matter (CDOM) maps from the fusion products with the input simulation maps. The comparison shows an average relative errors on Chl, SPM, and CDOM, respectively, of 64.6%, 6.2%, and 9.5% with the SSTF method. The SSTF method was also compared with an existing fusion method called the spatial and temporal adaptive reflectance fusion model (STARFM). © 2008-2012 IEEE.","Biological materials; Geostationary satellites; Orbits; Signal to noise ratio; Weather satellites; Average relative error; Colored dissolved organic matter; Geostationary Earth orbit; High temporal resolution; Low earth orbit(LEO); Meteosat third generation; Multispectral satellite image; Suspended particulate matters; coastal zone; data quality; GOCI; ocean color; open ocean; satellite imagery; signal-to-noise ratio; spatial resolution; spatiotemporal analysis; spectral analysis; Image fusion","Fusion; image simulation; meteosat Third Generation (MTG); Ocean and Land Color Instrument; ocean color","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84973519387"
"Lestiana H.; Sukristiyanti","Lestiana, H. (57201065641); Sukristiyanti (57201057276)","57201065641; 57201057276","Spatial resolution enhancement of satellite image data using fusion approach","2018","IOP Conference Series: Earth and Environmental Science","118","1","012047","","","","10.1088/1755-1315/118/1/012047","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043294912&doi=10.1088%2f1755-1315%2f118%2f1%2f012047&partnerID=40&md5=6867c5a19094b76acba362d4a9f3fb5a","Object identification using remote sensing data has a problem when the spatial resolution is not in accordance with the object. The fusion approach is one of methods to solve the problem, to improve the object recognition and to increase the objects information by combining data from multiple sensors. The application of fusion image can be used to estimate the environmental component that is needed to monitor in multiple views, such as evapotranspiration estimation, 3D ground-based characterisation, smart city application, urban environments, terrestrial mapping, and water vegetation. Based on fusion application method, the visible object in land area has been easily recognized using the method. The variety of object information in land area has increased the variation of environmental component estimation. The difficulties in recognizing the invisible object like Submarine Groundwater Discharge (SGD), especially in tropical area, might be decreased by the fusion method. The less variation of the object in the sea surface temperature is a challenge to be solved. © Published under licence by IOP Publishing Ltd.","Discharge (fluid mechanics); Groundwater; Image fusion; Image resolution; Object recognition; Oceanography; Remote sensing; Surface waters; Application of fusion; Component estimation; Object identification; Satellite image datas; Sea surface temperature (SST); Smart city applications; Spatial-resolution enhancement; Submarine groundwater discharge; Image enhancement","","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85043294912"
"Medina J.; Carrillo I.; Upegui E.","Medina, Javier (57197825929); Carrillo, Ivan (57201589455); Upegui, Erika (36459015100)","57197825929; 57201589455; 36459015100","Spectral and spatial assessment of the TDW Wavelet transform decimated and not decimated for the fusion of OrbView-2 satellite images; [Evaluación espectral y espacial de la transformada Wavelet TDW decimada y no decima para la fusión de imágenes satelitales OrbView-2.]","2018","Iberian Conference on Information Systems and Technologies, CISTI","2018-June","","","1","6","5","10.23919/CISTI.2018.8399418","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049910117&doi=10.23919%2fCISTI.2018.8399418&partnerID=40&md5=f5122a518d1e95459d550af604cba4c1","The objective of this article is to develop and evaluate two methodologies that allow to improve the spatial resolution without significant loss of the spectral resolution of a multispectral image (MULT) and panchromatic (PAN) OrbView-2. In the first method, the algorithm is used: Discrete Transformation of Decimal Wavelet (TWD decimated) or Mallat Algorithm. The Value is obtained from the MULT. Then applying the fusion to the Value and PAN component through the TWD decimated daubechies (db4) generates a new Value (nval-m). With the nuance and saturation of the MULT image, the inverse HSV-RGB transformation is performed to generate a new multispectral image (N-MULT1). In the second methodology, the algorithm is used: Discrete Wavelet Transform not decimated (TWD not decimated) or Algorithm of À trous, applying the fusion to the Value component and PAN through the TWD not decimated generates a new Value (nval-a) and with the nuance and saturation of the MULT image the inverse HSV-RGB transform is made to generate a new multispectral image (N-MULT2). Finally, the results of the two methods are presented using the ERGAS, RASE and Qu indices for assessment. It is obtained that the à trous method is better spatially and spectrally. © 2018 AISTI.","Discrete wavelet transforms; Fusion reactions; Image enhancement; Image fusion; Information systems; Information use; Inverse problems; Discrete transformation; Mallat; Mallat algorithm; Multispectral images; Satellite images; Spatial assessment; Spatial resolution; Wavelet; Color image processing","Fusion; Mallat; Satellite images; Wavelet; À trous","Conference paper","Final","","Scopus","2-s2.0-85049910117"
"Chaudhary S.K.; Kumar D.; Jain M.K.","Chaudhary, S.K. (57113093800); Kumar, D. (8304745200); Jain, M.K. (56291584700)","57113093800; 8304745200; 56291584700","Performance analysis of hyperspherical colour sharpening method for IRS satellite images","2016","Imaging Science Journal","64","6","","305","312","7","10.1080/13682199.2016.1190898","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978514825&doi=10.1080%2f13682199.2016.1190898&partnerID=40&md5=0b254300b9a581bd439289d224ee0c96","Various image fusion methods have been developed and investigated for different remote sensing (RS) applications. Hyperspherical Colour Sharpening (HCS) method was recently proposed for World View-2 imagery. A limited study has been carried out to find the performance of HCS method for other datasets. In this paper, an experiment is engineered in which HCS method was applied on Indian remote sensing (IRS) datasets. The performance analysis of the method was carried by both qualitative and quantitative methods. In addition to that the quality of indices image for each method is compared to analyse the suitability of methods for various applications based on these indices. Brovey transformation (BT), principal component substitution (PCS), high pass filtering (HPF) and discrete wavelet transform-based principal component substitution (DWT-PCS) were also applied on the selected data and used in comparative analysis with the HCS method. The study reveals that HCS method outperforms in terms of the spectral fidelity, but produces some shortcoming for spatial resolutions. The quality of indices images show that BT and HCS methods do not hold the spatial details after fusion indices image computation, while indices from HPF, DWT-PCS and PCS hold some of spatial information injected into fused output. © 2016 The Royal Photographic Society.","Color; Discrete wavelet transforms; High pass filters; Image analysis; Image fusion; Metadata; Remote sensing; Wavelet transforms; Comparative analysis; Hyperspherical; Image fusion methods; Performance analysis; Principal Components; Quality metrics; Quantitative method; Spatial informations; Principal component analysis","Hyperspherical colour transform; Image fusion; Quality metrics; Remote sensing","Article","Final","","Scopus","2-s2.0-84978514825"
"Venkatesh H.; Viswanath K.","Venkatesh, H. (57192540905); Viswanath, K. (49663698000)","57192540905; 49663698000","Fusion of satellite images in transform domain","2016","International Conference on Communication and Signal Processing, ICCSP 2016","","","7754497","1884","1888","4","10.1109/ICCSP.2016.7754497","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006736212&doi=10.1109%2fICCSP.2016.7754497&partnerID=40&md5=781308c10aa5229436dbfc6162b71e53","Image fusion taking into account the wavelet and fourier change grades rich multispectral points of importance yet provides fewer spatial subtle elements from basis images. Wavelet performs well at direct elements yet not at non-straight cutoffs since Wavelets don't utilize the geometric assets of assemblies. Curvelet overwhelmed such challenges in highlight representation. A novel Image fusion principle through high pass exploiting Local Magnitude Ratio (LMR) in (FDCT) Fast Discrete Curvelet Transforms area and Discrete wavelet transform (DWT) is characterized. Indian Remote Sensing Geo satellite pictures are utilized for MS and Pan pictures. This mixture guideline produces HR multispectral picture with high spatial determination resolution. This strategy is contrasted and wavelet, Principal Component Analysis (PCA), Fast Discrete Curvelet Transforms area combination techniques. The Proposed procedure results in multispectral information alongside spatial points of interest. © 2016 IEEE.","Image fusion; Principal component analysis; Remote sensing; Signal processing; Wavelet transforms; Fast discrete curvelet transforms; Fusion principles; GEO satellites; Guided filtering; Local magnitude; Satellite images; Spatial points; Transform domain; Discrete wavelet transforms","Discrete wavelet transforms Fast Discrete Curvelet Transforms; Guided Filtering; Image Fusion; Principal Component Analysis","Conference paper","Final","","Scopus","2-s2.0-85006736212"
"Sghaier M.O.; Hammami I.; Foucher S.; Lepage R.","Sghaier, Moslem Ouled (56421930900); Hammami, Imen (57221369679); Foucher, Samuel (6701728686); Lepage, Richard (56275061200)","56421930900; 57221369679; 6701728686; 56275061200","Flood extent mapping from time-series SAR images based on texture analysis and data fusion","2018","Remote Sensing","10","2","237","","","","10.3390/rs10020237","40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042532275&doi=10.3390%2frs10020237&partnerID=40&md5=3a2e106a2b4e21fd04807b2b76d1823f","Nowadays, satellite images are considered as one of the most relevant sources of information in the context of major disasters management. Their availability in extreme weather conditions and their ability to cover wide geographic areas make them an indispensable tool toward an effective disaster response. Among the various available sensors, Synthetic Aperture Radar (SAR) is distinguished in the context of flood management by its ability to penetrate cloud cover and its robustness to unfavourable weather conditions. This work aims at developing a new technique for flooded areas extraction from high resolution time-series SAR images. The proposed approach is mainly based on three steps: first, homogeneous regions characterizing water surfaces are extracted from each SAR image using a local texture descriptor. Then, mathematical morphology is applied to filter tiny artifacts and small homogeneous areas present in the image. And finally, spatial and radiometric information embedded in each pixel are extracted and are fused with the same pixel information but from another image to decide if the current pixel belongs to a flooded region. In order to assess the performance of the proposed algorithm, our methodology was applied to time-series images acquired before and during three different flooding events: (1) Richelieu River and lake Champlain floods, Quebec, Canada in 2011; (2) Evros River floods, Greece in 2014 and (3) Western and southwestern of Iran floods in 2016. Experiments show that our approach gives very promising results compared to existing techniques. © 2018 by the authors.","Data fusion; Disasters; Extraction; Flood control; Floods; Formal logic; Image fusion; Image processing; Image texture; Mathematical morphology; Meteorology; Pixels; Synthetic aperture radar; Time series; Time series analysis; Dempster-Shafer theory; Extreme weather conditions; Homogeneous regions; Indispensable tools; Pixel information; SAR Images; Sources of informations; Structural feature; Radar imaging","Data fusion; Dempster-Shafer theory; Flood extraction; Mathematical morphology; Structural Feature Set; Time-series SAR images","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85042532275"
"Zhang K.; Wang M.; Yang S.; Jiao L.","Zhang, Kai (56451954400); Wang, Min (55553729000); Yang, Shuyuan (8159166000); Jiao, Licheng (7102491544)","56451954400; 55553729000; 8159166000; 7102491544","Convolution structure sparse coding for fusion of panchromatic and multispectral images","2019","IEEE Transactions on Geoscience and Remote Sensing","57","2","8457487","1117","1130","13","10.1109/TGRS.2018.2864750","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053154901&doi=10.1109%2fTGRS.2018.2864750&partnerID=40&md5=25ae93bff5ec5e500510e0605002a0d7","Recently, sparse coding-based image fusion methods have been developed extensively. Although most of them can produce competitive fusion results, three issues need to be addressed: 1) these methods divide the image into overlapped patches and process them independently, which ignore the consistency of pixels in overlapped patches; 2) the partition strategy results in the loss of spatial structures for the entire image; and 3) the correlation in the bands of multispectral (MS) image is ignored. In this paper, we propose a novel image fusion method based on convolution structure sparse coding (CSSC) to deal with these issues. First, the proposed method combines convolution sparse coding with the degradation relationship of MS and panchromatic (PAN) images to establish a restoration model. Then, CSSC is elaborated to depict the correlation in the MS bands by introducing structural sparsity. Finally, feature maps over the constructed high-spatial-resolution (HR) and low-spatial-resolution (LR) filters are computed by alternative optimization to reconstruct the fused images. Besides, a joint HR/LR filter learning framework is also described in detail to ensure consistency and compatibility of HR/LR filters. Owing to the direct convolution on the entire image, the proposed CSSC fusion method avoids the partition of the image, which can efficiently exploit the global correlation and preserve the spatial structures in the image. The experimental results on QuickBird and Geoeye-1 satellite images show that the proposed method can produce better results by visual and numerical evaluation when compared with several well-known fusion methods. © 2018 IEEE.","Codes (symbols); Convolution; Correlation methods; Glossaries; Image fusion; Image reconstruction; Image resolution; Numerical methods; Petroleum reservoir evaluation; Restoration; Satellite imagery; Convolution structure; High spatial resolution; Image fusion methods; Learning frameworks; Multispectral images; Panchromatic (Pan) image; Sparse coding; Spatial resolution; correlation; GeoEye; image analysis; multispectral image; numerical method; panchromatic image; pixel; QuickBird; satellite imagery; spatial resolution; Image coding","Convolution sparse coding (CSC); image fusion; multispectral (MS) image; panchromatic (PAN) image; structure sparsity","Article","Final","","Scopus","2-s2.0-85053154901"
"Jin W.; Gong F.; Tang B.; Wang S.","Jin, Wei (36076638300); Gong, Fei (57189991691); Tang, Biao (57205486722); Wang, Shangli (57205598031)","36076638300; 57189991691; 57205486722; 57205598031","Cloud Types Identification for Meteorological Satellite Image Using Multiple Sparse Representation Classifiers via Decision Fusion","2019","IEEE Access","7","","8598716","8675","8688","13","10.1109/ACCESS.2018.2890295","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060736129&doi=10.1109%2fACCESS.2018.2890295&partnerID=40&md5=2ac412e166d6a3f7249d335b71d465dd","Meteorological satellite can monitor the weather conditions in large scales effectively; some solutions and researches have been raised for cloud types identification in satellite cloud image analysis. Extracting the features of the satellite image and designing effective classifier play important roles in implementing cloud types identification system. Since different features describe the characteristics of the cloud image in different perspectives, the collaborative utilization of the different features help to improve the accuracy of cloud classification. This paper proposed a new method to identify cloud types from meteorological satellite image using multiple sparse representation classifiers via decision fusion. First, followed by different types of features extracting, multiple sparse representation-based classifiers were trained respectively. Then, the strategy of decision fusion was introduced to fuse the outputs of multiple classifiers. In order to bring about a reasonable fusion rule, the fusion weights were determined by an adaptive iterative procedure, and the iterative procedure was constructed according to the performance of each sub-classifier. Finally, an adaptive weighted fusion was implemented to determine the cloud type according to the outputs of sub-classifiers and their corresponding weights. The experimental results on FY-2G satellite data demonstrate that the proposed method gains higher recognition accuracy than each separated sub-classifier, which suggests that the strategy of decision fusion can take advantage of each sub-classifier. Moreover, the proposed method achieves competitive results when compared with the other state-of-the-art methods. The computation efficiency of the proposed method is also analyzed briefly. © 2013 IEEE.","Image classification; Image enhancement; Iterative methods; Remote sensing; Satellite imagery; Atmospheric remote sensing; Cloud classification; Cloud imagery; Decision fusion; Sparse representation; Image fusion","Atmospheric remote sensing; cloud classification; decision fusion; satellite cloud imagery; sparse representation-based classifier","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85060736129"
"Chang N.-B.; Bai K.; Imen S.; Chen C.-F.; Gao W.","Chang, Ni-Bin (7202467963); Bai, Kaixu (36676931900); Imen, Sanaz (36863826600); Chen, Chi-Farn (7501959001); Gao, Wei (55649026100)","7202467963; 36676931900; 36863826600; 7501959001; 55649026100","Multisensor Satellite Image Fusion and Networking for All-Weather Environmental Monitoring","2018","IEEE Systems Journal","12","2","","1341","1357","16","10.1109/JSYST.2016.2565900","33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973571929&doi=10.1109%2fJSYST.2016.2565900&partnerID=40&md5=fdeba645f086ad0a1278772e8a370d8e","Given the advancements of remote sensing technology, large volumes of remotely sensed images with different spatial, temporal, and spectral resolutions are available. To better monitor and understand the changing Earth's environment, fusion of remotely sensed images with different spatial, temporal, and spectral resolutions is critical for distinctive feature retrieval, interpretation, mapping, and decision analysis. A suite of methods have been developed to fuse multisensor satellite images for different purposes in the past few decades. This paper provides a thorough review of contemporary and classic image fusion methods and presents a summary of their phenomenological applications, with challenges and perspectives, for environmental systems analysis. Cross-mission satellite image fusion, networking, and missing value pixel reconstruction for environmental monitoring are described, and their complex integration is illustrated with a case study of Lake Nicaragua that elucidates the state-of-the-art remote sensing technologies for advancing water quality management. © 2007-2012 IEEE.","Environmental engineering; Environmental management; Environmental technology; Image analysis; Photomapping; Quality management; Remote sensing; Satellites; Spectral resolution; Systems analysis; Water conservation; Water management; Water quality; Complex integrations; Environmental Monitoring; Environmental systems analysis; Feature retrieval; Multi-sensor satellite images; Remote sensing technology; Remotely sensed images; Satellite images; Image fusion","Earth observation; environmental systems engineering; feature extraction; image fusion; remote sensing; satellite networking","Article","Final","","Scopus","2-s2.0-84973571929"
"Li W.; Jiang J.; Guo T.; Zhou M.; Tang Y.; Wang Y.; Zhang Y.; Cheng T.; Zhu Y.; Cao W.; Yao X.","Li, Wei (57205166392); Jiang, Jiale (56289787100); Guo, Tai (57209567732); Zhou, Meng (57203944956); Tang, Yining (57208160329); Wang, Ying (57767139300); Zhang, Yu (56662268900); Cheng, Tao (56278310400); Zhu, Yan (8921604000); Cao, Weixing (55489902600); Yao, Xia (14022139100)","57205166392; 56289787100; 57209567732; 57203944956; 57208160329; 57767139300; 56662268900; 56278310400; 8921604000; 55489902600; 14022139100","Generating red-edge images at 3M spatial resolution by fusing sentinel-2 and planet satellite products","2019","Remote Sensing","11","12","1422","","","","10.3390/rs11121422","15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068177402&doi=10.3390%2frs11121422&partnerID=40&md5=c29bc81d9238fbb43dba448e861a04b9","High-resolution satellite images can be used to some extent to mitigate the mixed-pixel problem caused by the lack of intensive production, farmland fragmentation, and the uneven growth of field crops in developing countries. Specifically, red-edge (RE) satellite images can be used in this context to reduce the influence of soil background at early stages as well as saturation due to crop leaf area index (LAI) at later stages. However, the availability of high-resolution RE satellite image products for research and application globally remains limited. This study uses the weight-and-unmixing algorithm as well as the SUPer-REsolution for multi-spectral Multi-resolution Estimation (Wu-SupReME) approach to combine the advantages of Sentinel-2 spectral and Planet spatial resolution and generate a high-resolution RE product. The resultant fused image is highly correlated (R2 > 0.98) with Sentinel-2 image and clearly illustrates the persistent advantages of such products. This fused image was significantly more accurate than the originals when used to predict heterogeneous wheat LAI and therefore clearly illustrated the persistence of Sentinel-2 spectral and Planet spatial advantage, which indirectly proved that the fusion methodology of generating high-resolution red-edge products from Planet and Sentinel-2 images is possible. This study provided method reference for multi-source data fusion and image product for accurate parameter inversion in quantitative remote sensing of vegetation. © 2019 by the authors.","Crops; Developing countries; Image fusion; Image resolution; Planets; Remote sensing; Fusion image; Sentinel-2; SupReME; Unmixing; Wheat LAI; Satellites","Fusion image; Planet; Sentinel-2; SupReME; Weight-and-unmixing; Wheat LAI","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85068177402"
"Ahmed T.; Singh D.; Gupta S.; Raman B.","Ahmed, Tasneem (55549594300); Singh, Dharmendra (36912015700); Gupta, Shweta (55781518700); Raman, Balasubramanian (23135470700)","55549594300; 36912015700; 55781518700; 23135470700","An efficient application of fusion approach for hot spot detection with MODIS and PALSAR-1 data","2016","Geocarto International","31","7","","715","738","23","10.1080/10106049.2015.1076061","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940571059&doi=10.1080%2f10106049.2015.1076061&partnerID=40&md5=aad2a72c932e9f557050fafa8e5a258b","Hot spot detection with satellite images, especially with synthetic aperture radar (SAR) images is still a challenging task. Several researchers have used TM/optical data for identification of hot spot but the use of SAR data is very limited for this type of application. The fusion of SAR data with TM/optical data may add additional information which in turn will lead for enhancement of detection capability of the hot spot. Therefore, this study explores the possibility of fusion of Moderate Resolution Imaging Spectroradiometer (MODIS) and Phased Array L-band Synthetic Aperture Radar (PALSAR) satellite images for the hot spot detection. Image fusion is emerging as a powerful tool where information of various sensors can be used for obtaining better results. For this purpose, vegetation greenness and roughness information which is obtained from MODIS and PALSAR satellite images, respectively, are used for fusion, and then, a contextual-based thresholding algorithm is applied to the fused image for hot spot detection. The proposed approach comprises of two steps: (1) application of genetic algorithm-based scheme for image fusion of MODIS and PALSAR satellite images, and (2) classification of the fused image as either hot spot or non-hot spot pixels by employing a contextual thresholding technique. The algorithm is tested over the Jharia Coal Field region of India, where hot spot is one of the major problems and it is observed that the proposed thresholding technique classifies the each pixel of the fused image into two categories: hot spot and non-hot spot and the proposed approach detects the hot spot with better accuracy and less false alarm. © 2015 Taylor & Francis.","genetic algorithm; MODIS; PALSAR; satellite data; satellite imagery; threshold; vegetation dynamics; vegetation index","CPR; GEMI; genetic algorithm (GA); hot spots; image fusion; MODIS; MSAVI; PALSAR; polarimetric indices; thresholding; vegetation indices","Article","Final","","Scopus","2-s2.0-84940571059"
"Shin J.-I.; Kim T.; Yoon W.-S.; Park H.-J.","Shin, Jung-Il (37019211900); Kim, Taejung (57205421554); Yoon, Wan-Sang (57202440288); Park, Hyeong-Jun (57212273533)","37019211900; 57205421554; 57202440288; 57212273533","Improving satellite-aerial image matching success rate by image fusion","2018","Proceedings - 2018 2nd European Conference on Electrical Engineering and Computer Science, EECS 2018","","","8910110","224","227","3","10.1109/EECS.2018.00049","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076375697&doi=10.1109%2fEECS.2018.00049&partnerID=40&md5=f6e60a0fc81ced783852de7cc91b4a89","Image matching is an important method to collect ground control points (GCPs) by finding correspondence between incoming images and chips of reference image maps. It is an essential process for automated precise geo-registration of satellite imagery. To get higher georeferencing accuracy, reference chips must be matched precisely on the images. The importance of higher matching success rate is increased with limited number of chips. In this study, we aim to match incoming satellite images against reference chips generated from aerial color ortho-images. Matching the two dataset is difficult since they have different spectral responses as well as different textures. We try to improve matching success rate by using pansharpened satellite images. The results showed higher matching success rate with pansharpened images due to similar spectral range and higher spatial resolution. Therefore, pansharpened image is helpful to improve image matching success rate in automated precise georeferencing of high-resolution satellite imagery. © 2018 IEEE.","Antennas; Image fusion; Image matching; Rock mechanics; Satellite imagery; Textures; Geo-registration; Ground control points; High resolution satellite imagery; Pan-sharpening; Pansharpened images; Satellite images; Spatial resolution; Spectral response; Image enhancement","Image matching; Pan-sharpening; Satellite image","Conference paper","Final","","Scopus","2-s2.0-85076375697"
"Babua D.K.; Schmidtb M.; Dahmsc T.; Conradd C.","Babua, Dinesh Kumar (57200385846); Schmidtb, Marco (57189234332); Dahmsc, Thosten (57190568320); Conradd, Christopher (57193768034)","57200385846; 57189234332; 57190568320; 57193768034","Impact on quality and processing time due to change in pre-processing operation sequence onmoderate resolution satellite images","2016","Proceedings of the International Astronautical Congress, IAC","0","","","","","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016500426&partnerID=40&md5=80b825f83168ac2cd214eda2fe144065","Despite having many Earth orbiting remote sensing satellites, even with the completion of Sentinel 2 constellation the revisit time of satellites over a particular area will only come down to 5 days from 16-26 days revisit time of Landsat, SPOT and IRS satellites. This is still far-off from satisfying the need of daily high spatial resolution images required for crop monitoring and rapid changes in ecosystem. Generation of high spatial remote sensing time series by fusing high temporal moderate resolution images obtained from MODIS, MERIS, SPOTVegetation with low temporal high resolution images obtained from Landsat, SPOT, IRS and Sentinels proved to be cost effective and efficient solution. Images obtained from different sensors cannot be used in the image fusion process directly. The images should be first pre-processed to make it consistent with each other in terms of projection system, pixel size. Usually the high temporal moderate resolution images will be reprojected and resampled to match the low temporal high resolution images. Since everyday moderate resolution images are used for the time series generation, this left us with pre-processing huge amount of image data. This makes the pre-processing operation highly time consuming. It also demands huge disk space for data storage and handling and high computing power for quick processing. Several attempts were made to optimize the pre-processing run time and effective data handling. Preprocessing is a sequential process where the image is processed in several steps. In every individual pre-processing step the complete image data is being used for processing. The concerned study area in the image used in the subsequent image fusion process covers only a fraction of the image. This shows that large amount of image data which is not useful in the subsequent process is also being processed in pre-processing operations. This directly translates to longer pre-processing run time. In this paper a novel technique is proposed to optimize the run time by reducing the amount of image data used in the pre-processing steps. This is done by cropping the image in the first place and using the reduced image data in the pre-processing operations. The proposed method is tested using the Geospatial Data Abstraction Library (GDAL). In this paper different pre-processing sequences are applied on the MODIS 500m resolution data. The output from each sequence is analyzed to study the impact due to the change in pre-processing operation sequence and the results are presented. Copyright © 2016 by the International Astronautical Federation (IAF). All rights reserved.","Cost effectiveness; Data handling; Digital storage; Image fusion; Orbits; Radiometers; Remote sensing; Satellites; Space optics; Time series; GDAL; High resolution image; High spatial resolution images; Image preprocessing; Pre-processing; Pre-processing operations; Remote sensing satellites; Time-series generation; Image processing","GDAL; Image fusion; Image pre-processing; Pre-processing framework; Pre-processing sequence","Conference paper","Final","","Scopus","2-s2.0-85016500426"
"Alexakis D.D.; Sarris A.; Kalaitzidis C.; Papadopoulos N.; Soupios P.","Alexakis, Dimitrios D. (55901750800); Sarris, Apostolos (15019709500); Kalaitzidis, Chariton (15722439200); Papadopoulos, Nikos (55327516400); Soupios, Pantelis (15835749500)","55901750800; 15019709500; 15722439200; 55327516400; 15835749500","Integrated use of satellite remote sensing, GIS, and ground spectroscopy techniques for monitoring olive oil mill waste disposal areas on the island of Crete, Greece","2016","International Journal of Remote Sensing","37","3","","669","693","24","10.1080/01431161.2015.1136444","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955507349&doi=10.1080%2f01431161.2015.1136444&partnerID=40&md5=d94c2644e8da3a31e4c50da652a1a9ea","Olive oil mill wastes (OOMW) constitute a major pollution factor in olive-growing regions and an important problem to be solved for the agricultural industry. Olive oil mill wastes are normally deposited in tanks, or directly into the soil or even on adjacent torrents, rivers, and lakes, posing a high risk of environmental pollution in regard to public health. This study aims to develop integrated satellite remote sensing, geographical information systems (GIS), and ground spectroscopy methodologies to detect and monitor OOMW disposal areas on the island of Crete, Greece in the Southeastern Mediterranean. More than 1000 disposal tanks were mapped through an extended global positioning system (GPS) survey that took place throughout the island. Satellite images of both high (IKONOS) and medium (Landsat 8 OLI (Operational Land Imager)) resolution were preprocessed and analysed by applying geometric, radiometric, and atmospheric corrections. A library with a spectral signature of OOMW including both different time periods and satellite sensors was developed. At the same time, ground spectroscopy campaigns were carried out and a complementary spectral signature library was developed. The narrow band reflectance of ground measurements was recalculated using the relative response filters of the corresponding satellite sensors. Both libraries were compared for their accuracy through statistical approaches and the optimum spectral range for detecting OOMW areas was estimated. Subsequently, further auxiliary image-processing techniques such as image fusion, linear spectral unmixing (LSU), false-colour composites (FCCs), image classification, and principal component analysis (PCA) were applied to satellite images to enhance OOMW patterns, and an innovative OOMW detection index for Landsat 8 was developed. In addition, several vegetation indices were applied and compared in regard to their efficiency in detecting waste ponds. Finally an integrated, semi-automatic methodology was developed in the GIS environment employing classification algorithms for the detection of waste ponds. This study highlights the potential of satellite remote sensing, GIS, and ground spectroscopy in the semi–automatic detection of OOMW disposal areas in the context of the Mediterranean landscape. © 2016 Taylor & Francis.","Aegean Islands; Crete [Greece]; Greece; Agriculture; Classification (of information); Global positioning system; Health risks; Image analysis; Image enhancement; Image fusion; Lakes; Landforms; Oil tanks; Olive oil; Principal component analysis; Remote sensing; River pollution; Satellites; Waste disposal; IKONOS; LANDSAT; Oil-mill waste; Satellite remote sensing; Spectral signature; algorithm; classification; environmental fate; GIS; IKONOS; Landsat; mill; remote sensing; satellite data; spectral resolution; waste disposal; waste management; Geographic information systems","classification; ground spectroscopy; IKONOS; Landsat 8; Olive oil mill wastes (OOMW); satellite remote sensing; spectral signatures","Article","Final","","Scopus","2-s2.0-84955507349"
"Liu X.; Wang Y.; Liu Q.","Liu, Xiangyu (57192693924); Wang, Yunhong (34870959400); Liu, Qingjie (55534263100)","57192693924; 34870959400; 55534263100","Remote Sensing Image Fusion Based on Two-Stream Fusion Network","2018","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10704 LNCS","","","428","439","11","10.1007/978-3-319-73603-7_35","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042122813&doi=10.1007%2f978-3-319-73603-7_35&partnerID=40&md5=4b8e074451051447d2fb76a6d3bd6c53","Remote sensing image fusion (or pan-sharpening) aims at generating high resolution multi-spectral (MS) image from inputs of a high spatial resolution single band panchromatic (PAN) image and a low spatial resolution multi-spectral image. In this paper, a deep convolutional neural network with two-stream inputs respectively for PAN and MS images is proposed for remote sensing image pan-sharpening. Firstly the network extracts features from PAN and MS images, then it fuses them to form compact feature maps that can represent both spatial and spectral information of PAN and MS images, simultaneously. Finally, the desired high spatial resolution MS image is recovered from the fused features using an encoding-decoding scheme. Experiments on Quickbird satellite images demonstrate that the proposed method can fuse the PAN and MS image effectively. © 2018, Springer International Publishing AG.","Convolution; Deep learning; Deep neural networks; Image resolution; Neural networks; Remote sensing; Satellite imagery; Spectroscopy; Convolutional neural network; High spatial resolution; Multispectral images; Pan-sharpening; Panchromatic (Pan) image; QuickBird satellite; Remote sensing images; Spectral information; Image fusion","Convolutional neural networks; Deep learning; Image fusion; Pan-sharpening; Remote sensing","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85042122813"
"Mamatha G.; Sumalatha V.; Lakshmaiah M.V.","Mamatha, G. (57191729663); Sumalatha, V. (57195363358); Lakshmaiah, M.V. (57110351400)","57191729663; 57195363358; 57110351400","FPGA implementation of satellite image fusion using wavelet substitution method","2015","Proceedings of the 2015 Science and Information Conference, SAI 2015","","","7237290","1155","1159","4","10.1109/SAI.2015.7237290","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957836825&doi=10.1109%2fSAI.2015.7237290&partnerID=40&md5=00ee7f55c86665ae39cbf9d5272e64ee","Image fusion is a process of merging the relevant information from a set of images into a single image. The goal of image fusion in remote sensing is to create new images that contain both low spatial resolution multispectral data (color information) and high spatial resolution panchromatic data (details). The choice of appropriate wavelet filters for the design and implementation on FPGA, a detailed analysis has been carried out in MATLAB Simulink R2010b software using averaging, additive and substitutive fusion rules. In this paper substitutive rule using the Haar, Daubechies 3 (db3) and Cohen Daubechies Feauveau (CDF) 9/7 filters are used for image decomposition and reconstruction. CDF 9/7 is found to be the best filter and is chosen for FPGA implementation. Single level 2D-DWT based image fusion has been performed using substitutive method and then the hardware software co-simulation design has been synthesized in Xilinx ISE 13.1 and implemented on ML605 Virtex 6 FPGA kit. From the results, it is observed that the design consumes a total power of 4.349W and operates at a maximum frequency of 849.618MHz. © 2015 IEEE.","Computer software; Data fusion; Discrete wavelet transforms; Field programmable gate arrays (FPGA); Image processing; Image registration; Image resolution; Integrated circuit design; MATLAB; Reconfigurable hardware; Remote sensing; Satellite imagery; Design and implementations; FPGA implementations; Hardware-software co-simulation; High spatial resolution; Image decomposition; Image resampling; Multi-spectral data; Substitution method; Image fusion","DWT; FPGA; Image Fusion; Image Registration; Image Resampling","Conference paper","Final","","Scopus","2-s2.0-84957836825"
"Benedetti P.; Ienco D.; Gaetano R.; Ose K.; Pensa R.G.; Dupuy S.","Benedetti, Paola (57204511715); Ienco, Dino (25027558600); Gaetano, Raffaele (23491959900); Ose, Kenji (26967944200); Pensa, Ruggero G. (8984218100); Dupuy, Stephane (36004740600)","57204511715; 25027558600; 23491959900; 26967944200; 8984218100; 36004740600","                         M                         3                         Fusion: A Deep Learning Architecture for Multiscale Multimodal Multitemporal Satellite Data Fusion                     ","2018","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","11","12","8516352","4939","4949","10","10.1109/JSTARS.2018.2876357","51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055877123&doi=10.1109%2fJSTARS.2018.2876357&partnerID=40&md5=521586202aa1a2448e5914b587ba04fa","Modern Earth Observation systems provide remote sensing data at different temporal and spatial resolutions. Among all the available spatial mission, today the Sentinel-2 program supplies high temporal (every five days) and high spatial resolution (HSR) (10 m) images that can be useful to monitor land cover dynamics. On the other hand, very HSR (VHSR) imagery is still essential to figure out land cover mapping characterized by fine spatial patterns. Understanding how to jointly leverage these complementary sources in an efficient way when dealing with land cover mapping is a current challenge in remote sensing. With the aim of providing land cover mapping through the fusion of multitemporal HSR and VHSR satellite images, we propose a suitable end-To-end deep learning framework, namely M3text{Fusion}, which is able to simultaneously leverage the temporal knowledge contained in time series data as well as the fine spatial information available in VHSR images. Experiments carried out on the Reunion Island study area confirm the quality of our proposal considering both quantitative and qualitative aspects. © 2008-2012 IEEE.","Mascarene Islands; Reunion; Data fusion; Deep learning; Feature extraction; Image fusion; Image resolution; Knowledge management; Remote sensing; Satellite imagery; Satellites; Time series analysis; Land cover mapping; Satellite images; sentinel-2; Spatial resolution; Very high spatial resolutions; data quality; land cover; mapping; satellite data; satellite imagery; Sentinel; spatial resolution; time series; Mapping","Data fusion; deep learning; land cover mapping; satellite image time series; sentinel-2; very high spatial resolution (VHSR)","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85055877123"
"Chaudhari P.M.; Mahajan S.P.","Chaudhari, Pallavi M. (57202903578); Mahajan, Shrinvas P. (24824924000)","57202903578; 24824924000","Pixel based satellite image fusion using dual-tree complex and Curvelet transform","2018","International Conference on Recent Innovations in Signal Processing and Embedded Systems, RISE 2017","2018-January","","","264","268","4","10.1109/RISE.2017.8378164","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049730549&doi=10.1109%2fRISE.2017.8378164&partnerID=40&md5=993669949b02e4b3eebffcf65d56c15b","Multisensory Image fusion is the operation of combining complementary information from two or more source images into a single fused image. The fused image will supply supplementary information from source images and reduce the redundancy. Satellite image fusion is the process of fusion between high spectral but low resolution multispectral and low-spectral but high-resolution panchromatic images. Traditional fusion methods can't give the image with high spectral and spatial resolution. Fusion using DWT achieve an image with high spectral information but failed to provide spatial information and it has less sharpness in fused image. But using Curvelet transform we get a fused image with high spatial and spectral information with more sharpness. © 2017 IEEE.","Embedded systems; Signal processing; component; formatting; Insert (key words); style; styling; Image fusion","component; formatting; insert (key words); style; styling","Conference paper","Final","","Scopus","2-s2.0-85049730549"
"Liu Y.; Wu W.; Li Z.; Zhou Q.","Liu, Yizhu (57201062912); Wu, Wenbin (55707483300); Li, Zhaoliang (7409077047); Zhou, Qingbo (22235963800)","57201062912; 55707483300; 7409077047; 22235963800","Extracting irrigated cropland spatial distribution in China based on time-series NDVI","2017","Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering","33","22","","276","284","8","10.11975/j.issn.1002-6819.2017.22.036","10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043238198&doi=10.11975%2fj.issn.1002-6819.2017.22.036&partnerID=40&md5=2ca7733436579dadd7915a6e0f6eb8af","Geospatial information of irrigated cropland is necessary for the formulation of food policy, water management and climate change studies. In addition to those methods based on pure image classification or non-remote sensing data, spatial reconstruction of statistics by using remote sensing features, a branch of multi-data fusion, with the advantages of less relying on the sampling points with a good consistency with the statistical data, has played an important role in land cover mapping. However, it gains less attention in regional irrigated cropland extraction, which makes it unclear about its applicability in different regions. In this paper, we firstly tested a fusion method based on NDVI data and statistical data of spatial distribution of irrigated cropland in China. Then, quantitative and spatial accuracy assessment and comparisons with other datasets were also carried out for the sake of discussing the availability of the map. Finally, the possible factors reducing the accuracy of classification were discussed. The results showed that the ratio of irrigation farming decreased and the fragmentation of irrigated croplands increased gradually from east to west. Huang-Huai-Hai and Yangtze River plant regions were the places with the most concentrated irrigation. While in the locations with low precipitation such as northeastern and northwestern areas, irrigation farming was distributed along local water resources. Those irrigation areas were all consistent with the recognized irrigation areas. Quantitatively, the relative errors of more than 90% counties were within 5%, and most of the counties with high relative error (>30%) belonged to Shanxi while the rest were shared by several other provinces. From the view of absolute error, the number of negative ones was much less than positive ones, and this rule was also appropriate on province scale. The total spatial accuracy of the new map was 64.20%, but the values ranged from 31.21% to 90.64% on province scale. Provinces with the accuracies higher than average level were mostly distributed in the eastern areas of the country, and the precision level went lower from north to south. Meanwhile, there was no apparent geographical rule in west. Referring to the comparisons with similar datasets, this fusion method of statistic and remote sensing data could not only perform better quantitatively, but also provide more spatial details than data fusion method without satellite images. In addition, it maintained a same spatial accuracy level with the image classification but accelerated the operating process. These indicated that, the output of the method was both quantitatively and qualitatively comparable to that of similar method in China, yet there was a certain distance with its first application in America. Analysis suggested that, the cropland mask, the method hypothesis and the selected features are the major factors which largely influence the mapping accuracy, so the improvement of the method relies on better cropland maps, and optimization of geographical and spectral features. © 2017, Editorial Department of the Transactions of the Chinese Society of Agricultural Engineering. All right reserved.","Climate change; Data fusion; Errors; Forestry; Image classification; Image fusion; Image processing; Importance sampling; Irrigation; Photomapping; Remote sensing; Sampling; Spatial distribution; Statistics; Water management; Water resources; Accuracy of classifications; Data fusion methods; Geo-spatial informations; Irrigated cropland; Land cover mapping; NDVI; Remote sensing data; Spatial reconstruction; Mapping","Data fusion; Irrigated cropland; NDVI; Spatial distribution","Article","Final","","Scopus","2-s2.0-85043238198"
"Naik V.V.; Gharge S.","Naik, Vineet Vilas (57192688488); Gharge, Saylee (56572733800)","57192688488; 56572733800","Satellite image resolution enhancement using DTCWT and DTCWT based fusion","2016","2016 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2016","","","7732338","1957","1962","5","10.1109/ICACCI.2016.7732338","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007352806&doi=10.1109%2fICACCI.2016.7732338&partnerID=40&md5=ae54b67369724205b60fa848a338848d","To increase the resolution of any image, interpolation techniques are adopted. The high frequency components in the low resolution (LR) image are lost when the images are interpolated. To overcome this problem a new satellite image resolution enhancement algorithm based on Dual Tree Complex Wavelet transform (DTCWT) and its rotated version have been proposed. DTCWT and Rotated DTCWT give 32 subbands of an image, out of which 24 are high frequency (HF) subbands which give 12 different angular information and 8 are low frequency (LF) subbands. The HF subbands are interpolated by Lanczos Interpolation to preserve the high frequency contents of the image. Non Local Means (NLM) filtering is used to eliminate the artifacts which are generated by DTCWT and rotated DTCWT. To obtain the two enhanced high resolution images inverse transforms are performed over respective subbands. The final two high resolution (HR) images are fused together with DTCWT based fusion to give resolution enhanced HR image. To evaluate the performance of the proposed algorithm three performance parameters namely PSNR, SSIM and Q-Index are evaluated for a database of 60 grayscale images of resolution 256×256. The subjective and objective results are compared with the existing techniques to prove the superiority of the proposed algorithm. © 2016 IEEE.","Image resolution; Information science; Interpolation; Inverse transforms; Partial discharges; Trees (mathematics); Wavelet transforms; Dual tree complex wavelet transform (DT-CWT); Dual-tree complex wavelet transform; High frequency components; High resolution image; Interpolation techniques; Non local means (NLM); Performance parameters; Resolution enhancement; Image fusion","Dual Tree Complex Wavelet Transform (DTCWT]!; Non Local Means (NLM) filtering; Resolution Enhancement (RE)","Conference paper","Final","","Scopus","2-s2.0-85007352806"
"Zhang Y.; Foody G.M.; Ling F.; Li X.; Ge Y.; Du Y.; Atkinson P.M.","Zhang, Yihang (55658053900); Foody, Giles M. (7007014233); Ling, Feng (56278268300); Li, Xiaodong (55878368700); Ge, Yong (26655529300); Du, Yun (56420121700); Atkinson, Peter M. (7201906181)","55658053900; 7007014233; 56278268300; 55878368700; 26655529300; 56420121700; 7201906181","Spatial-temporal fraction map fusion with multi-scale remotely sensed images","2018","Remote Sensing of Environment","213","","","162","181","19","10.1016/j.rse.2018.05.010","23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047057538&doi=10.1016%2fj.rse.2018.05.010&partnerID=40&md5=f79120e0d8f0ee5cbc0f2ec3e93b8e3f","Given the common trade-off between the spatial and temporal resolutions of current satellite sensors, spatial-temporal data fusion methods could be applied to produce fused remotely sensed data with synthetic fine spatial resolution (FR) and high repeat frequency. Such fused data are required to provide a comprehensive understanding of Earth's surface land cover dynamics. In this research, a novel Spatial-Temporal Fraction Map Fusion (STFMF) model is proposed to produce a series of fine-spatial-temporal-resolution land cover fraction maps by fusing coarse-spatial-fine-temporal and fine-spatial-coarse-temporal fraction maps, which may be generated from multi-scale remotely sensed images. The STFMF has two main stages. First, FR fraction change maps are generated using kernel ridge regression. Second, a FR fraction map for the date of prediction is predicted using a temporal-weighted fusion model. In comparison to two established spatial-temporal fusion methods of spatial-temporal super-resolution land cover mapping model and spatial-temporal image reflectance fusion model, STFMF holds the following characteristics and advantages: (1) it takes account of the mixed pixel problem in FR remotely sensed images; (2) it directly uses the fraction maps as input, which could be generated from a range of satellite images or other suitable data sources; (3) it focuses on the estimation of fraction changes happened through time and can predict the land cover change more accurately. Experiments using synthetic multi-scale fraction maps simulated from Google Earth images, as well as synthetic and real MODIS-Landsat images were undertaken to test the performance of the proposed STFMF approach against two benchmark spatial-temporal reflectance fusion methods: the Enhanced Spatial and Temporal Adaptive Reflectance Fusion Model (ESTARFM) and the Flexible Spatiotemporal Data Fusion (FSDAF) model. In both visual and quantitative evaluations, STFMF was able to generate more accurate FR fraction maps and provide more spatial detail than ESTARFM and FSDAF, particularly in areas with substantial land cover changes. STFMF has great potential to produce accurate time-series fraction maps with fine-spatial-temporal-resolution that can support studies of land cover dynamics at the sub-pixel scale. © 2018 Elsevier Inc.","Benchmarking; Economic and social effects; Image enhancement; Optical resolving power; Photomapping; Pixels; Reflection; Regression analysis; Remote sensing; Satellite imagery; Kernel ridge regressions; Land cover; Quantitative evaluation; Remotely sensed images; Spatial and temporal resolutions; Spatial temporals; Spectral unmixing; Super-resolution mappings; benchmarking; land cover; Landsat; mapping; MODIS; prediction; regression analysis; remote sensing; research work; satellite data; satellite imagery; sensor; spatial resolution; spatiotemporal analysis; Image fusion","Fraction maps; Land cover; Spatial-temporal fusion; Spectral unmixing; Super-resolution mapping","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85047057538"
"Li S.; Tang H.","Li, Shaodan (56654516800); Tang, Hong (36816706600)","56654516800; 36816706600","Building damage extraction triggered by earthquake using the UAV imagery","2018","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","3","","929","936","7","10.5194/isprs-archives-XLII-3-929-2018","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046957318&doi=10.5194%2fisprs-archives-XLII-3-929-2018&partnerID=40&md5=6c53d1f567ce4bd67ea8f47029133d8a","When extracting building damage information, we can only determine whether the building is collapsed using the post-earthquake satellite images. Even the satellite images have the sub-meter resolution, the identification of slightly damaged buildings is still a challenge. As the complementary data to satellite images, the UAV images have unique advantages, such as stronger flexibility and higher resolution. In this paper, according to the spectral feature of UAV images and the morphological feature of the reconstructed point clouds, the building damage was classified into four levels: basically intact buildings, slightly damaged buildings, partially collapsed buildings and totally collapsed buildings, and give the rules of damage grades. In particular, the slightly damaged buildings are determined using the detected roof-holes. In order to verify the approach, we conduct experimental simulations in the cases of Wenchuan and Ya'an earthquakes. By analyzing the post-earthquake UAV images of the two earthquakes, the building damage was classified into four levels, and the quantitative statistics of the damaged buildings is given in the experiments. © Authors 2018. CC BY 4.0 License.","Earthquakes; Image fusion; Image processing; Remote sensing; Satellites; Unmanned aerial vehicles (UAV); Building damage; Collapsed buildings; Complementary data; Earthquake disaster; Experimental simulations; Extracting buildings; Morphological features; Point cloud; Buildings","Building damage information; Earthquake disasters; Image fusion; Point clouds; UAV imagery","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85046957318"
"Bhandi V.; Sumithra Devi K.A.","Bhandi, Vijayakumar (57216628878); Sumithra Devi, K.A. (37073625600)","57216628878; 37073625600","Image Retrieval by Fusion of Features from Pre-trained Deep Convolution Neural Networks","2019","1st International Conference on Advanced Technologies in Intelligent Control, Environment, Computing and Communication Engineering, ICATIECE 2019","","","9063814","35","40","5","10.1109/ICATIECE45860.2019.9063814","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084110074&doi=10.1109%2fICATIECE45860.2019.9063814&partnerID=40&md5=b0248af8600d2ac7042b079511a87cbe","Image retrieval is a challenging problem in computer vision domain. Traditional content based image retrieval (CBIR) systems were built to retrieve images based on low level content representations like color, texture and shape. These domain specific handcrafted features performed well in various image retrieval applications. The choice of image features greatly affects the performance of such systems. Also, one needs deeper understanding of the domain in order to choose right features for image retrieval application. Recent advances in image retrieval focus on creating features which are domain independent. Machine learning can help to learn important representations from images. Convolution neural networks (CNN) are an important class of machine learning models. CNNs can derive high-level multi-scale features from image data. CNNs with deep layers are widely used in image classification problems. Creating a new effective deep CNN model requires huge training time, computing resources and big datasets. There are many deep CNN models like VGG16, ResNet, Alexnet etc., which are pre-trained on huge datasets and model weights are shared for transferring the learnt knowledge to new domains. Pre-trained CNNs can be applied to image retrieval problem by extracting features from fully connected layers of the model before output layer. In this work, two leading pre-trained CNN models VGG16 and ResNet are used to create a CBIR method. Learnt features from these pre-trained models are used to create a fusion feature and use them for image retrieval. The proposed CBIR framework is applied to image retrieval problem in a different domain, satellite images. © 2019 IEEE.","Content based retrieval; Convolution; Deep neural networks; Image fusion; Machine learning; Textures; Content representation; Contentbased image retrieval (CBIR) system; Convolution neural network; Domain independents; Extracting features; Machine learning models; Multi-scale features; Retrieval applications; Search engines","Content based image retrieval; Deep convolution neural networks; Learnt features; ResNet; VGG16","Conference paper","Final","","Scopus","2-s2.0-85084110074"
"Jeevanand N.; Verma P.A.; Saran S.","Jeevanand, Nithya (57204876309); Verma, Prabhakar Alok (57189896345); Saran, Sameer (7003795359)","57204876309; 57189896345; 7003795359","Fusion of hyperspectral and multispectral imagery with regression kriging and the LULU operators; A comparison","2018","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","5","","583","588","5","","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057626721&partnerID=40&md5=1a3a8b8f0165aae868e32d7c6b7db234","In this digital world, there is a large requirement of high resolution satellite image. Images at a low resolution may contain relevant information that has to be integrated with the high resolution image to obtain the required information. This is being fulfilled by image fusion. Image fusion is merging of different resolution images into a single image. The output image contains more information, as the information is integrated from both the images Image fusion was conducted with two different algorithms: regression kriging and the LULU operators. First, regression Kriging estimates the value of a dependent variable at unsampled location with the help of auxiliary variables. Here we used regression Kriging with the Hyperion image band as the response variables and the LISS III image bands are the explanatory variables. The fused image thus has the spectral variables from Hyperion image and the spatial variables from the LISS III image. Second, the LULU operator is an image processing methods that can be used as well in image fusion technique. Here we explored to fuse the Hyperion and LISS III image. The LULU operators work in three stages of the process, viz the decomposition stage, the fusion and the reconstruction stage. Quality aspects of the fused image for both techniques have been compared for spectral quality (correlation) and spatial quality (entropy). The study concludes that the quality of the fused image obtained with regression kriging is better than that obtained with the LULU operator. © 2018 International Society for Photogrammetry and Remote Sensing. All Rights Reserved.","Classification (of information); Image processing; Interpolation; Regression analysis; High resolution image; High resolution satellite images; Image fusion techniques; Image processing - methods; LULU operators; Multi-spectral imagery; Regression-kriging; Slums; Image fusion","Classification; Image fusion; LULU operators; Regression Kriging; Slums","Conference paper","Final","","Scopus","2-s2.0-85057626721"
"Ren R.; Gu L.; Fu H.; Sun C.","Ren, Ruizhi (15835523400); Gu, Lingjia (15834718400); Fu, Haoyang (56727208100); Sun, Chenglin (35216653800)","15835523400; 15834718400; 56727208100; 35216653800","Super-resolution algorithm based on sparse representation and wavelet preprocessing for remote sensing imagery","2017","Journal of Applied Remote Sensing","11","2","026014","","","","10.1117/1.JRS.11.026014","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021652863&doi=10.1117%2f1.JRS.11.026014&partnerID=40&md5=d88902d678b61c4edcba4994255a96f3","An effective super-resolution (SR) algorithm is proposed for actual spectral remote sensing images based on sparse representation and wavelet preprocessing. The proposed SR algorithm mainly consists of dictionary training and image reconstruction. Wavelet preprocessing is used to establish four subbands, i.e., low frequency, horizontal, vertical, and diagonal high frequency, for an input image. As compared to the traditional approaches involving the direct training of image patches, the proposed approach focuses on the training of features derived from these four subbands. The proposed algorithm is verified using different spectral remote sensing images, e.g., moderate-resolution imaging spectroradiometer (MODIS) images with different bands, and the latest Chinese Jilin-1 satellite images with high spatial resolution. According to the visual experimental results obtained from the MODIS remote sensing data, the SR images using the proposed SR algorithm are superior to those using a conventional bicubic interpolation algorithm or traditional SR algorithms without preprocessing. Fusion algorithms, e.g., standard intensity-hue-saturation, principal component analysis, wavelet transform, and the proposed SR algorithms are utilized to merge the multispectral and panchromatic images acquired by the Jilin-1 satellite. The effectiveness of the proposed SR algorithm is assessed by parameters such as peak signal-to-noise ratio, structural similarity index, correlation coefficient, root-mean-square error, relative dimensionless global error in synthesis, relative average spectral error, spectral angle mapper, and the quality index Q4, and its performance is better than that of the standard image fusion algorithms. © 2017 Society of Photo-Optical Instrumentation Engineers (SPIE).","Errors; Image fusion; Image reconstruction; Image segmentation; Mean square error; Optical resolving power; Principal component analysis; Radiometers; Satellite imagery; Signal to noise ratio; Spectrometers; Wavelet transforms; Intensity hue saturations; Moderate resolution imaging spectroradiometer; Peak signal to noise ratio; Sparse representation; Structural similarity indices; Super resolution; Super resolution algorithms; Wavelet transformations; Remote sensing","Chinese Jilin-1 satellite imagery; image fusion; moderate-resolution imaging spectroradiometer; sparse representation; super-resolution; wavelet transformation","Article","Final","","Scopus","2-s2.0-85021652863"
"Guan K.; Li Z.; Rao L.N.; Gao F.; Xie D.; Hien N.T.; Zeng Z.","Guan, Kaiyu (56382070400); Li, Zhan (36193003800); Rao, Lakshman Nagraj (57202462415); Gao, Feng (56486548700); Xie, Donghui (7202588306); Hien, Ngo The (57202465706); Zeng, Zhenzhong (55068709500)","56382070400; 36193003800; 57202462415; 56486548700; 7202588306; 57202465706; 55068709500","Mapping paddy rice area and yields over Thai binh province in viet nam from MODIS, Landsat, and ALOS-2/PALSAR-2","2018","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","11","7","","2238","2252","14","10.1109/JSTARS.2018.2834383","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048482869&doi=10.1109%2fJSTARS.2018.2834383&partnerID=40&md5=2a378a5e56a8a22667cff2d1de4d5137","This study uses multiple satellite datasets to map paddy rice areas and yields for the Thai Binh Province, Viet Nam, over the summer growing season of 2015. The major datasets used are: first, surface reflectance and vegetation indices (VI) by fusing the optical observations from the Landsat sensors and the MODerate Resolution Imaging Spectroradiometer; and second, the L-band radar data from the PALSAR-2 sensor onboard the Advanced Land Observing Satellite 2. We find that although the fused VI time series are not necessarily beneficial for paddy rice mapping, the fusion datasets reduce observational gaps and allow us to better identify peak VI values and derive their empirical relationships with crop-cutting yield data (R^{2}= {\text{0.4}} for all the rice types, and R^{2}= {\text{0.69}} for the dominant rice type -58% of all the sampled fields). The L-band radar data have slightly lower performance in rice mapping than the optical satellite data, while it has much less contribution to yield estimation than the optical data. Furthermore, our study suggests the geolocation errors of satellite images be taken into account when selecting small sample areas for crop cutting. This practice will ensure the representativeness of crop-cutting sample areas with regard to satellite observations and thus better linkages between field data and satellite pixels for yield modeling. We also highlight the need of crop-cutting data from multiple years and/or at different regions to account for the spatial and temporal variations of harvest index to improve the spatially explicit rice yield estimates through satellite observations. © 2008-2012 IEEE.","Thai Binh; Viet Nam; Agriculture; Crops; Earth (planet); Image fusion; Mapping; Optical sensors; Production; Radiometers; Remote sensing; Satellite imagery; Satellites; Spectrometers; Advanced land observing satellites; Crop yield; LANDSAT; Moderate resolution imaging spectroradiometer; MODIS; Paddy rice; Viet Nam; agricultural application; ALOS; crop yield; cropping practice; growing season; image processing; Landsat; MODIS; paddy field; PALSAR; satellite data; vegetation mapping; Space-based radar","Advanced Land Observing Satellite 2 (ALOS-2); agriculture; crop yield; image fusion; Landsat; moderate resolution imaging spectroradiometer (MODIS); paddy rice; Viet Nam","Article","Final","","Scopus","2-s2.0-85048482869"
"Gharbia R.; El Baz A.H.; Hassanien A.E.","Gharbia, Reham (57210330680); El Baz, Ali Hassan (15841799500); Hassanien, Aboul Ella (57192178208)","57210330680; 15841799500; 57192178208","An adaptive image fusion rule for remote sensing images based on the particle swarm optimization","2017","Proceeding - IEEE International Conference on Computing, Communication and Automation, ICCCA 2016","","","7813903","1080","1085","5","10.1109/CCAA.2016.7813903","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011066949&doi=10.1109%2fCCAA.2016.7813903&partnerID=40&md5=5cf7c7f143728c0d7a7423d9b7daf628","This paper proposes an adaptive remote sensing image fusion technique based on the particle swarm optimization (PSO) to get the optimum fused image. Firstly, the principal component analysis (PCA) is applied such as feature extraction. The PCA is applied to the multi-spectral (MS) images to concentrate the spatial resolution. Secondly, the discrete cosine transform (DCT) transforms the images into the frequency domain. Thirdly, the particle swarm optimization (PSO) is used to obtain an adaptive weight of the fusion rule. Then, the adaptive fusion rule is applied to the DCT coefficients. Finally, the fused image is obtained through the inverse of principal component analysis (IPCA) and the inverse of the discrete cosine transform (IDCT). The different satellite sensors have different characteristics in reflecting spectral and spatial information of the same scene. Therefore, the proposed technique was implemented on many satellite images such as MODIS, ETM+, SPOT, ASTER and MSS satellite. The experimental results demonstrated that the adaptive remote sensing image fusion technique based on the PSO preserves the spectral resolution and improves the spatial information. © 2016 IEEE.","Cosine transforms; Discrete cosine transforms; Feature extraction; Frequency domain analysis; Image analysis; Image compression; Image reconstruction; Inverse transforms; Particle swarm optimization (PSO); Principal component analysis; Quality control; Remote sensing; Satellite imagery; Satellites; Discrete Cosine Transform(DCT); Fusion quality; Fusion rule; Multi sensor images; Multi-spectral; Image fusion","Adaptive image fusion rule; discrete cosine transform (DCT); image fusion quality metrics; Multi-sensor image fusion; panchromatic (Pan) and multi-spectral(MS) image; principal component analysis (PCA); Remote sensing; the particle swarm optimization (PSO)","Conference paper","Final","","Scopus","2-s2.0-85011066949"
"Goyal M.; Rajan K.S.","Goyal, Mayank (57200607787); Rajan, K.S. (56397697900)","57200607787; 56397697900","Object based fusion of multi-sensor imagery while preserving spectrally significant information","2017","International Geoscience and Remote Sensing Symposium (IGARSS)","2017-July","","8127884","4028","4031","3","10.1109/IGARSS.2017.8127884","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041833446&doi=10.1109%2fIGARSS.2017.8127884&partnerID=40&md5=2895ecb69a5823d8608587a6838aa679","Data fusion is a prevalent method to extract the best combination of satellite images from different modalities - spectral, spatial, temporal. A new method of object-based fusion of high resolution multispectral (MS) and panchromatic (PAN) images is proposed in this paper, which emphasizes on spectral characteristics preservation. It is a hybrid approach where individual objects detected in the images are considered for mapping data and information transfer is done on a per-pixel basis. In addition, the paper proposes a quantitative assessment measure to assess the spectral distortion of the fused outcomes. The quantitative results demonstrate that the proposed method is better in terms of preserving spectral characteristics as compared to other widely used methods such as Principle Component (PC) based fusion, Intensity Hue Saturation (IHS) based fusion and Color Normalization (CN) or Brovey. © 2017 IEEE.","","Multi sensor image fusion; Object based image fusion; Spectral distortion","Conference paper","Final","","Scopus","2-s2.0-85041833446"
"You J.; Pei Z.; Wang F.; Wu Q.; Guo L.","You, Jiong (35197618800); Pei, Zhiyuan (12241096000); Wang, Fei (57218131599); Wu, Quan (35786787500); Guo, Lin (35169490200)","35197618800; 12241096000; 57218131599; 35786787500; 35169490200","Area extraction of winter wheat at county scale based on modified multivariate texture and GF-1 satellite images","2016","Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering","32","13","","131","139","8","10.11975/j.issn.1002-6819.2016.13.019","17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975116965&doi=10.11975%2fj.issn.1002-6819.2016.13.019&partnerID=40&md5=b5cb0d74e578d8d6e3e0c212c25c5a44","Winter wheat is grown in a wider area in China. Monitoring its planting area is therefore a key link for national food security. And area extraction is based on the availability of data source. As the first new satellite of GF series domestic satellites, GF-1 satellite realizes the combination of high spatial resolution, multi-spectrum, and wide field of view (WFV) which has been applied in agricultural monitoring nearly three years. It is necessary to evaluated GF-1 imagery for agricultural applications, especially for the planting area monitoring of food crops. In this paper, we studied the effectiveness of area extraction of winter wheat at a county scale using the WFV imagery from GF-1 satellite. An approach using both spectral information and multivariate texture was proposed in order to make full use of spatial structure information in satellite imagery to further improve classification accuracy of the stable crop. Firstly, the multivariate texture was extracted through modeling based on the modification of multivariate variogram, and the model parameter measured spatial correlation with respect to all the bands of a multispectral image was designed as a distance metric computed by mapping the Mahalanobis distance between spatial point pair into the Euclidean space so that the Mahalanobis distance can be computed as Euclidean distance. We realized this transformation through the Cholesky decomposition of the covariance matrix item in the Mahalanobis distance expression. Then the derived multivariate texture image was combined with spectral data, and the fusion of spectral and texture information was input into the supervised classification technique of support vector machine to identify winter wheat. Two GF-1 images acquired on November 2013 and January 2014 with four spectral bands (blue, green, red, and near-infrared) and 16 m pixel size covering the large area of winter wheat in Suixi county in Anhui province were selected as remotely sensed data source. Classifications were generated based on the proposed method using the modified multivariate texture information and other two traditional methods using spectral data alone and plus traditional texture images at bi-temporal, respectively. Accuracy assessments based on test samples were used to evaluate classification results. Compared with those from other two traditional methods, classification results from the proposal method had a significant improvement with the overall accuracy of 4.12% and 2.36% in seeding stage, and with the overall accuracy of 2.59% and 0.94% in overwintering stage. Z-test statistics were computed for paired comparisons among three classification results at bi-temporal respectively, and the confidence level values were all less than 2.5%. Comparative analysis was carried out by computing the relative errors between the extracted area from classification results of the proposed method and the statistical area for winter wheat in some certain quadrats. With no consideration of the possible objective influence from imaging quality, phenology or measurement precision of quadrats, accuracies of the extracted area from classification results of the proposed method in quadrats were generally better than 90%. Then a Rapideye image covering the same area acquired on April 2014 with a higher resolution was used as a reference to evaluate the availability of the proposal method in the larger test regions with size of 5 km × 5 km. Consistency of the extracted area of winter wheat from classifications using GF-1 images and the reference data from Rapideye image in test regions were able to achieve nearly 97% when winter wheat grown stably. From the results of experiments, it was found that fusion of multivariate texture and spectral information with GF-1 satellite images could significantly improve the overall accuracy of winter wheat identification, and the proposed approach presented in this study also can be useful for different crops in other regions. © 2016, Editorial Department of the Transactions of the Chinese Society of Agricultural Engineering. All right reserved.","Agricultural machinery; Agriculture; Covariance matrix; Crops; Extraction; Food supply; Image acquisition; Image fusion; Image processing; Image texture; Information use; Infrared devices; Linear transformations; Remote sensing; Satellite imagery; Satellites; Statistical tests; Textures; Agricultural monitoring; Classification accuracy; County scale; Features fusions; High spatial resolution; Spatial structure information; Supervised classification; Winter wheat; Classification (of information)","Area extraction; County scale; Features fusion; Remote sensing; Satellites; Textures; Winter wheat","Article","Final","","Scopus","2-s2.0-84975116965"
"Taxak N.; Singhal S.","Taxak, Nidhi (57210554936); Singhal, Sachin (57210563107)","57210554936; 57210563107","High PSNR based Image Fusion by Weighted Average Brovery Transform Method","2019","Proceedings of 3rd International Conference on 2019 Devices for Integrated Circuit, DevIC 2019","","","8783400","451","455","4","10.1109/DEVIC.2019.8783400","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070933402&doi=10.1109%2fDEVIC.2019.8783400&partnerID=40&md5=c806facecea70ac73d818f7f296d46b5","Image Fusion is a method, in which two relevant Image get combine and generate a new Image. The generated image has excellent clarity as compared to the previous input image. Image Fusion Technique is improving the performance of the images and increase the application of Image Fusion. In the Base paper, they present Image Fusion for Two-Dimensional Multiresolution 2-D image. The applications of the Image fusion is using various fields like multi - Focus Images, CT, Multi-Sensor Satellite image and MR of the Human Brain. In this Paper, working for improve PSNR(Peak Signal to Noise Ratio) and Reduce to MSE (Mean Square Error). For improve the performance of Image fusion using Weighted Average Brovery Transform. In the base paper, PSNR and MSE are comparing by use PCA, DWT, DWT-PCA, DCT-PCA, DWT-DCT-PCA methods. Proposed Weighted Average Brovery Transform method is showing better results as compare to base paper results. © 2019 IEEE.","Discrete cosine transforms; Discrete wavelet transforms; Image enhancement; Image fusion; Image segmentation; Integrated circuits; Mean square error; Signal reconstruction; Signal to noise ratio; Wavelet transforms; Fused images; Fusion performance evaluation; Image fusion techniques; Multi sensor images; Multi-sensor satellite images; PSNR (peak signal to noise ratio); Transform methods; Weighted averages; Computerized tomography","Fused Images; Image Fusion; Image Fusion Performance Evaluation Metrics; Multi-Resolution; multi-resolution SVD; Multi-sensor image fusion; Wavelet based Fusion; Wavelet Transform","Conference paper","Final","","Scopus","2-s2.0-85070933402"
"Kalaivani K.; Phamila A.V.","Kalaivani, K. (57356275100); Phamila, Asnath Victy (55578679400)","57356275100; 55578679400","Pixel level fusion of multi temporal landsat images using discrete wavelet transform for detecting changes","2017","Journal of Advanced Research in Dynamical and Control Systems","9","5","","125","130","5","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025649534&partnerID=40&md5=87ab7a285905d3b332b719d347ae6df7","Landsat Thematic Images acquired at various intervals helps to measure the environmental changes. This paper presents a discrete wavelet based pixel level fusion of multitemporal landsat Thematic Mapper(TM) images of the same geographical area captured at periodic intervals to extract the essential information required to assess and monitor the changes occurred between the acquisition dates. The multispectral bands of the images were used in constructing the fusion decision map. The approximation coefficients of wavelet decomposition of the input images were averaged. The maximum intensity of the horizontal, vertical and diagonal coefficients among the input images were computed in constructing the fused image. The resultant fused image is analyzed based on the statistical measures such as relative mean difference, variation difference, contrast similarity and correlation coefficient. The experimental results show that the proposed approach is effective in fusing the satellite images for better image interpretation. © 2017 Institute of Advanced Scientific Research, Inc. All rights reserved.","","Change Detection; Discrete Wavelet Transform (DWT); Image Fusion; Multi-temporal Images; Remote Sensing","Article","Final","","Scopus","2-s2.0-85025649534"
"Kwan C.; Zhu X.; Gao F.; Chou B.; Perez D.; Li J.; Shen Y.; Koperski K.; Marchisio G.","Kwan, Chiman (7201421216); Zhu, Xiaolin (55696724800); Gao, Feng (56486548700); Chou, Bryan (57197859877); Perez, Daniel (57615948600); Li, Jiang (56226550100); Shen, Yuzhong (12805813200); Koperski, Krzysztof (6603540174); Marchisio, Giovanni (6602723609)","7201421216; 55696724800; 56486548700; 57197859877; 57615948600; 56226550100; 12805813200; 6603540174; 6602723609","Assessment of spatiotemporal fusion algorithms for planet and worldview images","2018","Sensors (Switzerland)","18","4","1051","","","","10.3390/s18041051","32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044977898&doi=10.3390%2fs18041051&partnerID=40&md5=e6a995dbfdbee69b05a9e9261115c712","Although Worldview-2 (WV) images (non-pansharpened) have 2-m resolution, the re-visit times for the same areas may be seven days or more. In contrast, Planet images are collected using small satellites that can cover the whole Earth almost daily. However, the resolution of Planet images is 3.125 m. It would be ideal to fuse these two satellites images to generate high spatial resolution (2 m) and high temporal resolution (1 or 2 days) images for applications such as damage assessment, border monitoring, etc. that require quick decisions. In this paper, we evaluate three approaches to fusingWorldview (WV) and Planet images. These approaches are known as Spatial and Temporal Adaptive Reflectance Fusion Model (STARFM), Flexible Spatiotemporal Data Fusion (FSDAF), and Hybrid Color Mapping (HCM), which have been applied to the fusion of MODIS and Landsat images in recent years. Experimental results using actual Planet andWorldview images demonstrated that the three aforementioned approaches have comparable performance and can all generate high quality prediction images. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Damage detection; Earth (planet); Planets; Satellite imagery; Forward prediction; High spatial resolution; High temporal resolution; Pan-sharpening; Spatio-temporal data; Spatio-temporal fusions; Spatiotemporal; Worldview; article; prediction; satellite imagery; Image fusion","Forward prediction; Image fusion; Pansharpening; Planet; Spatiotemporal; Worldview","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85044977898"
"Gao Y.; Liang Z.; Wang B.; Wu Y.; Wu P.","Gao, Yan (57195473211); Liang, Zeyu (57205220878); Wang, Biao (56498129900); Wu, Yanlan (12141267000); Wu, Penghai (55644317800)","57195473211; 57205220878; 56498129900; 12141267000; 55644317800","Wetland Change Detection Using Cross-Fused-Based and Normalized Difference Index Analysis on Multitemporal Landsat 8 OLI","2018","Journal of Sensors","2018","","8130470","","","","10.1155/2018/8130470","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059148193&doi=10.1155%2f2018%2f8130470&partnerID=40&md5=546ff2fd4b3691affd5c83424097a9b8","Wetlands are one of the most important ecosystems on the Earth and play a critical role in regulating regional climate, preventing floods, and reducing flood severity. However, it is difficult to detect wetland changes in multitemporal Landsat 8 OLI satellite images due to the mixed composition of vegetation, soil, and water. The main objective of this study is to quantify change to wetland cover by an image-to-image comparison change detection method based on the image fusion of multitemporal images. Spectral distortion is regarded as candidate change information, which is generated by the spectral and spatial differences between multitemporal images during the process of image cross-fusion. Meanwhile, the normalized difference vegetation index (NDVI) and normalized difference water index (NDWI) were extracted from the cross-fused image as a normalized index image to enhance and increase the information about vegetation and water. Then, the modified iteratively reweighted multivariate alteration detection (IR-MAD) is applied to the generally fused images and normalized difference index images, providing a good evaluation of spectral distortion. The experimental results show that the proposed method performed better to reduce the detection errors due to the complicated areas under different ground types, especially in cultivated areas and forests. Moreover, the proposed method was tested and quantitatively assessed and achieved an overall accuracy of 96.67% and 93.06% for the interannual and seasonal datasets, respectively. Our method can be a tool to monitor changes in wetlands and provide effective technical support for wetland conservation. © 2018 Yan Gao et al.","Earth (planet); Floods; Image fusion; Iterative methods; Vegetation; Wetlands; Alteration detections; Multi-temporal image; Normalized difference indices; Normalized difference vegetation index; Normalized difference water index; Spectral distortions; Wetland change detections; Wetland conservation; Image enhancement","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85059148193"
"Bayik Ç.; Topan H.; Özendi M.; Oruç M.; Cam A.; Abdikan S.","Bayik, Çaglar (55789802700); Topan, Hüseyin (9247721400); Özendi, Mustafa (55790388000); Oruç, Murat (9737848300); Cam, Ali (55944475400); Abdikan, Saygin (55515101500)","55789802700; 9247721400; 55790388000; 9737848300; 55944475400; 55515101500","Geospatial analysis using remote sensing images: Case studies of zonguldak test field","2016","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","2016-January","","","435","442","7","10.5194/isprsarchives-XLI-B1-435-2016","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987858864&doi=10.5194%2fisprsarchives-XLI-B1-435-2016&partnerID=40&md5=e3496343016b898898c09024958749d3","Inclined topographies are one of the most challenging problems for geospatial analysis of air-borne and space-borne imageries. However, flat areas are mostly misleading to exhibit the real performance. For this reason, researchers generally require a study area which includes mountainous topography and various land cover and land use types. Zonguldak and its vicinity is a very suitable test site for performance investigation of remote sensing systems due to the fact that it contains different land use types such as dense forest, river, sea, urban area; different structures such as open pit mining operations, thermal power plant; and its mountainous structure. In this paper, we reviewed more than 120 proceeding papers and journal articles about geospatial analysis that are performed on the test field of Zonguldak and its surroundings. Geospatial analysis performed with imageries include elimination of systematic geometric errors, 2/3D georeferencing accuracy assessment, DEM and DSM generation and validation, ortho-image production, evaluation of information content, image classification, automatic feature extraction and object recognition, pan-sharpening, land use and land cover change analysis and deformation monitoring. In these applications many optical satellite images are used i.e. ASTER, Bilsat-1, IKONOS, IRS-1C, KOMPSAT-1, KVR-1000, Landsat-3-5-7, Orbview-3, QuickBird, Pleiades, SPOT-5, TK-350, RADARSAT-1, WorldView-1-2; as well as radar data i.e. JERS-1, Envisat ASAR, TerraSAR-X, ALOS PALSAR and SRTM. These studies are performed by Departments of Geomatics Engineering at Bülent Ecevit University, at Istanbul Technical University, at Yildiz Technical University, and Institute of Photogrammetry and GeoInformation at Leibniz University Hannover. These studies are financially supported by TÜBITAK (Turkey), the Universities, ESA, Airbus DS, ERSDAC (Japan) and Jülich Research Centre (Germany).","Classification (of information); Data fusion; Feature extraction; Geodetic satellites; Geometrical optics; Image classification; Image fusion; Image reconstruction; Land use; Object recognition; Open pit mining; Photogrammetry; Radar; Remote sensing; Space optics; Space-based radar; Systematic errors; Thermoelectric power plants; Urban growth; Change detection; Geospatial applications; Optical image; Radar data; Test site; Image analysis","Change detection; Geospatial applications; Image fusion; Optical images; Radar data; Zonguldak test site","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-84987858864"
"Daza R.J.M.; Upegui E.","Daza, Ruben Javier Medina (57193828334); Upegui, Erika (36459015100)","57193828334; 36459015100","Image fusion using the Wavelet TRW and Haar transforms: Enhancement of spatial resolution for the Ikonos images from Ortophotos","2016","Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS","0","","7883048","197","202","5","10.1109/ICSESS.2016.7883048","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016933074&doi=10.1109%2fICSESS.2016.7883048&partnerID=40&md5=ae2cf216f5e1a2a25ae94167caf31468","This article has as a purpose to develop and assess two methodologies that allow to enhance spatial resolution without significant loss of the spectral resolution, with an Ikonos image and a Ortophoto. Using the RGB-IHS transform and the wavelet implementation of the Wavelet TRWH transform (Fast Haar transform) and Haar. Applying the fusion to the intensity components of the multispectral image (Im) and the ones from the ortophoto (Io) through the Wavelet haar transform predefined in Matlab together with the ARSIS technique, a new intensity l is generated respectively. To perform the inverse transforms IHS-RGB and thus obtain an multispectral image. Finally the obtained results are shown with the mathematical-statistical indexes CC, ERGAS, RSE and Qu. © 2016 IEEE.","Fusion reactions; Image fusion; Image resolution; Inverse transforms; MATLAB; Wavelet transforms; Fast Haar transforms; IHS transforms; multiespectral; Multispectral images; ortophoto; Satellite images; Spatial resolution; Wavelet; Image enhancement","Fusion; multiespectral; ortophoto; satellite images; Wavelet","Conference paper","Final","","Scopus","2-s2.0-85016933074"
"Leichter A.; Wittich D.; Rottensteiner F.; Werner M.; Sester M.","Leichter, Artem (57201775813); Wittich, Dennis (57204565966); Rottensteiner, Franz (6506388437); Werner, Martin (7402991876); Sester, Monika (21735637400)","57201775813; 57204565966; 6506388437; 7402991876; 21735637400","Improved classification of satellite imagery using spatial feature maps extracted from social media","2018","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","4","","403","410","7","10.5194/isprs-archives-XLII-4-335-2018","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056156143&doi=10.5194%2fisprs-archives-XLII-4-335-2018&partnerID=40&md5=560691f38ae7cd5c850d35453055a8dc","In this work, we consider the exploitation of social media data in the context of Remote Sensing and Spatial Information Sciences. To this end, we explore a way of augmenting and integrating information represented by geo-located feature vectors into a system for the classification of satellite images. For that purpose, we present a quite general data fusion framework based on Convolutional Neural Network (CNN) and an initial examination of our approach on features from geo-located social media postings on the Twitter and Sentinel images. For this examination, we selected six simple Twitter features derived from the metadata, which we believe could contain information for the spatial context. We present initial experiments using geotagged Twitter data from Washington DC and Sentinel images showing this area. The goal of classification is to determine local climate zones (LCZ). First, we test whether our selected feature maps are not correlated with the LCZ classification at the geo-tag position. We apply a simple boost tree classifier on this data. The result turns out not to be a mere random classifier. Therefore, this data can be correlated with LCZ. To show the improvement by our method, we compare classification with and without the Twitter feature maps. In our experiments, we apply a standard pixel-based CNN classification of the Sentinel data and use it as a baseline model. After that, we expand the input augmenting additional Twitter feature maps within the CNN and assess the contribution of these additional features to the overall F1-score of the classification, which we determine from spatial cross-validation. © Authors 2018.","Data fusion; Deep learning; Image classification; Image enhancement; Image fusion; Neural networks; Remote sensing; Satellite imagery; Social networking (online); Trees (mathematics); Convolutional Neural Networks (CNN); Integrating information; Satellite images; Social media datum; Social media minings; Spatial cross validations; Spatial features; Spatial information science; Classification (of information)","Classification; Data fusion; Deep learning; Satellite images; Social media mining","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85056156143"
"Sun Y.; Zhang H.; Shi W.","Sun, Yue (57868733500); Zhang, Hua (36995174200); Shi, Wenzhong (7402664815)","57868733500; 36995174200; 7402664815","A spatio-temporal fusion method for remote sensing data Using a linear injection model and local neighbourhood information","2019","International Journal of Remote Sensing","40","8","","2965","2985","20","10.1080/01431161.2018.1538585","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057341275&doi=10.1080%2f01431161.2018.1538585&partnerID=40&md5=3f32d2270c8de5e48888ab1c3e0f14da","This paper presents a spatio-temporal fusion method for remote sensing images by using a linear injection model and local neighbourhood information. In this method, the linear injection model is first introduced to generate an initial fused image, the spatial details are extracted from the fine-resolution image at the base date, and are weighted by a proper injection gains. Then, the spatial details and the relative spectral information from the coarse-resolution images are blended to generate the fusion result. To further enhance its robustness to the noise, the local neighbourhood information, derived from the fine-resolution image and the fused result simultaneously, is introduced to refine the initial fused image to obtain a more accurate prediction result. The algorithm can effectively capture phenology change or land-cover-type change with minimum input data. Simulated data and two types of real satellite images with seasonal changes and land-cover-type changes are employed to test the performance of the proposed method. Compared with a spatial and temporal adaptive reflectance fusion model (STARFM) and a flexible spatio-temporal fusion algorithm (FSDAF), results show that the proposed approach improves the accuracy of fused images in phenology change area and effectively captures land-cover-type reflectance changes. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","Biology; Image enhancement; Reflection; Remote sensing; Accurate prediction; Fine-resolution images; Reflectance changes; Remote sensing data; Remote sensing images; Spatio-temporal fusions; Spectral information; Temporal adaptive; algorithm; land cover; neighborhood; phenology; remote sensing; spatiotemporal analysis; Image fusion","","Article","Final","","Scopus","2-s2.0-85057341275"
"Abbasi A.P.","Abbasi, A. Palham (57194244115)","57194244115","Percentage of vegetation cover of rangelands using ETM+ image processing case study: Rangelands of Safaroud Watershed, Mazandaran","2016","IIOAB Journal","7","","","188","191","3","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019532334&partnerID=40&md5=5c1c506f606707d8c6c91e261fa94265","The aim of this study was to determine the percentage of vegetation cover of rangelands using digital data of Landsat 8 satellite sensor. For this purpose, satellite images of rangelands of Safaroud watershed in Mazandaran province (Iran) were prepared. Then, visiting the region, field data were taken by random-classified sampling method. In homogeneous regions, rangelands of the sampling units were determined randomly. In each unit, 10 plots of one square meter were placed on the circumference of a circle with a radius of 30 meters, and the percentage of vegetation cover of each plot was estimated. Average vegetation cover of 10 plots was considered as a percentage of the Central plot vegetation cover. For image processing, vegetation index and image fusion techniques were used. The estimation model of the region vegetation cover percentage was developed using stepwise regression statistical analysis on data obtained from field observations as the dependent variable, and analogous pixel value on satellite data obtained by processing the images as independent variable. In this model, images of raw data band 3 (b3), the fusion band 2 (his2) and TVI vegetation index were diagnosed as suitable images. By applying the model on the above images, region vegetation cover percentage was prepared. Using the Regroup technique, the map is divided into different classes, and cover classes map was prepared. Map accuracy was assessed using error matrix technique, and total accuracy and kappa coefficient of the map were calculated 78.2 and 74.5, respectively. © 2016, Institute of Integrative Omics and Applied Biotechnology. All rights reserved.","Article; dependent variable; ETM sensor; image analysis; image processing; independent variable; information processing; Iran; principal component analysis; rangeland; sensor; statistical analysis; stepwise regression analysis; vegetation; watershed","Data fusion; Mus musculus; Safaroud watershed; Satellite image processing; Stepwise regression; Toxoplasmosis; Traditional medicine; Vegetation cover percentage","Article","Final","","Scopus","2-s2.0-85019532334"
"Chu J.; Chen Y.; Zhao J.; Wang F.","Chu, Jialan (57188715925); Chen, Yanlong (36719912800); Zhao, Jianhua (57191638541); Wang, Fei (57213679968)","57188715925; 36719912800; 57191638541; 57213679968","Evaluation on BJ-2 Image Fusion Algorithms for Satellite Images of Coastal Aquaculture Sea Areas","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","","","8898091","2826","2829","3","10.1109/IGARSS.2019.8898091","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077685827&doi=10.1109%2fIGARSS.2019.8898091&partnerID=40&md5=222b8629bc3bd772e088238e0e097a0e","Coastal aquaculture sea areas is of great significance to monitor these aquaculture sea areas through the means of a remote sensing technology. The images after fusion are provided with both the high-resolution feature of panchromatic images and the spectral characteristics of multi-spectral images, thereby strengthening the image information and facilitating its application. According to the characteristics of the aquaculture sea area in concern, five fusion algorithms, namely, Brovey Transform, Gram-Schmidt Transform, Principal Component Analysis, Pan Sharp, and Nearest Neighbor Diffusion PanSharpening were adopted to fuse the BJ-2 multi-spectral and panchromatic image data of the areas in the shallow sea raft culture, cage culture, and reclamation culture acquired in Zhangzhou coastal aquaculture sea area of the Fujian Province. Then the fusion images are evaluated subjectively and objectively to provide the best fusion scheme for monitoring aquaculture by remote sensing. The results showed that: (1) the five fusion algorithms are able to significantly improve both the spatial resolution and the utilization ratio of the BJ-2 satellite images; (2) the fusion effects of PSH method can provide the most optimum solution in terms of spectral retentivity and detail expression, and are the best in all the three fusion experiments on aquaculture sea information; (3) the acquired bright-color and high-contrast images make the fusion effects of NNDiffuse the best in terms of image contrast and information enhancement; (4) PSH algorithm is appropriate for use when BJ-2 is used for visual interpretation and thematic charting of shallow sea raft culture, cage culture and reclamation culture and other information; on the other hand, it is recommended to use NNDiffuse for automatic classification and identification. © 2019 IEEE.","Aquaculture; Classification (of information); Geology; Image enhancement; Quality control; Remote sensing; Spectroscopy; Automatic classification; BJ-2; Gram-Schmidt transform; Image fusion algorithms; Quality evaluation; Remote sensing technology; Sea areas; Spectral characteristics; Image fusion","Aquaculture sea area; BJ-2; Image fusion; Quality evaluation.","Conference paper","Final","","Scopus","2-s2.0-85077685827"
"Dhivya R.; Prakash R.","Dhivya, R. (57200013747); Prakash, R. (57215195561)","57200013747; 57215195561","Edge detection of satellite image using fuzzy logic","2019","Cluster Computing","22","","","11891","11898","7","10.1007/s10586-017-1508-x","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038869971&doi=10.1007%2fs10586-017-1508-x&partnerID=40&md5=e14bb2f284d64a597b74402f61d94624","Edge detection plays an important role in the field of image processing. Various edge detection techniques are obtained like Sobel, PSO Preweitt, Laplacian and Laplacian of Gaussian. These techniques consume some restrictions such as fixed edge thickness and some parameter like threshold is problematic to implement. Although many different edge-detection methods have been proposed for gray-scale, color, and multispectral images, they still face difficulties when extracting edge features from hyperspectral images (HSIs) that contain a large number of bands with very narrow gap in the spectral domain. High performance computing (HPC) is a technique used to assemble process and analyze more quantity of remote sensing (satellite) data which needs less processing time. HPC method is used in distributed & cluster Computing, parallel computing and following satellite data analyzing & processing approaches like geo-referencing, image edge detection, image classification, image mosaicking, Morphological/neural approach and image fusion for hyperspectral satellite data. Stimulated by means of the specific clustering of theory called gravitational theory, an original edge detection process. The conservative methods include the usage of linear time invariant filters. Recognition of edge is done by these filters as a These filters recognize an edge as a sudden conversion of grey scale pixel intensity. These techniques are well recognized and computationally effective. Canny, Sobel, Robert, Kirsch, Prewitt and LOG, on idea of spatial differential filters by using local grade. Within the less time these filters process the data and are inclined to noise. But in fuzzy technique, it does not include like this restriction, by altering the rules and output parameters, it is possible to change the thickness of the edge. In this paper, a new technique is created on fuzzy logic, which is suggested for detection of edge in digital images deprived of finding the threshold value. This method starts through segmenting the images into sections by means of fluctuating 3 × 3 binary matrixes. The pixels of edge are planned to a range of standards separated from each other. The results of this proposed technique is compared with the results obtained from PSO and neural network methods. This suggested technique provides a permanent effect in the lines smoothness and straightness for the straight lines and good roundness for the curved lines. And sharpness in the curves. © 2017, Springer Science+Business Media, LLC, part of Springer Nature.","Cluster computing; Computer circuits; Edge detection; Hyperspectral imaging; Image classification; Image fusion; Laplace transforms; Particle swarm optimization (PSO); Pixels; Remote sensing; Satellites; Spectroscopy; Temporal logic; Edge detection methods; Gravitational theory; High performance computing; High performance computing (HPC); Hyperspectral satellite; Laplacian of Gaussian; Linear time invariant; Neural network method; Fuzzy logic","Fuzzy logic; High performance computing; Hyperspectral images; Neural edge detection; PSO","Article","Final","","Scopus","2-s2.0-85038869971"
"Meng L.; Liu H.; Zhang X.; Ren C.; Ustin S.; Qiu Z.; Xu M.; Guo D.","Meng, Linghua (56909339300); Liu, Huanjun (36626123200); Zhang, Xinle (35099665300); Ren, Chunying (23052217800); Ustin, Susan (35570142700); Qiu, Zhengchao (57193914317); Xu, Mengyuan (57195335792); Guo, Dong (57225947007)","56909339300; 36626123200; 35099665300; 23052217800; 35570142700; 57193914317; 57195335792; 57225947007","Assessment of the effectiveness of spatiotemporal fusion of multi-source satellite images for cotton yield estimation","2019","Computers and Electronics in Agriculture","162","","","44","52","8","10.1016/j.compag.2019.04.001","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063914161&doi=10.1016%2fj.compag.2019.04.001&partnerID=40&md5=96ed233e62901ba6d1483224c40d773a","                             Deficiencies in the spatiotemporal resolution of remote sensing (RS) images limit crop yield estimation at the farm and field scale. These deficiencies may be alleviated by fusion of high spatial and temporal resolution images such as MODIS and Landsat. In this study, a new daily MODIS NDVI product (reconstructed MODIS) was generated from 16-day composite images using the Extreme Model, which integrates the NDVI value with the corresponding specific date information at each pixel. The Flexible Spatiotemporal Data Fusion (FSDAF) model was then used to create two fused, high-resolution time-series products (fused MODIS and fused reconstructed MODIS) in order to enhance the spatial and temporal effectiveness of satellite images for field-scale applications. Three yield estimation models were then built using time-series data of Landsat NDVI, predicted NDVI from fused MODIS, and predicted NDVI from fused reconstructed MODIS. The methodology was tested on a farm field over the cotton growing season in the San Joaquin Valley of California. Results showed that: (1) the time trend of NDVI over the growing season for the fused reconstructed MODIS was more similar to that of Landsat than were either of MODIS or fused MODIS, indicating that the specific date of MODIS pixels is important for time-series analysis; (2) the NDVI from fused reconstructed MODIS provided the best correlation with Landsat NDVI, with R                             2                              and RMSE values 15% higher than for fused MODIS; (3) correlation between cotton yield and all three datasets at the pixel level was statistically significant for all image dates, and (4) the accuracy of the cotton yield estimation model using predicted NDVI from fused reconstructed MODIS (R                             2                              = 0.79; RMSE = 488.01) was higher than with fused MODIS (R                             2                              = 0.77; RMSE = 513.96) and only slightly lower than with Landsat (R                             2                              = 0.84, RMSE = 463.12). This study improved the accuracy of MODIS-based yield estimation using fusion images, and the results can be applied to improve vegetation monitoring and quantitative modeling using MODIS NDVI at the field scale.                          © 2019 Elsevier B.V.","California; San Joaquin Valley; United States; Gossypium hirsutum; Cotton; Cultivation; Data fusion; Image enhancement; Image fusion; Image reconstruction; Pixels; Remote sensing; Time series analysis; Date information; Field scale; Modis ndvi; Quantitative modeling; Spatial and temporal resolutions; Spatio-temporal fusions; Spatio-temporal resolution; Yield estimation; assessment method; cotton; crop yield; data interpretation; Landsat; MODIS; NDVI; pixel; reconstruction; remote sensing; satellite imagery; time series; yield response; Radiometers","Data fusion; Date information; Field scale; Reconstructed MODIS NDVI; Yield estimation","Article","Final","","Scopus","2-s2.0-85063914161"
"Bhandari A.K.; Rahul K.","Bhandari, Ashish Kumar (25651606700); Rahul, Kusuma (57209648408)","25651606700; 57209648408","A novel local contrast fusion-based fuzzy model for color image multilevel thresholding using grasshopper optimization","2019","Applied Soft Computing Journal","81","","105515","","","","10.1016/j.asoc.2019.105515","20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066130959&doi=10.1016%2fj.asoc.2019.105515&partnerID=40&md5=3de3ae1819c7d2833388bc38860f7de7","The segmentation process is considered the significant step of an image processing system due to its extreme inspiration on the subsequent image analysis. Out of various approaches, thresholding is one of the most popular schemes for image segmentation. In segmentation, image pixels are arranged in various regions based on their intensity levels. In this paper, a straightforward and efficient fusion-based fuzzy model for multilevel color image segmentation using grasshopper optimization algorithm (GOA) has been proposed. Thresholding based segmentation lacks accuracy in segmenting the ambiguous images due to their complex characteristics, uncertainties and inherent fuzziness. However, the fuzzy entropy resolves these problems, but it is unable for segmenting at higher levels and also the complexity level for selecting suitable thresholds is high. The selection of metaheuristic GOA reduces this problem by selecting optimal threshold values. Therefore, to increase the quality of the segmented image, a simple and effective multilevel thresholding method is exploited by using the concept of fusion which is based on the local contrast. Experimental outputs demonstrate that fusion-based multilevel thresholding is better than most specific segmentation methods and can be validated by comparing the different numerical parameters. Experiments on standard daily-life color and satellite images are conducted to prove the effectiveness of the proposed scheme. © 2019 Elsevier B.V.","Color; Entropy; Image fusion; Numerical methods; Optimization; Complex characteristics; Fuzzy entropy; Image processing system; Local contrast; Multilevel thresholding; Multilevel thresholding method; Multilevels; Optimization algorithms; Image segmentation","Fuzzy entropy; Grasshopper optimization algorithm; Image fusion; Local contrast; Multi-level image segmentation","Article","Final","","Scopus","2-s2.0-85066130959"
"Zhang X.; Cui J.; Wang W.; Lin C.","Zhang, Xin (57077122400); Cui, Jintian (57194626513); Wang, Weisheng (57192258031); Lin, Chao (57194622410)","57077122400; 57194626513; 57192258031; 57194622410","A study for texture feature extraction of high-resolution satellite images based on a direction measure and gray level co-occurrence matrix fusion algorithm","2017","Sensors (Switzerland)","17","7","1474","","","","10.3390/s17071474","136","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021267094&doi=10.3390%2fs17071474&partnerID=40&md5=9990cc39c4ba2cfa407317ec83514e4b","To address the problem of image texture feature extraction, a direction measure statistic that is based on the directionality of image texture is constructed, and a new method of texture feature extraction, which is based on the direction measure and a gray level co-occurrence matrix (GLCM) fusion algorithm, is proposed in this paper. This method applies the GLCM to extract the texture feature value of an image and integrates the weight factor that is introduced by the direction measure to obtain the final texture feature of an image. A set of classification experiments for the high-resolution remote sensing images were performed by using support vector machine (SVM) classifier with the direction measure and gray level co-occurrence matrix fusion algorithm. Both qualitative and quantitative approaches were applied to assess the classification results. The experimental results demonstrated that texture feature extraction based on the fusion algorithm achieved a better image recognition, and the accuracy of classification based on this method has been significantly improved. © 2017 by the authors.","Extraction; Feature extraction; Image classification; Image fusion; Image processing; Image recognition; Image reconstruction; Support vector machines; Accuracy of classifications; Direction measure; Gray level co occurrence matrix(GLCM); Gray level co-occurrence matrix; High resolution remote sensing images; High resolution satellite images; Qualitative and quantitative approaches; Texture feature extraction; algorithm; article; diagnostic test accuracy study; feature extraction; quantitative analysis; satellite imagery; support vector machine; Image texture","Direction measure; Gray level co-occurrence matrix; Image classification; Texture feature extraction","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85021267094"
"Fatemi S.B.; Gholinejad S.","Fatemi, Sayyed Bagher (56581482700); Gholinejad, Saeid (57193855503)","56581482700; 57193855503","Assessing the effectiveness of Google Earth images for spatial enhancement of RapidEye multi-spectral imagery","2019","International Journal of Remote Sensing","40","12","","4526","4543","17","10.1080/01431161.2019.1569280","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060596083&doi=10.1080%2f01431161.2019.1569280&partnerID=40&md5=045a031ff315f814179cba5f0aa09f29","RapidEye satellite images with high spatial resolution, affordable prices and having Red-Edge band have high potential for time series issues, especially in vegetation studies. Despite these beneficial properties, RapidEye images with 5 m spatial resolution are not sufficiently useful for some applications. According to this problem, enhancing the spatial resolution of RapidEye images can significantly improve the results of the subsequent processes on these images. Fusion of high spatial resolution with high spectral resolution images is known as an effective way to enhance the quality of multispectral remotely sensed images. Unfortunately, the lack of panchromatic band with high spatial resolution has been faced the procedure of improving the spatial resolution of RapidEye images with major problems. In this paper, we have proposed using the free Google Earth (GE) images which have high spatial resolution and high-coverage of land surface to enhance the spatial information of RapidEye images. A simulated panchromatic image has been generated by three band GE image and with three different methods: Mean, principal component analysis (PCA) and weighted average of GE image bands. In the last method, the weights are extracted from the spectral response curve of the satellite which captured the GE image. The simulated panchromatic image has been utilized for pansharpening of RapidEye image in five well-known methods: Brovey, Gram-Schmidt (GS), intensity-hue-saturation (IHS), Pansharp1 and Pansharp2. The most important point is finding the GE image with lowest lag time with RapidEye image. By satisfying this condition, the experiments illuminated that the proposed method can effectively enhance the spatial quality of RapidEye image. Also, this study presented that Pansharp2 method, which used simulated panchromatic image generated by the spectral response curve information, has revealed the best results of RapidEye image pansharpening. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Image resolution; Principal component analysis; Spectral resolution; Spectroscopy; High spatial resolution; High spectral resolution images; Intensity hue saturations; Multi-spectral imagery; Panchromatic images; Remotely sensed images; Spatial enhancement; Spatial informations; image analysis; Internet; multispectral image; RapidEye; satellite imagery; spatial analysis; spatial resolution; Image enhancement","","Article","Final","","Scopus","2-s2.0-85060596083"
"Li H.; Jing L.; Tang Y.; Wang L.","Li, Hui (56148844400); Jing, Linhai (23492470700); Tang, Yunwei (35197211600); Wang, Liming (57196331308)","56148844400; 23492470700; 35197211600; 57196331308","An image fusion method based on image segmentation for high-resolution remotely-sensed imagery","2018","Remote Sensing","10","5","790","","","","10.3390/rs10050790","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047555687&doi=10.3390%2frs10050790&partnerID=40&md5=41c27fcac083bd3ada97d0b892a7c2c4","Fusion of high spatial resolution (HSR) multispectral (MS) and panchromatic (PAN) images has become a research focus with the development of HSR remote sensing technology. In order to reduce the spectral distortions of fused images, current image fusion methods focus on optimizing the approach used to extract spatial details from the PAN band, or on the optimization of the models employed during the injection of spatial details into the MS bands. Due to the resolution difference between the MS and PAN images, there is a large amount of mixed pixels (MPs) existing in the upsampled MS images. The fused versions of these MPs remain mixed, although they may correspond to pure PAN pixels. This is one of the reasons for spectral distortions of fusion products. However, few methods consider spectral distortions introduced by the mixed fused spectra of MPs. In this paper, an image fusion method based on image segmentation was proposed to improve the fused spectra of MPs. The MPs were identified and then fused to be as close as possible to the spectra of pure pixels, in order to reduce spectral distortions caused by fused MPs and improve the quality of fused products. A fusion experiment, using three HSR datasets recorded byWorldView-2, WorldView-3 and GeoEye-1, respectively, was implemented to compare the proposed method with several other state-of-the-art fusion methods, such as haze- and ratio-based (HR), adaptive Gram-Schmidt (GSA) and smoothing filter-based intensity modulation (SFIM). Fused products generated at the original and degraded scales were assessed using several widely-used quantitative quality indexes. Visual inspection was also employed to compare the fused images produced using the original datasets. It was demonstrated that the proposed method offers the lowest spectral distortions and more sharpened boundaries between different image objects than other methods, especially for boundaries between vegetation and non-vegetation objects. © 2018 by the authors.","Image enhancement; Image segmentation; Modulation; Pixels; Remote sensing; Satellite imagery; Vegetation; High resolution satellite images; High spatial resolution; High-resolution remotely sensed imageries; Mixed pixel; Pan-sharpening; Panchromatic (Pan) image; Remote sensing technology; Smoothing filter based intensity modulation; Image fusion","High resolution satellite image; Image segmentation; Mixed pixel; Pansharpening","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85047555687"
"Maharnisha G.; Kumar G.R.; Arunraj R.","Maharnisha, Gandla (57202899817); Kumar, Gandla Roopesh (57215913272); Arunraj, R. (57196052542)","57202899817; 57215913272; 57196052542","Satellite image registration and image fusion by using principle component analysis","2018","International Journal of Engineering and Technology(UAE)","7","2.19 Special issue  19","","106","110","4","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082366285&partnerID=40&md5=6a3c665eda0c30f4bbfa6451d1bb2188","This aims to fused image registration and image fusion used to spatial resolution images by principle component analysis method. Digital image processing requires either the full image or a part of image. It will be processed from the user's point of view like the radius of object. Wavelet technique will improve the spatial resolution to produce spectral degradation in output image. To overcome the spectral degradation, PCA fusion method can be used. PCA uses curve which represent edges and extraction of the detailed information from the image. PAN and MS images are used by individual acquired low frequency approximate component and high frequency detail components in this PCA. To evaluate the image fusion accuracy, Peak Signal to Noise Ratio and Root Mean Square Error are used. The advantages of using digital image processing are preservation of original data accuracy, flexibility and repeatability. © 2016 Authors.","","Image enhancement; Image fusion; Image registration; PCA; Remote sensing","Article","Final","","Scopus","2-s2.0-85082366285"
"Masood F.; Qazi I.-U.-H.; Khurshid K.","Masood, Faisal (57207621994); Qazi, Imtnan-Ul-Haque (32267497000); Khurshid, Khurram (57119490500)","57207621994; 32267497000; 57119490500","Saliency-based visualization of hyperspectral satellite images using hierarchical fusion","2018","Journal of Applied Remote Sensing","12","4","046011","","","","10.1117/1.JRS.12.046011","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056104875&doi=10.1117%2f1.JRS.12.046011&partnerID=40&md5=155e98a761c8e715b314fc79ad8eff5e","Owing to a large number of spectral bands, it is always a challenge to devise an optimal visualization method for hyperspectral images. An algorithm must maintain a balance between dimensionality reduction and restoration of maximum spectral information. A methodology for visualization of hyperspectral imagery is proposed based on extraction of salient regions. For that, spectral bands are selected from different combinations of principal component analysis, minimum noise fraction, and saliency maps. A hierarchical fusion method is proposed, which is applied on the selected bands to obtain a final three band RGB image. The qualitative and quantitative results of the proposed method are very encouraging once compared with other state-of-the-art methods. © 2018 Society of Photo-Optical Instrumentation Engineers (SPIE).","Hyperspectral imaging; Principal component analysis; Spectroscopy; Visualization; Dimensionality reduction; Graph-based visual saliencies; Hierarchical fusions; Hyper-spectral imageries; Hyperspectral satellite; Minimum noise fraction; Quaternion Fourier transforms; State-of-the-art methods; Image fusion","graph-based visual saliency; hierarchical fusion; hyperspectral images; minimum noise fraction; phase spectrum of quaternion Fourier transform; principal component analysis","Article","Final","","Scopus","2-s2.0-85056104875"
"Subramanian P.; Alamelu N.R.; Aramudhan M.","Subramanian, P. (57200000221); Alamelu, N.R. (6506953872); Aramudhan, M. (14053476100)","57200000221; 6506953872; 14053476100","A novel approach of image fusion based on noiselet transform","2017","Journal of Computational and Theoretical Nanoscience","14","3","","1303","1307","4","10.1166/jctn.2017.6449","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021755680&doi=10.1166%2fjctn.2017.6449&partnerID=40&md5=a4113d46fb8e8e6c7982dc664524c157","In remote sensing applications, mostly panchromatic satellite images and multispectral satellite images are utilized for image fusion. The panchromatic satellite image with the maximum resolution and the multispectral satellite image with coarser resolution is transmitted. These images are merged to convey important information at the receiver station. The community of remote sensing deploy image fusion for spectral distortion reduction. In earlier the image fusion is implemented based on the wavelet and curvelet transform. Due to the curves, curls, bends in the satellite images the wavelet and curvelet shows a negative sign of performances. Since, the noiselet transform performs well under the rough curved surfaces. This work contributes to the image fusion by combining multispectral and panchromatic images from satellite utilizing Noiselet transform. The proposed system is analyzed by evaluating various parameter such as CC, RMSE, RASE and ERGAS. Here, few sets of test images have been taken and for entire the test data, the proposed technique gives better result compared with the other techniques. The proposed techniques achieves the fused results of the noiselet shown in CC, RMSE, and RASE. © 2017 American Scientific Publishers All rights reserved.","","Curvelet; Fusion; Noiselet; Wavelet","Article","Final","","Scopus","2-s2.0-85021755680"
"Rai K.K.; Rai A.; Dhar K.; Senthilnath J.; Omkar S.N.; Ramesh K.N.","Rai, Kunal Kumar (57189068716); Rai, Aparna (57189074038); Dhar, Kanishka (57189067594); Senthilnath, J. (35183910200); Omkar, S.N. (6603162849); Ramesh, K.N. (57218252431)","57189068716; 57189074038; 57189067594; 35183910200; 6603162849; 57218252431","SIFT-FANN: An efficient framework for spatio-spectral fusion of satellite images","2017","Journal of the Indian Society of Remote Sensing","45","1","","55","65","10","10.1007/s12524-016-0576-3","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965057566&doi=10.1007%2fs12524-016-0576-3&partnerID=40&md5=de842e478eb0b8bfe6fea3a546204388","Image fusion techniques are widely used for remote sensing data. A special application is for using low resolution multi-spectral image with high resolution panchromatic image to obtain an image having both spectral and spatial information. Alignment of images to be fused is a step prior to image fusion. This is achieved by registering the images. This paper proposes the methods involving Fast Approximate Nearest Neighbor (FANN) for automatic registration of satellite image (reference image) prior to fusion of low spatial resolution multi-spectral QuickBird satellite image (sensed image) with high spatial resolution panchromatic QuickBird satellite image. In the registration steps, Scale Invariant Feature Transform (SIFT) is used to extract key points from both images. The keypoints are then matched using the automatic tuning algorithm, namely, FANN. This algorithm automatically selects the most appropriate indexing algorithm for the dataset. The indexed features are then matched using approximate nearest neighbor. Further, Random Sample Consensus (RanSAC) is used for further filtering to obtain only the inliers and co-register the images. The images are then fused using Intensity Hue Saturation (IHS) transform based technique to obtain a high spatial resolution multi-spectral image. The results show that the quality of fused images obtained using this algorithm is computationally efficient. © 2016, Indian Society of Remote Sensing.","algorithm; data set; image analysis; image resolution; multispectral image; panchromatic image; QuickBird; remote sensing; satellite data; satellite imagery; spatial resolution","Fast approximate nearest Neighbor; Image fusion; Scale invariant feature transform","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84965057566"
"Li F.; Hong S.; Wang L.","Li, Fulin (57207114141); Hong, Shaohua (24466471900); Wang, Lin (35262942100)","57207114141; 24466471900; 35262942100","A new satellite image fusion method based on distributed compressed sensing","2018","Proceedings - International Conference on Image Processing, ICIP","","","8451648","1882","1886","4","10.1109/ICIP.2018.8451648","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062896330&doi=10.1109%2fICIP.2018.8451648&partnerID=40&md5=790c446e8e6c307bc9a3690a6074edc4","In this paper, we propose a method for fusion of low-resolution multispectral (LRM) image and high-resolution panchromatic (HRP) image to obtain high-resolution multispectral (HRM) image based on distributed compressed sensing (DCS). In the proposed method, HRP image is firstly used to obtain approximation and detail dictionary. Then, joint-sparsity-model-1 (JSM-1) is applied directly to both LRM bands and HRM bands. Each band in LRM image is decomposed into common component and innovation component which can be sparsely represented over the approximation dictionary. Based on Orthogonal Matching Pursuit (OMP) algorithm, the sparse coefficients are calculated from JSM-1 of the LRM image. Lastly, each band in HRM image is modeled as the fusion of the corresponding LRM band and detail band over the detail dictionary. Two datasets are used in the experiments to validate the proposed method and the results show that the proposed method has better performance than the traditional methods. © 2018 IEEE.","Compressed sensing; Image compression; Distributed Compressed Sensing; Joint sparsity models; Low resolution multispectral images; Panchromatic images; Satellite images; Image fusion","Distributed compressed sensing; High-resolution panchromatic image; Joint sparsity model; Low-resolution multispectral image; Satellite image fusion","Conference paper","Final","","Scopus","2-s2.0-85062896330"
"Swathika R.; Sharmila T.S.","Swathika, R. (55823315000); Sharmila, T. Sree (55337283900)","55823315000; 55337283900","Image fusion for MODIS and Landsat images using top hat based moving technique with FIS","2019","Cluster Computing","22","","","12939","12947","8","10.1007/s10586-018-1802-2","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041232924&doi=10.1007%2fs10586-018-1802-2&partnerID=40&md5=8a13c08000bc0fffe826c33435d77227","The image fusion technique is widely used in various applications like military, remote sensing, security and medical imaging. In image fusion, two different images with similar index is fused to extract the exact information. The Landsat and Moderate resolution imaging spectroradiometer images taken from artificial satellite are not perfectly distinguishable. The principal component analysis, discrete cosine transform and discrete wavelet transform with spatial frequency are the existing methods used for fusing images. The principal component analysis and discrete cosine transform were applicable only for low precision and low quality applications. Also, the output image faced drawbacks that resulted in blurred image with low recognition rate. In order to obtain image clarity and accuracy, the top hat based moving technique with fuzzy inference system is proposed in this paper. The white top hat and black top hat techniques filter the light and dark character of the image. Then the fusion is performed by fuzzy inference system. The proposed method is used to retrieve satellite images which are highly informative and the image clarity is also high since the entropy value of the proposed method is high when compared to other conventional techniques. The proposed method has higher PSNR value compared with the state-of-the-art techniques which indicates the proposed fused image has good quality. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Discrete cosine transforms; Discrete wavelet transforms; Fuzzy inference; Fuzzy systems; Medical imaging; Military applications; Military photography; Principal component analysis; Quality control; Radiometers; Remote sensing; Satellite imagery; Signal reconstruction; Spectrometers; Conventional techniques; Fuzzy inference systems; Image fusion techniques; Moderate resolution imaging spectroradiometer; Recognition rates; Satellite images; Spatial frequency; State-of-the-art techniques; Image fusion","Discrete wavelet transform; Moderate resolution imaging spectroradiometer; Principal component analysis; Top hat based moving technique with fuzzy inference system","Article","Final","","Scopus","2-s2.0-85041232924"
"Liu Y.; Fan X.","Liu, Yan (57056544400); Fan, Xiaoya (7403394163)","57056544400; 7403394163","Key technologies of satellite remote sensing data image processing based flight simulator visual","2015","Xibei Gongye Daxue Xuebao/Journal of Northwestern Polytechnical University","33","6","","1027","1034","7","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954204839&partnerID=40&md5=37775e4bd986f44e0ba9f507ecd0d412","In this paper, the spectral characteristics of based on Satellite remote sensing data, remote sensing data to explore Worldview Ortho-rectification, band combination, integration and other aspects of processing and color adjustments in flight simulation processing key technologies. Base on Lhasa airport Satellite images, By using with high-resolution processing software ERDAS remote sensing applications, QB and SPOT5 and ALOS data used in the experiment to try different mathematical methods and parameters, where the parameters are summarized regularity, the resulting imagery meets the system requirements of the whole airport flight procedures coverage area. © 2015, Northwestern Polytechnical University. All right reserved.","Application programs; Color matching; Computer software; Data fusion; Data handling; Error analysis; Errors; Extraction; Feature extraction; Flight simulators; Geometry; Image fusion; Image matching; Image processing; Image reconstruction; Least squares approximations; Pixels; Principal component analysis; Satellite imagery; Satellites; Color adjustments; Flight simulation; High resolution processing; Least square approximations; Remote sensing applications; Satellite images; Satellite remote sensing data; Spectral characteristics; Remote sensing","Color adjustment; Computer software; Data fusion; Error analysis; Errors; Feature extraction; Flight simulation; Geographic feature extraction; Geometry; Image fusion; Image matching; Least square approximations; Pixels; Principal component analysis; Remote sensing; Satellite image correction; Satellite topography","Article","Final","","Scopus","2-s2.0-84954204839"
"Li X.; Qi W.","Li, Xu (55273488000); Qi, Weifeng (57188809587)","55273488000; 57188809587","An effective pansharpening method for WorldView-2 satellite images","2015","Proceedings of 2015 International Conference on Estimation, Detection and Information Fusion, ICEDIF 2015","","","7280168","88","92","4","10.1109/ICEDIF.2015.7280168","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963548414&doi=10.1109%2fICEDIF.2015.7280168&partnerID=40&md5=b6ed51b1adbc0967c8607117ec9eaa1a","Pansharpening has been an important tool in remote sensing applications, which transforms a set of low-spatial-resolution multispectral images to high-spatial-resolution images by fusing a co-registered fine-spatial-resolution panchromatic image. The new style very high-resolution WorldView-2 satellite images have posed challenges to the image fusion techniques. An effective pansharpening method based on correspondence analysis is presented in this paper. The experimental results show that the presented method can effectively obtain a better trade-off between the spectral fidelity and the spatial resolution enhancement compared to some existing methods. © 2015 IEEE.","Economic and social effects; Image fusion; Information fusion; Optical resolving power; Remote sensing; Satellite imagery; Correspondence analysis; High spatial resolution images; Image fusion techniques; Multi-spectral; Pan-sharpening; Panchromatic; Remote sensing applications; Spatial-resolution enhancement; Image resolution","Multispectral; Panchromatic; Pansharpening; Resolution","Conference paper","Final","","Scopus","2-s2.0-84963548414"
"Wu X.-Y.; Chai J.; Liu F.; Chen Z.-H.","Wu, Xiao-Yan (57201699885); Chai, Jing (55160519200); Liu, Fan (57207949715); Chen, Ze-Hua (56000549900)","57201699885; 55160519200; 57207949715; 56000549900","Remote Sensing Image Fusion Based on Minimum Hausdorff Distance and Non-sampled Shearlet Transform","2018","Guangzi Xuebao/Acta Photonica Sinica","47","2","0210002","","","","10.3788/gzxb20184702.0210002","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045854694&doi=10.3788%2fgzxb20184702.0210002&partnerID=40&md5=e7884e1c5e7b50bd10176321701bdda0","In order to preserve both spectral and spatial information simultaneously in fused image, we introduce the minimum Hausdorff distance and Non-Sampled Shearlet Transform (NSST) to construct a new method for remote sensing image fusion. Firstly, Principal Component Analysis (PCA) transform is applied in the original multispectral image to obtain the first principal component, this component and the panchromatic image are decomposed by NSST respectively to obtain the corresponding low frequency subband coefficients and high frequency subband coefficients. Then, the low frequency subband coefficients are fused by sparse representation, the sparse coefficients of sparse representation are fused with the region space frequency; for the high frequency subband coefficients, the regional structure similarity is utilized, using the minimum Hausdorff distance to represent the correlation of regions and different fusion strategies are adopted according to the correlation. Finally, the fused coefficients are transformed by inverse NSST to obtain the new principal component, the new component and other higher order principal components are transformed by inverse PCA transform to obtain the fused image. In this paper, three QuickBird satellite images and one SPOT satellite image are selected for testing, the results show that compared with the traditional fusion strategy algorithms, the fusion results obtained by proposed method have better objective evaluation index and subjective visual effect. © 2018, Science Press. All right reserved.","Geometry; Image analysis; Image fusion; Inverse problems; Remote sensing; Space optics; Subjective testing; First principal components; Hausdorff distance; Principal component analysis transforms; Remote sensing images; Shearlet transforms; Sparse representation; Spatial informations; Subband coefficients; Principal component analysis","Minimum Hausdorff distance; Non-subsampled Shearlet transform; Principal component analysis; Remote sensing image fusion; Sparse representation","Article","Final","","Scopus","2-s2.0-85045854694"
"Zhao Y.; Huang B.; Song H.","Zhao, Yongquan (57192575717); Huang, Bo (55388074800); Song, Huihui (36572623600)","57192575717; 55388074800; 36572623600","A robust adaptive spatial and temporal image fusion model for complex land surface changes","2018","Remote Sensing of Environment","208","","","42","62","20","10.1016/j.rse.2018.02.009","79","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042030427&doi=10.1016%2fj.rse.2018.02.009&partnerID=40&md5=1cbdbd18d56fb2d08f39a4bee68ad832","Spatial and temporal satellite image fusion (STIF) has provided a feasible alternative for generating imagery with both high spatial and temporal resolution, thus expanding the applications of existing satellite sensors. However, a critical challenge confronting the further development of STIF is to systematically and robustly address complex land surface changes, which include land cover changes without shape changes (e.g., crop rotation) and land cover changes with shape changes (e.g., urban expansion), in addition to conventional land surface changes (e.g., phenological changes of vegetation). This paper presents the Robust Adaptive Spatial and Temporal Fusion Model (RASTFM) to tackle this challenge with one prior pair of MODIS-Landsat images. In RASTFM, land surface changes are reorganized into non-shape changes (including phenological changes and land cover changes without shape changes) and shape changes (i.e., land cover changes with shape changes), which are handled differently. However, both non-shape changes and shape changes are predicted through a Non-Local Linear Regression (NL-LR) of the subject pixel's similar neighbors. A regression based high-pass modulation is also performed as a post-processing step to improve both the spatial details and spectral fidelity of the predicted Landsat image. Unlike other STIF models (e.g., the Spatial and Temporal Adaptive Reflectance Fusion Model, STARFM), RASTFM can find similar neighboring pixels more precisely through a non-local searching strategy and derives the weights of similar neighbors more rigorously via a linear regression model. As both non-shape and shape changes are treated based on the regression of similar neighboring pixels, the land surface changes are processed in a unified manner. Experiments that use one simulated and three actual MODIS-Landsat datasets featured by different types of land surface changes were conducted to demonstrate the performance of RASTFM. Comparisons with the state-of-the-art STIF models, including weighted function, unmixing and dictionary-learning methods, show that NL-LR based RASTFM can capture the land surface changes in various landscapes more accurately and robustly in a unified manner, thereby facilitating the continuous and detailed monitoring of complex and diverse land surface dynamics. © 2018 Elsevier Inc.","Image enhancement; Image processing; Linear regression; Pixels; Radiometers; Regression analysis; Satellite imagery; Surface measurement; Critical challenges; Feasible alternatives; Image super resolutions; Linear regression models; Phenological changes; Shape change; Spatial and temporal resolutions; Spatio-temporal fusions; complexity; experimental study; feasibility study; image resolution; land cover; land surface; Landsat; MODIS; performance assessment; pixel; regression analysis; satellite imagery; sensor; shape; spatiotemporal analysis; Image fusion","Image super-resolution; NL-LR; Non-shape change; Shape change; Spatiotemporal fusion","Article","Final","","Scopus","2-s2.0-85042030427"
"Pour T.; Burian J.; Miřijovský J.","Pour, Tomáš (57190172675); Burian, Jaroslav (35112842600); Miřijovský, Jakub (56483246400)","57190172675; 35112842600; 56483246400","Application of seath algorithm on high resolution data sets of selected cities","2016","International Multidisciplinary Scientific GeoConference Surveying Geology and Mining Ecology Management, SGEM","1","","","","","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061827143&partnerID=40&md5=9780e31929349f3a25b17a64b498063c","In this paper authors processed five satellite image of five different Middle-European cities taken by five different sensors. The aim of the paper was to find methods and approaches leading to evaluation and spatial data extraction from areas of interest. For this reason, data were firstly pre-processed using image fusion, mosaicking and segmentation processes. Results going into the next step were two polygon layers; first one representing single objects and the second one representing city blocks. In the second step, polygon layers were classified and exported into Esri shapefile format. Classification was partly hierarchical expert based and partly based on the tool SEaTH used for separability distinction and thresholding. Final results along with visual previews were attached to the original thesis. Results are evaluated visually and statistically in the last part of the paper. In the discussion author described difficulties of working with data of large size, taken by different sensors and different also thematically. © 2016, International Multidisciplinary Scientific Geoconference. All rights reserved.","Image analysis; Image fusion; Laws and legislation; Satellite imagery; European cities; High resolution data; Obia; Satellite images; Seath; Segmentation process; Single object; Urban areas; Image segmentation","Image Analysis; Obia; Satellite Imagery; Seath; Urban Areas","Conference paper","Final","","Scopus","2-s2.0-85061827143"
"Xue J.; Leung Y.; Fung T.","Xue, Jie (55377240700); Leung, Yee (56220381700); Fung, Tung (7102715957)","55377240700; 56220381700; 7102715957","An unmixing-based Bayesian model for spatio-temporal satellite image fusion in heterogeneous landscapes","2019","Remote Sensing","11","3","324","","","","10.3390/rs11030324","19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061370060&doi=10.3390%2frs11030324&partnerID=40&md5=480bd1f14abec9b84a2cf829fe297de8","Studies of land surface dynamics in heterogeneous landscapes often require satellite images with a high resolution, both in time and space. However, the design of satellite sensors often inherently limits the availability of such images. Images with high spatial resolution tend to have relatively low temporal resolution, and vice versa. Therefore, fusion of the two types of images provides a useful way to generate data high in both spatial and temporal resolutions. A Bayesian data fusion framework can produce the target high-resolution image based on a rigorous statistical foundation. However, existing Bayesian data fusion algorithms, such as STBDF (spatio-temporal Bayesian data fusion) -I and -II, do not fully incorporate the mixed information contained in low-spatial-resolution pixels, which in turn might limit their fusion ability in heterogeneous landscapes. To enhance the capability of existing STBDF models in handling heterogeneous areas, this study proposes two improved Bayesian data fusion approaches, coined ISTBDF-I and ISTBDF-II, which incorporate an unmixing-based algorithm into the existing STBDF framework. The performance of the proposed algorithms is visually and quantitatively compared with STBDF-II using simulated data and real satellite images. Experimental results show that the proposed algorithms generate improved spatio-temporal-resolution images over STBDF-II, especially in heterogeneous areas. They shed light on the way to further enhance our fusion capability. © 2019 by the authors.","Bayesian networks; Data visualization; Image enhancement; Image resolution; Remote sensing; Satellites; Bayesian data fusions; Bayesian estimation framework; Heterogeneous landscapes; High resolution image; High spatial resolution; Spatial and temporal resolutions; Spatio-temporal resolution; Unmixing; Image fusion","Bayesian estimation framework; Heterogeneous landscape; High spatiotemporal resolution; Image fusion; Remote sensing; Spatial unmixing","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85061370060"
"Hoa L.N.H.; Cuong L.D.; Ke L.C.","Hoa, Luong Nguyen Hoang (57192643662); Cuong, Le Danh (57192640194); Ke, Luong Chinh (55349390600)","57192643662; 57192640194; 55349390600","Enhanced spatial resolution for VNREDSat-1 multispectral images using IHS fusion technique based on sensor spectral response function","2016","Proceedings - 2016 8th International Conference on Knowledge and Systems Engineering, KSE 2016","","","7758071","304","308","4","10.1109/KSE.2016.7758071","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006974081&doi=10.1109%2fKSE.2016.7758071&partnerID=40&md5=0d031be32ef12b726708d09311bd66fd","Fusion technique of panchromatic image Pan in high spatial resolution with multispectral images MS (R, G, B, NIR) in low spatial resolution of Vietnam VNREDSat-1 satellite images to create multispectral images in high spatial resolution is described in this paper. The fusion method is based on the sensor spectral characteristics of VNREDSat-1, so called as sensor spectral response function. The proposed algorithm for image fusion will be evaluated through quantitative quality of fused images, based on the image statistical parameters such as the threshold error (bias), standard deviation (SD), root mean square error (RMSE) and ERGAS index. Surveying results of five studied show that the solution using the distances weighting between four multispectral image channels (R, G, B, NIR) and Pan image of Vietnam VNREDSat-1 data for Intensity-Hue-Saturation (IHS) method was very effective in fast calculation time, low cost, good quality of fused images. © 2016 IEEE.","Image resolution; Infrared devices; Mean square error; Satellite imagery; Systems engineering; High spatial resolution; Intensity hue saturations; Multispectral images; Panchromatic images; Root mean square errors; Spectral characteristics; Spectral response functions; Statistical parameters; Image fusion","","Conference paper","Final","","Scopus","2-s2.0-85006974081"
"Hyma Lakshmi T.V.; Srikavya K.C.; Madhu T.","Hyma Lakshmi, T.V. (56938851000); Srikavya, K. Ch. (57220043625); Madhu, Tenneti (12138817700)","56938851000; 57220043625; 12138817700","Satellite image enhancement based on the half-band polynomial sub bands fusion and CLAHE","2018","Journal of Advanced Research in Dynamical and Control Systems","10","4","","333","338","5","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069642942&partnerID=40&md5=2710548a071ba6bffa5e02b6065115cd","--The acquisition of high resolution satellite images is very difficult due to the instrument limitation, high altitude of the satellite's orbit and atmospheric conditions. Low resolution satellite images consists a lot of mixed pixels which degrade the detection and recognition of the information. However, high resolution images play a key role in many image processing applications. In this paper we proposed novel satellite image enhancement technique based on the half band polynomial sub bands image fusion and contrast limited adaptive histogram equalization. First the input image is decomposed into two low resolution images based on the half band polynomial. The two low resolution images are registered at a specific shift from one another by using quincunx sampling and dyadic integer coefficient wavelet filter is used to restore the resolution lost by CCD array of cameras and then, contrast limited adaptive histogram equalization is applied for contrast enhancement. The proposed method has been tested on different satellite images. The quantitative (peak signal-to-noise ratio) and visual results show the superiority of the proposed technique over the conventional and state-of-art image resolution enhancement techniques. © 2018, Institute of Advanced Scientific Research, Inc.. All rights reserved.","","Clip limit based adaptive histogram equalization; Contrast enhancement; Half band polynomial; Satellite images; Super resolution","Article","Final","","Scopus","2-s2.0-85069642942"
"Saxena N.; Sharma K.K.","Saxena, Nidhi (56516227500); Sharma, K.K. (55645022100)","56516227500; 55645022100","A two-dimensional discrete fractional Fourier transform-based pansharpening scheme","2019","International Journal of Remote Sensing","40","16","","6098","6115","17","10.1080/01431161.2019.1587203","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062728488&doi=10.1080%2f01431161.2019.1587203&partnerID=40&md5=7eeb13b72476e7d1c258c137bb29b9ec","In this paper, a new approach for fusion of multi-spectral (MS) and panchromatic (Pan) images based on 2D-discrete fractional Fourier transform (2D-DFRFT) is proposed. The proposed technique is closer in approach to the other filtering-based pansharpening schemes existing in the literature. In the proposed method histogram equalized Pan image is transformed using the 2D-DFRFT and further used to generate the pansharpened image using appropriate pansharpening rule. The angle parameters associated with the 2D-DFRFT provide additional degrees of freedom which are optimized by single-objective particle swarm optimization (PSO) algorithm for finding better pansharpening results. Simulation results of the proposed technique carried out in MATLAB are presented for IKONOS and GeoEye-1 satellite images and compared with existing fusion methods in terms of both visual perception and objective metrics such as Q-index (Q4), Spectral Angle Mapper (SAM), relative dimensionless global error (ERGAS) and quality with-no reference (QNR). It is observed that the proposed pansharpening scheme provides improved spectral and spatial quality as compared with the existing schemes. The effects of aliasing and mis-registration errors on the proposed method are also investigated and compared with existing pansharpening methods. It is seen that the proposed method is robust against aliasing and mis-registration errors. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Degrees of freedom (mechanics); Errors; MATLAB; Particle swarm optimization (PSO); Discrete fractional Fourier transforms; Objective metrics; Panchromatic (Pan) image; Pansharpened images; Particle swarm optimization algorithm; Registration error; Spectral angle mappers; Visual perception; algorithm; data quality; Fourier transform; GeoEye; histogram; IKONOS; multispectral image; panchromatic image; remote sensing; satellite imagery; two-dimensional modeling; Image fusion","","Article","Final","","Scopus","2-s2.0-85062728488"
"Ghahremani M.; Ghassemian H.","Ghahremani, Morteza (55912181900); Ghassemian, Hassan (57204122949)","55912181900; 57204122949","A compressed-sensing-based pan-sharpening method for spectral distortion reduction","2016","IEEE Transactions on Geoscience and Remote Sensing","54","4","7335613","2194","2206","12","10.1109/TGRS.2015.2497309","75","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949908191&doi=10.1109%2fTGRS.2015.2497309&partnerID=40&md5=593663643109fecca828ccbfa064ea15","Recently, the compressed sensing (CS) theory has become an interesting topic for pan-sharpening of multispectral images. The CS theory ensures that, under the sparsity regularization, an unknown sparse signal can be exactly recovered from a drastically smaller number of linear measurements. In this paper, we propose a CS-based approach for fusion of the multispectral and panchromatic satellite images. The contribution of this paper is twofold. First, with the spatial and spectral characteristics of the satellite images, we assume that each patch of the unknown high spatial resolution intensity (HRI) component can be represented as a linear combination of atoms in a dictionary trained only from the panchromatic image; thus, the problem of generating an optimal dictionary is solved. Second, we propose an iterative algorithm to obtain the sparsest coefficients. The sparsest coefficients ensure that the estimated HRI component can be correctly recovered from the panchromatic image. The IKONOS, QuickBird, and WorldView-2 data are used to evaluate the performance of the proposed method. The experimental results demonstrate that the proposed method generates high-quality pan-sharpened multispectral bands quantitatively and perceptually. © 1980-2012 IEEE.","Algorithms; Iterative methods; Satellite imagery; Signal reconstruction; High spatial resolution; Iterative algorithm; Multispectral images; Panchromatic images; Panchromatic satellites; Sparsity regularizations; Spectral characteristics; Spectral distortions; algorithm; experimental study; IKONOS; image analysis; measurement method; QuickBird; remote sensing; satellite data; satellite imagery; spatial resolution; WorldView; Compressed sensing","Compressed sensing (CS); Image fusion; Multispectral data; Pan-sharpening; Panchromatic data; Sparse representation","Article","Final","","Scopus","2-s2.0-84949908191"
"Patel M.I.; Thakar V.K.","Patel, Manish I. (57188760171); Thakar, Vishvjit K. (8418004000)","57188760171; 8418004000","Speed improvement in image registration using maximum likelihood based mutual information","2015","ICACCS 2015 - Proceedings of the 2nd International Conference on Advanced Computing and Communication Systems","","","7324130","","","","10.1109/ICACCS.2015.7324130","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962784363&doi=10.1109%2fICACCS.2015.7324130&partnerID=40&md5=ab480cd29804a75e2047c34853fc44b1","One of the important steps in image fusion is image registration. The process of determining the spatial transformation that maps the points in the target image to the points in the source image is known as image registration. Various image registration approaches can be classified as area, feature and transform domain based. Choice of approach depends on image contents and application. In case of area based approach, during the image registration process similarity measure (also known as similarity metric) is required to measure the similarity between two images. Various similarity measures have been reported such as sum of squared difference, sum of absolute difference, cross correlation, normalized cross correlation and Mutual Information (MI). For multimodal image registration MI is more appropriate. The computation time for MI is challenging for large images for example, satellite images. Various techniques are found in literature to compute MI. One of the techniques is maximum likelihood mutual information (MLMI), which estimates MI between two random variables. In this paper, we have performed image registration using MI as a similarity measure. In this case MI is computed using two approaches; one is MLMI and second is histogram based. Computation time for image registration process on various images is observed and compared for both approaches. It is shown that computation time of IR based on first approach is less than the second approach. © 2015 IEEE.","Image coding; Image fusion; Image registration; Maximum likelihood; Multimodal image registration; Mutual informations; Normalized cross correlation; Registration process; Similarity measure; Spatial transformation; Sum of absolute differences; Sum of squared differences; Image processing","image registration; maximum likelihood; mutual information; similarity measure","Conference paper","Final","","Scopus","2-s2.0-84962784363"
"Omar Z.; Hamzah N.; Stathaki T.","Omar, Zaid (37014766900); Hamzah, Nur’Aqilah (56426870300); Stathaki, Tania (7003386658)","37014766900; 56426870300; 7003386658","Adaptive chebyshev fusion of vegetation imagery based on SVM classifier","2016","Jurnal Teknologi","78","6-11","","9","17","8","10.11113/jt.v78.9175","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976416466&doi=10.11113%2fjt.v78.9175&partnerID=40&md5=b92279e5775ea73e4f78d4d110e171da","A novel adaptive image fusion method by using Chebyshev polynomial analysis (CPA), for applications in vegetation satellite imagery, is introduced in this paper. Fusion is a technique that enables the merging of two satellite cameras: panchromatic and multi-spectral, to produce higher quality satellite images to address agricurtural and vegetation issues such as soiling, floods and crop harvesting. Recent studies show Chebyshev polynomials to be effective in image fusion mainly in medium to high noise conditions, as per real-life satellite conditions. However, its application was limited to heuristics. In this research, we have proposed a way to adaptively select the optimal CPA parameters according to user specifications. Support vector machines (SVM) is used as a classifying tool to estimate the noise parameters, from which the appropriate CPA degree is utilised to perform image fusion according to a look-up table. Performance evaluation affirms the approach’s ability in reducing the computational complexity to perform fusion. Overall, adaptive CPA fusion is able to optimize an image fusion system’s resources and processing time. It therefore may be suitably incorporated onto real hardware for use on vegetation satellite imagery. © 2016 Penerbit UTM Press. All rights reserved.","","Chebyshev polynomials; Image fusion; Remote sensing","Article","Final","","Scopus","2-s2.0-84976416466"
"Daza R.J.M.; Becerra Gonzalez L.C.; Leon J.C.M.","Daza, Ruben Javer Medina (57193828334); Becerra Gonzalez, Laura Cristina (57190662145); Leon, Jhon Camilo Matiz (57188955737)","57193828334; 57190662145; 57188955737","Improving the spatial resolution of Ikonos images based on orthophotos: An application of image fusion with wavelet transform; [Mejoramiento de la resolución espacial de las imágenes Ikonos a partir de ortofotos: una aplicación de la fusión de imágenes con la Transformada Wavelet]","2016","Iberian Conference on Information Systems and Technologies, CISTI","2016-July","","7521528","","","","10.1109/CISTI.2016.7521528","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982162392&doi=10.1109%2fCISTI.2016.7521528&partnerID=40&md5=ba88c8dd8da695e5fc3f503c11e1b3b9","This article aims to develop and evaluate two methodologies that improve the spatial resolution without significant loss of spectral resolution, with an Ikonos and orthophoto image. Using the transformation RGB-IHS principal component analysis (PCA). Applying fusion to components multispectral image intensity (Im) and orthophotos (Io) by the wavelet transform. Similarly to the main component of the multispectral image (CP1M) and orthophoto (CP1o) using Wavelet transformed together with ARSIS technique a new intensity and a major new component is generated respectively. To perform the inverse transformed independently IHS-RGB and IACP, and thus obtain two multispectral images. Finally, the results obtained with the mathematical-statistical indices CC, ERGAS, RASE and Qu are presented. © 2016 AISTI.","Fusion reactions; Genes; Image resolution; Information systems; Principal component analysis; Wavelet transforms; Multi-spectral; Multispectral images; Ortho photos; Orthophoto images; Satellite images; Spatial resolution; Statistical indices; Wavelet; Image fusion","Fusion; multispectral; orthophoto; satellite images; Wavelet","Conference paper","Final","","Scopus","2-s2.0-84982162392"
"Bahmanyar R.; Espinoza-Molina D.; Datcu M.","Bahmanyar, Reza (56042026400); Espinoza-Molina, Daniela (26642362900); Datcu, Mihai (7004523124)","56042026400; 26642362900; 7004523124","Multisensor Earth Observation Image Classification Based on a Multimodal Latent Dirichlet Allocation Model","2018","IEEE Geoscience and Remote Sensing Letters","15","3","","459","463","4","10.1109/LGRS.2018.2794511","22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041660854&doi=10.1109%2fLGRS.2018.2794511&partnerID=40&md5=61a846a17f2d3db8689a08f156c74801","Many previous researches have already shown the advantages of multisensor land-cover classification. Here, we propose an innovative land-cover classification approach based on learning a joint latent model of synthetic aperture radar (SAR) and multispectral satellite images using multimodal latent Dirichlet allocation (mmLDA), a probabilistic generative model. It has already been successfully applied to various other problems dealing with multimodal data. For our experiments, we chose overlapping SAR and multispectral images of two regions of interest. The images were tiled into patches and their local primitive features were extracted. Then each image patch is represented by SAR and multispectral bag-of-words (BoW) models. The BoW values are both fed to the mmLDA, resulting in a joint latent data model. A qualitative and quantitative validation of the topics based on ground-truth data demonstrate that the land-cover categories of the regions are correctly classified, outperforming the topics obtained using individual single modality data. © 2004-2012 IEEE.","Image classification; Image fusion; Statistics; Synthetic aperture radar; Earth observation images; Land cover classification; Latent Dirichlet allocation; Multispectral images; Multispectral satellite image; Quantitative validation; Regions of interest; Synthetic aperture radar (SAR) images; EOS; image classification; image processing; land classification; land cover; model; multispectral image; numerical method; radar imagery; sensor; synthetic aperture radar; Radar imaging","Image fusion; land-cover classification; multimodal latent Dirichlet allocation (mmLDA); multispectral images; synthetic aperture radar (SAR) images","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85041660854"
"Jing Z.; Lu C.; Li Z.; Wenhao G.; Chao W.","Jing, Zhang (57650042100); Lu, Chen (57192588502); Li, Zhuo (57191699923); Wenhao, Geng (57202580065); Chao, Wang (56113236000)","57650042100; 57192588502; 57191699923; 57202580065; 56113236000","Multiple saliency features based automatic road extraction from high-resolution multispectral satellite images","2018","Chinese Journal of Electronics","27","1","","133","139","6","10.1049/cje.2017.11.008","18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048749768&doi=10.1049%2fcje.2017.11.008&partnerID=40&md5=60d63abd845c8835e1bc4715f8f0af1c","Roads as important artificial objects are the main body of modern traffic system, which provide many conveniences for human civilization. With the development of remote sensing and hyperspectral imaging technology, how to automatically and accurately extract road network from high-resolution multispectral satellite images has become a hot and challenging research topic of geographic information technology. In this paper, an automatic road extraction method from high-resolution multispectral satellite images is proposed by using multiple saliency features. Firstly, road edge is extracted by detecting local linear edge with Singular value decomposition (SVD). Secondly, road regions are constructed by K-means clustering after extracting the feature of background difference. Then road network is achieved by integrating multiple saliency features with Total variation (TV) based image fusion algorithm. Finally, the non-road parts and noises are removed from road network by optimizing multiple salient features with post-processing and morphological operations. The experimental results show that the proposed method can achieve a superior performance in completeness and correctness. © 2018 Chinese Institute of Electronics.","Extraction; Feature extraction; Hyperspectral imaging; Image fusion; K-means clustering; Mathematical morphology; Roads and streets; Satellites; Singular value decomposition; Spectroscopy; Artificial objects; Automatic road extraction; Feature-based; High resolution; High-resolution multispectral satellite image; Multiple saliency feature; Multispectral satellite image; Road extraction; Road network; Saliency features; Remote sensing","High-resolution multispectral satellite images; Multiple saliency features; Road extraction; Road network","Article","Final","","Scopus","2-s2.0-85048749768"
"Korosov A.A.; Pozdnyakov D.V.","Korosov, Anton A. (6505884703); Pozdnyakov, Dmitry V. (56370460300)","6505884703; 56370460300","Fusion of data from Sentinel-2/MSI and Sentinel-3/OLCI","2016","European Space Agency, (Special Publication) ESA SP","SP-740","","","","","","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988527720&partnerID=40&md5=5447134425902a85de7c3bf365940a75","Multisensor image fusion is the process of combining relevant information from two or more satellite images into a single image. The fused image can have complementary spatial and spectral resolution characteristics. We suggest a method for fusion of data from Sentinel-2 multi spectral imager (MSI) and Sentinel-3 Ocean and Land Color Instrument (OLCI). In the visible range MSI measures radiance with 10 m resolution at 490, 560 and 665 nm; with 20 m resolution at 705 nm; and with 60 m resolution at 443 nm. In the visible range OLCI measures with 300 m spatial resolution at 400, 412, 443, 490, 510, 560, 620, 665, 673, 681, 708 nm. The data from the visible from both sensors is fused to get products with values of remote sensing reflectance wavelengths of OLCI and with spatial resolution of 60 m using an artificial neural network.","Image fusion; Image resolution; Neural networks; Spectroscopy; Fused images; Multi spectral imager; Multisensor image fusion; Remote-sensing reflectance; Satellite images; Single images; Spatial resolution; Visible range; Remote sensing","","Conference paper","Final","","Scopus","2-s2.0-84988527720"
"Biswas B.; Dey K.N.; Chakrabarti A.","Biswas, Biswajit (7103207978); Dey, Kashi Nath (7005770173); Chakrabarti, Amlan (24342850300)","7103207978; 7005770173; 24342850300","Remote Sensing Image Fusion using Multithreshold Otsu Method in Shearlet Domain","2015","Procedia Computer Science","57","","","554","562","8","10.1016/j.procs.2015.07.388","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944096855&doi=10.1016%2fj.procs.2015.07.388&partnerID=40&md5=8c47465573a3361f224eb764cae484e4","In remote sensing image fusion, preservation of spectral information and enhancement of spatial resolution are key issues. In this paper, a novel approach of remote sensing satellite image fusion method have been proposed based on Otsu's Multi-thresholding Method (MOM) in shearlet domain. We make that happened in two folds, i) shearlet transform (ST) is applied in each high- spatial-resolution Panchromatic (PAN) and multi-spectral (MS) image separately, ii) the updated low frequency sub-band shearlet coefficients from decomposed shealet images are composed by the MOM method and select largest low-pass band automatically. The process of different high-pass sub-band shearlet coefficients have been discussed in detail. For obtaining the fused result we use the inverse shearlet transformation (IST). The experimental results show that the proposed method outperforms many state-of- the-art techniques in performance assessment. © 2015 The Authors. Published by Elsevier B.V.","Image reconstruction; Image resolution; Inverse problems; Remote sensing; Satellite imagery; High spatial resolution; Multithreshold; Mutual informations; Performance assessment; Remote sensing images; Remote sensing satellites; Shearlet transforms; State-of-the-art techniques; Image fusion","multithreshold; mutual information; Remote sensing image fusion; shearlet transform","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-84944096855"
"Bai Y.; Wong M.S.; Shi W.-Z.; Wu L.-X.; Qin K.","Bai, Yang (56201568500); Wong, Man Sing (57210337677); Shi, Wen-Zhong (7402664815); Wu, Li-Xin (55714061400); Qin, Kai (35220430700)","56201568500; 57210337677; 7402664815; 55714061400; 35220430700","Advancing of land surface temperature retrieval using extreme learning machine and spatio-temporal adaptive data fusion algorithm","2015","Remote Sensing","7","4","","4424","4441","17","10.3390/rs70404424","36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937906214&doi=10.3390%2frs70404424&partnerID=40&md5=8c8f68b0cfb764e287bf54adb6de7882","As a critical variable to characterize the biophysical processes in ecological environment, and as a key indicator in the surface energy balance, evapotranspiration and urban heat islands, Land Surface Temperature (LST) retrieved from Thermal Infra-Red (TIR) images at both high temporal and spatial resolution is in urgent need. However, due to the limitations of the existing satellite sensors, there is no earth observation which can obtain TIR at detailed spatial- and temporal-resolution simultaneously. Thus, several attempts of image fusion by blending the TIR data from high temporal resolution sensor with data from high spatial resolution sensor have been studied. This paper presents a novel data fusion method by integrating image fusion and spatio-temporal fusion techniques, for deriving LST datasets at 30 m spatial resolution from daily MODIS image and Landsat ETM+ images. The Landsat ETM+ TIR data were firstly enhanced based on extreme learning machine (ELM) algorithm using neural network regression model, from 60 m to 30 m resolution. Then, the MODIS LST and enhanced Landsat ETM+ TIR data were fused by Spatio-temporal Adaptive Data Fusion Algorithm for Temperature mapping (SADFAT) in order to derive high resolution synthetic data. The synthetic images were evaluated for both testing and simulated satellite images. The average difference (AD) and absolute average difference (AAD) are smaller than 1.7 K, where the correlation coefficient (CC) and root-mean-square error (RMSE) are 0.755 and 1.824, respectively, showing that the proposed method enhances the spatial resolution of the predicted LST images and preserves the spectral information at the same time. © 2015 by the authors; licensee MDPI, Basel, Switzerland.","Algorithms; Atmospheric temperature; Data fusion; Image resolution; Infrared imaging; Knowledge acquisition; Learning algorithms; Learning systems; Mean square error; Radiometers; Regression analysis; Satellite imagery; Sensor data fusion; Surface measurement; Surface properties; Extreme learning machine; Land surface temperature; LANDSAT; Modis; Spatial temporals; Thermal infrared images; Image fusion","Extreme learning machine; Land surface temperature; Landsat; Modis; Spatial-temporal fusion; Thermal infrared images","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84937906214"
"Thriveni R.; Ramashri","Thriveni, R. (55616905900); Ramashri (57053434300)","55616905900; 57053434300","Edge preserving Satellite image enhancement using DWT-PCA based fusion and morphological gradient","2015","Proceedings of 2015 IEEE International Conference on Electrical, Computer and Communication Technologies, ICECCT 2015","","","7226022","","","","10.1109/ICECCT.2015.7226022","16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954125965&doi=10.1109%2fICECCT.2015.7226022&partnerID=40&md5=694b156e8fcd9101eacac3043a91559c","Image processing is a very broad field that includes compression, feature detection, and classification etc. The output of the digital sensor is a 'raw' digital image that consists of an array of digital count values with each value representing the brightness, or gray level, of a pixel in the image. The effort on edge enhancement is to emphasize specific feature of the image for visual perception or feature extraction. Edge-preserving image enhancement is of great interest in Satellite image processing. In this study we propose a DWT-PCA based fusion and Morphological gradient for enhancement of Satellite images. The input image is decomposed into different sub bands through DWT. PCA based fusion is apply on the low-low sub band, and input image for contrast enhancement. IDWT is used to reconstructs the enhanced image. To achieve a sharper boundary discontinuities of image, an intermediate stage estimating the fine detail sub bands is required. This is done by the success of threshold decomposition, morphological gradient based operators are used to detect the locations of the edges and sharpen the detected edges. The proposed method has been shown that improved visibility and perceptibility of various digital satellite images. © 2015 IEEE.","Discrete wavelet transforms; Feature extraction; Image enhancement; Image fusion; Image segmentation; Satellite imagery; Satellites; Wavelet transforms; Color images; Contrast Enhancement; Digital satellite images; Edge enhancements; Intermediate stage; Morphological gradient; Satellite image processing; Threshold decomposition; Image processing","Discrete wavelet transforms (DWT); Morphological Gradient; PCA Based Fusion; satellite color image contrast enhancement","Conference paper","Final","","Scopus","2-s2.0-84954125965"
"Huang Q.; Zhao Z.; Gao Q.; Meng Y.; Ma J.; Chen J.","Huang, Qingqing (55467449900); Zhao, Zhongming (7404147874); Gao, Qiong (56733985400); Meng, Yu (35778744500); Ma, Jianglin (55500025100); Chen, Jingbo (56386393100)","55467449900; 7404147874; 56733985400; 35778744500; 55500025100; 56386393100","Improved fusion method for remote sensing imagery using NSCT and extend IHS","2015","IFAC-PapersOnLine","28","3","","64","69","5","10.1016/j.ifacol.2015.06.059","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953862425&doi=10.1016%2fj.ifacol.2015.06.059&partnerID=40&md5=a7918660b91c5a3c865265c1597fe4a4","This paper proposes a hybrid fusion method that can combine the advantages of two popular image fusion schemes: fusion in the spatial domain and fusion in the transform domain. The Extend IHS (EIHS) fusion method is chosen within the spatial domain fusion scheme because this method can well maintain the spatial details of the panchromatic image while reducing the spectral distortion of the multispectral images by taking into account the spectral response of each spectral band. However, using EIHS may lead to severe spectral distortion in some cases as we will discover in this paper, hence Nonsubsampled Contourlet Transform (NSCT) is introduced as it can preserve the spectrum discontinuity of multispectral images. By doing so, both spatial details in the panchromatic image and spectral information in the multispectral image are kept in the fused image. Experiments with QuickBird and IKONOS satellite images show that the proposed method can obtain better visual fusion results than traditional image fusion methods, which is also supported by the image fusion numerical criteria. © 2015, IFAC (International Federation of Automatic Control) Hosting by Elsevier Ltd. All rights reserved.","Image enhancement; Numerical methods; Remote sensing; EIHS; Ikonos satellite image; Image fusion methods; Multispectral images; Non subsampled contourlet transform (NSCT); NSCT; Remote sensing imagery; Spectrum discontinuities; Spectral distortions; Spectral information; Image fusion","EIHS; Image fusion; NSCT; Remote sensing","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-84953862425"
"Byun Y.; Han Y.; Chae T.","Byun, Younggi (36140045400); Han, Youkyung (55457676600); Chae, Taebyeong (54408189100)","36140045400; 55457676600; 54408189100","Image fusion-based change detection for flood extent extraction using bi-temporal very high-resolution satellite images","2015","Remote Sensing","7","8","","10347","10363","16","10.3390/rs70810347","51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939436339&doi=10.3390%2frs70810347&partnerID=40&md5=69dbcf181c31f1eccc8e4c2fa27b62b1","Change detection based on satellite images acquired from an area at different dates is of widespread interest, according to the increasing number of flood-related disasters. The images help to generate products that support emergency response and flood management at a global scale. In this paper, a novel unsupervised change detection approach based on image fusion is introduced. The approach aims to extract the reliable flood extent from very high-resolution (VHR) bi-temporal images. The method takes an advantage of the spectral distortion that occurs during image fusion process to detect the change areas by flood. To this end, a change candidate image is extracted from the fused image generated with bi-temporal images by considering a local spectral distortion. This can be done by employing a universal image quality index (UIQI), which is a measure for local evaluation of spectral distortion. The decision threshold for the determination of changed pixels is set by applying a probability mixture model to the change candidate image based on expectation maximization (EM) algorithm. We used bi-temporal KOMPSAT-2 satellite images to detect the flooded area in the city of N'djamena in Chad. The performance of the proposed method was visually and quantitatively compared with existing change detection methods. The results showed that the proposed method achieved an overall accuracy (OA = 75.04) close to that of the support vector machine (SVM)-based supervised change detection method. Moreover, the proposed method showed a better performance in differentiating the flooded area and the permanent water body compared to the existing change detection methods. © 2015 by the authors; licensee MDPI, Basel, Switzerland.","Algorithms; Flood control; Floods; Image processing; Maximum principle; Satellite imagery; Satellites; Signal detection; Support vector machines; Change detection; Expectation-maximization algorithms; Image quality index; Spectral distortions; Supervised change detection; Unsupervised change detection; Very high resolution; Very high resolution satellite images; Image fusion","Change detection; Flood extent; KOMPSAT-2 satellite imagery; Spectral distortion","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84939436339"
"Merkle N.; Müller R.; Reinartz P.","Merkle, N. (57194604557); Müller, R. (7404246697); Reinartz, P. (56216874200)","57194604557; 7404246697; 56216874200","Registration of optical and SAR satellite images based on geometric feature templates","2015","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","40","1W5","","447","452","5","10.5194/isprsarchives-XL-1-W5-447-2015","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974536576&doi=10.5194%2fisprsarchives-XL-1-W5-447-2015&partnerID=40&md5=0657dffb3aa3f27ae704d1bd6cf5986b","Image registration is required for different remote sensing applications, like change detection or image fusion. Since research studies have shown the outstanding absolute geometric accuracy of high resolution radar satellites images like TerraSAR-X, the importance of SAR images as source for geolocation enhancement has increased. Due to this fact, multi-sensor image to image registration of optical and SAR images can be used for the improvement of the absolute geometric processing and accuracy of optical ima ges with TerraSAR-X as reference. In comparison to the common optical and SAR image registration methods the proposed method is a combination of intensity-based and feature-based approaches. The proposed method avoids the direct and often difficult detection of features from the SAR images. SAR-like templates are generated from features detected from the optical image. These templates are used for an intensity-based matching with the SAR image. The results of the matching process are ground control points, which are used for the estimation of translation parameters followed by a subpixel translation of the optical image. The proposed image registration method is tested for two pairs of TerraSAR-X and QuickBird images and one pair of TerraSAR-X andWorldView-2 i mages of a suburban area. The results show that with the proposed method the geometric accuracy of optical images can be enhanced.","Feature extraction; Geometrical optics; Geometry; Image fusion; Image matching; Image processing; Image registration; Remote sensing; Rock mechanics; Satellites; Space-based radar; Synthetic aperture radar; Image; Matching; Multi sensor; Multi-spectral; Optical; Registration; Radar imaging","Image; Matching; Multisensor; Multispectral; Optical; Registration; SAR","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84974536576"
"Abd Manaf S.; Mustapha N.; Sulaiman M.N.; Husin N.A.; Abdul Hamid M.R.","Abd Manaf, Syaifulnizam (55185057700); Mustapha, Norwati (24802568600); Sulaiman, Md Nasir (22434244300); Husin, Nor Azura (25825147600); Abdul Hamid, Mohd Radzi (57190281942)","55185057700; 24802568600; 22434244300; 25825147600; 57190281942","Fusion of optical and SAR in extracting shoreline at northeast coast of peninsular Malaysia","2015","ACRS 2015 - 36th Asian Conference on Remote Sensing: Fostering Resilient Growth in Asia, Proceedings","","","","","","","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964057231&partnerID=40&md5=ea1b71bb8b9fecedcfca8cb0d49b0cc6","Shoreline extraction is important to identify exact land and water boundary of a country. However, it is difficult and time consuming for a large region when using traditional ground survey techniques. Alternatively, by using remote sensing for extracting shoreline is rapid and highly accurate thus minimizing the mapping errors. Although Google Map and Google Earth are open freely for public, they are not suitable to extract shoreline due to some important spectral information have been remove out. The problem in shoreline detection is the difficulty of extraction according to hydrodynamic condition of coastal area such as tides, current, etc. that leads to low accuracy rate. In extracting shoreline, remotely sensed images could be analyzed by using satellite image processing techniques. By using fusion of multispectral and SAR images, shoreline could be extracted with a higher accuracy rate.","Extraction; Image fusion; Optical data processing; Radar imaging; Remote sensing; Satellite imagery; Space-based radar; Synthetic aperture radar; Ground surveys; Highly accurate; Hydrodynamic conditions; Optical satellite images; Remotely sensed images; Satellite image processing; Spectral information; Water boundaries; Image processing","Image fusion; Optical satellite image; Shoreline extraction; Synthetic Aperture Radar (SAR)","Conference paper","Final","","Scopus","2-s2.0-84964057231"
"Biswas B.; Sen B.K.; Choudhuri R.","Biswas, Biswajit (7103207978); Sen, Biplab Kanti (57188667120); Choudhuri, Ritamshirsa (57021475200)","7103207978; 57188667120; 57021475200","Remote Sensing Image Fusion using PCNN Model Parameter Estimation by Gamma Distribution in Shearlet Domain","2015","Procedia Computer Science","70","","","304","310","6","10.1016/j.procs.2015.10.098","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962736454&doi=10.1016%2fj.procs.2015.10.098&partnerID=40&md5=4fc2b93eb194fb4a1cb219275218127d","Here the proposed approach deals with some adaptive parameters in pulse coupled neural network (PCNN) model which are highly suitable in image fusion. Initially, the source images are separately decomposed into multi-scaled and multi-directional bands by shearlet transform (ST). Later, the PCNN model is mapped between the decomposed low pass ST sub-bands which depends on linking pulse response and coupling strength with regional statistics of ST coefficients. The process of different high pass ST sub-bands and utilization of singular value decomposition (SDV) have been discussed in details. Finally, we have obtained fusion results by the inverse shearlet transformation (IST). The experimental results on satellite images show that the proposed method has good performance and able to preserve spectral information and high spatial details simultaneously like the original source images. The objective evaluation criteria and visual effect illustrate that our proposed method has a better edge over the prevalent image fusion methods. © 2015 The Authors.","Environmental protection; Image reconstruction; Inverse problems; Neural networks; Probability distributions; Remote sensing; Singular value decomposition; Gamma distribution; Remote sensing images; Shearlet transforms; Single value decompositions; Spectral angle mappers; Image fusion","gamma distribution; pulse code neural network; Remote sensing image fusion; shearlet transform; single value decomposition; spectral angle mapper","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-84962736454"
"Subramanian P.; Alamelu N.R.; Aramudhan M.","Subramanian, P. (57200000221); Alamelu, N.R. (6506953872); Aramudhan, M. (14053476100)","57200000221; 6506953872; 14053476100","Fusion of multispectral and panchromatic images and its quality assessment","2015","ARPN Journal of Engineering and Applied Sciences","10","9","","4126","4132","6","","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930149241&partnerID=40&md5=b41813c0710f6afe520475fcef35fca8","Image fusion is the process of merging two or more images obtained from the same sensor at different times or from two or more sensors at the same instant. The objective is to obtain more information from the fused image than from the individual images. In satellite images, the lower spatial resolution multispectral images are fused with higher spatial resolution panchromatic images. The fusion should result in the transfer of spectral and spatial information without introducing any artifacts. The goal is to combine the spectral and spatial resolutions of the multispectral and the panchromatic images respectively to obtain a high-resolution multispectral image. Most of the fusion techniques that have been proposed are based on the compromise between the desired spatial enhancement and the spectral consistency. This paper provides an overview of the techniques available in the literature for the fusion of multispectral and panchromatic images. The evaluation of the fusion technique employed is also an important step in the fusion process. Various quality metrics have been used in the literature to study, compare and assess the fusion technique employed. This paper provides a brief study on such quality metrics employed in the literature. © 2006-2015 Asian Research Publishing Network (ARPN).","","Contourlet; Fusion; Noiselet; Pan sharpening; Quality assessment metrics; Shearlet; Wavelet","Article","Final","","Scopus","2-s2.0-84930149241"
"Khobragade A.N.; Raghuwanshi M.M.","Khobragade, Anand N. (56538617800); Raghuwanshi, Mukesh M. (16643975400)","56538617800; 16643975400","Data fusion algorithms for horticulture classification using multi-sensory satellite images","2015","11th IEEE India Conference: Emerging Trends and Innovation in Technology, INDICON 2014","","","7030408","","","","10.1109/INDICON.2014.7030408","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924203986&doi=10.1109%2fINDICON.2014.7030408&partnerID=40&md5=34d1e6c7e24b7bd31bbf596490fb50ab","With the advent of numerous remote sensing sensors available for the researcher, the fusion of digital image data has become a imperative tool for classifying remote sensing image and evaluation too. Remote sensing image fusion not only improves the spatial resolution of the original multispectral image, but also improves the spectral quality of merged product. Quantitative and qualitative digital image fusion is an emerging research domain that motivates the scholars for producing high quality image with best multi-spectral capabilities. PAN Sharpened images endow with increased interpretation capabilities as data with various distinctiveness are combined and process effectively. The objective of satellite data fusion is to reduce uncertainty and minimize redundancy in the merged image while maximizing relevant details particular to remote sensing applications. Horticulture in India having great impact on agro based economy. It motivates us for carrying research as very few attempts are made in order to address the issues pertaining with horticulture application of remote sensing. Referring to the results obtained from quantitative and qualitative analysis of fused images, it is obvious that Brovey and Wavelet algorithms outperformed as compared to others. © 2014 IEEE.","Agriculture; Data fusion; Image classification; Image enhancement; Image processing; Pixels; Remote sensing; Data fusion algorithm; Multi-spectral; Pan-sharpening; Panchromatic; Quantitative and qualitative analysis; Remote sensing applications; Remote sensing images; Remote sensing sensors; Image fusion","Data fusion; Image Processing; Multispectral; PAN Sharpening; Panchromatic; Pixel; Remote Sensing","Conference paper","Final","","Scopus","2-s2.0-84924203986"
"Alkama S.; Chahir Y.; Berkani D.","Alkama, S. (37049850100); Chahir, Y. (6506225899); Berkani, D. (6602432758)","37049850100; 6506225899; 6602432758","Label maps fusion for the marginal segmentation of multi-component images","2015","Neural Network World","25","4","","405","426","21","10.14311/NNW.2015.25.021","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987707928&doi=10.14311%2fNNW.2015.25.021&partnerID=40&md5=10102834958fbe77f79a3b3a461540e2","In this paper, we propose a new technique for merging the label maps obtained by the marginal segmentation of a multi-component image. In the marginal segmentation, each component of the multi-component image is inde- pendently segmented by labeling the pixels of the same class with the same label. Therefore the number of label maps corresponds to the number of components in the image. It is then necessary to merge them in order to have a single label map, i.e. a single segmented image. In the most merging techniques, the compatibility links between these maps are performed a priori by making the correspondences between their labels. However the various components are segmented and labeled independently, label maps are considered as independent sources. It is then diffi- cult to establish the relationship compatibilities between labels. The method we propose does not a priori assume any compatibility links. The label maps are com- bined by superposition. Unfortunately, an over-segmentation is produced. To cope with this problem, the insignificant regions and classes are eliminated. Finally, classes are grouped by using hierarchical agglomerative clustering algorithm. Tests performed on color and satellite images show the effectiveness of this method and its superiority compared to the vector segmentation. The self-organizing map is used during the segmentation process in both marginal and vector segmentations. © CTU FTS 2015.","Clustering algorithms; Conformal mapping; Image fusion; Merging; Self organizing maps; Hierarchical agglomerative clustering algorithm; Independent sources; Label maps; Merging techniques; Multicomponent images; Number of components; Segmentation process; Self-organization maps; Image segmentation","Fusion of label maps; Marginal segmentation; Multi-component image; Self Organization Maps","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-84987707928"
"Konstantinidis D.; Stathaki T.; Argyriou V.; Grammalidis N.","Konstantinidis, Dimitrios (57208065320); Stathaki, Tania (7003386658); Argyriou, Vasileios (13806485100); Grammalidis, Nikos (6701851845)","57208065320; 7003386658; 13806485100; 6701851845","A probabilistic feature fusion for building detection in satellite images","2015","VISAPP 2015 - 10th International Conference on Computer Vision Theory and Applications; VISIGRAPP, Proceedings","2","","","205","212","7","10.5220/0005260502050212","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939482423&doi=10.5220%2f0005260502050212&partnerID=40&md5=2bb72ec20dd2094e414a0fa495bbfc7d","Building segmentation from 2D images can be a very challenging task due to the variety of objects that appear in an urban environment. Many algorithms that attempt to automatically extract buildings from satellite images face serious problems and limitations. In this paper, we address some of these problems by applying a novel approach that is based on the fusion of Histogram of Oriented Gradients (HOG), Normalized Difference Vegetation Index (NDVI) and Features from Accelerated Segment Test (FAST) features. We will demonstrate that by taking advantage of the multi-spectral nature of a satellite image and by employing a probabilistic fusion of the aforementioned features, we manage to create a novel methodology that increases the performance of a building detector compared to other state-of-the-art methods.","Buildings; Feature extraction; Image segmentation; Satellites; Building detection; Fast algorithms; Histogram of oriented gradients (HOG); NDVI; Normalized difference vegetation index; Satellite images; State-of-the-art methods; Urban environments; Image fusion","Building detection; FAST algorithm; HOG; NDVI; Probabilistic fusion; Satellite images","Conference paper","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-84939482423"
"Beulah David D.; Dorairangaswamy M.A.","Beulah David, D. (56039319000); Dorairangaswamy, M.A. (55411918500)","56039319000; 55411918500","An unsupervised change detection system for satellite images with various dimensions","2015","Journal of Chemical and Pharmaceutical Sciences","8","2","","173","179","6","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938592767&partnerID=40&md5=b815b8321edb01f9e4360ec8bf476dbd","This paper proposes a system for finding changes in satellite images taken at two different intervals of time and it may be some years or occurrences of images before and after flooding etc.,. The changes are obtained as binary labels (changed/unchanged) for each pixel. The input images may be of monochromatic or color images and also these images may be of various graphic file formats like PNG, BMP, JPG etc.,. The RGB images are converted to gray images. The mean ratio and log ratio are obtained from both input images. These are fused together to form a difference image using Discrete Wavelet Transform (DWT). A fuzzy clustering approach is applied to classify both changed and unchanged regions in the difference image. Previously this system is done using Fuzzy Local Information C means clustering. To enhance the changed information and to reduce the effect of noise, the spatial contextual information is added along with the self data information using Reformulated Fuzzy Local Information C-means Clustering (RFLICM). The resultant change detected images are showing good performance than the existing techniques. The performance measures are compared using Percentage of Correct Classification (PCC) and Kappa statistic parameter which gives the measure of accuracy for FLICM and RFLICM. Experimental results are compared for different dimensions of satellite images with different file formats taken at different intervals of time and the computation time is also found out.","Article; flooding; fuzzy system; image analysis; kappa statistics; noise; satellite imagery","Dimensions; Image Fusion; Percentage of Correct Classification; Reformulated Fuzzy Local Information C-means Clustering; Spatial Contextual Information","Article","Final","","Scopus","2-s2.0-84938592767"
"Daza R.J.M.; Cardona E.S.U.","Daza, Rubén Javer Medina (57193828334); Cardona, Erika Sofia Upegui (36459015100)","57193828334; 36459015100","Assessment of WorldView-2 satellite-image fusion using Daubechies Wavelet transform; [Evaluación de la fusión de imágenes satelitales WorldView-2 usando la Transformada Wavelet Daubechies]","2015","2015 10th Iberian Conference on Information Systems and Technologies, CISTI 2015","","","7170564","","","","10.1109/CISTI.2015.7170564","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943279986&doi=10.1109%2fCISTI.2015.7170564&partnerID=40&md5=77a7e6f4bd3a5b1c08ee26338e28dd85","This paper aims to show an outline of transform Wavelet Daubechies, the main characteristics of them and subsequently exposed methodological form that was used in the development of experimental procedures were performed to apply RGB-HIS method together with ARSIS technique to fused WorldView-2 images, finally presents the results obtained with the application of this method using five filters associated to Wavelet Daubechies (db2, bd3, db4, db5 y db8) on five levels of decomposition. © 2015 AISTI.","Fusion reactions; Image fusion; Information systems; Information use; Wavelet decomposition; Daubechies; Daubechies Wavelet; Experimental procedure; Multi-spectral; panchromatic; Satellite images; Worldview-2; Discrete wavelet transforms","Fusion; multispectral; panchromatic; satellite images; Wavelet Daubechies","Conference paper","Final","","Scopus","2-s2.0-84943279986"
"Mangalraj P.; Agrawal A.","Mangalraj, P. (56901364700); Agrawal, Anupam (56900480800)","56901364700; 56900480800","Fusion of Multi-Sensor Satellite Images Using Non-Subsampled Contourlet Transform","2015","Procedia Computer Science","54","","","713","720","7","10.1016/j.procs.2015.06.084","11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944062758&doi=10.1016%2fj.procs.2015.06.084&partnerID=40&md5=ebec74030d06000d2504dc58deeac240","The presented research work proposes fusion of multi-sensor satellite images using non subsampled contourlet transform. In the proposed work, trade-off between the spectral distortion and enhancement of spatial information is witnessed while fusing two multi-sensor images. The ills of wavelet based fusion techniques such as limited directionality, lack of phase information and shift invariant are addressed with the help of Non subsampled contourlet transform. The Non subsampled contourlet helps to retain the intrinsic structural information while decomposing and reconstructing the image components. Decision based rules are applied for component substitution for fusion. The experiments are carried out against the current state of art and observed that the proposed system provides promising results visually and quantitatively. The efficiency of the proposed system in the fused product is analysed qualitatively by Isodata classification algorithm. © 2015 The Authors.","Data mining; Economic and social effects; Fusion reactions; Image enhancement; Image processing; Signal processing; Wavelet analysis; Classification algorithm; Component substitution; Multi sensor images; Multi-sensor satellite images; Non-sub-sampled contourlet transforms; Non-subsampled contourlet; Spectral distortions; Structural information; Image fusion","Fusion; Intrinsic structural information; Multi-sensor Images; Non subsampled contourlet transform; Spectral distortion","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-84944062758"
"Gowri M.; Kiruthika C.; Swathika R.; Sree Sharmila T.","Gowri, M. (57210633220); Kiruthika, C. (55270580400); Swathika, R. (55823315000); Sree Sharmila, T. (55337283900)","57210633220; 55270580400; 55823315000; 55337283900","Satellite image fusion based on advanced color enhanced IHS","2015","International Journal of Applied Engineering Research","10","20","","18675","18680","5","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942916921&partnerID=40&md5=6bd80bf6b9c9f04b3ac9104d16986574","Image fusion plays a significant role in remote sensing applications, as it is the process of integrating relevant information from multiple source images to form a highly informative fused image. Several fusion techniques have been developed in order to produce the fused image of superior quality. In remote sensing, image fusion technique has been used to extricate the spatial information from the panchromatic image and fuse it with the spectral information of the multispectral image of the same scene taken at same or different time intervals, to produce an enhanced fused image i.e., pan sharpened image with both high spatial and spectral resolution characteristics. In this paper, an advanced satellite image fusion method based on Intensity Hue Saturation (IHS) is proposed. The main aim of this work is to perform fusion of high spatial resolution panchromatic image (PAN) with three bands of a single high spectral resolution multispectral image (MS) separately in a color improvised manner with IHS transformation. The individual R, G, B improvised images resulted from the first level fusion acts as an active accelerator for obtaining a color enhanced pan sharpened fused image. The experimental results obtained by the proposed fusion scheme shows that the fused image can efficiently preserve the spectral details as well as improve the spatial quality of the image when compared to other standard PCA and IHS based fusion methods. For this experiment, high resolution panchromatic and multispectral images were collected from remote sensing satellites such as WORLDVIEW-1 and WORLDVIEW-2 via DigitalGlobe. © Research India Publications.","","Advanced color enhanced IHS; Color enhancement; Entropy; Image fusion; Intensity hue saturation; Pan sharpened RGB image; Peak Signal-to-Noise Ratio (PSNR); Root Mean Square Error (RMSE); Standard Deviation (SD)","Article","Final","","Scopus","2-s2.0-84942916921"
"Rao D.S.; Seetha M.; Krishna Prasad M.H.M.","Rao, D.S. (57226537415); Seetha, M. (54795736200); Krishna Prasad, M.H.M. (54795323700)","57226537415; 54795736200; 54795323700","Novel approach for iterative image fusion using fuzzy and neuro fuzzy logic","2015","International Journal of Geoinformatics","11","2","","29","39","10","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939170740&partnerID=40&md5=7295d5b2706e019763f53ac19919d4ef","Image fusion may be defined as an approach of merging two or more input images in to a single fused image which is comparatively more informative than all the input images. Image fusion aims to reduce the redundancy and uncertainty in the output and aims to maximize application related significant information. Fused images are used in diverse applications such as remote sensing, machine vision, biometrics, medical imaging and military domain. In this paper, we carry out iterative image fusion through fuzzy logic and neuro fuzzy logic techniques by fusing satellite images obtained from two or more image sensors to improve visualization capability. We also compare the proposed iterative image fusion approach based on fuzzy logic and neuro fuzzy logic with two more approaches like Principal component analysis (PCA) based fusion and the wavelet transform based image fusion. Fused images obtained from iterative image fusion using fuzzy and neuro fuzzy and other comparative methods are assessed through typical quality evaluation metrics. The proposed iterative fusion based on fuzzy logic approach divulges better values in some metrics whereas iterative image fusion based on neuro fuzzy logic technique provides better values in other metrics. Due to the potentiality of the fuzzy logic and neuro fuzzy logic. The overall experimental results generated from suggested approach substantiate that the utilization of the iterative image fusion using fuzzy logic and neuro fuzzy logic techniques would efficiently improve the quality grade of the fused image with concurrent confinement of spectral and spatial information. © 2015, Geoinformatics International.","fuzzy mathematics; image analysis; remote sensing; satellite imagery; spatial analysis; spectral analysis; uncertainty analysis","","Article","Final","","Scopus","2-s2.0-84939170740"
"Zhang H.K.; Huang B.","Zhang, Hankui K. (34874017400); Huang, Bo (55388074800)","34874017400; 55388074800","A new look at image fusion methods from a Bayesian Perspective","2015","Remote Sensing","7","6","","6828","6861","33","10.3390/rs70606828","52","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933501683&doi=10.3390%2frs70606828&partnerID=40&md5=3ff4fe98526e1418d2d7d75ff0f66ee6","Component substitution (CS) and multi-resolution analysis (MRA) are the two basic categories in the extended general image fusion (EGIF) framework for fusing panchromatic (Pan) and multispectral (MS) images. Despite of the method diversity, there are some unaddressed questions and contradictory conclusions about fusion. For example, is the spatial enhancement of CS methods better than MRA methods? Is spatial enhancement and spectral preservation competitive? How to achieve spectral consistency defined by Wald et al. in 1997? In their definition any synthetic image should be as identical as possible to the original image once degraded to its original resolution. To answer these questions, this research first finds out that all the CS and MRA methods can be derived from the Bayesian fusion method by adjusting a weight parameter to balance contributions from the spatial injection and spectral preservation models. The spectral preservation model assumes a Gaussian distribution of the desired high-resolution MS images, with the up-sampled low-resolution MS images comprising the mean value. The spatial injection model assumes a linear correlation between Pan and MS images. Thus the spatial enhancement depends on the weight parameter but is irrelevant of which category (i.e., MRA or CS) the method belongs to. This paper then adds a spectral consistency model in the Bayesian fusion framework to guarantee Wald's spectral consistency with regard to arbitrary sensor point spread function. Although the spectral preservation in the EGIF methods is competitive to spatial enhancement, the Wald's spectral consistency property is complementary with spatial enhancement. We conducted experiments on satellite images acquired by the QuickBird and WorldView-2 satellites to confirm our analysis, and found that the performance of the traditional EGIF methods improved significantly after adding the spectral consistency model. © 2015 by the authors.","Data fusion; Image analysis; Optical transfer function; Bayesian data fusions; Bayesian perspective; Component substitution; Consistency property; General image fusions; Image fusion methods; Pan-sharpening; Spectral consistency; Image fusion","Bayesian data fusion; Pansharpening; Point spread function; Quality tradeoff; Spectral consistency","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84933501683"
"Chang C.H.; Hsieh Y.T.; Wu S.T.; Chen C.T.; Chen J.C.","Chang, C.H. (56939376000); Hsieh, Y.T. (35336856900); Wu, S.T. (14049496500); Chen, C.T. (8943452800); Chen, J.C. (36930042500)","56939376000; 35336856900; 14049496500; 8943452800; 36930042500","Applying image fusion to integrate radar images and SPOT multispectral satellite images for forest type classification","2015","Taiwan Journal of Forest Science","30","3","","","","","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946097208&partnerID=40&md5=c47f5ea45becdf59f31b0b574b3e5370","[No abstract available]","","Forest type classification; Image fusion; Multispectral image; Synthetic aperture radar","Note","Final","","Scopus","2-s2.0-84946097208"
"Lal A.M.; Anouncia S.M.","Lal, Anisha M. (56808822200); Anouncia, S. Margret (25822351600)","56808822200; 25822351600","Detection of boundaries by fusing the topographic sheets and multi-spectral images for geographic landscapes","2015","International Journal of Ecology and Development","30","3","","11","25","14","","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940375593&partnerID=40&md5=01cd16b792acd25345359bc9d7dd6649","Image fusion is a process of blending the complementary as well as the common features of a set of images, to generate a resultant image with superior information content in terms of subjective as well as objective analysis point of view. Especially in the case of remotely sensed panchromatic and multispectral images its play a vital role to help subjective and objective analysis. Many algorithms and software tools have been developed for fusing panchromatic and multispectral datasets. Also, a number of methods have been proposed and developed for the comparative evaluation of fusion results. So most of the attempts focused on the change detection which had a few limitations. Thus a trail is made to detect, discover and reveal the boundary of satellite images (Raster and spatial vector data) using a novel approach for easy detection of boundary for classifying environmental changes in this paper. In this study, methods that evaluate fusion quality are tested for different images and test sites and the analysis shows that in most cases the tested methods performs well. © 2015 IJED (CESER Publications).","","Environmental changes; Image fusion; Multispectral; Panchromatic; Remotely sensed","Article","Final","","Scopus","2-s2.0-84940375593"
"Li X.; He M.-Y.; Zhang L.","Li, Xu (55523051700); He, Ming-Yi (7402609138); Zhang, Lei (57196129274)","55523051700; 7402609138; 57196129274","New pansharpening method for worldview-2 satellite images","2015","Dianzi Keji Daxue Xuebao/Journal of the University of Electronic Science and Technology of China","44","1","","28","32","4","10.3969/j.issn.1001-0548.2015.01.004","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922590864&doi=10.3969%2fj.issn.1001-0548.2015.01.004&partnerID=40&md5=0776f9840374382a22c8ba79493eb4ae","New-style high resolution WorldView-2 satellite images pose challenges to the image fusion techniques. A new pansharpening method is proposed in this paper. First, 8-band multispectral imagery is resampled by nearest neighbor interpolation. According to the relative spectral responses between the multispectral band and the panchromatic band, a low spatial resolution panchromatic image is evaluated through multivariate linear regression. The spatial details are extracted from the original panchromatic image, and then injected into the component space of multispectral imagery. Finally, the pansharpened results are produced by employing inverse correspondence analysis transform. The experimental results show that the proposed method can obtain a better trade-off between the spatial resolution enhancement and the spectral information preservation compared to some existing methods. ©, 2015, Univ. of Electronic Science and Technology of China. All right reserved.","Economic and social effects; Fusion reactions; Image reconstruction; Image resolution; Optical resolving power; Remote sensing; Wavelet transforms; Correspondence analysis; Image fusion techniques; Multi-spectral imagery; Multivariate linear regressions; Nearest neighbor interpolation; Relative spectral response; Remote sensing images; Spatial-resolution enhancement; Image fusion","Correspondence analysis; Fusion; Remote sensing image; Resolution; Wavelet transform","Article","Final","","Scopus","2-s2.0-84922590864"
"Nikolakopoulos K.; Oikonomidis D.","Nikolakopoulos, Konstantinos (6602629539); Oikonomidis, Dimitrios (35092814100)","6602629539; 35092814100","Quality assessment of ten fusion techniques applied on worldview-2","2015","European Journal of Remote Sensing","48","","A009","141","167","26","10.5721/EuJRS20154809","44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934933531&doi=10.5721%2fEuJRS20154809&partnerID=40&md5=d3c193a78d70a0ed3ac57726ee8c148c","Fusion or merging or pansharpening is the digital processing that combines the high spatial and multispectral information to obtain a fused multispectral image that retains the spatial information from the high resolution panchromatic image, as well as the spectral characteristics of the lower resolution multispectral image. Many fusion algorithms were developed and tested on different commercial satellite data such as Ikonos and Quickbird, however, the efficacy of these algorithms is weakly assessed on the new satellite images of Worldview-2 with very high spatial resolution. In the present study ten well known fusion techniques namely Color Normalized (CN), Ehlers, Gram-Schmidt, High Pass Filter (HPF), Local Mean Matching (LMM), Local Mean and Variance Matching (LMVM), Modified IHS (Modihs), Pansharp, PCA and Wavelet are used for the fusion of Worldview-2 panchromatic and multispectral data. Fused images were evaluated for spectral and spatial fidelity using visual inspection and different quality indexes such as the correlation coefficient (CC), ERGAS, the Universal Image Quality Index (Q), the Expanded Quality Index (Q4expand) and the Entropy values. Under each quality metric the fusion algorithms were ranked and best performances were indentified. It has been proved that all fusion algorithms have a different performance with the new multispectral bands of Worldview-2 in comparison to the classical ones. It has also been proved that almost all quality indices present a very strong dependency to the spatial resolution of the input data. The Q4expand quality index is proposed as the main quality discriminator since it gave the most robust results independently of the spectral and spatial input resolution. Pansharp algorithm took the lead in spatial enhancement while Ehlers and HPF are ranked in the first places for spectral preservation.","Color matching; Fusion reactions; High pass filters; Image quality; Image resolution; Quality assurance; Commercial satellites; Correlation coefficient; Index; Multispectral images; Spatial informations; Spectral characteristics; Very high spatial resolutions; Worldview-2; algorithm; assessment method; entropy; index method; performance assessment; QuickBird; satellite data; satellite imagery; spatial analysis; spatial resolution; spectral analysis; technological change; wavelet analysis; WorldView; Image fusion","Fusion; Index; Quality; Worldview-2","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-84934933531"
"Li X.","Li, Xu (55273488000)","55273488000","Grouped band based fusion method for WorldView-2 satellite images","2015","Yuhang Xuebao/Journal of Astronautics","36","3","","324","329","5","10.3873/j.issn.1000-1328.2015.03.011","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928225263&doi=10.3873%2fj.issn.1000-1328.2015.03.011&partnerID=40&md5=da76c33afeb85ec1e8874f51ec18ef2e","A novel grouped-band based fusion method for WorldView-2 satellite images is presented. According to the spectral response matching characteristics between the panchromatic band and every multispectral band, the input multispectral images of eight bands are divided into two groups. Then two different fusion models are individually designed to process the grouped data. The grouping strategy is easy and practical. The experimental results show that the proposed method performs well for WorldView-2 data set. Visual and objective evaluations demonstrate that the proposed method can achieve a better global fusion quality than some existing methods. ©, 2015, China Spaceflight Society. All right reserved.","Aerospace engineering; Space flight; Grouped band; Grouping strategies; Multispectral images; Objective evaluation; Panchromatic bands; Panchromatic images; Satellite images; Spectral response; Image fusion","Grouped band; Image fusion; Multispectral image; Panchromatic image","Article","Final","","Scopus","2-s2.0-84928225263"
"Ghanima D.; Benabadji N.; Hassini A.B.; Belbachir A.H.","Ghanima, D. (56780445500); Benabadji, N. (14015135100); Hassini, A.B. (8572356500); Belbachir, A.H. (8529100000)","56780445500; 14015135100; 8572356500; 8529100000","A new image fusion algorithm compared at wavelet transform","2015","International Journal of Imaging and Robotics","15","1","","49","61","12","","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939128607&partnerID=40&md5=a14b9a5f2ae8f7ba4fbecf6d37bed4e3","Shearlets as a novel Multiscale Geometric Analysis (MGA) tool are equipped with a rich mathematical structure similar to the wavelets transform, which are associated to a multiresolution analysis. Recently, shearlets have been used in image denoising, sparse image representation and edge detection. In this paper, we propose a new approach for satellite image merging based on the Fast Finite Shearlet Transform (FFST) devlopped by Sören Häuser and applied to images acquired by Indian Remote Sensing IRS-1C. We have compared our method with others based on the multiresolution decomposition obtained using the “A trous” and Haar discrete algorithms of wavelet transform. The numerical experiments presented in this paper demonstrate that the Discrete Shearlet Transform is very competitive in image merging. © 2015 by IJIR (CESER PUBLICATIONS).","","Image merging; Indian remote sensing IRS-1C images; Shearlet; Wavelet transform","Article","Final","","Scopus","2-s2.0-84939128607"
