"Authors","Author full names","Author(s) ID","Titles","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","DOI","Cited by","Link","Abstract","Indexed Keywords","Author Keywords","Document Type","Publication Stage","Open Access","Source","EID"
"Wang J.; Feng D.; Zhang R.; Xu L.; Hu W.","Wang, Junjie (57193073134); Feng, Dejun (7401981139); Zhang, Ran (57191477744); Xu, Letao (55496843800); Hu, Weidong (36064974400)","57193073134; 7401981139; 57191477744; 55496843800; 36064974400","An Inverse Synthetic Aperture Radar Image Modulation Method Based on Coding Phase-Switched Screen","2019","IEEE Sensors Journal","19","18","8717672","7915","7922","7","10.1109/JSEN.2019.2917432","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070966188&doi=10.1109%2fJSEN.2019.2917432&partnerID=40&md5=1f82262bd8f7c22211b5e9f28e57fc16","Multiple false target images deception is an effective strategy to protect vital military targets from detection and recognition by inverse synthetic aperture radar (ISAR). Previous research about it focuses mainly on the interrupted-sampling and sub-Nyquist sampling repeater jamming based on digital radio frequency memory (DRFM). The digital image synthesis (DIS) technique or scatter-wave modulation is used to simulate electromagnetic scattering of the real target. However, it is difficult to realize due to the high reconnaissance accuracy requirement and a heavy computational burden. Moreover, the protected target remains in the same location and the false targets' amplitude envelope based on periodic modulation is relatively fixed, which is not conducive to deception. In this paper, an ISAR image modulation method based on coding phase-switched screen (PSS) is proposed against ISAR. The method uses the target bait made of PSS or attaches the PSS to the protected target surface to impose phase modulation onto the reflected signal. As a result, multiple false target images with verisimilar properties are formed around the protected target position when the reflected signal is received and processed by the victim ISAR. Besides, the protected target is concealed and the flexible amplitude control of false targets is achieved. The simulation results are performed to verify the effectiveness of the proposed method. © 2001-2012 IEEE.","Codes (symbols); Digital radio; Image coding; Inverse problems; Inverse synthetic aperture radar; Military photography; Modulation; Radar imaging; Radar signal processing; Coding modulation; Computational burden; Digital radio frequency memory; Electromagnetic scattering; False targets; Inverse synthetic aperture radars (ISAR); Phase switched screen; Sub-Nyquist sampling; Radar target recognition","coding modulation; false targets; Inverse synthetic aperture radar (ISAR); phase-switched screen (PSS)","Article","Final","","Scopus","2-s2.0-85070966188"
"Giry-Fouquet Y.; Baussard A.; Enderli C.; Porges T.","Giry-Fouquet, Yann (57329471000); Baussard, Alexandre (6603433755); Enderli, Cyrille (56047849700); Porges, Tristan (36069744200)","57329471000; 6603433755; 56047849700; 36069744200","SAR image synthesis with GAN and continuous aspect angle and class constraints","2022","Proceedings of the European Conference on Synthetic Aperture Radar, EUSAR","2022-July","","","809","814","5","","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143598382&partnerID=40&md5=b8d962fdbc679b2c12bca4de0e80fc95","Target classification generally requires large databases, especially for deep learning methods. However, it is not always possible to have access to a database of sufficient size for certain imaging modalities. For example, in synthetic aperture radar (SAR) imaging only limited incidence angles and aspect angles can be available. Unfortunately, to overcome this problem, most of the classical data augmentation methods are inappropriate for SAR data. Thus, in a previous work, we evaluated conditional Generative Adversarial Networks to generate synthetic SAR images at given aspect angles and for specific target classes. Among the various models evaluated the so-called StyleGAN2-Ada, slightly modified to take into account the specificity of SAR images, appear to be the most efficient model. However, we observed that some of the generated images had wrong aspect angles. In this contribution we propose to correct this problem by adding a regularization term recently proposed in a model called Generator Regularized-cGAN. Our experiments show that this modification strongly reduce the problem. © 2022 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Classification (of information); Deep learning; Generative adversarial networks; Learning systems; Radar imaging; Aspects angle; Data augmentation; Images synthesis; Imaging modality; Incidence angles; Large database; Learning methods; Synthetic aperture radar images; Synthetic aperture radar imaging; Target Classification; Synthetic aperture radar","","Conference paper","Final","","Scopus","2-s2.0-85143598382"
"Du W.-L.; Zhou Y.; Zhu H.; Zhao J.; Shao Z.; Tian X.","Du, Wen-Liang (55265123100); Zhou, Yong (35480110700); Zhu, Hancheng (55532134400); Zhao, Jiaqi (57138970300); Shao, Zhiwen (57189600890); Tian, Xiaolin (7202380154)","55265123100; 35480110700; 55532134400; 57138970300; 57189600890; 7202380154","A Semi-Supervised Image-to-Image Translation Framework for SAR-Optical Image Matching","2022","IEEE Geoscience and Remote Sensing Letters","19","","4516305","","","","10.1109/LGRS.2022.3223353","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142777987&doi=10.1109%2fLGRS.2022.3223353&partnerID=40&md5=0366797c0d795f602ca243d74eb3389a","Synthetic aperture radar (SAR) and optical image matching aims to acquire correspondences from a certain pair of SAR and optical images. Recent advances in the image-to-image translation provided a way to simplify the SAR-optical image matching into the SAR-SAR or optical-optical image matchings. The existing image-to-image translations mainly focus on supervised or unsupervised learning. However, gathering sufficient amounts of aligned training data for supervised learning is challenging, while unsupervised learning cannot guarantee enough correct correspondences. In this work, we investigate the applicability of semi-supervised image-to-image translation for SAR-optical image matching such that both aligned and unaligned SAR-optical images could be used. To this end, we combine the benefits of both supervised and unsupervised well-known image-to-image translation methods, i.e., Pix2pix and CycleGAN, and propose a simple yet effective semi-supervised image-to-image translation framework. Through extensive experimental comparisons to the baseline methods, we verify the effectiveness of the proposed framework in both semi-supervised and fully supervised settings.  © 2004-2012 IEEE.","Generative adversarial networks; Geometrical optics; Image matching; Radar imaging; Unsupervised learning; Generative adversarial network; Image translation; Images synthesis; Optical image; Optical-; Semi-supervised; Semi-supervised-image-synthesis; Synthetic aperture radar; Synthetic aperture radar images; Training data; network analysis; radar imagery; supervised learning; synthetic aperture radar; Synthetic aperture radar","Generative adversarial networks (GANs); image matching; semi-supervised image synthesis; synthetic aperture radar (SAR)","Article","Final","","Scopus","2-s2.0-85142777987"
"Meleshin Y.M.; Khasanov M.S.; Merkulova Z.V.; Dovgal T.A.; Kurganov V.V.","Meleshin, Yury M. (57189239337); Khasanov, Marat S. (57194234794); Merkulova, Zhanna V. (57151493700); Dovgal, Timofey A. (57194239986); Kurganov, Vladislav V. (57189250062)","57189239337; 57194234794; 57151493700; 57194239986; 57189250062","Approach to optimization of radar image synthesis from hologram with redundant pulse frequency rate","2018","Proceedings of the 2018 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering, ElConRus 2018","2018-January","","","1681","1684","3","10.1109/EIConRus.2018.8317427","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047967196&doi=10.1109%2fEIConRus.2018.8317427&partnerID=40&md5=85b8c0e1cd754d92bb78da25dc288d66","In radar imaging there are cases where to obtain higher energy excess pulse frequency rate is used, while to save proportions of final image it's azimuth pixel size should be the same as range one. In most cases, final image compressing technique is used, but it involves redundant order Fourier transforms during image synthesis and consequently superfluous complexity. This paper offers an approach to reduce complexity of a radar image synthesis with pulse frequency rate much greater than Nyquist's boundary for required resolution. © 2018 IEEE.","Fast Fourier transforms; Fourier transforms; Image compression; Optimization; Synthetic aperture radar; Image compressing; Image synthesis; Nyquist; Pixel size; Pulse frequencies; Synthesis kernels; Radar imaging","azimuth synthesis kernel; FFT; optimization; SAR","Conference paper","Final","","Scopus","2-s2.0-85047967196"
"Martinez J.A.C.; Adarme M.X.O.; Turnes J.N.; Costa G.A.O.P.; De Almeida C.A.; Feitosa R.Q.","Martinez, J.A.C. (57218451094); Adarme, M.X.O. (57274825100); Turnes, J.N. (57216587254); Costa, G.A.O.P. (25642386000); De Almeida, C.A. (57209845177); Feitosa, R.Q. (6602453684)","57218451094; 57274825100; 57216587254; 25642386000; 57209845177; 6602453684","A COMPARISON OF CLOUD REMOVAL METHODS FOR DEFORESTATION MONITORING IN AMAZON RAINFOREST","2022","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","43","B3-2022","","665","671","6","10.5194/isprs-archives-XLIII-B3-2022-665-2022","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131917969&doi=10.5194%2fisprs-archives-XLIII-B3-2022-665-2022&partnerID=40&md5=8447700e1fefacd1f19230a481c218a7","Deforestation in tropical rainforests is a major source of carbon dioxide emissions, an important driver of climate change. For decades, the Brazilian government has maintained monitoring programs for deforestation detection in the Brazilian Legal Amazon area based on remotely sensed optical images in a protocol that involves considerable efforts of visual interpretation. However, the Amazon region is covered with clouds for most of the year, and deforestation assessment can rely only on images acquired in the dry season when cloud-free images are more likely to capture. One possibility to lessen that restriction and enable deforestation detection throughout the year is to synthesize cloud-free optical images from corresponding SAR images, which are only marginally influenced by atmospheric conditions. This work compares a set of such image synthesis methods, considering deforestation detection in the Amazon forest as the target application. Specifically, we evaluate three deep learning methods for cloud removal in Sentinel-2 images: a conditional Generative Adversarial Network (cGAN) based on the pix2pixi architecture; an extension of that method, which uses atrous convolutions (Atrous cGANi) to enhance fine image details; and a non-generative method (DSen2-CRi) based on residual networks. In the evaluation, we assess both the quality of the generated images and the accuracy obtained when performing deforestation detection from those images. We further compare those methods with an image aggregation tool available in Google Earth Engine (GEE Tooli), which creates cloud-free mosaics from sequences of images acquired at nearby dates. In this study, we considered two sites in the Brazilian Amazon, characterized by distinct vegetation and deforestation patterns. In terms of the quality metrics and classification accuracy, the Atrous cGANi was the best performing deep learning method. The GEE Tooli outperformed all those methods when dealing with images from the dry season but turned out to be the poorest performing method in the wet season.  © Authors 2022","Carbon dioxide; Data fusion; Deep learning; Deforestation; Generative adversarial networks; Geometrical optics; Image acquisition; Image enhancement; Quality control; Radar imaging; Synthetic aperture radar; Amazon rain forest; Cloud removal; Deep learning; Dry seasons; Learning methods; Optical data; Optical image; Optical imagery; Removal method; SAR-optical data fusion; Global warming","Cloud Removal; Deep learning; Deforestation; Optical imagery; SAR-optical Data fusion","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85131917969"
"Meleshin Y.M.; Khasanov M.S.; Prikhodko D.V.; Oreshkin V.I.","Meleshin, Yury M. (57189239337); Khasanov, Marat S. (57194234794); Prikhodko, Dmitry V. (24470422400); Oreshkin, Vitaly I. (57150422800)","57189239337; 57194234794; 24470422400; 57150422800","Numerical method for fourier transform of support function of SAR azimuth synthesis","2017","Proceedings of the 2017 IEEE Russia Section Young Researchers in Electrical and Electronic Engineering Conference, ElConRus 2017","","","7910796","1267","1269","2","10.1109/EIConRus.2017.7910796","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019459130&doi=10.1109%2fEIConRus.2017.7910796&partnerID=40&md5=90d50b1a6dca6e7c9cd6ab1950e44448","For a radar image synthesis obtained from synthetic aperture radar it's necessary to use its own support function (matched filter impulse response) for each range line. Fourier transform of the support function takes near a third of all computations, in case of range migration - substantially more. At the same time, the support function for any distance may be obtained by simple stretching and compression of the source function. These operations, according to the properties of Fourier transform, correspond to compression and stretching respectively in Fourier transform of function. In this work the numerical algorithm for Fourier transform of support function with O(N) complexity is considered. © 2017 IEEE.","Fourier transforms; Impulse response; Matched filters; Numerical methods; Radar; Radar imaging; Chirp; Image synthesis; Numerical algorithms; Range migration; Source functions; Support functions; Synthesis kernels; Synthetic aperture radar","Azimuth synthesis kernel; Chirp; LFM; Matched filter impulse response; SAR","Conference paper","Final","","Scopus","2-s2.0-85019459130"
"Guo M.; Zhu H.; Tai N.; Wang C.; Yuan N.","Guo, Min (57203198728); Zhu, Hong (57061119200); Tai, Ning (56414361200); Wang, Chao (57737773200); Yuan, Naichang (7005006477)","57203198728; 57061119200; 56414361200; 57737773200; 7005006477","Study on jamming method of inverse synthetic aperture radar based on three platform","2016","Proceedings of 2016 IEEE Information Technology, Networking, Electronic and Automation Control Conference, ITNEC 2016","","","7560441","652","655","3","10.1109/ITNEC.2016.7560441","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990934133&doi=10.1109%2fITNEC.2016.7560441&partnerID=40&md5=e278bf1f75c6260ac884fef080955964","Based on the basic principle of the multiply modulation jamming of synthetic aperture radar (SAR), a new jamming method of inverse synthetic aperture radar (ISAR) based on three platform is proposed: at first, it needs to choose an image template which is used to do 2D-FFT and compensation to generate jamming template; In order to get jamming data which need to compute the sampling interval and sample the jamming template; at last, the jamming data multiply the intercept signal to send out. The false target is created to provide an effective protection for a certain target send the result out. This method can achieve single or multiple false targets, and false targets can be adjusted according to the size, number and flight attitude of the ideal targets template. Simulation results demonstrate the effectiveness of this method. Because of the first step is independent and doesn't need any parameters of enemy ISAR system, which can be calculated in advance, comparing with the methods digital image synthesis, this method has less computational complexity. © 2016 IEEE.","Inverse problems; Jamming; Modulation; Radar; Radar imaging; Synthetic aperture radar; 2-D FFT; Basic principles; Digital image; False targets; Inverse synthetic aperture radars (ISAR); Sampling interval; three platform; Inverse synthetic aperture radar","ISAR jamming; multiply modulation; single or multiple false target; three platform","Conference paper","Final","","Scopus","2-s2.0-84990934133"
"Kniola M.; Kawalec A.; Lesnik C.; Szugajew M.","Kniola, Michal (57195527527); Kawalec, Adam (6602840570); Lesnik, Czeslaw (6507092083); Szugajew, Marcin (36474045000)","57195527527; 6602840570; 6507092083; 36474045000","Implementation of Block Adaptive Quantizer as a peripheral module for the FPGA-based SAR system","2017","Proceedings International Radar Symposium","","","8008231","","","","10.23919/IRS.2017.8008231","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028609981&doi=10.23919%2fIRS.2017.8008231&partnerID=40&md5=92a5143ace92a4d2bbf789b5a8750389","Due to large quantity of data needed for image synthesis in SAR applications, methods of raw signal compression were developed alongside actual imaging systems. Although performance of modern processing units allows on-platform, online image synthesis, data compressor still can be a valuable addition. Since it is no longer necessary part of SAR system, it should be delivered in a flexible, easy to use and low cost form - like low-resources demanding Intellectual Property core. In this paper chosen properties of raw SAR signal and some of compression methods are presented followed by compressor IP core implementation results.. © 2017 DGON.","Field programmable gate arrays (FPGA); Image processing; Intellectual property core; Radar; Radar imaging; Compression methods; Data compressor; Image synthesis; Online images; Processing units; Raw signals; SAR applications; SAR signals; Synthetic aperture radar","","Conference paper","Final","","Scopus","2-s2.0-85028609981"
"Turnes J.N.; Castro J.D.B.; Torres D.L.; Vega P.J.S.; Feitosa R.Q.; Happ P.N.","Turnes, Javier Noa (57216587254); Castro, Jose David Bermudez (57221592279); Torres, Daliana Lobo (57214144329); Vega, Pedro Juan Soto (57216790448); Feitosa, Raul Queiroz (6602453684); Happ, Patrick N. (55768214000)","57216587254; 57221592279; 57214144329; 57216790448; 6602453684; 55768214000","Atrous cGAN for SAR to Optical Image Translation","2022","IEEE Geoscience and Remote Sensing Letters","19","","","","","","10.1109/LGRS.2020.3031199","13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121785021&doi=10.1109%2fLGRS.2020.3031199&partnerID=40&md5=69801546b67a25708178ad951474a818","Conditional (cGAN)-based methods proposed so far for synthetic aperture radar (SAR)-to-optical image synthesis tend to produce noisy and unsharp optical outcomes. In this work, we propose the atrous-cGAN, a novel cGAN architecture that improves the SAR-to-optical image translation. The proposed generator and discriminator networks rely on atrous convolutions and incorporate an atrous spatial pyramid pooling (ASPP) module to enhance fine details in the generated optical image by exploiting spatial context at multiple scales. This letter reports experiments carried out to assess the performance of atrous-cGAN for the synthesis of Landsat-8 images from Sentinel-1A data based on three public data sets. The experimental analysis indicated that the atrous-cGAN consistently outperformed the classical pix2pix counterpart in terms of visual quality, similar to the true optical image, and as a feature learning tool for semantic segmentation.  © 2004-2012 IEEE.","Geometrical optics; Image enhancement; Radar imaging; Semantic Segmentation; Semantics; Synthetic aperture radar; Atrous spatial pyramid pooling; Image translation; Images synthesis; Multiple scale; Optical image; Optical-; Performance; Spatial context; Spatial pyramids; Synthetic aperture radar -optical synthesis; algorithm; satellite data; synthetic aperture radar; time series analysis; Generative adversarial networks","Atrous spatial pyramid pooling (ASPP); Generative adversarial networks; Synthetic aperture radar (SAR)-optical synthesis","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85121785021"
"Serafin P.; Leśnik C.; Zieliński K.","Serafin, Piotr (12795880400); Leśnik, Czesław (6507092083); Zieliński, Kacper (57220465994)","12795880400; 6507092083; 57220465994","Range cell migration compensation in inverse synthetic aperture radar","2020","Proceedings of SPIE - The International Society for Optical Engineering","11442","","114421F","","","","10.1117/12.2565753","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081138678&doi=10.1117%2f12.2565753&partnerID=40&md5=7feb32c89ec21c3088ed0ff731d52605","Inverse synthetic aperture radar is a system allowing for acquiring of high resolution images of moving objects. The image synthesis algorithms base on coherent integration of observed object's echo signals, which requires the exact knowledge of the object's movement parameters in order to compensate two fundamental phenomena: echo's initial phase modulation and range cell migration of the signal. In this paper results of research on range migration compensation method applying the keystone transform are presented. © SPIE. Downloading of the abstract is permitted for personal use only.","Inverse problems; Radar imaging; Coherent integration; High resolution image; Image synthesis; ISAR; Key stone transform; Moving objects; Range cell migration; Range migration; Inverse synthetic aperture radar","Inverse synthetic aperture radar; ISAR; Keystone transform; Range cell migration compensation; Range migration","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85081138678"
"Xu L.; Wong A.; Clausi D.A.","Xu, Linlin (55921131900); Wong, Alexander (15073608800); Clausi, David A. (7003991297)","55921131900; 15073608800; 7003991297","An Enhanced Probabilistic Posterior Sampling Approach for Synthesizing SAR Imagery with Sea Ice and Oil Spills","2017","IEEE Geoscience and Remote Sensing Letters","14","2","7797259","188","192","4","10.1109/LGRS.2016.2633572","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007110623&doi=10.1109%2fLGRS.2016.2633572&partnerID=40&md5=629bb5bd8b9ca008679764706c03d359","Although the synthesis of the synthetic aperture radar (SAR) imagery with both sea ice and oil spills can significantly benefit in improving the consistency and comprehensiveness of testing and evaluating algorithms that are designed for mapping cold ocean regions, creating such imagery is difficult due to the heterogeneity and complexity of the source images. This letter presents an enhanced region-based probabilistic posterior sampling approach to effectively synthesize SAR imagery with different ocean features. In the proposed approach, instead of relying entirely on the SAR intensity values, the posterior sampling is performed based on a number of quantitative factors, such as intensity, label field, and the prior class probability of sampling candidates, constituting a complete probabilistic framework that addresses key aspects in the synthesis of SAR imagery from heterogeneous sources. The experiments demonstrate that the proposed approach can better address the difficulties caused by the heterogeneity in the source images compared with the existing state-of-the-art ice synthesis method, and it will improve the consistency, comprehensiveness, and fairness of the evaluation of the remote sensing classification and segmentation algorithms. © 2016 IEEE.","Ice; Image processing; Image segmentation; Mapping; Marine pollution; Oil spills; Remote sensing; Sea ice; Synthetic aperture radar; Class probabilities; Evaluating algorithms; Heterogeneous sources; Probabilistic framework; Quantitative factors; Remote sensing classification; Segmentation algorithms; Synthetic Aperture Radar Imagery; Radar imaging","Image synthesis; oil spills; sea ice; Statistical texture modeling","Article","Final","","Scopus","2-s2.0-85007110623"
"Shiro E.","Shiro, Evgeny (57200596905)","57200596905","Potential of the reverse synthesis method for the high-quality SAR image synthesis","2018","International Geoscience and Remote Sensing Symposium (IGARSS)","2018-July","","8518457","8905","8908","3","10.1109/IGARSS.2018.8518457","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063126236&doi=10.1109%2fIGARSS.2018.8518457&partnerID=40&md5=8dce17b9fa8a18d13a2f6d468a305a1e","A potential of a new Reverse synthesis method proposed at IGARSS 2017 for the high-quality Synthetic Aperture Radar (SAR) image synthesis is presented. Images produced by the method are compared with the best existing approaches for the speckle noise reduction. Further capabilities for the image quality improvement like side lobe, range and azimuth reduction, contrast improvement, autofocusing and target detectability improvement are considered. The novel approach allows both: to produce high quality and high-resolution images from existing SAR raw data and to create new high-quality systems with reduced demands to the on-board equipment. © 2018 IEEE.","","High resolution; Image quality; Image synthesis; SAR; Speckle noise; Synthetic aperture imaging; Synthetic aperture radar","Conference paper","Final","","Scopus","2-s2.0-85063126236"
"Du W.-L.; Zhou Y.; Zhao J.; Tian X.","Du, Wen-Liang (55265123100); Zhou, Yong (35480110700); Zhao, Jiaqi (57138970300); Tian, Xiaolin (7202380154)","55265123100; 35480110700; 57138970300; 7202380154","K-Means Clustering Guided Generative Adversarial Networks for SAR-Optical Image Matching","2020","IEEE Access","8","","9279214","217554","217572","18","10.1109/ACCESS.2020.3042213","9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097759183&doi=10.1109%2fACCESS.2020.3042213&partnerID=40&md5=5003cba703defca1b0ca7cafa9124b5e","Synthetic Aperture Radar and optical (SAR-optical) image matching is a technique of finding correspondences between SAR and optical images. SAR-optical image matching can be simplified to single-mode image matching through image synthesis. However, the existing SAR-optical image synthesis methods are unable to provide qualified images for SAR-optical image matching. In this work, we present a K-means Clustering Guide Generative Adversarial Networks (KCG-GAN) to improve the image quality of synthesizing by constraining spatial information synthesis. KCG-GAN uses k-means segmentations as one of the image generator's inputs and introduces feature matching loss, segmentation loss, and L1 loss to the objective function. Meanwhile, to provide repeatable k-means segmentations, we develop a straightforward 1D k-means algorithm. We compare KCG-GAN with a leading image synthesis method-pix2pixHD. Qualitative results illustrate that KCG-GAN preserves more spatial structures than pix2pixHD. Quantitative results show that, compared with pix2pixHD, images synthesized by KCG-GAN are more similar to original optical images, and SAR-optical image matching based on KCG-GAN obtains at most 3.15 times more qualified matchings. Robustness tests demonstrate that SAR-optical image matching based on KCG-GAN is robust to rotation and scale changing. We also test three SIFT-like algorithms on matching original SAR-optical image pairs and matching KCG-GAN synthesized optical-optical image pairs. Experimental results show that our KCG-GAN significantly improves the performances of the three algorithms on SAR-optical image matching. © 2013 IEEE.","Geometrical optics; Image enhancement; Image matching; Image segmentation; K-means clustering; Synthetic aperture radar; Adversarial networks; Feature matching; Image generators; K-means segmentations; Objective functions; Quantitative result; Spatial informations; Spatial structure; Radar imaging","generative adversarial networks (GANs); Image matching; image synthesis; synthetic aperture radar (SAR)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85097759183"
"Willis C.J.; Pilgrim A.; Li E.K.C.","Willis, Chris J. (57196925111); Pilgrim, Alan (23012421900); Li, Emma K.C. (57214094958)","57196925111; 23012421900; 57214094958","SAR image simulation for performance assessment","2019","Proceedings of SPIE - The International Society for Optical Engineering","11155","","1115519","","","","10.1117/12.2532574","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078180040&doi=10.1117%2f12.2532574&partnerID=40&md5=8e605cb985b3620a04c63f5553bdf370","Performance assessment of image processing systems may be carried out using large volumes of data with known ground truth. Unfortunately such data, collected in sensor trials, can be challenging to source for many problems of interest. In particular, trials collection may require the acquisition of imagery in a range of scenario settings, imaging geometries and environmental conditions. An alternative to trials data collection uses synthetically generated imagery of objects and environments configured into realistic scenarios. For performance assessment of image processing chains, large volumes of synthetic imagery may be required in order to characterise individual algorithmic steps or for complete system assessment. In order to generate sufficiently large volumes for such characterisations the simulation approach must also be fast to execute. This paper presents a process for the generation of simulated Synthetic Aperture Radar (SAR) imagery which is fit-for-purpose for the task of algorithm and systems performance assessment of image processing for Automatic Target Detection, Recognition and Identification (ATDRI) tasks. The approach taken is based on the exploitation of computational geometry primitives. It uses a simplified imaging model and correctly treats both layover effects and shadowed regions on both the target object and within the background region. For speed and simplicity the simulation process synthesises single bounce reflections only. This means that the simulation is effective only up to the intermediate resolutions which are typically used for ATDRI applications. The input models are comprised of three-dimensional triangulations representing the geometric structure of the scene content, with each triangle having a parameterised scattering response based on distributional models often used for SAR imagery. The synthesis process generates a collection of two-dimensional arrays of distributional parameters of the same size as the image to be produced. It is straightforward to use these to generate representations of, for example, mean scattering response, or realistic-looking simulated SAR images with speckle 'noise'. Results are presented for different scene content and sensor configurations, including target aspect and sensor depression angles. © 2019 SPIE.","Computational geometry; Image processing; Radar target recognition; Remote sensing; Synthetic aperture radar; ATDRI; Automatic target detection; Image simulations; Image synthesis; Performance assessment; Radar imaging","ATDRI; Automatic Target Detection; Image simulation; Image synthesis; Performance assessment; Recognition & Identification; SAR; Synthetic Aperture Radar","Conference paper","Final","","Scopus","2-s2.0-85078180040"
"Bermudez J.D.; Happ P.N.; Oliveira D.A.B.; Feitosa R.Q.","Bermudez, J.D. (57200270007); Happ, P.N. (55768214000); Oliveira, D.A.B. (27567900100); Feitosa, R.Q. (6602453684)","57200270007; 55768214000; 27567900100; 6602453684","SAR to OPTICAL IMAGE SYNTHESIS for CLOUD REMOVAL with GENERATIVE ADVERSARIAL NETWORKS","2018","ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences","4","1","","5","11","6","10.5194/isprs-annals-IV-1-5-2018","34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056341243&doi=10.5194%2fisprs-annals-IV-1-5-2018&partnerID=40&md5=d4212f7c1e4135f41d0f4ccf9889527c","Optical imagery is often affected by the presence of clouds. Aiming to reduce their effects, different reconstruction techniques have been proposed in the last years. A common alternative is to extract data from active sensors, like Synthetic Aperture Radar (SAR), because they are almost independent on the atmospheric conditions and solar illumination. On the other hand, SAR images are more complex to interpret than optical images requiring particular handling. Recently, Conditional Generative Adversarial Networks (cGANs) have been widely used in different image generation tasks presenting state-of-the-art results. One application of cGANs is learning a nonlinear mapping function from two images of different domains. In this work, we combine the fact that SAR images are hardly affected by clouds with the ability of cGANS for image translation in order to map optical images from SAR ones so as to recover regions that are covered by clouds. Experimental results indicate that the proposed solution achieves better classification accuracy than SAR based classification. © Authors 2018.","","Cloud Removal; Conditional Generative Adversarial Networks; Deep Learning; Multispectral Images; SAR","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85056341243"
"Wang C.; Pei J.; Liu X.; Huang Y.; Mao D.; Zhang Y.; Yang J.","Wang, Chenwei (57211242566); Pei, Jifang (55787739300); Liu, Xiaoyu (57222261818); Huang, Yulin (23014806800); Mao, Deqing (57194656090); Zhang, Yin (55975581400); Yang, Jianyu (9239230100)","57211242566; 55787739300; 57222261818; 23014806800; 57194656090; 55975581400; 9239230100","SAR Target Image Generation Method Using Azimuth-Controllable Generative Adversarial Network","2022","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15","","","9381","9397","16","10.1109/JSTARS.2022.3218369","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141613271&doi=10.1109%2fJSTARS.2022.3218369&partnerID=40&md5=559a1c414ff5622e9bebfb6fb4462040","Sufficient synthetic aperture radar (SAR) target images are very important for the development of research works. However, available SAR target images are often limited in practice, which hinders the progress of SAR application. In this article, we propose an azimuth-controllable generative adversarial network to generate precise SAR target images with an intermediate azimuth between two given SAR images' azimuths. This network mainly contains three parts: 1) generator, 2) discriminator, and 3) predictor. Through the proposed specific network structure, the generator can extract and fuse the optimal target features from two input SAR target images to generate an SAR target image. Then, a similarity discriminator and an azimuth predictor are designed. The similarity discriminator can differentiate the generated SAR target images from the real SAR images to ensure the accuracy of the generated while the azimuth predictor measures the difference of azimuth between the generated and the desired to ensure the azimuth controllability of the generated. Therefore, the proposed network can generate precise SAR images, and their azimuths can be controlled well by the inputs of the deep network, which can generate the target images in different azimuths to solve the small sample problem to some degree and benefit the research works of SAR images. Extensive experimental results show the superiority of the proposed method in azimuth controllability and accuracy of SAR target image generation.  © 2008-2012 IEEE.","Automatic target recognition; Deep learning; Radar imaging; Radar target recognition; Synthetic aperture radar; Automatic target recognition; Azimuth; Azimuth-controllable; Deep learning; Generative adversarial network; Generator; Image generations; Images synthesis; Radar polarimetry; Synthetic aperture radar; Target image generation; Target images; Target recognition; azimuth; experimental study; image analysis; image classification; machine learning; synthetic aperture radar; Generative adversarial networks","Automatic target recognition (ATR); azimuth-controllable; deep learning; generative adversarial network (GAN); synthetic aperture radar (SAR); target image generation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85141613271"
"Ding J.; Liu H.; Chen B.; Wang Y.","Ding, Jun (57200583527); Liu, Hongwei (35337184800); Chen, Bo (56387823300); Wang, Yinghua (16425010100)","57200583527; 35337184800; 56387823300; 16425010100","SAR image target recognition in lack of pose images","2016","Xi'an Dianzi Keji Daxue Xuebao/Journal of Xidian University","43","4","","5","9","4","10.3969/j.issn.1001-2400.2016.04.002","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982947714&doi=10.3969%2fj.issn.1001-2400.2016.04.002&partnerID=40&md5=8e95fcb76702fcf364afb2c743bbebdb","The performance of synthetic aperture radar (SAR) image target recognition depends on the diversity of pose images in the training set. The problem of lack of pose images is considered, and the method of training data augmented with the synthesized pose images is introduced to train the classifier for target identification. Inspired by the sparse representation model, the model for synthesizing pose images is also developed, which approximately construct the missing pose image by linearly combining several images available. Experimental results on the moving and stationary target acquisition and recognition (MSTAR) dataset show that the proposed method of pose images synthesis can increase the recognition accuracy effectively. In particular, significant improvement can be obtained in the case of serious lack of pose images. © 2016, The Editorial Board of Journal of Xidian University. All right reserved.","Classification (of information); Image processing; Radar; Radar imaging; Synthetic aperture radar; Images synthesis; Lack of pose images; Recognition accuracy; Sparse representation; Stationary targets; Synthetic aperture radar (SAR) images; Target identification; Training data; Radar target recognition","Lack of pose images; Sparse representation; Synthetic aperture radar (SAR) image target recognition","Article","Final","","Scopus","2-s2.0-84982947714"
"Kim S.; Yu J.; Ka M.-H.","Kim, Seok (57200876704); Yu, Jiwoong (56822577000); Ka, Min-Ho (15834471000)","57200876704; 56822577000; 15834471000","SAR image synthesis with chirp scaling algorithm of 3D CAD model using em simulator","2015","Proceedings of the 2015 IEEE 5th Asia-Pacific Conference on Synthetic Aperture Radar, APSAR 2015","","","7306157","72","75","3","10.1109/APSAR.2015.7306157","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957707680&doi=10.1109%2fAPSAR.2015.7306157&partnerID=40&md5=49009c1052f00d89c40721ee13de3e97","In this paper, we describe a simple method for SAR image synthesis of a realistic target model using the general purpose EM simulator like FEKO and demonstrate the steps by processing the simulated SAR raw data with chirp-scaling algorithm (CSA), which is one of the most widely used SAR image formation algorithms. This method can benefit us many advantages like performance evaluation for target detection, estimation and target recognition with realistic target model in a cost-and-time effective way. © 2015 IEEE.","Algorithms; Computer aided design; Image processing; Radar; Synthetic aperture radar; Three dimensional computer graphics; 3D CAD Modeling; Chirp Scaling algorithm; Magnetic simulation; SAR image formation; SAR raw data; SIMPLE method; Target model; Target recognition; Radar imaging","Chirp-Scaling Algorithm; Electro-Magnetic Simulation; Synthetic Aperture Radar","Conference paper","Final","","Scopus","2-s2.0-84957707680"
"Sun Y.; Wang Y.; Hu L.; Huang Y.; Liu H.; Wang S.; Zhang C.","Sun, Yuanshuang (57219850285); Wang, Yinghua (16425010100); Hu, Liping (57198490400); Huang, Yuanyuan (57193827565); Liu, Hongwei (57205480555); Wang, Siyuan (57853004800); Zhang, Chen (57199502493)","57219850285; 16425010100; 57198490400; 57193827565; 57205480555; 57853004800; 57199502493","Attribute-Guided Generative Adversarial Network With Improved Episode Training Strategy for Few-Shot SAR Image Generation","2023","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","","","1","15","14","10.1109/JSTARS.2023.3239633","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147266303&doi=10.1109%2fJSTARS.2023.3239633&partnerID=40&md5=6a66707f5627a5a61478334f783a494f","Deep learning-based models usually require a large amount of data for training, which guarantees the effectiveness of the trained model. Generative models are no exception, and sufficient training data are necessary for the diversity of generated images. However, for SAR images, data acquisition is expensive. Therefore, SAR image generation under few training samples is still a challenging problem to be solved. In this paper, we propose an attribute-guided generative adversarial network (AGGAN) with improved episode training strategy for few-shot SAR image generation. Firstly, we design the AGGAN structure, and spectral normalization is used to stabilize the training in the few-shot situation. The attribute labels of AGGAN are designed to be the category and aspect angle labels, which are essential information for SAR images. Secondly, an improved episode training strategy is proposed according to the characteristics of the few-shot generative task, and it can improve the quality of generated images in the few-shot situation. In addition, we explore the effectiveness of the proposed method when using different auxiliary data for training and use the Moving and Stationary Target Acquisition and Recognition (MSTAR) benchmark dataset and a simulated SAR dataset for verification. The experimental results show that AGGAN and the proposed improved episode training strategy can generate images of better quality when compared with some existing methods, which have been verified through visual observation, image similarity measures, and recognition experiments. When applying the generated images to the 5-shot SAR image recognition problem, the average recognition accuracy can be improved by at least 4<inline-formula><tex-math notation=""LaTeX"">$\%$</tex-math></inline-formula>. Author","Data acquisition; Deep learning; Generative adversarial networks; Image enhancement; Image recognition; Job analysis; Radar imaging; Few-shot image generation; Image generations; Images synthesis; Metalearning; Radar polarimetry; Synthetic aperture radar; Synthetic aperture radar images; Task analysis; Transfer learning; Synthetic aperture radar","Data models; Few-shot image generation; generative adversarial network; Image recognition; Image synthesis; meta-learning; Radar polarimetry; synthetic aperture radar (SAR); Task analysis; Training; Transfer learning; transfer learning","Article","Article in press","All Open Access; Gold Open Access","Scopus","2-s2.0-85147266303"
"Guo J.; Lei B.; Ding C.; Zhang Y.","Guo, Jiayi (57194143247); Lei, Bin (14063767500); Ding, Chibiao (7202622015); Zhang, Yueting (57218470544)","57194143247; 14063767500; 7202622015; 57218470544","Synthetic Aperture Radar Image Synthesis by Using Generative Adversarial Nets","2017","IEEE Geoscience and Remote Sensing Letters","14","7","7927706","1111","1115","4","10.1109/LGRS.2017.2699196","71","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018916287&doi=10.1109%2fLGRS.2017.2699196&partnerID=40&md5=b5e0ce4044ac4aff172f4911bf99512f","Synthetic aperture radar (SAR) image simulators based on computer-aided drawing models play an important role in SAR applications, such as automatic target recognition and image interpretation. However, the accuracy of such simulators is due to geometric error and simplification in the electromagnetic calculation. In this letter, an end-to-end model was developed that could directly synthesize the desired images from the known image database. The model was based on generative adversarial nets (GANs), and its feasibility was validated by comparisons with real images and ray-tracing results. As a further step, the samples were synthesized at angles outside of the data set. However, the training process of GAN models was difficult, especially for SAR images which are usually affected by noise interference. The major failure modes were analyzed in experiments, and a clutter normalization method was proposed to ameliorate them. The results showed that the method improved the speed of convergence up to 10 times. The quality of the synthesized images was also improved. © 2017 IEEE.","Automatic target recognition; Computer aided analysis; Image processing; Radar; Radar target recognition; Ray tracing; Synthetic aperture radar; Computer-aided drawings; Electromagnetic calculations; Image interpretation; Noise interference; Normalization methods; Speed of convergence; Synthesized images; Synthetic aperture radar (SAR) images; Radar imaging","Generative adversarial nets (GANs); SAR image simulator; SAR interpretation; synthetic aperture radar (SAR)","Article","Final","","Scopus","2-s2.0-85018916287"
"Du W.-L.; Zhou Y.; Zhao J.; Tian X.; Yang Z.; Bian F.","Du, Wen-Liang (55265123100); Zhou, Yong (35480110700); Zhao, Jiaqi (57138970300); Tian, Xiaolin (7202380154); Yang, Zhi (57284929100); Bian, Fuqiang (57202867285)","55265123100; 35480110700; 57138970300; 7202380154; 57284929100; 57202867285","Exploring the Potential of Unsupervised Image Synthesis for SAR-Optical Image Matching","2021","IEEE Access","9","","9427486","71022","71033","11","10.1109/ACCESS.2021.3079327","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105853208&doi=10.1109%2fACCESS.2021.3079327&partnerID=40&md5=3ebbd56086511abe8160d0a847102a35","We consider SAR-optical image matching problems, where correspondences are acquired from a pair of SAR and optical images. Recent methods for such a problem typically simplify the SAR-optical image matching to the SAR-SAR or optical-optical image matchings using supervised-image-synthesis methods. However, training supervised-image-synthesis needs plenty of aligned SAR-optical image pairs while gathering sufficient amounts of aligned multi-modal image pairs is challenging in remote sensing. In this work, we investigate the applicability of unsupervised-image-synthesis for SAR-optical image matching such that the unaligned SAR-optical images could be used. To this end, we apply feature matching loss to a well known unsupervised-image-synthesis method, i.e., CycleGAN, to enforce the feature matching consistency. Moreover, we develop a shared-matching-strategy to improve the results of SAR-optical image matching further. Qualitative comparisons against CycleGAN, StarGAN, and DualGAN demonstrate the superiority of our approach. Quantitative results show that, compared with CycleGAN, StarGAN, and DualGAN, our method obtains at least 2.6 times more qualified SAR-optical matchings.  © 2013 IEEE.","Geometrical optics; Image enhancement; Image matching; Remote sensing; Feature matching; Image synthesis; Matching problems; Matchings; Multi-modal image; Optical image; Quantitative result; Radar imaging","generative adversarial networks (GANs); Image matching; synthetic aperture radar (SAR); unsupervised-image-synthesis","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85105853208"
"Kaniewski P.; Komorniczak W.; Leśnik C.; Cyrek J.; Susek W.; Serafin P.; Łabowski M.","Kaniewski, Piotr (35078873300); Komorniczak, Wojciech (23995326300); Leśnik, Czesław (6507092083); Cyrek, Jacek (24829458500); Susek, Waldemar (6508233371); Serafin, Piotr (12795880400); Łabowski, Michał (56938598600)","35078873300; 23995326300; 6507092083; 24829458500; 6508233371; 12795880400; 56938598600","S-band and ku-band sar system development for uav-based applications","2019","Metrology and Measurement Systems","26","1","","53","64","11","10.24425/mms.2019.126326","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070948421&doi=10.24425%2fmms.2019.126326&partnerID=40&md5=463735e521a3cd51c5e806d1cff21101","This paper describes a synthetic aperture radar system for tactical-level imagery intelligence installed on board an unmanned aerial vehicle. Selected results of its tests are provided. The system contains interchangeable S-band and Ku-band linear frequency-modulated, continuous wave radar sensors that were built within a frame of a research project named WATSAR, conducted by the Military University of Technology and WB Electronics S.A. One of several algorithms of radar image synthesis, implemented in the scope of the project, is described in this paper. The WATSAR system can create online and off-line radar images. © 2019 Polish Academy of Sciences. All rights reserved.","Antennas; Chirp modulation; Continuous wave radar; Military photography; Radar imaging; Unmanned aerial vehicles (UAV); Continuous Wave; Doppler algorithms; Image synthesis; Imagery intelligence (IMINT) system; Linear frequency modulated; Military University of Technology; Range; WB Electronics; Synthetic aperture radar","Doppler algorithm (RDA); Imagery intelligence (IMINT) system; Range; Synthetic aperture radar (SAR); Unmanned aerial vehicle (UAV)","Article","Final","","Scopus","2-s2.0-85070948421"
"Tsvetkov V.K.; Sheremet A.Y.; Zhmylev V.A.; Merkulova Z.V.; Baiguzov D.A.","Tsvetkov, Vadim K. (57189244146); Sheremet, Alexey Y. (57189248601); Zhmylev, Vladimir A. (57208001053); Merkulova, Zhanna V. (57151493700); Baiguzov, Denis A. (57207980305)","57189244146; 57189248601; 57208001053; 57151493700; 57207980305","Method for optimization of the radar image synthesis in the case of high antenna squint","2019","Proceedings of the 2019 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering, ElConRus 2019","","","8657284","2030","2033","3","10.1109/EIConRus.2019.8657284","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063439575&doi=10.1109%2fEIConRus.2019.8657284&partnerID=40&md5=4fa676b61c3df64b587f66db7d1ee83d","In radar image synthesis there are methods which allow improving the performance by reducing the number of samples in the obtained response signal. However, applying these methods before the azimuth Fourier transform can result in significant distortions. The first source of distortions is the uneven frequency response of simple decimation methods which can be mostly unnoticeable. The second type of distortions is the antenna squint and the corresponding Doppler shift in the azimuth spectrum which can be unknown. As simple decimation applies the low-pass filter response to the hologram spectrum, the effective signal might be eliminated. The proposed in this paper method allows to determine the position of Doppler spectrum as well as to suppress only the noise spectrum components, resulting in higher performance without the loss of the image quality. © 2019 IEEE","Doppler effect; Fast Fourier transforms; Frequency response; Image enhancement; Low pass filters; Optimization; Radar antennas; Synthetic aperture radar; Decimation method; Doppler spectra; Image synthesis; Noise spectra; Number of samples; Response signal; Synthesis kernels; Radar imaging","Azimuth synthesis kernel; FFT; Optimization; SAR","Conference paper","Final","","Scopus","2-s2.0-85063439575"
"Ka M.-H.; Shimkin P.E.; Baskakov A.I.; Babokin M.I.","Ka, Min-Ho (15834471000); Shimkin, Pavel E. (57197844463); Baskakov, Aleksandr I. (7006836990); Babokin, Mikhail I. (57197845525)","15834471000; 57197844463; 7006836990; 57197845525","A new single-pass SAR interferometry technique with a single-antenna for terrain height measurements","2019","Remote Sensing","11","9","1070","","","","10.3390/rs11091070","6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065744693&doi=10.3390%2frs11091070&partnerID=40&md5=a55603a1bb02880ea2eb0f50375496d4","One of the prospective research topics in radar remote sensing technology is the methodology for designing an optimal radar system for high-precision two-dimensional and three-dimensional image acquisition of the Earth's surface with minimal hardware requirements. In this study, we propose a single-pass interferometric synthetic aperture radar (SAR) imaging technique with only a single antenna for the estimation of the terrain height. This technique enabled us to obtain terrain height information in one flight of the carrier, on which only one receiving antenna was mounted. This single-antenna single-pass interferometry required a squint angle look geometry and additional image synthesis processing. The limiting accuracy of the terrain height measurement was approximately 1.5 times lower than that of the conventional two-pass mode and required a longer baseline than two-pass interferometry to have an equivalent accuracy performance. This imaging method could overcome the temporal decorrelation problem of two-pass interferometry due to a short time gap in the radar echo acquisitions during two sub-aperture intervals. We compared the accuracy performance of the terrain height measurements of our method with the conventional two-pass interferometry. This comparison was carried out at various spectral bandwidths, degrees of surface roughness, and baseline lengths. We validated our idea with numerical simulations of a digital elevation map, and showed real extracted data of the terrain heights in the Astrakhan and Volga regions of the Russian Federation, obtained from airborne SAR with our single-antenna single-pass interferometry technique. © 2019 by the authors.","Imaging techniques; Landforms; Radar antennas; Radar imaging; Receiving antennas; Remote sensing; Surface roughness; Synthetic aperture radar; Interferometric synthetic aperture radars; Limiting accuracy; Single antenna; Single pass; Single-pass interferometry; Single-pass SAR interferometry; Squint angles; Three-dimensional image acquisition; Interferometry","Interferometry; Limiting accuracy; Remote sensing; Single antenna; Single-pass; Squint angle; Synthetic aperture radar","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85065744693"
"Huang H.; Zhang F.; Zhou Y.; Yin Q.; Hu W.","Huang, Henghua (57219442515); Zhang, Fan (56320587700); Zhou, Yongsheng (22959334700); Yin, Qiang (36959885000); Hu, Wei (56316293300)","57219442515; 56320587700; 22959334700; 36959885000; 56316293300","High resolution sar image synthesis with hierarchical generative adversarial networks","2019","International Geoscience and Remote Sensing Symposium (IGARSS)","2019-July","","8900494","2782","2785","3","10.1109/IGARSS.2019.8900494","12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082673599&doi=10.1109%2fIGARSS.2019.8900494&partnerID=40&md5=a10eaaed3665d0fd8aacfcae65f8bade","Generative adversarial network (GAN) is an artificial neural network based on unsupervised learning method. Due to its powerful model representation capabilities, GAN has been introduced to synthesize synthetic aperture radar (SAR) image data, for the real sample is difficult to acquire. Largescale, high-resolution SAR images play an important role in promoting SAR applications, such as automatic target recognition and image interpretation. However, on account of the difficult training problem of GAN network, especially for SAR images with speckle noise, it is difficult to obtain high-resolution SAR images by simply transfer the net from optical image. Recent studies in other image fields have shown that hierarchical structure is an effective and useful way to decompose a generation task into several smaller subtasks. How to obtain more high-resolution SAR images from limited original samples through GAN is the target of our research. Therefore, in this paper, we introduce a hierarchical GAN network model to generate SAR images, through the multi-stage network, gradually improve the quality of the generated image, and finally obtain highresolution images. The type and aspect of generated images are determined by the input of condition vectors in the last two stages. In addition, we introduce the triple loss, in which the background loss is used to imitating background clutter noise of SAR image, the condition loss is to make the generated images' type and aspect become controllable, and the global loss for getting higher image generation quality. The generated images show high similarity with the real samples.  © 2019 IEEE.","Automatic target recognition; Geometrical optics; Image enhancement; Learning systems; Radar target recognition; Remote sensing; Synthetic aperture radar; Unsupervised learning; Adversarial networks; Hierarchical structures; High resolution image; High-resolution SAR; Image interpretation; Model representation; Synthetic aperture radar (SAR) images; Unsupervised learning method; Radar imaging","Automatic target recognition (ATR); Generative adversarial network(GAN); SAR simulator; Synthetic aperture radar (SAR); Triple loss","Conference paper","Final","","Scopus","2-s2.0-85082673599"
"Zhang Y.; Wang C.; Chen J.; Wang F.","Zhang, Yi (57203829285); Wang, Chengyi (57129401700); Chen, Jingbo (56386393100); Wang, Futao (56415234000)","57203829285; 57129401700; 56386393100; 56415234000","Shape-Constrained Method of Remote Sensing Monitoring of Marine Raft Aquaculture Areas on Multitemporal Synthetic Sentinel-1 Imagery","2022","Remote Sensing","14","5","1249","","","","10.3390/rs14051249","5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126285516&doi=10.3390%2frs14051249&partnerID=40&md5=33cc2687117b46356127f867c7e1d0db","Large-scale and periodic remote sensing monitoring of marine raft aquaculture areas is significant for scientific planning of their layout and for promoting sustainable development of marine ecology. Synthetic aperture radar (SAR) is an important tool for stable monitoring of marine raft aquaculture areas since it is all-weather, all-day, and cloud-penetrating. However, the scattering signal of marine raft aquaculture areas is affected by speckle noise and sea state, so their features in SAR images are complex. Thus, it is challenging to extract marine raft aquaculture areas from SAR images. In this paper, we propose a method to extract marine raft aquaculture areas from Sentinel-1 images based on the analysis of the features for marine raft aquaculture areas. First, the data are preprocessed using multitemporal phase synthesis to weaken the noise interference, enhance the signal of marine raft aquaculture areas, and improve the significance of the characteristics of raft aquaculture areas. Second, the geometric features of the marine raft aquaculture area are combined to design the model structure and introduce the shape constraint module, which adds a priori knowledge to guide the model convergence direction during the training process. Experiments verify that the method outperforms the popular semantic segmentation model with an F1 of 84.52%. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Aquaculture; Marine biology; Ocean currents; Radar imaging; Remote sensing; Semantic Segmentation; Semantics; Constrained method; Images synthesis; Large-scales; Monitoring of mariculture; Multi-temporal; Remote sensing monitoring; Scientific planning; Semantic segmentation; Sentinel-1; Synthetic aperture radar images; Synthetic aperture radar","Image synthesis; Monitoring of mariculture; SAR; Semantic segmentation","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85126285516"
"Renga A.; Graziano M.D.; Moccia A.","Renga, Alfredo (25632802300); Graziano, Maria Daniela (36815910800); Moccia, Antonio (7003833593)","25632802300; 36815910800; 7003833593","Formation Flying SAR: Analysis of Imaging Performance by Array Theory","2021","IEEE Transactions on Aerospace and Electronic Systems","57","3","9288956","1480","1497","17","10.1109/TAES.2020.3043526","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097930512&doi=10.1109%2fTAES.2020.3043526&partnerID=40&md5=9f62473e0b56af16cf426594b291e308","This article analyzes the process of image synthesis for a formation flying synthetic aperture radar (FF-SAR), which is a multistatic synthetic aperture radar (SAR) based on a cluster of receiving-only satellites flying in a close formation, in the framework of the array theory. Indeed, the imaging properties of different close receivers, when analyzed as isolated items, are very similar and form the so-called common array. Moreover, the relative positions among the receivers implicitly define a physical array, referred to as spatial diversity array. FF-SAR imaging can be verified as a result of the spatial diversity array weighting the common array. Hence, different approaches to beamforming can be applied to the spatial diversity array to provide the FF-SAR with distinctive capabilities, such as coherent resolution enhancement and high-resolution wide-swath imaging. Simulation examples are discussed which confirm that array theory is a powerful tool to quickly and easily characterize FF-SAR imaging performance.  © 1965-2011 IEEE.","Multistatic radars; Synthetic aperture radar; Formation flying; Image synthesis; Imaging performance; Imaging properties; Relative positions; Resolution enhancement; Simulation example; Spatial diversity; Radar imaging","Array theory; Distributed arrays; Formation flying SAR (FF-SAR); High-resolution wide-swath imaging; Multistatic SAR; Spaceborne SAR; Synthetic aperture radar(sar)","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85097930512"
"Willis C.J.; Francis G.K.","Willis, Chris J. (57196925111); Francis, Gary K. (57219465953)","57196925111; 57219465953","SAR ATR performance assessment using simple target models","2020","Proceedings of SPIE - The International Society for Optical Engineering","11536","","115360E","","","","10.1117/12.2574011","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092918075&doi=10.1117%2f12.2574011&partnerID=40&md5=dd57f94213ee0e5b44bd140126c4129e","Performance assessment of image processing systems is typically carried out using large volumes of data with known ground truth. Unfortunately such data can be challenging to source for many problems of interest. In particular, trials data collection for performance assessment may require the acquisition of imagery for a range of sensing, target and environmental conditions. This can be time consuming and expensive to achieve. We might also wish to assess the performance of systems which are yet to be built, or over target objects for which access is, at best, limited. These problems might be addressed through the use of synthetically-generated imagery which may be produced in volume for the sensor, environment and target configurations required. If sufficiently representative these may then be used within the performance assessment process for system characterization. A scheme for the generation of synthetic imagery has previously been published. This is deemed fit-for-purpose for algorithm and systems performance assessment of image processing for Automatic Target Detection and Recognition (ATDR) tasks in Synthetic Aperture Radar (SAR) imagery. The approach is effective up to the intermediate resolutions which are typically used for ATDR applications. The input models used for synthesis are comprised of three-dimensional triangulations representing the geometric structure of the scene content, with each triangle having a parameterized scattering response based on SAR distributional models. The modelling process is reliant on a skilled analyst to identify and encode the salient detail of the target object including: the geometry of the principal structural features, and; by encoding the surface textures within the scattering response. The synthesis process generates a collection of two-dimensional arrays of distributional parameters the same size as the image to be produced. It is straightforward to use these to generate representations of expected scattering response, or realistic-looking simulated SAR images with speckle. This paper examines the development of target models for use within the simulator, along with a selection of performance assessment results produced for a range of sensor characteristics. © 2020 SPIE.","Encoding (symbols); Image processing; Radar target recognition; Synthetic aperture radar; Textures; Automatic target detection and recognition; Environmental conditions; Image processing system; Performance assessment; Sensor characteristics; Synthetic Aperture Radar Imagery; System characterization; Two-dimensional arrays; Radar imaging","ATDRI; Automatic Target Detection; Image simulation; Image synthesis; Machine learning; Performance assessment; Recognition & Identification; SAR; Synthetic Aperture Radar; Target modelling","Conference paper","Final","","Scopus","2-s2.0-85092918075"
"Wang L.; Loffeld O.; Ma K.; Qian Y.","Wang, Ling (57191575459); Loffeld, Otmar (7003978381); Ma, Kaili (57193564607); Qian, Yulei (57206946003)","57191575459; 7003978381; 57193564607; 57206946003","Sparse ISAR imaging using a greedy Kalman filtering approach","2017","Signal Processing","138","","","1","10","9","10.1016/j.sigpro.2017.03.002","21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014952782&doi=10.1016%2fj.sigpro.2017.03.002&partnerID=40&md5=1d177a657b9ff9aaae2f429a4f5e15f8","The Compressive sensing (CS) theory provides a novel type of image reconstruction methods for radar imaging. A good image can be obtained using much less data as compared to the conventional imaging methods, however under the sparse assumptions of the scene/target in certain domains. In this paper, we present a Kalman filter based sparse reconstruction approach for ISAR imaging. As the Kalman filter has robust and excellent estimation performance in statistical settings for linear problems, it leads to good image reconstruction results for real ISAR data. In addition to the spatial sparsity of the scene, we exploit the sparsity in wavelet domain to improve the reconstruction of region-like features in the target image other than point-like features. The images obtained by assuming the sparsity in different domains are synthesized to further improve the image reconstruction. The ISAR real data processing demonstrates the performance of the Kalman filter based sparse ISAR imaging method and the effectiveness of the image synthesis methods. © 2017 Elsevier B.V.","Compressed sensing; Data handling; Image processing; Image reconstruction; Inverse synthetic aperture radar; Kalman filters; Radar; Signal reconstruction; Synthetic aperture radar; Compressive sensing; Conventional imaging; Estimation performance; Greedy algorithms; Image reconstruction methods; Inverse synthetic aperture radars (ISAR); Sparse reconstruction; Sparse recovery; Radar imaging","Compressive sensing (CS); Greedy algorithm; Inverse synthetic aperture radar (ISAR); Kalman Filter; Sparse recovery","Article","Final","","Scopus","2-s2.0-85014952782"
"Willis C.J.","Willis, Chris J. (57196925111)","57196925111","Simulated SAR for ATR pre-training","2021","Proceedings of SPIE - The International Society for Optical Engineering","11870","","118700C","","","","10.1117/12.2600151","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118823905&doi=10.1117%2f12.2600151&partnerID=40&md5=16b0d48eb4c1a18b8f08745029433e3e","Deep learning has revolutionized the performance of many computer vision systems in recent years. In particular deep convolutional neural networks have demonstrated ground-breaking performance in object classification from imagery. However, these techniques typically require sizeable volumes of training data in order to derive the large number of parameters that these types of approaches must learn. In many situations sufficient volumes of imagery for the object types of interest are unavailable. One solution to this problem is to use an initial training set which has properties similar to those of the objects of interest, but is available with a large number of labelled examples. These can be used for initial network training and the resulting partially-learned solution may subsequently be tuned using a smaller sample of the actual target objects. This type of approach, transfer learning, has shown considerable success in conventional imaging domains. Unfortunately, for Synthetic Aperture Radar imaging sensors, large volumes of labelled training samples of any type are hard to come by. The challenge is exacerbated when variations in imaging geometry and sensor configuration are taken into account. This paper examines the use of simulated SAR imagery in pre-training a deep neural network. The simulated imagery is generated using a straightforward process which has the capability to generate sufficient volumes of training exemplars in a modest amount of time. The samples generated are used to train a deep neural network which is then retrained using a comparatively small volume of MSTAR SAR imagery. The value of such a pre-training process is assessed using techniques to explain model performance by visualization. The assessment highlights some interesting aspects of the MSTAR SAR image set with regard to bias. © 2021 SPIE","Automatic target recognition; Convolutional neural networks; Deep neural networks; Radar imaging; Radar target recognition; ATDRI; Automatic target detection; Automatic target detection, recognition & identification; Images simulations; Images synthesis; MSTAR; Performance assessment; SAR; Target model; Target's identifications; Synthetic aperture radar","ATDRI; Automatic Target Detection, Recognition & Identification; Image simulation; Image synthesis; Machine learning; MSTAR; Performance assessment; SAR; Synthetic Aperture Radar; Target modelling","Conference paper","Final","","Scopus","2-s2.0-85118823905"
"Baier G.; Deschemps A.; Schmitt M.; Yokoya N.","Baier, Gerald (57188720676); Deschemps, Antonin (57221248595); Schmitt, Michael (7401931279); Yokoya, Naoto (36440631200)","57188720676; 57221248595; 7401931279; 36440631200","Synthesizing Optical and SAR Imagery from Land Cover Maps and Auxiliary Raster Data","2022","IEEE Transactions on Geoscience and Remote Sensing","60","","","","","","10.1109/TGRS.2021.3068532","7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104617195&doi=10.1109%2fTGRS.2021.3068532&partnerID=40&md5=4f1d774df6d33691b5d314efc9f28290","We synthesize both optical RGB and synthetic aperture radar (SAR) remote sensing images from land cover maps and auxiliary raster data using generative adversarial networks (GANs). In remote sensing, many types of data, such as digital elevation models (DEMs) or precipitation maps, are often not reflected in land cover maps but still influence image content or structure. Including such data in the synthesis process increases the quality of the generated images and exerts more control on their characteristics. Spatially adaptive normalization layers fuse both inputs and are applied to a full-blown generator architecture consisting of encoder and decoder to take full advantage of the information content in the auxiliary raster data. Our method successfully synthesizes medium (10 m) and high (1 m) resolution images when trained with the corresponding data set. We show the advantage of data fusion of land cover maps and auxiliary information using mean intersection over unions (mIoUs), pixel accuracy, and Fréchet inception distances (FIDs) using pretrained U-Net segmentation models. Handpicked images exemplify how fusing information avoids ambiguities in the synthesized images. By slightly editing the input, our method can be used to synthesize realistic changes, i.e., raising the water levels. The source code is available at https://github.com/gbaier/rs_img_synth, and we published the newly created high-resolution data set at https://ieee-dataport.org/open-access/geonrw.  © 1980-2012 IEEE.","Data fusion; HTTP; Radar imaging; Rasterization; Remote sensing; Synthetic aperture radar; Water levels; Adversarial networks; Auxiliary information; Digital elevation model; High resolution data; Information contents; Remote sensing images; Segmentation models; Spatially adaptive; land cover; mapping method; optical method; radar imagery; raster; synthetic aperture radar; Image processing","Deep learning; generative adversarial network (GAN); image synthesis; synthetic aperture radar (SAR)","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85104617195"
"Cao Y.; Xu L.; Peng J.","Cao, Yun (57202049913); Xu, Linlin (55921131900); Peng, Junhuan (12785442100)","57202049913; 55921131900; 12785442100","Smsynth: An imagery synthesis system for soil moisture retrieval","2018","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","3","","127","131","4","10.5194/isprs-archives-XLII-3-127-2018","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046956265&doi=10.5194%2fisprs-archives-XLII-3-127-2018&partnerID=40&md5=3104c71d784f2e8acb156cb9b7c737d6","Soil moisture (SM) is a important variable in various research areas, such as weather and climate forecasting, agriculture, drought and flood monitoring and prediction, and human health. An ongoing challenge in estimating SM via synthetic aperture radar (SAR) is the development of the retrieval SM methods, especially the empirical models needs as training samples a lot of measurements of SM and soil roughness parameters which are very difficult to acquire. As such, it is difficult to develop empirical models using realistic SAR imagery and it is necessary to develop methods to synthesis SAR imagery. To tackle this issue, a SAR imagery synthesis system based on the SM named SMSynth is presented, which can simulate radar signals that are realistic as far as possible to the real SAR imagery. In SMSynth, SAR backscatter coefficients for each soil type are simulated via the Oh model under the Bayesian framework, where the spatial correlation is modeled by the Markov random field (MRF) model. The backscattering coefficients simulated based on the designed soil parameters and sensor parameters are added into the Bayesian framework through the data likelihood where the soil parameters and sensor parameters are set as realistic as possible to the circumstances on the ground and in the validity range of the Oh model. In this way, a complete and coherent Bayesian probabilistic framework is established. Experimental results show that SMSynth is capable of generating realistic SAR images that suit the needs of a large amount of training samples of empirical models. © Authors 2018.","Backscattering; Image segmentation; Markov processes; Radar measurement; Remote sensing; Sampling; Search engines; Soil moisture; Structural frames; Synthetic aperture radar; Weather forecasting; Backscattering coefficients; Bayesian frameworks; Bayesian probabilistic frameworks; Image synthesis; Markov Random Field model; Markov random field models; Soil moisture retrievals; Spatial correlations; Radar imaging","Bayesian framework; Image synthesis; Markov random field model; Oh model; Soil moisture","Conference paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85046956265"
"Sibler P.; Sica F.; Schmitt M.","Sibler, Philipp (57219793990); Sica, Francescopaolo (56673917100); Schmitt, Michael (7401931279)","57219793990; 56673917100; 7401931279","Deep Learning-Based SAR Interferogram Synthesis from Raster and Land Cover Data","2022","International Geoscience and Remote Sensing Symposium (IGARSS)","2022-July","","","5236","5239","3","10.1109/IGARSS46834.2022.9884964","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141603213&doi=10.1109%2fIGARSS46834.2022.9884964&partnerID=40&md5=db5cf8b0d8ff765d97d184f36862ae15","Image-to-image translation between different imaging modalities in Earth observation has become a widely utilized application area of deep learning. However, most of the translation is performed on real-valued data, to some extent neglecting the opportunities of complex-valued SAR data for interferometric methods. In this work, we propose a multi-task deep learning approach for simulating complex-valued InSAR data based on splitting the overall task into multi-modal image-toimage translation sub-tasks. Instead of synthesizing complex-valued SAR data directly, magnitudes, phase values and coherence magnitudes are simulated in parallel and combined to full complex-valued information afterward. With experiments on a Sentinel-1 interferogram, conditioned by DEM and land cover data, we demonstrate the feasibility of the approach. © 2022 IEEE.","Deep learning; Interferometry; Learning systems; Radar imaging; Remote sensing; Auto encoders; Coherence estimation; Complex-valued; Deep learning; GAN; Images synthesis; Land cover; Multi tasks; SAR interferometry; SAR-interferometry; Synthetic aperture radar","autoencoder; CNN; coherence estimation; complex-valued; deep learning; GAN; image synthesis; multi-task; SAR; SAR interferometry","Conference paper","Final","","Scopus","2-s2.0-85141603213"
