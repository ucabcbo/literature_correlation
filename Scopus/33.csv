"Authors","Author full names","Author(s) ID","Titles","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","DOI","Cited by","Link","Abstract","Indexed Keywords","Author Keywords","Document Type","Publication Stage","Open Access","Source","EID"
"Fernandez R.; Fernandez-Beltran R.; Pla F.","Fernandez, Rafael (57222243976); Fernandez-Beltran, Ruben (55838551300); Pla, Filiberto (7006504936)","57222243976; 55838551300; 7006504936","SENTINEL-3 IMAGE SUPER-RESOLUTION USING DATA FUSION AND CONVOLUTIONAL NEURAL NETWORKS","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","2867","2870","3","10.1109/IGARSS47720.2021.9554826","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129884916&doi=10.1109%2fIGARSS47720.2021.9554826&partnerID=40&md5=85e41091ceadaed2fc3a7c5855bf1103","With the increasing availability of Sentinel-2 (S2) and Sentinel-3 (S3) data, developing higher-level data products becomes a very attractive option to relieve the spatial limitations of the Ocean and Land Colour Instrument (OLCI) of S3. In this context, this paper investigates the suitability of super-resolving operational OLCI products using the Multi-Spectral Instrument (MSI) of S2 as an offline spatial reference. Specifically, the proposed approach assembles a multi-spectral data fusion scheme together with a convolutinal neural network (CNN) mapping function to project the OLCI sensor onto its corresponding spatial reference which is synthetically generated by the OLCI/MSI fusion. In this way, the trained model is able to super-resolve operational OLCI products under demand without the need of using MSI data. The experimental part of the work shows the suitability of the proposed approach in the context of the Copernicus programme. © 2021 IEEE","Convolutional neural networks; Photomapping; Sensor data fusion; Spectral resolution; Convolutional neural network; Data products; Image super resolutions; Multi-spectral; Offline; Sentinel-2; Sentinel-3; Spatial reference; Super-resolution; Superresolution; Image fusion","image fusion; Sentinel-2 (S2); Sentinel-3 (S3); super-resolution (SR)","Conference paper","Final","","Scopus","2-s2.0-85129884916"
"Alboody A.; Puigt M.; Roussel G.; Vantrepotte V.; Jamet C.; Tran T.-K.","Alboody, Ahed (24528545800); Puigt, Matthieu (9132941600); Roussel, Gilles (57197306458); Vantrepotte, Vincent (22954813300); Jamet, Cédric (8600546000); Tran, Trung-Kien (57217442266)","24528545800; 9132941600; 57197306458; 22954813300; 8600546000; 57217442266","Deepsen3: Deep Multi-Scale Learning Model for Spatial-Spectral Fusion of Sentinel-2 and Sentinel-3 Remote Sensing Images","2022","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2022-September","","","","","","10.1109/WHISPERS56178.2022.9955139","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143137132&doi=10.1109%2fWHISPERS56178.2022.9955139&partnerID=40&md5=ae93d14c297f67122101f7ca3ece2eb1","Recently, deep learning methods that integrate image features gradually became a hot development trend in fusion of multispectral and hyperspectral remote sensing images, aka multi-sharpening. Fusion of a low spatial resolution hyperspectral image (LR-HSI datacube) with its corresponding high spatial resolution multispectral image (HR-MSI datacube) to reconstruct a high spatial resolution hyperspectral image (HR-HSI) has been a significant subject in recent years. Nevertheless, it is still difficult to achieve a high quality of spatial and spectral information fusion. In this paper, we propose a Deep Multi-Scale Learning Model (called DeepSen3) of spatial-spectral information fusion based on multi-scale inception residual convolutional neural network (CNN) for more efficient hyperspectral and multispectral image fusion from ESA remote sensing satellite missions (Sentinel-2 and Sentinel-3 images). The proposed DeepSen3 fusion network was applied to Sentinel-2 MSI (13 spectral bands with a spatial resolution ranging from 10, 20 to 60 m) and Sentinel-3 OLCI (21 spectral bands with a spatial resolution of 300 m) images. Extensive experiments demonstrate that the proposed DeepSen3 network achieves the best performance (both qualitatively and quantitatively) compared with recent state-of-the-art deep learning approaches.  © 2022 IEEE.","Convolution; Convolutional neural networks; Deep learning; Image fusion; Image resolution; Information fusion; Learning systems; Spectroscopy; Convolutional neural network; Deep learning; Features extraction; HyperSpectral; Hyperspectral image; Multi-scale inception; Multi-scales; Multi-spectral image; Multispectral images; Remote sensing images; Residual convolutional neural network (resnet-convolutional neural network); Sentinel-2 and sentinel-3 remote sensing image; Spatial-spectral image fusion; Spectral image fusions; Remote sensing","Deep Learning; Feature Extraction; HyperSpectral Images (HSI); Multi-Scale Inception; Multi-Spectral Images (MSI); Residual Convolutional Neural Network (ResNet-CNN); Sentinel-2 and Sentinel-3 Remote Sensing Images; Spatial-Spectral Image Fusion","Conference paper","Final","","Scopus","2-s2.0-85143137132"
"Alboody A.; Puigt M.; Roussel G.; Vantrepotte V.; Jamet C.; Tran T.K.","Alboody, Ahed (24528545800); Puigt, Matthieu (9132941600); Roussel, Gilles (57197306458); Vantrepotte, Vincent (22954813300); Jamet, Cedric (8600546000); Tran, Trung Kien (57217442266)","24528545800; 9132941600; 57197306458; 22954813300; 8600546000; 57217442266","Experimental Comparison of Multi-Sharpening Methods Applied to Sentinel-2 MSI and Sentinel-3 OLCI Images","2021","Workshop on Hyperspectral Image and Signal Processing, Evolution in Remote Sensing","2021-March","","9484009","","","","10.1109/WHISPERS52202.2021.9484009","2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112845236&doi=10.1109%2fWHISPERS52202.2021.9484009&partnerID=40&md5=2b0e58f3cf7340bccdfdc9bdab25341b","Multi-spectral images are crucial to detect and to understand phenomena in marine observation. However, in coastal areas, these phenomena are complex and their analyze requires multi-spectral images with both a high spatial and spectral resolution. Unfortunately, no satellite is able to provide both at the same time. As a consequence, multi-sharpening techniques - a.k.a. fusion or super- resolution of multi-spectral and/or hyper-spectral images - were proposed and consist of combining information from at least two multi-spectral images with different spatial and spectral resolutions. The fused image then combines their best characteristics. Various methods - based on different strategies and tools - have been proposed to solve this problem. This article presents a comparative review of fusion methods applied to Sentinel-2 MSI (13 spectral bands with a spatial resolution ranging from 10 to 60 m) and Sentinel-3 OLCI (21 spectral bands with a spatial resolution of 300 m) images. Indeed, both satellites are extensively used in marine observation and, to the best of the authors' knowledge, the fusion of their data was partially investigated (and not in the way we aim to do in this paper). To that end, we provide both a quantitative analysis of the performance of some state-of-the-art methods on simulated images, and a qualitative analysis on real images.  © 2021 IEEE.","Hyperspectral imaging; Image fusion; Image resolution; Remote sensing; Spectral resolution; Spectroscopy; Experimental comparison; Hyper-spectral images; Marine observations; Multispectral images; Qualitative analysis; Spatial resolution; State-of-the-art methods; Strategies and tools; Image analysis","Image fusion; Real data; Remote sensing; Sentinel-2 MSI; Sentinel-3 OLCI; Simulations","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85112845236"
"Mileva N.; Mecklenburg S.; Gascon F.","Mileva, Nikolina (57205202523); Mecklenburg, Susanne (6603464568); Gascon, Ferran (7005867979)","57205202523; 6603464568; 7005867979","New tool for spatio-temporal image fusion in remote sensing: A case study approach using Sentinel-2 and Sentinel-3 data","2018","Proceedings of SPIE - The International Society for Optical Engineering","10789","","107890L","","","","10.1117/12.2327091","4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059028854&doi=10.1117%2f12.2327091&partnerID=40&md5=13656998104e7f1f1dfb4dd46b0fd799","Remote sensing image fusion allows the spectral, spatial and temporal enhancement of images. New techniques for image fusion are constantly emerging shifting the focus from pan-sharpening to spatiotemporal fusion of data originating from different sensors and platforms. However, the application of image fusion in the field of Earth observation still remains limited. The number and complexity of the different techniques available today can be overwhelming thus preventing users from fully exploiting the potential of fusion. The aim of this study is to make fusion products more accessible to users by providing them with a simple tool for spatiotemporal fusion in Python. This tool will contribute to the better exploitation of data from available sensors making possible to bring the images to the spectral, spatial and temporal resolution required by the user. The fusion algorithm implemented in the tool is based on the spatial and temporal adaptive reflectance fusion model (STARFM) - a well established fusion technique in the field of remote sensing often used as benchmark by other algorithms. The capabilities of the tool are demonstrated by three case studies using Sentinel-2 and simulated Sentinel-3 data. The first case study is about deforestation in the Amazon forest. The other two case studies concentrate on detecting change in an agricultural site in Southern Germany and urban flooding caused by the hurricane Harvey. © 2018 SPIE.","Data fusion; Deforestation; Image enhancement; Reflection; Remote sensing; Urban growth; Case study approach; Remote sensing images; Sentinel-2; Sentinel-3; Spatial and temporal resolutions; Spatio-temporal fusions; Spatiotemporal images; Surface reflectance; Image fusion","Data fusion; Remote sensing; Sentinel-2; Sentinel-3; Surface reflectance","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85059028854"
"Peschoud C.; Minghelli A.; Mathieu S.; Lei M.; Pairaud I.; Pinazo C.","Peschoud, Cecile (57189630285); Minghelli, Audrey (6507427005); Mathieu, Sandrine (57204744545); Lei, Manchun (35868077200); Pairaud, Ivane (8869977400); Pinazo, Christel (6602655361)","57189630285; 6507427005; 57204744545; 35868077200; 8869977400; 6602655361","Fusion of Sun-Synchronous and Geostationary Images for Coastal and Ocean Color Survey Application to OLCI (Sentinel-3) and FCI (MTG)","2017","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","10","1","7487007","45","56","11","10.1109/JSTARS.2016.2558819","8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973519387&doi=10.1109%2fJSTARS.2016.2558819&partnerID=40&md5=08fb8dcd4a7a78e81c48c9f613355d10","Open ocean and coastal area monitoring requires multispectral satellite images with a middle spatial resolution ({\sim 300\ {\text{m}}}) and a high temporal repeatability ({\sim 1\ {\text{h}}}). As no current satellite sensors have such features, the aim of this study is to propose a fusion method to merge images delivered by a low earth orbit (LEO) sensor with images delivered by a geostationary earth orbit (GEO) sensor. This fusion method, called spatial spectral temporal fusion (SSTF), is applied to the future sensors-Ocean and Land Color Instrument (OLCI) (on Sentinel-3) and Flexible Combined Imager (FCI) (on Meteosat Third Generation) whose images were simulated. The OLCI bands, acquired at t0, are divided by the oversampled corresponding FCI band acquired at t0 and multiplied by the FCI bands acquired at t1. The fusion product is used for the next fusion at t1 and so on. The high temporal resolution of FCI allows its signal-To-noise ratio (SNR) to be enhanced by the means of temporal filtering. The fusion quality indicator ERGAS computed between SSTF fusion products and reference images is around 0.75, once the FCI images are filtered from the noise and 1.08 before filtering. We also compared the estimation of chlorophyll (Chl), suspended particulate matter (SPM), and colored dissolved organic matter (CDOM) maps from the fusion products with the input simulation maps. The comparison shows an average relative errors on Chl, SPM, and CDOM, respectively, of 64.6%, 6.2%, and 9.5% with the SSTF method. The SSTF method was also compared with an existing fusion method called the spatial and temporal adaptive reflectance fusion model (STARFM). © 2008-2012 IEEE.","Biological materials; Geostationary satellites; Orbits; Signal to noise ratio; Weather satellites; Average relative error; Colored dissolved organic matter; Geostationary Earth orbit; High temporal resolution; Low earth orbit(LEO); Meteosat third generation; Multispectral satellite image; Suspended particulate matters; coastal zone; data quality; GOCI; ocean color; open ocean; satellite imagery; signal-to-noise ratio; spatial resolution; spatiotemporal analysis; spectral analysis; Image fusion","Fusion; image simulation; meteosat Third Generation (MTG); Ocean and Land Color Instrument; ocean color","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84973519387"
"Cissé C.T.; Alboody A.; Puigt M.; Roussel G.; Vantrepotte V.; Jamet C.; Tran T.K.","Cissé, C.T. (57797817500); Alboody, A. (24528545800); Puigt, M. (9132941600); Roussel, G. (57197306458); Vantrepotte, V. (22954813300); Jamet, C. (8600546000); Tran, T.K. (57217442266)","57797817500; 24528545800; 9132941600; 57197306458; 22954813300; 8600546000; 57217442266","A NEW DEEP LEARNING METHOD FOR MULTISPECTRAL IMAGE TIME SERIES COMPLETION USING HYPERSPECTRAL DATA","2022","ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","2022-May","","","1546","1550","4","10.1109/ICASSP43922.2022.9747895","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134049776&doi=10.1109%2fICASSP43922.2022.9747895&partnerID=40&md5=000b7f09614904d39e30e0805752f56c","The massive development of remote sensing allowed many novel applications which bring new challenges. In particular, some applications such as marine observation require a good spatial, spectral, and temporal resolution. In order to tackle the last issue, spatio-temporal fusion of remote sensing data allows to complete a time series of multispectral images from, e.g., hyperspectral images. In this paper, we propose a new deep learning approach to that end. Our main contribution lies in the error completion task which allows to improve the completion performance. We show that our proposed method is able to produce high fidelity predictions with better quality indices than state-of-the-art methods on true images taken from the CIA/LGC database and Sentinel-2/Sentinel-3 data. © 2022 IEEE","Deep learning; Image fusion; Learning systems; Marine applications; Spectroscopy; Time series; Deep learning; Hyperspectral Data; Image time-series; Learning methods; Multispectral images; Novel applications; Remote-sensing; Spatio-temporal fusions; Time-series completion; Times series; Remote sensing","Deep Learning; Remote Sensing; Spatio-Temporal Fusion; Time-Series Completion","Conference paper","Final","","Scopus","2-s2.0-85134049776"
"Wang Q.; Atkinson P.M.","Wang, Qunming (55649569623); Atkinson, Peter M. (7201906181)","55649569623; 7201906181","Spatio-temporal fusion for daily Sentinel-2 images","2018","Remote Sensing of Environment","204","","","31","42","11","10.1016/j.rse.2017.10.046","181","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033214493&doi=10.1016%2fj.rse.2017.10.046&partnerID=40&md5=5d840fea0206383bd8d77cfdafdc99fc","Sentinel-2 and Sentinel-3 are two newly launched satellites for global monitoring. The Sentinel-2 Multispectral Imager (MSI) and Sentinel-3 Ocean and Land Colour Instrument (OLCI) sensors have very different spatial and temporal resolutions (Sentinel-2 MSI sensor 10 m, 20 m and 60 m, 10 days, albeit 5 days with 2 sensors, conditional upon clear skies; Sentinel-3 OLCI sensor 300 m, < 1.4 days with 2 sensors). For local monitoring (e.g., the growing cycle of plants) one either has the desired spatial or temporal resolution, but not both. In this paper, spatio-temporal fusion is considered to fuse Sentinel-2 with Sentinel-3 images to create nearly daily Sentinel-2 images. A challenging issue in spatio-temporal fusion is that there can be very few cloud-free fine spatial resolution images temporally close to the prediction time, or even available, strong temporal (i.e., seasonal) changes may exist. To this end, a three-step method consisting of regression model fitting (RM fitting), spatial filtering (SF) and residual compensation (RC) is proposed, which is abbreviated as Fit-FC. The Fit-FC method can be performed using only one Sentinel-3–Sentinel-2 pair and is advantageous for cases involving strong temporal changes (i.e., mathematically, the correlation between the two Sentinel-3 images is small). The effectiveness of the method was validated using two datasets. The created nearly daily Sentinel-2 time-series images have great potential for timely monitoring of highly dynamic environmental, agricultural or ecological phenomena. © 2017 Elsevier Inc.","Regression analysis; Down-scaling; Sentinel-2; Sentinel-3; Spatial and temporal resolutions; Spatial filterings; Spatial resolution images; Spatio-temporal fusions; Temporal resolution; correlation; data set; downscaling; image analysis; image resolution; regression analysis; satellite data; satellite imagery; satellite sensor; Sentinel; spatial resolution; spatiotemporal analysis; Image fusion","Downscaling; Image fusion; Sentinel-2; Sentinel-3","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85033214493"
"Adeniran I.A.; Zhu R.; Yang J.; Zhu X.; Wong M.S.","Adeniran, Ibrahim Ademola (57907674100); Zhu, Rui (57784827700); Yang, Jinxin (56009762200); Zhu, Xiaolin (55696724800); Wong, Man Sing (57419402600)","57907674100; 57784827700; 56009762200; 55696724800; 57419402600","Cross-Comparison between Sun-Synchronized and Geostationary Satellite-Derived Land Surface Temperature: A Case Study in Hong Kong","2022","Remote Sensing","14","18","4444","","","","10.3390/rs14184444","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138814022&doi=10.3390%2frs14184444&partnerID=40&md5=9fc5c6b4171f7f025f426bc5509ad23b","Harmonization of satellite imagery provides a good opportunity for studying land surface temperature (LST) as well as the urban heat island effect. However, it is challenging to use the harmonized data for the study of LST due to the systematic bias between the LSTs from different satellites, which is highly influenced by sensor differences and the compatibility of LST retrieval algorithms. To fill this research gap, this study proposes the comparison of different LST images retrieved from various satellites that focus on Hong Kong, China, by applying diverse retrieval algorithms. LST images generated from Landsat-8 using the mono-window algorithm (MWAL8) and split-window algorithm (SWAL8) would be compared with the LST estimations from Sentinel-3 SLSTR and Himawari-8 using the split-window algorithm (SWAS3 and SWAH8). Intercomparison will also be performed through segregated groups of different land use classes both during the daytime and nighttime. Results indicate that there is a significant difference among the quantitative distribution of the LST data generated from these three satellites, with average bias of up to −1.80 K when SWAH8 was compared with MWAL8, despite having similar spatial patterns of the LST images. The findings also suggest that retrieval algorithms and the dominant land use class in the study area would affect the accuracy of image-fusion techniques. The results from the day and nighttime comparisons revealed that there is a significant difference between day and nighttime LSTs, with nighttime LSTs from different satellite sensors more consistent than the daytime LSTs. This emphasizes the need to incorporate as much night-time LST data as available when predicting or optimizing fine-scale LSTs in the nighttime, so as to minimize the bias. The framework designed by this study will serve as a guideline towards efficient spatial optimization and harmonized use of LSTs when utilizing different satellite images associated with an array of land covers and at different times of the day. © 2022 by the authors.","Atmospheric temperature; Geostationary satellites; Image fusion; Land surface temperature; Land use; Surface measurement; Surface properties; Himawari-8; Hong-kong; Land surface temperature; Land use class; LANDSAT; Landsat-8; Mono-window algorithms; Retrieval algorithms; Split window algorithms; Temperature data; Landsat","Himawari-8; land surface temperature; Landsat-8; mono-window algorithm; split-window algorithm","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85138814022"
"Lin C.; Zhu A.-X.; Wang Z.; Wang X.; Ma R.","Lin, Chen (56165571100); Zhu, A-Xing (55647324800); Wang, Zhaofei (57208215526); Wang, Xiaorui (57364552200); Ma, Ronghua (55892478400)","56165571100; 55647324800; 57208215526; 57364552200; 55892478400","The refined spatiotemporal representation of soil organic matter based on remote images fusion of Sentinel-2 and Sentinel-3","2020","International Journal of Applied Earth Observation and Geoinformation","89","","102094","","","","10.1016/j.jag.2020.102094","27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084938761&doi=10.1016%2fj.jag.2020.102094&partnerID=40&md5=479e5747c19b5def9730648b5cac7aa2","Remote sensing technology is important for soil organic matter (SOM) estimation, but existing studies have mainly relied on a single data source. This limitation makes it difficult to simultaneously ensure high spatial resolution, high spectral accuracy and refined temporal granularity simultaneously, which cannot meet the requirements of the spatiotemporal dynamics representation. This study aimed to introduce a new remote sensing image source into SOM modeling and spatiotemporal estimation generated by fusing together Sentinel-2 and Sentinel-3 remote sensing images that have a 5-day revisit cycle; 10 m spatial resolution; and 21 different bands in blue, green, red and NIR spectral ranges. According to the image fusion process, a total of 52 available images were acquired between November 2016 and December 2018 in Donghai County, China. The fused images were used for SOM estimation model associated with 107 field samples. The results indicated that, first, the optimal model consisted of the band reflectivity (B20) and RVI (B18/B9), which were derived from the fused images, and the R2 approached 0.7 in the two phases of the synchronized data. Second, the modeling accuracy was influenced to some extent by the actual SOM content. The R2 values exceeded 0.75 when the SOM content was higher than 24 g/kg, while the R2 was even lower than 0.35 when the SOM content was lower. Third, the averaged SOM contents remained stable in general, while the seasonal variances can also be found during the two-year interval. The SOM contents maintained a low level during autumn and winter, while higher SOM levels were found in the spring and summer. Finally, the spatial variations could be described as ‘low in the west and high in the east’. In summary, the spatiotemporal dynamics of SOM highlighted the necessity of modeling with fused remote sensing images, and more effective modeling could be expected with the continued increase in SOM in future. © 2020 The Authors","China; Donghai [Jiangsu]; Jiangsu; environmental factor; remote sensing; Sentinel; soil organic matter; spatial resolution; spatial variation; spatiotemporal analysis","Environmental factors; Estimation model; Remote sensing; Sentinel 2/3; Soil organic matter","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85084938761"
"Lomelí-Huerta R.; Avila-George H.; Rivera-Caicedo J.P.; De-La-Torre M.","Lomelí-Huerta, Roberto (57678512600); Avila-George, Himer (36607394000); Rivera-Caicedo, Juan Pablo (54684821900); De-La-Torre, Miguel (22333630400)","57678512600; 36607394000; 54684821900; 22333630400","WATER POLLUTION DETECTION IN ACAPULCO COASTS USING MERGED DATA FROM THE SENTINEL-2 AND SENTINEL-3 SATELLITES","2021","International Geoscience and Remote Sensing Symposium (IGARSS)","","","","1518","1521","3","10.1109/IGARSS47720.2021.9553929","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129902247&doi=10.1109%2fIGARSS47720.2021.9553929&partnerID=40&md5=f0fb826b3db5da16c03577752facbfc2","Acapulco coasts are occasionally contaminated by illegal discharges originated by temporary or permanent floods that disembogue to the pacific ocean. Plumes formed by contaminated water running through the ocean can be distinguished in satellite imagery, and their reflectance is related to the polluting elements. Although some spacial agencies provide data from diverse multispectral sensors, application-specific requirements are fulfilled by merging heterogeneous imagery (differences in spatial, temporal, and spectral resolutions). This paper proposes a continuous monitoring strategy to detect pollution in water discharges by combining data from Sentinel-2 and Sentinel-3 platforms. First, the region of interest to be monitored is detected using the bands with high spatial resolution. Then, distance-based supervised machine learning is employed to detect pixel-wise pollution in water. Finally, the historic detections over time are presented to detect recurrent discharges. ©2021 IEEE","Image fusion; Image segmentation; Monitoring; Oil spills; Pollution detection; Remote sensing; Satellite imagery; Supervised learning; Contaminated water; Illegal discharges; Monitoring system; Pacific ocean; Remote-sensing; Satellite image fusion; Satellite images; Sentinel; Water pollution detections; Water running; Water pollution","contaminated water; monitoring system; remote sensing; satellite image fusion; Sentinel","Conference paper","Final","","Scopus","2-s2.0-85129902247"
"Tang Y.; Wang Q.; Tong X.; Atkinson P.M.","Tang, Yijie (57211522443); Wang, Qunming (55649569623); Tong, Xiaohua (55500134600); Atkinson, Peter M. (7201906181)","57211522443; 55649569623; 55500134600; 7201906181","Integrating spatio-temporal-spectral information for downscaling Sentinel-3 OLCI images","2021","ISPRS Journal of Photogrammetry and Remote Sensing","180","","","130","150","20","10.1016/j.isprsjprs.2021.08.012","3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113299870&doi=10.1016%2fj.isprsjprs.2021.08.012&partnerID=40&md5=e316b36778bd02aebd34e0727b605908","Sentinel-3 is a newly launched satellite implemented by the European Space Agency (ESA) for global observation. The Ocean and Land Colour Imager (OLCI) sensor onboard Sentinel-3 provides 21 band images with a fine spectral resolution and is of great value for ocean, land and atmospheric monitoring. The two platforms (Sentinel-3A and -3B) can provide OLCI images at an almost daily temporal resolution. The coarse spatial resolution of the 21 band OLCI images (i.e., 300 m), however, limits greatly their utility for local, precise monitoring. Sentinel-2, another satellite provided by ESA, carries the Multispectral Imager (MSI) sensor which can supply much finer spatial resolution (e.g., 10 m and 20 m) images. This paper introduces a new fusion framework integrating spatio-temporal-spectral information for downscaling Sentinel-3 OLCI images, which has two parts. Based on bands with similar wavelengths (i.e., bands 2, 3, 4 and 8a for Sentinel-2 and bands Oa4, Oa6, Oa8 and Oa17 for Sentinel-3), the four Sentinel-3 bands are first downscaled to the spatial resolution of Sentinel-2 images by applying spatio-temporal fusion to Sentinel-2 MSI and Sentinel-3 OLCI images. Then, to take full advantage of all 21 available OLCI bands of the Sentinel-3 images, the extended image pair-based spatio-spectral fusion (EIPSSF) method is proposed in this paper to downscale the other 17 bands. EIPSSF is performed based on the new concept of the extended image pair (EIP) and by exploiting existing spatio-temporal fusion approaches. The framework consisting of spatio-temporal and spatio-spectral fusion is entirely general, which provides a practical solution for comprehensive downscaling of Sentinel-3 OLCI images for fine spatial, temporal and spectral resolution monitoring. © 2021 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Image resolution; Remote sensing; Spectral resolution; Color imagers; Down-scaling; European Space Agency; Image pairs; Multispectral imagers; Sentinel-2; Sentinel-3; Spatial resolution; Spatio-temporal; Spectral information; downscaling; image resolution; integrated approach; satellite sensor; Sentinel; spatial resolution; spatiotemporal analysis; spectral resolution; Image fusion","Downscaling; Image fusion; Sentinel-2; Sentinel-3","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85113299870"
"Fernandez R.; Fernandez-Beltran R.; Pla F.","Fernandez, Rafael (57222243976); Fernandez-Beltran, Ruben (55838551300); Pla, Filiberto (7006504936)","57222243976; 55838551300; 7006504936","Inter-Sensor Remote Sensing Image Enhancement for Operational Sentinel-2 and Sentinel-3 Data Products","2020","International Geoscience and Remote Sensing Symposium (IGARSS)","","","9324071","1504","1507","3","10.1109/IGARSS39084.2020.9324071","0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102010234&doi=10.1109%2fIGARSS39084.2020.9324071&partnerID=40&md5=7e63a302423c3f8b2adf11c8230671a0","The recent availability of operational data from the Sentinel-2 and Sentinel-3 missions provides widespread opportunities to generate diverse high-level remote sensing products. However, the synergies between both multi-spectral instruments are often difficult to exploit from an operational perspective. Standard pansharpening algorithms may encounter important disadvantages due to the limited intersensor data availability in actual production environments. Moreover, the lack of a real high-resolution ground-truth for super-resolution techniques may affect the radiometric quality of the final result. In this scenario, this work investigates the viability of using the Multi-Spectral Instrument of Sentinel-2 for super-resolving data products acquired by the Ocean and Land Colour Instrument of Sentinel-3. Specifically, we define an inter-sensor image enhancement framework which combines a PCA-based component substitution pansharpening scheme with a CNN-based spatial enhancing super-resolution mapping. The conducted experiments reveal the suitability of the proposed approach for generating Level-4 data products within the Copernicus programme context. © 2020 IEEE.","Geology; Optical resolving power; Remote sensing; Component substitution; Data availability; Enhancement framework; Production environments; Radiometric quality; Remote sensing images; Sentinel-3 Mission; Super-resolution mappings; Image enhancement","image fusion; pansharpening; Sentinel-2 (S2); Sentinel-3 (S3); super-resolution (SR)","Conference paper","Final","","Scopus","2-s2.0-85102010234"
"Wang Q.; Shi W.; Li Z.; Atkinson P.M.","Wang, Qunming (55649569623); Shi, Wenzhong (7402664815); Li, Zhongbin (56289297800); Atkinson, Peter M. (7201906181)","55649569623; 7402664815; 56289297800; 7201906181","Fusion of Sentinel-2 images","2016","Remote Sensing of Environment","187","","","241","252","11","10.1016/j.rse.2016.10.030","137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992090962&doi=10.1016%2fj.rse.2016.10.030&partnerID=40&md5=95fcd536a1573efe288f6a1537ee531c","Sentinel-2 is a very new programme of the European Space Agency (ESA) that is designed for fine spatial resolution global monitoring. Sentinel-2 images provide four 10 m bands and six 20 m bands. To provide more explicit spatial information, this paper aims to downscale the six 20 m bands to 10 m spatial resolution using the four directly observed 10 m bands. The outcome of this fusion task is the production of 10 Sentinel-2 bands with 10 m spatial resolution. This new fusion problem involves four fine spatial resolution bands, which is different to, and more complex than, the common pan-sharpening fusion problem which involves only one fine band. To address this, we extend the existing two main families of image fusion approaches (i.e., component substitution, CS, and multiresolution analysis, MRA) with two different schemes, a band synthesis scheme and a band selection scheme. Moreover, the recently developed area-to-point regression kriging (ATPRK) approach was also developed and applied for the Sentinel-2 fusion task. Using two Sentinel-2 datasets released online, the three types of approaches (eight CS and MRA-based approaches, and ATPRK) were compared comprehensively in terms of their accuracies to provide recommendations for the task of fusion of Sentinel-2 images. The downscaled ten-band 10 m Sentinel-2 datasets represent important and promising products for a wide range of applications in remote sensing. They also have potential for blending with the upcoming Sentinel-3 data for fine spatio-temporal resolution monitoring at the global scale. © 2016","Europe; Image resolution; Interpolation; Remote sensing; Component substitution; Down-scaling; European Space Agency; Image fusion approach; Regression-kriging; Sentinel-2; Spatial informations; Spatio-temporal resolution; downscaling; image analysis; image resolution; kriging; regression analysis; satellite imagery; Sentinel; spatial resolution; Image fusion","Area-to-point regression kriging (ATPRK); Downscaling; Image fusion; Sentinel-2","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84992090962"
"Korosov A.A.; Pozdnyakov D.V.","Korosov, Anton A. (6505884703); Pozdnyakov, Dmitry V. (56370460300)","6505884703; 56370460300","Fusion of data from Sentinel-2/MSI and Sentinel-3/OLCI","2016","European Space Agency, (Special Publication) ESA SP","SP-740","","","","","","","1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988527720&partnerID=40&md5=5447134425902a85de7c3bf365940a75","Multisensor image fusion is the process of combining relevant information from two or more satellite images into a single image. The fused image can have complementary spatial and spectral resolution characteristics. We suggest a method for fusion of data from Sentinel-2 multi spectral imager (MSI) and Sentinel-3 Ocean and Land Color Instrument (OLCI). In the visible range MSI measures radiance with 10 m resolution at 490, 560 and 665 nm; with 20 m resolution at 705 nm; and with 60 m resolution at 443 nm. In the visible range OLCI measures with 300 m spatial resolution at 400, 412, 443, 490, 510, 560, 620, 665, 673, 681, 708 nm. The data from the visible from both sensors is fused to get products with values of remote sensing reflectance wavelengths of OLCI and with spatial resolution of 60 m using an artificial neural network.","Image fusion; Image resolution; Neural networks; Spectroscopy; Fused images; Multi spectral imager; Multisensor image fusion; Remote-sensing reflectance; Satellite images; Single images; Spatial resolution; Visible range; Remote sensing","","Conference paper","Final","","Scopus","2-s2.0-84988527720"
