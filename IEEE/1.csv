"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Structured Deep Unfolding Network for Optical Remote Sensing Image Super-Resolution","M. Shi; Y. Gao; L. Chen; X. Liu","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Geoscience and Remote Sensing Letters","5 Dec 2022","2022","19","","1","5","Single-image super-resolution technology is critical in remote sensing, effectively improving the resolution of target images, with super-resolution algorithms based on deep learning demonstrating superior performance. However, most neural networks present shortcomings, such as a lack of interpretability and requiring a long training time, limiting them in some application scenarios. Moreover, due to the multidegradation factors, tasks put forward higher requirements for the adaptability of algorithms. Therefore, this work develops a structured deep unfolding network (SDUNet), which is adaptable and requires a lower training time by cascading multiple small network modules. Additionally, the unfolding strategy proposed deals with multiple degradations, fully exploiting prior knowledge. The suggested method is challenged against state-of-the-art neural network methods on one optical remote sensing image (ORSI) dataset and one natural image dataset. The experimental results demonstrate our method’s effectiveness in requiring less training time, involving fewer parameters, and achieving a higher reconstruction performance for ORSI super-resolution.","1558-0571","","10.1109/LGRS.2022.3221612","National Key Research and Development Program of China(grant numbers:2021YFA0715400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955481","Deep unfolding;multidegradation;optical remote sensing image (ORSI);structured;super-resolution","Superresolution;Training;Convolution;Remote sensing;Task analysis;Neural networks;Degradation","deep learning (artificial intelligence);geophysical image processing;image reconstruction;image resolution;remote sensing","deep learning;natural image dataset;neural network methods;optical remote sensing image dataset;optical remote sensing image super-resolution;ORSI super-resolution;SDUNet;single-image super-resolution technology;structured deep unfolding network;super-resolution algorithms;target images;training time;unfolding strategy","","","","21","IEEE","18 Nov 2022","","","IEEE","IEEE Journals"
"Vehicle Detection in Remote Sensing Images Leveraging on Simultaneous Super-Resolution","H. Ji; Z. Gao; T. Mei; B. Ramesh","Electronic and Information School, Wuhan University, Wuhan, China; Temasek Laboratories, National University of Singapore, Singapore; Electronic and Information School, Wuhan University, Wuhan, China; Singapore Institute for Neurotechnology, National University of Singapore, Singapore","IEEE Geoscience and Remote Sensing Letters","25 Mar 2020","2020","17","4","676","680","Owing to the relatively small size of vehicles in remote sensing images, lacking sufficient detailed appearance to distinguish vehicles from similar objects, the detection performance is still far from satisfactory compared with the detection results on everyday images. Inspired by the positive effects of super-resolution convolutional neural network (SRCNN) for object detection and the stunning success of deep CNN techniques, we apply generative adversarial network frameworks to realize simultaneous SRCNN and vehicle detection in an end-to-end manner, and the detection loss is backpropagated into the SRCNN during training to facilitate detection. In particular, our work is unsupervised and bypasses the requirement of low-/high-resolution image pairs during the training stage, achieving increased generality and applicability. Extensive experiments on representative data sets demonstrate that our method outperforms the state-of-the-art detectors. (The source code will be made available after the review process).","1558-0571","","10.1109/LGRS.2019.2930308","Wuhan Institute Key Project(grant numbers:1WHS20171003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792159","Faster region-based convolutional neural network (R-CNN);feature fusion;remote sensing images;super-resolution convolutional neural network (SRCNN);vehicle detection","Image resolution;Generators;Remote sensing;Vehicle detection;Training;Detectors;Feature extraction","backpropagation;convolutional neural nets;geophysical image processing;image resolution;object detection;remote sensing;traffic engineering computing","backpropagation;simultaneous SRCNN;generative adversarial network frameworks;deep CNN techniques;object detection;super-resolution convolutional neural network;simultaneous super-resolution;remote sensing images;vehicle detection","","29","","26","IEEE","8 Aug 2019","","","IEEE","IEEE Journals"
"Developing Long Time Series 1-km Land Cover Maps From 5-km AVHRR Data Using a Super-Resolution Method","H. Wang; X. Zhao; S. Liang; D. Wu; X. Zhang; Q. Wang; J. Zhao; X. Du; Q. Zhou","Beijing Engineering Research Center for Global Land Remote Sensing Products, Faculty of Geographical Science, Institute of Remote Sensing Science and Engineering, Beijing Normal University, Beijing, China; Beijing Engineering Research Center for Global Land Remote Sensing Products, Faculty of Geographical Science, Institute of Remote Sensing Science and Engineering, Beijing Normal University, Beijing, China; Department of Geographical Sciences, University of Maryland, College Park, MD, USA; Department of Ecology and Evolutionary Biology, Cornell University, Ithaca, NY, USA; State Key Laboratory of Remote Sensing Science, Institute of Remote Sensing and Digital Earth, Chinese Academy of Science, Beijing, China; Beijing Engineering Research Center for Global Land Remote Sensing Products, Faculty of Geographical Science, Institute of Remote Sensing Science and Engineering, Beijing Normal University, Beijing, China; Beijing Engineering Research Center for Global Land Remote Sensing Products, Faculty of Geographical Science, Institute of Remote Sensing Science and Engineering, Beijing Normal University, Beijing, China; Beijing Engineering Research Center for Global Land Remote Sensing Products, Faculty of Geographical Science, Institute of Remote Sensing Science and Engineering, Beijing Normal University, Beijing, China; Beijing Engineering Research Center for Global Land Remote Sensing Products, Faculty of Geographical Science, Institute of Remote Sensing Science and Engineering, Beijing Normal University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","23 Jun 2021","2021","59","7","5479","5493","Dynamic land cover (LC) information is an essential part of environmental and ecological research. Therefore, acquiring dynamic LC data with high spatial resolution has attracted a great deal of attention in the remote sensing community. Nevertheless, the high-temporal resolution satellite data tend to have a coarse spatial resolution, and satellite data with high temporal resolution are often relatively low. Obtaining LC with high spatiotemporal resolution is extremely challenging. The super-resolution method can help researchers achieve this goal, and the recently developed neural-network-based deep learning algorithms have great potential for use as an alternative solution. This study proposes a focal loss temporal convolutional long short-term memory (FL-T-ConvLSTM) model for super-resolution LC classification research. It first trains the deep FL-T-ConvLSTM network to establish a transformation between low-resolution quantitative remote sensing parameters and high-resolution quantitative remote sensing parameters and then engages in nonlinear mapping with a high-resolution LC map. A long-term series 1-km super-resolution LC classification model based on deep learning was established and applied to the Beijing–Tianjin–Hebei region. Based on this method, a long-term series of 1-km LC maps from 1982 to 2019 can be obtained. The test accuracy and field validation accuracy of the model reached 90.1% and 86.8% when using reliable test samples and field test samples, respectively. This study provides a method for obtaining high-resolution LC classification products from low-resolution quantitative remote-sensing products.","1558-0644","","10.1109/TGRS.2020.3018109","National Key Research and Development Program of China(grant numbers:2016YFA0600103,2016YFB0501404); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186343","Focal loss temporal convolutional long short-term memory (FL-T-ConvLSTM);land cover (LC);long time series;quantitative remote sensing parameters;super-resolution","Spatial resolution;Remote sensing;Convolution;Time series analysis;Feature extraction;Data models","ecology;geophysical image processing;image resolution;learning (artificial intelligence);neural nets;remote sensing;time series","time series;AVHRR data;super-resolution method;dynamic land cover information;environmental research;ecological research;dynamic LC data;high spatial resolution;remote sensing community;high-temporal resolution satellite data;coarse spatial resolution;high temporal resolution;high spatiotemporal resolution;focal loss temporal convolutional long short-term memory;super-resolution LC classification research;deep FL-T-ConvLSTM network;low-resolution quantitative remote sensing parameters;high-resolution quantitative remote sensing parameters;high-resolution LC map;high-resolution LC classification products;remote-sensing products;land cover maps;long-term series;neural-network-based deep learning algorithms","","","","94","IEEE","3 Sep 2020","","","IEEE","IEEE Journals"
"SD-DCRN: SALIENCY DRIVEN DOUBLE-CHANNEL RESIDUAL NETWORK FOR SUPER-RESOLUTION OF REMOTE SENSING IMAGES","W. Li; Y. Feng; Y. Chen; L. Zhang","School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","3774","3777","Traditional methods of super-resolution of remote sensing images generally ignore the fact that significant areas usually have a higher demand for super-resolution compared to nonsignificant areas. According to this feature of remote sensing images, we propose a new model of super-resolutio-n based on double-channel residual dense network driven by saliency analysis. Firstly, we use a cascaded partial decoder model to obtain the saliency image of remote sensing images which contributes to distinguishing significant areas and background areas. Secondly, we adopt different super-resolution strategies for regions with different salient values and texture complexity. For the non-salient regions, we adopt the smaller number of RDBs and their internal convolution layers to save computer resources. For the salient regions, we increase the number of RDBs and layers to extract more complex features for super-resolution of the salient regions, which is conducive to the reconstruction of complex texture. Finally, the reconstructed salient regions and non-salient regions are superimposed to obtain the complete super-resolution results. Our experimental results show that the comprehensive perform of our method outperforms other super-resolution models in terms of metrics based on the peak signal-to-noise ratio and structural similarity.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883346","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883346","Remote sensing;image enhancement;super-resolution;saliency analysis;double-channel residual dense network","Measurement;Analytical models;PSNR;Convolution;Superresolution;Feature extraction;Remote sensing","feature extraction;geophysical image processing;image resolution;image texture;object detection;remote sensing","double-channel residual network;remote sensing images;significant areas;super-resolutio-n;double-channel residual dense network;saliency image;super-resolution strategies;nonsalient regions;reconstructed salient regions;complete super-resolution results;super-resolution models","","","","9","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Remote Sensing Image Super-Resolution via Enhanced Back-Projection Networks","X. Dong; Z. Xi; X. Sun; L. Yang","College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; Key Laboratory of Digital Earth Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Digital Earth Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1480","1483","Convolutional neural network (CNN)-based image super-resolution (SR) is one of the most active field of research in the remote sensing community. As a state-of-the-art super-resolving method, however, the dense deep back-projection network (DDBPN) ignores the mutual differences among the channel-wise features and discards the initial feature when performing reconstruction. In this paper, we develop an enhanced back-projection network (EBPN) with performance exceeding the DDBPN and other state-of-the-art methods. The performance improvement gains from introducing attention mechanism to capture the feature differences among channels and reconstructing images by using the element-wise sum of the upscaled initial feature and deep features learned at different depths. A retraining strategy is also employed to further boost the SR ability of EBPN for remote sensing images. Experimental results on a remote sensing dataset and four benchmark datasets demonstrate the superiority of EBPN.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323316","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323316","Super-resolution;remote sensing;back-projection;attention mechanism","Image reconstruction;Superresolution;Spatial resolution;Remote sensing;Feature extraction;Benchmark testing;Training","convolution;image classification;image reconstruction;image representation;image resolution;learning (artificial intelligence);neural nets;remote sensing","remote sensing dataset;remote sensing images;deep features;upscaled initial feature;element-wise sum;reconstructing images;feature differences;performance improvement gains;EBPN;performing reconstruction;discards;remote sensing image super-resolution;enhanced back-projection network;convolutional neural network-based image super-resolution;remote sensing community;state-of-the-art super-resolving method;dense deep back-projection network;DDBPN;mutual differences;channel-wise features","","4","","5","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"U-Shaped Attention Connection Network for Remote-Sensing Image Super-Resolution","W. Jiang; L. Zhao; Y. -J. Wang; W. Liu; B. -D. Liu","College of Oceanography and Space Informatics, China University of Petroleum (East China), Qingdao, China; College of Oceanography and Space Informatics, China University of Petroleum (East China), Qingdao, China; College of Control Science and Engineering, China University of Petroleum (East China), Qingdao, China; College of Control Science and Engineering, China University of Petroleum (East China), Qingdao, China; College of Control Science and Engineering, China University of Petroleum (East China), Qingdao, China","IEEE Geoscience and Remote Sensing Letters","7 Jan 2022","2022","19","","1","5","In recent years, deep learning-based remote-sensing image super-resolution (SR) methods have made significant progress, and these methods require a large number of synthetic data for training. To obtain sufficient training data, researchers often generate synthetic data via fixed bicubic downsampling methods. However, the synthesized data cannot reflect the complex degradation process of real remote-sensing images. Thus, performance will dramatically reduce when these methods work in real low-resolution (LR) remote-sensing images. This letter proposes a U-shaped attention connection network (US-ACN) for remote-sensing image SR to solve this issue. Our US-ACN does not rely on any synthetic external dataset for training and merely requires one LR image to complete the training. The US-ACN utilizes remote-sensing images’ strong internal feature repetitiveness and fully learns this internal repetitive feature through a well-designed US-ACN to achieve the remote-sensing image SR. In addition, we design a 3-D attention module to generate effective 3-D weights by modeling channel and spatial attention weights, which is more helpful for the learning of internal features. Through the U-shaped connection among attention modules, context information propagation and attention weights learning are fully utilized. Many experiments show that our US-ACN adequately adapts to the remote-sensing image SR in various situations and performs advanced performance.","1558-0571","","10.1109/LGRS.2021.3127988","National Natural Science Foundation of China(grant numbers:62072468); Natural Science Foundation of Shandong Province(grant numbers:ZR2019MF073); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9614163","Attention connection;image super-resolution (SR);internal feature;remote-sensing image;U-shaped","Remote sensing;Training;Superresolution;Feature extraction;Solid modeling;Sensors;Decoding","deep learning (artificial intelligence);geophysical image processing;image reconstruction;image resolution;remote sensing","U-shaped attention connection network;deep learning-based remote-sensing image super-resolution methods;synthetic data;low-resolution remote-sensing images;US-ACN;remote-sensing image SR;LR image;context information propagation;attention weights","","2","","24","IEEE","12 Nov 2021","","","IEEE","IEEE Journals"
"Blind Super-Resolution on Remote Sensing Images with Blur Kernel Prediction","R. Dong; L. Zhang; H. Fu","Joint Center for Global Change Studies, Beijing, China; Joint Center for Global Change Studies, Beijing, China; Joint Center for Global Change Studies, Beijing, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2879","2882","Single image super-resolution (SISR) is essential in many remote sensing applications. Most of the existing SISR methods on remote sensing images assume that the low resolution (LR) images are synthesized from high-resolution (HR) images by bicubic downscaling. However, the performance of those methods is limited in the real-world remote sensing scenario as the actual degradation is sometimes different from the assumption. Therefore, we introduce the blind super-resolution (SR) concept and propose a super-resolution method with blur kernel prediction (BKPSR). BKPSR first predicts the blur kernel code for an image and then utilizes the blur kernel code to assist the image super-resolution. Experimental results indicate that our method outperforms existing SISR methods on real-world remote sensing images.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554620","National Key Research and Development Plan of China(grant numbers:2017YFA0604500); National Natural Science Foundation of China(grant numbers:51761135015,U1839206); Center for High Performance Computing and System Simulation, Pilot National Laboratory for Marine Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554620","Blind super-resolution;remote sensing image;blur-kernel estimation;deep learning","Degradation;Codes;Superresolution;Sensors;Kernel;Remote sensing","geophysical image processing;image resolution;remote sensing","blur kernel prediction;image super-resolution;SISR methods;low resolution images;high-resolution images;real-world remote sensing scenario;blind super-resolution concept;blur kernel code;real-world remote sensing images","","","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Improving Super-Resolution Flood Inundation Mapping for Multispectral Remote Sensing Image by Supplying More Spectral Information","P. Wang; G. Zhang; H. Leung","College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Key Laboratory of Radar Imaging and Microwave Photonics, Ministry of Education, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada","IEEE Geoscience and Remote Sensing Letters","22 Apr 2019","2019","16","5","771","775","Super-resolution mapping is an effective technique in mapping flood inundation for multispectral remote sensing image. However, the traditional super-resolution flood inundation mapping (SRFIM) is unable to fully utilize the spectral information from multispectral remote sensing image band. In order to resolve this problem, a novel SRFIM by supplying more spectral information (SRFIM-MSI) is proposed to improve mapping accuracy. In the proposed SRFIM-MSI, the spectral information from the multispectral band is calculated by the normalized difference water index (NDWI). A spectral term constituted by NDWI is added into the traditional SRFIM. The proposed method is evaluated by using two Landsat 8 OLI multispectral data from the study area in Cambodia. The obtained results demonstrate that the proposed SRFIM-MSI produces better results than the traditional SRFIM methods.","1558-0571","","10.1109/LGRS.2018.2882516","National Natural Science Foundation of China(grant numbers:61801211,61871218,61501233,61501228); Fundamental Research Funds for the Central Universities(grant numbers:3082017NP2017421); National Aerospace Science Foundation of China(grant numbers:20185152); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8565995","Multispectral remote sensing image;spectral information;super-resolution flood inundation mapping (SRFIM);super-resolution mapping (SRM)","Spatial resolution;Remote sensing;Correlation;Graphical models;Distribution functions;Indexes","floods;geophysical image processing;hydrological techniques;image resolution;remote sensing","super-resolution flood inundation mapping;spectral information;multispectral remote sensing image band;SRFIM-MSI;mapping accuracy;multispectral band;spectral term;Landsat 8 OLI multispectral data;traditional SRFIM methods;normalized difference water index;Cambodia","","15","","26","IEEE","6 Dec 2018","","","IEEE","IEEE Journals"
"Super-Resolution of Remote Sensing Images Based on Transferred Generative Adversarial Network","W. Ma; Z. Pan; J. Guo; B. Lei","Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","1148","1151","Single image super-resolution (SR) has been widely studied in recent years as a crucial technique for remote sensing applications. This paper proposes a SR method for remote sensing images based on a transferred generative adversarial network (TGAN). Different from the previous GAN-based SR approaches, the novelty of our method mainly reflects from two aspects. First, the batch normalization layers are removed to reduce the memory consumption and the computational burden, as well as raising the accuracy. Second, our model is trained in a transfer-learning fashion to cope with the insufficiency of training data, which is the crux of applying deep learning methods to remote sensing applications. The model is firstly trained on an external dataset DIV2K and further fine-tuned with the remote sensing dataset. Our experimental results demonstrate that the proposed method is superior to SRCNN and SRGAN in terms of both the objective evaluation and the subjective perspective.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517442","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517442","Remote sensing images;super-resolution;generative adversarial network;transfer learning","Image resolution;Remote sensing;Signal resolution;Training;Generative adversarial networks;Knowledge engineering;Task analysis","geophysical image processing;image resolution;learning (artificial intelligence);remote sensing","remote sensing images;transferred generative adversarial network;single image super-resolution;remote sensing applications;SR method;previous GAN-based SR approaches;transfer-learning fashion;deep learning methods;remote sensing dataset","","23","","12","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"High Quality Remote Sensing Image Super-Resolution Using Deep Memory Connected Network","W. Xu; G. XU; Y. Wang; X. Sun; D. Lin; Y. WU","Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China; Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","8889","8892","Single image super-resolution is an effective way to enhance the spatial resolution of remote sensing image, which is crucial for many applications such as target detection and image classification. However, existing methods based on the neural network usually have small receptive fields and ignore the image detail. We propose a novel method named deep memory connected network (DMCN) based on a convolutional neural network to reconstruct high-quality super-resolution images. We build local and global memory connections to combine image detail with environmental information. To further reduce parameters and ease time-consuming, we propose downsampling units, shrinking the spatial size of feature maps. We test DMCN on three remote sensing datasets with different spatial resolution. Experimental results indicate that our method yields promising improvements in both accuracy and visual performance over the current state-of-the-art.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518855","remote sensing image;super-resolution;convolutional neural network;image fusion","Spatial resolution;Remote sensing;Image reconstruction;Training;Convolutional neural networks;Satellites","convolution;feedforward neural nets;geophysical image processing;image reconstruction;image resolution;remote sensing","deep memory connected network;single image super-resolution;convolutional neural network;high-quality super-resolution images;remote sensing datasets;high quality remote sensing image super-resolution;spatial resolution;DMCN","","15","","6","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Unsupervised Remote Sensing Image Super-Resolution Using Cycle CNN","P. Wang; H. Zhang; F. Zhou; Z. Jiang","Image Processing Center, School of Astronautics, Beihang University, Beijing, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China; DFH Satellite Co., Ltd., Beijing, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3117","3120","Single image super-resolution (SISR) is a useful procedure for many remote sensing applications. However, paired high-resolution and low-resolution remote sensing images are actually hard to acquire for supervised learning SR methods. In this paper, we propose an unsupervised network named Cycle-CNN to handle this problem. Our network consists of two generative CNNs for down-sampling and super-resolution separately, and can be trained with unpaired data. Experiments on panchromatic and multi-spectral images of GaoFen-2 satellite indicate that our method achieves state-of-the-art SR results and is robust against noise and blur in the remote sensing images.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898648","super-resolution;unsupervised learning;CNN;remote sensing image","Remote sensing;Training;Satellites;Computer vision;Unsupervised learning","convolutional neural nets;image resolution;learning (artificial intelligence);remote sensing","single image super-resolution;low-resolution remote sensing images;supervised learning SR methods;multispectral images;unsupervised remote sensing image super-resolution;cycle-CNN;GaoFen-2 satellite;panchromatic images","","15","","10","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Super-Resolution for Remote Sensing Images via Local–Global Combined Network","S. Lei; Z. Shi; Z. Zou","State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China","IEEE Geoscience and Remote Sensing Letters","20 Jul 2017","2017","14","8","1243","1247","Super-resolution is an image processing technology that recovers a high-resolution image from a single or sequential low-resolution images. Recently deep convolutional neural networks (CNNs) have made a huge breakthrough in many tasks including super-resolution. In this letter, we propose a new single-image super-resolution algorithm named local-global combined networks (LGCNet) for remote sensing images based on the deep CNNs. Our LGCNet is elaborately designed with its “multifork” structure to learn multilevel representations of remote sensing images including both local details and global environmental priors. Experimental results on a public remote sensing data set (UC Merced) demonstrate an overall improvement of both accuracy and visual performance over several state-of-the-art algorithms.","1558-0571","","10.1109/LGRS.2017.2704122","National Natural Science Foundation of China(grant numbers:61671037); Beijing Natural Science Foundation(grant numbers:4152031); funding project of the State Key Laboratory of Virtual Reality Technology and Systems, Beihang University(grant numbers:BUAA-VR-16ZZ-03); Fundamental Research Funds for the Central Universities(grant numbers:YWF-16-BJ-J-30); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7937881","Convolutional neural networks (CNNs);local–global combined network (LGCNet);remote sensing images;super-resolution","Remote sensing;Spatial resolution;Training;Convolution;Image reconstruction","image processing;neural nets;remote sensing","remote sensing images;local-global combined network;image processing technology;high-resolution image;convolutional neural networks;single-image super-resolution algorithm","","138","","22","IEEE","1 Jun 2017","","","IEEE","IEEE Journals"
"Remote Sensing Image Super-Resolution Via Attentional Feature Aggregation Generative Adversarial Network","F. Cai; K. -Y. Wu; F. Wang","Key Laboratory for Information Science of Electromagnetic Waves (MoE), School of Information Science and Technology, Fudan University, Shanghai, China; Key Laboratory for Information Science of Electromagnetic Waves (MoE), School of Information Science and Technology, Fudan University, Shanghai, China; Key Laboratory for Information Science of Electromagnetic Waves (MoE), School of Information Science and Technology, Fudan University, Shanghai, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2598","2601","The extraction of high-frequency details is generally neglected in single image super-resolution (SISR) for remote sensing images. In this paper, we propose an attentional feature aggregation generative adversarial network (AFA-GAN) with the capability of strong feature extraction and attentional feature fusion to generate high-resolution remote sensing images. We adopt the residual feature aggregation framework for the feature extraction to make full use of the hierarchical features on the residual branches. To better fuse global and local features with inconsistent scales, an attentional feature fusion mechanism is utilized in residual feature aggregation modules. The comprehensive experiments with state-of-the-art SISR methods on the UC Merced dataset demonstrate the effectiveness and superiority of our AFA-GAN.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884863","National Natural Science Foundation of China(grant numbers:61901122); Natural Science Foundation of Shanghai(grant numbers:20ZR1406300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884863","Remote sensing images;single image super-resolution (SISR);attentional feature aggregation (AFA);generative adversarial network (GAN)","Visualization;Fuses;Superresolution;Feature extraction;Generative adversarial networks;Remote sensing;Image reconstruction","feature extraction;geophysical image processing;image fusion;image reconstruction;image resolution;remote sensing","high-resolution remote sensing images;residual feature aggregation framework;hierarchical features;global features;local features;attentional feature fusion mechanism;residual feature aggregation modules;AFA-GAN;remote sensing image super-resolution;high-frequency details;single image super-resolution;attentional feature aggregation generative adversarial network;strong feature extraction","","","","18","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Structure-Texture Parallel Embedding for Remote Sensing Image Super-Resolution","T. Lu; K. Zhao; Y. Wu; Z. Wang; Y. Zhang","Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology, Wuhan, China; Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology, Wuhan, China; Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, NERCMS, China; Computer School, Hubei University of Arts and Science, Xiangyang, China","IEEE Geoscience and Remote Sensing Letters","27 Sep 2022","2022","19","","1","5","The structure and texture of images are crucial for remote sensing image super-resolution (SR). Generative adversarial networks (GANs) recover image details through adversarial training. However, the recovered images always have structural distortions, on the one hand, and GANs are difficult to train, on the other hand. In addition, some methods assist reconstruction by introducing prior information of the image, but this brings additional computational cost. To address this issue, we propose a novel structure-texture parallel embedding (SPE) method for SR of remote sensing images. Our method does not require additional image priors to reconstruct high-quality images. Specifically, we use the global structure information and local texture information of the image in the ascending space to guide the reconstruction result of the image. First, we design a structure preserving block (SPB) to extract global structural features in the ascending space of the image, so as to obtain global structure information for a priori representation. Then, we design a local texture attention module (LTAM) to restore richer texture details. We have conducted lots of experiments on Draper public dataset. Experimental results show that our proposed method not only achieves a better tradeoff between computational cost and performance, but also outperforms the existing several SR methods in terms of objective index evaluation and subjective visual effects.","1558-0571","","10.1109/LGRS.2022.3206348","National Natural Science Foundation of China(grant numbers:62072350,62171328,U1903214,62071339,61771353); Hubei Technology Innovation Project(grant numbers:2019AAA045); Central Government Guides Local Science and Technology Development Special Projects(grant numbers:2018ZYYD059); High value Intellectual Property Cultivation Project of Hubei Province; Enterprise Technology Innovation Project of Wuhan(grant numbers:202001602011971); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9888134","Remote sensing image super-resolution (SR);structure preserving;texture attention mechanism","Feature extraction;Remote sensing;Image reconstruction;Training;Superresolution;Convolution;Satellites","feature extraction;geophysical image processing;image reconstruction;image resolution;image texture;neural nets;remote sensing","Draper public dataset;structure-texture parallel embedding method;local texture attention module;structure preserving block;local texture information;global structure information;high-quality images;structural distortions;recovered images;image details;generative adversarial networks;remote sensing image super-resolution","","","","21","IEEE","12 Sep 2022","","","IEEE","IEEE Journals"
"Remote sensing image super-resolution: Challenges and approaches","D. Yang; Z. Li; Y. Xia; Z. Chen","School of Remote Sensing and Information Engineering, Wuhan University, China; School of Remote Sensing and Information Engineering, Wuhan University, China; School of Remote Sensing and Information Engineering, Wuhan University, China; School of Remote Sensing and Information Engineering, Wuhan University, China","2015 IEEE International Conference on Digital Signal Processing (DSP)","10 Sep 2015","2015","","","196","200","Remote sensing has a growing relevance in the modern society with the development of image processing of satellite imagery. However, due to the limitations of the current imaging sensors and the complex atmospheric conditions, we are facing great challenges in the remote sensing applications due to the limited spatial, spectral, radiometric and temporal resolutions. Therefore, super-resolution techniques have attracted much attention by which the low quality low resolution remote sensing images are enhanced. In this paper, we discuss the challenges in remote sensing image super-resolution and thereafter review the relevant approaches. More specifically, the different categories of remote sensing techniques, i.e., the learning-based, interpolation based, frequency domain based, and probability based methods, are reviewed and discussed. Furthermore, the super-resolution applications are discussed and insightful comments on future research directions are provided.","2165-3577","978-1-4799-8058-1","10.1109/ICDSP.2015.7251858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7251858","Super resolution;remote sensing;observation model","Image reconstruction;Remote sensing;Interpolation;Spatial resolution;Signal resolution;Wavelet transforms","frequency-domain analysis;geophysical image processing;image resolution;interpolation;learning (artificial intelligence);probability;remote sensing","remote sensing image superresolution;image processing;satellite imagery;complex atmospheric conditions;learning based method;interpolation based method;frequency domain based method;probability based method","","20","","23","IEEE","10 Sep 2015","","","IEEE","IEEE Conferences"
"Remote Sensing Image Super-Resolution via Dilated Convolution Network with Gradient Prior","Z. Liu; R. Feng; L. Wang; Y. Zhong; L. Zhang; T. Zeng","School of Computer Science, China University of Geosciences, P. R. China; Department of Mathematics, Chinese University of Hong Kong; School of Computer Science, China University of Geosciences, P. R. China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, P. R. China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, P. R. China; Department of Mathematics, Chinese University of Hong Kong","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2402","2405","Due to the limitations of the imaging sensor, the spatial resolution of satellite imagery is often insufficient, namely, low resolution (LR). Therefore, super-resolution (SR) is proposed, which strives to improve image resolution, perfectly to compensate for the shortcomings of satellite sensor imaging. In this study, we develop a unique dilated convolution network with gradient prior (DCNG) for remote sensing SR, aiming to extract powerful low-level features with gradient prior and efficitive network and then reconstruct the high-level feature details. The DCNG is built of two components: the Multi-Scale Feature Extraction Network and the Feature Reconstruction Network. In the Multi-Scale Feature Extraction Network, the Double-Path Dilated Residual Block (DPDRB) is designed with the dilation convolution operation to obtain the multi-scale features and increase the receptive field, the Global Self-attention Module (GSA) to catch the long-range dependency among picture patches, and a Gradient Propagation Network (GPN) is proposed to extract high-level gradient information. In the Feature Reconstruction Network, the Pixel Shuffle is introduced to reconstruct the feature by combining characteristics of different frequency bands. Experiments using Massachusetts_Roads and 3K VEHICLE_SR data sets indicate that our DCNG surpasses state-of-the-art algorithms in terms of quantitative and qualitative evaluations.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883673","National Natural Science Foundation of China(grant numbers:U21A2013,41925007); Hubei University(grant numbers:2020(B)003); National Key R&D Program of China(grant numbers:2021YFE0203700,NSFC/RGC N_CUHK 415/19,14300219,14302920,14301121); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883673","Remote sensing super-resolution;attention;dilated convolution;gradient prior","Satellites;Convolution;Image edge detection;Superresolution;Imaging;Feature extraction;Data mining","feature extraction;geophysical image processing;geophysical techniques;gradient methods;image enhancement;image reconstruction;image resolution;image segmentation;image sensors;remote sensing","remote sensing image super-resolution;gradient prior;imaging sensor;spatial resolution;satellite imagery;image resolution;satellite sensor imaging;unique dilated convolution network;DCNG;remote sensing SR;low-level features;efficitive network;high-level feature details;MultiScale Feature Extraction Network;Feature Reconstruction Network;Double-Path Dilated Residual Block;dilation convolution operation;multiscale features;Gradient Propagation Network;high-level gradient information;temperature 3.0 K","","","","11","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"EML-GAN: Generative Adversarial Network-Based End-to-End Multi-Task Learning Architecture for Super-Resolution Reconstruction and Scene Classification of Low-Resolution Remote Sensing Imagery","W. Deng; Q. Zhu; X. Sun; W. Lin; Q. Guan","School of Geography and Information Engineering, China University of Geosciences, Wuhan, China; School of Geography and Information Engineering, China University of Geosciences, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan, China; School of Geography and Information Engineering, China University of Geosciences, Wuhan, China; School of Geography and Information Engineering, China University of Geosciences, Wuhan, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5397","5400","High spatial resolution remote sensing images (HSR-RSIs) are critical to providing fine land cover/land use information for scene classification. The global low spatial resolution remote sensing images (LSR-RSIs) can be easily obtained at present, whereas it is still a challenge to acquire large-scale HSR-RSIs. In this paper, an algorithmic-based architecture is proposed to improve the spatial resolution of RSIs beyond the limits of imaging sensors. The generative adversarial network-based end-to-end multi-task learning architecture (EML-GAN) is proposed for LSR-RSIs super-resolution reconstruction and scene classification simultaneously. In EML-GAN, the generator network is used to recover the fine geometric structures of LSR-RSIs by fusing the deep contextual, structure, and edge information. In addition, the discriminator network is designed to predict the scene label and distinguish the real/fake of the input data. The proposed architecture is evaluated on a public dataset and two self-made dataset. The experimental results show that the proposed architecture improves the visual effect and classification performance of LSR-RSIs.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554060","National Natural Science Foundation of China(grant numbers:41901306); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554060","Scene classification;remote sensing images;generative adversarial network;super-resolution reconstruction","Image analysis;Image edge detection;Superresolution;Feature extraction;Visual effects;Generators;Sensors","geophysical image processing;image classification;image reconstruction;image resolution;image sensors;learning (artificial intelligence);remote sensing","EML-GAN;generative adversarial network-based end-to-end multitask learning architecture;scene classification;low-resolution remote sensing imagery;high spatial resolution remote sensing images;global low spatial resolution remote sensing images;large-scale HSR-RSIs;LSR-RSIs super-resolution reconstruction","","","","13","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Geosr: A Computer Vision Package for Deep Learning Based Single-Frame Remote Sensing Imagery Super-Resolution","Z. Guo; G. Wu; X. Shi; M. Sui; X. Song; Y. Xu; X. Shao; R. Shibasaki","Center for Spatial Information Science, the University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, the University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, the University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, the University of Tokyo, Kashiwa, Japan; School of Architecture, Harbin Institute of Technology, Harbin, China; Center for Spatial Information Science, the University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, the University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, the University of Tokyo, Kashiwa, Japan","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3376","3379","Recently, owing to the outstanding capability of deep learning in solving ill-posed problems, the single-frame super-resolution (SR) researches tend to focus on deep learning methods largely. However, related researches are implemented and evaluated through various datasets and different deep learning frameworks, which hinders the comparison of performance among different methods and heavily hampers the progress of SR techniques. In this study, we present GeoSR, an open source computer vision package for deep learning based single-frame remote sensing imagery super-resolution to facilitate the development of the SR community. As a unified, simple, and flexible package, GeoSR contains pipeline-like integrated tools from data retrieval to final result evaluation, which enables users to develop self-defined models conveniently; several state-of-the-art models trained through the same high-quality dataset are provided as the baseline in the package as well. Moreover, the proposed package could potentially serve as a viable backend for other related packages such as image segmentation with high efficiency.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900416","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900416","Super-resolution;deep learning;computer vision;remote sensing;open source","Deep learning;Remote sensing;Computer vision;Tools;Training","computer vision;geophysical image processing;image reconstruction;image resolution;image segmentation;learning (artificial intelligence);public domain software;remote sensing","geosr;single-frame remote sensing imagery super-resolution;single-frame super-resolution researches;deep learning methods;deep learning frameworks;open source computer vision package","","","","10","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Simultaneous Super-Resolution and Segmentation for Remote Sensing Images","S. Lei; Z. Shi; X. Wu; B. Pan; X. Xu; H. Hao","Image Processing Center, Beihang University, Beijing, China; Image Processing Center, Beihang University, Beijing, China; Image Processing Center, Beihang University, Beijing, China; Image Processing Center, Beihang University, Beijing, China; Image Processing Center, Beihang University, Beijing, China; The Flight Technology College, Civil Aviation University of China, Tianjin, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3121","3124","In this paper, we present an algorithm to simultaneously obtain high-resolution images and segmentation maps from low-resolution inputs. Super-resolution and segmentation both are challenging task, but they may have certain relationship. Super-resolution will provide images with more details that may help to improve the segmentation accuracy, while label maps in segmentation dataset may contribute to finer edges during super-resolution process. Therefore, we aim to combine these two tasks and explore the influence for each other. For this end, we proposed a new deep neural network to simultaneously address the super-resolution and segmentation tasks for remote sensing images, which is named S2Net. The S2Net is an integrated network composed of a super-resolution sub-network and a segmentation sub-network, which is trained in an end-to-end manner. Experimental results demonstrate that this combination can enhance the performance on these two tasks.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900402","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900402","Remote sensing images;Super-resolution;Segmentation;S2Net","Image segmentation;Remote sensing;Task analysis;Training;Airplanes","geophysical image processing;image resolution;image segmentation;neural nets;remote sensing","remote sensing images;high-resolution images;segmentation maps;low-resolution inputs;segmentation accuracy;segmentation dataset;super-resolution process;segmentation tasks;segmentation sub-network;deep neural network;S2Net","","13","","11","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Super-Resolution of Remote Sensing Images based on a Deep Plug-and-Play Framework","H. Tao","School of Software Sichuan University, Chengdu, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","625","628","Single image super-resolution (SISR) based on deep neural network (DNN) has been widely studied in recent years as a crucial technique for remote sensing (RS) applications. However, owing to the complexity and diversity of ground objects, there remains fundamental challenges to reconstruct a high-resolution (HS) RS image from a low-resolution (LR) RS image, especially with blur. In this paper, I propose a deep plug-and-play residual network, namely DPSRResNet, which can reconstruct high-quality HR RS images from LR SR images with Gaussian blur kernels via a deep plug-and-play framework. Specifically, a degradation model from the DPSR framework is given to utilize matured deblurring methods. Moreover, I adopt a deep plug-and-play algorithm to optimize the energy function, which allows plugging any super-resolver with a prior term. The proposed DPSRResNet is used as the crucial super-resolver for the framework, and a series of experimental results are presented to demonstrate the effectiveness of the proposed method on RS images.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324647","Single image super-resolution;remote sensing image;plug-and-play;residual network","Superresolution;Image resolution;Image reconstruction;Degradation;Kernel;Remote sensing;Energy resolution","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image reconstruction;image resolution;image restoration;remote sensing","remote sensing images;single image super-resolution;deep neural network;remote sensing applications;high-resolution RS image;low-resolution RS image;RS images;LR SR images;Gaussian blur kernels;DPSR framework;crucial super-resolver;deep plug-and-play framework","","1","","12","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Super Resolution for Remote Sensing Images via Improved Residual Network","H. Xie; H. Jiang; X. Liu; G. Li; H. Yang","Department of Aerospace Information, Space Engineering University, Beijing, China; Department of Aerospace Information, Space Engineering University, Beijing, China; Department of Aerospace Information, Space Engineering University, Beijing, China; Department of Aerospace Information, Space Engineering University, Beijing, China; Department of Aerospace Information, Space Engineering University, Beijing, China","2020 5th International Conference on Mechanical, Control and Computer Engineering (ICMCCE)","13 May 2021","2020","","","2295","2298","According to the processing characteristics of remote sensing image super-resolution, this paper studies a super resolution method based on improved residual network. First, we optimize the structure of the residual block to meet the needs of super-resolution tasks; then, we further deepen the network level, so that the network has a stronger learning ability. The reconstruction results on the remote sensing images dataset show that the improved residual network achieves better visual effect, and the objective evaluation index is significantly improved, which proves the effectiveness of the proposed method.","","978-1-6654-2314-4","10.1109/ICMCCE51767.2020.00496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9421814","component;super resolution;remote sensing;residual networks","Superresolution;Visual effects;Sensors;Indexes;Task analysis;Remote sensing;Image reconstruction","image reconstruction;image resolution;learning (artificial intelligence);remote sensing","remote sensing images;improved residual network;remote sensing image super-resolution;super resolution method;residual block;super-resolution tasks;network level","","","","6","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"Robust Super-Resolution Image Reconstruction Method for Geometrically Deformed Remote Sensing Images","J. Qin; I. Yanovsky","Department of Mathematical Sciences, Montana State University, Bozeman, MT; University of California Los Angeles, Joint Institute for Regional Earth System Science and Engineering, Los Angeles, CA","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","8050","8053","Due to the limitations of imaging sensors, remote sensing images often have limited resolution. To address this issue, various super-resolution (SR) image reconstruction techniques have been developed to reconstruct a high-resolution image from a sequence of low-resolution, noisy and blurry observations. In this paper, we propose an efficient super-resolution image reconstruction method for geometrically deformed remote sensing images, based on the nonlocal total variation (NLTV) regularization. The proposed minimization problem is solved by a fast primal-dual algorithm. Numerical experiments demonstrate the performance of the proposed method.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518056","Remote sensing images;super-resolution image reconstruction;primal-dual algorithm","Image reconstruction;Remote sensing;Spatial resolution;Sensors;Microsoft Windows;Computational efficiency","image reconstruction;image resolution;image sensors;minimisation;remote sensing","imaging sensors;super-resolution image reconstruction techniques;high-resolution image;blurry observations;remote sensing images;nonlocal total variation regularization;minimization problem;primal-dual algorithm;NLTV","","5","","14","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Generative Adversarial Network with Residual Dense Generator for Remote Sensing Image Super Resolution","R. Sustika; A. B. Suksmono; D. Danudirdjo; K. Wikantika","Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung (ITB), Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung (ITB), Bandung, Indonesia; Faculty of Earth Sciences and Technology, Institut Teknologi Bandung (ITB), Bandung, Indonesia","2020 International Conference on Radar, Antenna, Microwave, Electronics, and Telecommunications (ICRAMET)","25 Dec 2020","2020","","","34","39","Improving image resolution, especially spatial resolution, has been one of the most important concerns on remote sensing research communities. An efficient solution for improving spatial resolution is by using algorithm, known as super-resolution (SR). The super-resolution technique that received special attention recently is super-resolution based on deep learning. In this paper, we propose deep learning approach based on generative adversarial network (GAN) for remote sensing images super resolution. We used residual dense network (RDN) as generator network. Generally, deep learning with residual dense network (RDN) gives high performance on classical (objective) evaluation metrics meanwhile generative adversarial network (GAN) based approach shows a high perceptual quality. Experiment results show that combination of residual dense network generator with generative adversarial network training is found to be effective. Our proposed method outperforms the baseline method in terms of objective and perceptual quality evaluation metrics.","","978-1-7281-8922-2","10.1109/ICRAMET51080.2020.9298648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298648","convolutional neural network;generative adversarial network;remote sensing;image;residual dense network;super-resolution","Training;Spatial resolution;Remote sensing;Generators;Generative adversarial networks;PSNR;Measurement","image reconstruction;image resolution;learning (artificial intelligence);remote sensing","generative adversarial network training;residual dense generator;remote sensing image super resolution;image resolution;spatial resolution;remote sensing research communities;super-resolution technique;deep learning approach;remote sensing images super resolution;generator network;residual dense network generator","","2","","15","IEEE","25 Dec 2020","","","IEEE","IEEE Conferences"
"Dynamic Multi-Scale Network for Remote Sensing Image Super-Resolution","P. Yao; P. He; S. Cheng; L. Fu; Z. Guo; J. Zhao","Institute of Computing Technology, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; Beijing University of Civil Engineering and Architecture; Beijing University of Civil Engineering and Architecture","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","3766","3769","Although single image super-resolution(SISR) method with deep neural network has already been explored in depth in natural images, further research on SISR in remote sensing image is still desired as aerial imagery has distinctive characteristics such as varied scenes across wide areas. In this paper, considering the scarcity of remote sensing images that may restrict the performance of data-driven neural network, we first propose a new data augmentation method, RotBlur, to promote sample diversity dramatically with a rotated cropped block at random angle. And we also design a Dynamic Multi-Scale Network(DMSN) to enhance details of low-resolution(LR) remote sensing images adaptively according to current scene of various images. Experiments performed on the UC Merced Land-Use dataset demonstrate that our DMSN outperforms several state-of-the-art methods in terms of PSNR of reconstructed images.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883063","Chinese Academy of Sciences(grant numbers:XDA19020400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883063","Remote Sensing;Super-Resolution;Rot-Blur;Dynamic Multi-Scale Network","Deep learning;Adaptation models;Superresolution;Neural networks;Refining;Data models;Remote sensing","crops;geophysical image processing;image reconstruction;image resolution;neural nets;remote sensing","data augmentation method;reconstructed images;remote sensing image super-resolution;deep neural network;natural images;data-driven neural network","","","","16","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Small Object Detection from Remote Sensing Images with the Help of Object-Focused Super-Resolution Using Wasserstein GANs","L. Courtrai; M. -T. Pham; C. Friguet; S. Lefèvre","Univ. Bretagne Sud - IRISA, France; Univ. Bretagne Sud - IRISA, France; Univ. Bretagne Sud - IRISA, France; Univ. Bretagne Sud - IRISA, France","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","260","263","In this paper, we investigate and improve the use of a super-resolution approach to benefit the detection of small objects from aerial and satellite remote sensing images. The main idea is to focus the super-resolution on target objects within the training phase. Such a technique requires a reduced number of network layers depending on the desired scale factor and the reduced size of the target objects. The learning of our super-resolution network is performed using deep residual blocks integrated in a Wasserstein Generative adversarial network. Then, detection task is performed by exploiting two state-of-the-art detectors including Faster-RCNN and YOLOv3. Experiments were conducted on small vehicle detection from both aerial and satellite images from the VEDAI and xView data sets. Results showed that object-focused super-resolution improves the detection performance and facilitates the transfer learning from one data set to another.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323236","Small object detection;deep learning;super-resolution;Wasserstein GANs;remote sensing imagery","Superresolution;Detectors;Spatial resolution;Satellites;Task analysis;Object detection;Gallium nitride","geophysical image processing;image resolution;learning (artificial intelligence);object detection;remote sensing","aerial images;satellite images;object-focused super-resolution;detection performance;object detection;super-resolution approach;aerial sensing images;satellite remote sensing images;target objects;super-resolution network;Wasserstein Generative adversarial network;vehicle detection","","4","","12","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Dual-Resolution Local Attention Unfolding Network for Optical Remote Sensing Image Super-Resolution","M. Shi; Y. Gao; L. Chen; X. Liu","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Geoscience and Remote Sensing Letters","16 Dec 2022","2022","19","","1","5","Single-image super-resolution (SR) technology based on deep learning is widely applied in remote sensing. In recent years, the deep unfolding SR strategy has been proposed, which combines the neural networks with the traditional optimization-based algorithms, making the neural networks interpretable and achieving high performance. However, the typical deep unfolding algorithms usually treat different kinds of blurring kernels in the same way, so the algorithms cannot take advantage of the properties of blurring kernels, limiting the algorithm’s performance. To design an SR network that can fully use the properties of the Gaussian blurring kernels, a dual-resolution local attention unfolding network (DLANet) is proposed. Based on the Gaussian blurring functions, a low-resolution (LR) space branch is designed to supplement the high-resolution (HR) space branch. Specifically, for the Gaussian blurring kernels, the closer the pixel is to the center, the greater the weight is. It means that the pixel points retained after downsampling will contain more information about the original corresponding pixel points, and it could be easier to estimate their original pixel values. So we design two branches. The HR branch completes the estimation of the whole image, and the LR branch only estimates the points retained after downsampling. To better complete the feature fusion of the two branches, we propose a row–column decoupling local attention module. This module can retain more information when fuse features and the row–column decoupling strategy can reduce the computational complexity. Comprehensive experiments demonstrate the superiority of our method over the current state-of-the-art on remote sensing datasets.","1558-0571","","10.1109/LGRS.2022.3224041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9959886","Dual-resolution;Gaussian blurring kernels;local attention;super-resolution (SR);unfolding","Kernel;Image reconstruction;Superresolution;Neural networks;Feature extraction;Remote sensing;Degradation","feature extraction;image classification;image matching;image resolution;image restoration;learning (artificial intelligence);remote sensing","achieving high performance;algorithm;deep learning;deep unfolding SR strategy;dual-resolution local attention unfolding network;Gaussian blurring functions;Gaussian blurring kernels;high-resolution space branch;local attention module;low-resolution space branch;neural networks interpretable;optical remote sensing image super-resolution;original corresponding pixel points;remote sensing datasets;single-image super-resolution technology;SR network;traditional optimization-based algorithms","","","","13","IEEE","23 Nov 2022","","","IEEE","IEEE Journals"
"GCD Based Blind Super-Resolution for Remote Sensing Applications","N. Sharma; P. P. Dash; P. Saxena","Dept. of Elecntronics and Communication Engg, Birla Institute of Technology, Mesra, Ranchi, India; Dept. of Elecntronics and Communication Engg, Birla Institute of Technology, Mesra, Ranchi, India; Dept. of Elecntronics and Communication Engg, Birla Institute of Technology, Mesra, Ranchi, India","2018 2nd International Conference on Power, Energy and Environment: Towards Smart Technology (ICEPE)","7 Mar 2019","2018","","","1","6","The importance of remote sensing imageries is growing day by day. Extraction of fine details of desired regions worth for further processing and decision making. Usually the data bases of remote sensing imageries are very huge that overburden the processor. Super-Resolution overcomes this problem and yields a high-quality output in less time consumption. This paper aims to give a brief idea about one of the approaches of super-resolution known as blind super-resolution reconstruction approach. In this approach, Greatest Common Divisor (GCD) algorithm is embedded into the blind reconstruction technique. The HR images obtained from this method is compared with the interpolated images. The results shows the efficacy of the proposed method. The paper tries to overcome the limitations of the super resolution approach and a conclusive discussion of the whole method has been discussed.","","978-1-5386-4769-1","10.1109/EPETSG.2018.8658528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658528","Remote sensing;Satellite image;Super resolution;GCD;Blind reconstruction","Image resolution;Image reconstruction;Satellites;Mathematical model;Signal to noise ratio;Remote sensing;Signal resolution","decision making;geophysical image processing;image reconstruction;image resolution;interpolation;remote sensing","super resolution approach;blind reconstruction technique;Greatest Common Divisor algorithm;blind super-resolution reconstruction approach;remote sensing imageries;remote sensing applications;GCD based blind super-resolution","","","","9","IEEE","7 Mar 2019","","","IEEE","IEEE Conferences"
"Narrow Road Extraction from Remote Sensing Images Based on Super-Resolution Convolutional Neural Network","X. Zhou; X. Chen; Y. Zhang","School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Geographic Sciences, East China Normal University, Shanghai, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","685","688","In remote sensing images, it is usually hard to extract narrow roads with only several pixels width. To address this problem, the original remote sensing images are processed with super-resolution to enlarge the details of the narrow roads by a convolutional neural network method. Then the One-Class Support Vector Machine (OCSVM) classifier is applied after super-resolution for exact extraction of narrow roads. Experiments are conducted on an open dataset of remote sensing images to verify the performance of the new method and the results are compared with the method without image super-resolution. The experimental results demonstrate the validity and superiority of the new method.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517851","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517851","convolutional neural network;super-resolution;narrow road extraction","Roads;Remote sensing;Spatial resolution;Signal resolution;Data mining;Convolutional neural networks","convolution;feature extraction;feedforward neural nets;geographic information systems;geophysical image processing;image classification;image resolution;remote sensing;roads;support vector machines","narrow road extraction;super-resolution convolutional neural network;One-Class Support Vector Machine classifier;image super-resolution;remote sensing images;convolutional neural network","","","","8","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"ESPC_NASUnet: An End-to-End Super-Resolution Semantic Segmentation Network for Mapping Buildings From Remote Sensing Images","P. Xu; H. Tang; J. Ge; L. Feng","Beijing Key Laboratory for Remote Sensing of Environment, and Digital Cities, Faculty of Geographical Science, Beijing Normal University, Beijing, China; Beijing Key Laboratory for Remote Sensing of Environment, and Digital Cities, Faculty of Geographical Science, Beijing Normal University, Beijing, China; Beijing Key Laboratory for Remote Sensing of Environment, and Digital Cities, Faculty of Geographical Science, Beijing Normal University, Beijing, China; Beijing Key Laboratory for Remote Sensing of Environment, and Digital Cities, Faculty of Geographical Science, Beijing Normal University, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15 Jun 2021","2021","14","","5421","5435","Higher resolution building mapping from lower resolution remote sensing images is in great demand due to the lack of higher resolution data access, especially in the context of disaster assessment. High resolution building layout map is crucial for emergency rescue after the disaster. The emergency response time would be reduced if detailed building footprints were delineated from more easily available low-resolution data. To achieve this goal, we propose a super-resolution semantic segmentation network called ESPC_NASUnet, which consists of a feature super-resolution module and a semantic segmentation module. To the best of authors' knowledge, this is the first work to systematically explore a deep learning-based approach to generate semantic maps with higher spatial resolution from lower spatial resolution remote sensing images in an end-to-end fashion. The experimental results for two datasets suggest that the proposed network is the best among four different end-to-end architectures in terms of both pixel-level metrics and object-level metrics. In terms of pixel-level F1-score, the improvements are greater than 0.068 and 0.055. Regarding the object-level F1-score, the disparities between ESPC_NASUnet and other end-to-end methods are more than 0.083 and 0.161 in the two datasets, respectively. Compared with stage-wise methods, our end-to-end network is less impacted by low-resolution input images. Finally, the proposed network produces building semantic maps comparable to those generated by semantic segmentation networks trained with high-resolution images and the ground truth utilizing the two datasets.","2151-1535","","10.1109/JSTARS.2021.3079459","National Natural Science Foundation of China(grant numbers:41971280); National Key Research and Development Program of China Stem Cell and Translational Research(grant numbers:2017YFB0504104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9429949","Building extraction;end-to-end network;remote sensing;super-resolution semantic segmentation (SRSS)","Buildings;Semantics;Remote sensing;Spatial resolution;Image segmentation;Convolution;Superresolution","buildings (structures);cartography;deep learning (artificial intelligence);disasters;emergency services;geophysical image processing;image resolution;image segmentation;remote sensing","ESPC_NASUnet;end-to-end super-resolution semantic segmentation network;higher resolution building mapping;higher resolution data access;emergency response time;feature super-resolution module;semantic segmentation module;lower spatial resolution remote sensing images;pixel-level F1-score;object-level F1-score;end-to-end network;semantic segmentation networks;deep learning","","6","","44","CCBY","12 May 2021","","","IEEE","IEEE Journals"
"Enhanced Super-Resolution Mapping of Urban Floods Based on the Fusion of Support Vector Machine and General Regression Neural Network","L. Li; Y. Chen; T. Xu; K. Shi; C. Huang; R. Liu; B. Lu; L. Meng","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; CSIRO Land and Water, Canberra, ACT, Australia; Fenner School of Environment and Society, The Australian National University, Canberra, ACT, Australia; Chongqing Engineering Research Center for Remote Sensing Big Data Application, School of Geographical Sciences, Southwest University, Chongqing, China; College of Urban and Environmental Sciences, Northwest University, Xi’an, China; Beijing Laboratory of Water Resource Security, Capital Normal University, Beijing, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","22 Jul 2019","2019","16","8","1269","1273","Super-resolution mapping of urban flood (SMUF) is one of the hotspots in remote sensing and urban environment research. In this letter, a new SMUF method based on the fusion of support vector machine and general regression neural network (FSVMGRNN) was proposed to achieve enhanced performance. An SVM-SMUF algorithm was developed and a fusion criterion was formulated. Then, the FSVMGRNN-SMUF algorithm was developed. The results of FSVMGRNN-SMUF were evaluated using Landsat 8 OLI imagery of two representative cities in China. FSVMGRNN-SMUF yielded the most accurate SMUF results among the five SMUF methods according to visual comparisons and quantitative comparisons. The mapping accuracy of FSVMGRNN-SMUF related to the kernel functions was also analyzed and discussed. The results of this letter will help to boost practical applications of median-low resolution remote sensing images in urban flooding mapping, and to strengthen the means for monitoring and assessing urban flooding disasters.","1558-0571","","10.1109/LGRS.2019.2894350","National Basic Research Program of China (973 Program)(grant numbers:2018YFC0407804); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8636408","Fusion algorithm;general regression neural network (GRNN);super-resolution mapping;support vector machine (SVM);urban floods","Support vector machines;Urban areas;Remote sensing;Kernel;Image resolution;Artificial satellites;Earth","disasters;floods;geophysical image processing;hydrological techniques;image resolution;neural nets;regression analysis;remote sensing;support vector machines","enhanced super-resolution mapping;urban flood;support vector machine;general regression neural network;urban environment research;SMUF method;SVM-SMUF algorithm;fusion criterion;FSVMGRNN-SMUF algorithm;accurate SMUF results;mapping accuracy;median-low resolution remote sensing images;urban flooding mapping;urban flooding disasters;Landsat 8 OLI imagery","","5","","21","IEEE","6 Feb 2019","","","IEEE","IEEE Journals"
"Blind Super-Resolution Network for Remote Sensing Image","N. Zhang; Y. Wang; X. Wang","State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China; State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China; Academy of Broadcasting Science, National Radio and Television Administration, Beijing, China","2021 IEEE 5th Information Technology,Networking,Electronic and Automation Control Conference (ITNEC)","4 Nov 2021","2021","5","","424","428","In the past few years, image super-resolution has achieved remarkable progress, but due to the texture particularity of remote sensing images, the performance in remote sensing images are not very good. We consider that the texture of the same object in remote sensing image is highly similar, so that relevant textures can be transferred from the high resolution remote sensing image to the low resolution remote sensing image. In this paper, we propose a novel super-resolution network for remote sensing image. Specifically, we take a low resolution image and a reference high resolution image as the inputs, then utilize transformer structure to learn the texture transfer which allows the model to enhance the texture details of the low resolution image, to generate the super-resolution image. Experiments on public datasets show that our method achieves visual improvements.","2693-3128","978-1-6654-1599-6","10.1109/ITNEC52019.2021.9587196","National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9587196","super-resolution;remote sensing image;texture transfer;transformer structure","Visualization;Automation;Conferences;Superresolution;Transformers;Sensors;Remote sensing","geophysical image processing;image enhancement;image resolution;image texture;remote sensing","high resolution remote;low resolution remote sensing image;reference high resolution image;super-resolution image;blind super-resolution network;visual improvements","","","","19","IEEE","4 Nov 2021","","","IEEE","IEEE Conferences"
"A Super-resolution Method of Remote Sensing Image Using Transformers","C. Ye; L. Yan; Y. Zhang; J. Zhan; J. Yang; J. Wang","School of Computer, Hubei University of Technology, China; School of Computer, Hubei University of Technology, China; School of Computer, Hubei University of Technology, China; Wuhan Fiberhome Technical Services Co., Ltd., Wuhan, Hubei, China; Wuhan Fiberhome Technical Services Co., Ltd., Wuhan, Hubei, China; Wuhan Fiberhome Technical Services Co., Ltd., Wuhan, Hubei, China","2021 11th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)","5 Jan 2022","2021","2","","905","910","This paper proposes a Transformers-based super-resolution method for remote sensing images. Firstly, a remote sensing image super-resolution network based on convolutional neural network and Transformer module is constructed; then the training data is used to train the remote sensing image super-resolution network and the optimized network parameters are obtained; finally, the trained remote sensing image super-resolution network is used to super-resolve low-resolution remote sensing images to obtain high-resolution remote sensing images. Experiments are conducted on the public remote sensing dataset (UC Mercedes) and compared with several traditional super-resolution algorithms. The results show that the present algorithm is highly automated and has improved in both accuracy and efficiency.","2770-4254","978-1-6654-2605-3","10.1109/IDAACS53288.2021.9660904","National Natural Science Foundation of China(grant numbers:61772180); Natural Science Foundation of Hubei Province(grant numbers:2020CFB798); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9660904","Super-resolution;Remote Sensing Image;Transformers;Convolutional Neural Networks(CNNs)","Visualization;Correlation;Superresolution;Stacking;Data acquisition;Training data;Transformers","geophysical image processing;image resolution;neural nets;remote sensing","trained remote sensing image super-resolution network;low-resolution remote sensing images;high-resolution remote sensing images;public remote sensing dataset;super-resolution algorithms;Transformers-based super-resolution method","","1","","16","IEEE","5 Jan 2022","","","IEEE","IEEE Conferences"
"Transfering Super Resolution Convolutional Neural Network For Remote Sensing Data Sharpening","M. Iftene; M. E. A. Arabi; M. S. Karoui","Agence Spatiale Algérienne, Centre des Techniques Spatiales, Algeria; Agence Spatiale Algérienne, Centre des Techniques Spatiales, Algeria; Agence Spatiale Algérienne, Centre des Techniques Spatiales, Algeria","2018 9th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","27 Jun 2019","2018","","","1","4","Pansharpening process aims at fusing low-spatial/high-spectral resolutions multispectral/hyperspectral (MS/HS) remote sensing data with high-spatial resolution and without spectral diversity panchromatic (PAN) ones. This paper explores different data preparation possibilities, learning strategies and architectures, used in the convolutional neural network (CNN) approaches, for improving the performance of the pansharpening process of remote sensing MS/HS data. Also, in this paper, the super resolution CNN (SRCNN) architecture is adapted by adding a normalization step in the training phase of the CNN-based pansharpening process. Then, training datasets are prepared for fitting the generalization need. Experiments based on multi-source datasets are performed to evaluate the performance of the proposed SRCNN-based pansharpening architecture. The preliminary results are promising since they show that the proposed approach is competitive with some literature methods.","2158-6276","978-1-7281-1581-8","10.1109/WHISPERS.2018.8747223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8747223","Multispectral/Hyperspectral imaging;pansharpening;fusion;deep learning;convolutional neural networks;super-resolution","Remote sensing;Conferences;Indexes;Biological neural networks;Machine learning","geophysical image processing;hyperspectral imaging;image fusion;image resolution;learning (artificial intelligence);neural nets;remote sensing","high-spatial resolution;pansharpening process;remote sensing MS/HS data;super resolution CNN architecture;CNN-based;super resolution convolutional neural network;remote sensing data sharpening;data preparation possibilities;spectral diversity panchromatic;SRCNN-based pansharpening architecture","","1","","12","IEEE","27 Jun 2019","","","IEEE","IEEE Conferences"
"Single Frame Super Resolution with Convolutional Neural Network for Remote Sensing Imagery","J. Fu; Y. Liu; F. Li","Lanzhou Jiaotong University, LanZhou, China; Lanzhou Jiaotong University, LanZhou, China; Qian Xuesen Laboratory of Space Technology, Beijing, China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","8014","8017","In this paper, a new convolutional neural networks based super resolution(SR) is proposed. SR has been a hot research area for decades, and it includes two types: single frame based SR and multi-frame based SR. The focus of the paper is to reconstruct the corresponding high resolution image from a given low resolution image. The popular end-to-end learning architecture is improved and no preprocessing and image aggregation are needed. Our network model(RSCNN) uses different convolution kernels for a set of feature maps in the feature mapping step, which ensures the accuracy of reconstruction results under the premise of improving the reconstruction quality. The method is applied to Jilin-l which is the first self-developed commercial remote sensing satellite group in China. The results show the superiority of our method both visually and numerically by comparing with other excellent image super resolution algorithms.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518584","Single image super resolution;Convolutional Neural Network;Jinlin-l satellite","Image resolution;Remote sensing;Image reconstruction;Convolution;Feature extraction;Convolutional neural networks","convolution;feedforward neural nets;geophysical image processing;image reconstruction;image resolution;remote sensing","convolutional neural network;image aggregation;feature maps;reconstruction quality;single frame super resolution;remote sensing imagery;image super resolution;Jilin-l;remote sensing satellite group;RSCNN;China","","5","","23","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Research on Super-resolution Reconstruction Algorithm of Remote Sensing Image Based on Generative Adversarial Networks","J. Wenjie; L. Xiaoshu","School of Electronic Engineering, Guangxi Normal University, Guilin, China; School of Electronic Engineering, Guangxi Normal University, Guilin, China","2019 IEEE 2nd International Conference on Automation, Electronics and Electrical Engineering (AUTEEE)","12 Mar 2020","2019","","","438","441","Due to natural conditions and hardware manufacturing processes, the resolution of remote sensing images is generally low. Obtaining high-definition remote sensing images by simply improving hardware and manufacturing processes is not only costly and technically challenging but also cannot be deployed on a large scale. Aiming at the limitations of the traditional methods, this paper studies the image super-resolution reconstruction method for improving the generated anti-network. Firstly, the generator network is optimized, and an RRDB (Residual-in-Residual Dense without BN (Batch Normalization) is used. Block) module; secondly, the related idea of relativistic GAN (relativistic generative adversarial network) is introduced, the relative value of the discriminator is not the absolute value; finally, the sensation loss is improved, and the feature is used before the function is activated. The test results show that the proposed algorithm is better than SRGAN (Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network), SRCNN (Super-Resolution Convolutional Neural Network) and FSRCNN (Fast Super-Resolution Convolutional Neural Network). The clarity of the reconstructed image is improved, and the reconstructed image quality is significantly improved.","","978-1-7281-5030-7","10.1109/AUTEEE48671.2019.9033352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9033352","Aerial image;Super-resolution;Generative Adversarial Networks","Image reconstruction;Image resolution;Generators;Remote sensing;Gallium nitride;Generative adversarial networks;Reconstruction algorithms","geophysical image processing;image reconstruction;image resolution;neural nets;remote sensing","generator network;generated anti-network;image super-resolution reconstruction method;high-definition remote sensing images;hardware manufacturing processes;natural conditions;Generative Adversarial networks;remote sensing Image;Super-resolution reconstruction algorithm;reconstructed image quality;Fast Super-Resolution Convolutional;Super-Resolution Convolutional Neural Network;Photo-Realistic Single Image Super-Resolution;relativistic generative adversarial network","","","","19","IEEE","12 Mar 2020","","","IEEE","IEEE Conferences"
"Self-Attention Fusion Module for Single Remote Sensing Image Super-Resolution","H. Mei; H. Zhang; Z. Jiang","Key Laboratory of Spacecraft Design Optimization and Dynamic Simulation Technologies, Ministry of Education, Beijing, China; Department of Aerospace Information Engineering, School of Astronautics, Beihang University, Beijing, China; Department of Aerospace Information Engineering, School of Astronautics, Beihang University, Beijing, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2883","2886","Single image super-resolution (SISR) is an important procedure to improve many remote sensing applications. Global features play an important role in pixel generation of SISR. In this paper, we proposed a self-attention fusion module named as SAF module which combines spatial attention and channel attention in parallel to handle this problem. Our self-attention fusion module can be flexibly added to many popular deep-learning-based SISR models to further improve their representation ability and learn global features. Experiments on UC Merced dataset indicate that SAF module can improve the performance of classic SISR models and achieve state-of-the-art super-resolution results.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553766","National Key Research and Development Program of China(grant numbers:2019YFC1510905); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553766","super-resolution;spatial attention;channel attention;remote sensing images","Measurement;Image quality;Superresolution;Visual effects;Sensors;Task analysis;Spatial resolution","deep learning (artificial intelligence);geophysical image processing;image resolution;remote sensing","self-attention fusion module;single remote sensing image super-resolution;important procedure;remote sensing applications;global features;SAF module;spatial attention;channel attention;classic SISR models;state-of-the-art super-resolution results","","2","","11","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A Scale-Adaptive Super-Resolution Algorithm for Single Remote Sensing Image","W. Zhang; Z. Li; S. Chen; Y. Wang; H. Li","Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Army Logistics University, Chongqing, China; College of Resources and Environment, University of Chinese Academy of Sciences, Beijing, China; School of Earth Science and Resources, Chang'an University, Xi'an, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","4110","4113","Single image super-resolution (SISR) algorithm is to recover a high-resolution image from a single low-resolution one and has been widely applied in remote sensing (RS) reconstruction. Numerous SISR models have been proposed for RS ap-plications. However, most existing methods suffer from an inability to reconstruct multi-scale RS images using one fixed pre-trained model. Here, we design a scale-adaptive SISR algorithm for RS images. The main contributions are three-fold: (1) to be applied for the multi-scale reconstruction, we first employ the bicubic interpolation to stretch the images before import so that our convolutional neural network can focus on refining the details of reconstruction images; (2) to extract the deep information of ground surface from RS images, we design multi-scale residual network to recover the image details; (3) we adopt the least-absolute-error loss to constraint our network for reconstructing the RS images. It is demonstrated that our model achieves excellent performance for super-resolution of RS images.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883637","Remote sensing images;super-resolution;convolutional neural network","Interpolation;Surface reconstruction;Superresolution;Refining;Neural networks;Data mining;Convolutional neural networks","geophysical image processing;image reconstruction;image resolution;interpolation;neural nets;remote sensing","scale-adaptive super-resolution algorithm;single remote sensing image;single image super-resolution algorithm;high-resolution image;remote sensing reconstruction;numerous SISR models;RS ap-plications;multiscale RS images;scale-adaptive SISR algorithm;multiscale reconstruction;reconstruction images;design multiscale residual network;image details","","","","20","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Single Image Super-Resolution with Application to Remote-Sensing Image","F. Deeba; F. A. Dharejo; Y. Zhou; A. Ghaffar; M. H. Memon; S. Kun","Institute of Computer Network Information, Center Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Institute of Computer Network Information, Center Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Institute of Computer Network Information, Center Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of sciences, Bejing, China; The Pakistan Council of Scientific and Industrial Research Laboratories Complex, Karachi, Pakistan; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China","2020 Global Conference on Wireless and Optical Technologies (GCWOT)","7 Apr 2021","2020","","","1","6","To improve the resolution of satellite images, many researchers are committed to machine learning and neural network-based SR methods. SR has multiple residual network frameworks in deep learning that have improved performance and can extend thousands of layers in the system. However, each layer improves accuracy by doubling the number of layers, although training thousands of layers are too expensive, the process is slow, and there are functional recovery issues. To address these issues, we propose a super-resolution wide remote sensing residual network (WRSR), in which we increase the width and reduce the depth of the residual network, due to decreasing the depth of the network our model reduced memory costs. To enhance the resolution of the single image we showed that our method improves training loss performance by performing the weight normalization instead of augmentation technology. The results of the experiment show that the method performs well in terms of quantitative indicators (PSNR) and (SSIM).","","978-1-6654-1860-7","10.1109/GCWOT49901.2020.9391625","National Natural Science Foundation of China (NSFC)(grant numbers:61836013); National Key Research Development and Plan of China(grant numbers:2016YFB501901); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9391625","remote-sensing images;Low-resolution LR;super-resolution (SR);wide residual block","Training;Optical losses;Wireless communication;Wireless sensor networks;Superresolution;Remote sensing;Residual neural networks","deep learning (artificial intelligence);geophysical image processing;image resolution;neural nets;remote sensing","deep learning;functional recovery issues;super-resolution wide remote sensing residual network;network our model;loss performance;single image super-resolution;remote-sensing image;satellite images;machine learning;neural network-based SR methods;multiple residual network frameworks","","","","26","IEEE","7 Apr 2021","","","IEEE","IEEE Conferences"
"Satellite remote sensing image super resolution based on markov random fields","Z. -Z. Wang; Q. -J. Zhang; X. -L. Han","China Academy of Space Technology, Institute of Spacecraft System Engineering, Beijing, China; China Academy of Space Technology, Institute of Spacecraft System Engineering, Beijing, China; China Academy of Space Technology, Institute of Spacecraft System Engineering, Beijing, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","7256","7259","This paper studies satellite remote sensing image super resolution that employs image processing techniques to reconstruct the high-resolution image from a set of low-resolution observations of the same scene. A heuristic approach for maximum a posteriori (MAP) estimate of desired high-resolution image based on markov random fields (MRF) is presented. Under the posteriori distribution deduced by Bayesian criterion, the reconstruction image is derived by finding the global optimized estimation with the simulated annealing (SA) optimization mechanism. In the experiments, the proposed method is evaluated in a simulated framework that the estimate images are compared with the reference one using Normalized Mean Square Error (NMSE) criterion. The results quantitatively indicate the super performance of super resolution reconstruction and noise robustness obtained by our approach in comparison with the Cubic interpolation.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730892","Satellite remote sensing;Super resolution;Maximum a posteriori probability;Markov random field;Simulated annealing","Estimation;Image resolution;Image reconstruction;Satellites;Remote sensing;Interpolation;Optimization","Markov processes;mean square error methods;random processes;remote sensing","satellite remote sensing image;Markov random fields;maximum a posteriori;global optimized estimation;simulated annealing optimization mechanism;Normalized Mean Square Error;noise robustness;Cubic interpolation","","","","8","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Coupled Adversarial Training for Remote Sensing Image Super-Resolution","S. Lei; Z. Shi; Z. Zou","State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, USA","IEEE Transactions on Geoscience and Remote Sensing","22 Apr 2020","2020","58","5","3633","3643","Generative adversarial network (GAN) has made great progress in recent natural image super-resolution tasks. The key to its success is the integration of a discriminator which is trained to classify whether the input is a real high-resolution (HR) image or a generated one. Arguably, learning a strong discriminative prior is essential for generating high-quality images. However, in remote sensing images, we discover, through extensive statistical analysis, that there are more low-frequency components than natural images, which may lead to a “discrimination-ambiguity” problem, i.e., the discriminator will become “confused” to tell whether its input is real or not when dealing with those low-frequency regions, and therefore, the quality of generated HR images may be deeply affected. To address this problem, we propose a novel GAN-based super-resolution algorithm named coupled-discriminated GANs (CDGANs) for remote sensing images. Different from the previous GAN-based super-resolution models in which their discriminator takes in a single image at one time, in our model, the discriminator is specifically designed to take in a pair of images: a generated image and its HR ground truth, to make better discrimination of the inputs. We further introduce a dual pathway network architecture, a random gate, and a coupled adversarial loss to learn better correspondence between the discriminative results and the paired inputs. Experimental results on two public data sets demonstrate that our model can obtain more accurate super-resolution results in terms of both visual appearance and local details compared with other state of the arts. Our code will be made publicly available.","1558-0644","","10.1109/TGRS.2019.2959020","National Basic Research Program of China (973 Program)(grant numbers:2017YFC1405605); National Natural Science Foundation of China(grant numbers:61671037); Beijing Natural Science Foundation(grant numbers:4192034); National Defense Science and Technology Innovation Special Zone Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946581","Coupled adversarial training;deep convolutional neural networks;generative adversarial networks (GANs);remote sensing images;super-resolution","Remote sensing;Training;Generators;Gallium nitride;Task analysis","geophysical image processing;image representation;image resolution;learning (artificial intelligence);remote sensing;statistical analysis","CDGAN;coupled-discriminated GAN;GAN-based super-resolution;low-frequency components;high-quality images;strong discriminative;high-resolution image;natural image super-resolution tasks;generative adversarial network;remote sensing image super-resolution;coupled adversarial training;accurate super-resolution results;paired inputs;discriminative results;coupled adversarial loss;previous GAN-based super-resolution models;remote sensing images;generated HR images;low-frequency regions","","54","","58","IEEE","31 Dec 2019","","","IEEE","IEEE Journals"
"Super-Resolution Reconstruction of Remote Sensing Image Using Multi-Temporal Images With Partial Scene Distortions","A. Belov; A. Denisova","Samara National Research University, Samara, Russia; Samara National Research University, Samara, Russia","2020 International Conference on Information Technology and Nanotechnology (ITNT)","12 Nov 2020","2020","","","1","6","Earth remote sensing data obtained by various sensors are usually different in spatial and spectral resolution and in the registration time as well. Changes in observation conditions lead to brightness distortions, some of which are compensated by atmospheric correction. Unfortunately, the distortions in the composition of the scene (scene distortions) cannot be compensated using atmospheric correction and require fusion methods to be applied. The existing superresolution methods for remote sensing data are based on the assumption that there are no scene distortions in the analyzed images. In this article, we propose an algorithm for combining Earth remote sensing data with an increase in the spectral and spatial resolution taking into account scene distortions. We found that the use of a larger dataset including images with scene distortions reduces root mean square error of 2-4% on average if the dataset contains a small number of images without scene distortions (from 2 to 6). With the larger number of images without scene distortions, the error value decreases by 1%. If all the images in the input dataset contain scene distortions, the proposed algorithm achieves super-resolution restoration of the scene image as well.","","978-1-7281-7041-1","10.1109/ITNT49337.2020.9253307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9253307","remote sensing images;super-resolution;scene distortions","Earth;Superresolution;Brightness;Distortion;Sensors;Spatial resolution;Remote sensing","geophysical image processing;image reconstruction;image registration;image resolution;image restoration;mean square error methods;remote sensing","brightness distortions;atmospheric correction;Earth remote sensing data;scene image;remote sensing image;partial scene distortions;super-resolution reconstruction;multitemporal images;spectral resolution;spatial resolution;root mean square error","","","","13","IEEE","12 Nov 2020","","","IEEE","IEEE Conferences"
"Domain Adaptation and Super-Resolution Based Bi-Directional Semantic Segmentation Method for Remote Sensing Images","M. Liang; X. Wang","School of Computer Science, Shaanxi Normal University, Xian, China; School of Computer Science, Shaanxi Normal University, Xian, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","3500","3503","Image semantic segmentation methods based on convolutional neural network rely on supervised learning with ground truth, thus cannot be well extended to datasets that all of the data are unlabeled. Domain adaptation can solve the problem of inconsistent feature distribution between target and source domains. However, when the spatial resolution of remote sensing images in the source and target domains are not the same, those domain adaptation methods are not effective. In this paper, we propose a bi-directional semantic segmentation method based on super-resolution and domain adaption (BSSM-SRDA). With the help of generative adversarial learning, the method accomplishes semantic segmentation task from a low-resolution labelled data source domain to a high-resolution unlabelled data target domain by reducing differences in resolution and feature distribution. In addition, we propose a self-supervised learning algorithm that helps the domain discriminator to focus on those target data that has not been aligned with the source domain. The experiments demonstrate the superiority of the proposed method over other state-of-the-art methods on two remote sensing image datasets.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883823","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883823","Remote sensing image;semantic segmentation;domain adaptation;super resolution;self-supervised learning","Image segmentation;Visualization;Semantics;Superresolution;Supervised learning;Training data;Bidirectional control","convolutional neural nets;feature extraction;geophysical image processing;image classification;image resolution;image segmentation;learning (artificial intelligence);remote sensing","super-resolution;remote sensing images;image semantic segmentation methods;convolutional neural network;inconsistent feature distribution;source domains;spatial resolution;target domains;domain adaptation methods;semantic segmentation task;low-resolution labelled data source domain;high-resolution unlabelled data target domain;self-supervised learning algorithm;domain discriminator;remote sensing image datasets;bidirectional semantic segmentation method","","","","11","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Remote Sensing Image Super-Resolution via Multi-scale Enhancement Network","Y. Wang; Z. Shao; T. Lu; C. Wu; J. Wang","School of General Aviation, Jingchu University of Technology, Jingmen, China; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology, Wuhan, China; State Key Laboratory of Geo-information Engineering, Xi’an Research Institute of Surveying and Mapping. No.1, Middle Section of Yanta Road, Xi’an, China; Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","","2023","PP","99","1","1","In recent years, remote sensing images have attracted a lot of attention because of their special value. However, images acquired by satellite sensors are usually low-resolution (LR), so remote sensing images are much more difficult to infer high-frequency details from compared with ordinary digital images, which means they cannot meet the needs of certain downstream tasks. In this letter, we propose a multi-scale enhancement network (MEN), which uses multi-scale features of remote sensing images to enhance the network’s reconstruction capability. Specifically, the network extracts the coarse features of LR remote sensing images using convolutional layers. Then, these features are fed into the multi-scale enhancement module (MEM) proposed by this network, which uses a combination of convolutional layers with multiple convolutional kernel sizes to refine the extraction of multi-scale features, and finally, the final reconstructed image is generated by the reconstruction module. Extensive experiments show that MEN achieves significant reconstruction advantages in both objective and subjective aspects.","1558-0571","","10.1109/LGRS.2023.3248069","in part by Guangxi science and technology program(grant numbers:GuiKe 2021AB30019); Opening Fund of Hubei key Laboratory of Intelligent Robot(grant numbers:HBIR202103); National Natural Science Foundation of China(grant numbers:42090012); 03 special research and 5G project of Jiangxi Province in China(grant numbers:20212ABC03A09); Zhuhai industry university research cooperation project of China(grant numbers:ZH22017001210098PWC); Sichuan Science and Technology Program(grant numbers:2022YFN0031); Zhizhuo Research Fund on Spatial-Temporal Artificial Intelligence(grant numbers:ZZJJ202202); Hubei key R&D plan(grant numbers:2022BAA048); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10050509","Remote sensing;residual fusion network;multi-scale;super-resolution","Remote sensing;Image reconstruction;Feature extraction;Micromechanical devices;Training;Convolution;Kernel","","","","","","","IEEE","23 Feb 2023","","","IEEE","IEEE Early Access Articles"
"Video Satellite Imagery Super Resolution for ‘Jilin-1’ via a Single-and-Multi Frame Ensembled Framework","S. Zhang; Q. Yuan; J. Li","School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","2731","2734","Compared with traditional remote sensing images, satellite remote sensing video contains more useful information and can capture continuous dynamic video. Recently, many deep-learning based methods have been proposed for video super resolution. However, these methods tend to ignore the structural information and characteristics for video satellite imagery such as small ground targets, a wide range of scales and weak textures. To this end, this paper proposes a single-and-multi-frame ensembled framework called SMFE for remote sensing videos super-resolution. The SMFE framework combines a non-local based single image super resolution (SISR) network and a state-of-the-arts multi-frame super resolution (MFSR) network EDVR. Experiments have been performed to demonstrate the effectiveness of the proposed method on Jilin-1.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324509","super resolution;Jilin-1;video satellite imagery","Satellites;Superresolution;Image reconstruction;Feature extraction;Remote sensing;Motion compensation;Visualization","geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);remote sensing;video signal processing","single-and-multiframe;remote sensing videos super-resolution;SMFE framework;nonlocal based single image super resolution network;state-of-the-arts multiframe super resolution network EDVR;Jilin-1;video satellite imagery super resolution;traditional remote sensing images;satellite remote;continuous dynamic video;deep-learning based methods;video super resolution;structural information","","2","","8","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Super Resolution Generative Adversarial Network Based Image Augmentation for Scene Classification of Remote Sensing Images","Q. Zhu; X. Fan; Y. Zhong; Q. Guan; L. Zhang; D. Li","Hubei Key Laboratory of Regional Development and Environmental Response, Wuhan, China; School of Geography and Information Engineering, China University of Geosciences, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan, China; School of Geography and Information Engineering, China University of Geosciences, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","573","576","High spatial resolution remote sensing image (RSI) scene classification, aimed at automatically labelling images with the given semantic categories, has been a hot issue. As it's difficult for RSI to quickly obtain a large number of training samples from a specific area. Traditional scene classification researches were mainly using deep learning models to transfer natural images to RSI. Considering the differences between natural images and RSI, we trained several Super Resolution GAN models by using different resolution RSI data from Google earth image. This paper proposed a novel SRGAN-CNN framework. Through transferring the data with scene classification dataset to obtain high resolution fake RSI. The experimental results demonstrate that the proposed framework can enhance transfer effect and help improve the accuracy of scene classification using low resolution RSI.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324043","National Natural Science Foundation of China(grant numbers:41901306); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324043","Image super resolution;scene classification;remote sensing images;deep learning","Image resolution;Image reconstruction;Image analysis;Spatial resolution;Remote sensing;Feature extraction;Data models","","","","","","14","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Weak Target Detection in High-Resolution Remote Sensing Images by Combining Super-Resolution and Deformable FPN","Y. Bai; T. Zou; S. Ye; Z. Qin; G. Gao; Y. Gu","School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; Space Star Technology Co., LTD, Beijing, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","292","295","Weak target detection plays an important role in military and civilian fields. However, due to the limitation of the target size and the influence of complex background, the detection of weak target is a huge challenge. Therefore, based on high-resolution remote sensing image, this paper proposes a weak target detection network which combines super-resolution and deformable convolution. Firstly, the high-resolution remote sensing image is expanded and enhanced to eliminate the influence of complex background. Secondly, a detection network based on the deformable convolution and feature pyramid network (FPN) is used to solve the problem of less information caused by the fewer target pixels. In addition, this paper establishes a detection dataset only containing weak vehicles. The experimental results show that the proposed method achieves better detection results in the weak target detection problem.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323260","National Key R&D Program of China(grant numbers:2017YFC1405100); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323260","Weak target detection;super-resolution;deformable convolution","Feature extraction;Convolution;Object detection;Remote sensing;Image resolution;Superresolution;Strain","geophysical image processing;image resolution;object detection;remote sensing","high-resolution remote sensing image;super-resolution;target size;complex background;weak target detection network;deformable convolution;fewer target pixels;detection dataset;weak target detection problem","","","","6","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Collaborative Network for Super-Resolution and Semantic Segmentation of Remote Sensing Images","Q. Zhang; G. Yang; G. Zhang","Shanghai Key Laboratory of Multidimensional Information Processing, School of Computer Science and Technology, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Multidimensional Information Processing, School of Computer Science and Technology, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Multidimensional Information Processing, School of Computer Science and Technology, East China Normal University, Shanghai, China","IEEE Transactions on Geoscience and Remote Sensing","17 Jan 2022","2022","60","","1","12","In the past few years, multitask learning (MTL) has been widely used in a single model to solve the problems of multiple businesses. MTL enables each task to achieve high performance and greatly reduces computational resource overhead. In this work, we designed a collaborative network that simultaneously solves the super-resolution semantic segmentation and super-resolution image reconstruction. This algorithm can obtain high-resolution semantic segmentation and super-resolution reconstruction results by taking relatively low-resolution images as input when high-resolution data are inconvenient or computing resources are limited. The framework consists of three parts: the semantic segmentation branch (SSB), the super-resolution branch (SRB), and the structural affinity block (SAB). Specifically, the SSB, SRB, and SAB are responsible for completing super-resolution semantic segmentation, image super-resolution reconstruction, and associated features, respectively. Our proposed method is simple and efficient, and it can replace the different branches with most of the state-of-the-art models. The International Society for Photogrammetry and Remote Sensing (ISPRS) segmentation benchmarks were used to evaluate our models. In particular, super-resolution semantic segmentation on the Potsdam dataset reduced Intersection over Union (IoU) by only 1.8% when the resolution of the input image was reduced by a factor of two. The experimental results showed that our framework can obtain more accurate semantic segmentation and super-resolution reconstruction results than the single model.","1558-0644","","10.1109/TGRS.2021.3099300","National Nature Science Foundation of China(grant numbers:61731009,41301472); Science and Technology Commission of Shanghai Municipality(grant numbers:19511120600,18DZ2270800); Natural Science Foundation of Shanghai(grant numbers:21ZR1421200); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506999","Multitask learning (MTL);remote sensing;semantic segmentation;super resolution","Image segmentation;Semantics;Superresolution;Task analysis;Remote sensing;Image reconstruction;Image resolution","geophysical image processing;image reconstruction;image resolution;image segmentation;learning (artificial intelligence);photogrammetry;remote sensing","super-resolution semantic segmentation;accurate semantic segmentation;super-resolution reconstruction results;collaborative network;super-resolution image reconstruction;high-resolution semantic segmentation;low-resolution images;high-resolution data;semantic segmentation branch;super-resolution branch;remote sensing segmentation benchmarks;SSB;SRB;SAB;MTL;multitask learning;computational resource overhead;ISPRS;international society for photogrammetry and remote sensing;intersection over union;IoU","","6","","63","IEEE","4 Aug 2021","","","IEEE","IEEE Journals"
"RRSGAN: Reference-Based Super-Resolution for Remote Sensing Image","R. Dong; L. Zhang; H. Fu","Shanghai Sense-Time Intelligent Technology Company, Ltd., Shanghai, China; Department of Earth System Science, Tsinghua University, Beijing, China; Department of Earth System Science, Tsinghua University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","3 Dec 2021","2022","60","","1","17","Remote sensing image super-resolution (SR) plays an important role by supplementing the lack of original high-resolution (HR) images in the study scenarios of large spatial areas or long time series. However, due to the lack of imagery information in low-resolution (LR) images, single-image super-resolution (SISR) is an inherently ill-posed problem. Especially, it is difficult to reconstruct the fine textures of HR images at large upscaling factors (e.g., four times). In this work, based on Google Earth HR images, we explore the potential of the reference-based super-resolution (RefSR) method on remote sensing images, utilizing rich texture information from HR reference (Ref) images to reconstruct the details in LR images. This method can use existing HR images to help reconstruct the LR images of long time series or a specific time. We build a reference-based remote sensing SR data set (RRSSRD). Furthermore, by adopting the generative adversarial network (GAN), we propose a novel end-to-end reference-based remote sensing GAN (RRSGAN) for SR. RRSGAN can extract the Ref features and align them to the LR features. Eventually, the texture information in the Ref features can be transferred to the reconstructed HR images. In contrast to the existing RefSR methods, we propose a gradient-assisted feature alignment method that adopts the deformable convolutions to align the Ref and LR features and a relevance attention module (RAM) to improve the robustness of the model in different scenarios (e.g., land cover changes and cloud coverage). The experimental results demonstrate that RRSGAN is robust and outperforms the state-of-the-art SISR and RefSR methods in both quantitative evaluation and visual results, which indicates the great potential of the RefSR method for remote sensing tasks. Our code and data are available at https://github.com/dongrunmin/RRSGAN.","1558-0644","","10.1109/TGRS.2020.3046045","Shanghai Municipal Commission of Economy and Informatization(grant numbers:2019-RGZN-01015); National Key Research and Development Plan of China(grant numbers:2017YFA0604500); National Natural Science Foundation of China(grant numbers:51761135015,U1839206); Center for High Performance Computing and System Simulation, Pilot National Laboratory for Marine Science and Technology (Qingdao); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328132","Deep learning;remote sensing imagery;super-resolution (SR)","Remote sensing;Image reconstruction;Feature extraction;Earth;Internet;Gallium nitride;Superresolution","geophysical image processing;image reconstruction;image resolution;image texture;remote sensing","Ref features;LR features;reconstructed HR images;gradient-assisted feature alignment method;RefSR method;remote sensing image super-resolution;high-resolution images;low-resolution images;single-image super-resolution;Google Earth HR images;reference-based super-resolution method;texture information;HR reference images;LR images;reference-based remote sensing SR data set;end-to-end reference-based remote sensing GAN;RRSGAN;deformable convolution;relevance attention module;land cover changes;cloud coverage;quantitative evaluation","","8","","66","IEEE","18 Jan 2021","","","IEEE","IEEE Journals"
"Remote Sensing Image Super-Resolution via Residual Aggregation and Split Attentional Fusion Network","L. Chen; H. Liu; M. Yang; Y. Qian; Z. Xiao; X. Zhong","Key Laboratory of Software Engineering, Ürümqi, China; Key Laboratory of Software Engineering, Ürümqi, China; Key Laboratory of Software Engineering, Ürümqi, China; Key Laboratory of Software Engineering, Ürümqi, China; College of Mathematics and System Sciences, Xinjiang University, Ürümqi, China; Key Laboratory of Software Engineering, Ürümqi, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","6 Oct 2021","2021","14","","9546","9556","Remote sensing images contain various land surface scenes and different scales of ground objects, which greatly increases the difficulty of super-resolution tasks. The existing deep learning-based methods cannot solve this problem well. To achieve high-quality super-resolution of remote sensing images, a residual aggregation and split attentional fusion network (RASAF) is proposed in this article. It is mainly divided into the following three parts. First, a split attentional fusion block is proposed. It uses a basic split–fusion mechanism to achieve cross-channel feature group interaction, allowing the method to adapt to various land surface scene reconstructions. Second, to fully exploit multiscale image information, a hierarchical loss function is used. Third, residual learning is used to reduce the difficulty of training in super-resolution tasks. However, the respective residual branch features are used quite locally and fail to represent the real value. A residual aggregation mechanism is used to aggregate the local residual branch features to generate higher quality local residual branch features. The comparison of RASAF with some classical super-resolution methods using two widely used remote sensing datasets showed that the RASAF achieved better performance. And it achieves a good balance between performance and model parameter number. Meanwhile, the RASAF’s ability to support multilabel remote sensing image classification tasks demonstrates its usefulness.","2151-1535","","10.1109/JSTARS.2021.3113658","National Natural Science Foundation of China(grant numbers:61966035); National Natural Science Foundation of China(grant numbers:U1803261); Xinjiang Uygur Autonomous Region Innovation Team(grant numbers:XJEDU2017T002); Autonomous Region Graduate Innovation Project(grant numbers:XJ2020G074); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9541020","Remote sensing image;residual aggregation;split attentional fusion;super-resolution (SR)","Remote sensing;Superresolution;Image reconstruction;Task analysis;Sensors;Feature extraction;Learning systems","feature extraction;geophysical image processing;image classification;image fusion;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","remote sensing image super-resolution;split attentional fusion network;remote sensing images;land surface scenes;super-resolution tasks;deep learning-based methods;high-quality super-resolution;RASAF;split attentional fusion block;basic split-fusion mechanism;cross-channel feature group interaction;land surface scene reconstructions;multiscale image information;residual learning;respective residual branch features;residual aggregation mechanism;higher quality local residual branch features;classical super-resolution methods;widely used remote sensing datasets;multilabel remote sensing image classification tasks","","7","","42","CCBY","20 Sep 2021","","","IEEE","IEEE Journals"
"Super Resolution Enhancement of Satellite Remote Sensing Images of Transmission Tower Based on Multi-map Residual Network and Wavelet Transform","Z. Yang; B. Zhao; X. Ma; M. Luo; J. Han; W. Si","Power Transmission and Transformation Engineering, Research Institute China Electric Power Research Institute, Beijing, China; Power Transmission and Transformation Engineering, Research Institute China Electric Power Research Institute, Beijing, China; Power Transmission and Transformation Engineering, Research Institute China Electric Power Research Institute, Beijing, China; School of Surveying Science and Engineering, Shandong University of Science and Technology, Qingdao, China; State Grid Zhejiang Electric Power CO. LTD., Research Institute, Zhejiang, China; State Grid Hangzhou Power Supply Company, Hangzhou, China","2020 International Conference on Computer Vision, Image and Deep Learning (CVIDL)","30 Nov 2020","2020","","","16","20","Existing satellite remote sensing images are often used to observe the fuzzy phenomenon of transmission line bodies. It is necessary to enhance super-resolution, but traditional superresolution technology is difficult to obtain rich details and edge information of transmission towers. This paper proposes a multiscale edge enhancement method combining multi-map residual convolutional neural network and wavelet transform to solve these problems. Specifically, we first use a multi-map residual convolutional neural network to directly take the low-resolution image as the initial input of the network, and then use a convolutional layer to extract features. Secondly, a multi-mapping network is established by residual learning, and a batch normalization layer is added to optimize the network to enrich the feature information needed for high-resolution image aggregation. Finally, we use deconvolution layers to complete image upsampling and output high-resolution images, so the initial image can directly complete the end-to-end mapping relationship between low-resolution images and high-resolution images without performing preprocessing. On this basis, multiscale edge enhancement is performed on the transmission tower based on wavelet transform to obtain the final super-resolution enhancement result. Experiments on different benchmark data sets show that the proposed method is superior to the existing methods in the four quantitative indicators of peak signal-to-noise ratio, structural similarity, entropy and image detail enhancement.","","978-1-7281-9481-3","10.1109/CVIDL51233.2020.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9270467","super-resolution;power transmission tower;satellite remote sensing;convolutional neural network;wavelet transform;edge enhancement","Satellites;Image reconstruction;Wavelet transforms;Remote sensing;Poles and towers;Image edge detection;Training","convolutional neural nets;edge detection;feature extraction;image enhancement;image resolution;image sampling;remote sensing;wavelet transforms","super resolution enhancement;satellite remote sensing images;transmission tower;wavelet transform;transmission line bodies;multiscale edge enhancement method;multimap residual convolutional neural network;low-resolution image;convolutional layer;residual learning;high-resolution image aggregation;image upsampling;end-to-end mapping relationship;image detail enhancement;batch normalization layer","","","","15","IEEE","30 Nov 2020","","","IEEE","IEEE Conferences"
"Super Resolution of Airplane Target in Remote Sensing Images via A Multi-Degradation Model","F. Cai; K. Wu; H. Jia; F. Wang","Key Laboratory for Information, Science of Electromagnetic Waves (MoE), Fudan University, Shanghai, China; Key Laboratory for Information, Science of Electromagnetic Waves (MoE), Fudan University, Shanghai, China; Key Laboratory for Information, Science of Electromagnetic Waves (MoE), Fudan University, Shanghai, China; Key Laboratory for Information, Science of Electromagnetic Waves (MoE), Fudan University, Shanghai, China","2022 IEEE 14th International Conference on Advanced Infocomm Technology (ICAIT)","26 Aug 2022","2022","","","330","333","In this paper, we argue that the degradation model assumed by existing work on super-resolution of remote sensing images deviates from those in real-world images. To address the above problem, this article proposes a super-resolution reconstruction method for unpaired airplanes in remote sensing images, which consists of a model that simulates the multiple degradations in real-world scenarios and a super-resolution generative adversarial network that generates high-resolution images. Specifically, the novel degradation model can cover a wide range of degradations in natural scenes, which contains diverse factors of additive Gaussian noise, Poisson noise, Brown Gaussian noise, Gaussian blur, etc. Experiments are conducted on the airplane targets in the Gaofen challenge dataset, and the results demonstrate the superiority of our method compared to state-of-the-art methods, especially in raw remote sensing images with multiple noise and blur, which may be preferred in other practical satellite applications with harsh circumstances.","2770-1603","978-1-6654-7156-5","10.1109/ICAIT56197.2022.9862621","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9862621","remote sensing image super-resolution;aircraft targets in remote sensing images;multiple degradation model","Degradation;Airplanes;Visualization;Satellites;Atmospheric modeling;Gaussian noise;Superresolution","Gaussian noise;geophysical image processing;image reconstruction;image resolution;natural scenes;remote sensing","super resolution;airplane target;multidegradation model;remote sensing images;real-world images;super-resolution reconstruction method;unpaired airplanes;multiple degradations;super-resolution generative adversarial network;high-resolution images;degradation model;Brown Gaussian noise;Poisson noise;Gaussian blur;Gaofen challenge dataset","","","","15","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"Super-resolution for remote sensing images using content adaptive detail enhanced self examples","S. Vishnukumar; M. Wilscy","Department of Computer Science, University of Kerala, Thiruvananthapuram, Kerala, India; Department of Computer Science, University of Kerala, Thiruvananthapuram, Kerala, India","2016 International Conference on Circuit, Power and Computing Technologies (ICCPCT)","4 Aug 2016","2016","","","1","5","This paper proposes a single image super-resolution (SR) technique for remote sensing images using content adaptive detail enhanced self examples. This method exploits large number of similar patches exists in the remote sensing images by using self examples. A high frequency layer is extracted from the input low resolution image and details of the high frequency layer are enhanced using content adaptive method to form the self examples. The root mean square difference of feature vectors extracted from self examples is given to a Gaussian function to find the weight. Weighted average of pixel computed using weights predicts the pixels of the high resolution high frequency layer. The reconstructed high resolution high frequency layer is combined with the linearly interpolated high resolution image to form the final high resolution image. Qualitative and Quantitative experimental analysis show that the proposed method gives better results than other existing methods. The results have better visual quality since image details are well preserved.","","978-1-5090-1277-0","10.1109/ICCPCT.2016.7530375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530375","Remote Sensing Image;Super-resolution;Content Adaptive;Self example based","Image resolution;Image reconstruction;Interpolation;Image edge detection;Remote sensing;Computers;Root mean square","feature extraction;Gaussian processes;geophysical image processing;image enhancement;image resolution;interpolation;remote sensing","content adaptive detail enhanced self examples;remote sensing image super-resolution;high frequency layer extraction;low resolution image;root mean square difference;feature vectors;Gaussian function;weighted average computation;image pixels;linearly interpolated high resolution image;visual quality","","1","","23","IEEE","4 Aug 2016","","","IEEE","IEEE Conferences"
"Enhanced MRF based Super Resolution Method for Remote Sensing Images","S. Deepak; D. Patra","Dept. Of Electrical Engineering, National Institute of Technology Rourkela, Rourkela, INDIA; Dept. Of Electrical Engineering, National Institute of Technology Rourkela, Rourkela, INDIA","2019 International Conference on Range Technology (ICORT)","20 Apr 2020","2019","","","1","5","In this paper, a learning based enhanced Markov Random Field (MRF) based super resolution reconstruction (SRR) method for remote sensing image with embedded Image Euclidean distance (IMED) is proposed. A robust and transformation invariant similarity metric IMED is integrated for modelling compatibility functions (CF) and finding the similarity between image patches. Unlike traditional Euclidean distance, IMED takes into consideration the spatial relationships of pixels as well as the smallest deformation and therefore provides reasonable result. Further, an iterative belief propagation (BP) algorithm is used to find the optimal candidate patches and therefore high resolution (HR) patches. The experimental results demonstrate that the proposed method outperforms some of the state-of-the-art methods.","","978-1-7281-1353-1","10.1109/ICORT46471.2019.9069619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9069619","Super-resolution reconstruction (SRR);IMED;MAP-MRF;Belief propagation;remote sensing","Spatial resolution;Euclidean distance;Remote sensing;Image reconstruction;Training;Markov random fields","belief networks;geophysical image processing;image reconstruction;image resolution;iterative methods;learning (artificial intelligence);Markov processes;random processes;remote sensing","MRF;super resolution reconstruction;SRR;remote sensing image;compatibility functions;image patches;iterative belief propagation algorithm;high resolution patches;embedded image Euclidean distance;learning based enhanced Markov random field;transformation invariant similarity metric;IMED","","","","12","IEEE","20 Apr 2020","","","IEEE","IEEE Conferences"
"Remote Sensing Image Super-Resolution Using Novel Dense-Sampling Networks","X. Dong; X. Sun; X. Jia; Z. Xi; L. Gao; B. Zhang","College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; Key Laboratory of Digital Earth Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; School of Engineering and Information Technology, University of New South Wales, Canberra, ACT, Australia; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; Key Laboratory of Digital Earth Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; College of Resources and Environment, University of Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","20 Jan 2021","2021","59","2","1618","1633","Super-resolution (SR) techniques play a crucial role in increasing the spatial resolution of remote sensing data and overcoming the physical limitations of the spaceborne imaging systems. Though the convolutional neural network (CNN)-based methods have obtained good performance, they show limited capacity when coping with large-scale super-resolving tasks. The more complicated spatial distribution of remote sensing data further increases the difficulty in reconstruction. This article develops a dense-sampling super-resolution network (DSSR) to explore the large-scale SR reconstruction of the remote sensing imageries. Specifically, a dense-sampling mechanism, which reuses an upscaler to upsample multiple low-dimension features, is presented to make the network jointly consider multilevel priors when performing reconstruction. A wide feature attention block (WAB), which incorporates the wide activation and attention mechanism, is introduced to enhance the representation ability of the network. In addition, a chain training strategy is proposed to optimize further the performance of the large-scale models by borrowing knowledge from the pretrained small-scale models. Extensive experiments demonstrate the effectiveness of the proposed methods and show that the DSSR outperforms the state-of-the-art models in both quantitative evaluation and visual quality.","1558-0644","","10.1109/TGRS.2020.2994253","National Natural Science Foundation of China(grant numbers:91638201,41722108); National Key Research and Development Program of China(grant numbers:2016YFB0501501); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9107103","Attention mechanism;dense sampling;remote sensing image;super-resolution;wide activation","Image reconstruction;Remote sensing;Feature extraction;Spatial resolution;Convolutional neural networks","convolutional neural nets;geophysical image processing;image reconstruction;image resolution;image sampling;remote sensing","dense-sampling super-resolution network;large-scale SR reconstruction;remote sensing imageries;dense-sampling mechanism;low-dimension features;performing reconstruction;wide feature attention block;attention mechanism;large-scale models;pretrained small-scale models;remote sensing image super-resolution;super-resolution techniques;spatial resolution;remote sensing data;spaceborne imaging systems;convolutional neural network-based methods;large-scale super-resolving tasks;complicated spatial distribution;dense-sampling networks","","44","","55","IEEE","3 Jun 2020","","","IEEE","IEEE Journals"
"Temporal Super-Resolution of Microwave Remote Sensing Images","I. Yanovsky; B. Lambrigtsen","California Institute of Technology, Pasadena, CA, US; California Institute of Technology, Pasadena, CA, US","2018 IEEE 15th Specialist Meeting on Microwave Radiometry and Remote Sensing of the Environment (MicroRad)","13 Aug 2018","2018","","","1","6","We develop an approach for increasing the temporal resolution of a temporally blurred sequence of observations. Super-resolution is performed in time using a variational approach. By temporal super-resolution, we mean recovering rapidly evolving events that were corrupted by the induced blur of the sensor. A blurred sequence of observations is assumed to have been generated by convolution of a physical scene with a temporal rectangular convolution kernel whose support is the sensor exposure time. We solve the deconvolution problem using the Split-Bregman method. Such methodology is based on current research in sparse optimization and compressed sensing, which lead to unprecedented efficiencies for solving image reconstruction problems. We test our method using a simulated temporally blurred and noisy temporal precipitation sequence and show that our method significantly reduces the errors in the corrupted sequence.","","978-1-5386-5015-8","10.1109/MICRORAD.2018.8430695","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8430695","Deconvolution;microwave imaging;remote sensing;super-resolution;temporal resolution","Spatial resolution;Image reconstruction;Convolution;Deconvolution;Microwave imaging;Microwave theory and techniques","deconvolution;geophysical image processing;image reconstruction;image resolution;image restoration;image sensors;image sequences;remote sensing","temporal super-resolution;microwave remote sensing images;variational approach;induced blur;temporal rectangular convolution kernel whose support;sensor exposure time;noisy temporal precipitation sequence;Split-Bregman method","","3","","22","IEEE","13 Aug 2018","","","IEEE","IEEE Conferences"
"Zero-Shot Super Resolution for Satellite Remote Sensing Images","Y. Junzhi","School of Information and Electronics, Beijing Institute of Technology, Beijing, China","2019 IEEE International Conference on Signal, Information and Data Processing (ICSIDP)","21 Aug 2020","2019","","","1","5","Due to the great distance between the satellite platform and the ground targets of interests, various factors such as weather and light conditions degrade the image quality captured by the sensors. Single image super resolution (SISR) has always been an important research field in satellite remote sensing image process. With large amounts of low resolution to high resolution (LR-HR) pairs generated by predefined downscaling process, usually noise-free bicubic interpolation with anti-alias, recent deep learning models have shown great improvements on natural image under such ideal conditions. However the real-world degrading process of remote sensing (RS) images differs greatly from the ideal configuration, the state-of-the-art models lose their power when faced with the practical problems. This letter adapted the recently proposed zero shot super resolution scheme to accommodate satellite RS images, both quantitative and qualitative results show that our method outperforms the previous DL-based models by a clear margin.","","978-1-7281-2345-5","10.1109/ICSIDP47821.2019.9173007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173007","super resolution;zero shot;satellite remote sensing;LR-HR pairs","","image enhancement;image processing;image resolution;interpolation;learning (artificial intelligence);remote sensing","noise-free bicubic interpolation;recent deep learning models;natural image;real-world degrading process;remote sensing images;recently proposed zero shot super resolution scheme;satellite RS images;zero-shot super resolution;great distance;satellite platform;weather;light conditions;image quality;single image super resolution;satellite remote sensing image process;predefined downscaling process","","","","21","IEEE","21 Aug 2020","","","IEEE","IEEE Conferences"
"Dual Learning-Based Graph Neural Network for Remote Sensing Image Super-Resolution","Z. Liu; R. Feng; L. Wang; W. Han; T. Zeng","School of Computer Science and the Hubei Key Laboratory of Intelligent Geo Information Processing, China University of Geosciences, Wuhan, China; School of Computer Science and the Hubei Key Laboratory of Intelligent Geo Information Processing, China University of Geosciences, Wuhan, China; School of Computer Science and the Hubei Key Laboratory of Intelligent Geo Information Processing, China University of Geosciences, Wuhan, China; School of Computer Science and the Hubei Key Laboratory of Intelligent Geo Information Processing, China University of Geosciences, Wuhan, China; Department of Mathematics, The Chinese University of Hong Kong, Shatin, New Territories, Hong Kong","IEEE Transactions on Geoscience and Remote Sensing","2 Sep 2022","2022","60","","1","14","High-resolution (HR) remote sensing imagery plays a critical role in remote sensing image interpretation, and single image super-resolution (SISR) reconstruction technology is becoming increasingly valuable and significant. The state-of-the-art deep-learning-based SISR methods have demonstrated remarkable advantages while reconstructing complex texture details still remains a big challenge. Besides, as a typical ill-posed inverse problem, how to determine the optimal solution is another important topic. To address these problems, in this work, a dual learning-based graph neural network (DLGNN) is proposed, in which the graph neural network (GNN) is utilized to consider the self-similarity patches in remote sensing imagery by aggregating cross-scale neighboring feature patches, and dual learning strategy is adopted to refine the reconstruction results by constraining the mapping process in terms of the loss function, transferring the typical ill-posed problem to a well-posed one. Abundant experiments on 3K VEHICLE_SR datasets and Massachusetts Roads demonstrate the validity and outstanding performance for remote sensing image super-resolution (SR) tasks compared with other state-of-the-art SR construction methods. Code is available at https://github.com/CUG-RS/DLGNN","1558-0644","","10.1109/TGRS.2022.3199750","National Natural Science Foundation of China(grant numbers:41925007,U1711266); Hong Kong Scholars Program(grant numbers:XJ2020025); Hubei Key Laboratory of Regional Development and Environmental Response (Hubei University)(grant numbers:2020(B)003); Hubei Natural Science Foundation of China(grant numbers:2019CFA023); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9861602","Dual learning;graph neural network;remote sensing imagery;super-resolution (SR)","Remote sensing;Superresolution;Feature extraction;Image reconstruction;Graph neural networks;Task analysis;Learning systems","deep learning (artificial intelligence);geophysical image processing;graph theory;image reconstruction;image resolution;image texture;remote sensing","dual learning-based graph neural network;remote sensing image super-resolution;high-resolution remote sensing imagery;remote sensing image interpretation;single image super-resolution reconstruction;SISR;deep learning;texture details;DLGNN;self-similarity patches;cross-scale neighboring feature patches;mapping;loss function;3K VEHICLE_SR datasets;Massachusetts Roads","","3","","63","IEEE","18 Aug 2022","","","IEEE","IEEE Journals"
"Deep Learning for Remote Sensing Image Super-Resolution","M. R. UI Hoque; R. Burks; C. Kwan; J. Li","ECE Department, Old Dominion University, Norfolk, USA; CS Department, Samford University, Homewood, USA; Applied Research LLC, Rockville, USA; ECE Department, Old Dominion University, Norfolk, USA","2019 IEEE 10th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)","13 Feb 2020","2019","","","0286","0292","The aim of image super-Resolution (SR) is to enhance image resolution while still retain the integrity of the original image. There are many ongoing types of research on image super-resolution for natural images, but any a few on remote sensing images. In this paper, we proposed deep learning-based image super-resolution techniques, including convolutional neural network (CNN) and generative adversarial network (GAN) to enhance the resolution of remote sensing images by a factor 4. In CNN, it learns an end to end mapping from low-resolution image to high-resolution image whereas, in GAN, the model learns the mapping guided by the GAN loss and gives the sharper appearance in high-resolution images. Our experimental results show that visually GAN models perform well but are inferior to other models in terms of image quality metrics, whereas quantitatively CNN models outperform other super-resolution models.","","978-1-7281-3885-5","10.1109/UEMCON47517.2019.8993047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8993047","Remote sensing image;Super resolution;Machine Learning;Deep Learning;CNN;GAN","","convolutional neural nets;geophysical image processing;image enhancement;image resolution;learning (artificial intelligence);remote sensing","remote sensing image super-resolution;image resolution;natural images;deep learning-based image super-resolution techniques;generative adversarial network;image quality metrics;super-resolution models;convolutional neural network;CNN;GAN","","3","","25","IEEE","13 Feb 2020","","","IEEE","IEEE Conferences"
"Large Remote Sensing Image Super Resolution Using Self Attention Conditional Coordinate Network","X. Xiao; Y. Lu","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","3778","3781","Optical imagery is one of the most important sources for model remote sensing. Super resolution of the optical data could be very useful for industry and academia. Conventional solutions from computer vision only offers super resolution on small images describing relatively smaller scene and optimized towards human perception. In this paper, we proposed a new deep learning model for large remote sensing image super resolution. By using conditional coordinate and self-attention, the model could achieve arbitrary large image super resolution task with special focus on correctness of the details. Numerical evaluation of the model is carried out based on real satellite remote sensing data. Result shows a promising performance with PSNR $> 33\ \text{dB}$ and SSIM $> 0.93$.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883625","Super Resolution;Deep Learning;Neural Networks","Industries;Image resolution;Satellites;Computational modeling;Optical imaging;Adaptive optics;Numerical models","deep learning (artificial intelligence);geophysical image processing;image resolution;remote sensing","self attention conditional coordinate network;deep learning;image super resolution;satellite remote sensing data;optical imagery;optical data","","","","7","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Study on super-resolution reconstruction algorithm based on sparse representation and dictionary learning for remote sensing image","X. Zhao; R. Yang; Z. Qin; J. Wu","School of Mathmatics and Computer Science, Panzhihua college, Panzhihua, China; School of Civil and Architectural Engineering, Panzhihua college, Panzhihua, China; School of Mathmatics and Computer Science, Panzhihua college, Panzhihua, China; School of Mathmatics and Computer Science, Panzhihua college, Panzhihua, China","2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","26 Feb 2018","2017","","","1","4","Super-resolution image reconstruction plays a very important role in the interpretation of remote sensing images. Especially when the resolution of images is low, the size of the objects to be identified is close to the minimum resolution, and can be reconstructed by super-resolution better interpretation of the feature. In this paper, K-SVD algorithm is used to study the exampler of high resolution image library, and the dictionary of high resolution remote sensing image is obtained. The low resolution image is represented by high resolution dictionary, and the remote sensing reconstruction of remote sensing image is realized. Which improves the peak noise ratio and mean square error of the image, and has better performance than the interpolation algorithm. The method proposed in this paper has important significance and application prospect in remote sensing image application.","","978-1-5386-1937-7","10.1109/CISP-BMEI.2017.8302035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302035","Super-resolution;exampler;K-SVD;Sparse Representation","Remote sensing;Image reconstruction;Signal resolution;Spatial resolution;Dictionaries;Machine learning","compressed sensing;geophysical image processing;image reconstruction;image representation;image resolution;interpolation;remote sensing;singular value decomposition","super-resolution image reconstruction algorithm;K-SVD algorithm;Maoergai area landscape;Minjiang River;remote sensing reconstruction;high resolution dictionary;high resolution remote sensing image;high resolution image library","","1","","17","IEEE","26 Feb 2018","","","IEEE","IEEE Conferences"
"Locally-adapted convolution-based super-resolution of irregularly-sampled ocean remote sensing data","M. López-Radcenco; R. Fablet; A. Aïssa-El-Bey; P. Ailliot","Institut Mines-Télécom Atlantique, Université Bretagne Loire Technopôle, Brest Cedex 3, France; Institut Mines-Télécom Atlantique, Université Bretagne Loire Technopôle, Brest Cedex 3, France; Institut Mines-Télécom Atlantique, UMR 6285 LabSTICC, Université Bretagne Loire Technopôle Brest-Iroise CS83818, 29238 Brest Cedex 3, France; Laboratoire de Mathématiques de Bretagne Atlantique, Université de Brest, Brest Cedex, France","2017 IEEE International Conference on Image Processing (ICIP)","22 Feb 2018","2017","","","4307","4311","Super-resolution is a classical problem in image processing, with numerous applications to remote sensing image enhancement. Here, we address the super-resolution of irregularly-sampled remote sensing images. Using an optimal interpolation as the low-resolution reconstruction, we explore locally-adapted multimodal convolutional models and investigate different dictionary-based decompositions, namely based on principal component analysis (PCA), sparse priors and non-negativity constraints. We consider an application to the reconstruction of sea surface height (SSH) fields from two information sources, along-track altimeter data and sea surface temperature (SST) data. The reported experiments demonstrate the relevance of the proposed model, especially locally-adapted parametrizations with non-negativity constraints, to outperform optimally-interpolated reconstructions.","2381-8549","978-1-5090-2175-8","10.1109/ICIP.2017.8297095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8297095","Super-resolution;convolutional model;irregular sampling;dictionary-based decomposition;non-negativity","Image resolution;Image reconstruction;Dictionaries;Principal component analysis;Remote sensing;Analytical models;Calibration","convolution;geophysical image processing;geophysical signal processing;image enhancement;image reconstruction;image resolution;interpolation;ocean temperature;oceanographic regions;oceanographic techniques;principal component analysis;remote sensing","irregularly-sampled ocean remote sensing data;super-resolution;image processing;remote sensing image enhancement;irregularly-sampled remote sensing images;low-resolution reconstruction;multimodal convolutional models;sparse priors;sea surface height fields;along-track altimeter data;sea surface temperature data;optimally-interpolated reconstructions;dictionary-based decompositions;principal component analysis;PCA;SSH;SST","","2","","20","IEEE","22 Feb 2018","","","IEEE","IEEE Conferences"
"Multiattention Generative Adversarial Network for Remote Sensing Image Super-Resolution","S. Jia; Z. Wang; Q. Li; X. Jia; M. Xu","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Key Laboratory for Geo-Environmental Monitoring of Coastal Zone of the Ministry of Natural Resources, Shenzhen University, Shenzhen, China; School of Engineering and Information Technology, University of New South Wales, Canberra, ACT, Australia; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Geoscience and Remote Sensing","14 Jun 2022","2022","60","","1","15","Image super-resolution (SR) methods can generate remote sensing images with high spatial resolution without increasing the cost of acquisition equipment, thereby providing a feasible way to improve the quality of remote sensing images. Clearly, image SR is a severe ill-posed problem. With the development of deep learning, the powerful fitting ability of deep neural networks has solved this problem to some extent. Since the texture information of various remote sensing images are totally different from each other, in this article, we proposed a network based on generative adversarial network (GAN) to achieve high-resolution remote sensing images, named multiattention GAN (MA-GAN). The main body of the generator in MA-GAN contains three blocks: pyramid convolutional residual dense (PCRD) block, attention-based upsampling (AUP) block, and attention-based fusion (AF) block. Specifically, the developed attention pyramid convolutional (AttPConv) operator in the PCRD block combines multiscale convolution and channel attention (CA) to automatically learn and adjust the scale of residuals for better representation. The established AUP block uses pixel attention (PA) to perform arbitrary scales of upsampling. The AF block uses branch attention (BA) to integrate upsampled low-resolution images with high-level features. Besides, the loss function takes both adversarial loss and feature loss into consideration to guide the learning procedure of the generator. We have compared our MA-GAN approach with several state-of-the-art methods on a number of remote sensing scenes, and the experimental results consistently demonstrate the effectiveness of the proposed MA-GAN. For study replication, the source code will be released at: https://github.com/ZhihaoWang1997/MA-GAN.","1558-0644","","10.1109/TGRS.2022.3180068","National Natural Science Foundation of China(grant numbers:41971300,61901278); Key Project of Department of Education of Guangdong Province(grant numbers:2020ZDZX3045); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2022A1515011290); Natural Science Foundation of Guangdong Province(grant numbers:2021A1515011413); Shenzhen Scientific Research and Development Funding Program(grant numbers:20200803152531004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9787539","Generative adversarial network (GAN);remote sensing image;super-resolution (SR)","Remote sensing;Generators;Convolution;Generative adversarial networks;Task analysis;Spatial resolution;Interpolation","convolution;geophysical image processing;image resolution;image texture;learning (artificial intelligence);neural nets;remote sensing","multiattention generative adversarial network;remote sensing image super-resolution;super-resolution methods;high spatial resolution;image SR;deep neural networks;high-resolution remote sensing images;named multiattention GAN;MA-GAN;attention-based fusion;developed attention pyramid convolutional operator;multiscale convolution;channel attention;established AUP block;low-resolution images;remote sensing scenes","","4","","60","IEEE","3 Jun 2022","","","IEEE","IEEE Journals"
"Target-Guided Feature Super-Resolution for Vehicle Detection in Remote Sensing Images","J. Li; Z. Zhang; Y. Tian; Y. Xu; Y. Wen; S. Wang","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Key Laboratory of Aerospace Information Applications of CETC, CETC 54th Research Institute, Shijiazhuang, China; Key Laboratory of Aerospace Information Applications of CETC, CETC 54th Research Institute, Shijiazhuang, China","IEEE Geoscience and Remote Sensing Letters","4 Jan 2022","2022","19","","1","5","Vehicle detection in remote sensing images remains a challenge because most vehicles are small and cover only a relatively small area due to the low ground sample distance. Although image super-resolution can improve small object detection performance as a preprocessing step, methods for improving the quality of the entire image tend to focus on the majority backgrounds that are not important for detection and involve high computational cost. Inspired by the promising feature-level super-resolution method, in this letter, we propose a novel anchor-free vehicle detection network for small vehicle detection in remote sensing images. Specifically, a target-guided feature super-resolution network is proposed to enhance the features of the potential target. Besides, we propose a novel feature fusion module to improve the feature representation of shallow layers, which accounts for small object detection. Extensive experiments on three public remote sensing detection datasets [cars overhead with context (COWC), Vehicle Detection in Aerial Imagery (VEDAI), and UCAS-AOD] amply demonstrate that our method can achieve significant performance with a mean average precision of 0.933, 0.756, and 0.961, respectively.","1558-0571","","10.1109/LGRS.2021.3112172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9548683","Feature super-resolution;remote sensing images;vehicle detection","Feature extraction;Superresolution;Detectors;Vehicle detection;Remote sensing;Object detection;Semantics","feature extraction;geophysical image processing;image fusion;image representation;image resolution;object detection;remote sensing","remote sensing images;image super-resolution;object detection performance;promising feature-level super-resolution method;novel anchor-free vehicle detection network;target-guided feature super-resolution network;feature fusion module;public remote sensing detection datasets","","4","","25","IEEE","27 Sep 2021","","","IEEE","IEEE Journals"
"A Super Resolution Method for Remote Sensing Images Based on Cascaded Conditional Wasserstein GANs","B. Liu; H. Li; Y. Zhou; Y. Peng; A. Elazab; C. Wang","Northwest China Research Institute of Electronics Equipment, Xi’an, China; Northwest China Research Institute of Electronics Equipment, Xi’an, China; Northwest China Research Institute of Electronics Equipment, Xi’an, China; Shenzhen Institutes of Adavanced Technology, Chinese Academy of Sciences, Shenzhen, China; Computer Science Department, Misr Higher Institute for Commerce and Computers, Mansoura City, Egypt; University of Science and Technology of China, Hefei, P.R.China","2020 IEEE 3rd International Conference on Information Communication and Signal Processing (ICICSP)","20 Oct 2020","2020","","","284","289","High-resolution (HR) remote sensing imagery is quite beneficial for subsequent interpretation. Obtaining HR images can be achieved by upgrading the imaging device. Yet, the cost to perform this task is very huge. Thus, it is necessary to obtain HR images from low-resolution (LR) ones. In the literature, the super-resolution image reconstruction methods based on deep learning have unparalleled advantages in comparison to traditional reconstruction methods. This work is inspired by these current mainstream methods and proposes a novel cascaded conditional Wasserstein generative adversarial network (CCWGAN) architecture with the residual dense block to generate high quality remote sensing images. We validate the proposed method on the NWPU VHR-10 dataset. Experimental results show our CCWGAN method has superior performance compared with the state-of-the-art GAN methods.","","978-1-7281-8823-2","10.1109/ICICSP50920.2020.9232066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9232066","remote sensing images;cascaded conditional generative adversarial networks;wasserstein generative adversarial networks;residual dense block","Gallium nitride;Image edge detection;Remote sensing;Generative adversarial networks;Training;Generators;Deep learning","convolutional neural nets;geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","super-resolution image reconstruction methods;conditional Wasserstein generative adversarial network architecture;high quality remote sensing images;CCWGAN method;super resolution method;high-resolution remote sensing imagery;HR images;imaging device;cascaded conditional Wasserstein GAN;NWPU VHR-10 dataset","","","","18","IEEE","20 Oct 2020","","","IEEE","IEEE Conferences"
"An Effective Super-Resolution Reconstruction Method for Geometrically Deformed Image Sequences","J. Qin; I. Yanovsky","Department of Mathematics, University of Kentucky, Lexington, KY, USA; Joint Institute for Regional Earth System Science and Engineering, University of California, Los Angeles, CA, USA","2020 16th Specialist Meeting on Microwave Radiometry and Remote Sensing for the Environment (MicroRad)","5 Feb 2021","2020","","","1","4","Despite of the technology advancements, remote sensing images usually suffer from a poor spatial resolution. To resolve this issue, a lot of research efforts have been devoted to developing resolution enhancement methods which retrieve a high-resolution image out of its low-resolution degraded versions. In this paper, we consider a nonlocal total variation (NLTV) based super-resolution method which handles low-resolution images with geometric deformations. In particular, we apply the framework of alternating direction method of multipliers (ADMM) to deduce an effective algorithm, which involves soft thresholding and gradient descent. Effectiveness and robustness to noise of the proposed method are verified by various numerical experiments.","","978-1-7281-7093-0","10.1109/MicroRad49612.2020.9342611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9342611","Remote sensing images;super-resolution image reconstruction;nonlocal total variation;alternating direction method of multipliers (ADMM)","Superresolution;Convex functions;Robustness;Spatial resolution;Remote sensing;Image reconstruction;Strain","geometry;gradient methods;image enhancement;image reconstruction;image resolution;image sequences;remote sensing","technology advancements;remote sensing images;spatial resolution;resolution enhancement;high-resolution image;nonlocal total variation;low-resolution images;geometric deformations;robustness;super-resolution reconstruction;image sequence;NLTV;alternating direction method of multipliers;ADMM","","","","17","IEEE","5 Feb 2021","","","IEEE","IEEE Conferences"
"Super-resolution Reconstruction of Airborne Remote Sensing Images based on Multi-scale Fusion","F. Chu; H. Liu; Z. Wang; Z. Cao","College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China","2022 3rd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)","23 Dec 2022","2022","","","648","651","To extract more detailed features of airborne remote sensing images to obtain more information, super-resolution reconstruction is performed on them. However, the existing super-resolution reconstruction algorithms of airborne remote sensing images have poor feature extraction capabilities, and smooth image edges, and are difficult to restore high-frequency information effectively. In this paper, the residual features of different residual modules are densely connected to form a dense group (DG), which combines different residual features to reduce the redundancy of features and ensure the effective transmission of high-frequency residual features. Further, the residual features of DG are densely connected to realize the reuse of information, and combined with multi-scale fusion, a two-branch lightweight multi-scale fusion super-resolution reconstruction network is proposed. The experimental results show that the algorithm has good performance and is lightweight, and can obtain a better reconstruction effect.","","978-1-6654-5160-4","10.1109/ICBAIE56435.2022.9985886","Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9985886","component;multi-scale fusion;super-resolution reconstruction;airborne remote sensing image;residual dense network;lightweight","Image edge detection;Superresolution;Redundancy;Reconstruction algorithms;Feature extraction;Image restoration;Internet of Things","feature extraction;geophysical image processing;image fusion;image reconstruction;image resolution;remote sensing","airborne remote sensing images;detailed features;different residual features;different residual modules;existing super-resolution reconstruction algorithms;high-frequency information;high-frequency residual features;multiscale fusion super-resolution reconstruction network;poor feature extraction capabilities;reconstruction effect;smooth image edges","","","","11","IEEE","23 Dec 2022","","","IEEE","IEEE Conferences"
"SWCGAN: Generative Adversarial Network Combining Swin Transformer and CNN for Remote Sensing Image Super-Resolution","J. Tu; G. Mei; Z. Ma; F. Piccialli","School of Engineering and Technology, China University of Geosciences, Beijing, China; School of Engineering and Technology, China University of Geosciences, Beijing, China; School of Engineering and Technology, China University of Geosciences, Beijing, China; Department of Mathematics and Applications “R. Caccioppoli”, University of Naples Federico II, Napoli, Italy","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","27 Jul 2022","2022","15","","5662","5673","Easy and efficient acquisition of high-resolution remote sensing images is of importance in geographic information systems. Previously, deep neural networks composed of convolutional layers have achieved impressive progress in super-resolution reconstruction. However, the inherent problems of the convolutional layer, including the difficulty of modeling the long-range dependency, limit the performance of these networks on super-resolution reconstruction. To address the abovementioned problems, we propose a generative adversarial network (GAN) by combining the advantages of the swin transformer and convolutional layers, called SWCGAN. It is different from the previous super-resolution models, which are composed of pure convolutional blocks. The essential idea behind the proposed method is to generate high-resolution images by a generator network with a hybrid of convolutional and swin transformer layers and then to use a pure swin transformer discriminator network for adversarial training. In the proposed method, first, we employ a convolutional layer for shallow feature extraction that can be adapted to flexible input sizes; second, we further propose the residual dense swin transformer block to extract deep features for upsampling to generate high-resolution images; and third, we use a simplified swin transformer as the discriminator for adversarial training. To evaluate the performance of the proposed method, we compare the proposed method with other state-of-the-art methods by utilizing the UCMerced benchmark dataset, and we apply the proposed method to real-world remote sensing images. The results demonstrate that the reconstruction performance of the proposed method outperforms other state-of-the-art methods in most metrics.","2151-1535","","10.1109/JSTARS.2022.3190322","National Natural Science Foundation of China(grant numbers:11602235); Fundamental Research Funds for China Central Universities(grant numbers:2652021053); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9829280","Convolutional layers;generative adversarial network (GAN);remote sensing images;super-resolution reconstruction;swin transformer","Feature extraction;Superresolution;Transformers;Remote sensing;Image reconstruction;Generative adversarial networks;Task analysis","convolution;feature extraction;geographic information systems;geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);neural nets;remote sensing;unsupervised learning","real-world remote sensing images;simplified swin transformer;residual dense swin transformer block;adversarial training;pure swin transformer discriminator network;transformer layers;generator network;high-resolution images;pure convolutional blocks;previous super-resolution models;super-resolution reconstruction;convolutional layer;deep neural networks;high-resolution remote sensing images;efficient acquisition;easy acquisition;remote sensing image super-resolution;generative adversarial network combining swin transformer","","3","","44","CCBYNCND","13 Jul 2022","","","IEEE","IEEE Journals"
"Unified Framework for the Joint Super-Resolution and Registration of Multiangle Multi/Hyperspectral Remote Sensing Images","H. Chen; H. Zhang; J. Du; B. Luo","Mapping, and Remote Sensing, State Key Laboratory of Information Engineering in Surveying, Wuhan University, Wuhan, China; Mapping, and Remote Sensing, State Key Laboratory of Information Engineering in Surveying, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Mapping, and Remote Sensing, State Key Laboratory of Information Engineering in Surveying, Wuhan University, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","2 Jun 2020","2020","13","","2369","2384","In this article, a unified framework based on rank minimization (UFRM) is proposed for use with multiangle multi/hyperspectral remote sensing images, which simultaneously integrates image super-resolution reconstruction (SRR) and image registration. With the complementary information of different angle images and the high correlation between each band of the multi/hyperspectral images, a new image observation model is established to describe the mathematical degradation process of the observed low-resolution multiangle multi/hyperspectral images from the desired high-resolution (HR) multi/hyperspectral image. Based on the rank-one structure of the multiangle images, each observed image is decomposed into a foreground image for each angle image, and a background image, which is shared among all the multiangle images. A multichannel total variation constraint is applied to the target HR background image, with the consideration of the high correlation of different bands. Finally, an alternating minimization optimization strategy is utilized to resolve the joint cost function, which consists of the unknown image registration transformation parameters and the desired reconstruction image. As a result, the UFRM method can simultaneously achieve image registration and SRR. A number of experiments were conducted, which confirmed the superior performance of the proposed method.","2151-1535","","10.1109/JSTARS.2020.2993629","National Key Research and Development Program of China(grant numbers:2018YFB0504500); National Natural Science Foundation of China(grant numbers:61871298,41571362); CRSRI Open Research Program(grant numbers:CKWV2018486/KY); National Natural Science Foundation of China(grant numbers:41571362,41711530709); Geomatics Technology and Application key Laboratory of Qinghai Province(grant numbers:QDXS-2017-01); National Natural Science Foundation of Hubei Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091255","Multiangle;multi/hyperspectral;registration;super-resolution;rank-one","Remote sensing;Image registration;Spatial resolution;Image reconstruction;Imaging;Correlation","geophysical image processing;hyperspectral imaging;image reconstruction;image registration;image resolution;minimisation;remote sensing","image observation model;foreground image;background image;unknown image registration transformation parameters;image reconstruction;joint super-resolution;multihyperspectral remote sensing images;unified framework based on rank minimization;image super-resolution reconstruction;SRR;mathematical degradation process;low-resolution multiangle images;high-resolution multihyperspectral image;rank-one structure;multichannel total variation constraint;minimization optimization strategy;joint cost function;UFRM method","","5","","49","CCBY","11 May 2020","","","IEEE","IEEE Journals"
"A New Deep Generative Network for Unsupervised Remote Sensing Single-Image Super-Resolution","J. M. Haut; R. Fernandez-Beltran; M. E. Paoletti; J. Plaza; A. Plaza; F. Pla","Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain","IEEE Transactions on Geoscience and Remote Sensing","28 Oct 2018","2018","56","11","6792","6810","Super-resolution (SR) brings an excellent opportunity to improve a wide range of different remote sensing applications. SR techniques are concerned about increasing the image resolution while providing finer spatial details than those captured by the original acquisition instrument. Therefore, SR techniques are particularly useful to cope with the increasing demand remote sensing imaging applications requiring fine spatial resolution. Even though different machine learning paradigms have been successfully applied in SR, more research is required to improve the SR process without the need of external high-resolution (HR) training examples. This paper proposes a new convolutional generator model to super-resolve low-resolution (LR) remote sensing data from an unsupervised perspective. That is, the proposed generative network is able to initially learn relationships between the LR and HR domains throughout several convolutional, downsampling, batch normalization, and activation layers. Then, the data are symmetrically projected to the target resolution while guaranteeing a reconstruction constraint over the LR input image. An experimental comparison is conducted using 12 different unsupervised SR methods over different test images. Our experiments reveal the potential of the proposed approach to improve the resolution of remote sensing imagery.","1558-0644","","10.1109/TGRS.2018.2843525","Ministerio de Educación (resolución de 26 de diciembre de 2014 y de 19 de noviembre de 2015, de la Secretaría de Estado de Educación, Formación Profesional y Universidades, por la que se convocan ayudas para la formación de profesorado universitario, de los subprogramas de Formación y de Movilidad incluidos en el Programa Estatal de Promoción del Talento y su Empleabilidad, en el marco del Plan Estatal de Investigación Científica y Técnica y de Innovación 2013–2016); Consejería de Educación y Empleo, Junta de Extremadura(grant numbers:GR15005); Generalitat Valenciana(grant numbers:APOSTD/2017/007); Spanish Ministry of Economy(grant numbers:ESP2016-79503-C2-2-P); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8400496","Convolutional neural networks (CNNs);remote sensing;super-resolution (SR)","Spatial resolution;Remote sensing;Image reconstruction;Data models;Imaging;Training","geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","high-resolution training examples;convolutional generator model;low-resolution remote sensing data;unsupervised perspective;target resolution;LR input image;remote sensing imagery;unsupervised remote sensing single-image super-resolution;SR techniques;image resolution;finer spatial details;original acquisition instrument;fine spatial resolution;SR process;test images;deep generative network;remote sensing imaging applications;machine learning paradigms;unsupervised SR methods","","104","","94","IEEE","29 Jun 2018","","","IEEE","IEEE Journals"
"A Multi-Task Architecture for Remote Sensing by Joint Scene Classification and Image Quality Assessment","C. Zhang; Q. Wang; X. Li","School of Computer Science and Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi’an, Shaanxi, P.R. China; School of Computer Science and Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi’an, Shaanxi, P.R. China; School of Computer Science and Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi’an, Shaanxi, P.R. China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","10055","10058","In this work, we propose a compact multi-task architecture based on deep learning for remote sensing scene classification and image quality assessment (IQA) simultaneously. The model can be trained in an end-to-end manner, and the robustness of classification is improved in our method. More importantly, by exploiting IQA and super-resolution, the accurate classification results can be obtained even if the images are distorted or with low quality. To the best of our knowledge, it is the first successful attempt to associate IQA with scene classification in a unified multi-task architecture. Our method is evaluated on the expanded UC Merced Land-Use dataset after data augmentation. In comparison with some other methods, the experimental results show that the proposed structure makes a great improvement on both classification and IQA.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898659","Remote sensing;scene classification;image quality assessment;image super-resolution;multi-task learning;deep learning","Remote sensing;Image quality;Task analysis;Computer architecture;Deep learning","geophysical image processing;image classification;image resolution;learning (artificial intelligence);remote sensing","joint scene classification;image quality assessment;compact multitask architecture;deep learning;remote sensing scene classification;IQA;accurate classification results;unified multitask architecture;super-resolution;expanded UC Merced land-use dataset;data augmentation","","1","","13","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Multi-Level Strategy-Based Spatial Information Prediction for Spatiotemporal Remote Sensing Imagery Fusion","J. Chen; R. Feng; L. Wang; W. Han; J. Huang","School of Computer Science, China University of Geosciences, Wuhan, P.R.China; School of Computer Science, China University of Geosciences, Wuhan, P.R.China; School of Computer Science, China University of Geosciences, Wuhan, P.R.China; School of Computer Science, China University of Geosciences, Wuhan, P.R.China; School of Computer Science, China University of Geosciences, Wuhan, P.R.China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","637","640","Spatiotemporal fusion utilizes the complementarity of high-temporal-low-spatial (HTLS) and high-spatial-low-temporal (HSLT) resolution data to obtain high temporal and spatial (HTHS) resolution fusion data, which can effectively satisfy the demand for HTHS data. However, due to the difference of spatial resolution, it is difficult to obtain precise spatial information in spatiotemporal fusion. To solve this problem, a multi-level strategy-based spatial domain prediction algorithm is proposed to enhance the spatial information extraction in spatiotemporal remote sensing imagery fusion, which can reduce the noise superposition in the process of multiple reconstruction. By learning-based first and then interpolation-based Super resolution reconstruction, the proposed method can obtain better prediction of spatial information and improve the accuracy of spatiotemporal fusion.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323312","National Natural Science Foundation of China(grant numbers:41571413,41701429,U1711266,41571413,41925007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323312","Spatiotemporal fusion;Super-resolution reconstruction;EDSR;TPS;Remote sensing","Spatial resolution;Remote sensing;Spatiotemporal phenomena;Superresolution;Image reconstruction;Interpolation;Reconstruction algorithms","geophysical image processing;image fusion;image processing;image reconstruction;image resolution;interpolation;remote sensing","multilevel strategy-based spatial information prediction;spatiotemporal remote sensing imagery fusion;spatiotemporal fusion;HTHS data;spatial resolution;precise spatial information;multilevel strategy-based spatial domain prediction algorithm;spatial information extraction;learning-based;interpolation-based Super resolution reconstruction","","","","17","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"A Deep Multitask Convolutional Neural Network for Remote Sensing Image Super-Resolution and Colorization","J. Feng; Q. Jiang; C. -H. Tseng; X. Jin; L. Liu; W. Zhou; S. Yao","School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China; School of Computer Science, The University of Manchester, Manchester, U.K.; School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China","IEEE Transactions on Geoscience and Remote Sensing","7 Apr 2022","2022","60","","1","15","Remote sensing data have become increasingly vital in target detection, disaster monitoring, and military surveillance. Abundant pan-sharpening and super-resolution (SR) methods based on deep learning have been proposed and have achieved remarkable performance. However, pan-sharpening requires paired panchromatic (PAN) and multispectral (MS) images, and SR cannot increase the spectral resolution of PAN. Thus, we introduce a computational imaging-based method to recover or produce the incomplete data of single PAN or MS. This work also explores the integration of multiple tasks by a single neural network. We start with SR and colorization, study the feasibility of simultaneously finishing SR colorization, and use a model trained in SR colorization to finish pan-sharpening without MS. A generic neural network, remote sensing image improvement network (RSI-Net), is designed for remote sensing image SR, colorization, simultaneous SR colorization, and pan-sharpening. To verify its performance, RSI-Net is compared with the state-of-the-art SR and colorization methods. Experiments show that RSI-Net can be competitive in visual effects and evaluation indexes, and it performs well at simultaneous SR colorization, and RSI-Net finishes pan-sharpening and only needs to input PAN. Our experiments confirm the effect of integrating multiple tasks.","1558-0644","","10.1109/TGRS.2022.3154435","National Natural Science Foundation of China(grant numbers:62101481,62002313,61863036,11861071); Key Areas Research Program of Yunnan Province in China(grant numbers:202001BB050076); Key Laboratory in Software Engineering of Yunnan Province(grant numbers:2020SE408); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721252","Convolutional neural network (CNN);deep learning (DL);image colorization;image super-resolution (SR);remote sensing image","Remote sensing;Task analysis;Neural networks;Image color analysis;Gray-scale;Sensors;Feature extraction","geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);neural nets;object detection;remote sensing","deep multitask convolutional neural network;remote sensing image super-resolution;remote sensing data;abundant pan-sharpening;deep learning;MS;computational imaging-based method;incomplete data;single PAN;single neural network;generic neural network;remote sensing image improvement network;remote sensing image SR;simultaneous SR colorization;state-of-the-art SR;colorization methods;RSI-Net finishes pan-sharpening;input PAN","","2","","41","CCBY","24 Feb 2022","","","IEEE","IEEE Journals"
"Dual-Branch Multiscale Channel Fusion Unfolding Network for Optical Remote Sensing Image Super-Resolution","M. Shi; Y. Gao; L. Chen; X. Liu","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Geoscience and Remote Sensing Letters","5 Dec 2022","2022","19","","1","5","Single-image super-resolution (SR) technology is critical in remote sensing fields because it can effectively improve the details of target images. However, the application of deep learning is limited due to the lack of interpretability and the need for many parameters. This letter proposes an interpretable dual-branch multiscale channel fusion unfolding network (DMUNet) for optical remote sensing image (ORSI) SR. We design an unfolding network with double branches, each optimized with different strategies. Two branches focus on texture and edge reconstruction, respectively. This unfolding network follows the iteration process of the alternating direction method of multipliers (ADMM) and can learn the hyper-parameters adaptively. The functions of the two branches can complement each other. Further, to better fuse the feature maps of the two branches, a multiscale fusion module is proposed. This module can effectively fuse information between different branches, scales, and channels. It is noted that it only requires a little computation cost. Experiments on two public ORSI datasets demonstrate that our method can achieve significant performance in both quantitative evaluation and visual results.","1558-0571","","10.1109/LGRS.2022.3221614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955482","Alternating direction method of multipliers (ADMM);dual-branch;optical remote sensing image (ORSI);super-resolution (SR);unfolding","Image edge detection;Image reconstruction;Remote sensing;Convolution;Tensors;Superresolution;Kernel","convex programming;geophysical image processing;image fusion;image reconstruction;image resolution;iterative methods;learning (artificial intelligence);remote sensing","ADMM;alternating direction method of multipliers;DMUNet;double branches;dual-branch multiscale channel fusion unfolding network;edge reconstruction;iteration process;multiscale fusion module;optical remote sensing image SR;optical remote sensing image super-resolution;public ORSI datasets;remote sensing fields;single-image super-resolution technology;target images;texture reconstruction","","","","18","IEEE","18 Nov 2022","","","IEEE","IEEE Journals"
"Remote sensing recognition of residential areas based on GF-4 satellite image","W. Wu; W. Liu","National Disaster Reduction Center of China, Ministry of Civil Affairs, Beijing, China; 12th department, Beijing Institute of Space Mechanics & Electricity, Beijing, China","2018 Fifth International Workshop on Earth Observation and Remote Sensing Applications (EORSA)","3 Jan 2019","2018","","","1","4","Residential area is an important place for human habitation and life. Using remote sensing technology to identify residential areas is of great value for land resources planning and utilization, disaster prevention and relief and other fields. As the world's first high resolution optical remote sensing satellite for geosynchronous orbit, GF-4 satellite has high time resolution, medium spatial resolution and multispectral land detection capability, which provides a new data resource for residential monitoring. Closely combining with the detection characteristics of the GF-4 satellite, this paper proposes a remote sensing identification method based on GF-4 satellite, and the recognition ability of the GF-4 satellite to the residential area is analyzed. The remote sensing recognition of residential areas is mainly divided into four steps. First, Super-resolution image enhancement technology is used to improve the spatial resolution of GF-4 satellite PMS image. Then, the resolution enhanced image is processed by geometric correction, radiometric calibration and atmospheric correction. Third, the existing land use and land cover data are selected as prior knowledge to select typical sample areas. Based on the spectral characteristics and spectral relationship of different objects in GF-4 satellite image, decision tree classification method is used to eliminate the obvious non-residential areas such as cloud, vegetation, water and shadow, so as to reduce the subsequent data processing and reduce the false recognition rate in residential area. Finally, SVM classifier is selected for the classification of residential areas. Taking GF-4 satellite data in Jiashan county as experiment, the result shows that the user accuracy of resident recognition by this method is 89.96%, which is significantly higher than that without resolution enhancement in the same method. Besides, the spatial scope of the county and township residents can be effectively identified in GF-4 enhanced image.","","978-1-5386-6642-5","10.1109/EORSA.2018.8598622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598622","GF-4;Residential area recognition;Remote sensing information extraction","Spatial resolution;Remote sensing;Satellites;Satellite broadcasting;Reflection;Image recognition","decision trees;disasters;geophysical image processing;image classification;image enhancement;land cover;land use;land use planning;remote sensing;support vector machines","residential area;GF-4 satellite image;remote sensing technology;disaster prevention;remote sensing identification method;remote sensing recognition;Super-resolution image enhancement technology;GF-4 satellite PMS image;resolution enhanced image;land cover data;nonresidential areas;GF-4 satellite data;GF-4 enhanced image;land use;decision tree classification method;residential monitoring;SVM classifier","","1","","7","IEEE","3 Jan 2019","","","IEEE","IEEE Conferences"
"A Recurrent Refinement Network for Satellite Video Super-Resolution","Y. Xiao; X. Su; Q. Yuan","School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3865","3868","Deep learning-based methods have shown superior performance in VSR tasks. However, satellite video frames are characterized by large width, low resolution, and lack of features. Consequently, the conventional VSR method is not suitable for satellite video. In this paper, a recurrent refinement network is proposed. Considering that the vast majority of remote sensing images belong to the static background, a single-image SR (SISR) method is first used to obtain high-resolution features for a specific target frame. To further complement the missing details, the network learns the complementary information enhanced by an Encoder-Decoder structure from adjacent frames to refine the results of SISR. To measure the contribution of different adjacent frames to the recovery of the target frame, a temporal attention mechanism is introduced in the final fusion stage. The experiment on the video data of Jilin-1 demonstrates the effectiveness of our method.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553281","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553281","Satellite video;super-resolution;deep learning","Learning systems;Satellites;Aggregates;Superresolution;Task analysis;Remote sensing","image classification;image fusion;image resolution;learning (artificial intelligence);remote sensing;video signal processing","recurrent refinement network;satellite video super-resolution;deep learning-based methods;VSR tasks;satellite video frames;conventional VSR method;remote sensing images;single-image SR method;high-resolution features;specific target frame;different adjacent frames;video data","","","","7","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Super-Resolution for Cross-Sensor Optical Remote Sensing Images","S. Ambudkar; R. Raj; K. Billa; R. Hukumchand","Pixxel.space, Bengaluru, Karnataka, India; Pixxel.space, Bengaluru, Karnataka, India; Pixxel.space, Bengaluru, Karnataka, India; Pixxel.space, Bengaluru, Karnataka, India","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1880","1883","Generative adversarial network (GAN) models are becoming popular in the field of remote sensing for generating high spatial resolution images from their low resolution versions. In this study, four models including two basic Super-resolution GAN models and two non-GAN Deep Learning models were trained and tested to achieve 2.5m, and 5m spatial resolution from their 10m spatial resolution satellite data. The comparison of results showed that the SRGAN model performed better than the other deep learning models. The performance metrics were also found to be consistent with available literature.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883182","Super-resolution;generative adversarial network;resolution enhancement","Deep learning;Satellites;Superresolution;Optical fiber networks;Generative adversarial networks;Optical imaging;Data models","geophysical image processing;image resolution;learning (artificial intelligence);remote sensing","low resolution versions;basic Super-resolution GAN models;nonGAN Deep Learning models;5m spatial resolution;10m spatial resolution satellite data;SRGAN model;cross-sensor optical remote sensing;generative adversarial network models;high spatial resolution images;size 2.5 m;size 10.0 m;size 5.0 m","","","","15","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Boosting Small Ship Detection in Optical Remote Sensing Images via Image Super-Resolution","L. Li; Z. Zhou; S. Cui","School of Automation, Beijing Institute of Technology, Beijing; School of Automation, Beijing Institute of Technology, Beijing; School of Automation, Beijing Institute of Technology, Beijing","2021 33rd Chinese Control and Decision Conference (CCDC)","30 Nov 2021","2021","","","1508","1512","Small ships in optical remote sensing images are hard to detect due to the lack of sufficient detail information. In this paper, we adopt the image super-resolution technology to solve this problem. Specifically, an effective super-resolution network is designed to generate clear super-resolution ship images from small blurry ones produced by the ship detector. Inspired by the idea of generative adversarial network (GAN), the super-resolution network is trained together with a discriminator network in an adversarial way, aiming at generating more realistic super-resolution images. Moreover, to eliminate false detections, the discriminator network is also used to distinguish ship and non-ship images via an additional classification branch. Experimental results demonstrate the effectiveness of the proposed method.","1948-9447","978-1-6654-4089-9","10.1109/CCDC52312.2021.9601674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9601674","Ship detection;Image super-resolution;Generative adversarial network","Training;Superresolution;Detectors;Optical detectors;Optical imaging;Generative adversarial networks;Boosting","image classification;image resolution;marine radar;object detection;radar imaging;remote sensing;ships","discriminator network;super-resolution images;false detections;nonship images;boosting small ship detection;optical remote sensing images;image super-resolution technology;super-resolution network;clear super-resolution ship images;ship detector;generative adversarial network","","","","16","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Multiple Frame Splicing and Degradation Learning for Hyperspectral Imagery Super-Resolution","C. Deng; X. Luo; W. Wang","School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","6 Oct 2022","2022","15","","8389","8401","Hyperspectral imagery (HSI) is an emerging remote sensing technology to discriminate different remote sensing objects. However, the HSI spatial resolution is relatively low due to the trade-off in restricted physical hardware and various imaging conditions, restricting the subsequent object detection applications. At present, the single hyperspectral super resolution (SHSR) strategy has encountered the bottleneck on more precise details extraction, and the fusion hyperspectral image super resolution (FHSR) strategy must need extra RGB/multispectral information, which is not suitable for general HSI usage. Also, both types of current strategies focus less on the multiple degradation causes of low spatial resolution. In this article, a step forward in designing a novel framework of multiple frame splicing strategy to greatly improve the SHSR quality, and applying multiple HSI degradation models to better fit the real degradation circumstance. Specifically, the framework is an end-to-end super resolution (SR) network that supersedes a single up-sampling module and removes complex attention residual model due to the same size of multiple splicing low-resolution input samples with high-resolution outputs. The effective framework will alleviate the vague at higher multiples, and accelerate the training convergence. Based on this framework, multiple degradation low-resolution samples can be simultaneously combined to fit better for the blind SR result. Concretely, the degradation focus on the blur, noise, compression, and their combinations to simulate the real degradation. Experimental results on three different hyperspectral datasets demonstrate that the proposed multiple frame splicing and degradation model (MFSDM) algorithm can significantly enhance the details in the recovered high-resolution hyperspectral images, and outperforms the state-of-the-art SHSR methods.","2151-1535","","10.1109/JSTARS.2022.3207777","National Natural Science Foundation of China(grant numbers:62171040); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9895316","Hyperspectral remote sensing;hyperspectral super resolution;image super resolution;multiple degradation super resolution;multiple frame super resolution","Hyperspectral imaging;Degradation;Superresolution;Spatial resolution;Interpolation;Splicing;Image reconstruction","geophysical image processing;hyperspectral imaging;image reconstruction;image resolution;object detection;remote sensing","low spatial resolution;multiple frame splicing strategy;SHSR quality;multiple HSI degradation models;degradation circumstance;end-to-end super resolution network;complex attention residual model;multiple splicing low-resolution input samples;high-resolution outputs;higher multiples;multiple degradation low-resolution samples;degradation focus;different hyperspectral datasets;degradation model algorithm;high-resolution hyperspectral images;degradation learning;hyperspectral imagery super-resolution;emerging remote sensing technology;different remote sensing objects;HSI spatial resolution;restricted physical hardware;imaging conditions;subsequent object detection applications;single hyperspectral super resolution strategy;precise details extraction;fusion hyperspectral image super resolution strategy;general HSI usage;current strategies","","","","67","CCBYNCND","19 Sep 2022","","","IEEE","IEEE Journals"
"Satellite Video Super-Resolution via Multiscale Deformable Convolution Alignment and Temporal Grouping Projection","Y. Xiao; X. Su; Q. Yuan; D. Liu; H. Shen; L. Zhang","School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Resource and Environmental Sciences, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","28 Jan 2022","2022","60","","1","19","As a new earth observation tool, satellite video has been widely used in remote-sensing field for dynamic analysis. Video super-resolution (VSR) technique has thus attracted increasing attention due to its improvement to spatial resolution of satellite video. However, the difficulty of remote-sensing image alignment and the low efficiency of spatial–temporal information fusion make poor generalization of the conventional VSR methods applied to satellite videos. In this article, a novel fusion strategy of temporal grouping projection and an accurate alignment module are proposed for satellite VSR. First, we propose a deformable convolution alignment module with a multiscale residual block to alleviate the alignment difficulties caused by scarce motion and various scales of moving objects in remote-sensing images. Second, a temporal grouping projection fusion strategy is proposed, which can reduce the complexity of projection and make the spatial features of reference frames play a continuous guiding role in spatial–temporal information fusion. Finally, a temporal attention module is designed to adaptively learn the different contributions of temporal information extracted from each group. Extensive experiments on Jilin-1 satellite video demonstrate that our method is superior to current state-of-the-art VSR methods.","1558-0644","","10.1109/TGRS.2021.3107352","National Natural Science Foundation of China(grant numbers:41922008,61971319); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530280","Deformable convolution;satellite video;super-resolution (SR);temporal attention (TA);temporal grouping projection","Satellites;Convolution;Optical imaging;Remote sensing;Image reconstruction;Spatial resolution;Optical sensors","feature extraction;image classification;image fusion;image resolution;remote sensing;video signal processing","satellite video super-resolution;multiscale deformable convolution alignment;earth observation tool;remote-sensing field;video super-resolution technique;spatial resolution;remote-sensing image alignment;spatial-temporal information fusion;conventional VSR methods;accurate alignment module;satellite VSR;deformable convolution alignment module;alignment difficulties;remote-sensing images;temporal grouping projection fusion strategy;temporal attention module;Jilin-1 satellite video;current state-of-the-art VSR methods","","11","","66","IEEE","6 Sep 2021","","","IEEE","IEEE Journals"
"Super-Resolution Imaging for Real Aperture Radar by Two-Dimensional Deconvolution","X. Tuo; Y. Xia; Y. Zhang; J. Zhu; Y. Zhang; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","6630","6633","Real aperture super-resolution (RAS) technology is widely used in the field of radar forward-looking imaging. However, traditional RAS technology is based on the space-to-ground scanning mode. The essence of this technology is azimuth (angle) super-resolution, which is a one-dimensional super-resolution technology. In our work, we consider applying RAS technology to the space-to-space scanning. In this mode, we regard the echo of each range slice as the convolution of the target scattering coefficient distribution and the antenna pattern function. Its essence is azimuth and pitch super-resolution, which is a two-dimensional super-resolution technology. Finally, a reasonable objective function is constructed under the framework of regularization, and the ADMM solver is used to achieve two-dimensional super-resolution imaging. Simulations will prove the effectiveness of the proposed two-dimensional super-resolution algorithm.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554992","National Natural Science Foundation of China(grant numbers:61901090,61671117,61901092); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554992","Radar forward-looking imaging;real aperture super-resolution;two-dimensional super-resolution","Radar remote sensing;Deconvolution;Azimuth;Superresolution;Imaging;Scattering;Radar","deconvolution;electromagnetic wave scattering;image reconstruction;image resolution;iterative methods;radar antennas;radar imaging;radar resolution","pitch super-resolution;ADMM solver;angle super-resolution;radar forward-looking imaging;real aperture super-resolution technology;two-dimensional super-resolution algorithm;two-dimensional super-resolution imaging;two-dimensional super-resolution technology;antenna pattern function;target scattering coefficient distribution;space-to-space scanning;RAS technology;one-dimensional super-resolution technology;azimuth super-resolution;space-to-ground scanning mode;two-dimensional deconvolution;real aperture radar","","2","","8","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Adaptive Channel Attention and Feature Super-Resolution for Remote Sensing Images Spatiotemporal Fusion","S. Fang; S. Meng; Y. Cao; J. Zhang; W. Shi","Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data (Hefei University of Technology), Ministry of Education, Hefei, China; University of Science and Technology of China, Hefei, Anhui, China; Key Laboratory of Knowledge Engineering with Big Data (Hefei University of Technology), Ministry of Education, Hefei, China; Macau University of Science and Technology, Macau, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2572","2575","CNN-based Spatiotemporal image fusion (STIF) methods have achieved better performance than traditional researches. However, most CNN-based methods fail to make full use of hierarchical features, and ignore the quality and distribution characteristics of feature maps in fine-grained STIF. In this paper, we propose a network with channel attention and feature super-resolution for STIF (CAFSRNet). First, our method uses the low resolution time-domain changing images as input to extract changes more accurately and simplify computational overhead. Second, channel attention mechanism is introduced into Cross-spatial Resolution Mapping module to make the network pay more attention to informative features. Third, by adding feature super-resolution into the supervision process, we enhance the distribution of feature maps and the quality of mapping results. The qualitative and quantitative experimental results on various datasets demonstrate the superiority of our proposed method over the state-of-the-art methods.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9555093","National Key R&D Program of China(grant numbers:2018YFC0213104); National Natural Science Foundation of China(grant numbers:61872327,61175033); Fundamental Research Funds for the Central Universities(grant numbers:WK2380000001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555093","Spatiotemporal image fusion;learning-based;Convolutional neural network (CNN);channel attention;feature super-resolution","Superresolution;Neural networks;Visual effects;Feature extraction;Spatiotemporal phenomena;Indexes;Time-domain analysis","feature extraction;geophysical image processing;image fusion;image resolution;remote sensing;spatiotemporal phenomena","fine-grained STIF;feature super-resolution;low resolution time-domain changing images;channel attention mechanism;Cross-spatial Resolution Mapping module;network pay more attention;informative features;feature maps;adaptive channel attention;remote sensing images Spatiotemporal;CNN-based Spatiotemporal image fusion methods;CNN-based methods;hierarchical features","","","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Super-Resolution of Single Remote Sensing Image Based on Residual Dense Backprojection Networks","Z. Pan; W. Ma; J. Guo; B. Lei","Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","25 Sep 2019","2019","57","10","7918","7933","High-resolution (HR) images are always preferred for many remote sensing applications, which can be obtained from their low-resolution (LR) counterparts via a technique referred to as super-resolution (SR). Among SR approaches, single image SR (SISR) methods aim at reconstructing the HR image from only one LR image. In this paper, a residual dense backprojection network (RDBPN)-based SISR method is proposed to promote the resolution of RGB remote sensing images with median- and large-scale factors. The proposed network consists of several residual dense backprojection blocks that contain two kinds of modules, named the upprojection module and the downprojection module, and these modules are densely connected in one block. Different from the chain-connected backprojection structure, the proposed method applies a residual backprojection block structure, which can utilize residual learning in both global and local manners. We further simplify the network by replacing the downprojection unit with the downscaling unit to accelerate the speed of reconstruction, and this implementation is called fast RDBPN (FRDBPN). Several experiments under the UC Merced data set are conducted to validate the effectiveness of the proposed method, and the results indicate that: 1) the proposed residual block structure is superior to the chain-connected structure; 2) FRDBPN achieves a speedup of about 1.3 times with similar and even better-reconstructed performance in comparison with RDBPN; and 3) RDBPN and FRDBPN outperform several state-of-the-art methods in terms of both quantitative evaluation and visual quality.","1558-0644","","10.1109/TGRS.2019.2917427","National Natural Science Foundation of China(grant numbers:61701478); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8732688","Convolutional neural networks (CNNs);dense backprojection blocks;remote sensing images;residual learning;single image super-resolution (SISR)","Remote sensing;Image reconstruction;Spatial resolution;Image edge detection;Periodic structures;Learning systems","feature extraction;geophysical image processing;image classification;image reconstruction;image resolution;remote sensing","residual dense backprojection blocks;upprojection module;downprojection module;chain-connected backprojection structure;residual backprojection block structure;residual learning;residual block structure;chain-connected structure;RDBPN;super-resolution;single remote sensing image;residual dense backprojection networks;high-resolution images;remote sensing applications;low-resolution counterparts;SR approaches;single image SR methods;HR image;LR image;residual dense backprojection network-based SISR method;RGB remote sensing images","","50","","64","IEEE","6 Jun 2019","","","IEEE","IEEE Journals"
"Inter-Sensor Remote Sensing Image Enhancement for Operational Sentinel-2 and Sentinel-3 Data Products","R. Fernandez; R. Fernandez-Beltran; F. Pla","Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1504","1507","The recent availability of operational data from the Sentinel-2 and Sentinel-3 missions provides widespread opportunities to generate diverse high-level remote sensing products. However, the synergies between both multi-spectral instruments are often difficult to exploit from an operational perspective. Standard pansharpening algorithms may encounter important disadvantages due to the limited intersensor data availability in actual production environments. Moreover, the lack of a real high-resolution ground-truth for super-resolution techniques may affect the radiometric quality of the final result. In this scenario, this work investigates the viability of using the Multi-Spectral Instrument of Sentinel-2 for super-resolving data products acquired by the Ocean and Land Colour Instrument of Sentinel-3. Specifically, we define an inter-sensor image enhancement framework which combines a PCA-based component substitution pansharpening scheme with a CNN-based spatial enhancing super-resolution mapping. The conducted experiments reveal the suitability of the proposed approach for generating Level-4 data products within the Copernicus programme context.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324071","Sentinel-2 (S2);Sentinel-3 (S3);super-resolution (SR);pansharpening;image fusion","Spatial resolution;Pansharpening;Principal component analysis;Instruments;Remote sensing;Image enhancement;Superresolution","geophysical image processing;image enhancement;image fusion;image resolution;remote sensing;terrain mapping","inter-sensor remote sensing image enhancement;operational Sentinel-2;Sentinel-3 data products;recent availability;operational data;Sentinel-3 missions;diverse high-level remote sensing products;multispectral instruments;operational perspective;standard pansharpening algorithms;intersensor data availability;actual production environments;high-resolution ground-truth;super-resolution techniques;MultiSpectral Instrument;inter-sensor image enhancement framework;super-resolution mapping;Level-4 data products","","","","10","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Multilayer Degradation Representation-Guided Blind Super-Resolution for Remote Sensing Images","X. Kang; J. Li; P. Duan; F. Ma; S. Li","School of Robotics, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China","IEEE Transactions on Geoscience and Remote Sensing","3 Aug 2022","2022","60","","1","12","Remote sensing image super-resolution (SR) aims to boost the image resolution while recovering rich high-frequency details. Currently, most of the SR methods are based on an assumption that the degradation kernel is a specific downsampler. However, the degradation kernel is unknown and sophisticated for real remote sensing scenes, leading to a severe performance drop. To alleviate this problem, we propose a multilayer degradation representation-guided blind SR method for remote sensing images, which mainly consists of three key steps. First, an unsupervised representation learning is exploited to learn the degradation representation from low-resolution images. Then, a degradation-guided deep residual module is designed to model high-order features across different scales from the original images. Finally, a multilayer degradation-aware feature fusion mechanism is proposed to restore the finer details. Experiments on synthetic and real datasets demonstrate that the proposed method can achieve promising performance with respect to other state-of-the-art SR approaches.","1558-0644","","10.1109/TGRS.2022.3192680","National Key Research and Development Program of China(grant numbers:2021YFA0715203); Major Program of the National Natural Science Foundation of China(grant numbers:61890962); National Natural Science Foundation of China(grant numbers:61871179); Scientific Research Project of Hunan Education Department(grant numbers:19B105); National Science Foundation of Hunan Province(grant numbers:2019JJ50036,2020GK2038); Hunan Provincial Natural Science Foundation for Distinguished Young Scholars(grant numbers:2021JJ022); Huxiang Young Talents Science and Technology Innovation Program(grant numbers:2020RC3013); Changsha Natural Science Foundation(grant numbers:kq2202171); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833534","Blind super-resolution (SR);degradation-guided feature extraction;multilayer feature fusion;remote sensing image;representation learning","Degradation;Feature extraction;Superresolution;Remote sensing;Kernel;Image reconstruction;Imaging","deep learning (artificial intelligence);feature extraction;geophysical image processing;image fusion;image reconstruction;image representation;image resolution;remote sensing;unsupervised learning","multilayer degradation representation-guided blind super-resolution;remote sensing image super-resolution;SR methods;degradation kernel;unsupervised representation learning;degradation-guided deep residual module;multilayer degradation-aware feature fusion mechanism","","","","57","IEEE","20 Jul 2022","","","IEEE","IEEE Journals"
"Contextual Transformation Network for Lightweight Remote-Sensing Image Super-Resolution","S. Wang; T. Zhou; Y. Lu; H. Di","Beijing Laboratory of Intelligent Information Technology, School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Computer Vision Laboratory, ETH Zurich, Zurich, Switzerland; Beijing Laboratory of Intelligent Information Technology, School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Beijing Laboratory of Intelligent Information Technology, School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","28 Feb 2022","2022","60","","1","13","Current super-resolution networks typically reduce network parameters and multiadds operations by designing lightweight structures, but lightening the convolution layer is often ignored. In this work, we observe that  $3 \times 3$  convolutions occupy a high percentage of network parameters in most lightweight super-resolution networks. This motivates us to consider lightening super-resolution networks by replacing  $3 \times 3$  convolutions with lightweight convolutions, while maintaining the performance. To achieve this, we propose a lightweight convolution layer named contextual transformation layer (CTL). It can yield efficient contextual features through a context feature extraction module and enrich extracted contextual features through a context feature transformation module. Based on CTLs, we build a lightweight super-resolution network called contextual transformation network (CTN) for remote-sensing image super-resolution. Specifically, we use two CTLs to construct a contextual transformation block (CTB) for hierarchical feature learning. Interleaved with a CTB, a context enhancement module (CEM) is employed to enhance the extracted feature representations. All extracted features are processed by a contextual feature aggregation module for final remote-sensing image super-resolution. Extensive experiments are performed on a remote-sensing image super-resolution benchmark named UC Merced. Our method achieves superior results to the other state-of-the-art methods. To demonstrate the generalization ability of our CTL, we extend our CTN to two relevant tasks: natural image super-resolution and natural image denoising. Experimental results on natural image super-resolution benchmarks (i.e., Set5, Set14, B100, Urban100, and Manga109) and natural image denoising benchmarks (i.e., SIDD and DND) further prove the superiority of our method. Our code is publicly available at https://github.com/BITszwang/CTNet.","1558-0644","","10.1109/TGRS.2021.3132093","National Natural Science Foundation of China(grant numbers:61273273); National Key Research and Development Plan(grant numbers:2017YFC0112001); China Central Television(grant numbers:JG2018-0247); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9632567","Contextual feature learning;image super-resolution;lightweight neural network;remote sensing","Feature extraction;Superresolution;Convolution;Remote sensing;Task analysis;Image reconstruction;Benchmark testing","feature extraction;image denoising;image enhancement;image representation;image resolution;learning (artificial intelligence);neural nets","context feature transformation module;contextual transformation network;contextual transformation block;contextual feature aggregation module;remote-sensing image super-resolution;network parameters;lightweight convolution layer;contextual transformation layer;context feature extraction module;feature representations extraction;CTL;CTN;context enhancement module;CEM;hierarchical feature learning;natural image super-resolution;natural image denoising","","9","","84","IEEE","1 Dec 2021","","","IEEE","IEEE Journals"
"Hierarchical Feature Aggregation and Self-Learning Network for Remote Sensing Image Continuous-Scale Super-Resolution","N. Ni; H. Wu; L. Zhang","School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China","IEEE Geoscience and Remote Sensing Letters","10 Jan 2022","2022","19","","1","5","Conducting research on remote sensing image (RSI) super-resolution (SR) is important, especially in terms of the continuous scale, which is beneficial to the application of RSI, such as RSI object detection and data fusion. Continuous-scale SR aims to use a single model to achieve SR at arbitrary (integer and noninteger) scale factors. Therefore, in this letter, we propose a hierarchical feature aggregation and self-learning network for RSI continuous-scale SR (RSI-HFAS). Our network can magnify the RSI continuously, which is beneficial for extracting the RSI multiscale features. First, we design a hierarchical feature aggregation module (HFAM) that is used for hierarchical feature extraction by placing convolutional layers on different floors and completing global feature fusion, which is crucial for achieving RSI continuous-scale SR with a single model. Second, the proposed network introduces a feedback mechanism, which can refine the hierarchical feature through feature feedback and enrich the texture parts of the RSI step by step. Finally, we design a self-learning upscaling structure to dynamically predict the number and weights of the upsampling filters, which can achieve RSI continuous-scale SR. Compared to the meta-learning based on enhanced deep SR (META-EDSR) method, our experimental results show a nearly 0.2-dB improvement on the metrics of the peak signal-to-noise ratio (PSNR).","1558-0571","","10.1109/LGRS.2021.3122985","National Natural Science Foundation of China(grant numbers:61571050,41771407); Beijing Natural Science Foundation(grant numbers:L182029); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585484","Continuous-scale;feedback mechanism;hierarchical feature;remote sensing image (RSI);super-resolution (SR)","Feature extraction;Image reconstruction;Convolution;Task analysis;Superresolution;Remote sensing;Training","feature extraction;geophysical image processing;image fusion;image resolution;image sampling;image sequences;image texture;learning (artificial intelligence);object detection;remote sensing;sensor fusion","RSI continuous-scale SR;self-learning network;remote sensing image continuous-scale super-resolution;remote sensing image super-resolution;continuous scale;data fusion;RSI-HFAS;RSI continuously;RSI multiscale features;hierarchical feature aggregation module;hierarchical feature extraction;different floors;completing global feature fusion;RSI step","","2","","15","IEEE","26 Oct 2021","","","IEEE","IEEE Journals"
"Adaptive Super-Resolution for Remote Sensing Images Based on Sparse Representation With Global Joint Dictionary Model","B. Hou; K. Zhou; L. Jiao","Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education of China, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education of China, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education of China, Xidian University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","23 Mar 2018","2018","56","4","2312","2327","Sparse representation has been widely used in the field of remote sensing image super-resolution (SR) to restore a high-quality image from a low-resolution (LR) image, e.g., from the blurred and downsampled version of an LR image's high-resolution (HR) counterpart. It is well known that each image patch can be represented by a linear combination of the atoms of an overcomplete dictionary, and we can obtain an expression of sparse coefficients by l1 norm regularization. Owing to the lack of an inner relationship between image patches and an image's global information, the traditional methods of jointly training two overcomplete dictionaries cannot obtain good SR results. Therefore, we propose an effective approach for remote sensing image SR based on sparse representation. More specifically, a novel global joint dictionary model (GJDM) is used to explore the prior knowledge of images, including local and global characteristics. First, we train two dictionaries for detail image patches and HR patches. Second, in order to enhance the inner relationship between image patches, we introduce a global self-compatibility model for global regularization. Finally, the sparse representation and the local and nonlocal constraints are integrated to improve the performance of the model, and the fast adaptive shrinkage-thresholding algorithm is employed to solve the convex optimization problem in the GJDM. Compared with other methods, the results of the proposed method show good SR performance in preserving details and texture information and significant improvement in a peak signal-to-noise ratio.","1558-0644","","10.1109/TGRS.2017.2778191","National Natural Science Foundation of China(grant numbers:61671350,61173090,61072106,61271302); National Research Foundation for the Doctoral Program of Higher Education of China(grant numbers:20130203110009); National Basic Research Program (973 Program) of China(grant numbers:2013CB329402); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8197387","Fast adaptive shrinkage-thresholding algorithm (FASTA);global joint dictionary model (GJDM);remote sensing images;sparse representation;super-resolution (SR)","Dictionaries;Adaptation models;Remote sensing;Interpolation;Image reconstruction;Image edge detection;Image resolution","convex programming;geophysical image processing;image representation;image resolution;image restoration;image texture;remote sensing","global joint dictionary model;local characteristics;global characteristics;detail image patches;global self-compatibility model;global regularization;sparse representation;adaptive super-resolution;remote sensing image super-resolution;LR image;overcomplete dictionary;sparse coefficients;high-quality image restoration;low-resolution image;l1 norm regularization;image global information;HR patches;nonlocal constraints;fast adaptive shrinkage-thresholding algorithm;convex optimization problem;texture information;peak signal-to-noise ratio;GJDM","","35","","59","IEEE","13 Dec 2017","","","IEEE","IEEE Journals"
"An Unsupervised Remote Sensing Single-Image Super-Resolution Method Based on Generative Adversarial Network","N. Zhang; Y. Wang; X. Zhang; D. Xu; X. Wang","School of Optoelectronics, University of Chinese Academy of Sciences, Beijing, China; Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, China; School of Optoelectronics, University of Chinese Academy of Sciences, Beijing, China; School of Optoelectronics, University of Chinese Academy of Sciences, Beijing, China; Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, China","IEEE Access","14 Feb 2020","2020","8","","29027","29039","Image super-resolution (SR) technique can improve the spatial resolution of images without upgrading the imaging system. As a result, SR promotes the development of high resolution (HR) remote sensing image applications. Many remote sensing image SR algorithms based on deep learning have been proposed recently, which can effectively improve the spatial resolution under the constraints of HR images. However, images acquired by remote sensing imaging devices typically have lower resolution. Hence, an insufficient number of HR remote sensing images are available for training deep neural networks. In view of this problem, we propose an unsupervised SR method that does not require HR remote sensing images. The proposed method introduces a generative adversarial network (GAN) that obtains SR images through the generator; then, the SR images are downsampled to train the discriminator with low resolution (LR) images. Our method outperformed several methods in terms of the quality of the obtained SR images as measured by 6 evaluation metrics, which proves the satisfactory performance of the proposed unsupervised method for improving the spatial resolution of remote sensing images.","2169-3536","","10.1109/ACCESS.2020.2972300","National Natural Science Foundation of China(grant numbers:11703027); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8986554","Image super-resolution;unsupervised learning;remote sensing;generative adversarial network","Remote sensing;Image reconstruction;Generative adversarial networks;Training;Gallium nitride","convolutional neural nets;geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","HR remote sensing images;generative adversarial network;SR images;spatial resolution;unsupervised remote sensing single-image super-resolution method;super-resolution technique;imaging system;high resolution remote sensing image applications;remote sensing image SR algorithms;HR images;remote sensing imaging devices;unsupervised SR method","","10","","90","CCBY","7 Feb 2020","","","IEEE","IEEE Journals"
"Nonpairwise-Trained Cycle Convolutional Neural Network for Single Remote Sensing Image Super-Resolution","H. Zhang; P. Wang; Z. Jiang","Beijing Key Laboratory of Digital Media, Beihang University, Beijing, China; Beijing Key Laboratory of Digital Media, Beihang University, Beijing, China; Beijing Key Laboratory of Digital Media, Beihang University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","21 Apr 2021","2021","59","5","4250","4261","Single image super-resolution (SISR) is to recover the high spatial resolution image from a single low spatial resolution one, which is a useful procedure for many remote sensing applications. Most previous convolutional neural network (CNN)-based methods adopt supervised learning. However, paired high-resolution and low-resolution remote sensing images are actually hard to acquire for supervised learning SR methods. To handle this problem, we propose a novel cycle convolutional neural network (Cycle-CNN). Our network consists of two generative CNNs for down-sampling and SR separately and can be trained with unpaired data. We perform comprehensive experiments on panchromatic and multispectral images of the GaoFen-2 satellite and the UC Merced land use data set. Experimental results indicate that our method achieves state-of-the-art CNN-based SR results and is robust against noise and blur in remote sensing images. Comprehensively considering super-resolved image quality and time costs, our proposed method outperforms the compared learning-based SISR approaches.","1558-0644","","10.1109/TGRS.2020.3009224","National Key Research and Development Program of China(grant numbers:2016YFB0501300,2016YFB0501302,2019YFC1510905); National Natural Science Foundation of China(grant numbers:61501009); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9151194","Convolutional neural network (CNN);nonpairwise training;remote sensing image;super-resolution (SR)","Remote sensing;Image reconstruction;Spatial resolution;Training;Signal resolution;Image sensors","convolutional neural nets;geophysical image processing;image resolution;image sampling;learning (artificial intelligence);remote sensing","single remote sensing image super-resolution;remote sensing applications;supervised learning SR methods;cycle-CNN;panchromatic images;multispectral images;UC Merced land use data;image quality;nonpairwise-trained cycle convolutional neural network;high spatial resolution image recovery;generative CNN;down-sampling;GaoFen-2 satellite;super-resolved image quality","","8","","53","IEEE","28 Jul 2020","","","IEEE","IEEE Journals"
"DASRSNet: Multitask Domain Adaptation for Super-Resolution-Aided Semantic Segmentation of Remote Sensing Images","Y. Cai; Y. Yang; Y. Shang; Z. Shen; J. Yin","College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Zhejiang University–Deqing Institute of Advanced Technology and Industrialization, Deqing, China; Zhejiang University–Deqing Institute of Advanced Technology and Industrialization, Deqing, China; Institute for New Urbanization Studies, Huzhou, China","IEEE Transactions on Geoscience and Remote Sensing","5 Jan 2023","2023","61","","1","18","Unsupervised domain adaptation (UDA) has become an important technique for cross-domain semantic segmentation (SS) in the remote sensing community and obtained remarkable results. However, when transferring from high-resolution (HR) remote sensing images to low-resolution (LR) images, the existing UDA frameworks always fail to segment the LR target images, especially for small objects (e.g., cars), due to the severe spatial resolution shift problem. In this article, to improve the segmentation ability of UDA models for LR target images and small objects, we propose a novel multitask domain adaptation network (DASRSNet) for SS of remote sensing images with the aid of super-resolution (SR). The proposed DASRSNet contains domain adaptation for SS (DASS) branch, domain adaptation for SR (DASR) branch, and feature affinity (FA) module. Specifically, the DASS and DASR branches share the same encoder to extract the domain-invariant features for the target and source domains, and these two branches utilize different decoders and discriminators to conduct cross-domain SS task and SR task, which align the domain shift in output space and image space, respectively. Finally, the FA module, which involves the proposed FA loss, is applied to enhance the affinity of SS features and SR features for both source and target domains. The experimental results on the cross-city aerial datasets demonstrate the effectiveness and superiority of our DASRSNet against the recent UDA models.","1558-0644","","10.1109/TGRS.2022.3232129","National Natural Science Foundation of China(grant numbers:61825205); Key Research and Development Program of Zhejiang Province, China(grant numbers:2021C01017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9999252","Adversarial learning;multitask learning (MTL);remote sensing images;semantic segmentation (SS);super-resolution (SR);unsupervised domain adaptation (UDA)","Remote sensing;Spatial resolution;Feature extraction;Adaptation models;Task analysis;Semantic segmentation;Multitasking","feature extraction;geophysical image processing;image classification;image resolution;image segmentation;learning (artificial intelligence);remote sensing","cross-domain semantic segmentation;cross-domain SS task;DASRSNet;domain shift;domain-invariant features;existing UDA frameworks;image space;low-resolution images;LR target images;novel multitask domain adaptation network;output space;remote sensing community;remote sensing images;segmentation ability;severe spatial resolution shift problem;source domains;SR branch;SS branch;SS features;super-resolution-aided semantic segmentation;target domains;unsupervised domain adaptation","","","","53","IEEE","26 Dec 2022","","","IEEE","IEEE Journals"
"A universal remote sensing image quality improvement method with deep learning","Y. Wei; Q. Yuan; H. Shen; L. Zhang","Survey Mapping and Remote Sensing, Wuhan University, P.R. Chinay; School of Geodesy and Geomatics, Wuhan University, P.R. China; School of Resource and Environmental Sciences, Wuhan University, P.R. China; Survey Mapping and Remote Sensing, Wuhan University, P.R. Chinay","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","6950","6953","In this paper, we introduced a deep learning model: Convolutional neural network(CNN) from the field of natural image classification and restoration, to solve general quality improving tasks for remote sensing images, including super-resolution, denoising and haze removal. To take advantage of the content similarity among aerial images and the learning ability of deep learning models, we proposed the idea of training CNN on datasets collected from aerial images with specific degenerating factors, then apply the model to matched tasks. Experiments showed that our network achieved superior performance in quantified results, and visually reconstructed a satisfying majority of missing details from low-quality observations.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730813","Convolutional neural network;image restoration;single image super-resolution;blind denoising;non-uniform haze removal","Image restoration;Machine learning;Training;Remote sensing;Spatial resolution;Noise reduction","geophysical image processing;image classification;image denoising;image restoration;learning (artificial intelligence);neural nets;remote sensing","remote sensing image quality improvement method;deep learning model;convolutional neural network;image classification;image restoration;image denoising;haze removal;aerial images","","1","","15","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Transformer-Based Multistage Enhancement for Remote Sensing Image Super-Resolution","S. Lei; Z. Shi; W. Mo","AVIC Chengdu Aircraft Industrial (Group) Company Ltd., Chengdu, China; Image Processing Center, School of Astronautics, the Beijing Key Laboratory of Digital Media, and the State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; AVIC Chengdu Aircraft Industrial (Group) Company Ltd., Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","1 Mar 2022","2022","60","","1","11","Convolutional neural networks have made a great breakthrough in recent remote sensing image super-resolution (SR) tasks. Most of these methods adopt upsampling layers at the end of the models to perform enlargement, which ignores feature extraction in the high-dimension space, and thus, limits SR performance. To address this problem, we propose a new SR framework for remote sensing images to enhance the high-dimensional feature representation after the upsampling layers. We name the proposed method as a transformer-based enhancement network (TransENet), where transformers are introduced to exploit features at different levels. The core of the TransENet is a transformer-based multistage enhancement structure, which can be combined with traditional SR frameworks to fuse multiscale high-/low-dimension features. Specifically, in this structure, the encoders aim to embed the multilevel features in the feature extraction part and the decoders are used to fuse these encoded embeddings. Experimental results demonstrate that our proposed TransENet can improve super-resolved results and obtain superior performance over several state-of-the-art methods.","1558-0644","","10.1109/TGRS.2021.3136190","National Key Research and Development Program of China(grant numbers:2019YFC1510905); National Natural Science Foundation of China(grant numbers:62125102); Beijing Natural Science Foundation(grant numbers:4192034); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9654169","Deep convolutional neural networks (CNNs);remote sensing images;super-resolution (SR);transformer","Feature extraction;Transformers;Remote sensing;Convolution;Finite element analysis;Task analysis;Decoding","convolutional neural nets;feature extraction;geophysical image processing;image enhancement;image representation;image resolution;remote sensing","recent remote sensing image super-resolution tasks;SR performance;SR framework;remote sensing images;high-dimensional feature representation;transformer-based enhancement network;TransENet;transformer-based multistage enhancement structure;traditional SR frameworks;multilevel features;feature extraction part;convolutional neural networks","","3","","53","IEEE","16 Dec 2021","","","IEEE","IEEE Journals"
"Remote Sensing Image Super-Resolution Using Second-Order Multi-Scale Networks","X. Dong; L. Wang; X. Sun; X. Jia; L. Gao; B. Zhang","College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; Key Laboratory of Digital Earth Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; School of Engineering and Information Technology, University of New South Wales, Canberra, ACT, Australia; Key Laboratory of Digital Earth Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; College of Resources and Environment, University of Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","24 Mar 2021","2021","59","4","3473","3485","Remotely sensed images, especially in urban areas, have highly complex spatial distribution, since the ground objects have diverse ranges of sizes and shapes. This largely increases the difficulty of super-resolution (SR) tasks. Current deep convolutional neural network (CNN)-based SR methods often show limited performance when coping with complicated images. This article develops a second-order multi-scale super-resolution network (SMSR) to explore reconstruction tasks for difficult cases. Specifically, we propose a single-path feature reuse which cleverly captures multi-scale feature information through aggregating the features learned at different depths of a single path. Further, we present a second-order learning mechanism, which double reuses small-difference and large-difference features at local and global levels, makes use of the learned multi-scale information at maximum. The proposed methods achieve multi-scale learning using small-size convolution only, resulting in a lightweight and high-performance SR network. Experimental results show the superiority of our SMSR over state-of-the-art methods in super-resolving complicated image patterns. The effectiveness of SMSR is also demonstrated through its support to object recognition task.","1558-0644","","10.1109/TGRS.2020.3019660","National Natural Science Foundation of China(grant numbers:91638201,41722108); National Key Research and Development Program of China(grant numbers:2016YFB0501501); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9194276","Feature reuse;multi-scale;remote sensing image;second-order;super-resolution (SR)","Remote sensing;Image reconstruction;Spatial resolution;Convolution;Feature extraction;Task analysis","convolutional neural nets;geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);object recognition;remote sensing","remote sensing image super-resolution;multiscale information learning;complicated image patterns;high-performance SR network;lightweight performance SR network;small-size convolution;second-order learning mechanism;multiscale feature information;single-path feature reuse;reconstruction tasks;SMSR;second-order multiscale super-resolution network;complicated images;deep convolutional neural network;highly complex spatial distribution;urban areas","","20","","54","IEEE","10 Sep 2020","","","IEEE","IEEE Journals"
"Generative-Network Based Multimedia Super-Resolution for Uav Remote Sensing","Y. Turkar; C. Aluckal; S. De; V. Turkar; Y. Agarwadkar","University at Buffalo, SUNY, Buffalo, NY, USA; InfiCorridor Solutions Pvt. Ltd.; Capella Space; Don Bosco College of Engineering, Goa, India; InfiCorridor Solutions Pvt. Ltd.","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","527","530","Unmanned Aerial Vehicle (UAV) based aerial mapping has taken over the surveying industry thanks to low costs and ease of use. Although these UAVs have relatively high-resolution imaging systems, there exists a near exponential relationship between the ground sampling distance (GSD) and the number of images required - which is a function of flight altitude. To tackle this, we use a generative network based super-resolution approach to increase the GSD of images which effectively reduces flight time. In this paper we test the efficiency and efficacy of this approach using two multimedia super-resolution implementations. We also provide quantitative results comparing the two using various image processing metrics.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884486","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884486","Introduction;Methodology;Results;Conclusion;References","Measurement;Industries;Interpolation;Superresolution;Neural networks;High-resolution imaging;Autonomous aerial vehicles","autonomous aerial vehicles;geophysical image processing;image resolution;remote sensing;remotely operated vehicles","generative-network based multimedia super-resolution;uav remote sensing;Unmanned Aerial Vehicle;aerial mapping;surveying industry thanks;high-resolution imaging systems;exponential relationship;ground sampling distance;GSD;flight altitude;generative network;super-resolution approach;flight time;multimedia super-resolution implementations;image processing metrics","","","","11","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Multiframe resolution recovery of radar imagery: Towards super-resolution sensing","Y. V. Shkvarko; J. I. Yañez; G. D. Martin del Campo","CINVESTAV del IPN, Unidad Guadalajara, México; CINVESTAV del IPN, Unidad Guadalajara, México; CINVESTAV del IPN, Unidad Guadalajara, México","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","4487","4490","The aim of this study is to address a new approach and develop the relevant technique for super-resolution (SR) feature-enhanced recovery of microwave remote sensing (RS) imagery. The challenging proposition is twofold. First, we adapt the SR multi-scale iterative reconstructive (MSIR) image post-processing method for solving the inverse problem of recovery of the speckle corrupted low resolution RS images employing iterative projections onto the nested refined resolution frames. Second, we unify the modified RS-adapted MSIR method with the Descriptive Experiment Design Regularization (DEDR) high-resolution RS image enhancement technique for attaining the overall SR recovery with considerably enhanced resolution performances. Algorithmically, the MSIR processing loop is performed via the Fourier transform (FT) or wavelet transform (WT) of the input image. Different wavelet dictionaries were examined in order to approach the most speeded-up WT-based iterative MSIR-level image recovery.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326824","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326824","Fourier/wavelet transform;multi-scale iterative image recovery;remote sensing;super-resolution","Spatial resolution;Image reconstruction;Iterative methods;Imaging;Wavelet transforms;Speckle","geophysical image processing;image enhancement;image restoration;radar imaging;remote sensing by radar","multiframe resolution recovery;radar imagery;super-resolution sensing;super-resolution feature-enhanced recovery;microwave remote sensing imagery;SR MSIR image post-processing method;multiscale iterative reconstructive;iterative projections;Descriptive Experiment Design Regularization;DEDR high-resolution RS image enhancement technique;MSIR processing loop;input image wavelet transform;input image Fourier transform","","2","","8","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Scene-Adaptive Remote Sensing Image Super-Resolution Using a Multiscale Attention Network","S. Zhang; Q. Yuan; J. Li; J. Sun; X. Zhang","School of Geodesy and Geomatics, Wuhan University, Wuhan, China; Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Resource and Environmental Sciences, Wuhan University, Wuhan, China; Beijing Institute of Space Mechanics and Electricity, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","23 Jun 2020","2020","58","7","4764","4779","Remote sensing image super-resolution has always been a major research focus, and many deep-learning-based algorithms have been proposed in recent years. However, since the structure of remote sensing images tends to be much more complex than that of natural images, several difficulties still remain for remote sensing images super-resolution. First, it is difficult to depict the nonlinear mapping between high-resolution (HR) and low-resolution (LR) images of different scenes with the same model. Second, the wide range of scales within the ground objects in remote sensing images makes it difficult for single-scale convolution to effectively extract features of various scales. To address the above-mentioned issues, we propose a multiscale attention network (MSAN) to extract the multilevel features of remote sensing images. The basic component of MSAN is the multiscale activation feature fusion block (MAFB). In addition, a scene-adaptive super-resolution strategy for remote sensing images is employed to more accurately describe the structural characteristics of different scenes. The experiments undertaken on several data sets confirm that the proposed algorithm outperforms the other state-of-the-art algorithms, in both evaluation indices and visual results.","1558-0644","","10.1109/TGRS.2020.2966805","National Natural Science Foundation of China(grant numbers:41922008,61971319,41701400); China Postdoctoral Science Foundation(grant numbers:2018T110803); China Academy of Space Technology Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8978758","Channel attention;deep learning;multiscale activation;remote sensing imagery;scene adaptive","Remote sensing;Feature extraction;Image reconstruction;Convolution;Deep learning;Interpolation","feature extraction;geophysical image processing;image resolution;learning (artificial intelligence);neural nets;remote sensing","scene-adaptive remote sensing image super-resolution;multiscale attention network;natural images;scene-adaptive super-resolution strategy;multilevel feature extraction;MSAN;multiscale activation feature fusion block;high-resolution images;low-resolution images;deep learning","","46","","51","IEEE","3 Feb 2020","","","IEEE","IEEE Journals"
"Deepsum++: Non-Local Deep Neural Network for Super-Resolution of Unregistered Multitemporal Images","A. B. Molini; D. Valsesia; G. Fracastoro; E. Magli","Politecnico di Torino, Italy; Politecnico di Torino, Italy; Politecnico di Torino, Italy; Politecnico di Torino, Italy","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","609","612","Deep learning methods for super-resolution of a remote sensing scene from multiple unregistered low-resolution images have recently gained attention thanks to a challenge proposed by the European Space Agency. This paper presents an evolution of the winner of the challenge, showing how incorporating non-local information in a convolutional neural network allows to exploit self-similar patterns that provide enhanced regularization of the super-resolution problem. Experiments on the dataset of the challenge show improved performance over the state-of-the-art, which does not exploit non-local information.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324418","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324418","Super-resolution;CNN;Non-local","Convolution;Remote sensing;Image reconstruction;Feature extraction;Correlation;Two dimensional displays;Task analysis","geophysical image processing;image resolution;learning (artificial intelligence);neural nets;remote sensing","deepsum;nonlocal deep neural network;unregistered multitemporal images;remote sensing scene;low-resolution images;attention thanks;European Space Agency;nonlocal information;convolutional neural network;super-resolution problem","","6","","20","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"FeNet: Feature Enhancement Network for Lightweight Remote-Sensing Image Super-Resolution","Z. Wang; L. Li; Y. Xue; C. Jiang; J. Wang; K. Sun; H. Ma","College of Information Science and Engineering, Xinjiang University, Urumqi, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; College of Information Science and Engineering, Xinjiang University, Urumqi, China; College of Information Science and Engineering, Xinjiang University, Urumqi, China; Shanghai Institute of Satellite Engineering, Shanghai, China; Shanghai Institute of Satellite Engineering, Shanghai, China; Department of Electronic Engineering, Tsinghua University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","3 May 2022","2022","60","","1","12","In the field of remote sensing, due to memory consumption and computational burden, the single-image super-resolution (SISR) methods based on deep convolution neural networks (CNNs) are limited in practical application. To address this problem, we propose a lightweight feature enhancement network (FeNet) for accurate remote-sensing image super-resolution (SR). Considering the existence of equipment with extremely poor hardware facilities, we further design a lighter FeNet-baseline with about 158K parameters. Specifically, inspired by lattice structure, we construct a lightweight lattice block (LLB) as a nonlinear feature extraction function to improve the expression ability. Here, channel separation operation makes the upper and lower branches of the LLB only responsible for half of the features, and the weight coefficients calculated through the attention mechanism enable the upper and lower branches to communicate efficiently. Based on LLB, the feature enhancement block (FEB) is designed in a nested manner to obtain expressive features, where different layers are responsible for the features with different texture richness, and then features from different layers are sequentially fused from deep to shallow. Model parameters and multi-adds operations are used to evaluate network complexity, and extensive experiments on two remote-sensing and four SR benchmark test datasets show that our methods can achieve a good tradeoff between complexity and performance. Our code will be available at https://github.com/wangzheyuan-666/FeNet.","1558-0644","","10.1109/TGRS.2022.3168787","Shanghai Aerospace Science and Technology Innovation Fund(grant numbers:SAST2019-048); Cross-Media Intelligent Technology Project of Beijing National Research Center for Information Science and Technology (BNRist)(grant numbers:BNR2019TD01022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9759417","Convolutional neural network;lightweight feature enhancement network (FeNet);remote sensing;single image super-resolution (SISR)","Remote sensing;Feature extraction;Convolution;Task analysis;Superresolution;Image reconstruction;Head","convolutional neural nets;deep learning (artificial intelligence);feature extraction;image enhancement;image resolution;image texture;remote sensing","network complexity;lightweight remote-sensing image super-resolution;deep convolution neural networks;lightweight feature enhancement network;lighter FeNet-baseline;lattice structure;lightweight lattice block;LLB;nonlinear feature extraction function;channel separation operation;feature enhancement block;FEB;weight coefficients","","4","","46","IEEE","18 Apr 2022","","","IEEE","IEEE Journals"
"Achieving Super-Resolution Remote Sensing Images via the Wavelet Transform Combined With the Recursive Res-Net","W. Ma; Z. Pan; J. Guo; B. Lei","School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","27 May 2019","2019","57","6","3512","3527","Deep learning (DL) has been successfully applied to single image super-resolution (SISR), which aims at reconstructing a high-resolution (HR) image from its low-resolution (LR) counterpart. Different from most current DL-based methods, which perform reconstruction in the spatial domain, we use a scheme based in the frequency domain to reconstruct the HR image at various frequency bands. Further, we propose a method that incorporates the wavelet transform (WT) and the recursive Res-Net. The WT is applied to the LR image to divide it into various frequency components. Then, an elaborately designed network with recursive residual blocks is used to predict high-frequency components. Finally, the reconstructed image is obtained via the inverse WT. This paper has three main contributions: 1) an SISR scheme based on the frequency domain is proposed under a DL framework to fully exploit the potential to depict images at different frequency bands; 2) recursive block and residual learning in global and local manners are adopted to ease the training of the deep network, and the batch normalization layer is removed to increase the flexibility of the network, save memory, and promote speed; and 3) the low-frequency wavelet component is replaced by an LR image with more details to further improve performance. To validate the effectiveness of the proposed method, extensive experiments are performed using the NWPU-RESISC45 data set, and the results demonstrate that the proposed method outperforms several state-of-the-art methods in terms of both objective evaluation and subjective perspective.","1558-0644","","10.1109/TGRS.2018.2885506","National Natural Science Foundation of China(grant numbers:61701478,61331017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8600724","Recursive network;remote sensing image;residual learning;super resolution;wavelet transform (WT)","Spatial resolution;Image reconstruction;Remote sensing;Discrete wavelet transforms;Signal resolution","geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);remote sensing;wavelet transforms","super-resolution remote sensing images;wavelet transform combined;recursive Res-Net;deep learning;single image super-resolution;high-resolution image;low-resolution counterpart;DL-based methods;spatial domain;frequency domain;HR image;LR image;recursive residual blocks;high-frequency components;reconstructed image;SISR scheme;residual learning;deep network;low-frequency wavelet component;NWPU-RESISC45 data set;frequency bands","","62","","61","IEEE","3 Jan 2019","","","IEEE","IEEE Journals"
"Enhanced Resolution of FY4 Remote Sensing Visible Spectrum Images Utilizing Super-Resolution and Transfer Learning Techniques","B. Zhang; M. Ma; M. Wang; D. Hong; L. Yu; J. Wang; P. Gong; X. Huang","Ministry of Education Key Laboratory for Earth System Modeling, and Department of Earth System Science, Tsinghua University, Beijing, China; Ministry of Education Key Laboratory for Earth System Modeling, and Department of Earth System Science, Tsinghua University, Beijing, China; Ministry of Education Key Laboratory for Earth System Modeling, and Department of Earth System Science, Tsinghua University, Beijing, China; Key Laboratory of Computational Optical Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Ministry of Education Key Laboratory for Earth System Modeling, and Department of Earth System Science, Tsinghua University, Beijing, China; Peng Cheng Laboratory, Shenzhen, China; Department of Geography and Department of Earth Sciences, University of Hong Kong, Hong Kong; Ministry of Education Key Laboratory for Earth System Modeling, and Department of Earth System Science, Tsinghua University, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","12 Sep 2022","2022","15","","7391","7399","Remote sensing images acquired by the FY4 satellite are crucial for regional cloud monitoring and meteorological services. Inspired by the success of deep learning networks in image super-resolution, we applied image super-resolution to FY4 visible spectrum (VIS) images. However, training a robust network directly for FY4 VIS image super-resolution remains challenging due to the limited provision of high resolution FY4 sample data. Here, we propose a super-resolution and transfer learning model, FY4-SR-Net. It is composed of pretraining and fine-tuning models. The pretraining model was developed using a deep residual network and a large number of FY4 A 4 and 1 km resolution VIS images as the training data. The knowledge derived from 4 km to 1 km resolution images was incorporated into FY4 B 1 km to 0.25 km resolution VIS images. The FY4-SR-Net is fine-tuned by incorporating limited 1 km and 0.25 km resolution panchromatic images, and then producing 1km super-resolution VIS images of the FY4 satellite. Using the one-day FY4 test dataset for qualitative and quantitative evaluations, the FY4-SR-Net outperformed the classic bicubic interpolation approach with a 16.12% reduction in root-mean-square error and a 2.97% rise in peak signal-to-noise ratio averages. The structural similarity value average increased by 0.0026. This article provides a new precedent for improving the spatial resolution of FY4 series meteorological satellites, which has important scientific significance and application properties.","2151-1535","","10.1109/JSTARS.2022.3197401","National Key Research and Development Program of China(grant numbers:2020YFA0607900,2020YFA0608003); National Natural Science Foundation of China(grant numbers:42125503,42075137); Key Research and Development Program of Shaanxi Province, China(grant numbers:2020SF-434); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9852675","Fine-tuning;pretraining;remote sensing images;super-resolution;transfer learning","Spatial resolution;Remote sensing;Superresolution;Satellites;Data models;Training;Satellite broadcasting","deep learning (artificial intelligence);geophysical image processing;image denoising;image enhancement;image resolution;interpolation;remote sensing","enhanced resolution;deep learning networks;FY4 visible spectrum images;high resolution FY4 sample data;transfer learning model;FY4-SR-Net;super-resolution VIS images;FY4 series meteorological satellites;FY4 remote sensing visible spectrum images utilizing super-resolution;resolution panchromatic images;root-mean-square error;bicubic interpolation approach","","1","","43","CCBY","9 Aug 2022","","","IEEE","IEEE Journals"
"Video Satellite Imagery Super Resolution via Convolutional Neural Networks","Y. Luo; L. Zhou; S. Wang; Z. Wang","Collaborative Innovation Centre of Geospatial Technology, School of Remote Sensing Information Engineering, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, Computer School, Wuhan University, Wuhan, China; Division of Imaging Sciences and Biomedical Engineering Research, King’s College London, London, U.K; National Engineering Research Center for Multimedia Software, Computer School","IEEE Geoscience and Remote Sensing Letters","4 Dec 2017","2017","14","12","2398","2402","Video satellite imagery is a new technique for earth dynamic observation and has a wide range of uses in environmental fields. Despite its capability of dynamic targets' detection, it sustains a serious restriction of the image quality due to the degradation and compression in its imaging process. Hence, the super-resolution (SR) reconstruction on these compressed low-spatial-resolution images is of significance to afterward ground objects recognition and detection tasks. Based on the recent proposed state-of-the-art convolutional neural networks (CNNs) SR methods, we proposed an SR method which could get more precise reconstructed high-spatial-resolution images. Trained with Gaofen-2 satellite images, a robust CNN model specified in satellite image SR is obtained. Experimentally, the reconstruction results on Jilin-1 mission satellite images validate the effectiveness of our method.","1558-0571","","10.1109/LGRS.2017.2766204","National Natural Science Foundation of China(grant numbers:61671332); National Key Research and Development Program of China(grant numbers:2016YFB0100901); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8101498","Convolutional neural network (CNN);deep learning;super resolution (SR);video satellite","Satellites;Image reconstruction;Training;Spatial resolution;Neural networks;Remote sensing","cellular neural nets;data compression;geophysical image processing;image classification;image coding;image reconstruction;image resolution;neural nets;object recognition;remote sensing","earth dynamic observation;environmental fields;serious restriction;image quality;degradation;compression;imaging process;afterward ground objects recognition;detection tasks;convolutional neural networks SR methods;SR method;high-spatial-resolution images;Gaofen-2 satellite images;satellite image SR;reconstruction results;Jilin-1 mission satellite images;dynamic target detection;video satellite imagery superresolution;superresolution reconstruction;low-spatial-resolution image compression;reconstructed high-spatial-resolution images;robust CNN model","","68","","24","IEEE","9 Nov 2017","","","IEEE","IEEE Journals"
"Multi-target Super-resolution Technology of Remote Sensing based on L Regularization","X. Chen; Z. Ben","School of Electronics and Information Engineering Harbin Institute of Technology, Shenzhen, China; School of Energy and Power Engineering, Nanjing Institute of Technology, Nanjing, China","2022 7th International Conference on Intelligent Computing and Signal Processing (ICSP)","24 May 2022","2022","","","1747","1751","Based on regularization theory, L regularizer is used as a constraint term for regularized deconvolution for super-resolution imaging of remote sensing targets. In this paper, a super-resolution imaging model is established with L regulars as constraints, and the super-resolution imaging problem is transformed into a constrained optimization problem. Then, a half - threshold iterative algorithm for L - regular deconvolution convolution model is derived. Finally, point target simulation shows that the super-resolution imaging method based on L-regular deconvolution can achieve lower relative error than truncated singular value decomposition (TSVD) results, and has higher azimuth resolution and better robustness.","","978-1-6654-7857-1","10.1109/ICSP54964.2022.9778607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9778607","signal processing;super resolution;remote sensing image;L regularization","Deconvolution;Azimuth;Computational modeling;Superresolution;Imaging;Robustness;Signal resolution","deconvolution;geophysical image processing;image resolution;iterative methods;optimisation;remote sensing","remote sensing targets;constrained optimization problem;threshold iterative algorithm;regular deconvolution convolution model;point target simulation;superresolution imaging method;L-regular deconvolution;azimuth resolution;regularized deconvolution theory;TSVD;truncated singular value decomposition","","","","9","IEEE","24 May 2022","","","IEEE","IEEE Conferences"
"Shipsrdet: An End-to-End Remote Sensing Ship Detector Using Super-Resolved Feature Representation","S. He; H. Zou; Y. Wang; R. Li; F. Cheng","College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3541","3544","High-resolution remote sensing images can provide abundant appearance information for ship detection. Although several existing methods use image super-resolution (SR) approaches to improve the detection performance, they consider image SR and ship detection as two separate processes and overlook the internal coherence between these two correlated tasks. In this paper, we explore the potential benefits introduced by image SR to ship detection, and propose an end-to-end network named ShipSRDet. In our method, we not only feed the super-resolved images to the detector but also integrate the intermediate features of the SR network with those of the detection network. In this way, the informative feature representation extracted by the SR network can be fully used for ship detection. Experimental results on the HRSC dataset validate the effectiveness of our method. Our ShipSRDet can recover the missing details from the input image and achieves promising ship detection performance.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554079","National Natural Science Foundation of China(grant numbers:62071474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554079","Ship detection;image super-resolution;remote sensing;deep neural network","Superresolution;Neural networks;Detectors;Coherence;Feature extraction;Sensors;Feeds","geophysical image processing;image representation;image resolution;remote sensing;ships","ShipSRDet;SR network;detection network;informative feature representation;input image;ship detection performance;end-to-end remote sensing ship detector;super-resolved feature representation;high-resolution remote sensing images;abundant appearance information;image super-resolution;image SR;end-to-end network","","5","","15","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"SISR of Hyperspectral Remote Sensing Imagery Using 3D Encoder-Decoder RUNet Architecture","N. Aburaed; M. Q. Alkhatib; S. Marshall; J. Zabalza; H. A. Ahmad","Department of Electronic and Electrical Engineering, University of Strathclyde, UK; College of Engineering and IT, University of Dubai, UAE; Department of Electronic and Electrical Engineering, University of Strathclyde, UK; Department of Electronic and Electrical Engineering, University of Strathclyde, UK; College of Engineering and IT, University of Dubai, UAE","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1516","1519","Single Image Super Resolution (SISR) refers to the spatial enhancement of an image from a single Low Resolution (LR) observation. This topic is of particular interest to remote sensing community, especially in the area of Hyperspectral Imagery (HSI) due to their high spectral resolution but limited spatial resolution. Enhancing the spatial resolution of HSI is a pre-requisite that boosts the accuracy of other image processing tasks, such as object detection and classification. This paper deals with SISR of HSI through the 3D expansion of Robust UNet (RUNet). The network is developed, trained, and tested over two datasets, and compared against the original 2D-RUNet and other state-of-the-art approaches. Quantitative and qualitative evaluation show the superiority of 3D-RUNet and its ability to preserve the spectral fidelity of the enhanced HSI.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883578","Hyperspectral;Remote Sensing;Single Image Super Resolution;3D Convolution;3D-RUNet","Three-dimensional displays;Convolution;Object detection;Feature extraction;Sensors;Decoding;Mirrors","geophysical image processing;image processing;image resolution;object detection;remote sensing","spatial resolution;image processing tasks;object detection;classification;SISR;2D-RUNet;3D-RUNet;enhanced HSI;Hyperspectral remote sensing Imagery;encoder-decoder RUNet architecture;Single Image Super Resolution;spatial enhancement;single Low Resolution observation;remote sensing community;Hyperspectral Imagery;high spectral resolution","","1","","21","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Remote Sensing Image Super-Resolution using Multi-Scale Convolutional Neural Network","X. Qin; X. Gao; K. Yue","School of Electronics and Information, Hangzhou Dianzi University, Hangzhou, China; School of Electronics and Information, Hangzhou Dianzi University, Hangzhou, China; School of Electronics and Information, Hangzhou Dianzi University, Hangzhou, China","2018 11th UK-Europe-China Workshop on Millimeter Waves and Terahertz Technologies (UCMMT)","27 Feb 2020","2018","1","","1","3","Remote sensing images have advantages in large-area imaging and macroscopic integrity. However, in most commercial applications, further recognition and processing becomes difficult due to the low spatial resolution of the acquired images. Therefore, improving the resolution of remote sensing images has important practical significance. To solve this problem, we propose a remote sensing image super-resolution method based on deep learning technology. In order to obtain more detailed image information, we introduce multi-scale convolution to implement feature extraction and deconvolution be used to achieve the final 3× image reconstruction without bicubic interpolation. Experimental results show that our network achieves better performance than prior art methods and visual improvement of our results is easily noticeable.","2639-4537","978-1-5386-7497-0","10.1109/UCMMT45316.2018.9015801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9015801","","Convolution;Feature extraction;Deconvolution;Image reconstruction;Image resolution;Remote sensing;Neural networks","convolutional neural nets;feature extraction;geophysical image processing;image reconstruction;image resolution;interpolation;learning (artificial intelligence);remote sensing","multiscale convolutional neural network;remote sensing images;large-area imaging;low spatial resolution;remote sensing image super-resolution method;detailed image information;multiscale convolution;image reconstruction","","1","","12","IEEE","27 Feb 2020","","","IEEE","IEEE Conferences"
"Super-Resolution Reconstruction of Remote Sensing Images Based on GAN","L. Zhou; Y. Xia; Z. Liu","Jiangsu University of Science and Technology, Nanjing, China; Jiangsu University of Science and Technology, Nanjing, China; Jiangsu University of Science and Technology, Nanjing, China","2021 IEEE International Conference on Data Science and Computer Application (ICDSCA)","23 Dec 2021","2021","","","270","274","In recent years, the methods of super-resolution image reconstruction that based on deep learning have become a hot topic in research of computer vision. The methods of super-resolution image reconstruction that based on the Generative Adversarial Network (GAN) are not controlled in network generation, the models are easy to collapse, the generalization ability is undesirable, and the time complexity degree is too high. To fill these gaps, we propose a super-resolution image reconstruction method based on the GAN of encoding and decoding, which improves the quality of image reconstruction. First of all, our approach uses a design network with regularized structure to avoid model collapse. Then we build a generation network structure that based on encoding and decoding to suppress the uncontrollable defects of GAN network generated images. Finally, in the last layer of the generator, $\mathrm{N}^{\star}\mathrm{N}$ convolutional feature layer is included to replace the Softmax layer, which speeds up the training of the model. The experimental results show that the super-resolution remote sensing image reconstructed by the proposed method has higher reconstruction quality and better generalization ability in the DOTA training data sets. At the same time, the image reconstruction process can take much less time.","","978-1-6654-4054-7","10.1109/ICDSCA53499.2021.9649727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649727","GAN;Coding and Decoding;Remote Sensing Images;Super Resolution Reconstruction","Training;Deep learning;Image coding;Superresolution;Generative adversarial networks;Visual effects;Generators","computational complexity;computer vision;convolutional neural nets;geophysical image processing;image reconstruction;image resolution;remote sensing","generative adversarial network;generalization ability;superresolution image reconstruction method;design network;generation network structure;superresolution remote sensing image;deep learning;computer vision;time complexity degree;encoding;decoding;GAN network generated image;convolutional feature layer;softmax layer;DOTA training data sets","","","","11","IEEE","23 Dec 2021","","","IEEE","IEEE Conferences"
"High-definition processing of remote sensing images based on CUT-CycleGAN","L. Deng; Y. Zhang; X. Wang","Heilongjiang Provincial Key Laboratory of Complex Intelligent System and Integration, School of Automation, Harbin University of Science and Technology, Harbin, China; Heilongjiang Provincial Key Laboratory of Complex Intelligent System and Integration, School of Automation, Harbin University of Science and Technology, Harbin, China; Heilongjiang Provincial Key Laboratory of Complex Intelligent System and Integration, School of Automation, Harbin University of Science and Technology, Harbin, China","2021 40th Chinese Control Conference (CCC)","6 Oct 2021","2021","","","8158","8162","High-definition remote sensing images are more and more widely used in research and life. However, due to hardware conditions and transmission rate limitations, it is too expensive to directly obtain high-definition original images. So, it has become a research hotspot on how to use algorithms to receive high-definition remote sensing images from low-resolution images. In view of the existing super-resolution methods for remote sensing images, the dependence on a large number of matching low-resolution and high-resolution(LR-HR) data sets and the slow network training time. In this paper, contrast learning is used for unpaired image-to-image conversion model (CUT-CycleGAN), which uses cyclic consistency to achieve the purpose of training using unpaired images, and adds a contrast learning framework to effectively shorten CycleGAN's training time and to improve efficiency. The experiment selects SRGAN, CycleGAN, EDSR, and FSRCNN four existing super-resolution methods to compare with the method in this paper. The results show that the training time of CUT-CycleGAN is reduced by nearly 55.7%, and after training with unpaired images, the quality of the generated high-definition images is good enough.","1934-1768","978-9-8815-6380-4","10.23919/CCC52363.2021.9549656","National Science Foundation; Natural Science Foundation of Heilongjiang Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9549656","Super resolution;Comparative learning;Generative adversarial network;Remote sensing","Training;Learning systems;Superresolution;Hardware;Sensors;Remote sensing;Image reconstruction","convolutional neural nets;geophysical image processing;image matching;image resolution;learning (artificial intelligence);remote sensing","unpaired image-to-image conversion model;CUT-CycleGAN;super resolution;high-definition processing;high-definition remote sensing images;hardware conditions;transmission rate limitations;low-resolution images;low-resolution dataset matching;high-resolution dataset matching;contrast learning;SRGAN;EDSR;FSRCNN","","","","19","","6 Oct 2021","","","IEEE","IEEE Conferences"
"An Overview of the Contributions of Jose Manuel Bioucas-Dias to Remote Sensing Image Processing","A. Plaza; J. Li; M. A. T. Figueiredo","Hyperspectral Computing Laboratory, University of Extremadura, Cáceres, Spain; School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Instituto de Telecomunicações; Instituto Superior Técnico, Universidade de Lisboa, Portugal","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","13","16","José Manuel Bioucas-Dias was an outstanding expert in many different IEEE-related areas, including inverse problems in imaging, signal and image processing, pattern recognition, optimization, and remote sensing. He authored or coauthored more than 250 publications, including more than 100 journal papers (66 of which published in IEEE journals) and over 200 peer-reviewed international conference papers and book chapters. His contributions have been extremely influential in many different fields, namely phase estimation and unwrapping, convex optimization and Bayesian inference for imaging inverse problems, with a special emphasis on remote sensing, including synthetic aperture radar (SAR), hyperspectral unmixing, fusion, super-resolution, classification, and segmentation. In this paper, we provide an overview of his outstanding contributions to remote sensing image processing.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554718","Remote sensing;pattern recognition;optimization;signal and image processing;inverse problems","Image segmentation;Inverse problems;Superresolution;Phase estimation;Radar imaging;Pattern recognition;Remote sensing","Bayes methods;geophysical image processing;image resolution;image segmentation;inverse problems;iterative methods;radar imaging;remote sensing;reviews;synthetic aperture radar","super-resolution;outstanding contributions;remote sensing image processing;José Manuel Bioucas-Dias;outstanding expert;inverse problems;journal papers;IEEE journals;unwrapping optimization;convex optimization;peer-reviewed international conference papers;IEEE-related areas","","","","14","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Super-resolution reconstruction of remote sensing images based on convolutional neural networks","X. Liu; Y. Xu; Y. Che; J. Tang","School of Electronic and Information Engineering, Lanzhou Jiaotong University, Lan Zhou, China; School of Electronic and Information Engineering, Lanzhou Jiaotong University, Lan Zhou, China; School of Electronic and Information Engineering, Lanzhou Jiaotong University, Lan Zhou, China; School of Electronic and Information Engineering, Lanzhou Jiaotong University, Lan Zhou, China","2022 5th International Conference on Data Science and Information Technology (DSIT)","17 Nov 2022","2022","","","1","5","Aiming at the problem that the current remote sensing image super-resolution reconstruction algorithm extracts insufficient image information and lacks high-frequency information such as edges and textures, this paper proposes a remote sensing image super-resolution reconstruction algorithm based on multi-scale extraction and attention mechanism. The algorithm uses the Inception-ResNet module to fuse information extracted at different levels to obtain richer image features; introduces an attention mechanism to obtain high-frequency information and enriches texture details; uses a residual network to supplement image information and alleviate network gradient problems. Experiments show that the peak signal-to-noise ratio and structural similarity of the proposed algorithm are better than those of SRCNN, VDSR, SRGAN, and other comparison algorithms, and the reconstruction effect has more detailed information and clearer edge texture than the comparison algorithms.","","978-1-6654-9868-5","10.1109/DSIT55514.2022.9943916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943916","super-resolution reconstruction;multi-scale features;attention mechanism;residual network","PSNR;Image edge detection;Superresolution;Reconstruction algorithms;Feature extraction;Data mining;Information technology","edge detection;feature extraction;geophysical image processing;gradient methods;image reconstruction;image resolution;image texture;neural nets;remote sensing","attention mechanism;comparison algorithms;convolutional neural networks;current remote sensing image super-resolution reconstruction algorithm extracts insufficient image information;high-frequency information;multiscale extraction;network gradient problems;remote sensing images;richer image features","","","","10","IEEE","17 Nov 2022","","","IEEE","IEEE Conferences"
"Super Resolution Guided Deep Network for Land Cover Classification From Remote Sensing Images","J. Xie; L. Fang; B. Zhang; J. Chanussot; S. Li","Inria Grenoble Rhone-Alpes, Montbonnot-Saint-Martin, France; Peng Cheng Laboratory, Shenzhen, China; Department of Computer and Information Science, University of Macau, Taipa, Macau, China; Inria, CNRS, Grenoble INP, LJK, Université Grenoble Alpes, Grenoble, France; Key Laboratory of Visual Perception and Artificial Intelligence of Hunan Province, Changsha, China","IEEE Transactions on Geoscience and Remote Sensing","7 Feb 2022","2022","60","","1","12","The low resolution of remote sensing images often limits the land cover classification (LCC) performance. Super resolution (SR) can improve the image resolution, while greatly increasing the computational burden for the LCC due to the larger size of the input image. In this article, the SR-guided deep network (SRGDN) framework is proposed, which can generate meaningful structures from higher resolution images to improve the LCC performance without consuming more computational costs. In general, the SRGDN consists of two branches (i.e., SR branch and LCC branch) and a guidance module. The SR branch aims to increase the resolution of remote sensing images. Since high- and low-resolution image pairs cannot be directly provided by imaging sensors to train the SR branch, we introduce a self-supervised generative adversarial network (GAN) to estimate the downsampling kernel that can produce these image pairs. The LCC branch adopts the high-resolution network (HRNet) to retain as much resolution information with a few downsampling operations as possible. The guidance module teaches the LCC branch to learn the high-resolution information from the SR branch without the utilization of the higher-resolution images as the inputs. Furthermore, the guidance module introduces spatial pyramid pooling (SPP) to match the feature maps of different sizes in the two branches. In the testing stage, the guidance module and SR branch can be removed, and therefore do not create additional computational costs. Experimental results on three real datasets demonstrate the superiority of the proposed method over several well-known LCC approaches.","1558-0644","","10.1109/TGRS.2021.3120891","National Natural Science Foundation of China(grant numbers:61922029); Science and Technology Plan Project Fund of Hunan Province(grant numbers:2019RS2016); Postgraduate Scientific Research Innovation Project of Hunan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9576700","Guidance;land cover classification (LCC);remote sensing image;super resolution (SR)","Image resolution;Remote sensing;Feature extraction;Sensors;Streaming media;Computational efficiency;Indexes","image classification;image resolution;image sampling;neural nets;remote sensing","super resolution guided deep network;remote sensing images;land cover classification;image resolution;SR-guided deep network framework;higher resolution images;LCC branch;low-resolution image pairs;self-supervised generative adversarial network","","6","","56","IEEE","15 Oct 2021","","","IEEE","IEEE Journals"
"Single-Frame Remote Sensing Image Super-Resolution Reconstruction Algorithm Based on Two-Dimensional Wavelet","C. Zhou; J. Zhou","Key Laboratory for Digital Dongting Lake basin of Hunan Province & College of Science, Central South University of Forestry and Technology, Changsha Hunan, China; ZhongNan Engineering Corporation Limited, Changsha Hunan, China","2018 IEEE 3rd International Conference on Image, Vision and Computing (ICIVC)","18 Oct 2018","2018","","","360","363","The obtained precisely high frequency information is the key of single-frame image super-resolution reconstruction by using two-dimensional wavelet. Because the bicubic interpolation of high frequency components decomposed by wavelet will introduce noise, it will affect reconstruction effect. An improved algorithm using Fourier transform and zero-padding resampling instead of bicubic interpolation is proposed in this paper. The advantage of frequency domain interpolation is obtained by using Fourier transform and zero-padding resampling. And high frequency components obtained by wavelet decomposition of the original image can be interpolated optimally without introducing noise, which makes the high frequency details more precise in the reconstruction process. The experimental results show that the improved algorithm is superior to the traditional two-dimensional wavelet reconstruction algorithm, which can be applied to the single-frame remote sensing image super-resolution reconstruction.","","978-1-5386-4991-6","10.1109/ICIVC.2018.8492778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8492778","two-dimensional wavelet transform;zero-padding resampling;bicubic interpolation;single-frame image super-resolution reconstruction","Image reconstruction;Wavelet transforms;Interpolation;Image resolution;Reconstruction algorithms;Two dimensional displays","Fourier transforms;image reconstruction;image resolution;image sampling;interpolation;remote sensing;wavelet transforms","single-frame image super-resolution reconstruction;bicubic interpolation;zero-padding resampling;frequency domain interpolation;wavelet decomposition;two-dimensional wavelet reconstruction algorithm;single-frame remote sensing image;super-resolution reconstruction algorithm;Fourier transform","","2","","14","IEEE","18 Oct 2018","","","IEEE","IEEE Conferences"
"A Dual-Domain Super-Resolution Image Fusion Method With SIRV and GALCA Model for PolSAR and Panchromatic Images","W. Liu; J. Yang; J. Zhao; F. Guo","School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Jiangsu Key Laboratory of Resources and Environmental Information Engineering, School Environment and Spatial Information and China University of Mining and technology, Xuzhou, China; School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, China","IEEE Transactions on Geoscience and Remote Sensing","25 Feb 2022","2022","60","","1","14","Hyperspectral/multispectral and panchromatic of optical remote sensing images are commonly used for multisensor image fusion, which has been applied in various applications of Earth observation. However, the utilization of optical remote sensing data suffers from the limitation of bad weather and cloud contamination. To address aforementioned issue and enhance spatial details of polarimetric synthetic aperture radar (PolSAR) image, a novel dual-domain super-resolution image fusion method is proposed by combining improved spherically invariant random vector (ISIRV) model with generalized adaptive linear combination approximation (GALCA) technology in this study. The proposed method decomposes the task of image fusion into polarimetric and texture domain fusion by integrating polarimetric components of PolSAR image and texture detail component of panchromatic image, which can significantly improve spatial resolutions of the PolSAR image while preserving polarimetric information. The data fusion experiment is implemented with three data sets including panchromatic images of Gaofen-1 (GF-1) and Gaofen-2 (GF-2) and the quad-pol SAR data of Gaofen-3 (GF-3) and Radarsat-2. Results show that the proposed dual-domain image fusion method provides a better performance compared with state-of-the-art multisensor fusion methods (BT, PCA, GS, indusion, and PRACS) regarding qualitative and quantitative evaluations. In addition, results of image fusion are applied to image classification over agricultural and urban areas of China, which shows that classification accuracy is significantly improved when compared with the result using only the original image.","1558-0644","","10.1109/TGRS.2021.3134099","National Natural Science Foundation of China(grant numbers:41771377,42071295,41901286,62101219); Natural Science Foundation of Jiangsu(grant numbers:BK20201026,BK20210921); Science Foundation of Jiangsu Normal University(grant numbers:19XSRX006); Science and Technology Innovation Key project of Shenzhen(grant numbers:JCYJ20200109150833977); Open Research Fund of Jiangsu Key Laboratory of Resources and Environmental Information Engineering, China University of Mining and Technology(grant numbers:JS202107,JS202108); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643026","Generalized adaptive linear combination approximation (ALCA) method;improved spherically invariant random vector (SIRV) model;polarimetric domain;super-resolution image fusion;texture domain","Image fusion;Optical imaging;Optical sensors;Spatial resolution;Optical scattering;Adaptive optics;Remote sensing","agriculture;geophysical image processing;image classification;image fusion;image resolution;image sensors;radar imaging;radar polarimetry;remote sensing;remote sensing by radar;sensor fusion;synthetic aperture radar","state-of-the-art multisensor fusion methods;image classification;panchromatic image;optical remote sensing images;multisensor image fusion;optical remote sensing data suffers;polarimetric synthetic aperture radar image;novel dual-domain super-resolution image fusion method;spherically invariant random vector model;generalized adaptive linear combination approximation;polarimetric texture domain fusion;PolSAR image;spatial resolutions;data fusion experiment;Gaofen-1;Gaofen-2;Gaofen-3;dual-domain image fusion method","","1","","46","IEEE","8 Dec 2021","","","IEEE","IEEE Journals"
"Non-Locally up-Down Convolutional Attention Network for Remote Sensing Image Super-Resolution","H. Wang; Q. Hu; C. Wu; J. Chi; X. Yu","Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Faculty of Information Science and Engineering, Northeastern University, Shenyang, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China","IEEE Access","18 Sep 2020","2020","8","","166304","166319","Recently, single image super-resolution (SISR) has been widely applied in the field of remote sensing image processing and obtained remarkable performance. However, existing CNN-based remote sensing image super-resolution methods are unable to exploit shallow visual characteristics at global receptive fields, which results in the limited perceptual capability of these models. Furthermore, the low-resolution inputs and features contain abundant low-frequency information, which are weighed in channels and space equally, hence limiting the representational ability of CNNs. To solve these problems, we propose a non-locally up-down convolutional attention network (NLASR) for remote sensing image super-resolution. First, a non-local features enhancement module (NLEB) is constructed to obtain the spatial context information of high-dimensional feature maps, which allows our network to utilize global information to enhance low-level similar structured texture information with effect, overcoming the defects of deficiency perceptual ability of shallow convolutional layers. Second, an enhanced up-sampling channel-wise attention (EUCA) module and enhanced down-sampling spatial-wise attention (EDSA) module are proposed to weight the features at multiple scales. By integrating the channel-wise and multi-scale spatial information, the attention modules are able to compute the response values from the multi-scale regions of each neuron and then establish the accurate mapping from low to high resolution space. Extensive experiments on NWPU-RESISC45 and UCMerced-LandUse datasets show that the proposed method can provide state-of-the-art or even better performance in both quantitative and qualitative measurements.","2169-3536","","10.1109/ACCESS.2020.3022882","National Natural Science Foundation of China(grant numbers:61701101,61973093,U1713216,61901098,61971118); Fundamental Research Fund for the Central Universities of China(grant numbers:N2026005,N181602014,N2026004,N2026006,N2026001,N2011001); Project for the Science and Technology Major Special Plan of Liaoning(grant numbers:2019JH1/10100005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189886","Single image super-resolution (SISR);channel-wise and space-wise attention mechanisms;deep learning;remote sensing image processing","Remote sensing;Spatial resolution;Feature extraction;Convolution;Task analysis;Image reconstruction","feature extraction;geophysical image processing;image classification;image enhancement;image representation;image resolution;image segmentation;image texture;neural nets;remote sensing;terrain mapping","attention modules;multiscale spatial information;down-sampling spatial-wise attention module;up-sampling channel-wise attention module;low-level similar structured texture information;high-dimensional feature maps;spatial context information;nonlocal features enhancement module;low-frequency information;low-resolution inputs;global receptive fields;CNN-based remote sensing image super-resolution methods;remote sensing image processing;single image super-resolution;convolutional attention network;high resolution space","","7","","55","CCBYNCND","9 Sep 2020","","","IEEE","IEEE Journals"
"SD-FB-GAN: Saliency-Driven Feedback Gan for Remote Sensing Image Super-Resolution Reconstruction","J. Ma; H. Wu; J. Zhang; L. Zhang","College of Artificial Intelligence, Beijing Normal University, Beijing, China; College of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Engineering and Information Technology, University of New South Wales, Canberra, Australia; College of Artificial Intelligence, Beijing Normal University, Beijing, China","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","528","532","The visual characteristics of different regions in remote sensing images are significantly versatile, which poses a huge challenge to single image super-resolution. Although generative adversarial network (GAN) has shown great potential in generating photo-realistic results, it provides unsatisfactory performance in objective metrics owning to pseudo textures brought by adversarial learning. In this paper, we propose a new saliency-driven feedback GAN to cope with these problems. We design a saliency-driven feedback generator based on paired-feedback blocks (PFBBs) and recurrent structure to provide strong reconstruction ability. In the PFBB, the saliency map serves as an indicator to reflect the texture complexity, so different reconstruction principles can be applied to restore areas with varying levels of saliency. Besides, we propose to measure the visual quality of salient areas, non-salient areas, and the whole image with multi-discriminators, which can dramatically eliminate pseudo textures. Comprehensive evaluations and ablation studies validate the superiority of our proposal.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190835","Image reconstruction;super-resolution;deep learning;GAN;saliency analysis","Indexes;Economic indicators;Zirconium","geophysical image processing;image reconstruction;image resolution;image texture;neural nets;remote sensing","remote sensing image super-resolution reconstruction;single image super-resolution;generative adversarial network;photo-realistic results;pseudotextures;saliency-driven feedback gan;saliency-driven feedback generator;paired-feedback blocks;strong reconstruction ability;saliency map;SD-FB-GAN;reconstruction principles","","3","","25","IEEE","30 Sep 2020","","","IEEE","IEEE Conferences"
"Comparative Analysis of Single and Multi Frame Super Resolution in Satellite Imagery","S. Rana; H. Singh; A. Kumar","Photograrnmetry and Remote Sensing Department, ISRO, India; Water Resources Department, ISRO, India; Photograrnmetry and Remote Sensing Department, ISRO, India","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","7220","7223","Since last two decades there have been plenty of papers proposing a variety methods of single frame and multi-frame resolution enhancement. These methods are usually very sensitive to their assumed model of data and noise, which limits their utility. This paper analyses the contrast between single and multi-frame super resolution and addresses their shortcomings. The comparison is mainly visual and statistical. Where on one hand Multi-Frame technique is implemented using Ll norm minimization and robust regularization to deal with different data and noise models [1], Single Frame technique on the other is implemented through a tool developed in Java. The study area is Sitarganj city, Udham Singh Nagar district, Uttarakhand, India and the imagery is of LISS III and LISS IV sensors of ResourceSat-2 satellite. Both of these computationally inexpensive SR methods are robust to errors in motion, blur estimation, and result in sharp edges. Simulation results confirm the effectiveness of our method and demonstrate its superiority to other robust super-resolution methods.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517329","Super Resolution (SR);Single Frame (SF);Multi Frame (MF);Low Resolution (LR);High Resolution (HR);Image Resolution Enhancement;Frames per Second (FPS/fps);False Color Composite (FCC);Multispectral Scanner (MSS)","Tools;Image edge detection;Mathematical model;Minimization;Spatial resolution;Remote sensing","image resolution;nitrogen compounds;sulphur compounds;water pollution;water resources","single frame technique;multiframe technique;satellite imagery;comparative analysis;robust super-resolution methods;computationally inexpensive SR methods;noise models;multiframe super resolution","","","","5","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Super-Resolution of GF-1 Multispectral Wide Field of View Images via a Very Deep Residual Coordinate Attention Network","R. Liu; B. Cui; X. Fang; B. Guo; Y. Ma; J. An","First Institute of Oceanography, Ministry of Natural Resources, Qingdao, China; College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, China; College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, China; College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, China; First Institute of Oceanography, Ministry of Natural Resources, Qingdao, China; Information Science and Technology College, Dalian Maritime University, Dalian, China","IEEE Geoscience and Remote Sensing Letters","19 Jul 2022","2022","19","","1","5","GF-1 multispectral wide field of view (WFV) images, with a spatial resolution of 16 m, have been widely used in Earth monitoring. However, the spatial details provided by WFV images are not sufficient for many applications. Thus, this letter proposes a novel WFV image super-resolution (SR) algorithm called Gaofen residual coordinate attention network (GFRCAN) based on a very deep residual coordinate attention network. To form a very deep network, the residual-in-residual (RIR) structure consisting of several residual groups (RGs) with long skip connections is used. Meanwhile, the residual coordinate attention block (RCOAB) and adaptive multiscale spatial attention module (AMSA) are incorporated to focus on the high-frequency information and multiscale features adaptive weighted fusion. Besides, the spectral and spatial details of SR images are improved by incorporating peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) into the loss function. Both subjective and objective evaluation results show that the proposed model outperforms the state-of-the-art methods.","1558-0571","","10.1109/LGRS.2022.3190018","National Natural Science Foundation of China(grant numbers:42076189,42106179); China High Resolution Earth Observation System Program(grant numbers:41-Y30F07-9001-20/22); China-Korea Joint Ocean Research Center, China(grant numbers:PI-2022-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9826846","Coordinate attention;GF-1 multispectral wide field of view (WFV);remote sensing images;super-resolution (SR)","Feature extraction;Spatial resolution;Satellites;Training;Image sensors;Data mining;Superresolution","deep learning (artificial intelligence);geophysical image processing;image fusion;image resolution;remote sensing","long skip connections;SSIM;loss function;structural similarity index;PSNR;peak signal-to-noise ratio;multiscale feature adaptive weighted fusion;high-frequency information;AMSA;RCOAB;residual coordinate attention block;residual-in-residual structure;Gaofen residual coordinate attention network;SR algorithm;Earth monitoring;very deep residual coordinate attention network;GF-1 multispectral wide field of view image super-resolution;WFV image super-resolution algorithm;SR images;spectral details;adaptive multiscale spatial attention module;attention block;residual groups;deep network;spatial details;spatial resolution;view images;size 16.0 m","","","","20","IEEE","12 Jul 2022","","","IEEE","IEEE Journals"
"Remote Sensing Image Super-Resolution via Mixed High-Order Attention Network","D. Zhang; J. Shao; X. Li; H. T. Shen","Center for Future Media, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Sichuan Artificial Intelligence Research Institute, Yibin, China; Center for Future Media, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Sichuan Artificial Intelligence Research Institute, Yibin, China","IEEE Transactions on Geoscience and Remote Sensing","21 May 2021","2021","59","6","5183","5196","Recently, remote sensing images have become increasingly popular in a number of tasks, such as environmental monitoring. However, the observed images from satellite sensors often suffer from low-resolution (LR), making it difficult to meet the requirements for further analysis. Super-resolution (SR) aims to increase the image resolution while providing finer spatial details, which perfectly remedies the weakness of satellite images. Therefore, in this article, we propose an innovative mixed high-order attention network (MHAN) for remote sensing SR. It comprises two components: a feature extraction network for feature extraction, and a feature refinement network with high-order attention (HOA) mechanism for detail restoration. In the feature extraction network, we replace the elementwise addition with weighted channelwise concatenation in all skip connections, which greatly facilitates the information flow. In the feature refinement network, rather than exploring the first-order statistics (spatial or channel attention), we introduce the HOA module to restore the missing details. Finally, to fully exploit hierarchical features, we introduce the frequency-aware connection to bridge the feature extraction and feature refinement networks. Experiments on two widely used remote sensing image data sets demonstrate that our MHAN not only obtains better accuracy than the state-of-the-art methods but also shows the superiority in terms of running time and GPU cost. Code is available at https://github.com/ZhangDY827/MHAN.","1558-0644","","10.1109/TGRS.2020.3009918","National Natural Science Foundation of China(grant numbers:61672133,61832001,61632007); Sichuan Science and Technology Program(grant numbers:2019YFG0535); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9151234","Attention;image super-resolution (SR);satellite image","Remote sensing;Feature extraction;Image resolution;Image restoration;Image reconstruction;Task analysis;Satellites","feature extraction;geophysical image processing;geophysical techniques;image reconstruction;image resolution;remote sensing","high-order attention mechanism;feature extraction network;feature refinement network;first-order statistics;hierarchical features;remote sensing image data sets;sensing image super-resolution;image resolution;finer spatial details;satellite images;innovative mixed high-order attention network;remote sensing SR","","44","","54","IEEE","28 Jul 2020","","","IEEE","IEEE Journals"
"Large-Factor Super-Resolution of Remote Sensing Images With Spectra-Guided Generative Adversarial Networks","Y. Meng; W. Li; S. Lei; Z. Zou; Z. Shi","Shanghai Artificial Intelligence Laboratory, Shanghai, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China; AVIC Chengdu Aircraft Industrial (Group) Company Ltd., Chengdu, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China","IEEE Transactions on Geoscience and Remote Sensing","23 Nov 2022","2022","60","","1","11","Large-factor image super-resolution (SR) is a challenging task due to the high uncertainty and incompleteness of the missing details to be recovered. In remote sensing images, the subpixel spectral mixing and semantic ambiguity of ground objects make this task even more challenging. In this article, we propose a novel method for large-factor SR of remote sensing images named spectra-guided generative adversarial networks (SpecGANs). In response to the above problems, we explore whether introducing additional hyperspectral images (HSIs) to GAN as conditional input can be the key to solving the problems. Different from previous approaches that mainly focus on improving the feature representation of a single source input, we propose a dual-branch network architecture to effectively fuse low-resolution (LR) red, green, blue (RGB) images and corresponding HSIs, which fully exploit the rich hyperspectral information as conditional semantic guidance. Due to the spectral specificity of ground objects, the semantic accuracy of the generated images is guaranteed. To further improve the visual fidelity of the generated output, we also introduce the Latent Code Bank with rich visual priors under a generative adversarial training framework so that high-resolution, detailed, and realistic images can be progressively generated. Extensive experiments show the superiority of our method over the state-of-art image SR methods in terms of both quantitative evaluation metrics and visual quality. Ablation experiments also suggest the necessity of adding spectral information and the effectiveness of our designed fusion module. To our best knowledge, we are the first to achieve up to 32x SR of remote sensing images with high visual fidelity under the premise of accurate ground object semantics. Our code can be publicly available at https://github.com/YapengMeng/SpecGAN.","1558-0644","","10.1109/TGRS.2022.3222360","National Key Research and Development Program of China (Titled “Brain-inspired General Vision Models and Applications”); National Natural Science Foundation of China(grant numbers:62125102); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9950553","Deep convolutional neural networks (CNNs);generative adversarial networks (GANs);hyperspectral image (HSI);remote sensing image;super-resolution (SR)","Superresolution;Hyperspectral imaging;Semantics;Task analysis;Visualization;Generative adversarial networks;Image reconstruction","geophysical image processing;image classification;image fusion;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","accurate ground object semantics;additional hyperspectral images;factor super-resolution;generative adversarial training framework;ground objects;large-factor image super-resolution;large-factor SR;realistic images;remote sensing images;spectra-guided generative adversarial networks;state-of-art image SR methods","","","","63","IEEE","14 Nov 2022","","","IEEE","IEEE Journals"
"Remote Sensing Image Super-Resolution via Dual-Resolution Network Based on Connected Attention Mechanism","X. Zhang; Z. Li; T. Zhang; F. Liu; X. Tang; P. Chen; L. Jiao","School of Artificial Intelligence, Xidian University, Xi’an, China; School of Artificial Intelligence, Xidian University, Xi’an, China; School of Artificial Intelligence, Xidian University, Xi’an, China; School of Artificial Intelligence, Xidian University, Xi’an, China; School of Artificial Intelligence, Xidian University, Xi’an, China; School of Artificial Intelligence, Xidian University, Xi’an, China; School of Artificial Intelligence, Xidian University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","28 Jan 2022","2022","60","","1","13","Limited by hardware conditions and complex degradation processes, the obtained remote sensing images (RSIs) are often low-resolution (LR) data with insufficient high-frequency information. Image super-resolution (SR) aims to improve the spatial resolution of images and add reasonable detailed information. Although existing convolutional neural network (CNN)-based methods achieve good performance by adding residual structure and attention mechanism to the network, simply stacking the residual structure and embedding the attention module directly on the residual branch lead to localized use of features and information loss. To address the above problems, we propose a dual-resolution connected attention network (DRCAN). Specifically, a high-resolution (HR) learning branch is constructed to complement the mapping learning between LR images and HR images, and a connected attention module with residual learning is introduced to make full use of the different levels of intermediate layer features. Besides, we collect data at different resolutions from Google Earth to form a dataset named XD IPIU for RSIs SR. Extensive experiments demonstrate the effectiveness of the proposed model and DRCAN shows the state-of-the-art performance in terms of quantitative evaluation and visual quality.","1558-0644","","10.1109/TGRS.2021.3106681","National Natural Science Foundation of China(grant numbers:61772400,61772399,61801351,61871306,61902298); Key Research and Development Program in the Shaanxi Province of China(grant numbers:2019ZDLGY03-08); Key Scientific Research Program of Education Department in Shaanxi Province of China(grant numbers:20JY023); 2018 Postdoctoral Foundation of Shaanxi Province(grant numbers:2018BSHEDZZ46); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530281","Attention mechanism;convolutional neural networks (CNNs);dual-resolution branches;remote sensing images (RSIs);super-resolution (SR)","Image reconstruction;Feature extraction;Hidden Markov models;Remote sensing;Interpolation;Superresolution;Degradation","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image resolution;remote sensing","remote sensing image super-resolution;connected attention mechanism;low-resolution data;spatial image resolution;convolutional neural network;dual-resolution connected attention network;high-resolution learning branch;LR images;connected attention module;residual learning;RSI SR;CNN;Google Earth;XD IPIU dataset;mapping learning;DRCAN","","4","","51","IEEE","6 Sep 2021","","","IEEE","IEEE Journals"
"Single-Image Super-Resolution for Remote Sensing Images Using a Deep Generative Adversarial Network With Local and Global Attention Mechanisms","Y. Li; S. Mavromatis; F. Zhang; Z. Du; J. Sequeira; Z. Wang; X. Zhao; R. Liu","Zhejiang Provincial Laboratory of Geographic Information System (GIS), School of Earth Sciences, Zhejiang University, Hangzhou, China; Laboratory of Computer Science and Systems (LIS), The French National Centre for Scientific Research (CNRS), Aix-Marseille University, Marseille, France; Zhejiang Provincial Laboratory of Geographic Information System (GIS), School of Earth Sciences, Zhejiang University, Hangzhou, China; Zhejiang Provincial Laboratory of Geographic Information System (GIS), School of Earth Sciences, Zhejiang University, Hangzhou, China; Laboratory of Computer Science and Systems (LIS), The French National Centre for Scientific Research (CNRS), Aix-Marseille University, Marseille, France; City Intelligence, Cloud & AI, Huawei Technologies Company Ltd., Shenzhen, China; City Intelligence, Cloud & AI, Huawei Technologies Company Ltd., Shenzhen, China; Zhejiang Provincial Laboratory of Geographic Information System (GIS), School of Earth Sciences, Zhejiang University, Hangzhou, China","IEEE Transactions on Geoscience and Remote Sensing","13 Jan 2022","2022","60","","1","24","Super-resolution (SR) technology is an important way to improve spatial resolution under the condition of sensor hardware limitations. With the development of deep learning (DL), some DL-based SR models have achieved state-of-the-art performance, especially the convolutional neural network (CNN). However, considering that remote sensing images usually contain a variety of ground scenes and objects with different scales, orientations, and spectral characteristics, previous works usually treat important and unnecessary features equally or only apply different weights in the local receptive field, which ignores long-range dependencies; it is still a challenging task to exploit features on different levels and reconstruct images with realistic details. To address these problems, an attention-based generative adversarial network (SRAGAN) is proposed in this article, which applies both local and global attention mechanisms. Specifically, we apply local attention in the SR model to focus on structural components of the earth’s surface that require more attention, and global attention is used to capture long-range interdependencies in the channel and spatial dimensions to further refine details. To optimize the adversarial learning process, we also use local and global attentions in the discriminator model to enhance the discriminative ability and apply the gradient penalty in the form of hinge loss and loss function that combines <inline-formula> <tex-math notation=""LaTeX"">$L1$ </tex-math></inline-formula> pixel loss, <inline-formula> <tex-math notation=""LaTeX"">$L1$ </tex-math></inline-formula> perceptual loss, and relativistic adversarial loss to promote rich details. The experiments show that SRAGAN can achieve performance improvements and reconstruct better details compared with current state-of-the-art SR methods. A series of ablation investigations and model analyses validate the efficiency and effectiveness of our method.","1558-0644","","10.1109/TGRS.2021.3093043","National Key Research and Development Project(grant numbers:2018YFB0505000); Fundamental Research Funds for the Central Universities(grant numbers:2019QNA3013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9479919","Convolutional neural networks (CNNs);generative adversarial network (GAN);local and global attention module;remote sensing;single-image super super-resolution (SISR)","Remote sensing;Feature extraction;Image reconstruction;Spatial resolution;Signal processing algorithms;Biological system modeling;Generative adversarial networks","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image reconstruction;image resolution;remote sensing","single-image super-resolution;remote sensing images;deep generative adversarial network;global attention mechanisms;spatial resolution;deep learning;SR model;convolutional neural network;ground scenes;spectral characteristics;local receptive field;attention-based generative adversarial network;spatial dimensions;adversarial learning process;discriminator model;L1 pixel loss;L1 perceptual loss;relativistic adversarial loss;SRAGAN;gradient penalty;hinge loss;loss function","","4","","78","IEEE","12 Jul 2021","","","IEEE","IEEE Journals"
"Soft-Then-Hard Super-Resolution Mapping Based on Pansharpening Technique for Remote Sensing Image","P. Wang; M. Dalla Mura; J. Chanussot; G. Zhang","College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Grenoble Images Parole Signals Automatics Laboratory, Grenoble Institute of Technology, Grenoble, France; Grenoble Images Parole Signals Automatics Laboratory, Grenoble Institute of Technology, Grenoble, France; College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","21 Jan 2019","2019","12","1","334","344","Super-resolution mapping (SRM) technique can explore the spatial distribution information of land cover classes in mixed pixels for multispectral image (MSI) or hyspectral image (HSI). Soft-then-hard super-resolution mapping (STHSRM) is an important type of SRM technique. STHSRM first utilizes the subpixel sharpening to produce the high-resolution fractional images with the soft attribute values for each subpixel and then allocates the hard class labels to each subpixel. However, due to the low resolution in the original image, the fractional images are difficult to pick up the full spatial-spectral information from the original image. In this paper, pansharpening technique is utilized in STHSRM (STHSRM-PAN) to produce the fractional images with more spatial-spectral information, which improves the mapping results. First, the original low-resolution MSI or HSI and a panchromatic image (PAN) are fused by pansharpening technique to produce the improved resolution image with the high spectral resolution of MSI or HSI and the high spatial resolution of PAN. The high-resolution fractional images with more spatial-spectral information are then obtained by unmixing the improved resolution image. Finally, the class labels are assigned to each subpixel according to the soft attribute values from the high-resolution fractional images. Comparing with the state-of-the-art STHSRM algorithms, the STHSRM-PAN shows the best performance with the percentage correctly classified and Kappa coefficient (Kappa) in the three experimental results.","2151-1535","","10.1109/JSTARS.2018.2885793","National Natural Science Foundation of China(grant numbers:61801211,61871218,61501233,61501228); Fundamental Research Funds for the Central Universities(grant numbers:1004-,YAH18050,3082017NP2017421); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8584054","Pansharpening;remote sensing image;soft-then-hard super-resolution mapping;spatial-spectral information","Spatial resolution;Principal component analysis;Remote sensing;Correlation;Graphical models;Distribution functions","geophysical image processing;geophysical techniques;geophysics computing;image classification;image fusion;image resolution;land cover;remote sensing;terrain mapping","soft-then-hard super-resolution mapping;pansharpening technique;remote sensing image;super-resolution mapping technique;spatial distribution information;hyspectral image;SRM technique;high-resolution fractional images;spatial-spectral information;STHSRM-PAN;low-resolution MSI;panchromatic image;high spectral resolution;high spatial resolution;HSI","","16","","53","IEEE","20 Dec 2018","","","IEEE","IEEE Journals"
"Remote Sensing Image Sharpening by Integrating Multispectral Image Super-Resolution and Convolutional Sparse Representation Fusion","H. Wu; S. Zhao; J. Zhang; C. Lu","School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China","IEEE Access","15 Apr 2019","2019","7","","46562","46574","In remote sensing, it is quite necessary to fuse spectral information of low-resolution multispectral (LRMS) images and spatial information of panchromatic (PAN) images for obtaining high-resolution multispectral (HRMS) images. In this paper, an effective fusion method integrating multispectral (MS) image super-resolution and convolutional sparse representation (CSR) fusion is proposed to make full use of the spatial information of remote sensing images. First, for enhancing the spatial information of LRMS images with suitable sizes, a fast iterative image super-resolution algorithm based on the learned iterative shrinkage and thresholding algorithm (LISTA) is exploited in the first stage. It employs a feed-forward neural network to simplify the solution of sparse coefficients in the process of super-resolution. In the fusion stage, we propose a CSR-based image fusion framework, in which each MS super-resolution image and PAN image is decomposed into a basic layer and a detail layer, then we fuse the basic layers and the detail layers of the images, respectively. This hierarchical fusion strategy guarantees great performance in detail preservation. The experimental results on QuickBird, WorldView-2, and Landsat ETM+ datasets demonstrate that the proposed method outperforms other methods in terms of both objective evaluation and visual effect.","2169-3536","","10.1109/ACCESS.2019.2908968","National Natural Science Foundation of China(grant numbers:61772454,61811540410,61811530332); Scientific Research Fund of Hunan Provincial Education Department(grant numbers:16A008); Postgraduate Training Innovation Base Construction Project of Hunan Province(grant numbers:2017-451-30); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8681072","Remote sensing fusion;super-resolution;learned iterative shrinkage and thresholding algorithm (LISTA);convolutional sparse representation (CSR)","Spatial resolution;Transforms;Remote sensing;Iterative algorithms;Dictionaries;Image fusion","convolutional neural nets;geophysical image processing;image fusion;image representation;image resolution;image segmentation;iterative methods;learning (artificial intelligence);remote sensing","spectral information;low-resolution multispectral images;spatial information;panchromatic images;high-resolution multispectral images;convolutional sparse representation fusion;LRMS images;fast iterative image super-resolution algorithm;thresholding algorithm;CSR-based image fusion framework;hierarchical fusion strategy;multispectral image super-resolution;remote sensing image sharpening;iterative shrinkage learning;PAN images;feed-forward neural network;MS super-resolution image;QuickBird;WorldView-2;Landsat ETM+ datasets","","19","","50","OAPA","3 Apr 2019","","","IEEE","IEEE Journals"
"Stochastic Super-Resolution for Downscaling Time-Evolving Atmospheric Fields With a Generative Adversarial Network","J. Leinonen; D. Nerini; A. Berne","Federal Office of Meteorology and Climatology MeteoSwiss, Locarno-Monti, Switzerland; Federal Office of Meteorology and Climatology MeteoSwiss, Locarno-Monti, Switzerland; Environmental Remote Sensing Laboratory, École Polytechnique fédérale de Lausanne, Lausanne, Switzerland","IEEE Transactions on Geoscience and Remote Sensing","27 Aug 2021","2021","59","9","7211","7223","Generative adversarial networks (GANs) have been recently adopted for super-resolution, an application closely related to what is referred to as “downscaling” in the atmospheric sciences: improving the spatial resolution of low-resolution images. The ability of conditional GANs to generate an ensemble of solutions for a given input lends itself naturally to stochastic downscaling, but the stochastic nature of GANs is not usually considered in super-resolution applications. Here, we introduce a recurrent, stochastic super-resolution GAN that can generate ensembles of time-evolving high-resolution atmospheric fields for an input consisting of a low-resolution sequence of images of the same field. We test the GAN using two data sets: one consisting of radar-measured precipitation from Switzerland; the other of cloud optical thickness derived from the Geostationary Earth Observing Satellite 16 (GOES-16). We find that the GAN can generate realistic, temporally consistent super-resolution sequences for both data sets. The statistical properties of the generated ensemble are analyzed using rank statistics, a method adapted from ensemble weather forecasting; these analyses indicate that the GAN produces close to the correct amount of variability in its outputs. As the GAN generator is fully convolutional, it can be applied after training to input images larger than the images used to train it. It is also able to generate time series much longer than the training sequences, as demonstrated by applying the generator to a three-month data set of the precipitation radar data. The source code to our GAN is available at https://github.com/jleinonen/downscaling-rnn-gan.","1558-0644","","10.1109/TGRS.2020.3032790","Swiss National Science Foundation(grant numbers:#200020_175700); Swiss National Supercomputing Centre (CSCS)(grant numbers:sm35); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9246532","Atmosphere;clouds;image processing;meteorological radar;neural networks;remote sensing","Gallium nitride;Generators;Meteorology;Generative adversarial networks;Training","atmospheric optics;atmospheric precipitation;atmospheric techniques;clouds;geophysics computing;image resolution;remote sensing;remote sensing by radar;stochastic processes;time series;weather forecasting","input images;GAN generator;generated ensemble;super-resolution sequences;data sets;low-resolution sequence;time-evolving high-resolution;stochastic super-resolution GAN;recurrent resolution GAN;super-resolution applications;stochastic nature;stochastic downscaling;conditional GANs;low-resolution images;spatial resolution;atmospheric sciences;generative adversarial network;downscaling time-evolving atmospheric fields","","20","","55","IEEE","2 Nov 2020","","","IEEE","IEEE Journals"
"Super-Resolution for GaoFen-4 Remote Sensing Images","F. Li; L. Xin; Y. Guo; D. Gao; X. Kong; X. Jia","Qian Xuesen Laboratory of Space Technology, Beijing, China; Qian Xuesen Laboratory of Space Technology, Beijing, China; Western Sydney University, Penrith South, NSW, Australia; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Beijing Institute of Spacecraft System Engineering, Beijing, China; School of Electrical Engineering, Australian Defence Force Academy, University of New South Wales, ACT, Australia","IEEE Geoscience and Remote Sensing Letters","27 Dec 2017","2018","15","1","28","32","In this letter, the application of super-resolution (SR) techniques to GaoFen(GF)-4, which is the most advanced geostationary-orbit earth observing satellite in China, remote sensing images is investigated and tested. One of the shortcomings of the geostationary-orbit-based earth observing satellite is the limitation of spatial resolution. However, human beings never stop pursuing higher resolution in images. This is the first experiment of applying SR to a sequence of low-resolution (LR) images captured by GF-4 within a short time period. One of the barriers for applying SR to remote sensing images is the large time gaps between those LR image acquisition, because the reflection characteristic of the ground may change within the time period when those LR images were captured. However, GF-4 has the unique advantage of capturing a sequence of LR images of the same region in minutes, i.e., working as a staring camera from the point view of SR. The reconstructed high-resolution images of some regions in Beijing and Hainan are shown and evaluated in this letter. This letter demonstrates that the application of SR to geostationary-orbit-based earth observation data is feasible and valuable, and it has the potential to be applied to the images acquired by all other geostationary-orbit-based earth observing systems.","1558-0571","","10.1109/LGRS.2017.2768331","National Natural Science Foundation of China(grant numbers:41371415); National Key Research and Development Program of China(grant numbers:2016YFB0501301); National Natural Science Foundation of China(grant numbers:61773383); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8187652","GaoFen-4 (GF-4);maximum a posteriori (MAP);super-resolution (SR)","Spatial resolution;Remote sensing;Satellites;Wavelet transforms;Image reconstruction","artificial satellites;cameras;geophysical image processing;image enhancement;image resolution;remote sensing","low-resolution images;LR image acquisition;high-resolution images;earth observation data;earth observing systems;GaoFen-4 remote sensing images;super-resolution techniques;advanced geostationary-orbit earth observing satellite;Beijing;Hainan;China;ground reflection characteristics;camera","","29","","24","IEEE","12 Dec 2017","","","IEEE","IEEE Journals"
"A Summary Of Super-Resolution For Satellite Videos Via Learning-Based Methods","H. Liu; Y. Gu","School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China","2019 10th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","5 Dec 2019","2019","","","1","4","With the development of remote sensing techniques, remote sensing data can be obtained with higher spatial, higher spectral, and higher temporal resolution. In addition, to get higher spatial resolution, super-resolution for increasing spatial resolution is getting special attention. In this paper, we will focus on some classical learning-based superresolution methods to investigate the adaptability for satellite videos with low imaging quality. Methods include sparse representation, collaborative representation, and deep learning methods. Experiments show that learning-based methods can perform well for single-frame super-resolution for satellite videos. Methods based on deep learning show higher PSNR and SSIM. And multi-frame super-resolution will be good for moving objects. However, it may also bring negative influence for a stationary scene, which is caused by low satellite video quality, such as winkling noise, a vibration of a camera, overexposure of metals.","2158-6276","978-1-7281-5294-3","10.1109/WHISPERS.2019.8920882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920882","Super-Resolution;Satellite Videos;Dictionary Learning;Deep Learning.","Videos;Satellites;Training;Dictionaries;Spatial resolution;Machine learning","geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);remote sensing;video signal processing","satellite videos;learning-based methods;remote sensing techniques;remote sensing data;higher temporal resolution;higher spatial resolution;classical learning-based superresolution methods;low imaging quality;deep learning methods;higher PSNR;multiframe super-resolution;low satellite video quality","","","","7","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Super-Resolution-Based Change Detection Network With Stacked Attention Module for Images With Different Resolutions","M. Liu; Q. Shi; A. Marinoni; D. He; X. Liu; L. Zhang","Guangdong Provincial Key Laboratory for Urbanization and Geo-Simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory for Urbanization and Geo-Simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Department of Engineering, University of Cambridge, Cambridge, U.K.; Guangdong Provincial Key Laboratory for Urbanization and Geo-Simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory for Urbanization and Geo-Simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","13 Jan 2022","2022","60","","1","18","Change detection (CD) aims to distinguish surface changes based on bitemporal images. Since high-resolution (HR) images cannot be typically acquired continuously over time, bitemporal images with different resolutions are often adopted for CD in practical applications. Traditional subpixel-based methods for CD using images with different resolutions may lead to substantial error accumulation when the HR images are employed, which is because of intraclass heterogeneity and interclass similarity. Therefore, it is necessary to develop a novel method for CD using images with different resolutions that are more suitable for the HR images. To this end, we propose a super-resolution-based change detection network (SRCDNet) with a stacked attention module (SAM). The SRCDNet employs a super-resolution (SR) module containing a generator and a discriminator to directly learn the SR images through adversarial learning and overcome the resolution difference between the bitemporal images. To enhance the useful information in multiscale features, a SAM consisting of five convolutional block attention modules (CBAMs) is integrated to the feature extractor. The final change map is obtained through a metric learning-based change decision module, wherein a distance map between bitemporal features is calculated. Ablation study and comparative experiments on two large datasets, building change detection dataset (BCDD) and season-varying change detection dataset (CDD), and a real-image experiment on the Google dataset fully demonstrate the superiority of the proposed method. The source code of SRCDNet is available at <uri>https://github.com/liumency/SRCDNet</uri>.","1558-0644","","10.1109/TGRS.2021.3091758","Program for Guangdong Introducing Innovative and Entrepreneurial Teams(grant numbers:2017ZT07X355); Guangdong Natural Science Foundation(grant numbers:2019A1515011057); National Natural Science Foundation of China(grant numbers:61976234); Open research fund of National Key Laboratory of Surveying, Mapping and Remote Sensing Information Engineering, Wuhan University; Guangzhou Applied Basic Research Project; Center for Integrated Remote Sensing and Forecasting for Arctic Operations (CIRFA); Research Council of Norway (RCN)(grant numbers:237906); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9472869","Change detection (CD);fully convolutional networks (FCNs);metric learning;remote sensing images;super-resolution","Feature extraction;Remote sensing;Superresolution;Spatial resolution;Measurement;Semantics;Data mining","convolutional neural nets;feature extraction;image classification;image resolution;learning (artificial intelligence)","resolution difference;bitemporal images;convolutional block attention modules;metric learning-based change decision module;season-varying change detection dataset;super-resolution-based change detection network;stacked attention module;surface changes;high-resolution images;HR images;super-resolution module;SR images;subpixel-based methods;ablation study","","26","","49","IEEE","2 Jul 2021","","","IEEE","IEEE Journals"
"Remote Sensing Image Super-Resolution via Saliency-Guided Feedback GANs","H. Wu; L. Zhang; J. Ma","School of Artificial Intelligence, BNU, Beijing, China; School of Artificial Intelligence, BNU, Beijing, China; School of Artificial Intelligence, BNU, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","2 Dec 2021","2022","60","","1","16","In remote sensing images (RSIs), the visual characteristics of different regions are versatile, which poses a considerable challenge to single image super-resolution (SISR). Most existing SISR methods for RSIs ignore the diverse reconstruction needs of different regions and thus face a serious contradiction between high perception quality and less spatial distortion. The mean square error (MSE) optimization-based methods produce results of unsatisfactory visual quality, while generative adversarial networks (GANs) can produce photo-realistic but severely distorted results caused by pseudotextures. In addition, increasingly deeper networks, although providing powerful feature representations, also face problems of overfitting and occupying too much storage space. In this article, we propose a new saliency-guided feedback GAN (SG-FBGAN) to address these problems. The proposed SG-FBGAN applies different reconstruction principles for areas with varying levels of saliency and uses feedback (FB) connections to improve the expressivity of the network while reducing parameters. First, we propose a saliency-guided FB generator with our carefully designed paired-feedback block (PFBB). The PFBB uses two branches, a salient and a nonsalient branch, to handle the FB information and generate powerful high-level representations for salient and nonsalient areas, respectively. Then, we measure the visual perception quality of salient areas, nonsalient areas, and the global image with a saliency-guided multidiscriminator, which can dramatically eliminate pseudotextures. Finally, we introduce a curriculum learning strategy to enable the proposed SG-FBGAN to handle complex degradation models. Comprehensive evaluations and ablation studies validate the effectiveness of our proposal.","1558-0644","","10.1109/TGRS.2020.3042515","Beijing Natural Science Foundation(grant numbers:L182029); National Natural Science Foundation of China(grant numbers:61571050,41771407); Beijing Normal University (BNU) Interdisciplinary Research Foundation for the First-Year Doctoral Candidates(grant numbers:BNUXKJC1926); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9301233","Deep learning (DL);generative adversarial network (GAN);remote sensing;saliency detection;super-resolution (SR)","Visualization;Image reconstruction;Generative adversarial networks;Distortion;Gallium nitride;Sensors;Optimization","geophysical image processing;image classification;image reconstruction;image resolution;image texture;learning (artificial intelligence);mean square error methods;remote sensing","SG-FBGAN;feedback connections;saliency-guided FB generator;paired-feedback block;PFBB;nonsalient branch;FB information;high-level representations;nonsalient areas;visual perception quality;global image;saliency-guided multidiscriminator;pseudotextures;remote sensing image super-resolution;RSI;visual characteristics;single image super-resolution;SISR methods;high perception quality;spatial distortion;mean square error optimization-based methods;generative adversarial networks;feature representations;storage space;saliency-guided feedback GAN","","10","","62","IEEE","21 Dec 2020","","","IEEE","IEEE Journals"
"Unsupervised Remote Sensing Image Super-Resolution Method Based on Adaptive Domain Distance Measurement Network","Y. Hou; J. Zhang","Aerospace Information Research Institute, University of Chinese Academy of Sciences, Beijing, China; Aerospace Information Research Institute, University of Chinese Academy of Sciences, Beijing, China","2020 3rd International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)","2 Jul 2020","2020","","","256","259","Compared with supervised learning, unsupervised learning is more practical; however, the associated training process is more difficult and complex. To solve the problems of unstable training and insufficient diversity of generative adversarial networks (GAN), which are widely used to realize unsupervised learning, we propose a novel unsupervised remote sensing image super-resolution method based on a reverse generating network module and the adaptive domain distance measurement network. The discriminant network of GAN is considered as a tool to measure a certain image attribute instead of the original GAN binary classification network. Furthermore, the adaptive domain distance measurement network is used to back feed the information of a high-resolution image to guide the optimization of the generating network. The results of experiments performed on various datasets demonstrate the effectiveness of the proposed method.","","978-1-7281-8143-1","10.1109/AEMCSE50948.2020.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9131243","GAN;remote senseng;super resolution;domain","","geophysical image processing;image resolution;pattern classification;remote sensing;unsupervised learning","unsupervised remote sensing image super-resolution method;adaptive domain distance measurement network;supervised learning;unsupervised learning;generative adversarial networks;reverse generating network module;discriminant network;original GAN binary classification network;high-resolution image","","3","","15","IEEE","2 Jul 2020","","","IEEE","IEEE Conferences"
"An Improved Hyperspectral Image Super Resolution Restoration Algorithm Based on POCS","Y. Wang; X. He; Y. Shi; Q. Zhu; H. Yu","State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xian, China; Center for Hyperspectral Imaging in Remote Sensing (CHIRS), Information Science and Technology College, Dalian Maritime University, Dalian, China; Center for Hyperspectral Imaging in Remote Sensing (CHIRS), Information Science and Technology College, Dalian Maritime University, Dalian, China; Center for Hyperspectral Imaging in Remote Sensing (CHIRS), Information Science and Technology College, Dalian Maritime University, Dalian, China; Center for Hyperspectral Imaging in Remote Sensing (CHIRS), Information Science and Technology College, Dalian Maritime University, Dalian, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2460","2463","Super-resolution reconstruction is a rapidly growing research area in hyperspectral data processing. However, there exist some problems, such as edge blur, burr in the smooth area, subjective design of iteration times, et al. This paper analyzes the causes of blur and burr, and puts forward some countermeasures according to these problems. Firstly, gradient interpolation is used instead of the traditional nearest neighbor interpolation, which alleviates the edge blur to a certain extent problem, the projection operator calculated from the gradient map is introduced into the projection formula to solve the burr phenomenon in the smooth area. Then, the mean square error of the reconstructed image of adjacent iterations is used to measure the similarity of the reconstructed image between two adjacent iterations, which is used as the stopping criterion of iterations, avoiding the subjectivity of setting the iteration times artificially. Finally, the proposed algorithm is applied to every band of hyperspectral image. Experimental results show that the proposed algorithm has better performance than the traditional POCS algorithm in visual effect and quantitative criteria.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553830","China Postdoctoral Science Foundation(grant numbers:2020M670723,2020M680925); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553830","POCS;super resolution reconstruction;gradient interpolation;relaxation operator;adaptive iteration","Interpolation;Image edge detection;Simulation;Superresolution;Measurement uncertainty;Mean square error methods;Reconstruction algorithms","geophysical image processing;gradient methods;image reconstruction;image resolution;image restoration;interpolation;iterative methods","improved hyperspectral image super resolution restoration algorithm;super-resolution reconstruction;hyperspectral data processing;edge blur;smooth area;subjective design;iteration times;gradient interpolation;traditional nearest neighbor interpolation;extent problem;projection operator;gradient map;projection formula;burr phenomenon;mean square error;reconstructed image;adjacent iterations;traditional POCS algorithm","","","","5","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Remote Sensing Image Super-Resolution Using Sparse Representation and Coupled Sparse Autoencoder","Z. Shao; L. Wang; Z. Wang; J. Deng","Collaborative Innovation Center for Geospatial Technology, Wuhan, China; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, Wuhan, China; School of Electronic Information, Wuhan University, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20 Sep 2019","2019","12","8","2663","2674","Remote sensing image super-resolution (SR) refers to a technique improving the spatial resolution, which in turn benefits to the subsequent image interpretation, e.g., target recognition, classification, and change detection. In popular sparse representation-based methods, due to the complex imaging conditions and unknown degradation process, the sparse coefficients of low-resolution (LR) observed images are hardly consistent with the real high-resolution (HR) counterparts, which leads to unsatisfactory SR results. To address this problem, a novel coupled sparse autoencoder (CSAE) is proposed in this paper to effectively learn the mapping relation between the LR and HR images. Specifically, the LR and HR images are first represented by a set of sparse coefficients, and then, a CSAE is established to learn the mapping relation between them. Since the proposed method leverages the feature representation ability of both sparse decomposition and CSAE, the mapping relation between the LR and HR images can be accurately obtained. Experimentally, the proposed method is compared with several state-of-the-art image SR methods on three real-world remote sensing image datasets with different spatial resolutions. The extensive experimental results demonstrate that the proposed method has gained solid improvements in terms of average peak signal-to-noise ratio and structural similarity measurement on all of the three datasets. Moreover, results also show that with larger upscaling factors, the proposed method achieves more prominent performance than the other competitive methods.","2151-1535","","10.1109/JSTARS.2019.2925456","National Key Technologies Research and Development Program(grant numbers:2016YFE0202300,2016YFB0502603); National Natural Science Foundation of China(grant numbers:61671332,41771452,41771454); Fundamental Research Funds for the Central Universities(grant numbers:2042016kf0179,2042016kf1019); Special Task of Technical Innovation in Hubei Province(grant numbers:2017AAA123); Natural Science Fund of Hubei Province(grant numbers:2018CFA007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758165","Coupled sparse autoencoder (CSAE);image super-resolution (SR);remote sensing image;sparse representation","Dictionaries;Image reconstruction;Remote sensing;Training;Spatial resolution;Sparse matrices","geophysical image processing;image classification;image reconstruction;image representation;image resolution;learning (artificial intelligence);remote sensing","subsequent image interpretation;popular sparse representation-based methods;complex imaging conditions;sparse coefficients;low-resolution observed images;high-resolution counterparts;unsatisfactory SR results;sparse autoencoder;CSAE;mapping relation;feature representation ability;sparse decomposition;state-of-the-art image SR methods;image datasets;sensing image super-resolution;spatial resolution","","69","","38","IEEE","9 Jul 2019","","","IEEE","IEEE Journals"
"Estimation of relative sensor characteristics for hyperspectral super-resolution","C. Lanaras; E. Baltsavias; K. Schindler","Photogrammetry and Remote Sensing, ETH Zürich; Photogrammetry and Remote Sensing, ETH Zürich; Photogrammetry and Remote Sensing, ETH Zürich","2016 8th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","19 Oct 2017","2016","","","1","5","To enhance the spatial resolution of hyperspectral data, additional multispectral images of higher resolution can be used. However, to combine the two data sources information about the sensors is needed. In this paper we derive a model to estimate the relative spatial and spectral response of the two sensors. The proposed formulation includes non-negativity, recovers remaining registration (shift) errors, and uses prior information to adjust to the shape of the spectral response with either l1 or l2 norm regularization. The framework is tested both with real data and with simulated data where the ground truth is known.","2158-6276","978-1-5090-0608-3","10.1109/WHISPERS.2016.8071757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8071757","relative spectral response;relative spatial;response;hyperspectral super-resolution","Spatial resolution;Hyperspectral imaging;Kernel;Estimation;Channel estimation","hyperspectral imaging;image registration;remote sensing;sensors","registration errors;data sources information;multispectral images;hyperspectral super-resolution;hyperspectral data spatial resolution;relative sensor characteristics estimation;l2 norm regularization;l1 norm regularization","","","","12","IEEE","19 Oct 2017","","","IEEE","IEEE Conferences"
"Multi-Receptive-Fields Convolutional Network for Remote Sensing Images Super-Resolution","H. Wang; Q. Hu; J. Chi; C. Wu; X. Yu","College of Robot Science and Engineering, Northeastern University, Shenyang; College of Information Science and Engineering, Northeastern University, Shenyang; College of Robot Science and Engineering, Northeastern University, Shenyang; College of Robot Science and Engineering, Northeastern University, Shenyang; College of Robot Science and Engineering, Northeastern University, Shenyang","2021 33rd Chinese Control and Decision Conference (CCDC)","30 Nov 2021","2021","","","1525","1530","Recently, single image super-resolution (SISR) has been widely applied in the field of remote sensing image processing and obtained remarkable performance, focusing on restoring the high-resolution (HR) image from a low-resolution (LR) image. However, we observe that the existing CNN-based SISR methods mainly focus on wider or deeper architecture design, neglecting to exploit features at global receptive field. Moreover, the LR inputs and features contain abundant low-frequency information, which are perceived equally in the same receptive field, hence limiting the representational ability of CNNs. To solve these problems, we propose a Multi-Receptive-Fields Super Resolution Network (MRFSR) for remote sensing image reconstruction. The proposed network employs non-local neural network to enhance low-level complex features by expanding the receptive field of the shallow convolution layer. Moreover, we propose the multi-branch up- and down-sampling modules to deal with LR features in multiple receptive fields, which can enhance the high-frequency components and learn abstract feature representations in multiple scales, respectively. Extensive experiments on NPU-RESISC45 dataset shows that the proposed MRFSR can provide state-of-the-art or even better performance in both quantitative and qualitative measurements.","1948-9447","978-1-6654-4089-9","10.1109/CCDC52312.2021.9601623","National Natural Science Foundation of China(grant numbers:61701101,61973093,61901098,61971118,U20A20197); Fundamental Research Fund for the Central Universitiesof China(grant numbers:N2026005,N181602014,N2026004,N2026006,N2026001,N2011001); Project for the science and technology major special plan of Liaoning(grant numbers:2019JH1/10100005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9601623","Deep Learning;Convolutional Neural Network;Super Resolution;Remote Sensing Image","Training;Limiting;Convolution;Superresolution;Neural networks;Focusing;Sensors","convolutional neural nets;geophysical image processing;image enhancement;image reconstruction;image representation;image resolution;image sampling;remote sensing","abstract feature representation learning;remote sensing image super-resolution;single image super-resolution;remote sensing image processing;high-resolution image restoration;low-resolution image restoration;CNN-based SISR methods;architecture design;global receptive field;LR inputs;low-frequency information;remote sensing image reconstruction;nonlocal neural network;shallow convolution layer;LR features;multiple receptive fields;high-frequency components;multireceptive-field super resolution network;multireceptive-field convolutional network;representational ability;MRFSR;low-level complex feature enhancement;multibranch upsampling modules;multibranch downsampling modules;qualitative measurements;quantitative measurements","","","","39","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Data Augmentation for Multi-Image Super-Resolution","M. Ziaja; J. Nalepa; M. Kawulok","Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland; Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland; Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","119","122","Super-resolution reconstruction consists in generating a high-resolution image from a single low-resolution image or multiple images presenting the same area of interest. Existing state-of-the-art approaches to single-image and multi-image super-resolution are based on deep learning that requires large amounts of training data. They are commonly obtained by simulating low-resolution images from an original image treated as a high-resolution reference, but such simulation may not reflect the real-life operating conditions. Therefore, a serious obstacle in deploying super-resolution in real-world cases results from the lack of training data that would encompass real low-resolution images coupled with a real high-resolution reference. In this paper, we propose a new data augmentation technique underpinned with learning the relation between high and low resolution. This helps reduce the requirements concerned with the amount of real-life data necessary to train a super-resolution network, while providing higher-quality data for training, compared with the simulated low-resolution images. Our initial experimental results reported in the paper confirm that the proposed approach is suitable for multi-image super-resolution.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884609","European Space Agency; National Science Centre, Poland(grant numbers:2019/35/B/ST6/03006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884609","Super-resolution reconstruction;data augmentation;deep learning;multi-image super-resolution","Training;Deep learning;Superresolution;Training data;Geoscience and remote sensing;Image reconstruction","image reconstruction;image resolution;learning (artificial intelligence)","multiimage super-resolution;super-resolution reconstruction;high-resolution image;low-resolution image;multiple images;single-image;training data;high-resolution reference;high resolution;super-resolution network","","","","15","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Toward Faster and Accurate Post-Disaster Damage Assessment: Development of End-to-End Building Damage Detection Framework with Super-Resolution Architecture","X. Fu; T. Kouyama; H. Yang; R. Nakamura; I. Yoshikawa","National Institute of Advance Industrial Science and Technology, Tokyo, Japan; National Institute of Advance Industrial Science and Technology, Tokyo, Japan; The University of Tokyo, Tokyo, Japan; National Institute of Advance Industrial Science and Technology, Tokyo, Japan; The University of Tokyo, Tokyo, Japan","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1588","1591","Building damage detection (BDD) with satellite images has been frequently adopted as an essential reference for post-disaster rescue, whereas its timeliness is significantly impacted by the long revisit time of high-resolution remote sensing satellites. Therefore, a reliable super-resolution method which is optimized for accurate and detail BDD is fundamental one for advancing the BDD analysis even when we can use only low-resolution images after a disaster. Based on Super-Resolution Generative Adversarial Network (SRGAN) and U-Net convolutional network, an efficient and novel BDD framework is proposed in this paper for obtaining upsampled BDD results from low-resolution post-disaster images. We trained the framework using two disasters from the xBD dataset and tested three different structures. The results show that our training structure based on an end-to-end framework successfully generated super-resolution BDD maps from low-resolution images, which performed significantly better than those from a two-stage training structure.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883317","Super-resolution;building damage;xBD dataset;end-to-end network;deep learning","Training;Satellites;Architecture;Superresolution;Buildings;Generative adversarial networks;Reliability","buildings (structures);convolutional neural nets;disasters;geophysical image processing;image resolution;remote sensing","Super-Resolution Generative Adversarial Network;U-Net convolutional network;low-resolution post-disaster images;super-resolution BDD maps;post-disaster damage assessment;satellite images;post-disaster rescue;high-resolution remote sensing satellites;end-end building damage detection framework;SRGAN","","","","11","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Integration of region growing and morphological analysis with super-resolution land cover mapping","H. Jin; P. Li","Department of Geographical Sciences, University of Maryland, College Park, MD, USA; Institute of Remote Sensing and GIS, Peking University, Beijing, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","5099","5102","Converting probability maps derived from indicator cokriging (ICK) to a specific land cover classification map is the second step of super-resolution mapping (SRM) under the geostatistical framework. In this study, two image segmentation strategies, namely mathematical morphology and region growing, were applied on the ICK-derived probability maps in order to take into account spatial characteristics such as shape and connectivity. A case study in South Carolina (USA) showed that the thematic map created by the proposed method had an overall accuracy improved by 2% and Kappa improved by 6% compared to the map derived from the existing sequential generation process. This indicates our methodology as a promising alternative that can be embedded into SRM tasks.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730329","Super-resolution mapping (SRM);Probability maps;Morphological analysis;Region Growing","Roads;Image segmentation;Spatial resolution;Remote sensing;Shape;Morphological operations","geophysical image processing;image classification;image segmentation;land cover;probability","region morphological analysis;super-resolution land cover mapping;indicator cokriging;land cover classification map;super-resolution mapping;geostatistical framework;image segmentation strategy;mathematical morphology;region growing;ICK-derived probability map;south Carolina;USA","","","","7","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Learning an Intrinsic Graph Neural Network for Sartellite Video Super-Resolution","Y. Xiao; X. Su; Q. Yuan","School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","3751","3753","Existing video super-resolution (VSR) methods usually merge the redundant temporal information along frames to achieve information enhancement, which naturally discards the spatial redundancy information. This paper proposes an intrinsic Graph Neural Network (GNN) framework for satellite VSR to fully explore the internal spatial prior while considering the temporal information in the video frame sequence. Firstly, a Multi-Scale Deformable convolution (MSD) is adopted to accurately model the spatial-temporal relationship between frames. Then, we search for k-nearest neighbors to construct the spatial graph and profoundly excavate the prior spatial information brought by patch recurrence. Finally, the spatial-temporal redundant information is integrated and complementary. Experiments on Jilin-1 satellite video demonstrate the effectiveness of our framework.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883316","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883316","Satellite video;super-resolution;graph neural network;deep learning","Deformable models;Satellites;Convolution;Superresolution;Redundancy;Geoscience and remote sensing;Graph neural networks","graph theory;image resolution;image sequences;learning (artificial intelligence);neural nets;video signal processing","sartellite video super-resolution;video super-resolution methods;redundant temporal information;information enhancement;spatial redundancy information;intrinsic Graph Neural Network framework;satellite VSR;internal spatial;video frame sequence;MultiScale Deformable convolution;spatial-temporal relationship;spatial graph;prior spatial information;spatial-temporal redundant information;Jilin-1 satellite video","","","","5","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Gradient Enhanced Dual Regression Network: Perception-Preserving Super-Resolution for Multi-Sensor Remote Sensing Imagery","Z. Zhang; K. Gao; J. Wang; L. Min; S. Ji; C. Ni; D. Chen","Key Laboratory of Photoelectronic Imaging Technology and System, Ministry of Education, Beijing Institute of Technology, Beijing, China; Key Laboratory of Photoelectronic Imaging Technology and System, Ministry of Education, Beijing Institute of Technology, Beijing, China; Key Laboratory of Photoelectronic Imaging Technology and System, Ministry of Education, Beijing Institute of Technology, Beijing, China; Key Laboratory of Photoelectronic Imaging Technology and System, Ministry of Education, Beijing Institute of Technology, Beijing, China; Key Laboratory of Photoelectronic Imaging Technology and System, Ministry of Education, Beijing Institute of Technology, Beijing, China; Institute of Spacecraft System Engineering, CAST, Beijing, China; Institute of Spacecraft System Engineering, CAST, Beijing, China","IEEE Geoscience and Remote Sensing Letters","10 Jan 2022","2022","19","","1","5","Most existing learning-based single image super-resolution (SISR) methods mainly focus on improving reconstruction accuracy, but they always generate overly smoothed results that fail to match the visual perception. Although perceptual quality can be greatly improved via introducing adversarial loss, image fidelity may decrease to some extent. Moreover, most methods are trained and evaluated on simulated datasets and their performance would drop significantly on real remote sensing imagery. To solve the above problems, we propose a new SISR algorithm named gradient enhanced dual regression network (GEDRN). Based on the dual regression framework, we use share-source residual structure and non-local operation to learn abundant low-frequency information and long-distance spatial correlations. Besides, we not only introduce additional gradient information to avoid blurry results but also apply gradient loss and perceptual loss to further improve the perceptual quality. Our GEDRN is trained and tested on real-world multi-sensor satellite images. Experimental results demonstrate the superiority of the proposed method in achieving much better perceptual quality and ensuring high fidelity.","1558-0571","","10.1109/LGRS.2021.3134798","Qian Xuesen Laboratory of Space Technology(grant numbers:GZZKFJJ2020004); National Natural Science Foundation of China(grant numbers:61875013,61827814); Natural Science Foundation of Beijing Municipality(grant numbers:Z190018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9646910","Convolutional neural networks (CNNs);gradient enhanced dual regression network (GEDRN);multi-sensor satellite imagery;super-resolution","Image reconstruction;Remote sensing;Feature extraction;Convolution;Superresolution;Task analysis;Space vehicles","geophysical image processing;gradient methods;image reconstruction;image resolution;image sensors;learning (artificial intelligence);regression analysis;remote sensing","gradient enhanced dual regression network;perception-preserving super-resolution;multisensor remote sensing imagery;learning-based single image super-resolution methods;visual perception;perceptual quality;image fidelity;SISR algorithm;dual regression framework;long-distance spatial correlations;gradient information;gradient loss;perceptual loss;real-world multisensor satellite images","","1","","28","IEEE","10 Dec 2021","","","IEEE","IEEE Journals"
"Learning Spectral and Spatial Features Based on Generative Adversarial Network for Hyperspectral Image Super-Resolution","R. Jiang; X. Li; A. Gao; L. Li; H. Meng; S. Yue; L. Zhang","School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; Department of Electronic and Computer Engineering, Brunel University London, UK; School of Computer Science, University of Lincoln, Lincoln, UK; Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3161","3164","Super-resolution (SR) of hyperspectral images (HSIs) aims to enhance the spatial/spectral resolution of hyperspectral imagery and the super-resolved results will benefit many remote sensing applications. A generative adversarial network for HSIs super-resolution (HSRGAN) is proposed in this paper. Specifically, HSRGAN constructs spectral and spatial blocks with residual network in generator to effectively learn spectral and spatial features from HSIs. Furthermore, a new loss function which combines the pixel-wise loss and adversarial loss together is designed to guide the generator to recover images approximating the original HSIs and with finer texture details. Quantitative and qualitative results demonstrate that the proposed HSRGAN is superior to the state of the art methods like SRCNN and SRGAN for HSIs spatial SR.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900228","Hyperspectral images;super-resolution;generative adversarial network;residual network","Spatial resolution;Generative adversarial networks;Generators;Hyperspectral imaging","geophysical image processing;hyperspectral imaging;image enhancement;image resolution;image texture;learning (artificial intelligence);remote sensing","spectral features;spatial features;generative adversarial network;hyperspectral image super-resolution;hyperspectral imagery;super-resolved results;remote sensing applications;HSIs super-resolution;HSRGAN;spatial blocks;residual network;loss function;pixel-wise loss;adversarial loss;original HSIs;HSIs spatial SR","","7","","7","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Deep Intra Fusion for Hyperspectral Image Super-Resolution","J. Hu; H. Chen; M. Zhao; Y. Li","School of Computer Science and Engineering, Xi'an University of Technology, Xi'an, China; School of Computer Science and Engineering, Xi'an University of Technology, Xi'an, China; School of Computer Science and Engineering, Xi'an University of Technology, Xi'an, China; Joint Laboratory of High Speed Multi-source Image Coding and Processing, Xi'an University, Xi'an, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","2663","2666","Hyperspectral image (HSI) super-resolution is currently attracting great interest in remote sensing, since it allows the generation of high spatial resolution HSIs and circumventing the main limitation of the imagery sensors. This paper proposes a novel deep intra fusion network (IFN) for the HSI super-resolution, in which both the spatial and the spectral information have been fully and automatically exploited. Specifically, parallel convolutions are applied to two adjacent bands and their difference band, and obtain the high-dimensional features. Meanwhile, an automatically aggregation module is applied in the IFN to achieve the intra-fusion between these features. In this way, both the spatial information of the current band and the spectral information between neighboring bands are utilized in the super-resolving process. Experimental results and data analysis suggest the effectiveness of the proposed method.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324536","National Natural Science Foundation of China(grant numbers:61901362); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324536","hyperspectral image;super-resolution;deep intra fusion network","Superresolution;Spatial resolution;Training;Hyperspectral imaging;Feature extraction;Sensors;Kernel","data analysis;geophysical image processing;hyperspectral imaging;image reconstruction;image resolution;remote sensing","hyperspectral image super-resolution;remote sensing;high spatial resolution HSIs;imagery sensors;deep intra fusion network;IFN;HSI super-resolution;spectral information;adjacent bands;difference band;high-dimensional features;automatically aggregation module;intra-fusion;spatial information;current band;neighboring bands;super-resolving process","","","","12","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Deep Learning for Downscaling Remote Sensing Images: Fusion and super-resolution","M. Sdraka; I. Papoutsis; B. Psomas; K. Vlachos; K. Ioannidis; K. Karantzalos; I. Gialampoukidis; S. Vrochidis","Institute of Astronomy, Astrophysics, Space Applications, and Remote Sensing, National Observatory of Athens, Athens, Greece; Institute of Astronomy, Astrophysics, Space Applications, and Remote Sensing, National Observatory of Athens, Athens, Greece; Athena Research Center, Greece; Information Technologies Institute, Center for Research and Technology Hellas, Thessaloniki, Thessaloniki, Greece; Information Technologies Institute, Center for Research and Technology Hellas, Thessaloniki, Thessaloniki, Greece; National Technical University of Athens, Athens, Greece; Information Technologies Institute, Center for Research and Technology Hellas, Thessaloniki, Thessaloniki, Greece; Information Technologies Institute, Center for Research and Technology Hellas, Thessaloniki, Thessaloniki, Greece","IEEE Geoscience and Remote Sensing Magazine","2 Nov 2022","2022","10","3","202","255","The past few years have seen an accelerating integration of deep learning (DL) techniques into various remote sensing (RS) applications, highlighting their power to adapt and achieving unprecedented advancements. In the present review, we provide an exhaustive exploration of the DL approaches proposed specifically for the spatial downscaling of RS imagery. A key contribution of our work is the presentation of the major architectural components and models, metrics, and data sets available for this task as well as the construction of a compact taxonomy for navigating through the various methods. Furthermore, we analyze the limitations of the current modeling approaches and provide a brief discussion on promising directions for image enhancement, following the paradigm of general computer vision (CV) practitioners and researchers as a source of inspiration and constructive insight.","2168-6831","","10.1109/MGRS.2022.3171836","DeepCube(grant numbers:101004188); NEANIAS(grant numbers:863448); CALLISTO(grant numbers:101004152); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9786720","","Synthetic aperture radar;Feature extraction;Remote sensing;Hyperspectral imaging;Image enhancement;Computer vision;Deep learning;Superresolution;Satellites","computer vision;data integration;geophysical image processing;geophysical techniques;image enhancement;image resolution;remote sensing;statistical analysis","accelerating integration;architectural components;compact taxonomy;current modeling approaches;data sets;deep learning techniques;DL approaches;downscaling remote sensing images;exhaustive exploration;image enhancement;remote sensing applications;RS imagery;spatial downscaling;super-resolution;unprecedented advancements","","2","","267","IEEE","2 Jun 2022","","","IEEE","IEEE Magazines"
"An image sharpening strategy based on multiframe super resolution for multispectral data","J. Sun; Q. Lv; Z. Tan; Y. Liu","Key Laboratory of Computational Optical Imaging Technology, Academy of Opto-Electronics, Chinese Academy of Sciences, Beijing, Beijing, CN; Key Laboratory of Computational Optical Imaging Technology, Academy of Opto-Electronics, Chinese Academy of Sciences, Beijing, Beijing, CN; Key Laboratory of Computational Optical Imaging Technology, Academy of Opto-Electronics, Chinese Academy of Sciences, Beijing, Beijing, CN; Key Laboratory of Computational Optical Imaging Technology, Academy of Opto-Electronics, Chinese Academy of Sciences, Beijing, Beijing, CN","2016 8th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","19 Oct 2017","2016","","","1","5","Spatial resolution is one of the most important assessments to evaluate an image. Enhancing spatial resolution consequently becomes a hot issue. As is all known, multispectral (MS) image, which is widely studied in remote sensing (RS) field, can be fused with the corresponding high-resolution panchromatic image to promote spatial-quality. In this paper, we consider the question regarding how to enhance the spatial resolution of multispectral image in the case that we do not have high-resolution panchromatic image. The only inputs are the MS data and the same spatial-resolution multi-frame panchromatic image. This paper addresses the application of super-resolution (SR) reconstruction technique and provides a suggestion for MS image sharpening. We generate a high-resolution panchromatic image based on SR. Then we adjust it and the low-resolution MS image into the same size. At last, we fuse them via a hybrid image sharpening technique. Experiments demonstrated an effective processing result and a good performance.","2158-6276","978-1-5090-0608-3","10.1109/WHISPERS.2016.8071718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8071718","Multispectral image;spatial resolution;super resolution;image sharpening","Spatial resolution;Optical filters;Image reconstruction;Filtering algorithms;Principal component analysis;Wavelet transforms","image enhancement;image fusion;image reconstruction;image resolution;image sensors;remote sensing","image sharpening strategy;multiframe super resolution;multispectral data;remote sensing field;spatial-quality;spatial-resolution multiframe panchromatic image;super-resolution reconstruction technique;MS image sharpening;low-resolution MS image;hybrid image sharpening technique;multispectral image;high-resolution panchromatic image","","","","13","IEEE","19 Oct 2017","","","IEEE","IEEE Conferences"
"A Survey of Hyperspectral Image Super-Resolution Technology","M. Zhang; X. Sun; Q. Zhu; G. Zheng","School of Geography and Information Engineering, China University of Geosciences, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan, China; School of Geography and Information Engineering, China University of Geosciences, Wuhan, China; School of Geography and Information Engineering, China University of Geosciences, Wuhan, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","4476","4479","Hyperspectral images (HSIs) have very high spectral resolution, which can reflect the characteristics of different materials well. However, compared with RGB image or multispectral image (MSI), the spatial resolution of HSI is much lower, which limits its applications. Therefore, many super-resolution (SR) techniques have been proposed to reconstruct HSI with high spatial resolution image. To the best of our knowledge, there has not, to date, that been a study aimed at expatiating and summarizing the current research situation. Therefore, this is our motivation in this survey. In view of the promising development prospects in this field, this paper systematically reviews the existing SR methods of HSI. Specifically, two major categories are summarized, one is fusion-based methods, and the other is single HSI SR methods. At the end of the paper, several future development directions for HSI SR are given.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554409","National Natural Science Foundation of China(grant numbers:41901306); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554409","Hyperspectral remote sensing;image super-resolution;image fusion;singe HSI SR;deep learning","Image sensors;Superresolution;Sensors;Spatial resolution;Image reconstruction;Hyperspectral imaging","geophysical image processing;hyperspectral imaging;image reconstruction;image resolution","hyperspectral image super-resolution technology;high spectral resolution;multispectral image;super-resolution techniques;high spatial resolution image;current research situation;single HSI SR methods;RGB image;MSI","","5","","31","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Hyperspectral Imagery Super-Resolution Based on Self-Calibrated Attention Residual Network","B. Wang; S. Mei; Y. Feng; Q. Du","School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; Department of Electrical and Computer Engineering, Mississippi State University, Starkville, MS, USA","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3896","3899","Hyperspectral remote sensing images are well-known for their abundant spectral characteristics to discriminate different object materials. However, due to the constraints of sensor limitations and exceedingly high acquisition costs, it is difficult to obtain high spatial resolution hyperspectral imagery. Though many methods have been focusing on the restoration of the spatial structure information, spectral information may be over-smoothed during such spatial super-resolution. In this paper, a novel self-calibrated attention residual network (SCARN) is proposed to increase spatial resolution of hyperspectral images while retain spectral consistency. In particular, a self-calibrated attention residual block (SCARB) is elaborately designed to fully exploit the spatial information and the correlation between the spectra of the hyperspectral data. Concretely, self-calibrated convolution, instead of standard convolution, is adopted to adaptively construct long-range spatial and spectral dependencies around each spatial location of hyperspectral imagery, and attention module is inserted to improve the representation ability of spectral information. Finally, global and local residual connections are designed to ease the network training difficulty and maintain a higher restoration accuracy. Experimental results over two benchmark hyperspectral datasets demonstrate the effectiveness and superiority of the proposed SCARN method against the state-of-the-art methods.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554761","hyperspectral imagery;self-calibrated convolution;residual connection;super-resolution","Training;Correlation;Convolution;Superresolution;Feature extraction;Image restoration;Spatial resolution","calibration;geophysical image processing;hyperspectral imaging;image classification;image reconstruction;image resolution;remote sensing","hyperspectral imagery super-resolution;self-calibrated attention residual network;hyperspectral remote sensing images;abundant spectral characteristics;different object materials;exceedingly high acquisition costs;high spatial resolution hyperspectral imagery;spatial structure information;spectral information;spatial super-resolution;hyperspectral images;spectral consistency;attention residual block;spatial information;hyperspectral data;self-calibrated convolution;long-range spatial;spectral dependencies;spatial location;attention module;global connections;local residual connections;network training difficulty;benchmark hyperspectral datasets","","1","","8","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Super-Resolution of Multispectral Multiresolution Images from a Single Sensor","C. Lanaras; J. Bioucas-Dias; E. Baltsavias; K. Schindler","Photogrammetry and Remote Sensing, ETH, Zürich; Instituto de Telecomunicações, Universidade de Lisboa; Photogrammetry and Remote Sensing, ETH, Zürich; Photogrammetry and Remote Sensing, ETH, Zürich","2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","24 Aug 2017","2017","","","1505","1513","Some remote sensing sensors, acquire multispectral images of different spatial resolutions in variable spectral ranges (e.g. Sentinel-2, MODIS). The aim of this research is to infer all the spectral bands, of multiresolution sensors, in the highest available resolution of the sensor. We formulate this problem as a minimisation of a convex objective function with an adaptive (edge-reserving) regulariser. The data-fitting term accounts for individual blur and downsampling per band, while the regulariser ""learns"" the discontinuities from the higher resolution bands and transfers them to other bands. We also observed that the data can be represented in a lower-dimensional subspace, reducing the dimensionality of the problem and significantly improving its conditioning. In a series of experiments with simulated data, we obtain results that outperform state-of-the-art, while showing competitive qualitative results on real Sentinel-2 data.","2160-7516","978-1-5386-0733-6","10.1109/CVPRW.2017.194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8014928","","Spatial resolution;Signal resolution;Remote sensing;MODIS;Monitoring;Estimation","geophysical image processing;image resolution;image sampling;remote sensing","multispectral multiresolution images;super-resolution;single sensor;remote sensing sensors;variable spectral ranges;convex objective function;adaptive regulariser;data-fitting term;downsampling;lower-dimensional subspace;Sentinel-2 data","","29","","23","IEEE","24 Aug 2017","","","IEEE","IEEE Conferences"
"Shape characterization of land covers using super-resolution mapping","A. M. Muad","Department of Electrical, Universiti Kebangsaan Malaysia, Selangor, Malaysia","2017 IEEE 8th Control and System Graduate Research Colloquium (ICSGRC)","19 Oct 2017","2017","","","57","61","This paper presents a representation of land cover from a popular low spatial resolution of remote sensing image, MODIS 250 m. The spatial resolution of the MODIS image is enhanced using super-resolution mapping to a resolution that is equal to resolution of Landsat ETM+, which is 30 m. Two super-resolution mapping techniques, Hopfleld neural network and pixel swapping are used to represent the land covers as patch objects. Parameters for both techniques are varies to investigate their impact towards the characterization of the object in a single MODIS image and also in a time-series MODIS images.","","978-1-5386-0380-2","10.1109/ICSGRC.2017.8070568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8070568","Remote sensing;Hopfield neural network;pixel swapping;object based remote sensing;MODIS;Landsat","Lakes;MODIS;Spatial resolution;Remote sensing;Earth;Shape;Satellites","geophysical image processing;image enhancement;image resolution;land cover;neural nets;remote sensing","single MODIS image;remote sensing image;pixel swapping;land cover shape characterization;super-resolution mapping;MODIS image spatial resolution;Landsat ETM+;Hopfleld neural network;object characterization;time-series MODIS image","","","","22","IEEE","19 Oct 2017","","","IEEE","IEEE Conferences"
"A Multi-Degradation Aided Method for Unsupervised Remote Sensing Image Super Resolution With Convolution Neural Networks","N. Zhang; Y. Wang; X. Zhang; D. Xu; X. Wang; G. Ben; Z. Zhao; Z. Li","School of Optoelectronics, University of Chinese Academy of Sciences, Beijing, China; Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, China; School of Optoelectronics, University of Chinese Academy of Sciences, Beijing, China; Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, China; Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, China; School of Optoelectronics, University of Chinese Academy of Sciences, Beijing, China; School of Optoelectronics, University of Chinese Academy of Sciences, Beijing, China; School of Optoelectronics, University of Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","2 Dec 2021","2022","60","","1","14","In remote sensing, it is desirable to improve image resolution by using the image super-resolution (SR) technique. However, there are two challenges: the first one is that high-resolution (HR) images are insufficient or unavailable; another one is that the single degradation model such as bicubic (BIC) cannot super-resolve favorable images in the real world. To address the above two problems, this article presents a multi-degradation, unsupervised SR method based on deep learning. This framework consists of a degrader  $ {D}$  to fit the image degradation model and a generator  $ {G}$  to generate SR image. By introducing  $ {D}$ , calculating the loss function between SR image and HR image as supervised SR methods did can be converted into calculating loss between low resolution (LR) image and image degraded by SR image, thereby realizing unsupervised learning. Experiments on several degradation models show that our method renders the state-of-the-art results compared with existing unsupervised SR methods, and achieves competitive results in contrast with supervised SR methods. Moreover, for real remote sensing images obtained by the Jilin-1 satellite, our method obtained more plausible results visually, which demonstrate the potential in real-world applications.","1558-0644","","10.1109/TGRS.2020.3042460","Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9301235","Deep neural network (DNN);multi-degradation;remote sensing image;super-resolution (SR);unsupervised learning","Image resolution;Degradation;Spatial resolution;Kernel;Image reconstruction;Hyperspectral imaging;Gallium nitride","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image resolution;remote sensing;unsupervised learning","unsupervised SR methods;supervised SR methods;unsupervised remote sensing image super resolution;high-resolution images;single degradation model;image degradation model;SR image;multidegradation aided method;convolution neural networks;deep learning;low resolution image;unsupervised learning;Jilin-1 satellite","","5","","52","IEEE","21 Dec 2020","","","IEEE","IEEE Journals"
"An Approach To Super-Resolution Of Sentinel-2 Images Based On Generative Adversarial Networks","K. Zhang; G. Sumbul; B. Demir",Shanghai Jiao Tong University; Technische Universität Berlin; Technische Universität Berlin,"2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium (M2GARSS)","2 Jun 2020","2020","","","69","72","This paper presents a generative adversarial network based super-resolution (SR) approach (which is called as S2GAN) to enhance the spatial resolution of Sentinel-2 spectral bands. The proposed approach consists of two main steps. The first step aims to increase the spatial resolution of the bands with 20m and 60m spatial resolutions by the scaling factors of 2 and 6, respectively. To this end, we introduce a generator network that performs SR on the lower resolution bands with the guidance of the bands associated to 10m spatial resolution by utilizing the convolutional layers with residual connections and a long skip-connection between inputs and outputs. The second step aims to distinguish SR bands from their ground truth bands. This is achieved by the proposed discriminator network, which alternately characterizes the high level features of the two sets of bands and applying binary classification on the extracted features. Then, we formulate the adversarial learning of the generator and discriminator networks as a min-max game. In this learning procedure, the generator aims to produce realistic SR bands as much as possible so that the discriminator incorrectly classifies SR bands. Experimental results obtained on different Sentinel-2 images show the effectiveness of the proposed approach compared to both conventional and deep learning based SR approaches.","","978-1-7281-2190-1","10.1109/M2GARSS47143.2020.9105165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105165","Sentinel-2 images;super-resolution;generative adversarial network;remote sensing","Image color analysis;Superresolution;Neural networks;Geoscience and remote sensing;Games;Generative adversarial networks;Feature extraction","convolutional neural nets;feature extraction;game theory;geophysical image processing;image classification;image resolution;learning (artificial intelligence);minimax techniques","generative adversarial network;super-resolution approach;S2GAN;spatial resolution;Sentinel-2 spectral bands;generator network;lower resolution bands;ground truth bands;discriminator network;binary classification;adversarial learning;realistic SR bands;Sentinel-2 images;convolutional layers;feature extraction;min-max game;size 20.0 m;size 10.0 m;size 60.0 m","","3","","10","IEEE","2 Jun 2020","","","IEEE","IEEE Conferences"
"Two-dimensional Super-resolution Imaging for Real Aperture Radar by Iterative Adaptive Approach","J. Luo; Y. Zhang; Y. Zhang; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China","2022 IEEE Radar Conference (RadarConf22)","3 May 2022","2022","","","1","5","Real-aperture radar (RAR) super-resolution imaging is an important remote sensing technique, which has been widely studied and discussed recently. However, traditional super-resolution imaging approaches are commonly implemented for earth surface observation and mapping whose essence is to enhance the azimuth resolution of the image. In this paper, we consider the RAR super-resolution imaging problem of azimuth-pitch two-dimensional scanning, and extend the traditional azimuth-distance two-dimensional planar imaging to azimuth-pitch-distance three-dimensional imaging of the airspace. The core of this problem is the azimuth-pitch two-dimensional super-resolution processing. First, a fixed platform azimuth-pitch two-dimensional scanning radar echo model is introduced. Then, the two-dimensional convolutional echo model is transformed into a standard linear estimation form through discretization and vectorization. Finally, by constructing a weighted least squares cost function and employing the matrix inverse lemma, the target backscattering coefficient can be iteratively estimated. The proposed method has competitive two-dimensional resolution capability compared with existing ones. The simulation verifies the effectiveness of the proposed method.","","978-1-7281-5368-1","10.1109/RadarConf2248738.2022.9764238","National Natural Science Foundation of China(grant numbers:61671117,61901092); Collaborative Innovation Center of Information Sensing and Understanding; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9764238","Real aperture radar;super-resolution imaging;two-dimensional","Adaptation models;Deconvolution;Computational modeling;Superresolution;Imaging;Estimation;Radar","image reconstruction;image resolution;iterative methods;least squares approximations;matrix inversion;radar imaging;remote sensing;synthetic aperture radar","dimensional super-resolution;real aperture radar;iterative adaptive approach;real-aperture radar super-resolution imaging;important remote sensing technique;traditional super-resolution imaging approaches;earth surface observation;mapping whose essence;azimuth resolution;RAR super-resolution imaging problem;azimuth-distance two-dimensional planar;azimuth-pitch-distance;three-dimensional imaging;super-resolution processing;fixed platform azimuth-pitch;two-dimensional scanning radar echo model;two-dimensional convolutional echo model;two-dimensional resolution capability","","","","14","IEEE","3 May 2022","","","IEEE","IEEE Conferences"
"Super-Resolution Reconstruction Method of Remote Sensing Image Based on Multi-Feature Fusion","Z. -X. Huang; C. -W. Jing","Zhejiang Yijia Geographic Information Technology Company, Ltd., Hangzhou, China; Hangzhou Normal University, Hangzhou, China","IEEE Access","30 Jan 2020","2020","8","","18764","18771","The acquisition of remote sensing images is affected by imaging equipment and environmental conditions. Usually on lower performance devices, the resolution of the acquired images is also low. Among many methods, the super-resolution reconstruction method based on generative adversarial networks has obvious advantages over previous network models in reconstructing image texture details. However, it is found in experiments that not all of these reconstructed textures exist in the image itself. Aiming at the problem of whether the texture details of the reconstructed image are accurate and clear, we propose a super-resolution reconstruction method combining wavelet transform and generative adversarial network. Using wavelet multi-resolution analysis, training wavelet decomposition coefficients in the generative adversarial network can effectively improve the local detail information of the reconstructed image. Experimental results show that our method can effectively reconstruct more natural image textures and make the images more visually clear. In the remote sensing image test set, the four indicators of the algorithm, peak signal to noise ratio (PSNR), structural similarity (SSIM), Feature Similarity (FSIM) and Universal Image Quality (UIQ) are slightly better than the algorithms mentioned in the article.","2169-3536","","10.1109/ACCESS.2020.2967804","Key Special Projects through the Provincial Scientific Research Institutes Program of Zhejiang Province, China(grant numbers:2014F50022); Construction of Agricultural Science Park Program of Zhejiang Province, China(grant numbers:2019E70002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8963714","Remote sensing image;super-resolution;self-correlation;image texture","Image reconstruction;Wavelet transforms;Reconstruction algorithms;Remote sensing;Generative adversarial networks","image fusion;image reconstruction;image resolution;image texture;neural nets;remote sensing;wavelet transforms","wavelet multiresolution analysis;generative adversarial network;reconstructed image;natural image textures;remote sensing image test;super-resolution reconstruction method;remote sensing images;imaging equipment;image texture details;reconstructed textures;universal image quality;multi-feature fusion;environmental conditions;wavelet transform;training wavelet decomposition coefficients;peak signal to noise ratio;structural similarity;feature similarity","","11","","27","CCBY","20 Jan 2020","","","IEEE","IEEE Journals"
"Deep learning for ocean remote sensing: an application of convolutional neural networks for super-resolution on satellite-derived SST data","A. Ducournau; R. Fablet","Télécom-Bretagne;, Institut Mines-Télécom, Brest, France; Télécom-Bretagne;, Institut Mines-Télécom, Brest, France","2016 9th IAPR Workshop on Pattern Recogniton in Remote Sensing (PRRS)","2 Mar 2017","2016","","","1","6","In this paper, we propose to address the downscaling of ocean remote sensing data using image super-resolution models based on deep learning, and more particularly Convolutional Neural Networks (CNNs). The goal of this study, for which we focus on satellite-derived Sea Surface Temperature (SST) data, is to evaluate the efficiency and the relevance of deep learning architectures applied to oceanographic remote sensing data. By using a CNN architecture, namely SRCNN (Super Resolution CNN), on a large-scale dataset of SST fields, we show that it allows a considerable gain in terms of PSNR compared to classical downscaling techniques. These results point out the relevance of deep learning models specifically trained for ocean remote sensing data and advocate for other applications to the reconstruction of high-resolution sea surface geophysical fields from multi-sensor satellite observations.","","978-1-5090-5041-3","10.1109/PRRS.2016.7867019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7867019","","Image reconstruction;Machine learning;Oceans;Image resolution;Training;Remote sensing;Data models","data handling;geophysics computing;image resolution;learning (artificial intelligence);neural net architecture;ocean temperature;remote sensing;sensor fusion","deep learning;convolutional neural networks;CNN architecture;satellite-derived SST data;satellite-derived sea surface temperature data;ocean remote sensing data;image super-resolution models;oceanographic remote sensing data;SRCNN;super resolution CNN;PSNR;high-resolution sea surface geophysical field reconstruction;multisensor satellite observations","","34","","24","IEEE","2 Mar 2017","","","IEEE","IEEE Conferences"
"Hyperspectral image super resolution reconstruction with a joint spectral-spatial sub-pixel mapping model","X. Xu; X. Tong; J. Li; H. Xie; Y. Zhong; L. Zhang; D. Song","College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; School of Geosciences, China university of Petroleum, Shandong, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","6129","6132","Hyperspectral image super resolution (SR) reconstruction has been studied widely and many algorithms have been proposed. In this paper, a novel super resolution reconstruction method was designed by employing a joint spectral-spatial sub-pixel mapping model which aims to obtain the probabilities of sub-pixels to belong to different land cover classes by dividing mixed pixels into several sub-pixels. Given these sub-pixel probabilities, the resolution enhanced image can be further generated. The proposed approach has been evaluated using both synthetic and real hyperspectral images and compared with other well-known methods. The visual and quantitative comparisons confirm the effectiveness of the proposed method.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730601","Super resolution reconstruction;super resolution mapping;sub-pixel mapping;spectral unmixing;hyperspectral image","Hyperspectral imaging;Image reconstruction;Reconstruction algorithms;Spatial resolution","geophysical image processing;hyperspectral imaging;image reconstruction;land cover","hyperspectral image super resolution reconstruction;joint spectral-spatial subpixel mapping model;SR reconstruction;land cover classes;subpixel probabilities","","5","","13","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Local Spectral Super-Resolution for ALSAT-2B Images with Application to Anomaly Detection","A. Djerida; M. S. Karoui","Agence Spatiale Algérienne, Centre des Techniques Spatiales, Arzew, Algérie; Agence Spatiale Algérienne, Centre des Techniques Spatiales, Arzew, Algérie","2022 IEEE Mediterranean and Middle-East Geoscience and Remote Sensing Symposium (M2GARSS)","9 Aug 2022","2022","","","21","24","In this paper, a novel methodology is proposed to enhance the spectral resolution of optical remote sensing data that have very few spectral bands. Inspired by the availability of LANDSAT-8 images, a spectral super-resolution method is used and extended to enhance the resolution of ALSAT-2B images. First, a convenient LANDSAT-8 image that incorporates the targeted ALSAT-2B image is identified. Second, the LANDSAT-8 image is converted into dataset patches of RGB and B5, B6 and B7 spectral bands. A local spectral super-resolution method, based on deep learning, is then used to grasp the transformation between the considered patches. Finally, the learned transformation is applied to the ALSAT-2B scene. To assess the quality of the transformation, several criteria are used. In addition, the impact of the reconstructed bands is investigated on anomaly detection on a desert scene. Obtained results show a great improvement for the well-known Reed-Xiaoli detector.","","978-1-6654-2795-1","10.1109/M2GARSS52314.2022.9840206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9840206","Spectral super-resolution;Deep-learning;RGB images;LANDSAT-8 and ALSAT-2B","Earth;Artificial satellites;Satellites;Superresolution;Detectors;Optical detectors;Optical imaging","geophysical image processing;geophysical signal processing;image classification;image resolution;object detection;remote sensing","ALSAT-2B images;anomaly detection;spectral resolution;optical remote sensing data;convenient LANDSAT-8 image;targeted ALSAT-2B image;B7 spectral bands;local spectral super-resolution method;ALSAT-2B scene","","","","16","IEEE","9 Aug 2022","","","IEEE","IEEE Conferences"
"Super-Resolution Integrated Building Semantic Segmentation for Multi-Source Remote Sensing Imagery","Z. Guo; G. Wu; X. Song; W. Yuan; Q. Chen; H. Zhang; X. Shi; M. Xu; Y. Xu; R. Shibasaki; X. Shao","Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; School of Geography and Information Engineering, China University of Geosciences, Wuhan, China; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; Earth Observation Data Integration and Fusion Research Initiative, The University of Tokyo, Tokyo, Japan","IEEE Access","5 Aug 2019","2019","7","","99381","99397","Multi-source remote sensing imagery has become widely accessible owing to the development of data acquisition systems. In this paper, we address the challenging task of the semantic segmentation of buildings via multi-source remote sensing imagery with different spatial resolutions. Unlike previous works that mainly focused on optimizing the segmentation model, which did not enable the severe problems caused by the unaligned resolution between the training and testing data to be fundamentally solved, we propose to integrate SR techniques with the existing framework to enhance the segmentation performance. The feasibility of the proposed method was evaluated by utilizing representative multi-source study materials: high-resolution (HR) aerial and low-resolution (LR) panchromatic satellite imagery as the training and testing data, respectively. Instead of directly conducting building segmentation from the LR imagery by using the model trained using the HR imagery, the deep learning-based super-resolution (SR) model was first adopted to super-resolved LR imagery into SR space, which could mitigate the influence of the difference in resolution between the training and testing data. The experimental results obtained from the test area in Tokyo, Japan, demonstrate that the proposed SR-integrated method significantly outperforms that without SR, improving the Jaccard index and kappa by approximately 19.01% and 19.10%, respectively. The results confirmed that the proposed method is a viable tool for building semantic segmentation, especially when the resolution is unaligned.","2169-3536","","10.1109/ACCESS.2019.2928646","Ministry of Education, Culture, Sports, Science and Technology(grant numbers:19K15260); Japan Society for the Promotion of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8761866","Building segmentation;deep learning;remote sensing;super-resolution","Buildings;Image segmentation;Semantics;Remote sensing;Spatial resolution;Training","data acquisition;geophysical image processing;image resolution;image segmentation;learning (artificial intelligence);remote sensing","super-resolution integrated building semantic segmentation;multisource remote sensing imagery;segmentation model;building segmentation;LR imagery;deep learning-based super-resolution model;Tokyo;Japan;Jaccard index;kappa","","23","","64","CCBY","15 Jul 2019","","","IEEE","IEEE Journals"
"Location Aware Super-Resolution for Satellite Data Fusion","O. Adigun; P. A. Olsen; R. Chandra","Dept. of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA; Microsoft Research Research For Industry, Redmond, WA; Microsoft Research Research For Industry, Redmond, WA","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","3758","3761","Satellite data fusion involves images with different spatial, temporal, and spectral resolution. These images are taken under different illumination conditions, with different sensors and atmospheric noise. We use classic super-resolution algorithms to synthesize commercial satellite images (Pléiades) from a public satellite source (Sentinel-2). Each super-resolution method is then further improved by adaptive sharpening to the location by use of matrix completion (regression with missing pixels). Finally, we consider ensemble systems and a residual channel attention dual network with stochastic dropout. The resulting systems are visibly less blurry with higher fidelity and yield improved performance.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884391","Super-resolution;matrix completion;cloud removal","Location awareness;Image sensors;Satellites;Superresolution;Data integration;Lighting;Geoscience and remote sensing","artificial satellites;geophysical image processing;image fusion;image resolution;image restoration;sensor fusion","satellite data fusion;different spatial;spectral resolution;different illumination conditions;atmospheric noise;super-resolution algorithms;commercial satellite images;public satellite source;super-resolution method;location aware super-resolution","","","","12","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Gradient-Based Adaptive Image Super Resolution","A. Junaidi; C. -H. Lin; Y. -H. Tseng; L. -H. Chang; S. -C. Peng","Department of Geomatics, National Cheng Kung University, Taiwan; Department of Geomatics, National Cheng Kung University, Taiwan; Department of Geomatics, National Cheng Kung University, Taiwan; Satellite Image Division, National Space Organization, Taiwan; Satellite Image Division, National Space Organization, Taiwan","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2774","2777","Super-resolution (SR) has been used in the realm of remote sensing to improve the resolution of an image and get more detailed spatial information than the original image captured by the sensor on the acquisition device. Several SR methods with different approaches, only focusing on sharpening the edges and forgetting non-edge areas. One of the SR methods that utilize prior gradients, can produce high resolution (HR) images in a short time and produce sharp images for nonhomogeneous areas. But for areas that tend to be homogeneous, a lot of noise appears. This problem will affect the remote sensing process due to the amount of noise that arises. This paper offers to use dynamic weighting on the gradient prior that will reduce the noise on the homogeneous area, while still able to maintains to produce the sharp edges in non-homogeneous areas. An experimental comparison is conducted on both homogeneous and non-homogeneous area using the previous method and the proposed method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900578","Image super-resolution;dynamic weighting;gradient-based;gradient prior;image reconstruction","Image edge detection;Image reconstruction;Correlation;Satellites;Spatial resolution","gradient methods;image resolution;remote sensing","acquisition device;SR methods;high resolution images;remote sensing process;sharp edges;nonhomogeneous area;gradient-based adaptive image super resolution;spatial information;sharp image production","","","","13","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Comparison of density and positioning accuracy of PS extracted from super-resolution PSI with those from traditional PSI","Z. Hao; C. Bin; G. Zhichao; D. Han","School of Geographic and Biologic Information, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Geographic and Biologic Information, Nanjing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Department of Geoscience and Remote Sensing, Delft University of Technology, Delft, Netherlands","Journal of Systems Engineering and Electronics","12 Jan 2022","2021","32","6","1318","1324","In the application of persistent scatterer interferometry (PSI), deformation information is extracted from persistent scatterer (PS) points. Thus, the density and position of PS points are critical for PSI. To increase the PS density, a time-series In-SAR chain termed as ""super-resolution persistent scatterer interferometry"" (SR-PSI) is proposed. In this study, we investigate certain important properties of SR-PSI. First, we review the main workflow and dataflow of SR-PSI. It is shown that in the implementation of the Capon algorithm, the diagonal loading (DL) approach should be only used when the condition number of the covariance matrix is sufficiently high to reduce the discontinuities between the joint images. We then discuss the density and positioning accuracy of PS when compared with traditional PSI. The theory and experimental results indicate that SR-PSI can increase the PS density in urban areas. However, it is ineffective for the rural areas, which should be an important consideration for the engineering application of SR-PSI. Furthermore, we validate that the positioning accuracy of PS can be improved by SR-PSI via simulations.","1004-4132","","10.23919/JSEE.2021.000111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679701","super resolution;persistent scatterer interferometry (PSI);positioning accuracy","Strain;Superresolution;Spatial resolution;Filtering theory;Urban areas;Modeling;Loading","covariance matrices;deformation;radar interferometry;remote sensing by radar;synthetic aperture radar","super-resolution PSI;traditional PSI;persistent scatterer points;PS points;PS density;super-resolution persistent scatterer interferometry;SR-PSI","","","","","","12 Jan 2022","","","BIAI","BIAI Journals"
"Unsupervised Super-Resolution of Satellite Imagery for High Fidelity Material Label Transfer","A. Ghosh; M. Ehrlich; L. Davis; R. Chellappa","University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","5144","5147","Urban material recognition in remote sensing imagery is a challenging problem due to the difficulty of obtaining human annotations, especially on low resolution satellite images. To this end, we propose an unsupervised domain adaptation-based approach using adversarial learning. We aim to harvest information from smaller quantities of high resolution data (source domain) and utilize the same to super-resolve low resolution imagery (target domain). This can potentially aid in semantic as well as material label transfer from a richly annotated source to a target domain.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900639","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900639","Unsupervised Domain Adaptation;Adversarial learning;Super-resolution;Label transfer","Buildings;Satellites;Remote sensing;Training;Image segmentation","image classification;image resolution;learning (artificial intelligence);neural nets;remote sensing","satellite imagery;high fidelity material label transfer;urban material recognition;remote sensing imagery;human annotations;adversarial learning;high resolution data;unsupervised superresolution;unsupervised domain adaptation","","2","","9","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Single Image Super Resolution using a Hybrid Feature Dictionary for Remotely Sensed Images","S. Deepak; V. Khorgade; D. Patra","Dept. Of Electrical Engineering, National Institute of Technology, Rourkela, INDIA; Dept. Of Electrical Engineering, National Institute of Technology, Rourkela, INDIA; Dept. Of Electrical Engineering, National Institute of Technology, Rourkela, INDIA","2020 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)","16 Sep 2020","2020","","","1","6","In this paper, a sparse representation based single image super-resolution reconstruction (SRR) method using a self-learned hybrid feature dictionary is proposed. Efficient feature extraction plays a very important role in image SRR and most of the models use gradient-based feature extraction. These models, being an intensity-based, can be easily influenced by the intensity gradient to ignore essential edge profile and also fails to address the edge profiles like delta, roof and ramp edge which are very crucial for efficient reconstruction. Inspired by this, a hybrid feature based over-complete dictionary is formed by extracting various features of the LR input image. Features are extracted using the Fast Fourier Transform (FFT) procedure along with the first-and-second-order gradients. This dictionary is jointly trained with the HR image patch features using Orthogonal Matching Pursuit (OMP) and K-singular value decomposition (K-SVD) algorithm. By considering the similarity between the LR and HR image patch pairs, the output HR image is reconstructed using the sparse recovery model. Experimental analysis and results for remotely sensed data demonstrate that the proposed method reduces the computational complexity as well as outperforms other state-of-the-art methods in terms of qualitative and quantitative parameters. The average signal to noise ratio (PSNR) has improved significantly by +0.6 dB along with a notable boost in computational time and perceptual quality.","","978-1-7281-6828-9","10.1109/CONECCT50063.2020.9198523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9198523","Super-resolution reconstruction (SRR);sparse representation;dictionary training;feature extraction;remote sensing","Feature extraction;Dictionaries;Image reconstruction;Image edge detection;Matching pursuit algorithms;Image resolution;Remote sensing","computational complexity;fast Fourier transforms;feature extraction;image reconstruction;image representation;image resolution;learning (artificial intelligence);remote sensing;singular value decomposition","first-and-second-order gradients;orthogonal matching pursuit;OMP;K-singular value decomposition;K-SVD;signal to noise ratio;PSNR;FFT;sparse representation;remotely sensed data;sparse recovery model;HR image patch features;first- order gradients;fast Fourier transform;LR input image;over-complete dictionary;ramp edge;edge profile;intensity gradient;image SRR;feature extraction;single image super-resolution reconstruction method;remotely sensed images;hybrid feature dictionary","","","","16","IEEE","16 Sep 2020","","","IEEE","IEEE Conferences"
"Optically Enhanced Super-Resolution of Sea Surface Temperature Using Deep Learning","D. T. Lloyd; A. Abela; R. A. Farrugia; A. Galea; G. Valentino","Department of Communications and Computer Engineering, University of Malta, Msida, MSD, Malta; Department of Communications and Computer Engineering, University of Malta, Msida, MSD, Malta; Department of Communications and Computer Engineering, University of Malta, Msida, MSD, Malta; Department of Geosciences, Physical Oceanography Research Group, University of Malta, Msida, MSD, Malta; Department of Communications and Computer Engineering, University of Malta, Msida, MSD, Malta","IEEE Transactions on Geoscience and Remote Sensing","13 Jan 2022","2022","60","","1","14","Sea surface temperature (SST) can be measured from space using infrared sensors on Earth-observing satellites. However, the tradeoff between spatial resolution and swath size (and hence revisit time) means that SST products derived from remote sensing measurements commonly only have a moderate resolution (>1 km). In this article, we adapt the design of a super-resolution neural network architecture [specifically very deep super-resolution (VDSR)] to enhance the resolution of both top-of-atmosphere thermal images of sea regions and bottom-of-atmosphere SST images by a factor of 5. When tested on an unseen dataset, the trained neural network yields thermal images that have an RMSE  $2-3\times $  smaller than interpolation, with a 6–9 dB improvement in PSNR. A major contribution of the proposed neural network architecture is that it fuses optical and thermal images to propagate the high-resolution information present in the optical image to the restored thermal image. To illustrate the potential benefits of using super-resolution (SR) in the context of oceanography, we present super-resolved SST images of a gyre and an ocean front, revealing details and features otherwise poorly resolved by moderate resolution satellite images.","1558-0644","","10.1109/TGRS.2021.3094117","Project SATellite data Fusion and Imaging Resolution Enhancement for coastal areas (SAT-FIRE) financed by the Malta Council for Science and Technology, for and on behalf of the Foundation for Science and Technology, through the Space Research Fund(grant numbers:SRF-2018-1S1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9487005","Data fusion;deep learning;gyre;Landsat 8;ocean front;sea surface temperature (SST);Sentinel 3;super-resolution (SR);thermal infrared","Remote sensing;Satellites;Spatial resolution;Ocean temperature;Earth;Artificial satellites;Optical imaging","geophysical image processing;image resolution;infrared imaging;neural nets;ocean temperature;oceanographic techniques;oceanography;remote sensing","enhanced super-resolution;sea surface temperature;deep learning;infrared sensors;Earth-observing satellites;spatial resolution;swath size;revisit time;SST products;remote sensing measurements;super-resolution neural network architecture;deep super-resolution;top-of-atmosphere thermal images;sea regions;bottom-of-atmosphere SST images;trained neural network;6-9 dB improvement;high-resolution information present;optical image;restored thermal image;moderate resolution satellite images;size 1.0 km;noise figure 6.0 dB to 9.0 dB","","2","","59","IEEE","15 Jul 2021","","","IEEE","IEEE Journals"
"Improvement of the Example-Regression-Based Super-Resolution Land Cover Mapping Algorithm","Y. Zhang; Y. Du; F. Ling; X. Li","Institute of Geodesy and Geophysics, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Institute of Geodesy and Geophysics, Chinese Academy of Sciences, Wuhan, China; Institute of Geodesy and Geophysics, Chinese Academy of Sciences, Wuhan, China; Institute of Geodesy and Geophysics, Chinese Academy of Sciences, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","15 Jun 2015","2015","12","8","1740","1744","Super-resolution mapping (SRM) is a method for generating a fine-resolution land cover map from coarse-resolution fraction images. Example-regression-based SRM algorithms can estimate a fine-resolution land cover map with detailed spatial information by learning land cover spatial patterns from available land cover maps. Existing example-regression-based SRM algorithms are sensitive to fraction errors, and the results often include many linear artifacts and speckles. To overcome these shortcomings, this study proposes an improved example-regression-based SRM algorithm. The objective function of the proposed SRM algorithm comprises three terms. The first term is used to minimize the difference between the fraction values of the estimated fine-resolution land cover map and the input fraction values. The second term is used to maximize the class membership possibility values of the fine pixels in the result. The final term is used to make the result locally smooth. The proposed SRM algorithm is compared with several popular SRM algorithms using both synthetic and real fraction images. Experimental results indicate that the proposed SRM algorithm can produce results with less speckles and linear artifacts, more spatial details, smoother boundaries, and higher accuracies than the SRM results used for comparison.","1558-0571","","10.1109/LGRS.2015.2423496","Natural Science Foundation of Hubei Province for Distinguished Young Scholars(grant numbers:2013CFA031); Wuhan ChenGuang Youth Sci.&Tech. Project(grant numbers:2014072704011254); National Basic Research Program (973 Program) of China(grant numbers:2013cb733205); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7101265","Example based;subpixel mapping (SPM);super-resolution mapping (SRM);support vector regression (SVR);Example based;subpixel mapping (SPM);super-resolution mapping (SRM);support vector regression (SVR)","Remote sensing;Earth;Spatial resolution;Accuracy;Satellites;Optimization","geophysical image processing;geophysical techniques;land cover","input fraction values;example-regression-based SRM algorithm;land cover spatial patterns;coarse-resolution fraction images;fine-resolution land cover map;example-regression-based super-resolution cover mapping algorithm","","9","","20","IEEE","4 May 2015","","","IEEE","IEEE Journals"
"Super-Resolution of Large Volumes of Sentinel-2 Images with High Performance Distributed Deep Learning","R. Zhang; G. Cavallaro; J. Jitsev","Jülich Supercomputing Centre, Forschungszentrum, Germany; Jülich Supercomputing Centre, Forschungszentrum, Germany; Jülich Supercomputing Centre, Forschungszentrum, Germany","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","617","620","This work proposes a novel distributed deep learning model for Remote Sensing (RS) images super-resolution. High Performance Computing (HPC) systems with GPUs are used to accelerate the learning of the unknown low to high resolution mapping from large volumes of Sentinel-2 data. The proposed deep learning model is based on self-attention mechanism and residual learning. The results demonstrate that state-of-the-art performance can be achieved by keeping the size of the model relatively small. Synchronous data parallelism is applied to scale up the training process without severe performance loss. Distributed training is thus shown to speed up learning substantially while keeping performance intact.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323734","European Union(grant numbers:604102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323734","Sentinel-2;super-resolution;distributed deep learning;high performance computing","Training;Spatial resolution;Superresolution;Computational modeling;Deep learning;Data models;Throughput","geophysical image processing;image resolution;learning (artificial intelligence);parallel processing;remote sensing","residual learning;Sentinel-2 data;high resolution mapping;High Performance Computing systems;Remote Sensing images super-resolution;deep learning model;high Performance distributed deep learning;Sentinel-2 images;distributed training;severe performance loss","","7","","14","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Video Satellite Imagery Super-Resolution via a Deep Residual Network","J. Wu; Z. He; L. Zhuo","Guangdong Provincial Key Laboratory of Urbanization and Geo-simulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory of Urbanization and Geo-simulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory of Urbanization and Geo-simulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2762","2765","Recently, as a new remote sensing system, video satellite develops rapidly for long-time observation. Thanks to its high temporal resolution, video satellite has been extensively used for environmental detection, especially for dynamic target monitoring. However, limited by the imaging device, it sacrifices some of its spatial resolution. Therefore, the super-resolution (SR) technology applied to these images is crucial. Based on deep residual learning, which has obtained a great success in the single-image SR, we propose a SR network structure which consists of two main steps. First, we use multi-scale feature extraction to exploit more contextual information on video satellite imagery, which is aimed at inferring high frequency components. Then, we utilize a series of residual blocks to learn the mapping between low resolution and high resolution images in a deeper and more stable network. In our experiment, the SR reconstruction results on Jinlin-1 satellite images greatly indicate the effectiveness of our method and the potential of the residual network for video satellite imagery SR.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900265","video satellite;super-resolution (SR);deep residual network;multi-scale","Satellites;Convolution;Training;Feature extraction;Image reconstruction;Spatial resolution","feature extraction;geophysical image processing;image reconstruction;image resolution;remote sensing","deep residual network;remote sensing system;long-time observation;high temporal resolution;environmental detection;dynamic target monitoring;imaging device;spatial resolution;deep residual learning;single-image SR;SR network structure;multiscale feature extraction;high frequency components;residual blocks;high resolution images;SR reconstruction results;Jinlin-1 satellite images;video satellite imagery super-resolution","","5","","15","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Hyperspectral Image Super-Resolution Classification with a Small Training Set Using Spectral Variation Extended Endmember Library","Y. Zhang; T. Zhao; B. Xie; S. Mei","Shaanxi Key Laboratory of Information Acquisition and Processing, Northwestern Polytechnical University, Xi’an, China; Shaanxi Key Laboratory of Information Acquisition and Processing, Northwestern Polytechnical University, Xi’an, China; Shaanxi Key Laboratory of Information Acquisition and Processing, Northwestern Polytechnical University, Xi’an, China; Shaanxi Key Laboratory of Information Acquisition and Processing, Northwestern Polytechnical University, Xi’an, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3001","3004","Classification has been one of the most important applications of hyperspectral images (HSIs) in the past decade, because of the outstanding discrimination among different classes ensured by abundant and detailed spectral information enclosed in HSIs. While the classification accuracy must be guaranteed by plenty of training samples, which is difficult to be satisfied in many practical cases. Meanwhile, because of its comparatively low spatial resolution, mixed pixels are widely existed in HSIs which makes subpixel level classification techniques more preferable rather than traditional pixel-level ones. A novel super-resolution classification method is proposed in this paper to deal with the two above mentioned problems in HSI classification, that is, limited number of training samples and widely existed mixed pixels. Specifically, spectral variation is considered to construct spectral variation extended endmember library, with which the abundance fractions for each class within a mixed pixel are estimated using collaborative representation. And finally, the classification result with higher spatial resolution is obtained with subpixel spatial attraction model based subpixel mapping. Simulative experiments are employed for validation and comparison. Experimental results illustrate that the newly proposed method is capable of producing super-resolution classification map of low resolution HSI with less misclassification.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898080","Classification;hyperspectral;spectral variation;subpixel;super-resolution","Training;Spatial resolution;Hyperspectral imaging;Libraries","geophysical image processing;hyperspectral imaging;image classification;image resolution;remote sensing;spectral analysis","hyperspectral image super-resolution classification;small training set;spectral variation extended endmember library;HSIs;outstanding discrimination;abundant information;detailed spectral information;classification accuracy;training samples;comparatively low spatial resolution;mixed pixel;subpixel level classification techniques;traditional pixel-level ones;novel super-resolution classification method;HSI classification;classification result;higher spatial resolution;subpixel spatial attraction model;super-resolution classification map;low resolution HSI","","","","6","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Full-Spectrum Spectral Super-Resolution Method Based on LSMM","L. Sha; W. Zhang; J. Ma; Z. Li; R. Sun; M. Qin","University of Chinese Academy of Sciences, Beijing, China; Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; PLA Strategic Support Force Information Engineering University, Zhengzhou, China; Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Chang'an University, Xi'an, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2390","2393","Full-spectrum remote sensing images can simultaneously provide reflectance and emission information about objects, which has great application value. Hyperspectral imaging can record hundreds of spectral bands, but due to technical and space limitations, full-spectrum hyperspectral images (HSI) are difficult to obtain. Recently, we proposed a spectral super-resolution method based on the Linear Spectral Mixing Model (LSMM), which can generate full-spectrum hyperspectral images (HSI) from multispectral images (MSI). After the spectral-unmixing of MSI, we transform MS endmembers into full-spectrum HS endmembers by spectral library. Since the abundance of MSI and HSI with the same spatial resolution is consistent, we linearly mixed the abundance and HS endmember to obtain the full spectrum HSI. In this work, we use Sentinel-2 dataset and EO-1 ALI/Hyperion images to verify the accuracy and applicability. Compared with other works, our method can simulate full-spectrum HSI of large-area scenes without real HSI, which has a certain accuracy and provides more comprehensive information for applications.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883706","Full-spectrum;spectral super-resolution;hyperspectral;image simulation","Reflectivity;Degradation;Superresolution;Transforms;Forestry;Libraries;Image restoration","geophysical signal processing;geophysical techniques;hyperspectral imaging;image resolution;remote sensing;spectral analysis","full-spectrum Spectral super-resolution method;full-spectrum HSI;spatial resolution;spectral library;full-spectrum HS endmembers;spectral-unmixing;MSI;multispectral images;Linear Spectral Mixing Model;full-spectrum hyperspectral images;technical space limitations;spectral bands;reflectance;full-spectrum remote sensing images;LSMM","","","","10","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"On Hyperspectral Super-Resolution","J. Chanussot","Inria, CNRS, Grenoble INP, LJK, Univ. Grenoble Alpes, Grenoble, France","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","29","32","In this paper we will review seminal contributions of Prof. Jose Bioucas Dias for the improvement of the spatial resolution of hyperspectral images. Be it through the extension of pansharpening algorithms with spatial and spectral sparsity priors, using spectral unmixing, using a low-rank assumption from complementary multisource data, or by designing an edge-preserving convex formulation, Jose Bioucas Dias set up very solid and rigourous foundations for countless subsequent works.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553903","hyperspectral imaging;super-resolution;pansharpening","Image edge detection;Superresolution;Geoscience and remote sensing;Pansharpening;Solids;Spatial resolution;Hyperspectral imaging","convex programming;geophysical image processing;hyperspectral imaging;image fusion;image resolution;iterative methods;remote sensing","low-rank assumption;complementary multisource data;edge-preserving convex formulation;hyperspectral super-resolution;seminal contributions;spatial resolution;hyperspectral images;spatial sparsity priors;spectral sparsity priors","","1","","13","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Sentinel-3 Image Super-Resolution Using Data Fusion and Convolutional Neural Networks","R. Fernandez; R. Fernandez-Beltran; F. Pla","Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2867","2870","With the increasing availability of Sentinel-2 (S2) and Sentinel-3 (S3) data, developing higher-level data products becomes a very attractive option to relieve the spatial limitations of the Ocean and Land Colour Instrument (OLCI) of S3. In this context, this paper investigates the suitability of super-resolving operational OLCI products using the Multi-Spectral Instrument (MSI) of S2 as an offline spatial reference. Specifically, the proposed approach assembles a multi -spectral data fusion scheme together with a convolutinal neural network (CNN) mapping function to project the OLCI sensor onto its corresponding spatial reference which is synthetically generated by the OLCI/MSI fusion. In this way, the trained model is able to super-resolve operational OLCI products under demand without the need of using MSI data. The experimental part of the work shows the suitability of the proposed approach in the context of the Copernicus programme.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554826","Sentinel-2 (S2);Sentinel-3 (S3);image fusion;super-resolution (SR)","Image color analysis;Instruments;Oceans;Superresolution;Neural networks;Data integration;Geoscience and remote sensing","geophysical image processing;image fusion;image resolution;image sensors;neural nets;remote sensing;sensor fusion","corresponding spatial reference;super-resolve operational OLCI products;MSI data;Sentinel-3 image super-resolution;convolutional neural networks;Sentinel-2;Sentinel-3 data;higher-level data products;spatial limitations;MultiSpectral Instrument;offline spatial reference;multi-spectral data fusion scheme;convolutinal neural network mapping function;OLCI sensor","","","","16","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"3D super resolution scene depth reconstruction based on SkySat video image sequences","X. Wan; J. Liu; H. Yan; G. L. K. Morgan; T. Sun","Earth Science and Engineering Department, Imperial College London, London, UK; Earth Science and Engineering Department, Imperial College London, London, UK; Research Department, Jaguar Land Rover Limited, Warwick, UK; Earth Science and Engineering Department, Imperial College London, London, UK; Electronic Information School, Wuhan University, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","6653","6656","Traditional DEM (Digital Elevation Model) generation from satellite imagery is based on stereo pair or triple images using wide baseline. These days, a number of low-cost microsatellites, such as SkySat, have been launched. The high resolution video image sequences they provided result in large number of image frames and more flexible selection of baseline, which allows us to design a 3D super resolution scene reconstruction approach based on multiple narrow baseline stereo pairs. The multiple disparity maps, generated using Phase Correlation (PC) based sub-pixel stereo matching algorithm, are co-registered pixel by pixel and up-sampled and then stacked to produce a super resolution scene depth map. The scene depth image constructed in this way has three advantages: i) “pixel locking” error typical for sub-pixel image matching is minimized; ii) super resolution is achieved; and iii) occlusion problem is minimized by multiple narrow baseline stereo pairs. A 3D scene super resolution reconstruction example is demonstrated using a SkySat video image of Usak, Western Turkey.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730737","Super resolution;Phase Correlation;DEM generation","Image reconstruction;Spatial resolution;Three-dimensional displays;Satellites;Correlation;Image matching","digital elevation models;geophysical image processing;image reconstruction;image resolution;remote sensing;video signal processing","Western Turkey;Usak;occlusion problem;super resolution;subpixel image matching;pixel locking error;super resolution scene depth map;Phase Correlation based subpixel stereo matching algorithm;multiple disparity maps;multiple narrow baseline stereo pairs;baseline selection;image frames;high resolution video image sequences;low-cost microsatellites;wide baseline;triple images;satellite imagery;digital elevation model;SKYSAT video image sequences;3D super resolution scene depth reconstruction","","1","1","13","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"A Review of Spatiotemporal Super-Resolution Mapping for Remote Sensing Data Fusion","Y. Li; L. Wang; X. Liu; Q. Chu; X. Yang","National Engineering Research Center of Geographic Information System, China University of Geosciences, Wuhan, China; School of Computer Science, China University of Geosciences, Wuhan, China; Tech Company Ltd., Wuhan, China; National Engineering Research Center of Geographic Information System, China University of Geosciences, Wuhan, China; School of Computer Science, China University of Geosciences, Wuhan, China","IEEE Journal on Miniaturization for Air and Space Systems","29 Mar 2022","2022","3","1","9","18","Presently, due to the limitations of satellite launch cost and existing technology, it is scarcely possible to obtain single remotely sensed images with both fine-spatial resolution and high temporal resolution at the same time freely. For solving this kind of predicament, an effective method is to fuse multisource remote sensing data by using spatial–temporal super-resolution mapping (STSRM) algorithms. STSRM is developed on the foundation of super-resolution mapping (SRM), which is used for generating land-cover map with a finer spatial resolution by allocating subpixels position in the mixed pixels of coarse remotely sensed images. This review summarizes the existing mainstream models of spatiotemporal SRM and concludes the advantages and limitations of these methods. At the same time, this article analyzes methods of classification accuracy assessment, expounds the existing problems and challenges, and makes a forward-looking prospect for the future development direction of spatiotemporal SRM.","2576-3164","","10.1109/JMASS.2021.3091837","National Natural Science Foundation of China(grant numbers:42001308,U1711266,41925007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463413","Satellite images;spatial resolution;spatiotemporal data fusion;super-resolution mapping;temporal resolution","Spatial resolution;Remote sensing;Satellites;Correlation;Superresolution;Graphical models;Distribution functions","geophysical image processing;geophysical signal processing;image classification;image resolution;land cover;remote sensing;sensor fusion;spatiotemporal phenomena;terrain mapping","spatiotemporal super-resolution mapping;remote sensing data fusion;satellite launch cost;fine-spatial resolution;high temporal resolution;multisource remote sensing data;spatial-temporal super-resolution mapping;generating land-cover map;finer spatial resolution;coarse remotely;existing mainstream models;spatiotemporal SRM;article analyzes methods","","","","84","IEEE","23 Jun 2021","","","IEEE","IEEE Journals"
"Deep Learning for Multiple-Image Super-Resolution of Sentinel-2 Data","M. Kawulok; T. Tarasiewicz; J. Nalepa; D. Tyrna; D. Kostrzewa","Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland; Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland; Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland; Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland; Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3885","3888","Super-resolution (SR) reconstruction is a common term for techniques aimed at generating a high-resolution image from a single low-resolution image or multiple images showing the same scene. Multiple-image SR benefits from data fusion which allows for more accurate reconstruction of the underlying high-resolution information. Deep learning is extensively used for single-image SR, but its application to multiple-image SR is much less explored. Recently, several deep networks were proposed to enhance Proba-V images, and in this paper, we focus on employing them to super-resolve the Sentinel-2 images. In particular, we investigate the influence of the training data, including real and simulated low-resolution images, on the final SR outcome. Also, we make the simulated data publicly available.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553243","Silesian University of Technology(grant numbers:BKM21); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553243","Super-resolution reconstruction;satellite imaging;deep learning;multiple-image super-resolution","Deep learning;Superresolution;Training data;Geoscience and remote sensing;Data integration;Image reconstruction","data fusion;deep learning (artificial intelligence);geophysical image processing;image reconstruction;image resolution","multiple-image super-resolution;Sentinel-2 data;super-resolution reconstruction;multiple-image SR benefits;data fusion;deep learning;single-image SR;deep networks;Proba-V images","","4","","17","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"An End-To-End Framework For Low-Resolution Remote Sensing Semantic Segmentation","M. B. Pereira; J. A. d. Santos","Dept. of Computer Science, Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; Dept. of Computer Science, Universidade Federal de Minas Gerais, Belo Horizonte, Brazil","2020 IEEE Latin American GRSS & ISPRS Remote Sensing Conference (LAGIRS)","12 Aug 2020","2020","","","6","11","High-resolution images for remote sensing applications are often not affordable or accessible, especially when in need of a wide temporal span of recordings. Given the easy access to low-resolution (LR) images from satellites, many remote sensing works rely on this type of data. The problem is that LR images are not appropriate for semantic segmentation, due to the need for high-quality data for accurate pixel prediction for this task. In this paper, we propose an end-to-end framework that unites a super-resolution and a semantic segmentation module in order to produce accurate thematic maps from LR inputs. It allows the semantic segmentation network to conduct the reconstruction process, modifying the input image with helpful textures. We evaluate the framework with three remote sensing datasets. The results show that the framework is capable of achieving a semantic segmentation performance close to native high-resolution data, while also surpassing the performance of a network trained with LR inputs.","","978-1-7281-4350-7","10.1109/LAGIRS48042.2020.9165642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165642","Super-resolution;semantic segmentation;remote sensing;end-to-end framework","Semantics;Image segmentation;Spatial resolution;Remote sensing;Task analysis;Training","geophysical image processing;image reconstruction;image resolution;image segmentation;remote sensing","low-resolution images;remote sensing applications;high-resolution images;low-resolution remote sensing semantic segmentation;high-resolution data;semantic segmentation performance;remote sensing datasets;input image;semantic segmentation network;LR inputs;thematic maps;semantic segmentation module;super-resolution;end-to-end framework;accurate pixel prediction;high-quality data;LR images","","7","","17","IEEE","12 Aug 2020","","","IEEE","IEEE Conferences"
"PROBA-V-REF: Repurposing the PROBA-V Challenge for Reference-Aware Super Resolution","N. L. Nguyen; J. Anger; A. Davy; P. Arias; G. Facciolo","Université Paris-Saclay, CNRS, ENS Paris-Saclay, Centre Borelli, France; Kayrros SAS; Université Paris-Saclay, CNRS, ENS Paris-Saclay, Centre Borelli, France; Université Paris-Saclay, CNRS, ENS Paris-Saclay, Centre Borelli, France; Université Paris-Saclay, CNRS, ENS Paris-Saclay, Centre Borelli, France","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3881","3884","The PROBA-V Super-Resolution challenge distributes real low-resolution image series and corresponding high-resolution targets to advance research on Multi-Image Super Resolution (MISR) for satellite images. However, in the PROBA-V dataset the low-resolution image corresponding to the high-resolution target is not identified. We argue that in doing so, the challenge ranks the proposed methods not only by their MISR performance, but mainly by the heuristics used to guess which image in the series is the most similar to the high-resolution target. We demonstrate this by improving the performance obtained by the two winners of the challenge only by using a different reference image, which we compute following a simple heuristic. Based on this, we propose PROBA-V-REF a variant of the PROBA-V dataset, in which the reference image in the low-resolution series is provided, and show that the ranking between the methods changes in this setting. This is relevant to many practical use cases of MISR where the goal is to super-resolve a specific image of the series, i.e. the reference is known. The proposed PROBA-V-REF should better reflect the performance of the different methods for this reference-aware MISR problem.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554479","Region Ile-de-France(grant numbers:ANR-11-IDEX-0003-02); Office of Naval research(grant numbers:N00014-17-1-2552); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554479","multi-image super-resolution;satellite images;deep-learning;PROBA-V challenge","Training;Satellites;Superresolution;Geoscience and remote sensing","geophysical image processing;image resolution","PROBA-V-REF;low-resolution image series;high-resolution target;multiimage super resolution;satellite images;PROBA-V dataset;reference image;low-resolution series;reference-aware MISR problem;reference-aware super resolution;PROBA-V super-resolution challenge;simple heuristic","","2","","15","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Chest CT Image Super Resolution using Deep Learning Network Models","P. Rajeshwari; K. Shyamala","Department of CSE, Anurag University, Ghatkesar, India; Deptarment of CSE, College of Engineering, Osmania University, Hyderabad, India","2021 International Conference on Smart Generation Computing, Communication and Networking (SMART GENCON)","21 Dec 2021","2021","","","1","5","Image Super Resolution is a process of converting a Low Resolution image into High Resolution image with better visual quality and improved details. It is one of the most popular technique in image processing and computer vision. Super Resolution is applied in wide range of real world applications like medical imaging, surveillance applications and reconstruction of high quality remote sensing images. In the recent years, Super Resolution using deep learning techniques significantly improved accuracy. In this paper, Implemented four deep learning network models to generate High Resolution images of chest CT scans and evaluated the quantitative measure Peak Signal-to-Noise Ratio to compare accuracy of each CNN based deep leaning network models such as Super-Resolution Convolutional Neural Network (SRCNN), Enhanced Deep Super-Resolution (EDSR), Very Deep Super-Resolution (VDSR) and Deep Recursive Convolutional Network (DRCN).","","978-1-6654-2503-2","10.1109/SMARTGENCON51891.2021.9645873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9645873","super resolution;deep learning;medical images;convolution neural networks","Deep learning;Visualization;Satellites;Computed tomography;Computational modeling;Surveillance;Superresolution","computer vision;computerised tomography;convolution;feature extraction;image processing;image reconstruction;image resolution;learning (artificial intelligence);medical image processing;neural nets;remote sensing","chest CT image Super Resolution;deep learning network models;Low Resolution image;High Resolution image;image processing;computer vision;medical imaging;high quality remote sensing images;deep learning techniques;chest CT scans;deep leaning network models;Super-Resolution Convolutional Neural Network;Enhanced Deep Super-Resolution;Deep Recursive Convolutional Network","","","","32","IEEE","21 Dec 2021","","","IEEE","IEEE Conferences"
"A Super-Resolution Mapping Using a Convolutional Neural Network","T. Kasetkasem","Department of Electrical Engineering, Kasetsart University, Bangkok, Thailand","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3077","3080","In this paper, we propose an approach for super-resolution land cover mapping on remote sensing images based on a Convolutional Neural Network (CNN). Here, the CNN is trained to match the input subimages to the super resolution map around the training pixels. Since there are so many possible configurations of super-resolution map on a given set of pixels, a large number of training samples are required. To reduce the number of training samples, we converted the super-resolution to a set of level set functions and used the minimum mean square error between the predicted and actual level set functions as the training objective. The QUICKBIRD satellite image data cover a part of Kasetsart University's Bangkhen campus was used for evaluation. Experimental results showed that the proposed method has achieved superior accuracy than both Hopfield and Pixel-Swapping methods.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898537","super-resolution mapping;convolutional neural network;level set function","Training;Level set;Remote sensing;Spatial resolution;Convolutional neural networks","geophysical image processing;image classification;image resolution;neural nets;terrain mapping","convolutional neural network;super-resolution land cover mapping;training pixels;minimum mean square error;QUICKBIRD satellite image data;Hopfield method;Pixel-Swapping method;Kasetsart University;Bangkhen campus;input subimages","","1","","7","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Hyperspectral Super-Resolution: Exact Recovery In Polynomial Time","Q. Li; W. -K. Ma; Q. Wu","Department of Electronic Eng., The Chinese University of Hong Kong, Hong Kong SAR, China; Department of Electronic Eng., The Chinese University of Hong Kong, Hong Kong SAR, China; Department of Electronic Eng., The Chinese University of Hong Kong, Hong Kong SAR, China","2018 IEEE Statistical Signal Processing Workshop (SSP)","30 Aug 2018","2018","","","378","382","In hyperspectral remote sensing, the hyperspectral super-resolution (HSR) problem has recently received growing interest. Simply speaking, the problem is to recover a super-resolution image-which has high spectral and spatial resolutions-from some lower spectral and spatial resolution measurements. Many of the current HSR studies consider matrix factorization formulations, with an emphasis on algorithms and performance in practice. On the other hand, the question of whether a factorization model is equipped with provable recovery guarantees of the true super-resolution image is much less explored. In this paper we show that unique and exact recovery of the super-resolution image is not only possible, it can also be done in polynomial time. We employ the matrix factorization model commonly used in the context of hyperspectral unmixing, and show that if certain local sparsity conditions are satisfied then the matrix factors constituting the true super-resolution image can be recovered by a simple two-step procedure.","","978-1-5386-1571-3","10.1109/SSP.2018.8450697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8450697","Hyperspectral super-resolution;hyperspectral image;multispectral image;data fusion","Spatial resolution;Hyperspectral imaging;Signal resolution;Cameras;Conferences","hyperspectral imaging;image resolution;matrix decomposition;remote sensing","super-resolution image;hyperspectral unmixing;hyperspectral super-resolution;matrix factorization model;spatial resolution measurements;super-resolution problem;hyperspectral remote sensing;polynomial time","","5","","28","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Influence of Antenna Pattern Sidelobes on the Performance of Scanning Radar Angular Super-Resolution Algorithm","Y. Peng; W. Li; Y. Huang; J. Yang","Department of Electronic Engineering, University of Electronic Scicence and Technology of China, Chengdu, China; Department of Electronic Engineering, University of Electronic Scicence and Technology of China, Chengdu, China; Department of Electronic Engineering, University of Electronic Scicence and Technology of China, Chengdu, China; Department of Electronic Engineering, University of Electronic Scicence and Technology of China, Chengdu, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2315","2318","In order to improve the angular resolution of scanning radar, a lot of super-resolution algorithms have been developed in recent years. However, the super-resolution performance is affected by many factors due to the ill-conditioned nature of inverse problem. In this paper, from the perspective of numerical simulation, we illustrated the influence of the antenna pattern sidelobes on the condition number of the convolution matrix, and then analyzed the influence on the performance of the super-resolution algorithm.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883143","Scanning radar;antenna pattern;condition number;super resolution","Radar remote sensing;Convolution;Inverse problems;Superresolution;Radar;Radar antennas;Numerical simulation","antenna radiation patterns;deconvolution;image resolution;inverse problems;iterative methods;radar imaging;radar resolution;radar signal processing","antenna pattern sidelobes;scanning radar angular super-resolution algorithm;angular resolution;super-resolution performance;ill-conditioned nature","","","","6","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"SAR Image Super-Resolution Based on Noise-Free Generative Adversarial Network","F. Gu; H. Zhang; C. Wang; F. Wu","Key Laboratory of Digital Earth Science, of Institute of Remote Sensing and Digital Earth, Chinese Academy of Science, Beijing, China; Key Laboratory of Digital Earth Science, of Institute of Remote Sensing and Digital Earth, Chinese Academy of Science, Beijing, China; Key Laboratory of Digital Earth Science, of Institute of Remote Sensing and Digital Earth, Chinese Academy of Science, Beijing, China; Key Laboratory of Digital Earth Science, of Institute of Remote Sensing and Digital Earth, Chinese Academy of Science, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2575","2578","Deep learning has been successfully applied to the ordinary image super-resolution (SR). However, since the synthetic aperture radar (SAR) images are often disturbed by multiplicative noise known as speckle and more blurry than ordinary images, there are few deep learning methods for the SAR image SR. In this paper, a deep generative adversarial network (DGAN) is proposed to reconstruct the pseudo high-resolution (HR) SAR images. First, a generator network is constructed to remove the noise of low-resolution SAR image and generate HR SAR image. Second, a discriminator network is used to differentiate between the pseudo super-resolution images and the realistic HR images. The adversarial objective function is introduced to make the pseudo HR SAR images closer to real SAR images. The experimental results show that our method can maintain the SAR image content with high-level noise suppression. The performance evaluation based on peak signal-to-noise-ratio and structural similarity index shows the superiority of the proposed method to the conventional CNN baselines.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899202","Synthetic aperture radar;super-resolution;generative adversarial network","Radar polarimetry;Image reconstruction;Generators;Training;Generative adversarial networks","image denoising;image resolution;learning (artificial intelligence);neural nets;radar computing;radar imaging;radar resolution;synthetic aperture radar","deep generative adversarial network;realistic HR images;adversarial objective function;synthetic aperture radar images;SAR image superresolution;noise free generative adversarial network;deep learning;DGAN;pseudo high-resolution SAR images","","7","","12","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"A New Public Alsat-2B Dataset for Single-Image Super-Resolution","A. Djerida; K. Djerriri; M. S. Karoui; M. El Amin larabi","Agence Spatiale Algérienne, Centre des Techniques Spatiales, Arzew, Algérie; Agence Spatiale Algérienne, Centre des Techniques Spatiales, Arzew, Algérie; Agence Spatiale Algérienne, Centre des Techniques Spatiales, Arzew, Algérie; Agence Spatiale Algérienne, Centre des Techniques Spatiales, Arzew, Algérie","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","8095","8098","Recently, deep learning methods dominate the proposed solutions for image super-resolution due to their powerful properties. However, for remote sensing benchmarks, it is very expensive to obtain high spatial resolution images. Most of the super-resolution methods use down-sampling techniques to simulate low and high spatial resolution pairs and construct the training samples. As an alternative, the paper introduces a novel public remote sensing dataset (Alsat-2B) of low and high spatial resolution images (10m and 2.5m respectively) where the high-resolution images are obtained through pansharpening. Besides, the performance of some state-of-the-art methods is assessed based on common criteria. The obtained results reveal that the proposed scheme is promising and highlight the challenges in the dataset which show the need for advanced methods to grasp the relationship between the low and high-resolution patches.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554452","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554452","Single-image super-resolution;dataset creation;deep learning and Alsat-2B","Training;Deep learning;Interpolation;Superresolution;Pansharpening;Benchmark testing;Data models","deep learning (artificial intelligence);geophysical image processing;image resolution;image sampling;remote sensing","single-image superresolution;deep learning methods;remote sensing benchmarks;high spatial resolution images;public remote sensing dataset;low resolution patches;high-resolution patches;public Alsat-2B dataset;down-sampling technique;low spatial resolution images;pansharpening","","","","13","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Lightweight Feedback Convolution Neural Network for Remote Sensing Images Super-Resolution","J. Wang; Y. Wu; L. Wang; L. Wang; O. Alfarraj; A. Tolba","School of Information Science and Engineering, Fujian University of Technology, Fuzhou, China; Hunan Provincial Key Laboratory of Intelligent Processing of Big Data on Transportation, School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; Hunan Provincial Key Laboratory of Intelligent Processing of Big Data on Transportation, School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; School of Civil Engineering, Changsha University of Science and Technology, Changsha, China; Department of Computer Science, Community College, King Saud University, Riyadh, Saudi Arabia; Department of Mathematics and Computer Science, Faculty of Science, Menoufia University, Shebin El-Kom, Egypt","IEEE Access","28 Jan 2021","2021","9","","15992","16003","There are lots of image data in the field of remote sensing, most of which have low-resolution due to the limited image sensor. The super-resolution method can effectively restore the low-resolution image to the high-resolution image. However, the existing super-resolution method has both heavy computing burden and number of parameters. For saving costs, we propose the feedback ghost residual dense network (FGRDN), which considers the feedback mechanism as the framework to attain lower features through high-level refining. Further, for feature extraction, we replace the convolution of the residual dense blocks (RDBs) with ghost modules (GMs), which can remove the redundant channels and avoid the increase of parameters along with the network depth. Finally, the spatial and channel attention module (SCM) is employed in the end of the RDB to learn more useful information from features. Compared to other SOTA lightweight algorithms, our proposed algorithm can reach convergences more rapidly with fewer parameters, and the performance of the network can be markedly enhanced on the image texture and object contour reconstruction with better peak signal-to-noise ratio (PSNR) and structural similarity (SSIM).","2169-3536","","10.1109/ACCESS.2021.3052946","Deanship of Scientific Research at King Saud University, Riyadh, Saudi Arabia through the Research Group(grant numbers:RG-1438-070); National Natural Science Foundation of China(grant numbers:61772454,62072056); National Key Research and Development Program of China(grant numbers:2019YFC1511000); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328537","Remote sensing;super-resolution;feedback mechanism;ghost module;attention mechanism","Feature extraction;Convolution;Superresolution;Remote sensing;Image reconstruction;Data mining;Image sensors","convolutional neural nets;feature extraction;image resolution;image restoration;remote sensing","remote sensing images super-resolution;low-resolution image restoration;feedback ghost residual dense network;feedback mechanism;feature extraction;residual dense blocks;ghost modules;network depth;convolution neural network;spatial and channel attention module;SCM;RDBs;GMs;FGRDN","","3","","49","CCBY","19 Jan 2021","","","IEEE","IEEE Journals"
"Adaptive regularization method for forward looking Azimuth super-resolution of a Dual-Frequency Polarized Scatterometer","L. Liu; X. Dong; J. Zhu; D. Zhu","University of Chinese Academy of Science, Beijing, China; The CAS Key Laboratory of Microwave Remote Sensing, Chinese Academy of Science, Beijing, China; DFH Satellite co., Ltd, Beijing, China; The CAS Key Laboratory of Microwave Remote Sensing, Chinese Academy of Science, Beijing, China","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","739","742","Dual-Frequency Polarized Scatterometer (DFPSCAT) is a pencil-beam rotating scatterometer which is used to measure snow water equivalence (SWE). Respecting the low azimuth resolution of its forward-looking region, an adaptive regularization deconvolution super-resolution method, based on the scatterometer echo signal model, is proposed. Compared with the classical SIR and MAP algorithms, the proposed method can better reconstruct the original signal, and has less noise amplification. The algorithm processing accuracy with different Kpc is also studied, and the results show that when the value of Kpc is less than 0.1, nearly the entire restored data can satisfy the requirement of 0.5dB accuracy.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7325870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325870","DFPSCAT;azimuth super-resolution;adaptive regularization method;accuracy","Accuracy;Azimuth;Radar measurements;Spaceborne radar;Signal resolution;Adaptation models;Noise measurement","geophysical signal processing;remote sensing by radar;signal reconstruction;snow","adaptive regularization method;forward looking azimuth superresolution;dual-frequency polarized scatterometer;pencil-beam rotating scatterometer;snow water equivalence measurement;forward-looking region;scatterometer echo signal model;classical SIR algorithm;MAP algorithm;noise amplification;signal reconstruction","","2","","6","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Robust Deep Hyperspectral Imagery Super-Resolution","J. Nie; L. Zhang; C. Wang; W. Wei; Y. Zhang","School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","847","850","Fusing a low spatial resolution (LR) hyperspectral image (HSI) with a high spatial resolution (HR) multi-spectral image (MSI) is an effective way for HSI super-resolution. When the input LR HSI and the HR MSI are clean, most of existing fusion based methods can produce pleasing results. However, the input HSI and MSI are often corrupted with random noise in practice, which can greatly degrade the performance of these methods. To address this problem, we present a robust deep HSI super-resolution method in this study. In contrast to leveraging a heuristic shallow sparsity or low-rank prior in previous methods, we propose to employ a deep convolution neural network as the prior of the latent HR HSI. With such a prior, the fusion based HSI super-resolution can be formulated as an end-to-end deep learning problem, which can be effectively solved with the back-propagation algorithm. Due to the deep structure, the proposed image prior is able to capture more powerful statistics of the latent HR HSI, and thus can still produce pleasing results with noisy input images. Experimental results on two benchmark datasets demonstrate the effectiveness of the proposed method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900117","Hyperspectral image super-resolution;deep convolution neural networks;unsupervised learning","Noise measurement;Image reconstruction;Spatial resolution;Convolution;Neural networks","convolutional neural nets;geophysical image processing;hyperspectral imaging;image fusion;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","robust deep hyperspectral imagery super-resolution;low spatial resolution hyperspectral image;high spatial resolution multispectral image;MSI;input LR HSI;fusion based methods;input HSI;robust deep HSI super-resolution method;heuristic shallow sparsity;deep convolution neural network;end-to-end deep learning problem;deep structure;noisy input images","","3","","12","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Information Purification Network for Remote Sensing Image Super-Resolution","Z. Wang; L. Li; L. Xing; J. Wang; K. Sun; H. Ma","College of Information Science and Engineering, Xinjiang University, Urumqi, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; College of Information Science and Engineering, Xinjiang University, Urumqi, China; Shanghai Institute of Satellite Engineering, Shanghai, China; Shanghai Institute of Satellite Engineering, Shanghai, China; Department of Electronic Engineering, Tsinghua University, Beijing, China","Tsinghua Science and Technology","29 Sep 2022","2023","28","2","310","321","Recently, several well-performing deep convolutional neural networks were proposed for remote sensing image super-resolution (SR). However, these methods rarely consider that remote sensing images are corruptible by additional noise, blurring, and other factors. Therefore, to eliminate the interference of these factors, especially the noise, we propose a novel information purification network (IPN) for remote sensing image SR. The proposed information purification block (IPB) can process channel-wise features differently by channel separation and rescale spatial-wise features adaptively through the proposed multi-scale spatial attention mechanism. We further design an information group to explore a more powerful expressive combination of IPBs. Moreover, long and short skip connections can transmit abundant low-frequency information, making IPBs pay more attention to high-frequency information. We mix the images under various degradation models as training data in the training phase. In this way, the network can directly reconstruct various degraded images. Experiments on AID and UC Merced Land-Use datasets under multiple degradation models demonstrate that the proposed IPN performs better than state-of-the-art methods.","1007-0214","","10.26599/TST.2022.9010002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9906041","deep convolutional neural networks;remote sensing image;super-resolution;information purification network","Degradation;Training;Adaptation models;Purification;Superresolution;Training data;Sensors","geophysical image processing;image recognition;image reconstruction;image resolution;learning (artificial intelligence);neural nets;remote sensing","remote sensing image super-resolution;deep convolutional neural networks;remote sensing images;novel information purification network;remote sensing image SR;information purification block;IPB;channel-wise features;channel separation;rescale spatial-wise features;multiscale spatial attention mechanism;information group;low-frequency information;high-frequency information;degraded images","","","","36","","29 Sep 2022","","","TUP","TUP Journals"
"SAR Image Super-Resolution based on Artificial Intelligence","W. Yang; Z. Ma; Y. Shi","School of Electronic and information Engineering, Beihang University, Beijing, China; School of Electronic and information Engineering, Beihang University, Beijing, China; School of Electronic and information Engineering, Beihang University, Beijing, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","4643","4646","High-resolution synthetic aperture radar (SAR) image can provide detailed information of the target, which is a benefit for improving the performance of the following interpretation application. However, the higher the resolution, the more complex the system and the higher the cost. A new challenge is how to obtain high-resolution target images from medium resolution images, by using new technology, such as artificial intelligence. In this paper, a new method is proposed to improve the resolution based on the SRGAN-SSIM. Since SRGAN is developed for nature image super-resolution, which results in a poor performance for SAR image, pre-processing is implemented. A modified Non-Local Means (NLM) is adopted for speckle noise suppression. Then, SRGAN based net is used for super-resolution, and the loss function is optimized according to the SSIM. Finally, the method is verified by Terra-SAR images.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884456","Synthetic aperture radar (SAR);Image;Super-resolution (SR);AI;SRGAN","Costs;Superresolution;Noise reduction;Buildings;Geoscience and remote sensing;Speckle;Radar polarimetry","image denoising;image resolution;radar imaging;speckle;synthetic aperture radar","artificial intelligence;nature image super-resolution;SRGAN based net;Terra-SAR images;SAR image super-resolution;high-resolution synthetic aperture radar image;interpretation application;high-resolution target images;medium resolution images","","","","13","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"A Fast Multidimensional Data Fusion Algorithm For Hyperspectral Spatiotemporal Super-Resolution","P. -C. Chang; J. -T. Lin; C. -H. Lin; P. -W. Tang; Y. Liu","The Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; The Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Miin Wu School of Computing, National Cheng Kung University, Tainan, Taiwan; The Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; The Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan","2022 12th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","22 Nov 2022","2022","","","1","5","In hyperspectral remote sensing, obtaining fine spatial-temporal and spatial-spectral resolution images are two critical fusion issues due to inherent optical sensor trade-offs. However, simultaneous realization of spatial, spectral, and temporal super-resolution is highly challenging. This paper formulates a new fusion framework incorporating all the three spatial/spectral/temporal dimensions to achieve hyperspectral spatiotemporal (HST) super-resolution. Additionally, unlike many fusion methods assuming availability of the spatial blurring matrix (SBM) in the forward model, we go a step further to blindly achieve HST super-resolution by automatically estimating the SBM. Subsequently, final results can be obtained through the fast iterative shrinkage-thresholding algorithm (FISTA) and the convex optimization-based coupled nonnegative matrix factorization (CO-CNMF) algorithm. We compare results of the proposed HST super-resolution method, termed GFCSR, with other extended spatiotemporal fusion frameworks designed for multispectral images, and, as it turns out, quantitative evaluations demonstrate the superiority of our algorithm.","2158-6276","978-1-6654-7069-8","10.1109/WHISPERS56178.2022.9955073","Ministry of Science and Technology; National Cheng Kung University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955073","Convex optimization;hyperspectral image;image fusion;multispectral image;nonnegative matrix factorization;spatiotemporal super-resolution","Superresolution;Signal processing algorithms;Data integration;Signal processing;Iterative algorithms;Spatiotemporal phenomena;Optical sensors","geophysical image processing;hyperspectral imaging;image fusion;image resolution;image sampling;iterative methods;matrix decomposition;remote sensing;spatiotemporal phenomena;spectral analysis","CO-CNMF;convex optimization-based coupled nonnegative matrix factorization algorithm;critical fusion issues;extended spatiotemporal fusion frameworks;fast iterative shrinkage-thresholding algorithm;FISTA;fusion methods;HST superresolution method;hyperspectral remote sensing;hyperspectral spatiotemporal superresolution;inherent optical sensor trade-offs;multidimensional data fusion algorithm;SBM;spatial blurring matrix;spatial-spectral resolution images;spatial-spectral-temporal dimensions","","","","20","IEEE","22 Nov 2022","","","IEEE","IEEE Conferences"
"From Artifact Removal to Super-Resolution","J. Wang; Z. Shao; X. Huang; T. Lu; R. Zhang; Y. Li","State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Department of Geosciences, University of Arkansas, Fayetteville, AR, USA; School of Computer Science and Engineering, Wuhan Institute of Technology, Wuhan, China; Institute of Photogrammetry and Remote Sensing, Chinese Academy of Surveying and Mapping, Beijing, China; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","23 Aug 2022","2022","60","","1","15","Deep-learning-based super-resolution (SR) methods have been extensively studied and have achieved significant performance with deep convolutional neural networks. However, the results still suffer from the ringing effect, especially in satellite image SR tasks, due to the loss of image details in the satellite degradation process. In this article, we build a novel satellite SR framework by decomposing a high-resolution image into three components, i.e., low-resolution (LR), artifact, and high-frequency information. Specifically, we propose an artifact removal network with a self-adaption difference convolution (SDC) to fully exploit the structure prior in the LR image and predict the artifact map. Considering that the artifact map and the high-frequency map share a similar pattern, we introduce the supervised structure correction (SSC) block that establishes a bridge between the high-frequency generation process and the artifact removal process. Experimental results on satellite images demonstrate that the proposed method owns an improved tradeoff between the performance and the computational cost compared to existing state-of-the-art satellite and natural SR methods. The source code is available at https://github.com/jiaming-wang/ARSRN.","1558-0644","","10.1109/TGRS.2022.3196709","National Natural Science Foundation of China(grant numbers:42090012); Guangxi Science and Technology Program(grant numbers:GuiKe 2021AB30019); 03 Special Research and 5G Project of Jiangxi Province in China(grant numbers:20212ABC03A09); Zhuhai Industry University Research Cooperation Project of China(grant numbers:ZH22017001210098PWC); Sichuan Science and Technology Program(grant numbers:2022YFN0031); Zhizhuo Research Fund on Spatial-Temporal Artificial Intelligence(grant numbers:ZZJJ202202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9851467","Artifact removal;difference convolution;remote sensing;super-resolution (SR)","Satellites;Image edge detection;Task analysis;Convolution;Superresolution;Image reconstruction;Generative adversarial networks","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image resolution","deep convolutional neural networks;ringing effect;satellite image SR tasks;image details;satellite degradation process;high-resolution image;high-frequency information;artifact removal network;self-adaption difference convolution;LR image;artifact map;supervised structure correction block;high-frequency generation process;deep-learning-based super-resolution methods;low-resolution","","","","59","IEEE","5 Aug 2022","","","IEEE","IEEE Journals"
"NASA NeMO-Net - A Neural Multimodal Observation & Training Network for Marine Ecosystem Mapping at Diverse Spatiotemporal Scales","V. Chirayath; A. Li; J. Torres-Perez; M. Segal-Rozenhaimer; J. van den Bergh","NASA Ames Laboratory for Advanced Sensing, Mountain View, CA, USA; NASA Ames Laboratory for Advanced Sensing, Mountain View, CA, USA; NASA Ames Laboratory for Advanced Sensing, Mountain View, CA, USA; NASA Ames Laboratory for Advanced Sensing, Mountain View, CA, USA; NASA Ames Laboratory for Advanced Sensing, Mountain View, CA, USA","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","3633","3636","We present NeMO-Net, the first open-source fully convolutional neural network (FCNN) and interactive learning and training software aimed at assessing the present and past dynamics of shallow marine systems through habitat mapping into geomorphological (9 classes) and biological classes (22 classes). Shallow marine systems, particularly coral reefs, are under significant pressures due to climate change, ocean acidification, and other anthropogenic pressures, leading to rapid, often devastating changes, in these fragile and diverse ecosystems. Historically, remote sensing of shallow marine habitats has been limited to meter-scale imagery due to the optical effects of ocean wave distortion, refraction, and optical attenuation. NeMO-Net combines 3D cm-scale distortion-free imagery captured using NASA's airborne FluidCam and fluid lensing remote sensing technology with low resolution airborne and spaceborne datasets of varying spatial resolutions, spectral spaces, calibrations, and temporal cadence in a supercomputer-based deep learning framework. NeMO-Net augments and improves the benthic habitat classification accuracy of low-resolution datasets across large geographic and temporal scales using high-resolution training data from FluidCam. NeMO-Net's FCNN uses ResNet and RefineNet to perform semantic segmentation and cloud masking of remote sensing imagery of shallow marine systems from drones, manned aircraft, and satellites, including FluidCam, WorldView, Planet, Sentinel, and Landsat. Deep Laplacian Pyramid Super-Resolution Networks (LapSRN) alongside Domain Adversarial Neural Networks (DANNs) are used to augment low resolution imagery with high resolution drone-based datasets as well as recognize domain-invariant features across multiple instruments to achieve high classification accuracies, ameliorating inter-sensor spatial, spectral and temporal heterogeneities. An online active learning and citizen science application is used to allows users to provide interactive training data for NeMO-Net in 2D and 3D, fully integrated within an active learning framework. Preliminary results from a test case in Fiji demonstrate 9-class classification accuracy exceeding 84%.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323188","NASA(grant numbers:16-0046); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323188","Multimodal remote sensing;neural networks;coral reefs;fluid lensing;machine learning","Remote sensing;Fluids;Spatial resolution;Three-dimensional displays;Satellites;NASA;Decoding;Climate change","convolutional neural nets;deep learning (artificial intelligence);feature extraction;geophysical image processing;image classification;image resolution;image segmentation;marine systems;oceanographic techniques;remote sensing","spatial resolutions;supercomputer-based deep learning framework;benthic habitat classification accuracy;low-resolution datasets;geographic scales;temporal scales;high-resolution training data;remote sensing imagery;shallow marine systems;Deep Laplacian Pyramid Super-Resolution Networks;Domain Adversarial Neural Networks;low resolution imagery;high resolution drone-based datasets;interactive training data;Fiji demonstrate 9-class classification accuracy;NASA NeMO-Net;marine ecosystem mapping;diverse spatiotemporal scales;interactive learning;training software;habitat mapping;biological classes;fragile ecosystems;diverse ecosystems;shallow marine habitats;meter-scale imagery;ocean wave distortion;fluid lensing remote sensing technology;spaceborne datasets;NeMO-Net FCNN;Neural multimodal observation-training network;NASA airborne FluidCam;geomorphological classess;coral reefs;climate change;ocean acidification;anthropogenic pressures;3D cm-scale distortion-free imagery;low resolution airborne dataset;spectral spaces;calibrations;temporal cadence;ResNet;RefineNet;semantic segmentation;cloud masking;drones;manned aircraft;satellites;WorldView;Planet;Sentinel;Landsat;LapSRN;DANNs;temporal heterogeneities;online active learning;citizen science application;open-source fully convolutional neural network","","","","20","USGov","17 Feb 2021","","","IEEE","IEEE Conferences"
"A deep learning based spatial dependency modelling approach towards super-resolution","Arun P.V.; K. M. Buddhiraju","Centre for studies in Resources Engineering, Indian Institute of Technology, Bombay; Centre for studies in Resources Engineering, Indian Institute of Technology, Bombay","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","6533","6536","Super-resolution techniques use subpixel information to predict high resolution classification maps from coarse images. This study investigates for an unsupervised super-resolution approach which considers the image features to predict target spatial dependencies. Novelty of the approach is that the convolution neural networks and deep autoencoders are explored in this context. Evaluation over standard datasets revealed that the proposed method is more effective than the state of art unsupervised approaches. The method is also found to be preferable over variogram based approaches for complex scenes. This study also compares the effectiveness of shallow and deep networks and investigates the possible assessment of the optimal depth for the learning network. This technique can be further extended to a supervised framework.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730707","Super-resolution;Convolution network;hyperspectral classification","Spatial resolution;Convolution;Hyperspectral imaging;Neural networks","hyperspectral imaging;image classification;learning (artificial intelligence);neural nets;remote sensing","spatial dependency modelling approach;super-resolution technique;subpixel information;high-resolution image classification map;unsupervised super-resolution approach;image feature;convolution neural network;deep autoencoder;variogram-based approach;shallow learning network;deep learning network","","2","","12","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Deep Spectral Super-Resolution with Noisy Input","Z. Lang; L. Zhang; W. Wei; J. Nie; C. Tian; Y. Zhang","School of Computer Science, Northwestern Polytechnical University, Xi’an, Shaanxi, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, Shaanxi, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, Shaanxi, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, Shaanxi, China; School of Electronic and Engineering, Xidian University, Xi’an, Shaanxi; School of Computer Science, Northwestern Polytechnical University, Xi’an, Shaanxi, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","624","627","Learning based methods, e.g., sparse coding or deep convolutional neural networks (DCNNs) have underpinned much of recent progress in increasing the spectral resolution of an RGB image for hyperspectral image (HSI) super-resolution. However, these methods suffer severe performance loss, when the test RGB image distributed differently from the training set, e.g., being corrupted with random noise. To mitigate this problem, we propose an unsupervised deep spectral super-resolution method, which employs a DCNN to generate the latent HSI from an input RGB and encourages it to fit the input RGB image through down-sampling in spectral domain as well as a sparse gradient prior in spatial domain. Due to the powerful capacity of DCNN in capturing the low-level image statistics, the proposed method is able to automatically accommodate the noise corruption in the input RGB image. Experimental results shows the superior performance of the proposed method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900510","Spectral super-resolution;unsupervised learning;deep convolutional neural networks","Image reconstruction;Noise level;Noise measurement;Spatial resolution;TV","convolutional neural nets;feature extraction;geophysical image processing;hyperspectral imaging;image classification;image coding;image colour analysis;image representation;image resolution;image restoration;remote sensing;sparse matrices;unsupervised learning","noisy input;sparse coding;deep convolutional neural networks;spectral resolution;hyperspectral image super-resolution;performance loss;unsupervised deep spectral super-resolution method;latent HSI;input RGB image;spectral domain;sparse gradient;low-level image statistics","","1","","11","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Combined Model Color-Correction Method Utilizing External Low-Frequency Reference Signals for Large-Scale Optical Satellite Image Mosaics","H. Cui; G. Zhang; T. -Y. Wang; X. Li; J. Qi","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Geosciences and Info-Physics, Central South University, Changsha, China","IEEE Transactions on Geoscience and Remote Sensing","21 May 2021","2021","59","6","4993","5007","Optical satellites are affected by factors such as seasonal and atmospheric variation, illumination, and sensor distortion. Thus, satellite images covering large-scale area often show conspicuous color differences, resulting in poor color continuity of the mosaicked satellite image. This study proposes a novel combined model color correction (CMCC) method for high-resolution optical satellite images, which constructively combines a defogging model with a radiation correction model. First, this study analyzed the feasibility of using easily available low-resolution satellite images as external references to correct the color of high-resolution images and describes the selection criteria for external references. Second, considering the negative effects of atmosphere on the color and clarity of remote sensing images, we proposed an optical satellite image enhancement method, which is based on the content characteristics of remote sensing images and the dark channel prior defogging method. Finally, we designed a two-stage color correction process: 1) correcting the color of downsampled images via low-frequency modeling and replacement and 2) mapping the color of downsampled images to original images through local modeling and super-resolution color correction. Furthermore, this study proposes an indicator of quality considered mean absolute error (QCMAE) for quantitative evaluation of the color correction result. We selected 328 Gaofen-1 (GF-1) high-resolution images for the experiments. Visual effects and statistical results of images after being processed by the proposed CMCC are both superior to the three state-of-the-art methods, which verifies the effectiveness and reliability of the proposed method.","1558-0644","","10.1109/TGRS.2020.3018591","Key Research and Development Program of Ministry of Science and Technology(grant numbers:2018YFB0504905,2016YFB0500801); Quality Improvement of Chinese Satellite Data and Comprehensive Application Demonstration of Geology and Mineral Resources, National Natural Science Foundation of China(grant numbers:91538106,41501503,41601490,41501383); Open Research Fund of State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing(grant numbers:15E02); Fundamental Research Funds for the Central University(grant numbers:2042016kf0163); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9193955","Color correction;image enhancement;image mosaic;low frequency signal","Image color analysis;Satellites;Remote sensing;Atmospheric modeling;Adaptive optics;Optical imaging;Optical sensors","geophysical image processing;image colour analysis;image enhancement;image resolution;image segmentation;remote sensing","model color-correction method utilizing external low-frequency reference signals;large-scale optical satellite image mosaics;optical satellites;seasonal variation;atmospheric variation;large-scale area;conspicuous color differences;poor color continuity;mosaicked satellite image;combined model color correction method;high-resolution optical satellite images;defogging model;radiation correction model;low-resolution satellite images;external references;high-resolution images;remote sensing images;optical satellite image enhancement method;two-stage color correction process;downsampled images;low-frequency modeling;original images;local modeling;super-resolution color correction;color correction result","","3","","46","IEEE","10 Sep 2020","","","IEEE","IEEE Journals"
"Hyperspectral Image Super-Resolution Based on Multiscale Residual Block and Multilevel Feature Fusion","G. Yu; F. Zhang; T. Hu; W. Li; R. Tao","School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2170","2173","Hyperspectral images have high spectral resolution, but this is often at the expense of spatial resolution. Although deep learning-based super-resolution (SR) algorithms have shown comparative performance for spatial resolution enhancement, most of them cannot effectively extract features of different size objects because of single scale convolution. In deep architectures, low level features also tend to disappear during transmission. In this paper, an efficient network (MRBMFF) for enhancing the spatial resolution of hyperspectral image is proposed. Based on the multiscale residual block (MRB), features at different scales can be effectively extracted and fused. Meanwhile, the multilevel feature fusion (MFF) is introduced to concatenate the low and high level features. Effective SR images could be recovered after inputting their low-resolution counterparts to the proposed network. Experimental results show that the proposed network achieves superior reconstruction performance compared with the state-of-the-art approaches.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553552","Beijing Natural Science Foundation(grant numbers:L191004); National Natural Science Foundation of China(grant numbers:61731023,61922013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553552","hyperspectral imagery;super-resolution;multiscale residual block;feature fusion","Convolution;Superresolution;Geoscience and remote sensing;Deep architecture;Feature extraction;Spatial resolution;Image reconstruction","deep learning (artificial intelligence);feature extraction;geophysical image processing;image fusion;image reconstruction;image resolution","SR images;hyperspectral image super-resolution;multiscale residual block;multilevel feature fusion;high spectral resolution;deep learning-based super-resolution algorithms;spatial resolution enhancement;size objects;single scale convolution;deep architectures","","1","","11","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Self-Supervised Push-Frame Super-Resolution With Detail-Preserving Control And Outlier Detection","N. L. Nguyen; J. Anger; A. Davy; P. Arias; G. Facciolo","CNRS, ENS Paris-Saclay, Centre Borelli, Université Paris-Saclay, France; Kayrros SAS; CNRS, ENS Paris-Saclay, Centre Borelli, Université Paris-Saclay, France; CNRS, ENS Paris-Saclay, Centre Borelli, Université Paris-Saclay, France; CNRS, ENS Paris-Saclay, Centre Borelli, Université Paris-Saclay, France","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","131","134","Self-supervised training enables the application of deep-learning based methods for multi-image super-resolution of satellite imagery. In this work we propose two improvements on the self-supervised Deep-Shift-and-Add (DSA) method introduced by Nguyen et al. First, we demonstrate how the self-supervised loss of DSA can be extended to provide the image interpreter with a spatially varying parameter to control the trade-off between detail preservation and noise removal at test time. Second, we endow the DSA architecture with a mechanism that enables the network to be robust to outliers produced for example by dead pixels, reflections or registration errors.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883593","Office of Naval research(grant numbers:N00014-17-1-2552); CNRS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883593","push-frame burst satellite imaging;multi-image super-resolution;deep-learning;self-supervised learning;robust estimators","Training;Satellites;Superresolution;Geoscience and remote sensing;Reflection;Spatial resolution;Anomaly detection","deep learning (artificial intelligence);image registration;image resolution;supervised learning","self-supervised push-frame super-resolution;detail-preserving control;outlier detection;self-supervised training;deep-learning based methods;multiimage super-resolution;satellite imagery;image interpreter;spatially varying parameter;trade-off between detail preservation;noise removal;DSA architecture;self-supervised deep-shift-and-add method","","","","11","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"3D Expansion of SRCNN for Spatial Enhancement of Hyperspectral Remote Sensing Images","N. Aburaed; M. Q. Alkhatib; S. Marshall; J. Zabalza; H. Al Ahmad","Department of Electronic and Electrical Engineering, University of Strathclyde, UK; College of Engineering and IT, University of Dubai, UAE; Department of Electronic and Electrical Engineering, University of Strathclyde, UK; Department of Electronic and Electrical Engineering, University of Strathclyde, UK; College of Engineering and IT, University of Dubai, UAE","2021 4th International Conference on Signal Processing and Information Security (ICSPIS)","27 Dec 2021","2021","","","9","12","Hyperspectral Imagery (HSI) have high spectral resolution but suffer from low spatial resolution due to sensor tradeoffs. This limitation hinders utilizing the full potential of HSI. Single Image Super Resolution (SISR) techniques can be used to enhance the spatial resolution of HSI. Since these techniques rely on estimating missing information from one Low Resolution (LR) HSI, they are considered ill-posed. Furthermore, most spatial enhancement techniques cause spectral distortions in the estimated High Resolution (HR) HSI. This paper deals with the extension and modification of Convolutional Neural Networks (CNNs) to enhance HSI while preserving their spectral fidelity. The proposed method is tested, evaluated, and compared against other methodologies quantitatively using Peak Signal-to-noise Ratio (PSNR), Structural Similarity Index Measurement (SSIM), and Spectral Angle Mapper (SAM).","","978-1-6654-3796-7","10.1109/ICSPIS53734.2021.9652420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652420","Hyperspectral;remote sensing;single image super resolution;3D convolution","Visualization;Interpolation;Three-dimensional displays;PSNR;Information security;Distortion;Sensors","convolutional neural nets;geophysical image processing;image fusion;image resolution;remote sensing","high spectral resolution;low spatial resolution;single image super resolution techniques;low resolution HSI;spatial enhancement techniques;spectral distortions;spectral fidelity;spectral angle mapper;hyperspectral remote sensing;hyperspectral imagery;estimated high resolution HSI;SISR techniques;structural similarity index measurement;SSIM;SAM","","4","","11","IEEE","27 Dec 2021","","","IEEE","IEEE Conferences"
"Hybrid-Scale Self-Similarity Exploitation for Remote Sensing Image Super-Resolution","S. Lei; Z. Shi","Shenyuan Honors College, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","15 Dec 2021","2022","60","","1","10","Recently, deep convolutional neural networks (CNNs) have made great progress in remote sensing image super-resolution (SR). The CNN-based methods can learn powerful feature representation from plenty of low- and high-resolution counterparts. For remote sensing images, there are many similar ground targets recurred inside the image itself, both within the same scale and across different scales. In this article, we argue that this internal recurrence can be used for learning stronger feature representation, and we propose a new hybrid-scale self-similarity exploitation network (HSENet) for remote sensing image SR. Specifically, we introduce a single-scale self-similarity exploitation module (SSEM) to compute the feature correlation within the same scale image. Moreover, we design a cross-scale connection structure (CCS) to capture the recurrences across different scales. By combining SSEM and CCS, we further develop a hybrid-scale self-similarity exploitation module (HSEM) to construct the final HSENet, which simultaneously exploits single- and cross-scale similarities. Experimental results demonstrate that HSENet can obtain superior performance over several state-of-the-art methods. Besides, the effectiveness of our method is also verified by the assistance to the remote sensing scene classification task.","1558-0644","","10.1109/TGRS.2021.3069889","National Key Research and Development Program of China(grant numbers:2019YFC1510905); National Natural Science Foundation of China(grant numbers:61671037); Beijing Natural Science Foundation(grant numbers:4192034); Academic Excellence Foundation of BUAA for Ph.D. Students(grant numbers:20200666); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400474","Deep convolutional neural networks (CNNs);remote sensing images;self-similarity;super-resolution (SR)","Remote sensing;Feature extraction;Wavelet transforms;Task analysis;Superresolution;Image edge detection;Correlation","","","","6","","61","IEEE","12 Apr 2021","","","IEEE","IEEE Journals"
"Self-Normalizing Generative Adversarial Network for Super-Resolution Reconstruction of SAR Images","C. Zheng; X. Jiang; Y. Zhang; X. Liu; B. Yuan; Z. Li","School of Electronic Information and Electrical Engineering; School of Electronic Information and Electrical Engineering; Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering; School of Electronic Information and Electrical Engineering; Beijing Institute of Remote Sensing Information, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","1911","1914","High-resolution images with abundant detailed information are necessary elements for various applications of synthetic aperture radar (SAR). In this paper, a novel super-resolution image reconstruction method based on self-normalizing generative adversarial network (SNGAN) is proposed. Compared with other published GAN-based super-resolution algorithms, the proposed method reflects its superiority in two aspects. First, the scaled exponential linear units (SeLU) is introduced as the activation function of generator to give the GAN system self-normalization ability and make it more suitable for SAR images. Second, the batch normalization layers after convolution are canceled to reduce the computational requirement and model oscillation. Experiment results on the images of TerraSAR and MSTAR dataset demonstrate that the proposed method acquires satisfactory performance on the resolution enhancement and target recognition of SAR images.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900084","Generative adversarial network (GAN);super-resolution image reconstruction;target recognition","Image reconstruction;Radar polarimetry;Gallium nitride;Generative adversarial networks;Target recognition","image reconstruction;image resolution;neural nets;radar imaging;synthetic aperture radar","self-normalizing generative adversarial network;super-resolution reconstruction;SAR images;high-resolution images;synthetic aperture radar;batch normalization layers;resolution enhancement;super-resolution image reconstruction method;activation function;TerraSAR dataset;MSTAR dataset;target recognition","","9","","11","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Hyperspectral Image Super-Resolution via Local Low-Rank and Sparse Representations","R. Dian; S. Li; L. Fang; J. Bioucas-Dias","Instituto de Telecomunicacões, Universidade de Lisboa, Lisbon, Portugal; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; Instituto de Telecomunicacões, Universidade de Lisboa, Lisbon, Portugal","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","4003","4006","Remotely sensed hyperspectral images (HSIs) usually have high spectral resolution but low spatial resolution. A way to increase the spatial resolution of HSIs is to solve a fusion inverse problem, which fuses a low spatial resolution HSI (LR-HSI) with a high spatial resolution multispectral image (HR-MSI) of the same scene. In this paper, we propose a novel HSI super-resolution approach (called LRSR), which formulates the fusion problem as the estimation of a spectral dictionary from the LR-HSI and the respective regression coefficients from both images. The regression coefficients are estimated by formulating a variational regularization problem which promotes local (in the spatial sense) low-rank and sparse regression coefficients. The local regions, where the spectral vectors are low-rank, are estimated by segmenting the HR-MSI. The formulated convex optimization is solved with SALSA. Experiments provide evidence that LRSR is competitive with respect to the state-of-the-art methods.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8519213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519213","Hyperspectral image super-resolution;low rank;superpixels","Spatial resolution;Dictionaries;Hyperspectral imaging;Signal resolution","geophysical image processing;geophysical techniques;hyperspectral imaging;image fusion;image reconstruction;image representation;image resolution;remote sensing","state-of-the-art methods;SALSA;convex optimization;remotely sensed hyperspectral images;spectral vectors;local regions;spatial sense;variational regularization problem;respective regression coefficients;spectral dictionary;fusion problem;novel HSI super-resolution approach;high spatial resolution multispectral image;LR-HSI;low spatial resolution HSI;fusion inverse problem;high spectral resolution;HSIs;sparse representations;local low-rank;hyperspectral image super-resolution","","8","","15","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"A Group-Based Embedding Learning and Integration Network for Hyperspectral Image Super-Resolution","X. Wang; Q. Hu; J. Jiang; J. Ma","Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Electronic Information School, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","8 Nov 2022","2022","60","","1","16","Although natural image super-resolution methods have achieved impressive performance, single hyperspectral image super-resolution still remains a challenge due to the high dimensionality. In recent years, many single hyperspectral image super-resolution methods adopted the group-convolution strategy to design the network for reducing the computational burden. However, these methods still process all spectral bands at once during the deep feature extraction and reconstruction, which increases the difficulty of fully exploring the inherent data characteristic of hyperspectral images. Moreover, the advanced group-based methods make insufficient exploitation of complementary information contained in different bands, resulting in limited reconstruction performance. In this article, we propose a novel group-based single hyperspectral image super-resolution method termed group-based embedding learning and integration network (GELIN) to reconstruct high-resolution images in a group-by-group manner, which alleviates the difficulty of feature extraction and reconstruction for hyperspectral images. Specifically, a spatial–spectral embedding learning module is designed to extract rewarding spatial details and explore the correlations among spectra simultaneously. Considering the high similarity among different bands, a neighboring group integration module is proposed to fully exploit the complementary information contained in neighboring image groups to recover missing details in the target image group. Experimental results on both natural and remote sensing hyperspectral datasets demonstrate that the proposed method is superior to other state-of-the-art methods both visually and metrically.","1558-0644","","10.1109/TGRS.2022.3217406","National Natural Science Foundation of China(grant numbers:62276192); Key Research and Development Program of Hubei Province(grant numbers:2020BAB113); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9930808","Group convolution;hyperspectral image;neighboring groups;super-resolution","Hyperspectral imaging;Superresolution;Image reconstruction;Feature extraction;Spatial resolution;Convolution;Correlation","feature extraction;geophysical image processing;geophysical signal processing;hyperspectral imaging;image classification;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","group-based embedding learning;integration network;natural image super-resolution methods;single hyperspectral image super-resolution methods;group-convolution strategy;deep feature extraction;hyperspectral images;advanced group-based methods;reconstruction performance;novel group-based single hyperspectral image super-resolution method;high-resolution images;group-by-group manner;spatial-spectral embedding learning module;neighboring group integration module;neighboring image groups;target image group;natural sensing hyperspectral datasets;remote sensing hyperspectral datasets","","1","","50","IEEE","26 Oct 2022","","","IEEE","IEEE Journals"
"Fused Recurrent Network Via Channel Attention For Remote Sensing Satellite Image Super-Resolution","X. Li; D. Zhang; Z. Liang; D. Ouyang; J. Shao","University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China","2020 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2020","2020","","","1","6","Remote sensing satellite images often suffer from low spatial resolution. Image super-resolution plays an important role in remote sensing image processing. However, existing methods show that increasing network depth will inevitably lead to the dramatic increase of model parameters and the over-fitting problem. Besides, most methods treat different types of information (low-frequency and high-frequency) equally. Motivated by these observations, we propose a fused recurrent network via channel attention (CA-FRN) in this paper. The basic module, recursive channel attention block (RCAB), pays enough attention to the high-frequency information and diminishes the low-frequency information adaptively through channel attention. Based on RCAB, we render our model effective by retaining and fusing hierarchical local information of both low-resolution and high-resolution, and we enhance the network performance simply by increasing the number of RCABs without adding extra parameters. We evaluate the proposed model on satellite images from different datasets, and the proposed CA-FRN is superior to the state-of-the-art methods. Code is available at https://github.com/lxy0922/CAFRN.","1945-788X","978-1-7281-1331-9","10.1109/ICME46284.2020.9102948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102948","Satellite image super-resolution;fused recurrent network;channel attention","Satellites;Remote sensing;Spatial resolution;Recurrent neural networks;Feature extraction;Image reconstruction","artificial satellites;geophysical image processing;image fusion;image resolution;recurrent neural nets;remote sensing","remote sensing satellite image super-resolution;low spatial resolution;remote sensing image processing;fused recurrent network;recursive channel attention block;RCAB;high-frequency information;low-frequency information;hierarchical local information;CA-FRN","","1","","23","IEEE","9 Jun 2020","","","IEEE","IEEE Conferences"
"Spatiotemporal Super-Resolution Mapping by Considering the Point Spread Function Effect","P. Wang; X. Shen; G. Zhang","Hubei Key Laboratory of Regional Development and Environment Response, Hubei University, Wuhan, China; Key Laboratory of Radar Imaging and Microwave Photonics, Ministry of Education, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Key Laboratory of Radar Imaging and Microwave Photonics, Ministry of Education, Nanjing University of Aeronautics and Astronautics, Nanjing, China","IEEE Geoscience and Remote Sensing Letters","24 Dec 2021","2022","19","","1","5","With the help of the auxiliary information provided by the appropriate prior fine spectral image (PFSI) in the same region, spatiotemporal super-resolution mapping (SSM) shows greater potential and better performance than the traditional super-resolution mapping (SM) models based on only monotemporal image. However, the temporal dependence of the existing SSM models usually describes the relationship between the coarse fractional images from original coarse spectral image (OCSI) and the fine fractional images from the PFSI, and the scale of temporal dependence information is not accurate and rich due to the different scales and properties of two fractional images. In addition, the existing SSM models usually do not consider point spread function (PSF) effect, resulting in affecting the accuracy of mapping result. To resolve the abovementioned issues, this letter proposes a general SSM model based on fine and coarse scales temporal dependence (FCSTD) by considering PSF effect. The experimental results demonstrate that the proposed model produces better mapping results than the traditional SM models, as well as the SSM models.","1558-0571","","10.1109/LGRS.2021.3050620","National Natural Science Foundation of China(grant numbers:61801211,61871218); Open Research Project of the Hubei Key Laboratory of Intelligent Geo-Information Processing(grant numbers:KLIGIP-2019A05); Key Laboratory of Intelligent Optimization and Information Processing, Minnan Normal University(grant numbers:ZNYH202006); Open Project Program of Hubei Key Laboratory of Regional Development and Environment Response Fundamental(grant numbers:2020(B)004); Open Project Program of State Key Laboratory of Geo-Information Engineering(grant numbers:SKLGIE2019-M-3-4); Fundamental Research Funds for the Central Universities(grant numbers:NZ2020009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328812","Point spread function (PSF);spatiotemporal super-resolution mapping (SSM);spectral image;super-resolution mapping (SM);temporal dependence","Superresolution;Spatiotemporal phenomena;Laboratories;Remote sensing;Mathematical model;Spatial resolution;Radar imaging","","","","2","","20","IEEE","20 Jan 2021","","","IEEE","IEEE Journals"
"Sparsity-based approaches for multispectral super-resolution of tropical cyclone imagery","I. Yanovsky; B. Lambrigtsen","Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA","2016 14th Specialist Meeting on Microwave Radiometry and Remote Sensing of the Environment (MicroRad)","4 Aug 2016","2016","","","139","144","An aperture synthesis system produces ringing at sharp edges and other transitions in the observed field. In this paper, we have developed an efficient multispectral deconvolution method, based on Split Bregman total variation minimization technique, and showed it to reduce image ringing, blurring, and distortion, while sharpening the image and preserving information content. We also present a multispectral multiframe super-resolution method that is robust to image noise and noise in the point spread function and leads to additional improvements in spatial resolution. The methodologies are based on current research in sparse optimization and compressed sensing, which lead to unprecedented efficiencies for solving image reconstruction problems.","","978-1-5090-2951-8","10.1109/MICRORAD.2016.7530522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530522","Aperture synthesis system;inverse problems;microwave imaging;multispectral image analysis;remote sensing;spatial resolution;super-resolution","Image reconstruction;Image resolution;Deconvolution;Signal to noise ratio;Signal resolution;Apertures;Minimization","compressed sensing;geophysical image processing;image reconstruction;optimisation;remote sensing;storms","tropical cyclone imagery multispectral superresolution;aperture synthesis system;multispectral deconvolution method;Split Bregman total variation minimization technique;image ringing;image blurring;image distortion;sparse optimization;compressed sensing;image reconstruction problem","","","","18","IEEE","4 Aug 2016","","","IEEE","IEEE Conferences"
"Attention-based Residual Network for Single Image Remote Sensing Super-resolution","T. Barman; B. Deka","Dept. of Electronics and Communication Engineering, Tezpur University, Tezpur, India; Dept. of Electronics and Communication Engineering, Tezpur University, Tezpur, India","2022 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS)","9 Feb 2023","2022","","","569","574","Single image super-resolution (SISR) reconstruction is crucial in meeting the growing demand for remote sensing imaging applications that need high spatial resolution. With the advancement of deep convolutional neural networks (CNNs), remote sensing SR has received considerable attention and has shown promising performance in the recent years. An effective feature extraction approach of CNN-based SR methods determines the quality of reconstructed images as well as increase the representation ability of CNN by more accurately extracting feature abstraction. In order to enhance the representational ability of CNN, a deep residual spatial and channel squeeze-and-excitation (RSCSE) SR network is proposed for remote sensing images (RSIs) to extract the deeper features in terms of channel-wise and spatially. Furthermore, a local feature fusion approach is incorporated in RSCSE module to preserve local features adaptively. Experiments conducted on two remote sensing datasets demonstrate that the proposed RSCSE network performs better than state-of-the-art methods both visually and quantitatively.","","978-1-6654-6200-6","10.1109/ICCCIS56430.2022.10037720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10037720","Remote sensing image;single image super-resolution;CNN;attention mechanism","Visualization;Superresolution;Imaging;Feature extraction;Convolutional neural networks;Spatial resolution;Intelligent systems","","","","","","18","IEEE","9 Feb 2023","","","IEEE","IEEE Conferences"
"Single Hyperspectral Image Super-Resolution Using Admm-Adam Theory","T. -H. Lin; C. -H. Lin","Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; School of Computing, National Cheng Kung University, Tainan, Taiwan","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1756","1759","In the remote sensing field, the spatial resolution of hyperspectral images (HSIs) is poor compared to RGB and multispectral images. Hence, hyperspectral image super-resolution (HISR) has become a popular topic recently. A branch of HISR methods is based on image fusion, but these methods rely on high-spatial-resolution counterpart image (e.g., multispectral image of the same scene) that is, however, not always available. Therefore, developing single hyperspectral image super-resolution (SHISR) method is highly desired. Due to the lack of abundant high-quality HSIs (i.e., big data) in satellite remote sensing, deep learning itself would be insufficient to well solve SHISR. We solve SHISR based on the recently invented ADMM-Adam learning theory, which blends the advantages from deep learning and convex optimization, thereby allowing software engineers to solve various challenging inverse problems without big data and sophisticated regularizer. For the first time, ADMM-Adam is adopted to solve SHISR in this paper, and experimental evidences well support its superiority even just with small data.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883334","Ministry of Science and Technology(grant numbers:MOST 110-2636-E-006-026); MOE; National Cheng Kung University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883334","Hyperspectral image;single image superresolution;convex optimization;deep learning;alternating direction method of multipliers (ADMM);adaptive moment estimation (ADAM)","Deep learning;Satellites;Inverse problems;Superresolution;Big Data;Feature extraction;Convex functions","geophysical image processing;hyperspectral imaging;image fusion;image resolution;inverse problems;learning (artificial intelligence);remote sensing","high-quality HSIs;big data;satellite remote sensing;SHISR;recently invented ADMM-Adam learning theory;deep learning;convex optimization;admm-Adam theory;remote sensing field;spatial resolution;hyperspectral images;multispectral image;HISR methods;image fusion;high-spatial-resolution counterpart image;single hyperspectral image super-resolution method","","","","20","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"From Planetscope To Worldview: Micro-Satellite Image Super-Resolution With Optimal Transport Distance","C. Shin; S. Kim; Y. Kim","Agency for Defense Development (ADD), Daejeon, South Korea; Agency for Defense Development (ADD), Daejeon, South Korea; Agency for Defense Development (ADD), Daejeon, South Korea","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","898","902","The vast majority of prior work on satellite image super-resolution (SR) assumes the availability of paired training data, and then uses low-resolution (LR) images artificially generated by simple blurring and/or down-sampling. These methods often fail to produce convincing results in real-world data since the actual degradation is much more complex than manually designed. This paper presents a deep learning framework to model the degradation process of microsatellite image. To this end, we first introduce remote sensing dataset consisting of WorldView (0.4m) and PlanetScope (3m) satellite images. They are aligned to the same coordinate, but are collected at different days/times. Using such data, we design Degradation Network (DegNet), generating realistic micro-satellite images from its high-resolution (HR) counterpart. A degradation loss using an optimal transport distance is proposed which makes the empirical distribution, i.e., histogram of outputs to be similar to that of real microsatellite images. It faithfully reflects the degradation characteristic of micro-satellite while preserving the content of an input. Finally, a SR network is trained with the generated LR-HR pairs. Extensive experiments show that the proposed method greatly improves the SR performance on real-world data.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190810","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190810","Micro-satellite image;generative models;satellite image super-resolution;optimal transport distance;degradation learning","Degradation;Remote sensing;Satellites;Histograms;Image resolution;Training;Generators","deep learning (artificial intelligence);geophysical image processing;image reconstruction;image resolution;remote sensing","low-resolution images;deep learning framework;high-resolution counterpart;optimal transport distance;degradation characteristic;LR-HR pairs;microsatellite image super-resolution;planetscope satellite images;design degradation network;SR network","","1","","27","IEEE","30 Sep 2020","","","IEEE","IEEE Conferences"
"A No-Reference Super Resolution for Satellite Image Quality Enhancement for KOMPSAT-3","Y. Choi; Y. Kim","Korea Aerospace Research Institute, Daejeon, Republic of Korea; Sangmyung University, Cheonan, Republic of Korea","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","220","223","Recently, a deep learning based super-resolution (SR) technology has been applied to satellite images to improve spatial resolution and sharpness, and to increase extractable information. In this paper, we propose a no-reference single image super-resolution method that improves the image quality by doubling spatial resolution of Korea Multi-Purpose Satellite-3 (K3), achieving a ground sampling distance (GSD) of 0.7 m. When training SR networks, the proposed method generates low-resolution (LR) images by applying the degradation model to K3 images and creates enhanced high-resolution images (HRe) by applying the top and bottom hat transformation to the original high-resolution (HRo) images. As a result of applying SR to the original K3 image, it was possible to obtain an image with improved quality. Additionally, as a result of testing the Baotou area used for satellite image quality evaluation, it was confirmed that the resolution is similar to the spatial resolution of Korea Multi-Purpose Satellite-3A (K3A), which is a GSD of 0.55 m.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324422","super-resolution;KOMPSAT-3;satellite;top and bottom hat;deep learning","Training;Degradation;Superresolution;Satellites;Spatial resolution;Remote sensing;Image edge detection","artificial satellites;deep learning (artificial intelligence);image enhancement;image resolution","satellite image quality enhancement;KOMPSAT-3;satellite images;spatial resolution;no-reference single image super-resolution method;SR networks;low-resolution images;satellite image quality evaluation;Korea multipurpose satellite-3A;K3 image;GSD;enhanced high-resolution images;HRe;original high-resolution images;HRo;LR;ground sampling distance","","1","","12","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"SAR Image Super-Resolution Reconstruction Based on an Optimize Iterative Method for Regularization","Q. Zhan; Y. Chen; Y. Chen; Y. Lu; C. Xu","School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; China Centre for Resources Satellite Data and Application, Beijing, China; China Centre for Resources Satellite Data and Application, Beijing, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5075","5078","SAR image enhancement plays an important role in the process of SAR image processing and information interpretation. Super-resolution reconstruction is a widely adopted enhancement method. However, it is difficult to achieve a decent tradeoff between reconstruction effectiveness and the convergence speed for existing methods. To combat such problem, this paper proposed a novel solution to it, we started from the modeling of SAR image degradation principle, applying the adaptive line search strategy to the SAR image super-resolution reconstruction process, and redefined the step size selection in the reconstruction process, made it possible to achieve both reconstruction effectiveness and convergence speed. Compared with the existing empirical setting or iterative selection, the proposed method can reduce the number of iterations while guarantee the reconstruction results.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554072","Sichuan Science and Technology Plan Project(grant numbers:2019YJ0201); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554072","SAR image enhancement;super-resolution reconstruction;SAR image degradation;adaptive line search;Terra-SAR;Cosmo","Measurement;Visualization;Superresolution;Geoscience and remote sensing;Search problems;Radar polarimetry;Iterative methods","image enhancement;image reconstruction;image resolution;iterative methods;radar imaging;radar resolution;search problems;synthetic aperture radar","SAR image enhancement;information interpretation;reconstruction effectiveness;convergence speed;SAR image degradation principle;SAR image super-resolution reconstruction process;empirical setting;optimize iterative method;adaptive line search strategy;step size selection;iterative selection","","1","","7","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Study Of Super-resolution Methods Based On Fitted Dual Quadratic Polynomials","H. Liu; M. Liu; T. Zhang; W. Deng; X. Liu; J. Liu","School of Electrical and Information Engineering Wuhan Institute of Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Electrical and Information Engineering Wuhan Institute of Technology, Wuhan, China; School of Electrical and Information Engineering Wuhan Institute of Technology, Wuhan, China; School of Electrical and Information Engineering Wuhan Institute of Technology, Wuhan, China","2022 International Conference on Artificial Intelligence and Computer Information Technology (AICIT)","1 Nov 2022","2022","","","1","4","As an important index to measure infrared images, spatial resolution plays a key role in infrared remote sensing imaging, navigation guidance of aircraft and recognition of military targets. However, the pixel density of infrared imaging detectors is much lower than that of visible light detectors, resulting in low resolution of infrared images obtained. Infrared images also have shortcomings such as high noise, fuzzy interference and loss of high-frequency information, which affect the detection and recognition of targets. In this thesis, an infrared image super-resolution degradation model is established based on the degradation factors that occur in the infrared imaging process. The influence of noise and blur on improving the resolution of infrared images is analyzed, and in this way, a full-flow reconstruction model of infrared image super-resolution is established. On the basis of noise and blur removal,a super-resolution method based on fitted dual quadratic polynomials is proposed for the low resolution of infrared images. This method makes full use of the pixel information of the original image, and uses the fitted interpolation polynomial to expand the pixels of the low-resolution image to obtain a high-resolution image. On the basis of improving the resolution, the infrared image noise and blur are better suppressed, the detailed features are reflected and the subjective quality is improved.","","978-1-6654-5087-4","10.1109/AICIT55386.2022.9930297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9930297","infrared images;super-resolution;degenerate model;biquadratic polynomial","Degradation;Target recognition;Superresolution;Interference;Infrared imaging;Detectors;Military aircraft","image processing;image reconstruction;image resolution;infrared imaging;interpolation;remote sensing","super-resolution method;fitted dual quadratic polynomials;infrared images;infrared remote sensing imaging;infrared imaging detectors;infrared image super-resolution degradation model;infrared imaging process;low-resolution image;high-resolution image;infrared image noise","","","","16","IEEE","1 Nov 2022","","","IEEE","IEEE Conferences"
"Deep Learning Super Resolution of Sea Surface Temperature on South China Sea","J. J. D. Khoo; K. H. Lim; P. K. Pang","Department of Electrical and Computer Engineering, Curtin University Malaysia CDT 250, Miri, Malaysia; Department of Electrical and Computer Engineering, Curtin University Malaysia CDT 250, Miri, Malaysia; Department of Electrical and Computer Engineering, Curtin University Malaysia CDT 250, Miri, Malaysia","2022 International Conference on Green Energy, Computing and Sustainable Technology (GECOST)","12 Jan 2023","2022","","","176","180","Surface temperature is one of the key observations to analyse the greenhouse effect on the Earth. The surface of the ocean can be captured using satellite sensors and transmitted to a meteorological center for real-time analysis. The use of the deep learning paradigm in super resolution has its potential in geoscience applications to increase the data transmission latency and enhance low-quality observation from remote sensing data. In this paper, the deployment of Generative Adversarial Network (GAN) architecture is studied to apply resolution reconstruction using the South China Sea sea surface temperature data. In addition, the development of spectral normalization is added to the Enhanced Super Resolution Generative Adversarial Network (ESRGAN) architecture to improve the training mechanism of generator and discriminator. This improved ESRGAN is compared with its super resolution performance against peak signal-to-noise ratio and structural similarity index evaluation metrics. The experiment shows that the low resolution of South China Sea data can be inferred to obtain a higher resolution with a more realistic resolution as compared to the conventional upsampling approaches.","","978-1-6654-8663-7","10.1109/GECOST55694.2022.10010371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10010371","Sea Surface Temperature;Deep Learning;Super Resolution;Generative Adversarial Networks","Temperature sensors;Deep learning;Sea surface;Temperature distribution;Surface reconstruction;Computer architecture;Generative adversarial networks","image enhancement;image reconstruction;image resolution;learning (artificial intelligence);ocean temperature;oceanographic regions;oceanographic techniques;remote sensing","data transmission;deep learning paradigm;Enhanced Super Resolution Generative Adversarial Network architecture;greenhouse effect;key observations;low-quality observation;realistic resolution;remote sensing data;resolution reconstruction;South China Sea data;South China Sea sea surface temperature data;super resolution performance","","","","23","IEEE","12 Jan 2023","","","IEEE","IEEE Conferences"
"Spatio-Temporal Super-Resolution Reconstruction of Remote Sensing Data","I. Yanovsky; J. Qin","Joint Institute for Regional Earth System Science and Engineering, University of California, Los Angeles, CA, USA; Department of Mathematics, University of Kentucky, Lexington, KY, USA","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2907","2910","We present a spatio-temporal super-resolution method for reconstructing a sequence of observations collected by imaging satellites. A sequence of observations is assumed to be defined on a low resolution spatio-temporal grid. It is further assumed that the sequence is generated by blurring of a captured scene with a spatio-temporal convolution kernel and is degraded by noise. Our method simultaneously exhibits deconvolution of the sequence of images from the effects of spatio-temporal blur, denoising of the data, and upsampling of the low-resolution sequence to a high resolution spatiotemporal grid. We perform the super-resolution in the spacetime domain, as opposed to super-resolving the sequence separately and sequentially to a higher spatial and then temporal resolution grid. Simultaneous space-time optimization achieves a more efficient and more accurate reconstruction than reconstructing a sequence frame by frame. The proposed super-resolution methodology is based on total variation regularization and computes the solution using the alternating direction method of multipliers. Numerical results show our approach to be robust and computationally efficient.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553433","NSF(grant numbers:DMS 2012868,DMS 1941197); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553433","Alternating direction method of multipliers;upsampling;satellite images;super-resolution","Satellites;Convolution;Superresolution;Noise reduction;Spatiotemporal phenomena;Spatial resolution;Kernel","","","","","","19","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Efficient Resolution Enhancement of JPEG2000 Compressed Multispectral Images Using Deep Super-resolution Methods","A. Can Karaca; İ. Uçurmak; M. Kemal Güllü","Dept. of Computer Engineering, Yıldız Technical University, İstanbul, Turkey; Dept. of Computer Engineering, Yıldız Technical University, İstanbul, Turkey; Dept. of Computer Engineering, Yıldız Technical University, İstanbul, Turkey","2021 International Conference on INnovations in Intelligent SysTems and Applications (INISTA)","30 Sep 2021","2021","","","1","6","Multispectral imaging is one of the most important Earth observation techniques in remote sensing. Although their advantages, multispectral imaging systems continuously capture images resulting in enormous data volumes. To this end, some of the multispectral satellites use JPEG2000 based compression methods. However, the images that are compressed at low bit-rates contain compression artifacts and may present low-performances in remote sensing applications such as target detection and classification. In this paper, we propose the usage of three single image super-resolution methods, SRResNet, EDSR, and WDSR, for the resolution enhancement of JPEG2000 compressed images. First, the multispectral image is subsampled at factor of 4 along both spatial axes, and then the resulting image is compressed with JPEG2000. Finally, super-resolution methods are performed to improve the resolution and reduce the compression artifacts. Experiments were carried out on the Onera dataset shared by IEEE GRSS. The results are compared in terms of quality metrics such as signal-to-noise ratios, mean spectral angle, maximum spectral angle, and maximum absolute difference. Experimental results demonstrate that the proposed approaches provide higher quality metrics and better visual performance compared to bicubic upsampling.","","978-1-6654-3603-8","10.1109/INISTA52262.2021.9548453","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9548453","image super-resolution;multispectral image compression;JPEG2000 compression","Measurement;Training;Visualization;Image coding;Multispectral imaging;Superresolution;Transform coding","data compression;geophysical image processing;geophysical signal processing;image coding;image reconstruction;image resolution;remote sensing","multispectral image;single image super-resolution methods;remote sensing applications;low-performances;compression artifacts;low bit-rates;JPEG2000 based compression methods;multispectral satellites;enormous data volumes;multispectral imaging systems;important Earth observation techniques;deep super-resolution methods;JPEG2000 compressed multispectral images;efficient resolution enhancement","","","","24","IEEE","30 Sep 2021","","","IEEE","IEEE Conferences"
"Semi-Simulated Training Data for Multi-Image Super-Resolution","T. Tarasiewicz; J. Nalepa; M. Kawulok","Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland; KP Labs, Gliwice, Poland; KP Labs, Gliwice, Poland","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","481","484","Multi-image super-resolution is a branch of super-resolution reconstruction techniques aiming to resolve a set of lowresolution images into a high-resolution one. Unlike singleimage super-resolution, its goal is to fuse information embedded in different images depicting the same scene, usually captured at different times. Such data combination contains more high-resolution information than a single image, thus allowing for more accurate reconstruction results. One of the most critical challenges is to prepare training data for multi-image super-resolution since only a few datasets are available here, especially for satellite imaging applications. For this reason, many studies are conducted using simulated low-resolution images, but the results obtained for real-life data are often unsatisfactory. To overcome this problem, we propose a new semi-simulated approach of creating lowresolution images for training that resemble real-life ones much more accurately. We also investigate the performance of selected deep learning models trained with simulated and semi-simulated datasets and we show that the latter achieve better results when applied to real-world images.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884565","National Science Centre, Poland(grant numbers:2019/3S/B/ST6/03006); European Union scholarship through the European Social Fund(grant numbers:POWR.03.05.00-00-Z305); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884565","Super-resolution reconstruction;satellite imaging;deep learning;multi-image super-resolution","Training;Deep learning;Satellites;Fuses;Superresolution;Training data;Imaging","Gaussian processes;image denoising;image reconstruction;image resolution;learning (artificial intelligence)","semisimulated training data;multiimage super-resolution;super-resolution reconstruction techniques;lowresolution images;singleimage super-resolution;high-resolution information;single image;satellite imaging applications;low-resolution images;real-world images","","","","10","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"A Framework of Mixed Sparse Representations for Remote Sensing Images","F. Li; L. Xin; Y. Guo; J. Gao; X. Jia","Qian Xuesen Laboratory of Space Technology, Beijing, China; Qian Xuesen Laboratory of Space Technology, Beijing, China; School of Computing, Engineering and Mathematics, Western Sydney University, Parramatta, NSW, Australia; Discipline of Business Analytics, The University of Business School, The University of Sydney, NSW, Australia; School of Engineering and Information Technology, University of New South Wales at Canberra, ACT, Australia","IEEE Transactions on Geoscience and Remote Sensing","29 Dec 2016","2017","55","2","1210","1221","In this paper, a new framework of mixed sparse representations (MSRs) is proposed for solving ill-conditioned problems with remote sensing images. In general, it is very difficult to find a common sparse representation for remote sensing images because of complicated ground features. Here we regard a remote sensing image as a combination of subimage of smooth, edges, and point-like components, respectively. Since each domain transformation method is capable of representing only a particular kind of ground object or texture, a group of domain transformations are used to sparsely represent each subimage. To demonstrate the effect of the framework of MSR for remote sensing images, MSR is regarded as a prior for maximum a posteriori when solving ill-conditioned problems such as classification and super resolution (SR), respectively. The experimental results show that not only the new framework of MSR can improve classification accuracy but also it can construct a much better high-resolution image than other common SR methods. The proposed framework MSR is a competitive candidate for solving other remote sensing images-related ill-conditioned problems.","1558-0644","","10.1109/TGRS.2016.2621123","National Natural Science Foundation of China(grant numbers:41371415); Australian Research Council(grant numbers:DP130100364); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745953","Classification;compressive sensing (CS);mixed sparse representations (MSRs);super-resolution (SR)","Remote sensing;Spatial resolution;Hidden Markov models;Lenses;Wavelet transforms","hyperspectral imaging;image classification;remote sensing","Super-Resolution method;high-resolution image;classification accuracy;ground texture;ground object;domain transformation method;point-like subimage;edge subimage;smooth subimage;remote sensing image;mixed sparse representation","","22","","63","OAPA","16 Nov 2016","","","IEEE","IEEE Journals"
"Spectral super-resolution based on matrix factorization and spectral dictionary","Y. Zhao; C. Yi; J. Yang; J. C. -W. Chan","School of Automation, Northwestem Polytechnical University, Xi'An, China; School of Automation, Northwestem Polytechnical University, Xi'An, China; School of Automation, Northwestem Polytechnical University, Xi'An, China; Department of Electronics and Informatics, Vrije Universiteit Brussel, Belgium","2016 8th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","19 Oct 2017","2016","","","1","6","Spectral information in hyperspectral imagery (HSI) directly acquired by sensors, commonly with surplus bands and redundant information, takes high memory and transmission costs, resulting in reduced spatial resolution and aggravated spectral mixture. Therefore, the desired high spectral resolution HSI can be obtained via spectral super-resolution after acquiring original HSI with lower spectral resolution but relatively higher spatial resolution. In this paper, we proposed a spectral super-resolution method based on spectral matrix factorization and dictionary learning. High and low spectral resolution HSIs are assumed to have the same spatial resolution and share the same spectral signatures. So abundances of low spectral resolution imagery can provide high spatial information, while its endmembers can supply accurate spectral characteristics. Then several high spectral resolution HSIs in 2-D forms are utilized to train a spectral dictionary which contains both high spatial resolution information and high spectral resolution information. Finally, the desired spectral enhancement results are achieved through the use of spatial fidelity constraint. Experiments on Sandigo dataset indicated the superiority of our proposed method.","2158-6276","978-1-5090-0608-3","10.1109/WHISPERS.2016.8071766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8071766","Hyperspectral imagery;spectral super-resolution;matrix factorization;dictionary learning","Spatial resolution;Dictionaries;Hyperspectral imaging;Image reconstruction;Machine learning","hyperspectral imaging;image enhancement;image resolution;matrix decomposition;remote sensing;spectral analysis","spectral mixture;spectral super-resolution method;spectral matrix factorization;spectral dictionary;spectral enhancement;high-spectral resolution HSI;low-spectral resolution imagery;hyperspectral imagery;dictionary learning","","","","13","IEEE","19 Oct 2017","","","IEEE","IEEE Conferences"
"Monte Carlo simulation for phase unwrapping using super-resolution for remote sensing using synthetic aperture radar interferometry","Y. Saika","Department of Information and Computer Engineering, Gunma College, Maebashi, Japan","2015 15th International Conference on Control, Automation and Systems (ICCAS)","28 Dec 2015","2015","","","651","656","We investigate the problem of phase unwrapping using multiple interferograms on the basis of Bayesian inference using the maximizer of the posterior marginal (MPM) estimate by making use of Monte Carlo simulation for several artificial wave-fronts in remote sensing via the synthetic aperture radar (SAR) interferometry. The simulations find that there is a phase where phase unwrapping is realized under the constraint of the surface-consistency in the hyper-parameter space, and that the upper phase boundary of the phase is steady along the parameter tuning fluctuations around the MAP solution. Also, we clarify that the MPM estimate succeeds in reconstruct the wave-front similar to the original one under the constraint of the surface-consistency condition, if the interferograms are corrupted by the Gaussian noises. Then, we find that the MPM estimate accurately reconstructs original wave-fronts using multiple interferograms, even if the interferograms are corrupted by Gaussian noises whose standard deviation is not so small.","2093-7121","978-8-9932-1508-3","10.1109/ICCAS.2015.7364999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7364999","Bayesian inference;Monte Carlo simulation;MPM estimate;Phase unwrapping;Phase diagram","Interferometry;Surface waves;Standards;Annealing","Bayes methods;Gaussian noise;Monte Carlo methods;radar interferometry;remote sensing by radar;synthetic aperture radar","Monte Carlo simulation;phase unwrapping;super-resolution;remote sensing;synthetic aperture radar interferometry;Bayesian inference;maximizer of the posterior marginal estimate;artificial wave-fronts;hyper-parameter space;upper phase boundary;parameter tuning fluctuations;MAP solution;MPM estimate;surface-consistency condition;Gaussian noise","","","","15","","28 Dec 2015","","","IEEE","IEEE Conferences"
"An Unsupervised Change Detection Technique Based on a Super-Resolution Convolutional Autoencoder","L. Bergamasco; L. Martinatti; F. Bovolo; L. Bruzzone","University of Trento, Trento, Italy; University of Trento, Trento, Italy; Fondazione Bruno Kessler, Trento, Italy; University of Trento, Trento, Italy","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3337","3340","Deep Learning (DL) methods are widely used for Change Detection (CD) in multi-temporal Remote Sensing (RS) images. The recently reported unsupervised DL CD methods alleviate the problem of the labeled data collection affecting the supervised ones. Many of them exploit the DL models (e.g., Convolutional Autoencoder (CAE)) as a feature extractor and use the retrieved features to detect the changes. However, these features do not efficiently preserve the geometrical details, and they do not optimize the selection of informative features for change detection. We propose an unsupervised DL CD method that exploits the features extracted by a CAE trained with a super-resolution based loss function. The loss function allows the CAE to be trained to reconstruct the spatial information thus generating features preserving the geometrical details. The proposed method exploits a feature selection based on the Structured Similarity Index (SSIM) to perform a texture analysis and chooses couples of bi-temporal features providing relevant information about changes. We tested the proposed method on a couple of bi-temporal Landsat-8 images representing a burned area near Granada, Spain.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553859","Unsupervised Change Detection;Convolutional Autoencoder;Deep Learning;Super resolution;Unsupervised learning;Multitemporal Analysis","Earth;Deep learning;Artificial satellites;Superresolution;Data collection;Feature extraction;Indexes","deep learning (artificial intelligence);feature extraction;geophysical image processing;geophysical signal processing;image classification;image resolution;image texture;remote sensing","unsupervised change detection technique;multitemporal Remote Sensing images;labeled data collection;supervised ones;CAE;feature extractor;retrieved features;geometrical details;informative features;spatial information;feature selection;bitemporal features;superresolution based loss function;superresolution convolutional autoencoder;bitemporal Landsat-8 images","","2","","7","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"An Adversarial Training Framework for Sentinel-2 Image Super-Resolution","M. Ciotola; A. Martinelli; A. Mazza; G. Scarpa","Dipartimento di Ingegneria Elettrica e delle Tecnologie dell'Informazione, Università Federico II, Napoli (I); Dipartimento di Ingegneria Elettrica e delle Tecnologie dell'Informazione, Università Federico II, Napoli (I); Dipartimento di Ingegneria Elettrica e delle Tecnologie dell'Informazione, Università Federico II, Napoli (I); Dipartimento di Ingegneria Elettrica e delle Tecnologie dell'Informazione, Università Federico II, Napoli (I)","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","3782","3785","In this work is presented a new adversarial training framework for deep learning neural networks for super-resolution of Sentinel 2 images, exploiting the data fusion techniques on 10 and 20 meters bands. The proposed scheme is fully convolutional and tries to answer the need for generalization in scale, producing realistic and detailed accurate images. Furthermore, the presence of a $\mathcal{L}_{1}$ loss limits the instability of GAN training, limiting possible problems of spectral dis-tortion. In our preliminary experiments, the GAN training scheme has shown comparable results in comparison with the baseline approach.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883144","Super-Resolution;Data-Fusion;Convo-lutional Neural Network;Deep Learning;Sentinel-2;Generative Adversarial Network","Training;Meters;Deep learning;Limiting;Superresolution;Neural networks;Geoscience and remote sensing","geophysical image processing;image classification;image resolution;learning (artificial intelligence);neural nets;sensor fusion","deep learning neural networks;Sentinel 2 images;data fusion techniques;10 meters bands;20 meters bands;realistic images;detailed accurate images;GAN training scheme;adversarial training framework;Sentinel-2 image super-resolution;size 10.0 inch;size 20.0 inch","","1","","23","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Hyperspectral Image Super-Resolution via Multi-Domain Feature Learning","Q. Li; Q. Wang; X. Li","School of Computer Science and School of Artificial Intelligence, Optics and Electronics (iOPEN), Northwestern Polytechnical University, Xi'an, P.R. China; School of Computer Science and School of Artificial Intelligence, Optics and Electronics (iOPEN), Northwestern Polytechnical University, Xi'an, P.R. China; School of Computer Science and School of Artificial Intelligence, Optics and Electronics (iOPEN), Northwestern Polytechnical University, Xi'an, P.R. China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","4135","4138","Hyperspectral image super-resolution (SR) methods are continually being refreshed due to deep neural networks. Despite this, the existing works barely explore more spatial information using mixed 2D/3D convolution. Moreover, they do not make full use of multi-domain features to realize information complementation. To tackle these challenges, we propose a hyperspectral image SR approach via multi-domain feature learning. To be specific, a multi-domain feature learning strategy using 2D/3D unit is presented to explore spatial and spectral information by alternate manner. To recover the more details, the edge body generation mechanism (EBGM) is introduced to learn the high frequency information, which generates the edge prior. Besides, the multi-domain feature fusion (MDFF) is designed to fully integrated hierarchical know ledge from different 2D/3D units, leading to further achieve information complementation. Experiments demonstrate that our approach attains the better performance over the state-of-the-art methods.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554560","National Natural Science Foundation of China(grant numbers:U1864204,61773316,U1801262,61871470); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554560","Hyperspectral image;super-resolution;multi-domain feature learning;edge body generation","Deep learning;Three-dimensional displays;Convolution;Image edge detection;Superresolution;Geoscience and remote sensing;Image restoration","convolution;geophysical image processing;hyperspectral imaging;image resolution;learning (artificial intelligence);neural nets","multidomain feature learning;hyperspectral image super-resolution methods;deep neural networks;spatial information;information complementation;hyperspectral image SR approach;spectral information;high frequency information;multidomain feature fusion","","","","8","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Enhanced 3D Convolution for Hyperspectral Image Super-Resolution","D. Liu; J. Li; Q. Yuan","School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2452","2455","Three-dimensional (3D) convolution is well-suited for volumetric data exploration, and therefore it has great potential in spatial-spectral feature learning to promote hyperspectral image super-resolution (HSI SR). However, 3D convolution is computationally expensive, and this is especially true when it operates on the high spectral dimensionality. In this paper, we design the enhanced 3D (E3D) convolution, an efficient form of spatial-spectral convolution. The standard 3D convolution is factorized into sequential spatial and spectral components. And the novel lightweight spatial and spectral squeeze-and-excitation modules are incorporated to corresponding components, respectively. As such, E3D convolution can largely reduce the computational complexity and extract effective spatial-spectral features with the holistic information. We further construct a fully 3D convolutional network (E3DN) with the proposed E3D convolution. The additional global residual learning and share-source skip connections can achieve spectral mapping and facilitate feature propagation. The simulated and real experiments demonstrate the accuracy and performance advantages of E3DN.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553962","3D convolution;Hyperspectral image;squeeze-and-excitation;super-resolution","Three-dimensional displays;Convolution;Superresolution;Geoscience and remote sensing;Feature extraction;Data mining;Computational complexity","convolution;feature extraction;geophysical image processing;hyperspectral imaging;image representation;image resolution;learning (artificial intelligence)","enhanced 3D convolution;hyperspectral image super-resolution;three-dimensional convolution;volumetric data exploration;spatial-spectral feature learning;high spectral dimensionality;E3D;spatial-spectral convolution;standard 3D convolution;sequential spatial components;spectral components;spatial-spectral features;fully 3D convolutional network;E3DN;spectral mapping","","","","13","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Context-Aware Element Filter for Hyperspectral Image Super-Resolution","R. Ran; L. -J. Deng; C. -Y. Zhao","School of Mathematical Sciences; School of Mathematical Sciences; Yingcai Honors College, University of Electronic Science and Technology of China, Chengdu, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2378","2381","Hyperspectral image super-resolution (HISR) aims to fuse a low-resolution image (LR-HSI) and a high-resolution multispectral image (HR-MSI), generating a high-resolution hyperspectral image (HR-HSI). Previous attempts to apply convolutional neural networks (CNNs) with spatial-variant adaptive filters for HISR tasks. Such filters overcome the spatial invariance and content-agnostic property of standard convolution. However, the current adaptive filters only consider pixellevel specificity, ignoring that each element of the features has unique close relationships with their neighbourhoods. To address the issue, we propose a context-aware element filter (CEF) operation, which generates adaptive filters for each element with sufficient perception of the specificity of each element to improve the representation capability. CEF can generate a single-channel filter to trade off the computational resource consumption for each element and is appropriate for HISR tasks with element-level dependencies. Specifically, we design a new network structure for HISR, which utilizes CEF to replace the standard convolution in the residual block. Extensive experiments demonstrate the superiority of the proposed CEF both visually and quantitatively compared with state-of-the-art (SOTA) methods.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884944","Hyperspectral Image Super-resolution;Context-aware Filter;Convolutional Neural Network","Convolution;Fuses;Superresolution;Neural networks;Adaptive filters;Geoscience and remote sensing;Task analysis","adaptive filters;hyperspectral imaging;image filtering;image fusion;image recognition;image resolution;learning (artificial intelligence);neural nets","hyperspectral image super-resolution;low-resolution image;high-resolution multispectral image;high-resolution hyperspectral image;convolutional neural networks;spatial-variant adaptive filters;HISR tasks;standard convolution;current adaptive filters;context-aware element filter operation;CEF;single-channel filter;element-level dependencies","","","","13","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Bidirectional 3D Quasi-Recurrent Neural Network for Hyperspectral Image Super-Resolution","Y. Fu; Z. Liang; S. You","School of Computer Science and Technology, Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology, Beijing, China; Computer Vision Research Group, Insititute of Informatics, University of Amsterdam, Amsterdam, The Netherlands","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","4 Mar 2021","2021","14","","2674","2688","Hyperspectral imaging is unable to acquire images with high resolution in both spatial and spectral dimensions yet, due to physical hardware limitations. It can only produce low spatial resolution images in most cases and thus hyperspectral image (HSI) spatial super-resolution is important. Recently, deep learning-based methods for HSI spatial super-resolution have been actively exploited. However, existing methods do not focus on structural spatial-spectral correlation and global correlation along spectra, which cannot fully exploit useful information for super-resolution. Also, some of the methods are straightforward extension of RGB super-resolution methods, which have fixed number of spectral channels and cannot be generally applied to hyperspectral images whose number of channels varies. Furthermore, unlike RGB images, existing HSI datasets are small and limit the performance of learning-based methods. In this article, we design a bidirectional 3D quasi-recurrent neural network for HSI super-resolution with arbitrary number of bands. Specifically, we introduce a core unit that contains a 3D convolutional module and a bidirectional quasi-recurrent pooling module to effectively extract structural spatial-spectral correlation and global correlation along spectra, respectively. By combining domain knowledge of HSI with a novel pretraining strategy, our method can be well generalized to remote sensing HSI datasets with limited number of training data. Extensive evaluations and comparisons on HSI super-resolution demonstrate improvements over state-of-the-art methods, in terms of both restoration accuracy and visual quality.","2151-1535","","10.1109/JSTARS.2021.3057936","National Natural Science Foundation of China(grant numbers:61827901,62088101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9351612","Bidirectional 3D quasi-recurrent neural network;global correlation along spectra;hyperspectral image super-resolution;structural spatial-spectral correlation","Superresolution;Three-dimensional displays;Correlation;Spatial resolution;Deep learning;Training;Convolution","deep learning (artificial intelligence);geophysical image processing;hyperspectral imaging;image resolution;image sensors;recurrent neural nets;remote sensing","RGB super-resolution methods;spectral channels;hyperspectral images;RGB images;quasirecurrent neural network;HSI super-resolution;3D convolutional module;quasirecurrent pooling module;spatial-spectral correlation;global correlation;remote sensing HSI datasets;bidirectional 3D quasirecurrent;hyperspectral imaging;spatial dimensions;spectral dimensions;physical hardware limitations;low spatial resolution images;hyperspectral image spatial super-resolution;deep learning;HSI spatial super-resolution","","25","","51","CCBYNCND","9 Feb 2021","","","IEEE","IEEE Journals"
"Super-Resolution Land Cover Mapping Based on Multiscale Spatial Regularization","J. Hu; Y. Ge; Y. Chen; D. Li","School of Computer and Information Technology, Shanxi University, Taiyuan, China; State Key Laboratory of Resource and Environmental Information System, Chinese Academy of Sciences, Institute of Geographical Sciences and Natural Resources Research, Beijing, China; State Key Laboratory of Resource and Environmental Information System, Chinese Academy of Sciences, Institute of Geographical Sciences and Natural Resources Research, Beijing, China; School of Computer and Information Technology, Shanxi University, Taiyuan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","19 May 2017","2015","8","5","2031","2039","Super-resolution mapping (SRM) is a method for allocating land cover classes at a fine scale according to coarse fraction images. Based on a spatial regularization framework, this paper proposes a new regularization method for SRM that integrates multiscale spatial information from the fine scale as a smooth term and from the coarse scale as a penalty term. The smooth term is considered a homogeneity constraint, and the penalty term is used to characterize the heterogeneity constraint. Specifically, the smooth term depends on the local fine scale spatial consistency, and is used to smooth edges and eliminate speckle points. The penalty term depends on the coarse scale local spatial differences, and suppresses the over-smoothing effect from the fine scale information while preserving more details (e.g., connectivity and aggregation of linear land cover patterns). We validated our method using simulated and synthetic images, and compared the results to four representative SRM algorithms. Our numerical experiments demonstrated that the proposed method can produce more accurate maps, reduce differences in the number of patches, visually preserve smoother edges and more details, reject speckle points, and suppress over-smoothing.","2151-1535","","10.1109/JSTARS.2015.2399509","National Natural Science Foundation of China(grant numbers:41471296); Key Technologies Research and Development Program of China(grant numbers:2012BAH33B01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7045474","Fraction images;heterogeneity;homogeneity;multiscale;regularization;remote sensing;spatial dependence;super-resolution mapping (SRM);Fraction images;heterogeneity;homogeneity;multiscale;regularization;remote sensing;spatial dependence;super-resolution mapping (SRM)","Spatial resolution;Linear programming;Manganese;Accuracy;Remote sensing;Indexes","geophysical image processing;image classification;image resolution;land cover;terrain mapping","super-resolution mapping;SRM land cover;multiscale spatial regularization;land cover class;fraction image;spatial regularization framework;regularization method;multiscale spatial information;smooth term;penalty term;local fine scale spatial consistency;smooth edge;speckle point elimination;over-smoothing effect;fine scale information;linear land cover pattern connectivity;linear land cover pattern aggregation;image simulation;synthetic image","","25","","30","IEEE","19 Feb 2015","","","IEEE","IEEE Journals"
"Spatio-Temporal Resolution Enhancement for Geostationary Microwave Data","I. Yanovsky; J. Qin; B. Lambrigtsen","Joint Institute for Regional Earth System Science and Engineering, University of California, Los Angeles, CA, USA; Department of Mathematics, University of Kentucky, Lexington, KY, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA","2020 16th Specialist Meeting on Microwave Radiometry and Remote Sensing for the Environment (MicroRad)","5 Feb 2021","2020","","","1","4","In this paper, we provide a formulation for enhancing the spatio-temporal resolution of a remote sensing sequence of images. Such an image sequence could be captured by a sensor that convolves a physical scene with a spatio-temporal point spread function whose two-dimensional spatial component is the microwave instrument's point spread function and whose one-dimensional temporal component is the rectangular kernel with sensor exposure time as its support. We perform resolution enhancement in the space-time domain, as opposed to solving the deconvolution problem for each observation. Simultaneous space-time optimization achieves a more efficient and more accurate reconstruction. The proposed deconvolution method employs total variation regularization and solves the formulation via the Split-Bregman optimization algorithm. In our experiments, we use a simulated microwave image sequence of a hurricane and demonstrate that the proposed methodology improves the accuracy when compared to the observed sequence.","","978-1-7281-7093-0","10.1109/MicroRad49612.2020.9342539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9342539","Geostationary satellite;microwave imaging;remote sensing;spatio-temporal resolution;super-resolution","Microwave theory and techniques;Image sequences;Microwave radiometry;Spatial resolution;Remote sensing;Optimization;Microwave imaging","deconvolution;geophysical image processing;image enhancement;image reconstruction;image resolution;image sensors;image sequences;microwave detectors;microwave imaging;microwave measurement;optical transfer function;optimisation;remote sensing","geostationary microwave data;two-dimensional spatial component;microwave instrument;one-dimensional temporal component;rectangular kernel;deconvolution problem;Split-Bregman optimization algorithm;simulated microwave image sequence;space-time optimization domain;spatiotemporal point spread function;spatiotemporal resolution enhancement;remote sensing sequence imaging","","1","","22","IEEE","5 Feb 2021","","","IEEE","IEEE Conferences"
"Super-Resolution Classification of Hyperspectral Images with a Small Training Set Using Semi-Supervised Learning","Y. Zhang; D. Zhang; T. Wang","Shaanxi Key Laboratory of Information Acquisition and Processing School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; Shaanxi Key Laboratory of Information Acquisition and Processing School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; Shaanxi Key Laboratory of Information Acquisition and Processing School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China","2018 9th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","27 Jun 2019","2018","","","1","5","Classification has been one of the most important applications of Hyperspectral images (HSIs) in the past decade, because of the outstanding discrimination among different classes ensured by abundant and detailed spectral information enclosed in HSIs. While the classification accuracy must be guaranteed by plenty of training samples, which is difficult to be satisfied in many practical cases. Meanwhile, because of its comparatively low spatial resolution, mixed pixels are widely existed in HSIs which makes subpixel level classification techniques more preferable rather than traditional pixel-level ones. A novel super-resolution classification method is proposed in this paper to deal with the two above mentioned problems in HSI classification, that is, limited number of training samples and widely existed mixed pixels. Specifically, semi-supervised learning is employed for appropriate augmentation of training set, with which the abundance fractions for each class within a mixed pixel are estimated using collaborative representation. And finally, the classification result with higher spatial resolution is obtained with subpixel spatial attraction model based subpixel mapping. Simulative experimental results illustrate its outperformance over some state-of-the-art subpixel level classification methods.","2158-6276","978-1-7281-1581-8","10.1109/WHISPERS.2018.8747242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8747242","Classification;hyperspectral;semi-supervised;subpixel;super-resolution","Training;Spatial resolution;Hyperspectral imaging;Semisupervised learning;Measurement","geophysical image processing;hyperspectral imaging;image classification;image resolution;learning (artificial intelligence);remote sensing","subpixel level classification techniques;HSI classification;semisupervised learning;classification result;subpixel spatial attraction model;subpixel mapping;state-of-the-art subpixel;classification methods;super-resolution classification method;hyperspectral images;spectral information","","1","","4","IEEE","27 Jun 2019","","","IEEE","IEEE Conferences"
"Hybrid Constraints of Pure and Mixed Pixels for Soft-Then-Hard Super-Resolution Mapping With Multiple Shifted Images","Y. Chen; Y. Ge; G. B. M. Heuvelink; J. Hu; Y. Jiang","State Key Laboratory of Resources and Environmental Information System, Institute of Geographical Sciences and Natural Resources Research, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Resources and Environmental Information System, Institute of Geographical Sciences and Natural Resources Research, University of Chinese Academy of Sciences, Beijing, China; Soil Geography and Landscape Group, Wageningen University, Wageningen, The Netherlands; School of Computer and Information Technology, Shanxi University, Taiyuan, China; State Key Laboratory of Resources and Environmental Information System, Institute of Geographical Sciences and Natural Resources Research, University of Chinese Academy of Sciences, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","19 May 2017","2015","8","5","2040","2052","Multiple shifted images (MSIs) have been widely applied to many super-resolution mapping (SRM) approaches to improve the accuracy of fine-scale land-cover maps. Most SRM methods with MSIs involve two processes: subpixel sharpening and class allocation. Complementary information from the MSIs has been successfully adopted to produce soft attribute values of subpixels during the subpixel sharpening process. Such information, however, is not used in the second process of class allocation. In this paper, a new class-allocation algorithm, named “hybrid constraints of pure and mixed pixels” (HCPMP), is proposed to allocate land-cover classes to subpixels using MSIs. HCPMP first determines the classes of subpixels that overlap with the pure pixels of auxiliary images in MSIs, after which the remaining subpixels are classified using information derived from the mixed pixels of the base image in MSIs. An artificial image and two remote sensing images were used to evaluate the performance of the proposed HCPMP algorithm. The experimental results demonstrate that HCPMP successfully applied MSIs to produce SRM maps that are visually closer to the reference images and that have greater accuracy than five existing class-allocation algorithms. Especially, it can produce more accurate SRM maps for high-resolution land-cover classes than low-resolution cases. The algorithm takes slightly less runtime than class allocation using linear optimization techniques. Hence, HCPMP provides a valuable new solution for class allocation in SRM using auxiliary data from MSIs.","2151-1535","","10.1109/JSTARS.2015.2417191","National Natural Science Foundation of China(grant numbers:41471296); Key Technologies Research and Development Program of China(grant numbers:2012BAH33B01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7086001","Hybrid constraints;multiple shifted images (MSIs);remotely sensed imagery;super-resolution mapping (SRM);Hybrid constraints;multiple shifted images (MSIs);remotely sensed imagery;super-resolution mapping (SRM)","Resource management;Accuracy;Remote sensing;Image resolution;Uncertainty;Earth;DH-HEMTs","geophysical image processing;geophysical techniques;image classification;image resolution;land cover;optimisation;remote sensing","soft-then-hard super-resolution mapping;multiple shifted images;hybrid constraints;mixed pixels;fine-scale land-cover maps;MSI;subpixel sharpening process;class-allocation algorithm;auxiliary images;information classification;artificial image;remote sensing images;HCPMP algorithm;SRM maps;high-resolution land-cover classes;low-resolution cases;linear optimization techniques;auxiliary data;reference images","","36","","62","IEEE","14 Apr 2015","","","IEEE","IEEE Journals"
"Sub-pixel mapping for hyperspectral imagery using super-resolution then spectral unmixing","L. Wang; P. Wang","College of Information and Communications Engineering, Harbin Engineering University, Harbin, China; College of Information and Communications Engineering, Harbin Engineering University, Harbin, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","461","464","In this paper, a sub-pixel mapping (SPM) method based on super-resolution then spectral unmixing (SRTSUSPM) is proposed. In the proposed framework, firstly projection onto convex set (POCS) model with the endmembers of interest is applied to original imagery to obtain a high-resolution imagery; then the fraction images are derived from the high-resolution imagery by linear spectral mixture analysis (LSMA); finally hard attribute values on a per sub-pixel basis is implemented to achieve SPM. Experiments show that the higher mapping accuracy can be derived from the proposed SPM method.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729114","Hyperspectral imagery;SPM;super-resolution;endmembers of interest","Spatial resolution;Image reconstruction;Interpolation;Filtering;Mathematical model;Roads","hyperspectral imaging;image processing;remote sensing","hyperspectral imagery;super resolution;spectral unmixing;subpixel mapping method;projection-onto-convex set;POCS model;fraction images;linear spectral mixture analysis","","3","","5","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Achieving Information Super-resolution for Sentinel-2 NDVI Through Gaussian Process Regression","C. Karmakar; A. Antunes; M. Datcu","German Aerospace Center, Oberpfaffenhofen; SmartRural SL; German Aerospace Center, Oberpfaffenhofen","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","338","341","Super-resolution is used to recover high resolution images from low resolution images. We use this concept in a slightly different context to achieve higher quality knowledge from low resolution satellite images. The technique involves transfer learning from high to low resolution images using a Gaussian Process Regression model. We use high resolution drone images to train the model. This technique is applied in three case studies to verify the consistency of results in case of NDVI computation. However, the same technique can be applied to obtain for other application of satellite images in plant vigor assessment.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883934","Information Super-resolution;Gaussian Process Regression;Sentinel-2 Images;Drone Images;Transfer Learning;NDVI","Training;Satellites;Computational modeling;Transfer learning;Superresolution;Vegetation mapping;Gaussian processes","Gaussian processes;geophysical image processing;geophysics computing;image classification;image resolution;learning (artificial intelligence);regression analysis;remote sensing;vegetation mapping","information super-resolution;sentinel-2 ndvi;high resolution images;low resolution images;slightly different context;low resolution satellite images;Gaussian Process Regression model;high resolution drone images","","","","5","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Super Resolution Approach for the Satellite Data Based on the Generative Adversarial Networks","M. Lavreniuk; N. Kussul; A. Shelestov; A. Lavrenyuk; L. Shumilo","Space Research Institute NASU-SSAU, Kyiv, Ukraine; National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, Kyiv, Ukraine; National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, Kyiv, Ukraine; National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, Kyiv, Ukraine; National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, Kyiv, Ukraine","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1095","1098","In the past few years, medium and high-resolution data became freely available for downloading. It provides great opportunity for researchers not to select between solving the task with high-resolution data on small territory or on global scale, but with low-resolution satellite images. Due to high spectral and spatial resolution of the data, Sentinel-1 and Sentinel-2 are very popular sources of information. Nevertheless, in practice if we would like to receive final product in 10 m resolution we should use bands with 10 m resolution. Sentinel-2 has four such bands, but also has other bands, especially red-edge 20 m resolution bands that are useful for vegetation analysis and often are omitted due to lower resolution. Thus, in this study we propose methodology for enhancing resolution (super-resolution) of the existing low-resolution images to higher resolution images. The main idea is to use advanced methods of deep learning - Generative Adversarial Networks (GAN) and train it to increase the resolution for the satellite images. Experimental results for the Sentinel-2 data showed that this approach is efficient and could be used for creating high resolution products.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884460","deep learning;Generative Adversarial Networks;GAN;super-resolution;Sentinel-2","Deep learning;Image resolution;Satellites;Superresolution;Vegetation mapping;Generative adversarial networks;Spatial resolution","geophysical image processing;image resolution;remote sensing;vegetation","high-resolution data;low-resolution satellite images;high spectral resolution;spatial resolution;Sentinel-1;enhancing resolution;existing low-resolution images;higher resolution images;Generative Adversarial Networks;Sentinel-2 data;high resolution products;super resolution approach;satellite data;size 10.0 m;size 20.0 m","","","","23","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Increasing Landsat 5 TM Spatial Resolution to 15 M Using a Super-Resolution Deep Learning Model Trained with Pan-Sharpened Landsat 7 ETM+ DATA","F. H. Wagner; P. Joyce; R. Brienen; E. Gloor","GeoProcessing Division, Foundation for Science, Technology and Space Applications-FUNCATE, São José dos Campos, SP, Brazil; School of Geography, University of Leeds, Leeds, UK; School of Geography, University of Leeds, Leeds, UK; School of Geography, University of Leeds, Leeds, UK","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3877","3880","In this work, we aim to recover the information at 15 m spatial resolution from Landsat 5 TM (L5 TM) data with 30 m spatial resolution using a super-resolution deep learning model. The model is designed to predict a pan-sharpened Landsat 7 ETM+ (L7 ETM+) image at 15 m resolution from a L5 TM image at 30 m spatial resolution. For the model training, we used images of L5 TM and L7 ETM+ from the same region and at a time interval of acquisition < 10 days. Our results show that the model achieves to improve the spatial resolution of the L5 TM even with a modest sample for training, constituted only of 4225 couples of L5 TM and L7 ETM+ images of size 128 ×128 pixels from the Landsat tile 216068. We also found that L5 TM emulated reflectance values at 15 m spatial resolution were more comparable to the values and ranges of L7 ETM+ reflectance than the original L5 TM reflectance. With an improved dataset for training, this model could be used to produce a dataset of images spatially and radiometrically harmonized of L5 TM and L7 ETM+ at 15 m spatial resolution.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553862","FAPESP(grant numbers:2015/50484-0); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553862","Landsat;super-resolution;image cross-calibration;convolutional neural network;harmonized dataset","Earth;Training;Reflectivity;Artificial satellites;Superresolution;Predictive models;Radiometry","deep learning (artificial intelligence);geophysical image processing;geophysical techniques;image resolution;remote sensing","Landsat 5 TM image;L7 ETM+ reflectance;Landsat 5 TM spatial resolution;super-resolution deep learning model;Landsat 5 TM data;pan-sharpened Landsat 7 ETM+ image;L5 TM reflectance","","","","13","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Deep Spatial-Spectral Information Exploitation for Rapid Hyperspectral Image Super-Resolution","J. Hu; Y. Li; M. Zhao; Y. Zhang","School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; Joint Laboratory of High Speed Multi-source Image Coding and Processing, Xidian University, Xi’an, China; School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; Joint Laboratory of High Speed Multi-source Image Coding and Processing, Xidian University, Xi’an, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3109","3112","Limited by existing electromagnetic sensors, the hyperspectral image (HSI) is characterized by having a high spectral resolution but a low spatial resolution. The super-resolution (SR) technique, which aims at enhancing the spatial resolution of the input image, is a hot topic in computer vision. This paper presents a rapid HSI SR method based on a deep information distillation network (IDN) and an intra-fusion operation to fully utilize the spatial-spectral information. Specifically, some bands are firstly selected and super-resolved by utilizing their spatial information through IDN. Non-selected bands are super-resolved by spectral interpolation. Moreover, to take a full advantage of the information these non-selected bands conveys, intra-fusion is operated on the input HSI and the spectrally-interpolated high resolution HSI. Contrary to most existed fusion methods which require multiple observations of the same scene, this intra-fusion is more flexible, and makes further utilization of the information the input HSI conveys simultaneously. In addition, this method requires less computation and is more suitable for practical applications. Experimental data and comparative analysis have demonstrated the effectiveness this method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899111","hyperspectral image;super-resolution;deep spatial-spectral exploitation;intra-fusion","Spatial resolution;Correlation;Matrices;Hyperspectral sensors;Image reconstruction","geophysical image processing;hyperspectral imaging;image fusion;image reconstruction;image resolution;interpolation;remote sensing","IDN;spectrally-interpolated high resolution HSI;fusion methods;electromagnetic sensors;high spectral resolution;low spatial resolution;computer vision;deep information distillation network;intra-fusion operation;hyperspectral image super-resolution;deep spatial-spectral information exploitation;HSI SR method;nonselected bands conveys","","","","12","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Hyperspectral image super-resolution via convolutional neural network","S. Mei; X. Yuan; J. Ji; S. Wan; J. Hou; Q. Du","School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; Department of Computer Science, City University of Hong Kong, Kowloon, Hong Kong; Department of Electrical and Computer Engineering, Mississippi State University, MS, USA","2017 IEEE International Conference on Image Processing (ICIP)","22 Feb 2018","2017","","","4297","4301","Due to the tradeoff between spatial and spectral resolution in remote sensing imaging, hyperspectral images are often acquired with a relative low spatial resolution, which limits their applications in many areas. Inspired by recent achievements in convolutional neural network (CNN) based super resolution (SR), a novel CNN based framework is constructed for SR of hyperspectral images by considering both spatial context and spectral correlation. As a result, the spectral distortion incurred by directly applying traditional SR algorithms to hyperspectral images is alleviated. Experimental results on several benchmark hyperspectral datasets have demonstrated that higher quality of reconstruction and spectral fidelity can be achieved, compared to band-wise manner based algorithms.","2381-8549","978-1-5090-2175-8","10.1109/ICIP.2017.8297093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8297093","Hyperspectral;super-resolution;convolutional neural network;deep learning","Hyperspectral imaging;Spatial resolution;Image restoration;Distortion;Image reconstruction","geophysical image processing;hyperspectral imaging;image classification;image resolution;neural nets;remote sensing","convolutional neural network;hyperspectral images;spatial context;spectral correlation;spectral distortion;spectral fidelity;hyperspectral image super-resolution;spectral resolution;remote sensing imaging;relative low spatial resolution;SR algorithms;hyperspectral datasets;CNN based framework;CNN based super resolution","","16","","13","IEEE","22 Feb 2018","","","IEEE","IEEE Conferences"
"Multi-source Information Fusion Network for Optical Remote Sensing Image Super-resolution","M. Shi; Y. Gao; L. Chen; X. Liu","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2023","PP","99","1","14","The super-resolution algorithms based on deep learning can effectively increase optical remote sensing image (ORSI) details for further analysis tasks. Deep unfolding methods have been studied in recent years to bridge the gap between optimization-based and learning-based methods, which can take good advantage of the prior knowledge. However, these unfolding methods usually ignore the utilization of intermediate network features between different iteration stages, thereby limiting the performance of super-resolution results. We propose a multi-source information fusion network (MSFNet) for ORSI super-resolution to address this problem. We mainly consider three strategies to enhance the image super-resolution performance, including feature extraction strategy, information fusion strategy, and the structure of the unfolding network. Firstly, image information of various scales is helpful for mining potential features of images for image super-resolution. Therefore, we introduce multi-scale implicit constraints to the objective function. Secondly, we unfold the optimization process into a neural network by alternating direction method of multipliers (ADMM). The network framework follows the ADMM method's iteration process. This unfolding strategy can effectively utilize the prior information for image reconstruction. Thirdly, we propose a row-column decoupling Transformer module based on this unfolding framework for feature fusion. Specifically, the row Transformer block completes the feature fusion of various scales, and the column Transformer block completes the feature fusion of various channels. The fused features are transmitted to the next iteration stage for feature enhancement. And this fusion strategy enables the network to focus on the global information of the features. We perform experiments on three remote sensing image datasets to fully demonstrate the algorithm's effectiveness. Experiment results show that the proposed algorithm can achieve better image reconstruction performance.","2151-1535","","10.1109/JSTARS.2023.3242039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10045643","Remote sensing;super-resolution;multi-source;deep unfolding;information fusion;Transformer","Transformers;Image reconstruction;Remote sensing;Kernel;Degradation;Task analysis;Superresolution","","","","","","","CCBYNCND","15 Feb 2023","","","IEEE","IEEE Early Access Articles"
"Learning Dynamic Scale Awareness and Global Implicit Functions for Continuous-Scale Super-Resolution of Remote Sensing Images","H. Wu; N. Ni; L. Zhang","School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","7 Feb 2023","2023","61","","1","15","The mainstream remote sensing image (RSI) super-resolution (SR) algorithms treat tasks with different scale factors independently, and a single model can only process a fixed integer scale factor. However, in practical applications, it is important to continuously super-resolve RSIs to multiple resolutions, as different resolutions present various levels of detail. Retraining the model for each scale factor consumes huge computational resources and storage space. Existing continuous-scale SR models employ static convolutions, and most are designed for natural scenes, ignoring dynamic feature extraction needs for different scale factors and the inherent properties of RSIs. In addition, efficiently obtaining the continuous representation of RSIs and avoiding the artifacts of RSI SR results is still a challenging problem. To address the above problems, we propose a scale-aware dynamic network (SADN) for RSI continuous-scale SR. First, we devise a scale-aware dynamic convolutional (SAD-Conv) layer to handle the strong randomness of the RSI textural distribution and achieve dynamic feature extraction according to scale factors. Second, we devise a continuous-scale upsampling module (CSUM) with the multi-bilinear global implicit function (MBGIF) for any-scale upsampling. The CSUM constructs multiple feature spaces with asymptotic resolutions to approximate the continuous representation of an image, and then, the MBGIF makes full use of multiresolution features to map arbitrary coordinates to spectral values. We evaluate our SADN using various benchmarks, and the experimental results show that the CSUM can efficiently achieve continuous-scale upsampling while maintaining excellent objective and visual performance. Moreover, our SADN uses fewer parameters and even outperforms the state-of-the-art fixed-scale SR methods. The source code is available at https://github.com/hanlinwu/SADN.","1558-0644","","10.1109/TGRS.2023.3240254","Beijing Natural Science Foundation(grant numbers:4222046); National Natural Science Foundation of China(grant numbers:62271060,61571050,41771407); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10026827","Continuous scale;dynamic convolution;implicit function;remote sensing image (RSI);scale aware;super-resolution (SR)","Image resolution;Feature extraction;Convolutional codes;Task analysis;Training;Superresolution;Remote sensing","","","","","","49","IEEE","27 Jan 2023","","","IEEE","IEEE Journals"
"A Two-Layers Super-Resolution Based Generation Adversarial Spatiotemporal Fusion Model","S. Fang; Q. Guo; Y. Cao; J. Zhang","Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Hefei University of Technology, Ministry of Education, Hefei, China; University of Science and Technology of China, Hefei, Anhui, China; Key Laboratory of Knowledge Engineering with Big Data, Hefei University of Technology, Ministry of Education, Hefei, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","891","894","Remote sensing image spatiotemporal fusion (STF) algorism plays an important role by supplementing the lack of original high-resolution remote sensing satellite images in the study scenarios of dense time-series data. In recent years, the deep-learning-based STF algorithm has become a research hotspot with comparatively higher accuracy and robustness. However, due to the lack of sufficient high-quality images for training and the huge resolution gap between low-resolution images and high-resolution images, it is difficult to recover detailed information, especially for areas of land-cover change. In this paper, we propose a two-layers super-resolution based generation adversarial spatiotemporal fusion model(TLSRSTF) using smaller inputs to reduce pressure on data requirements and a mutual affine convolution to reduce model parameters. Specifically, we only use a pair of high-resolution and low-resolution images and a high-resolution image at any time. A spatial degradation consistency is constructed to adaptively determine the ratio of two layers of the super-resolution STF model. The quantitative and qualitative experimental results on public spatiotemporal fusion datasets demonstrate our superiority over the state-of-the-art methods.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883547","National Natural Science Foundation of China(grant numbers:61872327,61175033); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883547","Spatiotemporal Fusion;Generative Adversarial Networks(GAN);Mutual Affine Convolution","Training;Adaptation models;Satellites;Convolution;Superresolution;Data models;Robustness","geophysical image processing;image fusion;image resolution;learning (artificial intelligence);remote sensing;spatiotemporal phenomena","sensing image spatiotemporal fusion algorism;high-resolution remote sensing satellite images;dense time-series data;STF algorithm;comparatively higher accuracy;robustness;high-quality images;huge resolution gap;low-resolution images;high-resolution image;super-resolution STF model;public spatiotemporal fusion datasets","","","","9","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"3DRRDB: Super Resolution of Multiple Remote Sensing Images using 3D Residual in Residual Dense Blocks","M. R. Ibrahim; R. Benavente; F. Lumbreras; D. Ponsa","Computer Vision Center, Campus UAB, Barcelona, Spain; Computer Vision Center, Campus UAB, Barcelona, Spain; Computer Vision Center, Campus UAB, Barcelona, Spain; Computer Vision Center, Campus UAB, Barcelona, Spain","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","23 Aug 2022","2022","","","322","331","The rapid advancement of Deep Convolutional Neural Networks helped in solving many remote sensing problems, especially the problems of super-resolution. However, most state-of-the-art methods focus more on Single Image Super-Resolution neglecting Multi-Image Super-Resolution. In this work, a new proposed 3D Residual in Residual Dense Blocks model (3DRRDB) focuses on remote sensing Multi-Image Super-Resolution for two different single spectral bands. The proposed 3DRRDB model explores the idea of 3D convolution layers in deeply connected Dense Blocks and the effect of local and global residual connections with residual scaling in Multi-Image Super-Resolution. The model tested on the Proba-V challenge dataset shows a significant improvement above the current state-of-the-art models scoring a Corrected Peak Signal to Noise Ratio (cPSNR) of 48.79 dB and 50.83 dB for Near Infrared (NIR) and RED Bands respectively. Moreover, the proposed 3DRRDB model scores a Corrected Structural Similarity Index Measure (cSSIM) of 0.9865 and 0.9909 for NIR and RED bands respectively","2160-7516","978-1-6654-8739-9","10.1109/CVPRW56347.2022.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857363","","Training;Solid modeling;Three-dimensional displays;PSNR;Convolution;Superresolution;Pattern recognition","edge detection;geophysical image processing;image fusion;image representation;image resolution;neural nets;remote sensing","3D convolution layers;global residual connections;3DRRDB model scores;multiple remote sensing images;deep convolutional neural networks;remote sensing problems;remote sensing multiimage super-resolution;residual dense blocks model;single image super-resolution;multiimage superresolution;corrected structural similarity index measure;NIR;Proba-V challenge;noise figure 50.83 dB;noise figure 48.79 dB;V","","","","41","IEEE","23 Aug 2022","","","IEEE","IEEE Conferences"
"Texture variable analysis for landscape patches represented using super-resolution mapping","A. M. Muad","Department of Electrical, Universiti Kebangsaan Malaysia, Selangor, Malaysia","2017 IEEE 8th Control and System Graduate Research Colloquium (ICSGRC)","19 Oct 2017","2017","","","51","56","This paper presents the analyses of texture variables from the image enhanced using super-resolution mapping. Two widely known super-resolution mapping techniques, pixel swapping and Hopfield neural network are used. The texture analyses include land cover patches of varying sizes, shapes, and spatial pattern of patches. A time series coarse MODIS 250 images are used to improve the representation of land cover patches and reduce the spatial variability. Results show that using a fusion of time series images and properly setting the weights for the Hopfield neural network produce superior accuracy of representing the texture of land cover mapping.","","978-1-5386-0380-2","10.1109/ICSGRC.2017.8070567","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8070567","Remote sensing;Hopfield neural network;pixel swapping;texture variable;landscape pattern","MODIS;Spatial resolution;Lakes;Remote sensing;Time series analysis;Earth;Satellites","geophysical image processing;Hopfield neural nets;image enhancement;image fusion;land cover;remote sensing;time series","texture variable analysis;landscape patches;super-resolution mapping techniques;Hopfield neural network;land cover patches;land cover mapping;image enhancement;pixel swapping;MODIS 250 images;time series image fusion","","","","33","IEEE","19 Oct 2017","","","IEEE","IEEE Conferences"
"Robust Extraction and Super-Resolution of Low-Resolution Flying Airplane From Satellite Video","D. -L. Chen; L. Zhang; H. Huang","School of Computer, Beijing Institute of Technology, Beijing, China; School of Computer, Beijing Institute of Technology, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","8 Dec 2021","2022","60","","1","16","Extracting the flying airplane from the satellite video and enhancing its resolution are significant and demanding tasks in the remote sensing community. The challenge mainly lies in that the flying airplane target in the satellite video often suffers from detail loss due to complex background and limited spaceborne imaging device. In this article, a novel constructive model is proposed to model the airplane of low resolution for more complete extraction, and a new reflective symmetry shape prior is integrated into the super-resolution process to obtain the higher resolution result. Concretely, each frame can be decomposed as a linear combination of foreground and background with specific mixture ratios. With the assumption of uniform linear motion and the rigidity of the airplane, a periodic change of mixture ratios through frames is induced, which can construct the airplane as complete as possible by adopting the proposed iterative matting optimization. To further enhance the resolution of the extracted airplane, an improved alternating direction method of multipliers (ADMM) is utilized to solve the super-resolution problem with the reflective symmetry of the shape as prior. The effectiveness of our method with respect to extraction and super-resolution is borne out by the experiments on both synthetic and real data.","1558-0644","","10.1109/TGRS.2021.3064064","National Natural Science Foundation of China(grant numbers:61922014,61772069); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9381528","Airplane;matting;multiframe;subpixel;super-resolution (SR);symmetry","Airplanes;Satellites;Image resolution;Atmospheric modeling;Shape;Image reconstruction;Superresolution","geophysical image processing;image resolution;image sensors;iterative methods;optimisation;remote sensing;video signal processing","robust extraction;low-resolution flying airplane;satellite video;remote sensing community;flying airplane target;complex background;limited spaceborne imaging device;constructive model;reflective symmetry shape;super-resolution process;foreground background;mixture ratios;uniform linear motion;super-resolution problem","","4","","49","IEEE","18 Mar 2021","","","IEEE","IEEE Journals"
"Multi-Scale Fast Fourier Transform based Attention Network for Remote Sensing Image Super-Resolution","Z. Wang; Y. Zhao; J. Chen","School of Computer Computational Science, Hangzhou City University, Hangzhou, China; Shcool of Engineering, Hangzhou City University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2023","PP","99","1","14","Recently, with the rise and progress of convolutional neural networks (CNNs), CNN-based remote sensing image super-resolution (RSSR) methods have gained considerable advancement and showed great power for image reconstruction tasks. However, most of these methods cannot handle well the enormous number of objects with different scales contained in remote sensing images and thus limits super-resolution performance. To address these issues, we propose a Multi-Scale Fast Fourier Transform (FFT) based Attention Network (MSFFTAN) which employs a multi-input U-shape structure as backbone for accurate remote sensing image super-resolution. Specifically, we carefully design an FFT-based residual block consisting of an image domain branch and a Fourier domain branch to extract local details and global structures simultaneously. In addition, a Local-Global Channel Attention Block (LGCAB) is developed to further enhance the reconstruction ability of small targets. Finally, we present a Branch Gated Selective Block (BGSB) to adaptively explore and aggregate features from multiple scales and depths. Extensive experiments on two publicly datasets have demonstrated the superiority of MSFFTAN over the state-of-the-art (SOAT) approaches in aspects of both quantitative metrics and visual quality. The peak signal-to-noise ratio of our network is 1.5 dB higher than the SOAT method on the UCMerced LandUse with downscaling factor 2.","2151-1535","","10.1109/JSTARS.2023.3246564","National Natural Science Foundation of China(grant numbers:51875524); Program of the State Key Lab of CAD&CG(grant numbers:A2210); Zhejiang University, and the Key Research and Development Program of Zhejiang Province(grant numbers:2023C01168); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10049097","Remote Sensing Image;Super-Resolution;Multi-input Mechanism;Attention Mechanism;Fast Fourier Transform","Feature extraction;Superresolution;Image reconstruction;Remote sensing;Task analysis;Data mining;Logic gates","","","","","","","CCBY","20 Feb 2023","","","IEEE","IEEE Early Access Articles"
"Deep-Learning-Based Super-Resolution of Video Satellite Imagery by the Coupling of Multiframe and Single-Frame Models","H. Shen; Z. Qiu; L. Yue; L. Zhang","Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China; School of Resource and Environmental Sciences, Wuhan University, Wuhan, China; School of Geography and Information Engineering, China University of Geosciences, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","8 Feb 2022","2022","60","","1","14","Image super-resolution (SR) is an effective solution to the limitation of the spatial resolution of video satellite images, which is caused by the degradation and compression in the imaging phase. For the processing of satellite videos, the commonly employed deep-learning-based single-frame SR (SFSR) framework has limited performance without using complementary information between the video frames. On the other side, the multiframe SR (MFSR) can utilize temporal subpixel information to super-resolve the high-resolution (HR) imagery. However, although deeper and wider deep learning network provides powerful feature representations for SR methods, it has always been a challenge to accurately reconstruct the boundaries of ground objects in video satellite images. In this article, to address these issues, we propose an edge-guided video SR (EGVSR) framework for video satellite image SR, which couples the MFSR model and the edge-SFSR (E-SFSR) model in a unified network. The EGVSR framework is composed of an MFSR branch and an edge branch. The MFSR branch is used to extract the complementary features from the consecutive video frames. Concurrently, the edge branch acts as an SFSR model to translate the edge maps from the low-resolution modality to the HR one. At the final SR stage, the DBFM is built to focus on the promising inner representations of the features of the two branches and fuse them. Extensive experiments on video satellite imagery show that the proposed EGVSR method can achieve superior performance compared to the representative deep-learning-based SR methods.","1558-0644","","10.1109/TGRS.2021.3121303","National Key Research and Development Program of China(grant numbers:2019YFB2102900); National Natural Science Foundation of China(grant numbers:41801263); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9579427","Deep learning;edge prior;super-resolution (SR);video satellite","Satellites;Image edge detection;Image reconstruction;Spatial resolution;Feature extraction;Remote sensing;Deep learning","deep learning (artificial intelligence);feature extraction;image reconstruction;image representation;image resolution;remote sensing;video signal processing","image super-resolution;single-frame SR framework;multiframe SR;temporal subpixel information;high-resolution imagery;deep learning network;edge-guided video SR framework;MFSR branch;edge branch;video frames;SFSR;low-resolution modality;video satellite imagery;EGVSR;boundaries reconstruction;satellite videos processing","","","","67","IEEE","18 Oct 2021","","","IEEE","IEEE Journals"
"GPU-Accelerated Adaptive Dictionary Learning and Sparse Representations for Multispectral Image Super-resolution","T. Barman; B. Deka; A. V. V. Prasad","Department of Electronics and Communication Engineering, Tezpur University, Tezpur, India; Department of Electronics and Communication Engineering, Tezpur University, Tezpur, India; Natational Remote Sensing Center (NRSC) ISRO Hyderabad, Telengana, India","2021 IEEE 18th India Council International Conference (INDICON)","1 Feb 2022","2021","","","1","7","Recently, single image super-resolution (SISR) based on sparse representations has been gaining much attention from the research community in the field of remote sensing. In this paper, a fast SISR reconstruction framework is developed for multispectral remote sensing (MSRS) images based on adaptive dictionary learning and sparse representations. It consists of two major parts: first, a novel super-resolution approach is developed for MSRS using sparse coding and adaptive dictionary learning. High-frequency features present in the input low-resolution MS image are extracted by using Butterworth low-pass, difference of Gaussian (DoG), and Sobel filters in horizontal and vertical directions. The proposed feature extraction method reveals the edges and other detailed information present in the MS image effectively. Secondly, massively parallel algorithms are designed for adaptive dictionary learning and sparse reconstruction using the Compute Unified Device Architecture (CUDA)-enabled General Purpose-Graphics Processing Unit (GP-GPU) programming model. The proposed method GP-GPU implementation not only gives better results in terms of visual quality and objective fidelity criteria, but also significantly reduces the computation time compared to its CPU counterparts to achieve near-real time operating speed.","2325-9418","978-1-6654-4175-9","10.1109/INDICON52576.2021.9691521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9691521","Super-resolution;Sparse representations;Adaptive dictionary learning;Multispectral remote sensing;CUDA-enabled GP-GPU","Visualization;Image edge detection;Superresolution;Machine learning;Programming;Feature extraction;Real-time systems","coprocessors;feature extraction;geophysical image processing;graphics processing units;image fusion;image reconstruction;image resolution;parallel algorithms;remote sensing","GPU-accelerated adaptive dictionary learning;sparse representations;multispectral image super-resolution;single image super-resolution;fast SISR reconstruction framework;multispectral remote sensing images;MSRS;sparse coding;input low-resolution MS image;feature extraction;sparse reconstruction;General Purpose-Graphics Processing Unit;Compute Unified Device Architecture;objective fidelity criteria;GP-GPU","","2","","32","IEEE","1 Feb 2022","","","IEEE","IEEE Conferences"
"Forward-Looking Radar Super-Resolution Imaging Combined TSVD with L1 Norm Constraint","Z. Shu; Z. Zong; L. Huang; L. Huang","Research Institute of Electronic Science and Technology, University of Electronic Science and Technology of China; Research Institute of Electronic Science and Technology, University of Electronic Science and Technology of China; Research Institute of Electronic Science and Technology, University of Electronic Science and Technology of China; Research Institute of Electronic Science and Technology, University of Electronic Science and Technology of China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2559","2562","This paper is devoted to the research of methods and experiments of regularization deconvolution theory on the azimuth super-resolution of forward-looking imaging radar. L1 norm is usually used as a regular term to obtain a stable solution due to its strong resolving power for sparse targets. However, deconvolution is an ill-posed problem, in the process of deconvolution iteration, using the L1 norm as a regular term is sensitive to noise and may causes a large deviation between the solution and the true value due to the influence of noise. This paper proposes the super-resolution imaging method combined truncation singular value decomposition (TSVD) with L1 norm constraint. At lower SNR, this method effectively solves the problem of noise amplification during deconvolution iteration. The effectiveness and advancement of the proposed algorithm are verified by simulation results.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8897855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897855","Forward-looking imaging;azimuth super-resolution;TSVD;L1 norm.","Imaging;Radar imaging;Azimuth;Image resolution;Deconvolution;Matrix decomposition","deconvolution;image resolution;radar imaging;radar resolution;singular value decomposition","super-resolution imaging method;deconvolution iteration;L1 Norm Constraint;regularization deconvolution theory;azimuth super-resolution;imaging radar;forward-looking radar super-resolution imaging;TSVD;truncation singular value decomposition","","1","","7","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Deep Learning For Super-Resolution Of Unregistered Multi-Temporal Satellite Images","A. B. Molini; D. Valsesia; G. Fracastoro; E. Magli",Politecnico di Torino; Politecnico di Torino; Politecnico di Torino; Politecnico di Torino,"2019 10th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","5 Dec 2019","2019","","","1","5","Recently, convolutional neural networks (CNN) have been successfully applied to many remote sensing tasks. However, deep learning for multi-image superresolution from multitemporal imagery has received little attention so far. We propose a residual CNN that exploits both spatial and temporal correlations in the low-resolution image set by using 3D convolutional layers to combine multiple images from the same scene. The experiments have been carried out using a dataset of PROBA-V satellite ground images, composed of several low-resolution and high-resolution images taken at different times from instruments on the same platform, in the context of a challenge issued by the European Space Agency.","2158-6276","978-1-7281-5294-3","10.1109/WHISPERS.2019.8920910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920910","Multi-image superresolution;convolutional neural networks;multi-temporal images","Spatial resolution;Remote sensing;Machine learning;Image reconstruction;Brightness;Satellites","convolutional neural nets;geophysical image processing;image resolution;image sensors;learning (artificial intelligence);remote sensing","multiimage superresolution;multitemporal imagery;residual CNN;spatial correlations;temporal correlations;low-resolution image;3D convolutional layers;multiple images;PROBA-V satellite ground images;high-resolution images;unregistered multitemporal satellite images;convolutional neural networks;remote sensing tasks;deep learning","","1","","14","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"DeepSUM: Deep Neural Network for Super-Resolution of Unregistered Multitemporal Images","A. Bordone Molini; D. Valsesia; G. Fracastoro; E. Magli","Department of Electronics and Telecommunications, Politecnico di Torino, Turin, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Turin, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Turin, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Turin, Italy","IEEE Transactions on Geoscience and Remote Sensing","22 Apr 2020","2020","58","5","3644","3656","Recently, convolutional neural networks (CNNs) have been successfully applied to many remote sensing problems. However, deep learning techniques for multi-image super-resolution (SR) from multitemporal unregistered imagery have received little attention so far. This article proposes a novel CNN-based technique that exploits both spatial and temporal correlations to combine multiple images. This novel framework integrates the spatial registration task directly inside the CNN, and allows one to exploit the representation learning capabilities of the network to enhance registration accuracy. The entire SR process relies on a single CNN with three main stages: shared 2-D convolutions to extract high-dimensional features from the input images; a subnetwork proposing registration filters derived from the high-dimensional feature representations; 3-D convolutions for slow fusion of the features from multiple images. The whole network can be trained end-to-end to recover a single high-resolution image from multiple unregistered low-resolution images. The method presented in this article is the winner of the PROBA-V SR challenge issued by the European Space Agency (ESA).","1558-0644","","10.1109/TGRS.2019.2959248","Smart-Data@PoliTO Center for Big Data and Machine Learning Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946717","Convolutional neural networks (CNNs);dynamic filter networks;multi-image super resolution (MISR);multitemporal images","Remote sensing;Image reconstruction;Spatial resolution;Deep learning;Feature extraction;Image registration","convolutional neural nets;feature extraction;geophysical image processing;image filtering;image fusion;image registration;image representation;image resolution;learning (artificial intelligence);remote sensing","image fusion;high-dimensional feature representations;registration filters;high-dimensional feature extraction;SR process;registration accuracy;spatial registration task;temporal correlations;spatial correlations;CNN-based technique;multitemporal unregistered imagery;multiimage super-resolution;deep learning techniques;remote sensing problems;convolutional neural networks;unregistered multitemporal images;deep neural network;DeepSUM","","52","","69","IEEE","31 Dec 2019","","","IEEE","IEEE Journals"
"Permutation Invariance and Uncertainty in Multitemporal Image Super-Resolution","D. Valsesia; E. Magli","Department of Electronics and Telecommunications, Politecnico di Torino, Turin, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Turin, Italy","IEEE Transactions on Geoscience and Remote Sensing","17 Feb 2022","2022","60","","1","12","Recent advances have shown how deep neural networks can be extremely effective at super-resolving remote-sensing imagery, starting from a multitemporal collection of low-resolution (LR) images. However, existing models have neglected the issue of temporal permutation, whereby the temporal ordering of the input images does not carry any relevant information for the super-resolution (SR) task and causes such models to be inefficient with the, often scarce, ground-truth data that available for training. Thus, models ought not to learn feature extractors that rely on temporal ordering. In this article, we show how building a model that is fully invariant to temporal permutation significantly improves performance and data efficiency. Moreover, we study how to quantify the uncertainty of the super-resolved image so that the final user is informed on the local quality of the product. We show how uncertainty correlates with temporal variation in the series, and how quantifying it further improves model performance. Experiments on the Proba-V challenge dataset show significant improvements over the state of the art without the need for self-ensembling, as well as improved data efficiency, reaching the performance of the challenge winner with just 25% of the training data.","1558-0644","","10.1109/TGRS.2021.3130673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9627135","Convolutional neural networks (CNNs);multitemporal super-resolution (SR);self-attention;uncertainty estimation","Uncertainty;Data models;Superresolution;Training;Spatial resolution;Remote sensing;Estimation","deep learning (artificial intelligence);feature extraction;geophysical image processing;image resolution;remote sensing","improved data efficiency;training data;permutation invariance;multitemporal image super-resolution;deep neural networks;remote-sensing imagery;low-resolution images;temporal permutation;temporal ordering;scarce ground-truth data;feature extractors","","2","","42","IEEE","25 Nov 2021","","","IEEE","IEEE Journals"
"GJTD-LR: A Trainable Grouped Joint Tensor Dictionary With Low-Rank Prior for Single Hyperspectral Image Super-Resolution","C. Liu; Z. Fan; G. Zhang","School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China; School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China; Key Laboratory of Advanced Theory and Application in Statistics and Data Science-MOE, School of Computer Science and Technology, East China Normal University, Shanghai, China","IEEE Transactions on Geoscience and Remote Sensing","22 Sep 2022","2022","60","","1","17","Reconstructing a high-resolution hyperspectral image (HR-HSI) using a single low-resolution hyperspectral image (LR-HSI) is a significant technique for increasing the spatial resolution of HSIs and overcoming the physical limitation of the HSI sensor. Most single HSI super-resolution methods have achieved great success recently. However, owning to the difficulty of acquiring an HSI, the available training samples are relatively few, which will inevitably lead to relatively low performance. To address this issue, in this article, we propose a novel single HSI super-resolution method by combining a trainable grouped joint tensor dictionary and a low-rank prior (GJTD-LR). First, we design a trainable grouped joint tensor dictionary, which can build an accurate mapping relationship between training HR-HSIs and their corresponding LR-HSIs with relatively few training samples. To be specific, the training HR-HSI and LR-HSI pairs are decomposed into a joint tensor dictionary and a set of sparse coefficients using tensor–tensor product to fully preserve the spectral correlation. In addition, we apply a grouped strategy to divide the training images into several groups and learn a compact joint dictionary for each group. Second, a tensor low-rank model is forced into the reconstruction model to further capture the spatial correlation. Finally, GJTD-LR is optimized using alternating direction method of multipliers (ADMM), soft threshold algorithm, singular value decomposition, and Fourier domain transform. The experimental results on both remote sensed HSIs and indoor HSIs show the superiority of GJTD-LR to some other traditional and advanced single HSI super-resolution methods.","1558-0644","","10.1109/TGRS.2022.3204049","National Natural Science Foundation of China(grant numbers:61703278); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9875321","Group joint tensor dictionary;hyperspectral image (HSI) super-resolution;low-rank prior;tensor–tensor product","Superresolution;Training;Tensors;Dictionaries;Correlation;Spatial resolution;Image reconstruction","geophysical image processing;hyperspectral imaging;image reconstruction;image representation;image resolution;learning (artificial intelligence);remote sensing;singular value decomposition;tensors","available training samples;relatively low performance;novel single HSI super-resolution method;trainable grouped joint tensor dictionary;low-rank prior;GJTD-LR;training HR-HSI;corresponding LR-HSIs;relatively few training samples;LR-HSI pairs;tensor-tensor product;grouped strategy;training images;compact joint dictionary;tensor low-rank model;traditional HSI super-resolution methods;advanced single HSI super-resolution methods;single hyperspectral image super-resolution;high-resolution hyperspectral image;low-resolution hyperspectral image;HSI sensor","","","","56","IEEE","5 Sep 2022","","","IEEE","IEEE Journals"
"GIS guided remote sensing image data for rural industry and space interaction mechanism modeling","X. Chen; Y. Tao; L. Tong; R. Su","Art Design College, Zhejiang Gongshang University, Zhejiang, Hangzhou, China; Department of Architecture, Shenzhen University, Guangzhou, Shenzhen, China; School of Tourism and Urban-Rural Planning, Zhejiang Gongshang University, Zhejiang, Hangzhou, China; Art Design College, Zhejiang Gongshang University, Zhejiang, Hangzhou, China","2020 Fourth International Conference on Inventive Systems and Control (ICISC)","19 Aug 2020","2020","","","837","840","GIS guided remote sensing image data for rural industry and space interaction mechanism modeling is discussed in this manuscript. Aerospace remote sensing technology is a technology for obtaining the remote sensing image information data through the satellite ground observations, and these image data play an indispensable role in various fields. Hence, this paper proposes the following novel ideas. (1) In GIS management mode, spatial relation expression is clear at a glance, and the management and editing of the attribute fields are not restricted. (2) Super-resolution reconstruction can be regarded as the second-generation image restoration to a certain extent, we integrate the image processing technology to process the data. (3) The suggestions of the rural industry and space interaction mechanism modeling is provided.","","978-1-7281-2813-9","10.1109/ICISC47916.2020.9171164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171164","GIS System;Remote Sensing;Image Analysis;Rural Industry;space interaction","Industries;Satellites;Superresolution;Aerospace electronics;Control systems;Data models;Sensors","geographic information systems;geophysical image processing;image resolution;image restoration;remote sensing","image restoration;image processing technology;rural industry;space interaction mechanism modeling;aerospace remote sensing technology;remote sensing image information data;GIS management mode;spatial relation expression;super-resolution reconstruction;satellite ground observations","","","","17","IEEE","19 Aug 2020","","","IEEE","IEEE Conferences"
"Hyperspectral Image Super-resolution Using Generative Adversarial Network and Residual Learning","Q. Huang; W. Li; T. Hu; R. Tao","College of Information Science & Technology, Beijing University of Chemical Technology; College of Information Science & Technology, Beijing University of Chemical Technology; School of Information and Electronics, Beijing Institute Technology, Beijing, China; School of Information and Electronics, Beijing Institute Technology, Beijing, China","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3012","3016","Due to the limitation of image acquisition, hyperspectral remote sensing imagery is hard to reflect in both high spatial and spectral resolutions. Super-resolution (SR) is a technique which can improve the spatial resolution. Inspired by recent achievements in deep convolutional neural network (CNN) and generative adversarial network (GAN), a GAN based framework is proposed for hyperspectral image super-resolution. In the proposed method, residual learning is used to obtain a high metrics and spectral fidelity, and a shorter connection is set between the input layer and output layer. The gradient features from low-resolution (LR) image to high-resolution (HR) are utilized as auxiliary information to assist deep CNN to carry out counter training with discriminator. Experimental results demonstrate that the proposed SR algorithm achieves superior performance in spectral fidelity and spatial resolution compared with baseline methods.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683893","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683893","Hyperspectral Imagery;Super-Resolution;Generative Adversarial Network","","convolutional neural nets;geophysical image processing;hyperspectral imaging;image resolution;learning (artificial intelligence);remote sensing","spectral resolutions;generative adversarial network;hyperspectral image super-resolution;residual learning;spectral fidelity;low-resolution image;image acquisition;hyperspectral remote sensing imagery;high spatial resolutions;high-resolution image;GAN based framework","","9","","16","IEEE","17 Apr 2019","","","IEEE","IEEE Conferences"
"Single Image Super-resolution Reconstruction with Wavelet based Deep Residual Learning","J. Dou; Z. Tu; X. Peng","Department of Automation and Mechanical and Electrical engineering, Shanghai Polytechnic University, China; Department of Automation and Mechanical and Electrical engineering, Shanghai Polytechnic University, China; Department of Aerospace Information and Control, Shanghai Jiao Tong University, China","2020 Chinese Control And Decision Conference (CCDC)","11 Aug 2020","2020","","","4270","4275","We present a single-image super-resolution (SR) method for Remote Sensing Image based on deep learning within Discrete Wavelet Domain in this paper. Our method is inspired Residual Learning. Firstly, an input image is decomposed by single level 2D Discrete wavelet transform to get four sub-bands; The four sub-bands coefficients are feeding into the Deep Learning Residual Network to predict correspondingly residual images; Adding four sub-band images and residual images as the new sub-bands of 2D wavelet transform; Finally, uses the inverse 2D Discrete wavelet transform to get the final output Super Resolution HR image. Our proposed method performs better than existing methods in accuracy and visual improvements in our results are easily noticeable.","1948-9447","978-1-7281-5855-6","10.1109/CCDC49329.2020.9164678","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9164678","Super Resolution;Discrete Wavelet Transform;Deep Learning;Convolutional Neural Network;Residual Learning","Discrete wavelet transforms;Image resolution;Training;Machine learning;Two dimensional displays;Convolutional neural networks","discrete wavelet transforms;geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);neural nets;remote sensing","image super-resolution reconstruction;remote sensing image;discrete wavelet domain;2D discrete wavelet transform;sub-bands coefficients;residual images;sub-band images;wavelet based deep residual learning;inverse 2D discrete wavelet transform","","","","31","IEEE","11 Aug 2020","","","IEEE","IEEE Conferences"
"Sentinel-3 Super-Resolution Based on Dense Multireceptive Channel Attention","R. Fernandez; R. Fernandez-Beltran; J. Kang; F. Pla","Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; School of Electronic and Information Engineering, Soochow University, Suzhou, China; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","3 Aug 2021","2021","14","","7359","7372","The unprecedented availability of remote sensing data from different complementary Sentinel missions provides increasing opportunities to alleviate the spatial limitations of Sentinel-3 (S3) from an intersensor perspective. Nonetheless, effectively exploiting such intersensor synergies still raises important challenges for super-resolution (SR) algorithms in terms of operational data availability, sensor alignment and substantial resolution changes, among others. In this scenario, this article sets a new SR framework for spatially enhancing S3 ocean and land color instrument (OLCI) products by taking advantage of the higher spatial resolution of the Sentinel-2 (S2) multispectral instrument (MSI). To achieve this goal, we initially study some of the most important deep learning-based approaches. Then, we define a novel Level-4 SR framework which integrates a new convolutional neural network specially designed for super-resolving OLCI data. In contrast to other networks, the proposed SR architecture (termed as SRS3) employs a dense multireceptive field together with a residual channel attention mechanism to relieve the particularly low spatial resolution of OLCI while extracting more discriminating features for the large spatial resolution differences with respect to MSI. The experimental part of the work, conducted using ten coupled OLCI and MSI operational data, reveals the suitability of the presented Level-4 SR framework within the Copernicus programme context as well as the advantages of the proposed architecture with respect different state-of-the-art models when spatially enhancing OLCI products. The related codes will be publicly available at https://github.com/rufernan/SRS3.","2151-1535","","10.1109/JSTARS.2021.3097410","Ministry of Science, Innovation and Universities of Spain(grant numbers:RTI2018-098651-B-C54); Valencian Government of Spain(grant numbers:GV/2020/167); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9488297","Convolutional nural network (CNN);level-4 data processing;ocean and land color instrument (OLCI);sentinel-3 (s3);super-resolution (SR)","Spatial resolution;Remote sensing;Instruments;Earth;Superresolution;Satellites;Data models","deep learning (artificial intelligence);geophysical image processing;image resolution;remote sensing","Sentinel-3 super-resolution;dense multireceptive channel attention;unprecedented availability;remote sensing data;spatial limitations;intersensor perspective;intersensor synergies;super-resolution algorithms;operational data availability;sensor alignment;substantial resolution changes;higher spatial resolution;Sentinel-2 multispectral instrument;deep learning-based approaches;novel Level-4 SR framework;convolutional neural network;OLCI data;SR architecture;dense multireceptive field;residual channel attention mechanism;particularly low spatial resolution;spatial resolution differences;coupled OLCI;MSI operational data;OLCI products;Level-4 SR framework;complementary Sentinel missions","","1","","63","CCBY","16 Jul 2021","","","IEEE","IEEE Journals"
"DOVE: Decomposition Oriented Video super-rEsolution","H. Wang; W. Sun; Z. Chen; D. Yang","School of Remote Sensing and Information Engineering, Wuhan University, China; School of Remote Sensing and Information Engineering, Wuhan University, China; School of Remote Sensing and Information Engineering, Wuhan University, China; School of Remote Sensing and Information Engineering, Wuhan University, China","2020 IEEE International Conference on Visual Communications and Image Processing (VCIP)","29 Dec 2020","2020","","","375","378","Video super-resolution (VSR) has attracted a lot of attention that converts a low resolution (LR) video into a high resolution (HR) one. The original LR video is typically produced either by the downscaling processing or low-resolution sensor. Considering that the resolution degradation or limitation makes different impacts on different low-frequency (LF) and high-frequency (HF) components of the LR video signal, we propose a Decomposition Oriented Video super-rEsolution (DOVE) method in this paper. More specifically, a three-stream VSR network is designed in which the proposed LF and HF stream is responsible for modeling LF and HF components in the feature space. Moreover, a multi-frame refinement stream takes features of coarsely aligned frames as input and generates finely aligned counterparts progressively to guide the learning of LF and HF streams at the intermediate feature level. Furthermore, non-local channel attention is devised to capture long-range dependencies on a global scale both in the channel domain. Experimental results indicate that separating the learning of LF and HF components helps better estimate the HR frame from LR frames and superior VSR performance is achieved when compared with that of recent state-of-the-art methods.","2642-9357","978-1-7281-8068-7","10.1109/VCIP49819.2020.9301825","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9301825","video super-resolution;feature decomposition;deformable convolution;non-local attention","Convolution;Feature extraction;Three-dimensional displays;Computer architecture;Training;Computer vision;Optical imaging","image resolution;video signal processing","HF stream;LR frames;low resolution video;low-resolution sensor;resolution degradation;LR video signal;three-stream VSR network;multiframe refinement stream;DOVE;decomposition oriented video super-resolution","","","","13","IEEE","29 Dec 2020","","","IEEE","IEEE Conferences"
"An Adaptive Time-Varying Seismic Super-Resolution Inversion Based on Lp Regularization","H. Chen; J. Gao; B. Zhang","Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","21 Jul 2021","2021","18","8","1481","1485","The time-varying seismic super-resolution inversion technique becomes more and more attractive in seismic exploration. However, most existing inversion methods suffer from amplitude loss and manual adjustment parameters. In this letter, we present an adaptive time-varying seismic super-resolution inversion method based on the Lp (0 <; p <; 1) regularization to address these issues. First, the Lp-norm with 0 <; p <; 1 is applied to constrain the reflectivity to obtain a sparser and more robust solution than the L1 regularization. To solve the nonconvex inversion problem adaptively, second, we provide a new algorithm called singular value decomposition (SVD)-Hadamard product parametrization (HPP). The idea of the new algorithm is to apply an HPP to express the Lp (0 <; p ≤ 1) regularization into a sum of the L2 regularizations that are easy to be programed and solved. Then, the SVD is adopted to solve each L2 regularization. It is convenient to apply the L-curve method or its variants to determine the regularization parameters at each iteration for finishing the inversion adaptively. Finally, synthetic and field data examples are tested to validate the effectiveness of the proposed method.","1558-0571","","10.1109/LGRS.2020.3000339","Major Programs of National Natural Science Foundation of China(grant numbers:41390454); National Science and Technology Major Projects(grant numbers:2016ZX05024-001-007,2017ZX05069); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9118974","Reflectivity inversion;super-resolution inversion;time-varying","Convolution;Attenuation;Data models;Deconvolution;Time-frequency analysis;Cost function","geophysical techniques;image resolution;inverse problems;seismology;singular value decomposition","adaptive time-varying;time-varying seismic super-resolution inversion;seismic exploration;manual adjustment parameters;super-resolution inversion method;nonconvex inversion problem;singular value decomposition-Hadamard product parametrization;L-curve method;regularization parameters","","6","","21","IEEE","16 Jun 2020","","","IEEE","IEEE Journals"
"Evaluating Super-Resolution of Satellite Images: A Proba-V Case Study","M. Kawulok; P. Benecki; J. Nalepa; D. Kostrzewa","Silesian University of Technology, Faculty of Automatic Control, Electronics and Computer Science Akademicka 16, Gliwice, Poland; Silesian University of Technology, Faculty of Automatic Control, Electronics and Computer Science Akademicka 16, Gliwice, Poland; Silesian University of Technology, Faculty of Automatic Control, Electronics and Computer Science Akademicka 16, Gliwice, Poland; Silesian University of Technology, Faculty of Automatic Control, Electronics and Computer Science Akademicka 16, Gliwice, Poland","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","641","644","Super-resolution reconstruction is a process aimed at enhancing image spatial resolution. To evaluate the quality of super-resolution, the reconstruction outcome is compared with a ground-truth reference image, and the dissimilarity between them is commonly treated as a determinant of the reconstruction quality. While this is straightforward for simulated data, it becomes more challenging for real-world scenarios, in which reference images and the reconstruction inputs are acquired using different imaging sensors. In such cases, the dissimilarity also results from other factors concerned with different sensor characteristics. In a recently organized Proba-V Super Resolution Challenge, the reconstruction quality was assessed using a modified peak signal-to-noise ratio which compensates for small shifts and global changes in the brightness. In the study reported here, we investigate a number of image similarity metrics to verify their robustness against different levels of distortions applied to Proba-V images. We expect that the reported results will help in choosing appropriate metrics while developing new super-resolution solutions aimed at real-world scenarios.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323908","Silesian University of Technology(grant numbers:02/100/BKM20/0006 (DK),02/100/BKM20/0004 (PB)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323908","Super-resolution reconstruction;satellite imaging;image similarity","Measurement;Brightness;Interpolation;Image reconstruction;Superresolution;Robustness;Visualization","geophysical image processing;image enhancement;image reconstruction;image resolution;image sensors","peak signal-to-noise ratio;image similarity metrics;Proba-V images;super-resolution solutions;satellite images;Proba-V case study;super-resolution reconstruction;image spatial resolution;ground-truth reference image;reconstruction quality;reference images;reconstruction inputs;imaging sensors;sensor characteristics;Proba-V super resolution challenge","","","","9","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Ant colony optimization for super-resolution of hyperspectral images","S. Sharma; S. Sharma; K. M. Buddhiraju","Center of Studies in Resources Engineering, IIT, Bombay; Center of Studies in Resources Engineering, IIT, Bombay; Center of Studies in Resources Engineering, IIT, Bombay","2016 8th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","19 Oct 2017","2016","","","1","5","Remotely sensed images provide synaptic view of the earth's surface to study about the landscape elements. Classification of the ground surface into several classes facilitate in understanding the changes caused by climate, natural and human activities. For this purpose, hyperspectral images provide high spectral information. Due to poor spatial resolution the IFOV of the sensor contains many classes and the spectra obtained are often mixture of two classes. This results in misclassification. In this paper, sub-pixel analysis of hyperspectral images is carried out to deal with the mixed pixel problem. We propose a technique based on Ant Colony Optimization(ACO) which utilizes the spectral information to generate spatially high resolution images. Sub-pixel mapping implies division of mixed pixels into sub-pixels and allocating classes to them based on spatial contiguity and abundance fractions. To solve this spatial optimization problem, ACO has been applied which has shown significant improvement in the classification results.","2158-6276","978-1-5090-0608-3","10.1109/WHISPERS.2016.8071672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8071672","sub-pixel mapping;hyperspectral data;super-resolution;ant colony optimization;mixed pixel","Spatial resolution;Support vector machines;Hyperspectral imaging;Optimization;Training","ant colony optimisation;geophysical image processing;hyperspectral imaging;image classification;remote sensing","climate;remotely sensed images;hyperspectral image super-resolution;subpixel mapping;subpixel analysis;ant colony optimization;spectral information;human activities;spatial optimization problem","","1","","16","IEEE","19 Oct 2017","","","IEEE","IEEE Conferences"
"Agriculture Land Appraisal with Use of Remote Sensing and Infrastructure Data","N. Kussul; A. Shelestov; H. Yailymova; L. Shumilo; S. Drozd","Space Research Institute NASU-SSAU, Kyiv, Ukraine; Space Research Institute NASU-SSAU, Kyiv, Ukraine; Space Research Institute NASU-SSAU, Kyiv, Ukraine; Department of Geographical Sciences, University of Maryland, College Park, MD, USA; National Technical University of Ukraine “Igor Sikorsky Kiev Polytechnic Institute”, Kyiv, Ukraine","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2785","2788","1st July 2021 the law on the creation of land market start effect in Ukraine. As a result, land appraisal became cornerstone task in Ukrainian agriculture sector. The official methodology on land appraisal includes use of soil fertility characteristics combined with coefficients related to the distance to the infrastructure objects or settlements and placing of field in specific functional areas, like recreational, or areas with high level of radiation pollution. In this study we collected open source infostructure geospatial information and characteristics of fields obtained from remote sensing data - crop types and Normalized Difference Vegetation Index to build land price predictive model trained on the official land market information. This work designed to investigate potential of geo-informational technologies and remote sensing in the land appraisal use. We separated all available ground truth land price data into three groups by fields size - very small, small, medium and big. We found different relationships between field characteristics and prices. For very small fields the most important features are area, altitude, slope, bonitet and distances to elevators, villages and roads. For small fields the most important are bonitet, altitude, area and distances to cities and roads. For medium and big field's area, slope, distance to cities, roads and historical NDVI.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884045","deep learning;Generative Adversarial Networks;GAN;super-resolution;Sentinel-2","Pollution;Roads;Urban areas;Vegetation mapping;Soil;Predictive models;Agriculture","agriculture;crops;geographic information systems;land use planning;pricing;remote sensing;soil;vegetation;vegetation mapping","cornerstone task;Ukrainian agriculture sector;official methodology;soil fertility characteristics;infrastructure objects;settlements;specific functional areas;open source infostructure geospatial information;remote sensing data - crop types;Normalized Difference Vegetation Index;land price predictive model;official land market information;geo-informational technologies;land appraisal use;available ground truth land price data;fields size;field characteristics;bonitet;big field;agriculture land appraisal;infrastructure data;st July;land market start effect","","","","15","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"An Unsupervised Deep Learning Method for the Super-Resolution of Radar Sounder Data","E. Donini; A. Kasibovic; M. H. Garcia; L. Bruzzone; F. Bovolo","Center for Digital Society, Fondazione Bruno Kessler, Trento, Italy; Dept. of Information Engineering and Computer Science, University of Trento, Trento, Italy; Dept. of Information Engineering and Computer Science, University of Trento, Trento, Italy; Dept. of Information Engineering and Computer Science, University of Trento, Trento, Italy; Center for Digital Society, Fondazione Bruno Kessler, Trento, Italy","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1696","1699","Radar sounders (RSs) are widely used to image profiles (radargrams) of the subsurface of planetary bodies and the Earth. However, despite the huge scientific return from radargram analyses, their horizontal and vertical resolutions are limited by technical factors. Even if methods exist for improving the resolution, these are still limited by technical factors and introduce artifacts. This paper proposes an unsupervised deep-learning method that synthesizes accurate super-resolved radargrams overcoming these limitations. The method adopts the Cycle-Consistent Adversarial Network (CyleGAN) that learns the mapping function between the low- and high-resolution data distributions. The network is adapted to match the low- and high-resolution radargram characteristics, including the differences in dimensions and radiometric properties. The proposed method was successfully validated on airborne data at higher resolution and simulated data with lower resolution.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884343","super-resolution;deep learning;generative models;adversarial neural networks;radar sounder","Training;Geology;Superresolution;Imaging;Radar;Radar imaging;Radiometry","ground penetrating radar;image classification;image resolution;learning (artificial intelligence);remote sensing by radar;unsupervised learning","super-resolution;radar sounder data;radar sounders;RSs;image profiles;radargrams;planetary bodies;huge scientific return;radargram analyses;horizontal resolutions;vertical resolutions;technical factors;unsupervised deep-learning method;Cycle-Consistent Adversarial Network;low- resolution data distributions;high-resolution data distributions;low- resolution radargram characteristics;high-resolution radargram characteristics;airborne data","","","","8","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Implications of Very Deep Super-Resolution (VDSR) on RGB imagery for grain yield assessment in wheat","J. A. Fernandez-Gallego; S. C. Kefauver; N. A. Gutiérrez; M. T. Nieto-Taladriz; J. L. Araus","Programa de Ingeniería Electrónica, Facultad de Ingeniería Universidad de Ibagué, Ibagué, Colombia; Deparment of Evolutionary Biology, Ecology and Environmental Sciencies, Plant Physiology Section, University of Barcelona, Barcelona, Spain; Instituto Tecnológico Agrario de Castilla y León (ITACyL), Valladolid, Spain; Instituto Nacional de Investigación y Tecnología Agraria y Alimentaría (INIA), Madrid, Spain; Deparment of Evolutionary Biology, Ecology and Environmental Sciencies, Plant Physiology Section, University of Barcelona, Barcelona, Spain","2020 Virtual Symposium in Plant Omics Sciences (OMICAS)","13 Sep 2021","2020","","","1","5","RGB imagery has been widely used for crop management practices and phenotyping applications in recent years. Although RGB wavelengths (400-700 nm) are not able to capture all essential plant data (such as with full ultraviolet, near and long infrared wavelength coverage), RGB cameras are the most common types of cameras and are among the versatile imaging devices for proximal remote sensing applications. Deep learning strategies have improved a wide range of processes and deep learning concepts can be included in many applications. This work uses the Very Deep Super-Resolution (VDSP) technique to improve low-resolution RGB images in order to study grain yield assessment in wheat using vegetation indexes. The results show no significant differences between indexes calculated from low-resolution images and low-resolution images processed using VDSP with grain yield.","","978-1-6654-3331-0","10.1109/OMICAS52284.2020.9535654","Ministerio de Ciencia e Innovación; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9535654","deep learning;digital image processing;grain yield;RGB imagery;wheat","Deep learning;Superresolution;Vegetation mapping;Crops;Cameras;Indexes;Remote sensing","agriculture;computer vision;crops;deep learning (artificial intelligence);image colour analysis;image resolution;remote sensing","wheat;image resolution;RGB imagery;grain yield assessment;crop management;phenotyping;plant data;RGB cameras;imaging devices;proximal remote sensing;deep learning;very deep super resolution technique","","","","38","IEEE","13 Sep 2021","","","IEEE","IEEE Conferences"
"Effect of Visual Context Information for Super Resolution Problems","E. Aykut; K. Becek; B. Cengiz; S. Özkan; G. B. Akar","Orta Dogu Teknik Universitesi, Ankara, Ankara, TR; Orta Dogu Teknik Universitesi, Ankara, Ankara, TR; Orta Dogu Teknik Universitesi, Ankara, Ankara, TR; Orta Dogu Teknik Universitesi, Ankara, Ankara, TR; Orta Dogu Teknik Universitesi, Ankara, Ankara, TR","2019 27th Signal Processing and Communications Applications Conference (SIU)","22 Aug 2019","2019","","","1","4","In this study, the effect of visual context information to the performance of learning-based techniques for the super resolution problem is analyzed. Beside the interpretation of the experimental results in detail, its theoretical reasoning is also achieved in the paper. For the experiments, two different visual datasets composed of natural and remote sensing scenes are utilized. From the experimental results, we observe that keeping visual context information in the course of parameter learning for convolutional neural networks yields better performance compared to the baselines. Moreover, we summarize that fine-tuning pre-trained parameters with the related context yet fewer samples improves the results.","2165-0608","978-1-7281-1904-5","10.1109/SIU.2019.8806598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806598","Deep learning;Convolutional Neural Networks;Super Resolution","Image resolution;Mathematical model;Visualization;Convolutional neural networks;Image edge detection;Sun","convolutional neural nets;image resolution;learning (artificial intelligence);remote sensing","convolutional neural networks;parameter learning;remote sensing scenes;related context;different visual datasets;learning-based techniques;super resolution problem;visual context information","","","","","IEEE","22 Aug 2019","","","IEEE","IEEE Conferences"
"Super-resolution Reconstruction of Night-light Images Based on Improved SRCNN","T. Wu; X. Song; T. Gan; B. Zeng; J. Chen","School of Computer and Information Technology, Hohai University, Nanjing, China; Artificial Intelligence Academy, Hohai University, Nanjing, China; School of Computer and Information Technology, Hohai University, Nanjing, China; School of Computer and Information Technology, Hohai University, Nanjing, China; School of Computer and Information Technology, Hohai University, Nanjing, China","2022 4th International Conference on Advances in Computer Technology, Information Science and Communications (CTISC)","15 Aug 2022","2022","","","1","5","Night-light remote sensing images have been used in numerous fields and have brought much value to human society. However, the low resolution is a major drawback of night-light images, limiting its application in many ways. Image processing research proposes super-resolution reconstruction technology, which can obtain high-resolution images from low-resolution images. It is often used in some fields that need image details. We improve the SRCNN network structure by removing the bicubic interpolation with high computational complexity and replacing it with a deconvolutional layer. We added a feature extraction layer. We can extract more features in the image by using two convolution layers to extract the enlarged image. Finally, we also optimize the convolutional layer of the nonlinear mapping to reduce the training time. We produced a training set and a test set of night light images to evaluate the effect of network improvement. Through the final comparison, our method can improve the resolution of luminous image, which is greatly improved compared with SRCNN.","","978-1-6654-5872-6","10.1109/CTISC54888.2022.9849813","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849813","Night-light images;Remote sense;SRCNN;Super-resolution;Neural network;Satellites","Training;Interpolation;Information science;Runtime;Limiting;Deconvolution;Superresolution","feature extraction;image enhancement;image processing;image reconstruction;image resolution;interpolation;remote sensing","convolution layers;enlarged image;convolutional layer;night light images;luminous image;night-light images;night-light remote sensing images;super-resolution reconstruction technology;high-resolution images;low-resolution images;need image details","","","","11","IEEE","15 Aug 2022","","","IEEE","IEEE Conferences"
"Single Image Super-Resolution Using Depth Map as Constraint","H. Shi; J. Jiang; J. Yao; Z. Xu","School of Remote Sensing and Information Engineering, Wuhan University, P.R. China; School of Remote Sensing and Information Engineering, Wuhan University, P.R. China; School of Remote Sensing and Information Engineering, Wuhan University, P.R. China; School of Remote Sensing and Information Engineering, Wuhan University, P.R. China","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","538","542","Single image super-resolution based on the deep neural network has achieved great performance recently, but generating photo-realistic images remains a challenging problem. To tackle this issue, we propose a method that uses depth maps as a constraint to get better visual quality. Specifically, we propose a self-adaptive feature transform (AFT) layer, which can perform affine transformation on the feature map based on the depth map to constrain the plausible solution space of the SR image. Furthermore, we propose a hierarchical residual multi-scale fusion block to improve the representational ability of the network. Experimental results on benchmark datasets demonstrate that our method is superior to other perceptually-oriented SISR methods in terms of visual quality and also achieves state-of-the-art performance on quantitative metrics.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190978","super-resolution;depth map;feature transform;weight map","Training;Transforms;Visualization;Feature extraction;Measurement;Spatial resolution","affine transforms;deep learning (artificial intelligence);feature extraction;image fusion;image representation;image resolution","single image super-resolution;depth map;deep neural network;visual quality;feature map;SR image;hierarchical residual multiscale fusion block;self-adaptive feature transform;network representational ability;affine transformation","","","","26","IEEE","30 Sep 2020","","","IEEE","IEEE Conferences"
"Two-Dimension Joint Super-Resolution ISAR Imaging With Joint Motion Compensation and Azimuth Scaling","S. Shao; L. Zhang; J. Wei; H. Liu","National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; School of Electronics and Communication Engineering, Sun Yat–sen University, Guangzhou, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","21 Jul 2021","2021","18","8","1411","1415","The quality of inverse synthetic aperture radar (ISAR) images suffers seriously from the two-dimension (2-D) resolution and noise. The motion errors arising from translational and rotational motion further aggravate the image defocusing. For the limited bandwidth and short aperture (LB-SA) signal, this letter proposes a novel 2-D joint super-resolution (2D-JSR) ISAR imaging with joint motion compensation and azimuth scaling (JMCAS) algorithm. In this technique, a 2D-JSR signal model is established, enabling the 2-D high-resolution ISAR image to be generated by solving a sparsity-driven optimization problem with a modified quasi-Newton solver. In addition, a new JMCAS algorithm is developed to enhance the focusing performance of image. Not only can this algorithm jointly correct the range shift and phase error caused by translational motion, it can also complete the azimuth scaling and range spatial-variant phase error (RSVPE) compensation simultaneously. Through the iterative processing of 2D-JSR reconstruction and JMCAS, the well-focused and scaled high-resolution ISAR image can be obtained. Both simulated and real data experiments are provided to verify the effectiveness of the proposed algorithm.","1558-0571","","10.1109/LGRS.2020.3003578","National Natural Science Foundation of China(grant numbers:61771372,61771367); National Science Fund for Distinguished Young Scholars(grant numbers:61525105); 111 Project through the Fund for Foreign Scholars in University Research and Teaching Programs(grant numbers:B18039); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9126846","2-D joint super-resolution (2D-JSR) inverse synthetic aperture radar (ISAR) imaging;azimuth scaling;compressive sensing (CS);ISAR;motion compensation","Imaging;Azimuth;Motion compensation;Radar imaging;Image reconstruction;Integrated circuits","image reconstruction;image resolution;motion compensation;radar imaging;synthetic aperture radar","joint motion compensation;azimuth scaling algorithm;2D-JSR signal model;high-resolution ISAR image;JMCAS algorithm;range shift;translational motion;range spatial-variant phase error;2D-JSR reconstruction;dimension joint super-resolution ISAR imaging;inverse synthetic aperture radar images;motion errors;rotational motion;image defocusing;short aperture;2-D joint super-resolution","","7","","14","IEEE","26 Jun 2020","","","IEEE","IEEE Journals"
"Adaptive Importance Sampling Unscented Kalman Filter With Kernel Regression for SAR Image Super-Resolution","S. Kanakaraj; M. S. Nair; S. Kalady","Department of Computer Science and Engineering, National Institute of Technology Calicut, Kozhikode, India; Department of Computer Science, Artificial Intelligence & Computer Vision Lab, Cochin University of Science and Technology, Kochi, India; Department of Computer Science and Engineering, National Institute of Technology Calicut, Kozhikode, India","IEEE Geoscience and Remote Sensing Letters","17 Dec 2021","2022","19","","1","5","Resolution enhancement of Earth’s images from synthetic aperture radars (SARs), used for applications that require scene interpretations and detailed analysis, fails due to the presence of inherent speckle noise. An inexpensive alternative solution to the problem is to use super-resolution (SR) algorithms that deal with speckle. A novel approach to augment kernel regression into the Adaptive Importance Sampling Unscented Kalman Filter (AISUKF) framework for SAR image SR has been presented in this letter. We have experimented with three different nonlinear kernel regressions, namely, arc-cosine kernel, radial basis function kernel, and steering kernel (SK) regressions. Empirical results suggest that AISUKF with SK regression is more appropriate for the abovementioned SR problem resulting in a better denoised and more detail-preserved output.","1558-0571","","10.1109/LGRS.2020.3031600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9242259","Kernel regression;steering kernel (SK);super-resolution (SR);synthetic aperture radar (SAR) image;unscented Kalman filter (UKF)","Kernel;Kalman filters;Radar polarimetry;Speckle;Synthetic aperture radar","image resolution;importance sampling;Kalman filters;nonlinear filters;radar imaging;radar resolution;regression analysis;speckle;synthetic aperture radar","AISUKF;SAR image SR;arc-cosine kernel;radial basis function kernel;SAR image super-resolution;resolution enhancement;Earth images;synthetic aperture radars;scene interpretations;inherent speckle noise;super-resolution algorithms;nonlinear kernel regressions;adaptive importance sampling unscented Kalman filter framework","","3","","18","IEEE","28 Oct 2020","","","IEEE","IEEE Journals"
"Deep Mutual GAN for Life-Detection Radar Super Resolution","H. Xing; M. Bao; Y. Li; L. Shi; M. Xing","School of Electronic Engineering, Xidian University, Xi’an, China; School of Electronic Engineering, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; School of Electronic Engineering, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","16 Dec 2021","2022","19","","1","5","To improve the life-detection radar resolution under certain hardware conditions, in this letter, a deep mutual learning generative adversarial network model (Deep Mutual GAN) is proposed. In the proposed model, the generator can improve the angular resolution of the input low-resolution radar image by five times, which is enough to meet our requirements for the resolution of life detection. We innovatively use two generators in GAN with the same network structure and make the two generators learn from each other. In this way, the learning process of a generator is not only achieved by its confrontation with the discriminator but also guided by another generator. As a result, the knowledge of the generator is no longer only obtained through its own learning; each generator learns knowledge from another generator while learning knowledge by itself. The proposed model can effectively make the convergence of GAN more stable and improves the super resolution effect. We also introduce the details of the network structure of generator and discriminator, in which residual learning and a symmetrical network structure are applied. The experimental results show that the proposed method can achieve state-of-the-art imaging effect, which is meaningful for subsequent target detection and recognition.","1558-0571","","10.1109/LGRS.2021.3065696","National Key Research and Development Program of China(grant numbers:2018YFC0810202); Fundamental Research Funds for the Central Universities(grant numbers:JB190204); Science Foundation for Distinguished Young Scholars of Shaanxi Province(grant numbers:2020JC-25); Shaanxi Innovative Talents Promotion Plan-Science and Technology Innovation Team(grant numbers:2019TD-002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9389759","Deep mutual learning;generative adversarial network (GAN);life-detection radar imaging;super resolution (SR)","Generators;Radar imaging;Gallium nitride;Generative adversarial networks;Radar;Radar antennas;Receiving antennas","image resolution;learning (artificial intelligence);neural nets;object detection;radar imaging;radar resolution","life detection;learning process;super resolution effect;residual learning;symmetrical network structure;subsequent target detection;Deep Mutual GAN;life-detection radar super resolution;life-detection radar resolution;hardware conditions;deep mutual learning generative adversarial network model;angular resolution;input low-resolution radar image","","1","","17","IEEE","30 Mar 2021","","","IEEE","IEEE Journals"
"Double Prior Network for Multi-Degradation Remote Sensing Image Super-resolution","M. Shi; Y. Gao; L. Chen; X. Liu","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2023","PP","99","1","17","Image super-resolution (SR) is widely used in remote sensing because it can effectively increase image details. Neural networks have shown remarkable performance in recent years, benefitting from their end-to-end training. However, remote sensing images contain a variety of degradation factors. Neural networks lack flexibility in dealing with these complex issues compared with reconstruction-based approaches. Traditional neural network methods can not take advantage of prior knowledge and lack interpretability. To develop a flexible, accurate, and interpretable algorithm for remote sensing SR, we proposed an effective SR network called YSRNet. It is performed by unfolding a traditional optimization process into a learnable network. Combining conventional reconstruction-based methods and neural networks can significantly improve the algorithm's performance. Since the gradient features of remote sensing images contain valuable information, the total variation (TV) constraints and the deep prior constraints are introduced into the objective function for image SR. Furthermore, we propose an enhanced version called YSRNet+, which can apply attention weights to different prior terms and channels. Compared with the YSRNet, the YSRNet+ enables networks to focus more on useful prior information and improve the interpretability of networks. Experiments on three remote sensing datasets are performed to evaluate the algorithm's effectiveness. The experimental results demonstrate that the proposed algorithm performs better than some state-of-the-art neural network algorithms, especially in the scenario of the multi-degradation factors.","2151-1535","","10.1109/JSTARS.2023.3242053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10038630","Double prior;unfolding;super-resolution;remote sensing images;interpretability;multi-degradation;total variation","Remote sensing;Kernel;Image reconstruction;Degradation;Neural networks;TV;Optimization","","","","","","","CCBY","6 Feb 2023","","","IEEE","IEEE Early Access Articles"
"RFCNet: Remote Sensing Image Super-Resolution Using Residual Feature Calibration Network","Y. Xue; L. Li; Z. Wang; C. Jiang; M. Liu; J. Wang; K. Sun; H. Ma","College of Information Science and Engineering, Xinjiang University, Urumqi, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; College of Information Science and Engineering, Xinjiang University, Urumqi, China; College of Information Science and Engineering, Xinjiang University, Urumqi, China; College of Information Science and Engineering, Xinjiang University, Urumqi, China; Shanghai Institute of Satellite Engineering, Shanghai, China; Shanghai Institute of Satellite Engineering, Shanghai, China; Department of Electronic Engineering, Tsinghua University, Beijing, China","Tsinghua Science and Technology","13 Dec 2022","2023","28","3","475","485","In the field of single remote sensing image Super-Resolution (SR), deep Convolutional Neural Networks (CNNs) have achieved top performance. To further enhance convolutional module performance in processing remote sensing images, we construct an efficient residual feature calibration block to generate expressive features. After harvesting residual features, we first divide them into two parts along the channel dimension. One part flows to the Self-Calibrated Convolution (SCC) to be further refined, and the other part is rescaled by the proposed Two-Path Channel Attention (TPCA) mechanism. SCC corrects local features according to their expressions under the deep receptive field, so that the features can be refined without increasing the number of calculations. The proposed TPCA uses the means and variances of feature maps to obtain accurate channel attention vectors. Moreover, a region-level nonlocal operation is introduced to capture long-distance spatial contextual information by exploring pixel dependencies at the region level. Extensive experiments demonstrate that the proposed residual feature calibration network is superior to other SR methods in terms of quantitative metrics and visual quality.","1007-0214","","10.26599/TST.2022.9010018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9983980","Convolutional Neural Network (CNN);remote sensing image;Super-Resolution (SR);attention mechanism","Measurement;Visualization;Convolution;Superresolution;Calibration;Sensors;Convolutional neural networks","calibration;computer vision;convolutional neural nets;deep learning (artificial intelligence);feature extraction;geophysical image processing;image classification;image resolution;remote sensing","accurate channel attention vectors;calibration block;convolutional module performance;deep convolutional neural networks;deep receptive field;expressive features;feature maps;local features;residual feature calibration network;residual features;self-calibrated convolution;single remote sensing image super-resolution;two-path channel attention mechanism","","","","30","","13 Dec 2022","","","TUP","TUP Journals"
"Controllable Space-Time Video Super-Resolution via Enhanced Bidirectional Flow Warping","Y. Zhang; H. Wang; Z. Chen","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China","2022 IEEE International Conference on Visual Communications and Image Processing (VCIP)","16 Jan 2023","2022","","","1","5","Space-time video super-resolution targets to increase a given video's frame rate and resolution simultaneously. Al-though existing approaches have made great progress, most of them still suffer from the inaccurate approximation of large motions or fail to generate temporal consistent motion trajectory. To alleviate these problems, we carefully review the characteris-tics of different optical flow warping strategies, integrating and enhancing them to achieve more robust capabilities for handling extreme motions and time-modulated interpolation. Specifically, we utilize enhanced backward warping to perform alignment, mine space-time information across low resolution input frames, and propose an enhanced forward warping strategy to interpolate arbitrary intermediate frames. Furthermore, the proposed model can be trained end-to-end and produce intermediate results at any time by merely supervising the center moment. Experimental results show that the proposed algorithm performs favorably against the state-of-the-art methods in objective metrics and subjective visual effects.","2642-9357","978-1-6654-7592-1","10.1109/VCIP56404.2022.10008838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10008838","Video Super-Resolution;Video Interpolation;Bidirectional Flow Warping","Measurement;Interpolation;Visual communication;Ultraviolet sources;Superresolution;Visual effects;Trajectory","image resolution;image sequences;interpolation;video signal processing","alignment space-time information;controllable space-time video super-resolution;different optical flow warping strategies;enhanced bidirectional flow;enhanced forward warping strategy;given video;low resolution input frames;mine space-time information;space-time video super-resolution targets;temporal consistent motion trajectory;time-modulated interpolation","","","","28","IEEE","16 Jan 2023","","","IEEE","IEEE Conferences"
"Hyperspectral Image Super-Resolution Using Deep Feature Matrix Factorization","W. Xie; X. Jia; Y. Li; J. Lei","State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; School of Engineering and Information Technology, The University of New South Wales, Canberra, ACT, Australia; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","22 Jul 2019","2019","57","8","6055","6067","Hyperspectral images (HSIs) can describe the subtle differences in the spectral signatures of materials. However, they have low spatial resolution due to various hardware limitations. Improving it via postprocess without an auxiliary high-resolution (HR) image still remains a challenging problem. In this paper, we address this problem and propose a new HSI super-resolution (SR) method. Our approach, called deep feature matrix factorization (DFMF), blends feature matrix extracted by a deep neural network (DNN) with nonnegative matrix factorization strategy for super-resolving real-scene HSI. The estimation of the HR HSI is formulated as a combination of latent spatial feature matrix and spectral feature matrix. In the DFMF model, the input low-resolution (LR) HSI is first partitioned into several subsets according to the correlation matrix, and the key band is selected from each subset. Then, the key band group is super-resolved by a DNN model, and the HR key band group is then used as a guide to carry out deep spatial feature matrix. Specifically, the input LR HSI with prototype reflectance spectral vectors of the scene will be preserved when super-resolving in a spatial domain. Thus, the nonnegative spectral and spatial feature matrices are extracted simultaneously from alternately factorizing the pair of LR HSI and the HR key band group. Finally, the HR HSI is obtained by the integration of the spectral and spatial feature matrices. Experiments have been conducted on real-scene remote sensing HSI. Comparative analyses validate that the proposed DFMF method presents a superior super-resolving performance, as it preserves spectral information better.","1558-0644","","10.1109/TGRS.2019.2904108","National Natural Science Foundation of China(grant numbers:61801359,61571345,91538101,61501346,61502367,61701360); 111 Project(grant numbers:B08038); Fundamental Research Funds for the Central Universities(grant numbers:JB180104); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2016JQ6023,2016JQ6018); China Postdoctoral Science Foundation(grant numbers:2017M620440); Yangtse Rive Scholar Bonus Schemes; Ten Thousand Talent Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8678710","Band selection;deep neural network (DNN);hyperspectral image (HSI);matrix factorization;super-resolution (SR)","Spatial resolution;Feature extraction;Correlation;Hyperspectral imaging;Image reconstruction","geophysical image processing;hyperspectral imaging;image resolution;matrix decomposition;neural nets;remote sensing;vectors","hyperspectral image super-resolution;HSI super-resolution method;deep neural network;nonnegative matrix factorization strategy;real-scene HSI;HR HSI;latent spatial feature matrix;spectral feature matrix;DFMF model;correlation matrix;DNN model;deep spatial feature matrix;prototype reflectance spectral vectors;nonnegative spectral feature matrices;spatial feature matrices;real-scene remote sensing HSI;DFMF method;deep feature matrix factorization","","44","","41","IEEE","31 Mar 2019","","","IEEE","IEEE Journals"
"A super-resolution land cover mapping based on a random forest and Markov random field model","M. Sanpayao; T. Kasetkasem; T. Isshiki; P. Rakwatin; T. Chanwimaluang","Department of Electrical Engineering, Kasetsart University, Bangkok, Thailand; Department of Electrical Engineering, Kasetsart University, Bangkok, Thailand; Tokyo Institute of Technology, Tokyo, Japan; GISTDA, The Government Complex, Bangkok, Thailand; Knowledge Elicitation and Archiving Lab Laboratory, NECTEC, Pathumthani, Thailand","2017 14th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","7 Nov 2017","2017","","","553","556","A mixed pixel in remote sensed images is a major problem, and the super-resolution mapping is one of the approach to deal with this problem. In this paper, we address the problem of super-resolution mapping by combining a set of random forests with a Markov random field (MRF) model. Here, a random forest is trained to estimate a class proportion of only one land cover class. Thus, there are equal number of random forests as the number of land cover class. Then, the MRF model is used to choose the mostly likely super-resolution map from all the possibility that yield the similar class portion.","","978-1-5386-0449-6","10.1109/ECTICon.2017.8096297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8096297","Random forest;Super-resolution;Markov random field;Mixed pixels;Image classification","Image resolution;Decision trees;Training;Radio frequency;Markov random fields;Vegetation;Remote sensing","geophysical image processing;image classification;image resolution;land cover;Markov processes;terrain mapping","super-resolution remote sensed image mapping;MRF model;super-resolution map;land cover class;Markov random field model;random forest;super-resolution land cover mapping","","1","","8","IEEE","7 Nov 2017","","","IEEE","IEEE Conferences"
"Super-Resolution Reconstruction of Remote Sensing Images Using Generative Adversarial Network With Shallow Information Enhancement","Y. Fu; X. Zhang; M. Wang","College of Information and Computer Engineering, Northeast Forestry University, Harbin, China; College of Economics and Business Administration, Heilongjiang Institute of Technology, Harbin, China; College of Information and Computer Engineering, Northeast Forestry University, Harbin, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","11 Oct 2022","2022","15","","8529","8540","The super-resolution (SR) reconstruction method based on deep learning can significantly improve the spatial SR of remote sensing images. However, the current methods make insufficient use of the remote context information and channel information in shallow feature extraction, resulting in the limited effect of SR reconstruction. This article proposed a new SR reconstruction model, SIEGAN, which uses generative adversarial network with shallow information enhancement to improve the effect of SR reconstruction of remote sensing images. Similar to other generative adversarial models, SIEGAN is composed of generator and discriminator. But SIEGAN enhances the generator's ability to extract shallow information by using three different scale convolution operations. Specifically, a depthwise convolution is used to extract the local context information of each band of the image. A depthwise dilation convolution is used to capture the remote context information in the image. Finally, a 1×1 convolution is used to extract the correlation features between different channels in remote sensing images. In addition, SIEGAN uses U-Net network as its discriminator to provide detailed feedback per pixel to the generator to improve the model's ability to identify image details. And the spectral–spatial total variation loss function is introduced to ensure the spectral–spatial reliability of the reconstructed images. The experimental results on Gaofen-1 data proved that compared with the state-of-the-art models, SIEGAN has achieved better SR reconstruction performance. Furthermore, the reconstructed images by SIEGAN demonstrate better performance in land cover classification.","2151-1535","","10.1109/JSTARS.2022.3209819","National Natural Science Foundation of China(grant numbers:71473034); Natural Science Foundation of Heilongjiang Province(grant numbers:LH2019G001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9903573","Generative adversarial network (GAN);multiscale shallow information;remote sensing images;super-resolution (SR) reconstruction","Feature extraction;Image reconstruction;Superresolution;Spatial resolution;Remote sensing;Generative adversarial networks","","","","","","37","CCBY","26 Sep 2022","","","IEEE","IEEE Journals"
"Super-Resolution of VIIRS-Measured Ocean Color Products Using Deep Convolutional Neural Network","X. Liu; M. Wang","CIRA, Colorado State University, Fort Collins, CO, USA; Center for Satellite Applications and Research, National Environmental Satellite, Data, and Information Service (NESDIS)/National Oceanic and Atmospheric Administration (NOAA), College Park, MD, USA","IEEE Transactions on Geoscience and Remote Sensing","24 Dec 2020","2021","59","1","114","127","Since its launch in October 2011, the Visible Infrared Imaging Radiometer Suite (VIIRS) onboard the Suomi National Polar-orbiting Partnership (SNPP) satellite has provided high quality global ocean color products, which include normalized water-leaving radiance spectra nLw(λ) of six moderate (M) bands (M1-M6) at the wavelengths of 410, 443, 486, 551, 671, and 745 nm with a spatial resolution of 750-m, and one imagery (I) band at a wavelength of 638 nm with a spatial resolution of 375-m. Because the high-resolution I-band measurements are highly correlated spectrally to those of M-band data, it can be used as a guidance to super-resolve the M-band nLw(λ) imagery from 750-to 375-m spatial resolution. Super-resolving images from coarse spatial resolution to finer ones have been a field of very active research in recent years. However, no previous studies have been applied to satellite ocean color remote sensing, in particular, for VIIRS ocean color applications. In this study, we employ the deep convolutional neural network (CNN) technique to glean the high-frequency content from the VIIRS I1 band and transfer to super-resolved M-band ocean color images. The network is trained to super-resolve each of the VIIRS six M-bands nLw(λ) separately. In our results, the super-resolved (375-m) nLw(λ) images are much sharper and show finer spatial structures than the original images. Quantitative evaluations show that biases between the super-resolved and original nLw(λ) images are small for all bands. However, errors in the super-resolved nLw(λ) images are wavelength-dependent. The smallest error is found in the superresolved nLw(551) and nLw(671) images, and error increases as the wavelength decreases from 486 to 410 nm. The results show that the networks have the capability to capture the correlations of the M-band and the I1 band images to super-resolved M-band images.","1558-0644","","10.1109/TGRS.2020.2992912","Joint Polar Satellite System (JPSS) Funding; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097401","Deep convolutional neural network (CNN);image fusion;ocean color remote sensing;super-resolution;Visible Infrared Imaging Radiometer Suite (VIIRS)","Spatial resolution;Oceans;Image color analysis;Signal resolution;Satellite broadcasting;Sensors","convolutional neural nets;geophysical image processing;image resolution;infrared imaging;radiometry;remote sensing;underwater optics","original images;superresolved nL;M-band images;super-resolution;VIIRS-measured ocean color products;Visible Infrared Imaging Radiometer Suite;Suomi National Polar-orbiting Partnership satellite;high quality global ocean color products;normalized water-leaving radiance spectra;moderate bands;I-band measurements;M-band data;super-resolving images;coarse spatial resolution;satellite ocean color remote sensing;VIIRS ocean color applications;deep convolutional neural network technique;high-frequency content;M-band ocean color images;finer spatial structures;AD 2011 10;wavelength 638.0 nm;wavelength 410.0 nm to 486.0 nm;wavelength 551.0 nm;wavelength 671.0 nm;wavelength 745.0 nm","","10","","65","IEEE","20 May 2020","","","IEEE","IEEE Journals"
"Amplitude-Phase Deconvolution Method for Real Aperture Radar Super-Resolution Imaging","X. Tuo; H. Yang; H. Tang; X. Zhou; Y. Zhang; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","7413","7416","The real aperture radar (RAR) system can present full-view observation capability, but the coarse azimuth resolution restricts its application. Therefore, various super-resolution deconvolution methods are widely used in the real aperture super-resolution imaging field. But conventional deconvolution approaches only rely on amplitude information of antenna pattern profile, it will behave worse when forward-looking imaging with high speed or squint imaging. This paper analyzes the influence of phase and constructs a corresponding amplitude-phase model to resolve this problem. Finally, the effectiveness of the proposed amplitude-phase convolution model for forward-looking imaging with high speed or squint imaging is verified by simulations.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883570","National Natural Science Foundation of China(grant numbers:61901090,61901092); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883570","real aperture radar;super-resolution de-convolution;amplitude-phase model","Deconvolution;Convolution;Azimuth;Superresolution;Imaging;Radar imaging;Apertures","convolution;deconvolution;image resolution;radar imaging;radar resolution;synthetic aperture radar","full-view observation capability;coarse azimuth resolution;super-resolution deconvolution methods;aperture super-resolution imaging field;conventional deconvolution;amplitude information;antenna pattern profile;squint imaging;corresponding amplitude-phase model;amplitude-phase convolution model;amplitude-phase deconvolution method;real aperture radar super-resolution imaging;aperture radar system","","","","8","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Polarimetric SAR Image Super-Resolution VIA Deep Convolutional Neural Network","L. Lin; J. Li; Q. Yuan; H. Shen","School of Resource and Environmental Science, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Resource and Environmental Science, Wuhan University, Wuhan, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3205","3208","In order to solve the problem of full-polarimetric SAR image degradation, this paper proposes a full-polarimetric SAR image super-resolution reconstruction method combined with a convolutional neural network and residual compensation. Through the advantages of the deep convolutional neural network for nonlinear model fitting, this paper performs super-resolution reconstruction on low-resolution full-polarimetric SAR images, and then applies residual compensation to network reconstruction results, using low-resolution image information to the network. The super-resolution reconstruction results are corrected to obtain a high-resolution full-polarimetric SAR image. Compared with the traditional full-polarimetric SAR image super-resolution reconstruction method, the proposed method shows excellent results in both visual and quantitative evaluation indicators, especially the reconstruction of detailed information.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898160","Polarimetric SAR;Super-resolution;Residual learning;Convolutional neural network;Residual compensation","Radar polarimetry;Image reconstruction;Convolutional neural networks;Covariance matrices;Symmetric matrices","convolutional neural nets;image reconstruction;image resolution;radar imaging;radar polarimetry;radar resolution;synthetic aperture radar","residual compensation;low-resolution image information;full-polarimetric SAR image super-resolution reconstruction method;full-polarimetric SAR image degradation;deep convolutional neural network;polarimetric SAR image super-resolution;nonlinear model fitting;quantitative evaluation indicators;visual evaluation indicators","","8","","10","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"An alternating direction method for angular super-resolution in scanning radar","Y. Zha; L. Liu; J. Yang; Y. Huang","China Electronics Technology Group Corporation No. 38 Research Institute, Hefei, Anhui, China; China Electronics Technology Group Corporation No. 38 Research Institute, Hefei, Anhui, China; University of Electronic Science and Technology of China, Chengdu, Sichuan, China; University of Electronic Science and Technology of China, Chengdu, Sichuan, China","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","1626","1629","Angular super-resolution imaging plays a significant role in the area of the scanning radar imaging. Some deconvolution methods are used to realize the angular super-resolution on scanning radar. However, the ill-posed nature of the deconvolution problem means difficulties and inaccuracies in the search for the solution. In this paper, we present a novel method for angular super-resolution imaging in scanning radar using the alternating direction method for solving the constrained optimization problem. To this end, we first formulate the angular super-resolution problem as deconvolution task and then convert it to a constrained optimization problem by incorporating the prior information of the targets. We then attack the constrained optimization problem in augmented Lagrangian framework using an alternating direction method, leading to the algorithm that can be implemented easily. It is shown in a serious simulation that the proposed algorithm outperforms a number of existing deconvolution algorithms in terms of stability and precision.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127285","Radar imaging;alternating direction method;deconvolution;super-resolution","Signal resolution;Image resolution;Radar imaging;Deconvolution;Azimuth;Radar antennas","deconvolution;image resolution;iterative methods;optimisation;radar imaging","angular super-resolution imaging;alternating direction method;constrained optimization problem;angular super-resolution problem;scanning radar imaging;deconvolution methods;deconvolution problem","","","","8","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"PQA-CNN: Towards Perceptual Quality Assured Single-Image Super-Resolution in Remote Sensing","Y. Zhang; X. Dong; M. T. Rashid; L. Shang; J. Han; D. Zhang; D. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA","2020 IEEE/ACM 28th International Symposium on Quality of Service (IWQoS)","6 Oct 2020","2020","","","1","10","Recent advances in remote sensing open up unprecedented opportunities to obtain a rich set of visual features of objects on the earth's surface. In this paper, we focus on a single-image super-resolution (SISR) problem in remote sensing, where the objective is to generate a reconstructed satellite image of high quality (i.e., a high spatial resolution) from a satellite image of relatively low quality. This problem is motivated by the lack of high quality satellite images in many remote sensing applications (e.g., due to the cost of high resolution sensors, communication bandwidth constraints, and historic hardware limitations). Two important challenges exist in solving our problem: i) it is not a trivial task to reconstruct a satellite image of high quality that meets the human perceptual requirement from a single low quality image; ii) it is challenging to rigorously quantify the uncertainty of the results of an SISR scheme in the absence of ground truth data. To address the above challenges, we develop PQA-CNN, a perceptual quality-assured conventional neural network framework, to reconstruct a high quality satellite image from a low quality one by designing novel uncertainty-driven neural network architectures and integrating an uncertainty quantification model with the framework. We evaluate PQA-CNN on a real-world remote sensing application on land usage classifications. The results show that PQA-CNN significantly outperforms the state-of-the-art super-resolution baselines in terms of accurately reconstructing high-resolution satellite images under various evaluation scenarios.","1548-615X","978-1-7281-6887-6","10.1109/IWQoS49365.2020.9212942","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212942","Super-Resolution;Perceptual Quality;Uncertainty-Aware;Convolutional Neural Network","Satellites;Image reconstruction;Remote sensing;Uncertainty;Sensors;Spatial resolution","convolutional neural nets;geophysical image processing;image classification;image reconstruction;image resolution;image sensors;remote sensing","perceptual quality-assured conventional neural network framework;PQA-CNN;single-image superresolution problem;high spatial resolution;remote sensing applications;perceptual quality assured single-image superresolution;satellite image reconstruction;single low quality imaging;SISR scheme;uncertainty quantification model;land usage classifications;high-resolution satellite image reconstruction","","7","","46","IEEE","6 Oct 2020","","","IEEE","IEEE Conferences"
"Deep Hierarchical Pyramid Network With High- Frequency -Aware Differential Architecture for Super-Resolution Mapping","D. He; Y. Zhong","School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","24 Feb 2023","2023","61","","1","15","Super-resolution mapping (SRM) is a way to solve the mixed-pixel problem in urban land use/land cover caused by the limited spatial-resolving ability of satellite sensors, through resolution enhancement of the classification map. Recently, deep learning-based super-resolution mapping (DLSM) networks have been boomed, which can automatically learn a mapping pattern from low-resolution (LR) image to high-resolution (HR) land cover distribution to alleviate mixed-pixel problem. However, the urban compositions like buildings, trees, and roads exhibit a multiscale distribution with different size or orientation, which makes the traditional single-scale DLSM failed for an appropriate recognition. In addition, the urban compositions also show significant spatial heterogeneity with irregular distribution and intricate morphological shape, which are difficult to learn by simple convolutional layer. Therefore, it is necessary to explore the cue of these distribution characteristic to constrain the learning behavior of the network for better detail restoration. In this article, a deep hierarchical pyramid sub-pixel mapping network (HiSMNet) with high-frequency-aware differential architecture is proposed, which establishes an HP architecture to achieve explicit multiscale supervision of the feature map and prompt the network to learn a multiscale representation. In addition, a differential architecture is designed to enforce the network to intensify the learning of the high-frequency details. The validation experiments demonstrate that HiSMNet achieves superior performances in detailed delineation and outperformed the state-of-the-art DLSM models by up to 10% in terms of overall accuracy.","1558-0644","","10.1109/TGRS.2023.3243927","National Key Research and Development Program of China(grant numbers:2019YFB2103102); National Natural Science Foundation of China(grant numbers:42201340,42071350); Natural Science Foundation of Guangdong Province(grant numbers:2020A1515110708); China Postdoctoral Science Foundation(grant numbers:2020M683053); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10041948","Deep learning-based super-resolution mapping (DLSM);hierarchical pyramid (HP) architecture;high-frequency components (HiFCs);mixed-pixel problem;multiscale supervision;super-resolution mapping (SRM)","Superresolution;Deep learning;Spatial resolution;Remote sensing;Data models;Convolution;Analytical models","","","","","","67","IEEE","10 Feb 2023","","","IEEE","IEEE Journals"
"DARN: Distance Attention Residual Network for Lightweight Remote-Sensing Image Superresolution","Q. Wang; S. Wang; M. Chen; Y. Zhu","Faculty of Mechanical and Electrical Engineering, Kunming University of Science and Technology, Kunming, China; Faculty of Mechanical and Electrical Engineering, Kunming University of Science and Technology, Kunming, China; Faculty of Mechanical and Electrical Engineering, Kunming University of Science and Technology, Kunming, China; Faculty of Mechanical and Electrical Engineering, Kunming University of Science and Technology, Kunming, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","28 Dec 2022","2023","16","","714","724","The application of single-image superresolution (SISR) in remote sensing is of great significance. Although the state-of-the-art convolution neural network (CNN)-based SISR methods have achieved excellent results, the large model and slow speed make it difficult to deploy in real remote sensing tasks. In this article, we propose a compact and efficient distance attention residual network (DARN) to achieve a better compromise between model accuracy and complexity. The distance attention residual connection block (DARCB), the core component of the DARN, uses multistage feature aggregation to learn more accurate feature representations. The main branch of the DARCB adopts a shallow residual block (SRB) to flexibly learn residual information to ensure the robustness of the model. We also propose a distance attention block (DAB) as a bridge between the main branch and the branch of the DARCB; the DAB can effectively alleviate the loss of detail features in the deep CNN extraction process. Experimental results on two remote sensing and five super-resolution benchmark datasets demonstrate that the DARN achieves a better compromise than existing methods in terms of performance and model complexity. In addition, the DARN achieves the optimal solution compared with the state-of-the-art lightweight remote sensing SISR method in terms of parameter amount, computation amount, and inference speed. Our code will be available at https://github.com/candygogogogo/DARN.","2151-1535","","10.1109/JSTARS.2022.3227509","National Natural Science Foundation of China(grant numbers:52065035,51965029); Science and Technology Program of Yunnan Province(grant numbers:202002AC080001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9976189","Convolution neural network;lightweight;remote sensing;single image superresolution (SISR)","Feature extraction;Remote sensing;Task analysis;Image reconstruction;Convolution;Superresolution;Computational modeling","convolutional neural nets;deep learning (artificial intelligence);feature extraction;geophysical image processing;image resolution;object detection;remote sensing","accurate feature representations;convolution neural network-based SISR methods;DAB;DARCB;deep CNN extraction process;distance attention block;distance attention residual connection block;efficient distance attention residual network;lightweight remote sensing SISR method;lightweight remote-sensing image;model accuracy;multistage feature aggregation;remote sensing tasks;residual information;shallow residual block;single-image superresolution;slow speed","","","","43","CCBY","8 Dec 2022","","","IEEE","IEEE Journals"
"SAR Image Super-Resolution Base on Weighted Dense Connected Convolutional Network","J. Yu; W. Li; Z. Li; J. Wu; H. Yang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","2101","2104","In this paper, a weighted dense connected convolutional network(WDCCN) is proposed for SAR image super-resolution. In the network, to enhance feature propagation and the super-resolution performance, each layer will receive the output from all the previous layers in a different weight proportion. At last, the experimental results indicate that weighted dense connected convolutional network can realize SAR image super-resolution well.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324079","SAR;super-resolution;convolutional network;weighted dense connection","Superresolution;Feature extraction;Convolution;Radar polarimetry;Image reconstruction;Training;Silicon","image representation;image resolution;radar imaging;radar resolution;synthetic aperture radar","SAR image super-resolution base;super-resolution performance;different weight proportion","","1","","8","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Majorize-Minimization Based Super-Resolution Method for Radar Forward-Looking Imaging","Q. Zhang; Y. Zhang; Y. Zhang; Y. Huang; W. Li; J. Yang","University of Electronic Science and Technology of China, Chengdu, Sichuan, P. R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P. R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P. R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P. R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P. R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P. R. China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","3188","3191","Sparse regularization method has been widely used to realize super-resolution imaging in radar forward-looking imaging. However, most of existed methods directly minimize a nondifferentiable L1 regularization problem. In this paper, a Majorize-Minimization (MM) based super-resolution method is proposed to realize super-resolution for radar forward-looking imaging. According to MM principle, the proposed method converts the non-differentiable L1 regularization problem into a differentiable L2 regularization problem, and the real target distribution is obtained by solving the L2 regularization problem. Due to the introduction of the sparse prior, the proposed method can better improve the azimuth resolution of radar forward-looking imaging. In addition, the application of MM principle makes the non-differentiable L1 regularization easier to be solved. Finally, the superior performance of the proposed method is verified by simulation.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324322","Super-resolution;radar imaging;Majorize-Minimization;regularization","Radar imaging;Azimuth;Superresolution;Imaging;Radar;Radar antennas;Antennas","image resolution;minimisation;radar imaging","Majorize-Minimization based super-resolution method;radar forward-looking imaging;sparse regularization method;super-resolution imaging;existed methods;nondifferentiable L1 regularization problem;MM principle;differentiable L2 regularization problem;azimuth resolution","","1","","9","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Small Object Detection Leveraging on Simultaneous Super-resolution","H. Ji; Z. Gao; X. Liu; Y. Zhang; T. Mei","School of Remote Sensing and Information Engineering Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering Wuhan University, Wuhan, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; School of Remote Sensing and Information Engineering Wuhan University, Wuhan, China; Electronic and Information School, Wuhan University, Wuhan, China","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","803","810","Despite the impressive advancement achieved in object detection, the detection performance of small object is still far from satisfactory due to the lack of sufficient detailed appearance to distinguish it from similar objects. Inspired by the positive effects of super-resolution for object detection, we propose a framework that can be incorporated with detector networks to improve the performance of small object detection, in which the low-resolution image is super-resolved via generative adversarial network (GAN) in an unsupervised manner. In our method, the super-resolution network and the detection network are trained jointly. In particular, the detection loss is back-propagated into the super-resolution network during training to facilitate detection. Compared with available simultaneous super-resolution and detection methods which heavily rely on low-/high-resolution image pairs, our work breaks through such restriction via applying the CycleGAN strategy, achieving increased generality and applicability, while remaining an elegant structure. Extensive experiments on datasets from both computer vision and remote sensing communities demonstrate that our method obtains competitive performance on a wide range of complex scenarios.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9413058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413058","","Training;Image segmentation;Computer vision;Superresolution;Object detection;Detectors;Generative adversarial networks","computer vision;image resolution;object detection;remote sensing","low-resolution image;generative adversarial network;super-resolution network;detection network;simultaneous super-resolution;small object detection;detector networks;CycleGAN;computer vision;remote sensing","","1","","36","IEEE","5 May 2021","","","IEEE","IEEE Conferences"
"TransRes: A Deep Transfer Learning Approach to Migratable Image Super-Resolution in Remote Urban Sensing","Y. Zhang; R. Zong; J. Han; D. Zhang; T. Rashid; D. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA","2020 17th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)","4 Aug 2020","2020","","","1","9","Recent advances in remote sensing provide a powerful and scalable sensing paradigm to capture abundant visual information about the urban environments. We refer to such a sensing paradigm as remote urban sensing. In this paper, we focus on a migratable satellite image super-resolution problem in remote urban sensing applications. Our goal is to reconstruct satellite images of a high resolution in a target area where the high-resolution training data is not available by transferring a super-resolution model learned in a source area where such data is available. This problem is motivated by the limitation of current solutions that primarily rely on a rich set of high-resolution satellite images in the studied area that are not always available. Two important challenges exist in solving our problem: i) the target and source areas often have very different urban characteristics that prevent the direct application of a super-resolution model learned from the source area to the target area; ii) it is not a trivial task to ensure effective model migration with desirable quality without sufficient high quality training data. To address the above challenges, we develop TransRes, a deep adversarial transfer learning framework, to effectively reconstruct high-resolution satellite images without requiring any ground-truth training data from the studied area. We evaluate the TransRes framework using the real-world satellite imagery data collected from three different cities in Europe. The results show that TransRes consistently outperforms the state-of-the-art baselines by achieving the lowest perception errors under various application scenarios.","2155-5494","978-1-7281-6630-8","10.1109/SECON48991.2020.9158410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9158410","Urban Sensing;Remote Sensing;Migratable Image Super-Resolution;Transfer Learning","Satellites;Sensors;Image reconstruction;Spatial resolution;Urban areas;Training data","geophysical image processing;geophysical signal processing;image classification;image reconstruction;image resolution;image sensors;learning (artificial intelligence);remote sensing","TransRes;deep transfer;migratable image super-resolution;remote sensing;powerful sensing paradigm;scalable sensing paradigm;abundant visual information;urban environments;migratable satellite image super-resolution problem;remote urban sensing applications;high-resolution training data;super-resolution model;source area;high-resolution satellite images;source areas;different urban characteristics;effective model migration;sufficient high quality training data;deep adversarial transfer learning framework;ground-truth training data;real-world satellite imagery data","","7","","39","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Super-Resolving Sar Tomography Using Deep Learning","K. Qian; Y. Wang; Y. Shi; X. X. Zhu","Data Science in Earth Observation, Technical University of Munich, Munich, Germany; Remote Sensing Technology Institute, Germany Aerospace Center, Wessling, Germany; Data Science in Earth Observation, Technical University of Munich, Munich, Germany; Remote Sensing Technology Institute, Germany Aerospace Center, Wessling, Germany","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","4810","4813","Synthetic aperture radar tomography (TomoSAR) has been widely employed in 3-D urban mapping. However, state-of-the-art super-resolving TomoSAR algorithms are computationally expensive, because conventional numerical solvers need to solve the $l_{2^{-}}l_{1}$ mix norm minimization. This paper proposes a computationally efficient super-resolving To-moSAR inversion algorithm based on deep learning. We studied the potential of deep learning to mimic a conventional $l_{2}-l_{1}$ mix norm solver, i.e. iterative shrinkage thresholding algorithm (ISTA), and proposed several improvements of the complex-valued learned ISTA for TomoSAR inversion. Investigation on the super-resolution ability and estimator efficiency of the proposed algorithm shows that the proposed algorithm approaches the Cramer Rao lower bound (CRLB) with a computational efficiency more than 100 times better than the conventional solver.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554165","SAR tomography;Super-resolution;Complex-valued neural network;Compressive sensing;deep learning","Deep learning;Inverse problems;Superresolution;Geoscience and remote sensing;Tomography;Minimization;Iterative algorithms","deep learning (artificial intelligence);geophysical image processing;image resolution;iterative methods;minimisation;radar imaging;radar resolution;synthetic aperture radar;tomography","super-resolving SAR tomography;deep learning;synthetic aperture radar tomography;3D urban mapping;iterative shrinkage thresholding algorithm;complex-valued learned ISTA;super-resolution ability;computational efficiency;numerical solvers;super-resolving TomoSAR;l2-l1 mix norm minimization;super-resolving TomoSAR inversion;l2-l1 mix norm solver;ISTA;estimator efficiency;Cramer Rao lower bound;CRLB","","1","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Srbuildingseg-E2: An Integrated Model for End-to-End Higher-Resolution Building Extraction","L. Zhang; R. Dong; S. Yuan; H. Fu","Department of Earth System Science Tsinghua University, Ministry of Education Key Laboratory for Earth System Modeling, Beijing, China; Department of Earth System Science Tsinghua University, Ministry of Education Key Laboratory for Earth System Modeling, Beijing, China; Department of Electrical Engineering, The City University of Hong Kong, Hong Kong, China; Department of Earth System Science Tsinghua University, Ministry of Education Key Laboratory for Earth System Modeling, Beijing, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1356","1359","Automatic and accurate extraction of buildings from remote sensing images plays a vital role in many applications. However, existing approaches for building extraction generally apply high-resolution remote sensing images as input to attain high-resolution extraction results, which is time consuming and limited due to its spatiotemporal accessibility and cost. To address this challenge, in this paper, we propose an end-to-end approach, i.e., SRBuildingSeg-E2, to achieve higher-resolution building extraction from relatively low resolution remote sensing images. By integrating super resolution and semantic segmentation techniques, our proposed approach can attain high-resolution representations using low-resolution input. The quantitative assessment results reveal its promising performance in higher-resolution building extraction.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883295","Super resolution;semantic segmentation;building extraction;deep learning;SRBuildingSeg","Image segmentation;Head;Costs;Buildings;Superresolution;Semantics;Feature extraction","feature extraction;geophysical image processing;image resolution;image segmentation;remote sensing","end-to-end higher-resolution building extraction;high-resolution remote sensing images;high-resolution extraction results;end-to-end approach;SRBuildingSeg-E2;relatively low resolution remote sensing images;super resolution;high-resolution representations;low-resolution input","","","","8","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"How Effective Is Super-Resolution to Improve Dense Labelling of Coarse Resolution Imagery?","M. B. Pereira; J. A. dos Santos","Department of Computer Science, Universidade Federal de Minas Gerais, Brazil, Belo Horizonte, Minas Gerais; Department of Computer Science, Universidade Federal de Minas Gerais, Brazil, Belo Horizonte, Minas Gerais","2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)","5 Dec 2019","2019","","","202","209","Coarse resolution remote sensing images, such as LANDSAT and MODIS are easily found in public open repositories and, therefore, are widely used in many studies. But their use for automatic creation of thematic maps is very restrict since most of the deep-based semantic segmentation (a.k.a dense labelling) approaches are only suitable for subdecimeter data. In this paper, we design a straightforward framework in order to evaluate the effectiveness of deep-based super-resolution in the semantic segmentation of low-resolution remote sensing images. We carried out an extensive set of experiments on three remote sensing datasets with distinct nature/properties. The results show that super-resolution is effective to improve semantic segmentation performance on low-resolution aerial imagery. It not only outperforms unsupervised interpolation but also achieves semantic segmentation results comparable to high-resolution data.","2377-5416","978-1-7281-5227-1","10.1109/SIBGRAPI.2019.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8919823","super resolution, semantic segmentation, remote sensing","Image segmentation;Semantics;Remote sensing;Task analysis;Satellites;Spatial resolution","geophysical image processing;image resolution;image segmentation;remote sensing","dense labelling;coarse resolution imagery;coarse resolution remote sensing images;public open repositories;thematic maps;deep-based semantic segmentation;low-resolution remote sensing images;low-resolution aerial imagery;high-resolution data","","4","","23","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Visible-Assisted Infrared Image Super-Resolution Based on Spatial Attention Residual Network","X. Yang; M. Zhang; W. Li; R. Tao","School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China","IEEE Geoscience and Remote Sensing Letters","30 Dec 2021","2022","19","","1","5","Infrared images have a wide range of applications in military and civilian fields, including night vision, surveillance, and robotics. However, the most commonly used infrared images are low-resolution (LR), which lack texture details, and existing infrared image super-resolution (SR) algorithms are limited by the lack of spatial information utilization. To solve the above problems, a spatial attention residual network (SAResNet) is proposed. Specifically, the network consists of spatial attention residual block (SARB) with several short skip connections (SSCs). The SARB contains 20 spatial attention blocks (SAB), which adaptively adjusts weights of different spatial regions by considering interdependence between spatial features. Meanwhile, the visible images are considered as complementary sources; thus, a visible-assisted training strategy is designed for the infrared SR process, promoting details preservation. Furthermore, the spatial attention (SA) mechanism is utilized, which focuses more on spatial characteristics of the image and refines the main objects and target boundaries. Experimentally, the proposed method, SAResNet, is compared with existing SR methods, and the effectiveness of the proposed method is demonstrated based on both quantity and quality analyses.","1558-0571","","10.1109/LGRS.2021.3100061","National Natural Science Foundation of China(grant numbers:62001023,U1833203); Beijing Natural Science and Foundation(grant numbers:JQ20021,L191004); China Postdoctoral Science Foundation(grant numbers:BX20200058,2020M670163); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9509280","Infrared image;residual network (ResNet);spatial attention (SA);super-resolution (SR)","Feature extraction;Training;Convolution;Residual neural networks;Superresolution;Optical distortion;Load modeling","image resolution;image texture;infrared imaging;neural nets","spatial attention residual network;military fields;civilian fields;lack texture details;spatial information utilization;spatial attention residual block;spatial regions;spatial features;visible images;visible-assisted training strategy;infrared SR process;spatial attention mechanism;spatial characteristics;infrared image super-resolution algorithms","","2","","27","IEEE","9 Aug 2021","","","IEEE","IEEE Journals"
"Physics-Informed Hyperspectral Remote Sensing Image Synthesis With Deep Conditional Generative Adversarial Networks","L. Liu; W. Li; Z. Shi; Z. Zou","State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; Department of Guidance, Navigation and Control, School of Astronautics, Beihang University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","18 May 2022","2022","60","","1","15","High-resolution hyperspectral remote sensing images are of great significance to agricultural, urban, and military applications. However, collecting and labeling hyperspectral images are time-consuming, expensive, and usually heavily rely on domain knowledge. In this article, we propose a new method for generating high-resolution hyperspectral images and subpixel ground-truth annotations from RGB images. Given a single high-resolution RGB image as its conditional input, unlike previous methods that directly predict spectral reflectance and ignores the physics behind it, we consider both imaging mechanism and spectral mixing, introduce a deep generative network that first recovers the spectral abundance for each pixel, and then generate the final spectral data cube with the standard USGS spectral library. In this way, our method not only synthesizes high-quality spectral data existing in the real world but also generates subpixel-level spectral abundance with well-defined spectral reflectance characteristics. We also introduce a spatial discriminative network and a spectral discriminative network to improve the fidelity of the synthetic output from both spatial and spectral perspectives. The whole framework can be trained end-to-end in an adversarial training paradigm. We refer to our method as “Physics-informed Deep Adversarial Spectral Synthesis (PDASS).” On the IEEE grss_dfc_2018 dataset, our method achieves an MPSNR of 47.56 on spectral reconstruction accuracy and outperforms other state-of-the-art methods. As latent variables, the generated spectral abundance and the atmospheric absorption coefficients of sunlight also suggest the effectiveness of our method.","1558-0644","","10.1109/TGRS.2022.3173532","National Natural Science Foundation of China(grant numbers:62125102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9770778","Generation adversarial networks (GANs);hyperspectral image;imaging model;remote sensing;spectral super-resolution (SSR)","Hyperspectral imaging;Superresolution;Atmospheric modeling;Image reconstruction;Absorption;Spatial resolution;Libraries","geophysical image processing;geophysical signal processing;hyperspectral imaging;image classification;image colour analysis;image reconstruction;image resolution;remote sensing;spectral analysis","Physics-informed hyperspectral remote sensing image synthesis;deep conditional generative adversarial networks;high-resolution hyperspectral remote sensing images;agricultural applications;urban, applications;military applications;high-resolution hyperspectral images;subpixel ground-truth annotations;RGB images;single high-resolution RGB image;conditional input;imaging mechanism;spectral mixing;deep generative network;final spectral data cube;standard USGS spectral library;high-quality spectral data;subpixel-level spectral abundance;well-defined spectral reflectance characteristics;spatial discriminative network;spectral discriminative network;spatial perspectives;spectral perspectives;adversarial training paradigm;Physics-informed Deep Adversarial Spectral Synthesis;spectral reconstruction accuracy;generated spectral abundance","","1","","79","IEEE","9 May 2022","","","IEEE","IEEE Journals"
"Hyperspectral Image Super-Resolution by Spectral Mixture Analysis and Spatial–Spectral Group Sparsity","J. Li; Q. Yuan; H. Shen; X. Meng; L. Zhang","International School of Software, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Resource and Environmental Sciences, Wuhan University, Wuhan, China; School of Resource and Environmental Sciences, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","19 May 2017","2016","13","9","1250","1254","Due to the limitation of hyperspectral sensors and optical imaging systems, there are several irreconcilable conflicts between high spatial resolution and high spectral resolution of hyperspectral images (HSIs). Therefore, HSI super-resolution (SR) is regarded as an important preprocessing task for subsequent applications. In this letter, we use sparse representation to analyze the spectral and spatial feature of HSIs. Considering the sparse characteristic of spectral unmixing and high pattern repeatability of spatial-spectral blocks, we proposed a novel HSI SR framework utilizing spectral mixture analysis and spatial-spectral group sparsity. By simultaneously combining the sparsity and the nonlocal self-similarity of the images in the spatial and spectral domains, the method not only maintains the spectral consistency but also produces plenty of image details. Experiments on three hyperspectral data sets confirm that the proposed method is robust to noise and achieves better results than traditional methods.","1558-0571","","10.1109/LGRS.2016.2579661","National Natural Science Foundation of China(grant numbers:41401383,41422108); Hong Kong Scholars Program(grant numbers:XJ2014009); Cross-Disciplinary Collaborative Teams Program for Science, Technology and Innovation of the Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7517322","Hyperspectral image (HSI);sparse representation;super-resolution (SR)","Image reconstruction;Spatial resolution;Dictionaries;Spectral analysis;Hyperspectral sensors;Sparse matrices","geophysical image processing;geophysical techniques;hyperspectral imaging;remote sensing","hyperspectral image super-resolution;spectral mixture analysis;spatial-spectral group sparsity;hyperspectral sensor limitation;optical imaging systems;HSI super-resolution;HSI spectral feature;HSI spatial feature;spectral unmixing characteristic;spatial-spectral blocks;traditional methods","","58","","22","IEEE","20 Jul 2016","","","IEEE","IEEE Journals"
"Snow water equivalent monitoring from dual-frequency scatterometer on WCOM","J. Shi; X. Dong; D. Zhu; C. Xiong; G. Wang; L. Liu; Y. Cui","Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; The CAS Key Laboratory of Microwave Remote Sensing, CAS, Beijing, China; The CAS Key Laboratory of Microwave Remote Sensing, CAS, Beijing, China; Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; The CAS Key Laboratory of Microwave Remote Sensing, CAS, Beijing, China; The CAS Key Laboratory of Microwave Remote Sensing, CAS, Beijing, China; Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","1359","1362","Water Cycle Observation Mission (WCOM) is a mission dedicated to synergetic observations of global water cycle parameters, with emphasis on soil moisture, ocean surface salinity, snow water equivalent and frozen/thaw. WCOM implements its observation requirements by measurement of microwave emission/scattering of both the frequencies sensitive to the key parameters and also the auxiliary frequencies providing necessary atmospheric and surface roughness corrections. In order to satisfy this measurement requirements, WCOM is equipped with payloads with combination of active and passive microwave sounding capabilities of frequency from L-band to W-band. Dual Frequency Polarized Scatterometer (DFPSCAT) is one of the three payloads onboard the satellite of Water Cycle Observation Mission (WCOM). DFPSCAT is an X/Ku band rotating pencil beam scatterometer with 2-5 km resolution and 1000km swath for mapping of snow water equivalent (SWE) and freeze-thaw process. DFPSCAT achieves fine resolution by linear frequency modulation pulse compression along the elevation direction, and by unfocused synthetic aperture processing (a technique where the Doppler effect is exploited to synthesize a longer aperture to achieve an improved resolution), as well as super-resolution reconstruction by oversampling in the direction of the azimuth. Based on the payloads of WCOM mission, especially with X/Ku scatterometer and L/Ku/Ka radiometer active/passive observations, there are obvious advantages in snow water equivalent retrieval. The atmospheric correction of active and passive data should be performed before the retrieval. The estimation of SWE mainly rely on the high resolution X and Ku band scatterometer, and combined active/passive retrieval can provide more reliable SWE product. The retrieval method of SWE from X/Ku scatterometer is described, and combined active/passive retrieval is also briefly described.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127214","water cycle;satellite mission;radar;snow water equivalent;snow wetness","Radar measurements;Indexes","atmospheric measuring apparatus;atmospheric techniques;hydrological techniques;image resolution;oceanographic techniques;radiometers;radiometry;remote sensing;remote sensing by radar;snow;spaceborne radar;synthetic aperture radar;wind","DFPSCAT;linear frequency modulation pulse compression;WCOM mission;snow water equivalent retrieval;snow water equivalent monitoring;dual-frequency scatterometer;ocean surface salinity;microwave scattering;active microwave measurement;passive microwave measurement;water cycle observation mission;Ku band rotating pencil beam scatterometer;X band rotating pencil beam scatterometer;Ku scatterometer;X scatterometer;radiometer passive observation;radiometer active observation;dual frequency polarized scatterometer;atmospheric surface roughness correction;global water cycle parameter;synergetic observation;passive retrieval","","","","4","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Parallax Estimation for Push-Frame Satellite Imagery: Application to Super-Resolution and 3D Surface Modeling from Skysat Products","J. Anger; T. Ehret; G. Facciolo","Kayrros SAS; Université Paris-Saclay, CNRS, ENS Paris-Saclay, Centre Borelli, France; Université Paris-Saclay, CNRS, ENS Paris-Saclay, Centre Borelli, France","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2679","2682","Recent constellations of satellites, including the Skysat constellation, are able to acquire burst of images. This new acquisition mode allows for modern image restoration techniques, including multi-frame super-resolution. As the satellite moves during the acquisition of the burst, elevation changes in the scene translate into noticeable parallax. This parallax hinders the results of the restoration. To cope with this issue, we propose a novel parallax estimation method. The method is composed of a linear $\text{Plane}+\text{Parallax}$ decomposition of the apparent motion and a multi-frame optical flow algorithm that exploits all frames simultaneously. Using SkySat L1A images, we show that the estimated per-pixel displacements are important for applying multi-frame super-resolution on scenes containing elevation changes and that can also be used to estimate a coarse 3D surface model.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554340","Office of Naval research(grant numbers:N00014-17-1-2552); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554340","multi-frame optical flow;parallax estimation;super-resolution;3d reconstruction","Solid modeling;Three-dimensional displays;Satellites;Superresolution;Estimation;Geoscience and remote sensing;Image restoration","","","","2","","11","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Missing data super-resolution using non-local and statistical priors","R. Fablet; F. Rousseau","Institut Mines-Telecom/Telecom Bretagne;, UMR 6285 LabSTICC Technopole Brest Iroise, Brest, France; Institut Mines-Telecom/Telecom Bretagne;, UMR 6285 LabSTICC Technopole Brest Iroise, Brest, France","2015 IEEE International Conference on Image Processing (ICIP)","10 Dec 2015","2015","","","676","680","We here address the super-resolution of a high-resolution image involving missing data given that a low-resolution image of the same scene is available. This is a typical issue in the remote sensing of geophysical parameters from different spaceborne sensors. Such super-resolution application involves large downscaling factor (typically from 10 to 20) and the super-resolution model should account for both texture patterns and specific statistical features, especially the spectral and non-Gaussian features. In this context, we propose a novel non-local approach and formally states the solution as the joint minimization of several projection constraints. We illustrate the relevance of the proposed model on real ocean remote sensing data, namely sea surface temperature fields, as well on visual textures.","","978-1-4799-8339-1","10.1109/ICIP.2015.7350884","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350884","super-resolution;inpainting;non-local regularisation;non-Gaussian fields;spectral properties;geophysical fields;ocean remote sensing","Spatial resolution;Image reconstruction;Data models;Sensors;Minimization;Oceans","Gaussian processes;image resolution;image texture;statistical analysis","missing data super-resolution;nonlocal priors;statistical priors;high-resolution image;low-resolution image;spectral features;non-Gaussian features;visual textures","","7","","13","IEEE","10 Dec 2015","","","IEEE","IEEE Conferences"
"Mitigating Spatial and Spectral Differences for Change Detection Using Super-Resolution and Unsupervised Learning","J. Prexl; S. Saha; X. X. Zhu","Data Science in Earth Observation, Technical University of Munich, Taufkirchen/Ottobrunn, Germany; Data Science in Earth Observation, Technical University of Munich, Taufkirchen/Ottobrunn, Germany; Remote Sensing Technology Institute, German Aerospace Center (DLR), Weßling, Germany","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3113","3116","Change detection (CD) is one of the most researched areas in remote sensing. However, most CD methods assume that the pre-change and post-change images are acquired by the same sensor, having the same set of spectral bands and same spatial resolution. This severely limits the applicability of CD methods. It is not trivial to apply the existing CD methods in multisensor scenario. Towards this direction, we propose an unsupervised CD method that can handle large differences in spatial resolution and can work with completely different set of spectral bands. The proposed method uses a self-supervised super-resolution strategy to upsample the lower resolution image, thus mitigating differences in spatial resolution. To mitigate spectral differences, a self-supervised learning strategy is used that ingests both images as input and trains a network using self-supervised loss accounting for the spectral differences in both images. Once trained this network is used in deep change vector analysis framework for change detection. We validated the proposed method in an experimental setup where the pre-change and post-change images have different spatial resolution (10m and 20 m/pixel) and completely disjoint set of spectral bands.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554789","Change detection;Multisensor images;Multi-spatial resolution;Deep Change Vector Analysis;Deep learning","Superresolution;Urban areas;Time series analysis;Spatial resolution;Unsupervised learning;Remote sensing","","","","1","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Integrating Object Boundary in Super-Resolution Land-Cover Mapping","Y. Chen; Y. Ge; Y. Jia","State Key Laboratory of Resources and Environmental Information System, Institute of Geographical Sciences and Natural Resources Research, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Resources and Environmental Information System, Institute of Geographical Sciences and Natural Resources Research, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Resources and Environmental Information System, Institute of Geographical Sciences and Natural Resources Research, University of Chinese Academy of Sciences, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20 May 2017","2017","10","1","219","230","This paper proposes a novel class allocation strategy in units of object (UOO) for soft-then-hard super-resolution mapping (STHSRM). STHSRM involves two processes: 1) subpixel sharpening and 2) class allocation. The UOO is implemented in the second process by integrating the object boundaries as an additional structural constraint. First, UOO obtains the object boundaries from remote-sensing images by image segmentation. The number of subpixels within an object is then calculated for each class to meet the coherence constraint of fractional images imposed by soft classification. Finally, a linear optimization model is built for each object to obtain the optimal hard class labels of subpixels. A synthetic image and two real remote-sensing images are used to evaluate the effectiveness of UOO. The results are compared visually and quantitatively with two existing class allocation methods: 1) the highest attribute values first (HAVF) and 2) units of class (UOC). The experimental results show that UOO performs better than these two methods. UOO can better reduce the salt and pepper effect in resultant maps than both HAVF and UOC when dealing with real remote-sensing images. Moreover, UOO can better maintain the structure of land-cover patches, with smoother boundaries as compared with the two methods.","2151-1535","","10.1109/JSTARS.2016.2533571","National Natural Science Foundation of China(grant numbers:41471296); Key Technologies Research and Development Program of China(grant numbers:2012BAH33B01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7433947","Land cover;object boundary;remotely sensed imagery;super-resolution mapping (SRM)","Resource management;Remote sensing;Image segmentation;Spatial resolution;Prediction algorithms;Software algorithms","land cover","super-resolution land-cover mapping;soft-then-hard super-resolution mapping;STHSRM;remote-sensing images;image segmentation;linear optimization model;land-cover patches","","17","","51","IEEE","15 Mar 2016","","","IEEE","IEEE Journals"
"Sar Super-Resolution Using Physics-Aware Adaptive Compressed Sensing","S. Guha; M. Datcu; J. Ender",Fraunhofer Institute for High Frequency Physics and Radar Techniques (FHR); German Aerospace Center (DLR); Fraunhofer Institute for High Frequency Physics and Radar Techniques (FHR),"IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","52","55","The resolution requirements of modern radar applications are increasing rapidly and cannot be fulfilled by the limited number of wide-band radar systems. Many approaches have been explored to solve this problem under the topic of super-resolution. In this paper, we propose a hybrid algorithm for resolution improvement, where we aim to combine the adaptability of deep neural networks with the reliability and expertise of traditional domain-specific SAR processing.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884535","ISTA;Learned ISTA;Approximated Observation;SAR Super-resolution;High resolution radar;Algorithm Unrolling;Hybrid Approaches to Super-resolution","Deep learning;Adaptive systems;Superresolution;Neural networks;Approximation algorithms;Radar polarimetry;Reliability","image resolution;neural nets;object detection;radar imaging;radar resolution;synthetic aperture radar","resolution improvement;adaptability;deep neural networks;traditional domain-specific SAR processing;sar super-resolution;physics-aware;resolution requirements;modern radar applications;wide-band radar systems;hybrid algorithm","","","","11","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Simultaneously Azimuth-Pitch Super-Resolution Imaging for Ground-to-Air Radar","Q. Zhang; Y. Zhang; Y. Zhang; Y. Huang; J. Yang","University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5759","5762","The echo received by ground-to-air radar is a range-azimuth-pitch three-dimensional data. After pulse compression, the data of each range unit can be regarded as an azimuth-pitch two-dimensional (2D) echo. The resolution of azimuth and pitch is limited to antenna aperture. In this paper, the well-known Wiener filtering, Richardson-Lucy (RL) and total variation (TV) methods are introduced to simultaneously improve the azimuth-pitch resolution of ground-to-air radar. We first analyze the received signal of ground-to-air-radar, and model the echo of each range unit as a 2D convolution of target reflectivity distribution and azimuth-pitch antenna pattern. Then we deduce the Wiener filter, RL and TV methods in detail, and theoretically realize the super-resolution imaging of the azimuth and pitch. Finally, the super-resolution performance of different methods is verified by simulation.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553946","National Natural Science Foundation of China(grant numbers:61901090,61901092,61671117); China Post-Doctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553946","Ground-to-air radar;super-resolution;Wiener filtering;Richardson-Lucy;total variation","Wiener filters;TV;Azimuth;Superresolution;Two dimensional displays;Imaging;Radar","convolution;filtering theory;image reconstruction;image resolution;image restoration;Wiener filters","azimuth-pitch super-resolution imaging;ground-to-air radar;echo;range-azimuth-pitch;three-dimensional data;range unit;azimuth-pitch two-dimensional;Wiener filtering;azimuth-pitch resolution;ground-to-air-radar;azimuth-pitch antenna pattern;Wiener filter;super-resolution performance","","","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A Super-Resolution Imaging Method for Real-Aperture Scanning Radar Based on MRF Prior Model","K. Tan; J. Yang; X. Lu; W. Su; H. Gu","Department of Electronic Engineering, Nanjing University of Science and Technology, Nanjing, China; Department of Electronic Engineering, Nanjing University of Science and Technology, Nanjing, China; Department of Electronic Engineering, Nanjing University of Science and Technology, Nanjing, China; Department of Electronic Engineering, Nanjing University of Science and Technology, Nanjing, China; Department of Electronic Engineering, Nanjing University of Science and Technology, Nanjing, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5079","5082","Deconvolution technology can be utilized to improve the angular resolution of real-aperture scanning radar (RASR) with high efficiency and low cost. However, it is an ill-posed problem and the solution is sensitive to noise. Regularization methods are considered to be efficient ways to ease the noise sensitivity by absorbing the prior information into the objective function. In this paper, we propose a new super-resolution imaging method for RASA based on the Markov random field (MRF). Compared with the published angular super-resolution methods for RASA, the proposed method takes advantage of the two-dimensional spatial prior information and can recover the shape of scene much better. Simulations are carried out to demonstrate the effectiveness of the proposed method.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553280","National Natural Science Foundation of China(grant numbers:62001229,61801221); China Postdoctoral Science Foundation(grant numbers:2020M681604); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553280","Real-aperture scanning radar;super-resolution;regularization method;Markov prior model","Sensitivity;Deconvolution;Shape;Simulation;Superresolution;Imaging;Radar","deconvolution;image reconstruction;image resolution;Markov processes;maximum likelihood estimation;radar imaging","super-resolution imaging method;real-aperture scanning radar;MRF;deconvolution technology;angular resolution;regularization methods;noise sensitivity;published angular super-resolution methods;two-dimensional spatial prior information","","","","12","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Super-resolution reconstruction of hyperspectral imagery using an spectral unmixing based representational model","X. Sun; L. Xu; L. Yang; Y. Chen; Y. Fang; J. Peng","School of Land Science and Technology, China University of Geosciences, Beijing; School of Land Science and Technology, China University of Geosciences, Beijing; School of Land Science and Technology, China University of Geosciences, Beijing; School of Land Science and Technology, China University of Geosciences, Beijing; School of Land Science and Technology, China University of Geosciences, Beijing; School of Land Science and Technology, China University of Geosciences, Beijing","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","1607","1610","Efficient super-resolution of hyperspectral images (HSI) relies on the representational model (RM) that is capable of capturing the spatial and spectral correlation in hyperspectral images. In this paper, the spectral information in hyperspectral images is explained by linear spectral mixture model (LSMM), which expressed the observed pixels as a linear combination of endmembers, and the spatial information is captured by a spatial auto-regression model. The two component is combined in the maximum likelihood estimation (MLE) framework and solved by the expectation and maximization (EM) algorithm. Experiments on both simulated and real hyperspectral images demonstrate that the proposed method is not only capable of providing an accurate and effective super-resolution reconstruction of the image, but also capable of resisting the influence of noise.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729410","Super resolution;Hyperspectral images;Intrinsic representation;Spectral unmixing","Spatial resolution;Image reconstruction;Hyperspectral imaging;Biological system modeling;Adaptation models;Optimization","geophysical image processing;hyperspectral imaging;image resolution;maximum likelihood estimation;regression analysis","super-resolution reconstruction;spectral unmixing based representational model;hyperspectral image super-resolution;spatial correlation;spectral correlation;linear spectral mixture model;endmembers;spatial information;spatial autoregression model;maximum likelihood estimation framework;maximization algorithm;real hyperspectral images","","","","15","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Single Space Object Image Denoising and Super Resolution Reconstructing based on Unpaired images","E. Chen; X. Feng","Photoelectric Tracking Space Precision Measurement Laboratory Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an, China; Joint Laboratory for Ocean Observation and Detection(Xi'an Institute of Optics and Precision Mechanics), Pilot national laboratory for marine science and technology (Qingdao), Qingdao, China","2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)","3 Aug 2022","2022","10","","1572","1576","High quality space target image is of great significance for space attack and defense because space exploration missions are becoming more and more important. But high quality images of space object are difficult to obtain due to the large number of cosmic rays in the space environment, as well as the limitations of optical lenses, detectors and transmission links on satellites. Image denoising and super-resolution reconstruction are the most economical and effective methods to solve this problem. This paper presents an unpaired denoising and super-resolution reconstruction method for optical remote sensing images which could obtain the images has higher quality than dataset itself. In order to further improve the quality of optical remote sensing images, high quality natural images are added into the training set, and unpaired image data sets (natural images and optical remote sensing images belong to different fields and cannot correspond one to one) are adopted to complete the training of the whole network by using the idea of unsupervised learning. Through the verification tests of three optical remote sensing image data sets, it can be seen that the method in this paper has reconstructed high quality optical remote sensing images with higher resolution than the dataset itself.","2693-2865","978-1-6654-2207-9","10.1109/ITAIC54216.2022.9836590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9836590","component;dual cycle;generative adversiral network;space object image;unpaired","Training;Superresolution;Noise reduction;Optical computing;Optical fiber networks;Optical imaging;Remote sensing","geophysical image processing;image denoising;image reconstruction;image resolution;remote sensing;unsupervised learning","space target image;space exploration missions;high quality images;space environment;transmission links;high quality natural images;optical remote sensing images;single space object image denoising;space attack and defense","","","","15","IEEE","3 Aug 2022","","","IEEE","IEEE Conferences"
"A Deep Unfolding Method for Satellite Super Resolution","J. Wang; Z. Shao; X. Huang; T. Lu; R. Zhang","State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Department of Geosciences, University of Arkansas, Fayetteville, AR, USA; School of Computer Science and Engineering, Wuhan Institute of Technology, Wuhan, China; Institute of Photogrammetry and Remote Sensing at Chinese Academy of Surveying and Mapping, Beijing, China","IEEE Transactions on Computational Imaging","1 Nov 2022","2022","8","","933","944","Despite that existing deep-learning-based super resolution methods for satellite images have achieved great performance, these methods are generally designed to stack unaccountable and dense modules (i.e., residual blocks and dense blocks) to reach an optimal mapping function between low-resolution and high-resolution patches/images at the expense of computing resources. To address this challenge, we propose a deep unfolding method (LDUM) that includes two major components: 1) the pretreatment network and 2) the unfolding blocks. The main responsibility of the pretreatment network is to generate initial high-resolution images. Further, we model high-resolution images with the prior information, which can be seen as a combination of low-resolution and high-frequency residual images, and solve the optimization problem via the iterative proximal strategy. Specifically, we unfold the iterative process into a deep neural network to refine the reconstructed results, as each layer serves as an iterative step of the proposed optimization model. Thus, the proposed method is able to iteratively generate residual maps and high-resolution images by combining the powerful feature extraction capability of data-driven deep-learning-based methods and the interpretability of traditional model-driven algorithms. Experiments show that the proposed method, featured by its interpretable and lightweight merits, outperforms other state-of-the-art methods from quantitative and qualitative perspectives.","2333-9403","","10.1109/TCI.2022.3210329","National Natural Science Foundation of China(grant numbers:42090012); Guangxi science and technology program(grant numbers:2021AB30019); Jiangxi Province in China(grant numbers:20212ABC03A09); Zhuhai industry university research cooperation project of China(grant numbers:ZH22017001210098PWC); Sichuan Science and Technology Program(grant numbers:2022YFN0031); Hubei Key R&D Plan(grant numbers:2022BAA048); Zhizhuo Research Fund on Spatial-Temporal Artificial Intelligence(grant numbers:ZZJJ202202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9904907","Super resolution;optimization;unfolding;deep learning","Task analysis;Image reconstruction;Optimization;Satellites;Computational modeling;Remote sensing;Degradation","feature extraction;image reconstruction;image resolution;iterative methods;learning (artificial intelligence);neural nets;optimisation","iterative proximal strategy;deep neural network;optimization model;residual maps;deep unfolding method;satellite super resolution;existing deep-learning-based super resolution methods;satellite images;unaccountable modules;dense modules;residual blocks;dense blocks;optimal mapping function;pretreatment network;unfolding blocks;initial high-resolution images;model high-resolution images;high-frequency residual images;optimization problem","","","","76","IEEE","28 Sep 2022","","","IEEE","IEEE Journals"
"Resolution enhancement for hyperspectral images: A super-resolution and fusion approach","C. Kwan; J. H. Choi; S. Chan; J. Zhou; B. Budavari","Signal Processing, Inc., Rockville, MD, USA; Purdue University, West Lafayette, IN, USA; Purdue University, West Lafayette, IN, USA; Google, Inc., Mountain View, CA, USA; Signal Processing, Inc., Rockville, MD, USA","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","19 Jun 2017","2017","","","6180","6184","Many remote sensing applications require a high-resolution hyperspectral image. However, resolutions of most hyperspectral imagers are limited to tens of meters. Existing resolution enhancement techniques either acquire additional multispectral band images or use a pan band image. The former poses hardware challenges, whereas the latter has limited performance. In this paper, we present a new resolution enhancement method that only requires a color image. Our approach integrates two newly developed techniques in the area: (1) A hybrid color mapping algorithm, and (2) A Plug-and-Play algorithm for single image super-resolution. Comprehensive experiments using real hyperspectral images are conducted to validate and evaluate the proposed method.","2379-190X","978-1-5090-4117-6","10.1109/ICASSP.2017.7953344","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953344","Hyperspectral Imaging;Remote Sensing;Hybrid Color Mapping;Plug-and-Play ADMM;Super-resolution","Hyperspectral imaging;Image resolution;Image color analysis;Color;Fuses;Google","hyperspectral imaging;image colour analysis;image enhancement;image fusion;image resolution","single image super-resolution;plug-and-play algorithm;hybrid color mapping algorithm;color image;fusion approach;super-resolution approach;hyperspectral images;resolution enhancement","","24","2","28","IEEE","19 Jun 2017","","","IEEE","IEEE Conferences"
"Rethinking the High Frequency Components in Deep Sub-Pixel Mapping Network","D. He; Y. Zhong; Q. Shi; X. Liu","School of Geography and Planning, Sun Yat-Sen University, Guangzhou, China; Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China; School of Geography and Planning, Sun Yat-Sen University, Guangzhou, China; School of Geography and Planning, Sun Yat-Sen University, Guangzhou, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5366","5369","Deep sub-pixel mapping network (DSMNet) is a state-of-the-art approach in the field of sub-pixel mapping (SPM, also called super resolution mapping), combining deep learning theory, to solve the mixed pixel problem, which is ubiquitous in remote sensing images due to the spatial-resolving limitation. However, traditional DSMNet usually do not consider the multi-scale distribution characteristics of the real geographical distribution exposed in urban landscape. Furthermore, the heterogeneous distribution characteristics (high-frequency components) are the most important for SPM, but are difficult to learn and usually ignored in the tradition network models. In this paper, the high-frequency component aware (HFCA) module was proposed, based on the hierarchical supervised deep sub-pixel mapping network (HiDSMNet). HiDSMNet establishes a hierarchical supervised architecture for explicit multi-scale supervision to prompt the network to learn a multi-scale representation. Besides, HFCA module is integrated to prompt the network to intensify the learning of the high-frequency representation. The experimental results with three public datasets validated the superiority of the proposed HiDSMNet.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553075","National Natural Science Foundation of China(grant numbers:41771385); National Key Research and Development Program of China(grant numbers:2017YFB0504202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553075","Deep sub-pixel mapping network (DSMNet);sub-pixel mapping (SPM);high-frequency components;hierarchical supervised architecture","Deep learning;Architecture;Buildings;High frequency;Spatial resolution;Image reconstruction;Remote sensing","geophysical image processing;image classification;image resolution;learning (artificial intelligence);remote sensing","heterogeneous distribution characteristics;high-frequency components;tradition network models;high-frequency component aware module;hierarchical supervised deep sub-pixel mapping network;explicit multiscale supervision;high-frequency representation;high frequency components;super resolution mapping;deep learning theory;mixed pixel problem;multiscale distribution characteristics","","","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Super-resolution RFI localization with compressive sensing in synthetic aperture interferometric radiometers","J. Li; F. Hu; F. He; L. Wu; X. Peng; Y. Cheng; D. Zhu; K. Chen","School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","4734","4737","An accurate geolocation of the radio frequency interference (RFI) sources is significant to effectively switch off illegal transmitters. In this study, utilizing the sparse property of RFI in the observed scene, a super-resolution RFI localization method based on compressive sensing is presented in synthetic aperture interferometric radiometer (SAIR). Numerical results show the presented method can achieve an super-resolution RFI localization even when there are some missing data due to correlator or receiver failure.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326887","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326887","Compressive sensing;localization;radio frequency interference;super-resolution;synthetic aperture radiometry","Brightness temperature;Spatial resolution;Multiple signal classification;Compressed sensing;Signal resolution;Temperature measurement;Apertures","compressed sensing;geophysical signal processing;radar interferometry;radiometers;remote sensing by radar;synthetic aperture radar","superresolution RFI localization;compressive sensing;radiofrequency interference;RFI source geolocation;RFI sparse property;synthetic aperture interferometric radiometer;SAIR","","11","","10","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Multi-Image Super-Resolution for Remote Sensing using Deep Recurrent Networks","M. Rifat Arefin; V. Michalski; P. -L. St-Charles; A. Kalaitzis; S. Kim; S. E. Kahou; Y. Bengio",Mila - Quebec AI Institute; Mila - Quebec AI Institute; Mila - Quebec AI Institute; Element AI; Lawrence Livermore National Laboratory; Mila - Quebec AI Institute; Mila - Quebec AI Institute,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","816","825","High-resolution satellite imagery is critical for various earth observation applications related to environment monitoring, geoscience, forecasting, and land use analysis. However, the acquisition cost of such high-quality imagery due to the scarcity of providers and needs for high-frequency revisits restricts its accessibility in many fields. In this work, we present a data-driven, multi-image super resolution approach to alleviate these problems. Our approach is based on an end-to-end deep neural network that consists of an encoder, a fusion module, and a decoder. The encoder extracts co-registered highly efficient feature representations from low-resolution images of a scene. A Gated Re-current Unit (GRU)-based module acts as the fusion module, aggregating features into a combined representation. Finally, a decoder reconstructs the super-resolved image. The proposed model is evaluated on the PROBA-V dataset released in a recent competition held by the European Space Agency. Our results show that it performs among the top contenders and offers a new practical solution for real-world applications.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150720","","Image resolution;Image reconstruction;Satellites;Machine learning;Decoding;Remote sensing;Earth","feature extraction;geophysical image processing;image reconstruction;image resolution;recurrent neural nets;remote sensing","super-resolution;remote sensing;deep recurrent networks;high-resolution satellite imagery;earth observation applications;environment monitoring;land use analysis;acquisition cost;high-quality imagery;high-frequency revisits;multiimage super resolution approach;end-to-end deep neural network;encoder;fusion module;decoder;low-resolution images;super-resolved image;gated recurrent unit-based module;coregistered highly efficient feature representations","","6","","49","IEEE","28 Jul 2020","","","IEEE","IEEE Conferences"
"Adaptive Nonnegative Sparse Representation for Hyperspectral Image Super-Resolution","X. Li; Y. Zhang; Z. Ge; G. Cao; H. Shi; P. Fu","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","4 May 2021","2021","14","","4267","4283","As the hyperspectral images (HSIs) usually have a low spatial resolution, HSI super-resolution has recently attracted more and more attention to enhance the spatial resolution of HSIs. A common method is to fuse the low-resolution (LR) HSI with a multispectral image (MSI) whose spatial resolution is higher than the HSI. In this article, we proposed a novel adaptive nonnegative sparse representation-based model to fuse an HSI and its corresponding MSI. First, basing the linear spectral unmixing, the nonnegative structured sparse representation model estimates the sparse codes of the desired high-resolution HSI from both the LR-HSI and the MSI. Then, the adaptive sparse representation can balance the relationship between the sparsity and collaboration by generating a suitable coefficient. Finally, in order to obtain more accurate results, we alternately optimize the spectral basis and coefficients rather than keeping the spectral basis fixed. The alternating direction method of multipliers is applied to solve the proposed optimization problem. The experimental results on both ground-based HSIs and real remote sensing HSIs show the superiority of our proposed approach to some other state-of-the-art HSI super-resolution methods.","2151-1535","","10.1109/JSTARS.2021.3072044","Start Foundation of Nanjing University of Posts and Telecommunications(grant numbers:NY220157); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9399788","Adaptive sparse representation (ASR);hyperspectral image (HSI);spectral basis updating;super-resolution reconstruction","Superresolution;Spatial resolution;Hyperspectral imaging;Sparse matrices;Correlation;Matrix decomposition;Image reconstruction","geophysical image processing;hyperspectral imaging;image enhancement;image reconstruction;image representation;image resolution;image sensors;optimisation;remote sensing","hyperspectral image super-resolution;hyperspectral images;low spatial resolution;low-resolution HSI;multispectral image whose spatial resolution;novel adaptive nonnegative sparse representation-based model;corresponding MSI;linear spectral unmixing;nonnegative structured sparse representation model;sparse codes;high-resolution HSI;LR-HSI;adaptive sparse representation;spectral basis;ground-based HSIs;remote sensing HSIs;state-of-the-art HSI super-resolution methods","","8","","66","CCBY","9 Apr 2021","","","IEEE","IEEE Journals"
"A Fast and Accurate Basis Pursuit Denoising Algorithm With Application to Super-Resolving Tomographic SAR","Y. Shi; X. X. Zhu; W. Yin; R. Bamler","Chair of Remote Sensing Technology, Technical University of Munich, Munich, Germany; Signal Processing in Earth Observation, Technical University of Munich, Munich, Germany; Department of Mathematics, University of California at Los Angeles, Los Angeles, CA, USA; Chair of Remote Sensing Technology, Technical University of Munich, Munich, Germany","IEEE Transactions on Geoscience and Remote Sensing","26 Sep 2018","2018","56","10","6148","6158"," $L_{1}$  regularization is used for finding sparse solutions to an underdetermined linear system. As sparse signals are widely expected in remote sensing, this type of regularization scheme and its extensions have been widely employed in many remote sensing problems, such as image fusion, target detection, image super-resolution, and others, and have led to promising results. However, solving such sparse reconstruction problems is computationally expensive and has limitations in its practical use. In this paper, we proposed a novel efficient algorithm for solving the complex-valued  $L_{1}$  regularized least squares problem. Taking the high-dimensional tomographic synthetic aperture radar (TomoSAR) as a practical example, we carried out extensive experiments, both with the simulation data and the real data, to demonstrate that the proposed approach can retain the accuracy of the second-order methods while dramatically speeding up the processing by one or two orders. Although we have chosen TomoSAR as the example, the proposed method can be generally applied to any spectral estimation problems.","1558-0644","","10.1109/TGRS.2018.2832721","H2020 European Research Council(grant numbers:ERC-2016-StG-714087); Helmholtz Association(grant numbers:VH-NG-1018); Munich Aerospace e.V. Fakultat fur Luft-und Raumfahrt; Bavaria California Technology Center through the project Large-Scale Problems in Earth Observation; Gauss Centre for Supercomputing e.V.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412239","Basis pursuit denoising (BPDN);L₁ regularization;proximal gradient (PG);second-order cone programming (SOCP);TomoSAR","Synthetic aperture radar;Image reconstruction;Image resolution;Signal to noise ratio;Estimation;Remote sensing;Sensors","image denoising;image fusion;image reconstruction;image resolution;least squares approximations;radar imaging;remote sensing by radar;synthetic aperture radar","super-resolving tomographic SAR;underdetermined linear system;sparse signals;remote sensing problems;image fusion;target detection;image super-resolution;sparse reconstruction problems;high-dimensional tomographic synthetic aperture radar;TomoSAR;simulation data;spectral estimation problems;regularized least squares problem","","21","","23","OAPA","17 Jul 2018","","","IEEE","IEEE Journals"
"Infrared Image Super Resolution with Deep Neural Networks","K. Vassilo; T. Taha; A. Mehmood","University of Dayton, Dayton, OH; University of Dayton, Dayton, OH; Air Force Research Laboratory, Wright-Patterson AFB, OH","2021 11th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","19 Jul 2021","2021","","","1","5","Recent studies have shown that Deep Learning (DL) algorithms can significantly improve Super Resolution (SR) performance. Single image SR is useful in producing High Resolution (HR) images from their Low Resolution (LR) counterparts. The motivation for SR is the potential to assist algorithms such as object detection, localization, and classification. Insufficient work has been conducted using Generative Adversarial Networks (GANs) for SR on infrared (IR) images despite its promising ability to increase object detection accuracy by extracting more precise features from a given image. This work adopts the idea of a relativistic GAN that utilizes Residual in Residual Dense blocks (RRDBs) for feature ex- traction, a novel residual image addition, and a Pixel Transposed Convolutional Layer (PixelTCL) for up-sampling. Recent work has validated the use of GANs for Visible Light (VL) images, making them a strong candidate. The inclusion of these components produce more realistic and natural features while also receiving superior metric values.","2158-6276","978-1-6654-3601-4","10.1109/WHISPERS52202.2021.9484045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9484045","Deep Learning;Super Resolution;Generative Adversarial Network;Infrared Imaging","Deep learning;Image resolution;Object detection;Generative adversarial networks;Feature extraction;Generators;Classification algorithms","convolutional neural nets;deep learning (artificial intelligence);image resolution;object detection","residual in residual dense blocks;PixelTCL;VL images;residual image addition;pixel transposed convolutional layer;natural features;realistic features;visible light images;feature extraction;residual dense blocks;relativistic GAN;object detection accuracy;infrared images;GANs;generative adversarial networks;low resolution images;high resolution images;single image SR;super resolution performance;deep neural networks;image super resolution","","","","14","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"Super-Resolution-Guided Progressive Pansharpening Based on a Deep Convolutional Neural Network","J. Cai; B. Huang","Department of Geography and Resource Management, The Chinese University of Hong Kong, Hong Kong; Department of Geography and Resource Management, The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Geoscience and Remote Sensing","21 May 2021","2021","59","6","5206","5220","Pansharpening and super-resolution (SR) methods share the same target to improve the spatial resolution of images. Based on this similarity, we propose and develop a novel pansharpening algorithm that is guided by a deep SR convolutional neural network. The proposed framework comprises three components: an SR process, a progressive pansharpening process, and a high-pass residual module. Specifically, the SR process extracts inner spatial detail that is present in multispectral images. Then, progressive pansharpening is used as a detailed pansharpening process, and the high-pass residual module helps by directly injecting spatial detail from panchromatic images. The performance of the proposed network has been compared with that of traditional and other deep-learning-based pansharpening algorithms based on QuickBird, WorldView-3, and Landsat-8 data, and the results demonstrate the superiority of our algorithm.","1558-0644","","10.1109/TGRS.2020.3015878","Strategic Priority Research Program of the Chinese Academy of Sciences(grant numbers:XDA19090108); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9172104","Deep learning;multispectral (MS) image;panchromatic image;pansharpening;super-resolution (SR)","Spatial resolution;Remote sensing;Neural networks;Dictionaries;Transforms","geophysical image processing;geophysical signal processing;image colour analysis;image fusion;image resolution;learning (artificial intelligence);neural nets;remote sensing;spectral analysis","deep SR convolutional neural network;SR process;progressive pansharpening process;high-pass residual module;multispectral images;detailed pansharpening process;panchromatic images;super-resolution-guided progressive pansharpening;deep convolutional neural network;novel pansharpening algorithm","","34","","49","IEEE","20 Aug 2020","","","IEEE","IEEE Journals"
"Lightweight Stepless Super-Resolution of Remote Sensing Images via Saliency-Aware Dynamic Routing Strategy","H. Wu; N. Ni; L. Zhang","School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","24 Jan 2023","2023","61","","1","17","Deep learning-based algorithms have greatly improved the performance of remote sensing image (RSI) super-resolution (SR). However, increasing network depth and parameters cause a huge burden of computing and storage. Directly reducing the depth or width of existing models results in a large performance drop. We observe that the SR difficulty of different regions in an RSI varies greatly, and existing methods use the same deep network to process all regions in an image, resulting in a waste of computing resources. In addition, existing SR methods generally predefine integer scale factors and cannot perform stepless SR, i.e., a single model can deal with any potential scale factor. Retraining the model on each scale factor wastes considerable computing resources and model storage space. To address the above problems, we propose a saliency-aware dynamic routing network (SalDRN) for lightweight and stepless SR of RSIs. First, we introduce visual saliency as an indicator of region-level SR difficulty and integrate a lightweight saliency detector into the SalDRN to capture pixel-level visual characteristics. Then, we devise a saliency-aware dynamic routing strategy that employs path selection switches to adaptively select feature extraction paths of appropriate depth according to the SR difficulty of subimage patches. Finally, we propose a novel lightweight stepless upsampling module whose core is an implicit feature function for realizing mapping from low-resolution feature space to high-resolution feature space. Comprehensive experiments verify that the SalDRN can achieve a good tradeoff between performance and complexity. The code is available at https://github.com/hanlinwu/SalDRN.","1558-0644","","10.1109/TGRS.2023.3236624","Beijing Natural Science Foundation(grant numbers:4222046); National Natural Science Foundation of China(grant numbers:62271060,61571050,41771407); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10016645","Lightweight;remote sensing;saliency analysis;stepless;super-resolution (SR)","Computational modeling;Feature extraction;Routing;Computational complexity;Task analysis;Superresolution;Interpolation","","","","","","60","IEEE","13 Jan 2023","","","IEEE","IEEE Journals"
"On Training Deep Networks for Satellite Image Super-Resolution","M. Kawulok; S. Piechaczek; K. Hrynczenko; P. Benecki; D. Kostrzewa; J. Nalepa","Future Processing, Gliwice, Poland; Future Processing, Gliwice, Poland; Future Processing, Gliwice, Poland; Future Processing, Gliwice, Poland; Future Processing, Gliwice, Poland; Future Processing, Gliwice, Poland","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3125","3128","The capabilities of super-resolution (SR) reconstruction (i.e., techniques for enhancing image spatial resolution) have been boosted recently by the use of deep convolutional neural networks. For SR, they are learned using huge training sets composed of original images, each of which is coupled with a low-resolution counterpart. In this paper, we explore how the SR performance depends on the procedure employed to obtain the training data. Up to date, this has not been given much attention-commonly, bicubic downsampling is used. Our extensive experimental study indicates that the training data characteristics have a large impact on the reconstruction accuracy, and the widely-adopted approach is not the most effective for dealing with satellite images. Overall, we argue that developing better training data preparation routines may be pivotal in making SR suitable for real-world applications.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899098","Super-resolution reconstruction;deep learning;convolutional neural networks;satellite imaging","Image reconstruction;Satellites;Training;Artificial neural networks;Training data;Degradation","convolutional neural nets;image enhancement;image reconstruction;image resolution;learning (artificial intelligence)","satellite image super-resolution;super-resolution reconstruction;image spatial resolution enhancement;deep convolutional neural networks;huge training sets;low-resolution counterpart;SR performance;training data characteristics;training data preparation routines;SR suitable;deep network training;SR reconstruction","","5","","12","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Super-resolution Reconstruction of hyperspectral images via an improved MAP-based approach","H. Irmak; G. B. Akar; S. E. Yuksel; H. Aytaylan","Aselsan Inc., Ankara, Turkey; Dept. of Electrical and Electronics Eng., Middle East Technical University, Ankara, Turkey; Department of Electrical and Electronics Engineering, Hacettepe University, Ankara, Turkey; Department of Electrical and Electronics Engineering, Hacettepe University, Ankara, Turkey","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","7244","7247","Super-resolution Reconstruction (SRR) is technique to increase the spatial resolution of images. It is especially useful for hyperspectral images (HSI), which have good spectral resolution but low spatial resolution. In this study, we propose an improvement to our previous work and present a novel MAP-MRF (maximum a posteriori-Markov random Fields) based approach for the SRR of HSI. The key point of our approach is to find the abundance maps of an HSI and perform SRR on the abundance maps using MRF based energy minimization, without needing any other additional source of information. In order to do so, first, PCA is used to determine the endmembers. Second, SISAL and fully constraint least squares (FCLS) are used to estimate the abundance maps. Third, in order to find the high resolution abundance maps, the ill-posed inverse SRR problem for abundances is regularized with a MAP-MRF based approach. The MAP-MRF formulation is restricted with the constraints which are specific to the abundances. Using the non-linear programming (NLP) techniques, the convex MAP formulation is minimized and High Resolution (HR) abundance maps are obtained. Then, these maps are used to construct the HR HSI. This improved SRR method is verified on real data sets, and quantitative performance comparison is achieved using PSNR, SSIM and PSNR metrics. Our results indicate that this improved method gives very close results to the original high resolution images, keeps the spectral consistency, and performs better than the compared algorithms.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730889","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730889","Hyperspectral;Super-resolution Reconstruction;MAP-MRF;Non-Linear Programming","Hyperspectral imaging;Spatial resolution;Minimization;Principal component analysis;Measurement","hyperspectral imaging;image reconstruction;image resolution;least squares approximations;Markov processes;nonlinear programming;principal component analysis","super-resolution hyperspectral image reconstruction;improved map-based approach;super-resolution reconstruction;SRR;spatial image resolution;HSI;MAP-MRF based approach;maximum a posteriori-Markov random fields;MRF based energy minimization;SISAL;fully constraint least squares;FCLS;ill-posed inverse SRR problem;nonlinear programming techniques;NLP techniques;convex MAP formulation;high resolution abundance maps;SSIM metrics;PSNR metrics","","3","","18","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Multi-Losses Function Based Convolution Neural Network for Single Hyperspectral Image Super-Resolution","K. Zheng; L. Gao; B. Zhang; X. Cui","College of Geoscience and Surveying Engineering, China University of Mining and Technology (Beijing), Beijing, China; College of Geoscience and Surveying Engineering, China University of Mining and Technology (Beijing), Beijing, China; College of Geoscience and Surveying Engineering, China University of Mining and Technology (Beijing), Beijing, China; College of Geoscience and Surveying Engineering, China University of Mining and Technology (Beijing), Beijing, China","2018 Fifth International Workshop on Earth Observation and Remote Sensing Applications (EORSA)","3 Jan 2019","2018","","","1","4","Recently deep convolutional neural network (CNN) has made significant achievement in Single Image Super-Resolution (SISR). Most CNN-based SISR methods used the default L2 norm of the error. However, for Hyperspectral Image (HSI), this loss function may bring spectral inconsistencies. The main reason is that most methods did not pay much attention to spectral loss. To HSI, the loss function should capture not only spatial information but also spectral consistency. In this paper, a Multi-Losses Function Network (MLFN) simultaneously considering spatial and spectral information is proposed, and is composed of two parts: one is Concatenate Dense Residual Network (CDRN), and the other is Loss Network (LN). CDRN is an image reconstruction network which can utilize the hierarchical features extracted from the low-resolution image. LN includes pixel-wise spatial loss and spectral loss which drive the learning of the entire reconstruction model. The experimental results prove that the proposed MLFN can enhance spatial resolution with the consistency of the spectrum of HSI preserved.","","978-1-5386-6642-5","10.1109/EORSA.2018.8598551","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598551","Hyperspectral Image;Super-Resolution;Deep Learning;Spectral Consistency","Feature extraction;Spatial resolution;Image reconstruction;Convolution;Hyperspectral imaging;Training","feature extraction;feedforward neural nets;geophysical image processing;image reconstruction;image resolution;image sensors;learning (artificial intelligence)","deep convolutional neural network;significant achievement;Single Image Super-Resolution;CNN-based SISR methods;default L2 norm;HSI;loss function;spectral inconsistencies;spectral loss;spatial information;spectral consistency;spectral information;image reconstruction network;low-resolution image;pixel-wise spatial loss;spatial resolution;single hyperspectral image super-resolution;concatenate dense residual network;loss network;multiloss function network;multiloss function-based convolution neural Network","","2","","9","IEEE","3 Jan 2019","","","IEEE","IEEE Conferences"
"A spatial constraint and deep learning based hyperspectral image super-resolution method","J. Hu; Y. Li; X. Zhao; W. Xie","Joint Laboratory of High Speed Multi-source Image Coding and Processing, Xidian University, Xian, China; Joint Laboratory of High Speed Multi-source Image Coding and Processing, Xidian University, Xian, China; Joint Laboratory of High Speed Multi-source Image Coding and Processing, Xidian University, Xian, China; Joint Laboratory of High Speed Multi-source Image Coding and Processing, Xidian University, Xian, China","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","5129","5132","The image super-resolution (SR) technique, which aims at reconstructing a high-resolution (HR) image from a single low-resolution (LR) image, is a classical problem in computer vision. Limited by the imaging hardware, the spatial resolution of a hyperspectral images (HSI) is usually very coarse. Meanwhile, the spectral information of the HSI is extremely important for its applications and cannot be severely distorted. This paper presents a spatial constraint (SCT) strategy with combination of a deep learning method for HSI SR. The SCT strategy restraints the LR HSI generated by the reconstructed HR HSI should be spatially close to the input LR HSI. The deep learning method learns an end-to-end mapping between the spectral difference of the LR HSI and that of the HR HSI. The mapping is represented as a deep convolutional neural network (CNN). The CNN learned spectral difference is utilized to super-resolve the LR HSI while preserve the important spectral information of the desired HR HSI. Experiments have been conducted on three databases that contains both indoor scenes and outdoor scenes. Comparative analyses have verified the effectiveness of the overall method.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8128157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128157","super-resolution;hyperspectral image;convolutional neural network;spectral information","Image reconstruction;Spatial resolution;Databases;Machine learning;Hyperspectral imaging;Signal resolution","computer vision;convolution;hyperspectral imaging;image reconstruction;image representation;image resolution;learning (artificial intelligence);neural nets","spectral information;HR image;LR HSI;SCT strategy;CNN;computer vision;low-resolution image;high-resolution image;image super-resolution technique;hyperspectral image super-resolution method;deep convolutional neural network;HR HSI;spectral difference;end-to-end mapping;HSI SR;deep learning method;spatial constraint strategy;hyperspectral images;spatial resolution;imaging hardware","","2","","13","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Optimization of Antenna Rotation Speed and Super-Resolution Imaging Based on Split Bregman Algorithm for circular Scan ISAR Systems","Y. Zhu; P. Zhou; Z. Zhang; Y. Wang; X. Zhang","College of Oceanography and Space Informatics, China University of Petroleum, Qingdao, China; College of Oceanography and Space Informatics, China University of Petroleum, Qingdao, China; Beijing Research Institute of Telemetry, Beijing, China; Beijing Research Institute of Telemetry, Beijing, China; First Institute of Oceanography, Ministry of Natural Resources, Qingdao, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5083","5086","Regarding the imaging of circular scan inverse synthetic aperture radar (ISAR), the rapid circular scan of the antenna expands the beam coverage area. However, how to determine the rotation speed of the antenna is still a difficult problem. This paper proposes an antenna speed optimization model to quantify the antenna rotation speed. Under the constraints of the beam coverage area per second and the accumulated signal-to-noise ratio (SNR), the value of azimuth resolution is minimized. In addition, to improve the resolution of the image, the split Bregman algorithm is also introduced. This algorithm solves the problem that the azimuth resolution is still lower than the traditional ISAR after the antenna rotation speed is optimized. By optimizing the antenna rotation speed and processing data by the split Bregman algorithm, a super-resolution ISAR image is obtained. The simulation results verify the effectiveness of the method.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553823","National Key Research and Development Program of China(grant numbers:2017YFC1405600,ZR2019MF004); Shandong Provincial Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553823","Circular scan ISAR system;ISAR imaging;antenna rotation speed optimization;split Bregman algorithm;super-resolution imaging","Azimuth;Simulation;Superresolution;Imaging;Radar imaging;Radar antennas;Antennas","image resolution;radar imaging;synthetic aperture radar","super-resolution ISAR image;antenna rotation speed;super-resolution imaging;split Bregman algorithm;circular scan ISAR systems;circular scan inverse synthetic aperture radar;rapid circular scan;beam coverage area;antenna speed optimization model;azimuth resolution","","","","8","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A Multi-Looking Approach for Spatial Super-Resolution on Laboratory-Based Hyperspectral Images","D. C. Zanotta; A. M. Júnior; A. S. Aires; F. Bordin; G. Racolte; J. G. Motta; L. Kupssinskü; M. Muller; R. K. Horota; T. T. Guimarães; V. Sales; C. L. Cazarin; L. Gonzaga; M. R. Veronez","Vizlab - X-Reality and GeoInformatics Lab, UNISINOS, São Leopoldo, RS, Brazil; Graduate Program in Applied Computing at Vale do Rio dos Sinos University, São Leopoldo, RS, Brazil; Graduate Program in Applied Computing at Vale do Rio dos Sinos University, São Leopoldo, RS, Brazil; Vizlab - X-Reality and GeoInformatics Lab, UNISINOS, São Leopoldo, RS, Brazil; Graduate Program in Applied Computing at Vale do Rio dos Sinos University, São Leopoldo, RS, Brazil; Vizlab - X-Reality and GeoInformatics Lab, UNISINOS, São Leopoldo, RS, Brazil; Graduate Program in Applied Computing at Vale do Rio dos Sinos University, São Leopoldo, RS, Brazil; Graduate Program in Applied Computing at Vale do Rio dos Sinos University, São Leopoldo, RS, Brazil; Vizlab - X-Reality and GeoInformatics Lab, UNISINOS, São Leopoldo, RS, Brazil; Graduate Program in Applied Computing at Vale do Rio dos Sinos University, São Leopoldo, RS, Brazil; Vizlab - X-Reality and GeoInformatics Lab, UNISINOS, São Leopoldo, RS, Brazil; CENPES - PETROBRAS, Rio de Janeiro, Brazil; Graduate Program in Applied Computing at Vale do Rio dos Sinos University, São Leopoldo, RS, Brazil; Graduate Program in Applied Computing at Vale do Rio dos Sinos University, São Leopoldo, RS, Brazil","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3869","3872","Very high spatial resolution data seems to reach its maximum for orbital images due to unavoidable atmospheric interactions. At the same time, special hyperspectral cameras are being developed to operate on-board manned or unmanned aircrafts at a fixed optics, which prevents its using for imaging near objects in laboratory conditions. Both limitations can only be surpassed by using super-resolution principles. In this paper, we present a multi-looking approach for enhancing the spatial resolution of images acquired by systems that exhausted their natural ability to provide finer images. The method exploits multiple image takes with controlled spatial differences to produce a higher resolution output. Experiments with static hyperspectral sensor and synthetic data have proven the approach is sound and robust to many applications (e.g., rock samples).","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554164","Petróleo Brasileiro S.A. (PETROBRAS); Agência Nacional do Petróleo, Gás Natural e Biocombustíveis (ANP)(grant numbers:4600556376,4600583791); Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES)(grant numbers:001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554164","Hyperspectral data;spectral mixing;super-resolution;spatial enhancing","Visualization;Superresolution;Rocks;Robustness;Orbits;Spatial resolution;Tuning","cameras;geophysical image processing;hyperspectral imaging;image resolution","multilooking approach;spatial super-resolution;laboratory-based hyperspectral;high spatial resolution data;orbital images;unavoidable atmospheric interactions;special hyperspectral cameras;on-board manned;unmanned aircrafts;fixed optics;laboratory conditions;synthetic data;static hyperspectral sensor;higher resolution output;controlled spatial differences;multiple image;finer images;super-resolution principles","","","","5","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Cross-Modality Super-Resolution of Satellite Gravity Data for Geophysical Exploration","O. Alaofin; Y. Zhang; J. Sharma; X. Li",Louisiana State University; Louisiana State University; Louisiana State University; Louisiana State University,"IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","7539","7542","Gravity surveys have played an essential role in many geoscience fields, especially as an early screening tool for subsurface hydrocarbon exploration. Since land-based gravity surveys are often expensive and difficult to obtain in remote places, we explore the use of satellite-derived gravity data which is available throughout the Earth and updated periodically. Since the accuracy and resolution of the gravity measured from satellites are lower than land-based gravity measurements, the satellite-based data was enhanced through a deep-learning-based super-resolution (SR) technique. The SR-enhanced Bouguer and free-air gravity anomaly data were used for the classification of hydrocarbon regions using supervised machine learning. Results indicate the successful application of supervised machine learning for hydrocarbon classification using SR-enhanced Bouguer and free-air gravity anomalies with high prediction accuracy.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883035","Bouguer gravity;free-air gravity;super-resolution;Random Forest;hydrocarbon exploration","Earth;Satellites;Superresolution;Geophysical measurements;Machine learning;Forestry;Hydrocarbons","geophysical prospecting;geophysical techniques;gravity;image resolution;learning (artificial intelligence)","geophysical exploration;geoscience fields;early screening tool;subsurface hydrocarbon exploration;land-based gravity surveys;remote places;satellite-derived gravity data;satellites;land-based gravity measurements;satellite-based data;super-resolution technique;free-air gravity anomaly data;hydrocarbon regions;supervised machine learning;hydrocarbon classification;free-air gravity anomalies;cross-modality super-resolution;satellite gravity data","","","","10","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Scene Edge Target Recovery of Scanning Radar Angular Super-Resolution Based on Data Extrapolation","D. Mao; Y. Zhang; Y. Kang; Y. Zhang; W. Huo; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","6718","6721","Radar antenna can work in scanning mode to obtain a wide region observation. However, for the targets located at the scene edge, the targets are only swept by less than half of the radar beam. Therefore, the scene edge targets are recovered distortedly using the conventional angular super-resolution methods. To keep the performance of recovered targets in the full scene, in this paper, a data extrapolation-based parallel iterative adaptive approach (PIAA) is proposed. First, we analyze the cause of scene edge target distortion. Then, the echo data is extrapolated by half of the radar beam to compensate the unobserved data. Last, a parallel iterative adaptive approach is proposed to recover the targets efficiently. Simulation data is applied to verify the proposed method.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323387","National Natural Science Foundation of China(grant numbers:61901092,61901090); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323387","Scanning radar;angular super-resolution;data extrapolation;parallel iterative adaptive approach;scene edge target recovery","Radar imaging;Radar;Azimuth;Imaging;Superresolution;Radar antennas;Iterative methods","extrapolation;image resolution;iterative methods;radar antennas;radar imaging;radar resolution","radar beam;unobserved data;simulation data;scene edge target recovery;scanning radar angular super-resolution;radar antenna;scanning mode;wide region observation;scene edge targets;super-resolution methods;recovered targets;data extrapolation-based parallel iterative adaptive approach;scene edge target distortion;echo data","","","","10","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"D-SRCAGAN : DEM Super-resolution Generative Adversarial Network","X. Deng; W. Hua; X. Liu; S. Chen; W. Zhang; J. Duan","School of Geography and Information Engineering, China University of Geosciences (Wuhan), Wuhan, China; School of Geography and Information Engineering, China University of Geosciences (Wuhan), Wuhan, China; School of Geography and Information Engineering, China University of Geosciences (Wuhan), Wuhan, China; School of Geography and Information Engineering, China University of Geosciences (Wuhan), Wuhan, China; School of Geography and Information Engineering, China University of Geosciences (Wuhan), Wuhan, China; School of Geography and Information Engineering, China University of Geosciences (Wuhan), Wuhan, China","IEEE Geoscience and Remote Sensing Letters","","2022","PP","99","1","1","High-resolution digital elevation models (DEMs) are widely used in many fields such as mapping, hydrology, meteorology and geology, where they can improve the accuracy and reliability of many geographic analysis applications as an input. However, due to the high cost and difficulty of acquiring high-resolution DEMs, as well as the problems of edge smoothing, data distortion and fractures in reconstructed ground surfaces with traditional super-resolution DEM reconstruction techniques. Inspired by the excellence of generative adversarial neural networks in super-resolution image analysis, this paper investigates an approach for DEM super-resolution reconstruction with deep residual generative adversarial network. An advanced DEM Super-resolution Generative Adversarial Network (D-SRCAGAN) is proposed in this paper, which can reconstruct a quadruple higher resolution DEM by using low-resolution DEM. Compared with the bicubic and SRGAN methods, the D-SRCAGAN method reconstruction results can retain more topographic features and obtain higher RMSE values.","1558-0571","","10.1109/LGRS.2022.3224296","National Key Research and Development Project(grant numbers:2019YFC0605102); National Natural Science Foundation of China(grant numbers:NSFC 41972307); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9961205","Digital elevation model (DEM);Super-resolution reconstruction;Improved super-resolution generative adversarial network (D-SRCAGAN);Attention mechanism","Image reconstruction;Superresolution;Training;Convolution;Image resolution;Generative adversarial networks;Generators","","","","","","","IEEE","23 Nov 2022","","","IEEE","IEEE Early Access Articles"
"Automatic Determination, Feature-extraction, and Classification of Tidal-courses through Remote-sensing Images: Preliminary Studies","M. P. Cipolletti; C. A. Delrieux; G. M. E. Perillo","Instituto de Investigaciones en ingeniería Eléctrica (CONICET, UNS) and Departamento de Ingeniería Eléctrica y de Computadoras (DIEC), Universidad Nacional del Sur (UNS), Bahía Blanca, Argentina; Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET) and DIEC (UNS), Bahía Blanca, Argentina; Departamento de Geología (UNS), Instituto Argentino de Oceanografía (CONICET, UNS), Bahía Blanca, Argentina","2021 XIX Workshop on Information Processing and Control (RPIC)","24 Dec 2021","2021","","","1","5","Unlike rivers, tidal-paths present different drainage configurations within their complex distribution. The determinations of their features is the first step towards modeling their evolution. In this work, a methodology is presented for automatic morphometric extraction and characterization of tidal-paths over high resolution satellite images (IKONOS, 1 m resolution). The algorithm accurately computes the total length of the structure. In addition, it identifies and characterizes each branch by super-resolution. Then, the drainage paths without loops are classified defining the order in which they flood and ebb by effect of the tides. The method was tested on two tidal-paths with very different features: a rectangular or trellis drainage, and a dendritic one.","","978-1-6654-1436-4","10.1109/RPIC53795.2021.9648432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9648432","morphometry;tidal courses;direct measurement;remote-sensing","Statistical analysis;Superresolution;Windings;Surface morphology;Feature extraction;Classification algorithms;Surface topography","feature extraction;geophysical image processing;geophysical signal processing;image classification;image resolution;remote sensing;rivers","automatic determination;feature-extraction;tidal-courses;remote-sensing images;tidal-paths;different drainage configurations;complex distribution;determinations;automatic morphometric extraction;high resolution satellite images;super-resolution;drainage paths;size 1.0 m","","","","21","IEEE","24 Dec 2021","","","IEEE","IEEE Conferences"
"Combination of Super-Resolution PSI and Traditional PSI by Identification of Homogeneous Areas","H. Zhang; P. López-Dekker; S. Li","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Department of Geoscience and Remote Sensing, Delft University of Technology, Delft, The Netherlands; National-Local Joint Engineering Laboratory of Geo-Spatial Information Technology, Hunan University of Science and Technology, Xiangtan, China","IEEE Access","12 Oct 2020","2020","8","","181640","181649","The performance of Persistent Scatterer Interferometry (PSI) depends heavily on Persistent Scatterer (PS) density. In order to increase PS density, we can apply Super-Resolution reprocessing algorithms in PSI. Involving the reprocessing algorithms and the peak-detection-based Persistent Scatterer Candidate points (PSCs) selection method, the full PSI chain is referred to as Super-Resolution PSI (SR-PSI). The implementation of the Super-Resolution reprocessing algorithm, however, is computationally intensive, which makes SR-PSI time-consuming. In this work, we propose to improve the efficiency by constraining the Capon-based reprocessing to the non-homogeneous areas (e.g., urban areas). We notice that the Capon algorithm performs similarly as the Fourier-based algorithm for homogeneous regions (e.g., grassland), thus we can use Single Look Complex (SLC) images for these areas. With the Coefficient of Variation (CV) as the index, we divide the full image into two classes: homogeneous areas, for which we select PSCs from the original stack, and non-homogeneous areas, for which we extract PSCs from the Capon-based reprocessed images. Then we combine the PSCs of both cases for further PSI processing. We applied the combination method to a stack of TerraSAR-X data. The results show that the proposed approach is more computationally efficient than the original SR-PSI with the effectiveness uncompromised, especially for applications aiming at the urban deformation.","2169-3536","","10.1109/ACCESS.2020.3028491","National Natural Science Foundation of China(grant numbers:41901400); China Scholarship Council (CSC) through the Joint Ph.D. Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9211411","Homogeneous area;super-resolution;SAR;PSI","Strain;Spatial resolution;Standards;Estimation;Gaussian distribution","radar imaging;radar interferometry;radar resolution;remote sensing by radar;synthetic aperture radar","super-resolution psi;homogeneous areas;persistent scatterer interferometry;persistent scatterer density;PSI chain;nonhomogeneous areas;Capon algorithm;Fourier-based algorithm;Capon-based reprocessed images;PSI processing;original SR-PSI;peak-detection-based persistent scatterer candidate points selection method;super-resolution reprocessing algorithm;single look complex images;TerraSAR-X data","","1","","28","CCBY","2 Oct 2020","","","IEEE","IEEE Journals"
"Model Inspired Autoencoder for Unsupervised Hyperspectral Image Super-Resolution","J. Liu; Z. Wu; L. Xiao; X. -J. Wu","Jiangsu Provincial Engineering Laboratory for Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China; School of Computer Science, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science, Nanjing University of Science and Technology, Nanjing, China; Jiangsu Provincial Engineering Laboratory for Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China","IEEE Transactions on Geoscience and Remote Sensing","15 Mar 2022","2022","60","","1","12","This article focuses on hyperspectral image (HSI) super-resolution that aims to fuse a low-spatial-resolution HSI and a high-spatial-resolution multispectral image to form a high-spatial-resolution HSI (HR-HSI). Existing deep learning-based approaches are mostly supervised that rely on a large number of labeled training samples, which is unrealistic. The commonly used model-based approaches are unsupervised and flexible but rely on handcrafted priors. Inspired by the specific properties of model, we make the first attempt to design a model-inspired deep network for HSI super-resolution in an unsupervised manner. This approach consists of an implicit autoencoder network built on the target HR-HSI that treats each pixel as an individual sample. The nonnegative matrix factorization (NMF) of the target HR-HSI is integrated into the autoencoder network, where the two NMF parts, spectral and spatial matrices, are treated as decoder parameters and hidden outputs, respectively. In the encoding stage, we present a pixelwise fusion model to estimate hidden outputs directly and then reformulate and unfold the model’s algorithm to form the encoder network. With the specific architecture, the proposed network is similar to a manifold prior-based model and can be trained patch by patch rather than the entire images. Moreover, we propose an additional unsupervised network to estimate the point spread function and spectral response function. Experimental results conducted on both synthetic and real datasets demonstrate the effectiveness of the proposed approach.","1558-0644","","10.1109/TGRS.2022.3143156","National Natural Science Foundation of China(grant numbers:62071204,61871226,61772274); Natural Science Foundation of Jiangsu Province(grant numbers:BK20201338,BK20180018); Jiangsu Provincial Social Developing Project(grant numbers:BE2018727); China Postdoctoral Science Foundation(grant numbers:2021M691275); Jiangsu Postdoctoral Research Funding Program(grant numbers:2021K148B); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9681709","Autoencoder;hyperspectral image (HSI);nonnegative matrix factorization (NMF);super-resolution;unfolding","Superresolution;Spatial resolution;Hyperspectral imaging;Fuses;Decoding;Energy resolution;Tensors","geophysical image processing;hyperspectral imaging;image classification;image coding;image fusion;image reconstruction;image representation;image resolution;matrix algebra;matrix decomposition;neural nets;remote sensing;unsupervised learning","pixelwise fusion model;hidden outputs;encoder network;manifold prior-based model;model inspired autoencoder;unsupervised hyperspectral image super-resolution;low-spatial-resolution HSI;high-spatial-resolution multispectral image;high-spatial-resolution HSI;deep learning-based approaches;labeled training samples;model-based approaches;model-inspired deep network;HSI super-resolution;unsupervised manner;implicit autoencoder network;target HR-HSI;spectral matrices;spatial matrices;nonnegative matrix factorization;NMF;unsupervised network;point spread function;synthetic dataset;real dataset","","12","","70","IEEE","14 Jan 2022","","","IEEE","IEEE Journals"
"Producing Subpixel Resolution Thematic Map From Coarse Imagery: MAP Algorithm-Based Super-Resolution Recovery","L. Wang; P. Wang; C. Zhao","College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","19 May 2017","2016","9","6","2290","2304","Subpixel mapping (SPM) of hyperspectral remote sensing imagery is a promising technique for deriving fine mapping result by classification at fine spatial resolution. There is a type of algorithm for SPM, namely, the soft-then-hard SPM (STHSPM) algorithm that first estimates soft attribute values for land cover classes at subpixel level and then allocates classes for subpixel according to the soft attribute values. However, the fraction images derived from spectral unmixing are of less prior information of original hyperspectral remote sensing imagery and there are lots of errors in SPM result due to the limitation of spectral unmixing technology currently available. In this paper, a framework based on subpixel resolution thematic map, namely, super-resolution then classification (STC) is proposed to improve mapping result. In the proposed framework, a maximum a posteriori (MAP) model associated with the endmembers of interest (EOI), namely, T-MAP-SR is applied to the original coarse imagery to derive a high-resolution imagery with generous prior information. Then fine mapping result can be derived from the high-spatial resolution imagery by the available classification methods. Experiments show that the proposed framework can produce higher mapping accuracy result and protect the classes of interest (COI).","2151-1535","","10.1109/JSTARS.2016.2552224","National Natural Science Foundation of China(grant numbers:61275010); Ph.D. Programs Foundation of Ministry of Education of China(grant numbers:20132304110007); Fundamental Research Funds for the Central Universities(grant numbers:HEUCFD1410); Heilongjiang Natural Science Foundation(grant numbers:F201409); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7480345","Endmembers of interest (EOI);hyperspectral imagery (HSI);maximum a posteriori (MAP);subpixel mapping (SPM);super-resolution","Spatial resolution;Hyperspectral imaging;Sensors;Indexes","geophysical image processing;geophysical techniques;hyperspectral imaging;image classification;image resolution;remote sensing","subpixel resolution thematic map;coarse imagery;MAP algorithm-based super-resolution recovery;hyperspectral remote sensing imagery;subpixel mapping;fine spatial resolution;fine mapping;SPM algorithm;land cover class;image fraction;SPM error;subpixel resolution thematic map;super-resolution classification;aposteriori model;MAP;interest endmembers;T-MAP-SR;high-spatial resolution imagery;mapping accuracy","","12","","59","IEEE","27 May 2016","","","IEEE","IEEE Journals"
"Exploiting Digital Surface Models for Inferring Super-Resolution for Remotely Sensed Images","S. Karatsiolis; C. Padubidri; A. Kamilaris","CYENS Center of Excellence, Nicosia, Cyprus; CYENS Center of Excellence, Nicosia, Cyprus; Department of Computer Science, University of Twente, Enschede, NB, The Netherlands","IEEE Transactions on Geoscience and Remote Sensing","12 Oct 2022","2022","60","","1","13","Despite the plethora of successful super-resolution (SR) reconstruction (SRR) models applied to natural images, their application to remote sensing imagery tends to produce poor results. Remote sensing imagery is often more complicated than natural images, has its peculiarities such as being of lower resolution, contains noise, and often depicts large textured surfaces. As a result, applying nonspecialized SRR models like the enhanced SR generative adversarial network (ESRGAN) on remote sensing imagery results in artifacts and poor reconstructions. To address these problems, we propose a novel strategy for enabling an SRR model to output realistic remote sensing images: instead of relying on feature-space similarities as a perceptual loss, the model considers pixel-level information inferred from the normalized digital surface model (nDSM) of the image. This allows the application of better-informed updates during the training of the model which sources from a task (elevation map inference) that is closely related to remote sensing. Nonetheless, the nDSM auxiliary information is not required during production, i.e., the model infers an SR image without additional data. We assess our model on two remotely sensed datasets of different spatial resolutions that also contain the DSMs of the images: the Data Fusion 2018 Contest (DFC2018) dataset and the dataset containing the national LiDAR flyby of Luxembourg. We compare our model with ESRGAN, and we show that it achieves better performance and does not introduce any artifacts in the results. In particular, the results for the high-resolution DFC2018 dataset are realistic and almost indistinguishable from the ground-truth images.","1558-0644","","10.1109/TGRS.2022.3209340","European Union’s Horizon 2020 Research and Innovation Programme(grant numbers:739578); Government of the Republic of Cyprus through the Deputy Ministry of Research, Innovation and Digital Policy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9903066","Deep learning (DL);normalized digital surface model (nDSM);perceptual loss;remote sensing;super-resolution (SR) reconstruction (SRR)","Remote sensing;Task analysis;Image reconstruction;Training;Spatial resolution;Superresolution;Loss measurement","","","","","","50","CCBYNCND","26 Sep 2022","","","IEEE","IEEE Journals"
"Hyperspectral image super-resolution using sparse spectral unmixing and low-rank constraints","Z. Li; C. Li; C. Deng; J. Li","School of Electronic Engineering, Xidian University, Xi'an, China; School of Electronic Engineering, Xidian University, Xi'an, China; School of Electronic Engineering, Xidian University, Xi'an, China; School of Electronic Engineering, Xidian University, Xi'an, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","7224","7227","Hyperspectral images play an important role in real-world applications, such as recognition and remote sensing, etc. How to enhance the spatial resolution of hyperspectral image is still a challenging problem in this field. In this paper, we propose a novel hyperspectral image super-resolution approach by jointly incorporating the sparse, low-rank constraints and spectral mixture priori into a linear unmixing framework, which will make the unmixing framework more consistent with the real-world scenarios of the spectral mixture. Experiments on two public databases show that our proposed approach achieves much lower average reconstruction errors than other state-of-the-art methods.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730884","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730884","Hyperspectral image;super-resolution;image fusion;unmixing;joint constraints","Spatial resolution;Hyperspectral imaging;Databases;Sparse matrices;Image reconstruction","hyperspectral imaging;image resolution","sparse spectral unmixing;hyperspectral image super-resolution;low-rank constraints;spectral mixture;linear unmixing framework;reconstruction errors","","","","10","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Spectral Super-Resolution for Hyperspectral Image Reconstruction Using Dictionary and Machine Learning","S. Bhattacharya; K. Remane; B. Kindel; G. Tang","Department of Electrical, Computer and Energy Engineering, University of Colorado, Boulder, USA; Department of Electrical, Computer and Energy Engineering, University of Colorado, Boulder, USA; Laboratory for Atmospheric and Space Physics, University of Colorado, Boulder, USA; Department of Electrical, Computer and Energy Engineering, University of Colorado, Boulder, USA","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1764","1767","Hyperspectral sensors measure the radiance spectrum across hundreds of wavelength channels with a resolution typically on the order of 10 nm represented by the full-width-half-maximum (FWHM). The spectra are used in the study of surface materials in the biological, geological and oceanographic sciences to name a few, utilizing quantitative spectroscopic techniques. The instruments developed to measure such data are expensive due to the increased number of bands, and create large datasets that can be difficult to downlink for a given instance. Repeat cycle of space-borne hyperspectral observations of the earth surface is also less than those of multi-spectral sensors. It becomes incumbent to develop mechanisms that could be cost-effective and give desired results. With this aim, spectral Super-Resolution (SR) is attempted on the Airborne Visible and Infra-Red Imaging Spectrometer (AVIRIS) data to reconstruct the hyperspectral band radiance from equally-spaced narrow multi-spectral bands using dictionary learning, followed by denoising using machine learning. The hyperspectral band radiance are first estimated from 30 selected input multi-spectral bands using dictionary trained through K-Singular Value Decomposition (K-SVD), followed by denoising using Random Forest Regression. An overall Signal-to-Noise Ratio (SNR) of 31.58dB is observed from reconstruction after denoising using Random Forest.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883055","Spectral Super-Resolution;Signal and Image Processing;Image Reconstruction;Dictionary Learning","Surface reconstruction;Sea surface;Dictionaries;Wavelength measurement;Noise reduction;Superresolution;Sea measurements","geophysical image processing;geophysical signal processing;hyperspectral imaging;image classification;image reconstruction;image resolution;image sensors;learning (artificial intelligence);regression analysis;remote sensing;singular value decomposition;spectral analysis;spectrometers","hyperspectral image reconstruction;hyperspectral sensors;radiance spectrum;wavelength channels;biological sciences;geological sciences;oceanographic sciences;quantitative spectroscopic techniques;space-borne hyperspectral observations;earth surface;multispectral sensors;Infra-Red Imaging Spectrometer data;hyperspectral band radiance;equally-spaced narrow multispectral bands;dictionary learning;machine learning;input multispectral bands","","","","16","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Convolutional Neural Network Modelling for MODIS Land Surface Temperature Super-Resolution","B. M. Nguyen; G. Tian; M. -T. Vo; A. Michel; T. Corpetti; C. Granero-Belinchon","Mathematical and Electrical Engineering Department, Lab-STICC, IMT Atlantique, UMR CNRS 6285, Brest, France; Mathematical and Electrical Engineering Department, Lab-STICC, IMT Atlantique, UMR CNRS 6285, Brest, France; Mathematical and Electrical Engineering Department, Lab-STICC, IMT Atlantique, UMR CNRS 6285, Brest, France; ONERA-DOTA, University of Toulouse, Toulouse, France; CNRS, UMR 6554 LETG, Rennes, France; Mathematical and Electrical Engineering Department, Lab-STICC, IMT Atlantique, UMR CNRS 6285, Brest, France","2022 30th European Signal Processing Conference (EUSIPCO)","18 Oct 2022","2022","","","1806","1810","Nowadays, thermal infrared satellite remote sensors enable to extract very interesting information at large scale, in particular Land Surface Temperature (LST). However such data are limited in spatial and/or temporal resolutions which prevents from an analysis at fine scales. For example, MODIS satellite provides daily acquisitions with 1Km spatial resolutions which is not sufficient to deal with highly heterogeneous landscapes. Therefore, image super-resolution is a crucial task to better exploit MODIS LSTs. This issue is tackled in this paper. We introduce a deep learning-based algorithm, named Multi-residual U-Net, for super-resolution of MODIS LST single-images. Our proposed network is a modified version of U-Net architecture, which aims at super-resolving the input LST image from 1Km to 250m per pixel. The results show that our Multi-residual U-Net outperforms other state-of-the-art methods.","2076-1465","978-90-827970-9-1","10.23919/EUSIPCO55093.2022.9909569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9909569","Super-Resolution;CNN;U-Net;LST;MODIS","Training;Temperature sensors;Satellites;Superresolution;Land surface;Land surface temperature;Spatial resolution","atmospheric techniques;geophysical image processing;image resolution;land surface temperature;remote sensing","convolutional neural network modelling;MODIS Land Surface Temperature super-resolution;thermal infrared satellite remote sensors;particular Land Surface Temperature;MODIS satellite;highly heterogeneous landscapes;image super-resolution;deep learning-based algorithm;MODIS LST single-images;input LST image;U-Net architecture","","","","22","","18 Oct 2022","","","IEEE","IEEE Conferences"
"A Sub-Pixel Convolution-Based Residual Network for Hyperspectral Image Change Detection","L. Wang; L. Wan; L. Bruzzone","College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Dalian Minzu University, Dalin, China; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1059","1062","The very high spectral resolution in hyperspectral images (HSIs) presents an opportunity to detect subtle land-cover changes. However, availability of HSIs acquired from different platforms requires the development of change detection (CD) methods for HSIs capable to process images with different spatial resolutions. In this paper, we propose an end-to-end sub-pixel convolution-based residual network (SPCNet) to detect changes between high resolution (HR) and low resolution (LR) HSIs. First, an efficient sub-pixel convolution layer is introduced to upscale the LR feature maps into the HR one. Then, the super resolution (SR) block is designed to generate more discriminative representations in sub-pixel-based LR images. Moreover, the sub-pixel-based feature of LR image and pixel-based feature of HR image are concatenated as an input to the designed ResNet for HSI CD. Experimental results on two HSI datasets demonstrate the effectiveness of the proposed SPCNet.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884805","National Natural Science Foundation of China(grant numbers:62071084); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884805","Hyperspectral images;change detection;deep learning;super-resolution;residual network;remote sensing","Deep learning;Convolution;Geoscience and remote sensing;Sensors;Spatial resolution;Hyperspectral imaging;Residual neural networks","feature extraction;geophysical image processing;geophysical signal processing;hyperspectral imaging;image classification;image representation;image resolution","low resolution HSIs;efficient sub-pixel convolution layer;upscale the LR feature maps;super resolution block;sub-pixel-based LR images;sub-pixel-based feature;LR image;HR image;sub-pixel convolution-based residual network;hyperspectral image change detection;high spectral resolution;hyperspectral images;subtle land-cover changes;change detection methods","","","","7","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Range-Recursive IAA for Scanning Radar Angular Super-Resolution","Y. Zhang; A. Jakobsson; J. Yang","School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; Centre for Mathematical Sciences, Lunds Universitet, Lund, Sweden; School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Geoscience and Remote Sensing Letters","25 Sep 2017","2017","14","10","1675","1679","Recently, the iterative adaptive approach (IAA) was adopted to allow for the estimation of high-resolution scanning radar images. In this letter, we further develop this approach by introducing a range-recursive IAA (IAA-RR) formulation allowing for a computationally efficient updating of the resulting estimates along range. Besides exploiting the rich matrix structure to mitigate the computational complexity for each iteration, the correlation between adjacent range cells is exploited to accelerate the convergence of the IAA iterations. When an additional range measurement becomes available, further acceleration is available by exploiting the estimates already formed for the adjacent range cells. Compared with the existing fast IAA implementation, the proposed IAA-RR is shown to offer significant computational savings, without noticeable loss in performance. Numerical results illustrate the superior performance of the proposed IAA-RR algorithm.","1558-0571","","10.1109/LGRS.2017.2728038","Chinese and Swedish Research Councils; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8000686","Iterative adaptive approach (IAA);range-recursive (RR);scanning radar;super-resolution","Signal resolution;Radar;Azimuth;Estimation;Convergence;Convolution;Iterative methods","computational complexity;iterative methods;radar imaging;radar resolution","range-recursive IAA;scanning radar angular super-resolution;iterative adaptive approach;high-resolution scanning radar images;computational complexity;adjacent range cells","","25","","29","IEEE","3 Aug 2017","","","IEEE","IEEE Journals"
"Hydrological applications of super resolution SWE processing system over Europe","M. Takala; J. Ikonen; K. Luojus; J. Lemmetyinen; S. Metsämäki; J. Pulliainen; J. Cohen; A. Arslan","Finnish Meteorological Institute, Helsinki, Finland; Finnish Meteorological Institute, Helsinki, Finland; Finnish Meteorological Institute, Helsinki, Finland; Finnish Meteorological Institute, Helsinki, Finland; SYKE, Finnish Environment Institute, Helsinki, Finland; Finnish Meteorological Institute, Helsinki, Finland; Finnish Meteorological Institute, Helsinki, Finland; Finnish Meteorological Institute, Helsinki, Finland","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","4880","4881","Reliable global and regional scale SWE maps can be calculated by the assimilation of space borne derived SWE estimates and ground based SD observations. The spatial resolution of these products is ~25 km per pixel which is good enough for climate research but for hydrology a higher resolution is often optimal. A regional SWE processing system with nominal resolution of ~ 5 km per pixel over Europe is described in this paper. In addition the validation results show that the sensitivity to SWE is on the same level as with the lower resolution products. SWE data are also assimilated with HOPS hydrological model and the results show an improvement in river discharge estimates.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730273","SWE;Radiometer;Hydrology","Snow;Spatial resolution;Data models;Europe;Rivers;Hydrology","data assimilation;hydrology;remote sensing;rivers;snow","super resolution snow water equivalent processing system;super resolution SWE processing system;Europe;global scale SWE map;regional scale SWE map;space borne derived SWE estimation;SD observation;climate research;hydrology;SWE data assimilation;HOPS hydrological model;river discharge estimation","","","","4","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Perceptual improvements for Super-Resolution of Satellite Imagery","D. Bull; N. Lim; E. Frank","Dept of Computer Science, University of Waikato, Hamilton, New Zealand; Dept of Computer Science, University of Waikato, Hamilton, New Zealand; Dept of Computer Science, University of Waikato, Hamilton, New Zealand","2021 36th International Conference on Image and Vision Computing New Zealand (IVCNZ)","29 Dec 2021","2021","","","1","6","Super-resolution of satellite imagery poses unique challenges. We propose a hybrid method comprising two existing deep network super-resolution approaches, namely a feedforward network called DeepSUM, and ESRGAN, a GAN-based approach, to super-resolve multiple low-resolution images by a factor of four to obtain a single high-resolution image. We also introduce a novel loss function, called variation loss, to better define edges and textures to create a sharper, perceptually better output. Using our hybrid, we inherit some of the advantages of both deep learning approaches, resulting in super-resolved images that better show boundaries, textures, and details.","2151-2205","978-1-6654-0645-1","10.1109/IVCNZ54163.2021.9653355","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9653355","Super-Resolution;Computer Vision;Remote Sensing;Deep Neural Network","Deep learning;Satellites;Image edge detection;Superresolution;Neural networks;Sensors","deep learning (artificial intelligence);feedforward neural nets;geophysical image processing;image resolution;image texture","perceptual improvements;satellite imagery super-resolution;feedforward network;low-resolution images;ESRGAN;high-resolution image;variation loss;super-resolved images;variation loss;deep network super-resolution;DeepSUM;loss function;image texture;deep learning","","","","20","IEEE","29 Dec 2021","","","IEEE","IEEE Conferences"
"Coupled Convolutional Neural Network With Adaptive Response Function Learning for Unsupervised Hyperspectral Super Resolution","K. Zheng; L. Gao; W. Liao; D. Hong; B. Zhang; X. Cui; J. Chanussot","College of Geoscience and Surveying Engineering, China University of Mining and Technology, Beijing, China; Key Laboratory of Digital Earth Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Image Processing and Interpretation, IMEC Research Group, Ghent University, Ghent, Belgium; Remote Sensing Technology Institute (IMF), German Aerospace Center (DLR), Weßling, Germany; College of Resources and Environment, University of Chinese Academy of Sciences, Beijing, China; College of Geoscience and Surveying Engineering, China University of Mining and Technology, Beijing, China; Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","24 Feb 2021","2021","59","3","2487","2502","Due to the limitations of hyperspectral imaging systems, hyperspectral imagery (HSI) often suffers from poor spatial resolution, thus hampering many applications of the imagery. Hyperspectral super resolution refers to fusing HSI and MSI to generate an image with both high spatial and high spectral resolutions. Recently, several new methods have been proposed to solve this fusion problem, and most of these methods assume that the prior information of the point spread function (PSF) and spectral response function (SRF) are known. However, in practice, this information is often limited or unavailable. In this work, an unsupervised deep learning-based fusion method-HyCoNet-that can solve the problems in HSI-MSI fusion without the prior PSF and SRF information is proposed. HyCoNet consists of three coupled autoencoder nets in which the HSI and MSI are unmixed into endmembers and abundances based on the linear unmixing model. Two special convolutional layers are designed to act as a bridge that coordinates with the three autoencoder nets, and the PSF and SRF parameters are learned adaptively in the two convolution layers during the training process. Furthermore, driven by the joint loss function, the proposed method is straightforward and easily implemented in an end-to-end training manner. The experiments performed in the study demonstrate that the proposed method performs well and produces robust results for different data sets and arbitrary PSFs and SRFs.","1558-0644","","10.1109/TGRS.2020.3006534","National Natural Science Foundation of China(grant numbers:41722108,91638201); AXA Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141341","Adaptive learning;autoencoder;coupled convolutional neural network;hyperspectral image;super-resolution","Adaptive learning;Hyperspectral imaging;Convolutional neural networks;Image classification;Image fusion;Unsupervised learning;Superresolution","geophysical image processing;hyperspectral imaging;image classification;image fusion;image resolution;image sensors;learning (artificial intelligence);neural nets;optical transfer function;remote sensing;sensor fusion;unsupervised learning","hyperspectral imagery;poor spatial resolution;high spectral resolutions;fusion problem;spectral response function;SRF;unsupervised deep learning-based fusion method-HyCoNet-that;HSI-MSI fusion;prior PSF;coupled autoencoder nets;linear unmixing model;special convolutional layers;convolution layers;joint loss function;convolutional neural network;adaptive response function learning;unsupervised hyperspectral super resolution;hyperspectral imaging systems","","56","","65","IEEE","15 Jul 2020","","","IEEE","IEEE Journals"
"Airborne Radar Forward-Looking Super-Resolution Imaging using an Iterative Adaptive Approach","C. Li; Y. Zhang; Y. Zhang; Y. Huang; J. Yang","University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","7910","7913","Airborne radar forward-looking imaging is of great significance in many remote sensing applications. However, the existing synthetic aperture radar (SAR) and Doppler beam sharpening (DBS) imaging techniques are incapable of forward-looking imaging. The real aperture radar (RAR) using a scanning antenna can provide forward-looking images, but suffers from coarse azimuth resolution. In this paper, we extend the iterative adaptive approach (IAA) to forward-looking super-resolution imaging. Different from the conventional forward-looking convolution model, both the Doppler phase and antenna convolution are considered in the new model, allowing for more accurate reconstruction of the forward-looking imaging scenario when applying the IAA. Simulation results demonstrate that the IAA-based super-resolution imaging can overcome the deficiencies of the SAR and DBS techniques in forward-looking imaging direction.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517547","Airborne radar;forward-looking;iterative adaptive approach;Doppler phase;antenna convolution","Imaging;Radar imaging;Azimuth;Image resolution;Doppler effect;Atmospheric modeling;Satellite broadcasting","airborne radar;Doppler radar;image reconstruction;image resolution;iterative methods;radar imaging;radar resolution","real aperture radar;forward-looking imaging direction;forward-looking imaging scenario;Doppler beam sharpening imaging techniques;synthetic aperture radar;scanning antenna;IAA-based super-resolution imaging;coarse azimuth resolution;remote sensing applications;iterative adaptive approach;airborne radar forward-looking super-resolution imaging","","2","","6","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Hyperspectral Image Super-Resolution via Recurrent Feedback Embedding and Spatial–Spectral Consistency Regularization","X. Wang; J. Ma; J. Jiang","School of Electronic Information, Wuhan University, Wuhan, China; School of Electronic Information, Wuhan University, Wuhan, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Geoscience and Remote Sensing","8 Dec 2021","2022","60","","1","13","Hyperspectral images with tens to hundreds of spectral bands usually suffer from low spatial resolution due to the limitation of the amount of incident energy. Without auxiliary images, the single hyperspectral image super-resolution (SR) method is still a challenging problem because of the high-dimensionality characteristic and special spectral patterns of hyperspectral images. Failing to thoroughly explore the coherence among hyperspectral bands and preserve the spatial–spectral structure of the scene, the performance of existing methods is still limited. In this article, we propose a novel single hyperspectral image SR method termed RFSR, which models the spectrum correlations from a sequence perspective. Specifically, we introduce a recurrent feedback network to fully exploit the complementary and consecutive information among the spectra of the hyperspectral data. With the group strategy, each grouping band is first super-resolved by exploring the consecutive information among groups via feedback embedding. For better preservation of the spatial–spectral structure among hyperspectral data, a regularization network is subsequently appended to enforce spatial–spectral correlations over the intermediate estimation. Experimental results on both natural and remote sensing hyperspectral images demonstrate the advantage of our approach over the state-of-the-art methods.","1558-0644","","10.1109/TGRS.2021.3064450","National Natural Science Foundation of China(grant numbers:61773295,61971165); Key Research and Development Program of Hubei Province(grant numbers:2020BAB113); Natural Science Foundation of Hubei Province(grant numbers:2019CFA037); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380508","Feedback embedding;hyperspectral image;recurrent network;super-resolution (SR)","Hyperspectral imaging;Spatial resolution;Image reconstruction;Correlation;Feature extraction;Superresolution;Training","geophysical image processing;hyperspectral imaging;image resolution;remote sensing","spatial-spectral correlations;natural sensing hyperspectral images;remote sensing hyperspectral images;recurrent feedback embedding;spatial-spectral consistency regularization;spectral bands;low spatial resolution;auxiliary images;single hyperspectral image super-resolution method;high-dimensionality characteristic;special spectral patterns;hyperspectral bands;spatial-spectral structure;novel single hyperspectral image SR method;recurrent feedback network;consecutive information;hyperspectral data;grouping band","","17","","47","IEEE","17 Mar 2021","","","IEEE","IEEE Journals"
"Hyperspectral image super-resolution based on transform domain low rank tensor regularization","H. Han; H. Liu","School of Mathematics and Statistics, Nanjing University of Science and Technology, Nanjing, China; School of Mathematics and Statistics, Nanjing University of Science and Technology, Nanjing, China","2022 International Conference on Image Processing and Media Computing (ICIPMC)","16 Sep 2022","2022","","","80","84","In this paper, we propose a low rank regularized hyperspectral image (HSI) super-resolution method based on transform domain tensor. The spectral dimension subspace is learned from low spatial resolution hyperspectral image (LR-HSI) by singular value decomposition. Then representation coefficients of the subspace are grouped as several low rank tensors that are constrained in a data adaptive tensor transform domain, resulting in a low rank regularized super-resolution model. Numerical experiments show that compared with other methods, the proposed super-resolution method shows outstanding performance on enhancing the spatial structures.","","978-1-6654-6872-5","10.1109/ICIPMC55686.2022.00023","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9887470","Hyperspectral image;super-resolution;low rank;spectral dimension subspace;transform domain","Adaptation models;Tensors;Image processing;Superresolution;Transforms;Media;Numerical models","geophysical image processing;hyperspectral imaging;image resolution;remote sensing;singular value decomposition;tensors","spectral dimension subspace;low spatial resolution hyperspectral image;singular value decomposition;data adaptive tensor transform domain;transform domain low rank tensor regularization;low rank regularized hyperspectral image super-resolution method;HSI;LR-HSI","","","","14","IEEE","16 Sep 2022","","","IEEE","IEEE Conferences"
"Hyperspectral Super-Resolution of Locally Low Rank Images From Complementary Multisource Data","M. A. Veganzones; M. Simões; G. Licciardi; N. Yokoya; J. M. Bioucas-Dias; J. Chanussot","Grenoble Images Parole Signal Automatique Laboratory, CNRS, Saint-Martin-d’Hères, France; Instituto de Telecomunicações and the Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal; Grenoble Images Parole Signal Automatique Laboratory, Grenoble Institute of Technology, Saint-Martin-d’Hères, France; Department of Advanced Interdisciplinary Studies, The University of Tokyo, Tokyo, Japan; Instituto de Telecomunicações and the Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland","IEEE Transactions on Image Processing","8 Dec 2015","2016","25","1","274","288","Remote sensing hyperspectral images (HSIs) are quite often low rank, in the sense that the data belong to a low dimensional subspace/manifold. This has been recently exploited for the fusion of low spatial resolution HSI with high spatial resolution multispectral images in order to obtain super-resolution HSI. Most approaches adopt an unmixing or a matrix factorization perspective. The derived methods have led to state-of-the-art results when the spectral information lies in a low-dimensional subspace/manifold. However, if the subspace/manifold dimensionality spanned by the complete data set is large, i.e., larger than the number of multispectral bands, the performance of these methods mainly decreases because the underlying sparse regression problem is severely ill-posed. In this paper, we propose a local approach to cope with this difficulty. Fundamentally, we exploit the fact that real world HSIs are locally low rank, that is, pixels acquired from a given spatial neighborhood span a very low-dimensional subspace/manifold, i.e., lower or equal than the number of multispectral bands. Thus, we propose to partition the image into patches and solve the data fusion problem independently for each patch. This way, in each patch the subspace/manifold dimensionality is low enough, such that the problem is not ill-posed anymore. We propose two alternative approaches to define the hyperspectral super-resolution through local dictionary learning using endmember induction algorithms. We also explore two alternatives to define the local regions, using sliding windows and binary partition trees. The effectiveness of the proposed approaches is illustrated with synthetic and semi real data.","1941-0042","","10.1109/TIP.2015.2496263","European Research Council (Programme FP7/20072013) through the DECODA Project(grant numbers:2012-ERC-AdG-320594); French National Research Agency through the XIMRI Project(grant numbers:ANR-BLAN-SIMI2-LS-101019-6-01); Portuguese Science and Technology Foundation(grant numbers:SFRH/BD/87693/2012); Portuguese Science and Technology Foundation(grant numbers:PTDC/EEIPRO/1470/2012,UID/EEA/50008/2013); European Research Council through the CHESS Project(grant numbers:2012-ERC-AdG-320684); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7312998","Hyperspectral imagery;multispectral imagery;super-resolution;data fusion;dictionary learning;spectral unmixing;binary partition tree;Hyperspectral imagery;multispectral imagery;super-resolution;data fusion;dictionary learning;spectral unmixing;binary partition tree","Hyperspectral imaging;Spatial resolution;Sensors;Signal resolution","geophysical image processing;hyperspectral imaging;image fusion;image resolution;learning (artificial intelligence);regression analysis;remote sensing;trees (mathematics)","hyperspectral super-resolution;locally low rank image;complementary multisource data;remote sensing hyperspectral images;remote sensing HSI;low spatial resolution HSI;high spatial resolution multispectral images;spectral information;low-dimensional subspace;low-dimensional manifold;manifold dimensionality;subspace dimensionality;sparse regression problem;data fusion problem;local dictionary learning;endmember induction algorithms;sliding windows;binary partition trees","","122","","32","IEEE","30 Oct 2015","","","IEEE","IEEE Journals"
"Video Super Resolution Using Temporal Encoding ConvLSTM and Multi-Stage Fusion","Y. Zhang; Z. Chen; S. Liu","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Tencent Media Lab, Palo Alto, CA, USA","2020 IEEE International Conference on Visual Communications and Image Processing (VCIP)","29 Dec 2020","2020","","","298","301","Video super resolution is a challenging task and has attracted the attention of many researchers in recent years. In this paper, we propose a multi-stage spatio-temporal feature fusion network. Different from existing methods that only aggregate features from temporal branch once at a specified s tage of network, the proposed network is organized in a multi-stage manner so that the temporal correlation in features at different stages of the network can be fully exploited. Furthermore, we propose the temporal encoding convLSTM to effectively capture the temporal information at the end of each stage. Experiments on vid4 and viemo-90K demonstrate the effectiveness of the proposed method.","2642-9357","978-1-7281-8068-7","10.1109/VCIP49819.2020.9301823","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9301823","video super resolution;temporal correlation;convLSTM","Feature extraction;Correlation;Encoding;Image reconstruction;Training;Task analysis;Decoding","expectation-maximisation algorithm;feature extraction;image fusion;image resolution;spatiotemporal phenomena;video signal processing","temporal branch;temporal correlation;temporal encoding convLSTM;temporal information;video super resolution;multistage spatio-temporal feature fusion network;aggregate features","","","","9","IEEE","29 Dec 2020","","","IEEE","IEEE Conferences"
"Graph Convolutional Networks-Based Super-Resolution Land Cover Mapping","X. Zhang; Y. Ge; F. Ling; J. Chen; Y. Chen; Y. Jia","University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; State Key Laboratory of Earth Surface Processes and Resource Ecology, Beijing Normal University, Beijing, China; College of Hydrology and Water Resources, Hohai University, Nanjing, China; Academy of Forest Inventory and Planning, National Forestry and Grassland Administration, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","12 Aug 2021","2021","14","","7667","7681","Super-resolution mapping (SRM) is an effective technology to solve the problem of mixed pixels because it can be used to generate fine-resolution land cover maps from coarse-resolution remote sensing images. Current methods based on deep neural networks have been successfully applied to SRM, as they can learn complex spatial patterns from training data. However, they lack the ability to learn structural information between adjacent land cover classes, which is vital in the reconstruction of spatial distribution. In this article, an SRM method based on graph convolutional networks (GCNs), named SRMGCN, is proposed to improve SRM results by capturing structure information on the graph. In SRMGCN, a supervised inductive learning strategy with mini-graphs as input is considered, which is an extension of the GCN framework. Furthermore, two operations are designed in terms of adjacency matrix construction and an information propagation rule to help reconstruct detailed information of geographical objects. Experiments on three datasets with different spatial resolutions demonstrate the qualitative and quantitative superiority of SRMGCN over three other popular SRM methods.","2151-1535","","10.1109/JSTARS.2021.3100400","National Natural Science Foundation of China; Distinguished Young Scholars of China(grant numbers:41725006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9497702","Deep neural networks (DNNs);graph convolutional networks (GCNs);land cover;subpixel;super-resolution mapping (SRM)","Spatial resolution;Convolution;Feature extraction;Symmetric matrices;Superresolution;Laboratories;Image reconstruction","geophysical image processing;image classification;image resolution;land cover;remote sensing;terrain mapping","popular SRM methods;graph convolutional networks;super-resolution mapping;fine-resolution land cover maps;coarse-resolution remote sensing images;deep neural networks;complex spatial patterns;structural information;SRM method;SRM results;structure information;supervised inductive learning strategy;minigraphs;adjacent land cover class;super-resolution land cover","","3","","57","CCBY","27 Jul 2021","","","IEEE","IEEE Journals"
"Is There Any Recovery Guarantee with Coupled Structured Matrix Factorization for Hyperspectral Super-Resolution?","H. Liu; R. Wu; W. -K. Ma","Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China","2019 IEEE 8th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)","5 Mar 2020","2019","","","480","484","Coupled structured matrix factorization (CoSMF) for hyperspectral super-resolution (HSR) has recently drawn significant interest in hyperspectral imaging for remote sensing. Presently there are very few studies on the theoretical recovery guarantees of CoSMF. This paper makes one such endeavor by considering the CoSMF formulation by Wei et al., which, simply speaking, is similar to coupled non-negative matrix factorization. Assuming no noise, we show sufficient conditions under which the globably optimal solution to the CoSMF problem is guaranteed to deliver certain recovery accuracies. Our analysis suggests that sparsity and the pure-pixel (or separability) condition play a hidden role in enabling CoSMF to achieve some good recovery characteristics.","","978-1-7281-5549-4","10.1109/CAMSAP45676.2019.9022516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022516","hyperspectral super-resolution;coupled structured matrix factorization;recovery guarantee","Spatial resolution;Hyperspectral imaging;Signal resolution;Imaging","hyperspectral imaging;image resolution;matrix decomposition;remote sensing;sparse matrices","hyperspectral imaging;theoretical recovery guarantees;CoSMF formulation;nonnegative matrix factorization;CoSMF problem;recovery accuracies;recovery characteristics;recovery guarantee;coupled structured matrix factorization;hyperspectral super-resolution","","3","","15","IEEE","5 Mar 2020","","","IEEE","IEEE Conferences"
"Super-Resolution Reconstruction of Multi-Polarization Sar Images Based on Projections Onto Convex Sets Algorithm","J. Huang; B. Gao; Y. Chen; Y. Chen; L. Tong","School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","8456","8459","Resolution is one of the important indices to measure the quality of SAR images. Super-resolution reconstruction is a widely adopted resolution enhancement method. Many algorithms have been developed for the super-resolution reconstruction. Among these algorithms, this paper applies projections onto convex sets algorithm to SAR image reconstruction processing. The POCS can efficiently obtain high-resolution SAR images with enhanced details. However, the POCS requires many low-resolution SAR images of the same area to gain a better result, usually 10 to 20 images. Such requirement is very difficult to achieve when only single-polarization mode is included. In this paper, we propose a novel method that utilizes all the polarimetric images of the same original SAR data for the algorithm. Thus, the number of the available images is increased exponentially. The experiment results have demonstrated the effectiveness of our proposed method: The reconstructed high-resolution SAR image based on multi-polarimetric information is more detailed and clearer than that based on single-polarization information.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518557","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518557","SAR image;super-resolution reconstruction;POCS algorithm;multi-polarization information","Image reconstruction;Image resolution;Synthetic aperture radar;Bridges;Roads;Image sequences;Image edge detection","image enhancement;image reconstruction;image resolution;radar imaging;set theory;synthetic aperture radar","high-resolution SAR image;low-resolution SAR images;polarimetric images;original SAR data;super-resolution reconstruction;multipolarization SAR images;convex sets algorithm;resolution enhancement method;quality measurement;POCS;single-polarization mode;multipolarimetric information;SAR image reconstruction processing","","3","","7","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Sub-Pixel Mapping with Hyperspectral Images Using Super-Resolution","S. Gaur; K. M. Buddhiraju; A. Porwal","Department of Computer Sciences, University of Wisconsin-Madison; Centre of studies in Resources Engineering, Indian Institute of Technology Bombay, Mumbai; Centre of studies in Resources Engineering, Indian Institute of Technology Bombay, Mumbai","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","2459","2462","Hyperspectral images are rich in spectral content but their spatial resolution is relatively poor. It can lead to mixed pixels and sub-pixel targets. In order to improve the reliability of information provided by hyperspectral image analysis and make the results practically usable, one needs to improve their spatial resolution. Due to physical constraints and associated cost, increasing the resolution by improving the sensors may not be a practical option. Thus one effective solution is some form of post-processing of hyperspectral data. Such an algorithmic resolution enhancement is called “super-resolution”. In this paper single image super-resolution of hyperspectral image has been attempted. The use of Hopfield Neural Network for successful landuse/landcover classification of Hyperspectral image has been shown. A successful attempt was made to improve initialization of the Hopfield neural network. The results were verified visually as well as statistically.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517840","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517840","Hyperspectral Image;Super-resolution;Hopfield Neural Network;Landuse/landcover;Sub-pixel Mapping;Mixed Pixel","Spatial resolution;Hyperspectral imaging;Neurons;Hopfield neural networks;Sensors","geophysical image processing;Hopfield neural nets;hyperspectral imaging;image classification;image resolution;land cover;land use","spatial resolution;hyperspectral image analysis;algorithmic resolution enhancement;subpixel mapping;subpixel targets;mixed pixels targets;hyperspectral data post-processing;single image super-resolution;Hopfield neural network;landuse classification;landcover classification","","1","","7","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Space Variant-Based Maximum a Posteriori Angular Super-Resolution Algorithm for Real-Beam Scanning Radar","K. Tan; W. Li; Y. Zhang; Y. Huang; J. Yang; X. Yang","School of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; School of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; School of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; School of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; School of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; School of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","585","588","This paper proposes a space variant-based maximum a posteriori (MAP) angular super-resolution algorithm for highspeed moving real-beam scanning radar. Firstly, the aberration model of the antenna modulation function is established through analyzing the relationship between the scanning angle and the sight angle. Afterwards, an efficient piecewise constant model is formulated for the sake of reducing the computational complexity and restoring cost. Finally, the space variant-based MAP algorithm is derived based on the aberrant model. Simulation experiments demonstrate that the proposed method can improve the super-resolution performance of the high-speed platforms more efficiently than the traditional MAP method.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517700","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517700","Real-beam scanning radar;angular super-resolution;maximum a posteriori algorithm;space variant","Antennas;Image resolution;Convolution;Computational modeling;Signal resolution;Radar;Azimuth","aberrations;communication complexity;maximum likelihood estimation;modulation;piecewise constant techniques;radar antennas;radar resolution","posteriori angular super-resolution algorithm;highspeed moving real-beam scanning radar;aberration model;antenna modulation function;computational complexity;space variant-based MAP angular superresolution algorithm;space variant-based maximum a posteriori angular superresolution algorithm;aberrant model;efficient piecewise constant model","","","","7","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"NonRegSRNet: A Nonrigid Registration Hyperspectral Super-Resolution Network","K. Zheng; L. Gao; D. Hong; B. Zhang; J. Chanussot","Key Laboratory of Digital Earth Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Digital Earth Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Digital Earth Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; College of Resources and Environment, University of Chinese Academy of Sciences, Beijing, China; Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","1 Mar 2022","2022","60","","1","16","Due to the limitations of imaging systems, satellite hyperspectral imagery (HSI), which yields rich spectral information in many channels, often suffers from poor spatial resolution. HSI super-resolution (SR) refers to the fusion of high spatial resolution multispectral imagery (MSI) and low spatial resolution HSI to generate HSI that has both a high spatial and high spectral resolution. However, most existing SR methods assume that the two original images used are perfectly registered: in reality, nonrigid deformation areas can exist locally in the two images even if prior registration of the control points has been carried out. To address this problem, we propose a novel unsupervised spectral unmixing and image deformation correction network—NonRegSRNet—with multimodal and multitask learning that can be used for the joint registration of HSI and MSI and to produce SR imagery. More specifically, NonRegSRNet integrates the dense registration and SR tasks into a unified model that includes a triplet convolutional neural network. This allows these two tasks to complement each other so that better registration and SR results can be achieved. Furthermore, because the point spread function (PSF) and spectral response function (SRF) are often unavailable, two special convolutional layers are designed to adaptively learn the parameters of the PSF and SRF, which makes the proposed model more adaptable. Experimental results demonstrate that the proposed method has the ability to produce highly accurate and stable reconstructed images under complex nonrigid deformation conditions. (Code available at <uri>https://github.com/saber-zero/NonRegSRNet</uri>)","1558-0644","","10.1109/TGRS.2021.3135501","National Natural Science Foundation of China(grant numbers:62161160336,42030111); China Postdoctoral Science Foundation(grant numbers:2021M693234); MIAI@Grenoble Alpes(grant numbers:ANR-19-P3IA-0003); AXA Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650906","Adaptive learning;convolutional neural network;hyperspectral image;nonrigid registration;super-resolution (SR)","Spatial resolution;Strain;Image reconstruction;Task analysis;Deep learning;Image registration;Tensors","geophysical image processing;hyperspectral imaging;image reconstruction;image registration;image resolution;learning (artificial intelligence);medical image processing;neural nets;optical images;optical transfer function;remote sensing","spectral response function;highly accurate images;stable reconstructed images;complex nonrigid deformation conditions;nonrigid registration hyperspectral super-resolution network;imaging systems;satellite hyperspectral imagery;rich spectral information;poor spatial resolution;HSI super-resolution;high spatial resolution multispectral imagery;MSI;low spatial resolution HSI;high spectral resolution;existing SR methods;original images;nonrigid deformation areas;prior registration;unsupervised spectral unmixing;image deformation correction network;multitask learning;joint registration;SR imagery;dense registration;SR tasks;triplet convolutional neural network;SR results","","18","","85","IEEE","14 Dec 2021","","","IEEE","IEEE Journals"
"Bayesian Hyperspectral Image Super-Resolution in the Presence of Spectral Variability","F. Ye; Z. Wu; Y. Xu; H. Liu; Z. Wei","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Science, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Transactions on Geoscience and Remote Sensing","22 Dec 2022","2022","60","","1","13","Synthesizing a high-resolution (HR) hyperspectral image (HSI) by merging a low-resolution (LR) HSI with a corresponding HR multispectral image (MSI) has become a promising HSI super-resolution scheme. Most existing HSI-MSI fusion methods are effective to some extent, while several challenges remain. First, the spectral response of a given material exhibits considerable variability due to different acquisition times and conditions, however, variations in spectral signatures are often neglected. Second, a majority of off-the-shelf methods require predefined degradation operators, which can be unavailable in practice. To tackle the above issues, we introduce a novel fusion approach with a Bayesian framework. Specifically, we regard the up-sampled LR-HSI as the low-frequency component of the underlying HR-HSI. We characterize the texture features of high- and low-frequency components, respectively, which can enlarge modeling capacity and bypass the absence of degradation operators. Furthermore, we depict the relative smoothness of reflectance spectra with the Gaussian process. Extensive experiments on synthesized and real datasets illustrate the superiority of the proposed strategy in terms of fusion performance and robustness to spectral variability.","1558-0644","","10.1109/TGRS.2022.3228313","National Natural Science Foundation of China(grant numbers:62071233,61971223,61976117); Jiangsu Provincial Natural Science Foundation of China(grant numbers:BK20211570,BK20180018,BK20191409); Fundamental Research Funds for the Central Universities(grant numbers:30917015104,30919011103,30919011402,30921011209,JSGP202204); Key Projects of University Natural Science Fund of Jiangsu Province(grant numbers:19KJA360001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9980459","Bayesian inference;hyperspectral image (HSI);image fusion;multispectral image (MSI);spectral variability;super-resolution","Superresolution;Bayes methods;Mathematical models;Dictionaries;Degradation;Hyperspectral imaging;Spatial resolution","Bayes methods;Gaussian processes;geophysical image processing;hyperspectral imaging;image fusion;image reconstruction;image resolution;image texture;remote sensing","Bayesian framework;Bayesian hyperspectral image super-resolution;corresponding HR multispectral image;degradation operators;different acquisition times;existing HSI-MSI fusion methods;fusion approach;fusion performance;given material exhibits considerable variability;high-resolution hyperspectral image;low-frequency component;low-resolution HSI;LR-HSI;off-the-shelf methods;promising HSI super-resolution scheme;real datasets;robustness;spectral response;spectral signatures;spectral variability;synthesized datasets;underlying HR-HSI","","1","","54","IEEE","12 Dec 2022","","","IEEE","IEEE Journals"
"Efficient Deconvolution and Super-Resolution Methods in Microwave Imagery","I. Yanovsky; B. H. Lambrigtsen; A. B. Tanner; L. A. Vese","Joint Institute for Regional Earth System Science and Engineering, University of California, Los Angeles, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Department of Mathematics, University of California, Los Angeles, CA, USA","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","19 May 2017","2015","8","9","4273","4283","In this paper, we develop efficient deconvolution and super-resolution methodologies, and apply these techniques to reduce image blurring and distortion inherent in an aperture synthesis system. Such a system produces ringing at sharp edges and other transitions in the observed field. The conventional approach to suppressing sidelobes is to apply linear apodization, which has the undesirable side effect of degrading spatial resolution. We have developed an efficient total variation minimization technique based on Split Bregman deconvolution that reduces image ringing while sharpening the image and preserving information content. The model was generalized to include upsampling of deconvolved images to a higher resolution grid. Furthermore, a proposed multiframe super-resolution method is presented that is robust to image noise and noise in the point spread function, and leads to additional improvements in spatial resolution. Our super-resolution methodologies are based on current research in sparse optimization and compressed sensing, which lead to unprecedented efficiencies for solving image reconstruction problems.","2151-1535","","10.1109/JSTARS.2015.2424451","Jet Propulsion Laboratory; California Institute of Technology; National Aeronautics and Space Administration; National Science Foundation(grant numbers:DMS 1217239); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7109125","Aperture synthesis system;inverse problems;microwave imaging;remote sensing;sparse optimization;spatial resolution;super-resolution;Aperture synthesis system;inverse problems;microwave imaging;remote sensing;sparse optimization;spatial resolution;super-resolution","Deconvolution;Spatial resolution;Image reconstruction;Microwave imaging;TV;Signal to noise ratio","compressed sensing;geophysical image processing;image denoising;image reconstruction;image restoration;microwave imaging;optimisation","multiframe superresolution method;microwave imagery;image blurring;image distortion;aperture synthesis system;sidelobes;linear apodization;degrading spatial resolution;split Bregman deconvolution;image ringing;image noise;point spread function;compressed sensing;optimization;image reconstruction","","20","","32","IEEE","15 May 2015","","","IEEE","IEEE Journals"
"An Improved Adaptive Regularization Method for Forward Looking Azimuth Super-Resolution of a Dual-Frequency Polarized Scatterometer","L. Liu; X. Dong; J. Zhu; D. Zhu","University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Microwave Remote Sensing, Chinese Academy of Sciences, National Space Science Center, Beijing, China; DFH Satellite Co., Ltd., Beijing, China; Key Laboratory of Microwave Remote Sensing, Chinese Academy of Sciences, National Space Science Center, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","19 May 2017","2016","9","6","2145","2159","Dual-frequency polarized scatterometer (DFPSCAT) is a pencil-beam rotating scatterometer which is designed for snow water equivalent (SWE) measurement, and Doppler beam sharpening (DBS) technique is proposed for DFPSCAT to achieve the azimuth resolution. However, the DBS technique is inapplicable for the forward-looking and afterward-looking regions. Based on an approximate aperiodic model of scatterometer echo signal, an improved adaptive regularization deconvolution algorithm with gradient histogram preservation (GHP) constraint is implemented to settle the problem. To investigate its performance of resolution enhancement and resulted accuracy, both a synthetic backscattering coefficient (σ0) field reconstruction and SWE σ0 reconstruction are carried out. The results show that the proposed method can recover the truth signal and achieve azimuth resolution of 2 km with the designed scatterometer system, which is required by the SWE retrieval. Moreover, the relative errors of reconstructed σ0 are less than 0.5 dB that satisfy the accuracy requirement for SWE retrieval, and comparisons with observed results show that the error reduction is more than 0.03 dB. Meanwhile, a comparison between the proposed algorithm and some existing resolution enhancement methods is analyzed, which concludes that the proposed method can obtain a comparable resolution enhancement as L1 method and has less noise. The technique is also verified with advanced scatterometer (ASCAT) scatterometer data.","2151-1535","","10.1109/JSTARS.2016.2530738","Strategic Priority Program on Space Science from Chinese Academy of Sciences; Water Cycle Observation Mission(grant numbers:XDA04061202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7433405","Azimuth super-resolution;dual-frequency polarized scatterometer (DFPSCAT);reconstruction accuracy;snow water equivalent (SWE)","Radar measurements;Signal resolution;Azimuth;Spaceborne radar;Spatial resolution;Deconvolution","approximation theory;Doppler radar;error analysis;gradient methods;hydrological techniques;radar polarimetry;remote sensing by radar;snow;spaceborne radar","improved adaptive regularization method;forward looking azimuth super-resolution;dual-frequency polarized scatterometer;DFPSCAT;snow water equivalent measurement;Doppler beam sharpening technique;DBS technique;forward-looking region;afterward-looking region;gradient histogram preservation constraint;improved adaptive regularization deconvolution algorithm;synthetic backscattering coefficient field reconstruction;SWE reconstruction;SWE retrieval;L1 method;advanced scatterometer data;error reduction","","9","","26","IEEE","14 Mar 2016","","","IEEE","IEEE Journals"
"Single Image Super-Resolution via Multi-Scale Information Polymerization Network","T. Lu; Y. Wang; J. Wang; W. Liu; Y. Zhang","Wuhan Institute of Technology, Hubei Key Laboratory of Intelligent Robot, Wuhan, China; Wuhan Institute of Technology, Hubei Key Laboratory of Intelligent Robot, Wuhan, China; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Wuhan Institute of Technology, Hubei Key Laboratory of Intelligent Robot, Wuhan, China; Wuhan Institute of Technology, Hubei Key Laboratory of Intelligent Robot, Wuhan, China","IEEE Signal Processing Letters","13 Jul 2021","2021","28","","1305","1309","Recently, the performances of deep convolution neural networks (CNNs)-based single-image super-resolution (SISR) have been significantly improved. However, most of the existing CNN-based SISR methods mainly focus on wider or deeper networks and ignore the potential relationship between multi-scale features, leading to the limited representation ability of the reconstructed network. To address this problem, we propose a new multi-scale information polymerization network (MIPN). Specifically, we propose a multi-scale information polymerization block (MIPB), which uses convolution layers of different convolution kernel sizes to extract multi-scale image features, and effectively polymerizate the extracted features together to obtain fine image features. Moreover, we also propose a shallow residual block in MIPB. Compared with the traditional convolution layer, this proposed block can effectively extract image features without increasing the number of parameters. Extensive experiments show that the proposed method performs better than several state-of-the-art methods in quantitative and visual quality indicators.","1558-2361","","10.1109/LSP.2021.3084522","National Natural Science Foundation of China(grant numbers:62072350,62001334,61771353,62071339); Hubei Technology Innovation(grant numbers:2019AAA045); Central Government Guides Local Science and Technology Development Special(grant numbers:2018ZYYD059); High value Intellectual Property Cultivation Project of Hubei Province; Enterprise Technology Innovation Project of Wuhan(grant numbers:202001602011971); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442897","Convolution neural network;multi-scale information;image super-resolution","Feature extraction;Polymers;Convolution;Image reconstruction;Data mining;Superresolution;Kernel","convolution;feature extraction;image reconstruction;image representation;image resolution;neural nets","single image super-resolution;multiscale information polymerization network;deep convolution neural networks-based single-image super-resolution;existing CNN-based SISR methods;wider networks;deeper networks;multiscale features;reconstructed network;multiscale information polymerization block;different convolution kernel;multiscale image features;fine image features;traditional convolution layer","","6","","26","IEEE","27 May 2021","","","IEEE","IEEE Journals"
"Image Fusion for Hyperspectral Image Super-Resolution","H. Irmak; G. B. Akar; S. E. Y. uksel","Radar and Electronic Warfare Systems Business Sector, Aselsan Inc., Ankara, TURKEY; Dept. of Electrical and Electronics Eng., Middle East Techical University, Ankara, TURKEY; Dept. of Electrical and Electronics Eng., Hacettepe University, Ankara, TURKEY","2018 9th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","27 Jun 2019","2018","","","1","5","Hyperspectral sensors have high spectral resolution by capturing images in hundreds of bands. Despite the high spectral resolution, low spatial resolution of these sensors restricts the performance of the hyperspectral imaging applications such as target tracking and image classification. Fusing the hyper-spectral image (HSI) with higher spatial resolution RGB or multispectral image (MSI) data is a commonly used method in the resolution enhancement of the HSIs. In this paper, we propose a new fusion technique for the HSI super-resolution. The main contribution of this study is formulating the fusion problem in a quadratic manner and also regularizing the solution quadratically using smoothness prior. Moreover, another contribution of the proposed method is converting the fusion problem from spectral domain to the abundance map domain which gives more robust and spectrally consistent results. In the proposed method, first, abundance maps are obtained using linear spectral unmixing and then a quadratic energy function is obtained using these maps and high resolution (HR) RGB image. In addition, quadratic function is regularized using additional constraints. Solving the regularized quadratic function gives the HR abundance maps and these maps are used to reconstruct HR HSI. Experiments show that proposed method yields better performance as compared to state of the art methods in different performance metrics.","2158-6276","978-1-7281-1581-8","10.1109/WHISPERS.2018.8747231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8747231","Image Fusion;Super-resolution;Hyperspectral;Abundance Maps;Quadratic optimization","Hyperspectral imaging;Spatial resolution;Measurement;Visualization;Image reconstruction","geophysical image processing;hyperspectral imaging;image colour analysis;image fusion;image reconstruction;image resolution","hyperspectral sensors;high spectral resolution;low spatial resolution;hyperspectral imaging applications;target tracking;image classification;higher spatial resolution RGB;multispectral image data;HSI super-resolution;spectral domain;linear spectral unmixing;quadratic energy function;regularized quadratic function;image fusion technique;high resolution RGB imaging;hyperspectral image superresolution enhancement;MSI;HR HSI reconstruction","","4","","17","IEEE","27 Jun 2019","","","IEEE","IEEE Conferences"
"A Rooftop-Contour Guided 3D Reconstruction Texture Mapping Method for Building using Satellite Images","W. Zhang; H. Chen; W. Chen; S. Yang","Department of Information Engineering, Harbin Institute of Technology, Harbin, China; Department of Information Engineering, Harbin Institute of Technology, Harbin, China; Department of Information Engineering, Harbin Institute of Technology, Harbin, China; Department of Information Engineering, Harbin Institute of Technology, Harbin, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","3456","3459","Low-quality digital surface model (DSM) and blurred textures result in poor visualization of building reconstructions. In this paper, an edge-based block decomposition method for building rooftop reconstruction and side walls generation is proposed, which is applied in three-dimensional (3D) reconstruction texture mapping of buildings. The rooftop is decomposed into blocks according to the contour of the building's rooftop in the orthophoto. Each block is combined with the DSM generated by the stereo pair of satellite images to reconstruct the rooftop and interpolate to generate the side walls to obtain a regularized 3D point cloud of the building. For better texture mapping effect, single image super-resolution (SISR) method is used to enhance the texture details of remote sensing images. Experimental results show that the proposed method has better visualization effect than other 3D reconstruction methods based on satellite data.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883969","National Natural Science Foundation of China(grant numbers:61771170); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883969","Stereo pair;Rooftop reconstruction;Side walls generation;3D Building;Image super-resolution","Point cloud compression;Three-dimensional displays;Satellites;Buildings;Superresolution;Data visualization;Reconstruction algorithms","geophysical image processing;image reconstruction;image resolution;image texture;remote sensing;solid modelling;stereo image processing","rooftop-contour guided 3D reconstruction texture mapping method;satellite images;low-quality digital surface model;DSM;building reconstructions;edge-based block decomposition method;building rooftop reconstruction;side walls;regularized 3D point cloud;texture mapping effect;single image super-resolution method;texture details;remote sensing images;3D reconstruction methods","","","","11","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Nonnegative and Nonlocal Sparse Tensor Factorization-Based Hyperspectral Image Super-Resolution","W. Wan; W. Guo; H. Huang; J. Liu","Laboratory of Mathematics and Complex Systems (Ministry of Education of China), School of Mathematical Sciences, Beijing Normal University, Beijing, China; Department of Mathematics, Case Western Reserve University, Cleveland, OH, USA; Laboratory of Mathematics and Complex Systems (Ministry of Education of China), School of Mathematical Sciences, Beijing Normal University, Beijing, China; Laboratory of Mathematics and Complex Systems (Ministry of Education of China), School of Mathematical Sciences, Beijing Normal University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","24 Nov 2020","2020","58","12","8384","8394","Hyperspectral image (HSI) super-resolution refers to enhancing the spatial resolution of a 3-D image with many spectral bands (slices). It is a seriously ill-posed problem when the low-resolution (LR) HSI is the only input. It is better solved by fusing the LR HSI with a high-resolution (HR) multispectral image (MSI) for a 3-D image with both high spectral and spatial resolution. In this article, we propose a novel nonnegative and nonlocal 4-D tensor dictionary learning-based HSI super-resolution model using group-block sparsity. By grouping similar 3-D image cubes into clusters and then conduct super-resolution cluster by cluster using 4-D tensor structure, we not only preserve the structure but also achieve sparsity within the cluster due to the collection of similar cubes. We use 4-D tensor Tucker decomposition and impose nonnegative constraints on the dictionaries and group-block sparsity. Numerous experiments demonstrate that the proposed model outperforms many state-of-the-art HSI super-resolution methods.","1558-0644","","10.1109/TGRS.2020.2987530","National Key Research and Development Program of China(grant numbers:2017YFA0604903); China Scholarship Council(grant numbers:201706040141); National Science Foundation(grant numbers:DMS-1521582); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9082892","Hyperspectral imaging (HSI);nonlocal sparse tensor factorization (NLSTF);nonnegative tensor dictionary learning;super-resolution","Tensors;Dictionaries;Sparse matrices;Noise reduction;Spatial resolution;Correlation","geophysical image processing;hyperspectral imaging;image fusion;image reconstruction;image representation;image resolution;matrix decomposition;stereo image processing;tensors","nonnegative tensor factorization;spatial resolution;low-resolution HSI;high-resolution multispectral image;group-block sparsity;3D image cubes;super-resolution cluster;HSI super-resolution;nonlocal sparse tensor factorization;hyperspectral image super resolution;4D tensor tucker decomposition;nonlocal 4D tensor dictionary learning;nonnegative 4D tensor dictionary learning;LR HSI fusion","","19","","33","IEEE","30 Apr 2020","","","IEEE","IEEE Journals"
"Satellite super-resolution images depending on deep learning methods: A comparative study","H. M. Keshk; X. -C. Yin","Computer Science Department, University of Science and Technology Beijing, Beijing, China; Computer Science Department, University of Science and Technology Beijing, Beijing, China","2017 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","1 Jan 2018","2017","","","1","7","The deep learning neural network is a recent development that has become the subject of research in the computer vision and remote sensing disciplines. Super resolution (SR) images can be obtained using deep neural network methods that achieve a higher performance than all previous traditional methods. Here, in this study, the objective is to describe existing deep learning methods for SR satellite images. Different satellite data are used to predict the performance of each deep learning model. This article presents a brief overview of most deep learning techniques and compares them to obtain a more effective and efficient model. The deep network cascade model outperforms other deep learning algorithms; this algorithm is dependable in the reconstruction process for obtaining SR images and overcomes some drawbacks found in traditional reconstruction algorithms. The sparse coding network method remains valuable, and with some enhancements, further improvement in results can be achieved.","","978-1-5386-3142-3","10.1109/ICSPCC.2017.8242625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8242625","Deep learning;Super-resolution;Satellite Images;Remote Sensing;Deep Network Cascade;Sparse Coding Network","Machine learning;Satellites;Image resolution;Image reconstruction;Encoding;Remote sensing;Training","computer vision;image reconstruction;image resolution;learning (artificial intelligence);neural nets","satellite super-resolution images;deep learning methods;deep learning neural network;remote sensing disciplines;super resolution images;deep neural network methods;SR satellite images;deep learning model;deep learning techniques;deep network cascade model;deep learning algorithms;sparse coding network method;satellite data","","8","","30","IEEE","1 Jan 2018","","","IEEE","IEEE Conferences"
"Efficient SAR Tomographic Inversion via Sparse Bayesian Learning","Y. Wang; K. Qian; X. X. Zhu","German Aerospace Center, Remote Sensing Technology Institute, Weßling, Germany; German Aerospace Center, Remote Sensing Technology Institute, Weßling, Germany; German Aerospace Center, Remote Sensing Technology Institute, Weßling, Germany","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","4830","4832","SAR tomographic inversion (TomoSAR) has been widely employed for 3-D urban mapping. Existing algorithms are mostly based on an explicit inversion of the SAR imaging model, which are often computationally expensive for large scale processing. This is especially true for compressive sensing-based TomoSAR algorithms. Previous literature showed perspective of using data-driven methods like PCA and kernel PCA to decompose the signal and reduce the computational complexity of parameter inversion. This paper gives a preliminary demonstration of a data-driven TomoSAR method based on sparse Bayesian learning. Experiments on simulated data show the proposed algorithm can provide moderate detection rate and super-resolution power, comparing to the state-of-the-art compressive sensing based algorithms. As the proposed algorithm is purely based on conventional (non-superresolving) estimators, it is much more computationally efficient than compressive sensing based ones. This gives us a perspective of employing it for large scale TomoSAR processing. Experiments on real data will be given in the final paper.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554296","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554296","SAR tomography;sparse learning;machine learning;data-driven;InSAR;SAR","Superresolution;Geoscience and remote sensing;Tomography;Radar polarimetry;Bayes methods;Sensors;Kernel","Bayes methods;compressed sensing;geophysical image processing;image reconstruction;image resolution;principal component analysis;radar imaging;radar resolution;synthetic aperture radar;tomography","efficient SAR;sparse Bayesian learning;SAR tomographic inversion;3-D urban mapping;explicit inversion;SAR imaging model;scale processing;compressive sensing-based TomoSAR algorithms;data-driven methods;computational complexity;parameter inversion;preliminary demonstration;data-driven TomoSAR method;moderate detection rate;super-resolution power;state-of-the-art compressive sensing based algorithms;compressive sensing based ones;scale TomoSAR processing","","","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Advances on CNN-Based Super-Resolution of Sentinel-2 Images","M. Gargiulo","DIETI, University Federico II, Naples (I)","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3165","3168","Thanks to their temporal-spatial coverage and free access, Sentinel-2 images are very interesting for the community. However, a relatively coarse spatial resolution, compared to that of state-of-the-art commercial products, motivates the study of super-resolution techniques to mitigate such a limitation. Specifically, thirtheen bands are sensed simultaneously but at different spatial resolutions: 10, 20, and 60 meters depending on the spectral location. Here, building upon our previous convolutional neural network (CNN) based method [1], we propose an improved CNN solution to super-resolve the 20-m resolution bands benefiting spatial details conveyed by the accompanying 10-m spectral bands.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899186","Data fusion;deep learning;convolutional neural network;pansharpening","Spatial resolution;Remote sensing;Training;Meters;Convolutional neural networks","convolutional neural nets;image resolution","CNN-based super-resolution;Sentinel-2 images;temporal-spatial coverage;free access;relatively coarse spatial resolution;commercial products;convolutional neural network based method;improved CNN solution;resolution bands;spatial details;spectral bands","","3","","22","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Super-Resolution ISAR Imaging by Sequential Sparse Recovery","X. Bai; Y. Zou; Y. Feng; J. Zhao","School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2963","2966","Inverse synthetic aperture radar (ISAR) imaging needs a long coherent processing interval (CPI) to obtain high cross-range resolution. However, the Doppler frequency is time-varying for a maneuvering target, which will produce blurred ISAR image in a long CPI. In this article, we focus on super-resolution ISAR imaging during an adaptive short CPI by using sequential sparse recovery. To enhance the performance of SSL0, a regularized SSLO (Re-SSLO) and an entropy-based stopping rule are presented. Besides, KT-based MTRC compensation, SVD-based dictionary whitening and rotation correlation-based cross-range scaling are introduced into the processing scheme. The superiority of the proposed method is validated by the experimental results based on simulated data.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883499","National Natural Science Foundation of China(grant numbers:61731023,62171029,61931015,U21A20456); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883499","Inverse synthetic aperture radar (ISAR);Sparse recovery (SR);smoothed L0(SL0)","Time-frequency analysis;Dictionaries;Superresolution;Imaging;Geoscience and remote sensing;Radar imaging;Doppler effect","image resolution;radar imaging;radar resolution;singular value decomposition;synthetic aperture radar","super-resolution ISAR imaging;sequential sparse recovery;inverse synthetic aperture radar imaging;long coherent processing interval;high cross-range resolution;ISAR image;long CPI;adaptive short CPI;KT-based MTRC compensation;rotation correlation-based cross-range scaling;Doppler frequency;time-varying;maneuvering target;blurred ISAR image;entropy-based stopping rule;SVD-based dictionary whitening;singular value decomposition","","","","6","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Hyperspectral Super-Resolution by Unsupervised Convolutional Neural Network and Sure","H. V. Nguyen; M. O. Ulfarsson; J. R. Sveinsson; M. D. Mura","Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; GIPSA-Lab, Grenoble Institute of Technology, Saint Martin d'Hères, France","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","903","906","Recent advances in deep learning (DL) reveal that the structure of a convolutional neural network (CNN) is a good image prior (called deep image prior (DIP)), bridging the model-based and DL-based methods in image restoration. However, optimizing a DIP-based CNN is prone to over-fitting leading to a poorly reconstructed image. This paper derives a loss function based on Stein's unbiased risk estimate (SURE) for unsupervised training of a DIP-based CNN applied to the hyperspectral image (HSI) super-resolution. The SURE loss function is an unbiased estimate of the mean-square-error (MSE) between the clean low-resolution image and the low-resolution estimated image, which relies only on the observed low-resolution image. Experimental results on HSI show that the proposed method not only improves the performance, but also avoids overfitting. Codes are available at https://github.com/hvn2/SURE-MS-HS","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883576","University of Iceland(grant numbers:1547-15430); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883576","Hyperspectral image;image fusion;Stein's unbiased risk estimate (SURE);unsupervised CNN","Training;Filtering;Superresolution;Noise reduction;Geoscience and remote sensing;Pansharpening;Image restoration","convolutional neural nets;deep learning (artificial intelligence);hyperspectral imaging;image reconstruction;image resolution;image restoration;mean square error methods;unsupervised learning","unsupervised convolutional neural network;deep learning;image restoration;DIP-based CNN;poorly reconstructed image;Stein's unbiased risk estimate;unsupervised training;hyperspectral image super-resolution;SURE loss function;mean-square-error","","","","13","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Super-resolution reconstruction of hyperspectral images via low rank tensor modeling and total variation regularization","S. He; H. Zhou; Y. Wang; W. Cao; Z. Han","Shenyang Institute of Automation, Chinese Academy of Sciences; School of Mathematics and Statistics, Xi’ an Jiaotong University; Shenyang Institute of Automation, Chinese Academy of Sciences; School of Mathematics and Information Science, Shaanxi Normal University; Shenyang Institute of Automation, Chinese Academy of Sciences","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","6962","6965","In this paper, we propose a novel approach to hyperspectral image super-resolution by modeling the global spatial-and-spectral correlation and local smoothness properties over hyperspectral images. Specifically, we utilize the tensor nuclear norm and tensor folded-concave penalty functions to describe the global spatial-and-spectral correlation hidden in hyperspectral images, and 3D total variation (TV) to characterize the local spatial-and-spectral smoothness across all hyperspectral bands. Then, we develop an efficient algorithm for solving the resulting optimization problem by combing the local linear approximation (LLA) strategy and alternative direction method of multipliers (ADMM). Experimental results on one hyperspectral image dataset illustrate the merits of the proposed approach.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730816","Hyperspectral images;Super-resolution reconstruction;nuclear norm;Folded-concave penalty;3D total variation","Hyperspectral imaging;Tensile stress;Spatial resolution;Signal resolution;Image reconstruction","geophysical techniques;hyperspectral imaging;image resolution","hyperspectral image super-resolution reconstruction;low rank tensor modeling;3D total variation regularization;global spatial-and-spectral correlation;local smoothness properties;tensor nuclear norm;tensor folded-concave penalty functions;local spatial-and-spectral smoothness;hyperspectral bands;optimization problem solving;local linear approximation strategy;alternative direction multiplier method","","12","","16","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Multitemporal Hyperspectral Image Super-Resolution through 3D Generative Adversarial Network","J. Li; R. Cui; Y. Li; B. Li; Q. Du; C. Ge","The State Key Lab. of ISN, Xidian University, Xi'an, China; The State Key Lab. of ISN, Xidian University, Xi'an, China; The State Key Lab. of ISN, Xidian University, Xi'an, China; School of electronic and information, Northwestern Polytechnical University, Xi'an, China; The department of Electronic and Computer Engineering, Mississippi State University, Mississippi, USA; The State Key Lab. of ISN, Xidian University, Xi'an, China","2019 10th International Workshop on the Analysis of Multitemporal Remote Sensing Images (MultiTemp)","14 Oct 2019","2019","","","1","4","The super-resolution of multitemporal hyperspectral imagery is considered, wherein a 3D generative adversarial network (GAN) is promoted and employed. Firstly, we put the SR process in a generative adversarial network (GAN) framework, so that the resulted high resolution HSI can keep more texture details. Secondly, the input of our method is of full bands due to 3D kernel exploited. Furthermore, a series of spatial-spectral constraints or loss functions are imposed to guide the training of our generative network so as to further alleviate spectral distortion and texture blur. The experiments on the houston datasets demonstrate that the proposed GAN-based SR method with the best generalization ability can yield very high quality results.","","978-1-7281-4615-7","10.1109/Multi-Temp.2019.8866956","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8866956","Multitemporal Hyperspectral imagery;hyperspectral super-resolution;GAN;generalization ability","Hyperspectral imaging;Spatial resolution;Training;Three-dimensional displays;Generators","gallium compounds;geophysical image processing;hyperspectral imaging;image resolution;image texture","multitemporal hyperspectral image super-resolution;3D generative adversarial network;generative adversarial network framework;GAN-based SR method","","10","","7","IEEE","14 Oct 2019","","","IEEE","IEEE Conferences"
"Dual 1D-2D Spatial-Spectral CNN for Hyperspectral Image Super-Resolution","J. Li; R. Cui; B. Li; Y. Li; S. Mei; Q. Du","School of Telecommunications Engineering, Xidian University, China; School of Telecommunications Engineering, Xidian University, China; School of Electronics and Infromation, Northwestern Polytechnical University, China; School of Telecommunications Engineering, Xidian University, China; School of Electronics and Infromation, Northwestern Polytechnical University, China; The Department of Electrical and Computer Engineering, Mississippi State University, USA","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3113","3116","Hyperspectral image (HSI) spatial super-resolution(SR) is a challenging task. Compared with a RGB images, the mapping between the low-high HSI pairs is more difficult since much more spectral bands are involved. In this paper, a novel dual 1D-2D spatial-spectral convolutional neural network (CNN) architecture is proposed for spatial SR of HSIs. Specifically, by differential treatment over redundancy in spectral and spatial domains of an HSI, the spectral and spatial context are first separately explored by 1D and 2D convolution. These two kinds of feature information are then fused using a novel hierarchical side connection, which impose the spectral information to the spatial path gradually. Experimental results over benchmark Pavia data set demonstrate that the proposed architecture clearly outperform state-of-the-art 3D CNN based works in terms of both visual quality and quantitative assessment.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898352","dual networks;spatial-spectral;HSI;super-resolution","Three-dimensional displays;Convolution;Spatial resolution;Encoding;Kernel","convolutional neural nets;geophysical image processing;hyperspectral imaging;image resolution","spatial-spectral CNN;hyperspectral image super-resolution;RGB images;HSI pairs;spectral bands;novel dual 1D-2D spatial-spectral convolutional neural network architecture;spectral domains;spatial domains;spectral context;spatial context;spectral information;spatial path;state-of-the-art 3D CNN based works","","8","","9","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"SAR images super-resolution via cartoon-texture image decomposition and jointly optimized regressors","Z. Wang; S. Wang; C. Xu; C. Li; B. Yue; X. Liang","IST, Kyoto University, Kyoto, Japan; IST, Kyoto University, Kyoto, Japan; IST, Kyoto University, Kyoto, Japan; IST, Kyoto University, Kyoto, Japan; IST, Kyoto University, Kyoto, Japan; IST, Kyoto University, Kyoto, Japan","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","1668","1671","This paper presents a novel approach to enhance the spatial resolution of Synthetic Aperture Radar(SAR) images. SAR images super-resolution(SR) reconstruction is challenging since SAR images has more complex structures. Inspired by the recent advance on natural image SR techniques, we propose a joint learning based strategy[1], combined with the characteristics of SAR image, to reconstruct HR SAR images from LR SAR images. Our method has ability to handle the complicated structures of SAR images. Besides, SAR images are decomposed into cartoon components and texture components and processed respectively. The purpose of decomposing strategy is to reduce the influence of speckle noise of SAR images. The experimental results and comparative analyses verify the effectiveness of this algorithm.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127294","SAR images;image super-resolution cartoon-texture image decomposition;jointly optimized","Rail to rail outputs;Geology","image reconstruction;image resolution;image texture;learning (artificial intelligence);optimisation;radar imaging;regression analysis;synthetic aperture radar","SAR image;cartoon-texture image decomposition;Synthetic Aperture Radar images;SAR images super-resolution reconstruction;HR SAR image reconstruction;LR SAR image reconstruction;joint learning;jointly optimized regressors;natural image SR techniques","","7","","8","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"A Bayesian Super-Resolution Method for Forward-Looking Scanning Radar Imaging Based on Split Bregman","Q. Zhang; Y. Zhang; D. Mao; Y. Zhang; Y. Huang; J. Yang","University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","5135","5138","In forward-looking scanning radar imaging, the azimuth resolution can be improved by adding the sparse constraint. However, the azimuth resolution is limited with noise influence by traditional sparse regularization methods. In this paper, we propose a Bayesian super-resolution method that solves the L1 regularization problem using the split Bregman algorithm. This method decouples L1 and L2 norms for the independence of them to reduce the computational complexity. The simulations verify that the proposed algorithm provides a better resolution and de-noising ability compare with conventional methods.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518359","Forward-looking imaging;sparse constraint;super-resolution;split Bregman","Image resolution;Radar imaging;Signal resolution;Bayes methods;Radar antennas;Simulation","Bayes methods;image resolution;radar imaging","azimuth resolution;Bayesian super-resolution method;split Bregman algorithm;sparse constraint;forward-looking scanning radar imaging;L1 regularization problem","","4","","7","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Super resolution of synthetic aperture radar data by convex optimization","F. Biondi","Department of Electrical Engineering, Stanford University, Stanford, CA","2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing (CoSeRa)","17 Nov 2016","2016","","","28","32","The problem of chirped Synthetic Aperture Radar (SAR) is the high vulnerability of the received information, under Electromagnetic (EM) Corruption. This paper proposes a valid recovery solution of SAR Single Look Complex (SLC)1 images observed with low band signals. The recovery of high resolution images is made by Super-Resolution (SR) Signal Processing (SP), based on Spectrum Extrapolation (SE), implemented by Convex Programming (CP).","","978-1-5090-2920-4","10.1109/CoSeRa.2016.7745693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745693","Synthetic Aperture Radar (SAR);Jamming;Super-Resolution (SR);Spectrum Extrapolation (SE);Compressed Sensing (CS)","Synthetic aperture radar;Image resolution;Signal resolution;Jamming;Radar imaging;Chirp","convex programming;extrapolation;image resolution;radar imaging;synthetic aperture radar","chirped synthetic aperture radar;electromagnetic corruption;SAR single look complex images;SAR SLC images;high resolution images recovery;super-resolution signal processing;spectrum extrapolation;convex programming","","3","","9","IEEE","17 Nov 2016","","","IEEE","IEEE Conferences"
"Feedback Neural Network Based Super-Resolution of DEM for Generating High Fidelity Features","A. A. Kubade; A. Sharma; K. S. Rajan","International Institute of Information Technology, Hyderabad; International Institute of Information Technology, Hyderabad; International Institute of Information Technology, Hyderabad","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1671","1674","High resolution Digital Elevation Models(DEMs) are an important requirement for many applications like modelling water flow, landslides, avalanches etc. Yet publicly available DEMs have low resolution for most parts of the world. Despite tremendous success in image super-resolution task using deep learning solutions, there are very few works that have used these powerful systems on DEMs to generate HRDEMs. Motivated from feedback neural networks, we propose a novel neural network architecture that learns to add high frequency details iteratively to low resolution DEM, turning it into a high resolution DEM without compromising its fidelity. Our experiments confirm that without any additional modality such as aerial images(RGB), our network DSRFB achieves RMSEs of 0.59 to 1.27 across 4 different terrains having diverse geographical structures.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323310","Digital Elevation Models;Terrains;Super-resolution;Feedback Neural Networks","Feature extraction;Image reconstruction;Spatial resolution;Superresolution;Task analysis;Recurrent neural networks;Meters","digital elevation models;geomorphology;image resolution;learning (artificial intelligence);neural nets;terrain mapping","publicly available DEMs;image super-resolution task;deep learning solutions;neural networks;high frequency details;network DSRFB;generating high fidelity features;modelling water flow","","2","","11","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Super-Resolution of Sentinel-2 Images Based on Deep Channel-Attention Residual Network","X. Zhu; Y. Xu; Z. Wei","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","628","631","Sentinel-2 data has become an important tool for current and future earth observation due to its high quality, free availability and world-wide coverage. However, some of the spectral bands are sensed at reduced resolution due to design considerations and sensor hardware limitations. So in this paper we present a super-resolution method based on Convolutional Neural Networks (CNNs) to infer all the 20m spectral bands in the highest available resolution. This is accomplished by using an improved residual network and meanwhile we propose a channel attention mechanism to adaptively rescale the characteristics of the channels by considering the interdependencies among the channels. The proposed solution compares against several alternative methods according to different quality indexes. Our network provides the best results and a compelling visual effect on the sentinel-2 images.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8897860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897860","Sentinel-2;super-resolution;convolutional neural network;residual network;channel attention","Spatial resolution;Training;Neural networks;Indexes;Training data","convolutional neural nets;geophysical image processing;geophysical techniques;image resolution","improved residual network;channel attention mechanism;quality indexes;highest available resolution;Convolutional Neural Networks;super-resolution method;sensor hardware limitations;reduced resolution;spectral bands;world-wide coverage;future earth observation;current earth observation;sentinel-2 data;deep channel-attention residual network;sentinel-2 images;size 20.0 m","","2","","10","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"PySRResNet: Super Resolution for Video Satellite Imagery via Pyramid Residual Network","M. Xiao; Z. He; J. Wu","Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, The Southern Marine Science and Engineering Guangdong Laboratory Zhuhai, Guangdong Provincial Key Laboratory of Urbanization and Geo-simulation, Guangzhou, China; Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, The Southern Marine Science and Engineering Guangdong Laboratory Zhuhai, Guangdong Provincial Key Laboratory of Urbanization and Geo-simulation, Guangzhou, China; Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, The Southern Marine Science and Engineering Guangdong Laboratory Zhuhai, Guangdong Provincial Key Laboratory of Urbanization and Geo-simulation, Guangzhou, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","2105","2108","Video satellite is of great significance in change detection and military reconnaissance due to its high temporal resolution. However, restricted by the hardware conditions, spatial resolution must be sacrificed if temporal resolution is to be guaranteed. Because of this, how to reconstruct super resolution (SR) video satellite data is particularly important. Based on the proposed SR Residual Network (SRResNet), we proposed a Pyramid Residual Network (PySRResNet) model, using a pyramid structure to obtain features of different scales, including 1, 1/2 and 1/4, and concatenate them together to provide more detailed information for SR reconstruction. In addition, we reduced the number of blocks and removed the batch normalization layer to achieve good performance. Training with “Jilin-1” video satellite images, our PySRResNet can get superior grades than other comparing models both in PSNR and SSIM, which demonstrates the effectiveness of PySRResNet in video satellite imagery SR reconstruction.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323125","National Key R&D Program of China(grant numbers:2018YFB0505500,2018YFB0505503); Fundamental Research Funds for the Central Universities(grant numbers:19lgzd10); National Natural Science Foundation of China(grant numbers:41501368); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323125","PySRResNet;multi-scale features;super resolution;video satellite images","Image reconstruction;Satellites;Feature extraction;Training;Convolution;Superresolution;Spatial resolution","geophysical image processing;image reconstruction;image resolution;video signal processing","PySRResNet;change detection;military reconnaissance;high temporal resolution;hardware conditions;spatial resolution;super resolution video satellite data;SR residual network;pyramid structure;Jilin-1 video satellite images;video satellite imagery SR reconstruction;pyramid residual network model;batch normalization layer","","1","","14","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Super-Resolution Imaging of Real-Beam Scanning Radar Base on Accelerated Maximum a Posteriori Algorithm","W. Li; M. Niu; Y. Zhang; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, P.R. China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, P.R. China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, P.R. China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, P.R. China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, P.R. China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3173","3176","In this paper, an accelerated maximum a posteriori (AMAP) algorithm is proposed to realize fast and effective super resolution imaging of real beam scanning radar. The main idea of this algorithm is to construct a prediction vector based on the first and the second order of difference information before iteration. By using Taylor expansion series and second-order vector extrapolation technique, it aims to enhance the convergence speed of maximum a posteriori algorithm. Finally, the proposed algorithm is verified by simulations.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898837","Real beam scanning radar;super-resolution imaging;deconvolution;maximum a posteriori algorithm;acceleration","Radar imaging;Prediction algorithms;Acceleration;Azimuth;Signal processing algorithms;Convergence","extrapolation;image resolution;iterative methods;vectors","prediction vector;second-order vector extrapolation technique;super-resolution imaging;real-beam scanning radar base;accelerated maximum a posteriori algorithm;AMAP algorithm;Taylor expansion series","","1","","8","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Hyperspectral Image Super-Resolution Based on Multi-Scale Wavelet 3D Convolutional Neural Network","J. Yang; Y. -Q. Zhao; J. C. -W. Chan","Research & Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen, China; Research & Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen, China; Department of Electronics and Informatics, Vrije Universiteit Brussel, Brussel, Belgium","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2770","2773","Super-resolution (SR) of hyperspectral image (HSI) is of significance for its applications. Wavelet decomposition can be used to capture textures and structures in the HSI. In this study, we propose a multi-scale wavelet 3D convolutional neural network (MW-3D-CNN) for HSI SR. Instead of reconstructing the high resolution (HR) HSI directly, we predict the wavelet coefficients of HR HSI with the proposed network, which is composed of an embedding subnet and a predicting subnet. Both of them are built with 3D convolutional layers. The embedding subnet extracts deep spatial-spectral features from the low resolution (LR) HSI and represents the LR HSI as a set of feature cubes. The feature cubes are then fed to the predicting subnet. There are multiple output branches in the predicting subnet, each of which corresponds to a wavelet sub-band and predicts the wavelet coefficients of HR HSI. By applying inverse wavelet transform to the predicted wavelet coefficients, the HR HSI can be obtained. In the training stage, we propose to train MW-3D-CNN with L1 norm loss, which is more suitable than the conventional L2 norm loss for penalizing the errors in different wavelet sub-bands. In the experiment, the performance is tested on several HSI datasets.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898813","Super-resolution;hyperspectral;wavelet;CNN","Three-dimensional displays;Wavelet coefficients;Feature extraction;Spatial resolution;Correlation;Hyperspectral imaging","convolutional neural nets;feature extraction;geophysical image processing;hyperspectral imaging;image resolution;inverse transforms;wavelet transforms","hyperspectral image super-resolution;multiscale wavelet 3D convolutional neural network;wavelet decomposition;MW-3D-CNN;HSI SR;high resolution HSI;HR HSI;embedding subnet;predicting subnet;3D convolutional layers;low resolution HSI;LR HSI;feature cubes;wavelet sub-band;inverse wavelet transform;predicted wavelet coefficients;HSI datasets;deep spatial-spectral feature extraction;L1 norm loss","","1","","14","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Local Similarity Regularized Sparse Representation for Hyperspectral Image Super-Resolution","S. Tang; N. Zhou","Department of Criminal Science and Technology, Nanjing Forest Police College, Nanjing, China; Department of Criminal Science and Technology, Nanjing Forest Police College, Nanjing, China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","5120","5123","Recently, performance of hyperspectral image super-resolution (SR) has been significantly improved via sparse representation. However, most of these existing methods fail to consider the local geometrical structure of the sparse coefficients. To take this crucial issue into account, this paper proposes an effective method, which exploits the location related constraint about the sparse coefficients and incorporates their local similarity into the sparse coding process. Thus, the proposed method can preserve the properties of the aforementioned local geometrical structures. Based on the experimental results, the proposed method is demonstrated to be more effective than previous efforts in the task of hyperspectral image SR.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518168","Hyperspectral image;Super-resolution;Sparse representation;Local similarity","Hyperspectral imaging;Spatial resolution;Image reconstruction;Dictionaries;Encoding","geometry;hyperspectral imaging;image representation;image resolution","hyperspectral image super-resolution;sparse coefficients;sparse coding process;aforementioned local geometrical structures;hyperspectral image SR;local similarity regularized sparse representation","","","","11","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Super-resolution of infrared images based on hierarchical distillation network","W. Cai; B. Jiang; X. Jiang","Xi’an Research Institute of High Technology, Xi’an, Shaanxi, China; Xi’an Research Institute of High Technology, Xi’an, Shaanxi, China; Xi’an Research Institute of High Technology, Xi’an, Shaanxi, China","2022 3rd International Conference on Geology, Mapping and Remote Sensing (ICGMRS)","18 Aug 2022","2022","","","756","761","Aiming at the problem of low image resolution that easily occurs in the process of infrared images acquisition, this paper proposes a novel hierarchical distillation network to achieve infrared images super-resolution. By designing a cascaded residual distillation module, the negative impact of the over-deep network model is reduced; meanwhile, a dual-path feature fusion module is constructed to further enhance the feature expression capability of the network model. Experiments were conducted on public datasets and evaluated using two evaluation metrics, Peak Signal-to-Noise Ratio (PSNR) and Structure Similarity Index Measure (SSIM). The experimental results show that the method in this paper improves 1.97 and 0.033 in PSNR and SSIM, respectively, compared with RCAN, and generates images with high definition, strong structure and rich detail information.","","978-1-6654-8595-1","10.1109/ICGMRS55602.2022.9849268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849268","super-resolution;infrared images;convolutional neural network;attention mechanism","Measurement;PSNR;Fuses;Geology;Superresolution;Indexes;Image reconstruction","convolutional neural nets;deep learning (artificial intelligence);image denoising;image fusion;image resolution;infrared imaging","infrared image super-resolution;cascaded residual distillation module;deep network model;feature expression capability;evaluation metrics;peak signal-to-noise ratio;structure similarity index measure;infrared image acquisition;hierarchical distillation network;dual-path feature fusion module;PSNR;SSIM","","","","16","IEEE","18 Aug 2022","","","IEEE","IEEE Conferences"
"Super Resolution Reconstruction Technique in Passive Microwave Images of Arctic Sea Ice","X. Liu; T. Feng; J. Zhao; R. Li","College of Survey and Geo-Informatics, Tongji University, Shanghai, China; College of Survey and Geo-Informatics, Tongji University, Shanghai, China; Department of Computer Science and Technology, School of Electronics and Information Engineering, Tongji University, Shanghai, China; College of Survey and Geo-Informatics, Tongji University, Shanghai, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","4234","4237","Polar sea ice is one of the key parameters of cryosphere and polar environmental change, which plays an important role in the study of global climate change. High-resolution monitoring of polar sea ice relies mainly on optical satellite imagery and synthetic aperture radar (SAR) data, with limited spatial and temporal coverages for many applications. Passive microwave data is an important data source for continuous observations of polar sea ice, thanks to its working ability in all-sky conditions and its wide coverage. However, it is difficult to achieve high-resolution monitoring of polar sea ice using passive microwave data due to its coarse resolution. In order to solve this problem, super resolution (SR) reconstruction technique is adopted in this paper to improve the spatial resolution of passive microwave images. SR reconstruction technique based on both single-image and multi-image are attempted. AMSR2 level 3 (L3) Products of Brightness Temperatures (BTs) for Arctic sea ice are used as experimental data, and the reconstruction results obtained from different SR methods are compared and discussed.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898488","Super Resolution;passive microwave;Arctic;sea ice","Sea ice;Microwave FET integrated circuits;Microwave imaging;Microwave integrated circuits;Microwave theory and techniques;Arctic;Microwave radiometry;Climate change","oceanographic techniques;sea ice;synthetic aperture radar","super resolution reconstruction technique;passive microwave images;Arctic sea ice;polar sea ice;polar environmental change;high-resolution monitoring;synthetic aperture radar data;passive microwave data;data source;global climate change;optical satellite imagery;all-sky conditions;coarse resolution;spatial resolution;AMSR2 level 3 products;brightness temperatures","","","","14","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"A Frequency-Separated 3D-CNN for Hyperspectral Image Super-Resolution","L. Wang; T. Bi; Y. Shi","College of Information and Communications Engineering, Harbin Engineering University, Harbin, China; College of Information and Communications Engineering, Harbin Engineering University, Harbin, China; College of Information and Communications Engineering, Harbin Engineering University, Harbin, China","IEEE Access","18 May 2020","2020","8","","86367","86379","Considering the limitations such as cost, it is of great significance to use super-resolution methods to improve image spatial quality in the field of hyperspectral remote sensing. Due to little dependence on auxiliary information which is difficult to obtain, i.e., multispectral images and natural images, methods based on single-frame are generally considered to have good flexibility and application value. In this paper, a three-dimensional convolutional neural network with three branches combined with an analytical method is proposed, achieving better SR quality and suppressing spectral distortion as well. Firstly, the wavelet transformation is introduced to decompose the hyperspectral image into a variety frequency of components effectively and reversibly. Then, these components are fed into different three-dimensional convolutional branches respectively. Finally, hyperspectral images with high resolution are obtained by dimension amplification, detail reconstruction and inverse wavelet transformation. The presence of frequency separation and the architecture of our model having different branches designed according to frequency make it better than comparable approaches. The method proposed in this paper not only combines the high efficiency of analytical method and the flexibility of neural network, but inhibits the influence of spectral distortion as well. Compared with the state-of-art methods on real space-based hyperspectral image datasets, the effectiveness of the proposed method is demonstrated.","2169-3536","","10.1109/ACCESS.2020.2992862","National Natural Science Foundation of China(grant numbers:61675051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9087888","Hyperspectral remote sensing;super-resolution;wavelet transformation;neural network","Wavelet transforms;Feature extraction;Neural networks;Hyperspectral imaging;Image reconstruction","convolutional neural nets;geophysical image processing;hyperspectral imaging;image reconstruction;image resolution;inverse transforms;remote sensing;wavelet transforms","natural images;three-dimensional convolutional neural network;SR quality;spectral distortion;three-dimensional convolutional branches;detail reconstruction;inverse wavelet transformation;frequency separation;space-based hyperspectral image datasets;hyperspectral image super-resolution;super-resolution methods;image spatial quality;hyperspectral remote sensing;multispectral images;frequency-separated 3D-CNN;dimension amplification","","9","","49","CCBY","6 May 2020","","","IEEE","IEEE Journals"
"TR-MISR: Multiimage Super-Resolution Based on Feature Fusion With Transformers","T. An; X. Zhang; C. Huo; B. Xue; L. Wang; C. Pan","School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","3 Feb 2022","2022","15","","1373","1388","Multiimage super-resolution (MISR), as one of the most promising directions in remote sensing, has become a needy technique in the satellite market. A sequence of images collected by satellites often has plenty of views and a long time span, so integrating multiple low-resolution views into a high-resolution image with details emerges as a challenging problem. However, most MISR methods based on deep learning cannot make full use of multiple images. Their fusion modules are incapable of adapting to an image sequence with weak temporal correlations well. To cope with these problems, we propose a novel end-to-end framework called TR-MISR. It consists of three parts: An encoder based on residual blocks, a transformer-based fusion module, and a decoder based on subpixel convolution. Specifically, by rearranging multiple feature maps into vectors, the fusion module can assign dynamic attention to the same area of different satellite images simultaneously. In addition, TR-MISR adopts an additional learnable embedding vector that fuses these vectors to restore the details to the greatest extent. TR-MISR has successfully applied the transformer to MISR tasks for the first time, notably reducing the difficulty of training the transformer by ignoring the spatial relations of image patches. Extensive experiments performed on the PROBA-V Kelvin dataset demonstrate the superiority of the proposed model that provides an effective method for transformers in other low-level vision tasks.","2151-1535","","10.1109/JSTARS.2022.3143532","National Key Research and Development Program of China(grant numbers:2018AAA0100400); National Natural Science Foundation of China(grant numbers:62071466,61802407); Natural Science Foundation of Guangxi Province(grant numbers:2018GXNSFBA281086); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684717","Deep learning;end-to-end networks;feature extraction and fusion;multiimage super-resolution (MISR);remote sensing;transformers","Transformers;Superresolution;Satellites;Remote sensing;Task analysis;Deep learning;Image resolution","computer vision;deep learning (artificial intelligence);feature extraction;geophysical image processing;image fusion;image resolution;image sequences;remote sensing","TR-MISR;feature fusion;satellite market;low-resolution views;high-resolution image;MISR methods;image sequence;end-to-end framework;transformer-based fusion module;multiple feature maps;MISR tasks;image patches","","5","","84","CCBY","18 Jan 2022","","","IEEE","IEEE Journals"
"Spectral–Spatial Generative Adversarial Network for Super-Resolution Land Cover Mapping With Multispectral Remotely Sensed Imagery","C. Shang; S. Jiang; F. Ling; X. Li; Y. Zhou; Y. Du","School of Geosciences, Yangtze University, Wuhan, China; School of Geosciences, Yangtze University, Wuhan, China; Key laboratory of Monitoring and Estimate for Environment and Disaster of Hubei province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key laboratory of Monitoring and Estimate for Environment and Disaster of Hubei province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key laboratory of Monitoring and Estimate for Environment and Disaster of Hubei province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key laboratory of Monitoring and Estimate for Environment and Disaster of Hubei province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","22 Dec 2022","2023","16","","522","537","Super-resolution mapping (SRM) can effectively predict the spatial distribution of land cover classes within mixed pixels at a higher spatial resolution than the original remotely sensed imagery. The uncertainty of land cover fraction errors within mixed pixels is one of the most important factors affecting SRM accuracy. Studies have shown that SRM methods using deep learning techniques have significantly improved land cover mapping accuracy but have not coped well with spectral–spatial errors. This study proposes an end-to-end SRM model using a spectral–spatial generative adversarial network (SGS) with the direct input of multispectral remotely sensed imagery, which deals with spectral–spatial error. The proposed SGS comprises the following three parts: first, cube-based convolution for spectral unmixing is adopted to generate land cover fraction images. Second, a residual-in-residual dense block fully and jointly considers spectral and spatial information and reduces spectral errors. Third, a relativistic average GAN is designed as a backbone to further improve the super-resolution performance and reduce spectral–spatial errors. SGS was tested in one synthetic and two realistic experiments with multi/hyperspectral remotely sensed imagery as the input, comparing the results with those of hard classification and several classic SRM methods. The results showed that SGS performed well at reducing land cover fraction errors, reconstructing spatial details, removing unpleasant and unrealistic land cover artifacts, and eliminating false recognition.","2151-1535","","10.1109/JSTARS.2022.3228741","Natural Science Foundation of Hubei Province(grant numbers:2022CFB689); National Natural Science Foundation of China(grant numbers:U22A20567); National Natural Science Foundation of China(grant numbers:62071457); Key Scientific Research Projects of Water Conservancy in Hubei Province, China(grant numbers:HBSLKY202103); Application Foundation Frontier Project of Wuhan(grant numbers:2020020601012283); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9982425","Deep learning (DL);generative adversarial network (GAN);land cover fractions;spectral–spatial errors;super-resolution mapping (SRM)","Generative adversarial networks;Superresolution;Spatial resolution;Layout;Remote sensing;Graphical models;Distribution functions","geophysical image processing;image classification;image reconstruction;image resolution;land cover;terrain mapping","classic SRM methods;end-to-end SRM model;higher spatial resolution;land cover classes;land cover fraction errors;land cover fraction images;land cover mapping accuracy;mixed pixels;multispectral remotely sensed imagery;original remotely sensed imagery;SGS;spatial distribution;spatial information;spectral errors;spectral information;spectral unmixing;spectral-spatial error;spectral-spatial generative adversarial network;SRM accuracy;super-resolution land cover mapping;super-resolution mapping;super-resolution performance;unpleasant land cover artifacts;unrealistic land cover artifacts","","","","61","CCBY","12 Dec 2022","","","IEEE","IEEE Journals"
"Active Fire Detection in Multispectral Super-Resolved Sentinel-2 Images by Means of Sam-Based Approach","D. A. G. Dell'Aglio; M. Gargiulo; A. Iodice; D. Riccio; G. Ruello","DIETI, University Federico II, Via Claudio 21, Naples, Italy; DIETI, University Federico II, Via Claudio 21, Naples, Italy; DIETI, University Federico II, Via Claudio 21, Naples, Italy; DIETI, University Federico II, Via Claudio 21, Naples, Italy; DIETI, University Federico II, Via Claudio 21, Naples, Italy","2019 IEEE 5th International forum on Research and Technology for Society and Industry (RTSI)","11 Nov 2019","2019","","","124","127","In the last years, Sentinel-2 data have become extensively used by the remote sensing community due to their relatively fine spatial resolution, high revisit time ensured by the twin satellites Sentinel- 2 and, of course, their free availability. However, not all the bands are provided at the highest resolution (10 meters). For instance, the Short-Wave Infrared (SWIR) bands, very useful for fires monitoring applications, are provided at 20 meters. Therefore, in order to have a more detailed Active Fire maps, we have proposed a super-resolution data fusion method based on Convolutional Neural Network (CNN), hereafter SRNN+. Then we have compared the standard Active Fire Detection (AFDs) based on indices (AFIs) [1], widely used in literature for active fires monitoring purpose, with a method based on the Spectral Angular Mapper (SAM) [2]. The proposed analysis is validated on the widespread fires that damaged the volcano Vesuvius (Italy) during the summer of 2017.","2687-6817","978-1-7281-3815-2","10.1109/RTSI.2019.8895538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8895538","Data fusion;convolutional neural network;super-resolution;SAM;active fires;active fire indices","Spatial resolution;Measurement;Training;Monitoring;Remote sensing","fires;geophysical image processing;geophysical techniques;image resolution;neural nets;remote sensing;sensor fusion","multispectral super-resolved Sentinel-2 images;sam-based approach;Sentinel-2 data;remote sensing community;relatively fine spatial resolution;high revisit time;twin satellites Sentinel;free availability;highest resolution;10 meters;Short-Wave Infrared bands;detailed Active Fire maps;super-resolution data fusion method;Convolutional Neural Network;standard Active Fire Detection;active fires;Spectral Angular Mapper [2];widespread fires;size 20.0 A","","3","","18","IEEE","11 Nov 2019","","","IEEE","IEEE Conferences"
"A Two-step Spatio-Temporal satellite image Fusion Model for temporal changes of various LULC under one-pair prior images scenario","Yongquan Zhao; B. Huang","Department of Geography and Resource Management, The Chinese University of Hong Kong, Hong Kong, China; Department of Geography and Resource Management, The Chinese University of Hong Kong, Hong Kong, China","2016 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","24 Nov 2016","2016","","","1","5","This paper proposes a two-step spatio-temporal fusion model (TSTFM) for generating synthetic satellite remote sensing images with high-spatial and high-temporal resolution (HSaHTeR) based on one pair of prior images, which contain one low-spatial but high-temporal resolution (LSaHTeR) image and one high-spatial but low-temporal resolution (HSaLTeR) image. Considering both phenology and type surface temporal changes, the two steps in TSTFM are adopted to handle these two kinds of changes respectively, which are based on weighted mean and example-based image super-resolution approaches accordingly. In addition, a relative radiometric normalization process is conducted before performing the two-step spatio-temporal fusion (STF) process, which aims to calibrate radiometric differences of different kinds of satellite sensors. The proposed method was tested on two sets of test data: surface with mainly LULC phenology changes and surface with primarily LULC type changes. Experimental results show that TSTFM can capture both phenology and type changes efficiently and precisely even with one-pair prior images, and it can also maintain its robustness when facing extremely complex LULC.","","978-1-5090-2708-8","10.1109/ICSPCC.2016.7753699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7753699","Spatio-temporal fusion;weighted mean;image super-resolution;phenology change;type change;various LULC","MODIS;Satellites;Remote sensing;Earth;Spatial resolution;Satellite broadcasting","geophysical image processing;image fusion;image resolution;land use;radiometry;remote sensing","two-step spatio-temporal satellite image fusion model;LULC;one-pair prior images scenario;synthetic satellite remote sensing images;high-spatial and high-temporal resolution image;low-spatial but high-temporal resolution image;high-spatial but low-temporal resolution image;type surface temporal changes;phenology changes;TSTFM;weighted mean;example-based image super-resolution;relative radiometric normalization process;STF process;HSaHTeR image;LSaHTeR image;HSaLTeR image","","","","9","IEEE","24 Nov 2016","","","IEEE","IEEE Conferences"
"Multitemporal Mid-Infrared Imagery Based Calibration and Super Resolution for Gaofen-4","F. Li; L. Xin; Y. Guo; X. Jia","Oian Xuesen Laboratory of Space Technology, Beijinz, China; Oian Xuesen Laboratory of Space Technology, Beijinz, China; Western Sydney University, Parramatta, NSW, Australia; School of Engineering and Information Technology, University of New South Wales, Canberra, Australia","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","7038","7041","Gaofen-4 is the first optical geostationary satellite in China and it is in operation since 2016. Unfortunately, the mid-infrared band has a Ground Spatial Distance (GSD) of 400 m, which is low and limits its application in temperature retrieval. The calibration of this band is challenging as well. In this paper, a new data fusion method is proposed to improve both image quality and spatial resolution, by making use the advantage of high temporal resolution. Experimental results show that the reconstructed high resolution mid-infrared images not only provide more details visually but also gives more accurate and reliable temperature mapping than the original images. The proposed solution holds potential application for Gaofen-4 in the near future.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517414","Gaofen-4;super resolution;radiometric calibration;temperature retrieval","Spatial resolution;Ocean temperature;Radiometry;Calibration;Satellite broadcasting;Temperature measurement","atmospheric techniques;calibration;geophysical image processing;image resolution;infrared imaging;remote sensing;sensor fusion","mid-infrared band;temperature retrieval;data fusion method;image quality;spatial resolution;high temporal resolution;accurate temperature mapping;reliable temperature mapping;Gaofen-4;multitemporal mid-infrared imagery based calibration;optical geostationary satellite;GSD;ground spatial distance;high resolution reconstruction","","1","","8","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Multi-image Super-Resolution Algorithm Supported on Sentinel-2 Satellite Images Geolocation Error","M. Vaqueiro; J. M. Fonseca; H. Oliveira; A. Mora","SST-NOVA, Caparica, Portugal; CTS/UNINOVA, SST-NOVA, Caparica, Portugal; IT, Lisboa, Portugal IPB, Beja, Portugal; CTS/UNINOVA, SST-NOVA, Caparica, Portugal","2021 International Young Engineers Forum (YEF-ECE)","9 Aug 2021","2021","","","50","57","Every year, the hottest seasons are marked by forest fires. Monitoring these forest areas is more effective with the help of satellite imagery, since ground operations are hampered by vegetation density and height, making them less productive and more expensive. However, nowadays, freely available imagery from Sentinel-2 satellite has a maximum spatial resolution of 10 meters per pixel, a low resolution to identify small or thin structures in the image, such as roads, bridges, buildings, rivers, fuel breaks, among others.To improve image’s resolution, a new super-resolution algorithm, named KGEONP – K Geographically Nearest Pixels, is proposed in this paper. It benefits from Sentinel-2 regular observations (it has a revisit of 5 days) and the georeferencing error of its images (whose maximum value is 1.5 pixels). KGEONP seeks to add as much information as possible to the super-resolved image, by using data from K-nearest pixels and their spatial distance for computing each new pixel’s value.KGEONP was applied to Sentinel-2 images to increase resolution by a factor of 10 and was compared to state-of-the-art super-resolution techniques. It showed quite satisfactory results, with the capacity of increasing resolution and maintaining the structural data of the source images.","","978-1-6654-1264-3","10.1109/YEF-ECE52297.2021.9505092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9505092","Super-Resolution;Satellite Imagery;Earth Observation;Sentinel-2;Georeferencing Error","Meters;Interpolation;Satellites;Structural panels;Superresolution;Vegetation mapping;Forestry","fires;forestry;geophysical image processing;image resolution;remote sensing;vegetation","Sentinel-2 images;superresolution techniques;multiimage super-resolution algorithm supported;Sentinel-2 satellite images geolocation error;hottest seasons;forest fires;forest areas;satellite imagery;ground operations;vegetation density;freely available imagery;maximum spatial resolution;Sentinel-2 regular observations;georeferencing error;superresolved image;KGEONP;K geographically nearest pixels;time 5.0 d","","1","","21","IEEE","9 Aug 2021","","","IEEE","IEEE Conferences"
"High-Order Coupled Fully Connected Tensor Network Decomposition for Hyperspectral Image Super-Resolution","D. Jin; J. Liu; J. Yang; Z. Wu","Jiangsu Provincial Engineering Laboratory of Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China; Jiangsu Provincial Engineering Laboratory of Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China; Jiangsu Provincial Engineering Laboratory of Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China; School of Computer Science, Nanjing University of Science and Technology, Nanjing, China","IEEE Geoscience and Remote Sensing Letters","5 Oct 2022","2022","19","","1","5","Hyperspectral image (HSI) super-resolution addresses the problem of fusing a low-resolution HSI (LR-HSI) and a high-resolution multispectral image (HR-MSI) to produce a high-resolution HSI (HR-HSI). Tensor analysis has been proven to be an efficient method for HSI processing. However, the existing tensor-based methods of HSI super-resolution (HSI-SR) like the tensor train and tensor ring decomposition only establish an operation between adjacent two factors and are highly sensitive to the permutation of tensor modes, leading to an inadequate and inflexible representation. In this letter, we propose a novel method for HSI-SR by utilizing the specific properties of high-order tensors in fully-connected tensor network decomposition (FCTN). The proposed method first tensorizes the target HR-HSI into a high-order tensor that has multiscale spatial structures. Then, a coupled FCTN model is proposed to fuse the corresponding high-order tensors of LR-HSI and HR-MSI. Moreover, a weighted-graph regularization (WGR) is imposed on the spectral core tensors to preserve spectral information. In the proposed model, the superiorities of the FCTN lie in the outstanding capability for characterizing adequately the intrinsic correlations between any two modes of tensors and the essential invariance for transposition. Experimental results on three datasets show the effectiveness of the proposed approach as compared to other HSI-SR methods.","1558-0571","","10.1109/LGRS.2022.3207548","National Natural Science Foundation of China(grant numbers:62071204); Natural Science Foundation of Jiangsu Province(grant numbers:BK20201338); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894417","Fully-connected tensor network decomposition (FCTN);high-order tensor;hyperspectral image (HSI)","Tensors;Hyperspectral imaging;Superresolution;Correlation;Imaging;Geoscience and remote sensing;Fuses","geophysical image processing;graph theory;hyperspectral imaging;image fusion;image reconstruction;image representation;image resolution;remote sensing;tensors","hyperspectral image super-resolution;low-resolution HSI;LR-HSI;high-resolution multispectral image;high-resolution HSI;tensor analysis;HSI processing;existing tensor-based methods;HSI super-resolution;tensor train;tensor ring decomposition;tensor modes;high-order tensor;fully-connected tensor network decomposition;target HR-HSI;spectral core tensors;HSI-SR methods","","","","23","IEEE","16 Sep 2022","","","IEEE","IEEE Journals"
"A Novel Iterative Method for Improving Radar Angular Super-Resolution","X. Zhang; X. Liu","School of Information Science and Technology, Dalian Maritime University, Dalian, China; School of Information Science and Technology, Dalian Maritime University, Dalian, China","2016 International Conference on Identification, Information and Knowledge in the Internet of Things (IIKI)","5 Feb 2018","2016","","","134","137","In this paper a new method is proposed to improve radar angular super-resolution on the basis of the constrained optimization theory. We provide a quasi-BFGS algorithm for updating antenna pattern matrix so that the antenna pattern matrix and its transpose matrix could approximate a positive semi-definite matrix, then the model of radar scanning system meets the requirement of convex quadratic programming. By using Newton algorithm, the optimal solution of that model could be gained and then the target angular information is accordingly restored. Simulations manifest that a desirable resolution result is gained and it provides an amazing result that our method is superior to other methods at signal to noise ratio (SNR).","","978-1-5090-5952-2","10.1109/IIKI.2016.47","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8281188","angular super-resolution;constrained optimization;BFGS;Newton","Signal resolution;Radar antennas;Signal to noise ratio;Image resolution;Quadratic programming;Radar remote sensing","iterative methods;optimisation;radar antennas;radar resolution","constrained optimization theory;quasiBFGS algorithm;antenna pattern matrix;transpose matrix;positive semidefinite matrix;radar scanning system;convex quadratic programming;Newton algorithm;target angular information;radar angular super-resolution","","","","10","IEEE","5 Feb 2018","","","IEEE","IEEE Conferences"
"Super-Resolution ISAR Imaging for Maneuvering Target Based on Deep-Learning-Assisted Time–Frequency Analysis","J. Qian; S. Huang; L. Wang; G. Bi; X. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","3 Dec 2021","2022","60","","1","14","Traditional range-instantaneous Doppler (RID) methods for maneuvering target imaging suffer from the problems of low resolution and poor noise suppression. We propose a new super-resolution inverse synthetic aperture radar (ISAR) imaging method based on deep-learning-assisted time–frequency analysis (TFA). Our deep neural network resembles the basic structure of a U-net with two additional convolutional-upsampling layers and  $l_{1}$ -norm loss function for super-resolution generation and noise suppression. The neural network is trained in advance to learn the mapping function between the low-resolution time–frequency spectrum inputs and their high-resolution references. Then, the linear TFA assisted by the pretrained network is integrated into the RID-based ISAR imaging system and is found to achieve sharply focused and denoised target image with super-resolution. Both the simulated and real radar data are used to evaluate the performance of the proposed method. Numerical experimental results demonstrate the superiority of the proposed ISAR imaging method over traditional ones.","1558-0644","","10.1109/TGRS.2021.3050189","National Natural Science Foundation of China(grant numbers:61401077,61501375); Sichuan Science and Technology Program(grant numbers:2019YFG0099); China Postdoctoral Science Foundation(grant numbers:2015M580784); Natural Science Basis Research Plan in Shaanxi Province of China(grant numbers:2018JM6020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9330791","Deep learning;denoising;inverse synthetic aperture radar (ISAR);short-time Fourier transform (STFT);super-resolution","Radar imaging;Imaging;Radar;Superresolution;Neural networks;Noise reduction;Doppler effect","deep learning (artificial intelligence);Doppler radar;image denoising;image resolution;interference suppression;neural nets;radar imaging;synthetic aperture radar;time-frequency analysis","pretrained network;linear TFA;mapping function;norm loss function;convolutional-upsampling layers;U-net;range-instantaneous Doppler method;ISAR imaging method;denoised target image;RID-based ISAR imaging system;high-resolution references;low-resolution time-frequency spectrum inputs;super-resolution generation;deep neural network;super-resolution inverse synthetic aperture radar imaging method;noise suppression;deep-learning-assisted time-frequency analysis;maneuvering target imaging;super-resolution ISAR imaging","","10","","27","IEEE","21 Jan 2021","","","IEEE","IEEE Journals"
"A CNN-based Super-resolution Technique for Active Fire Detection on Sentinel-2 Data","M. Gargiulo; D. A. G. Dell’ Aglio; A. Iodice; D. Riccio; G. Ruello","University of Naples “Federico II”, Italy; University of Naples “Federico II”, Italy; University of Naples “Federico II”, Italy; University of Naples “Federico II”, Italy; University of Naples “Federico II”, Italy","2019 PhotonIcs & Electromagnetics Research Symposium - Spring (PIERS-Spring)","2 Mar 2020","2019","","","418","426","Remote Sensing applications can benefit from a relatively fine spatial resolution multispectral (MS) images and a high revisit frequency ensured by the twin satellites Sentinel-2. Unfortunately, only four out of thirteen bands are provided at the highest resolution of 10 meters, and the others at 20 or 60 meters. For instance the Short-Wave Infrared (SWIR) bands, provided at 20 meters, are very useful to detect active fires. Aiming to a more detailed Active Fire Detection (AFD) maps, we propose a super-resolution data fusion method based on Convolutional Neural Network (CNN) to move towards the 10-m spatial resolution the SWIR bands. The proposed CNN-based solution is compared to alternative methods in terms of some accuracy metrics. Moreover we have tested the super-resolved bands from an application point of view by monitoring active fire through classic indices. Advantages and limits of our proposed approach are validated on specific geographical area (the mount Vesuvius, close to Naples) that was damaged by widespread fires during the summer of 2017.","1559-9450","978-1-7281-3403-1","10.1109/PIERS-Spring46901.2019.9017857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9017857","","Spatial resolution;Training;Springs;Measurement;Monitoring;Photonics","fires;geophysical image processing;geophysical signal processing;image fusion;image resolution;neural nets;remote sensing;sensor fusion;terrain mapping","CNN-based super-resolution technique;Sentinel-2 data;Remote Sensing applications;relatively fine spatial resolution multispectral images;high revisit frequency;twin satellites Sentinel-2;Short-Wave Infrared bands;super-resolution data fusion method;Convolutional Neural Network;SWIR bands;CNN-based solution;super-resolved bands;Active Fire Detection maps","","8","","26","IEEE","2 Mar 2020","","","IEEE","IEEE Conferences"
"Pushing the Limits of Sentinel-2 for Building Footprint Extraction","C. Ayala; C. Aranda; M. Galar","Tracasa Instrumental, Sarriguren, Navarra; Tracasa Instrumental, Sarriguren, Navarra; Institute of Smart Cities (ISC), Public University of Navarre, Pamplona, Spain","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","322","325","Building footprint maps are of high importance nowadays since a wide range of services relies on them to work. However, activities to keep these maps up-to-date are costly and time-consuming due to the great deal of human intervention required. Several automation attempts have been carried out in the last decade aiming at fully automatizing them. However, taking into account the complexity of the task and the current limitations of semantic segmentation deep learning models, the vast majority of approaches rely on aerial imagery (<1 m). As a result, prohibitive costs and high revisit times prevent the remote sensing community from maintaining up-to-date building maps. This work proposes a novel deep learning architecture to accurately extract building footprints from high resolution satellite imagery (10 m). Accordingly, super-resolution and semantic segmentation techniques have been fused to make it possible not only to improve the building's boundary definition but also to detect buildings with sub-pixel width. As a result, fine-grained building maps at 2.5 m are generated using Sentinel-2 imagery, closing the gap between satellite and aerial semantic segmentation.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883103","Sentinel-2;Remote Sensing;Building Detection;Deep Learning;Convolutional Neural Networks","Deep learning;Image segmentation;Satellites;Buildings;Semantics;Superresolution;Neural networks","feature extraction;geophysical image processing;image resolution;image segmentation;learning (artificial intelligence);object detection;remote sensing","10 m;<;1 m;aerial imagery;aerial semantic segmentation;automation attempts;building footprint extraction;building footprint maps;buildings;deep learning architecture;fine-grained building maps;footprints;high resolution satellite imagery;high revisit times;human intervention;maps up-to-date;prohibitive costs;remote sensing community;semantic segmentation deep learning models;semantic segmentation techniques;Sentinel-2 imagery;size 1.0 m;size 10.0 m;size 2.5 m;super-resolution;up-to-date building maps","","","","12","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"An Iterative Approach to Super-Resolution using Multiple Low-Resolution Images","R. Srinath; J. Vrindavanam; V. P. Vasudev; S. S","Dept. of ECE, Nitte Meenakshi Institute of Technology, Bengaluru, India; Dept. of ECE, Nitte Meenakshi Institute of Technology, Bengaluru, India; Dept. of ECE, Nitte Meenakshi Institute of Technology, Bengaluru, India; Dept. of ECE, Nitte Meenakshi Institute of Technology, Bengaluru, India","2019 Global Conference for Advancement in Technology (GCAT)","3 Feb 2020","2019","","","1","6","Keeping in view the increasing requirements of super resolution in a wide range of applications, this paper adds to the existing literature of alternative algorithmic approach to develop a high resolution image from multiple low resolution images. The paper, after a review of the existing methods in super resolution, presents an iterative approach using multiple low-resolution images building on top of established tools like New Edge Directed Interpolation, through a novel approach. The approach tries to discover higher frequencies from a multiplicity of data samples available, and preserves these edges across iterations. The proposed method has been tested on images of a range of complexities, including on satellite images, and the results are promising.","","978-1-7281-3694-3","10.1109/GCAT47503.2019.8978291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8978291","Interpolation;Super-resolution;Image quality;Remote sensing;INEDI;edge detection","","image resolution;interpolation;iterative methods","iterative approach;super resolution approach;alternative algorithmic approach;high resolution image;multiple low resolution images;new edge directed interpolation approach","","","","20","IEEE","3 Feb 2020","","","IEEE","IEEE Conferences"
"Study on Super-Resolution of Images Obtained by Micro Satellite with CMOS Sensor","X. Jun; S. Tingting","Department of Optical Satellite Engineering, DFH Satellite Co., Ltd, Beijing, China; Department of Camera Design, Beijing Institute of Space Mechanics & Electricity, Beijing, China","2019 IEEE 4th International Conference on Signal and Image Processing (ICSIP)","17 Oct 2019","2019","","","907","910","This paper proposes a new image reconstruction algorithm to improve the resolution of images obtained by micro satellite with CMOS sensor. Satellite with CMOS Sensor can obtain images of same ground object in consecutive integration times. Because of the low attitude stability of micro satellite, there are sub-pixel displacements for same target between these images. In order to measure the displacements, three image registration algorithms, which are Maximum Mutual Information, SURF (Speeded Up Robust Features) and Keren, are compared through simulation experiment. Then, an image super-resolution reconstruction algorithm named Weighted Average Interpolation is proposed. Based on two sequential low-resolution images, one high-resolution image is acquired through Weighed Average Interpolation. Simulation result proved that PSNR in synthesized image is enhanced by 1. 44dB compared with that in bilinear interpolated image. Test chart imaging experiment showed that Average Gradient, Edge Intensity and Space Frequency of synthesized image are all obviously greater than of bilinear interpolated image. The resolution of synthesized image is effectively improved by Weighed Average Interpolation.","","978-1-7281-3660-8","10.1109/SIPROCESS.2019.8868688","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868688","super-resolution;micro satellite;CMOS sensor;image reconstruction","Interpolation;Satellites;Optical imaging;Image registration","CMOS image sensors;geophysical image processing;image reconstruction;image registration;image resolution;interpolation;remote sensing","microsatellite;CMOS sensor;image reconstruction algorithm;consecutive integration times;low attitude stability;image registration algorithms;image super-resolution reconstruction algorithm;Weighted Average Interpolation;low-resolution images;high-resolution image;Weighed Average Interpolation;synthesized image;bilinear interpolated image;test chart imaging experiment;noise figure 44.0 dB","","","","7","IEEE","17 Oct 2019","","","IEEE","IEEE Conferences"
"Optimal Endmember-Based Super-Resolution Land Cover Mapping","X. Li; X. Li; G. Foody; X. Yang; Y. Zhang; Y. Du; F. Ling","University of Chinese Academy of Sciences, Beijing, China; Chinese Academy of Sciences, Institute of Geodesy and Geophysics, Wuhan, China; School of Geography, The University of Nottingham, University Park, Nottingham, U.K.; National Engineering Research Center of Geographic Information System, China University of Geo-Sciences, Wuhan, China; Chinese Academy of Sciences, Institute of Geodesy and Geophysics, Wuhan, China; Chinese Academy of Sciences, Institute of Geodesy and Geophysics, Wuhan, China; Chinese Academy of Sciences, Institute of Geodesy and Geophysics, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","22 Jul 2019","2019","16","8","1279","1283","Super-resolution mapping (SRM) aims to determine the spatial distribution of the land cover classes contained in the area represented by mixed pixels to obtain a more appropriate and accurate map at a finer spatial resolution than the input remotely sensed image. The image-based SRM models directly use the observed images as input and can mitigate the uncertainty caused by class fraction errors. However, existing image-based SRM models always adopt a fixed set of endmembers used in the entire image, ignoring the spatial variability and spectral uncertainty of endmembers. To address this problem, this letter proposed an optimal endmember-based SRM (OESRM) model, which considers the spatial variations in endmembers, and determines the best-fit one for each coarse resolution pixel using the spectral angle and the spectral distance as the spectral similarity indexes. A Sentinel-2A and a Landsat-8 multispectral images were used to analyze the performance of OESRM, by comparing with three other SRM methods which adopt a fixed endmember set or multiple endmember sets. The results showed that OESRM generated resultant land cover maps with more spatial detail, and reduced the confusion between land cover classes with similar spectral features. The proposed OESRM model produced the results with the highest overall accuracy in both experiments, showing its effectiveness in reducing the effect of endmember uncertainty on SRM.","1558-0571","","10.1109/LGRS.2019.2894805","Chinese Academy of Sciences(grant numbers:XDA2003030201); Natural Science Foundation of Hubei Province(grant numbers:2018CFA062); Youth Innovation Promotion Association of the Chinese Academy of Sciences(grant numbers:2017384); National Natural Science Foundation of China(grant numbers:61671425); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8651308","Endmember uncertainty;optimal endmember;super-resolution mapping (SRM)","Spatial resolution;Remote sensing;Uncertainty;Graphical models;Distribution functions;Indexes","geophysical image processing;image classification;image resolution;land cover;terrain mapping","endmember uncertainty;optimal endmember-based super-resolution land cover;super-resolution mapping;spatial distribution;land cover classes;mixed pixels;appropriate map;accurate map;finer spatial resolution;observed images;class fraction errors;fixed set;spatial variability;spectral uncertainty;optimal endmember-based SRM model;spatial variations;coarse resolution pixel;spectral angle;spectral distance;spectral similarity indexes;Landsat-8 multispectral images;SRM methods;fixed endmember;multiple endmember sets;resultant land cover maps;OESRM model;spectral features;input remotely sensed image;image-based SRM models;Sentinel-2A","","6","","21","IEEE","24 Feb 2019","","","IEEE","IEEE Journals"
"Multimodal Sensors Image Fusion for Higher Resolution Remote Sensing Pan Sharpening","Y. Liu; Q. Teng; X. He; C. Ren; H. Chen","College of Electronics and Information Engineering, Sichuan University, Chengdu, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, China","IEEE Sensors Journal","14 Sep 2022","2022","22","18","18021","18034","Panchromatic (PAN) sensors and multispectral (MS) sensors are usually applied to remote sensing tasks. Pan sharpening is an effective image fusion method based on multimodal sensors. In pan sharpening, high-resolution (HR) PAN images from PAN sensors and corresponding low-resolution MS images from MS sensors are used to obtain the HR MS images. Normally, the ideal pan-sharpening image is a fused MS image with the same resolution as the PAN image. We hope to obtain the pan-sharpening images with higher resolution, which will not only preserve spatial structure information and spectral information from PAN images and MS images but also achieve super-resolution reconstruction. For this purpose, a novel pan-sharpening framework, called multilevel and multiscale fusion network (MLMSFN), is constructed. To our knowledge, our framework is the first work to achieve beyond the limit of existing image resolution in pan sharpening. We evaluate the effectiveness of our designed method, and the experiments testify that our method can obtain higher resolution pan-sharpening images.","1558-1748","","10.1109/JSEN.2022.3195243","National Natural Science Foundation of China(grant numbers:61871279,62211530110); Fundamental Research Funds for the Central Universities(grant numbers:2021SCU12061); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9851610","Multilevel and multiscale;multimodal sensors;pan sharpening;super-resolution (SR)","Image resolution;Image reconstruction;Task analysis;Remote sensing;Image sensors;Spatial resolution;Superresolution","geophysical image processing;image fusion;image reconstruction;image resolution;remote sensing","multimodal sensors image fusion;higher resolution remote sensing pan sharpening;panchromatic sensors;multispectral sensors;remote sensing tasks;effective image fusion method;high-resolution PAN images;PAN sensors;corresponding low-resolution;MS sensors;HR MS images;ideal pan-sharpening image;fused MS image;PAN image;super-resolution reconstruction;pan-sharpening framework;image resolution;higher resolution pan-sharpening images","","","","57","IEEE","5 Aug 2022","","","IEEE","IEEE Journals"
"Hyperspectral Image Super-Resolution Based on Spatial and Spectral Correlation Fusion","C. Yi; Y. -Q. Zhao; J. C. -W. Chan","Key Laboratory of Information Fusion Technology, Ministry of Education of China, School of Automation, Northwestern Polytechnical University, Xi’an, China; Key Laboratory of Information Fusion Technology, Ministry of Education of China, School of Automation, Northwestern Polytechnical University, Xi’an, China; Department of Electronics and Informatics, Vrije Universiteit Brussel, Brussel, Belgium","IEEE Transactions on Geoscience and Remote Sensing","22 Jun 2018","2018","56","7","4165","4177","Super-resolution image reconstruction has been utilized to overcome the problem of spatial resolution limitation in hyperspectral (HS) imaging. To improve the spatial resolution of HS image, this paper proposes an HS-multispectral (MS) fusion method, which exploits spatial and spectral correlations and proper regularization. High spatial correlation between MS image and the desired high-resolution HS image is conserved via an over-completed dictionary, and the spectral degradation between them projected onto the space of sparsity is applied as the spectral constraint. The high spectral correlation between high-spatial- and low-spatial-resolution HS image is preserved through linear spectral unmixing. The idea of an interactive feedback proposed in our previous work is also used when dealing with spatial reconstruction and unmixing. Low-rank property is introduced in this paper to regularize the sparse coefficients of the HS patch matrix, which is utilized as the spatial constraint. Experiments on both simulated and real data sets demonstrate that the proposed fusion algorithm achieves lower spectral distortions and the super-resolution results are superior to those of other state-of-the-art methods.","1558-0644","","10.1109/TGRS.2018.2828042","National Natural Science Foundation of China(grant numbers:61771391,61371152); National Natural Science Foundation of China(grant numbers:61511140292); Fundamental Research Funds for the Central Universities(grant numbers:3102015ZY045); China Scholarship Council(grant numbers:201706290150); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8358017","Hyperspectral (HS) image;low rank;spatial–spectral correlation;super-resolution enhancement","Correlation;Spatial resolution;Sparse matrices;Dictionaries;Degradation;Image reconstruction","geophysical image processing;image fusion;image reconstruction;image representation;image resolution","hyperspectral image super-resolution;spatial correlation fusion;spectral correlation fusion;super-resolution image reconstruction;spatial resolution limitation;hyperspectral imaging;HS-multispectral fusion method;spatial correlations;spectral correlations;high spatial correlation;MS image;high-resolution HS image;spectral degradation;spectral constraint;high spectral correlation;low-spatial-resolution HS image;linear spectral unmixing;spatial reconstruction;HS patch matrix;spatial constraint;fusion algorithm achieves;lower spectral distortions;super-resolution results","","48","","45","IEEE","11 May 2018","","","IEEE","IEEE Journals"
"CNN-Based Super-Resolution of Hyperspectral Images","P. V. Arun; K. M. Buddhiraju; A. Porwal; J. Chanussot","IIT Bombay, Mumbai, India; IIT Bombay, Mumbai, India; IIT Bombay, Mumbai, India; LJK, University of Grenoble Alpes, INRIA, CNRS, Grenoble INP, Grenoble, France","IEEE Transactions on Geoscience and Remote Sensing","27 Aug 2020","2020","58","9","6106","6121","Single-image super-resolution (SISR) techniques attempt to reconstruct the finer resolution version of a given image from its coarser version. In the SISR of hyperspectral data sets, the simultaneous consideration of spectral bands is crucial for ensuring the spectral fidelity. However, the high spectral resolution of these data sets affects the performance of conventional approaches. This research proposes the design of 3-D convolutional neural network (CNN)-based SISR architectures that can map the spatial-spectral characteristics of hypercubes to a finer spatial resolution. The proposed approaches facilitate the simultaneous optimization of sparse codes and dictionaries with regard to the super-resolution objective. Our main hypothesis is that the consideration of spectral aspects is essential for the spatial enhancement of hyperspectral images. Also, we propose that the regularized deconvolution of a coarser-scale hypercube, using learned 3-D filters, yields the required high-resolution version. Based on these hypotheses, a convolution-deconvolution framework is proposed to super-resolve the hypercubes in parallel with the reconstruction of a set of regularizing features. Novel sparse code optimization sub-networks proposed in this article give better performance than the existing strategies. The endmember similarities and hyperspectral image prior are considered while designing the proposed loss functions. In order to improve the generalizability, a collaborative spectral unmixing strategy is employed to refine the spectral base of the super-resolved result. The spatial-spectral accuracy of the super-resolved hypercubes, in terms of the validity of regularizing features and endmembers, is explored to devise an optimal ensemble strategy. The experiments, over different data sets, confirm better accuracy of the proposed frameworks compared to the prominent approaches.","1558-0644","","10.1109/TGRS.2020.2973370","Department of Science and Technology, Government of India, through the Network Project on Imaging Spectroscopy and Applications (NISA); MIAI @ Grenoble Alpes(grant numbers:ANR-19-P3IA-0003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9018371","Alternating direction method of multiplier (ADMM);fast iterative shrinkage thresholding algorithm (FISTA);hyperspectral;super-resolution","Spatial resolution;Hyperspectral imaging;Image reconstruction;Dictionaries;Convolutional codes","convolutional neural nets;deconvolution;hyperspectral imaging;image coding;image enhancement;image filtering;image reconstruction;image resolution;learning (artificial intelligence);neural net architecture","CNN-based super-resolution;hyperspectral image enhancement;single-image super-resolution techniques;hyperspectral data sets;simultaneous consideration;spectral bands;spectral fidelity;high spectral resolution;3D convolutional neural network-based SISR architectures;spatial-spectral characteristics;spatial resolution;simultaneous optimization;super-resolution objective;spatial enhancement;regularized deconvolution;coarser-scale hypercube;convolution-deconvolution framework;novel sparse code optimization sub-networks;collaborative spectral unmixing strategy;spectral base;spatial-spectral accuracy;super-resolved hypercubes;learned 3D filters;sparse code optimization;endmember similarities;optimal ensemble strategy;loss functions","","36","","77","IEEE","28 Feb 2020","","","IEEE","IEEE Journals"
"Deep Hyperspectral Prior: Single-Image Denoising, Inpainting, Super-Resolution","O. Sidorov; J. Y. Hardeberg","The Norwegian Colour and Visual Computing Laboratory, NTNU, Gjøvik, Norway; Norwegian Colour and Visual Computing Laboratory, NTNU, Gjovik, Norway","2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)","5 Mar 2020","2019","","","3844","3851","Deep learning algorithms have demonstrated state-of-the-art performance in various tasks of image restoration. This was made possible through the ability of CNNs to learn from large exemplar sets. However, the latter becomes an issue for hyperspectral image processing where datasets commonly consist of just a few images. In this work, we propose a new approach to denoising, inpainting, and super-resolution of hyperspectral image data using intrinsic properties of a CNN without any training. The performance of the given algorithm is shown to be comparable to the performance of trained networks, while its application is not restricted by the availability of training data. This work is an extension of original ""deep prior"" algorithm to hyperspectral imaging domain and 3D-convolutional networks.","2473-9944","978-1-7281-5023-9","10.1109/ICCVW.2019.00477","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022040","Hyperspectral Imaging;Deep Learning;Denoising;Super resolution;Inpainting;Deep Image Prior;Remote sensing;Image generation;3D CNN;Single image","Three-dimensional displays;Hyperspectral imaging;Two dimensional displays;Image resolution;Task analysis;Noise reduction;Convolutional codes","convolutional neural nets;hyperspectral imaging;image denoising;image resolution;image restoration;learning (artificial intelligence);set theory","3D-convolutional networks;CNNs;deep hyperspectral prior;hyperspectral imaging domain;deep prior algorithm;intrinsic properties;hyperspectral image data;hyperspectral image processing;exemplar sets;image restoration;deep learning algorithms;super-resolution;single-image denoising","","70","","40","IEEE","5 Mar 2020","","","IEEE","IEEE Conferences"
"A bayesian multi-frame image super-resolution algorithm using the Gaussian Information Filter","M. Woods; A. Katsaggelos","Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","19 Jun 2017","2017","","","1368","1372","Multi-frame image super-resolution (SR) is an image processing technology applicable to any digital, pixilated camera that is limited, by construction, to a certain number of pixels. The objective of SR is to utilize signal processing to overcome the physical limitation and emulate the “capabilities” of a camera with a higher-density pixel array. SR is well known to be an ill-posed problem and, consequently, state-of-the-art solutions approach it statistically, typically making use of Bayesian inference. Unfortunately, direct marginalization of the posterior distribution resulting from the Bayesian modeling is not analytically tractable. An approximation method, such as Variational Bayesian Inference (VBI), is a powerful tool that retains the advantages of statistical modeling. However, its derivation is tedious and model specific. In this paper, we propose an alternative approximate inference methodology, based upon the well-established, Gaussian Information Filter, which offers a much simpler mathematical derivation while retaining the statistical advantages of VBI.","2379-190X","978-1-5090-4117-6","10.1109/ICASSP.2017.7952380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7952380","Super-Resolution;Image-Processing;Inverse Problems;Remote Sensing;Photogrammetry","Bayes methods;Current measurement;Information filters;Mathematical model;Image resolution;Cameras;Computational modeling","approximation theory;Bayes methods;Gaussian processes;image resolution;inference mechanisms;information filters","Bayesian multiframe image super-resolution algorithm;Gaussian information filter;SR;image processing technology;pixilated camera;higher-density pixel array;approximation method;variational Bayesian inference;VBI;statistical modeling;approximate inference methodology","","4","","18","IEEE","19 Jun 2017","","","IEEE","IEEE Conferences"
"Unsupervised Deep Hyperspectral Super-Resolution With Unregistered Images","J. Nie; L. Zhang; W. Wei; C. Ding; Y. Zhang","School of Computer Science, Northwestern Polytechnical University, Xi’an, Shaanxi, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, Shaanxi, China; Research & Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen, China; School of Computer Science & Technology, Xi’an University of Posts and Telecommunications, Xi’an, Shaanxi, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, Shaanxi, China","2020 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2020","2020","","","1","6","Fusion based hyperspectral image (HSI) super-resolution has long been the research focus of hyperspectral image processing since it can generate a high-resolution (HR) HSI in both spatial and spectral domains. However, the success of the existing fusion based HSI super-resolution methods depends on the premise that the images utilized for fusion (i.e. the input low-spatial-resolution HSI and the low-spectral-resolution multispectral image) are exactly registered. Although such a premise is too idealistic to comply with in real cases, few efforts have considered this problem. To fill this gap, we propose to incorporate image registration into HSI super-resolution for joint unsupervised learning in this study. Specifically, a spatial transformer network (STN) is introduced to learn the parameters of the affine transformation between the input two images. In order to avoid over-fitting, we constrain the STN with a novel constraint during learning. By doing this, both the STN and super-resolution network can be cast into a weighted joint learning model without any supervision from the latent HR HSI. Experimental results demonstrate the effectiveness of the proposed method in coping with unregistered input images.","1945-788X","978-1-7281-1331-9","10.1109/ICME46284.2020.9102881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102881","Hyperspectral image fusion;unregistered image pairs;unsupervised","Spatial resolution;Image reconstruction;Hyperspectral imaging;Spectral analysis;Image registration","geophysical image processing;hyperspectral imaging;image fusion;image reconstruction;image registration;image resolution;learning (artificial intelligence);remote sensing;unsupervised learning","input low-spatial-resolution HSI;low-spectral-resolution multispectral image;image registration;joint unsupervised learning;spatial transformer network;super-resolution network;latent HR HSI;unregistered input images;unsupervised deep hyperspectral super-resolution;unregistered images;fusion based hyperspectral image super-resolution;hyperspectral image processing;high-resolution HSI;spatial domains;spectral domains;existing fusion;HSI super-resolution methods","","2","","23","IEEE","9 Jun 2020","","","IEEE","IEEE Conferences"
"Adaptive artificial bee colony based parameter selection for subpixel mapping multiagent system in remote-sensing imagery","D. Regan; S. K. Srivatsa","St. Peter's University, Chennai, India; Prathyusha Institute of Technology & Management, Chennai, India","2015 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)","13 Aug 2015","2015","","","1","8","Remote sensing has become an important source of land use/cover information at a range of spatial and temporal scales. The existence of mixed pixels is a major problem in remote-sensing image classification. Although the soft classification and spectral unmixing techniques can obtain an abundance of different classes in a pixel to solve the mixed pixel problem, the subpixel spatial attribution of the pixel will still be unknown. The subpixel mapping technique can effectively solve this problem by providing a fine-resolution map of class labels from coarser spectrally unmixed fraction images. However, most traditional subpixel mapping algorithms treat all mixed pixels as an identical type, either boundary-mixed pixel or linear subpixel, leading to incomplete and inaccurate results. To improve the subpixel mapping accuracy, this paper proposes an adaptive subpixel mapping framework based on a multiagent system for remote sensing imagery. In the proposed multiagent subpixel mapping framework, three kinds of agents, namely, feature detection agents, subpixel mapping agents and decision agents, are designed to solve the subpixel mapping problem. This confirms that MASSM is appropriate for the subpixel mapping of remote-sensing images. But the major problem is that the selection of the parameters becomes assumption in order to overcome these problems proposed work focus on adaptive selection of parameters based on the optimization methods, it automatically selects the parameters value in the classification, and it improves the classification results in the remote-sensing imagery. Experiments with artificial images and synthetic remote-sensing images were performed to evaluate the performance of the proposed artificial bee colony based optimization subpixel mapping algorithm in comparison with the hard classification method and other subpixel mapping algorithms: subpixel mapping based on a back-propagation neural network and the spatial attraction model. The experimental results indicate that the proposed algorithm outperforms the other two subpixel mapping algorithms in reconstructing the different structures in mixed pixels.","","978-1-4799-6818-3","10.1109/ICIIECS.2015.7193224","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7193224","Hyperspectral Image Sub-Pixel Mapping;Remote Sensing;Resolution;Enhancement;Subpixel Mapping;Super-Resolution Mapping;Artificial Bee Colony","Remote sensing;Spatial resolution;Lead;Classification algorithms;Image reconstruction;Indexes","backpropagation;image classification;remote sensing","adaptive artificial bee colony based parameter selection;subpixel mapping multiagent system;remote sensing;image classification;soft classification;spectral unmixing techniques;boundary-mixed pixel;linear subpixel;adaptive subpixel mapping;feature detection agents;subpixel mapping agents;decision agents;back-propagation neural network;spatial attraction model","","","","33","IEEE","13 Aug 2015","","","IEEE","IEEE Conferences"
"A Spectral–Spatial Jointed Spectral Super-Resolution and Its Application to HJ-1A Satellite Images","X. Han; H. Zhang; J. -H. Xue; W. Sun","Department of Electronic Engineering, Institute for Ocean Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Institute for Ocean Engineering, Tsinghua University, Beijing, China; Department of Statistical Science, University College London, London, U.K.; Department of Electronic Engineering, Institute for Ocean Engineering, Tsinghua University, Beijing, China","IEEE Geoscience and Remote Sensing Letters","30 Dec 2021","2022","19","","1","5","To generate a high-spatial-resolution hyperspectral (HHS) image from a high-spatial-resolution multispectral (HMS) image, both spatial information and spectral information should be considered simultaneously if we want to build a more accurate mapping from HMS to HHS. To this end, a spectral and spatial jointed spectral super-resolution method is proposed in this letter using an end-to-end learning strategy for each subspace with the cluster-based multibranch backpropagation neural network (BPNN). More specifically, in addition to the spectra similarity, a modified superpixel segmentation is introduced to jointly take spatial contextual information into account, and a new framework with it is given. Comparisons on the Columbia University Automated Vision Environment (CAVE) data set show that our proposed method outperforms other relative state-of-the-art methods more than 0.3 in the root mean squared error (RMSE) and more than 1.0 in the spectral angle mapper (SAM) index. Especially, an exemplary application is demonstrated using the synchronized observation data collected by the multispectral and hyperspectral sensors mounted on the HJ-1A satellite at the same time.","1558-0571","","10.1109/LGRS.2021.3073501","National Nature Science Foundation of China(grant numbers:41971294); China Postdoctoral Science Foundation(grant numbers:2020M680560); Cross-Media Intelligent Technology Project of Beijing National Research Center for Information Science and Technology(grant numbers:BNR2019TD01022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9420149","HJ-1A satellite image;spectral and spatial jointed;spectral super-resolution;subspace-based learning","Superresolution;Satellites;Image segmentation;Training;Image reconstruction;Neural networks;Sun","backpropagation;geophysical image processing;geophysical signal processing;geophysical techniques;image classification;image resolution;image segmentation;mean square error methods;neural nets;remote sensing;spectral analysis","spatial information;spectral information;HMS;HHS;spectral resolution method;spatial jointed spectral super-resolution method;end-to-end learning strategy;cluster-based multibranch backpropagation neural network;spatial contextual information;Columbia University Automated Vision Environment data;spectral angle mapper index;spectral-spatial jointed spectral super-resolution;satellite images;high-spatial-resolution hyperspectral image;high-spatial-resolution multispectral image;current 1.0 A","","5","","23","IEEE","30 Apr 2021","","","IEEE","IEEE Journals"
"Self-FuseNet: Data Free Unsupervised Remote Sensing Image Super-Resolution","D. Mishra; O. Hadar","School of Electrical and Computer Engineering, Ben Gurion University of the Negev, Beersheba, Israel; School of Electrical and Computer Engineering, Ben Gurion University of the Negev, Beersheba, Israel","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","8 Feb 2023","2023","16","","1710","1727","Real-world degradations deviate from ideal degradations, as most deep learning-based scenarios involve the ideal synthesis of low-resolution (LR) counterpart images by popularly used bicubic interpolation. Moreover, supervised learning approaches rely on many high-resolution (HR) and LR image pairings to reconstruct missing information based on their association, developed by complex long hours of deep neural network training. Additionally, the trained model's generalizability on various image datasets with various distributions is not guaranteed. To overcome this challenge, we proposed our novel Self-FuseNet, particularly for extremely poor-resolution satellite images. Also, the network exhibits strong generalization performance on additional datasets (both “ideal” and “nonideal” scenarios). The network is especially for those image datasets suffering from the following two significant limitations: 1) nonavailability of ground truth HR images; 2) limitation of a large count of the unpaired dataset for deep neural network training. The benefit of the proposed model is threefold: 1) it does not require any significant extensive training data, either paired or unpaired but only a single LR image without prior knowledge of its distribution; 2) it is a simple and effective model for super-resolving very poor-resolution images, saving computational resources and time; 3) using UNet, the processing of data are accelerated by the network's wide skip connections, allowing image reconstruction with fewer parameters. Rather than using an inverse approach, as common in most deep learning scenarios, we introduced a forward approach to super-resolve exceptionally LR remote sensing images. This demonstrates its supremacy over recently proposed state-of-the-art methods for unsupervised single real-world image blind super-resolution.","2151-1535","","10.1109/JSTARS.2023.3239758","The Ministry of Science and Technology, Israel(grant numbers:3-17380); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025676","Blind image super-resolution (SR);data fusion;deep learning;self-fusion;unsupervised image super-resolution (SR)","Feature extraction;Superresolution;Satellites;Training;Image reconstruction;Spatial resolution;Deep learning","","","","","","64","CCBY","25 Jan 2023","","","IEEE","IEEE Journals"
"A Remote-Sensing Image Pan-Sharpening Method Based on Multi-Scale Channel Attention Residual Network","X. Li; F. Xu; X. Lyu; Y. Tong; Z. Chen; S. Li; D. Liu","College of Computer and Information, Hohai University, Nanjing, China; College of Computer and Information, Hohai University, Nanjing, China; College of Computer and Information, Hohai University, Nanjing, China; School of Information Engineering, Zhengzhou University, Zhengzhou, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Information Center, Yellow River Conservancy Commission, Zhengzhou, China; Information Center, Yellow River Conservancy Commission, Zhengzhou, China","IEEE Access","11 Feb 2020","2020","8","","27163","27177","Pan-sharpening is a significant task that aims to generate high spectral- and spatial- resolution remote-sensing image by fusing multi-spectral (MS) and panchromatic (PAN) image. The conventional approaches are insufficient to protect the fidelity both in spectral and spatial domains. Inspired by the robust capability and outstanding performance of convolutional neural networks (CNN) in natural image super-resolution tasks, CNN-based pan-sharpening methods are worthy of further exploration. In this paper, a novel pan-sharpening method is proposed by introducing a multi-scale channel attention residual network (MSCARN), which can represent features accurately and reconstruct a pan-sharpened image comprehensively. In MSCARN, the multi-scale feature extraction blocks comprehensively extract the coarse structures and high-frequency details. Moreover, the multi-residual architecture guarantees the consistency of feature learning procedure and accelerates convergence. Specifically, we introduce a channel attention mechanism to recalibrate the channel-wise features by considering interdependencies among channels adaptively. The extensive experiments are implemented on two real-datasets from GaoFen series satellites. And the results show that the proposed method performs better than the existing methods both in full-reference and no-reference metrics, meanwhile, the visual inspection displays in accordance with the quantitative metrics. Besides, in comparison with pan-sharpening by convolutional neural networks (PNN), the proposed method achieves faster convergence rate and lower loss.","2169-3536","","10.1109/ACCESS.2020.2971502","National Basic Research Program of China (973 Program)(grant numbers:2018YFC0407105); Technology Project of China Huaneng Group(grant numbers:MW 2017/P28); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8981952","Pan-sharpening;deep learning;multi-scale feature extraction;multi-residual learning;channel-attention mechanism;convergence acceleration","Feature extraction;Remote sensing;Spatial resolution;Computer architecture;Convolution;Convolutional neural networks","convolutional neural nets;feature extraction;geophysical image processing;image fusion;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","remote-sensing image pan-sharpening method;multiscale channel attention residual network;spectral domains;spatial domains;convolutional neural networks;natural image super-resolution tasks;CNN-based pan-sharpening methods;pan-sharpened image;multiscale feature extraction blocks;multiresidual architecture;channel attention mechanism;channel-wise features;spatial-resolution remote-sensing image","","16","","52","CCBY","4 Feb 2020","","","IEEE","IEEE Journals"
"Spatial–Temporal Super-Resolution Land Cover Mapping With a Local Spatial–Temporal Dependence Model","X. Li; F. Ling; G. M. Foody; Y. Ge; Y. Zhang; L. Wang; L. Shi; X. Li; Y. Du","School of Geography, The University of Nottingham, University Park, Nottingham, U.K.; Sino-Africa Joint Research Centre, Chinese Academy of Sciences, Wuhan, China; School of Geography, The University of Nottingham, University Park, Nottingham, U.K.; State Key Laboratory of Resources and Environmental Information System, Institute of Geographic Sciences and Natural Resources Research, Chinese Academy of Sciences, Beijing, China; Sino-Africa Joint Research Centre, Chinese Academy of Sciences, Wuhan, China; Sino-Africa Joint Research Centre, Chinese Academy of Sciences, Wuhan, China; Sino-Africa Joint Research Centre, Chinese Academy of Sciences, Wuhan, China; Sino-Africa Joint Research Centre, Chinese Academy of Sciences, Wuhan, China; Sino-Africa Joint Research Centre, Chinese Academy of Sciences, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","24 Jun 2019","2019","57","7","4951","4966","The mixed pixel problem is common in remote sensing. A soft classification can generate land cover class fraction images that illustrate the areal proportions of the various land cover classes within pixels. The spatial distribution of land cover classes within each mixed pixel is, however, not represented. Super-resolution land cover mapping (SRM) is a technique to predict the spatial distribution of land cover classes within the mixed pixel using fraction images as input. Spatial-temporal SRM (STSRM) extends the basic SRM to include a temporal dimension by using a finer-spatial resolution land cover map that pre- or postdates the image acquisition time as ancillary data. Traditional STSRM methods often use one land cover map as the constraint, but neglect the majority of available land cover maps acquired at different dates and of the same scene in reconstructing a full state trajectory of land cover changes when applying STSRM to time-series data. In addition, the STSRM methods define the temporal dependence globally, and neglect the spatial variation of land cover temporal dependence intensity within images. A novel local STSRM (LSTSRM) is proposed in this paper. LSTSRM incorporates more than one available land cover map to constrain the solution, and develops a local temporal dependence model, in which the temporal dependence intensity may vary spatially. The results show that LSTSRM can eliminate speckle-like artifacts and reconstruct the spatial patterns of land cover patches in the resulting maps, and increase the overall accuracy compared with other STSRM methods.","1558-0644","","10.1109/TGRS.2019.2894773","Chinese Academy of Sciences(grant numbers:XDA 2003030201); Youth Innovation Promotion Association CAS(grant numbers:2017384); National Natural Science Foundation of China(grant numbers:61671425,51809250); Natural Science Foundation of Hubei Province(grant numbers:2018CFA062); British Academy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8677291","Image series;spatial dependence;super-resolution mapping (SRM);temporal dependence","Spatial resolution;Remote sensing;Adaptation models;Graphical models;Distribution functions;Forestry","geophysical image processing;image classification;image resolution;image segmentation;land cover;terrain mapping;vegetation mapping","STSRM methods;land cover temporal dependence intensity;local temporal dependence model;land cover patches;super-resolution land cover mapping;mixed pixel problem;land cover class fraction images;land cover changes;land cover map;spatial-temporal SRM;local spatial-temporal dependence model","","9","","57","IEEE","29 Mar 2019","","","IEEE","IEEE Journals"
"Super-Resolution Multilayer Structure Analysis via Depth Adaptive Compressed Sensing for Terahertz Subsurface Imaging","H. Morimoto; S. Kidera","Graduate School of Informatics and Engineering, University of Electro-Communications, Tokyo, Japan; Japan Science Technology Agency, Saitama, Japan","IEEE Geoscience and Remote Sensing Letters","24 Dec 2021","2022","19","","1","5","Super-resolution subsurface imaging based on sparse regularization is presented in assuming the terahertz (THz) band multilayer structure analysis. The THz wave subsurface imaging with  $\mu $ -scale spatial resolution and penetration depth are promising for several applications, such as nondestructive testing and chemical/biomedical compound analyses. The sparse regularization-based compressed sensing (CS) approach has considerable potential to provide super-resolution subsurface imaging in a time-of-flight estimation. However, using optical lens-based measurements, e.g., THz time-domain spectroscopic (THz-TDS) systems, a depth resolution is highly dependent on the depth of each layer, which becomes more critical in the out-of-focus case. This study demonstrated that the above depth-dependence could be solved by using an appropriate depth-dependent reference signal, by using the THz-TDS measured data.","1558-0571","","10.1109/LGRS.2020.3043481","Japan Science Technology Agency (JST), Precursory Research for Embryonic Science and Technology (PRESTO), Japan(grant numbers:JPMJPR1771); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9301180","Compressed sensing (CS);multilayer structure analysis;super-resolution depth imaging;terahertz time-domain spectroscopic (THz-TDS) system","Imaging;Signal resolution;Bandwidth;Nonhomogeneous media;Dielectrics;Dielectric measurement;Spatial resolution","","","","2","","14","IEEE","21 Dec 2020","","","IEEE","IEEE Journals"
"A Detection and Information Extraction Approach for UAV Swarm","D. Yang; W. Yi; Z. Ren; H. Wang; Y. Huang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","3347","3350","Unmanned aerial vehicle (UAV) swarm has shown great potential in civilian and military applications. Consequently, there is a high demand for accurate UAV swarm detection and information estimation. In this paper, a detection and information extraction approach for UAV swarm is proposed. First of all, in response to resolving the closely spaced UAVs, we use the pulse compression technique in range dimension and super-resolution technique in azimuth dimension, and we can get a super-resolution result. Subsequently, a constant false alarm rate (CFAR) detection-clustering algorithm is used in the super-resolution result to detect the targets in the UAV swarm and estimate the number of targets. Lastly, the contour estimation of the UAV swarm is obtained by a convex hull algorithm used in the CFAR detection-clustering result. In addition, simulation results are given to verify the effectiveness of the proposed approach.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884648","UAV swarm;radar detection;super-resolution;target number estimation;swarm contour estimation","Radar remote sensing;Azimuth;Simulation;Superresolution;Estimation;Radar;Autonomous aerial vehicles","autonomous aerial vehicles;feature extraction;image resolution;pattern clustering;radar detection;remotely operated vehicles","UAV swarm;unmanned aerial vehicle swarm;information estimation;information extraction approach;closely spaced UAVs;range dimension;super-resolution technique;super-resolution result;constant false alarm rate detection-clustering algorithm;CFAR detection-clustering result","","","","10","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Improving the Spatial Resolution of Landsat TM/ETM+ Through Fusion With SPOT5 Images via Learning-Based Super-Resolution","H. Song; B. Huang; Q. Liu; K. Zhang","Nanjing University of Information Science and Technology, Nanjing, China; Chinese University of Hong Kong, Shatin, Hong Kong; Nanjing University of Information Science and Technology, Nanjing, China; Nanjing University of Information Science and Technology, Nanjing, China","IEEE Transactions on Geoscience and Remote Sensing","16 Sep 2014","2015","53","3","1195","1204","To take advantage of the wide swath width of Landsat Thematic Mapper (TM)/Enhanced Thematic Mapper Plus (ETM+) images and the high spatial resolution of Système Pour l'Observation de la Terre 5 (SPOT5) images, we present a learning-based super-resolution method to fuse these two data types. The fused images are expected to be characterized by the swath width of TM/ETM+ images and the spatial resolution of SPOT5 images. To this end, we first model the imaging process from a SPOT image to a TM/ETM+ image at their corresponding bands, by building an image degradation model via blurring and downsampling operations. With this degradation model, we can generate a simulated Landsat image from each SPOT5 image, thereby avoiding the requirement for geometric coregistration for the two input images. Then, band by band, image fusion can be implemented in two stages: 1) learning a dictionary pair representing the high- and low-resolution details from the given SPOT5 and the simulated TM/ETM+ images; 2) super-resolving the input Landsat images based on the dictionary pair and a sparse coding algorithm. It is noteworthy that the proposed method can also deal with the conventional spatial and spectral fusion of TM/ETM+ and SPOT5 images by using the learned dictionary pairs. To examine the performance of the proposed method of fusing the swath width of TM/ETM+ and the spatial resolution of SPOT5, we illustrate the fusion results on the actual TM images and compare with several classic pansharpening methods by assuming that the corresponding SPOT5 panchromatic image exists. Furthermore, we implement the classification experiments on both actual images and fusion results to demonstrate the benefits of the proposed method for further classification applications.","1558-0644","","10.1109/TGRS.2014.2335818","Hong Kong Research Grant Council(grant numbers:CUHK 444612); National Natural Science Foundation of China(grant numbers:61272223); National Science Foundation of Jiangsu Province(grant numbers:BK2012045); Nanjing University of Information Science and Technology Scientific Research Foundation(grant numbers:S8113049001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6866167","Landsat Thematic Mapper (TM) or Enhanced Thematic Mapper Plus (ETM+) image;spatial resolution;Système Pour l'Observation de la Terre 5 (SPOT5) image;super-resolution;swath width;Landsat Thematic Mapper (TM) or Enhanced Thematic Mapper Plus (ETM+) image;spatial resolution;Système Pour l'Observation de la Terre 5 (SPOT5) image;super-resolution;swath width","Spatial resolution;Dictionaries;Training;Degradation;Sensors;Satellites","geophysical image processing;image classification;image fusion;image resolution;learning (artificial intelligence);remote sensing","classification experiments;image fusion;Enhanced Thematic Mapper Plus;Landsat Thematic Mapper;learning-based superresolution;SPOT5 images;Landsat TM/ETM+ images;spatial resolution","","49","","34","IEEE","25 Jul 2014","","","IEEE","IEEE Journals"
"Super-Resolution of Hyperspectral Images: Use of Optimum Wavelet Filter Coefficients and Sparsity Regularization","R. C. Patel; M. V. Joshi","Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar, India; Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar, India","IEEE Transactions on Geoscience and Remote Sensing","9 Oct 2014","2015","53","4","1728","1736","Hyperspectral images (HSIs) have high spectral resolution, but they suffer from low spatial resolution. In this paper, a new learning-based approach for super-resolution (SR) using the discrete wavelet transform (DWT) is proposed. The novelty of our approach lies in designing application-specific wavelet basis (filter coefficients). An initial estimate of SR is obtained by using these filter coefficients while learning the high-frequency details in the wavelet domain. The final solution is obtained using a sparsity-based regularization framework, in which image degradation and the sparseness of SR are estimated using the estimated wavelet filter coefficients (EWFCs) and the initial SR estimate, respectively. The advantage of the proposed algorithm lies in 1) the use of EWFCs to represent an optimal point spread function to model image acquisition process; 2) use of sparsity prior to preserve neighborhood dependencies in SR image; and 3) avoiding the use of registered images while learning the initial estimate. Experiments are conducted on three different kinds of images. Visual and quantitative comparisons confirm the effectiveness of the proposed method.","1558-0644","","10.1109/TGRS.2014.2346811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6884838","Hyperspectral;regularization;sparsity;super-resolution (SR);wavelet;Hyperspectral;regularization;sparsity;super-resolution (SR);wavelet","Principal component analysis;Training;Discrete wavelet transforms;Spatial resolution;Databases;Degradation","digital filters;discrete wavelet transforms;geophysical image processing;hyperspectral imaging;remote sensing","hyperspectral image superresolution;optimum wavelet filter coefficients;sparsity regularization;spectral resolution;spatial resolution;learning based approach;discrete wavelet transform;DWT;application specific wavelet basis;wavelet domain high frequency details;sparsity based regularization framework;image degradation;estimated wavelet filter coefficients;EWFC;initial superresolution estimate;optimal point spread function;image acquisition process modelling;sparsity prior","","27","","44","IEEE","27 Aug 2014","","","IEEE","IEEE Journals"
"A Modified Generative Adversarial Nets Integrated With Stochastic Approach for Realizing Super-Resolution Reservoir Simulation","F. Han; H. Zhang; S. Chatterjee; Q. Guo; S. Wan","Department of Geological Science and Engineering, Hohai University, Nanjing, China; Department of Geological Science and Engineering, Hohai University, Nanjing, China; Department of Geological and Mining Engineering and Sciences, Michigan Technological University, Houghton, USA; Department of Geological Science and Engineering, Hohai University, Nanjing, China; Department of Chemistry, Michigan Technological University, Houghton, USA","IEEE Transactions on Geoscience and Remote Sensing","22 Jan 2020","2020","58","2","1325","1336","Simulations and seismic inversions exhibit good performance in reservoir modeling task for the steady performance of conventional techniques. However, they still hardly meet the high demand of petroleum exploration since the impossibility of reaching high resolution both in vertical and lateral directions. Furthermore, simulations can only provide high-resolution results near loggings, while seismic inversions usually contain band-limited problems. Therefore, we present the modified generative adversarial nets with a decoder (DeGAN) as a novel approach, which is integrated with sequential simulation to realize super-resolution reservoir simulation. Specifically, the proposed method provides a geological model with high vertical resolution and optimized by the Zeoppritz function, introducing logging and seismic data simultaneously. After resampling and warping, DeGAN can be trained by these data sets and supplies a structure to generate high-frequency parts for reconstructing a super-resolution simulation of a subsurface profile. The proposed method presents the three-flow architecture of DeGAN to balance the contributions of three neural network models and utilizes this strategy in an offshore area successfully. By introducing multiple data sets, density experiments demonstrate that this approach can provide density profile with super-resolution for revealing possible thin layers, and the frequency distribution is in accord with loggings. The positive result verifies the effectiveness of this approach for providing a super-resolution simulation to supply a solution to the problem of the band-limited profile in seismic inversion.","1558-0644","","10.1109/TGRS.2019.2945946","National Natural Science Foundation of China(grant numbers:41374116,41674113); Postgraduate Research & Practice Innovation Program of Jiangsu Province(grant numbers:KYCX18_0623); Fundamental Research Funds for the Central Universities(grant numbers:2018B696X14); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886693","Band-limited problem;generative adversarial nets (GAN);geophysical modeling;stochastic simulation;super-resolution","Data models;Stochastic processes;Gallium nitride;Geology;Bandwidth;Reservoirs","geophysical image processing;geophysical techniques;image resolution;neural nets;reservoirs;stochastic processes","stochastic approach;super-resolution reservoir simulation;sequential simulation;high vertical resolution;super-resolution simulation;neural network models;modified generative adversarial nets;seismic inversions;Zeoppritz function;subsurface profile;three-flow architecture;multiple data sets;frequency distribution;band-limited profile","","6","","45","IEEE","30 Oct 2019","","","IEEE","IEEE Journals"
"Super-Resolution Radar Tomographic Imaging with Exploiting Spatial Diversity","H. Sun; H. Feng; Y. Lu","Agency for Science, Technology and Research, Institute for Infocomm Research, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","4196","4199","It is well known that the resolution of conventional radar is typically limited by the bandwidth of adopted waveform. However, we should not forget that the potential spatial resolution that radar can achieve could be much better, more precisely, in the order of sub-wavelength. Such radar operating °mode is called radar tomography, which exploits the spatial diversity, instead of large waveform bandwidth, to achieve super high spatial resolution. Although the theory of radar tomography had been developed for decades, very few experimental validations were reported in public literatures. In this paper, the investigations on radar tomographic imaging are conducted and validated with the measurements in microwave anechoic chamber. The spatial resolutions achieved in the experiments show good agreement with theoretical results.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883052","Radar tomography;microwave imaging;synthetic aperture radar","Microwave measurement;Radar remote sensing;Radar measurements;Spatial diversity;Superresolution;Radar;Bandwidth","anechoic chambers (electromagnetic);image reconstruction;image resolution;radar imaging;radar resolution;tomography","conventional radar;adopted waveform;potential spatial resolution;radar tomography;spatial diversity;waveform bandwidth;super high spatial resolution;spatial resolutions;super-resolution radar tomographic imaging","","","","11","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"A Radar Forward-Looking Super-Resolution Method Based On Singular Value Weighted Truncation","X. Tuo; Y. Zhang; D. Mao; Y. Kang; Y. Huang","School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","9180","9183","The truncated singular value decomposition (TSVD) method has been applied to radar forward-looking imaging, however which suffers limited resolution. Especially under low signal to noise ratio (SNR) condition, there is a contradiction between keeping more singular values to improve resolution and suppressing noise amplification. In this paper, a method based on singular value weighted truncation is proposed to improve the resolution under low SNR condition. First, this paper analyses the essence of the conventional TSVD method. Then, the passage constructs a new singular value function to reserve more singular value on the original truncation parameter. Compared with the conventional TSVD method, the more singular values are retained which can improve the resolution under the premise of suppressing noise. Simulations demonstrate the effectiveness of the proposed method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898704","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898704","Radar forward-looking;truncated singular value decomposition;super-resolution.","Radar imaging;Signal to noise ratio;Imaging;Aircraft","image resolution;radar imaging;singular value decomposition","super-resolution method;singular value weighted truncation;truncated singular value decomposition method;noise ratio condition;suppressing noise;low SNR condition;conventional TSVD method;singular value function;original truncation parameter;signal to noise ratio condition","","1","","8","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"A Super-Resolution Computational Coincidence Imaging Method Based on SIMO Radar System","S. Zhu; X. Dong; M. Zhang; R. Lu; J. Li; X. Chen; A. Zhang","School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Telecommunication and Information Engineering, Xian University of Posts and Telecommunications, Xi’an, China; School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","4 Dec 2017","2017","14","12","2265","2269","A super-resolution computational imaging method, called post random modulation radar imaging, based on single-input multiple-output radar detection system is proposed in this letter. In the proposed method, the target is detected in coherent mode using the multilinear frequency modulation signal. The echoes received by the radar elements of the receiving array are recorded, respectively. Then, random modulations of the directional pattern factor of the receiving radar array, which are nonlinear processes, are optimized according to the position and the size of the target that are estimated roughly using the traditional method. Finally, the super-resolution radar imaging is obtained to solve the equation group formed by the data from the nonlinear post random modulation process. The resolution of the proposed imaging method can break the diffraction limit corresponding to the aperture of the receiving radar array. The anti-interference ability of the proposed approach is improved significantly compared with the incoherent imaging method using a multiple-input single-output structure. Experiments are carried out to validate the proposed approach.","1558-0571","","10.1109/LGRS.2017.2761552","Shaanxi Provincial Natural Science Foundation(grant numbers:2017ZDXM-GY-009); China Postdoctoral Science Foundation(grant numbers:2017M613136); Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China(grant numbers:61471292,61501365,61471388,61331005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8082758","Coincidence imaging;incoherent imaging;multilinear frequency modulation (MLFM) signal;random modulation","Radar imaging;Imaging;Image resolution;Frequency modulation;Signal resolution","frequency modulation;image resolution;MIMO radar;optimisation;radar antennas;radar detection;radar imaging;radar resolution","nonlinear post random modulation process;receiving radar array;incoherent imaging method;single-output structure;super-resolution computational coincidence imaging method;SIMO radar system;multiple-output radar detection system;multilinear frequency modulation signal;radar elements;directional pattern factor;super-resolution radar imaging;post random modulation radar imaging","","8","","14","IEEE","25 Oct 2017","","","IEEE","IEEE Journals"
"A Novel Sub-Pixel Mapping Model Based on Pixel Aggregation Degree for Small-Sized Land-Cover","S. Wu; P. Yang; J. Ren; Z. Chen; C. Liu","Institute of Agricultural Resources and Regional Planning, Chinese Academy of Agricultural Sciences, Beijing, China; Institute of Agricultural Resources and Regional Planning, Chinese Academy of Agricultural Sciences, Beijing, China; Institute of Agricultural Resources and Regional Planning, Chinese Academy of Agricultural Sciences, Beijing, China; Institute of Agricultural Resources and Regional Planning, Chinese Academy of Agricultural Sciences, Beijing, China; Institute of Agricultural Resources and Regional Planning, Chinese Academy of Agricultural Sciences, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3073","3076","To further improve the accuracy of remote sensing classification and land-cover recognition at sub-pixel level, a novel sub-pixel mapping (SPM) model was first proposed by introducing the concept of pixel aggregation degree (PAD) which could simulate the spatial distribution of small-sized land-cover. In the proposed novel SPM model, based on the distribution of sub-pixel random initialization, PAD algorithm was optimized sub-pixel distribution to obtain final SPM results. Using a Sentinel-2 remote sensing data, related SPM experiments were performed to verify both accuracy and effect of PAD SPM model. The experimental results indicated that the SPM accuracy based on PAD model were superior to the classification results of the K-mean and the SPM results of traditional spatial attraction model. It was shown that the PAD model had certain feasibility and applicability which provided a new idea to better break the limitations of remote sensing image spatial resolution, and was beneficial to the subsequent research and application of remote sensing image.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899769","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899769","sub-pixel mapping;super-resolution mapping;pixel aggregation degree;optimization algorithm;small-sized land-cover","Remote sensing;Graphical models;Distribution functions;Spatial resolution;Correlation;Image reconstruction;Computational modeling","geophysical image processing;image classification;land cover;terrain mapping","novel sub-pixel mapping model;pixel aggregation degree;small-sized land-cover;remote sensing classification;land-cover recognition;sub-pixel level;spatial distribution;sub-pixel random initialization;PAD algorithm;optimized sub-pixel distribution;Sentinel-2 remote sensing data;SPM experiments;PAD SPM model;SPM accuracy;traditional spatial attraction model;remote sensing image spatial resolution","","","","22","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Reconstructing High-Resolution Ocean Subsurface and Interior Temperature and Salinity Anomalies From Satellite Observations","L. Meng; C. Yan; W. Zhuang; W. Zhang; X. Geng; X. -H. Yan","College of Earth, Ocean and Environment, University of Delaware, Newark, DE, USA; College of Earth, Ocean and Environment, University of Delaware, Newark, DE, USA; State Key Laboratory of Marine Environmental Science, College of Ocean and Earth Sciences, Xiamen University, Xiamen, China; State Key Laboratory of Marine Environmental Science, College of Ocean and Earth Sciences, Xiamen University, Xiamen, China; Engineering Research Center for Ocean Remote Sensing Big Data, Fujian Province Higher Education Institutes, Xiamen University, Xiamen, China; Joint Center for Remote Sensing, University of Delaware–Xiamen University, Newark, DE, USA","IEEE Transactions on Geoscience and Remote Sensing","2 Feb 2022","2022","60","","1","14","Accurately retrieving ocean interior parameters from remote sensing observations is essential for ocean and climate studies because direct observations are sparse and costly. Furthermore, high-resolution structure of seawater properties is critical for understanding the oceanic processes and changes on multiple scales. Here, we designed a new method based on a deep neural network to retrieve subsurface temperature anomaly (STA) and subsurface salinity anomaly (SSA) in the Pacific Ocean at high (1/4°) and super (1/12°) horizontal resolution. We utilized multisource satellite-observed sea surface data (e.g., sea level, temperature, salinity, and wind vector) as inputs. The results revealed that our model retrieved the high- and super-resolution STA/SSA with high accuracy, and the model was reliable in a wide range of depths (near surface to 4000 m) and times (all months in 2014). Regarding the high-resolution STA (SSA) estimation, the average coefficient of determination ( $R^{2}$ ) was 0.984 (0.966), and the average root-mean-squared error (RMSE) was 0.068 °C (0.016 psu). For the super-resolution STA, the average  $R^{2}$  was 0.988 and RMSE was 0.093 °C. Here, we established an effective technique that improved the resolution and accuracy of estimating the ocean interior parameters from satellite observation. The new technique provides some new insights into oceanic observation and dynamics.","1558-0644","","10.1109/TGRS.2021.3109979","National Key Research and Development Program of China(grant numbers:2019YFA0606702); National Natural Science Foundation of China(grant numbers:91858202,41630963,41776003); State Oceanic Administration (SOA) Global Change and Air–Sea Interaction Project(grant numbers:GASI-02-PAC-YGST2-02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9542964","Deep learning;high resolution;ocean temperature and salinity;parameter estimation;remote sensing","Oceans;Ocean temperature;Sea surface;Salinity (geophysical);Estimation;Spatial resolution;Surface treatment","mean square error methods;neural nets;ocean temperature;oceanographic regions;oceanographic techniques;remote sensing;sea level;seawater;wind","oceanic observation;high-resolution Ocean subsurface;interior temperature;salinity anomalies;satellite observation;ocean interior parameters;remote sensing observations;climate studies;high-resolution structure;seawater properties;oceanic processes;deep neural network;subsurface temperature;subsurface salinity;Pacific Ocean;horizontal resolution;multisource satellite-observed sea surface data;sea level;high-resolution STA estimation;average root-mean-squared error;temperature 0.068 degC;temperature 0.093 degC;size 4000.0 m","","6","","70","IEEE","21 Sep 2021","","","IEEE","IEEE Journals"
"MSISR : Modified Single Image Super-Resolution Using Relu Based 2D CNN For Satellite Images","S. R. Soni; K. Pandey; V. Sharma","Department of Computer Science (CSE), T.I.T, Bhopal (M.P.), INDIA; Department of Computer Science (CSE), T.I.T, Bhopal (M.P.), INDIA; Department of Computer Science (CSE), T.I.T, Bhopal (M.P.), INDIA","2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT)","26 Dec 2022","2022","","","1","7","In this research, we presented a Modified Single Image Super-Resolution (MSISR) using enhanced very deep super resolution (VDSR). The suggested technique is based on convolutional neural networks and uses up-sampling and residual inputs for training (an essential part of SISR) with a level of 20. The proposed method hybrid fusion of the enhanced bi-cubic method. The proposed MSISR shows better result in terms of peak signal to noise ratio as well as structural similarity index measurement. The proposed method also show good visual outcomes as compare to other previous techniques in terms of butter and resolution. These two factors play a significant role in the outcome analysis of image super resolution (ISR). For the analysis of proposed method use standard data sets like the UC Mecred Field. Data Set are available for the training and testing of the proposed approach. For the simulation of proposed method used well know tool that is matrix laboratory version R2020B.","","978-1-6654-5262-5","10.1109/ICCCNT54827.2022.9984280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9984280","Deep neural network;Satellite Image;synthetic aperture radar (SAR);Remote Sensing Image;up sampling;Residual;Relu;CNN and hybrid fusion","Training;Visualization;Satellites;Spaceborne radar;Superresolution;Sensors;Convolutional neural networks","convolutional neural nets;geophysical image processing;gradient methods;image resolution;regression analysis","convolutional neural networks;deep super resolution;enhanced bi-cubic method;image super resolution;modified single image super-resolution;MSISR;Relu based 2D CNN;satellite images;UC mecred field;very deep super resolution","","","","28","IEEE","26 Dec 2022","","","IEEE","IEEE Conferences"
"Hyperspectral Anomaly Detection via Image Super-Resolution Processing and Spatial Correlation","Z. Li; Y. Zhang","Department of Information Engineering, School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; Department of Information Engineering, School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Geoscience and Remote Sensing","24 Feb 2021","2021","59","3","2307","2320","Anomaly detection is a key problem in hyperspectral image (HSI) analysis with important remote sensing applications. Traditional methods for hyperspectral anomaly detection are mostly based on the distinctive statistical features of the HSIs. However, the anomaly-detection performance of these methods has been negatively impacted by two major limitations: 1) failure to consider the spatial pixel correlation and the ground-object correlation and 2) the existence of the mixing pixels caused by both lower spatial resolution and higher spectral resolution, which leads to higher false-alarm rates. In this article, these two problems are largely solved through a novel hyperspectral anomaly-detection method based on image super-resolution (SR) and spatial correlation. The proposed method encompasses two innovative ideas. First, based on the spectral variability in the anomaly targets, an extended linear mixing model can be obtained with more accurate ground-object information. Then, image SR is used to improve the spatial resolution of the HSIs by injecting the ground-object information from the mixing model. This alleviates the effect of mixed pixels on anomaly detection. Second, spatial correlation is exploited jointly with the global Reed-Xiaoli (GRX) method and the ground-object correlation detection for anomaly detection. Experimental results show that the proposed method not only effectively improves the hyperspectral spatial resolution and reduces the false-alarm rate but also increases the detectability with the spatial correlation information. Furthermore, the results for the real HSIs demonstrate that the proposed method achieves higher rates of anomaly detection with lower false-alarm rates.","1558-0644","","10.1109/TGRS.2020.3005924","National Science Foundation of China(grant numbers:61871150); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140416","Anomaly detection;hyperspectral image (HSI);spatial correlation;spectral variability;super-resolution (SR)","Anomaly detection;Correlation;Spatial resolution;Hyperspectral imaging;Object detection","geophysical image processing;hyperspectral imaging;image classification;image resolution;object detection;remote sensing","hyperspectral anomaly detection;image super-resolution processing;hyperspectral image analysis;anomaly-detection performance;spatial pixel correlation;mixing pixels;lower spatial resolution;higher spectral resolution;false-alarm rate;novel hyperspectral anomaly-detection method;anomaly targets;accurate ground-object information;mixed pixels;ground-object correlation detection;hyperspectral spatial resolution;detectability;spatial correlation information","","11","","54","IEEE","14 Jul 2020","","","IEEE","IEEE Journals"
"Insulators Detection with High Resolution Images","F. Zhou; W. Jin; Y. Ma; G. Wen; L. Liu; Z. Zheng","Joint Laboratory of power remote sensing technology (Electric Power Research Institute, Yunnan Power Grid Company Ltd., China Southern Power Grid), Kunming, Yunnan; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, Sichuan; Joint Laboratory of power remote sensing technology (Electric Power Research Institute, Yunnan Power Grid Company Ltd., China Southern Power Grid), Kunming, Yunnan; Joint Laboratory of power remote sensing technology (Electric Power Research Institute, Yunnan Power Grid Company Ltd., China Southern Power Grid), Kunming, Yunnan; Department of Engineering, Durham University, UK; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, Sichuan","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2179","2182","The potential safety hazards for the power grid caused by explosion of insulators occur again and again. Thus, the detecting and monitoring of insulators on the transmission towers is vital. In the paper, a novel method was proposed to detect insulators with high resolution satellites images. First, the SuperView-1 (0.5 m) and WorldView-3 (0.3 m) scenes of Yunnan were gathered, and then gram-schmidt method was used to fusion the original images. Second, a wide deep super resolution network (WDSR) is used to enhance the images resolution by 4 times. Third, fake color output and 1% linear stretched were applied to enhance image detail. Then, an object detection neural network based on feature pyramid networks (FPN) was used to detect transmission tower. Finally, a high-resolution network (HR-Net) was used to detect insulators on the tower. For comparison, three different class weight calculation methods and online hard example mining (OHEM) training methods of HR-Net were also proposed. HR-Net-c2-ohem final achieved highest 0.8001 of F1-Score. Therefore, our proposed method is robust to detect the insulators of transmission line tower with high resolution satellites images.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883889","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883889","insulators;object detection;semantic segmentation;super-resolution;high resolution satellites images","Training;Image resolution;Satellites;Power transmission lines;Numerical analysis;Poles and towers;Neural networks","feature extraction;geophysical image processing;image classification;image colour analysis;image enhancement;image resolution;learning (artificial intelligence);neural nets;object detection;poles and towers;power grids","potential safety hazards;transmission tower;high resolution satellites images;SuperView-1;gram-schmidt method;original images;wide deep super resolution network;images resolution;1% linear stretched;object detection neural network;feature pyramid networks;high-resolution network;different class weight calculation methods;transmission line tower;insulators detection;high resolution images;size 0.5 m;size 0.3 m","","","","8","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Joint Sparse Representation-based Single Image Super-resolution for Remote Sensing Applications","B. Deka; H. U. Mullah; T. Barman; S. Datta","Department of Electronics and Communication Engineering, Tezpur University, Assam, India; Department of Electronics and Communication Engineering, Tezpur University, Assam, India; Department of Electronics and Communication Engineering, Tezpur University, Assam, India; Department of Electronics and Communication Engineering, Tezpur University, Assam, India","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2023","PP","99","1","15","Sparse representation-based single image super-resolution (SISR) methods use a coupled overcomplete dictionary trained from high-resolution (HR) images/ image patches. Since, remote sensing (RS) satellites capture images of large areas, these images usually have poor spatial resolution and obtaining an effective dictionary as such would be very challenging. Moreover, traditional patch-based sparse representation (PSR) models for reconstruction tend to give unstable sparse solution and produce visual artefact in the recovered images. To mitigate these problems, in this paper, we have proposed an adaptive joint sparse representation (JSR)-based SISR method that is dependent only on the input low-resolution (LR) image for dictionary training and sparse reconstruction. The new model combines patch-based local sparsity and group sparse representation (GSR)-based non-local sparsity in a single framework, which helps in stabilizing the sparse solution and improve the SISR results. Experimental results are evaluated both visually and quantitatively for several RGB and multispectral RS datasets, where the proposed method shows improvements in PSNR by 1–4 dB and 2–3 dB over the state-of-the-art sparse representation- and deep learning-based SR methods, respectively. Land cover classification applied on the super-resolved images further validate the advantages of the proposed method. Finally, for practical RS applications, we have performed parallel implementation in general purpose graphics processing units (GPGPU) and achieved significant speed-ups (30-40×) in the execution time.","2151-1535","","10.1109/JSTARS.2023.3244069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10045723","Super-resolution;dictionary training;joint sparse representation;remote sensing;parallel processing","Dictionaries;Image reconstruction;Training;Spatial resolution;Image restoration;Feature extraction;Sensors","","","","","","","CCBY","16 Feb 2023","","","IEEE","IEEE Early Access Articles"
"Spectral Response Function-Guided Deep Optimization-Driven Network for Spectral Super-Resolution","J. He; J. Li; Q. Yuan; H. Shen; L. Zhang","School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Resource and Environmental Sciences, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan, China","IEEE Transactions on Neural Networks and Learning Systems","31 Aug 2022","2022","33","9","4213","4227","Hyperspectral images (HSIs) are crucial for many research works. Spectral super-resolution (SSR) is a method used to obtain high-spatial-resolution (HR) HSIs from HR multispectral images. Traditional SSR methods include model-driven algorithms and deep learning. By unfolding a variational method, this article proposes an optimization-driven convolutional neural network (CNN) with a deep spatial–spectral prior, resulting in physically interpretable networks. Unlike the fully data-driven CNN, auxiliary spectral response function (SRF) is utilized to guide CNNs to group the bands with spectral relevance. In addition, the channel attention module (CAM) and the reformulated spectral angle mapper loss function are applied to achieve an effective reconstruction model. Finally, experiments on two types of data sets, including natural and remote sensing images, demonstrate the spectral enhancement effect of the proposed method, and also, the classification results on the remote sensing data set verified the validity of the information enhanced by the proposed method.","2162-2388","","10.1109/TNNLS.2021.3056181","National Natural Science Foundation of China(grant numbers:41922008,62071341,61971319); Hubei Science Foundation for Distinguished Young Scholars(grant numbers:2020CFA051); Fundamental Research Funds for the Central Universities(grant numbers:531118010209); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357488","Convolutional neural network (CNN);hyperspectral image (HSI);optimization driven;spectral response function (SRF);spectral super-resolution (SSR)","Spatial resolution;Optimization;Image reconstruction;Degradation;Superresolution;Noise reduction;Minimization","deep learning (artificial intelligence);feature extraction;geophysical image processing;hyperspectral imaging;image classification;image reconstruction;image resolution;learning (artificial intelligence);neural nets;optimisation;remote sensing;spectral analysis","spectral superresolution;high-spatial-resolution HSIs;HR multispectral images;traditional SSR methods;model-driven algorithms;deep learning;variational method;optimization-driven convolutional neural network;deep spatial-spectral;physically interpretable networks;fully data-driven CNN;auxiliary spectral response function;spectral relevance;reformulated spectral angle mapper loss function;natural sensing images;remote sensing images;spectral enhancement effect;spectral response function-guided deep optimization-driven network;hyperspectral images;HR;SRF;channel attention module;CAM;remote sensing data set;remote sensing data set","","12","","53","IEEE","18 Feb 2021","","","IEEE","IEEE Journals"
"Spatial and Spectral Joint Super-Resolution Using Convolutional Neural Network","S. Mei; R. Jiang; X. Li; Q. Du","School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; Department of Electrical and Computer Engineering, Mississippi State University, Starkville, USA","IEEE Transactions on Geoscience and Remote Sensing","23 Jun 2020","2020","58","7","4590","4603","Many applications have benefited from the images with both high spatial and spectral resolution, such as mineralogy and surveillance. However, it is difficult to acquire such images due to the limitation of sensor technologies. Recently, super-resolution (SR) techniques have been proposed to improve the spatial or spectral resolution of images, e.g., improving the spatial resolution of hyperspectral images (HSIs) or improving spectral resolution of color images (reconstructing HSIs from RGB inputs). However, none of the researches attempted to improve both spatial and spectral resolution together. In this article, these two types of resolution are jointly improved using convolutional neural network (CNN). Specifically, two kinds of CNN-based SR are conducted, including a simultaneous spatial-spectral joint SR (SimSSJSR) that conducts SR in spectral and spatial domain simultaneously and a separated spatial-spectral joint SR (SepSSJSR) that considers spectral and spatial SR sequentially. In the proposed SimSSJSR, a full 3-D CNN is constructed to learn an end-to-end mapping between a low spatial-resolution mulitspectral image (LR-MSI) and the corresponding high spatial-resolution HSI (HR-HSI). In the proposed SepSSJSR, a spatial SR network and a spectral SR network are designed separately, and thus two different frameworks are proposed for SepSSJSR, namely SepSSJSR1 and SepSSJSR2, according to the order that spatial SR and spectral SR are applied. Furthermore, the least absolute deviation, instead of mean square error (MSE) in traditional SR networks, is chosen as the loss function for the proposed networks. Experimental results over simulated images from different sensors demonstrated that the proposed SepSSJSR1 is most effective to improve spatial and spectral resolution of MSIs sequentially by conducting spatial SR prior to spectral SR. In addition, validation on real Landsat images also indicates that the proposed SSJSR techniques can make full use of available MSIs for high-resolution-based analysis or applications.","1558-0644","","10.1109/TGRS.2020.2964288","National Natural Science Foundation of China(grant numbers:61671383); Natural Science Foundation of Shaanxi Province(grant numbers:2018JM6005); Fundamental Research Funds for the Central Universities(grant numbers:3102018AX001); Seed Foundation of Innovation and Creation for Graduate Students in NPU(grant numbers:ZZ2019164); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8974222","Convolutional neural network (CNN);hyperspectral image (HSI);multispectral image (MSI);spatial–spectral;super-resolution (SR)","Spatial resolution;Image reconstruction;Hyperspectral imaging;Signal resolution","convolutional neural nets;hyperspectral imaging;image colour analysis;image resolution;learning (artificial intelligence);mean square error methods","RGB;CNN;MSIs;HR-HSI;high spatial-resolution HSI;LR-MSI;mean square error;MSE;MSE;HSIs;separated spatial-spectral joint SR;spatial domain;spectral domain;simultaneous spatial-spectral joint SR;CNN-based SR;color images;hyperspectral images;super-resolution techniques;convolutional neural network;spectral joint super-resolution;spatial super-resolution;high-resolution-based analysis;Landsat images;spectral resolution;spatial resolution;simulated images;SR networks;SepSSJSR2;SepSSJSR1;spectral SR network;spatial SR network;spatial-resolution HSI;low spatial-resolution mulitspectral image","","54","","33","IEEE","29 Jan 2020","","","IEEE","IEEE Journals"
"Recovery of Partially Corrupted SAR Images by Super-Resolution Based on Spectrum Extrapolation","F. Biondi","Facoltà di Ingegneria, Università Degli Studi Dell’Aquila, L’Aquila (AQ), Italy","IEEE Geoscience and Remote Sensing Letters","23 Jan 2017","2017","14","2","139","143","The problem of chirped synthetic aperture radar (SAR) systems is the high vulnerability of the received information to electromagnetic (EM) attacks. This letter proposes a valid recovery solution for SAR single-look complex images that are corrupted by noncoherent EM noise covering only the higher frequency spectrum. The solution consists of, first, exporting the spectrum damages that occur in the native data and, second, focusing only the survived spectrum information at lower resolution. The recovery of the original image is done by super-resolution signal processing based on spectrum extrapolation and implemented by convex programming.","1558-0571","","10.1109/LGRS.2016.2615564","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7790855","Compressed sensing;jamming;spectrum extrapolation (SE);super-resolution (SR);synthetic aperture radar (SAR).","Synthetic aperture radar;Signal resolution;Jamming;Image resolution;Energy resolution;Radar imaging","convex programming;extrapolation;image resolution;radar imaging;radar resolution;synthetic aperture radar","partially corrupted SAR single-look complex imaging;synthetic aperture radar;electromagnetic attack;EM attack;noncoherent EM noise corruption;frequency spectrum extrapolation;superresolution signal processing;convex programming","","23","","8","Crown","19 Dec 2016","","","IEEE","IEEE Journals"
"A TV Forward-Looking Super-Resolution Imaging Method Based on TSVD Strategy for Scanning Radar","Y. Zhang; X. Tuo; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","23 Jun 2020","2020","58","7","4517","4528","Because of the poor performance of the conventional total variation (TV) super-resolution imaging method in low signal-to-noise ratio (SNR) condition, a TV super-resolution imaging method based on the truncated singular value decomposition (TSVD) strategy is proposed. First, based on the regularization theory, the TV function is selected as the constraint term to construct objective function. Second, to solve the problem of noise amplification faced by the conventional TV method, this article reconstructs the objective function based on the TSVD strategy, which improves the antinoise performance by discarding small singular values of antenna convolution matrix. Finally, due to the nondifferentiable property of reconstructed objective function, this article utilizes the iterative reweighted norm (IRN) method. Since the influence of the noise is weakened by the TSVD strategy, the proposed method can achieve super-resolution imaging and contour preservation in low SNR condition. The simulation and experimental results demonstrate the effectiveness of the proposed method.","1558-0644","","10.1109/TGRS.2019.2958085","National Natural Science Foundation of China(grant numbers:61671117,61901090); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8982029","Iterative reweighted norm (IRN);radar super-resolution imaging;total variation (TV);truncated singular value decomposition (TSVD)","Radar imaging;Imaging;TV;Azimuth;Antennas","image denoising;image reconstruction;image resolution;iterative methods;singular value decomposition","total variation super-resolution imaging method;singular values;noise amplification;truncated singular value decomposition strategy;low signal-to-noise ratio;scanning radar;TV forward-looking super-resolution imaging method;low SNR condition;contour preservation;TSVD strategy;iterative reweighted norm method;reconstructed objective function","","34","","46","IEEE","4 Feb 2020","","","IEEE","IEEE Journals"
"Simultaneous Super-Resolution and Target Detection of Forward-Looking Scanning Radar via Low-Rank and Sparsity Constrained Method","W. Li; W. Zhang; Q. Zhang; Y. Zhang; Y. Huang; J. Yang","Department of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","24 Sep 2020","2020","58","10","7085","7095","Forward-looking imaging and target detection are highly desirable in many military and civilian fields, such as search and rescue, sea surface surveillance, airport surveillance, and guidance. However, there is a blind zone of forward-looking imaging for conventional Doppler beam sharpening and synthetic aperture radar. Scanning radar can be utilized to obtain a real beam image of a forward-looking area and implement target detection, while its azimuth resolution is poor due to the limitation of antenna size. Besides, during the processing procedure, imaging and target detection are usually regarded as two independent parts, which means that the imaging result will directly affect the detection performance. In this article, an integrated algorithm of super-resolution imaging and target detection for forward-looking scanning radar is proposed. In this algorithm, first of all, low-rank and sparse constraints as regularization norms are incorporated into the forward-looking scanning radar imaging and the objective function is established. Subsequently, the convex theory is utilized to solve the objective function and transform the problem of simultaneous super-resolution imaging and target detection into an optimization problem. Lastly, the super-resolution imaging and the target detection results are obtained simultaneously by solving the optimization problem using the alternating direction method of multipliers. In addition, simulation and experiment results are given to verify the effectiveness of the proposed algorithm.","1558-0644","","10.1109/TGRS.2020.2979508","National Natural Science Foundation of China(grant numbers:61671117,61901090); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9050509","Forward-looking imaging;low-rank and sparse matrix decomposition;scanning radar;super-resolution;target detection","Object detection;Imaging;Radar imaging;Azimuth;Linear programming","Doppler radar;image resolution;object detection;radar antennas;radar imaging;synthetic aperture radar","super-resolution imaging;target detection results;simultaneous super-resolution;forward-looking scanning radar;forward-looking imaging;beam image;scanning radar imaging;processing procedure,","","8","","52","IEEE","30 Mar 2020","","","IEEE","IEEE Journals"
"A Super-Resolution Sparse Aperture ISAR Sensors Imaging Algorithm via the MUSIC Technique","Q. Liu; A. Liu; Y. Wang; H. Li","Research Institute of Electronic Engineering Technology, Harbin Institute of Technology, Harbin, China; Department of Communication Engineering, Harbin Institute of Technology, Weihai, China; Research Institute of Electronic Engineering Technology, Harbin Institute of Technology, Harbin, China; Research Institute of Electronic Engineering Technology, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Geoscience and Remote Sensing","27 Aug 2019","2019","57","9","7119","7134","The conventional range-Doppler (RD) technique uses fast Fourier transformation (FFT) to generate focused images. However, the spectrum of FFT has high sidelobes and wide main lobes and the resolution of RD is limited by the radar parameters so that the RD method cannot generate super-resolution images especially with sparse aperture (SA) data. A super-resolution SA inverse synthetic aperture radar (SA-ISAR) imaging algorithm via the multiple signal classification (MUSIC) technique is proposed in this paper. The proposal uses the MUSIC algorithm to estimate the location and employs the least-squares technique to calculate the intensity of each scatterer. Then, the scatterers can be precisely depicted in the images without the interference of sidelobes and wide main lobes. The resolution of the proposal depends less on the radar parameters, and it can be further improved by using a smaller search step. Experiments obtained by processing of simulated and raw data demonstrate that the proposal can efficiently generate super-resolution images with full aperture (FA) or SA data.","1558-0644","","10.1109/TGRS.2019.2911686","National Natural Science Foundation of China(grant numbers:61622107,61871146); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8719021","Multiple signal classification (MUSIC);sparse aperture inverse synthetic aperture radar (SA-ISAR) imaging;super-resolution","Radar imaging;Imaging;Image resolution;Signal resolution;Multiple signal classification;Proposals","fast Fourier transforms;image resolution;least squares approximations;radar imaging;signal classification;synthetic aperture radar","search step;focused images;conventional range-Doppler technique;super-resolution sparse aperture ISAR sensors;least-squares technique;MUSIC algorithm;multiple signal classification technique;inverse synthetic aperture radar imaging algorithm;sparse aperture data;super-resolution images;RD method;radar parameters;wide main lobes;high sidelobes;FFT","","7","","33","IEEE","21 May 2019","","","IEEE","IEEE Journals"
"Super-resolution land cover mapping based on deep learning and level set method","W. Bupphawat; T. Kasetkasem; I. Kumazawa; P. Rakwatin; T. Chanwimaluang","Department of Electrical Engineering, Kasetsart University, Bangkok, Thailand; Department of Electrical Engineering, Kasetsart University, Bangkok, Thailand; Imaging Science and Engineering Laboratory, Tokyo Institute of Technology, Yokohama, Japan; GISTDA, The Government Complex, Bangkok, Thailand; Knowledge Elicitation and Archiving Lab Laboratory, NECTEC, Pathumthani, Thailand","2017 14th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","7 Nov 2017","2017","","","557","560","In this paper, we proposed an approach for super-resolution land cover mapping on remote sensing images based on the deep learning technique, namely Convolutional Neural Network (CNN) by combining with the level set method (LSM). Here, the CNN is used to find the probabilities that a subpixel belonging to a land cover class, and the LSM is employed to fine tune the boundaries among land cover classes. The QUICKBIBD satellite image data cover a part of Kasetsart University was used for evaluation. Experimental result showed that the proposed method has achieved superior accuracy than both Hopfield and Pixel-Swapping methods.","","978-1-5386-0449-6","10.1109/ECTICon.2017.8096298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8096298","Supper-resolution mapping;Deep Learning;Level set method","Image resolution;Level set;Neural networks;Machine learning;Training;Electronic mail;Convolution","geophysical techniques;land cover;neural nets;remote sensing;terrain mapping","convolutional neural network;QUICKBIBD satellite image data cover;Kasetsart University;Hopfield method;pixel-swapping method;deep learning technique;remote sensing images;level set method;super-resolution land cover mapping;land cover class;CNN","","2","","9","IEEE","7 Nov 2017","","","IEEE","IEEE Conferences"
"Hyperspectral Images Super-Resolution via Learning High-Order Coupled Tensor Ring Representation","Y. Xu; Z. Wu; J. Chanussot; Z. Wei","Jiangsu Key Lab of Image and Video Understanding for Social Security, Nanjing University of Science and Technology, Nanjing, China; Jiangsu Key Lab of Image and Video Understanding for Social Security, Nanjing University of Science and Technology, Nanjing, China; Univ. Grenoble Alpes, INRIA, CNRS, Grenoble INP, LJK, Grenoble, France; Jiangsu Key Lab of Image and Video Understanding for Social Security, Nanjing University of Science and Technology, Nanjing, China","IEEE Transactions on Neural Networks and Learning Systems","30 Oct 2020","2020","31","11","4747","4760","Hyperspectral image (HSI) super-resolution is a hot topic in remote sensing and computer vision. Recently, tensor analysis has been proven to be an efficient technology for HSI image processing. However, the existing tensor-based methods of HSI super-resolution are not able to capture the high-order correlations in HSI. In this article, we propose to learn a high-order coupled tensor ring (TR) representation for HSI super-resolution. The proposed method first tensorizes the HSI to be estimated into a high-order tensor in which multiscale spatial structures and the original spectral structure are represented. Then, a coupled TR representation model is proposed to fuse the low-resolution HSI (LR-HSI) and high-resolution multispectral image (HR-MSI). In the proposed model, some latent core tensors in TR of the LR-HSI and the HR-MSI are shared, and we use the relationship between the spectral core tensors to reconstruct the HSI. In addition, the graph-Laplacian regularization is introduced to the spectral core tensors to preserve the spectral information. To enhance the robustness of the proposed model, Frobenius norm regularizations are introduced to the other core tensors. Experimental results on both synthetic and real data sets show that the proposed method achieves the state-of-the-art super-resolution performance.","2162-2388","","10.1109/TNNLS.2019.2957527","National Natural Science Foundation of China(grant numbers:61701238,61772274,61471199,61976117,11431015,61501241,61671243,61802190); Jiangsu Provincial Natural Science Foundation of China(grant numbers:BK20170858,BK20180018,BK20191409); Fundamental Research Funds for the Central Universities(grant numbers:30919011234,30917015104,30919011103,30919011402); China Postdoctoral Science Foundation(grant numbers:2017M611814,2018T110502); Jiangsu Province Postdoctoral Science Foundation(grant numbers:1701148B); Key Projects of University Natural Science Fund of Jiangsu Province, China(grant numbers:19KJA360001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948303","Hyperspectral image (HSI);multiscale;multispectral image (MSI);super-resolution;tensor ring (TR)","Tensors;Sparse matrices;Hyperspectral imaging;Spatial resolution;Fuses","computer vision;geophysical image processing;graph theory;hyperspectral imaging;image representation;image resolution;remote sensing;tensors","hyperspectral image super resolution;remote sensing;computer vision;tensor analysis;HSI image processing;HSI super resolution;high order coupled TR representation;high order coupled tensor ring representation;Frobenius norm regularizations;graph Laplacian regularization","","44","","60","IEEE","1 Jan 2020","","","IEEE","IEEE Journals"
"A Super-Resolution Scheme for Multichannel Radar Forward-Looking Imaging Considering Failure Channels and Motion Error","R. Chen; W. Li; K. Li; Y. Zhang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Geoscience and Remote Sensing Letters","6 Feb 2023","2023","20","","1","5","To obtain high-resolution images of the objects in front of platform, a super-resolution scheme for multichannel radar forward-looking imaging considering failure channels and motion error is proposed in this study. In the scheme, a failure channel detection method based on the correlation of pulse-compressed data of different channels is presented first, and then a revised steering matrix considering failure channels and motion error is constructed. Finally, the echo data are processed by the iterative adaptive approach (IAA) with the revised steering matrix. Simulation results are given to illustrate the effectiveness of the proposed scheme when dealing with failure channels and motion error.","1558-0571","","10.1109/LGRS.2023.3234264","National Natural Science Foundation of China(grant numbers:62171107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10006820","Failure channels;forward-looking imaging;iterative adaptive approach (IAA);motion error;multichannel radar;super-resolution","Radar imaging;Imaging;Superresolution;Receiving antennas;Correlation;Radar antennas;Azimuth","","","","","","14","IEEE","5 Jan 2023","","","IEEE","IEEE Journals"
"Timing performance of wide scintillator crystal elements for super-resolution clinical PET","J. W. Cates; G. Chinn; C. S. Levin","University of the Chinese Academy of Sciences, Beijing, China; Space Microwave Remote Sensing System Department, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Space Microwave Remote Sensing System Department, Institute of Electronics, Chinese Academy of Sciences, Beijing, China","2016 IEEE Nuclear Science Symposium, Medical Imaging Conference and Room-Temperature Semiconductor Detector Workshop (NSS/MIC/RTSD)","19 Oct 2017","2016","","","1","3","Super-resolution is a technique to reconstruct PET images at a higher spatial resolution than intrinsically available from the detector resolution. This is done through oversampling projection data by moving the detector ring or the patient bed at increments finer than the crystal pitch of the systems detectors, increasing the sampling frequency so that resolution may be recovered without aliasing artifacts. If this technique were applied to a clinical, whole-body scanner, large area crystal elements (> 4 mm wide) could be used in the detector ring, and through movement of the patient bed, spatial resolution of a typical whole-body system could potentially be recovered (~5-7 mm). Using wider crystal elements offers some unique advantages, such as improved system photon sensitivity from overall reduced dead space between pixel elements, improved scintillation light collection efficiency from wider crystal geometry due to a better light collection aspect ratio, reduced cost on cutting and preparing scintillation material, immensely simplified electronic readout, and less sensitivity to inaccurate positioning of inter-crystal scatter events (which are more probable than photoelectric events) due to larger pixel volume. Since fine spatial information comes from the patient bed translation, sub-pixel positioning information is not required from the PET detector, and signal processing can be optimized for timing performance. Therefore, this technique is a potential solution for achieving excellent timing performance in a simplistic and potentially lower-cost PET system design. With these considerations in mind, this work investigates the achievable coincidence time resolution (CTR) with larger width LYSO:Ce crystals 1:1 coupled to analog SiPMs.","","978-1-5090-1642-6","10.1109/NSSMIC.2016.8069399","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8069399","","Crystals;Detectors;Timing;Photonics;Spatial resolution;Oscilloscopes","image reconstruction;image resolution;medical image processing;positron emission tomography;scintillation counters","wide scintillator crystal elements;super-resolution clinical PET;detector resolution;oversampling projection data;detector ring;crystal pitch;sampling frequency;whole-body scanner;area crystal elements;pixel elements;light collection aspect ratio;scintillation material;patient bed translation;PET detector;PET image reconstruction;spatial resolution;whole-body system;scintillation light collection efficiency;simplified electronic readout;timing performance;coincidence time resolution;system photon sensitivity;intercrystal scatter events;subpixel positioning information","","","","4","IEEE","19 Oct 2017","","","IEEE","IEEE Conferences"
"A Super-Resolution Convolutional-Neural-Network-Based Approach for Subpixel Mapping of Hyperspectral Images","X. Ma; Y. Hong; Y. Song; Y. Chen","School of Land Science and Technology, China University of Geosciences, Beijing, China; School of Land Science and Technology, China University of Geosciences, Beijing, China; Australasian Joint Research Centre for Building Information Modeling, School of Design and the Built Environment, Curtin University, Perth, Australia; School of Land Science and Technology, China University of Geosciences, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","3 Feb 2020","2019","12","12","4930","4939","A new subpixel mapping (SPM) method based on a super-resolution convolutional neural network (SRCNN) is proposed to generate subpixel land cover maps for hyperspectral images. The SRCNN is used to restore the image spatial resolution from a coarse input image, which is equivalent to interpolation. First, an efficient subpixel convolutional neural network, which is a state-of-the-art SRCNN, is utilized to calculate the subpixel soft class value via a transfer learning strategy. Then, a classifier is used to transform the subpixel soft class values to hard-classified land cover maps with the constraint of fraction images. Experiments on three different hyperspectral images demonstrate that the SPM accuracy of the proposed SRCNN-based method is significantly better than those of three traditional SPM methods. In addition, the SRCNN-based SPM method has a simplified calculation process, does not require training data, and is less time consuming. This article provides a new solution for SPM of hyperspectral images.","2151-1535","","10.1109/JSTARS.2019.2941089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847414","Deep learning;hyperspectral remote sensing image;subpixel mapping (SPM);super-resolution convolutional neural network (SRCNN);transfer learning (TL)","Hyperspectral imaging;Spatial resolution;Deep learning;Convolutional neural networks","convolutional neural nets;geophysical image processing;geophysical techniques;image classification;image resolution;interpolation;land cover;learning (artificial intelligence);remote sensing;terrain mapping","super-resolution convolutional-neural-network-based approach;subpixel mapping method;subpixel land cover maps;image spatial resolution;coarse input image;subpixel soft class value;hard-classified land cover maps;fraction images;hyperspectral images;SRCNN-based SPM method;subpixel convolutional neural network","","9","","28","IEEE","24 Sep 2019","","","IEEE","IEEE Journals"
"Unsupervised and Unregistered Hyperspectral Image Super-Resolution With Mutual Dirichlet-Net","Y. Qu; H. Qi; C. Kwan; N. Yokoya; J. Chanussot","Department of Electrical Engineering and Computer Science, Advanced Imaging and Collaborative Information Processing Group, The University of Tennessee, Knoxville, TN, USA; Department of Electrical Engineering and Computer Science, Advanced Imaging and Collaborative Information Processing Group, The University of Tennessee, Knoxville, TN, USA; Applied Research LLC, Rockville, MD, USA; Geoinformatics Unit, RIKEN Center for Advanced Intelligence Project (AIP), Tokyo, Japan; Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Grenoble, France","IEEE Transactions on Geoscience and Remote Sensing","4 Jan 2022","2022","60","","1","18","Hyperspectral images (HSIs) provide rich spectral information that has contributed to the successful performance improvement of numerous computer vision and remote sensing tasks. However, it can only be achieved at the expense of images’ spatial resolution. HSI super-resolution (HSI-SR), thus, addresses this problem by fusing low-resolution (LR) HSI with the multispectral image (MSI) carrying much higher spatial resolution (HR). Existing HSI-SR approaches require the LR HSI and HR MSI to be well registered, and the reconstruction accuracy of the HR HSI relies heavily on the registration accuracy of different modalities. In this article, we propose an unregistered and unsupervised mutual Dirichlet-Net ( $u^{2}$ -MDN) to exploit the uncharted problem domain of HSI-SR without the requirement of multimodality registration. The success of this endeavor would largely facilitate the deployment of HSI-SR since registration requirement is difficult to satisfy in real-world sensing devices. The novelty of this work is threefold. First, to stabilize the fusion procedure of two unregistered modalities, the network is designed to extract spatial information and spectral information of two modalities with different dimensions through a shared encoder–decoder structure. Second, the mutual information (MI) is further adopted to capture the nonlinear statistical dependencies between the representations from two modalities (carrying spatial information) and their raw inputs. By maximizing the MI, spatial correlations between different modalities can be well characterized to further reduce the spectral distortion. We assume that the representations follow a similar Dirichlet distribution for their inherent sum-to-one and nonnegative properties. Third, a collaborative  $l_{2,1}$ -norm is employed as the reconstruction error instead of the more common  $l_{2}$ -norm to better preserve the spectral information. Extensive experimental results demonstrate the superior performance of  $u^{2}$ -MDN as compared to the state of the art.","1558-0644","","10.1109/TGRS.2021.3079518","National Aeronautics and Space Administration (NASA)(grant numbers:NNX12CB05C,NNX16CP38P); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442804","Hyperspectral image (HSI);mutual information (MI);super-resolution (SR);unregistered;unsupervised deep learning","Spatial resolution;Image reconstruction;Data mining;Bayes methods;Superresolution;Tensors;Optimization","computer vision;geophysical image processing;hyperspectral imaging;image fusion;image reconstruction;image registration;image representation;image resolution;remote sensing;statistical analysis","registration requirement;mutual information;spatial correlations;computer vision;remote sensing tasks;HSI superresolution;low-resolution HSI;multispectral image;LR HSI;unregistered Dirichlet-Net;unsupervised mutual Dirichlet-Net;unregistered hyperspectral image superresolution;unsupervised hyperspectral image superresolution;image spatial resolution;MSI;HR HSI reconstruction accuracy;fusion procedure;shared encoder-decoder structure;nonlinear statistical dependencies;Dirichlet distribution;sum-to-one properties;collaborative l2,1-norm;u2-MDN","","12","","85","IEEE","27 May 2021","","","IEEE","IEEE Journals"
"High-Resolution InSAR Building Layovers Detection and Exploitation","C. Rossi; M. Eineder","Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen, Germany","IEEE Transactions on Geoscience and Remote Sensing","4 Sep 2015","2015","53","12","6457","6468","Layover affects the quality of urban interferometric synthetic aperture radar (InSAR) digital elevation models. Moreover, it is generally difficult to interpret because of the superposition of several contributions in a single SAR pixel. In this paper, a novel technique for the extraction of building layovers is first presented. It makes use of the geocoding stage embedded in the InSAR processor. It is shown that building layovers create a regular pattern in the mapping counter, a map describing the number of occurrences of a SAR pixel in the elevation model. Its exploitation yields a generation of a layover map without the use of external supports. The integration in the processor with a limited additional computational load and the capability to isolate layover signatures are additional benefits. Layover patches are then individually analyzed toward a better understanding of the complex urban signal return. A spectral estimation framework is employed to assess the slopes superimposed in the patches. Fringe-frequency estimation is involved. A set of simulations made for a nonparametric (fast Fourier transform) and a parametric (multiple signal classification) technique is performed prior to testing on real data. It is demonstrated that in X-band, for a single interferogram, just one layover contributor, when it dominates over the others, can be extracted with a sufficient accuracy. The algorithms are tested on a TanDEM-X spotlight acquisition over Berlin (Germany).","1558-0644","","10.1109/TGRS.2015.2440913","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7128381","Fringe-frequency estimation;geocoding;interferometric SAR (InSAR);layover detection;layover scattering decomposition;super-resolution;urban mapping;Fringe-frequency estimation;geocoding;interferometric SAR (InSAR);layover detection;layover scattering decomposition;super-resolution;urban mapping","Buildings;Synthetic aperture radar;Radiation detectors;Estimation;Computational modeling;Accuracy;Satellites","digital elevation models;remote sensing by radar;synthetic aperture radar","high-resolution InSAR building layovers detection;interferometric synthetic aperture radar;mapping counter;SAR pixel;elevation model;Fringe-frequency estimation;X-band;TanDEM-X spotlight acquisition;Berlin;Germany","","17","","34","IEEE","18 Jun 2015","","","IEEE","IEEE Journals"
"Siamese Generative Adversarial Network for Change Detection Under Different Scales","M. Liu; Q. Shi; P. Liu; C. Wan","Guangdong Provincial Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","2543","2546","Change detection methods based on low-resolution (LR) images with higher temporal resolution often lead to fuzzy results, while high-resolution images (HRIs) can provide more detailed information to solve this problem. However, it's hard to obtain two tiles of HRIs with high-quality for rapid change detection in actual production due to low temporal resolution and high cost. Therefore, it is necessary to explore a change detection method combing low- and high-resolution images to acquire urban change areas more accurately and quickly. In this paper, an end-to-end siamese generative adversarial network (SiamGAN) integrating a super resolution network and the siamese structure was proposed for change detection under different scales. The super-resolution network is used to reconstruct low-resolution images into high-resolution images, while the siamese structure is adopted as the classification network to detect changes. In the experiments, SiamGAN achieved an F1 of 76.06% and an IoU of 61.52% in the test set, which is respectively 5.68% and 6.92% higher than the CNN-based methods using LR images after bicubic interpolation. The results show that our proposed method can effectively overcome difference in scale between low- and high-resolution images and perform change detection more precisely and rapidly.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323499","Change detection;siamese network;super-resolution;high resolution images","Generators;Feature extraction;Training;Superresolution;Generative adversarial networks;Spatial resolution;Remote sensing","geophysical image processing;image reconstruction;image resolution;interpolation","change detection method;low-resolution images;higher temporal resolution;high-resolution images;rapid change detection;low temporal resolution;urban change areas;end-to-end siamese generative adversarial network;super resolution network;siamese structure;super-resolution network","","","","14","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Enhanced Super-Resolution via Squeeze-and-Residual-Excitation in Aerial Imagery","B. Khan; M. M. Fraz; A. Mumtaz","National University of Sciences and Technology (NUST), Islamabad, Pakistan; National University of Sciences and Technology (NUST), Islamabad, Pakistan; Center of Excellence in Science and Applied Technologies (CESAT), Islamabad, Pakistan","2021 International Conference on Frontiers of Information Technology (FIT)","8 Feb 2022","2021","","","19","24","Super-resolution (SR) presents us with an outstanding technique of enhancing applications associated with aerial and remote-sensing imagery, hence, tasks like classification, segmentation and object detection can benefit significantly from well-performing SR models. Extensive research is being done in the field of SR for both ground-level and aerial imagery where convolutional neural networks (CNN) have attained incredible progress. Numerous deep CNNs use the attention mechanism in their architectures and one such mechanism is the Squeeze-and-Excitation (SE) inter-channel attention. Although SE block has enhanced the performance of many models, there is no residual mechanism used within its structure. Therefore, in this paper, we propose the Squeeze-and-Residual-Excitation (SRE) attention block. SRE improves upon the SE block by using residual mechanism within its structure to deliver performance gain in the task of SR. Based on our SRE attention mechanism we propose an enhanced SR framework for remote-sensing imagery. We call our model the Squeeze-and-Residual-Excitation Holistic Attention Network (SRE-HAN) that outperforms other attention-based deep SR models for two levels of resolution enhancement: 4x- and 8x-upsampling on two diverse aerial imagery datasets: Satellite Imagery Multi-Vehicles Dataset (SIMD) consisting of 5000 high-resolution (HR) aerial images, and Cars-Overhead-With-Context (COWC). Furthermore, by using YoloV5 object-detection model, we carry out multiple experiments to substantiate the effectiveness of these SR models on the task of object detection on SIMD.","","978-1-6654-0830-1","10.1109/FIT53504.2021.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9701381","Super-Resolution;Remote Sensing Imagery;Aerial Imagery;Squeeze-and-Excitation","Image segmentation;Satellites;Superresolution;Object detection;Performance gain;Sensors;Convolutional neural networks","feature extraction;geophysical image processing;image classification;image reconstruction;image representation;image resolution;neural nets;object detection;remote sensing","ground-level;convolutional neural networks;incredible progress;numerous deep CNNs;SE block;residual mechanism;performance gain;SRE attention mechanism;enhanced SR framework;remote-sensing imagery;attention-based deep SR models;resolution enhancement;diverse aerial imagery datasets;Satellite Imagery MultiVehicles Dataset;high-resolution aerial images;YoloV5 object-detection model;object detection;enhanced super-resolution;outstanding technique;segmentation","","1","","19","IEEE","8 Feb 2022","","","IEEE","IEEE Conferences"
"Super-Resolution Surface Mapping for Scanning Radar: Inverse Filtering Based on the Fast Iterative Adaptive Approach","Y. Zhang; Y. Zhang; W. Li; Y. Huang; J. Yang","University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","27 Dec 2017","2018","56","1","127","144","High-resolution scanning radar mapping of the surface is an effective tool for addressing concerns in local environmental and social investigation fields. Regrettably, the azimuth resolution of a scanning radar is constrained by the antenna beamwidth. Multiple super-resolution approaches have been applied to the scanning radar to enhance the azimuth resolution, but they suffer from limited resolution improvement. In this paper, a methodology to derive surface estimates from the scanning radar at an improved azimuth resolution is proposed. We first consider the truncated spectrum by discarding the unreliable frequencies to suppress the noise amplification. Then, based on the iterative adaptive approach (IAA), a novel inverse filtering method is formulated to obtain lower sidelobes and a higher resolution. Finally, by taking advantage of the Fourier property of the steering matrix and the Toeplitz structure of the covariance matrix, we exploit the Gohberg-Semencul representation and the data-dependent trigonometric polynomials to derive a fast IAA (FIAA)-based inverse filtering to mitigate the computational burden. Simulation results and real data processing demonstrate that the proposed FIAA-based inverse filtering outperforms the existing super-resolution approaches in resolution improvement and results in a higher computational efficiency.","1558-0644","","10.1109/TGRS.2017.2743263","National Natural Science Foundation of China(grant numbers:61671117,61301273); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031984","Gohberg–Semencul (GS);inverse filtering;iterative adaptive approach (IAA);resolution improvement;scanning radar;super-resolution;Toeplitz;trigonometric polynomials","Azimuth;Radar imaging;Signal resolution;Spatial resolution;Iterative methods","adaptive signal processing;covariance matrices;estimation theory;filtering theory;Fourier analysis;iterative methods;polynomial matrices;radar antennas;radar resolution;signal denoising;signal representation;spectral analysis;Toeplitz matrices","FIAA;fast IAA-based inverse filtering;data-dependent trigonometric polynomials;Gohberg-Semencul representation;covariance matrix;Toeplitz structure;steering matrix;Fourier property;noise amplification suppression;truncated spectrum;surface estimates;antenna beamwidth;multiple super-resolution approaches;improved azimuth resolution;social investigation fields;local environmental investigation fields;high-resolution scanning radar mapping;fast iterative adaptive approach;super-resolution surface mapping","","62","","49","IEEE","12 Sep 2017","","","IEEE","IEEE Journals"
"A Cascaded Spectral–Spatial CNN Model for Super-Resolution River Mapping With MODIS Imagery","Z. Yin; F. Ling; X. Li; X. Cai; H. Chi; X. Li; L. Wang; Y. Zhang; Y. Du","Anhui Province Key Laboratory of Wetland Ecosystem Protection and Restoration, Anhui University, Hefei, China; Key Laboratory for Environment and Disaster Monitoring and Evaluation of Hubei, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; University of Chinese Academy of Sciences, Beijing, China; Key Laboratory for Environment and Disaster Monitoring and Evaluation of Hubei, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory for Environment and Disaster Monitoring and Evaluation of Hubei, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory for Environment and Disaster Monitoring and Evaluation of Hubei, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory for Environment and Disaster Monitoring and Evaluation of Hubei, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory for Environment and Disaster Monitoring and Evaluation of Hubei, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory for Environment and Disaster Monitoring and Evaluation of Hubei, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","17 Feb 2022","2022","60","","1","13","Rivers are important elements of the earth’s ecosystem, and their spatial distribution information is critical for the study of hydrological and biogeochemical processes. Moderate Resolution Imaging Spectroradiometer (MODIS) imagery has been widely used for river mapping due to its high temporal resolution and long-term observation records, which are essential to capture the rapid fluctuation of rivers. However, when the conventional hard classification methods are used, the accuracy of the river maps produced from MODIS data (and especially for those rivers with narrow widths) is often limited because mixed pixels are common in MODIS imagery, due to coarse spatial resolution. In this article, a cascaded spectral–spatial information combined deep convolutional neural network (CNN) model for super-resolution river mapping (DeepRivSRM) is proposed to produce Landsat-like fine-resolution river maps from MODIS images. In DeepRivSRM, a CNN made up of a spectral unmixing module and a super-resolution mapping (SRM) module is introduced to handle the spectral and spatial information simultaneously. Moreover, for training the DeepRivSRM model, an adaptive cross-entropy loss function incorporating the fraction information of the rivers is designed to improve the performance of the DeepRivSRM model for small rivers. The proposed method was evaluated with MODIS images from three test sites and was compared with hard classification, a conventional SRM method, and a CNN-based SRM method. The results show that DeepRivSRM can generate more accurate river maps by effectively learning the subpixel-scale spatial–spectral information in MODIS imagery.","1558-0644","","10.1109/TGRS.2021.3129789","Chinese Academy of Sciences through the Strategic Priority Research Program(grant numbers:XDA 2003030201); Hubei Natural Science Foundation through the Innovation Group Project(grant numbers:2019CFA019); Natural Science Foundation of China(grant numbers:62071457); Application Foundation Frontier Project of Wuhan(grant numbers:2020020601012283); Key Scientific Research Projects of Water Conservancy in Hubei Province, China(grant numbers:HBSLKY202103); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623549","Adaptive cross-entropy loss function;deep learning;fraction image;moderate resolution imaging spectroradiometer (MODIS);river mapping;super-resolution mapping (SRM)","Rivers;MODIS;Spatial resolution;Feature extraction;Convolutional neural networks;Training;Monitoring","convolutional neural nets;geophysical image processing;radiometry;rivers;terrain mapping","spatial distribution information;Moderate Resolution Imaging Spectroradiometer imagery;high temporal resolution;long-term observation records;conventional hard classification methods;MODIS data;MODIS imagery;coarse spatial resolution;cascaded spectral-spatial information;deep convolutional neural network model;super-resolution river mapping;fine-resolution river maps;spectral unmixing module;super-resolution mapping module;DeepRivSRM model;CNN-based SRM method;accurate river maps;subpixel-scale spatial-spectral information;cascaded spectral-spatial CNN model;Landsat-like fine-resolution river maps","","3","","68","IEEE","22 Nov 2021","","","IEEE","IEEE Journals"
"PMDRnet: A Progressive Multiscale Deformable Residual Network for Multi-Image Super-Resolution of AMSR2 Arctic Sea Ice Images","X. Liu; T. Feng; X. Shen; R. Li","Center for Spatial Information Science and Sustainable Development Applications, College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; Center for Spatial Information Science and Sustainable Development Applications, College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; Center for Spatial Information Science and Sustainable Development Applications, College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; Center for Spatial Information Science and Sustainable Development Applications, College of Surveying and Geo-Informatics, Tongji University, Shanghai, China","IEEE Transactions on Geoscience and Remote Sensing","25 Mar 2022","2022","60","","1","18","The extent of the area covered by polar sea ice is an important indicator of global climate change. Continuous monitoring of Arctic sea ice concentration (SIC) primarily relies on passive microwave images. However, passive microwave images have coarse spatial resolution, resulting in SIC production with significant blurring at the ice–water divides. In this article, a novel multi-image super-resolution (MISR) network called progressive multiscale deformable residual network (PMDRnet) is proposed to improve the spatial resolution of sea ice passive microwave images according to the characteristics of both passive microwave images and sea ice motions. To achieve image alignment with complex and large Arctic sea ice motions, we design a novel alignment module that includes a progressive alignment strategy and a multiscale deformable convolution alignment unit. In addition, the temporal attention mechanism is used to adaptively fuse the effective spatiotemporal information across image sequence. The sea ice-related loss function is designed to provide more detailed sea ice information of the network to improve super-resolution performance and further benefit finer Arctic SIC results. Experimental results demonstrate that PMDRnet significantly outperforms the current state-of-the-art MISR methods and can generate super-resolved SIC products with finer texture features and much sharper sea ice edges. The code and datasets of PMDRnet are available at https://doi.org/10.5061/dryad.k3j9kd590.","1558-0644","","10.1109/TGRS.2022.3151623","National Key Research and Development Program of China(grant numbers:2017YFA0603100); National Science Foundation of China(grant numbers:41801335,41941006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714397","Arctic sea ice;deep learning (DL);deformable convolution (DConv);multi-image super-resolution (MISR);passive microwave image;temporal attention","Sea ice;Microwave theory and techniques;Microwave integrated circuits;Microwave imaging;Microwave FET integrated circuits;Silicon carbide;Arctic;Climate change","geophysical image processing;image sequences;image texture;sea ice","image sequence;sea ice-related loss function;detailed sea ice information;super-resolution performance;benefit finer Arctic SIC results;PMDRnet;SIC products;sharper sea ice edges;progressive multiscale deformable residual network;AMSR2 Arctic sea ice images;polar sea ice;Arctic sea ice concentration;coarse spatial resolution;SIC production;ice-water divides;novel multiimage super-resolution network;sea ice passive microwave images;image alignment;complex Arctic sea ice motions;large Arctic sea ice motions;progressive alignment strategy;multiscale deformable convolution alignment unit","","1","","62","IEEE","15 Feb 2022","","","IEEE","IEEE Journals"
"Deep Blind Hyperspectral Image Super-Resolution","L. Zhang; J. Nie; W. Wei; Y. Li; Y. Zhang","Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, School of Computer Science, Northwestern Polytechnical University, Xi’an, China; Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, School of Computer Science, Northwestern Polytechnical University, Xi’an, China; Research & Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen, China; Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, School of Computer Science, Northwestern Polytechnical University, Xi’an, China; National Engineering Laboratory for Integrated Aerospace-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Neural Networks and Learning Systems","2 Jun 2021","2021","32","6","2388","2400","The production of a high spatial resolution (HR) hyperspectral image (HSI) through the fusion of a low spatial resolution (LR) HSI with an HR multispectral image (MSI) has underpinned much of the recent progress in HSI super-resolution. The premise of these signs of progress is that both the degeneration from the HR HSI to LR HSI in the spatial domain and the degeneration from the HR HSI to HR MSI in the spectral domain are assumed to be known in advance. However, such a premise is difficult to achieve in practice. To address this problem, we propose to incorporate degeneration estimation into HSI super-resolution and present an unsupervised deep framework for “blind” HSIs super-resolution where the degenerations in both domains are unknown. In this framework, we model the latent HR HSI and the unknown degenerations with deep network structures to regularize them instead of using handcrafted (or shallow) priors. Specifically, we generate the latent HR HSI with an image-specific generator network and structure the degenerations in spatial and spectral domains through a convolution layer and a fully connected layer, respectively. By doing this, the proposed framework can be formulated as an end-to-end deep network learning problem, which is purely supervised by those two input images (i.e., LR HSI and HR MSI) and can be effectively solved by the backpropagation algorithm. Experiments on both natural scene and remote sensing HSI data sets show the superior performance of the proposed method in coping with unknown degeneration either in the spatial domain, spectral domain, or even both of them.","2162-2388","","10.1109/TNNLS.2020.3005234","National Natural Science Foundation of China(grant numbers:61671385); Science, Technology and Innovation Commission of Shenzhen Municipality(grant numbers:JCYJ20190806160210899); Seed Foundation of Innovation and Creation for Graduate Students in Northwestern Polytechnical University(grant numbers:CX2020025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136736","Deep unsupervised learning;fusion-based hyperspectral image (HSI) super-resolution;unknown degeneration","Spatial resolution;Spectral analysis;Generators;Computer science;Hyperspectral imaging","backpropagation;deep learning (artificial intelligence);geophysical image processing;hyperspectral imaging;image resolution;remote sensing;unsupervised learning","low spatial resolution HSI;HR multispectral image;HR HSI;LR HSI;spatial domain;HR MSI;spectral domain;degeneration estimation;unsupervised deep framework;blind HSIs super-resolution;unknown degeneration;deep network structures;image-specific generator network;spatial domains;spectral domains;end-to-end deep network learning problem;input images;remote sensing HSI;deep blind hyperspectral image super-resolution;high spatial resolution hyperspectral image;backpropagation algorithm;atural scene","","28","","54","IEEE","8 Jul 2020","","","IEEE","IEEE Journals"
"Fine-grained Adversarial Image Inpainting with Super Resolution","Y. Li; B. Jiang; Y. Lu; L. Shen",Beijing Institute of Remote Sensing Information; Beijing Institute of Remote Sensing Information; Beijing Institute of Remote Sensing Information; Beijing Institute of Remote Sensing Information,"2019 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2019","2019","","","1","8","Image inpainting refers to synthesizing plausible contents for images with missing regions. However, current methods often create blurry textures, distorted structures and loss of details, especially when the image has complex scenes or large missing regions. We propose a fine-grained adversarial image inpainting model with super resolution. It performs a coarse-to-fine inpainting procedure in two stages. The proposed generator first synthesizes initial predictions of the missing regions with a novel encoder-decoder structure. Then it refines the predicted missing regions by generating high-frequency details via super resolution. We evaluate the proposed from both pixel level and semantic level. Experiments demonstrate that the proposed can generate higher quality inpainting results than the baseline models in both metrics.","2161-4407","978-1-7281-1985-4","10.1109/IJCNN.2019.8852241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852241","Image Inpainting;Image Completion;Super Resolution","Image resolution;Generators;Feature extraction;Generative adversarial networks;Image restoration;Decoding;Neural networks","image coding;image reconstruction;image resolution;image restoration;image texture","super resolution;plausible contents;blurry textures;distorted structures;complex scenes;fine-grained adversarial image inpainting model;coarse-to-fine inpainting procedure;predicted missing regions;high-frequency details;encoder-decoder structure;higher quality inpainting","","3","","29","IEEE","30 Sep 2019","","","IEEE","IEEE Conferences"
"Resolution Enhancement for Large-Scale Real Beam Mapping Based on Adaptive Low-Rank Approximation","Y. Zhang; J. Luo; Y. Zhang; Y. Huang; X. Cai; J. Yang; D. Mao; J. Li; X. Tuo; Y. Zhang","Yangtze Delta Region Institute, University of Electronic Science and Technology of China, Quzhou, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; Yangtze Delta Region Institute, University of Electronic Science and Technology of China, Quzhou, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; Yangtze Delta Region Institute, University of Electronic Science and Technology of China, Quzhou, China","IEEE Transactions on Geoscience and Remote Sensing","13 Sep 2022","2022","60","","1","21","Recently, a variety of super-resolution (SR) methods have been devoted to enhancing the angular resolution of real beam mapping (RBM) imagery in modern microwave remote sensing applications. When addressing large-scale datasets, however, they suffer from notably high computational complexity due to high-dimensional matrix inversion, multiplication, or singular value decomposition (SVD). To overcome this limitation, this article presents a low-complexity SR strategy based on adaptive low-rank approximation (LRA). Our underlying idea is first to construct a random matrix sketching to sample the raw echo measurements and restore the surface map of reflectivity in a low-dimensional linear space. The resulting low-complexity strategy enables substantial computational complexity reduction for a group of SR methods, at the cost of introducing a manually adjusted LRA parameter. Using the Fourier transform-based antenna analysis method, we further reveal that the LRA parameter that ensures support resolution improvement can be determined by a closed-form function of the aperture length, the wavelength, and the field of view, allowing for adaptively and efficiently selecting the optimal LRA parameter that well balances the tradeoff between LRA error and computational efficiency. We use both simulated and real datasets to demonstrate that the proposed LRA-based SR strategy can provide significant speedup without performance loss.","1558-0644","","10.1109/TGRS.2022.3202073","National Natural Science Foundation of China(grant numbers:61901092,61901090,61671117); Special Science Foundation of Quzhou; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9875209","Adaptive parameter selection;closed-form function;low-rank approximation (LRA);real beam mapping (RBM);super-resolution (SR)","Antennas;Azimuth;Computational modeling;Antenna measurements;Sensors;Computational complexity;Adaptive arrays","approximation theory;computational complexity;image resolution;matrix inversion;remote sensing;remote sensing by laser beam;singular value decomposition","large-scale real beam mapping;adaptive low-rank approximation;super-resolution methods;angular resolution;beam mapping imagery;modern microwave remote sensing applications;notably high computational complexity;high-dimensional matrix inversion;singular value decomposition;low-complexity SR strategy;random matrix;raw echo measurements;low-dimensional linear space;low-complexity strategy;substantial computational complexity reduction;SR methods;manually adjusted LRA parameter;antenna analysis method;optimal LRA parameter;LRA error;LRA-based SR strategy;Fourier transform-based antenna analysis method","","1","","65","IEEE","2 Sep 2022","","","IEEE","IEEE Journals"
"Pansharpening via Super-Resolution Iterative Residual Network With a Cross-Scale Learning Strategy","S. Chen; H. Qi; K. Nan","Sichuan Highway Planning, Survey, Design and Research Institute Ltd., Chengdu, China; Faculty of Geosciences and Environmental Engineering, Southwest Jiaotong University, Chengdu, China; Sichuan Highway Planning, Survey, Design and Research Institute Ltd., Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","8 Mar 2022","2022","60","","1","16","Pansharpening exploits the high-spatial-resolution panchromatic (HR PAN) images to restore the spatial resolution of the corresponding low-spatial-resolution multi-spectral (LR MS) image, producing a fused image and high-spatial-resolution multi-spectral (HR MS) image. Recently, many methods based on convolutional neural networks (CNNs) have been put forth for the pansharpening task, but most of them still have some limitations, such as the simple stacked convolutional architectures resulting in information distortion, and some scale-related problems caused by the supervised learning strategy. Therefore, we propose a method named super-resolution iterative residual (SRIR) network with a cross-scale (CS) learning strategy to overcome these drawbacks. Regarding the SRIR we propose, we design an upsampling network based on a sub-pixel convolution structure to replace the traditional upsampling pre-processing. We adopt the iterative networks framework and design a new spatial information injection module to continuously inject spatial and spectral features into the network, which can enhance the information flow and transmission. We produce approximate HR MS with a guidance filter and map the residual information between the approximate HR MS and the reference HR MS by SRIR to enhance the quality of fused images. Regarding the CS we propose, we train the network at degraded scale, which is named deep prior, and then design a finer-scale unsupervised fine-tuning loss function to refine the network parameters with deep priors, to overcome the scale effect. Experiments show the following: 1) SRIR-based pansharpening method can obtain the best result at the degraded scale; 2) the scale-effect is negatively correlated with the depth of the network, meaning that the deeper the network, the stronger the robustness to scale effect; 3) the CS learning strategy can widely improve the performance of CNNs-based pansharpening methods in full-resolution; and 4) our method can produce better results at full-resolution scale than all the other traditional and deep learning methods.","1558-0644","","10.1109/TGRS.2021.3138096","Key Research and Development Projects in Sichuan, China(grant numbers:2021YFS0334); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9662300","A super-resolution iterative residual (SRIR) network;cross-scale (CS) learning strategy;finer-scale unsupervised fine-tuning loss function;pansharpening","Pansharpening;Supervised learning;Superresolution;Spatial resolution;Residual neural networks;Convolutional neural networks;Convolution","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image enhancement;image fusion;image resolution;image sampling;iterative methods;remote sensing","super-resolution iterative residual network;cross-scale learning strategy;high-spatial-resolution panchromatic images;low-spatial-resolution multispectral image;LR MS;image fusion;high-spatial-resolution multispectral image;convolutional neural networks;convolutional architectures;information distortion;supervised learning strategy;upsampling network;sub-pixel convolution structure;iterative networks framework;spatial information injection module;spatial features;spectral features;information flow;residual information;finer-scale unsupervised fine-tuning loss function;network parameters;CS learning strategy;CNNs-based pansharpening methods;full-resolution scale;deep learning methods;HR MS;SRIR-based pansharpening method;upsampling pre-processing","","","","61","IEEE","23 Dec 2021","","","IEEE","IEEE Journals"
"A Deep Network Architecture for Super-Resolution-Aided Hyperspectral Image Classification With Classwise Loss","S. Hao; W. Wang; Y. Ye; E. Li; L. Bruzzone","College of Information and Control Engineering, Qingdao University of Technology, Qingdao; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Faculty of Geosciences and Environmental Engineering, Southwest Jiaotong University, Chengdu, China; College of Information and Control Engineering, Qingdao University of Technology, Qingdao; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy","IEEE Transactions on Geoscience and Remote Sensing","20 Jul 2018","2018","56","8","4650","4663","The supervised deep networks have shown great potential in improving the classification performance. However, training these supervised deep networks is very challenging for hyperspectral image given the fact that usually only a small amount of labeled samples are available. In order to overcome this problem and enhance the discriminative ability of the network, in this paper, we propose a deep network architecture for a super-resolution (SR)-aided hyperspectral image classification with classwise loss (SRCL). First, a three-layer SR convolutional neural network (SRCNN) is employed to reconstruct a high-resolution image from a low-resolution image. Second, an unsupervised triplet-pipeline CNN (TCNN) with an improved classwise loss is built to encourage intraclass similarity and interclass dissimilarity. Finally, SRCNN, TCNN, and a classification module are integrated to define the SRCL, which can be fine-tuned in an end-to-end manner with a small amount of training data. Experimental results on real hyperspectral images demonstrate that the proposed SRCL approach outperforms other state-of-the-art classification methods, especially for the task in which only a small amount of training data are available.","1558-0644","","10.1109/TGRS.2018.2832228","Natural Science Foundation of Shandong Province(grant numbers:ZR2017PF004,ZR2018MF002); National Natural Science Foundation of China(grant numbers:61701272); Fundamental Research Funds for the Central Universities(grant numbers:2682016CX083); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8390939","Classwise loss;convolutional neural networks (CNNs);deep learning;hyperspectral image classification;remote sensing;super-resolution (SR)","Hyperspectral imaging;Training;Feature extraction;Image reconstruction;Task analysis;Image resolution","feature extraction;geophysical image processing;hyperspectral imaging;image classification;image resolution;neural nets;unsupervised learning","deep network architecture;super-resolution-aided hyperspectral image classification;supervised deep networks;three-layer SR convolutional neural network;high-resolution image;low-resolution image;improved classwise loss;classification module;unsupervised triplet-pipeline CNN;intraclass similarity;interclass dissimilarity","","51","","49","IEEE","20 Jun 2018","","","IEEE","IEEE Journals"
"Hyperspectral image super-resolution extending: An effective fusion based method without knowing the spatial transformation matrix","Y. Li; L. Zhang; C. Tian; C. Ding; Y. Zhang; W. Wei","Northwestern Polytechnical University, School of Computer Science, Xi'an, China; Northwestern Polytechnical University, School of Computer Science, Xi'an, China; Xidian University, School of Electronic Engineering, Xi'an, China; Northwestern Polytechnical University, School of Computer Science, Xi'an, China; Northwestern Polytechnical University, School of Computer Science, Xi'an, China; Northwestern Polytechnical University, School of Computer Science, Xi'an, China","2017 IEEE International Conference on Multimedia and Expo (ICME)","31 Aug 2017","2017","","","1117","1122","Hyperspectral image (HSI) super-resolution, a technique to obtain higher (often spatial) resolution image from the original image, has been extensively studied and applied to lots of fields such as computer vision, remote sensing, etc. Though fusion based method has achieved state-of-the-art result, it always assume the spatial transformation matrix is given in advance, whereas such a matrix is actually unknown in reality. An unsuitable given matrix will deteriorate the superresolution result greatly. To address this issue, we propose a novel fusion based HSI super-resolution method without knowing the spatial transformation matrix. Specifically, we incorporate super-resolution and spatial transformation matrix estimation into a unified framework. We alternately estimate the matrix and the higher spatial resolution HSI. We find that without given the spatial transformation matrix, the proposed method can obtain more accurate reconstruction result compared with other competing methods. Experimental results demonstrate the effectiveness of the proposed method.","1945-788X","978-1-5090-6067-2","10.1109/ICME.2017.8019510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019510","Hyperspectral;super-resolution;spatial transformation estimation","Spatial resolution;Image reconstruction;Databases;Hyperspectral imaging;Dictionaries;Optimization","hyperspectral imaging;image fusion;image resolution;matrix algebra","hyperspectral image super-resolution;fusion based HSI super-resolution;spatial transformation matrix estimation","","7","","21","IEEE","31 Aug 2017","","","IEEE","IEEE Conferences"
"Multi-Frame Super-Resolution Algorithm Based on Attention Mechanism","C. Guo; J. Jiang; Q. Wang; G. Chen","College of Photonic and Electronic Engineering, Fujian Normal University, Fuzhou, China; College of Photonic and Electronic Engineering, Fujian Normal University, Fuzhou, China; College of Photonic and Electronic Engineering, Fujian Normal University, Fuzhou, China; College of Photonic and Electronic Engineering, Fujian Normal University, Fuzhou, China","2021 IEEE 6th International Conference on Signal and Image Processing (ICSIP)","28 Jan 2022","2021","","","431","435","In the field of computer vision, image super-resolution is a difficult task, which have many applications in remote sensing, military and so on. In this paper, we introduce the convolutional block attention module (CBAM) into super-resolution problem, proposing a novel method called multi-frame super-resolution (MFSR) algorithm based on attention mechanism. Our proposed MFSR algorithm uses a three-layer CNN as benchmark and cascades CBAM at the end of each CNN block. The proposed algorithm can deliver a high-resolution output corresponding to the center (3rd) input frame. The average PSNR and SSIM of our algorithm are 33.318dB and 0.906 respectively, which outperform other MFSR algorithm.","","978-1-6654-3904-6","10.1109/ICSIP52628.2021.9688891","Natural Science Foundation of Fujian Province; Health; Technology Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9688891","Attentional Mechanism;Multi-frame image super-resolution;PSNR;SSIM","Computer vision;Military computing;Convolution;Conferences;Superresolution;Convolutional neural networks;Task analysis","computer vision;convolutional neural nets;image resolution","convolutional block attention module;multiframe super-resolution algorithm;MFSR algorithm;high-resolution output;center input frame;computer vision;image super-resolution;CBAM;three-layer CNN;SSIM;PSNR","","","","14","IEEE","28 Jan 2022","","","IEEE","IEEE Conferences"
"Dynamic monitoring of urban expansion and economic development in Beijing based on multisource remote sensing images","X. Guan; B. Zeng; X. Song; T. Gan; J. Chen","School of Computer and Information Technology, Hohai University, Nanjing, China; School of Computer and Information Technology, Hohai University, Nanjing, China; Artificial Intelligence Academy, Hohai University, Nanjing, China; School of Computer and Information Technology, Hohai University, Nanjing, China; School of Computer and Information Technology, Hohai University, Nanjing, China","2022 4th International Conference on Advances in Computer Technology, Information Science and Communications (CTISC)","15 Aug 2022","2022","","","1","5","The rapid development of society has promoted the development of urbanization process. Impervious surface area as the most prominent feature of the urbanization process, accurate monitoring of its temporal and spatial dynamics plays a key role in comprehensive understanding the urbanization process. As a comprehensive technology of earth observation, remote sensing technology provides a fast and convenient way for urban expansion trend analysis with its characteristics of macroscopical, accurate and timely. Based on the time domain spectral characteristics of Landsat-8 remote sensing images and spectral indexes such as NDBI, NDVI and DEM, this paper uses the random forest classification algorithm in Google Earth Engine to extract the impervious surface area of Beijing in 2014, 2017 and 2020. The classification results are verified based on 2000 randomly selected verification points from high-resolution Google Earth images. The results show that the random forest classification algorithm based on GEE has high classification accuracy (the overall accuracy is higher than 95%, and the kappa coefficient is higher than 0.90). In addition, Nighttime light remote sensing image can reflect economy. Super-resolution convolutional neural network can improve the resolution of images. Combining the classification results with high-resolution NPP/VIIRS images, the dynamics of urban expansion and economic development can be clearly demonstrated.","","978-1-6654-5872-6","10.1109/CTISC54888.2022.9849808","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849808","GEE;Landsat-8;NPP/VIIRS;impervious surface area;random forest;SRCNN;Beijing","Economics;Earth;Surface reconstruction;Urban areas;Superresolution;Market research;Classification algorithms","geophysical image processing;image classification;neural nets;remote sensing","spatial dynamics;urbanization process;comprehensive technology;earth observation;remote sensing technology;urban expansion trend analysis;spectral characteristics;Landsat-8 remote sensing images;random forest classification algorithm;Google Earth Engine;impervious surface area;Beijing;2000 randomly selected verification points;high-resolution Google Earth images;high classification accuracy;Nighttime light remote sensing image;economic development;dynamic monitoring;multisource remote sensing images;temporal dynamics","","","","10","IEEE","15 Aug 2022","","","IEEE","IEEE Conferences"
"Thermal UAV Image Super-Resolution Guided by Multiple Visible Cues","Z. Zhao; Y. Zhang; C. Li; Y. Xiao; J. Tang","China Electronics Technology Group Corporation, 38th Research Institute, Hefei, China; Anhui Provincial Key Laboratory of Multimodal Cognitive Computation, School of Computer Science and Technology, Anhui University, Hefei, China; Information Materials and Intelligent Sensing Laboratory of Anhui Province, Anhui Provincial Key Laboratory of Multimodal Cognitive Computation, School of Artificial Intelligence, Anhui University, Hefei, China; Information Materials and Intelligent Sensing Laboratory of Anhui Province, Anhui Provincial Key Laboratory of Multimodal Cognitive Computation, School of Artificial Intelligence, Anhui University, Hefei, China; Anhui Provincial Key Laboratory of Multimodal Cognitive Computation, School of Computer Science and Technology, Anhui University, Hefei, China","IEEE Transactions on Geoscience and Remote Sensing","13 Jan 2023","2023","61","","1","14","Unmanned aerial vehicle (UAV) thermal-imaging has received much attention, but the insufficient image resolution caused by thermal imaging systems is still a crucial problem that limits the understanding of thermal UAV images. However, high-resolution visible images are relatively easy to access, and it is thus valuable for exploring useful information from visible image to assist thermal UAV image super-resolution (SR). In this article, we propose a novel multiconditioned guidance network (MGNet) to effectively mine the information of visible images for thermal UAV image SR. High-resolution visible UAV images usually contain salient appearance, semantic, and edge information, which plays a critical role in boosting the performance of thermal UAV image SR. Therefore, we design an effective multicue guidance module (MGM) to leverage the appearance, edge, and semantic cues from visible images to guide thermal UAV image SR. In addition, we build the first benchmark dataset for the task of thermal UAV image SR guided by visible images. It is collected by a multimodal UAV platform and composes of 1025 pairs of manually aligned visible and thermal images. Extensive experiments on the built dataset show that our MGNet can effectively leverage useful information from visible images to improve the performance of thermal UAV image SR and perform well against several state-of-the-art methods. The dataset is available at: https://github.com/mmic-lcl/Datasets-and-benchmark-code.","1558-0644","","10.1109/TGRS.2023.3234058","Joint Funds of the National Natural Science Foundation of China(grant numbers:U20B2068); University Synergy Innovation Program of Anhui Province(grant numbers:GXXT-2021-038); Natural Science Foundation of Anhui Province(grant numbers:2208085J18,2208085QF192); National Natural Science Foundation of China(grant numbers:62076003,62076005); Natural Science Foundation of Anhui Higher Education Institution(grant numbers:2022AH040014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10005291","Feature modulation;multiple visible cues;remote sensing;swin transformer;thermal image super-resolution (SR);unmanned aerial vehicle (UAV)","Image edge detection;Semantics;Autonomous aerial vehicles;Feature extraction;Task analysis;Imaging;Image reconstruction","autonomous aerial vehicles;image resolution;infrared imaging","high-resolution visible images;high-resolution visible UAV images;manually aligned visible images;multicue guidance module;thermal imaging systems;thermal UAV image super-resolution;unmanned aerial vehicle thermal-imaging","","","","72","IEEE","4 Jan 2023","","","IEEE","IEEE Journals"
"Deep Convolutional Neural Network Framework for Subpixel Mapping","D. He; Y. Zhong; X. Wang; L. Zhang","School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Hubei Provincial Engineering Research Center of Natural Resources Remote Sensing Monitoring, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Hubei Provincial Engineering Research Center of Natural Resources Remote Sensing Monitoring, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","26 Oct 2021","2021","59","11","9518","9539","Subpixel mapping (SPM) is an effective way to solve the mixed pixel problem, which is a ubiquitous phenomenon in remotely sensed imagery, by characterizing subpixel distribution within the mixed pixels. In fact, the majority of the classical and state-of-the-art SPM algorithms can be viewed as a convolution process, but these methods rely heavily on fixed and handcrafted kernels that are insufficient in characterizing a geographically realistic distribution image. In addition, the traditional SPM approach is based on the prerequisite of abundance images derived from spectral unmixing (SU), during which process uncertainty inherently exists and is propagated to the SPM. In this article, a kernel-learnable convolutional neural network (CNN) framework for subpixel mapping (SPMCNN-F) is proposed. In SPMCNN-F, the kernel is learnable during the training stage based on the given training sample pairs of low- and high-resolution patches for learning a geographically realistic prior, instead of fixed priors. The end-to-end mapping structure enables direct subpixel information extraction from the original coarse image, avoiding the uncertainty propagation from the SU. In the experiments undertaken in this study, two state-of-the-art super-resolution networks were selected as application demonstrations of the proposed SPMCNN-F method. In experiment part, three hyperspectral image data sets were adopted, two in a synthetic coarse image approach and one in a real coarse image approach, for the validation. Additionally, a new data set with pairs of Moderate-resolution Imaging Spectroradiometer (MODIS) and Landsat images were adopted in a real coarse image approach, for further validation of SPMCNN-F in large-scale area. The restored fine distribution images obtained in all the experiments showed a perceptually better reconstruction quality, both qualitatively and quantitatively, confirming the superiority of the proposed SPM framework.","1558-0644","","10.1109/TGRS.2020.3032475","National Natural Science Foundation of China(grant numbers:42071350,41771385); China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9258409","Convolutional neural network (CNN);hyperspectral imagery;mixed pixel problem;subpixel mapping (SPM);super-resolution (SR) network","Convolutional neural networks;Uncertainty;Hyperspectral imaging;Kernel;Training;Superresolution;Convolution","convolutional neural nets;geophysical image processing;geophysical techniques;image classification;image resolution;terrain mapping","synthetic coarse image approach;restored fine distribution images;SPM framework;deep convolutional neural network framework;subpixel mapping;mixed pixel problem;subpixel distribution;mixed pixels;classical state-of-the-art SPM algorithms;convolution process;fixed handcrafted kernels;geographically realistic distribution image;traditional SPM approach;abundance images;SU;process uncertainty;kernel-learnable convolutional neural network framework;given training sample pairs;high-resolution patches;fixed priors;end-to-end mapping structure;direct subpixel information extraction;original coarse image;uncertainty propagation;state-of-the-art super-resolution networks;SPMCNN-F method;hyperspectral image data sets","","23","","61","IEEE","12 Nov 2020","","","IEEE","IEEE Journals"
"Multi-Frame Super-Resolution Algorithm Based on a WGAN","K. Ning; Z. Zhang; K. Han; S. Han; X. Zhang","School of Computer Science and Technology, North China University of Technology, Beijing, China; School of Computer Science and Technology, North China University of Technology, Beijing, China; School of Computer Science and Technology, North China University of Technology, Beijing, China; School of Computer Science and Technology, North China University of Technology, Beijing, China; School of Science, Institute of Photoelectronics Technology, Beijing Jiaotong University, Beijing, China","IEEE Access","18 Jun 2021","2021","9","","85839","85851","Image super-resolution reconstruction has been widely used in remote sensing, medicine and other fields. In recent years, due to the rise of deep learning research and the successful application of convolutional neural networks in the image field, the super-resolution reconstruction technology based on deep learning has also achieved great development. However, there are still some problems that need to be solved. For example, the current mainstream image super-resolution algorithms based on single or multiple frames pursue high performance indicators such as PSNR and SSIM, while the reconstructed image is relatively smooth and lacks many high-frequency details. It is not conducive to application in a real environment. To address such problem, this paper proposes a super-resolution reconstruction model of sequential images based on Generative Adversarial Networks (GAN). The proposed approach combines the registration module to fuse adjacent frames, effectively use the detailed information in multiple consecutive frames, and enhances the spatio-temporality of low-resolution images in sequential images. While the GAN was used to improve the effect of image high-frequency texture detail reconstruction, WGAN was introduced to optimize model training. The reconstruction results not only improved the PSNR and SSIM indexes but also reconstructed more high-frequency detail textures. Finally, in order to further improve the perception effect, an additional registration loss item RLT is introduced in the GAN network perception loss. Through extensive experiments, it shows that the model proposed in this paper effectively obtains the information between the sequence images. When the PSNR and SSIM indicators are improve, it can reconstruct better high-frequency texture details than the current advanced multi-frame algorithms.","2169-3536","","10.1109/ACCESS.2021.3088128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9452141","Super-resolution reconstruction;sequential images;convolutional neural network;Wasserstein generative adversarial network (WGAN)","Image reconstruction;Superresolution;Generative adversarial networks;Spatial resolution;Generators;Visual perception","edge detection;image denoising;image reconstruction;image resolution;image sampling;image sequences;image texture;learning (artificial intelligence);maximum likelihood estimation;neural nets;wavelet transforms","remote sensing;deep learning research;convolutional neural networks;image field;super-resolution reconstruction technology;current mainstream image super-resolution algorithms;single frames;high performance indicators;reconstructed image;high-frequency details;super-resolution reconstruction model;sequential images;Generative Adversarial Networks;multiple consecutive frames;low-resolution images;image high-frequency texture;WGAN;high-frequency detail textures;GAN network perception loss;sequence images;high-frequency texture details;current advanced multiframe algorithms;multiframe super-resolution algorithm","","3","","39","CCBY","11 Jun 2021","","","IEEE","IEEE Journals"
"Online Super-Resolution Imaging for Airborne Scanning Radar Based on Sliding Window RLS Algorithm","J. Luo; Y. Zhang; Y. Zhang; Y. Zhang; Y. Huang; H. Yang; J. Yang","Yangtze Delta Region Institute of UESTC, Quzhou, China; Yangtze Delta Region Institute of UESTC, Quzhou, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5067","5070","Airborne radar high-squint looking imaging is an important research for remote sensing. The traditional Doppler beam sharpening based on fast Fourier transform (FFT) has good real-time performance but low cross-range resolution. Many super-resolution methods have been proposed to enhance the cross-range resolution for airborne radar. However, these methods generally adopt the batch processing mode with high computational complexity and high memory usage, which lead to poor real-time performance. This paper proposes an online super-resolution imaging approach for airborne scanning radar based on sliding window recursive least square (SWRLS) algorithm. The current scattering estimation can be derived recursively through downdating and updating. The proposed method effectively improves the cross-range resolution as well as the real-time performance and memory occupancy, which is beneficial to high-quint continuous realtime imaging for airborne radar. Simulation results are given to demonstrate the effectiveness of the proposed method.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553500","National Natural Science Foundation of China(grant numbers:61901092); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553500","Airborne radar;high-squint looking;online imaging;sliding window","Fast Fourier transforms;Simulation;Airborne radar;Superresolution;Satellite broadcasting;Imaging;Scattering","airborne radar;computational complexity;Doppler radar;fast Fourier transforms;image resolution;least squares approximations;radar imaging;radar resolution;recursive estimation;synthetic aperture radar","airborne scanning radar;sliding window RLS algorithm;airborne radar high-squint;traditional Doppler beam sharpening;cross-range resolution;super-resolution methods;high computational complexity;high memory usage;poor real-time performance;online super-resolution imaging approach;window recursive least square algorithm;high-quint continuous realtime","","","","8","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Low-Level Feature Enhancement Network for Semantic Segmentation of Buildings","Z. Wan; Q. Zhang; G. Zhang","School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Computer Science and Technology, East China Normal University, Shanghai, China","IEEE Geoscience and Remote Sensing Letters","26 May 2022","2022","19","","1","5","In recent years, convolutional neural networks (CNNs) have been widely used in extracting buildings from remote sensing images. Both semantic representation and spatial location details are crucial for this task. We propose the methods to enhance the performance of semantic segmentation by using these low-level features considering that man-made buildings in aerial images have strong textures and edges. Texture Enhancement Attention Module (TEAM) is proposed to strengthen feature in the position with rich texture and improve the semantic representation. Edge Extraction Module (EEM) is applied for directly guiding spatial details learning, which starts with super-resolution maps created by Super-Resolution Module (SRM). Detail Supplement Module (DSM) is designed to further provide the details for decoder. On this basis, we propose a low-level feature enhancement network (LFENet) for semantic segmentation of buildings. Experimental results on two aerial datasets show that our works greatly improve the accuracy over the baseline and other models.","1558-0571","","10.1109/LGRS.2022.3173626","Natural Science Foundation of Shanghai(grant numbers:21ZR1421200); National Nature Science Foundation of China(grant numbers:61731009,41301472); Science and Technology Commission of Shanghai Municipality(grant numbers:19511120600,18DZ2270800); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771243","Building extraction;convolutional neural networks (CNNs);edge;semantic segmentation;texture","Semantics;Feature extraction;Buildings;Convolution;Image edge detection;Superresolution;Correlation","edge detection;feature extraction;geophysical image processing;image classification;image enhancement;image resolution;image segmentation;image texture;learning (artificial intelligence);neural nets;remote sensing","man-made buildings;aerial images;strong textures;Texture Enhancement Attention Module;rich texture;semantic representation;Edge Extraction Module;spatial details learning;Super-Resolution Module;Detail Supplement Module;low-level feature enhancement network;convolutional neural networks;extracting buildings;remote sensing images;spatial location details;low-level features","","","","18","IEEE","9 May 2022","","","IEEE","IEEE Journals"
"A Latent Encoder Coupled Generative Adversarial Network (LE-GAN) for Efficient Hyperspectral Image Super-Resolution","Y. Shi; L. Han; L. Han; S. Chang; T. Hu; D. Dancey","Department of Computing and Mathematics, Faculty of Science and Engineering, Manchester Metropolitan University, Manchester, U.K; Department of Computing and Mathematics, Faculty of Science and Engineering, Manchester Metropolitan University, Manchester, U.K; Department of Computer Science, Brunel University London, Uxbridge, U.K; State Key Laboratory of Remote Sensing Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; College of Plant Protection, Hebei Agriculture University, Baoding, China; Department of Computing and Mathematics, Faculty of Science and Engineering, Manchester Metropolitan University, Manchester, U.K","IEEE Transactions on Geoscience and Remote Sensing","10 Aug 2022","2022","60","","1","19","Realistic hyperspectral image (HSI) super-resolution (SR) techniques aim to generate a high-resolution (HR) HSI with higher spectral and spatial fidelity from its low-resolution (LR) counterpart. The generative adversarial network (GAN) has proven to be an effective deep learning framework for image SR. However, the optimization process of existing GAN-based models frequently suffers from the problem of mode collapse, leading to the limited capacity of spectral–spatial invariant reconstruction. This may cause the spectral–spatial distortion to the generated HSI, especially with a large upscaling factor. To alleviate the problem of mode collapse, this work has proposed a novel GAN model coupled with a latent encoder (LE-GAN), which can map the generated spectral–spatial features from the image space to the latent space and produce a coupling component to regularize the generated samples. Essentially, we treat an HSI as a high-dimensional manifold embedded in a latent space. Thus, the optimization of GAN models is converted to the problem of learning the distributions of HR HSI samples in the latent space, making the distributions of the generated SR HSIs closer to those of their original HR counterparts. We have conducted experimental evaluations on the model performance of SR and its capability in alleviating mode collapse. The proposed approach has been tested and validated based on two real HSI datasets with different sensors (i.e., AVIRIS and UHD-185) for various upscaling factors (i.e.,  $\times 2$ ,  $\times 4$ , and  $\times 8$ ) and added noise levels (i.e.,  $\infty $ , 40, and 80 dB) and compared with the state-of-the-art SR models (i.e., hyperspectral coupled network (HyCoNet), low tensor-train rank (LTTR), band attention GAN (BAGAN), SR-GAN, and WGAN). Experimental results show that the proposed model outperforms the competitors on the SR quality, robustness, and alleviation of mode collapse. The proposed approach is able to capture spectral and spatial details and generate more faithful samples than its competitors. It has also been found that the proposed model is more robust to noise and less sensitive to the upscaling factor and has been proven to be effective in improving the convergence of the generator and the spectral–spatial fidelity of the SR HSIs.","1558-0644","","10.1109/TGRS.2022.3193441","Biotechnology and Biological Sciences Research Council (BBSRC)(grant numbers:BB/R019983/1,BB/S020969/1); Newton Fund Institutional Links through the Newton-Ungku Omar Fund Partnership [the grant is funded by the U.K. Department of Business, Energy, and Industrial Strategy (BEIS)](grant numbers:ID 332438911); Open Research Fund of Key Laboratory of Digital Earth Science, Chinese Academy of Sciences(grant numbers:2019LDE003); Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/W007762/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9837938","Deep learning (DL);generative adversarial network (GAN);hyperspectral image (HSI) super-resolution (SR)","Superresolution;Generative adversarial networks;Generators;Spatial resolution;Optimization;Data models;Distortion","deep learning (artificial intelligence);geophysical image processing;hyperspectral imaging;image coding;image denoising;image reconstruction;image resolution;tensors","realistic hyperspectral image super resolution techniques;spectral spatial invariant reconstruction;spectral spatial distortion;generated spectral spatial features;spectral spatial fidelity;SR HSI;spatial details;spectral details;SR quality;SR-GAN;hyperspectral coupled network;state-of-the-art SR models;HSI datasets;generated SR;HR HSI samples;high dimensional manifold;coupling component;latent space;image space;LE-GAN;GAN model;generated HSI;GAN-based models;optimization process;image SR;deep learning framework;higher spectral fidelity;high resolution HSI;generative adversarial network;latent encoder","","","","69","IEEE","25 Jul 2022","","","IEEE","IEEE Journals"
"Hyperspectral Image Compression and Super-Resolution Using Tensor Decomposition Learning","A. Aidini; M. Giannopoulos; A. Pentari; K. Fotiadou; P. Tsakalides","Department of Computer Science, University of Crete; Department of Computer Science, University of Crete; Department of Computer Science, University of Crete; Department of Computer Science, University of Crete; Department of Computer Science, University of Crete","2019 53rd Asilomar Conference on Signals, Systems, and Computers","30 Mar 2020","2019","","","1369","1373","As the field of remote sensing for Earth Observation is rapidly evolving, there is an increasing demand for developing suitable methods to store and transmit the massive amounts of the generated data. At the same time, as multiple sensors acquire observations with different dimensions, super-resolution methods come into play to unify the framework for upcoming statistical inference tasks. In this paper, we employ a tensor-based structuring of multi-spectral image data and we propose a low-rank tensor completion scheme for efficient image-content compression and recovery. To address the problem of low-resolution imagery, we further provide a robust algorithmic scheme for super-resolving satellite images, followed by a state-of-the-art convolutional neural network architecture serving the classification task of the employed images. Experimental analysis on real-world observations demonstrates the detrimental effects of image compression on classification, an issued successfully addressed by the proposed recovery and super-resolution schemes.","2576-2303","978-1-7281-4300-2","10.1109/IEEECONF44664.2019.9048735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9048735","Multi-Spectral Image Classification;Compression;Tensor Unfoldings;Super Resolution;Alternating Direction Method of Multipliers","Tensors;Image coding;Task analysis;Spatial resolution;Signal resolution","convolutional neural nets;data compression;geophysical image processing;geophysical techniques;hyperspectral imaging;image classification;image coding;image resolution;learning (artificial intelligence);remote sensing;tensors","hyperspectral image compression;remote sensing;Earth Observation;super-resolution methods;statistical inference tasks;multispectral image data;low-rank tensor completion scheme;low-resolution imagery;robust algorithmic scheme;super-resolving satellite images;super-resolution schemes;convolutional neural network architecture;image-content compression","","2","","18","IEEE","30 Mar 2020","","","IEEE","IEEE Conferences"
"Sparse coding for super-resolution via K-means classification","Xiao Aoran; Shao Zhenfeng; Z. Wang","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, China; Wuhan University, Wuhan, Hubei, CN","2017 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)","7 Sep 2017","2017","","","363","368","Super-resolution techniques reconstructing a higher resolution image from one or multiple low-resolution images are helpful to visual recognition under the scenarios of insufficient acquisition resolution. Due to the limited wireless network transmission bandwidth or mobile device processing capacity, image resolution in mobile phones and other mobile devices is not as high as expected, which restricts the clarity of the image display. This kind of resolution-improvement technique shows a great value for the mobile business. wing to the graceful theoretical foundation, image super-resolution methods via sparse coding have gained much popularity since it was proposed in 2008. However, the underlying single sparse dictionary in the existing methods is difficult to adapt to complex and diversified image contents so that the promotion of representation precision heavily depends on the growth of dictionary volume. In this paper, we propose to learn a set of coupled-dictionaries corresponding to unequal content complexity by using K-means classification, and then adaptively choose an appropriate one for each input low-resolution patch during super-resolution reconstruction. The experimental results on public dataset show that our approach outperforms the classic sparse coding based methods in terms of visual effects and PSNR metrics.","","978-1-5386-0560-8","10.1109/ICMEW.2017.8026254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8026254","super-resolution;dictionary learning;K-means;sparse representation","Interpolation;Image resolution;Training;Testing","image classification;image coding;image reconstruction;image resolution;mobile handsets","sparse coding;K-means classification;higher resolution image reconstruction;low-resolution images;visual recognition;mobile phones;image display clarity;sparse dictionary;coupled-dictionaries;superresolution reconstruction","","","","","IEEE","7 Sep 2017","","","IEEE","IEEE Conferences"
"Hyperspectral Image Super Resolution Based on Multiscale Feature Fusion and Aggregation Network With 3-D Convolution","J. Hu; Y. Tang; S. Fan","School of Electrical and Information Engineering, Changsha University of Science and Technology, Changsha, China; School of Electrical and Information Engineering, Changsha University of Science and Technology, Changsha, China; Key Laboratory of Electric Power Robot of Hunan Province, Changsha University of Science and Technology, Changsha, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","16 Sep 2020","2020","13","","5180","5193","The spectral resolution of hyperspectral images (HSIs) is very high. Nevertheless, their spatial resolution is low due to various hardware limitations. Therefore, it is important to study HSI super resolution to improve their spatial resolution. In this article, for hyperspectral single-image super resolution, we propose a multiscale feature fusion and aggregation network with 3-D convolution (MFFA-3D) by cascading the MFFA-3D block. The MFFA-3D block includes a group multiscale feature fusion part and a multiscale feature aggregation part. In group multiscale feature fusion part, a novel group multiscale feature fusion method is proposed. Group feature fusion module and two-step multiscale module are proposed in multiscale feature aggregation part. In order to prevent spectral distortion, a spectral gradient loss function is proposed and combined with the mean square error loss function to form the final loss function. Since the proposed super-resolution (SR) network is a full 3-D convolutional network, our method can perform direct super-resolution transfer even if the number of the bands of test images is different from that of the training images. The experiments over simulated and real HSIs demonstrate the superiority of the proposed method in terms of qualitative and quantitative evaluation.","2151-1535","","10.1109/JSTARS.2020.3020890","National Natural Science Foundation of China(grant numbers:61601061,61971071); Scientific Research Fund of Hunan Provincial Education Department(grant numbers:14B006); Open Research Fund of Key Laboratory of Electric Power Robot of Hunan Province(grant numbers:PROF1902); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184151","3-D convolutional neural network;group;hyperspectral image (HSI);multiscale feature fusion;super resolution (SR)","Three-dimensional displays;Spatial resolution;Convolution;Interpolation;Image reconstruction;Hyperspectral sensors","convolutional neural nets;feature extraction;geophysical image processing;hyperspectral imaging;image fusion;image resolution;learning (artificial intelligence);mean square error methods","mean square error loss function;multiscale feature aggregation part;group multiscale feature fusion part;MFFA-3D block;hyperspectral single-image super resolution;HSI super resolution;spatial resolution;spectral resolution;aggregation network;direct super-resolution transfer;full 3-D convolutional network;spectral gradient loss function;two-step multiscale module","","10","","33","CCBY","1 Sep 2020","","","IEEE","IEEE Journals"
"Boosting the Accuracy of Multispectral Image Pansharpening by Learning a Deep Residual Network","Y. Wei; Q. Yuan; H. Shen; L. Zhang","State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China; School of Resource and Environmental Science, Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, the Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","25 Sep 2017","2017","14","10","1795","1799","In the field of multispectral (MS) and panchromatic image fusion (pansharpening), the impressive effectiveness of deep neural networks has recently been employed to overcome the drawbacks of the traditional linear models and boost the fusion accuracy. However, the existing methods are mainly based on simple and flat networks with relatively shallow architectures, which severely limits their performance. In this letter, the concept of residual learning is introduced to form a very deep convolutional neural network to make the full use of the high nonlinearity of the deep learning models. Through both quantitative and visual assessments on a large number of high-quality MS images from various sources, it is confirmed that the proposed model is superior to all the mainstream algorithms included in the comparison, and achieves the highest spatial-spectral unified accuracy.","1558-0571","","10.1109/LGRS.2017.2736020","National Natural Science Foundation of China(grant numbers:41401383,41422108); Fundamental Research Funds for the Central Universities(grant numbers:2042017kf0180); Natural Science Foundation of Hubei Province(grant numbers:ZRMS2016000241); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8012503","Convolutional neural network;data fusion;pansharpening;remote sensing;residual learning","Machine learning;Neural networks;Spectral analysis;Spatial resolution;Training;Feature extraction","convolution;image colour analysis;image fusion;image resolution;learning (artificial intelligence);neural nets","multispectral image pansharpening;deep residual network;panchromatic image fusion;residual learning;deep convolutional neural network;image super-resolution","","309","","24","IEEE","17 Aug 2017","","","IEEE","IEEE Journals"
"Adversarial Spectral Super-Resolution for Multispectral Imagery Using Spatial Spectral Feature Attention Module","Z. Liu; H. Zhu; Z. Chen","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Hubei Luojia Laboratory, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","8 Feb 2023","2023","16","","1550","1562","Acquiring high-quality hyperspectral imagery with high spatial and spectral resolution plays an important role in remote sensing. Due to the limited capacity of sensors, providing high spatial and spectral resolution is still a challenging issue. Spectral super-resolution (SSR) increases the spectral dimensionality of multispectral images to achieve resolution enhancement. In this article, we propose a spectral resolution enhancement method based on the generative adversarial network framework without introducing additional spectral responses prior. In order to adaptively rescale informative features for capturing interdependencies in the spectral and spatial dimensions, a spatial spectral feature attention module is introduced. The proposed method jointly exploits spatio-spectral distribution in the hyperspectral manifold to increase spectral resolution while maintaining spatial content consistency. Experiments are conducted on both synthetic Landsat 8 and Sentinel-2 radiance data and real coregistered advanced land image and Hyperion (MS and HS) images, which indicates the superiority of the proposed method compared to other state-of-the-art methods.","2151-1535","","10.1109/JSTARS.2023.3238853","National Natural Science Foundation of China(grant numbers:62036005); Special Fund of Hubei Luojia Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024263","Adversarial learning;attention mechanism;hyperspectral imagery;spectral super-resolution (SSR)","Hyperspectral imaging;Spatial resolution;Image reconstruction;Superresolution;Sensors;Correlation;Cameras","","","","","","52","CCBY","23 Jan 2023","","","IEEE","IEEE Journals"
"HASIC-Net: Hybrid Attentional Convolutional Neural Network With Structure Information Consistency for Spectral Super-Resolution of RGB Images","J. Li; S. Du; R. Song; C. Wu; Y. Li; Q. Du","CAS Key Laboratory of Spectral Imaging Technology, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; Department of Electrical and Computer Engineering, Mississippi State University, Starkville, MS, USA","IEEE Transactions on Geoscience and Remote Sensing","15 Mar 2022","2022","60","","1","15","Spectral super-resolution (SSR), referring to the recovery of a reasonable hyperspectral image (HSI) from a single RGB image, has achieved satisfactory performance as part of the continued development of a convolutional neural network (CNN) in remote sensing image processing. However, the majority of existing algorithms focus on the pursuit of networks with deeper or broader architecture. Such algorithms have a poor channel or band feature extraction and fusing performance, and fail to fully leverage the input RGB images. To overcome these issues, we present a novel hybrid attentional CNN with structure information consistency (HASIC-net) that uses a two-pathway architecture. Specifically, both sides are stacked with several 2-D residual groups (2-DRGs) and residual groups (1-DRGs) equipped with channel or band attention (BA) modules, which mainly focuses on extracting channel statistics and bandwise features, respectively, by a parallel pooling architecture. We introduce several transversal connections from 2-DRG to 1-DRG to realize the interaction of information flow between both sides. In addition, we take the structure information of both RGB images and HSI into consideration and devise a structure information consistency (SIC) module to merge the structure tensor prior to the RGB images with the input of each 2-DRG. We then combine spectral gradient constraint loss with mean relative absolute error as a novel loss function to further restrain the spectral distortion and smooth the reconstructed spectral response curves. Experimental results on four benchmark datasets (i.e., NTIRE 2020, NTIRE 2018, CAVE, and Harvard) demonstrate that our proposed HASIC-net achieves state-of-the-art performance.","1558-0644","","10.1109/TGRS.2022.3142258","National Nature Science Foundation of China(grant numbers:61901343); State Key Laboratory of Geo-Information Engineering(grant numbers:SKLGIE2020-M-3-1); China Postdoctoral Science Foundation(grant numbers:2017M623124); China Postdoctoral Science Special Foundation(grant numbers:2018T111019); Science and Technology on Space Intelligent Control Laboratory(grant numbers:ZDSYS-2019-03); Fundamental Research Funds for the Central Universities(grant numbers:JB190107); National Nature Science Foundation of China(grant numbers:61571345,61671383,91538101,61501346,61502367); Higher Education Discipline Innovation Project(grant numbers:B08038); Innovation Fund of Xidian University(grant numbers:10221150004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678983","Channel or band attention (BA) modules (CBAMs);spectral gradient constraint;spectral super-resolution (SSR);structure information consistency (SIC)","Image reconstruction;Convolutional neural networks;Superresolution;Encoding;Feature extraction;Silicon carbide;Hyperspectral imaging","convolutional neural nets;geophysical image processing;hyperspectral imaging;image colour analysis;image resolution;statistical analysis","channel statistical extraction;BA modules;band attention modules;NTIRE 2020 benchmark datasets;NTIRE 2018 benchmark datasets;CAVE benchmark datasets;Harvard benchmark datasets;input RGB imaging;spectral response curve reconstruction;HASIC-net;spectral distortion;spectral gradient constraint loss;structure tensor;structure information consistency module;information flow;1-DRG;parallel pooling architecture;2-DRG;2-D residual groups;fusing performance;remote sensing image processing;CNN;HSI;hyperspectral image;spectral super-resolution;hybrid attentional convolutional neural network","","4","","53","IEEE","12 Jan 2022","","","IEEE","IEEE Journals"
"Deep Joint Estimation Network for Satellite Video Super-Resolution With Multiple Degradations","H. Liu; Y. Gu","School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Geoscience and Remote Sensing","19 Apr 2022","2022","60","","1","15","Super-resolution (SR) for satellite video data has been a hot research topic in the field of remote sensing video analysis. The existing satellite video SR methods assume that the blur kernel in the imaging degradation model is known. However, the blur kernel in real satellite videos is usually unknown, which inevitably results in poor performance when the true blur kernel is not consistent with a predefined blur kernel. To address this issue, this article proposes a deep joint estimation network for satellite video SR (JENSVSR), which jointly estimates blur kernels and SR frames. Specifically, JENSVSR is composed of a video SR subnetwork and a blur kernel estimation subnetwork. On one hand, the video SR subnetwork makes use of multiple video frames to generate super-resolved satellite frames. To effectively fuse information from adjacent frames, an alignment and fusion module is proposed in the feature space. On the other hand, the blur estimation subnetwork is also proposed to predict blur kernels. The two subnetworks are coupled by cross-task feature fusion modules (CTFFMs) to achieve joint estimation rather than two-step independent estimation. The performance of our proposed method is evaluated on synthetic and real satellite videos. The experimental results show that our proposed method is superior to the current state-of-the-art SR methods.","1558-0644","","10.1109/TGRS.2022.3163790","National Natural Science Foundation of Key International Cooperation(grant numbers:61720106002); National Science Fund for Excellent Young Scholars(grant numbers:61522107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745539","Blur kernel estimation;multiple degradations;satellite video;super-resolution (SR)","Kernel;Satellites;Estimation;Degradation;Image reconstruction;Spatial resolution;Convolution","image fusion;image reconstruction;image resolution;image restoration;video signal processing","deep joint estimation network;satellite video super-resolution;satellite video data;remote sensing video analysis;existing satellite video SR methods;satellite videos;predefined blur kernel;SR frames;video SR subnetwork;blur kernel estimation subnetwork;multiple video frames;super-resolved satellite frames;blur estimation subnetwork;current state-of-the-art SR methods","","","","57","IEEE","31 Mar 2022","","","IEEE","IEEE Journals"
"Online Point Cloud Super Resolution using Dictionary Learning for 3D Urban Perception","R. C. Shinde; A. V. Potnis; S. S. Durbha","Centre of Studies in Resources Engineering, Indian Institute of Technology Bombay, Mumbai, India; Centre of Studies in Resources Engineering, Indian Institute of Technology Bombay, Mumbai, India; Centre of Studies in Resources Engineering, Indian Institute of Technology Bombay, Mumbai, India","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","4414","4417","Real-time embedded vision tasks require extraction of complex geometric and morphological features from the raw 3D point cloud acquired using range scanning systems like lidar, radar etc. and depth cameras. Such applications are found in autonomous navigation, surveying, 3D mapping and localization tasks such as automatic target recognition (ATR). Typically, a dataset acquired during surveying by remote sensing lidar scanners, known as point cloud, is (1) huge in size and requires a big chunk of memory for processing at a single instance and, (2) experiences missing information due to rapid change in orientation of the sensor while scanning. In our work, we are addressing both the issues combinedly by proposing an online point cloud super-resolution approach for translating a low dimensional point cloud to a high dimensional dense point cloud by learning dictionaries in the low-dimensional subspace. We are presenting our approach for an urban road scenario by reconstructing dense point clouds of 3D objects and comparing results based on PSNR and Hausdorff distance.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323992","lidar point cloud super-resolution;online dictionary learning;3D vision and perception","Three-dimensional displays;Superresolution;Machine learning;Image resolution;Laser radar;Image reconstruction;Dictionaries","","","","","","5","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Real-Time Super-Resolution ISAR Imaging Using Unsupervised Learning","X. Huang; J. Ding; Z. Xu","National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","7 Jan 2022","2022","19","","1","5","Compressive sensing (CS) enables high-resolution inverse synthetic aperture radar (ISAR) imaging with limited measurements. However, these methods reconstruct images via iterative optimization, resulting in a high computational load. Recently, convolutional neural networks (CNNs) have been used to perform super-resolution ISAR imaging in real time, where high-resolution images are necessarily used as ground truth. However, the desired high-resolution images are not reliable in practice. This letter presents an unsupervised CNN-based framework for super-resolution ISAR imaging. The well-trained CNN can directly produce high-resolution ISAR images in real time. Moreover, the network is trained in an unsupervised manner, which is suitable for practical applications. Furthermore, a pseudo  $\ell _{0}$ -norm has been used as the sparse constraint for the exact image reconstruction. The proposed approach has been used to process the real ISAR data, and the experimental results are convincing.","1558-0571","","10.1109/LGRS.2021.3128525","National Science Foundation of China(grant numbers:62171358); Fundamental Research Funds for the Central Universities of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615196","Convolutional neural networks (CNNs);inverse synthetic aperture radar (ISAR);radar imaging","Imaging;Superresolution;Convolution;Radar imaging;Image reconstruction;Airplanes;Convolutional neural networks","compressed sensing;convolutional neural nets;image reconstruction;image resolution;iterative methods;optimisation;radar imaging;synthetic aperture radar;unsupervised learning","high computational load;high-resolution images;unsupervised CNN-based framework;high-resolution ISAR images;image reconstruction;ISAR data;high-resolution inverse synthetic aperture radar imaging;real-time super-resolution ISAR imaging;unsupervised learning","","2","","13","IEEE","16 Nov 2021","","","IEEE","IEEE Journals"
"DEM Extraction from Airborne Lidar Point Cloud in Thick-Forested Areas via Convolutional Neural Network","Y. Zhang; S. Xiang; Y. Wan; H. Cao; Y. Luo; Z. Zheng","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Division of Imaging Sciences and Biomedical Engineering Research, King's College London, London, U.K.; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","461","464","Digital Elevation Model (DEM), representing the height of the earth terrain, is one of the crucial geographic information products. One of the main data source of DEM is the airborne LiDAR point cloud with its non-ground-reflections filtered out. Point cloud filtering in thick-forested areas is difficult without enough ground control points when using conventional methods. In this paper, a supervised method is proposed to handle the problem of automatic DEM extraction with little ground control points. The design of the method is inspired by the successful application of the convolutional neural networks (CNN) in the image super resolution (SR) process. First, with the given LiDAR point cloud, the digital surface model (DSM) is resampled with regular grid. Then, by learning the spatial autocorrelation between the DSM and its corresponding DEM, a robust CNN model is established. Finally, the DEM in thick-forested areas can be generated from the DSM with the trained model. Experimental results at two different mountain sites in China validate the effectiveness of the proposed method of high-precision DEM generation.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323201","National Key Research and Development Program of China(grant numbers:2017YFB0503004); National Natural Science Foundation of China(grant numbers:41871368); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323201","Digital Elevation Model (DEM);Digital Surface Model (DSM);convolutional neural network (CNN);LiDAR point cloud;DEM extraction","Three-dimensional displays;Laser radar;Training;Interpolation;Image reconstruction;Feature extraction;Correlation","airborne radar;digital elevation models;geographic information systems;geophysical image processing;image resolution;neural nets;optical radar;remote sensing;terrain mapping","thick-forested areas;convolutional neural network;Digital Elevation Model;crucial geographic information products;main data source;airborne lidar point cloud;nonground-reflections;ground control points;supervised method;automatic DEM extraction;given LiDAR point cloud;digital surface model;DSM;corresponding DEM;robust CNN model;high-precision DEM","","","","12","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"An efficient approach for spattotemporal image fusion with application to HSHT land cover change simulation","M. Ding; H. Wang; L. Sui","Chang'an Universtiy, Xi'an, China; Xi'an University of Finance and Economics, Xi'an, China; Chang'an Universtiy, Xi'an, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","2578","2581","Monitoring fast land-cover changes at fine special resolution is an important requirement for global environmental change research. In this paper, we present a novel spatiotemporal fusion framework to efficiently simulate surface reflectance with both high-spatial and high-temporal (HSHT) resolution. The main contribution may be divided into two parts. First, a semi-physical unmixing algorithm is developed to super-resolve the heterogeneous landscapes with phenology change. Second, a super-resolution method is proposed for the land-cover-type changed landscape based on nonlocal-crossing-similarity property. The method is demonstrated on two types of data: images primarily with phenology changes and images primarily with land-cover-type changes. By comparing with other well-known spatiotemporal fusion algorithms, we evaluate the precision of the proposed approach.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729666","Spatiotemporal image fusion;super-resolution;land-cover change;nonlocal-self-similarity","Remote sensing;Satellites;Earth;MODIS;Spatial resolution;Reflectivity","land cover;remote sensing","spatiotemporal image fusion;HSHT land cover change simulation;fine special resolution;global environmental change research;novel spatiotemporal fusion framework;high-spatial and high-temporal resolution;semiphysical unmixing algorithm;land-cover-type changed landscape;nonlocal-crossing-similarity property","","","","8","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Deep Learning for Multiple-Image Super-Resolution","M. Kawulok; P. Benecki; S. Piechaczek; K. Hrynczenko; D. Kostrzewa; J. Nalepa","Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland; Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland; Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland; Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland; Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland; Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, Gliwice, Poland","IEEE Geoscience and Remote Sensing Letters","21 May 2020","2020","17","6","1062","1066","Super-resolution (SR) reconstruction is a process aimed at enhancing the spatial resolution of images, either from a single observation, based on the learned relation between low and high resolution, or from multiple images presenting the same scene. SR is particularly important, if it is not feasible to acquire images at the desired resolution, while there are single or many observations available at lower resolution - this is inherent to a variety of remote sensing scenarios. Recently, we have witnessed substantial improvement in single-image SR attributed to the use of deep neural networks for learning the relation between low and high resolution. Importantly, deep learning has not been widely exploited for multiple-image super-resolution, which benefits from information fusion and in general allows for achieving higher reconstruction accuracy. In this letter, we introduce a new approach to combine the advantages of multiple-image fusion with learning the low-to-high resolution mapping using deep networks. The results of our extensive experiments indicate that the proposed framework outperforms the state-of-the-art SR methods.","1558-0571","","10.1109/LGRS.2019.2940483","European Space Agency (SuperDeep Project, realized by Future Processing); Statutory Research Funds of Institute of Informatics, Silesian University of Technology, Poland(grant numbers:02/020/BK_18/0128); Silesian University of Technology, Poland(grant numbers:BKM-556/RAU2/2018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884136","Convolutional neural networks (CNNs);deep learning;image processing;super resolution (SR)","Image reconstruction;Spatial resolution;Satellites;Deep learning;Imaging;Gallium nitride","image fusion;image reconstruction;image resolution;learning (artificial intelligence);neural nets","single-image SR;deep neural networks;deep learning;multiple-image super-resolution;multiple-image fusion;low-to-high resolution mapping;super-resolution reconstruction;spatial resolution;single observation;information fusion","","44","","22","IEEE","28 Oct 2019","","","IEEE","IEEE Journals"
"A Fast Sparse Azimuth Super-Resolution Imaging Method of Real Aperture Radar Based on Iterative Reweighted Least Squares With Linear Sketching","X. Tuo; Y. Zhang; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","18 Mar 2021","2021","14","","2928","2941","It is greatly significant to achieve radar forward-looking region imaging. Due to the limitation of phase ambiguity and small Doppler gradient in forward-looking region, synthetic aperture radar and Doppler beam sharpening cannot work for forward-looking imaging, while real aperture radar (RAR) has arbitrary imaging geometry. Nevertheless, restricted by the antenna aperture, azimuth resolution of RAR is coarse, super-resolution technology is required to improve its azimuth resolution. Exploiting the sparse prior information of the target, the super-resolution problem can be transformed into an L1 norm minimization problem mathematically. Iterative reweighted algorithm can effectively solve the L1 norm minimization problem by replacing L1 norm with reweighted L2 norm and computing the weight in each iteration. However, it suffers from a large computational load due to the repeated multiplications and inversions of large matrices. In this article, a fast azimuth super-resolution imaging method of RAR based on iterative reweighted least squares (IRLS) with linear sketching (LS) was proposed to achieve fast super-resolution imaging of RAR. The LS theory is employed to compress echo matrix and antenna measurement matrix into much smaller matrices via multiplying them by an embedded matrix. Then, the IRLS solver was utilized to address the reconstructed objective function. Much of the expensive computation can then be performed on the smaller matrices, thereby accelerating the algorithm. Simulations and experimental data prove that the proposed algorithm can offer a time complexity reduction without loss of imaging performance.","2151-1535","","10.1109/JSTARS.2021.3061430","National Natural Science Foundation of China(grant numbers:61901090,61901092); Collaborative Innovation Center of Information Sensing and Understanding, Xidian University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361073","Iterative reweighted least squares (IRLS);linear sketching (LS);real aperture radar (RAR);super-resolution imaging","Azimuth;Radar imaging;Imaging;Image resolution;Superresolution;Antenna measurements;Radar","computational complexity;image reconstruction;image resolution;iterative methods;least squares approximations;matrix algebra;minimisation;radar imaging;radar resolution;synthetic aperture radar","imaging performance;smaller matrices;antenna measurement matrix;iteration;iterative reweighted algorithm;norm minimization problem;super-resolution problem;sparse prior information;super-resolution technology;azimuth resolution;antenna aperture;arbitrary imaging geometry;RAR;Doppler beam sharpening;synthetic aperture radar;Doppler gradient;region imaging;linear sketching;iterative reweighted least squares;real aperture radar;fast sparse azimuth super-resolution imaging method","","6","","52","CCBY","23 Feb 2021","","","IEEE","IEEE Journals"
"Validating Enhanced Resolution of Microwave Sounder Imagery Through Fusion with Infrared Sensors| Data","I. Yanovsky; Y. Wen; A. Behrangi; M. Schreier; B. Lambrigtsen","Joint Institute for Regional Earth System Science and Engineering, University of California, Los Angeles, CA, USA; NOAA/National Severe Storms Laboratory, Norman, OK, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA","2018 IEEE 15th Specialist Meeting on Microwave Radiometry and Remote Sensing of the Environment (MicroRad)","13 Aug 2018","2018","","","1","5","In this paper, we describe and validate a data fusion methodology and apply it to enhance the resolution of a microwave image using the data from a collocated infrared/visible sensor. Such an approach takes advantage of the spatial resolution of the infrared instrument and the sensing accuracy of the microwave instrument. We test our method using a precipitation scene captured with the Advanced Microwave Sounding Unit (AMSU-B) microwave instrument and the Advanced Very High Resolution Radiometer (AVHRR) infrared instrument and compare the results to simultaneous radar observations. We show that the data fusion product is better than the original AMSU-Band AVHRR observations across all statistical indicators.","","978-1-5386-5015-8","10.1109/MICRORAD.2018.8430703","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8430703","Data fusion;precipitation;remote sensing;sparse optimization;super-resolution","Microwave theory and techniques;Microwave imaging;Data integration;Spatial resolution;Mathematical model;Rain","geophysical equipment;geophysical image processing;microwave imaging;radiometers;remote sensing;remote sensing by radar;sensor fusion","microwave sounder imagery;infrared sensors;data fusion methodology;microwave image;collocated infrared/visible sensor;spatial resolution;sensing accuracy;Advanced Microwave Sounding Unit microwave instrument;Advanced Very High Resolution Radiometer infrared instrument;data fusion product;original AMSU-Band AVHRR observations","","","","18","IEEE","13 Aug 2018","","","IEEE","IEEE Conferences"
"A Spectral Grouping and Attention-Driven Residual Dense Network for Hyperspectral Image Super-Resolution","D. Liu; J. Li; Q. Yuan","School of Geodesy and Geomatics, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","27 Aug 2021","2021","59","9","7711","7725","Although unprecedented success has been achieved in convolutional neural network (CNN)-based super-resolution (SR) for natural images, hyperspectral image (HSI) SR without auxiliary high-resolution images remains a challenging task due to the high spectral dimensionality, where learning effective spatial and spectral representations is of great importance. In this article, we introduce a novel CNN-based HSI SR method, termed spectral grouping and attention-driven residual dense network (SGARDN) to facilitate the modeling of all spectral bands and focus on the exploration of spatial-spectral features. Considering the block characteristic of HSI, we employ group convolutions in and between groups composed of highly similar spectral bands at early stages to extract informative spatial features and avoid spectral disorder caused by normal convolution. To exploit spectral prior, a new spectral attention mechanism constructed by covariance statistics of features is designed to adaptively recalibrate features. We adapt the spectral attention for group convolutions to rescale grouping features with holistic spectral information. These two sequential operations called spectral grouping and integration module aim to extract effective shallow spatial-spectral features that are reused in the following layers. On the other hand, the residual dense block can better deal with spatial-spectral features by experimental comparison and hence is combined with the spectral attention to form a new basic building block for powerful feature expression and spectral correlation learning. The experimental results on synthesized and real-scenario HSIs demonstrate the feasibility and superiority of the proposed method over other state-of-the-art methods.","1558-0644","","10.1109/TGRS.2021.3049875","National Natural Science Foundation of China(grant numbers:41922008,61971319,62071341); Hubei Science Foundation for Distinguished Young Scholars(grant numbers:2020CFA051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9329109","Convolutional neural network (CNN);group convolution;hyperspectral image (HSI);spectral attention mechanism;super-resolution (SR)","Feature extraction;Correlation;Image reconstruction;Spatial resolution;Superresolution;Hyperspectral imaging;Convolution","feature extraction;geophysical image processing;hyperspectral imaging;image classification;image representation;image resolution;learning (artificial intelligence);neural nets","grouping features;holistic spectral information;effective shallow spatial-spectral features;residual dense block;spatial-spectral features;powerful feature expression;spectral correlation learning;hyperspectral image super-resolution;convolutional neural network-based super-resolution;natural images;hyperspectral image SR;high-resolution images;high spectral dimensionality;learning effective spatial representations;spectral representations;novel CNN-based HSI SR method;termed spectral grouping;attention-driven residual dense network;group convolutions;highly similar spectral bands;informative spatial features;spectral disorder;normal convolution;spectral attention mechanism","","33","","52","IEEE","20 Jan 2021","","","IEEE","IEEE Journals"
"An Explicit and Scene-Adapted Definition of Convex Self-Similarity Prior With Application to Unsupervised Sentinel-2 Super-Resolution","C. -H. Lin; J. M. Bioucas-Dias","Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Instituto de Telecomunicacoes, Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal","IEEE Transactions on Geoscience and Remote Sensing","22 Apr 2020","2020","58","5","3352","3365","Sentinel-2 satellite, launched by the European Space Agency, plays a critical role in various Earth observation missions. However, the spatial resolutions of Sentinel-2 images are different across its spectral bands, including four bands with a resolution of 10 m, six bands with a resolution of 20 m, and three bands with a resolution of 60 m. To facilitate the effectiveness of analyzing these images, super-resolving of the low-/medium-resolution bands to a higher resolution is desired. As in any image restoration inverse problems, we exploit image self-similarity, a commonly observed property in natural images, which underlies the state-of-the-art techniques, e.g., in image denoising. However, the design of self-similarity priors in nondiagonal inverse problems is challenging; often, a denoiser based on self-similarity is plugged into the iterations of an algorithm, without a guarantee of convergence in general. In this article, for the first time, we introduce a convex and scene-adapted regularizer built explicitly on a self-similarity graph directly learned from the Sentinel-2 images. We then develop a fast algorithm, termed Sentinel-2 super-resolution via scene-adapted self-similarity (SSSS). We experimentally show the superiority of SSSS over four commonly observed scenes, indicating the potential usage of our convex self-similarity regularization in other imaging inverse problems.","1558-0644","","10.1109/TGRS.2019.2953808","Fundação para a Ciência e a Tecnologia (FCT)-Portugal, Ministry of Education and Science (MEC); The European Regional Development Fund (FEDER) PT2020 Partnership Agreement(grant numbers:UID/EEA/50008/2019); Young Scholar Fellowship Program (Einstein Program) of Ministry of Science and Technology (MOST), Taiwan(grant numbers:MOST108-2636-E-006-012); Higher Education Sprout Project of Ministry of Education (MOE) to the Headquarters of University Advancement at National Cheng Kung University (NCKU); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931230","Convex optimization;scene-adapted self-similarity;self-similarity;Sentinel-2 satellite;super-resolution","Spatial resolution;Inverse problems;Imaging;Convex functions;Europe","convex programming;geophysical image processing;graph theory;image denoising;image resolution;image restoration;inverse problems;iterative methods","Sentinel-2 super-resolution via scene-adapted self-similarity;nondiagonal inverse problems;image denoising;image self-similarity;image restoration inverse problems;Sentinel-2 images;spatial resolutions;Earth observation missions;European Space Agency;Sentinel-2 satellite;unsupervised Sentinel-2 super-resolution;imaging inverse problems;convex self-similarity regularization","","30","","55","IEEE","11 Dec 2019","","","IEEE","IEEE Journals"
"SAR Parametric Super-Resolution Image Reconstruction Methods Based on ADMM and Deep Neural Network","Y. Wei; Y. Li; Z. Ding; Y. Wang; T. Zeng; T. Long","Beijing Key Laboratory of Embedded Real-time Information Processing Technology, Beijing, China; Beijing Key Laboratory of Embedded Real-time Information Processing Technology, Beijing, China; Beijing Institute of Technology Chongqing Innovation Center, Chongqing, China; Beijing Key Laboratory of Embedded Real-time Information Processing Technology, Beijing, China; Beijing Institute of Technology Chongqing Innovation Center, Chongqing, China; Beijing Key Laboratory of Embedded Real-time Information Processing Technology, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","23 Nov 2021","2021","59","12","10197","10212","The compressed sensing (CS)-based synthetic aperture radar (SAR) imaging methods have emerged as the standard approach to obtain super-resolution (SR) SAR images and achieve extraordinary performances. However, they face three challenges. First, this kind of method is mainly based on the point scattering model and not suitable for characterizing the line-segment-scattering and surface-scattering features of distributed targets. Second, the hyperparameters in these methods are hard to tune to optimal values. Third, due to a large amount of calculation, these methods are difficult to apply in practice. In this article, to solve these problems, we introduce the line-segment-scatterers (LSSs) and rectangular-plate-scatterers (RPSs) in SAR echo model to develop the SAR hybrid echo model and propose two SAR parametric SR image reconstruction methods based on solving a CS problem, where three penalties are utilized to exploit the sparsity of the point scatterers, LSSs, and RPSs, respectively. At the core of the first method is a direct solver called multicomponent alternating direction method of multipliers (MC-ADMM) solver that solves the CS problem quickly and iteratively based on closed derivative expressions. In contrast, the second method maps the MC-ADMM solver into a deep unfolded neural network, i.e., the parametric SR imaging network (PSRI-Net), which is faster, and the parameters can be automatically set to the optimum. Since all the parameters of the MC-ADMM solver are learned discriminatively through end-to-end training in PSRI-Net. Extensive simulation and practical experiments are carried out to demonstrate the effectiveness of the proposed methods.","1558-0644","","10.1109/TGRS.2021.3052793","National Science Fund for Distinguished Yong Scholars(grant numbers:61625103); Key Program of National Natural Science Foundation of China(grant numbers:11833001,61931002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340592","Deep neural network (DNN);line-segment-scatterer (LSS);multicomponent alternating direction method of multipliers (MC-ADMM);parametric super-resolution (SR) imaging network (PSRI-Net);rectangular-plate-scatterer (RPS);SR image reconstruction;synthetic aperture radar (SAR)","Synthetic aperture radar;Radar polarimetry;Imaging;Scattering;Radar imaging;Image reconstruction;Radar","image reconstruction;image resolution;iterative methods;radar imaging;synthetic aperture radar","super-resolution SAR images;point scattering model;line-segment-scattering;surface-scattering features;line-segment-scatterers;rectangular-plate-scatterers;SAR hybrid echo model;SAR parametric SR image reconstruction methods;CS problem;point scatterers;multicomponent alternating direction method;method maps;MC-ADMM solver;deep unfolded neural network;parametric SR imaging network;SAR parametric super-resolution image reconstruction methods;deep neural network;compressed sensing-based synthetic aperture radar imaging methods","","15","","51","IEEE","29 Jan 2021","","","IEEE","IEEE Journals"
"Structure–Color Preserving Network for Hyperspectral Image Super-Resolution","B. Pan; Q. Qu; X. Xu; Z. Shi","Science and Technology on Special System Simulation Laboratory, Beijing Simulation Center, Beijing, China; School of Statistics and Data Science and the Key Laboratory of Pure Mathematics and Combinatorics of Ministry of Education, Nankai University, Tianjin, China; College of Computer Science, Nankai University, Tianjin, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","1 Mar 2022","2022","60","","1","12","Fusion-based hyperspectral super-resolution (HSR) algorithms usually utilize a low-resolution hyperspectral image (LR-HSI) and a high-resolution multispectral image (MSI) to generate a high-resolution hyperspectral image (HR-HSI), which have attracted increasing attention in recent years. However, how to deal with the abundant spectral information of hyperspectral images and complex structure characteristics of MSIs has always been the focus and difficulty of fusion-based HSR. In this article, we propose a new structure–color preserving network (SCPNet) for HSR, which is developed under the basis of the joint attention mechanism. The SCPNet mainly includes three modules: structure-preserving module (SPM), color-preserving module (CPM), and cross-fusion module. The SPM is constructed based on the spatial attention, which aims to capture and enhance the significant structure information from the high-resolution MSI. Meanwhile, the CPM is constructed based on the channel attention, where the spectral characteristics in the LR-HSI are preserved during the reconstruction process. Finally, we propose a cross attention-based cross-fusion strategy to integrate the features from the two branches and reconstruct the final HR-HSI. The major contribution of SCPNet is that the structure and color information is described and preserved via the joint attention mechanism. Experimental results indicate that the proposed SCPNet has presented advantages on three benchmark datasets when compared with some state-of-the-art HSR methods.","1558-0644","","10.1109/TGRS.2021.3135028","National Key Research and Development Program of China(grant numbers:2019YFC1510905); National Natural Science Foundation of China(grant numbers:62001251,62001252); China Postdoctoral Science Foundation(grant numbers:2020M670631); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9648196","Attention mechanism;hyperspectral super-resolution (HSR);structure–color preserving","Hyperspectral imaging;Spatial resolution;Feature extraction;Image reconstruction;Image color analysis;Tensors;Correlation","geophysical image processing;hyperspectral imaging;image colour analysis;image fusion;image reconstruction;image resolution;sensor fusion","structure-color preserving network;hyperspectral image super-resolution;super-resolution algorithms;low-resolution hyperspectral image;high-resolution multispectral image;high-resolution hyperspectral image;abundant spectral information;hyperspectral images;fusion-based HSR;SCPNet;joint attention mechanism;SPM;color-preserving module;CPM;cross-fusion module;spatial attention;significant structure information;high-resolution MSI;channel attention;spectral characteristics;LR-HSI;cross attention-based cross-fusion strategy;final HR-HSI;color information;state-of-the-art HSR methods","","3","","55","IEEE","13 Dec 2021","","","IEEE","IEEE Journals"
"A Novel Fast Approach for SAR Tomography: Two-Step Iterative Shrinkage/Thresholding","L. Wei; T. Balz; L. Zhang; M. Liao","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, and the Collaborative Innovation Center for Geospatial Technology, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, and the Collaborative Innovation Center for Geospatial Technology, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, and the Collaborative Innovation Center for Geospatial Technology, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, and the Collaborative Innovation Center for Geospatial Technology, Wuhan University, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","19 May 2017","2015","12","6","1377","1381","As an advanced technique, synthetic aperture radar (SAR) tomography makes it possible to overcome the layover problem induced by the intrinsic side-looking geometry of SAR sensors. However, traditional nonparametric spectral estimators, e.g., truncated singular value decomposition, are limited by their poor elevation resolution. On the other hand, the compressive-sensing-based approaches using the basis-pursuit strategy to find an L1-norm minimization solution for SAR tomography (TomoSAR) are extremely time consuming. Therefore, a fast and robust tomographic algorithm with super-resolution capability is needed. In this letter, we propose a new approach for TomoSAR based on two-step iterative shrinkage/thresholding (TWIST). TWIST uses a two-step strategy to speed up the L1-norm minimization procedure and can achieve an exceptionally fast convergence speed for TomoSAR. Experimental studies with simulated signals and a spotlight-mode TerraSAR-X data set were carried out to demonstrate the merits of the proposed TWIST approach in terms of robustness, fast convergence speed, and super-resolution capability.","1558-0571","","10.1109/LGRS.2015.2402124","National Natural Science Foundation of China(grant numbers:61331016,41174120,41271457,41021061); Research Fund for the Doctoral Program of Higher Education of China(grant numbers:20110141110057); Fundamental Research Funds for the Central Universities(grant numbers:201161902020006); Shanghai Academy of Spaceflight Technology Innovation Fund(grant numbers:SAST201321); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7052307","Basis pursuit (BP);compressive sensing (CS);L1-norm minimization;synthetic aperture radar (SAR) tomography;truncated singular value decomposition (TSVD);two-step iterative shrinkage/thresholding (TWIST);Basis pursuit (BP);compressive sensing (CS);L1-norm minimization;synthetic aperture radar (SAR) tomography;truncated singular value decomposition (TSVD);two-step iterative shrinkage/thresholding (TWIST)","Synthetic aperture radar;Tomography;Image resolution;Signal resolution;Minimization;Remote sensing;Signal to noise ratio","iterative methods;minimisation;radar resolution;synthetic aperture radar","SAR tomography;two-step iterative shrinkage-thresholding;synthetic aperture radar tomography;intrinsic side-looking geometry;SAR sensor;nonparametric spectral estimation;truncated singular value decomposition;compressive-sensing-based approach;basis-pursuit strategy;L1-norm minimization solution;TomoSAR;super-resolution capability;spotlight-mode TerraSAR-X data set;TWIST approach","","28","","18","IEEE","2 Mar 2015","","","IEEE","IEEE Journals"
"Interactformer: Interactive Transformer and CNN for Hyperspectral Image Super-Resolution","Y. Liu; J. Hu; X. Kang; J. Luo; S. Fan","School of Electrical and Information Engineering, Changsha University of Science and Technology, Changsha, China; School of Electrical and Information Engineering, Changsha University of Science and Technology, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Automation, Wuhan University of Technology, Wuhan, China; School of Electrical and Information Engineering, Changsha University of Science and Technology, Changsha, China","IEEE Transactions on Geoscience and Remote Sensing","27 Jun 2022","2022","60","","1","15","Due to rich spectral information, hyperspectral images (HSIs) have been widely used in various fields. However, limited by imaging systems, the low spatial resolution of HSIs has become an important problem. In this article, for enhancing the spatial resolution, Interactformer is proposed to interact with global and local features extracted by transformer and 3-D convolutional neural network (CNN) branches. Within the transformer branch, a separable self-attention module with linear complexity is designed to solve the problem that traditional self-attention mechanisms suffer from large memory costs due to quadratic complexity. In the 3-D CNN branch, the spectral attention module and 3-D convolution are applied jointly to better protect the spectral correlation among spectral bands and facilitate local feature extraction of HSIs. The interactive attention unit between the two parallel branches is designed to interact with local and global feature information adaptively. Compared with state-of-the-art super-resolution (SR) methods, the proposed method reconstructs better HSI in simulated SR experiments, real SR experiments, and classification experiments, which proves that Interactformer can effectively improve the spatial resolution while preserving the spectral information.","1558-0644","","10.1109/TGRS.2022.3183468","Natural Science Foundation of Hunan Province, China(grant numbers:2021JJ40609,2021JJ40610); National Natural Science Foundation of China(grant numbers:61601061); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796466","Convolutional neural network (CNN);hyperspectral image (HSI) super-resolution (SR);interactive attention unit (IAU);transformer","Feature extraction;Transformers;Three-dimensional displays;Superresolution;Convolutional neural networks;Correlation;Spatial resolution","feature extraction;geophysical image processing;hyperspectral imaging;image classification;image reconstruction;image representation;image resolution;neural nets","Interactformer;interactive transformer;CNN;hyperspectral image super-resolution;rich spectral information;hyperspectral images;HSIs;imaging systems;low spatial resolution;global features;local features;transformer branch;separable self-attention module;linear complexity;traditional self-attention mechanisms;quadratic complexity;spectral attention module;spectral correlation;spectral bands;local feature extraction;interactive attention unit;parallel branches;local feature information;global feature information;state-of-the-art super-resolution methods","","4","","54","IEEE","15 Jun 2022","","","IEEE","IEEE Journals"
"Super-Resolution Optimal Basic Wavelet Transform and Its Application in Thin-Bed Thickness Characterization","Y. Tian; J. Gao; D. Wang; Z. Li","Department of Geoscience and Petroleum, Norwegian University of Science and Technology, Trondheim, Norway; School of Information and Communications Engineering and the National Engineering Research Center of Offshore Oil and Gas Exploration, Xi’an Jiaotong University, Xi’an, China; National Engineering Laboratory for Exploration and Development of Low-Permeability Oil and Gas Fields, Xi’an, China; School of Information and Communications Engineering and the National Engineering Research Center of Offshore Oil and Gas Exploration, Xi’an Jiaotong University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","30 Aug 2022","2022","60","","1","12","Continuous wavelet transform (CWT) is often used to extract the peak frequency attribute for characterizing the thin-bed thickness. Good joint time–frequency (TF) resolution is beneficial for the extraction of peak frequency. However, due to Heisenberg’s uncertain principle, the time and frequency resolution of CWT cannot be obtained simultaneously. In this article, combining the adaptive superlet transform and the optimal basic wavelet (OBW), a super-resolution OBW transform (SROBWT) is proposed to obtain the best joint TF resolution. The OBW matching the seismic wavelet is constructed as a basic wavelet of the adaptive superlet transform. Here, taking the best joint TF resolution of the seismic wavelet as the target, a parameter selection method is proposed for the adaptive superlet transform. Furthermore, based on the proposed SROBWT and wedge model, a workflow is proposed to characterize the thin-bed thickness. The synthetic and field seismic data are employed to demonstrate the validity of the proposed methods. All the corresponding results show that the SROBWT has a better joint TF resolution than the conventional methods and the proposed workflow can correctly characterize the spatial variation of the thin-bed thickness, which is beneficial for further sediment sources analysis and reservoir prediction.","1558-0644","","10.1109/TGRS.2022.3199450","National Key Research and Development Program of China(grant numbers:2020YFA0713403,2020YFA0713400); Natural Science Basic Research Program of Shaanxi(grant numbers:2022JQ-230); China Postdoctoral Science Foundation(grant numbers:2021M692520); China Scholarship Council (CSC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9858173","Adaptive superlet;super-resolution optimal basic wavelet transform (SROBWT);thin-bed thickness characterization","Transforms;Continuous wavelet transforms;Time-frequency analysis;Superresolution;Reservoirs;Uncertainty;Oils","geophysical signal processing;geophysical techniques;sediments;seismology;time-frequency analysis;wavelet transforms","thin-bed thickness characterization;continuous wavelet;CWT;peak frequency attribute;good joint time-frequency;frequency resolution;adaptive superlet;super-resolution OBW;SROBWT;joint TF resolution;seismic wavelet;super-resolution optimal basic wavelet transform","","","","41","IEEE","17 Aug 2022","","","IEEE","IEEE Journals"
"Endmember-Assisted Camera Response Function Learning, Toward Improving Hyperspectral Image Super-Resolution Performance","J. Zhao; Y. Qu; S. Ninomiya; W. Guo","Laboratory of Field Phenomics, Graduate School of Agriculture and Life Sciences, The University of Tokyo, Tokyo, Japan; Department of Electrical Engineering and Computer Science, Advanced Imaging and Collaborative Information Processing Group, The University of Tennessee, Knoxville, TN, USA; Plant Phenomics Research Center, Nanjing Agricultural University, Nanjing, China; Laboratory of Field Phenomics, Graduate School of Agriculture and Life Sciences, The University of Tokyo, Tokyo, Japan","IEEE Transactions on Geoscience and Remote Sensing","22 Jun 2022","2022","60","","1","14","The camera response function (CRF) that projects hyperspectral radiance to the corresponding RGB images is important for most hyperspectral image super-resolution (HSI-SR) models. In contrast to most studies that focus on improving HSI-SR performance through new architectures, we aim to prevent the model performance drop by learning the CRF of any given HSIs and RGB image from the same scene in an unsupervised manner, independent of the HSI-SR network. Accordingly, we first decompose the given RGB image into endmembers and an abundance map using the Dirichlet autoencoder architecture. Thereafter, a linear CRF learning network is optimized to project the reference HSIs to the RGB image that can be similarly decomposed like the given RGB, assuming that objects in both images share the same endmembers and abundance map. The quality of the RGB images generated from the learned CRFs is compared with that of the corresponding ground-truth images based on the true CRFs of two consumer-level cameras Nikon 700D and Canon 500D. We demonstrate that the effectively learned CRFs can prevent significant performance drop in three popular HSI-SR models on RGB images from different categories of standard datasets of CAVE, ICVL, Chikusei, Cuprite, Salinas, and KSC. The successfully learned CRF using the method proposed in this study would largely promote a wider implementation of HSI-SR models since tremendous performance drop can be prevented practically.","1558-0644","","10.1109/TGRS.2022.3182425","Japan Science and Technology Agency (JST) AIP Acceleration Research “Studies of CPS platform to raise big-datadriven AI agriculture”; Strategic International Collaborative Research Program (SICORP)(grant numbers:JPMJSC16H2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794687","Abundance map;camera response function (CRF);endmember;hyperspectral image (HSI);super-resolution;unsupervised deep learning","Cameras;Hyperspectral imaging;Image reconstruction;Spatial resolution;Imaging;Superresolution;Image color analysis","cameras;geophysical image processing;hyperspectral imaging;image coding;image colour analysis;image resolution;image sensors;unsupervised learning","Dirichlet autoencoder architecture;CAVE datasets;Chikusei datasets;Cuprite datasets;Salinas datasets;KSC datasets;ICVL datasets;consumer-level cameras;Nikon 700D;Canon 500D;HSI-SR network models;thyperspectral image super-resolution performance;hyperspectral image super-resolution models;RGB imaging;endmember-assisted camera response function learning;CRF learning;ground-truth imaging;linear CRF learning network","","","","71","CCBY","13 Jun 2022","","","IEEE","IEEE Journals"
"Balanced Tikhonov and Total Variation Deconvolution Approach for Radar Forward-Looking Super-Resolution Imaging","W. Huo; X. Tuo; Y. Zhang; Y. Zhang; Y. Huang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Geoscience and Remote Sensing Letters","16 Dec 2021","2022","19","","1","5","In radar forward-looking super-resolution imaging, improving the azimuth resolution while acquiring the contour information of the target has significant research value. In this letter, an approach based on the balanced Tikhonov and total variation (TV) deconvolution is proposed for radar forward-looking super-resolution imaging. We combine the Tikhonov regularization and TV regularization to construct the objective function and resolve the respective cost function using the alternating direction method of multipliers (ADMM). In each iteration, the gradient function of the target scattering coefficient is used as the adaptive weighted parameter to control automatically the weighting between the penalty terms from TV and the Tikhonov regularization. For the target with a sharper outline, the proportion of TV regularization penalty terms is increased; for the target with a smoother outline, the proportion of penalty term from the Tikhonov regularization is enhanced. The simulation and experimental results are considered to show the effectiveness of the proposed method. Compared with traditional super-resolution imaging methods, the proposed approach has superior outline retention capacity.","1558-0571","","10.1109/LGRS.2021.3072389","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9411929","Outline;super-resolution imaging;Tikhonov regularization;total variation (TV) regularization","Radar imaging;TV;Imaging;Azimuth;Radar;Superresolution;Convolution","deconvolution;gradient methods;image resolution;iterative methods;radar imaging","gradient function;target scattering coefficient;Tikhonov regularization;TV regularization penalty terms;penalty term;super-resolution imaging;total variation deconvolution;radar forward-looking super-resolution imaging;azimuth resolution;balanced Tikhonov;alternating direction method of multipliers;ADMM","","5","","18","IEEE","23 Apr 2021","","","IEEE","IEEE Journals"
"GAN-Based Multi-level Mapping Network for Satellite Imagery Super-Resolution","K. Jiang; Z. Wang; P. Yi; J. Jiang; G. Wang; Z. Han; T. Lu","National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China","2019 IEEE International Conference on Multimedia and Expo (ICME)","5 Aug 2019","2019","","","526","531","Although many deep-learning-based image super-resolution (SR) methods have been proposed, most of them assume that all hierarchical features share the unified mapping equations. They ignore the differences between mapping equations at different feature levels, and create an average effect of mapping prediction, thus poorly building the mapping relations between low resolution (LR) and high resolution (HR) spaces. In this paper, we propose a multi-level mapping framework along with the adversarial learning strategy, namely MMGAN, for satellite imageries SR reconstruction. We also construct a feature extraction and tuning block (FETB) for fine feature expression. In particular, a novel two-dimension dense unit (DU) and a mapping attention unit (MAU) are constructed for building multi-level mappings in different stages. With our strategies, an HR image is reconstructed directly from the input image using multi-level mappings. Extensive experiments on Kaggle Open Source Dataset and Jilin-1 video satellite images exhibit superior reconstruction performance when compared with the state-of-the-art SR approaches.","1945-788X","978-1-5386-9552-4","10.1109/ICME.2019.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784713","Remote sensing imagery, super resolution, multi-level mapping, attention unit, adversarial learning","Feature extraction;Image reconstruction;Satellites;Image resolution;Convolution;Mathematical model;Training","feature extraction;geophysical image processing;image reconstruction;image representation;image resolution;learning (artificial intelligence);remote sensing","GAN-based multilevel mapping network;satellite imagery super-resolution;deep-learning-based image super-resolution methods;hierarchical features;unified mapping equations;mapping prediction;high resolution spaces;adversarial learning strategy;satellite imageries SR reconstruction;mapping attention unit;Jilin-1 video satellite images;HR image reconstruction;SR approaches;low resolution spaces;Kaggle Open Source dataset;feature extraction and tuning block","","4","","23","IEEE","5 Aug 2019","","","IEEE","IEEE Conferences"
"Partially constrained adaptive beamforming for super-resolution at Low SNR","E. Hornberger; S. D. Blunt; T. Higgins","Radar Systems & Remote Sensing Lab (RSL), University of Kansas, Lawrence, KS, USA; Radar Systems & Remote Sensing Lab (RSL), University of Kansas, Lawrence, KS, USA; Radar Division, US Naval Research Laboratory, Washington, DC, USA","2015 IEEE 6th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)","21 Jan 2016","2015","","","129","132","The reiterative super-resolution (RISR) algorithm was previously developed to enable adaptive beamforming with as few as one time snapshot, is robust to temporally correlated signals, and accounts for array calibration errors. Here a gain-constrained version (denoted GC-RISR) is derived followed by a partially-constrained version (PC-RISR). It is shown that an interesting trait of the latter is spatial super-resolution at SNR values lower than is typical for adaptive beamforming techniques as a trade-off for requiring more iterations to converge. The PCRISR formulation is controlled by a selectable parameter that serves a role similar to that of an adaptive step-size which balances between convergence speed and accuracy.","","978-1-4799-1963-5","10.1109/CAMSAP.2015.7383753","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7383753","","Signal to noise ratio;Signal resolution;Arrays;Gain;Spatial resolution;Calibration;Convergence","array signal processing;convergence","partially constrained adaptive beamforming;super-resolution;low SNR;reiterative super-resolution algorithm;array calibration errors;gain-constrained version;GC-RISR;partially-constrained version;PC-RISR;selectable parameter;adaptive step-size;convergence speed","","6","","10","IEEE","21 Jan 2016","","","IEEE","IEEE Conferences"
"Spectral Super Resolution of Hyperspectral Images via Coupled Dictionary Learning","K. Fotiadou; G. Tsagkatakis; P. Tsakalides","Institute of Computer Science, Foundation for Research & Technology–Hellas, Heraklion, Greece; Institute of Computer Science, Foundation for Research & Technology–Hellas, Heraklion, Greece; Institute of Computer Science, Foundation for Research & Technology–Hellas, Heraklion, Greece","IEEE Transactions on Geoscience and Remote Sensing","23 Apr 2019","2019","57","5","2777","2797","High-spectral resolution imaging systems play a critical role in the identification and characterization of objects in a scene of interest. Unfortunately, multiple factors impair spectral resolution, as in the case of modern snapshot spectral imagers that associate each hyperpixel with a specific spectral band. In this paper, we introduce a novel postacquisition computational technique aiming to enhance the spectral dimensionality of imaging systems by exploiting the mathematical frameworks of sparse representations and dictionary learning. We propose a coupled dictionary learning model which considers joint feature spaces, composed of low- and high-spectral resolution hypercubes, in order to achieve spectral superresolution performance. We formulate our spectral coupled dictionary learning optimization problem within the context of the alternating direction method of multipliers, and we manage to update the involved quantities via closed-form expressions. In addition, we consider a realistic spectral subsampling scenario, taking into account the spectral response functions of different satellites. Moreover, we apply our spectral superresolution algorithm on real satellite data acquired by Landsat-8 and Sentinel-2 sensors. Finally, we have investigated the problem of hyperspectral image unmixing using the recovered high-spectral resolution data cube, and we are able to demonstrate that the proposed scheme provides significant value in hyperspectral image understanding techniques. Experimental results demonstrate the ability of the proposed approach to synthesize high-spectral-resolution 3-D hypercubes, achieving better performance compared to state-of-the-art resolution enhancement methods.","1558-0644","","10.1109/TGRS.2018.2877124","DEDALE project; 665044; European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8535036","Alternating direction method of multipliers;coupled dictionary learning;hyperspectral image enhancement;remote sensing image processing;sparse representations;spectral resolution enhancement;spectral super-resolution","Spatial resolution;Hyperspectral imaging;Machine learning;Instruments","geophysical image processing;geophysical techniques;hyperspectral imaging;image enhancement;image resolution;learning (artificial intelligence)","Sentinel-2 sensor;Landsat-8 sensor;spectral coupled dictionary learning optimization problem;mathematical frameworks;hyperspectral image understanding techniques;high-spectral resolution data cube;hyperspectral image unmixing;spectral superresolution algorithm;spectral response functions;realistic spectral subsampling scenario;spectral superresolution performance;high-spectral resolution hypercubes;coupled dictionary learning model;spectral dimensionality;novel postacquisition computational technique;specific spectral band;modern snapshot spectral imagers;high-spectral resolution imaging systems;spectral super resolution;state-of-the-art resolution enhancement methods;high-spectral-resolution 3-D hypercubes","","23","","70","IEEE","14 Nov 2018","","","IEEE","IEEE Journals"
"A Review of Spatial Enhancement of Hyperspectral Remote Sensing Imaging Techniques","N. Aburaed; M. Q. Alkhatib; S. Marshall; J. Zabalza; H. A. Ahmad",NA; NA; NA; NA; NA,"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2023","PP","99","1","27","Remote sensing technology has undeniable importance in various industrial applications, such as mineral exploration, plant detection, defect detection in aerospace and shipbuilding, and optical gas imaging, to name a few. Remote sensing technology has been continuously evolving, offering a range of image modalities that can facilitate the aforementioned applications. One such modality is Hyperspectral Imaging (HSI). Unlike Multispectral Images (MSI) and natural images, HSI consist of hundreds of bands. Despite their high spectral resolution, HSI suffer from low spatial resolution in comparison to their MSI counterpart, which hinders the utilization of their full potential. Therefore, spatial enhancement, or Super Resolution (SR), of HSI is a classical problem that has been gaining rapid attention over the past two decades. The literature is rich with various SR algorithms that enhance the spatial resolution of HSI while preserving their spectral fidelity. This paper reviews and discusses the most important algorithms relevant to this area of research between 2002-2022, along with the most frequently used datasets, HSI sensors, and quality metrics. Meta-analysis are drawn based on the aforementioned information, which is used as a foundation that summarizes the state of the field in a way that bridges the past and the present, identifies the current gap in it, and recommends possible future directions.","2151-1535","","10.1109/JSTARS.2023.3242048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10035973","Remote Sensing;Hyperspectral;Super Resolution;Single Image Super Resolution;Fusion;Convolutional Neural Networks;Spatial Enhancement;Literature Review","Spatial resolution;Sensors;Image resolution;Hyperspectral imaging;Satellites;Earth;Superresolution","","","","","","","CCBY","3 Feb 2023","","","IEEE","IEEE Early Access Articles"
"Tuning Parameter Selection for Sentinel-2 Sharpening Using Wald's Protocol","S. E. Armannsson; J. Sigurdsson; J. R. Sveinsson; M. O. Ulfarsson","Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2871","2874","In recent years numerous model-based methods for super-resolution of Sentinel-2 (S2) multispectral images have been suggested. Super-resolution aims to enhance the resolution of a captured image by upscaling and enhancing the details. The performance of model-based methods relies on carefully selecting regularizers and tuning parameters. This paper investigates whether using Wald's protocol, i.e., selecting tuning parameters at reduced-resolution, translates to a good performance at a full-scale. To investigate this, we use the recently proposed S2Sharp method and show that selecting its tuning parameters using Wald's protocol improves its performance.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553346","University of Iceland Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553346","Image fusion;image sharpening;multispectral (MS) multiresolution images;parameter selection;scale invariance;Sentinel-2 constellation;super-resolution","Measurement;Image quality;Protocols;Parameter estimation;Superresolution;Geoscience and remote sensing;Bayes methods","geophysical image processing;image enhancement;image resolution","Wald's protocol;Sentinel-2 multispectral images;super-resolution;captured image;reduced-resolution;S2Sharp;parameter selection tuning;Sentinel-2 sharpening;image upscaling;image enhancement;model-based methods","","1","","13","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Enhanced Hyperspectral Image Super-Resolution via RGB Fusion and TV-TV Minimization","M. Vella; B. Zhang; W. Chen; J. F. C. Mota","Institute of Sensors, Signals and Systems, Heriot-Watt University, Edinburgh EH14 4AS, UK; State Key Laboratory of Rail Traffic Control and Safety, Beijing Jiaotong University, China; State Key Laboratory of Rail Traffic Control and Safety, Beijing Jiaotong University, China; Institute of Sensors, Signals and Systems, Heriot-Watt University, Edinburgh EH14 4AS, UK","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","3837","3841","Hyperspectral (HS) images contain detailed spectral information that has proven crucial in applications like remote sensing, surveillance, and astronomy. However, because of hardware limitations of HS cameras, the captured images have low spatial resolution. To improve them, the low-resolution hyperspectral images are fused with conventional high-resolution RGB images via a technique known as fusion based HS image super-resolution. Currently, the best performance in this task is achieved by deep learning (DL) methods. Such methods, however, cannot guarantee that the input measurements are satisfied in the recovered image, since the learned parameters by the network are applied to every test image. Conversely, model-based algorithms can typically guarantee such measurement consistency. Inspired by these observations, we propose a framework that integrates learning and model based methods. Experimental results show that our method produces images of superior spatial and spectral resolution compared to the current leading methods, whether model-or DL-based.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506715","Deep learning;super-resolution;hyper-spectral imaging;optimization;total variation","Current measurement;Surveillance;Superresolution;Neural networks;Extraterrestrial measurements;Minimization;Cameras","geophysical image processing;hyperspectral imaging;image fusion;image resolution;remote sensing","current leading methods;enhanced hyperspectral image super-resolution;RGB fusion;TV-TV minimization;detailed spectral information;remote sensing;hardware limitations;HS cameras;captured images;low spatial resolution;low-resolution hyperspectral images;conventional high-resolution RGB images;fusion based HS image super-resolution;deep learning methods;recovered image;test image;model-based algorithms;model based methods;superior spatial resolution;spectral resolution","","2","","29","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Multi-Contrast Brain MRI Image Super-Resolution With Gradient-Guided Edge Enhancement","H. Zheng; K. Zeng; D. Guo; J. Ying; Y. Yang; X. Peng; F. Huang; Z. Chen; X. Qu","Key Laboratory of Intelligent Processing of Image and Graphics, School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, China; Fujian Provincial Key Laboratory of Plasma and Magnetic Resonance, College of Physical Science and Technology, Xiamen University, Xiamen, China; School of Computer and Information Engineering, Fujian Provincial University Key Laboratory of Internet of Things Application Technology, Xiamen University of Technology, Xiamen, China; Fujian Provincial Key Laboratory of Plasma and Magnetic Resonance, College of Physical Science and Technology, Xiamen University, Xiamen, China; Fujian Provincial Key Laboratory of Plasma and Magnetic Resonance, College of Physical Science and Technology, Xiamen University, Xiamen, China; Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, Shenzhen, China; Neusoft Medical System, Shanghai, China; Fujian Provincial Key Laboratory of Plasma and Magnetic Resonance, College of Physical Science and Technology, Xiamen University, Xiamen, China; Fujian Provincial Key Laboratory of Plasma and Magnetic Resonance, College of Physical Science and Technology, Xiamen University, Xiamen, China","IEEE Access","25 Oct 2018","2018","6","","57856","57867","In magnetic resonance imaging (MRI), the super-resolution technology has played a great role in improving image quality. The aim of this paper is to improve edges of brain MRI by incorporating the gradient information of another contrast high-resolution image. Multi-contrast images are assumed to possess the same gradient direction in a local pattern. We proposed to establish a relation model of gradient value between different contrast images to restore a high-resolution image from its input low-resolution version. The similarity of image patches is employed to estimate intensity parameters, leading a more accurate reconstructed image. Then, an iterative back-projection filter is applied to the reconstructed image to further increase the image quality. The new approach is verified on synthetic and real brain MRI images and achieves higher visual quality and higher objective quality criteria than the compared state-of-the-art super-resolution approaches. The gradient information of the multi-contrast MRI images is very useful. With a proper relation model, the proposed method enhances image edges in MRI image super-resolution. Improving the MRI image resolution from very low-resolution observations is challenging. We tackle this problem by first modeling the relation of gradient value in multi-contrast MRI and then performing fast supper-resolution methods. This relation model may be helpful for other MRI reconstruction problems.","2169-3536","","10.1109/ACCESS.2018.2873484","National Key R&D Program of China(grant numbers:2017YFC0108703); National Natural Science Foundation of China(grant numbers:61571380,61871341,61811530021,U1632274,61672335,61601389); Natural Science Foundation of Fujian Province(grant numbers:2018J06018,2016J05205); Fundamental Research Funds for the Central Universities(grant numbers:20720180056); Science and Technology Program of Xiamen(grant numbers:3502Z20183053); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478767","MRI;image reconstruction;super-resolution;multi-contrast images","Magnetic resonance imaging;Image resolution;Image edge detection;Interpolation;Brain modeling;Image reconstruction;Remote sensing","biomedical MRI;brain;image denoising;image enhancement;image reconstruction;image resolution;medical image processing","contrast images;multicontrast brain MRI image super-resolution;MRI reconstruction problems;low-resolution observations;MRI image resolution;image edges;multicontrast MRI images;compared state-of-the-art super-resolution approaches;higher objective quality criteria;higher visual quality;accurate reconstructed image;image patches;input low-resolution version;gradient value;relation model;gradient direction;multicontrast images;contrast high-resolution image;gradient information;image quality;super-resolution technology;magnetic resonance imaging;gradient-guided edge enhancement","","22","","41","OAPA","2 Oct 2018","","","IEEE","IEEE Journals"
"Nonlinear Multi-scale Super-resolution Using Deep Learning","K. Tran; A. Panahi; A. Adiga; W. Sakla; H. Krim","Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC; Computational Engineering Division, Lawrence Livermore National Laboratory, Livermore, CA; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3182","3186","We propose a deep learning architecture capable of performing up to 8× single image super-resolution. Our architecture incorporates an adversarial component from the super-resolution generative adversarial networks (SRGANs) and a multi-scale learning component from the multiple scale super-resolution network (MSSRNet), which only together can recover smaller structures inherent in satellite images. To further enhance our performance, we integrate progressive growing and training to our network. This, aided by feed forwarding connections in the network to move along and enrich information from previous inputs, produces super-resolved images at scaling factors of 2, 4, and 8. To ensure and enhance the stability of GANs, we employ Wasserstein GANs (WGANs) during training. Experimentally, we find that our architecture can recover small objects in satellite images during super-resolution whereas previous methods cannot.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682354","super-resolution;remote sensing data;GANs;dilated convolutions","Spatial resolution;Satellites;Training;Signal resolution;Convolution;Gallium nitride","geophysical image processing;image resolution;learning (artificial intelligence);neural nets","deep learning architecture;multiscale learning component;satellite images;single image superresolution;nonlinear multiscale superresolution;superresolution generative adversarial networks;multiple scale superresolution network;Wasserstein GANs","","2","","25","IEEE","17 Apr 2019","","","IEEE","IEEE Conferences"
"Fast Unsupervised Spatiotemporal Super-Resolution for Multispectral Satellite Imaging Using Plug-and-Play Machinery Strategy","C. -H. Lin; C. -Y. Sie; P. -Y. Lin; J. -T. Lin","Miin Wu School of Computing, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2568","2571","Acquiring high-spatial-resolution (HSR) images at high temporal sampling rate is not economical and even not achievable using contemporary multispectral satellite imaging hardware. An alternative is to fuse a set of HSR images acquired at low sampling rate, with another set of low-spatial-resolution images acquired at high sampling rate, and such fusion problem is referred to as spatiotemporal super-resolution (STSR). We mitigate the ill-posedness of the STSR problem by incorporating the image self-similarity prior (S2P), which is the key behind the design of several state-of-the-art imaging inverse problems. Unlike most super-resolution works in the computer vision area, our method does not rely on collecting big data. Instead, we propose a fully unsupervised STSR method by adopting the popular strategy in machine learning, known as plug-and-play optimization, and by carefully refining the required matrix computation/inversion. We term our method as STSRS2P, whose superiority and low computational complexity will be experimentally verified.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554710","Einstein Program (Young Scholar Fellowship Program) of Ministry of Science and Technology (MOST), Taiwan(grant numbers:MOST 109-2636-E-006-022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554710","Multispectral satellite;image fusion;spatiotemporal super-resolution;image self-similarity;plug-and-play","Computer vision;Satellites;Superresolution;Refining;Imaging;Big Data;Benchmark testing","","","","1","","14","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Hybrid Local and Nonlocal 3-D Attentive CNN for Hyperspectral Image Super-Resolution","J. Yang; L. Xiao; Y. -Q. Zhao; J. C. -W. Chan","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; Department of Electronics and Informatics, Vrije Universiteit Brussel, Brussels, Belgium","IEEE Geoscience and Remote Sensing Letters","23 Jun 2021","2021","18","7","1274","1278","A deep convolutional neural network (CNN) has shown its great potential in hyperspectral image (HSI) super-resolution (SR). Integrating CNN with attention mechanism is expected to boost the SR performance. However, how to learn attention along the spectral, spatial, and channel dimensions of HSI is still an open issue, and the current attention mechanism is not efficient in capturing long-range interdependency in HSI. In this letter, we first design a local 3-D attention module to learn the spectral-spatial-channel attention by exploiting local contextual information in HSI. Then, we propose a nonlocal 3-D attention module, in which the long-range interdependency in HSI can be exploited for attention learning. By jointly embedding the local and nonlocal attention in a residual 3-D CNN, a hybrid local and nonlocal 3-D attentive CNN can be built for HSI SR. The experimental results show that local and nonlocal attention formulation leads to competitive SR performance.","1558-0571","","10.1109/LGRS.2020.2997092","National Natural Science Foundation of China(grant numbers:61771391,61871226); Jiangsu Provincial Social Developing Project(grant numbers:BE 2018727); Fundamental Research Funds for the Central Universities(grant numbers:30920021134); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106364","Attention;convolutional neural network (CNN);hyperspectral;super-resolution (SR)","Feature extraction;Correlation;Hyperspectral imaging;Convolutional neural networks;Pairwise error probability","convolutional neural nets;geophysical image processing;hyperspectral imaging;image resolution;learning (artificial intelligence);remote sensing","3-D attentive CNN;hyperspectral image super-resolution;deep convolutional neural network;spectral dimensions;spatial dimensions;long-range interdependency;spectral-spatial-channel attention;local contextual information;attention learning;HSI SR;local attention formulation;nonlocal attention formulation;channel dimensions;hybrid local and nonlocal 3D attentive CNN;local 3-D attention module","","11","","20","IEEE","2 Jun 2020","","","IEEE","IEEE Journals"
"Monte-Carlo Siamese Policy on Actor for Satellite Image Super Resolution","L. Rout; S. Shah; S. M. Moorthi; D. Dhar","Signal and Image Processing Group, Indian Space Research Organisation; Space Applications Centre; Signal and Image Processing Group, Indian Space Research Organisation; Signal and Image Processing Group, Indian Space Research Organisation","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","757","767","In the past few years supervised and adversarial learning have been widely adopted in various complex computer vision tasks. It seems natural to wonder whether another branch of artificial intelligence, commonly known as Reinforcement Learning (RL) can benefit such complex vision tasks. In this study, we explore the plausible usage of RL in super resolution of remote sensing imagery. Guided by recent advances in super resolution, we propose a theoretical framework that leverages the benefits of supervised and reinforcement learning. We argue that a straightforward implementation of RL is not adequate to address ill-posed super resolution as the action variables are not fully known. To tackle this issue, we propose to parameterize action variables by matrices, and train our policy network using Monte-Carlo sampling. We study the implications of parametric action space in a model-free environment from theoretical and empirical perspective. Furthermore, we analyze the quantitative and qualitative results on both remote sensing and non-remote sensing datasets. Based on our experiments, we report considerable improvement over state-of-the-art methods by encapsulating supervised models in a reinforcement learning framework.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150726","","Image resolution;Remote sensing;Learning (artificial intelligence);Mathematical model;Task analysis;Machine learning;Feature extraction","computer vision;geophysical image processing;image resolution;learning (artificial intelligence);Monte Carlo methods;remote sensing","reinforcement learning framework;nonremote sensing datasets;parametric action space;Monte-Carlo sampling;policy network;remote sensing imagery;complex vision tasks;RL;adversarial learning;satellite image super resolution;Monte-Carlo Siamese policy","","3","","57","IEEE","28 Jul 2020","","","IEEE","IEEE Conferences"
"A truncated singular value decomposition method for angular super-resolution in scanning radar","Y. Huang; Y. Zha; J. Yang",School of Electronic Engineering University of Electronic Science and Technology of China; School of Electronic Engineering University of Electronic Science and Technology of China; School of Electronic Engineering University of Electronic Science and Technology of China,"2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","3560","3563","Angular super-resolution of scanning radar is an important problem in radar system. Some deconvolution methods are used to realize the angular super-resolution in scanning radar. However, the ill-posed nature of the deconvolution problem leads to the noise amplification in the angular super-resolution image. This phenomenon brings the difficulty in signal detection and tracking. In this paper, a deconvolution algorithm based on truncated singular value decomposition is proposed that achieves the angular super-resolution and noise suppression in scanning radar. To this end, we first convert the angular super-resolution task in scanning radar as an equivalent deconvolution problem. Then, the cause of noise amplification is analysed, which leads to the truncation singular value method for solving the deconvolution problem. Simulation results demonstrate that the proposed method is effective in achieving angular resolution with suppressing the noise amplification.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326590","Radar imaging;truncated singular value decomposition;deconvolution;convex optimization","Signal resolution;Deconvolution;Radar imaging;Radar antennas;Spatial resolution","deconvolution;interference suppression;radar imaging;radar resolution;singular value decomposition","angular super-resolution;scanning radar;deconvolution methods;noise amplification;truncated singular value decomposition;noise suppression","","4","","14","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"A Full-Resolution Training Framework for Sentinel-2 Image Fusion","M. Ciotola; M. Ragosta; G. Poggi; G. Scarpa","Dipartimento di Ingegneria Elettrica e delle Tecnologie dell'Informazione, Università Federico II, Napoli, (I); Dipartimento di Ingegneria Elettrica e delle Tecnologie dell'Informazione, Università Federico II, Napoli, (I); Dipartimento di Ingegneria Elettrica e delle Tecnologie dell'Informazione, Università Federico II, Napoli, (I); Dipartimento di Ingegneria Elettrica e delle Tecnologie dell'Informazione, Università Federico II, Napoli, (I)","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","1260","1263","This work presents a new unsupervised framework for training deep learning models for super-resolution of Sentinel-2 images by fusion of its 10-m and 20-m bands. The proposed scheme avoids the resolution downgrade process needed to generate training data in the supervised case. On the other hand, a proper loss that accounts for cycle-consistency between the network prediction and the input components to be fused is proposed. Despite its unsupervised nature, in our preliminary experiments the proposed scheme has shown promising results in comparison to the supervised approach. Besides, by construction of the proposed loss, the resulting trained network can be ascribed to the class of multi-resolution analysis methods.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553199","Super-resolution;data-fusion;convolutional neural network;machine learning;Sentinel-2","Training;Deep learning;Superresolution;Training data;Geoscience and remote sensing;Image fusion","geophysical image processing;image classification;image fusion;image resolution;learning (artificial intelligence);neural nets","full-resolution training framework;Sentinel-2 image fusion;unsupervised framework;deep learning models;super-resolution;Sentinel-2 images;resolution downgrade process;training data;supervised case;proper loss;cycle-consistency;network prediction;input components;unsupervised nature;supervised approach;resulting trained network;multiresolution analysis methods","","6","","20","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Improving the Spatial Resolution of Imaging Instruments Using Software","M. Mareboyana; J. L. Moigne; P. Dabney","Bowie State University, Bowie, MD; Software Engineering Division, NASA Goddard, Greenbelt, MD; NASA Goddard, Biospheric Sciences Lab, Greenbelt, MD","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","7990","7993","In order to overcome spatial resolution limitations associated with physical sensor limitations when using smallsats and cubesats, we utilize an image processing technology referred to as Super-Resolution (SR). In general, software approaches are increasingly considered in connection with smaller satellites for which size, mass and power constraints limit the sensor capabilities. Being able to perform hardware vs. software trades might enable more capabilities for a lower cost. This paper describes recent experiments conducted to optimize the spatial enhancement of acquired observations using multiple sub-pixel shifted low resolution image.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518234","super-resolution;radial basis functions","Spatial resolution;Image reconstruction;Earth;Artificial satellites;Remote sensing;Software","artificial satellites;image processing;image resolution;image sensors;optimisation","imaging instruments;super-resolution;satellites;hardware trades;optimization;multiple sub-pixel shifted low resolution image;spatial enhancement;software trades;sensor capabilities;power constraints;mass;software approaches;image processing technology;cubesats;smallsats;physical sensor limitations;spatial resolution limitations","","","","3","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Fusformer: A Transformer-Based Fusion Network for Hyperspectral Image Super-Resolution","J. -F. Hu; T. -Z. Huang; L. -J. Deng; H. -X. Dou; D. Hong; G. Vivone","School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Science, Xihua University, Chengdu, China; Key Laboratory of Computational Optical Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Institute of Methodologies for Environmental Analysis, National Research Council, Tito Scalo, Italy","IEEE Geoscience and Remote Sensing Letters","8 Aug 2022","2022","19","","1","5","Hyperspectral image super-resolution (HISR) is to fuse a low-resolution hyperspectral image (LR-HSI) and a high-resolution multispectral image (HR-MSI), aiming to obtain a high-resolution hyperspectral image (HR-HSI). Recently, various convolution neural network (CNN)-based techniques have been successfully applied to address the HISR problem. However, these methods generally only consider the relation of a local neighborhood by convolution kernels with a limited receptive field, thus ignoring the global relationship in a feature map. In this letter, we design a Transformer-based architecture (called Fusformer) for the HISR problem, which is the first attempt to apply the Transformer architecture to this task to the best of our knowledge. Because of the excellent ability of feature representations, especially by the self-attention (SA) in the Transformer, our approach can globally explore the intrinsic relationship within features. Considering the specific HISR problem, since the LR-HSI holds the primary spectral information, our method estimates the spatial residual between the upsampled low-resolution multispectral image (LR-MSI) and the desired HR-HSI, reducing the burden of training the whole data in a smaller mapping space. Various experiments show that our approach outperforms current state-of-the-art (SOTA) HISR methods. The code is available at https://github.com/J-FHu/Fusformer.","1558-0571","","10.1109/LGRS.2022.3194257","National Natural Science Foundation of China(grant numbers:12171072,61702083,61876203); Key Projects of Applied Basic Research in Sichuan Province(grant numbers:2020YJ0216); National Key Research and Development Program of China(grant numbers:2020YFA0714001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9841513","Hyperspectral image super-resolution (HISR);image fusion;remote sensing;Transformer","Transformers;Hyperspectral imaging;Task analysis;Computer architecture;Training;Superresolution;Feature extraction","geophysical image processing;hyperspectral imaging;image fusion;image representation;image resolution;neural nets","Transformer-based fusion network;hyperspectral image super-resolution;low-resolution hyperspectral image;high-resolution multispectral image;Transformer-based architecture;Transformer architecture;specific HISR problem;LR-HSI;low-resolution multispectral image;current state-of-the-art HISR methods","","2","","37","IEEE","27 Jul 2022","","","IEEE","IEEE Journals"
"Fast Marginalized Sparse Bayesian Learning for 3-D Interferometric ISAR Image Formation Via Super-Resolution ISAR Imaging","Y. Wu; S. Zhang; H. Kang; T. S. Yeo","Key Laboratory of Integrated Electronic System, Ministry of Education, Chengdu, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Key Laboratory of Integrated Electronic System, Ministry of Education, Chengdu, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","19 May 2017","2015","8","10","4942","4951","Compressed sensing (CS) has been successfully applied to inverse synthetic aperture radar (ISAR) imaging of moving targets. In existing CS-based ISAR imaging algorithms, Laplace distribution is widely adopted to enforce sparseness on signal recovery. However, this kind of CS method using Laplace prior encounters the problems of determining optimum regularization factor and heavy computation load. In this paper, a fast marginalized sparse Bayesian learning (MSBL) method is proposed for three-dimensional (3-D) interferometric super-resolution ISAR imaging. After deriving the target sparsity-driven imaging model, a fast MSBL approach is applied to obtain super-resolution ISAR image, and then a high-quality 3-D view of the target is achieved via the interferometry technique using an ISAR imagery pair. Experiments on simulated and real data are provided to validate the effectiveness of the proposed method.","2151-1535","","10.1109/JSTARS.2015.2455508","University of Electronic Science and Technology of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7182259","Compressed sensing (CS);interferometric inverse synthetic aperture radar (ISAR);marginalized sparse Bayesian learning (MSBL);super resolution;Compressed sensing (CS);interferometric inverse synthetic aperture radar (ISAR);marginalized sparse Bayesian learning (MSBL);super resolution","Compressed sensing;Bayes methods;Image resolution;Image reconstruction;Inverse synthetic aperture radar","geophysical techniques;synthetic aperture radar","fast marginalized sparse Bayesian learning;3D interferometric ISAR image formation;inverse synthetic aperture radar imaging;CS-based ISAR imaging algorithms;Laplace distribution;three-dimensional interferometric super- resolution ISAR imaging","","17","","36","IEEE","7 Aug 2015","","","IEEE","IEEE Journals"
"γ-Net: Superresolving SAR Tomographic Inversion via Deep Learning","K. Qian; Y. Wang; Y. Shi; X. X. Zhu","Data Science in Earth Observation, Technical University of Munich, Munich, Germany; Department of EO Data Science, German Aerospace Center, Remote Sensing Technology Institute, Weßling, Oberpfaffenhofen, Germany; Chair of Remote Sensing Technology, Technical University of Munich, Munich, Germany; Department of EO Data Science, German Aerospace Center, Remote Sensing Technology Institute, Weßling, Oberpfaffenhofen, Germany","IEEE Transactions on Geoscience and Remote Sensing","19 Apr 2022","2022","60","","1","16","Synthetic aperture radar tomography (TomoSAR) has been extensively employed in 3-D reconstruction in dense urban areas using high-resolution SAR acquisitions. Compressive sensing (CS)-based algorithms are generally considered as the state-of-the art in super-resolving TomoSAR, in particular in the single look case. This superior performance comes at the cost of extra computational burdens, because of the sparse reconstruction, which cannot be solved analytically, and we need to employ computationally expensive iterative solvers. In this article, we propose a novel deep learning-based super-resolving TomoSAR inversion approach,  $\boldsymbol {\gamma }$ -Net, to tackle this challenge.  $\boldsymbol {\gamma }$ -Net adopts advanced complex-valued learned iterative shrinkage thresholding algorithm (CV-LISTA) to mimic the iterative optimization step in sparse reconstruction. Simulations show the height estimate from a well-trained  $\boldsymbol {\gamma }$ -Net approaches the Cramér-Rao lower bound (CRLB) while improving the computational efficiency by one to two orders of magnitude comparing to the first-order CS-based methods. It also shows no degradation in the super-resolution power comparing to the state-of-the-art second-order TomoSAR solvers, which are much more computationally expensive than the first-order methods. Specifically,  $\boldsymbol {\gamma }$ -Net reaches more than 90% detection rate in moderate super-resolving cases at 25 measurements at 6 dB SNR. Moreover, simulation at limited baselines demonstrates that the proposed algorithm outperforms the second-order CS-based method by a fair margin. Test on real TanDEM-X data with just six interferograms also shows high-quality 3-D reconstruction with high-density detected double scatterers.","1558-0644","","10.1109/TGRS.2022.3164193","China Scholarship Council(grant numbers:201908080038); European Research Council (ERC), Acronym: So2Sat(grant numbers:ERC-2016-StG-714087); Helmholtz Association through the Framework of Helmholtz AI–Local Unit “Munich Unit at Aeronautics, Space and Transport (MASTr)”(grant numbers:ZT-I-PF-5-01); Helmholtz Excellent Professorship “Data Science in Earth Observation-Big Data Fusion for Urban Research”(grant numbers:W2-W3-100); German Federal Ministry of Education and Research (BMBF) in the framework of the International Future AI Laboratory through the “Artificial Intelligence for Earth Observation (AI4EO): Reasoning, Uncertainties, Ethics and Beyond”(grant numbers:01DD20001); German Federal Ministry of Economics and Technology in the framework of the “National Center of Excellence ML4Earth”(grant numbers:50EE2201C); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745947","Complex-valued learned iterative shrinkage thresholding algorithm (LISTA);compressive sensing (CS);synthetic aperture radar~(SAR) tomography (TomoSAR);super-resolution","Synthetic aperture radar;Superresolution;Deep learning;Neural networks;Reflectivity;Imaging;Image reconstruction","compressed sensing;deep learning (artificial intelligence);image reconstruction;iterative methods;optimisation;radar computing;radar imaging;synthetic aperture radar;tomography","moderate super-resolving cases;second-order CS-based method;SAR tomographic inversion;synthetic aperture radar tomography;dense urban areas;high-resolution SAR acquisitions;compressive sensing-based algorithms;single look case;extra computational burdens;sparse reconstruction;deep learning;shrinkage thresholding algorithm;iterative optimization step;γ-Net approaches;Cramér-Rao lower bound;computational efficiency;first-order CS-based methods;super-resolution power;first-order methods;second-order TomoSAR solvers;high-quality 3D reconstruction;superresolving SAR tomographic inversion;complex-valued learned iterative shrinkage thresholding algorithm;iterative optimization;TanDEM-X data;six interferograms;high-density detected double scatterers","","5","","44","CCBY","1 Apr 2022","","","IEEE","IEEE Journals"
"A CNN-Based Pansharpening Method with Perceptual Loss","S. Vitale","Dipartimento di Ingegneria, Università di Napoli Parthenope (I)","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3105","3108","Pansharpening is a classical data fusion task that is often necessary when dealing with data sensed through multiresolution acquisition systems. These systems, in fact, provide a single panchromatic band at full spatial resolution coupled with a multispectral lower resolution image of the same scene, which must be fused (pansharpened) to generate a full spatial-spectral resolution datacube. In the last few years, there has been a methodological shift in pansharpening towards the deep learning (DL) paradigm. Most DL solutions proposed thus far use self-supervised learning. Training is carried out on data at downgraded resolution, where ground truth data are also available. Then, the trained network is applied to perform pansharpening on native resolution data. As a consequence, such solutions show good results on low-resolution datasets, but less convincing results on full-resolution data, due to limited generalization ability. In this work, to address this problem, we enrich the training loss function with a perceptual term computed on full-resolution data, obtaining promising experimental results.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900390","Data fusion;deep learning;convolutional neural network;super-resolution","Spatial resolution;Training;Feature extraction;Data integration;Deep learning;Remote sensing","geophysical image processing;image fusion;image resolution;learning (artificial intelligence);remote sensing","deep learning paradigm;spatial-spectral resolution datacube;pansharpened;multispectral lower resolution image;spatial resolution;single panchromatic band;multiresolution acquisition systems;classical data fusion task;perceptual loss;CNN-based pansharpening;training loss function;full-resolution data;low-resolution datasets;native resolution data;ground truth data;downgraded resolution;self-supervised learning","","9","","20","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Multibranch Cnn-Based Pansharpening With Skip Connection","M. E. A. Larabi; M. S. Karoui; S. Chaib; K. Bakhti; M. I. Tchenar","Agence Spatial Algérienne,Centre des Techniques Spatiale, Arzew, Algérie; Agence Spatial Algérienne,Centre des Techniques Spatiale, Arzew, Algérie; School of computer science, Harbin Institute of Technology, China; Agence Spatial Algérienne,Centre des Techniques Spatiale, Arzew, Algérie; The State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China","2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium (M2GARSS)","2 Jun 2020","2020","","","137","140","Recent research on multispectral (MS) and panchromatic (PN) images fusion that known as pansharpening has progressed with the development of Convolutional Neural Networks (CNN). However, the states-of-the-arts methods are principally based on simple networks with shallow architectures that may limit their performance. Recently, residual learning (ResNet) exhibit improved performance in many application domains. At the same time, numerous upsampling methods were developed, from the classical interpolation to learning based methods. In this paper, ResNet is employed to make the full exploitation of the high nonlinearity of CNN. Moreover, an ensemble of upsampling methods were joined in the developed Multibranch Pansharpening Network (MPN) that prove good performance to reconstruct high-resolution MS images. The proposed approach is applied to QuickBird data, its efficiency is assessed with universally used performance criteria in spatial and spectral domains. Experimental results of the proposed approach show better spatial performance than classical methods and competitive spectral performance against the state-of-the-art approaches.","","978-1-7281-2190-1","10.1109/M2GARSS47143.2020.9105231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105231","CNN;Deep Learning;super-resolution;pansharpening;Transposed Convolution.","Training;Learning systems;Interpolation;Convolution;Pansharpening;Convolutional neural networks;Remote sensing","convolutional neural nets;geophysical image processing;image fusion;image reconstruction;image resolution;image sampling;interpolation;learning (artificial intelligence);remote sensing","skip connection;convolutional neural networks;shallow architectures;residual learning;ResNet;upsampling methods;interpolation;spatial domains;spectral domains;multibranch pansharpening network;multibranch CNN-based pansharpening;multispectral images fusion;panchromatic images fusion;high-resolution MS images;image reconstruction","","3","","22","IEEE","2 Jun 2020","","","IEEE","IEEE Conferences"
"Spectral Constrained Residual Attention Network for Hyperspectral Pansharpening","Z. Zhou; J. Feng; X. Wu; J. Shi; X. Zhang","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi'an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi'an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi'an, China; Northwestern Polytechnical University, School of Electronics and Information, Xi'an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi'an, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2386","2389","Deep learning methods have been widely used in the task of hyperspectral pansharpening. However, most of these methods regard the Panchromatic (PAN) image as a kind of auxiliary information, which is mainly used as spatial details to add on the hyperspectral image (HSI) after processing. Obviously, this kind of methods utilize the PAN image insufficiently, resulting in the imbalance of spatial preservation and spatial preservation. In this paper, a spectral constrained residual attention network (SCRAN) is proposed by using the PAN image as the foundation of the pansharpening task and concerning on the spectral and spatial learning. The proposed SCRAN method consists of three parts: a spectral feature extraction net, an attention spatial residual net and a spectral reconstruction net. A spectral constrained loss function is designed to enhance the spectral learning ability of SCRAN. Additionally, in SCRAN, a deep back-projection network (DBPN) is operated to upsample the HSI, and the histogram matching is applied to the PAN image to make it closer to the HSI in terms of spectral bands.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883551","National Natural Science Foundation of China(grant numbers:61871306,61836009,62172600,62077038); Natural Science Basic Research Program of Shaanxi(grant numbers:2022JC-45,2022GY-065); Fundamental Research Funds for the Central Universities(grant numbers:JB211901); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883551","hyperspectral pansharpening;attention mechanism;super resolution;deep residual neural network;histogram matching","Deep learning;Histograms;Geoscience and remote sensing;Pansharpening;Feature extraction;Task analysis;Spatial resolution","feature extraction;geophysical image processing;geophysical signal processing;image classification;image fusion;image reconstruction;image resolution;image sampling;learning (artificial intelligence);remote sensing","spectral constrained residual attention network;hyperspectral pansharpening;Panchromatic image;spatial details;hyperspectral image;HSI;PAN image;spatial preservation;pansharpening task;spatial learning;SCRAN method;spectral feature extraction net;attention spatial residual net;spectral reconstruction net;spectral constrained loss function;spectral learning ability;deep back-projection network;spectral bands","","1","","12","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Downscaling of Satellite Air Quality Data Using Deep Learning¡","A. Rapuzzi; C. Nattero; M. Menapace; P. Campanella; L. Cademartori; C. Lomonaco","A-SIGN, Italy; FadeOut Software, Italy; FadeOut Software, Italy; FadeOut Software, Italy; Università degli Studi di Genova; Università degli Studi di Genova","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","6606","6609","This research addresses the use of machine learning for downscaling pollution information from multiple satellite sources. The proposed solution uses a Convolutional Neural Network (CNN)-based segmentation architecture (U-Net [1]) to perform a resolution enhancement task. Readings obtained by spatially sparse ground stations are used as the ground truth to guide the task. A custom implementation of this solution won the AI4EO Air Quality & Health challenge [2] initiated in 2021 by the European Space Agency (ESA) [3], on a need expressed by the European Centre for Medium-Range Weather Forecasts (ECMWF) [4] and the Copernicus Atmosphere Monitoring Service (CAMS) [5]. In that successful case, the algorithm was trained and tested on volatile particulate matter (PM2.5, from Copernicus Atmosphere Monitoring Service) and nitrogen dioxide (NO2, from Sentinel-5P TROPOMI) data over three Areas of Interest: Northern Italy, California and South Africa.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884163","Downscaling;Deep Learning;Air Pollution;Earth Observation;Super-Resolution;Machine Learning","Image segmentation;Satellites;European Space Agency;Weather forecasting;Geoscience and remote sensing;Prediction algorithms;Nitrogen","air pollution;air quality;atmospheric techniques;convolutional neural nets;deep learning (artificial intelligence);geophysics computing;remote sensing","satellite air quality data;deep learning;machine learning;downscaling pollution information;multiple satellite sources;CNN;resolution enhancement task;sparse ground stations;ground truth;custom implementation;AI4EO Air Quality & Health;European Space Agency;European Centre;Medium-Range Weather Forecasts;Copernicus Atmosphere Monitoring Service;volatile particulate matter;Sentinel-5P TROPOMI;convolutional neural network-based segmentation architecture","","","","23","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Hyperspectral Image Generation From Rgb Images With Semantic and Spatial Distribution Consistency","L. Liu; Z. Shi; Y. Zao; H. Chen","Image Processing Center, School of Astronautics, Beihang University, Beijing, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1804","1807","Generating hyperspectral images (HSI) from RGB imagery can obtain HSI with both high spatial and spectral resolution, which overcomes the limitations of imaging hardware conditions. Many HSI generation methods target learning a 3-n mapping from RGB to HSI, lacking concern of the spectral categories and spatial distribution. In this paper, we propose an HSI generation method preserving the band structure similarity and semantic information. We design an MLP based classifier and trained it on many spectra of known semantic categories. Then we use it to map the spectra to semantic space and constrain the distance between the embedding of generated spectra and that of the real ones. Meanwhile, a structure similarity loss is added to constrain the spatial information. Experiment results verified the superiority of the proposed method.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884531","National Natural Science Foundation of China(grant numbers:62125102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884531","Hyperspectral Image;Sepctral Super-resolution;Image generation;HSI classification","Graphical models;Image synthesis;Semantics;Superresolution;Imaging;Geoscience and remote sensing;Hardware","feature extraction;geophysical image processing;geophysical techniques;image classification;image colour analysis;image processing;image sensors;learning (artificial intelligence);multilayer perceptrons;pattern classification;remote sensing","hyperspectral image generation;rgb images;spatial distribution consistency;hyperspectral images;RGB imagery;high spatial resolution;spectral resolution;HSI generation method;3-n mapping;spectral categories;band structure similarity;semantic information;known semantic categories;semantic space;generated spectra;spatial information","","","","13","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Separation of scattering phenomena in super-resolution ISAR imaging using constrained music","J. Mitchell; S. Tjuatja","Department of Electrical Engineering, The University of Texas at Arlington UTA, Arlington, TX; Department of Electrical Engineering, The University of Texas at Arlington UTA, Arlington, TX","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","1586","1589","In ISAR Multiple Signal Classification (MUSIC) imaging, the target is generally modeled as a collection of point scatterers. This simplistic model is robust but does not accurately image other scattering phenomena such as physical optics scattering from targets that are large with respect to wavelength. Utilization of the point scattering model for MUSIC imaging of physical optics scattering results in the distribution of target energy across several image pixels. This abstract introduces a method for separating scattering returns from objects with distinct size and shape or with different scattering mechanisms. A new scattering model is proposed to estimate physical optics scattering from spherical scatterers. Using constrained MUSIC techniques, returns from scatterers with a specific size and shape can be eliminated from the super-resolution ISAR image.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326086","","Multiple signal classification;Scattering;Clutter;Imaging;Physical optics;Mathematical model;Reflection","image resolution;radar imaging;signal classification;synthetic aperture radar","scattering phenomena;super-resolution ISAR imaging;constrained music;ISAR multiple signal classification imaging;MUSIC imaging;point scatterer;simplistic model;point scattering model;physical optics scattering;target energy;image pixel;scattering return;scattering mechanism;spherical scatterer;constrained MUSIC technique;super-resolution ISAR image","","2","","4","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Fast Majorize-Minimization based Super-Resolution Algorithm for Radar Forward-Looking Imaging","X. Yin; L. Liu; Y. Huang; M. Feng; Y. Zhang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2055","2058","Recently, super-resolution techniques have been widely used in real aperture radar superresolution imaging. In this paper, we propose a fast sparse superresolution algorithm which is based on majorize-minimization(MM) method to realize fast superresolution imaging of sparse targets in radar forward-looking area. First, we establish a model of rader forward-looking imaging and analyze the echo signal. Second, we use the majorize-minimization (MM) method to obtain the real target distribution. Due to the expensive computational cost of MM algorithm, we proposed an fast matrix inversion approach which is based on divide and conquer strategy. The superior performance of the proposed method is verified by simulations.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883171","superresolution imaging;majorize-minimization;fast matrix inversion","Analytical models;Deconvolution;Computational modeling;Superresolution;Imaging;Radar;Radar imaging","image resolution;image sequences;iterative methods;radar imaging","fast sparse superresolution algorithm;fast superresolution imaging;sparse targets;majorize-minimization method;MM algorithm;fast matrix inversion approach;fast majorize-minimization;super-resolution algorithm;radar forward-looking imaging;super-resolution techniques;aperture radar superresolution imaging","","","","7","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Validation of Super-resolution GNSS-R using an Airborne Field Trial","J. W. Cheong; P. Kuthethoor; A. G. Dempster","Australian Center for Space Engineering Research (ACSER), School of Elec. Eng. & Telecom., University of New South Wales, Sydney, NSW, Australia; Australian Center for Space Engineering Research (ACSER), School of Elec. Eng. & Telecom., University of New South Wales, Sydney, NSW, Australia; Australian Center for Space Engineering Research (ACSER), School of Elec. Eng. & Telecom., University of New South Wales, Sydney, NSW, Australia","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","5929","5932","Conventional GNSS-R uses both coherent and noncoherent integration to obtain the Delay-Doppler map (DDM). In the field of phased array angle-of-arrival estimation, this is akin to the conventional beam-forming technique. It is also well known that super-resolution techniques such as MUSIC can obtain higher accuracy than conventional beamforming especially in the case of multiple signals. In this paper, we explore how this technique can be adapted to GNSS-R to obtain high resolution DDM representations. Its primary application will be to improve upon conventional GNSS-R altimetry. Further extrapolation of this result can also be used to isolate the DDM contributions of sea targets from sea clutter that reside within the same iso-delay region of the DDM. Airborne field trials conducted on 4th November 2011 are processed using both conventional GNSS-R and our proposed method that shows a clear improvement in its peak gradient, an important criterion for estimating a signal component's code delay. We further show a real-world example of a DDM formed by two distinct contributions that otherwise would not be detectable using the conventional DDM.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324368","","Delays;Superresolution;Multiple signal classification;Global Positioning System;Correlation;Australia;Aircraft","array signal processing;direction-of-arrival estimation;image resolution;oceanographic techniques;radar clutter;satellite navigation","super-resolution GNSS-R;airborne field trial;coherent integration;noncoherent integration;Delay-Doppler map;phased array angle-of-arrival estimation;conventional beam-forming technique;super-resolution techniques;conventional beamforming;high resolution DDM representations;conventional GNSS-R altimetry;DDM contributions;iso-delay region;signal component;conventional DDM","","","","12","Crown","17 Feb 2021","","","IEEE","IEEE Conferences"
"Learning Differential Transport Operators for the Joint Super-Resolution of Sea Surface Tracers and Prediction of Subgrid-Scale Features","R. Fablet; J. Le Sommer; J. M. Molines; L. Drumetz; F. Rousseau; B. Chapron","Lab-STICC, IMT Atlantique, Brest, France; CNRS, IGE, Grenoble, France; CNRS, IGE, Grenoble, France; Lab-STICC, IMT Atlantique, Brest, France; Lab-STICC, IMT Atlantique, Brest, France; Ifremer, LOPS, Brest, France","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","7916","7919","This work deals with data-driven and learning-based approaches to fill space-time sampling gaps in the observation of sea surface tracers such as Sea Surface Height (SSH), Sea Surface temperature (SST), Ocean Colour,... More precisely, we jointly address field super-resolution and the prediction of subgrid-scale features, which is novel to our knowledge. From a methodological point of view, we consider deep learning architectures with a view to learning geophysically-sound differential operators (i.e. trasnport operators). Based on an Observing System Simulation Experiment representative of SWOT fast sampling phase using NATL60 simulation data, we illustrate the relevance of the proposed methodological framework which reconstructs more than 90% of the variance of the high-resolution SSH anomaly field and above 90% of the subgrid-scale variance of this anomaly. We also illustrate significant gain w.r.t. other baseline neural network architectures and further discuss the relevance of the reported contribution for other tracer fields and case studies.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900571","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900571","Ocean surface tracers;SSH;superresolution;subgrid-scale features;deep learning;differential operators","Ocean temperature;Sea surface;Training;Sensors;Encoding","learning (artificial intelligence);neural nets;ocean temperature;oceanographic regions;oceanographic techniques;underwater optics","Observing System Simulation Experiment representative;SWOT fast sampling phase;NATL60 simulation data;high-resolution SSH anomaly field;subgrid-scale variance;tracer fields;differential transport operators;joint super-resolution;sea surface tracers;subgrid-scale features;space-time sampling gaps;Sea Surface Height;Sea Surface temperature;field super-resolution;deep learning architectures;geophysically-sound differential operators;data-driven approach;learning-based approach;ocean colour;baseline neural network architectures","","","","18","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Super-Resolution for MIMO Array SAR 3-D Imaging Based on Compressive Sensing and Deep Neural Network","C. Wu; Z. Zhang; L. Chen; W. Yu","School of Electronic Information and Electrical Engineering, Shanghai Key Laboratory of Intelligent Sensing and Recognition, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Key Laboratory of Intelligent Sensing and Recognition, Shanghai Jiao Tong University, Shanghai, China; Science and Technology on Microwave Imaging Laboratory, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; School of Electronic Information and Electrical Engineering, Shanghai Key Laboratory of Intelligent Sensing and Recognition, Shanghai Jiao Tong University, Shanghai, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","18 Jun 2020","2020","13","","3109","3124","Multiple-input multiple-output (MIMO) array synthetic aperture radar (SAR) can straightly obtain the 3-D imagery of the illuminated scene with the single-pass flight. Generally, the Rayleigh resolution of the elevation direction is unacceptable due to the length limitation of linear array. The super-resolution imaging algorithms within the compressive sensing (CS) framework have been extensively studied because of the essential spatial sparsity in the elevation direction. However, the super-resolution performance of the existing sparse reconstruction algorithms will deteriorate dramatically in the case of lower signal-to-noise ratio (SNR) level or a few antenna elements. To overcome this problem, a new super-resolution imaging structure based on CS and deep neural network (DNN) for MIMO array SAR is proposed in this article. In this new algorithm, the spatial filtering based on CS is first proposed to reserve the signals only impinging from the prespecified space subregions. Thereafter, a group of parallel end-to-end DNN regression models are designed for mapping the potential sparse recovery mathematical model and further locating the true scatterers in the elevation direction. Finally, extensive simulations and airborne MIMO array SAR experiments are investigated to validate that the proposed method can realize the state-of-the-art super-resolution imaging against other existing related methods.","2151-1535","","10.1109/JSTARS.2020.3000760","National Natural Science Foundation of China(grant numbers:U1830103); National Pre-Research Foundation of China(grant numbers:61406190101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9112264","Compressive sensing (CS);deep neural network (DNN);multiple-input multiple-output (MIMO);super-resolution;synthetic aperture radar (SAR);3-D imaging","Imaging;MIMO communication;Synthetic aperture radar;Neural networks;Compressed sensing","airborne radar;antenna arrays;image filtering;image reconstruction;image resolution;MIMO radar;neural nets;radar antennas;radar computing;radar imaging;radar resolution;regression analysis;spatial filters;stereo image processing;synthetic aperture radar","illuminated scene;single-pass flight;Rayleigh resolution;linear array;super-resolution imaging algorithms;compressive sensing framework;spatial sparsity;sparse reconstruction algorithms;signal-to-noise ratio;super-resolution imaging structure;deep neural network;parallel end-to-end DNN regression models;airborne MIMO array SAR experiments;MIMO array SAR 3D imaging;multiple-input multiple-output array synthetic aperture radar;3D imagery;sparse recovery mathematical model;SNR","","16","","61","CCBY","9 Jun 2020","","","IEEE","IEEE Journals"
"Sharpening the 20 M Bands of SENTINEL-2 Image Using an Unsupervised Convolutional Neural Network","H. V. Nguyen; M. O. Ulfarsson; J. R. Sveinsson","Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2875","2878","This paper proposes a novel method for sharpening the 20 m bands of the multispectral images acquired by the Sentinel-2 (S2) constellation. We formulate the S2 sharpening as an inverse problem and solve it using an unsupervised convolutional neural network (CNN), called S2UCNN. The proposed method extends the deep image prior provided by a CNN structure with S2 domain knowledge. We incorporate a modulation transfer function-based degradation model as a network layer. We add the 10 m bands to both the network input and output to take advantage of the multitask learning. Experimental results with a real S2 dataset show that the proposed method outperforms the competitive methods on reduced-resolution data and gives very high quality sharpened image on full-resolution data.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9555082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555082","Remote sensing;Sentinel-2;image fusion;sharpening;super-resolution;unsupervised convolutional neural network","Degradation;Inverse problems;Modulation;Convolutional neural networks;Remote sensing;Electronics packaging","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image resolution;inverse problems;optical transfer function;unsupervised learning","unsupervised convolutional neural network;multispectral images;Sentinel-2 constellation;deep image;CNN structure;S2 domain knowledge;network layer;high quality sharpened image;modulation transfer function-based degradation;S2UCNN;Sentinel-2 image sharpening;S2 sharpening;inverse problem;multitask learning;S2 dataset;full-resolution data","","","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Learning Graph Regularisation for Guided Super-Resolution","R. De Lutio; A. Becker; S. D'Aronco; S. Russo; J. D. Wegner; K. Schindler","EcoVision Lab, Photogrammetry and Remote Sensing, ETH Zurich; EcoVision Lab, Photogrammetry and Remote Sensing, ETH Zurich; EcoVision Lab, Photogrammetry and Remote Sensing, ETH Zurich; EcoVision Lab, Photogrammetry and Remote Sensing, ETH Zurich; Institute for Computational Science, University of Zurich; EcoVision Lab, Photogrammetry and Remote Sensing, ETH Zurich","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","1969","1978","We introduce a novel formulation for guided super-resolution. Its core is a differentiable optimisation layer that operates on a learned affinity graph. The learned graph potentials make it possible to leverage rich contextual information from the guide image, while the explicit graph optimisation within the architecture guarantees rigorous fidelity of the high-resolution target to the low-resolution source. With the decision to employ the source as a constraint rather than only as an input to the prediction, our method differs from state-of-the-art deep architectures for guided super-resolution, which produce targets that, when downsampled, will only approximately reproduce the source. This is not only theoretically appealing, but also produces crisper, more natural-looking images. A key property of our method is that, although the graph connectivity is restricted to the pixel lattice, the associated edge potentials are learned with a deep feature extractor and can encode rich context information over large receptive fields. By taking advantage of the sparse graph connectivity, it becomes possible to propagate gradients through the optimisation layer and learn the edge potentials from data. We extensively evaluate our method on several datasets, and consistently outperform recent baselines in terms of quantitative reconstruction errors, while also delivering visually sharper outputs. Moreover, we demonstrate that our method generalises particularly well to new datasets not seen during training.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.00202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879114","Low-level vision; Deep learning architectures and techniques; Machine learning; Optimization methods; RGBD sensors and analytics","Deep learning;Training;Superresolution;Optimization methods;Lattices;Computer architecture;Feature extraction","feature extraction;graph theory;image reconstruction;image resolution;image sampling;learning (artificial intelligence);optimisation","learned affinity graph;learned graph potentials;leverage rich contextual information;guide image;explicit graph optimisation;high-resolution target;low-resolution source;state-of-the-art deep architectures;guided super-resolution;sparse graph connectivity;graph regularisation;differentiable optimisation layer","","","","62","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Learn to have Color and Detail: An End-to-End Panchromatic Image Enhancement","M. Zhou; Y. Wang; G. Wu; R. Shibasaki","School of Computer Science, Queensland University of Technology, Brisbane, QLD, Australia; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2628","2631","Due to the limited resolution and chrominance information, panchromatic images can not be widely used in accurate earth observation applications, such as road extraction, vehicle detection, and building segmentation. In this research, we propose a cascaded fully convolutional network (CFCN) to achieve panchromatic image super-resolution and image colorization in an end-to-end manner. Experiments on a multispectral image dataset demonstrate that panchromatic images enhanced by the proposed CFCN can achieve high learned extraction similarity as compared to aerial images.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553507","JST (Japan Science and Technology Agency)(grant numbers:JPMJAS2019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553507","Super-resolution;Image Colorization;Deep Learning;Learned Extraction Similarity","Measurement;Earth;Image segmentation;Image color analysis;Vehicle detection;Roads;Superresolution","feature extraction;geophysical image processing;image classification;image colour analysis;image enhancement;image resolution;image segmentation;learning (artificial intelligence);remote sensing","chrominance information;panchromatic images;accurate earth observation applications;road extraction;vehicle detection;cascaded fully convolutional network;CFCN;panchromatic image super-resolution;multispectral image dataset;high learned extraction similarity;aerial images;end-to-end panchromatic image enhancement","","","","13","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A CNN-Based Fusion Method for Super-Resolution of Sentinel-2 Data","M. Gargiulo; A. Mazza; R. Gaetano; G. Ruello; G. Scarpa","DIETI, University Federico II, Naples, Italy; DIETI, University Federico II, Naples, Italy; CIRAD, UMR-TETIS Laboratory, Montpellier, France; DIETI, University Federico II, Naples, Italy; DIETI, University Federico II, Naples, Italy","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","4713","4716","Sentinel-2 data represent a rich source of information for the community due to the free access and to the temporal-spatial coverage assured. However, some of the spectral bands are sensed at reduced resolution due to a compromise between technological limitations and Copernicus program's objectives. For this reason in this work we present a new super-resolution method based on Convolutional Neural Networks (CNNs) to rise the resolution of the short wave infra-red (SWIR) band from 20 to 10 meters, that is the highest resolution provided. This is accomplished by fusing the target band with the finer-resolution ones. The proposed solution compares favourably against several alternative methods according to different quality indexes. In addition we have also tested the use of the super-resolved band from an applicative perspective by detecting water basins through the Modified Normalized Difference Water Index (MNDWI).","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518447","Deep learning;convolutional neural network;normalized difference water index;Sentinel-2;pansharpening","Spatial resolution;Training;Indexes;Convolutional neural networks;Meters","geophysical image processing;image fusion;image resolution;neural nets;remote sensing;water resources","short wave infrared band;Sentinel-2 data;water basins;Modified Normalized Difference Water Index;MNDWI;Convolutional Neural Networks;Copernicus program;spectral bands;CNN-based fusion method;super-resolved band","","12","","17","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Hyperspectral Image Super-Resolution Based on Multiscale Mixed Attention Network Fusion","J. Hu; Y. Tang; Y. Liu; S. Fan","School of Electrical and Information Engineering and the Key Laboratory of Electric Power Robot of Hunan Province, Changsha University of Science and Technology, Changsha, China; School of Electrical and Information Engineering and the Key Laboratory of Electric Power Robot of Hunan Province, Changsha University of Science and Technology, Changsha, China; School of Electrical and Information Engineering and the Key Laboratory of Electric Power Robot of Hunan Province, Changsha University of Science and Technology, Changsha, China; School of Electrical and Information Engineering and the Key Laboratory of Electric Power Robot of Hunan Province, Changsha University of Science and Technology, Changsha, China","IEEE Geoscience and Remote Sensing Letters","11 Jan 2022","2022","19","","1","5","Hyperspectral images (HSIs) contain rich spectral information and have great application value. However, due to various hardware limitations, the spatial resolution of HSIs acquired by the sensor is low. HSI super-resolution (SR) attracts much attention to improve spatial quality. In this letter, a single HSI SR method based on network fusion is proposed. Our method includes the SR network part and fusion part. In the SR network part, we construct 3-D multiscale mixed attention networks (3-D-MSMANs) by cascading 3-D multiscale mixed attention block (3-D-MSMAB) to restore high-resolution HSIs. 3-D-MSMAB consists of the 3-D Res2net module and the mixed attention module. 3-D Res2net module is a simple and effective multiscale method. The mixed attention module is proposed by combining the first- and second-order statistics of features. In addition, we use the mutual learning loss between 3-D-MSMAN so that they can learn from each other. In the fusion part, the fusion module is designed to merge the output of each 3-D-MSMAN. Our method can achieve good results in both simulated and real SR experiments. Code is available at https://github.com/LYT-max/Mixed-Attention-for-HSI-SR.","1558-0571","","10.1109/LGRS.2021.3124974","National Natural Science Foundation of China(grant numbers:61601061); Natural Science Foundation of Hunan Province, China(grant numbers:2021JJ40609); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9598826","Hyperspectral image (HSI);image super-resolution (SR);mixed attention;mutual learning","Three-dimensional displays;Superresolution;Convolution;Spatial resolution;Hyperspectral imaging;Image reconstruction;Feature extraction","hyperspectral imaging;image fusion;image reconstruction;image resolution;learning (artificial intelligence)","single HSI SR method;SR network part;fusion part;high-resolution HSIs;mixed attention module;effective multiscale method;fusion module;hyperspectral image super-resolution;hyperspectral images;spectral information;spatial resolution;HSI super-resolution;spatial quality;multiscale mixed attention network fusion;3D Res2net module;3D-MSMAB;3D multiscale mixed attention block;3D-MSMAN;3D multiscale mixed attention networks","","4","","17","IEEE","2 Nov 2021","","","IEEE","IEEE Journals"
"Super Resolution and Interferences Suppression Technique Applied to SHARAD Data","M. C. Raguso; M. Mastrogiuseppe; R. Seu; L. Piazzo","DIET Dept., Sapienza University of Rome, Rome, Italy; DIET Dept., Sapienza University of Rome, Rome, Italy; DIET Dept., Sapienza University of Rome, Rome, Italy; DIET Dept., Sapienza University of Rome, Rome, Italy","2018 5th IEEE International Workshop on Metrology for AeroSpace (MetroAeroSpace)","2 Sep 2018","2018","","","242","246","Herein we present a super resolution and electromagnetic interference suppression technique based on Maximum Entropy Method and applied to data acquired by the SHAllow RADar (SHARAD) on board the NASA's 2005 Mars Reconnaissance Orbiter (MRO) mission, currently operating on Mars. We show that the proposed algorithm allows to enhance signal-to-noise ratio by several decibels and the range resolution over a factor of three. Subsurface imaging is improved remarkably, allowing additional insights for the scientific community in the interpretation of the SHARAD radar data.","2575-7490","978-1-5386-2474-6","10.1109/MetroAeroSpace.2018.8453529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453529","Ground penetrating radar;radar sounding;SHARAD;subsurface radar;range resolution;auto-regressive methods;EMI suppression;bandwidth extrapolation;Mars","Radar imaging;Bandwidth;Image resolution;Electromagnetic interference;Signal resolution;Signal to noise ratio","interference suppression;Mars;maximum entropy methods;planetary remote sensing;remote sensing by radar","subsurface imaging;Mars Reconnaissance Orbiter mission;interferences suppression technique applied;SHARAD radar data;range resolution;signal-to-noise ratio;SHAllow RADar;Maximum Entropy Method;electromagnetic interference suppression technique;super resolution","","7","","17","IEEE","2 Sep 2018","","","IEEE","IEEE Conferences"
"Improving InSAR Image Quality and Co-Registration through CNN-Based Super-Resolution","K. A. H. Kelany; A. Baniasadi; N. Dimopoulos; M. Gara","Department of Electrical and Computer Engineering, University of Victoria, Victoria, BC, Canada; Department of Electrical and Computer Engineering, University of Victoria, Victoria, BC, Canada; Department of Electrical and Computer Engineering, University of Victoria, Victoria, BC, Canada; 3v Geomatics Inc., Vancouver, BC, Canada","2020 IEEE International Symposium on Circuits and Systems (ISCAS)","28 Sep 2020","2020","","","1","5","Interferometric Synthetic Aperture Radar (InSAR) is a measuring technology that uses the phase information contained in the images of the Synthetic Aperture Radar (SAR). InSAR has been recognized as a potential method for digital elevation models (DEMs) generation and ground surface deformation measurement. Nonetheless, the quality of InSAR data is influenced by many critical factors. Including image co-registration, interferogram generation, phase unwrapping and geocoding. Image co-registration aims to align two or more images so that the same pixel in each image corresponds to the same point of the target scene. This study proposes a new algorithm for improving Image co-registration and interferogram generation of SAR using learning-based images super-resolution (SR). We show that our approach improves the conventional approaches.","2158-1525","978-1-7281-3320-1","10.1109/ISCAS45731.2020.9180733","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9180733","","Image resolution;Synthetic aperture radar;Signal resolution;Coherence;Training;Strain;Radar imaging","digital elevation models;image registration;image resolution;radar imaging;radar interferometry;remote sensing by radar;synthetic aperture radar","phase unwrapping;geocoding;Image co-registration aims;image corresponds;learning-based images super-resolution;InSAR image quality;CNN-based super-resolution;Interferometric Synthetic Aperture Radar;measuring technology;phase information;ground surface deformation measurement;InSAR data","","2","","25","IEEE","28 Sep 2020","","","IEEE","IEEE Conferences"
"Fusion of microwave and infrared data for enhancing its spatial resolution","I. Yanovsky; A. Behrangi; M. Schreier; V. Dang; B. Wen; B. Lambrigtsen","Joint Institute for Regional Earth System Science and Engineering, University of California Los Angeles, Los Angeles, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","2625","2628","The images acquired by microwave sensors are blurry and of low-resolution. On the other hand, the images obtained using infrared/visible sensors are of sufficiently high-resolution. In this paper, we develop a data fusion methodology and apply it to enhance resolution of a microwave image using the data from a collocated infrared/visible sensor. Such an approach takes advantage of the spatial resolution of the infrared instrument and the sensing accuracy of the microwave instrument. We tested our method using precipitation scenes captured with the Advanced Microwave Sounding Unit (AMSU) microwave instrument and the Advanced Very High Resolution Radiometer (AVHRR).","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127533","Data fusion;inverse problems;microwave imaging;remote sensing;sparse optimization;spatial resolution;super-resolution","Microwave imaging;Microwave theory and techniques;Spatial resolution;Data integration;Microwave radiometry;Sensors","atmospheric precipitation;geophysical image processing;image fusion;image resolution;microwave imaging;remote sensing","low-resolution;data fusion methodology;microwave image;infrared instrument;microwave instrument;Advanced Microwave Sounding Unit;Advanced Very High Resolution Radiometer;infrared sensor;visible sensor;precipitation scene","","","","16","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"On Coupling Classification and Super-Resolution in Remote Urban Sensing: An Integrated Deep Learning Approach","Y. Zhang; R. Zong; L. Shang; D. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; School of Information Sciences, University of Illinois Urbana-Champaign, Champaign, IL, USA; School of Information Sciences, University of Illinois Urbana-Champaign, Champaign, IL, USA; School of Information Sciences, University of Illinois Urbana-Champaign, Champaign, IL, USA","IEEE Transactions on Geoscience and Remote Sensing","9 May 2022","2022","60","","1","17","Motivated by the state-of-the-art optical sensing and image processing technologies, remote urban sensing (RUS) has emerged as a powerful sensing paradigm to capture abundant visual information about the urban environment for intelligent city monitoring, planning, and management. In this article, we focus on a classification and super-resolution coupling (CSC) problem in RUS applications, where the goal is to explore the interdependence between two critical tasks (i.e., classification and super-resolution) to concurrently boost the performance of both the tasks. Two fundamental challenges exist in solving our problem: 1) it is challenging to obtain accurate classification results and generate high-quality reconstructed images without knowing either of them a priori and 2) the noise embedded in the image data could be amplified infinitely by the complex interdependence and coupling between the two tasks. To address these challenges, we develop SCLearn, a novel deep convolutional neural network architecture, to couple the classification task with the super-resolution task in an integrated learning framework to concurrently boost the performance of both the tasks. The evaluation results on a real-world RUS application over two different cities in Europe (Barcelona and Berlin) show that SCLearn consistently outperforms the state-of-the-art baselines by simultaneously achieving better land usage classification accuracy and higher reconstructed image quality under various application scenarios.","1558-0644","","10.1109/TGRS.2022.3169703","National Science Foundation(grant numbers:IIS-2008228,CNS-1845639,CNS-1831669); Army Research Office(grant numbers:W911NF-17-1-0409); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761962","Classification;integrated deep learning;smart urban sensing;super-resolution","Task analysis;Superresolution;Sensors;Image reconstruction;Visualization;Convolutional neural networks;Satellites","convolutional neural nets;deep learning (artificial intelligence);image classification;image reconstruction;learning (artificial intelligence);pattern classification","coupling classification;remote urban sensing;integrated deep learning;optical sensing;image processing;powerful sensing paradigm;abundant visual information;urban environment;intelligent city monitoring;RUS applications;high-quality reconstructed images;image data;deep convolutional neural network architecture;super-resolution task;integrated learning framework;real-world RUS application;land usage classification accuracy;higher reconstructed image quality;SCLearn","","","","64","CCBY","22 Apr 2022","","","IEEE","IEEE Journals"
"Structural-Correlated Self-Examples Based Superresolution of Single Remote Sensing Image","H. Shen; B. Hou; Z. Wen; L. Jiao","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi’an, China; Key Laboratory of Information Fusion Technology of MOE, Northwestern Polytechnical University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi’an, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","5 Sep 2018","2018","11","9","3209","3223","Image superresolution methods are of great importance to image analysis and interpretation and have been intensively studied and widely applied. The main research works on single-image superresolution are how to construct the training image database and how to learn the mapping relationship between low- and high-resolution images. Considering only a single image, a novel super-resolution method for self-examples learning without depending on any external training images is proposed in this paper. The training self-examples are extracted from the gradually degraded versions of the testing image and their corresponding interpolated counterparts to build internal high- and low-resolution training databases. Inspired by the concept of “coarse-to-fine,” the upscaling process is performed gradually as well. The algorithm includes two steps during each upscaling procedure. For each low-resolution patch, the first step is to find structural-correlated patches by sparse representation throughout the training database to learn global linear mapping function between low- and high-resolution image patches without any assumption on the data, and the second step takes the advantage of sparse representation as a local constraint on super-resolution result. At each upscaling procedure, iterative back projection is applied to guarantee the consistency of the estimated image. Moreover, the internal training database will be updated according to the newly generated upscaled image. Experiments show that the proposed algorithm can achieve good performance on peak signal-to-noise ratio and structural similarity index and produce excellent visual effects compared with other super-resolution methods.","2151-1535","","10.1109/JSTARS.2018.2847450","National Natural Science Foundation of China(grant numbers:61671350); Foundation for Innovative Research Groups of the National Natural Science Foundation of China(grant numbers:61621005); National Natural Science Foundation of China(grant numbers:91438201); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8402088","Direct mapping (DM);image superresolution;internal database;sparse representation;structural-correlated","Training;Signal resolution;Databases;Spatial resolution;Remote sensing;Dictionaries","image resolution;interpolation;learning (artificial intelligence);remote sensing","self-examples learning;iterative back projection;local constraint;peak signal-to-noise ratio;structural similarity index;high-resolution image patches;global linear mapping function;sparse representation;structural-correlated patches;low-resolution patch;upscaling process;low-resolution training databases;testing image;training self-examples;external training images;high-resolution images;mapping relationship;training image database;single-image superresolution;image analysis;image superresolution methods;single remote sensing image;structural-correlated self-examples","","3","","36","IEEE","3 Jul 2018","","","IEEE","IEEE Journals"
"Estimating location of land cover patch in super-resolution mapping by hopfield neural network","S. K. M. Zaki; A. M. Muad","Department of Electrical, Electronic & Systems Engineering, UKM, Bangi, Selangor, Malaysia; Department of Electrical, Electronic & Systems Engineering, UKM, Bangi, Selangor, Malaysia","2015 IEEE Symposium on Computer Applications & Industrial Electronics (ISCAIE)","15 Oct 2015","2015","","","42","47","Super-resolution mapping (SRM) aims to locate subpixel class fractions geographically in the area represented by a mixed pixel. The accuracy of small sub-pixel class patches are represented by the popular SRM method is explored. It is shown that the accuracy of predicted patch location from the Hopfield Neural of SRM is a function of patch size. Specifically, the accuracy with which patch location is predicted varies inversely with patch size, with very small patches subject to large mis-location errors. A means to reduce the magnitude of mis-location error through the use of multiple sub-pixel shifted imagery is illustrated and the implications to popular site-specific accuracy assessment discussed. The use of multiple subpixel shifted images was able to reduce the error in patch location by more than half for very small patches and represents a simple but effective enhancement to SRM applications.","","978-1-4799-8969-0","10.1109/ISCAIE.2015.7298325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298325","remote sensing;multiple sub-pixel shifted;mixed pixel","Accuracy;Spatial resolution;Standards;Remote sensing;Neurons;Resource management","estimation theory;Hopfield neural nets;hyperspectral imaging;image enhancement;image resolution;land cover;vegetation mapping","land cover patch location estimation;superresolution mapping;SRM;Hopfield neural network;subpixel class fraction;subpixel shifted imagery;image enhancement","","","","10","IEEE","15 Oct 2015","","","IEEE","IEEE Conferences"
"Sub-Pixel Width Road Network Extraction Using Sentinel-2 Imagery","C. Ayala; C. Aranda; M. Galar","Tracasa Instrumental, Sarriguren, Navarra; Tracasa Instrumental, Sarriguren, Navarra; Institute of Smart Cities (ISC), Public University of Navarre, Pamplona, Spain","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2174","2177","Nowadays, road maps play a key role in our society. Therefore, keeping those maps up-to-date is highly important. The extraction of road networks from satellite imagery is a complex problem, not only because of occlusions, shadows produced by non-road objects, but also due to the limited spatial resolution of the imagery used. The feasibility to detect a road depends on its width, which can reach sub-pixel size in some satellite products. In the last decade, many attempts have been carried out to automatize this labour. However, the vast majority of methods rely on aerial imagery, whose costs are not yet affordable for maintaining up-to-date maps. This work demonstrates that it is also possible to accurately detect roads using freely available Sentinel-2 imagery, regardless of their width. For that purpose, a new deep learning architecture which combines semantic segmentation and super-resolution techniques is proposed. As a result, fine-grained road network maps at 2.5 m are generated from 10 m imagery taken as input. To evaluate this proposal a data-set composed of 20 cities spread across the Spanish territory is used.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9555128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555128","Sentinel-2;Remote Sensing;Road Network Extraction;Deep Learning;Convolutional Neural Networks","Image segmentation;Satellites;Roads;Neural networks;Urban areas;Superresolution;Semantics","cartography;deep learning (artificial intelligence);geophysical image processing;geophysical techniques;image resolution;image segmentation;remote sensing;roads","satellite imagery;complex problem;nonroad objects;spatial resolution;subpixel size;satellite products;aerial imagery;up-to-date maps;Sentinel-2 imagery;super-resolution techniques;fine-grained road network maps;subpixel width road network extraction;Spanish territory;deep learning;semantic segmentation;size 2.5 m;size 10.0 m","","","","14","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Parallel Multispectral Image Super-resolution Based on Sparse Representations","H. U. Mullah; B. Deka","Dept. of Electronics and Communication Engg., Tezpur University, Assam, India; Dept. of Electronics and Communication Engg., Tezpur University, Assam, India","2019 2nd International Conference on Innovations in Electronics, Signal Processing and Communication (IESC)","18 Nov 2019","2019","","","104","109","Image super-resolution (SR) produces a high-resolution (HR) image using either a single or multiple low-resolution (LR) input image(s) of the same scene. Sparse representation techniques are effectively applied for image SR because of their high reconstruction accuracy. SR reconstruction is accomplished through learning of an overcomplete dictionary and then solving a series of regularization problems applied on each patch extracted from the input image. This paper demonstrates a sparse representation based coupled overcomplete dictionary training and SR procedure for LR multispectral images. The proposed work is also implemented using a multicore parallel processing technique to provide faster reconstruction. Experimental results show superiority of the proposed method over some others.","","978-1-7281-0744-8","10.1109/IESPC.2019.8902436","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902436","sparse representation;super-resolution;multi-core processing;remote sensing","","","","","","","20","IEEE","18 Nov 2019","","","IEEE","IEEE Conferences"
"Joint-SRVDNet: Joint Super Resolution and Vehicle Detection Network","M. Mostofa; S. N. Ferdous; B. S. Riggan; N. M. Nasrabadi","Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, USA; Department of Electrical and Computer Engineering, University of Nebraska–Lincoln, Lincoln, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, USA","IEEE Access","13 May 2020","2020","8","","82306","82319","In many domestic and military applications, aerial vehicle detection and super-resolution algorithms are frequently developed and applied independently. However, aerial vehicle detection on super-resolved images remains a challenging task due to the lack of discriminative information in the super-resolved images. To address this problem, we propose a Joint Super-Resolution and Vehicle Detection Network (Joint-SRVDNet) that tries to generate discriminative, high-resolution images of vehicles from low-resolution aerial images. First, aerial images are up-scaled by a factor of 4x using a Multi-scale Generative Adversarial Network (MsGAN), which has multiple intermediate outputs with increasing resolutions. Second, a detector is trained on super-resolved images that are upscaled by factor 4x using MsGAN architecture and finally, the detection loss is minimized jointly with the super-resolution loss to encourage the target detector to be sensitive to the subsequent super-resolution training. The network jointly learns hierarchical and discriminative features of targets and produces optimal super-resolution results. We perform both quantitative and qualitative evaluation of our proposed network on VEDAI, xView and DOTA datasets. The experimental results show that our proposed framework achieves better visual quality than the state-of-the-art methods for aerial super-resolution with 4x up-scaling factor and improves the accuracy of aerial vehicle detection.","2169-3536","","10.1109/ACCESS.2020.2990870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9079855","Aerial images;multi-scale generative adversarial network (MsGAN);super-resolution;vehicle detection","Vehicle detection;Training;Feature extraction;Computer architecture;Gallium nitride","image representation;image resolution;learning (artificial intelligence)","aerial super-resolution;aerial vehicle detection;joint super resolution;vehicle detection network;super-resolution algorithms;super-resolved images;high-resolution images;low-resolution aerial images;multiscale generative adversarial network;detection loss;super-resolution loss;joint-SRVDNet","","18","","60","CCBY","28 Apr 2020","","","IEEE","IEEE Journals"
"Context-Aware Guided Attention Based Cross-Feedback Dense Network for Hyperspectral Image Super-Resolution","W. Dong; J. Qu; T. Zhang; Y. Li; Q. Du","State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; Department of Electronic and Computer Engineering, Mississippi State University, Starkville, MS, USA","IEEE Transactions on Geoscience and Remote Sensing","15 Jun 2022","2022","60","","1","14","Convolutional neural networks (CNNs) have shown impressive performance in computer vision due to their nonlinearity. Particularly, DenseNet (DN) that facilitates feature reuse in a feedforward (FF) manner has achieved state-of-the-art reconstruction accuracy for super-resolution (SR). However, most DN-based SR models transfer the features generated from each layer to all the subsequent layers, inevitably introducing redundancy, especially for high-dimensional hyperspectral (HS) images. To tackle this problem, we propose a two-branch cross-feedback dense network with context-aware guided attention (CFDcagaNet) for HS super-resolution (HSSR), which allows the network to learn the attention maps of high-level features and refine the low-level features in a feedback (FB) manner across two branches. Context-aware guided attention (CAGA) uses high-level posterior information to provide more faithful spatial–spectral guidance for low-level features, which enables CFDcagaNet to learn more effective spatial–spectral features at low levels and yield more effective spatial–spectral transfer in the network. Extensive experiments on widely used datasets demonstrate that the proposed method outperforms state-of-the-art methods in terms of both quantitative values and visual qualities.","1558-0644","","10.1109/TGRS.2022.3180484","National Natural Science Foundation of China(grant numbers:62101414); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2021JQ-194,2021JQ-197); Fundamental Research Funds for the Central Universities(grant numbers:XJS210108,XJS210104); China Post-Doctoral Science Foundation(grant numbers:2021M702546,2021M702548); Scientific and Technological Activities for Overseas Students of Shaanxi Province(grant numbers:2020-017); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2020A1515110856); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9789157","Context-aware guided attention (CAGA);cross-feedback;dense network;hyperspectral (HS) image super-resolution","Feature extraction;Spatial resolution;Pansharpening;Superresolution;Hyperspectral imaging;Semantics;Image reconstruction","computer vision;convolutional neural nets;feature extraction;geophysical image processing;hyperspectral imaging;image classification;image reconstruction;image representation;image resolution;learning (artificial intelligence)","reconstruction accuracy;DN-based SR models;two-branch cross-feedback dense network;context-aware guided attention;HS super-resolution;attention map learning;high-level features;low-level features;feedback manner;high-level posterior information;spatial-spectral features;convolutional neural networks;feature reuse;feedforward manner;high-dimensional hyperspectral image superresolution;CNN;computer vision;DenseNet;CFDcagaNet;HS superresolution;HSSR;spatial-spectral transfer","","2","","42","IEEE","6 Jun 2022","","","IEEE","IEEE Journals"
"Spectral Super-Resolution Based on Dictionary Optimization Learning via Spectral Library","H. -F. Yan; Y. -Q. Zhao; J. C. -W. Chan; S. G. Kong","School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; Department of Electronics and Informatics, Vrije Universiteit Brussel, Brussels, Belgium; Department of Computer Engineering, Sejong University, Seoul, South Korea","IEEE Transactions on Geoscience and Remote Sensing","13 Jan 2023","2023","61","","1","16","Extensive works have been reported in hyperspectral images (HSIs) and multispectral images (MSIs) fusion to raise the spatial resolution of HSIs. However, the limited acquisition of HSIs has been an obstacle to such approaches. Spectral super-resolution (SSR) of MSI is a challenging and less investigated topic, which can also provide high-resolution synthetic HSIs. To deal with this high ill-posedness problem, we perform super-resolution enhancement of MSIs in the spectral domain by incorporating a spectral library as a priori. First, an aligned spectral library, which maps the open-source spectral library to a specific spectral library created for the reconstructed HR HSI, is represented. An intermediate latent HSI is obtained by fusing the spatial information from MSI and the hyperspectral information from a specific spectral library. Then, we use low-rank attribute embedding to transfer latent HSI into a robust subspace. Finally, a low-rank HSI dictionary representing the hyperspectral information is learned from the latent HSI. The adaptive sparse coefficient of MSI is obtained with a nonnegative constraint. By fusing these two terms, we get the final HR HSI. The proposed SSR model does not require any pretraining stages. We confirm the validity and superiority of our proposed SSR algorithm by comparing it with several benchmark state-of-the-art approaches on different datasets.","1558-0644","","10.1109/TGRS.2022.3229439","National Natural Science Foundation of China (NSFC)(grant numbers:61771391); Key Research and Development (R&D) Plan of Shaanxi Province(grant numbers:2020ZDLGY07-11); Fundamental Research Funds for the Central Universities; Science, Technology and Innovation Commission of Shenzhen Municipality(grant numbers:JCYJ20170815162956949,JCYJ20180306171146740); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9987530","Dictionary optimization learning;low-rank attribute embedding (LAE);spectral library alignment (SLA);spectral super-resolution (SSR) reconstruction","Libraries;Dictionaries;Hyperspectral imaging;Superresolution;Spatial resolution;Image reconstruction;Correlation","geophysical image processing;hyperspectral imaging;image enhancement;image reconstruction;image representation;image resolution;learning (artificial intelligence);spectral analysis","aligned spectral library;challenging investigated topic;dictionary optimization;final HR HSI;high-resolution synthetic HSIs;hyperspectral information;intermediate latent HSI;less investigated topic;MSI;open-source spectral library;reconstructed HR HSI;spatial information;specific spectral library;spectral domain;spectral super-resolution","","","","69","IEEE","15 Dec 2022","","","IEEE","IEEE Journals"
"Super-Resolution Land Cover Mapping Using Multiscale Self-Similarity Redundancy","Y. Zhang; F. Ling; X. Li; Y. Du","University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Institute of Geodesy and Geophysics, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Institute of Geodesy and Geophysics, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Institute of Geodesy and Geophysics, Chinese Academy of Sciences, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20 May 2017","2015","8","11","5130","5145","Super-resolution mapping (SRM) is a method to estimate a fine-resolution land cover map from coarse-resolution fraction images. SRM is an ill-posed problem and regularization terms are always needed to be introduced to well-pose the solution. The regularization term based on the maximal spatial dependence has been widely used in SRM; however, it is often too simple to provide detailed land cover pattern information. In this paper, a novel SRM algorithm, which adopts a new regularization term that is generated using the multiscale self-similarity redundancy feature in fraction images, is proposed. Based on the multiscale self-similarity redundancy, the proposed SRM algorithm magnifies the input coarse-resolution fraction images to the images with the same spatial resolution as the final fine-resolution map to be estimated. A coarse-to-fine strategy is applied to insure the stability of the magnifying process. During the magnifying process, support vector regression is used to learn the relationship between image patches in fraction images and the down-sampled images, which is applied to estimate the magnified fraction images. The new regularization term is then constructed based on the final magnified fraction images and used to provide additional information for SRM. The proposed SRM algorithm was compared with popular SRM algorithms using both synthetic and real images. Experimental results show that the multiscale self-similarity redundancy feature widely exists in fraction images, and provides valuable land cover information for SRM. Resultant fine-resolution land cover maps generated by the proposed SRM algorithm have higher accuracy than other algorithms.","2151-1535","","10.1109/JSTARS.2015.2480120","National Basic Research Program (973 Program) of China(grant numbers:2013cb733205); Natural Science Foundation of Hubei Province for Distinguished Young Scholars(grant numbers:2013CFA031); Key Laboratory of Mapping from Space; National Administration of Surveying, Mapping and Geoinformation(grant numbers:K201409); Distinguished Young Scientist Grant of the Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299621","Multiscale self-similarity redundancy;spatial regularization;super-resolution mapping (SRM);support vector regression (SVR);Multiscale self-similarity redundancy;spatial regularization;super-resolution mapping (SRM);support vector regression (SVR)","Redundancy;Spatial resolution;Support vector machines;Algorithm design and analysis;Error analysis","fractals;geophysical image processing;image resolution;land cover;terrain mapping","super-resolution land cover mapping;multiscale self-similarity redundancy;fine-resolution land cover map;coarse-resolution fraction image;SRM regularization terms;maximal spatial dependence;land cover pattern information;SRM algorithm;images;multiscale self-similarity redundancy;final fine-resolution map;coarse-to-fine strategy;magnifying process;support vector regression;down-sampled image;magnified fraction images","","11","","48","IEEE","16 Oct 2015","","","IEEE","IEEE Journals"
"Beam-Recursive Iterative Adaptive Approach for Scanning Radar Angular Superresolution","Y. Zhang; Y. Zhang; D. Mao; Y. Kang; Y. Zhang; J. Yang","University of Electronic Science and Technology of China, Chengdu; University of Electronic Science and Technology of China, Chengdu; University of Electronic Science and Technology of China, Chengdu; University of Electronic Science and Technology of China, Chengdu; University of Electronic Science and Technology of China, Chengdu; University of Electronic Science and Technology of China, Chengdu","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","9145","9148","Angular resolution of scanning radar is constrained by the size of antenna aperture. Such coarse resolution can not satisfy the applications of microwave remote sensing that require high resolution. Iterative adaptive approach (IAA) is a recently introduced method for scanning radar angular super-resolution, which could notably improve the angular resolution and suppress the noise amplification. In this paper, we further this development, by presenting a beam-recursive I-AA, allowing for adjusting the regularization parameter adaptively and dynamically for varying scenario. Such implementation could effectively eliminate the artifacts on background when applying the batch IAA to resolve closely spaced strong targets. Moreover, the technique offers a promising potential that deserves further attention on computationally efficient implementation and real-time imaging along antenna beam scanning. Simulations are provided to validate the effectiveness of the proposed approach.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899814","Scanning radar;angular resolution;iterative adaptive approach;beam-recursive","Radar antennas;Radar imaging;Radar remote sensing;Imaging","iterative methods;radar antennas;radar resolution","angular resolution;antenna aperture;coarse resolution;microwave remote sensing;radar angular super-resolution;antenna beam scanning;beam-recursive iterative adaptive approach;scanning radar angular superresolution","","","","12","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"ResLap: Generating High-Resolution Climate Prediction Through Image Super-Resolution","J. Cheng; Q. Kuang; C. Shen; J. Liu; X. Tan; W. Liu","School of Computer, Wuhan University, Wuhan, China; Public Meteorological Service Center, China Meteorological Administration, Beijing, China; School of Computer, Wuhan University, Wuhan, China; School of Computer, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Computer, Wuhan University, Wuhan, China","IEEE Access","3 Mar 2020","2020","8","","39623","39634","In recent years, many models based on the convolutional neural network have achieved high-quality reconstruction for single image super-resolution. Meanwhile, many researches on image super-resolution have been applied to various fields. However, only a few research works have been applied to climate prediction. In this paper, we present ResLap to achieve high-resolution climate prediction. ResLap is a spatial downscaling method that converts low spatial resolution climate data into high-resolution regional climate forecasts. This method mainly introduces a novel residual dense block (RDB) into the Laplacian pyramid super-resolution network (LapSRN). Among them, we use LapSRN to achieve upsampling image reconstruction, and adopt RDB to fully extract the hierarchical features from all the convolutional layers. Extensive experimental results on benchmark climate datasets show that our new proposed model performs better than many super-resolution methods. Besides, the climate data are more complicated than the general image, because of its dynamic and chaotic nature. To facilitate model training, we integrate original climate data provided by the China Meteorological Administration, then convert it into trainable climate images. We also publish some climate image datasets online for research. Finally, we avoid the checkerboard artifacts in the generated high-resolution climate images.","2169-3536","","10.1109/ACCESS.2020.2974785","National Basic Research Program of China (973 Program)(grant numbers:2018YFC1507801,2017YFB0504202,2018YFB2100504); National Natural Science Foundation of China(grant numbers:61972290,41871312); Natural Science Foundation of Hubei Province(grant numbers:2017CFB433); Fundamental Research Funds for the Central Universities(grant numbers:2042019kf0226); Fuzhou University(grant numbers:2016LSDMIS06); Beijing Key Laboratory of Urban Spatial Information Engineering(grant numbers:2017209); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9001044","Super-resolution;climate image;checkerboard artifacts;convolutional neural network","Meteorology;Spatial resolution;Feature extraction;Image reconstruction;Convolution;Deconvolution","climatology;feature extraction;geophysical image processing;image reconstruction;image resolution;image sampling;weather forecasting","climate image datasets;high-resolution climate images;ResLap;convolutional neural network;high-quality reconstruction;single image super-resolution;spatial downscaling method;low spatial resolution climate data;high-resolution regional climate forecasts;Laplacian pyramid super-resolution network;upsampling image reconstruction;high-resolution climate prediction;residual dense block;LapSRN;China Meteorological Administration","","13","","35","CCBY","18 Feb 2020","","","IEEE","IEEE Journals"
"ISTA-Net Model-driven Deep Unfolding Network for Hyperspectral and Multispectral Image Fusion","X. Wang; Q. Zhu; N. Qi","Beijing University of Technology, China; Beijing University of Technology, China; Beijing University of Technology, China","2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)","3 Aug 2022","2022","10","","1208","1212","Hyperspectral images (HSI) with high spatial and spectral resolutions have many applications in astronautics, re-mote sensing, and so on. However, it is challenging to obtain HSI with existing imaging techniques due to hardware limitations. In most cases, high-resolution multispectral (HrMS) images or low-resolution hyperspectral (LrHS) images are obtained. Therefore, the fusion of HrMS images and LrHS images for HSI super-resolution has attracted widespread attention. In this paper, we propose a network denoted as a model-based deep unfolding net-work(DuFNet) for hyperspectral image super-resolution (HSSR) task with clear interpretability. Specifically, we integrate the ISTA-Net into a well-established fusion network that is MHF-Net to fully take advantage of the generalization of the ISTA-Net. Experimental results demonstrate that the proposed NAM-DuFNet outperforms existing state-of-the-art methods in terms of subjective and objective results.","2693-2865","978-1-6654-2207-9","10.1109/ITAIC54216.2022.9836742","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9836742","Hyperspectral;super-resolution;interpretability;fusion network","Superresolution;Optimization methods;Imaging;Iterative algorithms;Sensors;Task analysis;Spatial resolution","geophysical image processing;hyperspectral imaging;image fusion;image resolution;remote sensing","hyperspectral image fusion;multispectral image fusion;high-spatial resolutions;spectral resolutions;remote sensing;hardware limitations;high-resolution multispectral images;low-resolution hyperspectral images;HrMS images;LrHS images;HSI super-resolution;hyperspectral image super-resolution task;MHF-Net;HSSR task;NAM-DuFNet;ISTA-net model-driven deep unfolding network","","","","13","IEEE","3 Aug 2022","","","IEEE","IEEE Conferences"
"Multiframe Video Satellite Image Super-Resolution via Attention-Based Residual Learning","Z. He; J. Li; L. Liu; D. He; M. Xiao","Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), Guangdong Provincial Key Laboratory of Urbanization and Geo-Simulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), Guangdong Provincial Key Laboratory of Urbanization and Geo-Simulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Department of Geography, University of Cincinnati (UC), Cincinnati, OH, USA; City College of Dongguan University of Technology, Dongguan, China; Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), Guangdong Provincial Key Laboratory of Urbanization and Geo-Simulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China","IEEE Transactions on Geoscience and Remote Sensing","4 Jan 2022","2022","60","","1","15","Video satellite can generate video image sequences with rich dynamic information, thus providing a new way for monitoring moving objects. However, to maintain high temporal resolution, video satellite images usually sacrifice their spatial resolution. Therefore, super-resolution (SR) plays a vital role in improving the quality of video satellite images. In this article, we propose a multiframe video SR neural network (MVSRnet) for video satellite image SR reconstruction. The proposed MVSRnet consists of three main subnetworks: an optical flow estimation subnetwork (OFEnet), an upscaling subnetwork (Upnet) and an attention-based residual learning subnetwork (ARLnet). The OFEnet aims to estimate low-resolution (LR) optical flow of multiple image frames. Upnet is then constructed to enhance the resolution of both input frames and the estimated LR optical flows. Motion compensation is subsequently performed according to the high-resolution (HR) optical flows. Finally, the compensated HR cube is fed to the ARLnet to generate SR results. Different from existing video satellite image SR methods, the proposed MVSRnet is a multiframe-based method with an attention mechanism, which can merge the motion information among adjacent frames and highlight the importance of extracted features. Experiments conducted on Jilin-1 and OVS-1 video satellite images demonstrate that the proposed MVSRnet significantly outperforms some state-of-the-art SR methods.","1558-0644","","10.1109/TGRS.2021.3072381","National Key Research and Development Program of China(grant numbers:2020YFA0714103,2018YFB0505503,2017YFC1502706); Innovation Group Project of Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai)(grant numbers:311021018); National Key Laboratory of Science and Technology on Automatic Target Recognition(grant numbers:WDZC20205500205); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2019A1515011877); Fundamental Research Funds for the Central Universities(grant numbers:19lgzd10); Guangzhou Science and Technology Planning Project(grant numbers:202002030240); Key-Area Research and Development Program of Guangdong Province(grant numbers:2020B0202010002); 2018 Key Research Platforms and Research Projects of Ordinary Universities in GuangDong Province(grant numbers:2018KQNCX360); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442915","Attention;multiframe super-resolution (SR);optical flow estimation;remote sensing;residual learning;video satellite","Satellites;Optical imaging;Satellite broadcasting;Optical sensors;Spatial resolution;Image reconstruction;Convolution","feature extraction;geophysical image processing;image reconstruction;image resolution;image sequences;learning (artificial intelligence);motion compensation;neural nets;video signal processing","video image sequences;high temporal resolution;spatial resolution;multiframe video SR neural network;MVSRnet;video satellite image SR reconstruction;attention-based residual learning subnetwork;low-resolution optical flow;image frames;high-resolution optical flows;video satellite image SR methods;OVS-1 video satellite images;multiframe video satellite image superresolution;OFEnet;upscaling subnetwork;Upnet;ARLnet;motion compensation;feature extraction;Jilin-1 video satellite images;LR optical flow estimation;HR cube compensation","","4","","53","IEEE","27 May 2021","","","IEEE","IEEE Journals"
"Forward-Looking Angular Super-Resolution for Moving Radar Platform with Complex Deconvolution","Y. Wu; Y. Zhang; D. Mao; Y. Huang; J. Yang","University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","6484","6487","The conventional deconvolution approaches which just rely on amplitude information behave worse when the radar platform speed is fast, and the approaches which just use the doppler phase caused by the platform moving can't achieve forward-looking imaging. To achieve forward-looking angular super-resolution for moving radar platform, in this paper, a complex deconvolution method which utilizes both amplitude and doppler phase information is proposed. The complex convolution matrix is constructed through the corresponding relation between the amplitude and doppler phase. The truncated singular value decomposition (TSVD) method is applied to suppress noise amplification to achieve deconvolution. Simulations demonstrate that the proposed method can achieve forward-looking angular super-resolution for moving radar platform.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518152","forward-looking imaging;complex deconvolution;amplitude;doppler phase;TSVD","Convolution;Radar imaging;Deconvolution;Image resolution;Mathematical model;Signal resolution","deconvolution;Doppler radar;image motion analysis;image resolution;radar imaging;singular value decomposition","moving radar platform;truncated singular value decomposition method;TSVD method;noise amplification;complex convolution matrix;complex deconvolution method;doppler phase;radar platform speed;amplitude information;conventional deconvolution approaches;forward-looking angular super-resolution","","3","","5","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"A Pixel Level Scaled Fusion Model to Provide High Spatial-Spectral Resolution for Satellite Images Using LSTM Networks","C. A. Theran; M. A. Álvarez; E. Arzuaga; H. Sierra","Laboratory for Applied Remote Sensing, Imaging and Photonics, University of Puerto Rico Mayaguez; Laboratory for Applied Remote Sensing, Imaging and Photonics, University of Puerto Rico Mayaguez; Laboratory for Applied Remote Sensing, Imaging and Photonics, University of Puerto Rico Mayaguez; Laboratory for Applied Remote Sensing, Imaging and Photonics, University of Puerto Rico Mayaguez","2019 10th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","5 Dec 2019","2019","","","1","5","Pixel-level fusion of satellite images coming from multiple sensors allows for an improvement in the quality of the acquired data both spatially and spectrally. In particular, multispectral and hyperspectral images have been fused to generate images with a high spatial and spectral resolution. In literature, there are several approaches for this task, nonetheless, those techniques still present a loss of relevant spatial information during the fusion process. This work presents a multi scale deep learning model to fuse multispectral and hyperspectral data, each with high-spatial-and-low-spectral resolution (HSaLS) and low-spatial-and-high-spectral resolution (LSaHS) respectively. As a result of the fusion scheme, a high-spatial-and-spectral resolution image (HSaHS) can be obtained. In order of accomplishing this result, we have developed a new scalable high spatial resolution process in which the model learns how to transition from low spatial resolution to an intermediate spatial resolution level and finally to the high spatial-spectral resolution image. This step-by-step process reduces significantly the loss of spatial information. The results of our approach show better performance in terms of both the structural similarity index and the signal to noise ratio.","2158-6276","978-1-7281-5294-3","10.1109/WHISPERS.2019.8921269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8921269","Data Fusion;Long Short Term Memory;Pixel level;Super resolution;hyperspectral image;multispectral image","Spatial resolution;Hyperspectral imaging;Image sensors;Sensors;Signal resolution","image classification;image fusion;image resolution;learning (artificial intelligence);object detection","pixel level scaled fusion model;satellite images;pixel-level fusion;multispectral images;hyperspectral images;spatial information;fusion process;multiscale deep learning model;multispectral data;hyperspectral data;high-spatial-and-low-spectral resolution;fusion scheme;high-spatial- resolution image;scalable high spatial resolution process;low spatial resolution;intermediate spatial resolution level;spatial-spectral resolution image;high spatial-spectral resolution;signal to noise ratio;structural similarity index","","6","","12","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Learning Deep Resonant Prior for Hyperspectral Image Super-Resolution","Z. Gong; N. Wang; D. Cheng; X. Jiang; J. Xin; X. Yang; X. Gao","State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Transactions on Geoscience and Remote Sensing","7 Jul 2022","2022","60","","1","14","The hyperspectral image super-resolution (HSISR) task has been widely studied, and significant progress has been made by leveraging the deep convolution neural network (CNN) techniques. Nevertheless, the scarcity of training images hinders the research progress of the HSISR task. Moreover, the differences in imaging conditions and the number of spectral bands among different datasets make it very difficult to construct a unified deep neural network. In this article, we first present a nontraining-based HSISR method based on deep prior knowledge, which captures the image before restoring the high-resolution image by using the intrinsic characteristics of CNN. Then, we append a special network input processing module (IPM) onto the HSISR network to automatically adjust the structure of the input so that the choice of network structure is no longer limited, while the network design focuses on exploiting the spatial information of hyperspectral images (HSIs) and the correlation between spectral bands, making the method more suitable for HSISR tasks and greatly extending its applications. Extensive experimental results on the HSI datasets illustrate the effectiveness of the proposed method, and we have got comparable results with the state-of-the-art methods while requiring no training samples.","1558-0644","","10.1109/TGRS.2022.3185647","National Key Research and Development Program of China(grant numbers:2018AAA0103202); National Natural Science Foundation of China(grant numbers:61922066,61876142,62036007,62176198,62176195,61976166); Technology Innovation Leading Program of Shaanxi(grant numbers:2022QFY01-15); Open Research Projects of Zhejiang Laboratory(grant numbers:2021KG0AB01); Key Research and Development Program of Shaanxi(grant numbers:2021GY-030,2022JQ-682); Fundamental Research Funds for the Central Universities(grant numbers:JB210115,XJS220119); Innovation Fund of Xidian University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9804845","Deep convolutional neural network (DCNN);hyperspectral remote sensing;image super-resolution","Superresolution;Task analysis;Hyperspectral imaging;Electronics packaging;Convolutional neural networks;Correlation;Spatial resolution","convolutional neural nets;deep learning (artificial intelligence);hyperspectral imaging;image resolution;image restoration","hyperspectral image superresolution;deep convolution neural network;HSISR task;spectral bands;unified deep neural network;nontraining-based HSISR method;deep prior knowledge;high-resolution image restoration;HSISR network;network structure;network design;deep resonant prior learning;deep CNN;network input processing module;spatial information","","","","43","IEEE","23 Jun 2022","","","IEEE","IEEE Journals"
"Bayesian fusion of multispectral and panchromatic images","G. Khademi; H. Ghassemian","Image Processing and Information Analysis Lab., Tarbiat Modares University, Tehran, Iran; Image Processing and Information Analysis Lab., Tarbiat Modares University, Tehran, Iran","2017 10th Iranian Conference on Machine Vision and Image Processing (MVIP)","23 Apr 2018","2017","","","20","25","In this paper, a model-based pansharpening method based on the super-resolution (SR) paradigm is developed. The spatial and spectral relationships between the desired high resolution multispectral (MS) image and the observed low resolution MS and panchromatic (Pan) images are combined with an appropriate image prior model via Bayesian theory. Maximum a posteriori (MAP) estimation is employed to convert the inverse problem of restoring the desired MS image into a constrained optimization problem. The final desired MS image is obtained by the conjugate gradient (CG) algorithm. Experimental results on two datasets show the effectiveness of the proposed method compared to the well-known pansharpening methods according to the quantitative evaluation metrics and visual inspection.","2166-6784","978-1-5386-4405-8","10.1109/IranianMVIP.2017.8342363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8342363","Image fusion;maximum a posteriori (MAP) estimation;pansharpening;remote sensing;super-resolution (SR)","Spatial resolution;Sensors;Bayes methods;Estimation;Probability density function","Bayes methods;geophysical image processing;image fusion;image resolution;inverse problems;remote sensing","well-known pansharpening methods;final desired MS image;constrained optimization problem;inverse problem;maximum a posteriori estimation;Bayesian theory;appropriate image prior model;observed low resolution MS;desired high resolution multispectral image;spectral relationships;spatial relationships;super-resolution paradigm;panchromatic images;multispectral images;Bayesian fusion","","7","","32","IEEE","23 Apr 2018","","","IEEE","IEEE Conferences"
"Real-World DEM Super-Resolution Based on Generative Adversarial Networks for Improving InSAR Topographic Phase Simulation","Z. Wu; Z. Zhao; P. Ma; B. Huang","Institute of Space and Earth Information Science, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Institute of Space and Earth Information Science, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Shenzhen Research Institute, The Chinese University of Hong Kong, Shenzhen, China; Institute of Space and Earth Information Science, The Chinese University of Hong Kong, Hong Kong, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","3 Sep 2021","2021","14","","8373","8385","Topographic phase simulation is important for deformation estimation in differential synthetic aperture radar (SAR) interferometry. The most commonly used 30 m resolution shuttle radar topography mission (SRTM) digital elevation model (DEM) is usually required to be resampled due to its relatively low resolution (LR) comparing to the high resolution (HR) SAR images. Although the WorldDEM with a 12 m resolution achieves global coverage, it is not available freely. Consequently, it is useful to evaluate the practicability of the super-resolution (SR) from LR SRTM DEMs to HR WorldDEM ones, which has not been investigated. Most existing DEM SR models are trained with synthetic datasets in which the LR DEMs are downsampled from their HR counterparts. However, these models become less effective when applied to real-world scenarios due to the domain gap between the synthetic and real LR DEMs. In this article, we constructed a real-world DEM SR dataset, where the LR and HR DEMs were collected from SRTM and WorldDEM, respectively. An enhanced SR generative adversarial network model was adapted to train on the dataset. Considering that the real LR-HR pairs may suffer from misalignment, we introduced the perceptual loss for better optimizing the model. Moreover, a logarithmic normalization was proposed to compress the wide elevation range and adjust the uneven distribution. We also pretrained the model using natural images since collecting sufficient HR DEMs is costly. Experiments demonstrate that the proposed method achieves near 0.69 dB improvement of peak signal-to-noise ratio. In addition, our method is also validated to improve the topographic phase simulation by 23.42% of MSE.","2151-1535","","10.1109/JSTARS.2021.3105123","National Natural Science Foundation of China(grant numbers:41971278); Research Grants Council of Hong Kong(grant numbers:CUHK14504219,CUHK14206818,AoE/E-603/18); National Key R&D Program of China(grant numbers:2019YFC1510400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516888","Deep learning;digital elevation model;generative adversarial network;InSAR topographic phase simulation;super resolution (SR)","Generative adversarial networks;Synthetic aperture radar;Adaptation models;Training;Superresolution;Earth;Satellites","digital elevation models;geophysical image processing;image resolution;radar imaging;radar interferometry;remote sensing by radar;synthetic aperture radar;topography (Earth)","synthetic datasets;LR DEMs;real-world DEM;SR dataset;enhanced SR generative adversarial network model;LR-HR pairs;world DEM super-resolution;generative adversarial networks;improving InSAR topographic phase simulation;deformation estimation;differential synthetic aperture radar interferometry;relatively low resolution comparing;high resolution SAR images;LR SRTM DEMs;HR WorldDEM ones;DEM SR models;30 m resolution shuttle radar topography mission digital elevation model;HR DEMs","","5","","54","CCBY","18 Aug 2021","","","IEEE","IEEE Journals"
"Pan-Sharpen Multispectral Images Using Sparse Representation","P. -H. Hsu; H. -L. Kuo","Department of Civil Engineering, National Taiwan University; Department of Civil Engineering, National Taiwan University","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","5143","5146","Pan-sharpening is an image fusion technique of synthesizing a high-resolution multispectral image from a low-resolution multispectral image and a high-resolution panchromatic image. In this paper, a novel pan-sharpening method for remote sensing images has been proposed with sparse representation over learned dictionaries. In the proposed method, the dictionaries are learned only from the high-resolution panchromatic image via the joint learning algorithm, instead of learning from the high-resolution multispectral image which are not available in practice. The sparse coefficients of the panchromatic image and low-resolution panchromatic image are calculated by the orthogonal matching pursuit algorithm. Then, the fused high-resolution multispectral image can be constructed by combining the obtained sparse coefficients and the high-resolution dictionary. The experiment results indicate that the proposed method not only preserve spectral and spatial details of the source images but overcoming the drawbacks of fusion distortion.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8519099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519099","Pan-sharpening;super resolution;sparse representation;dictionary learning;regularization","Dictionaries;Machine learning;Image reconstruction;Matching pursuit algorithms;Spatial resolution;Principal component analysis","geophysical image processing;geophysical techniques;image fusion;image representation;image resolution;remote sensing","sparse representation;image fusion technique;high-resolution multispectral image;low-resolution multispectral image;high-resolution panchromatic image;pan-sharpening method;remote sensing images;sparse coefficients;low-resolution panchromatic image;high-resolution dictionary;source images;pan-sharpen multispectral images;learned dictionaries;joint learning algorithm;orthogonal matching pursuit algorithm","","2","","7","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Adaptive Norm Selection for Regularized Image Restoration and Super-Resolution","H. Shen; L. Peng; L. Yue; Q. Yuan; L. Zhang","Collaborative Innovation Center of Geospatial Technology, Wuhan, China; School of Resource and Environmental Sciences, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan, China; School of Resource and Environmental Sciences, Wuhan University, Wuhan, China; Collaborative Innovation Center of Geospatial Technology, Wuhan, China","IEEE Transactions on Cybernetics","20 May 2017","2016","46","6","1388","1399","In the commonly employed regularization models of image restoration and super-resolution (SR), the norm determination is often challenging. This paper proposes a method to adaptively determine the optimal norms for both fidelity term and regularization term in the (SR) restoration model. Inspired by a generalized likelihood ratio test, a piecewise function is proposed to solve the norm of the fidelity term. This function can find the stable norm value in a certain number of iterations, regardless of whether the noise type is Gaussian, impulse, or mixed. For the regularization norm, the main advantage of the proposed method is that it is locally adaptive. Specifically, it assigns different norms for different pixel locations, according to the local activity measured by a structure tensor metric. The proposed method was tested using different types of images. The experimental results and error analyses verify the efficacy of the method.","2168-2275","","10.1109/TCYB.2015.2446755","National Natural Science Foundation of China(grant numbers:41422108); National Major Basic Research Development Program of China (973 Program)(grant numbers:2011CB707103); Program for Changjiang Scholars and Innovative Research Team in University(grant numbers:IRT1278); Hubei Natural Science Foundation(grant numbers:2011CDA096); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163577","Adaptive norm selection;image restoration;super-resolution (SR);Adaptive norm selection;image restoration;super-resolution (SR)","Image restoration;Noise;Image edge detection;Standards;Adaptation models;Tensile stress;TV","feature selection;Gaussian noise;image resolution;image restoration;impulse noise;iterative methods;tensors","adaptive norm selection;image restoration;image superresolution;SR;regularization model;piecewise function;iteration process;Gaussian noise;impulse noise;structure tensor metric","","44","","51","IEEE","21 Jul 2015","","","IEEE","IEEE Journals"
"SelfS2: Self-Supervised Transfer Learning for Sentinel-2 Multispectral Image Super-Resolution","X. Qian; T. -X. Jiang; X. -L. Zhao","Kash Institute of Electronics and Information Industry, Kashgar, China; Kash Institute of Electronics and Information Industry, Kashgar, China; Research Center for Image and Vision Computing, School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","7 Dec 2022","2023","16","","215","227","The multispectral image captured by the Sentinel-2 satellite contains 13 spectral bands with different resolutions, which may hider some of the subsequent applications. In this article, we design a novel method to super-resolve 20- and 60-m coarse bands of the S2 images to 10 m, achieving a complete dataset at the 10-m resolution. To tackle this inverse problem, we leverage the deep image prior expressed by the convolution neural network (CNN). Specifically, a plain ResNet architecture is adopted, and the 3-D separable convolution is utilized to better capture the spatial–spectral features. The loss function is tailored based on the degradation model, enforcing the network output obeying the degradation process. Meanwhile, a network parameter initialization strategy is designed to further mine the abundant fine information provided by existing 10-m bands. The network parameters are inferred solely from the observed S2 image in a self-supervised manner without involving any extra training data. Finally, the network outputs the super-resolution result. On the one hand, our method could utilize the high model capacity of CNNs and work without large amounts of training data required by many deep learning techniques. On the other hand, the degradation process is fully considered, and each module in our work is interpretable. Numerical results on synthetic and real data illustrate that our method could outperform compared state-of-the-art methods.","2151-1535","","10.1109/JSTARS.2022.3224987","National Natural Science Foundation of China(grant numbers:12001446,61876203,12171072); Natural Science Foundation of Sichuan, China(grant numbers:2022NSFSC1798,2022NSFSC0507); Applied Basic Research Project of Sichuan Province(grant numbers:2021YJ0107); Key Project of Applied Basic Research in Sichuan Province(grant numbers:2020YJ0216); National Key Research and Development Program of China(grant numbers:2020YFA0714001); Sichuan Science and Technology Project(grant numbers:2021ZYD0021); Fundamental Research Funds for the Central Universities; Guanghua Talent Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9964200","Deep image prior;self-supervised learning;Sentinel-2 satellite;separable 3-D convolution;super-resolution","Spatial resolution;Superresolution;Degradation;Tensors;Training data;Satellite broadcasting;Pansharpening","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;geophysical techniques;image resolution;inverse problems;remote sensing","3-D separable convolution;CNN;coarse bands;convolution neural network;deep image prior;deep learning techniques;degradation process;inverse problem;loss function;network parameter initialization strategy;observed S2 image;ResNet architecture;self-supervised transfer learning;SelfS2;Sentinel-2 multispectral image super-resolution;Sentinel-2 satellite;spatial-spectral features;spectral bands","","1","","63","CCBY","28 Nov 2022","","","IEEE","IEEE Journals"
"Super-Resolution-Aided Sea Ice Concentration Estimation From AMSR2 Images by Encoder–Decoder Networks With Atrous Convolution","T. Feng; X. Liu; R. Li","Center for Spatial Information Science and Sustainable Development Applications, College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; Center for Spatial Information Science and Sustainable Development Applications, College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; Center for Spatial Information Science and Sustainable Development Applications, College of Surveying and Geo-Informatics, Tongji University, Shanghai, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","9 Jan 2023","2023","16","","962","973","Passive microwave data is an important data source for the continuous monitoring of Arctic-wide sea ice concentration (SIC). However, its coarse spatial resolution leads to blurring effects at the ice-water divides, resulting in the great challenges of fine-scale and accurate SIC estimation, especially for regions with low SIC. Besides, the SIC derived by operational algorithms using high-frequency passive microwave observations has great uncertainties in open water or marginal ice zones due to atmospheric effects. In this article, a novel framework is proposed to achieve accurately SIC estimation with improved spatial details from original low-resolution Advanced Microwave Scanning Radiometer 2 (AMSR2) images, with joint the super-resolution (SR) and SIC estimation network. Based on the SR network, the spatial resolution of original AMSR2 images can be improved by four times, benefiting to construct AMSR2 SR features with more high-frequency information for SIC estimation. The SIC network with an encoder–decoder structure and atrous convolution, is employed to accurately perform the SIC retrieval by considering the characteristics of passive microwave images in the Arctic sea ice region. Experimental results show that the proposed SR-Aided SIC estimation approach can generate accurate SIC with more detailed sea ice textures and much sharper sea ice edges. With respect to MODIS SIC products distributed in Arctic scale, the proposed model achieves a root-mean-square error (RMSE) of 5.94% and mean absolute error (MAE) of 3.04%, whereas the Arctic Radiation and Turbulence Interaction Study (ARTIST) Sea Ice (ASI) SIC results have three and two times greater values of RMSE and MAE.","2151-1535","","10.1109/JSTARS.2022.3232533","National Key Research and Development Program of China(grant numbers:2017YFA0603100,2021YFB3900105); National Natural Science Foundation of China(grant numbers:41801335,41941006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9999481","Arctic sea ice concentration;convolutional neural networks;passive microwave image;super resolution","Spatial resolution;Estimation;Sea ice;Microwave integrated circuits;Microwave imaging;Microwave FET integrated circuits;Microwave theory and techniques","edge detection;geophysical image processing;image resolution;mean square error methods;microwave imaging;oceanographic regions;oceanographic techniques;radiometry;remote sensing;sea ice","AMSR2 SR features;Arctic scale;Arctic sea ice region;Arctic-wide sea ice concentration;atrous convolution;blurring effects;coarse spatial resolution;encoder-decoder networks;encoder-decoder structure;high-frequency information;high-frequency passive microwave observations;ice-water divides;low-resolution Advanced Microwave Scanning Radiometer 2 images;MODIS SIC products;open water;original AMSR2 images;passive microwave data;passive microwave images;sea ice edges;sea ice textures;SIC network;SIC retrieval;spatial details;SR network;SR-Aided SIC estimation approach;super-resolution-Aided Sea Ice concentration estimation;Turbulence Interaction Study Sea Ice SIC results","","","","30","CCBYNCND","27 Dec 2022","","","IEEE","IEEE Journals"
"A CNN-Based Sentinel-2 Image Super-Resolution Method Using Multiobjective Training","V. Vasilescu; M. Datcu; D. Faur","Speech and Dialogue Laboratory and the Center for Spatial Information, University Politehnica of Bucharest, Bucharest, Romania; Center for Spatial Information, University Politehnica of Bucharest, Bucharest, Romania; Center for Spatial Information, University Politehnica of Bucharest, Bucharest, Romania","IEEE Transactions on Geoscience and Remote Sensing","9 Feb 2023","2023","61","","1","14","Deep learning methods have become ubiquitous tools in many Earth observation applications, delivering state-of-the-art results while proving to generalize for a variety of scenarios. One such domain concerns the Sentinel-2 (S2) satellite mission, which provides multispectral images in the form of 13 spectral bands, captured at three different spatial resolutions: 10, 20, and 60 m. This research aims to provide a super-resolution mechanism based on fully convolutional neural networks (CNNs) for upsampling the low-resolution (LR) spectral bands of S2 up to 10-m spatial resolution. Our approach is centered on attaining good performance with respect to two main properties: consistency and synthesis. While the synthesis evaluation, also known as Wald’s protocol, has spoken for the performance of almost all previously introduced methods, the consistency property has been overlooked as a viable evaluation procedure. Recently introduced techniques make use of sensor’s modulation transfer function (MTF) to learn an approximate inverse mapping from LR to high-resolution images, which is on a direct path for achieving a good consistency value. To this end, we propose a multiobjective loss for training our architectures, including an MTF-based mechanism, a direct input–output mapping using synthetically degraded data, along with direct similarity measures between high-frequency details from already available 10-m bands, and super-resolved images. Experiments indicate that our method is able to achieve a good tradeoff between consistency and synthesis properties, along with competitive visual quality results.","1558-0644","","10.1109/TGRS.2023.3240296","CENTURION-H2020-SPACE-2018-2020–“Copernicus Datacube and AI Services for Society, Industry and New Market Generation”; EUROPEAN COMMISSION; European Health and Digital Executive Agency(grant numbers:101004311); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10026840","Consistency;convolutional neural networks (CNNs);Sentinel-2 (S2);super-resolution;synthesis","Spatial resolution;Superresolution;Training;Neural networks;Monitoring;Degradation;Optimization","","","","","","46","CCBY","27 Jan 2023","","","IEEE","IEEE Journals"
"Multi-target super-resolution using compressive sensing arguments for multipath interference recovery","V. N. Xuan; K. Hartmann; W. Weihs; O. Loffeld","Center for Sensorsystems, University of Siegen, Siegen, Germany; Center for Sensorsystems, University of Siegen, Siegen, Germany; Center for Sensorsystems, University of Siegen, Siegen, Germany; Center for Sensorsystems, University of Siegen, Siegen, Germany","2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing (CoSeRa)","17 Nov 2016","2016","","","148","152","The multipath interference (MPI) adds noises to the time-of-flight (TOF) measurements and then causes depth estimation inaccuracy. This paper combines multi-frequency TOF (MFT) acquisition and compressive sensing (CS) approaches to reconstruct the multipath reflections. Mismatch model and depth resolution problems will be analyzed to achieve a good measurement accuracy with a high probability.","","978-1-5090-2920-4","10.1109/CoSeRa.2016.7745718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745718","super-resolution;compressed sensing;time-of-light;multi-frequency;multipath","Frequency measurement;Compressed sensing;Noise measurement;Signal resolution;Correlation;Image reconstruction;Cameras","compressed sensing;estimation theory;image reconstruction;image resolution;interference (signal);object detection","multitarget superresolution;compressive sensing;multipath interference recovery;MPI;time-of-flight measurements;TOF measurements;multifrequency TOF;MFT;depth estimation inaccuracy","","3","","10","IEEE","17 Nov 2016","","","IEEE","IEEE Conferences"
"One new method on image super-resolution reconstruction","L. Zhang; X. Wang; C. Li; Q. Li; X. Li","College of Computer and Information Engineering, Hohai University, Nanjing, China; College of Computer and Information Engineering, Hohai University, Nanjing, China; College of Computer and Information Engineering, Hohai University, Nanjing, China; College of Computer and Information Engineering, Hohai University, Nanjing, China; College of Computer and Information Engineering, Changzhou Institute of Technology, Changzhou, China","2015 IEEE International Conference on Information and Automation","1 Oct 2015","2015","","","79","82","According to the image quality degradation in super-resolution reconstruction, we present a new algorithm for a single image super-resolution reconstruction to improve the image resolution. Considering the limitations that the extracted features of low-resolution image can not adapt to image direction changes, we propose a new feature-extracted method, and we build a new global optimization framework with analysis sparse prior based on the multiple extracted features, joint dictionary learning. Experiments show the effectiveness of our method.","","978-1-4673-9104-7","10.1109/ICInfA.2015.7279262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7279262","resolution reconstruction;sparse representation;multi-features extraction;sparse prior","Image reconstruction;Image resolution;Feature extraction;Dictionaries;Filter banks;Joints;Remote sensing","feature extraction;image reconstruction;image resolution;learning (artificial intelligence);optimisation","image quality degradation;single image super-resolution reconstruction;extracted features;low-resolution image;image direction changes;feature-extracted method;global optimization framework;joint dictionary learning","","1","","17","IEEE","1 Oct 2015","","","IEEE","IEEE Conferences"
"Super-Resolution reconstruction for terahertz pulsed imaging","X. Lin; Z. Zhang; J. Zhang","Beijing Institute of Space Mechanics and Electricity, Beijing, China; Beijing Institute of Space Mechanics and Electricity, Beijing, China; Shanghai Institute of Applied Physics, Chinese Academy of Sciences, Shanghai, China","2017 42nd International Conference on Infrared, Millimeter, and Terahertz Waves (IRMMW-THz)","16 Oct 2017","2017","","","1","2","Terahertz technology is one of emerging technologies that has a potential to change our life. There is considerable interest in using electromagnetic terahertz pulses for imaging purposes. In this paper we presented initial results for improving the resolution of terahertz pulsed imaging system utilizing methodology of super-resolution reconstruction. We attempt to reconstruct an super-resolution(SR) reconstruction terahertz image from four subpixel-shifted low resolution(LR) terahertz images acquired under the same experimental condition via the THz-TDS system. The experimental results are analyzed and discussed. It was shown in laboratory experiments that SR has good effect of reconstructing a SR terahertz image from multi-frame LR.","2162-2035","978-1-5090-6050-4","10.1109/IRMMW-THz.2017.8067254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8067254","","Imaging;Image reconstruction;Spatial resolution;Signal resolution;Remote sensing;Detectors","biological techniques;biology computing;image reconstruction;image resolution;terahertz wave imaging","terahertz technology;electromagnetic terahertz pulses;super-resolution reconstruction;SR terahertz image;terahertz pulsed imaging;subpixel-shifted low resolution terahertz images;multiframe LR","","1","","7","IEEE","16 Oct 2017","","","IEEE","IEEE Conferences"
"Through-the-Wall Radar Super-Resolution Imaging Based on Cascade U-Net","S. Huang; J. Qian; Y. Wang; X. Yang; L. Yang","School of Resources and Environment, UESTC, Chengdu, China; School of Resources and Environment, UESTC, Chengdu, China; School of Resources and Environment, UESTC, Chengdu, China; School of Information and Communication Engineering, UESTC, Chengdu, China; College of Electronic Information and Automation, Civil Aviation University of China, Tianjin, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2933","2936","High-resolution radar imaging will give us detailed information of target, which becomes basic function of radar systems. Improvement of image resolution of the existing radar system is also important. Based on deep learning, a new method for super-resolution through-the-radar imaging is proposed. A network, called cascade U-net (CU-net), is proposed in this paper. The results of simulation and real data experiments demonstrate the effectiveness of our methods.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900569","Through-the-wall radar imaging;Deep learning","Radar imaging;Deep learning;Transmitters;Receivers","image resolution;learning (artificial intelligence);radar computing;radar imaging;radar resolution","image resolution;CU-net;high-resolution radar imaging;through-the-wall radar super-resolution imaging;cascade U-net;deep learning","","2","","6","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Spectral Super-Resolution Using Hybrid 2D-3D Structure Tensor Attention Networks with Camera Spectral Sensitivity Prior","C. Wu; J. Li; R. Song; Y. Li","School of Telecommunications Engineering, Xidian University, China; School of Telecommunications Engineering, Xidian University, China; School of Telecommunications Engineering, Xidian University, China; School of Telecommunications Engineering, Xidian University, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1857","1860","With the development of deep convolutional neural networks (CNNs), spectral super-resolution (SSR) has obtained a significant improvement, which aims to recover the hyperspectral image (HSI) from a single RGB. However, the existing mapping algorithms lack of utilization of the camera spectral sensitivity (CSS) and only focus on wider or deeper architecture design, neglecting to explore the feature correlations of intermediate layers, thus preventing the representational ability of CNNs. In our paper, a novel hybrid 2D-3D structure tensor attention networks (HSTAN) with CSS prior is proposed for SSR. In specific, a structure tensor attention (STA) embedded in the residual block is invented to extract the salient high-frequency spatial details for adequate spatial feature expression. Furthermore, the CSS is firstly exploited as a prior to avoid its influence of SSR quality, based on which the reconstructed RGB can be calculated naturally through the super-resolved HSI, then the final loss incorporates the discrepancies of RGB and the HSI as a finer constraint. Experimental results demonstrate the superiority of our proposed algorithm.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323553","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323553","SSR;HSTAN;structure tensor attention;camera spectral sensitivity prior","Tensors;Image reconstruction;Cascading style sheets;Feature extraction;Superresolution;Hyperspectral imaging;Correlation","cameras;geophysical image processing;image colour analysis;image reconstruction;image resolution;tensors","single RGB;camera spectral sensitivity;CSS;structure tensor attention;salient high-frequency spatial details;SSR quality;spectral super-resolution;spatial feature expression;HSTAN;hybrid 2D-3D structure tensor attention networks;STA;superresolved HSI;RGB;hyperspectral imaging","","1","","10","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Combined based on minimum distance orthogonal matching pursuit method for support recovery improvement in super-resolution compressed sensing","V. N. Xuan; K. Hartmann; W. Weihs; O. Loffeld","Center for Sensorsystems, University of Siegen, Siegen, Germany; Center for Sensorsystems, University of Siegen, Siegen, Germany; Center for Sensorsystems, University of Siegen, Siegen, Germany; Center for Sensorsystems, University of Siegen, Siegen, Germany","2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing (CoSeRa)","17 Nov 2016","2016","","","257","261","This paper introduces a new scenario, named combined based on minimum distance orthogonal matching pursuit (CMD-OMP) which utilizes the strength of two available recovery methods at different ranges of minimum distance. Particularly, OMP with a global optimization and non-negative constrained least square algorithm (a MATLAB function implemented as OMP with a modification step) will be studied comparatively and then interacted together to improve signal support recovery performance in super-resolution compressed sensing.","","978-1-5090-2920-4","10.1109/CoSeRa.2016.7745740","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745740","","Matching pursuit algorithms;Signal resolution;Sensors;Spatial resolution;Compressed sensing;Optimization","compressed sensing;image resolution;least squares approximations","minimum distance orthogonal matching pursuit method;support recovery improvement;super resolution compressed sensing;CMD-OMP;nonnegative constrained least square algorithm;MATLAB function","","","","8","IEEE","17 Nov 2016","","","IEEE","IEEE Conferences"
"A Variational Approach with Nonlocal Self-Similarity and Joint-Sparsity for Hyperspectral Image Super-Resolution","T. Xu; T. -Z. Huang; Y. Chen; J. Huang; L. -J. Deng","School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Computer and Information Engineering, Jiangxi Normal University, Nanchang, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2444","2447","The aim of hyperspectral image super-resolution (HSI-SR) is to produce high spatial resolution hyperspectral image (HR - HSI) by exploiting the available high spatial resolution multispectral image (HR-MSI) and low spatial resolution hyperspectral image (LR-HSI). In this work, we develop a novel matrix factorization (MF)-based HSI -SR way, which formulates the HSI -SR problem as estimating the spectral dictionary from the observed LR - HSI and the coefficient matrix from both the observed HR-MSI and LR-HSI. Specifically, we first estimate the spectral dictionary from the observed LR - HSI by the dictionary learning algorithm with redundancy assumption. Moreover, based on the superpixel segmentation technology used in the observed HR-MSI, the coefficient vectors are grouped. By concatenating the joint-sparse, nonlocallow-rank, and nonnegative priors of the grouped coefficient vectors, we develop a novel coefficient matrix estimation variational model, which fully explores the nonlocal self-similarity of the desired HR-HSI. The proposed coefficient matrix estimation model is solved under the alternating direction method of multipliers (ADMM) framework. Experimental results prove the superiority of the proposed way from the quantitative and qualitative analysis.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554815","NSFC(grant numbers:61772003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554815","Hyperspectral image fusion;joint-sparsity;nonlocal self-similarity;spectral unmixing","Dictionaries;Image color analysis;Superresolution;Redundancy;Estimation;Machine learning;Convex functions","geophysical image processing;hyperspectral imaging;image representation;image resolution;image segmentation;matrix algebra;matrix decomposition","high spatial resolution hyperspectral image;HR - HSI;available high spatial resolution multispectral image;low spatial resolution hyperspectral image;novel matrix factorization-based HSI -SR way;HSI -SR problem;spectral dictionary;observed LR - HSI;observed HR-MSI;LR-HSI;novel coefficient matrix estimation variational model;nonlocal self-similarity;desired HR-HSI;coefficient matrix estimation model;hyperspectral image super-resolution;HSI-SR","","","","14","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Super-Resolution Method of Forward Scanning Radar Based on Weibull Distribution","J. Shen; Y. Zhang; X. Tuo; H. Yang; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2047","2050","To address scanning radar forward-looking sea imaging, this paper proposed a super-resolution method based on Weibull distribution. The proposed method in our work introduced the generalized Gaussian distribution and Weibull distribution to represent the prior distribution of the target and the sea clutter respectively, which are more suitable for actual sea imaging. And the corresponding objective function was derived under the MAP framework. In order to overcome the objective function's nonlinearity, this paper adopt Newton-Raphson iterative method to resolve it. Finally, through simulations, which indicates that the proposed method has superior imaging performance compared with other traditional methods for sea imaging.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883106","National Natural Science Foundation of China(grant numbers:61901090,61671117,61901092); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883106","Radar forward-looking imaging;generalized Gaussian distribution;Weibull distribution","Simulation;Superresolution;Imaging;Radar;Radar imaging;Gaussian distribution;Linear programming","Gaussian distribution;image representation;image resolution;iterative methods;Newton method;Newton-Raphson method;radar clutter;radar imaging;Weibull distribution","super-resolution method;Weibull distribution;generalized Gaussian distribution;sea clutter;actual sea imaging;corresponding objective function;forward scanning radar","","","","9","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Spectral Super-Resolution for Multispectral Image Based on Spectral and Spatial Strategies","C. Yi; Y. -Q. Zhao; J. C. -W. Chan","Research & Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen, China; Research & Development Institute of Northwestern Polytechnical University in Shenzhen, Shenzhen, China; Department of Electronics and Informatics, Vrije Universiteit Brussel, Brussel, Belgium","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","851","854","A spectral super-resolution method is proposed in this paper to recover a high spectral resolution hyperspectral (HS) image from multispectral (MS) images. The proposed method involves spectral improvement strategy and spatial preservation strategy. For spectral improvement strategy, auxiliary MS/HS image pairs of different landscapes are exploited to estimate spectral response relationship so that a HS image is obtained as an intermediate result. Then, spectral dictionary learning is exploited to recover more accurate spectral reconstruction result. Spatial preservation strategy is used as spatial constraint to ensure spatial consistency. Additionally, low rank property of HS image is also introduced to make use of global spectral coherence among HS bands. Experiments are conducted on real MS/HS data (ALI and Hyperion) captured by EO-1 satellite. Experiment results demonstrate the superiority of our proposed method to other state-of-art methods.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898630","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898630","Hyperspectral image;Spectral resolution enhancement;Spectral dictionary;Low rank","Spatial resolution;Image reconstruction;Hyperspectral imaging;Machine learning;Dictionaries;Distortion","geophysical image processing;geophysical techniques;hyperspectral imaging;image reconstruction;image resolution","spectral improvement strategy;spatial preservation strategy;spectral response relationship;spectral dictionary learning;accurate spectral reconstruction result;spatial constraint;spatial consistency;global spectral coherence;HS bands;multispectral image;spectral strategies;spatial strategies;spectral super-resolution method;high spectral resolution hyperspectral image;auxiliary MS/HS image pairs;EO-1 satellite","","","","10","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Two-Step Dimension Reduction Strategy for Real-Aperture Radar Fast Super-Resolution Imaging","X. Tuo; D. Mao; Y. Zhang; M. Feng; Y. Zhang; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Geoscience and Remote Sensing Letters","20 Jul 2022","2022","19","","1","5","For real-aperture radar, its azimuth resolution is much coarser than the range resolution after pulse compression, super-resolution algorithms are desired to enhance its azimuth resolution. However, the super-resolution algorithms must require enough azimuth sampling to ensure their performance. When wide scanning scope or dense azimuth sampling, the amount of data will increase significantly, which brings a large computational burden to super-resolution processing. To cover this problem, we propose a two-step dimension reduction strategy. First, by using linear sketching technology, the high-dimensional matrices are projected to the low-dimensional space, thus accelerating the matrix–matrix multiplications in super-resolution algorithms. Second, exploiting Sherman–Morrison formula, we further realized the acceleration of the matrix inversion in super-resolution algorithms. The proposed two-step acceleration strategy in our work is applicable to the existing deconvolution super-resolution algorithms, including regularization methods and Bayesian methods. It can be verified by simulation and experimental data that the proposed accelerated algorithms have advantages in computing time without losing the quality of super-resolution imaging.","1558-0571","","10.1109/LGRS.2022.3188704","National Natural Science Foundation of China(grant numbers:61901090,61901092); China Postdoctoral Science Foundation(grant numbers:BX20220055); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815325","Acceleration strategy;linear sketching (LS);real-aperture radar (RAR)","Azimuth;Antenna measurements;Superresolution;Signal resolution;Radar imaging;Imaging;Radar antennas","Bayes methods;image resolution;matrix inversion;matrix multiplication;radar imaging","two-step dimension reduction strategy;real-aperture radar fast super-resolution imaging;azimuth resolution;range resolution;deconvolution super-resolution algorithms;azimuth sampling;high-dimensional matrices;Bayesian method;Sherman-Morrison formula;matrix inversion;matrix-matrix multiplications","","1","","11","IEEE","5 Jul 2022","","","IEEE","IEEE Journals"
"Short Range SAR Imaging for 2D Micro-Deformation Detection","Z. Shao; X. Zhang; J. Ren; Y. Li","School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; CAS, National Space Science Center, Beijing, China","2018 IEEE International Symposium on Antennas and Propagation & USNC/URSI National Radio Science Meeting","13 Jan 2019","2018","","","569","570","With the development of modern remote sensing techniques, high stability and super-resolution detection abilities are required to obtain an excellent performance in micro-deformation monitoring regions, such as civil architectures monitoring, disaster alarming and environment monitoring. A portable synthetic aperture radar (SAR) system based on interference technique and phase inversing technique is proposed and utilized for 2-D micro-deformation monitoring in this paper. Experiments are constructed to verify that the system can preciously and accurately get the micro-deformation in range direction and azimuth directions.","1947-1491","978-1-5386-7102-3","10.1109/APUSNCURSINRSM.2018.8608216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8608216","Micro-deformation;SAR;Super-resolution;Interferometry","Synthetic aperture radar;Monitoring;Azimuth;Strain;Imaging;Radar imaging;Image resolution","deformation;image resolution;radar imaging;remote sensing by radar;synthetic aperture radar","microdeformation monitoring regions;civil architectures monitoring;disaster alarming;environment monitoring;portable synthetic aperture radar system;interference technique;phase inversing technique;short range SAR imaging;modern remote sensing techniques;super-resolution detection abilities;2D microdeformation detection","","","","9","IEEE","13 Jan 2019","","","IEEE","IEEE Conferences"
"A Comparative Study of Loss Functions for Hyperspectral SISR","N. Aburaed; M. Q. Alkhatib; S. Marshall; J. Zabalza; H. A. Ahmad","Department of Electronic and Electrical Engineering, University of Strathclyde, UK; College of Engineering and IT, University of Dubai, UAE; Department of Electronic and Electrical Engineering, University of Strathclyde, UK; Department of Electronic and Electrical Engineering, University of Strathclyde, UK; College of Engineering and IT, University of Dubai, UAE","2022 30th European Signal Processing Conference (EUSIPCO)","18 Oct 2022","2022","","","484","487","The spatial enhancement of Hyperspectral Imagery (HSI) is a popular research area among the community of image processing in general and remote sensing in particular. HSI contribute to a wide variety of industrial applications, such as Land Cover Land Use. The characterstic that distinguishes HSI from other type of images is the ability to uniquely describe objects with spectral signatures. This can be achieved due to the sensor's ability to capture reflectance in narrowly spaced wavelength bands, which yields an HSI cube with hundreds of bands. However, this ability compromises the spatial resolution of HSI, which must be improved for practicality and usability. There are several studies in the literature related to HSI Super Resolution (HSI-SR), especially using Convolutional Neural Networks (CNNs). Nonetheless, the investigation of the most suitable loss functions to train these networks is necessary and remains as an area to investigate. This paper conducts a comparative study of the most widely used loss functions and their effect on one of the state-of-the-art HSI-SR CNNs, mainly 3D-SRCNN. The paper also proposes a hybrid loss function based on the comparative results, and proves its superiority against other loss functions in terms of Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index Measurement (SSIM), and Spectral Angle Mapper (SAM).","2076-1465","978-90-827970-9-1","10.23919/EUSIPCO55093.2022.9909827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9909827","Hyperspectral;Super Resolution;CNN;3D SR-CNN;Loss Function","Reflectivity;PSNR;Image processing;Europe;Loss measurement;Indexes;Spatial resolution","geophysical image processing;hyperspectral imaging;image classification;image processing;image reconstruction;image resolution;learning (artificial intelligence);neural nets;remote sensing","suitable loss;loss functions;state-of-the-art HSI-SR CNNs;hybrid loss function;Hyperspectral SISR;spatial enhancement;Hyperspectral Imagery;popular research area;image processing;general sensing;remote sensing;industrial applications;Land Cover Land Use;distinguishes HSI;narrowly spaced wavelength bands;HSI cube;spatial resolution;HSI Super Resolution;Convolutional Neural Networks","","","","23","","18 Oct 2022","","","IEEE","IEEE Conferences"
"Super-Resolution Mapping Based on Spatial–Spectral Correlation for Spectral Imagery","P. Wang; L. Wang; H. Leung; G. Zhang","Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, Heilongjiang, China; Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada; Key Laboratory of Radar Imaging and Microwave Photonics, Ministry of Education, Nanjing University of Aeronautics and Astronautics, Nanjing, China","IEEE Transactions on Geoscience and Remote Sensing","24 Feb 2021","2021","59","3","2256","2268","Due to the influences of imaging conditions, spectral imagery can be coarse and contain a large number of mixed pixels. These mixed pixels can lead to inaccuracies in the land-cover class (LC) mapping. Super-resolution mapping (SRM) can be used to analyze such mixed pixels and obtain the LC mapping information at the subpixel level. However, traditional SRM methods mostly rely on spatial correlation based on linear distance, which ignores the influences of nonlinear imaging conditions. In addition, spectral unmixing errors affect the accuracy of utilized spectral properties. In order to overcome the influence of linear and nonlinear imaging conditions and utilize more accurate spectral properties, the SRM based on spatial-spectral correlation (SSC) is proposed in this work. Spatial correlation is obtained using the mixed spatial attraction model (MSAM) based on the linear Euclidean distance. Besides, a spectral correlation that utilizes spectral properties based on the nonlinear Kullback-Leibler distance (KLD) is proposed. Spatial and spectral correlations are combined to reduce the influences of linear and nonlinear imaging conditions, which results in an improved mapping result. The utilized spectral properties are extracted directly by spectral imagery, thus avoiding the spectral unmixing errors. Experimental results on the three spectral images show that the proposed SSC yields better mapping results than state-of-the-art methods.","1558-0644","","10.1109/TGRS.2020.3004353","National Natural Science Foundation of China(grant numbers:61801211,61871218,61675051); China Postdoctoral Science Foundation(grant numbers:2019M651824); Open Project Program of the State Key Laboratory of CAD&CG(grant numbers:A2011); Zhejiang University, Open Fund of Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University(grant numbers:2019MIP006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9130890","Kullback–Leibler distance (KLD);mixed spatial attraction model (MSAM);spatial–spectral correlation (SSC);spectral imagery;super-resolution mapping (SRM)","Correlation;Imaging;Euclidean distance;Optimization;Resource management;Probability density function","geophysical image processing;geophysical techniques;image classification;image resolution;terrain mapping","super-resolution mapping;spatial-spectral correlation;spectral imagery;land-cover class mapping;LC mapping information;traditional SRM methods;spatial correlation;linear distance;nonlinear imaging conditions;spectral unmixing errors;utilized spectral properties;accurate spectral properties;mixed spatial attraction model;linear Euclidean distance;spatial correlations;spectral correlations;spectral images;nonlinear Kullback-Leibler distance","","82","","50","IEEE","1 Jul 2020","","","IEEE","IEEE Journals"
"Exploring the Relationship Between 2D/3D Convolution for Hyperspectral Image Super-Resolution","Q. Li; Q. Wang; X. Li","School of Computer Science and the Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi’an, China; School of Computer Science and the Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi’an, China; School of Computer Science and the Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","24 Sep 2021","2021","59","10","8693","8703","Hyperspectral image super-resolution (SR) methods based on deep learning have achieved significant progress recently. However, previous methods lack the joint analysis between spectrum and horizontal or vertical direction. Besides, when both 2D and 3D convolution are in the network, the existing models cannot effectively combine the two. To address these issues, in this article, we propose a novel hyperspectral image SR method by exploring the relationship between 2D/3D convolution (ERCSR). Our method alternately employs 2D and 3D units to solve the problem of structural redundancy by sharing spatial information during reconstruction for existing model, which can enhance the learning ability of 2D spatial domain. Importantly, compared with the network using 3D units, i.e., 2D units are replaced by 3D units, it can not only reduce the size of the model but also improve the performance of the model. Furthermore, to exploit the spectrum fully, the split adjacent spatial and spectral convolution (SAEC) is designed to parallelly explore information between spectrum and horizontal or vertical direction in space. Experiments on widely used benchmark datasets demonstrate that the proposed approach outperforms state-of-the-art SR algorithms across different scales in terms of quantitative and qualitative analysis.","1558-0644","","10.1109/TGRS.2020.3047363","National Key R&D Program of China(grant numbers:2018YFB1107403); National Natural Science Foundation of China(grant numbers:U1864204,61773316,U1801262,61871470); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9334383","Convolutional neural networks (CNNs);hybrid convolution;hyperspectral image;split adjacent spatial and spectral convolution (SAEC);super-resolution (SR)","Three-dimensional displays;Convolution;Hyperspectral imaging;Two dimensional displays;Image reconstruction;Solid modeling;Feature extraction","convolution;image reconstruction;image representation;image resolution;learning (artificial intelligence)","vertical direction;hyperspectral image super-resolution methods;deep learning;horizontal direction;hyperspectral image SR method;2D spatial domain;split adjacent spatial and spectral convolution;SR algorithm;quantitative analysis;qualitative analysis","","39","","41","IEEE","22 Jan 2021","","","IEEE","IEEE Journals"
"Hyperspectral Image Super-Resolution via Intrafusion Network","J. Hu; X. Jia; Y. Li; G. He; M. Zhao","Shaanxi Key Laboratory for Network Computing and Security Technology, School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; School of Engineering and Information Technology, University of New South Wales, Canberra, Australia; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; Shaanxi Key Laboratory for Network Computing and Security Technology, School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","24 Sep 2020","2020","58","10","7459","7471","This article presents an intrafusion network (IFN) for hyperspectral image (HSI) super-resolution (SR). Given that the HSI is a 3-D data cube with both the spatial information and the spectral information, the key challenge to construct HSI SR is how to efficiently exploit the spectral information among consecutive low-resolution (LR) bands, besides the spatial information. The proposed IFN consists of three modules, including the spectral difference module, the parallel convolution module, and the intrafusion module, which directly utilizes both the spatial information and the spectral information for reconstructing the high-resolution HSI. Different from most of the existed methods that tackle the spatial and spectral information separately, the proposed spatial-spectral utilization is achieved in one integrated network, which opens up a new way for HSI SR. Meanwhile, applications of this three modules strategy (first spectral difference, then parallel convolution, and finally, intrafusion) on both the conventional convolutional neural network and the residual network with deeper depth have shown the generalization capacity of this proposal. Experimental results and data analysis demonstrate the effectiveness of the proposed method using three hyperspectral data sets.","1558-0644","","10.1109/TGRS.2020.2982940","National Natural Science Foundation of China(grant numbers:61901362); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2019JQ-729); Shaanxi Provincial Department of Education Fund(grant numbers:19JK0585); Ph.D. Research Startup Foundation of the Xi’an University of Technology(grant numbers:112/256081809); National Natural Science Foundation of China(grant numbers:U1704130); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9057496","Hyperspectral image (HIS);intrafusion;spectral difference;super-resolution (SR)","Spatial resolution;Convolution;Image reconstruction;Hyperspectral imaging;Convolutional neural networks","convolutional neural nets;data analysis;geophysical image processing;hyperspectral imaging;image representation;image resolution;neural nets","hyperspectral image super-resolution;3-D data cube;spatial information;spectral information;HSI SR;low-resolution bands;IFN;spectral difference module;parallel convolution module;intrafusion module;high-resolution HSI;spatial-spectral utilization;integrated network;residual network;hyperspectral data sets;intrafusion network","","31","","31","IEEE","6 Apr 2020","","","IEEE","IEEE Journals"
"Hybrid 2-D–3-D Deep Residual Attentional Network With Structure Tensor Constraints for Spectral Super-Resolution of RGB Images","J. Li; C. Wu; R. Song; W. Xie; C. Ge; B. Li; Y. Li","CAS Key Laboratory of Spectral Imaging Technology, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","24 Feb 2021","2021","59","3","2321","2335","RGB image spectral super-resolution (SSR) is a challenging task due to its serious ill-posedness, which aims at recovering a hyperspectral image (HSI) from a corresponding RGB image. In this article, we propose a novel hybrid 2-D-3-D deep residual attentional network (HDRAN) with structure tensor constraints, which can take fully advantage of the spatial-spectral context information in the reconstruction progress. Previous works improve the SSR performance only through stacking more layers to catch local spatial correlation neglecting the differences and interdependences among features, especially band features; different from them, our novel method focuses on the context information utilization. First, the proposed HDRAN consists of a 2D-RAN following by a 3D-RAN, where the 2D-RAN mainly focuses on extracting abundant spatial features, whereas the 3D-RAN mainly simulates the interband correlations. Then, we introduce 2-D channel attention and 3-D band attention mechanisms into the 2D-RAN and 3D-RAN, respectively, to adaptively recalibrate channelwise and bandwise feature responses for enhancing context features. Besides, since structure tensor represents structure and spatial information, we apply structure tensor constraint to further reconstruct more accurate high-frequency details during the training process. Experimental results demonstrate that our proposed method achieves the state-of-the-art performance in terms of mean relative absolute error (MRAE) and root mean square error (RMSE) on both the “clean” and “real world” tracks in the NTIRE 2018 Spectral Reconstruction Challenge. As for competitive ranking metric MRAE, our method separately achieves a 16.06% and 2.90% relative reduction on two tracks over the first place. Furthermore, we investigate HDRAN on the other two HSI benchmarks noted as the CAVE and Harvard data sets, also demonstrating better results than state-of-the-art methods.","1558-0644","","10.1109/TGRS.2020.3004934","National Key Research and Development Program of China(grant numbers:2018AAA0102702); National Nature Science Foundation of China(grant numbers:61901343); China Postdoctoral Science Foundation(grant numbers:2017M623124); China Postdoctoral Science Special Foundation(grant numbers:2018T111019); Open Research Fund of the CAS Key Laboratory of Spectral Imaging Technology(grant numbers:LSIT201924W); Fundamental Research Funds for the Central Universities(grant numbers:JB190107); National Nature Science Foundation of China(grant numbers:61571345,61671383,91538101,61501346,61502367); Higher Education Discipline Innovation Project(grant numbers:B08038); National Key Research and Development Program of China; Key Research and Development Program of Shaanxi Province(grant numbers:2017KJXX-50); National Defense Key Laboratory of China(grant numbers:6142411184413); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9133131","Attention mechanism;hybrid 2-D–3-D deep residual attentional network (HDRAN);spatial–spectral context information;spectral super-resolution (SSR);structure tensor","Hyperspectral imaging;Image reconstruction;Feature extraction;Spatial resolution;Tensors;Correlation","feature extraction;geophysical image processing;hyperspectral imaging;image colour analysis;image reconstruction;image resolution;mean square error methods;spectral analysis;tensors","structure tensor constraint;Spectral super-resolution;hyperspectral image;corresponding RGB image;novel hybrid 2-D-3-D deep residual attentional network;HDRAN;spatial-spectral context information;local spatial correlation;band features;context information utilization;2D-RAN;3D-RAN;abundant spatial features;2-D channel attention;3-D band attention mechanisms;channelwise;bandwise feature responses;context features;spatial information;NTIRE 2018 Spectral Reconstruction Challenge;2.90% relative reduction","","21","","58","IEEE","3 Jul 2020","","","IEEE","IEEE Journals"
"Satellite Video Super-Resolution Based on Adaptively Spatiotemporal Neighbors and Nonlocal Similarity Regularization","H. Liu; Y. Gu; T. Wang; S. Li","School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; Key Laboratory of Space Utilization, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","24 Nov 2020","2020","58","12","8372","8383","Recently, super-resolution (SR) of satellite videos has received increasing attention as it can overcome the limitation of spatial resolution in applications of satellite videos to dynamic analysis. The low quality of satellite videos presents big challenges to the development of the spatial SR techniques, e.g., accurate motion estimation and motion compensation for multiframe SR. Therefore, reasonable image priors in maximum a posteriori (MAP) framework, where motion information among adjacent frames is involved, are needed to regularize the solution space and generate the corresponding high-resolution frames. In this article, an effective satellite video SR framework based on locally spatiotemporal neighbors and nonlocal similarity modeling is proposed. Firstly, local prior knowledge is represented by means of adaptively exploiting spatiotemporal neighbors. In this way, implicitly local motion information can be captured without explicit motion estimation. Secondly, the nonlocal spatial similarity is integrated into the proposed SR framework to enhance texture details. Finally, the locally spatiotemporal regularization and nonlocal similarity modeling bring out a complex optimization problem, which is solved via the iterated reweighted least squares in the proposed SR framework. The videos from the Jilin-1 satellite and the OVS-1A satellite are used for evaluating the proposed method. Experimental results show that the proposed method demonstrates better SR performance in preserving edges and texture details compared with the-state-of-art video SR methods.","1558-0644","","10.1109/TGRS.2020.2987400","National Natural Science Foundation of Key International Cooperation(grant numbers:61720106002); National Science Foundation for Excellent Young Scholars(grant numbers:61522107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9080534","Adaptively spatiotemporal neighbors;implicit motion estimation;maximum a posteriori (MAP);nonlocal similarity;satellite video;super-resolution (SR)","Satellites;Motion estimation;Spatiotemporal phenomena;Adaptation models;Image reconstruction;Degradation;Image edge detection","artificial satellites;image resolution;image texture;iterative methods;motion compensation;motion estimation;spatiotemporal phenomena;video signal processing","adaptively spatiotemporal neighbors;nonlocal similarity regularization;satellite videos;spatial resolution;motion estimation;motion compensation;multiframe SR;high-resolution frames;nonlocal similarity modeling;nonlocal spatial similarity;spatiotemporal regularization;Jilin-1 satellite;video SR methods;satellite video super-resolution;satellite video SR framework;maximum a posteriori framework","","17","","53","IEEE","28 Apr 2020","","","IEEE","IEEE Journals"
"Spectral Super-Resolution of Multispectral Images Using Spatial–Spectral Residual Attention Network","X. Zheng; W. Chen; X. Lu","Key Laboratory of Spectral Imaging Technology CAS, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, Shaanxi, China; University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Spectral Imaging Technology CAS, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, Shaanxi, China","IEEE Transactions on Geoscience and Remote Sensing","26 Jan 2022","2022","60","","1","14","The spectral super-resolution of multispectral image (MSI) refers to improving the spectral resolution of the MSI to obtain the hyperspectral image (HSI). Most recent works are based on the sparse representation to unfold the MSI into the 2-D matrix in advance for subsequent operations, which results in that the spatial information of MSI cannot be fully explored. In this article, a spatial–spectral residual attention network (SSRAN) is proposed to simultaneously explore the spatial and spectral information of MSI for reconstructing the HSI. The proposed SSRAN is composed of the feature extraction part, the nonlinear mapping part, and the reconstruction part. Firstly, the multispectral features of the input MSI are extracted in the feature extraction part. Second, in the nonlinear mapping part, the spatial–spectral residual blocks are proposed to explore spatial and spectral information of MSI for mapping the multispectral features to the hyperspectral features. Finally, in the reconstruction part, a 2-D convolution is used to reconstruct the HSI from the hyperspectral features. Also, a neighboring spectral attention module is specially designed to explicitly constrain the reconstructed HSI to maintain the correlation among neighboring spectral bands. The proposed SSRAN outperforms the state-of-the-art methods on both simulated and real databases.","1558-0644","","10.1109/TGRS.2021.3104476","National Science Fund for Distinguished Young Scholars(grant numbers:61925112); National Natural Science Foundation of China(grant numbers:61806193,61772510); Innovation Capability Support Program of Shaanxi(grant numbers:2020KJXX-091,2020TD-015); Key Research and Development Program of Shaanxi(grant numbers:2020ZDLGY04-03); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9519844","Attention;convolutional neural networks;hyperspectral image (HSI);multispectral image (MSI);spatial–spectral features;spectral super-resolution","Feature extraction;Image reconstruction;Task analysis;Hyperspectral imaging;Dictionaries;Superresolution;Convolution","feature extraction;geophysical image processing;geophysical signal processing;image classification;image representation;image resolution;spectral analysis","spectral super-resolution;multispectral image;spatial-spectral residual attention network;spectral resolution;hyperspectral image;spatial information;SSRAN;spectral information;feature extraction part;nonlinear mapping part;reconstruction part;multispectral features;input MSI;spatial-spectral residual blocks;hyperspectral features;neighboring spectral attention module;reconstructed HSI;spectral bands","","11","","49","IEEE","20 Aug 2021","","","IEEE","IEEE Journals"
"Multitask Learning for Super-Resolution of Seismic Velocity Model","Y. Li; J. Song; W. Lu; P. Monkam; Y. Ao","Department of Automation, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China; Geophysical Department, Research Institute of Petroleum Exploration and Development, China National Petroleum Corporation (CNPC), Beijing, China; Department of Automation, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China; Department of Automation, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China; Department of Automation, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","27 Aug 2021","2021","59","9","8022","8033","Full waveform inversion (FWI) is a powerful tool for estimating the underground velocity model. However, it is computationally expensive and the resulting models tend to be not accurate enough. Thus, to improve the efficiency and accuracy of FWI, we propose a super-resolution (SR) method based on deep learning to enhance the resolution of the seismic velocity model. Since the edge images of the seismic velocity model are also widely used in geophysics, a multitask learning (MTL) network with hard parameter sharing is applied to perform the SR of the seismic velocity model and its edge images. The proposed MTL model dubbed M-RUDSR includes a global residual skip connection, an encoder-decoder structure of U-Net, and a dense skip connection structure. Besides, two networks for comparison, namely, RUDSR and M-RUSR, are proffered. RUDSR is a single-task version of M-RUDSR, whereas M-RUSR is a simplified version of M-RUDSR without a dense skip connection structure. Compared with RUDSR and M-RUSR, M-RUDSR produced the best results for all kinds of blurring levels and achieved better visual details. We found that FWI followed by SR can help reduce the computational cost of FWI in the high-frequency part of the spectrum, as well as achieve better high-frequency details recovery. The experimental results show that M-RUDSR is a practical recovery scheme in SR of the seismic velocity model and can be applied to a real data set efficiently.","1558-0644","","10.1109/TGRS.2020.3034502","National Key Research and Development Program of China(grant numbers:2018YFA0702501); Key State Science and Technology Project(grant numbers:2016ZX05024001-005); NSFC(grant numbers:41974126,41674116); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250617","Deep learning;edge image;multitask learning (MTL);seismic velocity model;super-resolution (SR)","Task analysis;Image edge detection;Computational modeling;Deep learning;Convolution;Correlation","deep learning (artificial intelligence);geophysical image processing;geophysical techniques;seismic waves;seismology;waveform analysis","seismic velocity model;FWI;underground velocity model;super-resolution method;multitask learning network;MTL model;M-RUDSR;dense skip connection structure;RUDSR;U-Net encoder-decoder structure;residual skip connection;hard parameter sharing;edge images;deep learning;full waveform inversion","","11","","60","IEEE","6 Nov 2020","","","IEEE","IEEE Journals"
"Hyperspectral Super-Resolution via Global–Local Low-Rank Matrix Estimation","R. Wu; W. -K. Ma; X. Fu; Q. Li","Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, USA; Peng Cheng Laboratory, Shenzhen, China","IEEE Transactions on Geoscience and Remote Sensing","24 Sep 2020","2020","58","10","7125","7140","Hyperspectral super-resolution (HSR) is a problem that aims to estimate an image of high spectral and spatial resolutions from a pair of coregistered multispectral (MS) and hyperspectral (HS) images, which have coarser spectral and spatial resolutions, respectively. In this article, we pursue a lowrank matrix estimation approach for HSR. We assume that the spectral-spatial matrices associated with the whole image and the local areas of the image have low-rank structures. The local low-rank assumption, in particular, has the aim of providing a more flexible model for accounting for local variation effects due to endmember variability. We formulate the HSR problem as a global-local rank-regularized least-squares problem. By leveraging on the recent advances in nonconvex large-scale optimization, namely the smooth Schatten-p approximation and the accelerated majorization-minimization method, we develop an efficient algorithm for the global-local low-rank problem. Numerical experiments on synthetic, semi-real, and real data show that the proposed algorithm outperforms a number of benchmark algorithms in terms of recovery performance.","1558-0644","","10.1109/TGRS.2020.2979908","Shun Hing Institute of Advanced Engineering, The Chinese University of Hong Kong(grant numbers:#MMT-8115059); National Science Foundation(grant numbers:NSF ECCS 1608961,NSF ECCS 1808159); Army Research Office(grant numbers:ARO W911NF-19-1-0247); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9044632","Endmember variability (EV);hyperspectral (HS);hyperspectral super-resolution (HSR);low-rank matrix estimation","Spatial resolution;Estimation;Sensors;Dictionaries;Hyperspectral imaging;Optimization","convex programming;geophysical image processing;hyperspectral imaging;image resolution;least squares approximations;matrix decomposition;minimisation","hyperspectral super-resolution;spatial resolutions;spectral-spatial matrices;low-rank structures;low-rank assumption;local variation effects;HSR problem;global-local rank-regularized least-squares problem;low-rank problem;global-local low-rank matrix estimation;smooth Schatten-p approximation;accelerated majorization-minimization method","","10","","54","IEEE","23 Mar 2020","","","IEEE","IEEE Journals"
"A Unified Network for Arbitrary Scale Super-Resolution of Video Satellite Images","Z. He; D. He","Guangdong Provincial Key Laboratory of Urbanization and Geo-Simulation, Center of Integrated Geographic Information Analysis, Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; City College, Dongguan University of Technology, Dongguan, China","IEEE Transactions on Geoscience and Remote Sensing","24 Sep 2021","2021","59","10","8812","8825","Super-resolution (SR) has attracted increasing attention as it can improve the quality of video satellite images. Most previous studies only consider several integer magnification factors and focus on obtaining a specific SR model for each scale factor. However, in the real world, it is a common requirement to zoom the videos arbitrarily by rolling the mouse wheel. In this article, we propose a unified network for arbitrary scale SR (ASSR) of video satellite images. The proposed ASSR consists of two modules, i.e., feature learning module and arbitrary upscale module. The feature learning module accepts multiple low-resolution (LR) frames and extracts useful features of those frames by using many 3-D residual blocks. The arbitrary upscale module takes the extracted features as input and enhances the spatial resolution by subpixel convolution and bicubic-based adjustment. Different from existing video satellite image SR methods, ASSR can continuously zoom LR video satellite images with arbitrary integer and noninteger scale factors in a single model. Experiments have been conducted on real video satellite images acquired by Jilin-1 and OVS-1. Quantitative and qualitative results have demonstrated that ASSR has superior reconstruction performance compared with the state-of-the-art SR methods.","1558-0644","","10.1109/TGRS.2020.3038653","National Key Research and Development Program of China(grant numbers:2018YFB0505500,2018YFB0505503); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2019A1515011877); Fundamental Research Funds for the Central Universities(grant numbers:19lgzd10); Guangzhou Science and Technology Planning Project(grant numbers:202002030240); National Natural Science Foundation of China(grant numbers:41501368); Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai)(grant numbers:99147-42080011); 2018 Key Research Platforms and Research Projects of Ordinary Universities in Guangdong Province(grant numbers:2018KQNCX360); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277650","Arbitrary scale;deep learning;super-resolution (SR);video satellite","Satellites;Convolution;Feature extraction;Spatial resolution;Image reconstruction;Image edge detection;Training","image reconstruction;image resolution;learning (artificial intelligence);video signal processing","video satellite image SR methods;ASSR;LR video satellite images;noninteger scale factors;unified network;arbitrary scale super-resolution;specific SR model;scale factor;arbitrary scale SR;feature learning module;arbitrary upscale module;low-resolution frames","","6","","46","IEEE","2 Dec 2020","","","IEEE","IEEE Journals"
"Deep Learning for Simultaneous Seismic Image Super-Resolution and Denoising","J. Li; X. Wu; Z. Hu","School of Earth and Space Sciences, University of Science and Technology of China, Hefei, China; School of Earth and Space Sciences, University of Science and Technology of China, Hefei, China; School of Computer Science and OPTIMAL, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","6 Dec 2021","2022","60","","1","11","Seismic interpretation is often limited by low resolution and strong noise data. To deal with this issue, we propose to leverage deep convolutional neural network (CNN) to achieve seismic image super-resolution and denoising simultaneously. To train the CNN, we simulate a lot of synthetic seismic images with different resolutions and noise levels to serve as training data sets. To improve the perception quality, we use a loss function that combines the  $\ell _{1}$  loss and multiscale structural similarity loss. Extensive experimental results on both synthetic and field seismic images demonstrate that the proposed workflow can significantly improve the perception of quality of original data. Compared to conventional methods, the network obtains better performance in enhancing detailed structural and stratigraphic features, such as thin layers and small-scale faults. From the seismic images super-sampled by our CNN method, a fault detection method can compute more accurate fault maps than from the original seismic images.","1558-0644","","10.1109/TGRS.2021.3057857","National Science Foundation of China(grant numbers:41974121); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9364884","Deep learning;geophysical image processing;image denoising;super-resolution","Image resolution;Superresolution;Training data;Training;Noise reduction;Convolution;Computational modeling","convolutional neural nets;deep learning (artificial intelligence);fault diagnosis;geophysical image processing;image denoising;image enhancement;image resolution;seismology","simultaneous seismic image super-resolution;seismic interpretation;deep convolutional neural network;synthetic seismic images;perception quality;loss function;multiscale structural similarity loss;synthetic field seismic images;CNN method;fault detection method","","6","","31","IEEE","26 Feb 2021","","","IEEE","IEEE Journals"
"Integration of Super-Resolution ISAR Imaging and Fine Motion Compensation for Complex Maneuvering Ship Targets Under High Sea State","S. Shao; H. Liu; L. Zhang; P. Wang; J. Wei","National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; School of Electronics and Communication Engineering, Sun Yat-sen University, Guangzhou, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; School of Information Science and Technology, Northwest University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","18 Mar 2022","2022","60","","1","20","Under high sea state, ship targets make complex maneuvering motions due to strong disturbances such as sea waves and sea winds. Selecting the optimal imaging time interval to shorten the coherent processing interval (CPI) can reduce the complexity of motion errors, but the imaging resolution is affected as well, i.e., the motion error complexity and imaging resolution are constrained by each other. To address this problem, this article proposes a novel inverse synthetic aperture radar (ISAR) imaging framework for complex maneuvering ship targets to achieve the integration of super-resolution (SR) ISAR imaging and fine motion compensation (ISRFMC) under high sea state. With regard to the complex maneuvering motion of ship targets, we analyze the motion errors caused by the time-variant rotational velocity and imaging projection plane (IPP) on the echo signals, respectively, and a fine phase error model is established to uniformly represent the dual time-variant characteristic (DTVC) of complex maneuvering ship targets. Moreover, a deformed Akaike information criterion (DAIC) is developed to realize the adaptive selection of the phase error model with the image sharpness as the objective function. Underpinned by the Bayesian compressive sensing (BCS) theory, the SR ISAR imaging can be realized by solving a sparsity-driven optimization problem via a modified quasi-Newton solver. Particularly, the fine phase errors are constructed as the model errors of image reconstruction, and the particle swarm optimization algorithm (PSO) is utilized to solve the maximum image sharpness optimization problem in order to perform the joint fine motion compensation and azimuth scaling (JFMCAS). ISRFMC or the integration of SR ISAR imaging and fine motion compensation can be achieved through alternate iteration, so as to obtain well-focused and scaled high-resolution ISAR images of complex maneuvering ship targets under high sea state. Extensive experiments based on both simulated and real data verify that the proposed algorithm is capable of addressing the conflict between imaging resolution and motion error complexity under high sea state.","1558-0644","","10.1109/TGRS.2022.3147266","National Natural Science Foundation of China(grant numbers:62101407,61701379); Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project)(grant numbers:B18039); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9695466","Complex maneuvering ship targets;fine motion compensation;high sea state;inverse synthetic aperture radar (ISAR);super-resolution (SR) imaging","Imaging;Marine vehicles;Radar imaging;Motion compensation;Sea state;Complexity theory;Signal processing algorithms","Bayes methods;image reconstruction;image resolution;motion compensation;particle swarm optimisation;radar imaging;radar resolution;ships;synthetic aperture radar","super-resolution ISAR imaging;complex maneuvering ship targets;high sea state;complex maneuvering motion;optimal imaging time interval;motion error complexity;inverse synthetic aperture radar imaging framework;time-variant rotational velocity;imaging projection plane;fine phase error model;SR ISAR imaging;image reconstruction;maximum image sharpness optimization problem;joint fine motion compensation;particle swarm optimization algorithm","","2","","47","IEEE","27 Jan 2022","","","IEEE","IEEE Journals"
"An Iterative Regularization Method Based on Tensor Subspace Representation for Hyperspectral Image Super-Resolution","T. Xu; T. -Z. Huang; L. -J. Deng; N. Yokoya","Research Center for Image and Vision Computing, School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; Research Center for Image and Vision Computing, School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; Research Center for Image and Vision Computing, School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; RIKEN Center for Advanced Intelligence Project, Tokyo, Japan","IEEE Transactions on Geoscience and Remote Sensing","3 Jun 2022","2022","60","","1","16","Hyperspectral image super-resolution (HSI-SR) can be achieved by fusing a paired multispectral image (MSI) and hyperspectral image (HSI), which is a prevalent strategy. But, how to precisely reconstruct the high spatial resolution hyperspectral image (HR-HSI) by fusion technology is a challenging issue. In this article, we propose an iterative regularization method based on tensor subspace representation (IR-TenSR) for MSI-HSI fusion, thus HSI-SR. First, we propose a tensor subspace representation (TenSR)-based regularization model that integrates the global spectral–spatial low-rank and the nonlocal self-similarity priors of HR-HSI. These two priors have been proven effective, but previous HSI-SR works cannot simultaneously exploit them. Subsequently, we design an iterative regularization procedure to utilize the residual information of acquired low-resolution images, which are ignored in other works that produce suboptimal results. Finally, we develop an effective algorithm based on the proximal alternating minimization method to solve the TenSR-regularization model. With that, we obtain the iterative regularization algorithm. Experiments implemented on the simulated and real datasets illustrate the advantages of the proposed IR-TenSR compared with the state-of-the-art fusion approaches. The code is available at https://github.com/liangjiandeng/IR_TenSR.","1558-0644","","10.1109/TGRS.2022.3176266","National Natural Science Foundation of China(grant numbers:12171072,61702083); Key Projects of Applied Basic Research in Sichuan Province(grant numbers:2020YJ0216); National Key Research and Development Program of China(grant numbers:2020YFA0714001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9777947","Global spatial–spectral low-rank prior;hyperspectral image super-resolution;iterative regularization;nonlocal self-similarity;proximal alternating minimization;tensor subspace","Tensors;Correlation;Spatial resolution;Hyperspectral imaging;Task analysis;Superresolution;Iterative algorithms","geophysical image processing;hyperspectral imaging;image fusion;image reconstruction;image representation;image resolution;iterative methods;minimisation;tensors","hyperspectral image super-resolution;high spatial resolution hyperspectral image;HR-HSI;iterative regularization method;IR-TenSR;MSI-HSI fusion;tensor subspace representation-based regularization model;global spectral-spatial low-rank;previous HSI-SR works;iterative regularization procedure;acquired low-resolution images;proximal alternating minimization method;TenSR-regularization model;iterative regularization algorithm;paired multispectral image;fusion technology","","2","","74","IEEE","18 May 2022","","","IEEE","IEEE Journals"
"Enhancing Mid–Low-Resolution Ship Detection With High-Resolution Feature Distillation","S. He; H. Zou; Y. Wang; R. Li; F. Cheng; X. Cao; M. Li","College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China","IEEE Geoscience and Remote Sensing Letters","16 Dec 2021","2022","19","","1","5","To enhance mid–low-resolution ship detection, existing methods generally use image super-resolution (SR) as a preprocessing step and feed the super-resolved images to the detectors. However, these methods only use high-resolution (HR) images as ground-truth labels to supervise the training of their SR module but overlook the rich HR information in the detection stage. Inspired by the recent advances in knowledge distillation, in this letter, we design a feature distillation framework to fully exploit the information in ground-truth HR images to handle mid–low-resolution ship detection. Our framework consists of a student network and a teacher network. The student network first super-resolves input images using an SR module and then feeds the super-resolved images to the detection module. The teacher network whose architecture is the same as the student detection module directly takes HR images as input to generate HR feature representation and then distills these HR features to the student network through a distillation loss. Using our feature distillation framework, HR images are not only used as ground-truth labels to train the SR module but also provide “ground-truth” features to train the detection module, which enhances the detection performance of the student network. We apply our framework to several popular detectors, including FCOS, Faster-RCNN, Mask-RCNN, and Cascase-RCNN, and conduct extensive ablation studies to validate its effectiveness and generality. Experimental results on the HRSC2016, DOTA, and NWPU VHR-10 datasets demonstrate that, when applying our framework to Faster-RCNN, our method can outperform several state-of-the-art detection methods in terms of mAP50 and mAP75.","1558-0571","","10.1109/LGRS.2021.3110404","National Natural Science Foundation of China(grant numbers:62071474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9537901","Knowledge distillation (KD);mid–low-resolution images;remote sensing;ship detection;super-resolution (SR)","Feature extraction;Marine vehicles;Image resolution;Training;Detectors;Sorting;Remote sensing","convolutional neural nets;feature extraction;geophysical image processing;image classification;image representation;image resolution;object detection;recurrent neural nets;remote sensing;ships","mid-low-resolution ship detection;high-resolution feature distillation;image superresolution;high-resolution images;SR module;knowledge distillation;feature distillation framework;student network;teacher network;student detection module;ground-truth HR image;distillation loss;ground-truth features;HR feature representation;HRSC2016 dataset;DOTA dataset;NWPU VHR-10 dataset;faster-RCNN","","1","","27","CCBY","15 Sep 2021","","","IEEE","IEEE Journals"
"A MAP-Based Approach for Hyperspectral Imagery Super-Resolution","H. Irmak; G. B. Akar; S. E. Yuksel","Radar and Electronic Warfare Systems Business Sector (REHIS), ASELSAN Inc., Ankara, Turkey; Department of Electrical and Electronics Engineering, Middle East Techical University, Ankara, Turkey; Department of Electrical and Electronics Engineering, Hacettepe University, Ankara, Turkey","IEEE Transactions on Image Processing","27 Mar 2018","2018","27","6","2942","2951","In this paper, we propose a novel single image Bayesian super-resolution (SR) algorithm where the hyperspectral image (HSI) is the only source of information. The main contribution of the proposed approach is to convert the ill-posed SR reconstruction problem in the spectral domain to a quadratic optimization problem in the abundance map domain. In order to do so, Markov random field based energy minimization approach is proposed and proved that the solution is quadratic. The proposed approach consists of five main steps. First, the number of endmembers in the scene is determined using virtual dimensionality. Second, the endmembers and their low resolution abundance maps are computed using simplex identification via the splitted augmented Lagrangian and fully constrained least squares algorithms. Third, high resolution (HR) abundance maps are obtained using our proposed maximum a posteriori based energy function. This energy function is minimized subject to smoothness, unity, and boundary constraints. Fourth, the HR abundance maps are further enhanced with texture preserving methods. Finally, HR HSI is reconstructed using the extracted endmembers and the enhanced abundance maps. The proposed method is tested on three real HSI data sets; namely the Cave, Harvard, and Hyperspectral Remote Sensing Scenes and compared with state-of-the-art alternative methods using peak signal to noise ratio, structural similarity, spectral angle mapper, and relative dimensionless global error in synthesis metrics. It is shown that the proposed method outperforms the state of the art methods in terms of quality while preserving the spectral consistency.","1941-0042","","10.1109/TIP.2018.2814210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8310636","Hyperspectral image;super-resolution reconstruction;MAP Framework;quadratic programming","Hyperspectral imaging;Image reconstruction;Minimization;Spatial resolution;Bayes methods;Dictionaries","Bayes methods;geophysical image processing;hyperspectral imaging;image fusion;image reconstruction;image resolution;Markov processes;maximum likelihood estimation;minimisation;remote sensing","abundance map domain;Markov random field;energy minimization approach;virtual dimensionality;low resolution abundance maps;splitted augmented Lagrangian constrained least squares algorithms;fully constrained least squares algorithms;high resolution abundance maps;maximum a posteriori based energy function;HR abundance maps;texture preserving methods;HR HSI;extracted endmembers;enhanced abundance maps;HSI data sets;spectral angle mapper;spectral consistency;Hyperspectral imagery super-resolution;novel single image Bayesian super-resolution algorithm;hyperspectral image;SR reconstruction problem;spectral domain;quadratic optimization problem;HSI","","37","","57","IEEE","9 Mar 2018","","","IEEE","IEEE Journals"
"Optical Flow Reusing for High-Efficiency Space-Time Video Super Resolution","Y. Zhang; H. Wang; H. Zhu; Z. Chen","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, Hubei, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, Hubei, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, Hubei, China; Hubei Luojia Laboratory, Hubei, China","IEEE Transactions on Circuits and Systems for Video Technology","","2022","PP","99","1","1","In this paper, we consider the task of space-time video super-resolution (ST-VSR), which can increase the spatial resolution and frame rate for a given video simultaneously. Despite the remarkable progress of recent methods, most of them still suffer from high computational costs and inefficient long-range information usage. To alleviate these problems, we propose a Bidirectional Recurrence Network (BRN) with the optical-flow-reuse strategy to better use temporal knowledge from long-range neighboring frames for high-efficiency reconstruction. Specifically, an efficient and memory-saving multi-frame motion utilization strategy is proposed by reusing the intermediate flow of adjacent frames, which considerably reduces the computation burden of frame alignment compared with traditional LSTM-based designs. In addition, the proposed hidden state in BRN is updated by the reused optical flow and refined by the Feature Refinement Module (FRM) for further optimization. Moreover, by utilizing intermediate flow estimation, the proposed method can inference non-linear motion and restore details better. Extensive experiments demonstrate that our optical-flow-reuse-based bidirectional recurrent network (OFR-BRN) is superior to state-of-the-art methods in accuracy and efficiency. Codes are available on URL: https://github.com/hahazh/OFR-BRN.","1558-2205","","10.1109/TCSVT.2022.3222875","Hubei Luojia Laboratory; National Natural Science Foundation of China(grant numbers:62036005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9954319","Video Super-Resolution;Video Frame Interpolation;Optical Flow","Optical flow;Superresolution;Spatial resolution;Interpolation;Task analysis;Estimation;Convolution","","","","","","","IEEE","17 Nov 2022","","","IEEE","IEEE Early Access Articles"
"Mutual-Feed Learning for Super-Resolution and Object Detection in Degraded Aerial Imagery","J. Yang; K. Fu; Y. Wu; W. Diao; W. Dai; X. Sun","School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","23 Aug 2022","2022","60","","1","16","The resolution degradation poses a huge challenge for object detection (OD) in aerial imagery. The existing methods use super-resolution (SR) based on generative adversarial network (GAN) to restore texture details in degraded images. However, constrained detection results are still acquired due to object feature difference between restored and clear images. Therefore, we propose a simple yet effective learning method called mutual-feed learning (MFL) to solve the problem in this article. A closed-loop structure is designed via building the feedback connection based on the feedforward connection between the two tasks. It effectively delivers the object spatial and feature information from OD to SR and provides restoration-enhanced images from SR to OD. Specifically, a feedback of region of interest (FROI) module is introduced to realize a region-level discrimination under the guidance of object information. It guides the discrimination process of SR. Furthermore, a multiscale object information (MSOI) module is developed to implement a feature-level restoration by narrowing the differences in object-related features. It improves the generation process of SR. Then OD can be performed in restoration-enhanced images to obtain more accurate results. Extensive experiments over Northwestern Polytechnical University (NWPU) Very High Resolution (VHR)-10, Cars Overhead With Context (COWC), and Fine-grained Object Recognition (FAIR)1M datasets show that the method can achieve state-of-the-art results.","1558-0644","","10.1109/TGRS.2022.3198083","National Natural Science Foundation of China(grant numbers:61725105); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854813","Closed-loop framework;feedback of region of interest (FROI);multiscale object information (MSOI);mutual-feed learning (MFL);object detection (OD);super-resolution (SR)","Image resolution;Image restoration;Task analysis;Feature extraction;Object detection;Detectors;Generators","computer vision;feature extraction;feedback;geophysical image processing;image classification;image enhancement;image resolution;image restoration;image texture;learning (artificial intelligence);object detection;object recognition","super-resolution;object detection;degraded aerial imagery;resolution degradation;generative adversarial network;mutual-feed learning;closed-loop structure;feedback connection;feedforward connection;object spatial;region-level discrimination;multiscale object information module;feature-level restoration;object-related features;Northwestern Polytechnical University Very High Resolution-10;object recognition","","1","","43","IEEE","11 Aug 2022","","","IEEE","IEEE Journals"
"Lightweight Multiresolution Feature Fusion Network for Spectral Super-Resolution","S. Mei; G. Zhang; N. Wang; B. Wu; M. Ma; Y. Zhang; Y. Feng","School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","12 Jan 2023","2023","61","","1","14","Spectral super-resolution (SR), which reconstructs high spatial-resolution hyperspectral images (HSIs) from RGB inputs, has been demonstrated to be one of the effective computational imaging techniques to acquire HSIs. Though deep neural networks have shown their superiority in such a complex mapping problem, existing networks generally involve a very complex structure with huge amounts of parameters, resulting in giant memory occupation. In this article, a lightweight multiresolution feature fusion network (MRFN) is proposed, which adopts a multiresolution feature extraction and fusion framework to fully explore RGB inputs in different scales of resolution. Specifically, a lightweight feature extraction module (LFEM), which adopts cheap convolution and attention mechanisms, is constructed to explore different scales of features under a lightweight structure. Moreover, a hybrid loss function is proposed by encountering not only pixel-value level reconstruction error but also spectral continuity and fidelity. Experiments over three benchmark datasets, i.e., CAVE, Interdisciplinary Computational Vision Laboratory (ICVL), and NTIRE2022 datasets, have demonstrated that the proposed MRFN can reconstruct HSIs from RGB inputs in higher quality with fewer parameters and computational floating-point operations (FLOPs) compared with several state-of-the-art networks.","1558-0644","","10.1109/TGRS.2023.3234124","National Natural Science Foundation of China(grant numbers:62171381); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10005275","Convolutional neural network (CNN);hyperspectral image (HSI);lightweight network;spectral super-resolution (SR)","Image reconstruction;Feature extraction;Spatial resolution;Hyperspectral imaging;Convolution;Neural networks;Task analysis","cartography;deep learning (artificial intelligence);feature extraction;geophysical image processing;hyperspectral imaging;image fusion;image motion analysis;image resolution","attention mechanisms;complex mapping problem;computational imaging techniques;deep neural networks;fusion framework;HSI;LFEM;lightweight feature extraction module;lightweight multiresolution feature fusion network;MRFN;multiresolution feature extraction;RGB inputs;spatial-resolution hyperspectral images;spectral continuity;spectral super-resolution","","","","53","IEEE","4 Jan 2023","","","IEEE","IEEE Journals"
"Implicit Neural Representation Learning for Hyperspectral Image Super-Resolution","K. Zhang; D. Zhu; X. Min; G. Zhai","Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai, China; Institute of AI Education, East China Normal University, Shanghai, China; Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai, China; Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Transactions on Geoscience and Remote Sensing","5 Jan 2023","2023","61","","1","12","Hyperspectral image (HSI) super-resolution (SR) without additional auxiliary image remains a constant challenge due to its high-dimensional spectral patterns, where learning an effective spatial and spectral representation is a fundamental issue. Recently, implicit neural representations (INRs) are making strides as a novel and effective representation, especially in the reconstruction task. Therefore, in this work, we propose a novel HSI reconstruction model based on INR which represents HSI by a continuous function mapping a spatial coordinate to its corresponding spectral radiance values. In particular, as a specific implementation of INR, the parameters of the parametric model are predicted by a hypernetwork that operates on feature extraction using a convolution network. It makes the continuous functions map the spatial coordinates to pixel values in a content-aware manner. Moreover, periodic spatial encoding is deeply integrated with the reconstruction procedure, which makes our model capable of recovering more high-frequency details. To verify the efficacy of our model, we conduct experiments on three HSI datasets (CAVE, NUS, and NTIRE2018). Experimental results show that the proposed model can achieve competitive reconstruction performance in comparison with the state-of-the-art methods. In addition, we provide an ablation study on the effect of individual components of our model. We hope this article could serve as a potent reference for future research.","1558-0644","","10.1109/TGRS.2022.3230204","National Natural Science Foundation of China(grant numbers:62271312,62001289,62225112,61831015); Foundation of Key Laboratory of Artificial Intelligence, Ministry of Education, China; National Key Research and Development Program of China(grant numbers:2021YFE0206700); Shanghai Municipal Science and Technology Major Project(grant numbers:2021SHZDZX0102); Shanghai Pujiang Program(grant numbers:22PJ1407400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9991174","Hypernetwork;hyperspectral image (HSI);implicit neural representation (INR);spectral super-resolution (SR)","Superresolution;Image reconstruction;Hyperspectral imaging;Spatial resolution;Task analysis;Three-dimensional displays;Convolutional neural networks","geophysical image processing;hyperspectral imaging;image coding;image reconstruction;image representation;image resolution;learning (artificial intelligence)","additional auxiliary imaging;CAVE datasets;continuous function mapping;high-dimensional spectral patterns;HSI reconstruction model;hyperspectral image super-resolution;implicit neural representation learning;INR learning;NTIRE2018 datasets;NUS datasets;parametric model;periodic spatial encoding;spatial coordinates;spatial representation;spectral radiance values;spectral representation","","","","60","IEEE","16 Dec 2022","","","IEEE","IEEE Journals"
"Multilevel Progressive Network With Nonlocal Channel Attention for Hyperspectral Image Super-Resolution","J. Hu; Y. Liu; X. Kang; S. Fan","School of Electrical and Information Engineering, Changsha University of Science and Technology, Changsha, China; School of Electrical and Information Engineering, Changsha University of Science and Technology, Changsha, China; College of Robotics, Hunan University, Changsha, China; School of Electrical and Information Engineering, Changsha University of Science and Technology, Changsha, China","IEEE Transactions on Geoscience and Remote Sensing","29 Nov 2022","2022","60","","1","14","Deep convolutional neural networks (CNNs) have made great progress in the super-resolution (SR) of hyperspectral images (HSIs). However, most methods utilize convolution to explore local features, and global features are ignored. It is expected that combining nonlocal mechanism with CNN will improve the performance of HSI SR. This article presents a multilevel progressive HSI SR network. The dense nonlocal and local block (DNLB) is constructed to combine local and global features, which are used to reconstruct SR images at each level. Due to the high dimension of HSI, original nonlocal methods produce memory-expensive attention maps. We develop a nonlocal channel attention block to extract the global features of HSIs efficiently. Spatial-spectral gradient is injected in the nonlocal attention block to obtain better details. Furthermore, the progressive learning mode-based multilevel network is proposed to reconstruct HSI with fine details. A number of experiments demonstrate that our method can reconstruct HSIs more accurately than existing methods.","1558-0644","","10.1109/TGRS.2022.3221550","National Key Research and Development Program of China(grant numbers:2021YFA0715203); National Natural Science Foundation of China(grant numbers:62271087); Natural Science Foundation of Hunan Province, China(grant numbers:2021JJ40609); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9945989","Convolutional neural network (CNN);hyperspectral image (HSI) super-resolution (SR);multilevel progressive network (MPNet);nonlocal channel attention","Feature extraction;Superresolution;Hyperspectral imaging;Image reconstruction;Three-dimensional displays;Convolutional neural networks;Spatial resolution","geophysical image processing;hyperspectral imaging;image reconstruction;image representation;image resolution;learning (artificial intelligence);neural nets","convolution;convolutional neural networks;dense nonlocal block;global features;hyperspectral image super-resolution;hyperspectral images;local features;memory-expensive attention maps;multilevel progressive HSI SR network;multilevel progressive network;nonlocal attention block;nonlocal channel attention block;nonlocal mechanism;original nonlocal methods;progressive learning mode-based multilevel network;SR images","","","","55","IEEE","10 Nov 2022","","","IEEE","IEEE Journals"
"External-Internal Attention for Hyperspectral Image Super-Resolution","Z. Guo; J. Xin; N. Wang; J. Li; X. Gao","State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; School of Electronic Engineering, Xidian University, Xi’an, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Transactions on Geoscience and Remote Sensing","3 Oct 2022","2022","60","","1","14","In recent years, hyperspectral image (HSI) super-resolution (SR) has made significant progress by leveraging convolution neural networks. Existing methods with spectral or spatial attention, which only consider the spectral similarity or pixel-pixel similarity, ignore sample-sample correlations and sparsity. Therefore, based on the fusion of HSI and multispectral image, we propose a new HSI SR model with external-internal attention (EIA). Instead of considering a single sample, external attention module is employed to exploit the incorporating correlations between different samples to get a better feature representation. In addition, an internal attention module based on nonlocal operation is designed to explore the long-range dependencies information. Particularly, oriented to high mapping precision and low computational cost inference, spherical locality sensitive hashing (LSH) is used to divide features into different hash buckets so that every query point is calculated in the hash bucket assigned to it, rather than based a weight sum of features across all positions. The sequential EIA greatly improves the generalization ability and robustness of the model by modeling at the dataset level and at the sample level. Extensive experiments are conducted on five widely used datasets in comparison with state-of-the-art models, demonstrating the advantage of the method we proposed.","1558-0644","","10.1109/TGRS.2022.3207230","National Key Research and Development Program of China(grant numbers:2018AAA0103202); National Natural Science Foundation of China(grant numbers:62176195,61922066,61876142,62036007,61976166); Technology Innovation Leading Program of Shaanxi(grant numbers:2022QFY01-15,2021GY-030); Open Research Projects of Zhejiang Laboratory(grant numbers:2021KG0AB01); Fundamental Research Funds for the Central Universities; Innovation Fund of Xidian University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9893844","External-internal attention (EIA);hyperspectral image (HSI);spherical locality sensitive hashing (SLSH);super-resolution (SR)","Superresolution;Image reconstruction;Hyperspectral imaging;Spatial resolution;Convolution;Correlation;Computational modeling","geophysical image processing;hyperspectral imaging;image representation;image resolution;neural nets","convolution neural networks;spectral attention;spatial attention;spectral similarity;pixel-pixel similarity;sample-sample correlations;multispectral image;HSI SR model;external-internal attention;external attention module;incorporating correlations;feature representation;internal attention module;long-range dependencies information;spherical locality sensitive hashing;different hash buckets;sample level;hyperspectral image super-resolution","","","","64","IEEE","16 Sep 2022","","","IEEE","IEEE Journals"
"A New Spectral-Spatial Sub-Pixel Mapping Model for Remotely Sensed Hyperspectral Imagery","X. Xu; X. Tong; A. Plaza; J. Li; Y. Zhong; H. Xie; L. Zhang","College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; Hyperspectral Computing Laboratory, Escuela Politecnica, University of Exremadura, Cáceres, Spain; School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","25 Oct 2018","2018","56","11","6763","6778","In this paper, a new joint spectral-spatial subpixel mapping model is proposed for hyperspectral remotely sensed imagery. Conventional approaches generally use an intermediate step based on the derivation of fractional abundance maps obtained after a spectral unmixing process, and thus the rich spectral information contained in the original hyperspectral data set may not be utilized fully. In this paper, a concept of subpixel abundance map, which calculates the abundance fraction of each subpixel to belong to a given class, was introduced. This allows us to directly connect the original (coarser) hyperspectral image with the final subpixel result. Furthermore, the proposed approach incorporates the spectral information contained in the original hyperspectral imagery and the concept of spatial dependence to generate a final subpixel mapping result. The proposed approach has been experimentally evaluated using both synthetic and real hyperspectral images, and the obtained results demonstrate that the method achieves better results when compared to other seven subpixel mapping methods. The numerical comparisons are based on different indexes such as the overall accuracy and the CPU time. Moreover, the obtained results are statistically significant at 95% confidence.","1558-0644","","10.1109/TGRS.2018.2842748","National Key Research and Development Program of China(grant numbers:2018YFB0505404); National Natural Science Foundation of China(grant numbers:41401398,41325005,41201426,41171352,41171327); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8410597","Hyperspectral imaging;spectral unmixing;subpixel mapping;super-resolution mapping","Hyperspectral imaging;Genetic algorithms;Image resolution;Linear programming;Neural networks","hyperspectral imaging;image processing;remote sensing","synthetic images;remotely sensed hyperspectral imagery;fractional abundance maps;spectral unmixing process;hyperspectral images;hyperspectral remotely sensed imagery;hyperspectral data;spectral-spatial sub-pixel mapping model;subpixel mapping methods","","19","","44","IEEE","12 Jul 2018","","","IEEE","IEEE Journals"
"Using Super-Resolution Algorithms for Small Satellite Imagery: A Systematic Review","K. Karwowska; D. Wierzbicki","Faculty of Civil Engineering and Geodesy, Department of Imagery Intelligence, Military University of Technology, Warszawa, Poland; Faculty of Civil Engineering and Geodesy, Department of Imagery Intelligence, Military University of Technology, Warszawa, Poland","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","6 May 2022","2022","15","","3292","3312","In recent years, we have witnessed significant development in the space sector, in particular regarding Earth imaging. Small satellites, whose size and construction make their production much cheaper, are becoming increasingly popular. As a result, a larger number of satellites may be placed in space, and thus, they may perform more frequent observations of selected spots on Earth. Unfortunately, the construction of these satellites also affects their observation capacity as they have a weaker spatial resolution. Scientists have been dealing with the problem of improving the spatial resolution of satellite imaging for many years. Numerous methods were developed that allow for the best possible representation of high-resolution images based on low-resolution images. However, the application of traditional solutions to improve the resolution of digital images requires an additional high-resolution image. As far as images obtained by small satellites (e.g., nano, micro, or mini) are concerned, the difference between the spatial resolution of panchromatic and multispectral images is small (e.g., for SkySat-3 – SkySat-15 satellites, it is only 0.16 m). The need to increase the spatial resolution of an image that does not have a corresponding higher resolution image (e.g., a panchromatic image or a sequence of images) causes additional problems. This article presents a review of the methods to improve the spatial resolution of small-satellite imaging. The authors analyze the interpolation, pansharpening, and digital image processing methods. Additionally, the article focuses on presenting solutions based on deep learning that enables the enhancement of the spatial resolution of images obtained from small satellites. The methodology of creating databases used for network training is described. Finally, the authors present the main limitations of the analyzed solutions and future development trends that will enable to improve the spatial resolution with the use of a single image.","2151-1535","","10.1109/JSTARS.2022.3167646","Wojskowa Akademia Techniczna; Faculty of Civil Engineering and Geodesy, Military University of Technology(grant numbers:531-4000-22-786); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757881","Convolutional neural networks;deep learning;neural networks;single image super-resolution (SISR);super- resolution","Spatial resolution;Interpolation;Imaging;Small satellites;Digital images;Superresolution;Pansharpening","artificial satellites;deep learning (artificial intelligence);geophysical image processing;image enhancement;image representation;image resolution","multispectral imaging;panchromatic imaging;digital image processing methods;super-resolution algorithms;small satellite imagery;spatial resolution;low-resolution imaging;digital imaging;high-resolution imaging;SkySat-3-SkySat-15 satellites;image representation","","2","","191","CCBY","14 Apr 2022","","","IEEE","IEEE Journals"
"Super-Resolution Doppler Velocity Estimation by Kernel-Based Range– $\tau$  Point Conversions for UWB Short-Range Radars","M. Setsu; T. Hayashi; J. He; S. Kidera","Graduate School of Informatics and Engineering, University of Electro-Communications, Tokyo, Japan; Graduate School of Informatics and Engineering, University of Electro-Communications, Tokyo, Japan; Graduate School of Informatics and Engineering, University of Electro-Communications, Tokyo, Japan; Japan Science Technology Agency, PRESTO, Saitama, Japan","IEEE Transactions on Geoscience and Remote Sensing","25 Mar 2020","2020","58","4","2430","2443","Lower band ultrawideband (UWB) Doppler radar is promising for through-wall imaging, e.g., human body detection in rescue scenarios. The inherent problem with pulse-Doppler radar is the tradeoff between the Doppler velocity resolution and the resulting temporal resolution that makes it difficult to conduct real-time target tracking, because the separation of micro-Doppler velocities of the human body requires a higher Doppler velocity resolution. This problem is particularly severe for lower band UWB radar systems, which are required to attain a sufficient penetration depth in concrete material in the through-the-wall imaging scenario. Because UWB signals generally have large fractional bandwidths, the reflected pulse is located over a range gate along the slow-time direction; this is well known as the range walk problem. As a promising solution to this problem, this article newly introduces a technique for a super-resolution Doppler velocity estimation algorithm based on Gaussian kernel density estimation, which converts observed range-τ points to Doppler-associated ranges. In addition, this approach makes an important contribution for super-resolution range extraction with a compressed sensing (CS) filter, which is combined with the range-point migration (RPM) method for human body imaging associated with micro-Doppler components. 2-D or 3-D numerical simulations, including human body imaging scenario, demonstrate that the proposed method allows both accurate Doppler velocity estimation and human body imaging, which can be updated at the pulse-repetition interval.","1558-0644","","10.1109/TGRS.2019.2949104","Japan Science and Technology Agency(grant numbers:JPMJPR1771); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897595","Compressed sensing (CS);kernel density estimation;micro-Doppler for human body;pulse Doppler radar;range-point migration (RPM);through-the-wall imaging (TWI);ultrawideband (UWB) radar","Doppler effect;Estimation;Radar imaging;Imaging;Doppler radar;Image resolution;Ultra wideband radar","compressed sensing;Doppler radar;image filtering;image resolution;numerical analysis;object detection;radar imaging;target tracking;ultra wideband radar","microDoppler velocities;higher Doppler velocity resolution;lower band UWB radar systems;sufficient penetration depth;through-the-wall imaging scenario;UWB signals;reflected pulse;range gate;slow-time direction;range walk problem;super-resolution Doppler velocity estimation algorithm;Gaussian kernel density estimation;observed range-τ points;Doppler-associated ranges;super-resolution range extraction;range-point migration method;microDoppler components;human body imaging scenario;accurate Doppler velocity estimation;kernel-based range-τ point conversions;UWB short-range radars;lower band ultrawideband Doppler radar;through-wall imaging;human body detection;rescue scenarios;inherent problem;pulse-Doppler radar;temporal resolution;real-time target tracking","","15","","26","IEEE","13 Nov 2019","","","IEEE","IEEE Journals"
"Constructing 10-m NDVI Time Series From Landsat 8 and Sentinel 2 Images Using Convolutional Neural Networks","Z. Ao; Y. Sun; Q. Xin","School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Key Laboratory of Geospatial Technology for the Middle and Lower Yellow River Regions (Henan University), Ministry of Education, Kaifeng, China; State Key Laboratory of Desert and Oasis Ecology, Research Center for Ecology and Environment of Central Asia, Chinese Academy of Sciences, Urumqi, China","IEEE Geoscience and Remote Sensing Letters","21 Jul 2021","2021","18","8","1461","1465","Normalized difference vegetation index (NDVI) carries valuable information related to the photosynthetic activity of vegetation and is essential for monitoring phenological changes and ecosystem dynamics. The medium to high spatial resolution satellite images from Landsat 8 and Sentinel 2 offer opportunities to generate dense NDVI time series at 10-m resolution to improve our understanding of the land surface processes. However, synergistic use of Landsat 8 and Sentinel 2 for generating frequent and consistent NDVI data remains challenging as they have different spatial resolutions and spectral response functions. In this letter, we developed an attentional super resolution convolutional neural network (ASRCNN) for producing 10-m NDVI time series through fusion of Landsat 8 and Sentinel 2 images. We evaluated its performance in two heterogeneous areas. Quantitative assessments indicated that the developed network outperforms five commonly used fusion methods [i.e., enhanced deep convolutional spatiotemporal fusion network (EDCSTFN), super resolution convolutional neural network (SRCNN), spatial and temporal adaptive reflectance fusion model (STARFM), enhanced STARFM (ESTARFM), and flexible spatiotemporal data fusion (FSDAF)]. The influence of the method selection on the fusion accuracy is much greater than that of the fusion strategy in blending Landsat-Sentinel NDVI. Our results illustrate the advantages and potentials of the deep learning approaches on satellite data fusion.","1558-0571","","10.1109/LGRS.2020.3003322","National Key Research and Development Program of China(grant numbers:2017YFA0604300); Natural Science Foundation of China(grant numbers:U1811464,41875122); Western Talents(grant numbers:2018XBYJRC004); Guangdong Top Young Talents(grant numbers:2017TQ04Z359); Open Foundation of Key Laboratory of Geospatial Technology for the Middle and Lower Yellow River Regions (Henan University), Ministry of Education(grant numbers:GTYR201810); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9125996","Convolutional neural network (CNN);data fusion;deep learning;remote sensing;spatiotemporal data","Remote sensing;Artificial satellites;Earth;Spatiotemporal phenomena;Spatial resolution;Time series analysis;Training","geophysical image processing;geophysical techniques;image fusion;image resolution;neural nets;phenology;remote sensing;sensor fusion;spatiotemporal phenomena;time series;vegetation;vegetation mapping","Landsat 8;Sentinel 2 images;convolutional neural networks;normalized difference vegetation index;high spatial resolution satellite images;Sentinel 2 offer opportunities;dense NDVI time series;10-m resolution;frequent data;consistent NDVI data;attentional super resolution convolutional neural network;developed network;temporal adaptive reflectance fusion model;flexible spatiotemporal data fusion;Landsat-Sentinel NDVI;satellite data fusion","","6","","32","IEEE","25 Jun 2020","","","IEEE","IEEE Journals"
"Accuracy of super-resolution for hyperspectral ocean observations","J. L. Garrett; D. Langer; K. Avagian; A. Stahl","Norwegian University of Science and Technology, Trondheim, Norway; Norwegian University of Science and Technology, Trondheim, Norway; Norwegian University of Science and Technology, Trondheim, Norway; Norwegian University of Science and Technology, Trondheim, Norway","OCEANS 2019 - Marseille","14 Oct 2019","2019","","","1","8","Super-resolution, a class of techniques used to reconstruct a high-resolution image from one or more low-resolution observations, is a possible route to utilize the full remote imaging capabilities of small satellites and unmanned aerial vehicles. Here, we test two frequently-used variants, Robust Super-Resolution (RSR) and Projection onto Convex Sets (POCS), to see how accurately each technique reconstructs images from a small satellite. The two techniques are chosen because each utilizes a different kind of prior knowledge. RSR utilizes knowledge about the scene, while POCS utilizes knowledge about the imaging process. The algorithms are run on three bands of two hyperspectral images: one lab-acquired image of a wooden block and one simulated image of a remote sensing ocean scene. The superresolution reconstructions of the simulated image are evaluated by calculating the brightness error and spectral angle with respect to the original scene. Both super-resolution algorithms improve both metrics relative to the raw, registered data. RSR achieves more improvement overall, but POCS operates faster.","","978-1-7281-1450-7","10.1109/OCEANSE.2019.8867142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8867142","","Image reconstruction;Oceans;Sea measurements;Imaging;Hyperspectral imaging","geophysical image processing;hyperspectral imaging;image enhancement;image reconstruction;image resolution;oceanographic techniques;remote sensing","hyperspectral ocean observations;low-resolution observations;remote imaging capabilities;unmanned aerial vehicles;Robust Super-Resolution;RSR;POCS;imaging process;hyperspectral images;lab-acquired image;one simulated image;remote sensing ocean scene;superresolution reconstructions;super-resolution algorithms;high-resolution image reconstruction;projection onto convex sets;wooden block;brightness error;spectral angle;small satellites","","2","","26","IEEE","14 Oct 2019","","","IEEE","IEEE Conferences"
"Airborne Forward-Looking Radar Super-Resolution Imaging Using Iterative Adaptive Approach","Y. Zhang; D. Mao; Q. Zhang; Y. Zhang; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","6 Aug 2019","2019","12","7","2044","2054","Airborne forward-looking radar (AFLR) imaging has raised many concerns in fields of Earth observation, independent of weather and daytime. Constrained by imaging principles, conventional high-resolution radar imaging techniques such as synthetic aperture radar (SAR) and Doppler beam sharpening (DBS) are incapable of AFLR imaging. The real aperture radar (RAR) can obtain AFLR images using a scanning antenna, but suffers from coarse cross-range resolution. Recently, there has been much attention paid to the iterative adaptive approach (IAA), which draws from the benefits of RAR imaging and provides improved cross-range resolution. However, earlier work on the IAA imposed a convolution model on the received azimuth echo, neglecting the effect of the Doppler phase. This model mismatch degrades the imaging performance for moving platforms. To settle this problem, this paper first establishes a Doppler-convolution model of AFLR imaging, where both Doppler phase and antenna convolution effects are considered, allowing more accurate reconstruction when applying the IAA to formulate a super-resolution image. Then, a data-depended approach for Doppler centroid estimation is proposed to circumvent the problem of low estimation precision using platform motion parameters delivered by navigational devices mounted on the radar platform. Simulation results demonstrate that the proposed implementation of the IAA based on the Doppler-convolution model and Doppler centroid estimation can overcome the deficiencies of the SAR and DBS techniques in the forward-looking imaging direction, and present a noticeably superior performance as compared with conventional AFLR imaging methods.","2151-1535","","10.1109/JSTARS.2019.2920859","China Postdoctoral Science Foundation; National Natural Science Foundation of China(grant numbers:61671117); Collaborative Innovation Center of Information Sensing and Understanding; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738819","Doppler centroid estimation;forward-looking;iterative adaptive approach;super-resolution","Imaging;Radar imaging;Image resolution;Doppler effect;Azimuth;Synthetic aperture radar","airborne radar;Doppler radar;image resolution;iterative methods;radar imaging;radar resolution","Doppler phase;imaging performance;Doppler-convolution model;antenna convolution effects;super-resolution image;Doppler centroid estimation;radar platform;imaging direction;conventional AFLR imaging methods;airborne forward-looking radar super-resolution imaging;radar imaging;imaging principles;conventional high-resolution radar;aperture radar;AFLR images;coarse cross-range resolution;RAR imaging;improved cross-range resolution","","39","","38","IEEE","18 Jun 2019","","","IEEE","IEEE Journals"
"SAR Image Super Resolution using Importance Sampling Unscented Kalman Filter","S. Kanakaraj; M. S. Nair; S. Kalady","Department of Computer Science and Engineering, National Institute of Technology Calicut, Kozhikode, India; Department of Computer Science, University of Kerala, Thiruvananthapuram, India; Department of Computer Science and Engineering, National Institute of Technology Calicut, Kozhikode, India","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","13 Feb 2018","2018","11","2","562","571","Synthetic aperture radar (SAR) imaging is a crucial tool in providing images of the earth's surface for military and civilian applications such as target surveillance and its classification. The precision of the application degrades with the presence of inherent speckle and poor resolution of images from the SAR image acquisition devices. Thus, the objective of the proposed method is to develop a technique to enhance the resolution while despeckling the inherent noise, simultaneously, since the conventional super resolution methods have failed to do the same. Moreover, the works from the literature that super resolve SAR images have also neglected the signal-dependent noise model. The work proposed in this paper significantly reduces the speckle and super resolves the SAR image using an Importance Sampling Unscented Kalman Filter framework that best models the non-linearity of the system. The technique has been assessed quantitatively and qualitatively on synthetic images as well as on real SAR images. The performance evaluation based on peak signal-to-noise-ratio, structural similarity index measure, feature similarity index measure, edge preservation factor, and equivalent number of looks values throw light on the superiority of the proposed method over the standard and other recent techniques. This can serve to generate images with a better reconstructive quality that would aid various applications in multidisciplinary domains.","2151-1535","","10.1109/JSTARS.2017.2779795","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239604","Denoising;Importance Sampling (IS);Kalman Filter (KF);Super Resolution (SR);Synthetic Aperture Radar (SAR) image;Unscented Kalman Filter (UKF)","Image resolution;Synthetic aperture radar;Kalman filters;Probability density function;Covariance matrices;Speckle;Monte Carlo methods","image denoising;image filtering;image resolution;importance sampling;Kalman filters;nonlinear filters;radar imaging;radar resolution;speckle;synthetic aperture radar","SAR image super resolution;synthetic aperture radar imaging;military applications;civilian applications;target surveillance;inherent speckle;SAR image acquisition devices;inherent noise;conventional super resolution methods;super resolve SAR images;signal-dependent noise model;synthetic images;signal-to-noise-ratio;earth surface;importance sampling unscented Kalman filter framework","","15","","30","IEEE","25 Dec 2017","","","IEEE","IEEE Journals"
"Hybrid Inexact BCD for Coupled Structured Matrix Factorization in Hyperspectral Super-Resolution","R. Wu; H. -T. Wai; W. -K. Ma","Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong, Hong Kong; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Signal Processing","18 Mar 2020","2020","68","","1728","1743","This paper develops a first-order optimization method for coupled structured matrix factorization (CoSMF) problems that arise in the context of hyperspectral super-resolution (HSR) in remote sensing. To best leverage the problem structures for computational efficiency, we introduce a hybrid inexact block coordinate descent (HiBCD) scheme wherein one coordinate is updated via the fast proximal gradient (FPG) method, while another via the Frank-Wolfe (FW) method. The FPG-type methods are known to take less number of iterations to converge, by numerical experience, while the FW-type methods can offer lower per-iteration complexity in certain cases; and we wish to take the best of both. We show that the limit points of this HiBCD scheme are stationary. Our proof treats HiBCD as an optimization framework for a class of multi-block structured optimization problems, and our stationarity claim is applicable not only to CoSMF but also to many other problems. Previous optimization research showed the same stationarity result for inexact block coordinate descent with either FPG or FW updates only. Numerical results indicate that the proposed HiBCD scheme is computationally much more efficient than the state-of-the-art CoSMF schemes in HSR.","1941-0476","","10.1109/TSP.2020.2975910","Shun Hing Institute of Advanced Engineering; The Chinese University of Hong Kong(grant numbers:#MMT-8115059); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9013083","Hyperspectral super-resolution;coupled matrix factorization;non-convex optimization","Optimization;Spatial resolution;Hyperspectral imaging;Signal resolution","computational complexity;geophysical image processing;gradient methods;hyperspectral imaging;image resolution;iterative methods;matrix decomposition;optimisation;remote sensing","FPG method;hybrid inexact block coordinate descent scheme;CoSMF schemes;multiblock structured optimization problems;optimization framework;HiBCD scheme;per-iteration complexity;FW-type methods;FPG-type methods;Frank-Wolfe method;fast proximal gradient method;descent scheme;computational efficiency;remote sensing;HSR;coupled structured matrix factorization problems;first-order optimization method;hyperspectral super-resolution;hybrid inexact BCD","","5","","43","IEEE","26 Feb 2020","","","IEEE","IEEE Journals"
"Group Shuffle and Spectral-Spatial Fusion for Hyperspectral Image Super-Resolution","X. Wang; Y. Cheng; X. Mei; J. Jiang; J. Ma","Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Electronic Information School, Wuhan University, Wuhan, China","IEEE Transactions on Computational Imaging","18 Jan 2023","2022","8","","1223","1236","Recently, super-resolution (SR) tasks for single hyperspectral images have been extensively investigated and significant progress has been made by introducing advanced deep learning-based methods. However, hyperspectral image SR is still a challenging problem because of the numerous narrow and successive spectral bands of hyperspectral images. Existing methods adopt the group reconstruction mode to avoid the unbearable computational complexity brought by the high spectral dimensionality. Nevertheless, the group data lose the spectral responses in other ranges and preserve the information redundancy caused by continuous and similar spectrograms, thus containing too little information. In this paper, we propose a novel single hyperspectral image SR method named GSSR, which pioneers the exploration of tweaking spectral band sequence to improve the reconstruction effect. Specifically, we design the group shuffle that leverages interval sampling to produce new groups for separating adjacent and extremely similar bands. In this way, each group of data has more varied spectral responses and less redundant information. After the group shuffle, the spectral-spatial feature fusion block is employed to exploit the spectral-spatial features. To compensate for the adjustment of spectral order by the group shuffle, the local spectral continuity constraint module is subsequently appended to constrain the features for ensuring the spectral continuity. Experimental results on both natural and remote sensing hyperspectral images demonstrate that the proposed method achieves the best performance compared to the state-of-the-art methods.","2333-9403","","10.1109/TCI.2023.3235153","National Natural Science Foundation of China(grant numbers:62276192,62071339); Key Research and Development Program of Hubei Province(grant numbers:2020BAB113,2021CFB464); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10011536","Hyperspectral image;super-resolution;group shuffle;spectral-spatial feature fusion block;local spectral continuity constraint module","Hyperspectral imaging;Superresolution;Feature extraction;Spatial resolution;Imaging;Image reconstruction;Spectrogram","deep learning (artificial intelligence);geophysical image processing;hyperspectral imaging;image reconstruction;image resolution;remote sensing","deep learning-based methods;group shuffle;GSSR;high spectral dimensionality;hyperspectral image super-resolution;local spectral continuity constraint module;natural sensing hyperspectral images;remote sensing hyperspectral images;single hyperspectral image SR method;spectral band sequence;spectral-spatial feature fusion block;spectral-spatial fusion","","","","41","IEEE","9 Jan 2023","","","IEEE","IEEE Journals"
"Generative Adversarial Networks for Spectral Super-Resolution and Bidirectional RGB-To-Multispectral Mapping","K. G. Lore; K. K. Reddy; M. Giering; E. A. Bernal","United Technologies Research Center, E. Hartford, CT; United Technologies Research Center, E. Hartford, CT; United Technologies Research Center, E. Hartford, CT; University of Rochester, Rochester, NY","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","9 Apr 2020","2019","","","926","933","Acquisition of multi-and hyperspectral imagery imposes significant requirements on the hardware capabilities of the sensors involved. In order to keep costs manageable, and due to limitations in the sensing technology, tradeoffs between the spectral and the spatial resolution of hyperspectral images are usually made. Such tradeoffs are usually not necessary when considering acquisition of traditional RGB imagery. We investigate the use of statistical learning, and in particular, of conditional generative adversarial networks (cGANs) to estimate mappings from three-channel RGB to 31-band multispectral imagery. We demonstrate the application of the proposed approach to (i) RGB-to-multispectral image mapping, (ii) spectral super-resolution of image data, and (iii) recovery of RGB imagery from multispectral data.","2160-7516","978-1-7281-2506-0","10.1109/CVPRW.2019.00122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9025450","","Spatial resolution;Image reconstruction;Task analysis;Training;Hyperspectral imaging","geophysical image processing;hyperspectral imaging;image colour analysis;image resolution;image sensors;remote sensing;spectral analysis","sensing technology;hardware capabilities;significant requirements;hyperspectral imagery;Bidirectional RGB-To-Multispectral;multispectral data;spectral super-resolution;RGB-to-multispectral image mapping;31-band multispectral imagery;three-channel RGB;conditional generative adversarial networks;traditional RGB imagery;considering acquisition;hyperspectral images;spatial resolution","","10","","30","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"Numerical Evaluation of the Traffic Flow Indicators Using Super-Resolution Satellite Imagery","I. N. Pugachev; G. Y. Markelov; V. S. Tormozov; A. O. Nosenko","Vice-Rector, Doctor of Technical Sciences, Pacific National University, PNU, Khabarovsk, Russian Federation; Computer Engineering Department, Pacific National University, PNU, Khabarovsk, Russian Federation; Department of Computer Software and Automated Systems, Pacific National University, PNU, Khabarovsk, Russian Federation; Foreign Language Department, Pacific National University, PNU, Khabarovsk, Russian Federation","2019 International Multi-Conference on Industrial Engineering and Modern Technologies (FarEastCon)","19 Dec 2019","2019","","","1","4","The article is devoted to methods of numerical evaluation of traffic flow indicators (TFP) using super-resolution satellite imagery. The method includes several main stages: the stage of extracting images of the space intervals, the stage of detection and classification of vehicles, and the stage of numerical calculation of the intensity and combination of the traffic flow based on the vehicles distributing on the space interval. The main tasks and problems associated with the detection and classification of vehicles are given.","","978-1-7281-0061-6","10.1109/FarEastCon.2019.8934802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8934802","detection;image recognition;selective search;satellite imagery;computer vision;transport planning;satellite pictures;image processing;traffic flow;convolution neural network;machine learning;artificial intelligence","Satellites;Roads;Training;Convolutional neural networks;Urban areas;Classification algorithms","feature extraction;geophysical image processing;image classification;image resolution;remote sensing;road traffic","traffic flow indicators;super-resolution satellite imagery;space interval;vehicle classification;vehicle detection;extracting image stage","","1","","22","IEEE","19 Dec 2019","","","IEEE","IEEE Conferences"
"Super-resolution: Sparse dictionary design method using quantitative comparison","M. Moustafa; H. M. Ebeid; A. Helmy; T. M. Nazamy; M. F. Tolba","Data Reception Analysis and Receiving Station Affairs, National Authority for Remote Sensing and Space Science, Cairo, Egypt; Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Data Reception Analysis and Receiving Station Affairs, National Authority for Remote Sensing and Space Science, Cairo, Egypt; Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt","2015 IEEE Seventh International Conference on Intelligent Computing and Information Systems (ICICIS)","4 Feb 2016","2015","","","383","389","Single image super resolution (SISR) is the process that obtains a high resolution image from a single low resolution (LR) image by increasing the high frequency information and removing the degradation of the noise. Sparse representation of signal assumes linear combinations of a few atoms from a pre -specified dictionary. Sparse representation has been used successfully as a prior in signal reconstruction. Dictionary design is crucial for the success of reconstruction high resolution images. This paper evaluates the performance of dictionary design models in both mathematical and learning based models, it also compares the wavelet method, Haar method, DCT method, MOD method and K-SVD method. Various experiments are conducted using a real SPOT-4 satellite image. Experimental results demonstrate that the learning based approaches are very effective in increasing resolution and compare favorably to mathematical based approaches.","","978-1-5090-1950-2","10.1109/IntelCIS.2015.7397249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7397249","Shift Estimation;SPOT-5 Images;Super Resolution","Image resolution;Signal resolution;Dictionaries;IP networks;Image coding;Discrete cosine transforms;Encoding","artificial satellites;discrete cosine transforms;geophysical image processing;Haar transforms;image denoising;image reconstruction;image representation;image resolution;learning (artificial intelligence);singular value decomposition;wavelet transforms","sparse dictionary design method;quantitative analysis;single-image super-resolution;SISR;high-resolution image;single-low-resolution image;single-LR image;high-frequency information;noise degradation removal;sparse representation;signal reconstruction;high-resolution image reconstruction;performance evaluation;mathematical-based model;learning-based model;wavelet method;Haar method;DCT method;MOD method;K-SVD method;SPOT satellite image","","2","","27","IEEE","4 Feb 2016","","","IEEE","IEEE Conferences"
"Learning Discrete Representations From Reference Images for Large Scale Factor Image Super-Resolution","W. Sun; Z. Chen","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, Hubei, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, Hubei, China","IEEE Transactions on Image Processing","28 Jan 2022","2022","31","","1490","1503","Image super-resolution (SR) task aims to recover high-resolution (HR) images from degraded low-resolution (LR) images, which has achieved great progress due to the recent advances of deep neural networks. Due to severe information loss of the LR images, it is more challenging to reconstruct high quality HR images at large scale factors, i. e., higher than  $4\times $ . Traditional reference image based SR methods usually perform patch matching to locate detailed texture from HR reference images which could provide fine details from similar image contents. But it suffers from difficulties in achieving good matching in the largely downscaled image space or feature space due to the ill-posed nature between LR and HR mapping. In this paper, we tackle this problem by exploiting fine details contained in reference HR images. Inspired by vector quantization (VQ), we propose a simple yet effective auto-encoder convolutional neural network (CNN) module to learn discrete representations of images. Furthermore, we propose to progressively learn pairs of cross-scale discrete feature representations using paired LR and HR reference images. The coarser scale of the discrete representation is responsible for encoding the global image structure while the paired finer scale of the discrete representation takes charge of capturing missing details in the finer image scale. During inference, continuous features of the test LR image are used as queries to retrieve finer scale discrete representations (value) by searching the nearest coarser scale discrete representations (key). Then, the queries and retrieved values are combined to progressively recover the HR image. Experimental results indicate that when compared with the state-of-the-art image SR models, the proposed method can achieve advanced performance in terms of both objective quality and subjective quality. The code will be available on URL: https://github.com/sunwj/refsr.","1941-0042","","10.1109/TIP.2022.3142999","National Natural Science Foundation of China(grant numbers:62036005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687314","Super-resolution;reference image;discrete representation;vector quantization","Vector quantization;Task analysis;Superresolution;Sun;Spatial resolution;Periodic structures;Neural networks","convolutional neural nets;deep learning (artificial intelligence);image coding;image reconstruction;image representation;image resolution;image texture;vector quantisation","high-resolution reference images;low-resolution reference images;deep neural networks;HR reference images;cross-scale discrete feature representations;global image structure encoding;large scale factor image super-resolution;LR reference images;autoencoder convolutional neural network;vector quantization;autoencoder CNN;discrete image representation learning;high quality HR image reconstruction","","","","58","IEEE","20 Jan 2022","","","IEEE","IEEE Journals"
"Persistent Scatterer Densification Through Capon-Based SAR Reprocessing for Sentinel-1 TOPS Data","H. Zhang; P. López-Dekker; F. v. Leijen","School of Geographic and Biologic Information, Nanjing University of Posts and Telecommunications, Nanjing, China; Department of Geoscience and Remote Sensing, Delft University of Technology, Delft, The Netherlands; Department of Geoscience and Remote Sensing, Delft University of Technology, Delft, The Netherlands","IEEE Geoscience and Remote Sensing Letters","20 Dec 2021","2022","19","","1","5","Several researchers have shown that the Capon algorithm can be applied to reprocess SAR images, resulting in super-resolution reconstructed scenes with lower sidelobe levels. Thus by employing the Capon-based reprocessed images in Persistent Scatterer Interferometry (PSI), the persistent scatterer (PS) density can be increased. In this letter, we exploit the Capon-based PS densification method for Sentinel-1 (S-1)Terrain Observation by Progressive Scans(TOPS) data. We propose a revised robust approach of the Capon algorithm, which applies the automatic diagonal loading (DL) method when the condition number of the covariance matrix is big enough. The proposed approach is robust and can avoid spurious persistent scatterer candidate (PSC) points introduced by DL approaches. We also consider and analyze the spectral property caused by the scanning mode of TOPS in the reprocessing. We applied the revised-robust-Capon-based reprocessing algorithm to a stack of real-life S-1 data and selected PSCs from them. The final result shows that the number of PSs increases by approximately 30% with respect to the original stack.","1558-0571","","10.1109/LGRS.2020.3048370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325527","Persistent scatterer (PS) densification;robust Capon algorithm;sentinel-1 (S-1)","Covariance matrices;Strain;Approximation algorithms;Standards;Histograms;Signal to noise ratio;Optical interferometry","densification;image reconstruction;image resolution;radar imaging;radar interferometry;synthetic aperture radar","Persistent Scatterer densification;Capon-based SAR reprocessing;Sentinel-1 TOPS data;Capon algorithm;SAR images;super-resolution reconstructed scenes;lower sidelobe levels;Persistent Scatterer Interferometry;persistent scatterer density;Capon-based PS densification method;Terrain Observation;revised robust approach;automatic diagonal loading method;spurious persistent scatterer candidate;revised-robust-Capon-based reprocessing","","","","18","IEEE","15 Jan 2021","","","IEEE","IEEE Journals"
"LoGSRN: Deep Super Resolution Network for Digital Elevation Model","D. Shin; S. Spittle","School of Creative Technologies, University of Portsmouth, Winston Churchill Avenue, Portsmouth, UK; Space Applications Catapult, Electron Building, Fermi Avenue, Harwell, Oxford, UK","2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)","28 Nov 2019","2019","","","3060","3065","The spatial resolution of a Digital Elevation Model (DEM) plays a crucial role in many practical remote sensing applications. However, it is normally limited by the spatial resolution of the raw input imagery, from which a DEM is derived. One solution to enhance the limited resolution of a DEM during the post-processing, is fusing previously obtained high resolution DEM data. This data-driven approach appears particularly promising, considering the recent success of a deep convolutional network in single image super resolution (SISR). In this paper, we propose a new SISR network that can recover a high resolution DEM. Instead of configuring a single network directly mapping low resolution depth values to high resolution depth values, we propose a new model consisting of 3 subnetworks, i.e. a) extracting feature maps; b) inferring the high frequency details; c) refining the result combining the low resolution input with the details from b). This is similar to LapSRN [1] in that both adopt a Laplacian image pyramid to model the scaling process in SISR. However, the proposed method implements a much deeper subnetworks efficiently with multiple recursive feedback and feedforward connections, and an additional Laplacian of Gaussian (LoG)based loss function help to produce more effective training results. In this research, we also produce a high quality DEM dataset obtained from optical and lidar sensors, from satellites and aircraft respectively, covering different scenes found in remote sensing applications. Our experiments demonstrate that the proposed model performs better than other standard deep SISR models in terms of the training convergence and the Peak Signal to Noise Ratio (PSNR) of a reconstructed DEM.","2577-1655","978-1-7281-4569-3","10.1109/SMC.2019.8914037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8914037","","Feature extraction;Spatial resolution;Training;High frequency;Laplace equations;Optical sensors","convolutional neural nets;digital elevation models;feature extraction;feedback;feedforward;Gaussian processes;geophysical image processing;image reconstruction;image resolution;remote sensing","lidar sensors;optical sensors;training convergence;peak signal to noise ratio;PSNR;Laplacian of Gaussian based loss function;feedforward connections;multiple recursive feedback;scaling process;Laplacian image pyramid;LapSRN;LoGSRN;low resolution depth mapping;low resolution input;high frequency details;feature map extraction;high resolution depth;high resolution DEM;SISR network;single image super resolution;deep convolutional network;data-driven approach;raw input imagery;practical remote sensing applications;spatial resolution;digital elevation model;deep super resolution network;reconstructed DEM;standard deep SISR models;high quality DEM","","2","","26","IEEE","28 Nov 2019","","","IEEE","IEEE Conferences"
"Hyperspectral Image Super-Resolution via Deep Spatiospectral Attention Convolutional Neural Networks","J. -F. Hu; T. -Z. Huang; L. -J. Deng; T. -X. Jiang; G. Vivone; J. Chanussot","School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; FinTech Innovation Center, Financial Intelligence and Financial Engineering Research Key Laboratory of Sichuan Province, School of Economic Information Engineering, Southwestern University of Finance and Economics, Chengdu, China; National Research Council–Institute of Methodologies for Environmental Analysis, CNR-IMAA, Tito Scalo, Italy; Université Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Grenoble, France","IEEE Transactions on Neural Networks and Learning Systems","30 Nov 2022","2022","33","12","7251","7265","Hyperspectral images (HSIs) are of crucial importance in order to better understand features from a large number of spectral channels. Restricted by its inner imaging mechanism, the spatial resolution is often limited for HSIs. To alleviate this issue, in this work, we propose a simple and efficient architecture of deep convolutional neural networks to fuse a low-resolution HSI (LR-HSI) and a high-resolution multispectral image (HR-MSI), yielding a high-resolution HSI (HR-HSI). The network is designed to preserve both spatial and spectral information thanks to a new architecture based on: 1) the use of the LR-HSI at the HR-MSI’s scale to get an output with satisfied spectral preservation and 2) the application of the attention and pixelShuffle modules to extract information, aiming to output high-quality spatial details. Finally, a plain mean squared error loss function is used to measure the performance during the training. Extensive experiments demonstrate that the proposed network architecture achieves the best performance (both qualitatively and quantitatively) compared with recent state-of-the-art HSI super-resolution approaches. Moreover, other significant advantages can be pointed out by the use of the proposed approach, such as a better network generalization ability, a limited computational burden, and the robustness with respect to the number of training samples. Please find the source code and pretrained models from https://liangjiandeng.github.io/Projects_Res/HSRnet_2021tnnls.html.","2162-2388","","10.1109/TNNLS.2021.3084682","National Natural Science Foundation of China(grant numbers:61772003,61702083,12001446,61876203); National Key Research and Development Program of China(grant numbers:2020YFA0714001); Key Projects of Applied Basic Research in Sichuan Province(grant numbers:2020YJ0216); Fundamental Research Funds for the Central Universities(grant numbers:JBK2102001); MIAI@Grenoble Alpes(grant numbers:ANR- 19-P3IA-0003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9449622","Attention module (AM);deep convolutional neural network (CNN);hyperspectral image (HSI) super-resolution;image fusion;pixelShuffle (PS)","Superresolution;Tensors;Spatial resolution;Hyperspectral imaging;Computer architecture;Training data;Learning systems","geophysical image processing;hyperspectral imaging;image fusion;image reconstruction;image representation;image resolution;learning (artificial intelligence);neural nets;remote sensing","deep convolutional neural networks;deep spatiospectral attention convolutional neural networks;high-resolution HSI;high-resolution multispectral image;HR-MSI's scale;HSIs;hyperspectral image super-resolution;hyperspectral images;inner imaging mechanism;low-resolution HSI;LR-HSI;network architecture;network generalization ability;output high-quality spatial details;plain mean squared error loss function;recent state-of-the-art HSI super-resolution approaches;satisfied spectral preservation;simple architecture;spatial information thanks;spatial resolution;spectral channels;spectral information thanks","","10","","81","IEEE","9 Jun 2021","","","IEEE","IEEE Journals"
"LiDAR Super-Resolution Based on Segmentation and Geometric Analysis","D. Tian; D. Zhao; D. Cheng; J. Zhang","School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China","IEEE Transactions on Instrumentation and Measurement","21 Sep 2022","2022","71","","1","17","In this work, we propose a new light detection and ranging (LiDAR) super-resolution method for indoor and outdoor scenes in urban environments without training, converting to images and auxiliary sensors. To generate high-resolution (high-res) point clouds from the low-resolution (low-res) measurement of a sparse LiDAR, we deconstruct the whole problem into three sequential modules. First, to avoid feature interference, the raw data are segmented into the ground and nonground points. Then, these two types of points are reorganized into a more regular representation of the coordinates. Finally, the high-res point clouds are generated via a new geometric method. We present abundant synthetic and real data based on testing and evaluation of the proposed method. Qualitative and quantitative comparisons show that our method is effective and robust.","1557-9662","","10.1109/TIM.2022.3204097","China National Key Research and Development Program(grant numbers:2021YFC3090401); National Natural Science Foundation of China(grant numbers:62105372); Foundation of Key Laboratory of National Defense Science and Technology(grant numbers:6142401200301); Natural Science Foundation of Hunan Province(grant numbers:2021JJ40794); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9875347","Coordinates reorganization;geometric analysis;least squares;light detection and ranging (LiDAR) super-resolution;range sensing;segmentation","Laser radar;Superresolution;Point cloud compression;Three-dimensional displays;Sensors;Interpolation;Fitting","feature extraction;image resolution;image segmentation;optical radar;remote sensing by laser beam","LiDAR super-resolution;geometric analysis;light detection;super-resolution method;indoor scenes;outdoor scenes;urban environments;auxiliary sensors;sparse LiDAR;sequential modules;feature interference;raw data;nonground points;high-res point clouds;geometric method;abundant synthetic data","","","","38","IEEE","5 Sep 2022","","","IEEE","IEEE Journals"
"Microwave Correlation Forward-Looking Super-Resolution Imaging Based on Compressed Sensing","Y. Quan; R. Zhang; Y. Li; R. Xu; S. Zhu; M. Xing","School of Electronic Engineering, Xidian University, Xi’an, China; Key Laboratory for Radar Signal Processing, Xidian University, Xi’an, China; Key Laboratory for Radar Signal Processing, Xidian University, Xi’an, China; Beijing Institute of Electronic System Engineering, Beijing, China; Key Laboratory for Radar Signal Processing, Xidian University, Xi’an, China; Key Laboratory for Radar Signal Processing, Xidian University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","24 Sep 2021","2021","59","10","8326","8337","Forward-looking correlated imaging plays an increasingly important role in modern radar imaging systems. It overcomes disadvantages of traditional side or squint synthetic aperture radar (SAR) which is dependent on specific relative motion between the radar and target scene. A new microwave forward-looking correlated 3-D imaging method based on random radiation field combined with sparse reconstruction is proposed in this article. Firstly, phased array radar (PAR) is adopted to form different and random antenna patterns. Then, combined with the compressed sensing (CS) theory, the target image can be recovered with very few samples which can break through Rayleigh resolution limitation. Furthermore, the proposed method can achieve resolution at least 5.5 times higher than real aperture imaging. To raise computation efficiency of sparse reconstruction, an improved quasi-Newton iteration method based on graphics processing unit (GPU) platform is developed. Meanwhile, a GPU-based (NVIDIA Tesla K40c) accelerated computing method can significantly reduce the processing time compared with the time given by a personal computer (PC). Both simulation and field experiment verify the validity of the proposed method.","1558-0644","","10.1109/TGRS.2020.3047018","National Natural Science Foundation of China(grant numbers:61772397); National Key Research and Development Program of China(grant numbers:2016YFE0200400); Science and Technology Innovation Team of Shaanxi Province(grant numbers:2019TD-002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321349","2-D random radiation pattern;compressed sensing (CS);forward-looking imaging;graphics processing unit (GPU);microwave correlation;phased array radar (PAR);super-resolution;temporal-spatial","Radar imaging;Imaging;Radar;Microwave imaging;Radar antennas;Microwave theory and techniques;Scattering","graphics processing units;image reconstruction;image resolution;image sensors;iterative methods;Newton method;parallel architectures;phased array radar;radar antennas;radar imaging;synthetic aperture radar","quasiNewton iteration method;GPU-based;microwave correlation forward-looking super-resolution imaging;forward-looking correlated imaging;modern radar imaging systems;traditional side;specific relative motion;target scene;3-D imaging method;random radiation field;sparse reconstruction;phased array radar;different antenna patterns;random antenna patterns;compressed sensing theory;target image;Rayleigh resolution limitation;5.5 times higher;aperture imaging","","8","","41","IEEE","13 Jan 2021","","","IEEE","IEEE Journals"
"TV-Sparse Super-Resolution Method for Radar Forward-Looking Imaging","Q. Zhang; Y. Zhang; Y. Huang; Y. Zhang; J. Pei; Q. Yi; W. Li; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","27 Aug 2020","2020","58","9","6534","6549","Real-aperture radar can be utilized to realize forward-looking imaging by antenna scanning the imaging region. However, low azimuth resolution seriously affects its practical application. Although traditional super-resolution methods could enhance azimuth resolution to a certain extent, effective preservation of contour information for important targets still remains to be a problem. In this article, a method of total variation-sparse (TV-sparse) multiconstraint deconvolution is proposed to improve azimuth resolution of forward-looking imaging as well as preserve contour information of important targets. Since our interested targets usually appear to be sparse, the sparse constraint of the target is introduced first to achieve high resolution of forward-looking images, which may cause the loss of target contour information in the meantime. Second, total variation (TV) constraint is introduced based on the sparse constraint, converting traditional single-constraint super-resolution problem to a multiconstraint problem. We then use the split Bregman algorithm (SBA) to solve the multiconstraint problem, whose solution is the super-resolution image of radar forward-looking region. Compared with traditional super-resolution methods, the proposed method can improve the azimuth resolution of radar forward-looking imaging as well as better restore target contour information by adjusting respective weights of sparse constraint and TV constraint. Finally, the performance of the proposed method is validated with the simulation and measured data.","1558-0644","","10.1109/TGRS.2020.2977719","National Natural Science Foundation of China(grant numbers:61671117); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9037095","Deconvolution;radar imaging;sparse;super-resolution;total variation (TV)","Radar imaging;Image resolution;Radar antennas;Azimuth;Signal resolution;Imaging","compressed sensing;deconvolution;image resolution;radar imaging","real aperture radar;low azimuth resolution;sparse constraint;target contour information;total variation constraint;multiconstraint problem;single constraint superresolution problem;total variation sparse multiconstraint deconvolution;radar forward looking imaging;TV sparse superresolution;split Bregman algorithm","","28","","49","IEEE","16 Mar 2020","","","IEEE","IEEE Journals"
"The Effects of Super-Resolution on Object Detection Performance in Satellite Imagery","J. Shermeyer; A. Van Etten","CosmiQ Works, In-Q-Tel; CosmiQ Works, In-Q-Tel","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","9 Apr 2020","2019","","","1432","1441","We explore the application of super-resolution techniques to satellite imagery, and the effects of these techniques on object detection algorithm performance. Specifically, we enhance satellite imagery beyond its native resolution, and test if we can identify various types of vehicles, planes, and boats with greater accuracy than native resolution. Using the Very Deep Super-Resolution (VDSR) framework and a custom Random Forest Super-Resolution (RFSR) framework we generate enhancement levels of 2×, 4×, and 8× over five distinct resolutions ranging from 30 cm to 4.8 meters. Using both native and super-resolved data, we then train several custom detection models using the SIMRDWN object detection framework. SIMRDWN combines a number of popular object detection algorithms (e.g. SSD, YOLO) into a unified framework that is designed to rapidly detect objects in large satellite images. This approach allows us to quantify the effects of super-resolution techniques on object detection performance across multiple classes and resolutions. We also quantify the performance of object detection as a function of native resolution and object pixel size. For our test set we note that performance degrades from mean average precision (mAP) = 0.53 at 30 cm resolution, down to mAP = 0.11 at 4.8 m resolution. Super-resolving native 30 cm imagery to 15 cm yields the greatest benefit; a 13-36% improvement in mAP. Super-resolution is less beneficial at coarser resolutions, though still provides a small improvement in performance.","2160-7516","978-1-7281-2506-0","10.1109/CVPRW.2019.00184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9025375","","Satellites;Object detection;Boats;Spatial resolution;Training;Automobiles","geophysical image processing;image enhancement;image resolution;object detection;random forests;remote sensing","super-resolution techniques;mean average precision;super-resolved data;RFSR framework;VDSR framework;very deep super-resolution framework;satellite imagery enhancement;custom random forest super-resolution framework;performance degradion;super-resolving native imagery;object pixel size;object detection performance;satellite images;SIMRDWN object detection framework;custom detection models;native resolution;object detection algorithm performance;size 4.8 m;size 30.0 cm;size 15.0 cm;size 30.0 cm to 4.8 A","","72","","43","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"Reinforced Swin-Convs Transformer for Simultaneous Underwater Sensing Scene Image Enhancement and Super-resolution","T. Ren; H. Xu; G. Jiang; M. Yu; X. Zhang; B. Wang; T. Luo","School of Mathematics and Statistics, Ningbo University, Ningbo, China; School of Mathematics and Statistics, Ningbo University, Ningbo, China; Faculty of Information Science and Engineering, Ningbo University, Ningbo, China; Faculty of Information Science and Engineering, Ningbo University, Ningbo, China; School of Mathematics and Statistics, Ningbo University, Ningbo, China; School of Mathematics and Statistics, Ningbo University, Ningbo, China; Faculty of Information Science and Engineering, Ningbo University, Ningbo, China","IEEE Transactions on Geoscience and Remote Sensing","23 Sep 2022","2022","60","","1","16","Underwater image enhancement (UIE) technology aims to tackle the challenge of restoring the degraded underwater images due to light absorption and scattering. Meanwhile, the ever-increasing requirement for higher resolution images from a lower resolution in the underwater domain cannot be overlooked. To address these problems, a novel U-Net-based reinforced Swin-Convs Transformer for simultaneous enhancement and superresolution (URSCT-SESR) method is proposed. Specifically, with the deficiency of U-Net based on pure convolutions, the Swin Transformer is embedded into U-Net for improving the ability to capture the global dependence. Then, given the inadequacy of the Swin Transformer capturing the local attention, the reintroduction of convolutions may capture more local attention. Thus, an ingenious manner is presented for the fusion of convolutions and the core attention mechanism to build a reinforced Swin-Convs Transformer block (RSCTB) for capturing more local attention, which is reinforced in the channel and the spatial attention of the Swin Transformer. Finally, experimental results on available datasets demonstrate that the proposed URSCT-SESR achieves the state-of-the-art performance compared with other methods in terms of both subjective and objective evaluations. The code is publicly available at https://github.com/TingdiRen/URSCT-SESR.","1558-0644","","10.1109/TGRS.2022.3205061","Natural Science Foundation of China(grant numbers:62171243,61871247,62071266,61931022,61671412,62271276); Zhejiang Natural Science Foundation of China(grant numbers:LY19F020009,LY21F010003,LY19F010002,LQ20F010002,LY21F010014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9881581","Super-resolution (SR);Swin-Convs Transformer;U-Net;underwater image enhancement (UIE)","Transformers;Atmospheric modeling;Generative adversarial networks;Image resolution;Image enhancement;Convolutional neural networks;Superresolution","image enhancement;image resolution","simultaneous underwater sensing scene image enhancement;super-resolution;image enhancement technology;degraded underwater images;light absorption;higher resolution images;underwater domain;simultaneous enhancement;URSCT-SESR;Swin Transformer;local attention;core attention mechanism;reinforced Swin-Convs Transformer block;restoring;scattering;novel U-Net-based reinforced Swin-Convs Transformer;superresolution;(URSCT-SESR) method;convolutions;Swin Transformer capturing;embedded;reintroduction;ingenious manner;fusion;mechanism;spatial attention;datasets demonstrate;state-of-the-art;subjective;objective evaluations;U-Net;capture;lower resolution;U","","2","","69","IEEE","8 Sep 2022","","","IEEE","IEEE Journals"
"SRDN: A Unified Super-Resolution and Motion Deblurring Network for Space Image Restoration","X. Yang; X. Wang; N. Wang; X. Gao","State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Transactions on Geoscience and Remote Sensing","21 Feb 2022","2022","60","","1","11","Space target super-resolution (SR) is a domain-specific single image SR problem aiming to help distinguish the satellite and spacecrafts from numerous space debris. Compared to the other object SR problem, images for space target are always in low quality with varies of degradation condition, as a result of long distance and motion blur, which significantly reduces the manual classification reliability, especially for these small targets, e.g., satellite payloads. To address this challenge, we present an end-to-end SR and deblurring network (SRDN). Concretely, focusing on the low-resolution (LR) space target images with blind motion blur, we integrate the SR and deblur function together, improving the image quality by a unified generative adversarial network (GAN)-based framework. We implement a deblur module by using contrastive learning to extract degradation feature and add symmetrical downsampling and upsampling modules to the SR network in order to restore texture information, while shortcut connections are redesigned to maintain the global similarity. Extensive experiments on the public satellite dataset, BUAA-SID-share1.5, demonstrate that our network outperforms the state-of-the-art SR and deblur methods.","1558-0644","","10.1109/TGRS.2021.3131264","National Natural Science Foundation of China(grant numbers:61976166,62036007,62176195,61922066,61876142); Key Research and Development Program of Shaanxi(grant numbers:2021GY-030); Innovation Capacity Support Plan of Shaanxi Province(grant numbers:2020KJXX-027); Fundamental Research Funds for the Central Universities(grant numbers:JB210115); Open Research Projects of Zhejiang Laboratory(grant numbers:2021KG0AB01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9627923","Artificial intelligence;artificial neural networks;high-resolution (HR) imaging;image denoising","Feature extraction;Target recognition;Degradation;Image resolution;Superresolution;Generative adversarial networks;Image restoration","astronomical image processing;feature extraction;image motion analysis;image representation;image resolution;image restoration;image texture;learning (artificial intelligence);neural nets","blind motion blur;deblur function;image quality;unified generative adversarial network-based framework;deblur module;SR network;public satellite dataset;SRDN;unified super-resolution;motion deblurring network;space image restoration;space target super-resolution;domain-specific single image SR problem;space debris;object SR problem;manual classification reliability;low-resolution space target images;SR and deblurring network;symmetrical downsampling module;symmetrical upsampling module;BUAA-SID-share1.5 dataset","","3","","57","IEEE","29 Nov 2021","","","IEEE","IEEE Journals"
"Analysis of super-resolution radar imaging based on sparse regularization","X. Zhu; G. Jin; F. He; Z. Dong; G. Chen; D. Zhao","Institute of Space Electronic and Information Technology, National University of Defense Technology, Changsha, Hunan, P.R.China; Institute of Space Electronic and Information Technology, National University of Defense Technology, Changsha, Hunan, P.R.China; Institute of Space Electronic and Information Technology, National University of Defense Technology, Changsha, Hunan, P.R.China; Institute of Space Electronic and Information Technology, National University of Defense Technology, Changsha, Hunan, P.R.China; Shanghai Institute of Satellite Engineering (SISE), Shanghai, China; Shanghai Institute of Satellite Engineering (SISE), Shanghai, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","1046","1049","For sparse signals (direct or indirect), sparse imaging methods can break through limitations of the conventional SAR methods. In this paper, we introduce the basic theory of sparse representation and reconstruction, and then implements several imaging algorithms including FFT and sparse methods. Through comparison, we conclude a good sparse reconstruction algorithm in SAR imaging. Besides, a new strategy of finding a better regularization parameter in sparse reconstruction is implemented. The imaging result of us has a higher resolution and much lower side lobe than the conventional algorithm based on matched filter theory.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729265","SAR;regularization parameter;sparse;reconstruction","Imaging;Image resolution;Signal resolution;Synthetic aperture radar;Radar polarimetry;Radar imaging;Image reconstruction","image reconstruction;image representation;image resolution;matched filters;radar imaging;radar resolution;synthetic aperture radar","super-resolution radar imaging analysis;sparse regularization;sparse imaging method;SAR method;sparse representation;sparse reconstruction algorithm;FFT;SAR imaging;matched filter theory;synthetic aperture radar","","1","","7","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Super Resolution Detection Method of Moving Object based on Optical Image Fusion with MMW Radar","Z. Deng; Z. Cui; Z. Cao","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1900","1903","Due to the defects of millimeter wave (MMW) radar in angle resolution, with the increase of detection distance, the ability of radar to distinguish adjacent objects in azimuth direction will be weakened, resulting in the loss and misestimation of objects information. To solve this problem, radar and optical image object detection methods are fused. The information obtained from the optical image data is used to provide a prior information for radar signal processing algorithm, so as to improve the performance of radar object detection system. Based on the simulations and experiments in a variety of multi-object moving scenes, it shows that the fusion method can improve the detection accuracy of the system and restore the spatial location of the objects more accurately than traditional ways.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883395","millimeter wave radar;computer vision;sensor fusion;DOA;object detection","Laser radar;Radar detection;Signal processing algorithms;Object detection;Radar imaging;Millimeter wave radar;Optical imaging","image fusion;image resolution;object detection;optical images;radar signal processing","super resolution detection method;optical image fusion;MMW radar;millimeter wave radar;angle resolution;detection distance;adjacent objects;azimuth direction;misestimation;objects information;optical image object detection methods;optical image data;radar signal processing algorithm;radar object detection system;multiobject moving scenes;fusion method;detection accuracy","","","","10","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"On the Performance of Reweighted  $L_{1}$ Minimization for Tomographic SAR Imaging","P. Ma; H. Lin; H. Lan; F. Chen","Institute of Space and Earth Information Science and Shenzhen Research Institute, The Chinese University of Hong Kong, ShaTin, Hong Kong, China; Institute of Space and Earth Information Science and Shenzhen Research Institute, The Chinese University of Hong Kong, ShaTin, Hong Kong, China; State Key Laboratory of Resources and Environmental Information System, Institute of Geographic Sciences and Natural Resources Research, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Digital Earth Science, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China","IEEE Geoscience and Remote Sensing Letters","19 May 2017","2015","12","4","895","899","L1 minimization has proven to be useful for tomographic synthetic aperture radar (SAR) imaging because it has super-resolution capability and produces no sidelobes. However, it cannot always derive the sparsest solution and often yields outliers in recovery. Consequently, it is usually difficult to extract true persistent scatterers straightforwardly in practice. To enhance the sparsity, we introduce iterative reweighted L1 minimization for sparse inversion. The weight factor is computed in each iteration, according to the previous tomographic magnitude to establish a more democratic penalization rule. Our simulation results indicate that the reweighted algorithm can achieve perfect recovery when noise is lower. Specifically, when the signal-to-noise ratio is equal to 5 dB, two reweighted iterations can improve the probability of true sparsity from 29.2% to 99.8% for single scatterers and from 0.2% to 95.4% for double scatterers. Due to the enhanced sparsity, we can directly identify scatterers without the need for further model selection. The method is validated using 44 TerraSAR-X/ TanDEM-X images. Single and double scatterers are detected in urban areas. Verification using light detection and ranging (LiDAR) data indicates that we achieve submeter accuracy of the height estimates.","1558-0571","","10.1109/LGRS.2014.2365613","State Key Laboratory of Resources and Environmental Information System; Key Laboratory of Geodesy and Earth's Dynamics(grant numbers:SKLGED2014-2-3-E); Innovation and Technology Support Programme of HKSAR, China(grant numbers:ITS/075/13); National Key Technology R&D Program of China(grant numbers:2012BAH32B03); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6952913","Reweighted $L_{1}$ minimization;TerraSAR-X/TanDEM-X;tomographic synthetic aperture radar (SAR) imaging;urban areas;Reweighted $L_{1}$ minimization;TerraSAR-X/TanDEM-X;tomographic synthetic aperture radar (SAR) imaging;urban areas","Tomography;Minimization;Synthetic aperture radar;Signal to noise ratio;Image reconstruction;Remote sensing","digital elevation models;electromagnetic wave scattering;geophysical image processing;image resolution;iterative methods;minimisation;optical radar;radar imaging;remote sensing by radar;synthetic aperture radar;tomography","iterative reweighted L1 minimization;tomographic SAR imaging;synthetic aperture radar;super-resolution capability;persistent scatterer extraction;sparse inversion;weight factor;penalization rule;signal-to-noise ratio;TerraSAR-X images;TanDEM-X images;model selection;light detection and ranging;LiDAR;height estimation","","26","","12","IEEE","11 Nov 2014","","","IEEE","IEEE Journals"
"Self-Supervised Super-Resolution for Multi-Exposure Push-Frame Satellites","N. L. Nguyen; J. Anger; A. Davy; P. Arias; G. Facciolo","CNRS, ENS Paris-Saclay, Centre Borelli, Universite Paris-Saclay, France; Kayrros SAS; CNRS, ENS Paris-Saclay, Centre Borelli, Universite Paris-Saclay, France; CNRS, ENS Paris-Saclay, Centre Borelli, Universite Paris-Saclay, France; CNRS, ENS Paris-Saclay, Centre Borelli, Universite Paris-Saclay, France","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","1848","1858","Modern Earth observation satellites capture multi-exposure bursts of push-frame images that can be super-resolved via computational means. In this work, we propose a super-resolution method for such multi-exposure sequences, a problem that has received very little attention in the literature. The proposed method can handle the signal-dependent noise in the inputs, process sequences of any length, and be robust to inaccuracies in the exposure times. Furthermore, it can be trained end-to-end with self-supervision, without requiring ground truth high resolution frames, which makes it especially suited to handle real data. Central to our method are three key contributions: i) a base-detail decomposition for handling errors in the exposure times, ii) a noise-level-aware feature encoding for improved fusion of frames with varying signal-to-noise ratio and iii) a permutation invariant fusion strategy by temporal pooling operators. We evaluate the proposed method on synthetic and real data and show that it outperforms by a significant margin existing single-exposure approaches that we adapted to the multi-exposure case.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.00190","GENCI-IDRIS(grant numbers:2022-AD011012453RI,2022-ADO11012458RI); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9880235","Photogrammetry and remote sensing; Computational photography; Low-level vision; Self-& semi-& meta- & unsupervised learning","Photography;Earth;Satellites;Superresolution;Encoding;Pattern recognition;Signal resolution","cameras;geophysical image processing;image classification;image fusion;image reconstruction;image representation;image resolution;image sensors;image sequences;learning (artificial intelligence);remote sensing;terrain mapping","process sequences;exposure times;self-supervision;ground truth high resolution frames;noise-level-aware feature encoding;signal-to-noise ratio;single-exposure;multiexposure case;self-supervised super-resolution;multiexposure push-frame satellites;Modern Earth observation;capture multiexposure bursts;push-frame images;computational means;super-resolution method;multiexposure sequences;signal-dependent noise","","3","","58","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Super-resolution imaging method based on target null theory","D. Lu; B. Pang; S. Xing; D. Dai; X. Wang","State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics and Information System, National University of Defence Technology, Changsha, China; State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics and Information System, National University of Defence Technology, Changsha, China; State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics and Information System, National University of Defence Technology, Changsha, China; State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics and Information System, National University of Defence Technology, Changsha, China; College of Electronic Science, National University of Defence Technology, Changsha, China","IET International Radar Conference (IET IRC 2020)","22 Sep 2021","2020","2020","","1739","1743","Due to the extremely successful application in remote sensing, polarimetric radar systems are used to observe a large number of manmade targets, such as urban areas, ships and vehicles, etc. These targets contain many dihedral and trihedral structures, which can be strong scattering points in a radar image. However, due to the limitation of resolution, some scatters in one resolution cell cannot be resolved, making it difficult to achieve the fine structure of manmade targets. In order to solve this problem, a super-resolution imaging method based on target null theory is presented in this paper.","","","10.1049/icp.2021.0537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9545906","","","electromagnetic wave polarisation;image resolution;radar imaging;radar polarimetry","target null theory;remote sensing;polarimetric radar systems;manmade targets;dihedral structures;trihedral structures;strong scattering points;radar image;resolution cell;super-resolution imaging method","","","","","","22 Sep 2021","","","IET","IET Conferences"
"MUSIC-Based Super-Resolution CMP Velocity-Depth Analysis for Multilayer Cases","C. Zhou; M. Sato","Graduate School of Environmental Studies, Tohoku University, Sendai, Japan; Center for Northeast Asian Studies, Tohoku University, Sendai, Japan","IEEE Geoscience and Remote Sensing Letters","6 Feb 2023","2023","20","","1","5","This letter proposes a multiple signal classification (MUSIC)-based algorithm to generate a super-resolution velocity-depth spectrum for precise subsurface multilayer analysis, which cannot be achieved by conventional Common MidPoint (CMP) velocity-depth analysis. A self-adaptive peak detection process and a MUSIC algorithm with a modified steering matrix are the key components of the proposed method. Both numerical simulation and experimentation are used to verify the feasibility of this study. Regarding both accuracy and resolution, the results show that the suggested method outperforms the conventional SAR-based method, as the layer information on the spectra is correctly located and strongly focused. Moreover, the proposed approach can distinguish between the layers that cause weak reflections and those that cause strong reflections. Compared to previous studies, the proposed method enables self-adaptive super-resolution imaging in ground penetrating radar (GPR) CMP subsurface layer analysis, and it has a great potential for usage in other GPR subsurface applications.","1558-0571","","10.1109/LGRS.2023.3235363","Japan Science and Technology agency (JST) support for pioneering research initiated by the next generation home (Spring)(grant numbers:JPMJSP2114); Japan Society Promotion of Science (JSPS) KAKENHI(grant numbers:JP20K20990); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10012355","CMP;GPR;MUSIC;near field","Multiple signal classification;Time-domain analysis;Reflection;Estimation;Signal resolution;Covariance matrices;Superresolution","","","","","","12","IEEE","9 Jan 2023","","","IEEE","IEEE Journals"
"Research on GAN-based Image Super-Resolution Method","X. Xue; X. Zhang; H. Li; W. Wang","College of Information Science and Technology, Northeast Normal University, Changchun, China; College of Information Science and Technology, Northeast Normal University, Changchun, China; College of Information Science and Technology, Northeast Normal University, Changchun, China; College of Information Science and Technology, Northeast Normal University, Changchun, China","2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)","1 Sep 2020","2020","","","602","605","Super-Resolution (SR) refers to the reconstruction of high-resolution image from low-resolution image, which has important application value in object detection, medical imaging, satellite remote sensing and other fields. In recent years, with the rapid development of deep learning, the image super-resolution reconstruction method based on deep learning has made remarkable progress. In this paper, R-SRGAN (Residual Super-Resolution Generative Adversarial Networks) is used to build the model and realize image super-resolution. By adding residual blocks between adjacent convolutional layers of the GAN generator, more detailed information is retained. At the same time, the Wassertein distance is used as a loss function to enhance the training effect and achieve image super-resolution.","","978-1-7281-7005-3","10.1109/ICAICA50127.2020.9182617","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9182617","Super-Resolution;Image Processing;Generative Adversarial Networks","Image resolution;Signal resolution;Training;Generative adversarial networks;Generators;Interpolation;Gallium nitride","image reconstruction;image resolution;learning (artificial intelligence);neural nets;object detection","deep learning;image superresolution reconstruction method;GAN-based image superresolution method;residual superresolution generative adversarial networks;R-SRGAN","","3","","17","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Change Detection in Hyperdimensional Images Using Untrained Models","S. Saha; L. Kondmann; Q. Song; X. X. Zhu","Department of Aerospace, and Geodesy, Data Science in Earth Observation, Technical University of Munich, Ottobrunn, Germany; Remote Sensing Technology Institute, German Aerospace Center (DLR), Weßling, Germany; Remote Sensing Technology Institute, German Aerospace Center (DLR), Weßling, Germany; Department of Aerospace and Geodesy, Data Science in Earth Observation (SiPEO, former: Signal Processing in Earth Observation), Technical University of Munich, Ottobrunn, Germany","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","10 Nov 2021","2021","14","","11029","11041","Deep transfer-learning-based change detection methods are dependent on the availability of sensor-specific pretrained feature extractors. Such feature extractors are not always available due to lack of training data, especially for hyperspectral sensors and other hyperdimensional images. Moreover models trained on easily available multispectral (RGB/RGB-NIR) images cannot be reused on such hyperdimensional images due to their irregular number of bands. While hyperdimensional images show large number of spectral bands, they generally show much less spatial complexity, thus reducing the requirement of large receptive fields of convolution filters. Recent works in the computer vision have shown that even untrained deep models can yield remarkable result in some tasks like super-resolution and surface reconstruction. This motivates us to make a bold proposition that untrained lightweight deep model, initialized with some weight initialization strategy, can be used to extract useful semantic features from bi-temporal hyperdimensional images. Based on this proposition, we design a novel change detection framework for hyperdimensional images by extracting bitemporal features using an untrained model and further comparing the extracted features using deep change vector analysis to distinguish changed pixels from the unchanged ones. We further use the deep change hypervectors to cluster the changed pixels into different semantic groups. We conduct experiments on four change detection datasets: three hyperspectral datasets and a hyperdimensional polarimetric synthetic aperture radar dataset. The results clearly demonstrate that the proposed method is suitable for change detection in hyperdimensional remote sensing data.","2151-1535","","10.1109/JSTARS.2021.3121556","German Federal Ministry of Education, and Research; International Future AI lab; Artificial Intelligence for Earth Observation: Reasoning, Uncertainties, Ethics, and Beyond(grant numbers:01DD20001); European Research Council; European Union's Horizon 2020 research, and innovation programme(grant numbers:ERC-2016-StG-714087); Helmholtz Association through the Framework of Helmholtz AI(grant numbers:ZT-I-PF-5-01); Munich Unit @Aeronautics, Space, and Transport; Helmholtz Excellent Professorship; Data Science in Earth Observation - Big Data Fusion for Urban Research(grant numbers:W2-W3-100); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582825","Change detection (CD);deep image prior;deep learning;hyperdimensional images;hyperspectral images","Hyperspectral imaging;Feature extraction;Earth;Data models;Transfer learning;Deep learning;Synthetic aperture radar","feature extraction;geophysical image processing;image classification;image colour analysis;image resolution;image segmentation;learning (artificial intelligence);radar imaging;remote sensing;synthetic aperture radar;vectors","untrained model;deep change vector analysis;changed pixels;deep change hypervectors;change detection datasets;hyperdimensional polarimetric synthetic aperture radar dataset;hyperdimensional remote sensing data;deep transfer-learning-based change detection methods;sensor-specific pretrained feature extractors;easily available multispectral images;untrained deep models;untrained lightweight deep model;bi-temporal hyperdimensional images;novel change detection framework","","6","","55","CCBY","20 Oct 2021","","","IEEE","IEEE Journals"
"Super-Resolution for Hyperspectral and Multispectral Image Fusion Accounting for Seasonal Spectral Variability","R. A. Borsoi; T. Imbiriba; J. C. M. Bermudez","Lagrange Laboratory, Université Côte d’Azur, Nice, France; Department of Electrical Engineering, Federal University of Santa Catarina (DEE-UFSC), Florianópolis, Brazil; Department of Electrical Engineering, Federal University of Santa Catarina (DEE-UFSC), Florianópolis, Brazil","IEEE Transactions on Image Processing","12 Sep 2019","2020","29","","116","127","Image fusion combines data from different heterogeneous sources to obtain more precise information about an underlying scene. Hyperspectral-multispectral (HS-MS) image fusion is currently attracting great interest in remote sensing since it allows the generation of high spatial resolution HS images and circumventing the main limitation of this imaging modality. Existing HS-MS fusion algorithms, however, neglect the spectral variability often existing between images acquired at different time instants. This time difference causes variations in spectral signatures of the underlying constituent materials due to the different acquisition and seasonal conditions. This paper introduces a novel HS-MS image fusion strategy that combines an unmixing-based formulation with an explicit parametric model for typical spectral variability between the two images. Simulations with synthetic and real data show that the proposed strategy leads to a significant performance improvement under spectral variability and state-of-the-art performance otherwise.","1941-0042","","10.1109/TIP.2019.2928895","National Council for Scientific and Technological Development (CNPq)(grant numbers:304250/2017-1,409044/2018-0,141271/2017-5,204991/2018-8); Conselho Nacional de Desenvolvimento Científico e Tecnológico(grant numbers:PNPD/1811213); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8768351","Hyperspectral data;multispectral data;endmember variability;seasonal variability;super-resolution;image fusion","Image fusion;Spatial resolution;Sensors;Hyperspectral sensors;Image sensors;Atmospheric modeling","geophysical image processing;hyperspectral imaging;image fusion;image resolution;remote sensing","super-resolution;seasonal spectral variability;hyperspectral-multispectral image fusion;high spatial resolution HS images;imaging modality;HS-MS fusion algorithms;time difference;spectral signatures;different acquisition;seasonal conditions;novel HS-MS image fusion strategy;typical spectral variability;heterogeneous sources;time instants;constituent materials;remote sensing;unmixing-based formulation;explicit parametric model","","57","","45","IEEE","22 Jul 2019","","","IEEE","IEEE Journals"
"An Improved SRGAN Based Ambiguity Suppression Algorithm for SAR Ship Target Contrast Enhancement","J. Ai; G. Fan; Y. Mao; J. Jin; M. Xing; H. Yan","Key Laboratory of Radar Imaging and Microwave Photonics, Nanjing University of Aeronautics and Astronautics, Ministry of Education, Nanjing, China; Intelligent Interconnected Systems Laboratory of Anhui, Hefei University of Technology, Hefei, China; Intelligent Interconnected Systems Laboratory of Anhui, Hefei University of Technology, Hefei, China; Intelligent Interconnected Systems Laboratory of Anhui, Hefei University of Technology, Hefei, China; Academy of Advanced Interdisciplinary Research, Xidian University, Xi’an, China; Key Laboratory of Radar Imaging and Microwave Photonics, Nanjing University of Aeronautics and Astronautics, Ministry of Education, Nanjing, China","IEEE Geoscience and Remote Sensing Letters","29 Dec 2021","2022","19","","1","5","Due to the specific characteristics of synthetic aperture radar (SAR), there will be ambiguity interference in SAR images, resulting in low contrast of the ship target to the clutter. This letter proposes an improved super-resolution generative adversarial network (ISRGAN) based ambiguity suppression algorithm for SAR ship target contrast enhancement. The proposed ISRGAN is the first attempt of using GAN for SAR ambiguity suppression. As a post-processing procedure, it does not need prior information of SAR systems, so it can be applied to various observation scenes and different acquisition modes. The generator of ISRGAN embeds the residual dense network (RDN) to optimally fuse the global and local features of the image, and it effectively improves the completeness of the feature information used for SAR ship target contrast enhancement. The superiority of ISRGAN on ambiguity suppression is validated on the Chinese Gaofen-3 imagery.","1558-0571","","10.1109/LGRS.2021.3111553","National Natural Science Foundation of China(grant numbers:62071164,61701157); China Postdoctoral Science Foundation(grant numbers:2020T130165); open fund of Key Laboratory of Radar Imaging and Microwave Photonics, Nanjing University of Aeronautics and Astronautics, Ministry of Education(grant numbers:NJ20210008); Fundamental Research Funds for the Central Universities of China(grant numbers:JZ2020HGTB0012,PA2021AKSK0113); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9539247","Azimuth ambiguity suppression;improved super-resolution generative adversarial network (ISRGAN);synthetic aperture radar (SAR);target contrast enhancement","Feature extraction;Synthetic aperture radar;Convolution;Marine vehicles;Radar polarimetry;Generators;Generative adversarial networks","image enhancement;image resolution;object detection;radar imaging;ships;synthetic aperture radar","SAR ship target contrast enhancement;ISRGAN;improved SRGAN based ambiguity suppression algorithm;SAR images;super-resolution generative adversarial network based ambiguity suppression algorithm;SAR ambiguity suppression;SAR systems","","3","","15","IEEE","16 Sep 2021","","","IEEE","IEEE Journals"
"Complex-Valued Sparse Long Short-Term Memory Unit with Application to Super-Resolving SAR Tomography","K. Qian; Y. Wang; P. Jung; Y. Shi; X. X. Zhu","Data Science in Earth Observation, Technical University of Munich, Munich, Germany; Germany Aerospace Center, Remote Sensing Technology Institute, Wessling, Germany; Communications and Information Theory Chair, Technical University of Berlin, Berlin, Germany; Data Science in Earth Observation, Technical University of Munich, Munich, Germany; Germany Aerospace Center, Remote Sensing Technology Institute, Wessling, Germany","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","591","594","To achieve super-resolution synthetic aperture radar (SAR) tomography (TomoSAR), compressive sensing (CS)-based algorithms are usually employed, which are, however, computationally expensive, and thus is not often applied in large-scale processing. Recently, deep unfolding techniques have provided a good combination of physical model-based algorithms and the ability of neural networks to learn from data. In this vein, iterative CS-based algorithms can usually be un-rolled as neural networks with only 10 to 20 layers. When trained, it shows great computational efficiency for further TomoSAR processing. However, the learning architecture of neural networks built in this approach tends to result in error propagation and information loss, thus degrading the performance. In this paper, we propose to employ complex-valued sparse long short-term memory (CV-SLSTM) units to tackle this problem by incorporating historically updating information into the optimization procedure and preserving full information. Simulations are carried out to validate the performance of the proposed algorithm.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883246","SAR tomography;Super-resolution;Complex-valued neural network;deep learning","Veins;Neural networks;Superresolution;Computer architecture;Tomography;Logic gates;Propagation losses","image resolution;iterative methods;neural nets;radar imaging;radar resolution;synthetic aperture radar;tomography","physical model-based algorithms;neural networks;CS-based algorithms;great computational efficiency;TomoSAR processing;complex-valued sparse long short-term memory unit;super-resolving SAR tomography;large-scale processing","","","","10","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Hyperspectral Image Super-Resolution by Spectral Difference Learning and Spatial Error Correction","J. Hu; Y. Li; W. Xie","State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","25 Sep 2017","2017","14","10","1825","1829","A hyperspectral image (HSI) super-resolution (SR) is a highly attractive topic in computer vision. However, most existed methods require an auxiliary high-resolution (HR) image with respect to the input low-resolution (LR) HSI. This limits the practicability of these HSI SR methods. Moreover, these methods often destroy the important spectral information. This letter presents a deep spectral difference convolutional neural network (SDCNN) with the combination of a spatial-error-correction (SEC) model for HSI SR. This method allows for full exploration of the spectral and spatial correlations, which achieves a good spatial information enhancement and spectral information preservation. In the proposed method, the key band is automatically selected and super-resolved with the boundary bands. Meanwhile, spectral difference mapping between the LR and HR HSIs can be learned by the SDCNN, and then be transformed according to the SEC model, which aims at correcting the spatial error while preserving the spectral information. The rest nonkey bands will be super-resolved under the guidance of the transformed spectral difference. Experimental results on synthesized and real-scenario HSIs suggest that the proposed method: (1) achieves comparable performance without requiring any auxiliary images of the same scene and (2) requires less computation time than the state-of-the-art methods.","1558-0571","","10.1109/LGRS.2017.2737637","National Natural Science Foundation of China(grant numbers:61222101,61272120,61301287,61350110239); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019794","Convolutional neural network;hyperspectral image (HSI);spatial-error-correction (SEC);super-resolution (SR)","Spatial resolution;Correlation;Hyperspectral imaging;Training;Computer vision","feedforward neural nets;hyperspectral imaging;image enhancement;image resolution;learning (artificial intelligence);spectral analysis","hyperspectral image super-resolution;spectral difference learning;Spatial Error Correction;HSI SR methods;computer vision;deep spectral-difference convolutional neural network;SDCNN;spatial-error-correction model;SEC model;spectral correlations;spatial correlations;spatial information enhancement;spectral information preservation;boundary bands;spectral difference mapping;LR HSI;HR HSI;auxiliary images","","44","","12","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Aerial Image Super Resolution via Wavelet Multiscale Convolutional Neural Networks","T. Wang; W. Sun; H. Qi; P. Ren","College of Information and Control Engineering, China University of Petroleum (East China), Qingdao, China; College of Information and Control Engineering, China University of Petroleum (East China), Qingdao, China; College of Engineering, The University of Tennessee, Knoxville, TN, USA; College of Information and Control Engineering, China University of Petroleum (East China), Qingdao, China","IEEE Geoscience and Remote Sensing Letters","20 Apr 2018","2018","15","5","769","773","We develop an aerial image super-resolution method by training convolutional neural networks (CNNs) with respect to wavelet analysis. To this end, we commence by performing wavelet decomposition to aerial images for multiscale representations. We then train multiple CNNs for approximating the wavelet multiscale representations, separately. The multiple CNNs thus trained characterize aerial images in multiple directions and multiscale frequency bands, and thus enable image restoration subject to sophisticated culture variability. For inference, the trained CNNs regress wavelet multiscale representations from a low-resolution aerial image, followed by wavelet synthesis that forms a restored high-resolution aerial image. Experimental results validate the effectiveness of our method for restoring complicated aerial images.","1558-0571","","10.1109/LGRS.2018.2810893","National Natural Science Foundation of China(grant numbers:61671481); Qingdao Applied Fundamental Research(grant numbers:16-5-1-11-jch); Fundamental Research Funds for the Central Universities(grant numbers:18CX05014A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8316893","Convolutional neural networks (CNNs);super resolution;wavelet analysis","Wavelet analysis;Spatial resolution;Image restoration;Training;Convolutional neural networks;Convergence","convolution;edge detection;image resolution;image restoration;learning (artificial intelligence);neural nets;regression analysis;wavelet transforms","image restoration;wavelet synthesis;low-resolution aerial image;multiscale frequency bands;wavelet multiscale representations;multiple CNNs;wavelet decomposition;wavelet multiscale convolutional neural networks;aerial image super resolution;high-resolution aerial image","","26","","15","IEEE","15 Mar 2018","","","IEEE","IEEE Journals"
"An I/Q-Channel Modeling Maximum Likelihood Super-Resolution Imaging Method for Forward-Looking Scanning Radar","K. Tan; W. Li; J. Pei; Y. Huang; J. Yang","School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Geoscience and Remote Sensing Letters","21 May 2018","2018","15","6","863","867","Deconvolution techniques provide efficient implementations for super-resolution imaging for forward-looking scanning radar. However, deconvolution is normally an ill-posed problem, and the solution is extremely sensitive to noise. From a statistical perspective, maximum likelihood (ML) methods are able to condition the ill-posed problem into a well-posed one. Nevertheless, traditional ML methods only consider the amplitude of the echo and by ignoring the phase that do not adequately model the radar imaging system. In this letter, an I/Q-channel modeling ML method is proposed for forward-looking scanning radar. First, the probability model of the echo is deduced by jointly considering noise in the I and Q channels. Then, a probability density function of the received data is deduced and used to formulate the likelihood function. Finally, the targets can be precisely estimated by maximizing this likelihood function. The results of simulations and experiments are provided to illustrate the effectiveness of the proposed method.","1558-0571","","10.1109/LGRS.2018.2811043","National Natural Science Foundation of China(grant numbers:41661671117,61301273); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8320850","Forward-looking scanning radar;I/Q-channel modeling (IQCM);maximum likelihood (ML) method;super-resolution imaging","Radar imaging;Azimuth;Image resolution;Imaging;Data models;Scattering","deconvolution;maximum likelihood estimation;probability;radar imaging;radar resolution","likelihood function;maximum likelihood super-resolution imaging method;deconvolution techniques;echo;radar imaging system;I/Q-channel modeling ML method;probability density function;forward-looking scanning radar","","19","","21","IEEE","21 Mar 2018","","","IEEE","IEEE Journals"
"Super-resolution beamformer with coherence factor treatment","C. Li; H. Li; Q. Guo; J. Wang","Acoustic Science and Technology Laboratory, Harbin Engineering University, Key Laboratory of Marine Information Acquisition and Security (Harbin Engineering University), Ministry of Industry and Information College of Underwater Acoustic Engineering, Harbin Engineering University, Harbin, China; Acoustic Science and Technology Laboratory, Harbin Engineering University, Key Laboratory of Marine Information Acquisition and Security (Harbin Engineering University), Ministry of Industry and Information College of Underwater Acoustic Engineering, Harbin Engineering University, Harbin, China; Acoustic Science and Technology Laboratory, Harbin Engineering University, Key Laboratory of Marine Information Acquisition and Security (Harbin Engineering University), Ministry of Industry and Information College of Underwater Acoustic Engineering, Harbin Engineering University, Harbin, China; Acoustic Science and Technology Laboratory, Harbin Engineering University, Key Laboratory of Marine Information Acquisition and Security (Harbin Engineering University), Ministry of Industry and Information College of Underwater Acoustic Engineering, Harbin Engineering University, Harbin, China","2022 3rd International Conference on Geology, Mapping and Remote Sensing (ICGMRS)","18 Aug 2022","2022","","","338","344","Digita1 beamforming is widely used in underwater acoustical imaging systems, such as side-scan and multi-beam sonars, for subsea surveying, anti-terrorist and diver detecting. Without increasing the system complexity, e.g., enlarging the aperture size of the transducer array, the super-resolution beamformer (BF) seems attractive to improve the resolution and the resultant image quality. However, super-resolution BF approaches generally suffer from a rapid increase in terms of computation load as a price, e.g., invoked power spectrum estimators and compressive sensing solvers. To overcome such issue, a coherence factor (CF) is employed to refine the BF result (CF-BF). In this paper, CF is redefined to incorporate the Fresnel approximation, which can be implemented by FFT readily and efficiently. Generally, an extra FFT and three Hadamard matrix product are required in addition to the conventional BF. According to the simulation and experimental results, our proposed CF-BF enhances the resolution and performs well in suppressing the background noise level, performing on-per with the other state-of-the-art super-resolution BF approaches in terms of image quality while being much faster.","","978-1-6654-8595-1","10.1109/ICGMRS55602.2022.9849304","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849304","super-resolution;beamforming;coherence factor;acoustical image","Image quality;Transducers;Superresolution;Sonar;Imaging;Coherence;Real-time systems","approximation theory;array signal processing;compressed sensing;fast Fourier transforms;Fresnel diffraction;Hadamard matrices;image denoising;image enhancement;image resolution;sonar imaging","super-resolution beamformer;coherence factor treatment;digital beamforming;underwater acoustical imaging systems;multibeam sonars;subsea surveying;image quality;power spectrum estimator;diver detecting;antiterrorist detecting;Fresnel approximation;FFT;Hadamard matrix product;resultant image quality;power spectrum estimators;compressive sensing solvers","","","","46","IEEE","18 Aug 2022","","","IEEE","IEEE Conferences"
"Convolutional Neural Network Based Models for Improving Super-Resolution Imaging","Y. Sun; W. Zhang; H. Gu; C. Liu; S. Hong; W. Xu; J. Yang; G. Gui","College of Telecommunication and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; Jiangsu Key Laboratory of Big Data Security and Intelligent Processing, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunication and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Management, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunication and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunication and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunication and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunication and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China","IEEE Access","11 Apr 2019","2019","7","","43042","43051","Many fields, such as remote sensing, medical imaging, and biological detection, pose a technical challenge for achieving super-resolution imaging. Convolutional neural networks (CNNs) are considered one of the potential solutions to realize the super-resolution. In this paper three-layer, CNN-based models are proposed to reconstruct the super-resolution images using four optimization algorithms, i.e., stochastic gradient descent, adaptive gradient (AdaGrad), root mean square prop (RMSprop), and adaptive moment estimation (ADAM). Among these four optimizations, ADAM is considered to have the best performance. To further verify the impact of the number of convolution layers on performance, a selection of CNN-based models with four convolutional layers is then proposed, each of which is named with the convolution parameters. All the four-layer models are optimized with ADAM, and the experimental results indicate that the 9-3-3-5 model achieves the best performance in the super-resolution reconstruction task.","2169-3536","","10.1109/ACCESS.2019.2908501","National Natural Science Foundation of China(grant numbers:61672297); Jiangsu Specially Appointed Professor Program(grant numbers:RK002STP16001); Summit of the Six Top Talents Program of Jiangsu(grant numbers:XYDXX-010); Program for High-Level Entrepreneurial and Innovative Talents Introduction(grant numbers:CZ0010617002); Nanjing University of Posts and Telecommunications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8681029","Super-resolution imaging;deep learning;convolutional neural networks;adaptive moment estimation","Image resolution;Image reconstruction;Signal resolution;Optimization;Training;Biomedical imaging","convolutional neural nets;gradient methods;image reconstruction;image resolution;mean square error methods","convolutional neural network based models;super-resolution imaging;CNN-based models;ADAM;super-resolution reconstruction task;optimization algorithms;stochastic gradient descent;adaptive gradient;AdaGrad;root mean square prop;RMSprop;adaptive moment estimation","","24","","35","OAPA","3 Apr 2019","","","IEEE","IEEE Journals"
"Research on the Lake Surface Water Temperature Downscaling Based on Deep Learning","Z. Yu; K. Yang; Y. Luo; P. Wang; Z. Yang","Faculty of Geography, Yunnan Normal University, and GIS Technology Research Center of Resource and Environment in Western China, Ministry of Education, Yunnan, China; Faculty of Geography, Yunnan Normal University, and GIS Technology Research Center of Resource and Environment in Western China, Ministry of Education, Yunnan, China; Faculty of Geography, Yunnan Normal University, and GIS Technology Research Center of Resource and Environment in Western China, Ministry of Education, Yunnan, China; School of Information Science & Engineering, Yunnan University, Yunnan, China; College of Information Technology, Guangdong Polytechnic College, Guangdong, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15 Jun 2021","2021","14","","5550","5558","Lake surface water temperature (LSWT) is an important factor of water ecological environment. As global warming, LSWT is also on the rise. Research on the main reasons of LSWT rising is the basis for controlling and improving the regional ecological environment. However, it is difficult for the existing remote sensing images to take into account the temporal and spatial resolution. Low-resolution images have a serious impact on data accuracy and even produce incorrect results. Therefore, obtaining high temporal and spatial resolution images by downscaling is of great significance to more accurately analyze the temporal and spatial characteristics of LSWT. In this article, Dianchi Lake is selected as research area, and the high spatial resolution image (Landsat) and high temporal resolution image (MODIS) are taken as data. Based on the downscaling algorithm of statistics and learning, DisTrad– super-resolution convolutional neural network (SRCNN) downscaling model is proposed, and the monthly average dataset of LSWT with 50 m resolution is constructed. The results showed 1) DisTrad–SRCNN can reflect the most distribution characteristics of LSWT (SSIMday = 0.96, PSNRday = 23.97; SSIMnight = 0.95, PSNRnight = 24.99). 2) LSWT had an overall upward trend (CRday = 0.22 °C/10a, CRnight = 0.21 °C/10a), showing a cyclical change of cold–warm–cold about 4 years. 3) The northern and lakeshore area were basically in the high temperature, and the whole lake presents a 4–5-year warm–cold–warm periodic change; the LSWT closer to the urban and residential areas and its change rate were relatively high, which indirectly reflected the serious impact of human activities on LSWT.","2151-1535","","10.1109/JSTARS.2021.3079357","National Natural Science Foundation of China under Grant(grant numbers:41761084); China High Technology Research and Development Program(grant numbers:2012AA121402); Yunnan Natural Science Foundation of China under Grant(grant numbers:2016FD020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9428586","DisTrad;downscaling;lake surface water temperature (LSWT);plateau lakes;super-resolution convolutional neural network (SRCNN)","Lakes;Image resolution;Remote sensing;Spatial resolution;Earth;Artificial satellites;MODIS;Global warming","atmospheric temperature;climatology;ecology;geophysical image processing;global warming;image resolution;lakes;land surface temperature;neural nets;remote sensing;water quality","Lake surface water temperature downscaling;water ecological environment;LSWT rising;regional ecological environment;remote sensing images;high temporal resolution images;spatial resolution images;temporal characteristics;spatial characteristics;Dianchi Lake;high spatial resolution image;high temporal resolution image;superresolution convolutional neural network downscaling model;DisTrad","","2","","42","CCBY","11 May 2021","","","IEEE","IEEE Journals"
"Fast Sparse-TSVD Super-Resolution Method of Real Aperture Radar Forward-Looking Imaging","X. Tuo; Y. Zhang; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","21 Jul 2021","2021","59","8","6609","6620","Most existing super-resolution imaging methods fail to work in low signal-to-noise ratio (SNR) condition due to the ill-posed antenna measurement matrix, but the sparse-truncated singular value decomposition (TSVD) method can effectively suppress noise and improve azimuth resolution in low SNR condition. However, the current sparse-TSVD method encounters large computation cost, resulting in a slow algorithm speed. In this work, a fast sparse-TSVD super-resolution imaging method of real aperture radar is proposed. First, the proposed method is based on the results of TSVD, using the truncated unitary matrix and diagonal matrix to reconstruct the signal convolution model. The dimension of the reconstructed antenna measurement matrix reduces from  $N \times N$  to  $k \times N$ , and the dimension of the reconstructed echo matrix reduces from  $N \times 1$  to  $k \times 1$ , where  $N$  is azimuth sampling points and  $k$  is truncation parameter,  $N \gg k$ . Much of the expensive matrix– multiplication computation can then be performed on the smaller matrices, thereby accelerating the algorithm. Second, an objective function is established as the  ${l_{1}}$  constraint based on the regularization strategy. Lastly, this article employs iterative reweighted least square (IRLS) method to solve the objective function, and the dimension of the reversed matrix is lessened from  $N \times N$  to  $k \times k$ , speeding up the algorithm further. The simulation and real data verify that the proposed algorithm not only improves the azimuth resolution in low SNR condition but also increases computational efficiency compared with the sparse-TSVD method.","1558-0644","","10.1109/TGRS.2020.3027053","National Natural Science Foundation of China(grant numbers:61901090); Collaborative Innovation Center of Information Sensing and Understanding; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9228888","Real aperture radar (RAR);sparse-truncated singular value decomposition (TSVD);super-resolution","Radar imaging;Azimuth;Antenna measurements;Imaging;Signal resolution","convolution;image reconstruction;image resolution;image sampling;iterative methods;least squares approximations;matrix algebra;matrix multiplication;optimisation;radar imaging;radar resolution;singular value decomposition","truncation parameter;reweighted least square method;low SNR condition;truncated unitary matrix;diagonal matrix;signal convolution model;azimuth sampling points;fast sparse-TSVD superresolution method;real aperture radar forward-looking imaging;low signal-to-noise ratio condition;ill-posed antenna measurement matrix;sparse-truncated singular value decomposition method;noise suppression;matrix-multiplication computation;objective function;l1 constraint;regularization strategy;iterative reweighted least square method;IRLS method;computational efficiency","","17","","36","IEEE","16 Oct 2020","","","IEEE","IEEE Journals"
"Fast Super-resolution 3D SAR Imaging Using an Unfolded Deep Network","J. Gao; Y. Ye; S. Li; Y. Qin; X. Gao; X. Li","College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; TH Satellite Center of China, Beijing, China; TH Satellite Center of China, Beijing, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China","2019 IEEE International Conference on Signal, Information and Data Processing (ICSIDP)","21 Aug 2020","2019","","","1","5","For 3D Synthetic Aperture Radar (SAR) imaging, one typical approach is to achieve the cross-track ID focusing for each range-azimuth pixel after obtaining a stack of 2D complex-valued images. The cross-track focusing is the main difficulty as its aperture length is limited and the antenna positions are usually non-uniformly distributed. Sparsity regularization methods are widely used to tackle these problems. However, these methods are of obvious limitations. The most well-known ones are their heavy computational burdens and unsatisfied stabilities. In this letter, an efficient deep network-based cross-track imaging method is proposed. When trained, the imaging process, i.e. the forward propagation of the network, is made up of simple matrix-vector calculations and element-wise nonlinearity operations, which significantly speed up the imaging. Also, we find that the deep network is of good robustness against noise and model errors. Comprehensive simulations and experiments have been carried out, and the superiority of the proposed method can be clearly seen.","","978-1-7281-2345-5","10.1109/ICSIDP47821.2019.9173392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173392","3D Synthetic Aperture Radar (3D SAR);line spectral estimation;deep networks;tomography SAR (TomoSAR);down-looking linear array SAR (DLLA-SAR)","","image reconstruction;image resolution;radar imaging;remote sensing by radar;synthetic aperture radar","imaging process;efficient deep network-based cross-track imaging method;heavy computational burdens;sparsity regularization methods;antenna positions;aperture length;cross-track focusing;2D complex-valued images;range-azimuth pixel;cross-track ID;3D Synthetic Aperture Radar imaging;unfolded deep network;fast super-resolution 3D SAR imaging","","7","","18","IEEE","21 Aug 2020","","","IEEE","IEEE Conferences"
"Super-Resolution of Seismic Velocity Model Guided by Seismic Data","Y. Li; J. Song; W. Lu; P. Monkam; Y. Ao","Department of Automation, Easy-Signal Group, State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China; Geophysical Department, Research Institute of Petroleum Exploration and Development, CNPC, Beijing, China; Department of Automation, Easy-Signal Group, State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China; Department of Automation, Easy-Signal Group, State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China; Department of Automation, Easy-Signal Group, State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","29 Dec 2021","2022","60","","1","12","Recently, a multitask learning framework named M: multitask, R: global residual skip connection structure, U: encoder–decoder structure of U-Net, D: dense skip connection structure, and SR: super-resolution (M-RUDSR) has successfully improved the accuracy of full-waveform inversion (FWI) results by enhancing the resolution of the seismic velocity model. However, M-RUDSR does not make full use of seismic data even though it contains high wavenumber information, which can help enhance the resolution of the velocity model. Moreover, the effects of employing seismic data realized by simply increasing the model’s input and output channels are limited since the seismic velocity model and seismic data are in different frequency bands. Therefore, we propose to consider super-resolution (SR) of seismic data and its edge images as supplementary auxiliary tasks of the seismic velocity model SR. Besides, the proposed method named M-RUDSRv2 improves the resolution of the seismic velocity model leveraging a three-step learning strategy. First, the model in M-RUDSRv2 is trained preliminarily on the specific data where the seismic velocity model and seismic data are in the same blurring levels. Then, the pretrained model is fine-tuned on the extensive data, where the seismic velocity model and seismic data are in various kinds of blurring levels, to achieve strong generalization ability. Finally, the fitted model focuses on improving the resolution of the seismic velocity model by adjusting the parameters in the loss function. Comparative experiments on synthetic and field data validate the superior performance of M-RUDSRv2 compared with M-RUDSR in SR of the seismic velocity model.","1558-0644","","10.1109/TGRS.2021.3075622","National Key Research and Development Program of China(grant numbers:2018YFA0702501); NSFC(grant numbers:41974126); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426445","Deep learning;multitask learning (MTL);seismic data;seismic velocity model;super-resolution","Data models;Image edge detection;Task analysis;Training;Superresolution;Pipelines;Computational modeling","geophysical signal processing;geophysical techniques;seismic waves;seismology","seismic data;seismic velocity model;multitask learning framework;global residual skip connection structure;U-Net encoder-decoder structure;dense skip connection structure;full-waveform inversion;edge images;supplementary auxiliary tasks","","6","","35","IEEE","7 May 2021","","","IEEE","IEEE Journals"
"FDFNet: A Fusion Network for Generating High-Resolution Fully PolSAR Images","L. Lin; H. Shen; J. Li; Q. Yuan","School of Resource and Environmental Sciences, Wuhan University, Wuhan, China; Collaborative Innovation Center of Geospatial Technology and the School of Resource and Environmental Sciences, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; Collaborative Innovation Center of Geospatial Technology and the School of Geodesy and Geomatics, Wuhan University, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","7 Jan 2022","2022","19","","1","5","Deep learning shows potential superiority in the image fusion field. To solve the problem of the spatial resolution degradation of polarimetric synthetic aperture radar (PolSAR) images caused by system limitation, we propose a fully PolSAR images and DualSAR images fusion network (FDFNet). We use low resolution (LR)-PolSAR super-resolution (LPSR) and modified cross attention mechanism (MCroAM) to perform data fusion on LR-PolSAR and high resolution (HR)-dual-polarization synthetic aperture radar (DualSAR) and design a polarimetric decomposition attention module to introduce the polarimetric parameters of LR-PolSAR images to maintain polarimetric information. Besides, we use the differential information between LR-PolSAR and HR-DualSAR to guide spatial resolution reconstruction. The loss function based on the  $L_{1} $  norm is used to constrain the network training process. The experimental results show the superiority of the proposed method over the existing methods in visual and quantitative evaluation. In addition, polarimetric decomposition experiments verify the effectiveness of the proposed method to maintain polarimetric information.","1558-0571","","10.1109/LGRS.2021.3127958","National Natural Science Foundation of China(grant numbers:61671334,62071341); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9614198","Differential information;dual-polarization synthetic aperture radar (DualSAR);fully-polarimetric synthetic aperture radar (PolSAR);fusion;polarimetric decomposition","Feature extraction;Spatial resolution;Scattering;Image reconstruction;Superresolution;Image fusion;Handheld computers","geophysical image processing;image fusion;image reconstruction;image resolution;learning (artificial intelligence);radar imaging;radar polarimetry;remote sensing by radar;synthetic aperture radar","generating high-resolution fully PolSAR;image fusion field;spatial resolution degradation;polarimetric synthetic aperture radar images;fully PolSAR images;LR-PolSAR images;polarimetric information;DualSAR images fusion network;low resolution-PolSAR super-resolution","","","","8","IEEE","12 Nov 2021","","","IEEE","IEEE Journals"
"Learning Spatial-Spectral Prior for Super-Resolution of Hyperspectral Imagery","J. Jiang; H. Sun; X. Liu; J. Ma","Peng Cheng Laboray, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Peng Cheng Laboray, Shenzhen, China; Electronic Information School, Wuhan University, Wuhan, China","IEEE Transactions on Computational Imaging","8 Jul 2020","2020","6","","1082","1096","Recently, single gray/RGB image super-resolution reconstruction task has been extensively studied and made significant progress by leveraging the advanced machine learning techniques based on deep convolutional neural networks (DCNNs). However, there has been limited technical development focusing on single hyperspectral image super-resolution due to the high-dimensional and complex spectral patterns in hyperspectral image. In this article, we make a step forward by investigating how to adapt state-of-the-art deep learning based single gray/RGB image super-resolution approaches for computationally efficient single hyperspectral image super-resolution, referred as SSPSR. Specifically, we introduce a spatial-spectral prior network (SSPN) to fully exploit the spatial information and the correlation between the spectra of the hyperspectral data. Considering that the hyperspectral training samples are scarce and the spectral dimension of hyperspectral image data is very high, it is nontrivial to train a stable and effective deep network. Therefore, a group convolution (with shared network parameters) and progressive upsampling framework is proposed. This will not only alleviate the difficulty in feature extraction due to high dimension of the hyperspectral data, but also make the training process more stable. To exploit the spatial and spectral prior, we design a spatial-spectral block (SSB), which consists of a spatial residual module and a spectral attention residual module. Experimental results on some hyperspectral images demonstrate that the proposed SSPSR method enhances the details of the recovered high-resolution hyperspectral images, and outperforms state-of-the-arts. The source code is available at [Online]. Available: https://github.com/junjun-jiang/SSPSR.","2333-9403","","10.1109/TCI.2020.2996075","National Natural Science Foundation of China(grant numbers:61971165,61922027,61773295); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097432","Hyperspectral remote sensing;image super-resolution;deep convolutional neural networks (DCNNs);spatial-spectral prior","Hyperspectral imaging;Spatial resolution;Amplitude modulation;Imaging;Feature extraction","convolutional neural nets;feature extraction;hyperspectral imaging;image reconstruction;image representation;image resolution;image sampling;learning (artificial intelligence)","high-resolution hyperspectral images;spectral attention residual module;spatial residual module;spatial-spectral block;shared network parameters;effective deep network;stable network;hyperspectral image data;spectral dimension;hyperspectral training samples;hyperspectral data;spatial information;spatial-spectral prior network;computationally efficient single hyperspectral image super-resolution;state-of-the-art deep learning;complex spectral patterns;high-dimensional patterns;deep convolutional neural networks;advanced machine learning techniques;hyperspectral imagery","","79","","64","IEEE","20 May 2020","","","IEEE","IEEE Journals"
"Land Cover Change Detection at Subpixel Resolution With a Hopfield Neural Network","Q. Wang; W. Shi; P. M. Atkinson; Z. Li","Department of Land Surveying and GeoInformatics, The Hong Kong Polytechnic University, Kowloon, Hong Kong; The Hong Kong Polytechnic University, Kowloon, Hong Kong; Geography and Environment, University of Southampton, Highfield, Southampton, U.K.; Department of Land Surveying and GeoInformatics, The Hong Kong Polytechnic University, Kowloon, Hong Kong","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","19 May 2017","2015","8","3","1339","1352","In this paper, a new subpixel resolution land cover change detection (LCCD) method based on the Hopfield neural network (HNN) is proposed. The new method borrows information from a known fine spatial resolution land cover map (FSRM) representing one date for subpixel mapping (SPM) from a coarse spatial resolution image on another, closer date. It is implemented by using the thematic information in the FSRM to modify the initialization of neuron values in the original HNN. The predicted SPM result was compared to the original FSRM to achieve subpixel resolution LCCD. The proposed method was compared with the original unmodified HNN method as well as six state-of-the-art methods for LCCD. To explore the effect of uncertainty in spectral unmixing, which mainly originates from spectral separability in the input, coarse image, and the point spread function (PSF) of the sensor, a set of synthetic multispectral images with different class separabilities and PSFs was used in experiments. It was found that the proposed LCCD method (i.e., HNN with an FSRM) can separate more real changes from noise and produce more accurate LCCD results than the state-of-the-art methods. The advantage of the proposed method is more evident when the class separability is small and the variance in the PSF is large, that is, the uncertainty in spectral unmixing is large. Furthermore, the utilization of an FSRM can expedite the HNN-based processing required for LCCD. The advantage of the proposed method was also validated by applying to a set of real Landsat-Moderate Resolution Imaging Spectroradiometer (MODIS) images.","2151-1535","","10.1109/JSTARS.2014.2355832","Research Grants Council, Hong Kong(grant numbers:PolyU 5249/12E); Ministry of Science and Technology of China(grant numbers:2012BAJ15B04,2012AA12A305); National Natural Science Foundation of China(grant numbers:41331175); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6906234","Hopfield neural network (HNN);land cover change detection (LCCD);subpixel mapping (SPM);super-resolution mapping;Hopfield neural network (HNN);land cover change detection (LCCD);subpixel mapping (SPM);super-resolution mapping","Spatial resolution;Neurons;Remote sensing;Earth;Satellites;Uncertainty","geophysical techniques;land cover;remote sensing","land cover change detection;subpixel resolution;Hopfield neural network;LCCD method;fine spatial resolution land cover map;subpixel mapping;spatial resolution image;thematic information;neuron values;original unmodified HNN method;state-of-the-art methods;coarse image;sensor point spread function;synthetic multispectral images;Landsat-Moderate Resolution Imaging Spectroradiometer;MODIS images","","56","","65","IEEE","22 Sep 2014","","","IEEE","IEEE Journals"
"Deep Image- To-Image Transfer Applied to Resolution Enhancement of Sentinel-2 Images","M. Beaulieu; S. Foucher; D. Haberman; C. Stewart","Cornputer Research Institute of Montreal, Montreal, Quebec, Canada; Cornputer Research Institute of Montreal, Montreal, Quebec, Canada; Local Logic inc., Montreal, Canada; Local Logic inc., Montreal, Canada","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","2611","2614","Single Image Super-Resolution (SISR) is looking at restoring the missing high-resolution information from a single low-resolution image in order to increase the apparent spatial resolution by a factor of two or more. In recent years, convolution neural networks have been applied with great success to the problem of improving spatial resolution from a single image. With the advent of low-resolution (10 m) optical sensors such as Sentinel-2, it is interesting to explore the possibility of improving image resolution with Deep Learning (DL) techniques. The purpose of this article is to investigate the potential performances of recent DL super-resolution techniques. The techniques explored here include not only techniques for enhancing high-frequency content but also so-called image-to-image translation techniques based on Generative Adversarial Neural Networks (GAN). From our preliminary results, we show that GANs have the ability to restore complex textural information.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517655","Super-Resolution;Deep Learning;GAN;Optical Images","Spatial resolution;Training;Gallium nitride;Computer vision;Computer architecture;Neural networks","geophysical image processing;image resolution;image texture;neural nets","Deep image- to-image transfer;resolution enhancement;sentinel-2 images;Single Image Super-Resolution;missing high-resolution information;low-resolution image;apparent spatial resolution;convolution neural networks;low-resolution optical sensors;image resolution;super-resolution techniques;image-to-image translation techniques;Generative Adversarial Neural Networks;size 10.0 m","","7","","11","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Information multiple distillation super resolution network based on feedback mechanism","Y. Wu; Z. Chen; S. He; J. Wang","School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China; School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China","2021 IEEE Region 10 Symposium (TENSYMP)","4 Oct 2021","2021","","","1","6","There are lots of image data in the field of remote sensing, most of which have low-resolution due to the limited image sensor. The super-resolution method can effectively restore the low-resolution image to the high-resolution image. However, the existing super-resolution method has both heavy computing burden and number of parameters, which greatly limits the super resolution method in the mobile terminal. For saving costs, we propose the information multiple distillation network based on feedback mechanism (Feedback-IMDN), which considers the feedback mechanism as the framework to attain lower features through high-level refining. Further, for high-level feature extraction, we use the information multiple distillation blocks (IMDBs) to carry out hierarchical feature extraction with the method of course learning in the case of a small number of parameters. Compared to other state-of-the-art lightweight algorithms, our proposed algorithm can reach convergences more rapidly with fewer parameters, and the performance of the network can be markedly enhanced on the image texture and object contour reconstruction with better peak signal-to-noise ratio (PSNR) and structural similarity (SSIM).","2642-6102","978-1-6654-0026-8","10.1109/TENSYMP52854.2021.9550997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9550997","super resolution;information distillation;feedback mechanism","Image sensors;Image texture;PSNR;Convolution;Superresolution;Refining;Feature extraction","distillation;feature extraction;feedback;image enhancement;image reconstruction;image resolution;image texture;learning (artificial intelligence)","image sensor;highresolution imaging;information multiple distillation network;high-level refining;information multiple distillation blocks;feature extraction;image texture;object contour reconstruction;feedback-IMDN;lowresolution imaging;information multiple distillation superresolution network;PSNR;peak signal-to-noise ratio;structural similarity;SSIM","","","","18","IEEE","4 Oct 2021","","","IEEE","IEEE Conferences"
"Reconstructing Hyperspectral Images from RGB Inputs Based on Intrinsic Image Decomposition","N. Wang; S. Mei; Y. Zhang; B. Zhang; M. Ma; X. Zhang","School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2374","2377","Spectral super-resolution (SR), which generally reconstructs hyperspectral images (HSIs) from RGB inputs, has attracted lots of attention recently. In this paper, a spectral SR algorithm based on intrinsic image decomposition (IID) is proposed, in which RGB images are decomposed into reflectance images and shading images to fully explore RGB features for HSI reconstruction. Considering that features of the reflectance image are only related to the material of objects, the sparsity of material reflectivity is used to reconstruct the reflectance image of HSI. Moreover, an convonlutional neural network (CNN) is constructed to reconstruct shading parts of HSI. Finally, these two reconstructed results are fused to generate the high spectral resolution HSI and an enhancement network is also designed to further improve the recontruction performance. Experimental results with two benchmark datasets, ICVL and CAVE, demonstrate that the performance of the proposed algorithm is superior to several state-of-the-art spectral SR algorithms.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883751","National Natural Science Foundation of China(grant numbers:62171381); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883751","Hyperspectral;Super-resolution;Intrinsic image decomposition;Convolutional neural network","Reflectivity;Correlation;Neural networks;Superresolution;Geoscience and remote sensing;Image decomposition;Convolutional neural networks","computer vision;geophysical image processing;hyperspectral imaging;image classification;image colour analysis;image motion analysis;image reconstruction;image representation;image resolution;learning (artificial intelligence);neural nets","material reflectivity;reflectance image;reconstructed results;high spectral resolution HSI;state-of-the-art spectral SR algorithms;hyperspectral images;RGB inputs;intrinsic image decomposition;spectral SR algorithm;RGB images;reflectance images;shading images;RGB features;HSI reconstruction","","","","8","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Semisupervised Spectral Degradation Constrained Network for Spectral Super-Resolution","W. Chen; X. Zheng; X. Lu","University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Spectral Imaging Technology CAS, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China; Key Laboratory of Spectral Imaging Technology CAS, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","30 Dec 2021","2022","19","","1","5","Recently, various deep learning-based methods have been designed to improve the spectral resolution of the multispectral image (MSI) to obtain the hyperspectral image (HSI). These methods usually rely on sufficient MSI/HSI pairs for supervised training. However, collecting plentiful HSIs is time-consuming. In this letter, a semisupervised spectral degradation constrained network (SSDCN) is proposed to improve the spectral resolution of MSI. SSDCN is an autoencoder-like network that is composed of an encoder subnetwork for estimating HSI from input MSI and a decoder subnetwork for reconstructing MSI from the estimated HSI. A semisupervised training method is proposed to explore both MSI/HSI pairs and MSIs without ground-truth HSIs to optimize SSDCN. Simulated and two real databases are employed to demonstrate the effectiveness of SSDCN.","1558-0571","","10.1109/LGRS.2021.3079961","National Science Fund for Distinguished Young Scholars(grant numbers:61925112); National Natural Science Foundation of China(grant numbers:61806193,61772510); Innovation Capability Support Program of Shaanxi(grant numbers:2020KJXX-091,2020TD-015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440658","Deep learning;hyperspectral image (HSI);multispectral image (MSI);semisupervised training;spectral degradation;spectral super-resolution","Image reconstruction;Feature extraction;Degradation;Training;Hyperspectral imaging;Superresolution;Spatial databases","geophysical image processing;hyperspectral imaging;image classification;image resolution;learning (artificial intelligence);spectral analysis","semisupervised spectral degradation constrained network;spectral super-resolution;deep learning-based methods;spectral resolution;multispectral image;hyperspectral image;SSDCN;autoencoder-like network;input MSI;estimated HSI;semisupervised training method","","6","","21","IEEE","25 May 2021","","","IEEE","IEEE Journals"
"Spectral Super-Resolution via Model-Guided Cross-Fusion Network","R. Dian; T. Shan; W. He; H. Liu","National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, Xi’an, China; College of Electrical and Information Engineering and Key Laboratory of Visual Perception and Artificial Intelligence of Hunan Province, Hunan University, Changsha, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; School of Robotics, Hunan University, Changsha, China","IEEE Transactions on Neural Networks and Learning Systems","","2023","PP","99","1","12","Spectral super-resolution, which reconstructs a hyperspectral image (HSI) from a single red-green-blue (RGB) image, has acquired more and more attention. Recently, convolution neural networks (CNNs) have achieved promising performance. However, they often fail to simultaneously exploit the imaging model of the spectral super-resolution and complex spatial and spectral characteristics of the HSI. To tackle the above problems, we build a novel cross fusion (CF)-based model-guided network (called SSRNet) for spectral super-resolution. In specific, based on the imaging model, we unfold the spectral super-resolution into the HSI prior learning (HPL) module and imaging model guiding (IMG) module. Instead of just modeling one kind of image prior, the HPL module is composed of two subnetworks with different structures, which can effectively learn the complex spatial and spectral priors of the HSI, respectively. Furthermore, a CF strategy is used to establish the connection between the two subnetworks, which further improves the learning performance of the CNN. The IMG module results in solving a strong convex optimization problem, which adaptively optimizes and merges the two features learned by the HPL module by exploiting the imaging model. The two modules are alternately connected to achieve optimal HSI reconstruction performance. Experiments on both the simulated and real data demonstrate that the proposed method can achieve superior spectral reconstruction results with relatively small model size. The code will be available at https://github.com/renweidian.","2162-2388","","10.1109/TNNLS.2023.3238506","Open Research Fund of Key Laboratory of Digital Earth Science, Aerospace Information Research Institute Chinese Academy of Sciences, Chinese Academy of Sciences(grant numbers:2022LDE005); National Natural Science Foundation of China(grant numbers:62201205,62221002,11872070,42271370,12072366); CAAI-Huawei MindSpore Open Fund; Changsha Natural Science Foundation of China(grant numbers:kq2202170); Hubei Province Key Laboratory of Intelligent Information Processing and Real-time Industrial System (Wuhan University of Science and Technology); Key Laboratory of Spatial Data Mining Information Sharing of Ministry of Education, Fuzhou University(grant numbers:2023LSDMIS01); Open Fund of State Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University; Open Research Project of The Hubei Key Laboratory of Intelligent Geo-Information Processing(grant numbers:KLIGIP-2022-A03); foundation of Key Laboratory of Artificial Intelligence, Ministry of Education, P(grant numbers:0000DONOTUSETHIS0000.R); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10028670","Convolutional neural network;cross fusion (CF);imaging model;spectral super-resolution","Superresolution;Imaging;Spatial resolution;Convolutional neural networks;Image reconstruction;Cameras;Training data","","","","","","","IEEE","27 Jan 2023","","","IEEE","IEEE Early Access Articles"
"A Regularized Focuss Method for Radar Forward-Looking Imaging","X. Tuo; S. Wu; Y. Zhang; X. Cai; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China; School of Information and Communication Engineering, University of Electronic Science and Technology of China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","7685","7688","Exploiting the sparse property of the target of interest to achieve super-resolution imaging has been applied to real aperture radar (RAR) forward-looking imaging field. In this paper, we proposed a regularized FOCUSS method to realize RAR forward-looking super-resolution imaging. In addition, we discussed the influence of initialization on the imaging result, and selected the most suitable initialization for RAR forward-looking super-resolution imaging. Compared with the traditional sparse method based on Majorize-Minimization, our proposed algorithm has faster convergence speed under the same parameters condition.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884941","National Natural Science Foundation of China(grant numbers:61901092,61901090); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884941","forward-looking imaging;sparse characteristics;regularized FOCUSS","Radar remote sensing;Superresolution;Imaging;Radar;Radar imaging;Apertures;Robustness","image resolution;radar imaging","regularized focuss method;super-resolution imaging;RAR;imaging result;real aperture radar forward-looking imaging field","","","","10","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"SRARNet: A Unified Framework for Joint Superresolution and Aircraft Recognition","W. Tang; C. Deng; Y. Han; Y. Huang; B. Zhao","Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Information and Electronics, Beijing Institute of Technology, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","6 Jan 2021","2021","14","","327","336","Aircraft recognition in high-resolution remote sensing images has rapidly progressed with the advance of convolutional neural networks (CNNs). However, the previous CNN-based methods may not work well for recognizing aircraft in low-resolution remote sensing images because the blurred aircraft in these images offer insufficient details to distinguish them from similar types of targets. An intuitive solution is to introduce superresolution preprocessing. However, conventional superresolution methods mainly focus on reconstructing natural images with detailed texture rather than constructing a high-resolution object with strong discriminative information for the recognition task. To address these problems, we propose a unified framework for joint superresolution and aircraft recognition (Joint-SRARNet) that tries to improve the recognition performance by generating discriminative, high-resolution aircraft from low-resolution remote sensing images. Technically, this network integrates superresolution and recognition tasks into the generative adversarial network (GAN) framework through a joint loss function. The generator is constructed as a joint superresolution and refining subnetwork that can upsample small blurred images into high-resolution ones and restore high-frequency information. In the discriminator, we introduce a new classification loss function that forces the discriminator to distinguish between real and fake images while recognizing the type of aircraft. In addition, the classification loss function is back-propagated to the generator to obtain high-resolution images with discriminative information for easier recognition. Extensive experiments on the challenging multitype aircraft of remote sensing images (MTARSI) dataset demonstrate the effectiveness of the proposed method in restoring a clear super-resolved image from a small blurred image and significant improvement in the recognition performance. To our knowledge, this is the first work on joint superresolution and aircraft recognition tasks.","2151-1535","","10.1109/JSTARS.2020.3037225","National Natural Science Foundation of China(grant numbers:91838303,91738302); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9254000","Aircraft recognition;multitask GAN;superresolution","Aircraft;Image recognition;Task analysis;Remote sensing;Generative adversarial networks;Aircraft manufacture;Generators","backpropagation;convolutional neural nets;image classification;image resolution;image restoration;image sampling;object recognition;remote sensing","convolutional neural networks;SRARNet;GAN framework;CNN-based methods;generative adversarial network framework;high-resolution aircraft;natural images;conventional superresolution methods;blurred aircraft;low-resolution remote sensing images;high-resolution remote sensing images;aircraft recognition;blurred image","","4","","42","CCBY","10 Nov 2020","","","IEEE","IEEE Journals"
"Robust and Fast Super-Resolution SAR Tomography of Forests Based on Covariance Vector Sparse Bayesian Learning","J. Wan; C. Wang; P. Shen; H. Fu; J. Zhu","School of Geosciences and Info-Physics, Central South University, Changsha, China; School of Geosciences and Info-Physics, Central South University, Changsha, China; School of Geosciences and Info-Physics, Central South University, Changsha, China; School of Geosciences and Info-Physics, Central South University, Changsha, China; School of Geosciences and Info-Physics, Central South University, Changsha, China","IEEE Geoscience and Remote Sensing Letters","20 Dec 2021","2022","19","","1","5","A novel method based on covariance vector sparse Bayesian learning (CV-SBL) is proposed in this letter to reconstruct the vertical structure of forests using a small number of synthetic aperture radar (SAR) images. This method regards the inversion of forests reflectivity profiles in the wavelet domain as a sparse signal reconstruction (SSR). Based on the covariance matrix matching criterion, the backscatter power of forests signal and noise will be jointly solved adaptively. Through a few iterations, the exact positions of the closely spaced phase centers can be obtained to simplify the characterization of the vertical structure of the forests. Unlike the traditional compressive sensing (CS) method based on  $\ell _{1} $  norm convex optimization, the novel method can obtain a real sparse solution without setting hyper-parameters and has a more reliable and accurate reconstruction performance. Besides, the computational efficiency of the new method is much higher than that of the  $\ell _{1} $  minimization CS method, and it is more suitable for large-scale forests mapping applications. The proposed method is validated using P-band TropiSAR 2009 data set over a test site in Paracou, French Guiana. Furthermore, the reconstruction performance of the proposed method is compared with the spectral analysis methods (Beamforming and Capon) and the  $\ell _{1} $  minimization super-resolution CS.","1558-0571","","10.1109/LGRS.2021.3060829","National Natural Science Foundation of China(grant numbers:41671356,41531068,41820104005); Innovation Foundation for Postgraduate of Central South University(grant numbers:2020zzts689); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9369846","Compressive sensing (CS);forests structure;sparse Bayesian learning (SBL);synthetic aperture radar (SAR) tomography","Forestry;Image reconstruction;Tomography;Backscatter;Synthetic aperture radar;Superresolution;Minimization","Bayes methods;compressed sensing;convex programming;covariance matrices;forestry;geophysical techniques;image reconstruction;image resolution;learning (artificial intelligence);radar imaging;radar resolution;spectral analysis;synthetic aperture radar;tomography;vegetation mapping","fast super-resolution SAR tomography;covariance vector sparse Bayesian learning;vertical structure;synthetic aperture radar images;sparse signal reconstruction;covariance matrix matching criterion;sparse solution;reliable reconstruction performance;large-scale forests mapping applications;spectral analysis methods;forest signal;forest reflectivity profiles;CV-SBL;SAR images;l1 minimization super-resolution CS;P-band TropiSAR 2009 data set;Paracou;French Guiana;SSR;backscatter power","","2","","14","IEEE","4 Mar 2021","","","IEEE","IEEE Journals"
"Indicator Cokriging-Based Subpixel Mapping Without Prior Spatial Structure Information","Q. Wang; P. M. Atkinson; W. Shi","Department of Land Surveying and Geo-Informatics, The Hong Kong Polytechnic University, Kowloon, Hong Kong; Geography and Environment, University of Southampton, Southampton, U.K.; Department of Land Surveying and Geo-Informatics, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","4 Aug 2014","2015","53","1","309","323","Indicator cokriging (ICK) has been shown to be an effective subpixel mapping (SPM) algorithm. It is noniterative and involves few parameters. The original ICK-based SPM method, however, requires the semivariogram of land cover classes from prior information, usually in the form of fine spatial resolution training images. In reality, training images are not always available, or laborious work is needed to acquire them. This paper aims to seek spatial structure information for ICK when such prior land cover information is not obtainable. Specifically, the fine spatial resolution semivariogram of each class is estimated by the deconvolution process, taking the coarse spatial resolution semivariogram extracted from the class proportion image as input. The obtained fine spatial resolution semivariogram is then used to estimate class occurrence probability at each subpixel with the ICK method. Experiments demonstrated the feasibility of the proposed ICK with the deconvolution approach. It obtains comparable SPM accuracy to ICK that requires semivariogram estimated from fine spatial resolution training images. The proposed method extends ICK to cases where the prior spatial structure information is unavailable.","1558-0644","","10.1109/TGRS.2014.2321834","Ministry of Science and Technology of China(grant numbers:2012BAJ15B04); National Natural Science Foundation of China(grant numbers:41201451,41331175); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6819417","Indicator cokriging (ICK);land cover mapping;semivariogram;subpixel mapping (SPM);super-resolution mapping;Indicator cokriging (ICK);land cover mapping;semivariogram;subpixel mapping (SPM);super-resolution mapping","Spatial resolution;Deconvolution;Training;Remote sensing;Indexes;Satellites;Vectors","deconvolution;geophysical image processing;image resolution;land cover;probability;terrain mapping","prior spatial structure information;indicator cokriging-based subpixel mapping method;SPM accuracy;deconvolution approach;class occurrence probability;class proportion image;coarse spatial resolution semivariogram;deconvolution process;fine spatial resolution semivariogram;land cover information;fine spatial resolution training images;land cover classes;effective subpixel mapping algorithm","","48","","58","IEEE","21 May 2014","","","IEEE","IEEE Journals"
"Single-Frame Super-Resolution Of Real-World Spaceborne Hyperspectral Data","K. Mishra; R. D. Garg","Geomatics Engineering Group, Civil Engineering Department, Indian Institute of Technology Roorkee, Roorkee, Uttarakhand, India; Geomatics Engineering Group, Civil Engineering Department, Indian Institute of Technology Roorkee, Roorkee, Uttarakhand, India","2022 12th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","22 Nov 2022","2022","","","1","5","Single-frame super-resolution (SFSR) is a well-researched issue in inverse imaging with the latest developments in the field of hyperspectral remote sensing. Paucity of open-source very high-resolution benchmark datasets restricts these algorithms from being applied to real-world scenes captured by hyperspectral sensors and the users have to contain with the outputs of the simulated trials. We attempt to narrow down this void by generating 15 m spatial resolution datasets from the 30 m spatial resolution Hyperion dataset of Ahmedabad, India through two classic SFSR algorithms: iterative back projection (IBP) and sparse representation (VSR). Visually inspecting land cover features and their spectral profiles in the super-resolved results against open-source panchromatic data shows the successful preservation of the spectral and spatial content of the original Hyperion data by VSR. No-reference image quality metrics confirm this finding although the processing time remains quite high compared to IBP.","2158-6276","978-1-6654-7069-8","10.1109/WHISPERS56178.2022.9955121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955121","Hyperion;Iterative back projection;Sparse representation;BRISQUE;NIQE","Measurement;Image quality;Visualization;Superresolution;Signal processing algorithms;Imaging;Iterative algorithms","","","","","","26","IEEE","22 Nov 2022","","","IEEE","IEEE Conferences"
"The study of super-resolution reconstruction based on visual attention and wavelet analysis","S. Wang; Zhi-Qiang Song; L. Zhang; X. Li; Z. Wang","Logistical Information and Military logistics Engineering Department, Logistical Engineering University; Logistical Information and Military logistics Engineering Department, Logistical Engineering University; Logistical Information and Military logistics Engineering Department, Logistical Engineering University, China; Logistical Information and Military logistics Engineering Department, Logistical Engineering University; Logistical Information and Military logistics Engineering Department, Logistical Engineering University","2015 12th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)","20 Jun 2016","2015","","","295","298","The super-resolution reconstruction is an important method for improving the image quality, which possesses widely application in the fields of video monitoring, remote sensing imaging, medical image processing, etc. In this paper, firstly, the salient edges and the boundaries of salient objects were obtained by using the salient characteristics of visual attention based on computer visual model and wavelet analysis; secondly, the super-resolution image was synthetically acquired by adopting the bilinear interpolation in the contour's internal region and the adaptive interpolation in the boundaries' external region respectively. The simulation results showed that the visual effect of the reconstructed model was more according with human visual characteristics. In addition, the subjective judgment and objective evaluation is better than traditional reconstruction algorithm. The algorithm in this paper achieves good effects and reaches good feasibility and validity.","","978-1-4673-8266-3","10.1109/ICCWAMTIP.2015.7493995","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493995","Visual Attention;Wavelet Analysis;Salient Edges;Adaptive Interpolation;Super-Resolution","Image edge detection;Image reconstruction;Interpolation;Visualization;Spatial resolution;Signal resolution","","","","","","7","IEEE","20 Jun 2016","","","IEEE","IEEE Conferences"
"Super-Resolution Based Deep Learning Techniques for Panchromatic Satellite Images in Application to Pansharpening","G. Rohith; L. S. Kumar","National Institute of Technology Puducherry at Karaikal, Puducherry, India; National Institute of Technology Puducherry at Karaikal, Puducherry, India","IEEE Access","14 Sep 2020","2020","8","","162099","162121","Pansharpening is a technique that fuses the coarser resolution of multispectral imagery (MS) with high spatial resolution panchromatic (PAN) imagery. Pansharpening is prone to spectral distortions based on the nature of the panchromatic band. If the spatial features are unclear in the panchromatic image, the pan-sharpened image will not be able to produce clear images. Super-Resolution (SR) is a technique that enhances minute details of the features in the image, thereby improving spatial information in the image. By fusing the Multispectral image with the super-resolved panchromatic image, there is a chance for producing high-quality multispectral imagery (pan-sharpened image). In this paper, ten state-of-the-art super-resolution based on deep learning techniques are tested and analyzed using ten different publicly available panchromatic datasets. On analysis, a feedback network for image super-resolution (SRFBN) technique outperforms the other algorithms in terms of sharp edges and pattern clarity, which are not visible in the input image. The proposed method is the fusion of SR applied PAN image with the MS image using a benchmarked Band Depended Spatial Detail (BDSD) pansharpening algorithm. The proposed method experiments with six datasets from different sensors. On analysis, the proposed technique outperforms the other counterpart pansharpening algorithms in terms of enhanced spatial information in addition to sharp edges and pattern clarity at reduced spectral distortion. Hence, the super-resolution based pansharpening algorithm is recommended for high spatial image applications.","2169-3536","","10.1109/ACCESS.2020.3020978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184034","Deep Learning (DL);convolution neural networks (CNN);pansharpening applications","Spatial resolution;Satellites;Training;Machine learning;Signal resolution;Sensors","geophysical image processing;image fusion;image resolution;learning (artificial intelligence);remote sensing","deep learning techniques;panchromatic satellite images;coarser resolution;high spatial resolution panchromatic imagery;panchromatic band;pan-sharpened image;Multispectral image;super-resolved panchromatic image;high-quality multispectral imagery;state-of-the-art super-resolution;image super-resolution technique;sharp edges;pattern clarity;input image;PAN image;MS image;benchmarked Band Depended Spatial Detail pansharpening algorithm;counterpart pansharpening algorithms;enhanced spatial information;high spatial image applications;panchromatic datasets","","5","","45","CCBYNCND","1 Sep 2020","","","IEEE","IEEE Journals"
"StfNet: A Two-Stream Convolutional Neural Network for Spatiotemporal Image Fusion","X. Liu; C. Deng; J. Chanussot; D. Hong; B. Zhao","Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Informationand Electronics, Beijing Institute of Technology, Beijing, China; Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Informationand Electronics, Beijing Institute of Technology, Beijing, China; Univ. Grenoble Alpes, CNRS, Grenoble INP, GIPSA-lab, Grenoble, France; Signal Processing in Earth Observation (SiPEO), Technical University of Munich (TUM), Munich, Germany; Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Informationand Electronics, Beijing Institute of Technology, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","27 Aug 2019","2019","57","9","6552","6564","Spatiotemporal image fusion is considered as a promising way to provide Earth observations with both high spatial resolution and frequent coverage, and recently, learning-based solutions have been receiving broad attention. However, these algorithms treating spatiotemporal fusion as a single image super-resolution problem, generally suffers from the significant spatial information loss in coarse images, due to the large upscaling factors in real applications. To address this issue, in this paper, we exploit temporal information in fine image sequences and solve the spatiotemporal fusion problem with a two-stream convolutional neural network called StfNet. The novelty of this paper is twofold. First, considering the temporal dependence among image sequences, we incorporate the fine image acquired at the neighboring date to super-resolve the coarse image at the prediction date. In this way, our network predicts a fine image not only from the structural similarity between coarse and fine image pairs but also by exploiting abundant texture information in the available neighboring fine images. Second, instead of estimating each output fine image independently, we consider the temporal relations among time-series images and formulate a temporal constraint. This temporal constraint aiming to guarantee the uniqueness of the fusion result and encourages temporal consistent predictions in learning and thus leads to more realistic final results. We evaluate the performance of the StfNet using two actual data sets of Landsat-Moderate Resolution Imaging Spectroradiometer (MODIS) acquisitions, and both visual and quantitative evaluations demonstrate that our algorithm achieves state-of-the-art performance.","1558-0644","","10.1109/TGRS.2019.2907310","National Natural Science Foundation of China(grant numbers:91438203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693668","Convolutional neural network;spatiotemporal image fusion;super-resolution;temporal consistency;temporal dependence (TD)","Spatial resolution;Spatiotemporal phenomena;Remote sensing;Earth;Convolutional neural networks;Image fusion","convolutional neural nets;image fusion;image resolution;image sequences;image texture;learning (artificial intelligence);spatiotemporal phenomena","neighboring fine images;quantitative evaluations;visual evaluations;structural similarity;Landsat-Moderate Resolution Imaging Spectroradiometer acquisitions;temporal consistent predictions;temporal constraint;time-series images;output fine image;spatiotemporal fusion problem;fine image sequences;temporal information;coarse image;significant spatial information loss;single image super-resolution problem;high spatial resolution;spatiotemporal image fusion;two-stream convolutional neural network;StfNet","","101","","41","IEEE","17 Apr 2019","","","IEEE","IEEE Journals"
"Uniqueness of iterative back projection in super resolution techniques","C. A. Iyanda; S. Nizam Bin Yaakob; M. Nawir","School of Computer and Communication Engineering, University Malaysia Perlis, Pauh, Malaysia; School of Computer and Communication Engineering, Universiti Malaysia Perlis, Arau, Perlis, MY; School of Computer and Communication Engineering, University Malaysia Perlis, Pauh, Malaysia","2016 3rd International Conference on Electronic Design (ICED)","5 Jan 2017","2016","","","501","506","Despite the recent plethora of empirical attempt at improving image quality in the emerging image processing field, image resolution is pressingly fraught with dire challenges today. Image enhancement research remained progressive because of the advancement in contemporary globalization that mandates an improvement in image quality and it becomes essential to run the best quality of image in some applications such as in forensic unit where in order to obtain the best information, image has to be enlarged in terms of size. Degraded image, often occasioned by motion blur, inaccurate focusing and sensor noise aggregate during the process of acquiring image through an image acquisition device (Camera). The improvisational capacity of super resolution imaging algorithm compensates this degradations by reconstructing a high resolution image from honing and harnessing single or multiple low resolution image to facilitate and foster enhanced visual contents and scene recognitions. High quality images are required in applications of different fields, such as remote sensing, satellite imaging, surveillance, medical imaging, etc. This paper attempts a conceptual enquiry and presents an overview of the conventional techniques of super resolution, how the techniques works along with their pros and cons accordingly, recent improvements carried out by different researchers are dutifully delineated. The Iterative back projection (IBP) method is hereby suggested a promising super resolution method due to its unique features highlighted.","","978-1-5090-2160-4","10.1109/ICED.2016.7804696","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7804696","Image enhancement;High resolution;Low resolution;Super resolution;Iterative back projection","Image reconstruction;Interpolation;Image edge detection;Frequency-domain analysis;Cameras;Spatial resolution","image enhancement;image resolution;iterative methods","iterative back projection;image quality;image processing field;Image enhancement research;image resolution;motion blur;image acquisition device;super resolution imaging algorithm;satellite imaging;remote sensing;surveillance;medical imaging;IBP method","","1","","28","IEEE","5 Jan 2017","","","IEEE","IEEE Conferences"
"Dual-Frequency SAR Tomography with Long Sparse Non-Uniform Baseline in Ground-Based Lunar Mapping","Y. Li; Y. Wang; Z. Ding; T. Zeng","Beijing Institute of Technology Chongqing Innovation Center, Chongqing, China; Beijing Institute of Technology Chongqing Innovation Center, Chongqing, China; Beijing Institute of Technology Chongqing Innovation Center, Chongqing, China; Beijing Institute of Technology Chongqing Innovation Center, Chongqing, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2915","2918","Tomographic synthetic aperture radar (TomoSAR) is used to achieve three-dimensional imaging. Existing methods mainly focus on super-resolution without ambiguity. However, the baseline is uncontrollable in ground-based lunar mapping, which leads to long sparse non-uniform baseline with altitude ambiguity. To suppress the altitude ambiguity, this paper proposes an innovative dual-frequency de-ambiguity method. The mechanism is to enhance real targets and suppress the spurious targets by multiplying the images at different frequency points. Specifically, genetic algorithm (GA) is applied to achieve the optimum frequencies with the lowest peak sidelobe ratio. The computer simulation and real data experiments verify the effectiveness of the proposed approach.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553160","Natural Science Foundation of Chongqing, China(grant numbers:cstc2020jcyj-msxmX0663); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553160","TomoSAR;dual-frequency;Genetic algorithm;Non-uniform sampling;Defuzzification","Computer simulation;Moon;Superresolution;Poles and towers;Geoscience and remote sensing;Tomography;Radar imaging","genetic algorithms;image reconstruction;image resolution;radar imaging;remote sensing by radar;synthetic aperture radar;tomography","three-dimensional imaging;ground-based lunar mapping;long sparse nonuniform baseline;altitude ambiguity;dual-frequency de-ambiguity method;different frequency points;optimum frequencies;frequency SAR tomography;tomographic synthetic aperture radar","","","","5","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Rethinking CNN-Based Pansharpening: Guided Colorization of Panchromatic Images via GANs","F. Ozcelik; U. Alganci; E. Sertel; G. Unal","Artificial Intelligence and Data Science Research and Application Center, Istanbul Technical University (ITU), Istanbul, Turkey; Research Center for Satellite Communications and Remote Sensing (CSCRS), Istanbul Technical University (ITU), Istanbul, Turkey; Research Center for Satellite Communications and Remote Sensing (CSCRS), Istanbul Technical University (ITU), Istanbul, Turkey; Artificial Intelligence and Data Science Research and Application Center, Istanbul Technical University (ITU), Istanbul, Turkey","IEEE Transactions on Geoscience and Remote Sensing","24 Mar 2021","2021","59","4","3486","3501","Convolutional neural network (CNN)-based approaches have shown promising results in the pansharpening of the satellite images in recent years. However, they still exhibit limitations in producing high-quality pansharpening outputs. To that end, we propose a new self-supervised learning framework, where we treat pansharpening as a colorization problem, which brings an entirely novel perspective and solution to the problem compared with the existing methods that base their solution solely on producing a super-resolution version of the multispectral image. Whereas the CNN-based methods provide a reduced-resolution panchromatic image as the input to their model along with the reduced-resolution multispectral images and, hence, learn to increase their resolution together, we instead provide the grayscale transformed multispectral image as the input and train our model to learn the colorization of the grayscale input. We further address the fixed downscale ratio assumption during training, which does not generalize well to the full-resolution scenario. We introduce a noise injection into the training by randomly varying the downsampling ratios. Those two critical changes, along with the addition of adversarial training in the proposed PanColorization generative adversarial network (PanColorGAN) framework, help overcome the spatial-detail loss and blur problems that are observed in CNN-based pansharpening. The proposed approach outperforms the previous CNN-based and traditional methods, as demonstrated in our experiments.","1558-0644","","10.1109/TGRS.2020.3010441","Research Fund of the Istanbul Technical University Project(grant numbers:MGA-2017-40811); Turkcell-ITU Researcher Funding Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9153037","AI;colorization;convolutional neural networks (CNNs);deep learning;generative adversarial networks (GANs);image fusion;PanColorization generative adversarial network (PanColorGAN);pansharpening;self-supervised learning;super-resolution (SR)","Task analysis;Spatial resolution;Training;Standards;Sensors;Multiresolution analysis","convolutional neural nets;geophysical image processing;image colour analysis;image resolution;supervised learning","adversarial training;grayscale transformed multispectral image;blur problems;PanColorGAN;panchromatic image resolution;PanColorization generative adversarial network;CNN based pansharpening;panchromatic image colorization;self supervised learning;satellite images;convolutional neural network;multispectral image resolution","","37","","44","IEEE","31 Jul 2020","","","IEEE","IEEE Journals"
"Hyperspectral Image Super-Resolution by Band Attention Through Adversarial Learning","J. Li; R. Cui; B. Li; R. Song; Y. Li; Y. Dai; Q. Du","CAS Key Laboratory of Spectral Imaging Technology, Xi’an, China; State Key Laboratory of Integrated Service Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; State Key Laboratory of Integrated Service Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; Department of Electronic and Computer Engineering, Mississippi State University, Starkville, USA","IEEE Transactions on Geoscience and Remote Sensing","21 May 2020","2020","58","6","4304","4318","Hyperspectral image (HSI) super-resolution (SR) is a challenging task due to the problems of texture blur and spectral distortion when the upscaling factor is large. To meet these two challenges, band attention through the adversarial learning method is proposed in this article. First, we put the SR process in a generative adversarial network (GAN) framework, so that the resulted high-resolution HSI can keep more texture details. Second, different from the other band-by-band SR method, the input of our method is of full bands. In order to explore the correlation of spectral bands and avoid the spectral distortion, a band attention mechanism is proposed in our generative network. A series of spatial-spectral constraints or loss functions is imposed to guide the training of our generative network so as to further alleviate spectral distortion and texture blur. The experiments on the Pavia and Cave data sets demonstrate that the proposed GAN-based SR method can yield very high-quality results, even under large upscaling factor (e.g., $8\times $ ). More importantly, it can outperform the other state-of-the-art methods by a margin which demonstrates its superiority and effectiveness.","1558-0644","","10.1109/TGRS.2019.2962713","National Nature Science Foundation of China(grant numbers:61901343); China Postdoctoral Science Foundation(grant numbers:2017M623124); China Postdoctoral Science Special Foundation(grant numbers:2018T111019); Open Research Fund of the CAS Key Laboratory of Spectral Imaging Technology(grant numbers:LSIT201924W); Fundamental Research Funds for the Central Universities(grant numbers:JB190107); National Nature Science Foundation of China(grant numbers:61571345,61671383,91538101,61501346,61502367); Higher Education Discipline Innovation Project(grant numbers:B08038); Innovation Fund of Xidian University(grant numbers:10221150004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8960413","Adversarial learning;band attention;hyperspectral image (HSI) super-resolution (SR)","Spatial resolution;Hyperspectral imaging;Distortion;Training;Gallium nitride","correlation methods;hyperspectral imaging;image resolution;image texture;learning (artificial intelligence);neural nets;spectral analysis","texture blur;spectral distortion;upscaling factor;adversarial learning method;SR process;generative adversarial network framework;band attention mechanism;spatial-spectral constraints;hyperspectral image superresolution;HSI;spectral bands correlation;loss functions","","43","","46","IEEE","15 Jan 2020","","","IEEE","IEEE Journals"
"Unsupervised Recurrent Hyperspectral Imagery Super-Resolution Using Pixel-Aware Refinement","W. Wei; J. Nie; L. Zhang; Y. Zhang","Research and Development Institute, Northwestern Polytechnical University in Shenzhen, Shenzhen, China; National Engineering Laboratory for Integrated Aerospace-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, Xi’an, China; National Engineering Laboratory for Integrated Aerospace-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, Xi’an, China; National Engineering Laboratory for Integrated Aerospace-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","2 Dec 2021","2022","60","","1","15","Unsupervised fusion-based hyperspectral imagery (HSI) super-resolution (SR) is an essential task of HSI processing, which aims to reconstruct a high-resolution (HR) HSI using only an observed low-resolution HSI and a conventional HR image. Although a large number of unsupervised HSI SR methods have been proposed, the heuristic handcrafted image priors adopted by the majority of these methods restrict their capacity to capture specific characteristics of the HSI, as well as their ability to generalize to noisy observation images. In this study, we investigate a fusion-based HSI SR framework with the deep image prior, in which the deep neural network (rather than a heuristic handcrafted image prior) is exploited to capture plenty of image statistics. Within this framework, we further propose an unsupervised recurrence-based HSI SR method using pixel-aware refinement, which utilizes the intermediate reconstruction results to self-supervise unsupervised learning. Due to containing the information of the image-specific characteristic, the proposed method achieves better performance, in terms of both accuracy and robustness to noise, compared with the existing methods. Extensive experiments on four HSI data sets demonstrate the effectiveness of the proposed method.","1558-0644","","10.1109/TGRS.2020.3039534","National Natural Science Foundation of China(grant numbers:61671385,62071387,U19B2037); Science, Technology and Innovation Commission of Shenzhen Municipality(grant numbers:JCYJ20190806160210899); Seed Foundation of Innovation and Creation for Graduate Students in Northwestern Polytechnical University(grant numbers:CX2020025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9292466","Hyperspectral image super-resolution (SR);pixel-aware refinement;unsupervised deep learning","Image reconstruction;Spatial resolution;Optimization;Computer science;Training;Spectral analysis;Sparse matrices","deep learning (artificial intelligence);geophysical image processing;hyperspectral imaging;image classification;image fusion;image reconstruction;image representation;image resolution;statistics;unsupervised learning","image statistics;unsupervised recurrence-based HSI SR method;pixel-aware refinement;self-supervise unsupervised learning;image-specific characteristic;low-resolution HSI;heuristic handcrafted image prior;noisy observation images;fusion-based HSI SR framework;deep image prior;unsupervised recurrent hyperspectral imagery superresolution;unsupervised fusion-based hyperspectral imagery superresolution;high-resolution HSI reconstruction;deep neural network","","37","","45","IEEE","11 Dec 2020","","","IEEE","IEEE Journals"
"Pansharpening by Convolutional Neural Networks in the Full Resolution Framework","M. Ciotola; S. Vitale; A. Mazza; G. Poggi; G. Scarpa","Department of Electrical Engineering and Information Technology, University of Naples Federico II, Naples, Italy; Department of Science and Technology, University of Naples Parthenope, Naples, Italy; Department of Electrical Engineering and Information Technology, University of Naples Federico II, Naples, Italy; Department of Electrical Engineering and Information Technology, University of Naples Federico II, Naples, Italy; Department of Electrical Engineering and Information Technology, University of Naples Federico II, Naples, Italy","IEEE Transactions on Geoscience and Remote Sensing","19 Apr 2022","2022","60","","1","17","In recent years, there has been a growing interest in deep learning-based pansharpening. Thus far, research has mainly focused on architectures. Nonetheless, model training is an equally important issue. A first problem is the absence of ground truths, unavoidable in pansharpening. This is often addressed by training networks in a reduced-resolution domain and using the original data as ground truth, relying on an implicit scale invariance assumption. However, on full-resolution images, results are often disappointing, suggesting such invariance not to hold. A further problem is the scarcity of training data, which causes a limited generalization ability and a poor performance on off-training-test images. In this article, we propose a full-resolution training framework for deep learning-based pansharpening. The framework is fully general and can be used for any deep learning-based pansharpening model. Training takes place in the high-resolution domain, relying only on the original data, thus avoiding any loss of information. To ensure spectral and spatial fidelity, a suitable two-component loss is defined. The spectral component enforces consistency between the pansharpened output and the low-resolution multispectral input. The spatial component, computed at high resolution, maximizes the local correlation between each pansharpened band and the panchromatic input. At testing time, the target-adaptive operating modality is adopted, achieving good generalization with a limited computational overhead. Experiments carried out on WorldView-3, WorldView-2, and GeoEye-1 images show that methods trained with the proposed framework guarantee a pretty good performance in terms of both full-resolution numerical indexes and visual quality.","1558-0644","","10.1109/TGRS.2022.3163887","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745494","Convolutional neural network (CNN);data fusion;deep learning;image enhancement;multiresolution analysis (MRA);spectral distortion;structural consistency;super resolution;unsupervised learning","Pansharpening;Training;Spatial resolution;Sensors;Task analysis;Remote sensing;Multiresolution analysis","geophysical image processing;image classification;image fusion;image resolution;learning (artificial intelligence);neural nets;remote sensing","high-resolution domain;spectral component enforces consistency;pansharpened output;low-resolution multispectral input;pansharpened band;framework guarantee;full-resolution numerical indexes;convolutional neural networks;full resolution framework;deep learning-based pansharpening;model training;equally important issue;ground truth;training networks;reduced-resolution domain;implicit scale invariance assumption;full-resolution images;training data;off-training-test images;full-resolution training framework","","11","","94","IEEE","31 Mar 2022","","","IEEE","IEEE Journals"
"Fast and Slow Changes Constrained Spatio-Temporal Subpixel Mapping","C. Zhang; Q. Wang; P. Lu; Y. Ge; P. M. Atkinson","College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; College of Surveying and Geo-Informatics, Tongji University, Shanghai, China; State Key Laboratory of Resources and Environmental Information System, Institute of Geographic Sciences and Natural Resources Research, Chinese Academy of Sciences, Beijing, China; Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","28 Feb 2022","2022","60","","1","16","Subpixel mapping (SPM) is a technique to tackle the mixed-pixel problem and produces land cover and land use (LCLU) maps at a finer spatial resolution than the original coarse data. However, uncertainty exists unavoidably in SPM, which is an ill-posed downscaling problem. Spatio-temporal SPM methods have been proposed to deal with this uncertainty, but current methods fail to explore fully the information in the time-series images, especially more rapid changes over a short-time interval. In this article, a fast and slow changes constrained spatio-temporal subpixel mapping (FSSTSPM) method is proposed to account for fast LCLU changes over a short time interval and slow changes over a long time interval. Both fast and slow changes-based temporal constraints are proposed and incorporated simultaneously into the FSSTSPM to increase the accuracy of SPM. The proposed FSSTSPM method was validated using two synthetic datasets with various proportion errors. It was also applied to oil-spill mapping using a real PlanetScope-Sentinel-2 dataset and Amazon deforestation mapping using a real Landsat-Moderate Resolution Imaging Spectroradiometer (MODIS) dataset. The results demonstrate the superiority of FSSTSPM. Moreover, the advantage of FSSTSPM is more obvious with an increase in proportion errors. The concepts of the fast and slow changes, together with the derived temporal constraints, provide a new insight to enhance SPM by taking fuller advantage of the temporal information in the available time-series images.","1558-0644","","10.1109/TGRS.2021.3133534","National Natural Science Foundation of China(grant numbers:41971297,42171345); Tongji University(grant numbers:02502350047); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9641799","Downscaling;Hopfield neural network (HNN);land cover and land use (LCLU);spatio-temporal dependence;subpixel mapping (SPM);super-resolution mapping","Spatial resolution;Neurons;Monitoring;Image resolution;Uncertainty;Remote sensing;Satellites","geophysical image processing;geophysical techniques;image classification;image resolution;land cover;marine pollution;remote sensing;terrain mapping;time series;vegetation mapping","oil-spill mapping;Amazon deforestation mapping;Landsat-Moderate Resolution Imaging Spectroradiometer dataset;fast changes;slow changes;derived temporal constraints;temporal information;available time-series images;mixed-pixel problem;land cover;finer spatial resolution;original coarse data;downscaling problem;spatio-temporal SPM methods;short-time interval;spatio-temporal subpixel mapping method;fast LCLU changes;short time interval;long time interval;FSSTSPM method","","","","55","IEEE","7 Dec 2021","","","IEEE","IEEE Journals"
"Symmetrical Feature Propagation Network for Hyperspectral Image Super-Resolution","Q. Li; M. Gong; Y. Yuan; Q. Wang","School of Electronic Engineering, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Xidian University, Xi’an, China; School of Artificial Intelligence, Optics and Electronics (iOPEN), Northwestern Polytechnical University, Xi’an, China; School of Artificial Intelligence, Optics and Electronics (iOPEN), Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","21 Sep 2022","2022","60","","1","12","Single hyperspectral image (HSI) super-resolution (SR) methods using a auxiliary high-resolution (HR) RGB image have achieved great progress recently. However, most existing methods aggregate the information of RGB image and HSI early during input or shallow feature extraction, whose difference between two images has not been treated and discussed. Although a few methods combine both the image features in the middle layer of the network, they fail to make full use of the two inherent properties, i.e., rich spectra of HSI and HR content of RGB image, to guide model representation learning. To address these issues, in this article, we propose a dual-stage learning approach for HSI SR to learn a general spatial–spectral prior and image-specific details, respectively. In the coarse stage, we fully take advantage of two adjacent bands and RGB image to build the model. During coarse SR, a symmetrical feature propagation approach is developed to learn the inherent content of each image over a relatively long range. The symmetrical structure encourages the two streams to better retain their particularity. Meanwhile, it can realize the information interaction by the adaptive local block aggregation (ALBA) module. To learn image-specific details, a back-projection refinement network is embedded in the structure, which further improves the performance in fine stage. The experiments on four benchmark datasets demonstrate that the proposed approach presents excellent performance over the existing methods. Our code is publicly available at https://github.com/qianngli/SFPN.","1558-0644","","10.1109/TGRS.2022.3203749","National Natural Science Foundation of China(grant numbers:U21B2041,U1864204,61825603); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9874913","Block aggregation;hyperspectral image (HSI);separation-and-aggregation;super-resolution (SR);symmetrical structure","Three-dimensional displays;Spatial resolution;Feature extraction;Ions;Superresolution;Image edge detection;Training","","","","1","","42","IEEE","2 Sep 2022","","","IEEE","IEEE Journals"
"Spatiotemporal Satellite Image Fusion Using Deep Convolutional Neural Networks","H. Song; Q. Liu; G. Wang; R. Hang; B. Huang","Jiangsu Key Laboratory of Big Data Analysis Technology, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Big Data Analysis Technology, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China; Collaborative Innovation Center on Forecast and Evaluation of Meteorological Disasters, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Big Data Analysis Technology, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China; Chinese University of Hong Kong, Hong Kong","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","12 Mar 2018","2018","11","3","821","829","We propose a novel spatiotemporal fusion method based on deep convolutional neural networks (CNNs) under the application background of massive remote sensing data. In the training stage, we build two five-layer CNNs to deal with the problems of complicated correspondence and large spatial resolution gaps between MODIS and Landsat images. Specifically, we first learn a nonlinear mapping CNN between MODIS and low-spatial-resolution (LSR) Landsat images and then learn a super-resolution CNN between LSR Landsat and original Landsat images. In the prediction stage, instead of directly taking the outputs of CNNs as the fusion result, we design a fusion model consisting of high-pass modulation and a weighting strategy to make full use of the information in prior images. Specifically, we first map the input MODIS images to transitional images via the learned nonlinear mapping CNN and further improve the transitional images to LSR Landsat images via the fusion model; then, via the learned SR CNN, the LSR Landsat images are supersolved to transitional images, which are further improved to Landsat images via the fusion model. Compared with the previous learning-based fusion methods, mainly referring to the sparse-representation-based methods, our CNNs-based spatiotemporal method has the following advantages: 1) automatically extracting effective image features; 2) learning an end-to-end mapping between MODIS and LSR Landsat images; and 3) generating more favorable fusion results. To examine the performance of the proposed fusion method, we conduct experiments on two representative Landsat-MODIS datasets by comparing with the sparse-representation-based spatiotemporal fusion model. The quantitative evaluations on all possible prediction dates and the comparison of fusion results on one key date in both visual effect and quantitative evaluations demonstrate that the proposed method can generate more accurate fusion results.","2151-1535","","10.1109/JSTARS.2018.2797894","National Natural Science Foundation of China(grant numbers:41501377,61532009,91546117); Foundation of Jiangsu Province of China(grant numbers:BK20150906,15KJA520001); National Social and Scientific Fund Program(grant numbers:16ZDA047); HKRGC General Research Fund(grant numbers:14606315); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291042","Convolutional neural network (CNN);nonlinear mapping (NLM);spatial resolution;temporal resolution","Remote sensing;Earth;Artificial satellites;Spatial resolution;MODIS;Spatiotemporal phenomena;Training","feature extraction;feedforward neural nets;geophysical image processing;image fusion;image representation;image resolution;learning (artificial intelligence);remote sensing","Landsat-MODIS datasets;end-to-end mapping learning;automatic effective image feature extraction;MODIS images;massive remote sensing data;low-spatial-resolution Landsat images;accurate fusion results;spatiotemporal fusion model;representative Landsat-MODIS datasets;spatiotemporal method;sparse-representation-based methods;learned SR CNN;LSR Landsat images;learned nonlinear mapping CNN;transitional images;prior images;super-resolution CNN;spatial resolution gaps;spatiotemporal fusion method;deep convolutional neural networks;spatiotemporal satellite image fusion","","170","","35","IEEE","13 Feb 2018","","","IEEE","IEEE Journals"
"Rapid Hyperspectral Imaging System via Sub-Sampling Coding","B. Wei; Z. Zhao; J. Han; J. Lu; H. Qi","Jiangsu Key Laboratory of Spectral Imaging and Intelligence Sense, Nanjing University of Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Spectral Imaging and Intelligence Sense, Nanjing University of Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Spectral Imaging and Intelligence Sense, Nanjing University of Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Spectral Imaging and Intelligence Sense, Nanjing University of Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Spectral Imaging and Intelligence Sense, Nanjing University of Science and Technology, Nanjing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","2 May 2022","2022","15","","2986","2997","In recent years, with the rapid advancement of hyperspectral imaging technology, a growing number of hyperspectral reconstruction approaches have arisen. However, most present technologies have the drawback of being unable to perform both quick spectrum measurement and high image resolution at the same time. In order to address this issue, this article proposes a rapid hyperspectral imaging system via subsampling coding. First, the hyperspectral scene is subsampled using the designed Hadamard coding matrix, then a suitable network structure for the hyperspectral image (HSI) super-resolution is investigated, and lastly high-resolution HSIs are obtained while the number of encodings is reduced. The experimental results reveal that this method is adaptable to a variety of imaging situations and performs well. At the same time, in the field of hyperspectral remote sensing, the problem of relatively low spatial resolution of HSI can be better solved. Furthermore, the method has unlimited image spectral dimensions, good generalization ability and noise reduction capabilities.","2151-1535","","10.1109/JSTARS.2022.3164725","National Natural Science Foundation of China(grant numbers:61901220,61727802,62101265); China Postdoctoral Science Foundation(grant numbers:2021M691592); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9749827","Deep learning;hyperspectral image (HSI);neural networks;subsampling;super-resolution (SR)","Hyperspectral imaging;Image reconstruction;Spatial resolution;Superresolution;Encoding;Image coding;Error correction codes","geophysical image processing;Hadamard codes;hyperspectral imaging;image reconstruction;image resolution;remote sensing","rapid hyperspectral imaging system;sub-sampling coding;rapid advancement;hyperspectral imaging technology;hyperspectral reconstruction approaches;high image resolution;subsampling coding;hyperspectral scene;designed Hadamard coding matrix;hyperspectral image super-resolution;high-resolution HSIs;hyperspectral remote sensing;unlimited image spectral dimensions","","","","44","CCBY","5 Apr 2022","","","IEEE","IEEE Journals"
"Multi-Temporal Ultra Dense Memory Network for Video Super-Resolution","P. Yi; Z. Wang; K. Jiang; Z. Shao; J. Ma","National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China","IEEE Transactions on Circuits and Systems for Video Technology","3 Aug 2020","2020","30","8","2503","2516","Video super-resolution (SR) aims to reconstruct the corresponding high-resolution (HR) frames from consecutive low-resolution (LR) frames. It is crucial for video SR to harness both inter-frame temporal correlations and intra-frame spatial correlations among frames. Previous video SR methods based on convolutional neural network (CNN) mostly adopt a single-channel structure and a single memory module, so they are unable to fully exploit inter-frame temporal correlations specific for video. To this end, this paper proposes a multi-temporal ultra-dense memory (MTUDM) network for video super-resolution. Particularly, we embed convolutional long-short-term memory (ConvLSTM) into ultra-dense residual block (UDRB) to construct an ultra-dense memory block (UDMB) for extracting and retaining spatio-temporal correlations. This design also reduces the layer depth by expanding the width, thus avoiding training difficulties, such as gradient exploding and vanishing under a large model. We further adopt multi-temporal information fusion (MTIF) strategy to merge the extracted temporal feature maps in consecutive frames, improving the accuracy without requiring much extra computational cost. The experimental results on extensive public datasets demonstrate that our method outperforms the state-of-the-art methods by a large margin.","1558-2205","","10.1109/TCSVT.2019.2925844","National Key Research and Development Project(grant numbers:2016YFE0202300); National Natural Science Foundation of China(grant numbers:61671332,U1736206,61773295); Hubei Technological Innovation Special Fund(grant numbers:2017AAA123); Natural Science Fund of Hubei Province(grant numbers:2018CFA024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8752034","Convolutional neural network (CNN);video super-resolution;ultra dense memory block (UDRB);multi-temporal fusion","Correlation;Feature extraction;Image reconstruction;Neural networks;Motion estimation","convolutional neural nets;feature extraction;image fusion;image reconstruction;image resolution;learning (artificial intelligence);motion estimation;recurrent neural nets;spatiotemporal phenomena;video signal processing","convolutional neural network;single memory module;inter-frame temporal correlations;multitemporal ultra-dense memory network;video super-resolution;ultra-dense residual block;ultra-dense memory block;spatio-temporal correlations;multitemporal information fusion strategy;extracted temporal feature maps;consecutive frames;multitemporal ultra dense memory network;high-resolution frames;low-resolution frames;intra-frame spatial correlations;video SR methods;UDMB;convolutional long-short-term memory;ConvLSTM;MTUDM;CNN;MTIF","","76","","54","IEEE","1 Jul 2019","","","IEEE","IEEE Journals"
"Super-Resolved Fine-Scale Sea Ice Motion Tracking","Y. Xian; Z. I. Petrou; Y. Tian; W. N. Meier","Department of Computer Science, City University of New York, New York, NY, USA; Department of Electrical Engineering, The City College, City University of New York, New York, NY, USA; Department of Electrical Engineering, The City College and the Department of Computer Science, City University of New York, New York, NY, USA; Cryospheric Science Laboratory, NASA Goddard Space Flight Center, Greenbelt, MD, USA","IEEE Transactions on Geoscience and Remote Sensing","25 Sep 2017","2017","55","10","5427","5439","Monitoring sea ice activities is particularly critical to safe naval operations in the Arctic Ocean. Accurately tracking sea ice motions is essential to validate or even improve sea ice models for ice hazard forecasts at a fine scale. Fine-scale motions can be tracked from high-resolution radar or optical satellite imagery but with limited coverage. Daily motions over the entire Arctic are retrievable from passive microwave data, but at a much lower spatial resolution. Thus, providing motions at the passive microwave spatial and temporal coverage, but at an enhanced spatial resolution, will be a significant benefit. To break the resolution limitation and to boost tracking accuracy, a sequential super-resolved fine-scale sea ice motion tracking framework is proposed in which a hybrid example-based single image super-resolution algorithm is employed before the tracking procedure. Experiments demonstrate that the proposed framework significantly improves the tracking performance in both accuracy and robustness for a benchmark algorithm and a recently proposed state-of-the-art tracking algorithm.","1558-0644","","10.1109/TGRS.2017.2699081","Office of Naval Research(grant numbers:N000141310450); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8006299","AMSR2;example-based learning;maximum cross correlation (MCC);motion tracking;passive microwave;patch redundancy;sea ice;Suomi national polar-orbiting partnership (NPP);super-resolution (SR)","Sea ice;Tracking;Spatial resolution;Microwave FET integrated circuits;Microwave imaging;Microwave integrated circuits","geophysical image processing;hazards;image resolution;oceanographic regions;oceanographic techniques;remote sensing by radar;sea ice","super-resolved sea ice motion tracking;fine-scale sea ice motion;sea ice activity monitoring;Arctic Ocean;ice hazard forecasts;high-resolution radar;optical satellite imagery;passive microwave data;tracking accuracy;single image super-resolution algorithm","","12","","50","IEEE","9 Aug 2017","","","IEEE","IEEE Journals"
"Applications of Deep Learning-Based Super-Resolution for Sea Surface Temperature Reconstruction","B. Ping; F. Su; X. Han; Y. Meng","School of Earth System Science, Institute of Surface-Earth System Science, Tianjin University, Tianjin, China; LREIS, Institute of Geographic Sciences and Natural Resources Research, University of the Chinese Academy of Sciences, Beijing, China; School of Earth System Science, Institute of Surface-Earth System Science, Tianjin University, Tianjin, China; National Marine Data and Information Service, Tianjin, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","6 Jan 2021","2021","14","","887","896","Deep learning-based super-resolution (SR) methods have been widely used in natural images; however, their applications in satellite-derived sea surface temperature (SST) have not yet been fully discussed. Hence, it is necessary to analyze the validity of deep learning-based SR methods in SST reconstruction. In this study, an SR model, including multiscale feature extraction and multireceptive field mapping, was first proposed. Then, the proposed model and four other existing SR models were applied to SST reconstruction and analyzed. First, compared with the bicubic interpolation method, the SR models can improve the reconstruction accuracy. Compared with four other SR models, the proposed model can achieve the lowest mean squared error (MAE) in the East China Sea (ECS), in the northwest Pacific (NWP) and in the west Atlantic (WA), the second-lowest MAE in the southeast Pacific (SEP); the lowest root mean squared error (RMSE) in ECS and WA, the second-lowest RMSE in NWP and SEP. Additionally, ODRE model can acquire the highest or the second-highest peak single-to-noise ratio and structural similarity index in ECS, NWP, and SEP. Moreover, the number of missing pixels and SST variety are two essential factors in the SR performance. The proposed multiscale feature extraction process can enhance the SR performance, especially for small regions and stable SST regions. Finally, while a deeper network can be helpful in achieving SR performance, the approach of simply adding more dilation convolutions may not enhance the reconstruction accuracy.","2151-1535","","10.1109/JSTARS.2020.3042242","Natural Science Foundation of Tianjin City(grant numbers:18JCQNJC08900); State Key Laboratory of Resources and Environmental Information System; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9280336","Advanced microwave scanning radiometer 2 (AMSR2);deep learning;moderate-resolution imaging spectroradiometer (MODIS);sea surface temperature;super-resolution","MODIS;Ocean temperature;Microwave theory and techniques;Microwave imaging;Image reconstruction;Data models;Training","feature extraction;geophysical image processing;image reconstruction;image resolution;ocean temperature;oceanographic regions","sea surface temperature reconstruction;deep learning-based super-resolution methods;satellite-derived sea surface temperature;deep learning-based SR methods;SST reconstruction;SR model;bicubic interpolation method;reconstruction accuracy;East China Sea;second-lowest MAE;root mean squared error;second-lowest RMSE;ODRE model;SST variety;SR performance;multiscale feature extraction process;stable SST regions;northwest Pacific","","4","","45","CCBY","3 Dec 2020","","","IEEE","IEEE Journals"
"Multiscale Spatial Fusion and Regularization Induced Unsupervised Auxiliary Task CNN Model for Deep Super-Resolution of Hyperspectral Images","V. K. Ha; J. Ren; Z. Wang; G. Sun; H. Zhao; S. Marshall","Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, U.K.; National Subsea Centre, Robert Gordon University, Aberdeen, U.K.; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Oceanography and Space Informatics, China University of Petroleum (East China), Qingdao, China; School of Computer Sciences, Guangdong Polytechnic Normal University, Guangzhou, China; Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, U.K.","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","16 Jun 2022","2022","15","","4583","4598","Hyperspectral images (HSI) feature rich spectral information in many narrow bands but at a cost of a relatively low spatial resolution. As such, various methods have been developed for enhancing the spatial resolution of the low-resolution HSI (Lr-HSI) by fusing it with high-resolution multispectral images (Hr-MSI). The difference in spectrum range and spatial dimensions between the Lr-HSI and Hr-MSI has been fundamental but challenging for multispectral/hyperspectral (MS/HS) fusion. In this article, a multiscale spatial fusion and regularization induced auxiliary task based convolutional neural network model is proposed for deep super-resolution of HSI, where an Lr-HSI is fused with an Hr-MSI to reconstruct a high-resolution HSI (Hr-HSI) counterpart. The multiscale fusion is used to efficiently address the discrepancy in spatial resolutions between the two inputs. Based on the general assumption that the acquired Hr-MSI and the reconstructed Hr-HSI share similar underlying characteristics, the auxiliary task is proposed to learn a representation for improved generality of the model and reduced overfitting. Experimental results on five public datasets have validated the effectiveness of our approach in comparison with several state-of-the-art methods.","2151-1535","","10.1109/JSTARS.2022.3176969","Natural Environment Research Council(grant numbers:NE/S002545/1); Dazhi Scholarship of GPNU; National Natural Science Foundation of China(grant numbers:41971292,62072122); Scientific and Technological Planning Projects of Guangdong Province(grant numbers:2021A0505030074); Scientific Research Capability Improvement Project of Guangdong Key Construction(grant numbers:2021ZDJS025); ETF Scholarship from the Faculty of Engineering; University of Strathclyde; Government Scholarship of Vietnam; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9779940","Auxiliary task;convolutional neural networks (CNN);hyperspectral image (HSI);super-resolution (SR);multiscale spatial fusion","Task analysis;Image reconstruction;Tensors;Superresolution;Spatial resolution;Bayes methods;Training","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;hyperspectral imaging;image classification;image fusion;image resolution;spectral analysis;unsupervised learning","deep super-resolution;hyperspectral images;spatial resolution;low-resolution HSI;Lr-HSI;high-resolution multispectral images;multiscale spatial fusion;convolutional neural network model;high-resolution HSI;multiscale fusion;unsupervised auxiliary task CNN model;spectral information;Hr-MSI;multispectral-hyperspectral fusion;Hr-HSI","","","","59","CCBY","23 May 2022","","","IEEE","IEEE Journals"
"Holographic SAR Tomography 3-D Reconstruction Based on Iterative Adaptive Approach and Generalized Likelihood Ratio Test","D. Feng; D. An; L. Chen; X. Huang","College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China","IEEE Transactions on Geoscience and Remote Sensing","24 Dec 2020","2021","59","1","305","315","Holographic synthetic aperture radar (HoloSAR) tomography is an attractive imaging mode that can retrieve the 3-D scattering information of the observed scene over 360° azimuth angle variation. To improve the resolution and reduce the sidelobes in elevation, the HoloSAR imaging mode requires many passes in elevation, thus decreasing its feasibility. In this article, an imaging method based on iterative adaptive approach (IAA) and generalized likelihood ratio test (GLRT) is proposed for the HoloSAR with limited elevation passes to achieve super-resolution reconstruction in elevation. For the elevation reconstruction in each range-azimuth cell, the proposed method first adopts the nonparametric IAA to retrieve the elevation profile with improved resolution and suppressed sidelobes. Then, to obtain sparse elevation estimates, the GLRT is used as a model order selection tool to automatically recognize the most likely number of scatterers and obtain the reflectivities of the detected scatterers inside one range-azimuth cell. The proposed method is a super-resolving method. It does not require averaging in range and azimuth, thus it can maintain the range-azimuth resolution. In addition, the proposed method is a user parameter-free method, so it does not need the fine-tuning of any hyperparameters. The super-resolution power and the estimation accuracy of the proposed method are evaluated using the simulated data, and the validity and feasibility of the proposed method are verified by the HoloSAR real data processing results.","1558-0644","","10.1109/TGRS.2020.2994201","National Natural Science Foundation of China(grant numbers:61571447); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099001","3-D imaging;generalized likelihood ratio test (GLRT);holographic synthetic aperture radar (HoloSAR) tomography;iterative adaptive approach (IAA)","Image resolution;Apertures;Image reconstruction;Signal resolution;Synthetic aperture radar;Tomography;Three-dimensional displays","geophysical image processing;image reconstruction;image resolution;iterative methods;radar imaging;radar interferometry;radar resolution;remote sensing by radar;spaceborne radar;synthetic aperture radar","holographic SAR tomography 3-D reconstruction;iterative adaptive approach;generalized likelihood ratio test;holographic synthetic aperture radar tomography;attractive imaging mode;3-D scattering information;observed scene;azimuth angle variation;sidelobes;HoloSAR imaging mode;imaging method;GLRT;elevation passes;super-resolution reconstruction;elevation reconstruction;range-azimuth cell;nonparametric IAA;elevation profile;sparse elevation estimates;model order selection tool;detected scatterers;super-resolving method;range-azimuth resolution;user parameter-free method;super-resolution power","","12","","28","IEEE","22 May 2020","","","IEEE","IEEE Journals"
"Hyperspectral Image Super-Resolution Based on Tensor Spatial-Spectral Joint Correlation Regularization","Y. Xing; S. Yang; L. Jiao","Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education of China, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education of China, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education of China, Xidian University, Xi’an, China","IEEE Access","14 Apr 2020","2020","8","","63654","63665","Compared with natural image super-resolution, hyperspectral image super-resolution (HSR) is more complex because the redundancy in spectral bands and spatial information. To overcome the difficulties exist in HSR, in this paper, we propose a tensor spatial-spectral joint correlation based HSR method. Start with the tensor representation, we construct a series of fourth-order tensors to preserve the intrinsic structure of hyperspectral images, and then explore the spatial-spectral joint correlation based on meaningful interpretations of tensor canonical matrices. To further constrain the spectral characteristics, we analyze the sparsity of the spectral gradients and model it with Laplacian prior. Then, the two regularizations are combined with the reconstruction model to develop a new HSR method. Finally, an iterative optimization algorithm based on alternating direction method of multiplier (ADMM) and augmented Lagrangian multiplier method is proposed to reconstruct the high-resolution hyperspectral images. Experimental results on several data sets illustrate the effectiveness of our proposed method both in visual and numerical comparisons.","2169-3536","","10.1109/ACCESS.2020.2982494","National Natural Science Foundation of China(grant numbers:61771380,U1701267,61906145,U1730109,91438103); Major Research Plan in Shaanxi Province of China(grant numbers:2017ZDXM-GY-103,2017ZDCXL-GY-03-02); Science Basis Research Program in Shaanxi Province of China(grant numbers:16JK1823,2017JM6086,2019JQ-663); China Postdoctoral Science Foundation(grant numbers:2018M643587); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9050714","Hyperspectral image;low-rank analysis;spatial-spectral joint correlation;super-resolution;tensor decomposition","Tensors;Correlation;Hyperspectral imaging;Spatial resolution","hyperspectral imaging;image reconstruction;image representation;image resolution;iterative methods;matrix algebra;optimisation;tensors","ADMM;alternating direction method of multiplier;high-resolution hyperspectral images;spectral gradients;spectral characteristics;tensor canonical matrices;fourth-order tensors;tensor representation;HSR method;spatial information;spectral bands;natural image super-resolution;tensor spatial-spectral joint correlation regularization;hyperspectral image super-resolution","","1","","46","CCBY","30 Mar 2020","","","IEEE","IEEE Journals"
"Improving spatial resolution of LANDSAT spectral bands from a single RGB image using artificial neural network","A. Marques; P. Rossa; R. K. Horota; D. Brum; E. M. de Souza; A. S. Aires; L. Kupssinskü; M. R. Veronez; L. Gonzaga; C. L. Cazarin","Advanced Vizualization & Geoinformatics Laboratory, Unisinos University, São Leopoldo, Brazil; Advanced Vizualization & Geoinformatics Laboratory, Unisinos University, São Leopoldo, Brazil; Advanced Vizualization & Geoinformatics Laboratory, Unisinos University, São Leopoldo, Brazil; Advanced Vizualization & Geoinformatics Laboratory, Unisinos University, São Leopoldo, Brazil; Advanced Vizualization & Geoinformatics Laboratory, Unisinos University, São Leopoldo, Brazil; Advanced Vizualization & Geoinformatics Laboratory, Unisinos University, São Leopoldo, Brazil; Advanced Vizualization & Geoinformatics Laboratory, Unisinos University, São Leopoldo, Brazil; Advanced Vizualization & Geoinformatics Laboratory, Unisinos University, São Leopoldo, Brazil; Advanced Vizualization & Geoinformatics Laboratory, Unisinos University, São Leopoldo, Brazil; CENPES Petrobras S.A, Rio de Janeiro, Brazil","2019 13th International Conference on Sensing Technology (ICST)","26 Mar 2020","2019","","","1","6","Spectral information provided by multispectral and hyperspectral sensors has a great impact on remote sensing studies. These sensors are embedded in aircrafts and satellites like the Landsat, which has more data freely available but lack the spatial resolution that suborbital sensors have. To increase the spatial resolution, a series of techniques have been developed like pansharpenning data fusion and more advanced convolutional neural networks for super-resolution, however, the later requires large datasets. To overcome this requirement, this work aims to increase the spatial resolution of Landsat spectral bands using artificial neural networks that uses pixel kernels of a single high-resolution image from Google Earth. Using this method, the high-resolution spectral bands were generated with pixel size of 1m in contrast to the 15m of pansharpenned Landsat bands. The evaluate the predicted spectral bands the validation measures Universal Quality Index (UQI) and Spectral Angle Mapper (SAM) were used, showing values of 0.98 and 0.16 respectively, presenting good results.","2156-8073","978-1-7281-4807-6","10.1109/ICST46873.2019.9047670","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9047670","Landsat;high resolution;prediction;multispectral;Artificial Neural Networks;Spatial resolution","Earth;Remote sensing;Spatial resolution;Artificial satellites;Satellites;Google","convolutional neural nets;geophysical image processing;image colour analysis;image fusion;image resolution;remote sensing;spectral analysis","high-resolution spectral bands;pansharpenned Landsat bands;Spectral Angle Mapper;spatial resolution;LANDSAT spectral bands;single RGB image;artificial neural network;Spectral information;multispectral sensors;hyperspectral sensors;suborbital sensors;advanced convolutional neural networks;super-resolution;Landsat spectral bands;single high-resolution image;Universal Quality Index","","","","41","IEEE","26 Mar 2020","","","IEEE","IEEE Conferences"
"Comparison of Optimized Mathematical Methods in the Improvement of Raster Data and Map Display Resolution of Sentinel-2 Images","E. Bratsolis; A. Panagiotopoulou; M. Stefouli; E. Charou; N. Madamopoulos; S. Perantonis","Institute of Informatics and Telecommunications, NCSR Demokritos, Ag. Paraskevi, Greece; Institute of Informatics and Telecommunications, NCSR Demokritos, Ag. Paraskevi, Greece; Greek Institute of Geology and Mineral Exploration (I.G.M.E.), Acharne, Greece; Institute of Informatics and Telecommunications, NCSR Demokritos, Ag. Paraskevi, Greece; Department of Aeronautical Sciences, TGA, Dhekeleia, Greece; Institute of Informatics and Telecommunications, NCSR Demokritos, Ag. Paraskevi, Greece","2018 25th IEEE International Conference on Image Processing (ICIP)","6 Sep 2018","2018","","","2521","2525","High-Resolution (HR) satellite images are a prerequisite in many applications such as astronomy, remote sensing, geoscience and geographical information systems, not only for providing better visualization but also for extracting extra information details. In the present work a comparative study of different single image resolution enhancement techniques is carried out on Sentinel-2 images of bands B2, B3, B4 and B8. The authors describe the stochastic regularized super-resolution (SR) reconstruction technique and compare with others. The techniques under comparison are stochastic regularized SR reconstruction (SRSR), spatial-wavelet SR reconstruction (SWSR) and the conventional interpolation techniques nearest neighbor (NN), bilinear (BL), bicubic (BC) and spline (SP). These techniques are tested against each other in terms of Root Mean Square Error (RMSE), Xydeas and Petrovich (XP), and Correlation Coefficient (CC). Simulated experiments of single image resolution increase take place.","2381-8549","978-1-4799-7061-2","10.1109/ICIP.2018.8451729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451729","Stochastic regularized technique;spatial-wavelet transform;super-resolution reconstruction;interpolation;satellite image resolution enhancement","Image reconstruction;Spatial resolution;Satellites;Interpolation;Imaging;Task analysis","geographic information systems;geophysical image processing;image enhancement;image reconstruction;image resolution;interpolation;mean square error methods;remote sensing;splines (mathematics);stochastic processes","RMSE;Root Mean Square Error;spline;spatial-wavelet SR reconstruction;stochastic regularized super-resolution;interpolation techniques nearest neighbor;image resolution enhancement techniques;high-resolution satellite images;geographical information systems;geoscience;Sentinel-2 images;map display Resolution;raster data;optimized mathematical methods","","3","","25","IEEE","6 Sep 2018","","","IEEE","IEEE Conferences"
"The regularization method based on tsvd for forward-looking radar angular superresolution","Y. Wu; Y. Zhang; Y. Zhang; D. Mao; Y. Huang; Y. Zha","University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; China Electronics Technology Group Corporation No. 38 Research Institute, Hefei, China","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","4467","4470","The low angular resolution of scanning radar limits the application in the forward-looking imaging field. This paper proposes the mixed method of truncated singular value decomposition (TSVD) with regularization l1 norm to achieve the angular super-resolution. First, the TSVD technique is applied to suppress the noise amplification and keep the main information of targets. Then the angular super-resolution is obtained by analyzing the main information in the form of regularization l1 norm. The mixed method has the better performance, comparing with the TSVD method and regularization method. The performance has the lower sensitivity to the regularization parameter. Simulations and experimental results verify the efficacy of this method.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127991","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127991","forward-looking;truncated singular value decomposition;regularization l1 norm;angular super-resolution","Signal resolution;Image resolution;Radar imaging;Azimuth;Sensitivity;Antennas","deconvolution;image resolution;radar imaging;singular value decomposition","forward-looking imaging field;regularization l norm;noise amplification;imaging field;radar limits the application;low angular resolution;radar angular superresolution;regularization parameter;regularization method;mixed method;TSVD technique;angular super-resolution;truncated singular value decomposition","","3","","9","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Downscaling Surface Albedo to Higher Spatial Resolutions With an Image Super-Resolution Approach and PROBA-V Satellite Images","S. Karalasingham; R. C. Deo; D. Casillas-Pérez; N. Raj; S. Salcedo-Sanz","Centre for Applied Climate Science, University of Southern Queensland, Toowoomba, QLD, Australia; Centre for Applied Climate Science, University of Southern Queensland, Toowoomba, QLD, Australia; Department of Signal Processing and Communications, Universidad Rey Juan Carlos, Fuenlabrada, Madrid, Spain; School of Mathematics, Physics and Computing, University of Southern Queensland, Springfield Central, QLD, Australia; Department of Signal Processing and Communications, Universidad de Alcalá, Alcalá de Henares, Madrid, Spain","IEEE Access","23 Jan 2023","2023","11","","5558","5577","For bifacial solar photovoltaic panels, surface albedo plays a crucial role in estimating the radiant energy. Since land surfaces are heterogeneous, the actual albedo of the surface where the solar photovoltaic panel is placed can vary widely and its temporality and sparsity present a significant challenge for renewable energy engineers. This paper develops a new image super-resolution deep learning model based on convolutional neural network to generate high resolution spatial representations of surface albedo from coarse resolution remote sensing-based data. For selected Australian locations, we generated a higher resolution surface albedo using imagery from PROBA-V/SPOT Earth Observation satellites. We proposed a Deep Downscaling Spectral Model with Attention (DDSA) with the capability of processing 10-day albedo images captured at a relatively low (≈ 1 km) resolution. The proposed DDSA was then applied to downscale observed surface albedo and generate predicted albedo at 500 m, 333 m and 250 m resolutions. The proposed model was benchmarked with alternative deep learning, super-resolution approaches: Super-Resolution Convolution Neural Network (SRCNN), Enhanced Deep Super-Resolution network (EDSR), Efficient Sub-Pixel Convolutional Neural Network (ESPCN) and Residual Dense Network (RDN). The results showed that the proposed DDSA model outperformed all comparative models in terms of the mean square error (MSE)  $\approx ~0.0041$ , signal-to-noise ratio (PSNR)  $\approx ~39.471$ , Structural Similarity Index (SSIM)  $\approx ~0.999$  vs. an MSE  $\approx $  [0.0140-0.0387], PSNR  $\approx $  [29.761-33.850], SSIM  $\approx $  [0.9994-0.999]). We also cross-validated the downscaled images with satellite imagery and ground-based observations, which reaffirmed the proposed DDSA model’s ability to produce high resolution surface albedo maps and its potential applications for granular scale tracking and mapping solar energy where bifacial solar photovoltaic panels are placed.","2169-3536","","10.1109/ACCESS.2023.3236253","University of Southern Queensland Domestic Ph.D. Research Scholarship; Research and Training Scheme Fee Scholarship from Australian Government; Senetas Corporation under the Australian Postgraduate Research Internship and an International Research Project funded by the Spanish Ministry of Science and Innovation (MICINN), Spain(grant numbers:PID2020-115454GB-C21); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10015024","Surface albedo downscaling;image super resolution;depth-wise separable convolution;bifacial solar photovoltaic system","Spatial resolution;Land surface;Energy resolution;Remote sensing;Sea surface;Superresolution;Predictive models","","","","","","61","CCBY","11 Jan 2023","","","IEEE","IEEE Journals"
"Downward-Looking Linear Array Three-Dimensional SAR Imaging Based on the Two-Dimensional Mismatch Compensation","L. Kang; T. -c. Sun; Y. Luo; Q. Zhang; J. -c. Ni","Collaborative Innovation Center of Information Sensing and Understanding, Xi'an, China; Collaborative Innovation Center of Information Sensing and Understanding, Xi'an, China; Key Laboratory for Information Science of Electromagnetic Waves (Ministry of Education), Fudan University, Shanghai, China; Key Laboratory for Information Science of Electromagnetic Waves (Ministry of Education), Fudan University, Shanghai, China; Collaborative Innovation Center of Information Sensing and Understanding, Xi'an, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","7 Jan 2021","2021","14","","258","269","For downward-looking linear array (DLLA) three-dimensional (3-D) synthetic aperture radar (SAR), it is necessary to realize the super-resolution in both azimuth and cross-track direction due to the limited lengths of the synthetic aperture and the linear array. As all the scatterers are assumed on the uniform grids, the cross-track super-resolution can be achieved by 1-D compressed sensing. In the real imaging system, however, the gridding error should be considered because the biased scatterers lead to the mismatch of the measurement matrix and affect the imaging performance. The 1-D mismatch in cross-track direction has been solved by atomic norm minimization and off-grid sparse Bayesian inference. With the development of the super-resolution methods, the 2-D super-resolution in both azimuth and cross-track direction is realized by the 2-D compressed sensing (CS) algorithms. To solve the 2-D mismatch problem, a novel 2-D mismatch compensation method for DLLA 3-D SAR is proposed. Instead of converting the 2-D matrix signals to the 1-D vectors, the proposed method directly processes the 2-D mismatch with 2-D joint model. Furthermore, the 2-D joint model with 2-D mismatch is simplified as a normal sparse linear model, which is suitable for most of the CS reconstruction algorithms. It can not only provide better reconstruction performance but also reduce the memory cost and computation load. Finally, the simulation experiments are shown to demonstrate the validity of the proposed method.","2151-1535","","10.1109/JSTARS.2020.3043523","National Natural Science Foundation of China(grant numbers:61631019,61871396,61971434); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289013","Array synthetic aperture radar (SAR);compressed sensing (CS);measurement matrix mismatch;super-resolution;three-dimensional (3-D) synthetic aperture radar (SAR)","Synthetic aperture radar;Imaging;Azimuth;Solid modeling;Scattering;Image reconstruction;Computational modeling","compressed sensing;electromagnetic wave scattering;image reconstruction;image resolution;minimisation;radar imaging;synthetic aperture radar","three-dimensional SAR;downward-looking linear array;normal sparse linear model;2-D joint model;2-D matrix signals;DLLA 3-D;2-D compressed sensing algorithms;2-D super-resolution;super-resolution methods;off-grid sparse Bayesian inference;imaging performance;gridding error;imaging system;1-D compressed sensing;cross-track super-resolution;uniform grids;cross-track direction;synthetic aperture radar;linear array three-dimensional;two-dimensional mismatch compensation","","4","","34","CCBY","9 Dec 2020","","","IEEE","IEEE Journals"
"Unaligned Hyperspectral Image Fusion via Registration and Interpolation Modeling","J. Ying; H. -L. Shen; S. -Y. Cao","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; Ningbo Research Institute, Zhejiang University, Ningbo, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China","IEEE Transactions on Geoscience and Remote Sensing","4 Jan 2022","2022","60","","1","14","In satellite remote sensing, the hyperspectral sensor acquires high-spectral-resolution and low-spatial-resolution hyperspectral images (HSIs). Conversely, the multispectral sensor acquires low-spectral-resolution and high-spatial-resolution multispectral images (MSIs). Thus, HSI and MSI fusion is required to promote both spatial and spectral resolutions. Currently, most algorithms are based on the assumption that the HSI and MSI are perfectly aligned. However, this is hardly achievable in real scenarios when the two sensors acquire images from different viewpoints. In this article, we propose a fusion algorithm that consists of two stages, i.e., image registration and image fusion. For image registration, we introduce the normalized edge difference (NED) for image similarity measure considering the different resolutions of the original images. For image fusion, we incorporate the interpolation process in the spatial degradation model to compensate for the interpolation error. Experimental results show that our algorithm performs better than the state of the arts for unaligned image fusion.","1558-0644","","10.1109/TGRS.2021.3081136","National Natural Science Foundation of China(grant numbers:81973751); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442904","Hyperspectral image (HSI);image fusion;image interpolation;image registration;image super-resolution;multispectral image (MSI)","Image registration;Interpolation;Image edge detection;Image fusion;Transforms;Superresolution;Matrix decomposition","geophysical image processing;geophysical signal processing;hyperspectral imaging;image classification;image fusion;image registration;image resolution;image sensors;interpolation;remote sensing","unaligned hyperspectral image fusion;satellite remote sensing;hyperspectral sensor;high-spectral-resolution;low-spatial-resolution hyperspectral images;multispectral sensor;low-spectral-resolution;high-spatial-resolution multispectral images;spatial resolutions;spectral resolutions;fusion algorithm;image registration;image similarity measure;original images;spatial degradation model;unaligned image fusion","","5","","52","IEEE","27 May 2021","","","IEEE","IEEE Journals"
"An Unsupervised Laplacian Pyramid Network for Radiometrically Accurate Data Fusion of Hyperspectral and Multispectral Imagery","S. Huang; D. W. Messinger","Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, USA; Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, USA","IEEE Transactions on Geoscience and Remote Sensing","5 May 2022","2022","60","","1","17","Improving the spatial resolution of hyperspectral images (HSIs) has traditionally been an important topic in the field of remote sensing. Many approaches have been proposed based on various theories, including component substitution, multiresolution analysis, spectral unmixing, Bayesian probability, and tensor representation. However, these methods have some common disadvantages such that their performance degrades dramatically as the up-scale ratio increases, and they have little concern for the per-pixel radiometric accuracy of the sharpened image. Moreover, many learning-based methods have been proposed through decades of innovations, but most of them require a large set of training pairs, which is unpractical for many real problems. To solve these problems, we propose a stable hyperspectral sharpening method based on the Laplacian pyramid and the generative convolutional neural network (CNN), which achieves superior radiometric accuracy of the sharpened data in different up-scale ratios based on one single input pair. First, with a low-resolution HSI (LR-HSI) and high-resolution multispectral image (HR-MSI) pair, the preliminary high-resolution HSI (HR-HSI) is calculated via linear regression. Then, the high-frequency details of the preliminary HR-HSI are estimated via the subtraction between it and the CNN-generated-blurry version. By injecting the details to the output of the generative CNN with the LR-HSI as input, the final HR-HSI is obtained. Nine different state-of-the-art sharpening methods are chosen as our baselines, and three different datasets with different scene content are tested. Furthermore, the target detection method, the adaptive coherence estimator (ACE), is conducted on the reconstructed HR-HSI to evaluate the per-pixel radiometric accuracy. The results demonstrate that the proposed method has the best and the most stable performance in terms of spectral and spatial accuracies.","1558-0644","","10.1109/TGRS.2022.3168511","academic grant from the National Geospatial-Intelligence Agency(grant numbers:HM0476-19-1-2007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760380","Convolutional neural network (CNN);hyperspectral sharpening;image fusion;Laplacian pyramid;super-resolution","Hyperspectral imaging;Tensors;Bayes methods;Spatial resolution;Radiometry;Superresolution;Laplace equations","Bayes methods;convolutional neural nets;geophysical image processing;geophysical techniques;hyperspectral imaging;image enhancement;image fusion;image resolution;image sensors;object detection;remote sensing","unsupervised Laplacian pyramid network;multispectral imagery;spatial resolution;hyperspectral images;HSIs;remote sensing;component substitution;multiresolution analysis;spectral unmixing;Bayesian probability;tensor representation;performance degrades;per-pixel radiometric accuracy;sharpened image;learning-based methods;training pairs;stable hyperspectral sharpening method;generative convolutional neural network;superior radiometric accuracy;sharpened data;up-scale ratios;single input pair;low-resolution HSI;LR-HSI;high-resolution multispectral image pair;high-resolution HSI;CNN-generated-blurry version;generative CNN;sharpening methods;scene content;target detection method;reconstructed HR-HSI;spectral accuracies;spatial accuracies;up-scale ratio","","2","","51","IEEE","20 Apr 2022","","","IEEE","IEEE Journals"
"Unsupervised Remoting Sensing Super-Resolution via Migration Image Prior","J. Wang; Z. Shao; T. Lu; X. Huang; R. Zhang; Y. Wang",Wuhan University; Wuhan University; Wuhan Institute of Technology; University of Arkansas; Wuhan University; Wuhan Institute of Technology,"2021 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2021","2021","","","1","6","Recently, satellites with high temporal resolution have fostered wide attention in various practical applications. Due to limitations of bandwidth and hardware cost, however, the spatial resolution of such satellites is considerably low, largely limiting their potentials in scenarios that require spatially explicit information. To improve image resolution, numerous approaches based on training low-high resolution pairs have been proposed to address the super-resolution (SR) task. De-spite their success, however, low/high spatial resolution pairs are usually difficult to obtain in satellites with a high temporal resolution, making such approaches in SR impractical to use. In this paper, we proposed a new unsupervised learning framework, called ""MIP"", which achieves SR tasks without low/high resolution image pairs. First, random noise maps are fed into a designed generative adversarial network (GAN) for reconstruction. Then, the proposed method converts the reference image to latent space as the migration image prior. Finally, we update the input noise via an implicit method, and further transfer the texture and structured information from the reference image. Extensive experimental results on the Draper dataset show that MIP achieves significant improvements over state-of-the-art methods both quantitatively and qualitatively. The proposed MIP is open-sourced at https://github.com/jiaming-wang/MIP.","1945-788X","978-1-6654-3864-3","10.1109/ICME51207.2021.9428093","National Natural Science Foundation of China; Wuhan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9428093","Super-resolution;unsupervised learning;latent space;deep neural networks","Training;Satellites;Limiting;Superresolution;Neural networks;Generative adversarial networks;Sensors","geophysical image processing;image reconstruction;image resolution;image sampling;neural nets;remote sensing;unsupervised learning","unsupervised remoting sensing super-resolution;satellites;image resolution;unsupervised learning;reference image;migration image prior;low-high resolution pair training;Draper dataset;MIP;generative adversarial network;GAN","","1","","27","IEEE","9 Jun 2021","","","IEEE","IEEE Conferences"
"XD-STOD: Cross-Domain Superresolution for Tiny Object Detection","M. Fromm; M. Berrendorf; E. Faerman; Y. Chen; B. Schüss; M. Schubert","Lehrstuhl für Datenbanksysteme und Data Mining, Ludwig-Maximilians-Universität München, Munich, Germany; Lehrstuhl für Datenbanksysteme und Data Mining, Ludwig-Maximilians-Universität München, Munich, Germany; Lehrstuhl für Datenbanksysteme und Data Mining, Ludwig-Maximilians-Universität München, Munich, Germany; Ludwig-Maximilians-Universität München, Munich, Germany; Ludwig-Maximilians-Universität Munchen, Munich, Germany; Lehrstuhl für Datenbanksysteme und Data Mining, Ludwig-Maximilians-Universität München, Munich, Germany","2019 International Conference on Data Mining Workshops (ICDMW)","13 Jan 2020","2019","","","142","148","Monitoring the restoration of natural habitats after human intervention is an important task in the field of remote sensing. Currently, this requires extensive field studies entailing considerable costs. Unmanned Aerial vehicles (UAVs, a.k.a. drones) have the potential to reduce these costs, but generate immense amounts of data which have to be evaluated automatically with special techniques. Especially the automated detection of tree seedlings poses a big challenge, as their size and shape vary greatly across images. In addition, there is a tradeoff between different flying altitudes. Given the same camera equipment, a lower flying altitude achieves higher resolution images and thus, achieving high detection rates is easier. However, the imagery will only cover a limited area. On the other hand, flying at larger altitudes, allows for covering larger areas, but makes seedling detection more challenging due to the coarser images. In this paper we investigate the usability of super resolution (SR) networks for the case that we can collect a large amount of coarse imagery on higher flying altitudes, but only a small amount of high resolution images from lower flying altitudes. We use a collection of high-resolution images taken by a drone at 5m altitude. After training the SR models on these data, we evaluate their applicability to low quality images taken at 30m altitude (in-domain). In addition, we investigate and compare whether approaches trained on a highly diverse large data sets can be transferred to these data (cross-domain). We also evaluate the usability of the SR results based on their influence on the detection rate of different object detectors. We found that the features acquired from training on standard SR data sets are transferable to the drone footage. Furthermore, we demonstrate that the detection rate of common object detectors can be improved by SR techniques using both settings, in-domain and cross-domain.","2375-9259","978-1-7281-4896-0","10.1109/ICDMW.2019.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8955582","Object Detection;Super-Resolution;Remote-Sensing;Drone Imagery;Coniferous Seedlings","Detectors;Drones;Object detection;Training;Feature extraction","autonomous aerial vehicles;image resolution;mobile robots;object detection;remote sensing;robot vision","UAVs;standard SR data sets;SR models;high-resolution images;high resolution images;higher flying altitudes;coarse imagery;super resolution networks;coarser images;SR techniques;XD-STOD;cross-domain superresolution;tiny object detection;natural habitats;human intervention;remote sensing;unmanned aerial vehicles;drones;tree seedlings;flying altitudes;image resolution","","1","","30","IEEE","13 Jan 2020","","","IEEE","IEEE Conferences"
"Progressive Spatial–Spectral Joint Network for Hyperspectral Image Reconstruction","T. Li; Y. Gu","Heilongjiang Province Key Laboratory of Space-Air-Ground Integrated Intelligent Remote Sensing, Harbin, China; Heilongjiang Province Key Laboratory of Space-Air-Ground Integrated Intelligent Remote Sensing, Harbin, China","IEEE Transactions on Geoscience and Remote Sensing","4 Jan 2022","2022","60","","1","14","Hyperspectral (HS) images are widely used to identify and characterize objects in a scene of interest with high acquisition costs and low spatial resolution. It is an inexpensive way to obtain high-spatial-resolution HS images (HSIs) by spectral reconstruction from high-spatial-resolution multispectral (MS) images. In this article, we proposed a progressive spatial–spectral joint network (PSJN) to reconstruct HSIs from MS images. PSJN is composed of a 2-D spatial feature extraction module, a 3-D progressive spatial–spectral feature construction module, and a spectral postprocessing module. PSJN makes full use of the shallow spatial features extracted by the 2-D spatial feature extraction module with the spatial–spectral features extracted by the 3-D progressive spatial–spectral feature construction module. The 3-D progressive spatial–spectral feature construction module is designed to extract spatial–spectral information from local spectra in local space and construct spectral information from a few bands to a lot of bands in a pyramidal structure. Besides, a network updating mechanism is proposed to improve the spectral reconstruction effect of the images with poor original spectral reconstruction effect. The experimental results on three HS–MS datasets and one MS dataset demonstrate the efficacy of the proposed methods. Compared with the most advanced spectral reconstruction methods based on dictionary learning and deep learning, our method achieves the best performance of the latest methods in similarity evaluation and classification performance evaluation.","1558-0644","","10.1109/TGRS.2021.3079969","National Natural Science Foundation of Key International Cooperation(grant numbers:61720106002); National Natural Science Foundation for Outstanding Scholars(grant numbers:62025107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9439796","Hyperspectral (HS) data;multispectral (MS) data;neural networks;spectral reconstruction (SR);spectral super-resolution","Image reconstruction;Feature extraction;Spatial resolution;Sensors;Dictionaries;Deep learning;Reconstruction algorithms","deep learning (artificial intelligence);feature extraction;geophysical image processing;hyperspectral imaging;image classification;image reconstruction;image representation;image resolution","progressive spatial-spectral joint network;hyperspectral image reconstruction;high-spatial-resolution HS images;2-D spatial feature extraction module;3-D progressive spatial-spectral feature construction module;spectral postprocessing module;shallow spatial features;PSJN;deep learning;high-spatial-resolution multispectral MS images;HSI reconstruction;dictionary learning","","8","","44","IEEE","24 May 2021","","","IEEE","IEEE Journals"
"Zero-Shot Sentinel-2 Sharpening Using a Symmetric Skipped Connection Convolutional Neural Network","H. V. Nguyen; M. O. Ulfarsson; J. R. Sveinsson; J. Sigurdsson","Faculty of Electrical and Computer Engineering, University of Iceland; Faculty of Electrical and Computer Engineering, University of Iceland; Faculty of Electrical and Computer Engineering, University of Iceland; Faculty of Electrical and Computer Engineering, University of Iceland","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","613","616","Sentinel-2 (S2) satellite constellations can provide multispectral images of 10 m, 20 m, and 60 m resolution for visible, near-infrared (NIR) and short-wave infrared (SWIR) in the electromagnetic spectrum. In this paper, we present a sharpening method based on a symmetric skipped connection convolutional neural network, called SSC-CNN, to sharpen 20 m bands using 10 m bands. The main advantage of SSC-CNN architecture is that it brings the features of the input branch to the output, thus improving convergence without using too many deep layers. The proposed method uses the reduced-scale combination of 10 m bands and 20 m bands, and the observed 20 m bands as the training pairs. The experimental results using two Sentinel-2 datasets show that our method outperforms competitive methods in quantitative metrics and visualization.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323614","Sentinel-2;image fusion;image sharpening;super resolution;convolutional neural network","Image resolution;Spatial resolution;Training;Sea measurements;Remote sensing;Pansharpening;Measurement","convolutional neural nets;image classification;image resolution;image sensors;learning (artificial intelligence)","SSC-CNN architecture;Sentinel-2 datasets;zero-shot Sentinel-2 sharpening;symmetric skipped connection convolutional neural network;Sentinel-2 satellite constellations;near-infrared;sharpening method;size 20.0 m;size 60.0 m;size 10.0 m","","5","","10","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"A Cross-Scale Loss for CNN-Based Pansharpening","S. Vitale; G. Scarpa","Dipartimento di Ingegneria, Università degli Studi di Napoli Parthenope; Dipartimento di Ing. Elettrica e delle Tecnologie dell'informazione, Università Federico II di Napoli","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","645","648","To cope with the lack of input-output training samples, deep learning (DL) methods for pansharpening usually resort to Wald's protocol or other similar downscaling processes. By doing so, the scaled versions of the multispectral (MS) and panchromatic (PAN) components serve as input while the original MS plays as output during the training phase. As a side effect, the informational gap between reduced and full scales causes a mismatch between the training and test phases. In fact, DL methods typically provide a pretty good performance at reduced scale, with a good margin over traditional solutions that tends to vanish in the full-resolution framework. In this work, we propose a training framework that involves both the reduced and the full scale versions of the multiresolution image samples. This is achieved thanks to a suitably defined loss which comprises costs for both scales. Our numerical and visual experimental results confirm that the proposed approach provides an improved performance in the full-resolution case.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324219","Pansharpening;super-resolution;convolutional neural network;data fusion;machine learning","Training;Pansharpening;Image resolution;Spatial resolution;Remote sensing;Sensors;Noise measurement","geophysical image processing;image fusion;image resolution;image sampling;learning (artificial intelligence)","suitably defined loss;multiresolution image samples;scale versions;training framework;full-resolution framework;good margin;reduced scale;pretty good performance;DL methods;test phases;informational gap;training phase;original MS;scaled versions;similar downscaling processes;Wald's protocol;resort;deep learning methods;input-output training samples;CNN-based;cross-scale loss","","2","","17","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Super-Resolution of 3-D GPR Signals to Estimate Thin Asphalt Overlay Thickness Using the XCMP Method","S. Zhao; I. L. Al-Qadi","Department of Civil and Environmental Engineering, University of Illinois at Urbana–Champaign, Urbana, IL, USA; Illinois Center for Transportation, University of Illinois at Urbana–Champaign, Rantoul, IL, USA","IEEE Transactions on Geoscience and Remote Sensing","21 Jan 2019","2019","57","2","893","901","The extended common midpoint (XCMP) method can be used on multichannel 3-D ground-penetrating radar (GPR) to estimate the asphalt pavement thickness and dielectric constant without the need for calibration by taking cores. The XCMP method requires accurate time delay determination of pavement reflection. However, for thin asphalt overlay, the range resolution of 3-D GPR signal is insufficient to resolve the overlapped pulses of asphalt concrete (AC). The objective of this paper is to use multiple signal classification (MUSIC) algorithm to increase the resolution of 3-D GPR signals, such that thin asphalt overlay thickness can be accurately estimated. An evaluation of the MUSIC algorithm at a full-scale test section and a comparison with regularized deconvolution algorithm showed the MUSIC algorithm is an effective approach for increasing the 3-D GPR signal range resolution when the XCMP method is applied on thin AC overlay.","1558-0644","","10.1109/TGRS.2018.2862627","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8445691","3-D ground-penetrating radar (GPR);extended common midpoint (XCMP);super-resolution;thin asphalt overlay","Signal resolution;Ground penetrating radar;Dielectric constant;Antennas;Image resolution;Asphalt;Estimation","asphalt;concrete;condition monitoring;deconvolution;ground penetrating radar;road building;roads;signal classification;thickness measurement","XCMP method;pavement reflection;asphalt concrete;multiple signal classification algorithm;thin asphalt overlay thickness;extended common midpoint method;3-D GPR signals;multichannel 3-D ground-penetrating radar;dielectric constant;full-scale test section;regularized deconvolution algorithm;thin AC overlay","","19","","44","IEEE","24 Aug 2018","","","IEEE","IEEE Journals"
"Spectral Super-Resolution for Multispectral Image Based on Spectral Improvement Strategy and Spatial Preservation Strategy","C. Yi; Y. -Q. Zhao; J. C. -W. Chan","Department of Electronics and Informatics, Vrije Universiteit Brussel, Brussel, Belgium; School of Automation, Northwestern Polytechnical University, Xi’an, China; Department of Electronics and Informatics, Vrije Universiteit Brussel, Brussel, Belgium","IEEE Transactions on Geoscience and Remote Sensing","30 Oct 2019","2019","57","11","9010","9024","While hyperspectral (HS) images play a significant role in many applications, they often suffer from issues such as low spatial resolution, low temporal resolution, and some of the acquired spectral bands are either with low signal-to-noise ratio (SNR) or invalid because of the very high-noise level. To address this issue, a spectral super-resolution method is proposed in this paper to recover a high-spectral-resolution HS image from multispectral (MS) images. The reconstructed HS image will have the same spatial resolution and coverage as the input MS image. The proposed method involves spectral improvement strategy and spatial preservation strategy. For spectral improvement strategy, auxiliary MS/HS image pairs of different landscapes are exploited to estimate spectral response relationship so that an HS image is obtained as an intermediate result. Then, spectral dictionary learning is exploited to recover a more accurate spectral reconstruction result. Spatial preservation strategy is used as a spatial constraint to ensure spatial consistency. In addition, the low-rank property of HS image is also introduced to make the use of global spectral coherence among HS bands. Experiments are conducted on both simulated and real datasets including spectral enhancement of RGB image and the MS image generated by AVIRIS data and real MS/HS data (ALI and Hyperion) captured by Earth Observing-1 (EO-1) satellite. Experiment results demonstrate the superiority of our proposed method to other state-of-the-art methods.","1558-0644","","10.1109/TGRS.2019.2924096","National Natural Science Foundation of China(grant numbers:61771391,61371152); Shenzhen Science and Technology Innovation Commission(grant numbers:JCYJ20170815162956949,JCYJ20180306171146740); China Scholarship Council(grant numbers:201706290150); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8772077","Hyperspectral (HS) image;low rank;spectral dictionary;spectral resolution enhancement","Spatial resolution;Image reconstruction;Sensors;Correlation;Dictionaries;Signal resolution","geophysical image processing;geophysical techniques;hyperspectral imaging;image reconstruction;image resolution","multispectral image;spectral improvement strategy;spatial preservation strategy;low spatial resolution;low temporal resolution;spectral bands;low signal-to-noise ratio;spectral super-resolution method;high-spectral-resolution HS image;input MS image;spectral response relationship;spectral dictionary learning;accurate spectral reconstruction result;spatial constraint;spatial consistency;global spectral coherence;HS bands;spectral enhancement;RGB image;hyperspectral images;AVIRIS data;real MS/HS data;ALI;Hyperion;Earth Observing-1 satellite","","34","","51","IEEE","25 Jul 2019","","","IEEE","IEEE Journals"
"FSL-Unet: Full-Scale Linked Unet With Spatial–Spectral Joint Perceptual Attention for Hyperspectral and Multispectral Image Fusion","X. Wang; X. Wang; K. Zhao; X. Zhao; C. Song","School of Geography and the School of Computer and Information Technology, Liaoning Normal University, Dalian, China; School of Computer Science and Technology, Dalian University of Technology, Dalian, China; School of Computer and Information Technology, Liaoning Normal University, Dalian, China; School of Geography, Liaoning Normal University, Dalian, China; School of Geography and the School of Computer and Information Technology, Liaoning Normal University, Dalian, China","IEEE Transactions on Geoscience and Remote Sensing","3 Oct 2022","2022","60","","1","14","The application of hyperspectral image (HSI) is more and more extensive, but the lower spatial resolution seriously affects its application effect. Using low-resolution HSI (LR-HSI) and high-resolution (HR) multispectral image (MSI) fusion technology to achieve super-resolution reconstruction of HSI has become a mainstream method. However, most of the existing fusion methods do not make full use of the large-scale range of remote sensing images and neglect the preservation of spatial–spectral information in the fusion process. Considering that the spectral information in fused HR-HSI mainly depends on HSI, and the spatial information mainly depends on MSI, this article proposes a full-scale linked Unet with spatial–spectral joint perceptual attention (SSJPA) for hyperspectral and MSI fusion (FSL-Unet). The FSL-Unet consists of two modules. The first is the spatial–spectral attention extraction (SSAE) module, which is used to calculate the spectral attention of LR-HSI and the spatial attention of HR-MSI at different scales. The second is the full-scale link U-shaped fusion (FLUF) module, which adopts a multilevel feature extraction strategy, using denser full-scale skip connections to explore feature information in a finer-grained range, enabling the flexible combination of multiscale and multipath features. At the same time, we propose SSJPA on the encoder side of FLUF. SSJPA can make full use of the attention maps computed by the SSAE and then effectively embed spatial and spectral information into the fused image, enabling uninterrupted information transfer and aggregation. To demonstrate the effectiveness of FSL-Unet, we selected five public hyperspectral datasets for experiments. Compared with the other eight state-of-the-art fusion methods, the experimental results show that the FSL-Unet achieves competitive results. The source code for FSL-Unet can be downloaded from https://github.com/wxy11-27/FSL-Unet.","1558-0644","","10.1109/TGRS.2022.3208125","National Natural Science Foundation of China(grant numbers:41971388); Innovation Team Support Program of Liaoning Higher Education Department(grant numbers:LT2017013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9895448","Hyperspectral image (HSI);image fusion;multispectral image (MSI);perceptual attention;Unet","Spatial resolution;Hyperspectral imaging;Feature extraction;Decoding;Fuses;Tensors;Superresolution","feature extraction;geophysical image processing;hyperspectral imaging;image fusion;image resolution;remote sensing","full-scale linked Unet;spatial-spectral joint perceptual attention;hyperspectral imaging;low-resolution HSI;LR-HSI;high-resolution multispectral image fusion technology;super-resolution reconstruction;remote sensing images;spatial-spectral information;spatial information;SSJPA;MSI fusion;spatial-spectral attention extraction module;full-scale link U-shaped fusion;full-scale skip connections;attention mapping;image fusion;uninterrupted information transfer;aggregation;FSL-Unet;HR-HSI fusion process;FLUF module","","1","","45","IEEE","20 Sep 2022","","","IEEE","IEEE Journals"
"Microwave Single Pixel Imager (MSPI) Overview and Imaging Algorithm","J. Bobak; H. Alqadah; M. Nurnberger; S. Rudolph; D. Truesdale","US Naval Research Laboratory, Washington DC; US Naval Research Laboratory, Washington DC; US Naval Research Laboratory, Washington DC; US Naval Research Laboratory, Washington DC; US Naval Research Laboratory, Washington DC","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","8837","8840","An overview of the MSPI system and a description of the imaging algorithm is presented. The imaging algorithm relies on compressive sensing techniques, and also performs a super resolution operation. Quantified performance simulations are included, with discussion of how these results align with environmental remote sensing needs. The unique aperture is discussed in a separate paper.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898608","","Microwave radiometry;Image resolution;Microwave imaging;Microwave theory and techniques;Apertures;Microwave antennas","compressed sensing;geophysical image processing;image reconstruction;image resolution;radar imaging;remote sensing","compressive sensing techniques;quantified performance simulations;microwave single pixel imager overview;imaging algorithm;MSPI system;environmental remote sensing","","4","","6","USGov","14 Nov 2019","","","IEEE","IEEE Conferences"
"High-Speed Railway Bridge Vibration Measurement and Analysis Based on Radar Interferometry","Z. Shao; X. Zhang; J. Ren; Y. Li","School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; CAS, National Space Science Center, Beijing, China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","4099","4102","A newly designed radar based on interferometry is proposed and well designed in the paper. The designed radar can detect the vibration of the railway bridge with a super-resolution and a high precision, which also has remote sensing ability. The general bridge monitoring methods are expensive and time-consuming since it is difficult to install sensors that should be directly contact with the bridge, such as accelerometer and dynamometer. Based on the designed radar, experiments are constructed on a Beijing-Tianjin Inter-City high-speed railway bridge to prove that the radar interferometry can be used to preciously and accurately monitor the railway bridge's vibration.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518902","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518902","Vibration;Railway bridge;Interferometry","Bridges;Vibrations;Monitoring;Radar;Rail transportation;Structural panels;Vibration measurement","bridges (structures);condition monitoring;radar interferometry;rail traffic;railway engineering;remote sensing;structural engineering computing;vibration measurement;vibrational signal processing;vibrations","high-speed railway bridge vibration measurement;radar interferometry;high precision;remote sensing ability;general bridge monitoring methods;Beijing-Tianjin Inter-City high-speed railway bridge","","3","","17","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"SSCNET: Spectral-Spatial Consistency Optimization of CNN for Pansharpening","K. Doi; A. Iwasaki","Department of Aeronautics and Astronautics, the University of Tokyo, Tokyo, Japan; Department of Aeronautics and Astronautics, the University of Tokyo, Tokyo, Japan","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3141","3144","Recently, convolutional neural network (CNN) has achieved great results in pansharpening. Most pansharpening methods with CNN are based on PNN [1] inspired by super-resolution methods with CNN and learn the pansharpening of downsampled images. In this work, we presented a novel framework for pansharpening based on two desired property of pansharpened images: downsampled pansharpened images become low-resolution multi-spectral images (spectral consistency) and panchromatic images are approximated by weighted addition of each bands of pansharpened images (spatial consistency). Our framework train CNN to learn this spectral-spatial consistency. The advantage of our framework is that there is no scale mismatch between training and test data. We applied our method to Landsat-8 images and compared it with some previous methods.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8897928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897928","Pansharpening;convolutional neural network;deep learning;data fusion","Remote sensing;Artificial satellites;Earth;Spatial resolution;Principal component analysis;Optimization","convolutional neural nets;geophysical image processing;image resolution;image sampling;learning (artificial intelligence)","pansharpening methods;super-resolution methods;downsampled pansharpened images;spectral consistency;panchromatic images;CNN;Landsat-8 images;spectral-spatial consistency optimization;convolutional neural network;multi-spectral images","","4","","8","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Super-Resolving Commercial Satellite Imagery Using Realistic Training Data","X. Zhu; H. Talebi; X. Shi; F. Yang; P. Milanfar",Google Inc.; Google Inc.; Google Inc.; Google Inc.; Google Inc.,"2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","498","502","In machine learning based single image super-resolution, the degradation model is embedded in training data generation. However, most existing satellite image super-resolution methods use a simple down-sampling model with a fixed kernel to create training images. These methods work fine on synthetic data, but do not perform well on real satellite images. We propose a realistic training data generation model for commercial satellite imagery products, which includes not only the imaging process on satellites but also the post-process on the ground. We also propose a convolutional neural network optimized for satellite images. Experiments show that the proposed training data generation model is able to improve super-resolution performance on real satellite images.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190746","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190746","Remote sensing;satellite imagery;super-resolution","Satellites;Training data;Data models;Kernel;Spatial resolution;Degradation","convolutional neural nets;image resolution;learning (artificial intelligence)","satellite image super resolution;super resolving commercial satellite imagery;machine learning;training data generation model;downsampling model;convolutional neural network","","4","","21","IEEE","30 Sep 2020","","","IEEE","IEEE Conferences"
"A CNN-Based Model for Pansharpening of WorldView-3 Images","S. Vitale; G. Ferraioli; G. Scarpa","Dipartimento di Ingegneria, Università degli Studi di Napoli “Parthenope”, Naples, Italy; Dipartimento di Scienze e Tecnologie, Università degli Studi di Napoli “Parthenone”, Naples, Italy; DIETI, Università degli Studi di Napoli “Federico II”, Naples, Italy","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","5108","5111","Fusing a multispectral image with a co-registered higher resolution single panchromatic band, provided by any multiresolution satellite systems, to rise the resolution of the former to that of the latter is known as pansharpening, and can be regarded as a guided super-resolution problem. Recently the use of convolutional neural networks (CNNs) has been extended to the pansharpening problem achieving state-of-the-art performance. Following this research line, the objective of this work was two-fold: provide a trained CNN model fitted to a specific sensor (WorldView-3) and explore a range of architectural configurations varied in both width and depth, seeking for the optimal one. Numerical and visual results show that the proposed solution compares favourably against reference methods.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8519202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519202","Super-resolution;data-fusion;machine learning;multi-resolution;convolutional neural network","Spatial resolution;Training;Indexes;Convolutional neural networks;Visualization;Convolution","convolution;feedforward neural nets;geophysical image processing;hyperspectral imaging;image fusion;image resolution","WorldView-3 images;multispectral image;higher resolution single panchromatic band;multiresolution satellite systems;super-resolution problem;convolutional neural networks;pansharpening problem;CNN","","4","","17","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"A Novel Approach for Hyperspectral Image Superresolution Using Spectral Unmixing and Transfer Learning","J. R. Patel; M. V. Joshi; J. S. Bhatt","Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar, India; Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar, India; Indian Institute of Information Technology, Vadodara, India","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1512","1515","Hyperspectral image (HSI) Super-resolution (SR) methods enhance the spatial resolution. In this paper, we propose a novel SR approach for HSIs by making use of spectral unmixing and transfer learning. We first train a deep convolutional neural network (CNN) to learn the mapping between the low-resolution (LR) and high-resolution (HR) natural images and use the same for transfer learning to get the initial estimates of the super-resolved abundances where the input corresponds to LR abundances. To get the better estimates of abundances and hence improve the SR of HSIs, we use a regularization framework in which both the LR and HR abundances are modelled as Inhomogeneous Gaussian Markov field (IGMRF) that serves as the prior. Finally, the SR HSIs are obtained by using a linear mixing model that uses the SR abundances and the endmembers estimated using an appropriate technique. Experiments on synthetic as well as on real HSIs show that the proposed method performs better when compared to other existing approaches. The advantages of the proposed approach are: 1. The method do not require auxiliary image as used in many of the existing methods, 2. Spectral details are better preserved since the SR is carried out in abundance domain, 3. Computational complexity is reduced since the SR is carried out on abundances which are few in number when compared to HSIs.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324059","Convolutional neural network (CNN);Deep learning;Hyperspectral image (HSI) super-resolution;Inhomogeneous Gaussian Markov field (IGMRF)","Spatial resolution;Superresolution;Optimization;Signal resolution;Indexes;Hyperspectral imaging;Training","Gaussian processes;geophysical image processing;geophysical signal processing;hyperspectral imaging;image classification;image fusion;image resolution;learning (artificial intelligence);Markov processes;neural nets","spectral unmixing;transfer learning;deep convolutional neural network;low-resolution;initial estimates;super-resolved abundances;LR abundances;Inhomogeneous Gaussian Markov field;SR HSIs;linear mixing model;SR abundances;auxiliary image;spectral details;abundance domain;hyperspectral image superresolution;hyperspectral image Super-resolution methods;spatial resolution;novel SR approach","","","","21","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Deterministic Cramer-Rao Bound for Scanning Radar Sensing","Y. Zhang; Y. Zhang; Y. Huang; J. Yang; X. Yang","University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","9208","9211","In this paper, the Cramér-Rao Bound (CRB) for scanning radar sensing is investigated, providing an algorithm-independent bound on the angular estimation error. Based on the deterministic signal model, we first derive a numerical CRB for unknown real signal parameters. Then, the approximate closed-form expression of CRBs are further provided for the single target case. Meanwhile, the potential estimation error of various classical super-resolution sensing methods are quantitatively investigated in this paper, and compared with the presented CRB.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518677","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518677","Scanning radar;super-resolution sensing;closed-form Cramér-Rae bound","Radar;Signal resolution;Image resolution;Antennas;Signal to noise ratio;Sensors;Numerical models","approximation theory;parameter estimation;radar signal processing","angular estimation error;deterministic signal model;numerical CRB;unknown real signal parameters;approximate closed-form expression;potential estimation error;classical super-resolution sensing methods;deterministic Cramer-Rao bound;scanning radar sensing;algorithm-independent bound","","","","10","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Dual Frequency Polarized Scatterometer for global snow observation","D. Zhu; X. Dong; R. Yun; X. Xu; L. Liu; G. Wang","CAS, National Space Science Center, Beijing, China; CAS, National Space Science Center, Beijing, China; CAS, National Space Science Center, Beijing, China; CAS, National Space Science Center, Beijing, China; CAS, National Space Science Center, Beijing, China; CAS, National Space Science Center, Beijing, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","3451","3453","Dual Frequency Polarized Scatterometer (DFPSCAT) is one of the three payloads onboard the satellite of Water Cycle Observation Mission (WCOM). DFPSCAT is an X/Ku band rotating pencil beam scatterometer with 2-5 km resolution and 1000km swath for mapping of snow water equivalent (SWE) and freeze-thaw process [1]. DFPSCAT achieves fine resolution by linear frequency modulation pulse compression along the elevation direction, and by unfocused synthetic aperture processing (a technique where the Doppler effect is exploited to synthesize a longer aperture to achieve an improved resolution), as well as super-resolution reconstruction by oversampling in the direction of the azimuth.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729892","scatterometer;pencil beam;snow water equivalent;super resolution reconstruction;unfocused synthetic aperture","Radar measurements;Spaceborne radar;Azimuth;Snow;Radar tracking;Image resolution;Image reconstruction","Doppler effect;hydrological techniques;melting;snow","dual frequency polarized scatterometer;global snow observation;DFPSCAT;three payload onboard;X band rotating pencil beam scatterometer;Ku band rotating pencil beam scatterometer;snow water equivalent mapping;freeze-thaw process;linear frequency modulation pulse compression;super-resolution reconstruction;snow water equivalent;synthetic aperture processing","","","","3","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"A Regularized Iterative Adaptive Approach Based for Radar Forward-Looking Imaging","Y. Zhang; J. Li; Y. Zhang; F. Xu; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5151","5154","Iterative adaptive approach (IAA) is an effective super-resolution method to improve the resolution of airborne forward-looking radar imaging. Regretfully, the noise sensitivity caused by the non-full rank of matrix lead to the poor performance under low signal-to-noise ratio condition in the forward-looking imaging process. In response to this problem, a regularized IAA method (RIAA) based on singular value decomposition is proposed in this paper which utilizes singular value theory to decompose the autocorrelation matrix in the iteration which is applied to suppress the noise amplification and keep the main information of targets. Compared with conventional IAA method, the proposed method enjoys a preferable noise suppression performance without image quality degradation. Simulations are given to verify the performance gain.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554950","National Natural Science Foundation of China(grant numbers:61901092,61901090,61671117); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554950","forward-looking imaging;regularized iterative adaptive approach;singular value decomposition;super-resolution","Adaptation models;Superresolution;Imaging;Radar;Radar imaging;Iterative methods;Matrix decomposition","airborne radar;Doppler radar;image resolution;iterative methods;least squares approximations;radar clutter;radar imaging;singular value decomposition","matrix lead;low signal-to-noise ratio condition;imaging process;regularized IAA method;singular value decomposition;singular value theory;autocorrelation matrix;iteration;noise amplification;conventional IAA method;preferable noise suppression performance;image quality degradation;performance gain;regularized iterative adaptive approach;radar forward-looking;super-resolution method;radar imaging;noise sensitivity;nonfull rank","","","","11","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A New Deep Hierarchy for Underwater Image Reconstruction","Y. Song; G. Dong","National Lab of Radar Signal Processing, Xidian University; National Lab of Radar Signal Processing, Xidian University","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","4123","4126","The diminishing land resources compel us to pay more attention to the Marine. The underwater image restoration therefore plays an increasingly important role. The early works usually rely on image super-resolution reconstruction. This family of methods yet suffer from the phenomenon of gradient dispersion, resulting in poor restoration performance. To solve this problem, this paper proposes a new deep neural network. The dense block structure and the adaptive mechanism are combined in a unified framework. The high-frequency representations can be then exploited. Moreover, the best weights of each channel can be determined automatically. Multiple comparative studies are performed. The experimental results prove that the proposed method could solve the gradient dispersion effectively and ignore the redundant information simultaneously.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554172","National Natural Science Fund of China(grant numbers:61971324,61525105); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554172","Deep learning;Super-resolution reconstruction;Adaptive mechanism;Underwater image processing","Deep learning;Scalability;Oceans;Image edge detection;Superresolution;Interference;Image restoration","deep learning (artificial intelligence);image resolution;image restoration;marine engineering","new deep hierarchy;underwater image reconstruction;land resources;underwater image restoration;image super-resolution reconstruction;gradient dispersion;deep neural network;dense block structure;adaptive mechanism;high-frequency representations","","","","7","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Super-Resolved Multi-Temporal Segmentation with Deep Permutation-Invariant Networks","D. Valsesia; E. Magli",Politecnico di Torino; Politecnico di Torino,"IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","995","998","Multi-image super-resolution from multi-temporal satellite acquisitions of a scene has recently enjoyed great success thanks to new deep learning models. In this paper, we go beyond classic image reconstruction at a higher resolution by studying a super-resolved inference problem, namely semantic segmentation at a spatial resolution higher than the one of sensing platform. We expand upon recently proposed models exploiting temporal permutation invariance with a multi-resolution fusion module able to infer the rich semantic information needed by the segmentation task. The model presented in this paper has recently won the AI4EO challenge on Enhanced Sentinel 2 Agriculture.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884811","Super-resolution;image segmentation;deep neural networks","Deep learning;Uncertainty;Satellites;Superresolution;Neural networks;Semantics;Sensors","geophysical image processing;image fusion;image reconstruction;image resolution;image segmentation;learning (artificial intelligence)","super-resolved multitemporal segmentation;deep permutation-invariant networks;multiimage super-resolution;multitemporal satellite acquisitions;great success thanks;deep learning models;classic image reconstruction;super-resolved inference problem;semantic segmentation;spatial resolution;recently proposed models;temporal permutation invariance;multiresolution fusion module;rich semantic information;segmentation task","","","","10","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Jointly spatial-spectral resolution enhancement of hyperspectral imagery","Y. Zhao; C. Yi; J. Yang","School of Automation, Northwestern Polytechnical University, Xi'An, China; School of Automation, Northwestern Polytechnical University, Xi'An, China; School of Automation, Northwestern Polytechnical University, Xi'An, China","2015 7th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","23 Oct 2017","2015","","","1","4","For hyperspectral image, low spatial and spectral resolution will cause inaccurate object detection and classification. In this paper, a novel jointly spatial-spectral resolution enhancement algorithm is proposed to promote the spatial resolution and spectral resolution simultaneously, high spatial resolution information from panchromatic image is used as constraint in spectral enhancement while the high spectral resolution details are benefited for spatial enhancement, which makes spatial SR and spectral SR promote each other. The experiments prove that our algorithm can provide joint spatial-spectral enhanced results, which can outperform the state-of-art methods both in spatial and spectral domains.","2158-6276","978-1-4673-9015-6","10.1109/WHISPERS.2015.8075455","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8075455","Hyperspectral image;spatial-spectral super resolution;unmixing;sparse representation","Spatial resolution;Dictionaries;Sparse matrices;Hyperspectral imaging;Libraries;Matrices","feature extraction;geophysical image processing;geophysical signal processing;geophysical techniques;hyperspectral imaging;image enhancement;image fusion;image resolution;object detection;remote sensing","hyperspectral imagery;high spatial resolution information;panchromatic image;high spectral resolution details;spatial enhancement;object detection;object classification;joint spatial-spectral resolution enhancement algorithm;spatial SR;spectral SR","","","","16","IEEE","23 Oct 2017","","","IEEE","IEEE Conferences"
"Hyperspectral and Multispectral Image Fusion Based on Spectral Low Rank and Non-Local Spatial Similarities","R. Dian; S. Li","College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3137","3140","Fusing a hyperspectral image (HSI) with a multispectral image (MSI) of the same scene has become a popular way to increase the spatial resolution of HSI. In this paper, we propose a novel HSI and MSI fusion method (termed as the SSS), which is based on spectral low rank and non-local spatial similarities. Firstly, to exploit the high spectral correlations of the desired high spatial resolution HSI, we formulate the fusion problem as the estimation of low-dimensional spectral subspace and coefficients. Since the HSI preserves most of spectral information, the spectral subspace is estimated from HSI via singular value decomposition. With the spectral subspace known, we plug a state-of-the-art denoising algorithm, weighted nuclear norm minimization, into the alternating direction method of multipliers to estimate the coefficients, which can effectively promote the non-local similarities of desired high spatial resolution HSI. Experiments demonstrate that our method is competitive to the state-of-the-art approaches.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899108","Hyperspectral image super-resolution;low rank;superpixels","Spatial resolution;Hyperspectral imaging;Plugs;Noise reduction;Measurement;Estimation","geophysical image processing;hyperspectral imaging;image denoising;image fusion;image representation;image resolution;minimisation;remote sensing;singular value decomposition","hyperspectral image;multispectral image;MSI fusion method;high spectral correlations;desired high spatial resolution HSI;fusion problem;low-dimensional spectral subspace;spectral information;nonlocal similarities","","2","","11","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Unsupervised Blur Kernel Learning for Pansharpening","A. Guo; R. Dian; S. Li","College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","633","636","Deep learning (DL) for pansharpening has recently attracted considerable attentions. To construct training data, DL based pansharpening approaches often downsample the original multispectral image (MSI) and panchromatic image (PAN) with fixed blur kernel, which can be different from the real point spread functions (PSF) of the satellites. And a mismatched blur kernel will cause the pansharpening performance to drop dramatically. In this paper, we propose a novel blur kernel learning method for pansharpening, which can learn the spatial and spectral blur kernels between PAN and MSI in an unsupervised way. Specifically, we analyze the relationship between PAN and MSI, and then construct a mini net for blur kernel learning. Once the spatial blur kernel is found, a convolutional neural network (CNN) for pansharpening is trained on the downsampled dataset using the learned spatial blur kernel. Experimental results on GF-2 images demonstrate the superiority of the proposed method.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324543","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324543","Pansharpening;blur kernel learning;deep learning;hyperspectral image super-resolution","Kernel;Pansharpening;Image reconstruction;Feature extraction;Training;Spatial resolution;Satellites","geophysical image processing;image fusion;image resolution;image restoration;image sampling;image sensors;learning (artificial intelligence);neural nets;optical transfer function;remote sensing","MSI;panchromatic image;PAN;fixed blur kernel;point spread functions;mismatched blur kernel;pansharpening performance;novel blur kernel;spatial blur kernels;spectral blur kernels;learned spatial blur kernel;GF-2 images;unsupervised blur kernel learning;deep learning;considerable attentions;training data;pansharpening approaches","","1","","10","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"A Spark-based Parallel NPTSR Algorithm for Hyperspectral Image fusion","X. Liu; Y. Zhu; Q. Zhu; J. Sun","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","2021 Ninth International Conference on Advanced Cloud and Big Data (CBD)","11 Jul 2022","2022","","","13","18","NPTSR is a super-resolution method for hyperspectral image fusion that uses tensor-tensor product to characterize nonlocal patch for the purpose of fusing hyperspectral images and multispectral images. Due to its high computational efficiency in single-machine environments, it is difficult to adapt NPTSR to large-scale remote sensing datasets and large numbers of iterations during the hyperspectral image super-resolution procedure. To address the above-mentioned limitations, this paper proposes a Spark-based parallel method for NPTSR algorithm. We develop a parallel method for nonlocal patches extraction relying on the characteristics of remote sensing data in tensor representation. In addition, we design the parallel implementation of the iterative procedure involved in NPTSR algorithm to accelerate its execution on Spark. Experimental results show that, compared with the serial version, the parallel NPTSR algorithm achieves significant speedup while guaranteeing similar image fusion accuracy and convergence rate. Moreover, the parallel implementation exhibits decent scalability to the increasing size of hyperspectral dataset.","","978-1-6654-0745-8","10.1109/CBD54617.2021.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9816259","hyperspectral image;image fusion;NPTSR;tensor computation;parallel algorithm","Tensors;File systems;Scalability;Superresolution;Big Data;Iterative algorithms;Sparks","geophysical image processing;hyperspectral imaging;image fusion;image representation;image resolution;iterative methods;parallel processing;remote sensing;tensors","tensor representation;similar image fusion accuracy;convergence rate;parallel implementation exhibits decent scalability;hyperspectral dataset;Spark-based parallel NPTSR algorithm;hyperspectral image fusion;super-resolution method;tensor-tensor product;nonlocal patch;hyperspectral images;multispectral images;high computational efficiency;single-machine environments;large-scale remote sensing datasets;hyperspectral image super-resolution procedure;Spark-based parallel method;nonlocal patches extraction;remote sensing data","","","","10","IEEE","11 Jul 2022","","","IEEE","IEEE Conferences"
"Single Image Super-resolution with Self-similarity","Y. Nam; J. Mun; Y. Jang; J. Kim","Department of Electrical and Electronic Engineering, Yonsei University, Republic of Korea; Department of Electrical and Electronic Engineering, Yonsei University, Republic of Korea; Department of Electrical and Electronic Engineering, Yonsei University, Republic of Korea; Department of Electrical and Electronic Engineering, Yonsei University, Republic of Korea","2019 IEEE International Conference on Consumer Electronics (ICCE)","7 Mar 2019","2019","","","1","2","Degraded low-resolution (LR) images are often obtained from cameras. Resolution enhancement and image restoration are very practical in many fields such as medical imaging, surveillance system and remote sensing. Single image super-resolution is a technique which reconstruct a restored high-resolution (HR) image from a degraded LR image. In this paper, we propose single image super-resolution based on sparse coding using self-similarity prior. A sparsity constraint is used to jointly train coupled dictionaries which can generate high frequency details. Reconstructed HR output is enhanced with non-local means based on self-similarity prior. Experimental results demonstrate that our method shows higher performance than other existing algorithms.","2158-4001","978-1-5386-7910-4","10.1109/ICCE.2019.8662051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8662051","","Image resolution;Dictionaries;Image reconstruction;Image restoration;Interpolation;Signal resolution;Image coding","image coding;image enhancement;image resolution;image restoration","single image super-resolution;high-resolution image;degraded LR image;image restoration;degraded low-resolution images;resolution enhancement;sparse coding;sparsity constraint","","2","","6","IEEE","7 Mar 2019","","","IEEE","IEEE Conferences"
"Unsupervised Video Satellite Super-Resolution by Using Only a Single Video","Z. He; D. He; X. Li; J. Xu","Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; School of Computer and Information, City College of Dongguan University of Technology, Dongguan, China; Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), School of Geography and Planning, Sun Yat-sen University, Guangzhou, China","IEEE Geoscience and Remote Sensing Letters","24 Dec 2021","2022","19","","1","5","Recent studies have shown that deep-learning (DL)-based methods lead to improved performance in video satellite super-resolution (SR). However, the vast majority of prior work is supervised, which is restricted to artificially generated training data (e.g., predetermined bicubic downsampling). Unfortunately, in the real world, the low-resolution (LR) satellite video frames rarely obey these restrictions. To solve this problem, we resort to unsupervised learning and propose a video satellite SR method by using only a single video. The single video SR (SingleVSR) method takes advantage of the power of DL without relying on prior high-resolution (HR) and LR pairs. In the training phase, the LR frames are alternately processed by both downsampling network (i.e., NetLR) and upsampling network (i.e., NetHR). The losses obtained by LR frames and network outputs are used to optimize both NetLR and NetHR. In the testing phase, the trained NetHR is applied to generate the SR results of LR frames. In contrast to the existing video satellite SR methods, our SingleVSR does not require any assumption on degradation or any additional training data except for the single video to be tested. Experiments performed on Jilin-1 and OVS-1 satellite videos demonstrate the superiority of the proposed method.","1558-0571","","10.1109/LGRS.2020.3040972","National Key Research and Development Program of China(grant numbers:2018YFB0505500,2018YFB0505503,2017YFC1502706); National Key Laboratory of Science and Technology on Automatic Target Recognition(grant numbers:WDZC20205500205); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2019A1515011877); Fundamental Research Funds for the Central Universities(grant numbers:19lgzd10); Guangzhou Science and Technology Planning Project(grant numbers:202002030240); National Natural Science Foundation of China(grant numbers:41501368); Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai)(grant numbers:99147-42080011); 2018 Key Research Platforms and Research Projects of Ordinary Universities in Guangdong Province(grant numbers:2018KQNCX360); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9292410","Deep learning (DL);super-resolution (SR);unsupervised;video satellite","Satellites;Convolution;Training;Spatial resolution;Kernel;Feature extraction;Interpolation","","","","3","","28","IEEE","11 Dec 2020","","","IEEE","IEEE Journals"
"Satellite Image Target Super-Resolution With Adversarial Shape Discriminator","C. Shin; S. Kim; Y. Kim","Agency for Defence Development (ADD), Institute of Defense Advanced Technology Research, Daejeon, South Korea; Agency for Defence Development (ADD), Institute of Defense Advanced Technology Research, Daejeon, South Korea; Agency for Defence Development (ADD), Institute of Defense Advanced Technology Research, Daejeon, South Korea","IEEE Geoscience and Remote Sensing Letters","24 Dec 2021","2022","19","","1","5","Substantial progress in generative modeling has facilitated the development of perceptual-driven methods for image super-resolution (SR), which shows superior visual quality as rated by human observers. However, we discover that most existing methods are biased to synthesize fake details or enhanced textures and fail to learn representations of object shape. They are often misguided to recover the shape of small objects and focus on generating less meaningful high-frequency components. This is problematic when super-resolving satellite imagery since it contains many relatively small and clustered objects in a broad area. In this letter, we propose a new perceptual-driven SR method that has a stronger preference toward shape information. We integrate the scale-space filtering with the discriminator to attenuate high-frequency components in its decision space. It effectively encourages our discriminator to concentrate on structural shape information in differentiating real and fake images. We also devise a cross-scale aggregation network for the generator architecture. Experiments on WorldView data set demonstrate that our method achieves state-of-the-art performance compared to recent perceptual-driven methods.","1558-0571","","10.1109/LGRS.2020.3042238","Next Generation Research and Development Program through the Institute of Defense Advanced Technology Research; Agency for Defense Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302745","Cross-scale aggregation (CSA) network;image target super-resolution (SR);scale-space filtering;shape discriminator","Shape;Image reconstruction;Satellites;Generators;Feature extraction;Streaming media;Visualization","","","","1","","30","IEEE","22 Dec 2020","","","IEEE","IEEE Journals"
"GuidedNet: A General CNN Fusion Framework via High-Resolution Guidance for Hyperspectral Image Super-Resolution","R. Ran; L. -J. Deng; T. -X. Jiang; J. -F. Hu; J. Chanussot; G. Vivone","School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; Financial Intelligence and Financial Engineering Research Key Laboratory of Sichuan Province, School of Economic Information Engineering, FinTech Innovation Center, Southwestern University of Finance and Economics, Chengdu, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; Inria, CNRS, Grenoble INP, LJK, Univ. Grenoble Alpes, Grenoble, France; National Research Council-Institute of Methodologies for Environmental Analysis, CNR-IMAA, Tito Scalo, Italy","IEEE Transactions on Cybernetics","","2023","PP","99","1","14","Hyperspectral image super-resolution (HISR) is about fusing a low-resolution hyperspectral image (LR-HSI) and a high-resolution multispectral image (HR-MSI) to generate a high-resolution hyperspectral image (HR-HSI). Recently, convolutional neural network (CNN)-based techniques have been extensively investigated for HISR yielding competitive outcomes. However, existing CNN-based methods often require a huge amount of network parameters leading to a heavy computational burden, thus, limiting the generalization ability. In this article, we fully consider the characteristic of the HISR, proposing a general CNN fusion framework with high-resolution guidance, called GuidedNet. This framework consists of two branches, including 1) the high-resolution guidance branch (HGB) that can decompose the high-resolution guidance image into several scales and 2) the feature reconstruction branch (FRB) that takes the low-resolution image and the multiscaled high-resolution guidance images from the HGB to reconstruct the high-resolution fused image. GuidedNet can effectively predict the high-resolution residual details that are added to the upsampled HSI to simultaneously improve spatial quality and preserve spectral information. The proposed framework is implemented using recursive and progressive strategies, which can promote high performance with a significant network parameter reduction, even ensuring network stability by supervising several intermediate outputs. Additionally, the proposed approach is also suitable for other resolution enhancement tasks, such as remote sensing pansharpening and single-image super-resolution (SISR). Extensive experiments on simulated and real datasets demonstrate that the proposed framework generates state-of-the-art outcomes for several applications (i.e., HISR, pansharpening, and SISR). Finally, an ablation study and more discussions assessing, for example, the network generalization, the low computational cost, and the fewer network parameters, are provided to the readers. The code link is: https://github.com/Evangelion09/GuidedNet.","2168-2275","","10.1109/TCYB.2023.3238200","NSFC(grant numbers:12271083,62203089,12001446); Natural Science Foundation of Sichuan Province(grant numbers:2022NSFSC0501,2022NSFSC0507,2022NSFSC1798); Key Projects of Applied Basic Research in Sichuan Province(grant numbers:2020YJ0216); National Key Research and Development Program of China(grant numbers:2020YFA0714001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10035506","Convolutional neural network (CNN);high-resolution guidance;hyperspectral image super-resolution (HISR);image fusion;pansharpening;single-image super-resolution (SISR)","Image reconstruction;Task analysis;Superresolution;Pansharpening;Hyperspectral imaging;Spatial resolution;Training","","","","","","","IEEE","2 Feb 2023","","","IEEE","IEEE Early Access Articles"
"Optimizing and Evaluating Swin Transformer for Aircraft Classification: Analysis and Generalizability of the MTARSI Dataset","K. Gao; H. He; D. Lu; L. Xu; L. Ma; J. Li","Department of Systems Design Engineering, University of Waterloo, Waterloo, Canada; Department of Geography and Environmental Management, University of Waterloo, Waterloo, Canada; Department of Systems Design Engineering, University of Waterloo, Waterloo, Canada; Department of Systems Design Engineering, University of Waterloo, Waterloo, Canada; School of Statistics and Mathematics, Central University of Finance and Economics, Beijing, China; Department of Geography and Environmental Management, University of Waterloo, Waterloo, Canada","IEEE Access","30 Dec 2022","2022","10","","134427","134439","Aircraft classification via remote sensing images has many commercial and military applications. The Swin-Transformer has shown great promise, recently dominating general-purpose image classification benchmarks such as ImageNet. In this paper, we test whether the performance of the Swin-Transformer on general-purpose image classification translates to domain-specific aircraft classification using the Multi-Type Aircraft from the Remote Sensing Images dataset. We also investigate the effect of training procedure vs. model selection on the validation score. Our carefully trained Swin-Transformer model achieved an impressive 99.4 % validation set accuracy without super-resolution, and 99.5 % with super-resolution. Moreover, the generalization of models trained on the MTARSI dataset to real-world and synthetic aircraft classification is evaluated with some out-of-distribution samples. Our results demonstrate that the lack of complexity and heterogeneity of the MTARSI dataset, and the labeling errors resulted in models which struggle to achieve high accuracy on the adopted test samples despite near perfect validation scores.","2169-3536","","10.1109/ACCESS.2022.3231327","National Natural Science Foundation of China(grant numbers:41871380,42101451); Emerging Interdisciplinary Project of Central University of Finance and Economics in China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9996354","Aircraft classification;deep learning;MTARSI dataset;out-of-distribution;remote sensing;self-attention;Swin transformer;vision transformer","Aircraft;Atmospheric modeling;Transformers;Remote sensing;Military aircraft;Deep learning;Superresolution;Data models","aerospace computing;aircraft;deep learning (artificial intelligence);image classification;remote sensing","aircraft classification;general-purpose image classification;MTARSI dataset;Multi-Type Aircraft from the Remote Sensing Images dataset;Swin-Transformer","","","","43","CCBY","21 Dec 2022","","","IEEE","IEEE Journals"
"Feature registration of large resolution difference non-homologous SAR image pairs for sea ice drift tracking","P. Men; H. Guo; J. An; G. Li","Information Science and Technology College, Dalian Maritime University, Dalian, P.R.China; Information Science and Technology College, Dalian Maritime University, Dalian, P.R.China; Information Science and Technology College, Dalian Maritime University, Dalian, P.R.China; Information Science and Technology College, Dalian Maritime University, Dalian, P.R.China","2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP)","26 Apr 2021","2021","","","716","719","At present, SAR images from same source are widely used in the field of sea ice drift tracking. Due to the longer revisit time of homologous spaceborne satellites, only an average velocity can be determined. For longer time intervals, velocities due to short-duration events such as storms are lost. Synthetic Aperture Radar (SAR) images from different sources make it easy to construct image sequences with short time intervals. However, the resolution and noise level between non-homologous SAR image pairs often differ greatly. When there is a relatively large resolution difference between image pairs, the areal features between image pairs are very different, which increases the difficulty of feature registration. In this paper, a super-resolution reconstruction method is proposed to solve the problem of resolution difference between image pairs for sea ice drift. This method can significantly improve the quality of feature registration of image pairs from different SAR sensors. We demonstrate through several examples the effectiveness of the method in feature matching of large resolution difference images from different SAR sensors.","","978-1-6654-0413-6","10.1109/ICSP51882.2021.9408919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408919","Feature matching;Image registration;Sea ice drift tracking;Super-resolution reconstruction;Synthetic Aperture Radar (SAR)","Image sensors;Storms;Spaceborne radar;Superresolution;Radar tracking;Radar polarimetry;Synthetic aperture radar","image reconstruction;image registration;image resolution;image sequences;radar imaging;remote sensing by radar;sea ice;synthetic aperture radar","resolution difference images;different SAR sensors;feature registration;resolution difference nonhomologous SAR image pairs;sea ice drift tracking;SAR images;longer revisit time;homologous spaceborne satellites;longer time intervals;Synthetic Aperture Radar images;image sequences;short time intervals;noise level;super-resolution reconstruction method","","1","","12","IEEE","26 Apr 2021","","","IEEE","IEEE Conferences"
"Coupled Tensor Models Accounting for Inter-image Variability","R. A. Borsoi; C. Prévost; K. Usevich; D. Brie; J. C. M. Bermudez; C. Richard","Centre de Recherche en Automatique de Nancy, Université de Lorraine, Vandoeuvre-lès-Nancy, France; Centre de Recherche en Automatique de Nancy, Université de Lorraine, Vandoeuvre-lès-Nancy, France; Centre de Recherche en Automatique de Nancy, Université de Lorraine, Vandoeuvre-lès-Nancy, France; Centre de Recherche en Automatique de Nancy, Université de Lorraine, Vandoeuvre-lès-Nancy, France; Department of Electrical Engineering, Federal University of Santa Catarina, Florianópolis, SC, Brazil; Lagrange Laboratory, Université Côte d’Azur, Nice, France","2021 55th Asilomar Conference on Signals, Systems, and Computers","4 Mar 2022","2021","","","1586","1590","Coupled tensor approximation has recently emerged as a promising approach for the fusion of hyperspectral and multispectral images (respectively HSI and MSI). This problem is referred to as hyperspectral super-resolution, and consists in recovering a super-resolution image (SRI). Previously proposed tensor-based approaches share a common limitation: they assume that the observed images are acquired under exactly the same conditions. In practice, there exist very few optical satellites that carry both hyperspectral and multispectral sensors: thus, combining an HSI and an MSI acquired on board different missions has become a task of prime interest. Since the HSI and MSI are acquired at different time instants, they can differ by, e.g., illumination, atmospheric or seasonal changes. In this work, we address the problem of hyperspectral super-resolution accounting for inter-image variability. We propose a tensor degradation model accounting for variability between the observed HSI and MSI. After introducing noiseless recovery guarantees for the target SRI, we propose two algorithms based on low-rank tensor approximations. We illustrate the performance of the proposed approach for a set of synthetic and real datasets accounting for inter-image variability.","2576-2303","978-1-6654-5828-3","10.1109/IEEECONF53345.2021.9723178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723178","Hyperspectral;multispectral;inter-image variability;super-resolution;image fusion;tensor decomposition","Tensors;Satellites;Atmospheric modeling;Superresolution;Lighting;Optical imaging;Optical sensors","geophysical image processing;hyperspectral imaging;image colour analysis;image resolution;remote sensing;tensors","inter-image variability;coupled tensor approximation;hyperspectral images;multispectral images;respectively HSI;MSI;hyperspectral super-resolution;super-resolution image;tensor-based approaches;observed images;hyperspectral sensors;multispectral sensors;board different missions;different time instants;super-resolution accounting;tensor degradation model;observed HSI;low-rank tensor approximations;coupled tensor models","","","","22","IEEE","4 Mar 2022","","","IEEE","IEEE Conferences"
"Sentinel-2 Images at 2.5m Spatial Resolution via Deep-Learning: A Case Study in Zakythnos","A. Panagiotopoulou; E. Bratsolis; L. Grammatikopoulos; E. Petsa; E. Charou; K. Poirazidis; A. Martinis; N. Madamopoulos","NCSR Demokritos, Institute of Informatics and Telecommunications, Athens, Greece; Department of Surveying & Geoinformatics Engineering, University of West Attica, Athens, Greece; Department of Surveying and Geoinformatics Engineering, University of West Attica, Athens, Greece; Department of Surveying and Geoinformatics Engineering, University of West Attica, Athens, Greece; NCSR Demokritos, Institute of Informatics and Telecommunications, Athens, Greece; Department of Environment, Ionian University, Zakynthos, Greece; Department of Environment, Ionian University, Zakynthos, Greece; Department of Electrical Engineering, The City College of New York, New York, USA","2022 IEEE 14th Image, Video, and Multidimensional Signal Processing Workshop (IVMSP)","11 Jul 2022","2022","","","1","5","High-resolution (HR) satellite images can provide detailed information about land usage/land cover. Often, it is necessary that the satellite sensor inherent spatial resolution is increased through algorithmic processing of the image data acquired. Machine-learning and in particular deep-learning based super-resolution (SR) techniques are an effective tool for increasing the spatial resolution of images. In the current work, Sentinel-2 images are super-resolved to spatial resolution equal to 2.5 m/pixel by means of deep-learning based SR techniques. The area of study is Zakynthos island in Greece. A novel index called Normalized Carotenoid Reflectance Index (NCRI) is proposed for the assessment of land cover by olive trees.","","978-1-6654-7822-9","10.1109/IVMSP54334.2022.9816272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9816272","Sentinel-2;deep-learning;super-resolution;normalized carotenoid reflectance index;olive tree","Reflectivity;Satellites;Soil measurements;Moisture measurement;Superresolution;Indexes;Spatial resolution","deep learning (artificial intelligence);geophysical image processing;image resolution;land cover;remote sensing;vegetation mapping","machine learning;deep learning;super-resolution techniques;Sentinel-2 images;high-resolution satellite images;satellite sensor;spatial resolution;Zakythnos Item Abstract;Normalized Carotenoid Reflectance Index;NCRI;land cover;HR satellite images","","","","14","IEEE","11 Jul 2022","","","IEEE","IEEE Conferences"
"An Adversarial Super-Resolution Remedy for Radar Design Trade-offs","K. Armanious; S. Abdulatif; F. Aziz; U. Schneider; B. Yang","Institute of Signal Processing and System Theory, University of Stuttgart, Germany; Institute of Signal Processing and System Theory, University of Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Institute of Signal Processing and System Theory, University of Stuttgart, Germany","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","Radar is of vital importance in many fields, such as autonomous driving, safety and surveillance applications. However, it suffers from stringent constraints on its design parametrization leading to multiple trade-offs. For example, the bandwidth in FMCW radars is inversely proportional with both the maximum unambiguous range and range resolution. In this work, we introduce a new method for circumventing radar design trade-offs. We propose the use of recent advances in computer vision, more specifically generative adversarial networks (GANs), to enhance low-resolution radar acquisitions into higher resolution counterparts while maintaining the advantages of the low-resolution parametrization. The capability of the proposed method was evaluated on the velocity resolution and range-azimuth trade-offs in micro-Doppler signatures and FMCW uniform linear array (ULA) radars, respectively.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8902510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902510","Radar;Super-resolution;Micro-Doppler;MIMO;Range-azimuth;Convolutional neural network;CNN;Generative adversarial networks;GAN;Remote sensing","Radar imaging;Legged locomotion;Generators;Generative adversarial networks;Sensors","computer vision;CW radar;direction-of-arrival estimation;Doppler radar;FM radar;radar imaging;radar resolution","safety;surveillance applications;design parametrization;multiple trade-offs;FMCW radars;maximum unambiguous range;range resolution;radar design trade-offs;generative adversarial networks;low-resolution radar acquisitions;low-resolution parametrization;velocity resolution;FMCW uniform linear array radars;adversarial super-resolution remedy;range-azimuth trade-offs;computer vision","","15","","28","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Generative Adversarial Network-Based Methods in Super Resolution","S. Chen; X. Liu; S. Meng",NA; NA; NA,"ISCTT 2021; 6th International Conference on Information Science, Computer Technology and Transportation","22 Mar 2022","2021","","","1","7","Super-resolution (SR) is a crucial image processing technique to optimize the resolution of images and videos. Recent years have witnessed significant development of SR approaches using Generative Adversarial Nets (GAN). Herein, a thorough overview on the latest achievements of SR approaches using GAN are given. Specifically, we firstly define the SR problem. Then, we introduce traditional and deep-learning (DL)-based SR techniques including Convolutional Neural Network (CNN) and GAN methods. Afterward, we explore the background of GAN and pay special attention to GAN-based approaches such as SRGAN, GMGAN, and Cycle-GAN. In addition, we also cover the applications of GAN-based SR approaches in real life, including medical diagnosis and remote sensing.","","978-3-8007-5727-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9738930","","","","","","","","","","22 Mar 2022","","","VDE","VDE Conferences"
"Geometric Low-Rank Tensor Approximation for Remotely Sensed Hyperspectral And Multispectral Imagery Fusion","N. Liu; W. Li; R. Tao","School of Information and Electronics, Beijing Institute of Technology; School of Information and Electronics, Beijing Institute of Technology; School of Information and Electronics, Beijing Institute of Technology","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","2819","2823","Improving the spatial resolution of a hyperspectral image (HSI) is of great significance in the remotely sensed field. By fusing a high-spatial-resolution multispectral image (MSI) with an HSI collected from the same scene, hyperspectral and multispectral (HS–MS) fusion has been an emerging technique to address the issue. Extracting complex spatial information from MSIs while maintaining abundant spectral information of HSIs is essential to generate the fused high-spatial-resolution HSI (HS2I). A common way is to learn low-rank/sparse representations from HSI and MSI, then reconstruct the fused HS2I based on tensor/matrix decomposition or unmixing paradigms, which ignore the intrinsic geometry proximity inherited by the low-rank property of the fused HS2I. This study proposes to estimate the high-resolution HS2I via low-rank tensor approximation with geometry proximity as side information learned from MSI and HSI by defined graph signals, which we name GLRTA. Row graph ${\mathcal{G}_r}$ and column graph ${\mathcal{G}_c}$ are defined on the horizontal slice and lateral slice of MSI tensor $\mathcal{M}$ respectively, while spectral band graph ${\mathcal{G}_b}$ is defined on a frontal slice of HSI tensor $\mathcal{H}$. Experimental results demonstrate that the proposed GLRTA can effectively improve the reconstruction results compared to other competitive works.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746041","China Postdoctoral Science Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746041","Graph signal processing;hyperspectral imagery;low-rank tensor approximation;remote sensing;super-resolution","Geometry;Tensors;Signal processing;Robustness;Sensors;Data mining;Speech processing","approximation theory;geophysical image processing;image fusion;image reconstruction;image representation;image resolution;matrix decomposition;remote sensing;spectral analysis;tensors","multispectral imagery fusion;spatial resolution;hyperspectral image;high spatial resolution multispectral image;HS-MS;complex spatial information;high spatial resolution HSI;fused HS;intrinsic geometry proximity;low rank property;defined graph signals;MSI tensor;spectral band graph;HSI tensor;remotely sensed hyperspectral;geometric low rank tensor approximation","","1","","19","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"A Variational Pansharpening Algorithm Based on Total Variation and Primal-Dual Optimization","G. Khademi; H. Ghassemian","Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran; Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran","2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA)","5 Aug 2019","2019","","","64","69","This paper proposes a variational framework to estimate the high-resolution (HR) multispectral (MS) image from the low-resolution (LR) MS image and the panchromatic (Pan) image. The LR MS image is modeled as a decimation of the HR MS image. Furthermore, the Pan image is considered as a linear combination of the HR MS bands. A super-resolution (SR) model is defined in accordance with the image observation model and the total variation (TV) regularization. The SR reconstruction problem is modeled as a minimization problem, which is solved by an efficient primal-dual algorithm in a Euclidean setting. The result of comparing the proposed method with some recent classical and variational pansharpening methods proves the superiority of the proposed variational pansharpening algorithm.","2049-3630","978-1-7281-1621-1","10.1109/PRIA.2019.8786000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786000","image fusion;pansharpening;primal-dual optimization;remote sensing;total variation","Optimization;Image resolution;TV;Minimization;Sensors;Signal processing algorithms;Satellite broadcasting","geophysical image processing;image reconstruction;image resolution;minimisation;remote sensing;variational techniques","Euclidean setting;minimization problem;pan image;LR MS image;panchromatic image;low-resolution MS image;high-resolution multispectral image;variational framework;primal-dual optimization;variational pansharpening algorithm;variational pansharpening methods;primal-dual algorithm;SR reconstruction problem;total variation regularization;image observation model;super-resolution model;HR MS bands;HR MS image","","4","","23","IEEE","5 Aug 2019","","","IEEE","IEEE Conferences"
"Extracting Camera Pose Using Single Image Super Resolution Networks","B. Koskowich; M. Starek","Conrad Blucher Institute for Surveying Science, College of Science and Engineering, Texas A&M University Corpus Christi, Corpus Christi, Texas, USA; Conrad Blucher Institute for Surveying Science, College of Science and Engineering, Texas A&M University Corpus Christi, Corpus Christi, Texas, USA","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1873","1876","This work proposes a mechanism which can be used as a basis for allowing camera POSE information to be maintained reliably during loss or interference with inertial motion unit or positioning system integration. This basis is formed by employing image synthesis networks with atypical data for the network type: inputs are normal down scaled source imagery while outputs are native resolution images composed of the contents of the same scene viewed from a fixed offset position. The goal of this application is to simulate the presence of a binary camera from monocular hardware, which makes feasible certain POSE estimation workflows which would normally require binary cameras on monocular platforms. Being able to rapidly synthesize images of additional camera positions without having to physically navigate to those positions allows for two methods to build off each other. First, knowing that the model should consistently maintain a specific POSE from the source camera allows synthetic images to be used to artificially inflate available data during structure from motion processing with confidence in the accuracy of synthetic points. It also enables the comparison of an image at an actual physical location with the synthetic one later as a measure of POSE accuracy which can be incorporated into a solution for computing POSE of the image source.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323098","","Cameras;Training;Gallium nitride;Testing;Pose estimation;Neural networks;Three-dimensional displays","","","","","","16","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Learn to Be Clear and Colorful: An End-to-End Network for Panchromatic Image Enhancement","Y. Guo; M. Zhou; Y. Wang; G. Wu; R. Shibasaki","The Eighth Affiliated Hospital, Sun Yat-sen University, Shenzhen, China; School of Computer Science, Queensland University of Technology, Brisbane, QLD, Australia; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan; Center for Spatial Information Science, The University of Tokyo, Kashiwa, Japan","IEEE Geoscience and Remote Sensing Letters","28 Jan 2022","2022","19","","1","5","Benefiting from the high coverage and re-visiting frequency, the satellite imagery is an ideal data for large-scale, real-time earth observation. However, due to the limited resolution and chromatic information, the satellite images, especially the panchromatic images, are not capable of being used for accurate earth observations, such as road extraction, vehicle detection, and building segmentation. In this research, we propose a cascaded fully convolutional network (CFCN) consists of a residual dense super-resolution network (RDSRN) for grayscale image super-resolution (SR) and a residual deconvolution colorization network (RDCN) for grayscale image colorization. The unique architecture can simultaneously learn texture detail and color information from aerial images and then transfer to enhance panchromatic images. Furthermore, we also introduce an indirect evaluation metric, learned extraction similarity (LES), to estimate the image quality of the generated image in the absence of the ground truth. Experiments on a multispectral image dataset demonstrate that panchromatic images enhanced by the proposed CFCN are with both texture and color fidelity as compared to aerial image. For pre-trained U-Net, compared to the performance on raw panchromatic images, the CFCN enhanced images increase 12.8% of LES of overall accuracy (96.4% versus 83.6%).","1558-0571","","10.1109/LGRS.2022.3142994","Japan Science and Technology Agency (JST) aXis(grant numbers:JPMJAS2019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680692","Deep learning;image colorization;learned extraction similarity (LES);super-resolution (SR)","Superresolution;Gray-scale;Buildings;Satellites;Image color analysis;Measurement;Image quality","convolutional neural nets;deconvolution;deep learning (artificial intelligence);image colour analysis;image enhancement;image resolution;image segmentation;image texture","cascaded fully convolutional network;CFCN;residual deconvolution colorization network;grayscale image colorization;color information;aerial image;learned extraction similarity;image quality estimation;multispectral image dataset;color fidelity;raw panchromatic images;end-to-end network;panchromatic image enhancement;satellite imagery;real-time Earth observation;grayscale image superresolution;residual dense superresolution network;RDSRN;chromatic information;road extraction;vehicle detection;building segmentation;RDCN;texture detail learning;indirect evaluation metric;U-Net;deep learning","","1","","21","IEEE","13 Jan 2022","","","IEEE","IEEE Journals"
"Multispectral Image Super Resolution with Auto-Encoder Model and Fusion Technique","K. A. Reddy; P. S. V. S. P. Teja; G. K. Teja; K. Divya; J. Aravinth.","Department of Electronics and Communication Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India; Department of Electronics and Communication Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India; Department of Electronics and Communication Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India; Department of Electronics and Communication Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India; Department of Electronics and Communication Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, India","2022 7th International Conference on Communication and Electronics Systems (ICCES)","29 Jul 2022","2022","","","1485","1490","Obtaining High Resolution(HR) Multispectral Images which are not readily available is one of the more critical objectives in remote sensing applications as these images can be used for various agricultural applications and previously various other methods like pansharpening have been introduced. This paper proposes a novel convolutional auto-encoder for training the multispectral images obtained from Sentinel -2A Satellite and then pass the degraded multispectral image to obtain the reconstructed Multispectral Image which is spectrally enhanced and then fuse the image obtained from reconstruction with the original degraded image to obtain a spatial HR Multispectral Image. This fusion is done using various state of the art methods like Principal Component Analysis(PCA), Discrete Wavelet Transform Level-l(DWT) and Stationary Wavelet Transform Level-l(SWT) and the performance metrics.","","978-1-6654-9634-6","10.1109/ICCES54183.2022.9835943","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9835943","Convolutional Autoencoder;Multispectral Images;Principal Component Analysis(PCA);Discrete Wavelet Transform(DWT);Stationary Wavelet Transform(SWT)","Training;Measurement;Analytical models;Satellites;Pansharpening;Wavelet analysis;Discrete wavelet transforms","discrete wavelet transforms;geophysical image processing;image coding;image fusion;image reconstruction;image resolution;principal component analysis;remote sensing;wavelet transforms","Multispectral Image super Resolution;auto-encoder model;fusion technique;critical objectives;remote sensing applications;agricultural applications;novel convolutional auto-encoder;degraded multispectral image;reconstructed Multispectral Image;original degraded image;spatial HR Multispectral Image;wavelength 2.0 A","","","","20","IEEE","29 Jul 2022","","","IEEE","IEEE Conferences"
"Deep Shearlet Residual Learning Network for Single Image Super-Resolution","T. Geng; X. -Y. Liu; X. Wang; G. Sun","Department of Electronic Information and Optical Engineering, Nankai University, Tianjin, China; Department of Electrical Engineering, Columbia University, New York, NY, USA; Department of Electrical Engineering, Columbia University, New York, NY, USA; Department of Electronic Information and Optical Engineering, Nankai University, Tianjin, China","IEEE Transactions on Image Processing","9 Apr 2021","2021","30","","4129","4142","Recently, the residual learning strategy has been integrated into the convolutional neural network (CNN) for single image super-resolution (SISR), where the CNN is trained to estimate the residual images. Recognizing that a residual image usually consists of high-frequency details and exhibits cartoon-like characteristics, in this paper, we propose a deep shearlet residual learning network (DSRLN) to estimate the residual images based on the shearlet transform. The proposed network is trained in the shearlet transform-domain which provides an optimal sparse approximation of the cartoon-like image. Specifically, to address the large statistical variation among the shearlet coefficients, a dual-path training strategy and a data weighting technique are proposed. Extensive evaluations on general natural image datasets as well as remote sensing image datasets show that the proposed DSRLN scheme achieves close results in PSNR to the state-of-the-art deep learning methods, using much less network parameters.","1941-0042","","10.1109/TIP.2021.3069317","National Natural Science Foundation of China(grant numbers:61771262); Tianjin Science and Technology Major Project and Engineering(grant numbers:18ZXRHNC00140); Tianjin Key Laboratory of Optoelectronic Sensor and Sensor Network Technology; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394753","Single image super-resolution;shearlet transform;residual learning;convolutional neural network","Superresolution;Transforms;Deep learning;Training data;Remote sensing;Neural networks;Image reconstruction;Convolutional neural networks","","","","8","","57","IEEE","2 Apr 2021","","","IEEE","IEEE Journals"
"Super-Resolution of Forward-Looking Scanning Radar Based on Low-Rank and Sparse Constraints","W. Zhang; W. Li; Y. Zhang; Y. Zhang; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R.China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R.China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R.China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R.China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R.China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R.China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2758","2761","Regularization technology can be utilized to improve the azimuth resolution for forward-looking scanning radar. In this paper, low-rank and sparse constraints as regularization norms are incorporated into the forward-looking scanning radar imaging. This method can achieve azimuth superresolution and noise suppression. Simulations are given to verify the effectiveness of the method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898374","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898374","Forward-looking scanning radar;superresolution;low-rank and sparse constraints","Radar imaging;Azimuth;Radar antennas;Imaging","image denoising;image resolution;radar imaging;radar resolution","sparse constraints;regularization technology;azimuth superresolution;noise suppression;low-rank constraints;forward-looking scanning radar imaging","","1","","10","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Multihypothesis-Based Compressive Sensing Algorithm for Nonscanning Three-Dimensional Laser Imaging","H. Gao; Y. Zhang; H. Guo","School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","17 Jan 2018","2018","11","1","311","321","The resolution of nonscanning three-dimensional (3-D) imaging systems is limited by the number and accuracy of the array sensors. Moreover, for space-continuous targets in practical situations, the echo pulses in time-of-flight systems overlap and traditional peak detection is no longer suitable for super-resolution applications. Hence, compressive sensing (CS) has been introduced to achieve super-resolution. However, most of the conventional CS algorithms cannot be used directly for 3-D image reconstruction. In this paper, we propose a novel super-resolution algorithm for nonscanning 3-D laser imaging based on CS reconstruction. To acquire the range information of space-continuous targets, an all-one projection is implemented in advance to estimate the spatial distribution of the targets; a range observation matrix composed of time-interval basis vectors is then constructed to obtain the peak values of each frame from overlapping echo pulses. Because of the spatial continuity of the targets, Tikhonov regularization is utilized to solve the ill-posed inverse problem. Furthermore, to enhance the reconstruction quality of the adjacent frames, multihypothesis prediction is used with displacement and diffusion models to estimate the motion of the contour line. Simulation results based on real data from the ASTER global digital elevation model demonstrate the effectiveness and high accuracy of the proposed algorithm for complex landforms.","2151-1535","","10.1109/JSTARS.2017.2773469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119512","3-D laser imaging;compressive sensing (CS), multihypothesis (MH) prediction;super-resolution","Sensor arrays;Imaging;Image resolution;Image reconstruction;Laser radar;Compressed sensing","compressed sensing;digital elevation models;echo;image reconstruction;image resolution;inverse problems","multihypothesis prediction;spatial continuity;peak values;time-interval basis vectors;range observation matrix;spatial distribution;CS reconstruction;nonscanning 3-D laser;novel super-resolution algorithm;3-D image reconstruction;conventional CS algorithms;super-resolution applications;traditional peak detection;time-of-flight systems;echo pulses;space-continuous targets;array sensors;imaging systems;nonscanning three-dimensional laser;compressive sensing algorithm","","5","","50","IEEE","23 Nov 2017","","","IEEE","IEEE Journals"
"Utilizing Parallel Networks to Produce Sub-Pixel Shifted Images With Multiscale Spatio-Spectral Information for Soft-Then-Hard Sub-Pixel Mapping","P. Wang; G. Zhang; H. Leung","College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada","IEEE Access","25 Oct 2018","2018","6","","57485","57496","The distribution information of the land-cover classes in remote sensing image can be explored by sub-pixel mapping (SPM) technique. The soft-then-hard sub-pixel mapping (STHSPM) has become an important type of SPM method. The sub-pixel shifted images (SSI) from the same area can be utilized to improve the mapping result. However, the type of information in the fine SSI is insufficient, and the SSI-based STHSPM results are affected. To solve this problem, utilizing parallel networks to produce subpixel shifted images with multiscale spatio-spectral information (SSI-MSSI) for STHSPM is proposed. In SSI-MSSI, the fine SSI with multi-scale information and spatio-spectral information are obtained, respectively, from parallel networks, namely the multiscale network and spatio-spectral network. The multiscale network is spectral unmixing followed by mixed spatio attraction model and the spatio-spectral network is projected onto convex sets super-resolution followed by spectral unmixing. There two different kinds of fine SSI are integrated by appropriate weight parameter to produce the fine fractional images. Class allocation method then allocates the class labels into to each sub-pixel by the predicted value from the integrated fine fractional images. Three remote sensing images are tested to show that the proposed SSI-MSSI produces more accurate mapping results than the existing SSI-based STHSPM in the literature. In the quantitative accuracy assessment, the SSI-MSSI shows the best performance with the percentage correctly classified of 99.09% and 74.07% in the experimental results.","2169-3536","","10.1109/ACCESS.2018.2873813","National Natural Science Foundation of China(grant numbers:61801211,61871218,61501233,61501228); Fundamental Research Funds for the Central(grant numbers:56SYAH18050,3082017NP2017421); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481509","Remote sensing image;soft-then-hard sub-pixel mapping;sub-pixel shifted images;multiscale spatio-spectral information","Remote sensing;Resource management;Image resolution;Flowcharts;Satellites;Mathematical model;Indexes","geophysical image processing;image resolution;land cover;remote sensing;terrain mapping","multiscale information;parallel networks;multiscale network;spatio-spectral network;mixed spatio attraction model;spectral unmixing;class allocation method;integrated fine fractional images;remote sensing image;SSI-MSSI;sub-pixel shifted images;multiscale spatio-spectral information;soft-then-hard sub-pixel mapping;distribution information;land-cover classes;sub-pixel mapping technique;SSI-based STHSPM results;subpixel shifted images;fine fractional images","","7","","37","OAPA","4 Oct 2018","","","IEEE","IEEE Journals"
"Spatiotemporal Reflectance Fusion Using a Generative Adversarial Network","C. Shang; X. Li; Z. Yin; X. Li; L. Wang; Y. Zhang; Y. Du; F. Ling","College of Resources and Environment, University of Chinese Academy of Sciences, Beijing, China; College of Resources and Environment, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","13 Dec 2021","2022","60","","1","15","The spatiotemporal reflectance fusion method is used to blend high-temporal and low-spatial resolution images with their low-temporal and high-spatial resolution counterparts that were previously acquired by various satellite sensors. Recently, a wide variety of learning-based solutions have been developed, but challenges remain. These solutions usually require two sets of data acquired before and after the prediction time, making them unsuitable for near-real-time predicting. The solutions are always trained band by band and thus do not consider the spectral correlation. High-resolution temporal changes are difficult to reconstruct accurately with the network structure used, which lowers the accuracy of the fusion result. To address these problems, this study proposes a novel spatiotemporal adaptive reflectance fusion model using a generative adversarial network (GASTFN). In GASTFN, an end-to-end network, including a generative and discriminative network, is simultaneously trained for all spectral bands. The proposed model can be applied to the one-pair case, consider the spectral correlation of each band, and improve the process of producing super-resolution imagery by adopting the discriminative network for image reflectance values rather than temporal changes in reflectance. The proposed model has been verified with two actual satellite data sets acquired in heterogeneous landscapes and areas with abrupt changes, with a comparison of the state-of-art methods. The results show that GASTFN can generate the most accurate fusion images with more detailed textures, more realistic spatial shapes, and higher accuracy, demonstrating that the GASTFN is effective for predicting near-real-time changes in image reflectance and preserves the most valuable spatial information.","1558-0644","","10.1109/TGRS.2021.3065418","Hubei Provincial Natural Science Foundation for Innovation Groups(grant numbers:2019CFA019); Strategic Priority Research Program of Chinese Academy of Sciences(grant numbers:XDA2003030201); Natural Science Foundation of China(grant numbers:62071457); Application Foundation Frontier Project of Wuhan(grant numbers:2020020601012283); Hubei Province Natural Science Fund for Distinguished Young Scholars(grant numbers:2018CFA062); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9383451","Generative adversarial network (GAN);spatiotemporal fusion;super-resolution;temporal changes","Spatiotemporal phenomena;Remote sensing;Generative adversarial networks;Superresolution;Spatial resolution;Gallium nitride;Layout","","","","5","","51","IEEE","23 Mar 2021","","","IEEE","IEEE Journals"
"DDLPS: Detail-Based Deep Laplacian Pansharpening for Hyperspectral Imagery","K. Li; W. Xie; Q. Du; Y. Li","State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; Department of Electronic and Computer Engineering, Mississippi State University, Starkville, MS, USA; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","25 Sep 2019","2019","57","10","8011","8025","In this paper, we propose a new pansharpening method called detail-based deep Laplacian pansharpening (DDLPS) to improve the spatial resolution of hyperspectral imagery. This method includes three main components: upsampling, detail injection, and optimization. In particular, a deep Laplacian pyramid super-resolution network (LapSRN) improves the resolution of each band. Then, a guided image filter and a gain matrix are used to combine the spatial and spectral details with an optimization problem, which is formed to adaptively select an injection coefficient. The DDLPS method is compared with 11 state-of-the-art or traditional pansharpening approaches. The experimental results demonstrate the superiority of the DDLPS method in terms of both quantitative indices and visual appearance. In addition, the training of LapSRN is based on the data sets of traditional RGB images, which overcomes the practical difficulty of insufficient training samples for pansharpening.","1558-0644","","10.1109/TGRS.2019.2917759","National Natural Science Foundation of China(grant numbers:61801359,61571345,91538101,61501346,61502367,61701360); 111 Project(grant numbers:B08038); Fundamental Research Funds for the Central Universities(grant numbers:JB180104); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2016JQ6023,2016JQ6018); China Postdoctoral Science Foundation(grant numbers:2017M620440); Yangtse Rive Scholar Bonus Schemes(grant numbers:CJT160102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736034","Guided image filter;hyperspectral (HS) imaging;Laplacian pyramid super-resolution network (LapSRN);pansharpening;super-resolution;Sylvester equation","Spatial resolution;Laplace equations;Bayes methods;Distortion;Interpolation;Optimization","geophysical image processing;hyperspectral imaging;image colour analysis;image filtering;image resolution;image sampling;optimisation","DDLPS method;spatial resolution;guided image filter;optimization problem;deep Laplacian pyramid superresolution network;detail-based deep laplacian pansharpening approaches;hyperspectral image resolution;LapSRN;RGB imaging","","34","","47","IEEE","12 Jun 2019","","","IEEE","IEEE Journals"
"Subsurface fine structures survey by GPR B-scan image based on signal subspace method","T. Sun; Z. C. Zhang; B. Song; X. J. Tang; S. B. Liu","Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China; Wuhan University, Wuhan, Hubei, CN; State Key Laboratory of Geomechanics and Geotechnical Engineering, Chinese Academy of Sciences Xiaohongshan, Wuhan, China; State Key Laboratory of Geomechanics and Geotechnical Engineering, Chinese Academy of Sciences Xiaohongshan, Wuhan, China","2016 16th International Conference on Ground Penetrating Radar (GPR)","22 Sep 2016","2016","","","1","5","Ground Penetrating Radar (GPR) is an efficient remote sensing tool for geophysical subsurface survey. These structure characteristics are recorded in radar signal profiles by means of echo detection, amplitude and phase estimation. Besides the energy attenuation and absorption of GPR EM pulse during its propagating downward direction into the ground from a transmitting antenna, the strong interferences, clutters, multiples and random noise, often make the fine-structures hardly distinguishable. This paper develops a signal subspace method to detect fine fractures, leading to water intrusion at the Dazu Rock Carving site. With field surveying data, this method is validated to detect sub-surface fine structure with sparse representation and yields discriminative fracture signature for geological interpretation.","","978-1-5090-5181-6","10.1109/ICGPR.2016.7572593","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7572593","ground penetrating radar;signal subspace;MUSIC;Dazu Rock Carving;super-resolution","Decision support systems;Indexes;Ground penetrating radar;Clutter;Erbium","geophysical image processing;ground penetrating radar;remote sensing","subsurface fine structures;GPR B-scan image;signal subspace method;ground penetrating radar;remote sensing tool;geophysical subsurface survey;radar signal profiles;echo detection;phase estimation;amplitude estimation;GPR EM pulse;Dazu Rock Carving site;geological interpretation","","3","","9","IEEE","22 Sep 2016","","","IEEE","IEEE Conferences"
"DeepDT: Generative Adversarial Network for High-Resolution Climate Prediction","J. Cheng; J. Liu; Q. Kuang; Z. Xu; C. Shen; W. Liu; K. Zhou","School of Computer, Wuhan University, Wuhan, China; School of Computer, Wuhan University, Wuhan, China; Public Weather Services Center, China Meteorological Administration (CMA), Beijing, China; School of Big Data and Software Engineering, Chongqing University, Chongqing, China; School of Computer, Wuhan University, Wuhan, China; School of Computer, Wuhan University, Wuhan, China; School of Computer, Wuhan University, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","15 Dec 2021","2022","19","","1","5","Climate prediction is susceptible to a variety of meteorological factors, and downscaling technology is used for high-resolution climate prediction. This technology can generate small-scale regional climate prediction from large-scale climate output information. Inspired by the concept of image super resolution, we propose to apply the convolutional neural network (CNN) to downscaling technology. However, some unpleasant artifacts always appear in the final climate images generated by existing CNN-based models. To further eliminate these unpleasant artifacts, we present a new training strategy for the generative adversarial network, termed DeepDT. The key idea of our DeepDT is to train a generator and a discriminator separately. More specifically, we apply the residual-in-residual dense block as the basic frame structure to fully extract the features of the input. Additionally, we innovatively use a CNN model to fuse multiple climate elements to generate trainable climate images, and build a high-quality climate data set. Finally, we evaluate the DeepDT using the proposed climate data sets, and the experiments indicate that DeepDT performs best compared to most CNN-based models in climate prediction.","1558-0571","","10.1109/LGRS.2020.3041760","National Key Research and Development Program of China(grant numbers:2018YFC1507801); National Science Foundation of China (NSFC)(grant numbers:61972290); Fundamental Research Funds for the Central Universities(grant numbers:2042019kf0226); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9383802","Climate prediction;generative adversarial network;image super resolution","Meteorology;Generators;Predictive models;Feature extraction;Data models;Training;Generative adversarial networks","","","","3","","15","IEEE","23 Mar 2021","","","IEEE","IEEE Journals"
"Fast Scattered Far-Field Predictions for Super-Resolution ISAR Image Formation Using the Shooting and Bouncing Ray Technique","J. -I. Lee; D. -W. Seo","Interdisciplinary Major of Maritime AI Convergence, Korea Maritime and Ocean University, Busan, Republic of Korea; Interdisciplinary Major of Maritime AI Convergence, Korea Maritime and Ocean University, Busan, Republic of Korea","IEEE Access","21 Feb 2022","2022","10","","18182","18191","It is essential to obtain a large amount of inverse synthetic aperture radar (ISAR) image data for ISAR automatic target recognition. For a super-resolution ISAR image for a complex perfect electric conducting (PEC) computer-aided design (CAD) model, parameter estimation methods should be applied to  $M \times N$  scattered far-field data over  $M$  frequencies and  $N$  angles, which is conventionally obtained by using the shooting and bouncing ray (SBR) technique. Therefore,  $N$ -time ray tracing processes are required for  $N$  angles, and  $M \times N$ -time field calculations are required for  $M$  frequencies. In this paper, to reduce the computation time for  $M \times N$ -time field calculations, we introduce a fast scattered far-field prediction method for a super-resolution ISAR image of a complex PEC CAD model using the SBR technique. This method consists of two main ideas. First, under the small-angle approximation, we derive a DFT-based ISAR image formula in closed form, which allows the rapid acquisition of DFT-based ISAR image through just a one-time ray tracing process at the center frequency and angle. In addition, the scattered far-field data are also obtained by inverse discrete Fourier transforming the DFT-based ISAR image without  $N$  ray tracing processes and  $M \times N$  field calculations. Second, a field truncation method is employed to suppress errors in the scattered far-field data caused by the proposed closed-form formula. Further, by applying a parameter estimation method to the scattered far-field data, a super-resolution ISAR image is obtained quickly. Simulation results for complex PEC CAD models are in good agreement with the results for the conventional method, while the computation times are tremendously reduced.","2169-3536","","10.1109/ACCESS.2022.3151049","Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Education(grant numbers:2021R1I1A3044405); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712264","Far-field calculation;one-shot ISAR imaging;super-resolution ISAR imaging;shooting and bouncing ray~(SBR) technique;scattering center extraction","Solid modeling;Superresolution;Ray tracing;Scattering;Computational modeling;Synthetic aperture radar;Radar imaging","approximation theory;discrete Fourier transforms;electromagnetic wave scattering;image resolution;object recognition;parameter estimation;radar imaging;radar resolution;radar target recognition;ray tracing;synthetic aperture radar","fast scattered far-field predictions;super-resolution ISAR image formation;shooting and bouncing ray technique;inverse synthetic aperture radar image data;ISAR automatic target recognition;parameter estimation methods;N-time ray tracing processes;complex PEC CAD model;DFT-based ISAR image formula;field truncation method;SBR technique;perfect electric conducting computer-aided design model;inverse discrete Fourier transforming","","","","32","CCBYNCND","11 Feb 2022","","","IEEE","IEEE Journals"
"Learning Dynamic Generative Attention for Single Image Super-Resolution","R. Chen; Y. Zhang","Tianjin Key Laboratory of Imaging and Sensing Microelectronic Technology, School of Microelectronics, Tianjin University, Tianjin, China; Beijing Institute of Remote Sensing Information, Beijing, China","IEEE Transactions on Circuits and Systems for Video Technology","7 Dec 2022","2022","32","12","8368","8382","Attention mechanisms have achieved great success for image super-resolution as they can effectively improve the feature representation ability. However, most attention-based methods produce the static attention weights, which are applied identically for all input samples. This popular attention strategy is difficult to automatically adapt the content variations of each individual input, hence hindering further improvements of the magnification performance. To explore towards resolving this challenge, we propose a variational hybrid network with newly dynamic attention mechanisms for image super-resolution tasks. Specifically, we design a multi-scale variational encoder network to transform the curvature map of an input image into the latent space. This is made possible for randomly generated latent variables to reflect the valuable high-frequency information and recalibrate the main network. We utilize these latent variables to further generate controllable attention weights, which modulate not only frequency parameters of convolutional kernels but also spatial characteristics of feature maps for boosting representation power. Moreover, a curvature-domain loss is designed to help the main network to concentrate more on high-frequency geometric structures. Experimental results have revealed that our method can generate more realistic and visually pleasing high-resolution images in comparison to state-of-the-art methods.","1558-2205","","10.1109/TCSVT.2022.3192099","National Natural Science Foundation of China(grant numbers:61871284,61971047); Beijing Major Science and Technology Project(grant numbers:Z191100010618003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9832597","Image super-resolution;dynamic attention;curvature map;multi-scale variational encoder","Image reconstruction;Superresolution;Visualization;Feature extraction;Deep learning;Transforms","feature extraction;image representation;image resolution;learning (artificial intelligence)","attention-based methods;controllable attention weights;convolutional kernel frequency parameters;curvature map;curvature-domain loss;dynamic generative attention learning;feature map spatial characteristics;feature representation ability;high-frequency geometric structures;high-frequency information;high-resolution images;latent space;multiscale variational encoder network;randomly generated latent variables;single image superresolution;static attention weights;variational hybrid network","","","","53","IEEE","18 Jul 2022","","","IEEE","IEEE Journals"
"A Multi-Cooperative Deep Convolutional Neural Network for Spatiotemporal Satellite Image Fusion","W. Li; C. Yang; Y. Peng; X. Zhang","Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15 Oct 2021","2021","14","","10174","10188","Remote sensing satellite images with high temporal and high spatial resolution play a critical role in earth science applications. However, it is difficult for a single satellite to obtain such images due to technical and cost constraints. Therefore, spatiotemporal image fusion based on deep learning has received extensive attention in recent years. This article proposes a multicooperative deep convolutional neural network (MCDNet) for spatiotemporal satellite image fusion. This method is a new multinetwork model in which multiple networks work together to reconstruct the predicted image. The multinetwork model consists of a super-resolution network, a difference reconstruction network, and a collaborative training network. First, the super-resolution network uses the combination of a novel multiscale mechanism and dilated convolutions to make full use of the spectral information of the coarse image and upgrade it to a transitional image that matches the fine image. The difference reconstruction network uses structural relevance to complete the reconstruction of the fine difference image. The collaborative training network extracts the hidden information from the fine image and uses the time relevance to restrict the training of the difference reconstruction network. Finally, the fine difference image and the known fine image are combined to complete the image fusion. The new compound loss function can help multinetwork models better complete cooperative training. Through experiments on two datasets and comparison with existing fusion algorithms, the subjective and objective results prove that MCDNet can effectively reconstruct higher-quality prediction images.","2151-1535","","10.1109/JSTARS.2021.3113163","National Natural Science Foundation of China(grant numbers:61972060,U1713213,62027827); National Key R&D Program of China(grant numbers:2019YFE0110800); Natural Science Foundation of Chongqing(grant numbers:cstc2020jcyj-zdxmX0025,cstc2019cxcyljrc-td0270); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9540272","Convolutional neural network (CNN);dilated convolution;multiscale mechanism;spatiotemporal fusion","Image reconstruction;Convolutional neural networks;Spatiotemporal phenomena;Spatial resolution;Feature extraction;Satellites;Training","convolutional neural nets;deep learning (artificial intelligence);feature extraction;image fusion;image reconstruction;image resolution;remote sensing","multicooperative deep convolutional neural network;spatiotemporal satellite image fusion;remote sensing satellite images;temporal resolution;spatial resolution;deep learning;super-resolution network;difference reconstruction network","","4","","45","CCBY","16 Sep 2021","","","IEEE","IEEE Journals"
"Hyperspectral-Multispectral Image Fusion via Tensor Ring and Subspace Decompositions","H. Xu; M. Qin; S. Chen; Y. Zheng; J. Zheng","College of Computer Science, and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science, and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Sciences and Engineering, Tianjin University of Technology, Tianjin, China; Engineering Research Center of Digital Forensics, Ministry of Education, Nanjing, China; College of Computer Science, and Technology, Zhejiang University of Technology, Hangzhou, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","17 Sep 2021","2021","14","","8823","8837","Fusion from a spatially low resolution hyperspectral image (LR-HSI) and a spectrally low resolution multispectral image (MSI) to produce a high spatial-spectral HSI (HR-HSI), known as hyperspectral super resolution, has risen to a preferred topic for reinforcing the spatial-spectral resolution of HSI in recent years. In this work, we propose a new model, namely, low-rank tensor ring decomposition based on tensor nuclear norm (LRTRTNN), for HSI-MSI fusion. Specifically, for each spectrally subspace cube, similar patches are grouped to exploit both the global low-rank property of LR-HSI and the nonlocal similarity of HR-MSI. Afterward, a joint optimization of all groups via the presented LRTRTNN approximation is implemented in a unified cost function. With the introduced tensor nuclear norm (TNN) constraint, all 3D tensor ring factors are no longer unfolded to suit the matrix nuclear norm used in conventional methods, and the internal tensor structure can be naturally retained. The alternating direction method of multipliers is introduced for coefficients update. Numerical and visual experiments on real data show that our LRTRTNN method outperforms most state-of-the-art algorithms in terms of fusing performance.","2151-1535","","10.1109/JSTARS.2021.3108233","National Key R&D Program of China(grant numbers:2018YFE0126100); National Natural Science Foundation of China(grant numbers:62020106004,61602413); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LY19F030016); Open Research Projects of Zhejiang Lab(grant numbers:2019KD0AD01/007); Scientific Research Fund of the National Health Commission of China(grant numbers:WKJ-ZJ-2102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9525254","Hyperspectral imaging;hyperspectral super resolution;image fusion;low-rank decomposition;multispectral image (MSI);tenson ring;tensor nuclear norm (TNN)","Tensors;Spatial resolution;Hyperspectral imaging;Three-dimensional displays;Matrix decomposition;Sparse matrices;Earth","geophysical image processing;hyperspectral imaging;image fusion;image resolution;matrix algebra;remote sensing;tensors","spectrally subspace cube;low-rank property;LR-HSI;nonlocal similarity;presented LRTRTNN approximation;introduced tensor nuclear norm constraint;3D tensor ring factors;matrix nuclear norm;internal tensor structure;LRTRTNN method;hyperspectral-multispectral image fusion;spatially low resolution hyperspectral image;spectrally low resolution multispectral image;spatial-spectral HSI;HR-HSI;hyperspectral super resolution;preferred topic;low-rank tensor ring decomposition;HSI-MSI fusion","","6","","51","CCBY","30 Aug 2021","","","IEEE","IEEE Journals"
"NSTMR: Super Resolution of Sentinel-2 Images Using Nonlocal Nonconvex Surrogate of Tensor Multirank","X. -Q. Wang; T. -Y. Ji","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Mathematics and Statistics, Northwestern Polytechnical University, Xi’an, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15 Jun 2021","2021","14","","5694","5706","In this article, we address the super-resolution problems, which estimate the high-resolution multispectral images from the multispectral Sentinel-2 (S2) images with different resolutions. Since S2 images can be naturally represented by tensors, we reformulate the degradation process as the tensor-based form. Based on the degradation mechanism, we build a tensor-based optimization model for S2 images super-resolution problem, which fully exploits intrinsic nonlocal spatial similarity and global spectral redundancy. Specifically, the model consists of the data fidelity term and the low-multirank regularizer tailored to thoroughly mining the inherent spatial-nonlocal and spectral redundancy. Then, we develop an efficient alternating direction method of multipliers algorithm with theoretically guaranteed convergence to tackle the resulting tensor optimization problem. Numerical experiments including simulated and real data demonstrate that our method outperforms the competing methods visually and qualitatively.","2151-1535","","10.1109/JSTARS.2021.3083495","National Natural Science Foundation of China(grant numbers:12001432); Fundamental Research Funds for the Central Universities(grant numbers:31020180QD126); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440747","Alternating direction method of multipliers (ADMMs);global spectral redundancy;nonlocal spatial similarity;sentinel-2 (S2) image","Tensors;Spatial resolution;Superresolution;Three-dimensional displays;Redundancy;Pansharpening;Optimization","convex programming;geophysical image processing;image resolution;spectral analysis;tensors","intrinsic nonlocal spatial similarity;global spectral redundancy;low-multirank regularizer;tensor optimization;nonlocal nonconvex surrogate;tensor multirank;high-resolution multispectral images;multispectral Sentinel-2 images;tensor-based form;spatial-nonlocal redundancy;S2 images super-resolution;NSTMR;data fidelity term;alternating direction method of multipliers","","4","","49","CCBY","25 May 2021","","","IEEE","IEEE Journals"
"Spatial Light Modulator-Based Architecture to Implement a Super-Resolved Compressive Instrument for Earth Observation","V. Raimondi; L. Acampora; G. Amato; M. Baldi; D. Berndt; A. Bianchi; T. Bianchi; D. Borrelli; V. Colcelli; C. Corti; F. Corti; M. Corti; N. Cox; U. A. Dauderstädt; P. Dürr; S. F. González; P. Frosini; D. Guzzi; J. Huntingford; D. Kunze; D. Labate; N. Lamquin; C. Lastri; E. Magli; V. Nardino; C. Pache; L. Palombi; I. Pettinelli; G. Pilato; A. Pollini; L. Rossini; E. Suetta; D. Taricco; D. Valsesia; M. Wagner","CNR - IFAC, Sesto Fiorentino (FI), Italy; CNR - IFAC, Sesto Fiorentino (FI), Italy; CNR - IFAC, Sesto Fiorentino (FI), Italy; CNR - IFAC, Sesto Fiorentino (FI), Italy; IPMS - Fraunhofer Institut, Dresden, Germany; LEONARDO S.p.A., Campi Bisenzio (FI), Italy; Politecnico di Torino - DET, Torino, Italy; LEONARDO S.p.A., Campi Bisenzio (FI), Italy; CNR - IFAC, Sesto Fiorentino (FI), Italy; SAITEC srl, Firenze, Italy; SAITEC srl, Firenze, Italy; SAITEC srl, Firenze, Italy; ACRI-ST, Sophia-Antipolis, France; IPMS - Fraunhofer Institut, Dresden, Germany; IPMS - Fraunhofer Institut, Dresden, Germany; IPMS - Fraunhofer Institut, Dresden, Germany; RESOLVO srl, Firenze, Italy; CNR - IFAC, Sesto Fiorentino (FI), Italy; RESOLVO srl, Firenze, Italy; IPMS - Fraunhofer Institut, Dresden, Germany; LEONARDO S.p.A., Campi Bisenzio (FI), Italy; ACRI-ST, Sophia-Antipolis, France; CNR - IFAC, Sesto Fiorentino (FI), Italy; Politecnico di Torino - DET, Torino, Italy; CNR - IFAC, Sesto Fiorentino (FI), Italy; CSEM, Centre Suisse d'Electronique et Microtechnique, Neuchâtel, Switzerland; CNR - IFAC, Sesto Fiorentino (FI), Italy; RESOLVO srl, Firenze, Italy; LEONARDO S.p.A., Campi Bisenzio (FI), Italy; CSEM, Centre Suisse d'Electronique et Microtechnique, Neuchâtel, Switzerland; CSEM, Centre Suisse d'Electronique et Microtechnique, Neuchâtel, Switzerland; LEONARDO S.p.A., Campi Bisenzio (FI), Italy; Politecnico di Torino - DET, Torino, Italy; Politecnico di Torino - DET, Torino, Italy; IPMS - Fraunhofer Institut, Dresden, Germany","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","7864","7867","Due to a growing interest for imagery with high spatial and spectral resolution, Earth Observation sensors are producing increasing amounts of data. This poses a severe challenge in terms of computational, memory and transmission requirements. In order to overcome these limitations, a fascinating approach is the implementation of a compressive sensing architecture. In this paper, we present an instrumental concept based on the use of a spatial light modulator to implement a super-resolved, compressive demonstrator of an instrument aimed at Earth Observation in the visible and medium infrared spectral regions from geostationary platform.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554343","Compressive sensing;Earth Observation;infrared spectrometer;super-resolution","Earth;Image sensors;Instruments;Electrooptic modulators;Memory management;Modulation;Geoscience and remote sensing","compressed sensing;image resolution;optical design techniques;remote sensing;spatial light modulators","spatial light modulator-based architecture;super-resolved compressive instrument;imagery;high spatial resolution;spectral resolution;Earth Observation sensors;severe challenge;transmission requirements;fascinating approach;compressive sensing architecture;instrumental concept;compressive demonstrator;visible regions;medium infrared spectral regions","","","","11","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A Multiresolution Details Enhanced Attentive Dual-UNet for Hyperspectral and Multispectral Image Fusion","J. Fang; J. Yang; A. Khader; L. Xiao","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","26 Dec 2022","2023","16","","638","655","The fusion-based super-resolution of hyperspectral images (HSIs) draws more and more attention in order to surpass the hardware constraints intrinsic to hyperspectral imaging systems in terms of spatial resolution. Low-resolution (LR)-HSI is combined with a high-resolution multispectral image (HR-MSI) to achieve HR-HSI. In this article, we propose multiresolution details enhanced attentive dual-UNet to improve the spatial resolution of HSI. The entire network contains two branches. The first branch is the wavelet detail extraction module, which performs discrete wavelet transform on MSI to extract spatial detail features and then passes through the encoding–decoding. Its main purpose is to extract the spatial features of MSI at different scales. The latter branch is the spatio-spectral fusion module, which aims to inject the detail features of the wavelet detail extraction network into the HSI to reconstruct the HSI better. Moreover, this network uses an asymmetric feature selective attention model to focus on important features at different scales. Extensive experimental results on both simulated and real data show that the proposed network architecture achieves the best performance compared with several leading HSI super-resolution methods in terms of qualitative and quantitative aspects.","2151-1535","","10.1109/JSTARS.2022.3228941","National Natural Science Foundation of China(grant numbers:61871226,61571230,62001226); Jiangsu Provincial Social Developing Project(grant numbers:BE2018727); Natural Science Foundation of Jiangsu Province(grant numbers:BK20200465); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9983482","Attention mechanism;discrete wavelet transform;hyperspectral image (HSI);multiscale;UNet","Feature extraction;Data mining;Decoding;Discrete wavelet transforms;Tensors;Image coding;Hyperspectral imaging","discrete wavelet transforms;feature extraction;geophysical image processing;hyperspectral imaging;image fusion;image reconstruction;image resolution;neural nets;remote sensing","asymmetric feature selective attention model;fusion-based super-resolution;hardware constraints;high-resolution multispectral image fusion;HR-MSI;HSI super-resolution methods;hyperspectral imaging systems;multiresolution details enhanced attentive Dual-UNet;network architecture;spatial detail features;spatial resolution;spatio-spectral fusion module;wavelet detail extraction module;wavelet detail extraction network","","","","59","CCBY","13 Dec 2022","","","IEEE","IEEE Journals"
"Learning Token-Aligned Representations With Multimodel Transformers for Different-Resolution Change Detection","M. Liu; Q. Shi; J. Li; Z. Chai","Guangdong Provincial Key Laboratory for Urbanization and Geo-Simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory for Urbanization and Geo-Simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory for Urbanization and Geo-Simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory for Urbanization and Geo-Simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China","IEEE Transactions on Geoscience and Remote Sensing","7 Sep 2022","2022","60","","1","13","Different-resolution change detection (DRCD) is now becoming an urgent problem to be solved, which is of great potential in rapid monitoring, such as disaster assessment and urban expansion. In DRCD tasks, bitemporal inputs are given in the form of different resolutions, and thus, conventional change detection (CD) methods cannot be applied directly. Previous studies have attempted to deal with this problem by reconstructing the low-resolution (LR) image into a high-resolution (HR) one, including interpolation and super-resolution (SR). However, these solutions are limited by the availability of training data, making it hard to meet different kinds of needs. Besides, these image-level strategies have also ignored the interaction and alignment of high-level features. Therefore, we propose a new approach based on multimodel Transformers (MM-Trans), which solves the resolution gaps of bitemporal inputs in DRCD tasks from the perspective of feature alignment. In the MM-Trans, a weight-unshared feature extractor is first utilized to precisely capture the features of the different-resolution inputs. Then, a spatial-aligned Transformer (sp-Trans) is introduced to align the LR-image features to the same size of the HR-image ones, which can be optimized in a learnable way by an auxiliary token loss. After that, a semantic-aligned Transformer (se-Trans) is adopted, in which the bitemporal features can be further interacted and aligned semantically. Finally, a prediction head is employed to obtain fine-grained change results. Experiments conducted on three common CD datasets, CDD, S2Looking, and HTCD dataset, have shown the advancement of the MM-Trans and fully demonstrated its potential in DSCD tasks.","1558-0644","","10.1109/TGRS.2022.3200684","National Natural Science Foundation of China(grant numbers:61976234); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9864212","Change detection (CD);deep learning (DL);feature alignment;remote sensing;transformer","Feature extraction;Transformers;Task analysis;Spatial resolution;Image resolution;Interpolation;Land surface","deep learning (artificial intelligence);disasters;feature extraction;geophysical image processing;image resolution;interpolation;remote sensing","DRCD tasks;bitemporal inputs;low-resolution image;image-level strategies;high-level features;MM-Trans;feature alignment;weight-unshared feature extractor;LR-image features;bitemporal features;token-aligned representations;different-resolution change detection;multimodel transformers;spatial-aligned transformer","","1","","52","IEEE","22 Aug 2022","","","IEEE","IEEE Journals"
"Detecting Post Hurricane House Damage Using Geographic Information Related Multi-Resource Classification Model","Y. Li; S. Gu","Shanxi University Institute of Mathematical Science & Applied Mathematics, Taiyuan, China; The University of Sydney (USYD) Camperdown NSW 2006, Australia School of Computer Science","2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)","3 Feb 2022","2021","","","492","501","Hurricane, like other natural cataclysms that threaten human life and houses’ damage detection after a hurricane, is always a problem that needs to be solved. It is vital to retrieving the building damage status for planning rescue and reconstruction after the cataclysm. In this study, the convolutional neural networks (CNN) were utilized to identify collapsed buildings from post hurricane satellite imagery with the proposed workflow. Test accuracy (TeA), training accuracy (TrA), bootstrap algorithm, Grad-CAM, and feature maps (FM) were used as evaluation metrics. To overcome the imbalance, problems like overfitting, random flip, random sheer and zoom, and early stopping approach were tested on the investigations. The results demonstrated that the building collapsed information can be retrieved by utilizing post-event imagery. Simple convolutional neural network (SCNN) is the standard to compare the other two architectures, which achieved TrA 74.39% and TeA 76.91%, spend 18.22s per epoch. After adding an additional super resolution block specifically designed. The super resolution CNN with up sampling (SRCNN-US) reached lower TrA 78.01% but higher TeA 73.80% by spending nearly 4 times more (78.14s). Moreover, the multi input redesigned SCNN (MICNN) architecture showed better performance, with TrA value from 74.39% to 84.97% and TeA from 76.91% to 78.81% but consumed only 0.22s more per epoch. Combining MICNN and SRCNN-US, the MI-SRCNN-US model achieved the highest accuracy on the test set, 80.36%, and time-consuming, 83.50s/epoch. The 50 times bootstrap investigation shows that the MICNN makes predictions under more certainty with more accuracy. In subsequent evaluations, Grad-CAM and feature maps also prove that MICNN pays more attention to the building’s region rather than its surroundings. Therefore, the suitable method to promote classification performance is by using post-hurricane cataclysm satellite imagery together with related geographic coordinates information as the input of CNN.","","978-1-6654-2709-8","10.1109/ICBASE53849.2021.00098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9696065","convolutional neural networks (CNNs);SCNN;image classification;geographic coordinate;multi- resource knowledge;multi resource CNN (MICNN);super resolution CNN with up sampling (SRCNN-US);Lota","Training;Satellites;Image resolution;Object oriented modeling;Buildings;Transfer learning;Hurricanes","disasters;emergency management;feature extraction;geographic information systems;geophysical signal processing;geophysical techniques;image classification;learning (artificial intelligence);remote sensing;statistical analysis;storms","bootstrap algorithm;Grad-CAM;feature maps;evaluation metrics;random sheer;post-event imagery;simple convolutional neural network;TeA 76;additional super resolution block;super resolution CNN;multiinput;SCNN architecture;MICNN;TrA value;MI-SRCNN-US model;test set;50 times bootstrap investigation;classification performance;post-hurricane cataclysm satellite imagery;related geographic coordinates information;post hurricane house damage;geographic information related multiresource classification model;natural cataclysms;building damage status;convolutional neural networks;collapsed buildings;post hurricane satellite imagery","","","","21","IEEE","3 Feb 2022","","","IEEE","IEEE Conferences"
"A Twice Optimizing Net With Matrix Decomposition for Hyperspectral and Multispectral Image Fusion","D. Shen; J. Liu; Z. Xiao; J. Yang; L. Xiao","Jiangsu Provincial Engineering Laboratory for Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China; Jiangsu Provincial Engineering Laboratory for Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China; Jiangsu Provincial Engineering Laboratory for Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China; Jiangsu Provincial Engineering Laboratory for Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China; School of Computer Science and Engineering, the Nanjing University of Science and Technology, Nanjing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","28 Jul 2020","2020","13","","4095","4110","Fusing a low-resolution hyperspectral (LRHS) image and a high-resolution multispectral (HRMS) image to generate a high-resolution hyperspectral (HRHS) image has grown a significant and attractive application in remote sensing fields. Recently, the popularization of deep learning has injected more possibilities into the fusion work. However, there still exists a difficulty that is how to make the best of the acquired LRHS and HRMS images. In this article, we present a twice optimizing net with matrix decomposition to fulfill the fusion task, which can be roughly divided into three stages: pre-optimization, deep prior learning, post-optimization. Specifically, we first transform this fusion problem into a spectral optimization problem and a spatial optimization problem with the help of matrix decomposition. These two optimization problems can be handled sequentially by solving a linear equation, respectively, and then we can obtain the initial HRHS image by multiplying the two solutions. Next, we establish the mapping between the initial image and the reference image through an end-to-end deep residual network based on local and nonlocal connectivity. In order to get better performance, we have customized a loss function specifically for the fusion task as well. Finally, we return the predicted result again to the optimization procedure to get the final fusion image. After the evaluation on three simulated datasets and one real dataset, it illustrates that the proposed method outperforms many state-of-the-art ones.","2151-1535","","10.1109/JSTARS.2020.3009250","National Natural Science Foundation of China(grant numbers:61601201); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141409","Convolutional neural network (CNN);hyperspectral image;image fusion;loss function;super resolution","Feature extraction;Optimization;Hyperspectral imaging;Image resolution;Matrix decomposition;Image fusion","geophysical image processing;image fusion;image resolution;image sensors;learning (artificial intelligence);matrix decomposition;optimisation;remote sensing","high-resolution hyperspectral image;HRMS;high-resolution multispectral image;LRHS;low-resolution hyperspectral image;final fusion image;optimization procedure;end-to-end deep residual network;reference image;initial HRHS image;optimization problems;spatial optimization problem;spectral optimization problem;post-optimization;deep prior learning;pre-optimization;matrix decomposition;twice optimizing net;deep learning;remote sensing fields","","15","","57","CCBY","15 Jul 2020","","","IEEE","IEEE Journals"
"Bayesian sparse representation for hyperspectral image super resolution","N. Akhtar; F. Shafait; A. Mian","The University of Western Australia, Crawley, WA; The University of Western Australia, Crawley, WA; The University of Western Australia, Crawley, WA","2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","15 Oct 2015","2015","","","3631","3640","Despite the proven efficacy of hyperspectral imaging in many computer vision tasks, its widespread use is hindered by its low spatial resolution, resulting from hardware limitations. We propose a hyperspectral image super resolution approach that fuses a high resolution image with the low resolution hyperspectral image using non-parametric Bayesian sparse representation. The proposed approach first infers probability distributions for the material spectra in the scene and their proportions. The distributions are then used to compute sparse codes of the high resolution image. To that end, we propose a generic Bayesian sparse coding strategy to be used with Bayesian dictionaries learned with the Beta process. We theoretically analyze the proposed strategy for its accurate performance. The computed codes are used with the estimated scene spectra to construct the super resolution hyperspectral image. Exhaustive experiments on two public databases of ground based hyperspectral images and a remotely sensed image show that the proposed approach outperforms the existing state of the art.","1063-6919","978-1-4673-6964-0","10.1109/CVPR.2015.7298986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7298986","","Dictionaries;Hyperspectral imaging;Bayes methods;Spatial resolution;Yttrium","Bayes methods;hyperspectral imaging;image representation;image resolution;remote sensing;statistical distributions","hyperspectral image super resolution;nonparametric Bayesian sparse representation;probability distributions;generic Bayesian sparse coding strategy;Bayesian dictionary learning;Beta process;remotely sensed image","","148","","36","IEEE","15 Oct 2015","","","IEEE","IEEE Conferences"
"A Locally Optimized Model for Hyperspectral and Multispectral Images Fusion","K. Ren; W. Sun; X. Meng; G. Yang; J. Peng; J. Huang","Department of Geography and Spatial Information Techniques, Ningbo University, Ningbo, China; Department of Geography and Spatial Information Techniques, Ningbo University, Ningbo, China; Faculty of Electrical Engineering and Computer Science, Ningbo University, Ningbo, China; Department of Geography and Spatial Information Techniques, Ningbo University, Ningbo, China; Hubei Key Laboratory of Applied Mathematics, Faculty of Mathematics and Statistics, Hubei University, Wuhan, China; Key Laboratory of Environment Remediation and Ecological Health, Ministry of Education, College of Natural Resources and Environmental Science, Zhejiang University, Hangzhou, China","IEEE Transactions on Geoscience and Remote Sensing","28 Feb 2022","2022","60","","1","15","The maintenance of spectral variability between subclass objects and the relationship between hyperspectral (HS) bands have been a fundamental but challenging problem for fusing low spatial resolution (LR) HS and high spatial resolution (HR) multispectral (MS) images. This article presents a locally optimized image segmentation fusion (LOISF) framework for HS super-resolution reconstruction. First, LR HS and HR MS are clustered and segmented, and the label attributes of the segmented objects are identified by the prior information. Then, a novel joint fusion model for different typical ground objects is constructed based on spectral unmixing. The fusion problem is formulated mathematically as a convex optimization of a Frobenius norm, which includes spatial, spectral, and index constraints, with an alternating-directions’ optimization featuring linearization providing the solution. Experimental results demonstrate that the proposed LOISF preserves both spatial details and texture, achieving high spectral fidelity, and yielding significantly improved image quality compared to other state-of-the-art fusion methods.","1558-0644","","10.1109/TGRS.2021.3133670","National Natural Science Foundation of China(grant numbers:42122009,42171351,41971296,61871177,42171326,41801256,41801252); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LR19D010001,LQ18D010001); Hubei Provincial Natural Science Foundation of China(grant numbers:2021CFA087); Public Projects of Ningbo City(grant numbers:2021S089); Fundamental Research Funds for the Provincial Universities of Zhejiang(grant numbers:SJLZ2022002); Science and Technology Project for the Department of Natural Resources of Zhejiang Province(grant numbers:2021-30,2021-31); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9641801","Hyperspectral (HS);image fusion;locally optimized image segmentation fusion (LOISF);multispectral;unmixing","Spatial resolution;Matrix decomposition;Image segmentation;Indexes;Sparse matrices;Learning systems;Image fusion","convex programming;hyperspectral imaging;image fusion;image reconstruction;image resolution;image segmentation;image texture;linearisation techniques;pattern clustering;spectral analysis","locally optimized model;spectral variability;subclass objects;hyperspectral band;low spatial resolution image;high spatial resolution multispectral images;locally optimized image segmentation fusion framework;LOISF;object segmentation;joint fusion model;ground objects;spectral unmixing;convex optimization;spatial constraints;spectral constraint;alternating-directions optimization;spatial details;image texture;spectral fidelity;image quality;index constraint;hyperspectral superresolution reconstruction;hyperspectral image;image fusion;label attributes;prior information;Frobenius norm;linearization","","4","","58","IEEE","7 Dec 2021","","","IEEE","IEEE Journals"
"LFG-Net: Low-Level Feature Guided Network for Precise Ship Instance Segmentation in SAR Images","S. Wei; X. Zeng; H. Zhang; Z. Zhou; J. Shi; X. Zhang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","14 Jul 2022","2022","60","","1","17","Ship instance segmentation of high-resolution (HR) synthetic aperture radar (SAR) images is a valuable and challenging task due to the complex scattering and noise properties. In this article, we pioneered the construction of the low-level feature to discriminate the ships and complemented the super-resolution (SR) denoising techniques in the network modules, termed low-level feature guided network (LFG-Net), for precise ship instance segmentation in SAR images. LFG-Net consists of the low-level feature concerned pyramid (LFCP), the high-resolution feature interaction module (HR-FIM), and the compression recovery segmentation branch (CRSB). LFCP extends the vanilla feature pyramid network (FPN) with the  ${P_{1}}$  layer and complements SR techniques to capture the regional and texture information at the image level for small object segmentation. HR-FIM interacts with the bounding box region of interest (RoI) feature and mask RoI feature at the instance level with HR techniques to enhance the mask RoI feature. CRSB aims at recovering the HR mask predictions to improve the ship segmentation performance. Comprehensive experiments on high-resolution SAR images dataset (HRSID), polygon segmentation SAR ship detection dataset (PSeg-SSDD), and AirSARShip indicate that LFG-Net* achieves 11.7%, 6.3%, and 12.7% AP increments compared with the Mask R-CNN baseline, respectively. Besides, it receives 9.5%, 4.9%, and 7.3% AP increments compared with the state-of-the-art method, which bridges the gap of instance segmentation precision in SAR images. In terms of the visualized instance segmentation results, LFG-Net* is capable of segmenting the complex scenes, e.g., the adjacent distributed ships and ships with strong reflection noise interference, in SAR images. The code is available at: https://github.com/Evarray/LFG-Net.","1558-0644","","10.1109/TGRS.2022.3188677","National Key Research and Development Program of China(grant numbers:2017-YFB0502700); National Natural Science Foundation of China(grant numbers:61501098); High-Resolution Earth Observation Youth Foundation(grant numbers:GFZX04061502); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815311","Feature pyramid network (FPN);instance segmentation;region of interest (RoI);ship detection;synthetic aperture radar (SAR)","Marine vehicles;Image segmentation;Feature extraction;Synthetic aperture radar;Radar polarimetry;Task analysis;Transformers","feature extraction;geophysical image processing;image segmentation;image texture;object detection;radar imaging;remote sensing by radar;ships;synthetic aperture radar","precise ship instance segmentation;SAR images;high-resolution synthetic aperture radar images;complex scattering;noise properties;super-resolution;network modules;low-level feature concerned pyramid;high-resolution feature interaction module;compression recovery segmentation branch;vanilla feature pyramid network;image level;object segmentation;interest feature;instance level;ship segmentation performance;instance segmentation precision;visualized instance segmentation results;adjacent distributed ships;LFG-Net;low-level feature guided network;CRSB","","3","","65","IEEE","5 Jul 2022","","","IEEE","IEEE Journals"
"UWB Processing Applied to Multifrequency Radar Sounders: The Case of MARSIS and Comparison With SHARAD","L. Gambacorta; M. C. Raguso; M. Mastrogiuseppe; R. Seu","Dipartimento di Ingegneria dell’Informazione, Elettronica e Telecomunicazioni (DIET), La Sapienza Università di Roma, Rome, Italy; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Dipartimento di Ingegneria dell’Informazione, Elettronica e Telecomunicazioni (DIET), La Sapienza Università di Roma, Rome, Italy; Dipartimento di Ingegneria dell’Informazione, Elettronica e Telecomunicazioni (DIET), La Sapienza Università di Roma, Rome, Italy","IEEE Transactions on Geoscience and Remote Sensing","21 Nov 2022","2022","60","","1","14","We readapt ultrawideband (UWB) processing to enhance the range resolution of the Mars Advanced Radar for Subsurface and Ionosphere Sounding (MARSIS) up to a factor of 6 (25 m). The technique provides for the estimation of radar signature over a wider spectrum via the application of well-known super-resolution (SR) techniques to adjoining subbands. The measured spectra are first interpolated and then extrapolated outside the original bands. The revised algorithm includes the estimation and removal of ionospheric effects impacting the two signals. Because the processing requires the realignment of the echoes at different frequencies, we derived the maximum tolerable retracking error to obtain reliable super-resolved range profiles. This condition is fulfilled by low-roughness areas compared to MARSIS wavelength, which proves to be suitable for the application of our processing. Examples of super-resolved experimental products over different geological scenarios show the detection of shallow dielectric interfaces not visible from original MARSIS products. Our results are validated by comparison with the Shallow Radar (SHARAD) data acquired at the crossovers, demonstrating the potential of the method to provide enhanced imaging capabilities.","1558-0644","","10.1109/TGRS.2022.3216893","Italian Space Agency (ASI); Jet Propulsion Laboratory, California Institute of Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9928217","Autoregressive (AR) models;bandwidth extrapolation (BWE);bandwidth interpolation (BWI);ground penetrating radar (GPR);ionosphere effects;radar sounder;surface roughness","Radar imaging;Radar;Bandwidth;Extrapolation;Signal resolution;Image resolution;Radar tracking","ground penetrating radar;image resolution;Mars;planetary surfaces;radar imaging;radar resolution;remote sensing by radar","adjoining subbands;different geological scenarios;enhanced imaging capabilities;Ionosphere Sounding;ionospheric effects;low-roughness areas;Mars Advanced Radar;MARSIS wavelength;maximum tolerable retracking error;measured spectra;original bands;original MARSIS products;radar signature;radar sounders;range resolution;revised algorithm;shallow dielectric interfaces not visible;Shallow Radar data;SHARAD;size 25.0 m;super-resolved experimental products;super-resolved range profiles;ultrawideband processing;UWB processing;well-known super-resolution techniques;wider spectrum","","","","38","IEEE","25 Oct 2022","","","IEEE","IEEE Journals"
"IAA-Based High-Resolution ISAR Imaging With Small Rotational Angle","P. Hu; S. Xu; W. Wu; B. Tian; Z. Chen","Science and Technology on Automatic Target Recognition Laboratory, National University of Defense Technology, Changsha, China; Science and Technology on Automatic Target Recognition Laboratory, National University of Defense Technology, Changsha, China; Science and Technology on Automatic Target Recognition Laboratory, National University of Defense Technology, Changsha, China; College of Electronic Science and Engineering, National University of Defense Technology, Changsha, China; Science and Technology on Automatic Target Recognition Laboratory, National University of Defense Technology, Changsha, China","IEEE Geoscience and Remote Sensing Letters","25 Oct 2017","2017","14","11","1978","1982","The Fourier transform-based range Doppler method is commonly used in an inverse synthetic aperture radar. Although it has achieved good success in most scenarios, its performance is determined by the rotational angle, and the cross-range resolution is extremely low in the case of a small rotational angle. In this letter, to improve the cross-range resolution, a novel cross-range compression scheme based on the iterative adaptive approach (IAA) is proposed. In addition to the standard IAA to achieve high resolution, the efficient IAA is introduced to suppress the sidelobes due to noise. Both the simulation and experimental results demonstrate that the proposed method has the advantages of parameter-free, high accuracy, and high efficiency.","1558-0571","","10.1109/LGRS.2017.2744989","National Natural Science Foundation of China(grant numbers:61471373); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048504","Inverse synthetic aperture radar (ISAR);iterative adaptive approach (IAA);spectral estimation;super-resolution","Imaging;Signal resolution;Doppler effect;Spatial resolution;Covariance matrices;High-resolution imaging","data compression;Doppler radar;Fourier transforms;image coding;image resolution;interference suppression;iterative methods;radar imaging;radar resolution;synthetic aperture radar","inverse synthetic aperture radar;high-resolution ISAR imaging;Fourier transform-based range Doppler method;cross-range compression scheme;iterative adaptive approach","","20","","24","IEEE","22 Sep 2017","","","IEEE","IEEE Journals"
"Superresolution Land Cover Mapping Using a Generative Adversarial Network","C. Shang; X. Li; G. M. Foody; Y. Du; F. Ling","University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; School of Geography, University of Nottingham, Nottingham, U.K.; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","24 Dec 2021","2022","19","","1","5","Superresolution mapping (SRM) is a commonly used method to cope with the problem of mixed pixels when predicting the spatial distribution within low-resolution pixels. Central to the popular SRM method is the spatial pattern model, which is utilized to represent the land cover spatial distribution within mixed pixels. The use of an inappropriate spatial pattern model limits such SRM analyses. Alternative approaches, such as deep-learning-based algorithms, which learn the spatial pattern from training data through a convolutional neural network, have been shown to have considerable potential. Deep learning methods, however, are limited by issues such as the way the fraction images are utilized. Here, a novel SRM model based on a generative adversarial network (GAN), GAN-SRM, is proposed that uses an end-to-end network to address the main limitations of existing SRM methods. The potential of the proposed GAN-SRM model was assessed using four land cover subsets and compared to hard classification and several popular SRM methods. The experimental results show that of the set of methods explored, the GAN-SRM model was able to generate the most accurate high-resolution land cover maps.","1558-0571","","10.1109/LGRS.2020.3020395","Innovation Group Project of Hubei Natural Science Foundation(grant numbers:2019CFA019); Hubei Province Natural Science Fund for Distinguished Young Scholars(grant numbers:2018CFA062); Natural Science Foundation of China(grant numbers:61671425); Youth Innovation Promotion Association CAS(grant numbers:2017384); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195742","Deep learning;generative adversarial network (GAN);super-resolution mapping (SRM)","Generative adversarial networks;Training data;Layout;Spatial resolution;Training;Gallium nitride","","","","4","","26","IEEE","14 Sep 2020","","","IEEE","IEEE Journals"
"Optimization-Based Hyperspectral Spatiotemporal Super-Resolution","P. -C. Chang; J. -T. Lin; C. -H. Lin; P. -W. Tang; Y. Liu","Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Miin Wu School of Computing, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan","IEEE Access","12 Apr 2022","2022","10","","37477","37494","Due to hardware limitations and financial considerations, it is challenging to acquire fine spatial and temporal resolution (FSFT) images, which leads to the interest in spatiotemporal fusion problems. Instead of directly obtaining costly FSFT images, an alternative is to fuse fine spatial, coarse temporal resolution (FSCT) images with coarse spatial, fine temporal resolution (CSFT) images. Unlike existing spatiotemporal methods which are only designed for multispectral images, this paper first proposes a new fusion framework for hyperspectral spatiotemporal super-resolution, termed HSTSR. In this paper, we first deal with the coarse temporal resolution issue by adopting the fast iterative shrinkage-thresholding algorithm (FISTA) to estimate the missing images at the intermediate time series. Then, we fuse the hyperspectral image and the multispectral image in each time series via coupled nonnegative matrix factorization (CNMF) to get FSFT hyperspectral images. Importantly, we can automatically estimate the associated spatial blurring and spectral downsampling matrices without prior satellite hardware information. Compared with other extended multispectral spatiotemporal methods, our method not only attains satisfying qualities significantly faster, but also requires much less input data.","2169-3536","","10.1109/ACCESS.2022.3163266","Einstein Program (Young Scholar Fellowship Program) of the Ministry of Science and Technology (MOST), Taiwan(grant numbers:MOST 110-2636-E-006-026); Higher Education Sprout Project of Ministry of Education (MOE) to the Headquarters of University Advancement at National Cheng Kung University (NCKU); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745133","Gradient descent;ADMM;FISTA;convex optimization;hyperspectral;multispectral;spatiotemporal;super-resolution;image fusion","Spatial resolution;Spatiotemporal phenomena;Satellites;Hyperspectral imaging;Superresolution;Sensor fusion;Image sensors","geophysical image processing;hyperspectral imaging;image fusion;image resolution","optimization-based hyperspectral spatiotemporal super-resolution;hardware limitations;spatiotemporal fusion problems;costly FSFT images;fine spatial, coarse temporal resolution images;coarse spatial, fine temporal resolution images;multispectral image;fusion framework;coarse temporal resolution issue;fast iterative shrinkage-thresholding algorithm;missing images;FSFT hyperspectral images;spatial blurring;extended multispectral spatiotemporal methods","","2","","52","CCBY","30 Mar 2022","","","IEEE","IEEE Journals"
"SPCNet: A Subpixel Convolution-Based Change Detection Network for Hyperspectral Images With Different Spatial Resolutions","L. Wang; L. Wang; H. Wang; X. Wang; L. Bruzzone","College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy","IEEE Transactions on Geoscience and Remote Sensing","18 Jul 2022","2022","60","","1","14","The very high spectral resolution in hyperspectral images (HSIs) offers an opportunity to detect subtle land-cover changes. However, the availability of HSIs acquired from different platforms requires the development of change detection (CD) methods capable of processing HSIs with different spatial resolutions. In this article, we propose a general end-to-end subpixel convolution-based residual network (SPCNet) to accomplish the CD task between high spatial resolution (HR) and low spatial resolution (LR) HSIs. To effectively tackle the resolution matching issue, a super-resolution (SR) block with an efficient subpixel convolution layer is introduced to upscale the LR feature maps into HR maps. The subpixel convolution layer can fully explore the subpixel context information by learning an array of upscaling filters. Moreover, the designed SPC module is embedded into the LR branch to generate more discriminative representations. More importantly, the SPC module as a plug-and-play unit has the potential to be embedded into other baseline networks to enhance the feature learning capability. Experimental results on four HSI datasets demonstrate the effectiveness of the proposed SPCNet.","1558-0644","","10.1109/TGRS.2022.3189188","National Natural Science Foundation of China(grant numbers:62071084); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817383","Change detection (CD);deep learning;hyperspectral images (HSIs);multiscale images;remote sensing;residual network;subpixel convolution","Spatial resolution;Feature extraction;Convolution;Task analysis;Interpolation;Residual neural networks;Tensors","feature extraction;geophysical image processing;geophysical signal processing;hyperspectral imaging;image classification;image representation;image resolution;learning (artificial intelligence);neural nets;terrain mapping","efficient subpixel convolution layer;upscale the LR feature maps;subpixel context information;SPCNet;subpixel convolution-based change detection network;hyperspectral images;high spectral resolution;subtle land-cover changes;change detection methods;general end-to-end subpixel convolution;high spatial resolution;low spatial resolution HSIs;resolution matching issue;super-resolution block","","1","","45","IEEE","7 Jul 2022","","","IEEE","IEEE Journals"
"Real Aperture Radar Forward-Looking Imaging Based on Variational Bayesian in Presence of Outliers","W. Li; M. Li; L. Zuo; H. Chen; Y. Wu","National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; Beijing Institute of Radio Measurement, Beijing, China; Remote Sensing Image Processing and Fusion Group, School of Electronic Engineering, Xidian University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","21 Sep 2022","2022","60","","1","13","Traditional forward-looking imaging methods of real aperture radar yield unsatisfactory performance in the presence of outliers. In this article, a method based on variational Bayesian (VB) is proposed to obtain forward-looking imaging in the presence of outliers. First, considering the non-Gaussian property of the imaging noise due to the outliers, we propose to use the Student- $t$  distribution to model noise. In this model, the echo signal does not need preprocessing for the outliers. Second, the Laplace hierarchical distribution is introduced to describe the sparsity of the target. Then, the forward-looking imaging problem converts to the optimal problem. Finally, we give the VB derivation to solve the imaging parameter. To illustrate the imaging performance in the presence of outliers, the outliers are randomly added to some angles and the whole scene of the echo signal in the simulations, respectively. From the simulation results, we can see that the proposed method achieves excellent performance for forward-looking imaging in the presence of outliers.","1558-0644","","10.1109/TGRS.2022.3203807","National Natural Science Foundation of China(grant numbers:61871307,62172321); Fundamental Research Funds for the Central Universities(grant numbers:JB210207); Innovation Fund of Xidian University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9874893","Forward-looking imaging;outliers;sparse reconstruction;super-resolution;variational Bayesian (VB)","Imaging;Radar imaging;Radar;Radar antennas;Azimuth;Bayes methods;Image reconstruction","","","","","","48","IEEE","2 Sep 2022","","","IEEE","IEEE Journals"
"Learned Image Downscaling for Upscaling Using Content Adaptive Resampler","W. Sun; Z. Chen","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China","IEEE Transactions on Image Processing","6 Feb 2020","2020","29","","4027","4040","Deep convolutional neural network based image super-resolution (SR) models have shown superior performance in recovering the underlying high resolution (HR) images from low resolution (LR) images obtained from the predefined downscaling methods. In this paper, we propose a learned image downscaling method based on content adaptive resampler (CAR) with consideration on the upscaling process. The proposed resampler network generates content adaptive image resampling kernels that are applied to the original HR input to generate pixels on the downscaled image. Moreover, a differentiable upscaling (SR) module is employed to upscale the LR result into its underlying HR counterpart. By back-propagating the reconstruction error down to the original HR input across the entire framework to adjust model parameters, the proposed framework achieves a new state-of-the-art SR performance through upscaling guided image resamplers which adaptively preserve detailed information that is essential to the upscaling. Experimental results indicate that the quality of the generated LR image is comparable to that of the traditional interpolation based method and the significant SR performance gain is achieved by deep SR models trained jointly with the CAR model. The code is publicly available on: https://github.com/sunwj/CAR.","1941-0042","","10.1109/TIP.2020.2970248","National Natural Science Foundation of China(grant numbers:61771348); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8982168","Image resizing;downscaling;super-resolution;content adaptive;non-uniform resampling","Kernel;Adaptation models;Task analysis;Image resolution;Visualization;Automobiles;Image reconstruction","image enhancement;image reconstruction;image representation;image resolution;image sampling;interpolation;learning (artificial intelligence);neural nets","image super-resolution models;low resolution images;learned image downscaling method;content adaptive resampler;resampler network;content adaptive image resampling kernels;downscaled image;differentiable upscaling module;model parameters;image resamplers;generated LR image;interpolation based method;deep SR models;CAR model;convolutional neural network","","64","","61","IEEE","4 Feb 2020","","","IEEE","IEEE Journals"
"Basis Pursuit Denoising via Recurrent Neural Network Applied to Super-Resolving SAR Tomography","K. Qian; Y. Wang; P. Jung; Y. Shi; X. X. Zhu","Chair of Data Science in Earth Observation, Technical University of Munich, Munich, Germany; Chair of Data Science in Earth Observation, Technical University of Munich, Munich, Germany; Chair of Data Science in Earth Observation, Technical University of Munich, Munich, Germany; Chair of Remote Sensing Technology, Technical University of Munich, Munich, Germany; Chair of Data Science in Earth Observation, Technical University of Munich, Munich, Germany","IEEE Transactions on Geoscience and Remote Sensing","20 Dec 2022","2022","60","","1","15","Finding sparse solutions of underdetermined linear systems commonly requires the solving of  $L_{1}$  regularized least-squares minimization problem, which is also known as the basis pursuit denoising (BPDN). They are computationally expensive since they cannot be solved analytically. An emerging technique known as deep unrolling provided a good combination of the descriptive ability of neural networks, explainable, and computational efficiency for BPDN. Many unrolled neural networks for BPDN, e.g., learned iterative shrinkage thresholding algorithm and its variants, employ shrinkage functions to prune elements with small magnitude. Through experiments on synthetic aperture radar tomography (TomoSAR), we discover the shrinkage step leads to unavoidable information loss in the dynamics of networks and degrades the performance of the model. We propose a recurrent neural network (RNN) with novel sparse minimal gated units (SMGUs) to solve the information loss issue. The proposed RNN architecture with SMGUs benefits from incorporating historical information into optimization and, thus, effectively preserves full information in the final output. Taking TomoSAR inversion as an example, extensive simulations demonstrated that the proposed RNN outperforms the state-of-the-art deep learning-based algorithm in terms of super-resolution power and generalization ability. It achieved 10%–20% higher double-scatterer detection rate and is less sensitive to phase and amplitude ratio difference between scatterers. Test on real TerraSAR-X spotlight images also shows the high-quality 3-D reconstruction of the test site.","1558-0644","","10.1109/TGRS.2022.3221185","European Research Council(grant numbers:ERC-2016-StG-714087 (So2Sat)); Helmholtz Association; Framework of the Helmholtz Excellent Professorship “Data Science in Earth Observation—Big Data Fusion for Urban Research”(grant numbers:W2-W3-100); German Federal Ministry of Education and Research in the framework of the International Future AI Lab “AI4EO—Artificial Intelligence for Earth Observation: Reasoning, Uncertainties, Ethics and Beyond”(grant numbers:01DD20001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9969379","Basis pursuit denoising (BPDN);recurrent neural network (RNN);sparse reconstruction;synthetic aperture radar tomography (TomoSAR)","Logic gates;Imaging;Recurrent neural networks;Image reconstruction;Thresholding (Imaging);Deep learning;Signal processing algorithms","deep learning (artificial intelligence);image denoising;image reconstruction;iterative methods;least squares approximations;minimisation;radar computing;radar imaging;radar resolution;recurrent neural nets;synthetic aperture radar;tomography","basis pursuit denoising;BPDN;computational efficiency;deep learning-based algorithm;deep unrolling;double-scatterer detection rate;generalization ability;high-quality 3D reconstruction;historical information;information loss issue;iterative shrinkage thresholding algorithm;learned iterative shrinkage;least-squares minimization problem;recurrent neural network;RNN architecture;shrinkage functions;shrinkage step;SMGU benefits;sparse minimal gated units;sparse solutions;super-resolution power;super-resolving SAR tomography;synthetic aperture radar tomography;TerraSAR-X spotlight images;unavoidable information loss;underdetermined linear systems;unrolled neural networks","","","","37","CCBY","2 Dec 2022","","","IEEE","IEEE Journals"
"Simple Strategies to Build Random Compressive Sensing Matrices in Step-Frequency Radars","Y. -S. Yoon; Y. Hong; S. Kim","Radar-PGM Research and Development Center, Hanwha Systems Company, Yongin, South Korea; Radar-PGM Research and Development Center, Hanwha Systems Company, Yongin, South Korea; Radar-PGM Research and Development Center, Hanwha Systems Company, Yongin, South Korea","IEEE Geoscience and Remote Sensing Letters","26 Aug 2018","2018","15","9","1357","1361","By applying compressive sensing, we can obtain radar range profile using only part of the frequency bins in step-frequency radars. While the probability of success in obtaining the range profile depends on which frequency bins are used, it seems that there is no general and simple method to choose the set of frequency bins for better probability of success. Although random selection is said to be good enough, it would be better if we select those in some strategic ways. This letter deals with frequency selection strategies when deterministic ways are not applicable and the super-resolution range profile is necessary. The proposed strategies are tested with simulations and real measurement data set. The results show that the proposed method is better in achieving the probability of exact recovery than casual random selections.","1558-0571","","10.1109/LGRS.2018.2841189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8390936","Compressive sensing (CS);Fourier matrix;step-frequency signal","Radar imaging;Radar measurements;Time-frequency analysis;Signal resolution;Sensors","compressed sensing;matrix algebra;probability;radar resolution","frequency bins;random selection;frequency selection strategies;super-resolution range profile;build random compressive sensing matrices;step-frequency radars;radar range profile","","3","","17","IEEE","20 Jun 2018","","","IEEE","IEEE Journals"
"Effectiveness of Super-Resolution Technique on Vegetation Indices","G. Rohith; L. S. Kumar","National Institute of Technology Puducherry, Karaikal, Puducherry, India; National Institute of Technology Puducherry, Karaikal, Puducherry, India","IEEE Access","13 Jul 2021","2021","9","","97197","97227","The identification and interpretation of remote sensed (RS) objects in an image depend on how well the sensor captures the region. In rare cases, RS images may be vulnerable to a lack of interpretability issues in some parts of the image due to the sensor's limits and preprocessing techniques. Conventionally, the interpretation of the land cover pattern's shape and size is apparent when the distance between the sensor and object is closer to the visualization level of objects and viable with digital airborne imagery. In this paper, an integration of the Super-Resolution (SR) technique in the high-resolution imagery to achieve the closer visualization level for mapping the vegetation is proposed. This approach enables the higher interpretive potential to define the land pattern's shape and size with very high spatial resolution, closer proximity, detailed and distinguishable patterns. This approach helps to precisely predict the total vegetated study area for land use and land cover changes (LULCC) and chlorophyll-rich vegetation applications. The proposed algorithm is carried out in two phases. In the first phase, the SR technique applied test images are tested for vegetation detection and mapping the vegetation information in a region with fourteen vegetation indices. In the second phase, similar testing is done without applying SR for input test images. The experiment revealed that test images using the SR technique yielded higher average values of 5 percent and 1 percent for the Normalized Difference Vegetation Index (NDVI) and Fractional Vegetation Cover (FVC), respectively, as compared to images tested using the non-SR technique.","2169-3536","","10.1109/ACCESS.2021.3094283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9471881","Vegetation mapping;convolutional neural networks;ground sampling distance (GSD);NDVI","Vegetation mapping;Spatial resolution;Indexes;Measurement;Soil;Classification algorithms;Convolution","geophysical image processing;geophysical signal processing;image classification;image resolution;land cover;land use;remote sensing;vegetation;vegetation mapping","Super-Resolution technique;rare cases;RS images;interpretability issues;preprocessing techniques;land cover pattern;digital airborne imagery;high-resolution imagery;closer visualization level;higher interpretive potential;land pattern;high spatial resolution;distinguishable patterns;total vegetated study area;land use;land cover changes;chlorophyll-rich vegetation applications;SR technique;vegetation detection;vegetation information;fourteen vegetation indices;similar testing;input test images;higher average values;Normalized Difference Vegetation Index;Fractional Vegetation Cover;nonSR technique;efficiency 5.0 percent;efficiency 1.0 percent","","","","48","CCBYNCND","2 Jul 2021","","","IEEE","IEEE Journals"
"Self-supervised multi-image super-resolution for push-frame satellite images","N. L. Nguyen; J. Anger; A. Davy; P. Arias; G. Facciolo","CNRS, ENS Paris-Saclay, Centre Borelli, Université Paris-Saclay, France; Kayrros SAS; CNRS, ENS Paris-Saclay, Centre Borelli, Université Paris-Saclay, France; CNRS, ENS Paris-Saclay, Centre Borelli, Université Paris-Saclay, France; CNRS, ENS Paris-Saclay, Centre Borelli, Université Paris-Saclay, France","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1 Sep 2021","2021","","","1121","1131","Recent constellations of optical satellites are adopting multi-image super-resolution (MISR) from bursts of push-frame images as a way to increase the resolution and reduce the noise of their products while maintaining a lower cost of operation. Most MISR techniques are currently based on the aggregation of samples from registered low resolution images. A promising research trend aimed at incorporating natural image priors in MISR consists in using data-driven neural networks. However, due to the unavailability of ground truth high resolution data, these networks cannot be trained on real satellite images. In this paper, we present a framework for training MISR algorithms from bursts of satellite images without requiring high resolution ground truth. This is achieved by adapting the recently proposed frame-to-frame framework to process bursts of satellite images. In addition we propose an architecture based on feature aggregation that allows to fuse a variable number of frames and is capable of handling degenerate samplings while also reducing noise. On synthetic datasets, the proposed self-supervision strategy attains results on par with those obtained with a supervised training. We applied our framework to real SkySat satellite image bursts leading to results that are more resolved and less noisy than the L1B product from Planet.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522764","","Training;Satellites;Planets;Superresolution;Neural networks;Computer architecture;Optical imaging","artificial satellites;geophysical equipment;geophysical image processing;image resolution;image sampling;learning (artificial intelligence);neural nets;remote sensing","self-supervised multiimage super-resolution;push-frame satellite images;optical satellites;push-frame images;MISR techniques;registered low resolution images;natural image priors;data-driven neural networks;ground truth high resolution data;MISR algorithms;high resolution ground truth;frame-to-frame framework;SkySat satellite image bursts","","7","","69","IEEE","1 Sep 2021","","","IEEE","IEEE Conferences"
"Hyper-spectral Image Super-resolution Using Non-negative Spectral Representation with Data-Guided Sparsity","X. -H. Han; J. Wang; B. Shi; Y. Zheng; Y. -W. Chen","Graduate School of Science and Technology for Innovation, Yamaguchi University, Yamaguchi, Japan; Ritsumeikan Univerity, Kusatsu, Shiga, Japan; The Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan; National Institute of Informatics, Tokyo, Japan; Ritsumeikan Univerity, Kusatsu, Shiga, Japan","2017 IEEE International Symposium on Multimedia (ISM)","1 Jan 2018","2017","","","500","506","Hyperspectral imaging has great potential for understanding the characteristics of different materials in many applications ranging from remote sensing to medical imaging. However, due to various hardware limitations, only low-resolution hyperspectral and high-resolution multi-spectral images can be available using existing imaging techniques. This study aims to generate a high-resolution hyperspectral image via fusion of the available LR-HS and HR-MS images. We propose a novel hyperspectral image superresolution method via non-negative sparse representation of reflectance spectral with adaptive sparsity constraint. By analyzing local content similarity of a focused pixel in the available high-resolution multi-spectral image, which can measure pixel material purity according to surrounding pixels, we generate a sparsity map for guiding non-negative sparse coding optimization procedure of the spectral representation called non-negative spectral representation with data-guided sparsity. Since the proposed method adaptively adjust the sparsity in the spectral representation based on the local content of the available high-resolution multi-spectral image, it can produce more robust spectral representation for recovering the target high-resolution hyper-spectral image. Comprehensive experiments on two public hyperspectral datasets validate that the proposed method achieves promising performances compared with the existing state of the art methods.","","978-1-5386-2937-6","10.1109/ISM.2017.99","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241665","","Hyperspectral imaging;Dictionaries;Spatial resolution;Sparse matrices;Cameras","geophysical image processing;hyperspectral imaging;image reconstruction;image representation;image resolution;optimisation;remote sensing","hyper-spectral image super-resolution;nonnegative spectral representation;medical imaging;low-resolution hyperspectral;high-resolution multispectral image;high-resolution hyperspectral image;HR-MS images;nonnegative sparse representation;nonnegative sparse coding optimization procedure;robust spectral representation;target high-resolution hyper-spectral image;hyperspectral image superresolution method","","3","","35","IEEE","1 Jan 2018","","","IEEE","IEEE Conferences"
"Fast Spatio-Temporal Residual Network for Video Super-Resolution","S. Li; F. He; B. Du; L. Zhang; Y. Xu; D. Tao","School of Computer Science, Wuhan University, China; UBTECH Sydney AI Centre, SCS, FEIT, the University of Sydney, Australia; School of Computer Science, Wuhan University, China; School of Computer Science, Wuhan University, China; The State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, China; UBTECH Sydney AI Centre, SCS, FEIT, the University of Sydney, Australia","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","10514","10523","Recently, deep learning based video super-resolution (SR) methods have achieved promising performance. To simultaneously exploit the spatial and temporal information of videos, employing 3-dimensional (3D) convolutions is a natural approach. However, straight utilizing 3D convolutions may lead to an excessively high computational complexity which restricts the depth of video SR models and thus undermine the performance. In this paper, we present a novel fast spatio-temporal residual network (FSTRN) to adopt 3D convolutions for the video SR task in order to enhance the performance while maintaining a low computational load. Specifically, we propose a fast spatio-temporal residual block (FRB) that divide each 3D filter to the product of two 3D filters, which have considerably lower dimensions. Furthermore, we design a cross-space residual learning that directly links the low-resolution space and the high-resolution space, which can greatly relieve the computational burden on the feature fusion and up-scaling parts. Extensive evaluations and comparisons on benchmark datasets validate the strengths of the proposed approach and demonstrate that the proposed network significantly outperforms the current state-of-the-art methods.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.01077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953815","Vision Applications and Systems;Computational Photography","","convolutional neural nets;feature extraction;image filtering;image fusion;image resolution;learning (artificial intelligence);spatiotemporal phenomena;stereo image processing;video signal processing","video SR models;fast spatio-temporal residual network;cross-space residual learning;deep learning;video super-resolution methods;3-dimensional convolutions;high computational complexity;FRB;FSTRN;fast spatio-temporal residual block;3D filter;feature fusion;up-scaling parts","","67","","47","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"A 2D Spatial Smoothing MUSIC Superresolution FMCW SAR Imaging Algorithm1","Y. Wang; X. Wen; X. QiU","Chinese Academy of Sciences, Aerospace Information Research Institute, Soochow, China; Chinese Academy of Sciences, Aerospace Information Research Institute, Soochow, China; National Key Laboratory of Microwave Imaging Technology, Beijing, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5071","5074","The super-resolution algorithm can break through the theoretical resolution limit of radar and improve image resolution by several times under the condition of hardware parameter limitation. The improved resolution can see more details of the image, which is helpful for target detection and recognition. In this paper, a 2D spatial smoothing music superresolution FMCW SAR imaging algorithm is proposed. In this algorithm, the spatial smoothing MUSIC algorithm is used to establish the guidance vector relationship between the frequency domain and the spatial position of the targets, and GDE is used to estimate the number of sources. The algorithm can achieve the super-resolution reconstruction of the imaging target space.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554997","FMCW SAR;spatial smoothing MUSIC;GDE;Superresolution","Smoothing methods;Target recognition;Superresolution;Imaging;Object detection;Radar imaging;Radar polarimetry","CW radar;direction-of-arrival estimation;FM radar;image reconstruction;image resolution;radar imaging;signal classification;synthetic aperture radar","2D spatial smoothing MUSIC superresolution FMCW SAR imaging algorithm;super-resolution algorithm;image resolution;2D spatial smoothing music superresolution FMCW SAR imaging algorithm;spatial smoothing MUSIC algorithm;super-resolution reconstruction;imaging target space","","","","8","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A Two-Stream Multiscale Deep Learning Architecture for Pan-Sharpening","J. Wei; Y. Xu; W. Cai; Z. Wu; J. Chanussot; Z. Wei","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; GIPSA-lab, CNRS, Grenoble INP, Universite Grenoble Alpes, Grenoble, France; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; GIPSA-lab, CNRS, Grenoble INP, Universite Grenoble Alpes, Grenoble, France; Inria, CNRS, Grenoble INP, LJK, Universite Grenoble Alpes, Grenoble, France; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","25 Sep 2020","2020","13","","5455","5465","Pan-sharpening, which fuses the high-resolution panchromatic (PAN) image and the low-resolution multispectral image (MSI), is a hot topic in remote sensing. Recently, deep learning technology has been successfully applied in pan-sharpening. However, the existing methods ignore that the MSI and PAN image are at different resolutions and use the same networks to extract features of the two images. To address this problem, we propose a two-stream deep learning architecture, called coupled multiscale convolutional neural network, for pan-sharpening. The proposed network has three components, feature extraction subnetworks, fusion layer, and super-resolution subnetwork. In the feature extraction subnetworks, two subnetworks are used to extract the features of the MSI and PAN image separately. Different sizes of convolutional kernels are used in the first layers due to the different spatial resolutions. Thus, the source images are mapped to the similar scale. Then a multiscale asymmetric convolution factorization is used to extract features at different scales. In the fusion layer, the two feature extraction subnetworks are coupled. Features at the same scale are first summed, and then the features of all scales are concatenated as one feature map. At last, a super-resolution subnetwork is used to generate the high-resolution MSI. Experimental results on both synthetic and real data sets demonstrate that the proposed method outperforms the other state-of-the-art pan-sharpening methods.","2151-1535","","10.1109/JSTARS.2020.3021074","National Natural Science Foundation of China(grant numbers:61701238,61772274,61471199,61976117,11431015,61501241,61671243,61802190); Jiangsu Provincial Natural Science Foundation of China(grant numbers:BK20170858,BK20180018,BK20191409); Fundamental Research Funds for the Central Universities(grant numbers:30919011234,30917015104,30919011103,30919011402); China Postdoctoral Science Foundation(grant numbers:2017M611814,2018T110502); Jiangsu Province Postdoctoral Science Foundation(grant numbers:1701148B); University Natural Science Fund of Jiangsu Province(grant numbers:19KJA360001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185040","Convolutional neural network (CNN);image fusion;multiscale;pan-sharpening","Feature extraction;Deep learning;Neural networks;Kernel;Spatial resolution;Convolution","convolutional neural nets;feature extraction;image enhancement;image fusion;image resolution;learning (artificial intelligence);remote sensing","feature extraction subnetworks;fusion layer;super-resolution subnetwork;PAN image;source images;multiscale asymmetric convolution factorization;feature map;high-resolution MSI;pan-sharpening methods;two-stream multiscale deep learning architecture;high-resolution panchromatic image;low-resolution multispectral image;deep learning technology;coupled multiscale convolutional neural network","","14","","46","CCBY","2 Sep 2020","","","IEEE","IEEE Journals"
"k-Space Decomposition Based Range Points Migration Method for Millimeter Wave Radar","Y. Akiyama; S. Kidera","Graduate School of Informatics and Engineering, University of Electro-Communications, Japan; Graduate School of Informatics and Engineering, University of Electro-Communications Japan Science and Technology Agency (JST), PRESTO, Japan","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","680","683","Millimeter wave short range radar is a great potential for monitoring sensor being applicable to optically challenging environments (e.g., smog, fog or darkness). While a number of imaging algorithms have been intensively developed, the range points migration(RPM) method is regarded as one of the most promising options to achieve accurate and fast three-dimensional imaging. However, since the RPM is based on incoherent processing, it has disadvantage for angular resolution in considering millimeter wave radar with lower fractional bandwidth. To address with the above problem, this paper proposes a k-space decomposition based RPM method, where the received data is converted and decomposed into the k-space to retain the desired angular resolution. As a notable feature of the proposed method, it offers a clustered range points decomposed by k-space, which contributes to enhance an imaging accuracy by the RPM. The two-dimensional and three-dimensional numerical tests demonstrate the effectiveness of our proposed method, compared with other super resolution algorithms.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8897940","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897940","Millimeter wave radar;Range points migration (RPM);short-range sensor;k-space decomposition;Super-resolution imaging","Millimeter wave radar;Radar imaging;Image resolution;Imaging;Signal resolution","millimetre wave radar;radar imaging;radar resolution","millimeter wave radar;clustered range points;k-space decomposition based range points migration method;k-space decomposition based RPM method;angular resolution","","4","","9","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Sensor-specific Transfer Learning for Hyperspectral Image Processing","S. Mei; X. Liu; G. Zhang; Q. Du","School of Electronics and Information Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information Northwestern Polytechnical University, Xi'an, China; Department of Electrical and Computer Engineering, Mississippi State University, MS, USA","2019 10th International Workshop on the Analysis of Multitemporal Remote Sensing Images (MultiTemp)","14 Oct 2019","2019","","","1","4","Transfer learning (TL) has shown its great advantage to solve small-training-sample problems using knowledge learned from existing large data with deep learning techniques, which can be used for hyperspectral image intelligent processing in which labeled data is very difficult and even impossible to be obtained. However, the mismatch of hyperspectral sensors results in lots of difficulty for transfer learning to be used in hyperspectral image (HSI) processing. In this paper, sensor-specific based transfer learning is proposed for hyperspectral images acquired from same sensors, in which knowledge learn from hyperspectral images, e.g., the network structure and parameters of a deep neural network, are limited to transfer to images of the same sensor only. Specifically, the validity of sensor-specific transfer learning is evaluated using three deep learning based tasks, including feature learning, super-resolution, and image denoising. Experimental results from two benchmark datasets from the well-known ROSIS sensor, i.e., Pavia Centre and Pavia University, have demonstrated that sensor-specific based transfer learning can achieve satisfying performance even without fine-tune by small-training-samples on the target scene.","","978-1-7281-4615-7","10.1109/Multi-Temp.2019.8866896","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8866896","transfer learning;hyperspectral image processing;convolutional neural network (CNN);feature learning;super-resolution;image denoising","Hyperspectral imaging;Noise reduction;Training;Task analysis;Feature extraction","geophysical image processing;hyperspectral imaging;image classification;image denoising;learning (artificial intelligence);neural nets","sensor-specific transfer learning;hyperspectral image processing;deep learning techniques;hyperspectral image intelligent processing;hyperspectral sensors;sensor-specific based transfer learning;hyperspectral images;deep learning based tasks;feature learning;image denoising;ROSIS sensor","","2","","8","IEEE","14 Oct 2019","","","IEEE","IEEE Conferences"
"S3: A Spectral-Spatial Structure Loss for Pan-Sharpening Networks","J. -S. Choi; Y. Kim; M. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Artificial Intelligence Research Division, Korea Aerospace Research Institute, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Geoscience and Remote Sensing Letters","22 Apr 2020","2020","17","5","829","833","Recently, many deep-learning-based pan-sharpening methods have been proposed for generating high-quality pan-sharpened (PS) satellite images. These methods focused on various types of convolutional neural network (CNN) structures, which were trained by simply minimizing a spectral loss between network outputs and the corresponding high-resolution (HR) multi-spectral (MS) target images. However, owing to different sensor characteristics and acquisition times, HR panchromatic (PAN) and low-resolution MS image pairs tend to have large pixel misalignments, especially for moving objects in the images. Conventional CNNs trained with only the spectral loss with these satellite image data sets often produce PS images of low visual quality including double-edge artifacts along strong edges and ghosting artifacts on moving objects. In this letter, we propose a novel loss function, called a spectral-spatial structure (S3) loss, based on the correlation maps between MS targets and PAN inputs. Our proposed S3 loss can be very effectively used for pan-sharpening with various types of CNN structures, resulting in significant visual improvements on PS images with suppressed artifacts.","1558-0571","","10.1109/LGRS.2019.2934493","National Research Foundation of Korea (NRF); Ministry of Science, ICT and Future Planning through the Basic Science Research Program(grant numbers:2017R1A2A2A05001476); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812763","Convolutional neural network (CNN);deep learning;pan colorization;pan-sharpening;satellite imagery;spectral-spatial structure;super-resolution (SR)","Training;Satellites;Correlation;Spatial resolution;Visualization;Convolutional neural networks","convolutional neural nets;geophysical image processing;image classification;image fusion;image resolution;learning (artificial intelligence);remote sensing","spectral-spatial structure loss;MS targets;PAN inputs;CNN structures;PS images;deep-learning-based pan-sharpening methods;high-quality pan-sharpened satellite images;convolutional neural network structures;spectral loss;network outputs;multispectral target images;HR panchromatic;moving objects;satellite image data sets;double-edge artifacts;strong edges;ghosting artifacts;loss function","","11","","32","IEEE","26 Aug 2019","","","IEEE","IEEE Journals"
"SSRI-Net: an iterative network for SAR super-resoltion imaging","Z. Wang; Y. Wei; Z. Ding","School of Information and Electronics, Beijing Institute of Technology, Beijing, People's Republic of China; School of Information and Electronics, Beijing Institute of Technology, Beijing, People's Republic of China; School of Information and Electronics, Beijing Institute of Technology, Beijing, People's Republic of China","International Conference on Radar Systems (RADAR 2022)","7 Feb 2023","2022","2022","","38","42","SAR imaging is a widely used technique to solve the remote sensing problem. However, the image resolution of traditional imaging methods is limited by signal bandwidth. In order to solve this problem, a new iterative network is proposed to obtain SAR super-resolution images, i.e., SAR Super-Resolution Imaging Network (SSRI-Net). The proposed SSRI-Net is designed to implement SAR super-resolution imaging. In SSRI-Net, the SAR echo is transformed to the SAR reconstruction image, while an additional decoder part does the opposite operation. The SSRI-Net is composed of the unfolded Alternating Direction Method of Multipliers (ADMM), and the decoder part is formulated into a linear mapping to achieve self-supervised imaging. Numerical simulation and real-data experiment in microwave anechoic chamber demonstrate the robustness and effectiveness of the proposed method.","","978-1-83953-777-6","10.1049/icp.2022.2288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10038885","","","anechoic chambers (electromagnetic);image reconstruction;image resolution;radar imaging;synthetic aperture radar","image resolution;iterative network;remote sensing problem;SAR echo;SAR imaging;SAR reconstruction image;SAR super-resoltion imaging;SAR super-resolution images;SAR Super-Resolution Imaging Network;self-supervised imaging;SSRI-Net;traditional imaging methods","","","","","","7 Feb 2023","","","IET","IET Conferences"
"3D Point Clouds Data Super Resolution-Aided LiDAR Odometry for Vehicular Positioning in Urban Canyons","J. Yue; W. Wen; J. Han; L. -T. Hsu","Nanjing University of Science and Technology, Nanjing, Jiangsu, China; Intelligent Positioning and Navigation Lab, The Hong Kong Polytechnic University, Hong Kong; Nanjing University of Science and Technology, Nanjing, Jiangsu, China; Intelligent Positioning and Navigation Lab, The Hong Kong Polytechnic University, Hong Kong","IEEE Transactions on Vehicular Technology","9 Jun 2021","2021","70","5","4098","4112","LiDAR odometry algorithms are extensively studied for vehicular positioning. However, achieving high-precision positioning using low-cost 16-channel LiDAR in urban canyons remains a challenging problem due to the limited point cloud density from low-cost LiDAR and excessive dynamic surrounding objects. To fill this gap, this paper proposes enriching sparse 3D point clouds to denser clouds via a novel deep learning-based superresolution (SR) algorithm before its utilization in 3D LiDAR odometry. We validate the effectiveness of the proposed method using the KITTI dataset and a challenging dataset collected in an urban canyon (with complex environmental structures and dynamic objects) of Hong Kong. We conclude that significantly denser point clouds are achieved with considerable accuracy. In addition, significantly improved performance of 3D LiDAR odometry is obtained in the evaluated dataset collected in an urban canyon of Hong Kong.","1939-9359","","10.1109/TVT.2021.3069212","Hong Kong PolyU internal Grant on the project ZVKZ; National Natural Science Foundation of China(grant numbers:61601225); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9388922","LiDAR;sparse point clouds;superresolution;convolutional neural network;NDT;LiDAR odometry;vehicular positioning","Three-dimensional displays;Laser radar;Image coding;Discrete cosine transforms;Superresolution;Sensors;Vehicle dynamics","distance measurement;image resolution;learning (artificial intelligence);optical radar;remote sensing by laser beam","3D point clouds data super resolution-aided LiDAR odometry;vehicular positioning;urban canyon;LiDAR odometry algorithms;high-precision positioning;16-channel LiDAR;point cloud density;low-cost LiDAR;excessive dynamic surrounding objects;sparse 3D point clouds;superresolution algorithm;3D LiDAR odometry;challenging dataset;dynamic objects;denser point clouds","","8","","57","IEEE","29 Mar 2021","","","IEEE","IEEE Journals"
"Research on Hardware-in-the-loop Simulation of Stepped Frequency Ultra-wideband Radar","S. Liu; Z. Gao; Y. Jia; Y. Liu; X. Zhang","Key Lab of Microwave Remote Sensing, National Space Science Center, Chinese Academy of Sciences, School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Key Lab of Microwave Remote Sensing, National Space Science Center, Chinese Academy of Sciences, School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Key Lab of Microwave Remote Sensing, National Space Science Center, Chinese Academy of Sciences, School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Key Lab of Microwave Remote Sensing, National Space Science Center, Chinese Academy of Sciences, School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Key Lab of Microwave Remote Sensing, National Space Science Center, Chinese Academy of Sciences, School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China","2021 IEEE 15th International Conference on Electronic Measurement & Instruments (ICEMI)","21 Jan 2022","2021","","","478","482","The stepped frequency signal is an important signal form to improve the range resolution of radar system, which effectively reduces the hardware requirements for ultra-wideband radar system. This article uses two signal generators, a spectrum analyzer and an oscilloscope to establish a stepped frequency ultra-wideband radar hardware-in-the-loop simulation system, and obtains super-resolution range signal through frequency domain wideband synthesis. Combining hardware-in-the-loop simulation with computer data processing, the experimental results show that the time resolution of the ultra-wideband signal synthesized by 35 28MHz sub-pulses is up to 1.06ns. The larger the bandwidth formed by the stepped frequency, the higher the range resolution, which verifies the effect of the stepped frequency on improving the range resolution.","","978-1-6654-4491-0","10.1109/ICEMI52946.2021.9679575","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679575","stepped frequency;wideband synthesis;hardware-in-the-loop simulation;Ultra-wideband","Frequency synthesizers;Hardware-in-the-loop simulation;Frequency-domain analysis;Superresolution;Oscilloscopes;Radar;Interference","","","","","","7","IEEE","21 Jan 2022","","","IEEE","IEEE Conferences"
"Multi Spectral Image Fusion with Deep Convolutional Network","S. Eghbalian; H. Ghassemian","Image processing and Information Analysis Laboratory Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran; Image processing and Information Analysis Laboratory Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran","2018 9th International Symposium on Telecommunications (IST)","7 Mar 2019","2018","","","173","177","A new multispectral image fusion method is proposed, based on deep convolutional neural networks. For pan-sharpening problem, the proposed method utilize the both super-resolution fusion methods and deep convolutional neural network. By the spatial information from the panchromatic (PAN) image the Multi-Spectral (MS) image is enhanced. In the other hand, the proposed method is independent from the number of MS bands because the spatial information directly estimated from PAN image. Experiments on images of the representative database are shown, proposed method can achieve better result competitive with the current well known methods.","","978-1-5386-8274-6","10.1109/ISTEL.2018.8661137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8661137","Multi-spectral;Image fusion;Pansharpening;Convolutional neural networks;Super-resolution","Image fusion;Remote sensing;Spatial resolution;Convolutional neural networks;Transforms;Principal component analysis","convolutional neural nets;image colour analysis;image enhancement;image fusion;image resolution","multispectral image fusion;superresolution fusion methods;multispectral image enhancement;panchromatic image;pan-sharpening problem;deep convolutional neural network;PAN image","","4","","27","IEEE","7 Mar 2019","","","IEEE","IEEE Conferences"
"A subpixel mapping method for urban land use by reducing shadow effects","M. Hao; G. Dou; X. Zhang; H. Lin; W. Huo","Jiangsu Key Laboratory of Resource and Environment Information Engineering, China University of Ming and Technology, Xuzhou, China; Jiangsu Key Laboratory of Resource and Environment Information Engineering, China University of Ming and Technology, Xuzhou, China; Jiangsu Key Laboratory of Resource and Environment Information Engineering, China University of Ming and Technology, Xuzhou, China; Jiangsu Key Laboratory of Resource and Environment Information Engineering, China University of Ming and Technology, Xuzhou, China; Jiangsu Key Laboratory of Resource and Environment Information Engineering, China University of Ming and Technology, Xuzhou, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2023","PP","99","1","18","Urban land use classification is significant for urban development planning. Considering complex environments of urban surface features, traditional semantic segmentation methods are difficult to solve the problems of mixed pixels and limited spatial resolution of images. The subpixel mapping technology is an effective method to solve the above problems in urban land use classification. However, traditional subpixel mapping methods are sensitive to mountain shadow, high-rise building shadow and impermeable surface heterogeneity, resulting in false classification. Therefore, we propose a subpixel mapping method that can reduce the shadow effect. This method uses a multi-index feature fusion strategy to optimize the abundance of the shadow errors in the abundance image, and uses a super-resolution reconstruction neural network model to reconstruct the optimized abundance image for the subpixel mapping of urban land use. Experiments were conducted on Sentinel-2 images obtained over Yuelu District of Changsha City, Hunan Province, China. The experimental results show that the method proposed in this paper can effectively overcome the influence of building shadows and mountain shadows in urban land cover classification and is superior to traditional SPSAM, RBF, SRSPM and other methods in the effect and accuracy of urban land use subpixel mapping.","2151-1535","","10.1109/JSTARS.2023.3243895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10042183","Subpixel mapping, shadow;multi-index feature fusion;abundance optimization;super-resolution reconstruction","Superresolution;Image reconstruction;Remote sensing;Spatial resolution;Urban areas;Gravity;Buildings","","","","","","","CCBY","10 Feb 2023","","","IEEE","IEEE Early Access Articles"
"Sparse reconstruction automaton for synthetic aperture radar tomography","N. Ge; X. X. Zhu","Remote Sensing Technology Institute (IMF), German Aerospace Center (DLR), Wessling, Germany; Helmholtz Young Investigators Group “SiPEO”, Technische Universität München, Munich, Germany","2015 European Radar Conference (EuRAD)","7 Dec 2015","2015","","","25","28","In this paper, we report our findings on automating the sparse reconstruction process in tomography with synthetic aperture radar. Two hyperparameter-free approaches are introduced into the framework of SL1MMER (Scale-down by L1 norm Minimization, Model selection, and Estimation Reconstruction). By means of numerical simulations, we evaluate their performance regarding mean and standard deviation of elevation estimates, as well as detection rate. Preliminary results with real data are also provided.","","978-2-8748-7041-5","10.1109/EuRAD.2015.7346228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7346228","SAR tomography;sparse reconstruction;super-resolution;SL1MMER;LASSO;SPICE;LIKES","Synthetic aperture radar;SPICE;Signal to noise ratio;Image resolution;Tomography;Estimation;Image reconstruction","synthetic aperture radar;tomography","sparse reconstruction automaton;synthetic aperture radar tomography;SL1MMER;numerical simulations;scale-down by L1 norm minimization model selection and estimation reconstruction","","","","8","","7 Dec 2015","","","IEEE","IEEE Conferences"
"MIMO Radar Super-Resolution Imaging Based on Reconstruction of the Measurement Matrix of Compressed Sensing","J. Ding; M. Wang; H. Kang; Z. Wang","National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","16 Dec 2021","2022","19","","1","5","This letter proposes a novel sparse recovery method of multiple-input and multiple-output (MIMO) radar compressed sensing (CS) imaging algorithms. This method leverages the prior structure of the measurement matrix to judge targets’ locations and to estimate the sparsity level in the grid roughly and finally inhabits the emergence of false targets in the imaging figure. Explicitly, the algorithm we propose is inspired by the orthogonal matching pursuit (OMP) algorithm. First, the measurement matrix can be divided into some submatrices by column. Then, we estimate which submatrices do not contain signal components by the algorithms we propose in this literature to achieve the reconstruction of the measurement matrix. Finally, we use the sparse Bayesian learning algorithm and the sparsity adaptive matching pursuit algorithm to recover the target location and scattering intensity. Experiments validate that the reconstruction error of the algorithm we propose is much lower than other sparse recovery algorithms, and targets in the imaging are more obvious than other algorithms.","1558-0571","","10.1109/LGRS.2021.3064555","National Natural Science Foundation of China(grant numbers:61771380,U1730109,CEMEE 2017K0202B); Teaching Reform Research Project(grant numbers:19xcj047); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385389","Compressed sensing (CS);greedy algorithm;multiple-input and multiple-output (MIMO) radar;sparse Bayesian learning (SBL);sparsity adaptive matching pursuit (SAMP)","Radar imaging;Imaging;Matching pursuit algorithms;MIMO radar;Signal processing algorithms;Receivers;MIMO communication","Bayes methods;compressed sensing;image reconstruction;image resolution;iterative methods;matrix algebra;MIMO radar;radar imaging;radar resolution;time-frequency analysis","orthogonal matching pursuit algorithm;sparse Bayesian learning algorithm;scattering intensity;sparse recovery algorithms;MIMO radar superresolution imaging;measurement matrix reconstruction;OMP algorithm;CS imaging algorithms;compressed sensing imaging algorithms;multiple-input and multiple-output radar","","5","","26","IEEE","24 Mar 2021","","","IEEE","IEEE Journals"
"ISAR resolution enhancement via compressive sensing: A comparison with state of the art SR techniques","A. Bacci; E. Giusti; D. Cataldo; S. Tomei; M. Martorella","CNIT Radar and Surveillance System (RaSS) National Laboratory, Pisa, Italy; CNIT Radar and Surveillance System (RaSS) National Laboratory, Pisa, Italy; CNIT Radar and Surveillance System (RaSS) National Laboratory, Pisa, Italy; CNIT Radar and Surveillance System (RaSS) National Laboratory, Pisa, Italy; CNIT Radar and Surveillance System (RaSS) National Laboratory, Pisa, Italy","2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing (CoSeRa)","17 Nov 2016","2016","","","227","231","The applicability of Compressing Sensing (CS) to Inverse Synthetic Aperture Radar has been widely treated in the last few years. In particular, CS based image reconstruction algorithms have been developed and their effectiveness has been proven when dealing with data that are incomplete in slow time and/or frequency domain. Resolution enhancement has been identified as a case in which CS can be exploited to obtain good results even compared with state of the art super resolution techniques. In this paper an exhaustive performance analysis is performed and a numerical comparison among CS and conventional super resolution techniques is provided. Some performance indicators are defined and results are provided using real dataset.","","978-1-5090-2920-4","10.1109/CoSeRa.2016.7745734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745734","","Signal resolution;Spatial resolution;Radar;Image reconstruction;Compressed sensing;Performance analysis","compressed sensing;frequency-domain analysis;image enhancement;image reconstruction;image resolution;radar imaging;radar resolution;synthetic aperture radar;time-domain analysis","ISAR resolution enhancement;compressive sensing;SR techniques;inverse synthetic aperture radar;CS based image reconstruction algorithms;frequency domain;time domain;super resolution techniques;performance analysis","","8","","22","IEEE","17 Nov 2016","","","IEEE","IEEE Conferences"
"Outline Reconstruction for Radar Forward-Looking Imaging Based on Total Variation Functional Deconvloution Methodxs","Y. Wu; Y. Zhang; Y. Zhang; Y. Huang; J. Yang","University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","7267","7270","It is great significant to achieve clear outline reconstruction for radar forward-looking imaging. In this paper, we apply the total variation (TV) function as the regularization term operator to obtain the forward-looking imaging with clear outline. Firstly, we establish the deconvolution model, by which the forward-looking super-resolution imaging problem is converted into inverse problem. Then, taking the TV function as regularization constraint term, we construct the objective function to solve the inverse problem. Finally, we obtain the minimum of the objective function, by which we can achieve radar forward-looking super-resolution imaging with clear outline. Simulations verify effectiveness of the proposed method in reconstructing the outline of targets.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8519584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519584","clear outline reconstruction;forward-looking imaging;total variation (TV);regularization;deconvolution","Radar imaging;Imaging;Image resolution;Signal resolution;Image reconstruction;Deconvolution","deconvolution;gradient methods;image reconstruction;image resolution;image restoration;inverse problems;iterative methods;radar imaging","total variation functional deconvloution method;super-resolution imaging problem;regularization term operator;clear outline reconstruction;radar forward-looking imaging;inverse problem;objective function;regularization constraint term;TV function","","2","","7","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Experimental Comparison of Multi-Sharpening Methods Applied To Sentinel-2 MSI and Sentinel-3 OLCI Images","A. Alboody; M. Puigt; G. Roussel; V. Vantrepotte; C. Jamet; T. K. Tran","Univ. Littoral Côte d’Opale, Longuenesse, France; Univ. Littoral Côte d’Opale, Longuenesse, France; Univ. Littoral Côte d’Opale, Longuenesse, France; Univ. Littoral Côte d’Opale, Wimereux, France; Univ. Littoral Côte d’Opale, Wimereux, France; Univ. Littoral Côte d’Opale, Wimereux, France","2021 11th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","19 Jul 2021","2021","","","1","5","Multi-spectral images are crucial to detect and to understand phenomena in marine observation. However, in coastal areas, these phenomena are complex and their analyze requires multi-spectral images with both a high spatial and spectral resolution. Unfortunately, no satellite is able to provide both at the same time. As a consequence, multi-sharpening techniques-a.k.a. fusion or super- resolution of multi-spectral and/or hyper-spectral images-were proposed and consist of combining information from at least two multi-spectral images with different spatial and spectral resolutions. The fused image then combines their best characteristics. Various methods-based on different strategies and tools-have been proposed to solve this problem. This article presents a comparative review of fusion methods applied to Sentinel-2 MSI (13 spectral bands with a spatial resolution ranging from 10 to 60 m) and Sentinel-3 OLCI (21 spectral bands with a spatial resolution of 300 m) images. Indeed, both satellites are extensively used in marine observation and, to the best of the authors' knowledge, the fusion of their data was partially investigated (and not in the way we aim to do in this paper). To that end, we provide both a quantitative analysis of the performance of some state-of-the-art methods on simulated images, and a qualitative analysis on real images.","2158-6276","978-1-6654-3601-4","10.1109/WHISPERS52202.2021.9484009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9484009","Image fusion;Remote sensing;Sentinel-2 MSI;Sentinel-3 OLCI;Simulations;Real data","Satellites;Statistical analysis;Conferences;Sea measurements;Distance measurement;Sensors;Spatial resolution","geophysical image processing;geophysical techniques;hyperspectral imaging;image fusion;image resolution;remote sensing","fusion methods;multi-sharpening techniques;multisharpening methods;multisharpening techniques;simulated images;Sentinel-3 OLCI;spectral bands;fused image;spectral resolutions;hyper-spectral images;spectral resolution;high spatial resolution;multispectral images;Sentinel-2 MSI","","2","","21","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"PCB Defect Detection based on Generative Adversarial Network","S. You","State Key Laboratory on Integrated Optoelectronics, Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China","2022 2nd International Conference on Consumer Electronics and Computer Engineering (ICCECE)","21 Feb 2022","2022","","","557","560","This paper proposes a PCB defect detection scheme based on the generative confrontation network, which can be applied to the automatic detection system of PCB vision inspection (vision inspection). We use the edge-enhanced super-resolution GAN (EESRGAN) applied in the field of remote sensing to enhance the PCB images and complete the super-resolution detection of the reconstructed picture. And use the PCB pictures of different preprocessing models in an end-to-end manner to compare the recognition of PCB defects after training. Experiments on the PCB data set show that the PCB pictures after sliding cutting are input into the result of EESRGAN training, which can relatively accurately identify the 6 types of defects contained in the data set. Our results show the effectiveness of our data processing methods.","","978-1-6654-0886-8","10.1109/ICCECE54139.2022.9712737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712737","PCB defect detection;EESRGAN;Generative Adversarial Network","Training;Fault diagnosis;Machine vision;Image edge detection;Superresolution;Inspection;Generative adversarial networks","automatic optical inspection;computer vision;electronic engineering computing;fault diagnosis;image enhancement;image reconstruction;image resolution;inspection;neural nets;printed circuits","generative adversarial network;PCB defect detection;generative confrontation network;automatic detection system;PCB vision inspection;edge-enhanced super-resolution GAN;remote sensing;PCB images;super-resolution detection;reconstructed picture;PCB pictures;preprocessing models;PCB data;EESRGAN training","","2","","12","IEEE","21 Feb 2022","","","IEEE","IEEE Conferences"
"Low-Rank Tensor Decomposition With Smooth and Sparse Regularization for Hyperspectral and Multispectral Data Fusion","F. Ma; F. Yang; Y. Wang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electrical and Control Engineering, Liaoning Technical University, Huludao, China; School of Electronic and Information Engineering, Liaoning Technical University, Huludao, China","IEEE Access","21 Jul 2020","2020","8","","129842","129856","The fusion of hyperspectral and multispectral images is an effective way to obtain hyperspectral super-resolution images with high spatial resolution. A hyperspectral image is a datacube containing two spatial dimensions and a spectral dimension. The fusion methods based on non-negative matrix factorization need to reshape the three-dimensional data in matrix form, which will result in the loss of data structure information. Owing to the non-uniqueness of tensor rank and noise inference, there is a lot of redundant information in the spatial and spectral subspaces of tensor decomposition. To address the above problems, this article incorporates smooth and sparse regularization into low-rank tensor decomposition to reformulate a fusion method, in which the logarithmic sum function is adopted to eliminate the effect of redundant information and shadows in both spatial and spectral domains. Moreover, the total-variation-based regularizer is employed to vertically smooth the spectral factor matrix to suppress the noise. Then, the alternating direction multiplier method, as well as the conjugate gradient approach, is utilized to design a set of efficient algorithms by complexity reduction. The experimental results demonstrate that the proposed method can yield better performance than the state-of-the-art benchmark algorithms in most cases, which also verifies the effectiveness of incorporated regularizers in low signal-to-noise ratio environments for hyperspectral super-resolution images.","2169-3536","","10.1109/ACCESS.2020.3009263","Scientific Research Project of Colleges from the Liaoning Department of Education, China(grant numbers:LJ2017QL014,LJ2019QL006,LJ2019JL022); National Basic Research Program of China (973 Program)(grant numbers:2018YFB1403303); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139926","Remote sensing;image fusion;low-rank tensor decomposition;total variation;super-resolution","Tensile stress;Spatial resolution;Hyperspectral imaging;Matrix decomposition;Signal resolution","data structures;hyperspectral imaging;image fusion;image resolution;matrix decomposition;tensors","smooth regularization;sparse regularization;low-rank tensor decomposition;fusion method;redundant information;spatial domains;spectral domains;total-variation-based regularizer;spectral factor matrix;alternating direction multiplier method;regularizers;low signal-to-noise ratio environments;super-resolution images;hyperspectral data fusion;multispectral data fusion;hyperspectral images;multispectral images;high spatial resolution;hyperspectral image;spatial dimensions;spectral dimension;nonnegative matrix factorization need;three-dimensional data;matrix form;data structure information;nonuniqueness;tensor rank;spatial subspaces;spectral subspaces","","5","","56","CCBY","14 Jul 2020","","","IEEE","IEEE Journals"
"A map-based approach to resolution enhancement of hyperspectral images","H. Irmak; G. B. Akar; S. E. Yüksel","Aselsan Inc., Turkey; Dept. of Electrical and Electronics Eng., Middle East Technical University, Turkey; Dept. of Electrical and Electronics Eng., Hacettepe University, Turkey","2015 7th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","23 Oct 2017","2015","","","1","4","Hyperspectral imaging is widely used in many fields such as geology, medicine, meteorology, and so on. Despite the high spectral resolution, the spatial resolution of the hyperspectral sensors is severely limited. In this paper, we propose a novel maximum a posteriori (MAP)-based approach based on the joint superresolution of the abundance maps, to enhance the resolution of hyperspectral images. In the proposed approach, first, the endmembers and their abundance maps are estimated using Vertex Component Analysis (VCA) and Fully Constrained Least Squares (FCLS), respectively. Second, a high resolution (HR) abundance map is reconstructed for each low resolution (LR) abundance map using a MAP-based approach. In the MAP-formulation data, smoothness and edge preservation constraints are extended to include a unity constraint term specific to abundances. Finally, HR hyperspectral images are reconstructed using the HR abundance maps. The proposed algorithm is tested on both synthetic images and real image sequences. The experimental results and comparative analysis verify the effectiveness of the proposed algorithm.","2158-6276","978-1-4673-9015-6","10.1109/WHISPERS.2015.8075492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8075492","Hyperspectral;Super-resolution;Spectral Unmixing;Markov Random Field;Graph Cut Energy Minimization","Hyperspectral imaging;Spatial resolution;Signal resolution;Energy resolution;Algorithm design and analysis","hyperspectral imaging;image enhancement;image reconstruction;image resolution;least squares approximations;maximum likelihood estimation","maximum a posteriori;endmembers;vertex component analysis;fully constrained least squares;high resolution abundance map;low resolution abundance map;edge preservation constraints;HR hyperspectral image reconstruction;image sequences;MAP-based approach;hyperspectral image resolution enhancement;LR abundance map","","2","","15","IEEE","23 Oct 2017","","","IEEE","IEEE Conferences"
"Hyperspectral pansharpening based on unmixing techniques","L. Loncan; J. Chanussot; S. Fabre; X. Briottet","ONERA, GIPSA-LAB; ONERA, GIPSA-LAB; ONERA, GIPSA-LAB; ONERA, GIPSA-LAB","2015 7th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","23 Oct 2017","2015","","","1","4","Pansharpening first aims at fusing a panchromatic image with a multispectral image to generate an image with the high spatial resolution of the former and the spectral resolution of the latter. In the last decade many pansharpening algorithms have been presented in the literature using multispectral data. With the increasing availability of hyperspectral systems these methods are now extending to hyperspectral images. But the problem of the mixed pixel is generally ignored by the existing methods since their goal is to preserve the spectral information and add spatial information. In this work we compare different approaches to deal with mixed pixels as a pre-processing step before doing the fusion. This should improved the result by adding missing spectral information available in the reference image because of the mixed pixel.","2158-6276","978-1-4673-9015-6","10.1109/WHISPERS.2015.8075419","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8075419","Pansharpening;Hyperspectral;Panchromatique;Unmixing;Super-resolution","Spatial resolution;Hyperspectral imaging;Roads;Automobiles;Signal resolution","hyperspectral imaging;image colour analysis;image enhancement;image fusion;image resolution;spectral analysis","hyperspectral pansharpening;unmixing techniques;multispectral image;reference image;image resolution;panchromatic image fusion;panchromatique","","1","","6","IEEE","23 Oct 2017","","","IEEE","IEEE Conferences"
"An Efficient Anti-Interference Imaging Technology for Marine Radar","D. Mao; Y. Zhang; Y. Zhang; J. Pei; Y. Huang; J. Yang","School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","15 Dec 2021","2022","60","","1","13","Marine radar plays a significant role in ship navigation. However, when contending with interference among cosailing navigation radars, the echo data may be unintentionally corrupted, and it becomes challenging to obtain high-quality imagery using current radar imaging methods. To overcome this problem, an efficient anti-interference imaging framework is presented in this article based on the theory of nonuniform sampling. First, a beam-recursive anti-interference method based on the signal-to-interference-plus-noise ratio (SINR) estimation is proposed to compensate for the shortcoming of the traditional interference rejection method. Second, a nonuniform sampling model is established to well model the echo data with missing samples, which facilitates reconstructing the marine radar imagery from the missing echo data. Finally, a fast super-resolution method based on the dimension-reduction iterative adaptive approach (DRIAA) is proposed to reconstruct the distribution of sea-surface targets at a much lower computational complexity. Simulated and experimental results demonstrate that our anti-interference imaging framework can provide radar imagery with higher quality and lower computational complexity than the existing radar imaging methods in the presence of unintentional interference.","1558-0644","","10.1109/TGRS.2021.3068787","National Natural Science Foundation of China(grant numbers:61901092,61901090,61671117); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394593","Anti-interference;dimension-reduction iterative adaptive approach (DRIAA);marine radar;super-resolution imaging","Radar imaging;Radar;Interference;Radar antennas;Imaging;Superresolution;Signal to noise ratio","","","","1","","50","IEEE","2 Apr 2021","","","IEEE","IEEE Journals"
"Target Fast Reconstruction of Real Aperture Radar Using Data Extrapolation-Based Parallel Iterative Adaptive Approach","D. Mao; Y. Zhang; Y. Zhang; W. Huo; J. Pei; Y. Huang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","11 Feb 2021","2021","14","","2258","2269","Real aperture radar (RAR) usually sweeps a wide sector to continuously observe the scenario of interest. Because its angular resolution is limited by the size of the antenna aperture, target reconstruction methods are widely applied to obtain super-resolution radar images. However, the wide-sector processing mode suffers from high operational complexity because of the high-dimensional matrix inversion. Even worse, for the targets located at the scene edge, its echo data are received less than half beamwidth. The incomplete echo data will lead to the deformation of the reconstructed targets by existing reconstruction methods. To overcome the two problems, a data extrapolation-based parallel iterative adaptive approach is proposed to fast reconstruct the targets in the whole sector without the distortion at the scene edge. First, the echo model of RAR is repaired to remedy the model error. Then, based on the correlation of the echo data within one beamwidth, an autoregressive model is adopted to extrapolate the data of the missing half beamwidth. Finally, a parallel iterative adaptive approach method is proposed to efficiently recover the targets by exploiting the regular characteristics of the repaired steering matrix. Simulations and experimental data are applied to verify the proposed method.","2151-1535","","10.1109/JSTARS.2021.3054046","National Natural Science Foundation of China(grant numbers:61901092,61901090,61671117); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9335023","Parallel iterative adaptive approach (PIAA);real aperture radar (RAR);scene edge target reconstruction;super-resolution imaging","Data models;Radar;Radar antennas;Radar imaging;Adaptation models;Iterative methods;Image reconstruction","autoregressive processes;extrapolation;image reconstruction;image resolution;iterative methods;matrix inversion;radar imaging;radar resolution","data extrapolation-based parallel iterative adaptive approach;real aperture radar;antenna aperture;target reconstruction methods;super-resolution radar images;high-dimensional matrix inversion;reconstructed targets;echo model;parallel iterative adaptive approach method;target fast reconstruction;wide-sector processing mode;autoregressive model","","8","","42","CCBY","25 Jan 2021","","","IEEE","IEEE Journals"
"Artifact-free image reconstruction for satellite imagery","M. Ishii; T. Shibata; A. Sato","Information and Media Processing Laboratories, NEC Corporation, Nakahara-ku, Kawasaki, Kanagawa, Japan; Information and Media Processing Laboratories, NEC Corporation, Nakahara-ku, Kawasaki, Kanagawa, Japan; Information and Media Processing Laboratories, NEC Corporation, Nakahara-ku, Kawasaki, Kanagawa, Japan","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","2537","2540","This paper presents a novel image-reconstruction (IR) method for satellite imagery. To reduce unnatural artifacts, which often appear in existing IR methods, we propose a novel scheme to accurately estimate PSF and a novel regularization for IR. In the PSF estimation, hyper-parameters are estimated to reduce artifacts while improving sharpness based on our new criterion, which employs a residual of sigmoidal-function fitting to a strong edge on the reconstructed image as measurement of the amount of the artifacts. After the PSF estimation, we conduct IR based on the estimated PSF. In IR process, we employ a novel regularization that induces gradients of the reconstructed image to be close to those of its guide image. Since the guide image contains only the dominant structure of the input image without artifacts, the regularization leads to fewer artifacts. In addition, we employ a learning-based method for setting the spatially adaptive strength of the regularization effectively. Experimental results on real satellite imageries show that our method works better than other state-of-the-art IR methods.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729655","Image reconstruction;satellite imagery;super-resolution","Image reconstruction;Image edge detection;Satellites;Estimation;Erbium;Learning systems;Image sensors","artificial satellites;geophysical image processing;image reconstruction","artifact free image reconstruction;satellite imagery;unnatural artifacts reduction;hyperparameters;image sharpness;sigmoidal function fitting;PSF estimation","","2","","8","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Forward Looking Imaging of Airborne Multichannel Radar based on Modified IAA","R. Chen; W. Li; Y. Zhang; J. Yang","University of Electronic Science and Technology of China, Chengdu, P. R. China; University of Electronic Science and Technology of China, Chengdu, P. R. China; University of Electronic Science and Technology of China, Chengdu, P. R. China; University of Electronic Science and Technology of China, Chengdu, P. R. China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2987","2990","Receiving signals sequentially through multiple channels in azimuth, radar has the potential of forward looking high-resolution imaging. However, due to the limitation of platform size, its azimuth resolution is poor. In this paper, by considering the effect of platform motion and geometric distortion, a modified iterative adaptive algorithm(IAA) method is proposed to realize multichannel radar forward-looking superresolution imaging. Simulation results are illustrated to verify the effectiveness of the method.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884918","National Natural Science Foundation of China(grant numbers:62171107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884918","Multichannel radar;forward-looking imaging;IAA algorithm;super-resolution","Azimuth;Simulation;Superresolution;Airborne radar;Imaging;High-resolution imaging;Radar imaging","airborne radar;Doppler effect;filtering theory;image reconstruction;image resolution;iterative methods;radar imaging","modified IAA;receiving signals;multiple channels;high-resolution imaging;platform size;azimuth resolution;platform motion;geometric distortion;radar forward-looking;superresolution imaging;airborne multichannel radar","","","","9","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"A hyperspectral spatial-spectral enhancement algorithm","C. Yi; Y. Zhao; J. Yang","School of Automation, Northwestern Polytechnical University, Xi'an, P.R. China; School of Automation, Northwestern Polytechnical University, Xi'an, P.R. China; School of Automation, Northwestern Polytechnical University, Xi'an, P.R. China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","7228","7231","Low spatial and spectral resolution hyperspectral image will always degrade the performance of the subsequent applications, such as classification and object detection. The desired hyperspectral image is assumed to be reconstructed based on both high spatial and spectral features, which are always represented using endmembers and their abundances. In this paper, we propose a hyperspectral spatial and spectral resolution enhancement algorithm based on spectral unmixing and spatial constraints to simultaneously obtain high spatial-spectral resolution result. An intermediate high spatial but low spectral resolution HSI is introduced to establish mapping scheme of abundances and endmembers between low resolution input and desired high spatial-spectral resolution result. Experiments on the Sandigo dataset have illustrated that the proposed method is comparable or superior to other state-of-art methods.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730885","Hyperspectral image;unmixing;spatial-spectral super-resolution","Spatial resolution;Hyperspectral imaging;Image reconstruction;Dictionaries;Degradation","geophysical techniques","hyperspectral spatial-spectral enhancement algorithm;spatial-spectral resolution result;spectral resolution HSI;Sandigo dataset","","","","17","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Efficient Nonconvex Regularization for Azimuth Resolution Enhancement of Real Beam Scanning Radar","L. Chen; X. Jiang; P. Huang; Y. Zhang; X. Liu","Department of Electronic Engineering, Shanghai Jiao Tong University, China; Department of Electronic Engineering, Shanghai Jiao Tong University, China; Department of Electronic Engineering, Shanghai Jiao Tong University, China; Department of Electronic Engineering, Shanghai Jiao Tong University, China; Department of Electronic Engineering, Shanghai Jiao Tong University, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","692","695","Azimuth superresolution for real beam scanning radar aims to recover the high-resolution image from low-resolution echo. Among superresolution techniques, regularization-based methods are widely used, but most existing methods lead to the blurring of scattering targets and thus are difficult to distinguish between close targets. In this paper, we propose to employ the nonconvex ℓp-regularization with 0 <; p <; 1 to achieve the sparsity-driven superresolution, which further enhances the azimuth resolution. Furthermore, the resultant optimization problem is efficiently solved using an unified framework via incorporating different proximity operators. Simulation results validate the accuracy and efficiency of the proposed algorithm.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898637","scanning radar imaging;azimuth super-resolution;ℓp-regularization","Azimuth;Radar;Scattering;Radar antennas;Optimization","concave programming;image enhancement;image resolution;image restoration;radar imaging","high-resolution imaging;low-resolution echo;sparsity-driven superresolution;azimuth resolution enhancement;real beam scanning radar;azimuth superresolution enhancement techniques;scattering target blurring;efficient nonconvex ℓp regularization-based methods;optimization problem","","","","7","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Sparse Superresolution Imaging for Airborne Forward-Looking Radar with Multiple Frames Space","H. Chen; W. Gao; P. Wang; J. Yu; Y. Li","Beijing Institute of Radio Measurement, Beijing, China; Beijing Institute of Radio Measurement, Beijing, China; Beijing Institute of Radio Measurement, Beijing, China; Beijing Institute of Radio Measurement, Beijing, China; National Laboratory of Radar Signal Processing, Xidian University, Xi'an, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1816","1819","Airborne forward-looking radar (AFLR) imaging has attracted a lot of attention in fields of Earth observation, independent of weather and daytime. However, the forward-looking imaging quality is not very high. To solve this problem, a sparse superresolution imaging algorithm for AFLR with multiple frames space is proposed. Firstly, the echo model for AFLR is introduced. Then, a multiple frame space is constructed to better describe the distribution of noise and targets of the imaging scene. Finally, the forward-looking imaging problem is constructed as the optimization problem, and the Bayesian framework is used to perform the superresolution imaging. Simulation results and real data results are given to verify its effectiveness.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884278","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884278","Airborne forward-looking radar;forward-looking imaging;super-resolution","Meteorological radar;Spaceborne radar;Simulation;Superresolution;Airborne radar;Noise reduction;Imaging","airborne radar;Bayes methods;image resolution;object detection;radar imaging;synthetic aperture radar","imaging scene;imaging problem;airborne forward-looking radar;multiple frames space;imaging quality;sparse superresolution imaging algorithm;AFLR;multiple frame space","","","","14","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Nonlocal Coupled Tensor CP Decomposition for Hyperspectral and Multispectral Image Fusion","Y. Xu; Z. Wu; J. Chanussot; P. Comon; Z. Wei","Grenoble Images Speech Signal and Control Laboratory (GIPSA-lab), CNRS, Grenoble Institute of Technology (Grenoble INP), Université Grenoble Alpes, Grenoble, France; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Grenoble Images Speech Signal and Control Laboratory (GIPSA-lab), CNRS, Grenoble Institute of Technology (Grenoble INP), Université Grenoble Alpes, Grenoble, France; Grenoble Images Speech Signal and Control Laboratory (GIPSA-lab), CNRS, Université Grenoble Alpes, Grenoble, France; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Transactions on Geoscience and Remote Sensing","30 Dec 2019","2020","58","1","348","362","Hyperspectral (HS) super-resolution, which aims at enhancing the spatial resolution of hyperspectral images (HSIs), has recently attracted considerable attention. A common way of HS super-resolution is to fuse the HSI with a higher spatial-resolution multispectral image (MSI). Various approaches have been proposed to solve this problem by establishing the degradation model of low spatial-resolution HSIs and MSIs based on matrix factorization methods, e.g., unmixing and sparse representation. However, this category of approaches cannot well construct the relationship between the high-spatial-resolution (HR) HSI and MSI. In fact, since the HSI and the MSI capture the same scene, these two image sources must have common factors. In this paper, a nonlocal tensor decomposition model for hyperspectral and multispectral image fusion (HSI-MSI fusion) is proposed. First, the nonlocal similar patch tensors of the HSI are constructed according to the MSI for the purpose of calculating the smooth order of all the patches for clustering. Then, the relationship between the HR HSI and the MSI is explored through coupled tensor canonical polyadic (CP) decomposition. The fundamental idea of the proposed model is that the factor matrices in the CP decomposition of the HR HSI's nonlocal tensor can be shared with the matrices factorized by the MSI's nonlocal tensor. Alternating direction method of multipliers is used to solve the proposed model. Through this method, the spatial structure of the MSI can be successfully transferred to the HSI. Experimental results on three synthetic data sets and one real data set suggest that the proposed method substantially outperforms the existing state-of-the-art HSI-MSI fusion methods.","1558-0644","","10.1109/TGRS.2019.2936486","National Natural Science Foundation of China(grant numbers:61701238,61772274,61471199,61976117,91538108,11431015,61501241,61671243,61802190); Natural Science Foundation of Jiangsu Province(grant numbers:BK20170858,BK20180018); Fundamental Research Funds for the Central Universities(grant numbers:30919011234,30917015104,30919011103); Jiangsu Provincial Social Developing Project(grant numbers:BE2018727); China Postdoctoral Science Foundation(grant numbers:2017M611814,2015M570450,2018T110502); Jiangsu Province Postdoctoral Science Foundation(grant numbers:1701148B); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8835149","Coupled canonical polyadic (CP) decomposition;data fusion;hyperspectral images (HSIs);multispectral images (MSIs);nonlocal tensor","Spatial resolution;Hyperspectral imaging;Sparse matrices;Matrix decomposition","hyperspectral imaging;image colour analysis;image fusion;image representation;image resolution;matrix decomposition;optimisation;tensors","nonlocal coupled tensor CP decomposition;hyperspectral super-resolution;spatial resolution;hyperspectral image fusion;multispectral image fusion;HSI-MSI fusion methods;matrix factorization;high spatial resolution;canonical polyadic decomposition;alternating direction method of multipliers;ADMM optimization;false-color images","","58","","67","IEEE","12 Sep 2019","","","IEEE","IEEE Journals"
"DCSN: Deep Compressed Sensing Network for Efficient Hyperspectral Data Transmission of Miniaturized Satellite","C. -C. Hsu; C. -H. Lin; C. -H. Kao; Y. -C. Lin","Department of Management Information Systems, National Pingtung University of Science and Technology, Pingtung, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan","IEEE Transactions on Geoscience and Remote Sensing","27 Aug 2021","2021","59","9","7773","7789","Requirements of compressed sensing techniques targeted at miniaturized hyperspectral satellite applications include lightweight onboard hardware, high-speed sensing, low sampling rate for compressing the massive volume of typical hyperspectral data, and noise robustness for reliable data transmission to the ground station. We achieve all these aims via deep learning, and neural networks resulted from which can be implemented on-chip, thereby allowing light hardware implementation. Our neural networks were trained from small-scaled data, but, even so, the resulting encoder achieves a very low sampling rate and very high speed. Unlike typical network training, the input-output pairs are not square but stripe-like images, partly because compressed acquisition does not allow performing compression after obtaining complete data cube and partly because stripe-like acquisition well matches the popular pushbroom hyperspectral sensing schemes. Even with such hard restriction caused by nontraditional training, the resulting decoder still reconstructs the image with high accuracy. To match the requirement of pushbroom sensing, a lightweight encoder is proposed to compress the stripe-like images immediately. Meanwhile, multiscale feature fusion block (MFB) and aggregation (MFA) modules are proposed to form our decoder for enhancing the feature representation of the compressed acquisitions. Furthermore, we achieve joint spatial/spectral super-resolution (SR) progressively, ensuring accurate hyperspectral reconstruction via a low-rank-driven decoder. The encoder and decoder are trained in an end-to-end manner, where noise robustness is forced during the training stage. Comprehensive experiments demonstrate the superiority of the proposed hyperspectral compressed sensing method, as well as its one-shot transfer learning (OTL)-based extension, both quantitatively and qualitatively.","1558-0644","","10.1109/TGRS.2020.3034414","Ministry of Science and Technology (MOST), Taiwan(grant numbers:MOST 109-2218-E-006-032,109-2634-F-007-013,107-2218-E-020-002-MY3); Young Scholar Fellowship Program (Einstein Program) of Ministry of Science and Technology, Taiwan(grant numbers:MOST 109-2636-E-006-022); Higher Education Sprout Project of Ministry of Education (MOE) to the Headquarters of University Advancement at National Cheng Kung University (NCKU); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257426","Compressed sensing;deep learning (DL);hyperspectral image;miniaturized satellite;multiscale feature fusion","Training;Image coding;Neural networks;Decoding;Sensors;Noise robustness;Spatial resolution","compressed sensing;decoding;deep learning (artificial intelligence);geophysical image processing;hyperspectral imaging;image reconstruction;remote sensing","deep compressed sensing network;efficient hyperspectral data transmission;compressed sensing techniques;miniaturized hyperspectral satellite applications;lightweight onboard hardware;high-speed sensing;low sampling rate;deep learning;neural networks;light hardware implementation;small-scaled data;input-output pairs;compressed acquisition;complete data cube;nontraditional training;hyperspectral reconstruction;low-rank-driven decoder;hyperspectral compressed sensing method;pushbroom hyperspectral sensing schemes","","9","","44","IEEE","12 Nov 2020","","","IEEE","IEEE Journals"
"Deep speckle noise filtering","S. Foucher; M. Beaulieu; M. Dahmane; F. Cavayas","Vision and Imaging Team, Computer Research Institute of Montreal; Vision and Imaging Team, Computer Research Institute of Montreal; Vision and Imaging Team, Computer Research Institute of Montreal; Université de Montréal, Montreal, Canada","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","5311","5314","Speckle removal from single-channel and multi-dimensional SAR remains a difficult problem. In this paper, we are investigating the use of a Convolutional Neural Network (CNN), previously applied to the Super-Resolution problem, for speckle removal. Because speckle noise statistics is signal dependent, we are training the neural network on the residual image formed by the ratio of the observed intensity to the local mean. Preliminary results on SAR and PolSAR show the potential of CNN to retrieve lost image details.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8128203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128203","speckle;polarimetry;deep learning","Speckle;Image resolution;Training;Synthetic aperture radar;Computer architecture;Convolution","filtering theory;image denoising;image resolution;neural nets;radar imaging;radar polarimetry;speckle;synthetic aperture radar","deep speckle noise filtering;speckle removal;Convolutional Neural Network;CNN;Super-Resolution problem;speckle noise statistics","","6","","11","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Coastal flood monitoring based on AMSR-E data","W. Zheng; D. Sun; S. Li","China Meteorological Administration, National Satellite Meteorological Center; Department of Geography and Geoinformation Science, George Mason University; Department of Geography and Geoinformation Science, George Mason University","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","4399","4401","The coastal floods induced by hurricane storm surge are frequent, costly, and deadly hazards. Accurately and quickly estimating the spatial extent of floods is highly important for relief and rescue operations. In this study, we present an approach to estimate the extent of large-scale coastal floods using AMSR-E data through mixed-pixel linear decomposition. Furthermore, based on the water fraction, using the physical characteristics of water inundation that always proceed from the lowest to the highest elevation points in a basin, the flood map derived from the coarse-resolution AMSR-E measurements was extrapolated to a higher spatial resolution of 100 meters using DEM data. The comparison result with 250-m MODIS image showed the effectiveness of the super-resolution mapping method.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730146","Flood;WSF;AMSR-E;Hurricane","Floods;Hurricanes;Land surface;Sea surface;Ocean temperature;Surface topography;Spatial resolution","digital elevation models;floods;storms","coastal flood monitoring;AMSR-E data;hurricane storm surge;large-scale coastal flood;mixed-pixel linear decomposition;water fraction;water inundation;flood map;coarse-resolution AMSR-E measurements;DEM data;MODIS image;super-resolution mapping method","","5","","10","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Weakly Supervised Semantic Segmentation in the 2020 IEEE GRSS Data Fusion Contest","C. Robinson; K. Malkin; L. Hu; B. Dilkina; N. Jojic",Georgia Institute of Technology; Yale University; University of Southern California; University of Southern California; Microsoft Research,"IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","27 Sep 2021","2020","","","7046","7049","We propose an iterative clustering-based label super-resolution approach and epitome-based approach to weakly supervised semantic segmentation, as well as a deep learning-based postprocessing step for land cover segmentation. An ensemble of the iterative clustering and epitome approaches with the proposed postprocessing step results in a top validation leaderboard average accuracy of 70.43%. A similar ensemble, that also considers class accuracy feedback from the leaderboard, achieves a top Track 1 leaderboard average accuracy of 57.49%.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9547211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9547211","land cover mapping;weakly supervised semantic segmentation;deep learning","Image segmentation;Smoothing methods;Semantics;Superresolution;Clustering algorithms;Data integration;Training data","geophysical image processing;image classification;image fusion;image resolution;image segmentation;iterative methods;learning (artificial intelligence);sensor fusion;terrain mapping","weakly supervised semantic segmentation;2020 IEEE GRSS data fusion;iterative clustering-based label super-resolution approach;epitome-based approach;deep learning-based;land cover segmentation;epitome approaches;postprocessing step results;validation leaderboard average accuracy","","4","","7","IEEE","27 Sep 2021","","","IEEE","IEEE Conferences"
"Sparse non-ambiguous imaging of SAR moving targets","G. Xu; W. Hong; Y. Yu","State Key Laboratory of Millimeter Waves, Southeast University, Nanjing, P.R. China; State Key Laboratory of Millimeter Waves, Southeast University, Nanjing, P.R. China; State Key Laboratory of Millimeter Waves, Southeast University, Nanjing, P.R. China","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","2373","2376","Recently, sparse radar imaging has drawn more and more attentions, which has the superiority of feature enhancement, super-resolution and so on. In this paper, we focus on sparse moving target imaging (MTIm) using a SAR sensor from sparse aperture (SA) data. For maneuvering targets, their strong motion tends to introduce migration through range cell (MTRC), which increases the difficulty of SA imaging. In this paper, a novel algorithm of moving target imaging is proposed to deal with both the MTRC and SA. In the scheme, a scaled Fourier dictionary is employed to represent the MTRC. A hierarchical model of statistics is used to encode the sparsity of image. Then, SA imaging is treated as a problem of sparse Bayesian learning, which is solved by expectation maximization (EM) method. The scaled Fourier dictionary is modified to resolve the velocity ambiguity. Finally, experimental analysis is performed to confirm the effectiveness of the proposed method.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127468","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127468","Synthetic aperture radar (SAR);moving target imaging (MTIm);maneuvering targets;sparse Bayesian learning","Imaging;Synthetic aperture radar;Radar imaging;Azimuth;Signal processing algorithms;Apertures","expectation-maximisation algorithm;image enhancement;image motion analysis;image resolution;radar imaging;radar resolution;synthetic aperture radar","sparse nonambiguous imaging;SAR moving targets;sparse radar imaging;feature enhancement;super-resolution;sparse moving target imaging;SAR sensor;sparse aperture data;maneuvering targets;strong motion;MTRC;SA imaging;scaled Fourier dictionary;sparse Bayesian learning","","2","","19","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Stochastic Radiation Radar 3-D High Resolution Imaging Technique","D. Mao; Y. Zhang; Y. Zhang; C. Yu; X. Yang; J. Yang","University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan; University of Electronic Science and Technology of China, Chengdu, Sichuan","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3673","3676","Scene surveillance radar, which generates radar stochastic radiation field with time and space to obtain more observation information, plays a significant role in disaster monitoring and environmental security. To explore its three-dimensional (3-D) imaging capabilities, in this paper, we propose an echo rearrangement super-resolution imaging method to achieve 3D high resolution imaging for SRR. Because the echo of SRR is uncorrelated along sampling time, we adjust the conventional intrapulse frequency hopping to interpulse frequency hopping. In this way, the proposed method can improve the imaging resolution by echo rearrangement utilizing the noncorrelation with time of stochastic radiation field. The 3-D image provides the scene reflectivity estimation along polar coordinate system including pitch, azimuth and space distance. Simulation results are given to illustrate the performance of the proposed method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898816","Stochastic radiation radar;3-D imaging;resolution improvement","Imaging;Radar imaging;Image resolution;Time-frequency analysis;Stochastic processes;Antenna arrays","echo;frequency hop communication;image resolution;image sampling;radar imaging;radar resolution;search radar;stochastic processes","three-dimensional imaging capabilities;echo rearrangement super-resolution imaging method;SRR;sampling time;interpulse frequency hopping;imaging resolution;scene surveillance radar;stochastic radiation radar 3D high resolution imaging technique;radar stochastic radiation field generation;environmental security;disaster monitoring;intrapulse frequency hopping;scene reflectivity estimation;polar coordinate system;space distance","","1","","8","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Non-Linear least squares algorithm for detection of simple and double persistent scatterers","C. Dănişor; G. Fornaro; M. Datcu","University Politehnica of Bucharest; National Research Council, Italy; University Politehnica of Bucharest","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","6020","6023","Synthetic Aperture Radar (SAR) Tomography is a multi-temporal technique which can reconstruct the 3D profile of a scene. One of its main features consists in the ability to detect the presence of multiple Persistent Scatterers (PS) within the same resolution cell. This paper aims to investigate the super-resolution capabilities of SAR Tomography, by detecting targets situated at a distance which is close to Rayleigh resolution. Elevation positions of scatterers are determined with Capon estimation, which is characterized by higher side-lobs reduction. An adapted form of multi-looking is proposed for extraction of targets contribution from reconstructed reflectivity functions and for estimation of reflectivity power textures. An algorithm for detection of dominant and secondary PSs will be conducted based on the derived reflectivity estimates, trying to preserve the advantages of Capon filtering used for reflectivity reconstruction.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8128382","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128382","Non-linear Least Squares;SAR Tomography;Persistent Scatterers;Capon filtering;Multi-looking;TerraSAR-X","Synthetic aperture radar;Reflectivity;Filtering;Covariance matrices;Tomography;Maximum likelihood estimation","geophysical techniques;radar imaging;synthetic aperture radar;tomography","SAR Tomography;Rayleigh resolution;Capon estimation;multilooking;reconstructed reflectivity functions;reflectivity power textures;derived reflectivity estimates;reflectivity reconstruction;nonLinear least squares algorithm;Synthetic Aperture Radar Tomography;multitemporal technique;multiple Persistent Scatterers;super-resolution capabilities","","","","9","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Producing fine resolution thematic map using interpolation then classification","P. Wang; L. Wang","College of Information and Communications Engineering, Harbin Engineering University, Harbin, China; College of Information and Communications Engineering, Harbin Engineering University, Harbin, China","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","4778","4781","In this paper, a framework based on fine resolution thematic map, namely, interpolation then classification (ITC) is proposed. Firstly interpolation algorithm is applied in the original coarse hyperspectral imagery to derive a high-resolution imagery with generous prior information. Then fine resolution thematic map is derived from the high-resolution imagery by the available classification methods. Experiments on two real hyperspectral imagery showed that the proposed method produced higher accuracy result than interpolation-based soft-then-hard super-resolution mapping (I-STHSRM).","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8128070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128070","Hyperspectral imagery;interpolation;classification;STHSRM","Interpolation;Spatial resolution;Hyperspectral imaging;Classification algorithms;Mathematical model","geophysical image processing;image classification;image resolution;interpolation;terrain mapping","fine resolution;interpolation algorithm;original coarse hyperspectral imagery;high-resolution imagery;available classification methods;super-resolution mapping","","","","11","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Parameter Selection Criteria for Tomo-SAR Focusing","G. D. Martín-del-Campo-Becerra; S. A. Serafín-García; A. Reigber; S. Ortega-Cisneros","Microwaves and Radar Institute, German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Center for Research and Advanced Studies (Cinvestav), National Polytechnic Institute (IPN), Zapopan, Jalisco, Mexico; Microwaves and Radar Institute, German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Center for Research and Advanced Studies (Cinvestav), National Polytechnic Institute (IPN), Zapopan, Jalisco, Mexico","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","8 Jan 2021","2021","14","","1580","1602","The synthetic aperture radar (SAR) tomography (TomoSAR) inverse problem is commonly tackled in the context of the direction-of-arrival estimation theory. The latter allows achieving super resolution, along with ambiguity levels reduction, thanks to the use of parametric focusing methods, as multiple signal classification (MUSIC) and statistical regularization techniques, like the maximum-likelihood-inspired adaptive robust iterative approach (MARIA). Nevertheless, in order to correctly suit the considered signal model, MUSIC and most regularization approaches require an appropriate setting of the involved parameters. In both cases, the accuracy of the retrieved solutions depends on the right selection of the assigned values. Thus, with the aim of dealing with such an issue, this article addresses several parameter selection strategies, adapted specifically to the TomoSAR scenario. Parametric techniques as MUSIC solve the TomoSAR problem in a different manner as the regularization methods do, hence, each approach demands different methodologies for the proper estimation of their parameters. Consequently, we refer to the Kullback-Leibler information criterion for the model order selection of parametric techniques as MUSIC, whereas we rather explore the Morozov's discrepancy principle, the L-Curve, the Stein's unbiased risk estimate, and the generalized cross-validation to choose the regularization parameters. After the incorporation of these criteria to MUSIC and MARIA, respectively, their capabilities are first analyzed through simulations, and later on, utilizing real data acquired from an urban area.","2151-1535","","10.1109/JSTARS.2020.3042661","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9281339","Generalized cross-validation;information criteria;L-Curve;maximum likelihood (ML);model order selection (MOS);synthetic aperture radar (SAR) and tomography (TomoSAR)","Multiple signal classification;Synthetic aperture radar;Focusing;Inverse problems;Tomography;Direction-of-arrival estimation;Signal resolution","direction-of-arrival estimation;inverse problems;iterative methods;maximum likelihood estimation;radar signal processing;remote sensing by radar;signal classification;synthetic aperture radar;tomography","parameter selection criteria;tomo-SAR focusing;synthetic aperture radar tomography inverse problem;direction-of-arrival estimation theory;super resolution;ambiguity levels reduction;parametric focusing methods;MUSIC;statistical regularization techniques;maximum-likelihood-inspired adaptive robust iterative approach;MARIA;signal model;regularization approaches;parameter selection strategies;TomoSAR scenario;parametric techniques;TomoSAR problem;different manner;regularization methods;proper estimation;Kullback-Leibler information criterion;model order selection;Stein's unbiased risk estimate;regularization parameters","","5","","35","CCBY","4 Dec 2020","","","IEEE","IEEE Journals"
"Reconstruction of Hyperspectral Images From Spectral Compressed Sensing Based on a Multitype Mixing Model","Z. Wang; M. He; Z. Ye; K. Xu; Y. Nian; B. Huang","Department of Electric Engineering, Tongling University, Tongling, China; College of Biomedical Engineering and Imaging Medicine, Army Medical University (Third Military Medical University), Chongqing, China; School of Electronics and Control Engineering, Chang'an University, Xi'an, China; College of Electronic Science, National University of Defense and Technology, Changsha, China; College of Biomedical Engineering and Imaging Medicine, Army Medical University (Third Military Medical University), Chongqing, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","1 Jun 2020","2020","13","","2304","2320","Hyperspectral compressed sensing (HCS) based on spectral unmixing technique has shown great reconstruction performance. In particular, the linear mixed model (LMM) has been widely used in HCS reconstruction. However, due to the complexity of environmental conditions, instrumental configurations, and material nonlinear mixing effects, LMM cannot accurately represent the hyperspectral images, which limits the improvement of reconstruction quality. In this article, first, by introducing spectral variability, nonlinear mixing, and residuals, a multitype mixed model (MMM) is proposed to establish a more accurate hyperspectral image model. Then, a novel MMM-based HCS is proposed, which performs spectral compressed sampling at the sampling stage only, and at the reconstruction stage, by using spectral unmixing, an MMM-based HCS super-resolution reconstruction algorithm from spectral compressed sensing data is developed, and the alternating direction multiplier method is employed to estimate each component of the MMM, furthermore, reasonable prior knowledge of each component is introduced to improve the estimation accuracy. Experimental results on hyperspectral datasets demonstrate that the proposed model outperforms those state-of-the-art methods based on the LMM in terms of HCS reconstruction quality.","2151-1535","","10.1109/JSTARS.2020.2994334","Key Logistics Research Project(grant numbers:BLJ18J005); National Natural Science Foundation of China(grant numbers:41601344); Overseas Visiting and Research Project for Excellent Young Key Talents in Higher Education Institutions in Anhui Province(grant numbers:gxgwfx2019056); Quality Engineering Project of Universities of Anhui Province(grant numbers:2016zy126); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9094327","Compressed sensing;hyperspectral remote sensing;linear mixing model (LMM);spectral unmixing","Image reconstruction;Hyperspectral imaging;Compressed sensing;Imaging;Mathematical model;Image resolution","compressed sensing;geophysical image processing;hyperspectral imaging;image reconstruction;image resolution","linear mixed model;spectral unmixing technique;hyperspectral compressed sensing;multitype mixing model;HCS reconstruction quality;spectral compressed sensing data;MMM-based HCS super-resolution reconstruction algorithm;spectral compressed sampling;multitype mixed model;spectral variability;hyperspectral images;LMM","","6","","45","CCBY","15 May 2020","","","IEEE","IEEE Journals"
"Three-Dimensional Interferometric ISAR Imaging for the Ship Target Under the Bi-Static Configuration","Y. Wang; X. Li","Research Institute of Electronic Engineering Technology, Harbin Institute of Technology, Harbin, China; Research Institute of Electronic Engineering Technology, Harbin Institute of Technology, Harbin, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","19 May 2017","2016","9","4","1505","1520","In this paper, a novel three-dimensional (3-D) Interferometric inverse synthetic aperture radar (InISAR) imaging method, which especially works on the ship target, is presented. Considering the characteristics of the ship target and the 3-D InISAR system, the bistatic configuration is designed to avoid the imaging failure in special situations caused by the low velocity of the ship target. The specificity of the 3-D InISAR imaging technique makes the adoption of the optimal imaging time selection method based on the estimation of the Doppler center, which can help to select the imaging time when the cross-range resolution reaches maximum, effective and simple enough for the 3-D reconstruction of the ship target. Besides, the translational and angular motion compensations in such situations are explained clearly. Due to the shortness of the selected echoes caused by motion complexity of the ship target, the sparse Bayes learning method, which has a lot of advantages compared with other similar methods, is adopted to realize the super-resolution imaging for the purpose of separating the superposed scatterers and its superiority in reducing the computation load of the 3-D InISAR imaging system is demonstrated explicitly. Finally, the distortion of the reconstructed coordinate for the ship target caused by the bistatic configuration is corrected by the simplified coordinate transformation and the relationship between the coordinates of the ship target and the reconstructed 3-D model is explained in detail. Some experimental results are provided to substantiate the effectiveness of the 3-D InISAR imaging method for the ship target in this paper.","2151-1535","","10.1109/JSTARS.2015.2513774","National Natural Science Foundation of China(grant numbers:61471149); Program for New Century Excellent Talents in University(grant numbers:NCET-12-0149); National Science Foundation for Post-doctoral Scientists of China(grant numbers:2013M540292); Postdoctoral Science-Research Developmental Foundation of Heilongjiang province(grant numbers:LBH-Q11092); Heilongjiang Postdoctoral Specialized Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399675","3-D InISAR;bistatic configuration;coordinate transformation;estimation of the Doppler center;keystone transformation;optimal imaging time selection;ship target;sparse Bayes learning;3-D InISAR;bistatic configuration;coordinate transformation;estimation of the Doppler center;keystone transformation;optimal imaging time selection;ship target;sparse Bayes learning","Imaging;Marine vehicles;Radar imaging;Image reconstruction;Image resolution;Doppler effect;Frequency modulation","geophysical image processing;image reconstruction;oceanographic techniques;remote sensing by radar;solid modelling;synthetic aperture radar","ship target 3-D reconstruction;translational compensation;angular motion compensation;super-resolution imaging;bistatic configuration;simplified coordinate transformation;Doppler center;optimal imaging time selection method;3-D InISAR imaging technique;imaging failure;3-D InISAR imaging system;3-D InISAR imaging method;interferometric inverse synthetic aperture radar;bi-static configuration;3D interferometric ISAR imaging","","33","","37","IEEE","5 Feb 2016","","","IEEE","IEEE Journals"
"PRISMA Spatial Resolution Enhancement by Fusion With Sentinel-2 Data","N. Acito; M. Diani; G. Corsini","Consorzio Nazionale Interuniversitario per le Telecomunicazioni, Parma, Italy; Accademia Navale, Livorno, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20 Dec 2021","2022","15","","62","79","This article deals with the problem of improving the spatial resolution of hyperspectral (HS) data from the PRecursore IperSpettrale della Missione Applicativa (PRISMA) mission. For this purpose, higher spatial resolution data from the Sentinel-2 (S2) mission are exploited. Particularly, 10 S2 bands at 10 and 20 m spatial resolution are used to accomplish the PRISMA super-resolution (SR) task. The article presents a new end-to-end procedure, called PRISMA-SR, that starting from the S2 data and the low-resolution PRISMA image, provides a super-resolved image with a spatial resolution of 10 m and the same spectral resolution as the PRISMA HS sensor. The first step of the PRISMA-SR procedure consists in fusing S2 data at different spatial resolutions to obtain a synthetic MS image with 10 m spatial resolution and 10 spectral bands. Then, an unsupervised procedure is applied to coregister the fused S2 image and the PRISMA image. Finally, the two images at different spatial resolutions are properly combined in order to obtain the super-resolved HS image. Solutions for each step of the PRISMA-SR processing chain are proposed and discussed. Simulated data are used to show the effectiveness of the PRISMA-SR scheme and to investigate the impact on its performance of each step of the processing chain. Real S2 and PRISMA images are finally considered to provide an example of the application of the PRISMA-SR.","2151-1535","","10.1109/JSTARS.2021.3132135","PRISMA products; Italian Space Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9633196","Hyperspectral (HS) data processing;hyperspectral (HS)-multispectral (MS) data fusion;satellite missions","Spatial resolution;Hyperspectral imaging;Sensors;Satellites;Superresolution;Fuses;European Space Agency","aerospace instrumentation;geophysical equipment;geophysical image processing;image resolution;infrared spectrometers;remote sensing;visible spectrometers","PRISMA-SR scheme;PRISMA spatial resolution enhancement;Sentinel-2 data;hyperspectral data;PRecursore IperSpettrale della Missione Applicativa mission;Sentinel-2 mission;PRISMA super-resolution task;called PRISMA-SR;low-resolution PRISMA image;super-resolved image;spectral resolution;PRISMA HS sensor;PRISMA-SR procedure;spectral bands;fused S2 image;super-resolved HS image;PRISMA-SR processing chain","","2","","53","CCBY","2 Dec 2021","","","IEEE","IEEE Journals"
"An Individual Tree Segmentation Method from Mobile Mapping Point Clouds Based on Improved 3D Morphological Analysis","W. Wang; Y. Fan; Y. Li; X. Li; S. Tang","Shenzhen University & Key Laboratory of Urban Land Resources Monitoring & Simulation, Ministry of Natural Resources, Shenzhen, P.R. China; Shenzhen University & Key Laboratory of Urban Land Resources Monitoring & Simulation, Ministry of Natural Resources, Shenzhen, P.R. China; Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen, P.R. China; Shenzhen University & Key Laboratory of Urban Land Resources Monitoring & Simulation, Ministry of Natural Resources, Shenzhen, P.R. China; Shenzhen University & Key Laboratory of Urban Land Resources Monitoring & Simulation, Ministry of Natural Resources, Shenzhen, P.R. China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2023","PP","99","1","15","Street tree extraction based on the 3D mobile mapping point cloud plays an important role in building smart cities and creating highly accurate urban street maps. Existing methods are often over- or under-segmented when segmenting overlapping street tree canopies and extracting geometrically complex trees. To address this problem, we propose a method based on improved 3D morphological analysis for extracting street trees from mobile laser scanner (MLS) point clouds. First, the 3D semantic point cloud segmentation framework based on Deep Learning is used for pre-classification of the original point cloud to obtain the vegetation point cloud in the scene. Considering the influence of terrain unevenness, the vegetation point cloud is de-terraformed and slice point cloud containing tree trunks is obtained through spatial filtering on height. On this basis, a voxel-based region growing method constrained with the changing rate of convex area is used to locate the stree trees. Then we propose an progressive tree crown segmentation method, which first completed the preliminary individual segmentation of the tree crown point cloud based on the voxel-based region growth constrained by the minimum increment rule, and then optimizes the crown edges by “valley” structure-based clustering. In this paper, the proposed method is validated and the accuracy is evaluated using three sets of MLS Datasets collected from different scenarios. The experimental results show that the method can effectively identify and localize street trees with different geometries and has a good segmentation effect for street trees with large adhesion between canopies. The accuracy and recall of tree localization are higher than 96.08% and 95.83%, respectively, and the average precision and recall of instance segmentation in three datasets are higher than 93.23% and 95.41%, respectively.","2151-1535","","10.1109/JSTARS.2023.3243283","National Key Research and Development Program of China(grant numbers:2022YFB3903700); Research Program of Shenzhen S and T Innovation Committee(grant numbers:JCYJ20210324093012033); Natural Science Foundation of Guangdong Province(grant numbers:2121A1515012574); Key Laboratory of Urban Land Resources Monitoring and Simulation, MNR(grant numbers:KF-2021-06-125); National Natural Science Foundation of China(grant numbers:71901147,41901329,41971354,41971341); Shenzhen Polytechnic Institute of IOT, Shenzhen(grant numbers:518055); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10040735","Remote Sensing;Hyperspectral Image;Unsupervised Classification;Image Super-Resolution;Aquaculture Ponds Extraction;Diffusion Model","Vegetation;Point cloud compression;Three-dimensional displays;Vegetation mapping;Clustering algorithms;Feature extraction;Solid modeling","","","","","","","CCBY","8 Feb 2023","","","IEEE","IEEE Early Access Articles"
"Coherent-Detecting and Incoherent-Modulating Microwave Coincidence Imaging With Off-Grid Errors","K. Cao; Y. Cheng; K. Liu; J. Wang; H. Wang","College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China","IEEE Geoscience and Remote Sensing Letters","7 Jan 2022","2022","19","","1","5","In this letter, a novel microwave coincidence imaging (MCI) approach is proposed based on a multiple-input single-output (MISO) radar system to deal with the low signal-to-noise ratio (SNR) scenarios and off-grid problem. First, in coherent-detecting part, a linear frequency modulated (LFM) signal is transmitted, and dechirping processes are conducted to enhance the SNR of echoes. Then, in incoherent-modulating part, the post random phase-shifting modulations are conducted on the echoes, hence the temporal–spatial orthogonal reference radiation field of MCI is constructed, which provides the potential information of super-resolution. Further, to solve the off-grid problem of target’s scatterers in MCI, a new projecting-residual-based selection criterion is also proposed, combined with the preexisting signal subspace matching (SSM) method. The proposed method could largely eliminate the off-grid errors while conduct a reference matrix selection procedure, hence the reconstruction accuracy and computational complexity can be much improved and reduced, respectively. Finally, the validity of the proposed method and the super-resolution ability of MCI are verified by experiments.","1558-0571","","10.1109/LGRS.2021.3127713","National Natural Science Foundation of China(grant numbers:61801486,61921001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9612163","Matrix selection;microwave coincidence imaging (MCI);off-grid;signal subspace matching (SSM);super-resolution","Imaging;Radar imaging;Signal to noise ratio;Superresolution;Receivers;Radar;Scattering","computational complexity;filtering theory;frequency modulation;image reconstruction;image resolution;matrix algebra;MIMO communication;radar imaging;radar target recognition","temporal-spatial orthogonal reference radiation field;MCI;off-grid problem;projecting-residual-based selection criterion;preexisting signal subspace;off-grid errors;conduct;reference matrix selection procedure;incoherent-modulating microwave coincidence imaging;novel microwave coincidence imaging approach;multiple-input single-output radar system;low signal-to-noise ratio;coherent-detecting part;linear frequency;dechirping processes;SNR;incoherent-modulating part;post random phase-shifting modulations","","1","","17","IEEE","11 Nov 2021","","","IEEE","IEEE Journals"
"Two-Stage Pansharpening Based on Multi-Level Detail Injection Network","J. Hu; C. Du; S. Fan","Key Laboratory of Electric Power Robot of Hunan Province, Changsha University of Science and Technology, Changsha, China; School of Electrical and Information Engineering, Changsha University of Science and Technology, Changsha, China; Key Laboratory of Electric Power Robot of Hunan Province, Changsha University of Science and Technology, Changsha, China","IEEE Access","2 Sep 2020","2020","8","","156442","156455","Pansharpening is an effective technology to obtain high resolution multispectral (HRMS) images by fusing low resolution multispectral (LRMS) images and high resolution panchromatic (PAN) images. With the rapid development of deep learning, some pansharpening methods based on deep learning have been proposed. Although fused images are greatly improved, there are still some areas for improvement. For example, the spectral preservation is not good enough and the details of fused images are not rich enough. To address the above problems, a two-stage pansharpening method based on convolutional neural network (CNN) is proposed. In the first stage, image super-resolution technology with residual block is used to enhance LRMS. In order to preserve spectra, inspired by the SAM (spectral angle mapper) index, a new spectral loss function is proposed. The second stage is the fusion stage. Detail injection block is proposed by combining detail injection and CNN in this stage. Experiments on WorldView2 and GeoEye1 images demonstrate that our fused images present more spatial details and better spectra by comparing with existing methods.","2169-3536","","10.1109/ACCESS.2020.3019201","National Natural Science Foundation of China(grant numbers:61601061,61971071); Scientific Research Fund of Hunan Provincial Education Department(grant numbers:14B006); Open Research Fund of Key Laboratory of Electric Power Robot of Hunan Province(grant numbers:PROF1902); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174972","Pansharpening;detail injection block;residual learning;convolutional neural network","Spatial resolution;Remote sensing;Indexes;Transforms;Distortion;Convolutional neural networks","convolutional neural nets;geophysical image processing;image fusion;image resolution;remote sensing","deep learning;spectral preservation;two-stage pansharpening method;convolutional neural network;image super-resolution technology;LRMS;SAM index;fusion stage;detail injection block;GeoEye1 images;multilevel detail injection network;high resolution multispectral images;low resolution multispectral images;high resolution panchromatic images;pansharpening methods;CNN;spectral angle mapper index","","7","","58","CCBY","24 Aug 2020","","","IEEE","IEEE Journals"
"Cloud Segmentation, Denoising, and Compression Techniques for use on Sentinel-3 Satellite Data","M. C. Wong; Y. Wei; J. Halloy","Department of Electrical Engineering, City University of Hong Kong, Hong Kong, China; Department of Mathematics, The Chinese University of Hong Kong, Hong Kong, China; Department of Computer Science, The University of Tennessee, Knoxville, USA","TENCON 2022 - 2022 IEEE Region 10 Conference (TENCON)","20 Dec 2022","2022","","","1","5","Satellite images of the Earth's surface have a multitude of uses. However., this data comes with some inherent issues. One such issue is cloud coverage. We propose the use of image segmentation to identify clouds in images. Another problem is the size of the data., which must be transferred over the satellite's limited connection bandwidth. We propose several compression methods for reducing data size effectively. The data is of varying quality, so the use of noise removal techniques can improve the accuracy and usability of the data.","2159-3450","978-1-6654-5095-9","10.1109/TENCON55691.2022.9977982","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9977982","Deep Learning;GANs;Super-resolution;Image Processing","Performance evaluation;Earth;Image segmentation;Image coding;Satellites;Noise reduction;Bandwidth","artificial satellites;clouds;data compression;geophysical image processing;image denoising;image segmentation;remote sensing","cloud coverage;cloud segmentation;compression methods;compression techniques;data size;denoising;Earth's surface;image segmentation;inherent issues;noise removal techniques;satellite images;sentinel-3 satellite data","","","","17","IEEE","20 Dec 2022","","","IEEE","IEEE Conferences"
"Enhancing NDVI Calculation of Low-Resolution Imagery using ESRGANs","M. M. Khaliq; R. Mumtaz","School of Electrical Engineering and Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan; School of Electrical Engineering and Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan","2022 24th International Multitopic Conference (INMIC)","13 Dec 2022","2022","","","1","6","Normalized Difference Vegetation Index (NDVI) has been one of the key scales for monitoring multiple plant parameters, but satellite imagery is never up to date, which makes it difficult to get readings for the recent situation of field crops. Doing so with Unmanned Aerial System, drone, in this case, is an intricate task, but with its advantages which include timely and effective measurements with the least errors to be fixed in post-processing of data. Before this, NDVI has been calculated using an Unmanned Aerial System, but the problem of the low resolution of the imagery always lingers. With the recent advancement of generated adversarial networks, the up-scaling of images has been made possible, which, if done with the right model, rules out the need for upgrading the camera hardware that is never cost-effective. We have come up with the solution of calculating the vegetation index of field crops by implementing Enhanced Super-Resolution Generated Adversarial Networks with drone imagery to calculate the vegetation index of crop fields. A simple near-infrared spectrum camera is usually not capable of producing a higher resolution image, by implementing the aforementioned generated adversarial network, we have been able to calculate vegetation index for a comparably much higher resolution image without upgrading with sophisticated hardware. We were able to perform the calculations for more pixels (12952) against the same area yielded an output value of 0.829 as compared to 0.828 in the case of low-resolution imagery (546416 pixels). The averaged values for red and near-infrared pixels showed changes from 32.337 to 30.264 for red, and from 189.168 to 182.1656 for near-infrared pixels. The results produced with this technique are different from those generated using original images which account for a new gateway in the calculation of the NDVI.","2049-3630","979-8-3503-9710-9","10.1109/INMIC56986.2022.9972928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9972928","Machine Learning;super-resolution;Generative Adversarial Networks;Multispectral imagery;NDVI","Satellites;Superresolution;Vegetation mapping;Crops;Cameras;Hardware;Indexes","autonomous aerial vehicles;crops;geophysical image processing;image resolution;infrared imaging;mobile robots;neural nets;remote sensing","camera hardware;crop fields;data post-processing;drone imagery;enhanced super-resolution generated adversarial networks;ESRGANs;field crops;image resolution;low-resolution imagery;NDVI calculation;near-infrared pixels;near-infrared spectrum camera;normalized difference vegetation index;plant parameter monitoring;satellite imagery;unmanned aerial system","","","","22","IEEE","13 Dec 2022","","","IEEE","IEEE Conferences"
"Resolution Threshold Analysis of the Microwave Radar Coincidence Imaging","S. Zhu; Y. He; X. Chen; C. Guo; H. Shi; J. Li; X. Dong; A. Zhang","School of Information and Communications Engineering, Xi’an Jiaotong University, Xi’an, China; School of Electronic Science and Engineering, Xi’an Jiaotong University, Xi’an, China; State Key Laboratory of Millimeter Waves, Nanjing, China; School of Information and Communications Engineering, Xi’an Jiaotong University, Xi’an, China; School of Information and Communications Engineering, Xi’an Jiaotong University, Xi’an, China; School of Information and Communications Engineering, Xi’an Jiaotong University, Xi’an, China; School of Telecommunication and Information Engineering, Xi’an University of Posts and Telecommunications, Xi’an, China; School of Information and Communications Engineering, Xi’an Jiaotong University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","26 Feb 2020","2020","58","3","2232","2243","The resolution of the microwave radar coincidence imaging (MRCI) can break the diffraction limit, which has been validated by experiments. However, there is still no theoretical analysis. In this article, the resolution of the MRCI is theoretically analyzed using the orthogonal subspace projection algorithm based on the space spanned by the discrete reference radiation mode. First, a target location estimate (TLE) method using the data from the nonfocusing radar array of the MRCI system is proposed to estimate the target position assisted by the equivalent detection method. The estimation precision of the TLE method is approximately equal to the 3-dB beamwidth of the coherent transmitting radar array with the same aperture; hence, the imaging plane can be obtained. Then, the equivalent internal noise (generated by the error of the target distance estimation, i.e., the location of the imaging plane) is theoretically analyzed. Finally, the imaging resolution threshold of the MRCI system is theoretically analyzed. The relationship between the resolution threshold and the factors (such as the deployment of the transmitting radar array, the distance between the target and the radar array, and the signal-to-noise ratio of the imaging system) is summarized. The proposed estimation method and the analyses of the MRCI system are validated through a set of simulations and experiments.","1558-0644","","10.1109/TGRS.2019.2955789","National Key Lab of Radar Signal Processing; Natural Science Foundation of Shaanxi Province(grant numbers:2017ZDXM-GY-009); China Postdoctoral Science Foundation(grant numbers:2017M613136); Shaanxi Province Postdoctoral Science Foundation(grant numbers:2017BSHYDZZ13); Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China(grant numbers:61501365,61801368,61801366); State Key Laboratory of Millimeter Waves(grant numbers:K201933); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936526","Equivalent noise;microwave radar coincidence imaging (MRCI);orthogonal subspace projection algorithm;resolution;super-resolution imaging;time delay estimation","Imaging;Radar imaging;Correlation;Signal resolution","image resolution;microwave imaging;object detection;radar imaging","resolution threshold analysis;microwave radar coincidence imaging;theoretical analysis;orthogonal subspace projection algorithm;discrete reference radiation mode;target location estimate method;nonfocusing radar array;MRCI system;target position;equivalent detection method;estimation precision;TLE method;coherent transmitting radar array;imaging plane;target distance estimation;imaging resolution threshold;imaging system;estimation method","","5","","33","IEEE","18 Dec 2019","","","IEEE","IEEE Journals"
"Angular Superresolution of Real Aperture Radar Using Online Detect-Before-Reconstruct Framework","D. Mao; J. Yang; Y. Zhang; W. Huo; J. Luo; J. Pei; Y. Zhang; Y. Huang","School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; Yangtze Delta Region, Quzhou, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; Yangtze Delta Region, Quzhou, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","8 Mar 2022","2022","60","","1","17","Superresolution methods can be applied to real aperture radar (RAR) to improve its angular resolution by solving an inverse problem. However, traditional superresolution methods are achieved after batch data collection, which requires extensive operational complexity and storage space. To solve this problem for RAR, an online detect-before-reconstruct (DBR) framework is proposed in this article based on the sparse property of targets. First, along the range direction, each sample of the echo data is detected to reduce the computational complexity by reducing the dimension of the effective data. Second, along the azimuth direction, a data-adaptive online processing structure is proposed to reduce the storage requirement for the angular superresolution problem. Finally, within the online processing structure, a target data-adaptive updating strategy is proposed to reduce the number of iterations for each target grid. The online DBR-based framework can effectively reduce the operational complexity caused by the noise values of the echo data. Based on the proposed online processing structure, the storage requirement and the operational complexity of the angular superresolution for an RAR system can be greatly reduced without significant reconstruction performance loss. The results of simulations and experimental data verify the proposed framework.","1558-0644","","10.1109/TGRS.2021.3139355","National Natural Science Foundation of China(grant numbers:61901092,61901090); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9665733","Angular super-resolution imaging;online detect-before-reconstruct (DBR) framework;real aperture radar (RAR)","Superresolution;Radar antennas;Radar;Radar imaging;Complexity theory;Azimuth;Apertures","computational complexity;image reconstruction;image resolution;inverse problems;iterative methods;radar antennas;radar detection;radar imaging;radar resolution","real aperture radar;online detect-before-reconstruct framework;inverse problem;batch data collection;extensive operational complexity;storage space;range direction;echo data;computational complexity;azimuth direction;data-adaptive online processing structure;storage requirement;angular superresolution problem;target data-adaptive updating strategy;online DBR-based framework;RAR system;reconstruction performance loss","","3","","59","IEEE","30 Dec 2021","","","IEEE","IEEE Journals"
"Terrain-Guided Flatten Memory Network for Deep Spatial Wind Downscaling","T. Yu; R. Yang; Y. Huang; J. Gao; Q. Kuang","Public Meteorological Service Center, China Meteorological Administration, Beijing, China; Public Meteorological Service Center, China Meteorological Administration, Beijing, China; Public Meteorological Service Center, China Meteorological Administration, Beijing, China; Public Meteorological Service Center, China Meteorological Administration, Beijing, China; Public Meteorological Service Center, China Meteorological Administration, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","11 Nov 2022","2022","15","","9468","9481","High-resolution wind analysis plays an essential role in pollutant dispersion and renewable energy utilization. This article focuses on spatial wind downscaling. Specifically, a novel terrain-guided flatten memory network (abbreviated as TIGAM) with axial similarity constraint is proposed. TIGAM consists of three elaborately designed blocks, i.e., the similarity block, the reconstruction block, and the denoise block. To achieve long-spatial dependence, the similarity block interpolates low-resolution data to high resolution in an axial attention manner. Meanwhile, the reconstruction block aims to obtain a clearer high-resolution representation in closed form. Taking both of the meteorological prior and network design principle into consideration, this article also proposes a flatten memory module with learnable input for high-resolution denoising. Furthermore, for accurate detail reconstruction, a terrain-guided enhanced loss is presented benefitting from the high-resolution remote sensing data. This loss function integrates wind spatial distribution and terrain elegantly. Extensive quantitative and qualitative experiments demonstrate the superiority of the proposed TIGAM.","2151-1535","","10.1109/JSTARS.2022.3218016","National Natural Science Foundation of China(grant numbers:62106270); Innovation Program of Public Meteorological Service Center(grant numbers:M2021002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9932682","Deep learning;flatten memory network;image super-resolution;meteorological methods;spatial wind downscaling","Spatial resolution;Superresolution;Meteorology;Surfaces;Mathematical models;Image reconstruction;Wind speed","air pollution measurement;terrain mapping;wind","accurate detail reconstruction;axial attention manner;axial similarity constraint;deep spatial wind;denoise block;elaborately designed blocks;high-resolution denoising;high-resolution remote sensing data;high-resolution representation;high-resolution wind analysis;long-spatial dependence;low-resolution data;memory module;network design principle;novel terrain-guided flatten memory network;pollutant dispersion;reconstruction block;renewable energy utilization;spatial wind downscaling;terrain-guided enhanced loss;TIGAM;wind spatial distribution","","","","65","CCBY","31 Oct 2022","","","IEEE","IEEE Journals"
"Camera spectral sensitivity, illumination and spectral reflectance estimation for a hybrid hyperspectral image capture system","L. Zhang; Y. Fu; Y. Zheng; H. Huang","Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology; Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology; National Institute of Informatics; Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology","2017 IEEE International Conference on Image Processing (ICIP)","22 Feb 2018","2017","","","545","545","A variety of methods have been proposed to restore high resolution hyperspectral image (HSI) from a hybrid camera system, which captures high spatial resolution RGB images and low spatial resolution HSI. They focused unanimously on HSI super-resolution via fusion, yet did not explore the potential of this kind of system for camera spectral sensitivity (CSS), illumination spectrum, and high spatial resolution spectral reflectance recovery. In this paper, we present a sparse representation based method to estimate the CSS of the RGB camera under unknown illumination for the hybrid camera system. Furthermore, the illumination and high spatial resolution spectral reflectance are simultaneously recovered. Experimental results show the effectiveness of the proposed methods on camera spectral sensitivity, illumination spectrum and spectral reflectance recovery.","2381-8549","978-1-5090-2175-8","10.1109/ICIP.2017.8296340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8296340","Camera spectral sensitivity;illumination estimation;spectral reflectance recovery","Cameras;Lighting;Cascading style sheets;Mathematical model;Databases;Hyperspectral imaging;Sensitivity","cameras;geophysical image processing;hyperspectral imaging;image colour analysis;image reconstruction;image representation;image resolution;image sensors;reflectivity;remote sensing","HSI super-resolution;illumination spectrum;high spatial resolution spectral reflectance recovery;RGB camera;hybrid camera system;camera spectral sensitivity;spectral reflectance estimation;hybrid hyperspectral image capture system;high resolution hyperspectral image;high spatial resolution RGB images;low spatial resolution HSI","","","","19","IEEE","22 Feb 2018","","","IEEE","IEEE Conferences"
"Detection of single and double persistent scatterers based on RELAX in SAR tomography","Z. Hou; H. Luo; Z. Dong","School of Electronic Science and Engineering, National University of Defense Technology Changsha, Hunan, P.R., China; School of Electronic Science and Engineering, National University of Defense Technology Changsha, Hunan, P.R., China; School of Electronic Science and Engineering, National University of Defense Technology Changsha, Hunan, P.R., China","2017 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","1 Jan 2018","2017","","","1","6","Synthetic aperture Radar tomography has been widely used in 3D reconstruction in urban area. It can distinguish multi persistent scatterers in the same range-azimuth resolution cell. But how to detect and estimate the number and parameters of persistent scatterers is still an important and difficult problem need to be resolved. In this paper, a new method based on RELAX and generalized likelihood ratio test (RELAX-SC-GLRT) is proposed. This method combines the advantages of RELAX (super resolution and estimating accurately) and GLRT (detecting steadily and robustly). In the experiment with SAR images acquired by TerraSAR-X, this method has exhibited good performances in detecting single and double persistent scatterers.","","978-1-5386-3142-3","10.1109/ICSPCC.2017.8242601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8242601","synthetic aperture Radar tomography (TomoSAR);persistent scatterer (PS);RELAX;generalized likelihood ratio test (GLRT)","Estimation;Synthetic aperture radar;Focusing;Tomography;Signal to noise ratio;Apertures;Robustness","geophysical image processing;image reconstruction;radar imaging;radar interferometry;remote sensing by radar;synthetic aperture radar","single persistent scatterers;double persistent scatterers;SAR tomography;urban area;multipersistent scatterers;range-azimuth resolution cell;important problem;generalized likelihood ratio test;RELAX-SC-GLRT;super resolution;synthetic aperture radar tomography;3D reconstruction;RELAX and generalized likelihood ratio test;TerraSAR-X","","","","16","IEEE","1 Jan 2018","","","IEEE","IEEE Conferences"
"Fusion of Hyperspectral and Panchromatic Images Using Generative Adversarial Network and Image Segmentation","W. Dong; Y. Yang; J. Qu; W. Xie; Y. Li","State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","29 Dec 2021","2022","60","","1","13","Hyperspectral (HS) image fusion aims at integrating a panchromatic (PAN) image and an HS image, featuring the fused image with the spatial quality of the former and the spectral diversity of the latter. The classic fusion algorithm generally includes three consecutive procedures that are upsampling, detail extraction, and detail injection. In this article, we propose an HS and PAN image fusion method based on generative adversarial network and local estimation of injection gain. Instead of upsampling the HS image by classical interpolation techniques, a generative adversarial super-resolution network (GASN) is designed to obtain the interpolated HS image in the fusion framework. GASN establishes a spectral-information-based discriminator to conduct adversarial learning with the generator, so as to preserve the spectral information of the low-resolution HS image. An image segmentation-based injection gain estimation (ISGE) algorithm is subsequently proposed for HS and PAN images fusion. The injection gain is estimated over image segments obtained by a binary partition tree approach to improve the fusion performance. The proposed GASN and ISGE are implemented into two credible global estimation pansharpening methods, and experimental results prove the performance improvement of the proposed method. The proposed method is also compared with existing state-of-the-art methods, and experiments on several public databases demonstrate that the proposed method is competitive or superior to the state-of-the-art fusion methods.","1558-0644","","10.1109/TGRS.2021.3078711","National Defense Pre-Research Foundation; Higher Education Discipline Innovation Project(grant numbers:B08038); National Natural Science Foundation of China(grant numbers:61801359,61571345,91538101,61501346,61502367,61701360); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2021JQ-194,2021JQ-197); Fundamental Research Funds for the Central Universities(grant numbers:XJS210108,XJS210104); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2020A1515110856); Yangtze River Scholar Bonus Schemes of China(grant numbers:CJT160102); Ten Thousand Talent Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9437429","Details injection;hyperspectral (HS) fusion;image segment;injection gains","Estimation;Spatial resolution;Pansharpening;Image segmentation;Generators;Generative adversarial networks;Feature extraction","geophysical image processing;image fusion;image representation;image resolution;image sampling;image segmentation;interpolation;learning (artificial intelligence);neural nets;spectral analysis","spectral-information-based discriminator;adversarial learning;low-resolution HS image;image segmentation-based injection gain estimation algorithm;GASN;panchromatic image;hyperspectral image fusion;interpolation techniques;generative adversarial super-resolution network;interpolated HS image;HS image upsampling;PAN images fusion;global estimation pansharpening methods","","6","","43","IEEE","20 May 2021","","","IEEE","IEEE Journals"
"Water Content Continuous Monitoring of Grapevine Xylem Tissue Using a Portable Low-Power Cost-Effective FMCW Radar","C. Q. Mayoral; C. García González; J. C. I. Galarregui; D. Marín; D. Gastón; C. Miranda; R. Gonzalo; I. Maestrojuán; L. G. Santesteban; I. Ederra","Department of Electrical, Public University of Navarre, Pamplona, Spain; Department of Electrical, Public University of Navarre, Pamplona, Spain; Institute of Smart Cities, Public University of Navarre, Pamplona, Spain; Department of Agricultural Engineering, Public University of Navarre, Pamplona, Spain; Anteral S.L., Pamplona, Spain; Department of Agricultural Engineering, Public University of Navarre, Pamplona, Spain; Institute of Smart Cities, Public University of Navarre, Pamplona, Spain; Anteral S.L., Pamplona, Spain; Department of Agricultural Engineering, Public University of Navarre, Pamplona, Spain; Institute of Smart Cities, Public University of Navarre, Pamplona, Spain","IEEE Transactions on Geoscience and Remote Sensing","22 Jul 2019","2019","57","8","5595","5605","This paper presents the real-time monitoring of a grapevine's water content that flows up through the xylem tissue by means of a frequency-modulated continuous-wave radar. The application of an optimization process, based on the super-resolution multiple signal classification algorithm, has enabled the reduction of the bandwidth required to discern the xylem water content and, thus, the operating frequency, achieving a depth resolution of at least 3 mm. This design advantage has resulted in a significant step forward toward a real life application, allowing the use of fully-integrated off-the-shelf components in order to implement a completely portable low-power cost-effective radar at 23.1 GHz with a 3.4-GHz bandwidth. The sensor performance has been evaluated by means of three different experiments: irrigation cycles, day/night cycles, and comparison between irrigation cycles at different temperatures. From the experimental results, it is possible to assert that the contactless sensor presented in this paper is very sensitive to changes in the plant's water content, differentiating between daytime and nighttime. In addition, it has been proven that temperature has a noticeable influence over the evapotranspiration, observing negative drying slopes of 5.62 and 6.28 mV/cycle at 23 °C and 26 °C, respectively.","1558-0644","","10.1109/TGRS.2019.2900565","Spanish Ministry of Economy and Competitiveness(grant numbers:TEC2016-76997-C3-1-R); Navarra Government(grant numbers:PI025 VITHZ,0011-1365-2016-000084 RAFF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8671511","Contactless sensor;dielectric permittivity;frequency-modulated continuous-wave (FMCW) radar;group velocity;multiple signal classification (MUSIC) algorithm;range resolution;xylem water content","Radar;Monitoring;Pipelines;Temperature measurement;Dielectrics;Bandwidth;Temperature sensors","CW radar;FM radar;irrigation;optimisation;radar resolution;signal classification;telecommunication power management","irrigation cycles;water content continuous monitoring;grapevine xylem tissue;portable low-power cost-effective FMCW radar;real-time monitoring;frequency-modulated continuous-wave radar;optimization process;super-resolution multiple signal classification algorithm;xylem water content;depth resolution;fully-integrated off-the-shelf components;low-power cost-effective radar;day-night cycles;temperature 26.0 degC;frequency 23.1 GHz;temperature 23.0 degC;bandwidth 3.4 GHz","","5","","32","IEEE","19 Mar 2019","","","IEEE","IEEE Journals"
"Feature Balance for Fine-Grained Object Classification in Aerial Images","W. Zhao; T. Tong; L. Yao; Y. Liu; C. Xu; Y. He; H. Lu","Key Laboratory of Intelligent Control and Optimization for Industrial Equipment of Ministry of Education and School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; Key Laboratory of Intelligent Control and Optimization for Industrial Equipment of Ministry of Education and School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; Research Institute of Information Fusion, Naval Aviation University, Yantai, China; Research Institute of Information Fusion, Naval Aviation University, Yantai, China; Research Institute of Information Fusion, Naval Aviation University, Yantai, China; Research Institute of Information Fusion, Naval Aviation University, Yantai, China; Key Laboratory of Intelligent Control and Optimization for Industrial Equipment of Ministry of Education and School of Information and Communication Engineering, Dalian University of Technology, Dalian, China","IEEE Transactions on Geoscience and Remote Sensing","12 Apr 2022","2022","60","","1","13","Fine-grained object classification (FGOC) focuses on identifying subcategories of objects, which is crucial in military and civilian. Existing FGOC methods primarily focus on high-resolution aerial images, limiting their application on low-resolution (LR) FGOC that is a more realistic setting, especially on resource-constrained satellite devices. It is more challenging to deal with LR FGOC since objects’ details are blurred or missing. Addressing this issue, we make the first attempt to explore LR FGOC and propose a novel pipeline based on two technical insights: 1) feature balance strategy discriminatively integrates super-resolution weak and strong detailed presentations into coarse features of LR aerial images, achieving a feature balance to avoid that the weak detailed presentations are inhibited by the strong ones and 2) iterative interaction mechanism alternately refines feature details of the discriminative ship regions and optimizes the performance of FGOC. Moreover, we build a low-resolution fine-grained object (LFS) dataset to promote further study and evaluation. Extensive experiments on the proposed LFS dataset and the other three object datasets of DOTA, FS23, and HRSC2016 demonstrate that our method outperforms state-of-the-art algorithms. Dataset and code are publicly available at https://github.com/wdzhao123/FBNet.","1558-0644","","10.1109/TGRS.2022.3161433","National Natural Science Foundation of China(grant numbers:62176038,62022092,U1903215); Science and Technology Star of Dalian(grant numbers:2021RQ054); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9739789","Aerial images;feature balance;fine-grained object classification;iterative interaction;low resolution","Feature extraction;Marine vehicles;Image reconstruction;Superresolution;Predictive models;Pipelines;Task analysis","feature extraction;image classification;image resolution;object detection;ships","feature balance;fine-grained object classification;FGOC methods;high-resolution aerial images;low-resolution FGOC;resource-constrained satellite devices;LR FGOC;balance strategy;super-resolution;strong detailed presentations;coarse features;LR aerial images;weak detailed presentations;feature details;low-resolution fine-grained object","","3","","50","IEEE","22 Mar 2022","","","IEEE","IEEE Journals"
"k-Space Decomposition-Based 3-D Imaging With Range Points Migration for Millimeter-Wave Radar","Y. Akiyama; T. Ohmori; S. Kidera","Graduate School of Informatics and Engineering, The University of Electro-Communications, Tokyo, Japan; Graduate School of Informatics and Engineering, The University of Electro-Communications, Tokyo, Japan; Japan Science and Technology Agency (JST), PRESTO, Saitama, Japan","IEEE Transactions on Geoscience and Remote Sensing","21 Jul 2021","2021","59","8","6637","6650","In this article, we present a novel method that incorporates the range points migration (RPM) method,  $k$ -space decomposition-based accurate, and noise-robust range extraction filter for microwave or millimeter-wave (MMW) short-range radar using a considerably lower fractional bandwidth signal. The advantage for higher angular resolution in higher frequency systems, such as MMW radar, has been implemented to the incoherent-based RPM method, using the simple 1-D or 2-D Fourier transform-based processing to maintain the imaging accuracy in RPM processing for both the range and the angular directions. As an additional advantage of our method, it also offers data clustering in  $k$ -space, which can enhance the imaging accuracy of the RPM method. The numerical and experimental tests demonstrated that the proposed method offers numerous advantages over the Capon-based super-resolution algorithm or coherent-based imaging approaches.","1558-0644","","10.1109/TGRS.2020.3029301","JST, PRESTO, Japan(grant numbers:JPMJPR1771); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9234067","Human recognition;millimeter-wave (MMW) radar;range points (RPs) migration (RPM);3-D radar imaging","Radar imaging;Imaging;Image resolution;Scattering;Sensors;Azimuth","array signal processing;filtering theory;Fourier transforms;image resolution;radar imaging;radar resolution;ultra wideband radar","additional advantage;imaging accuracy;Capon-based super-resolution algorithm;space decomposition-based 3-D imaging;range points migration;millimeter-wave radar;k-space decomposition-based;noise-robust range extraction filter;millimeter-wave short-range radar;considerably lower fractional bandwidth signal;higher angular resolution;higher frequency systems;MMW radar;incoherent-based RPM method;RPM processing;angular directions","","3","","25","IEEE","20 Oct 2020","","","IEEE","IEEE Journals"
"Artificial intelligence technologies for Maritime Surveillance applications","V. Fontana; J. M. D. Blasco; A. Cavallini; N. Lorusso; A. Scremin; A. Romeo","RHEA Group, Frascati, Italy; RHEA Group, Frascati, Italy; RHEA Group, Frascati, Italy; RHEA Group, Frascati, Italy; RHEA Group, Frascati, Italy; RHEA Group, Frascati, Italy","2020 21st IEEE International Conference on Mobile Data Management (MDM)","7 Aug 2020","2020","","","299","303","The use of AI methods is currently evolving tasks done in the past by image analysts. During the last years, technology had helped to jump into fully automatic methods for monitoring and surveillance tasks, such as object detection, change detection and many more. In this work we want to show some of the AI-based models which RHEA Group has been working on which can be applied to the maritime domain, such as ship detection and super-resolution of satellite data. Each of these models can be further extended and specialized into specific monitoring and surveillance tasks, from the detection of ghost ships, measure environmental damage or monitoring of critical infrastructure near harbors or protected areas. In this paper, we illustrate some examples of the status of our research activities and the developments of these prototype applications.","2375-0324","978-1-7281-4663-8","10.1109/MDM48529.2020.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9162203","Artificial intelligence;deep learning;convolutional networks;remote sensing;maritime survemance;ship recognition;sAR;optical;environment;security","Image resolution;Satellites;Marine vehicles;Training;Task analysis;Object detection;Urban areas","artificial intelligence;image resolution;marine engineering;object detection;ships;surveillance","artificial intelligence;maritime surveillance;AI methods;image analysts;surveillance tasks;RHEA Group;maritime domain;ship detection;super-resolution;satellite data;ghost ships;environmental damage","","2","","20","IEEE","7 Aug 2020","","","IEEE","IEEE Conferences"
"Fast and Accurate Super-Resolution of FY-2 Infrared Cloud Images via Multi-Scale Fusion Network","Y. Guo; P. Xiao; M. Xue","Jiangsu Key Laboratory of Meteorological Observation and Information Processing, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Meteorological Observation and Information Processing, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Big Data Analysis Technology, Nanjing University of Information Science and Technology, Nanjing, China","IEEE Access","25 Oct 2019","2019","7","","152149","152157","This paper proposes an effective method to improve the spatial resolution of FengYun-2 (FY-2) infrared cloud images via deep convolutional neural networks. The proposed model consists of four parts: shallow feature representation block, stacked multi-scale fusion blocks, global feature fusion block, and feature reconstruction block. The multi-scale fusion block combines dilated convolution, local feature fusion and local residual learning to extract multi-scale local features from the original low-resolution image directly. Then these local features are all merged by the global feature fusion block to reconstruct the residual representations in high-resolution space. For training and testing, we have specially built a dataset of infrared cloud images. We evaluated the proposed method both on simulated and real data. Experimental results demonstrate that the proposed approach achieves improved reconstruction accuracy than the state-of-the-art methods. Besides, the concise structure of the proposed model enables it to be applicable in practice.","2169-3536","","10.1109/ACCESS.2019.2948037","National Natural Science Foundation of China(grant numbers:61673222,61701245,61701247); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873577","Infrared cloud image;super-resolution;deep convolutional neural network;multi-scale fusion network","Feature extraction;Clouds;Image reconstruction;Convolution;Spatial resolution;Task analysis","convolutional codes;feature extraction;image fusion;image reconstruction;image representation;image resolution;learning (artificial intelligence)","multiscale local features;low-resolution image;global feature fusion block;high-resolution space;multiscale fusion network;spatial resolution;FengYun-2;deep convolutional neural networks;shallow feature representation block;stacked multiscale fusion blocks;feature reconstruction block;multiscale fusion block;local feature fusion;local residual learning;FY-2 infrared cloud images","","","","36","CCBY","17 Oct 2019","","","IEEE","IEEE Journals"
"Fusion of Hyperspectral and Multispectral Images With Sparse and Proximal Regularization","F. Yang; Z. Ping; F. Ma; Y. Wang","School of Electrical and Control Engineering, Liaoning Technical University, Huludao, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic and Information Engineering, Liaoning Technical University, Huludao, China; School of Electronic and Information Engineering, Liaoning Technical University, Huludao, China","IEEE Access","31 Dec 2019","2019","7","","186352","186363","Fusion of hyperspectral and multispectral imagery data is utilized to reconstruct a super-resolution image with high spectral and spatial resolution, which plays a significant role in remote sensing image processing. Conversely, hyperspectral and multispectral data can be modeled as two low-dimensional subspaces by respectively spatially and spectrally degrading the desired image. A representative method is called coupled non-negative matrix factorization (CNMF) based on a Gaussian observation model, but it is an ill-posed inverse problem. In addition, from the perspective of matrix factorization, the matrixing process of hyperspectral and multispectral cube data generally results in the loss of structural information and performance degradation. To address these issues, this article proposes a proximal minimum-volume expression to regularize the convex simplex, enclosing all reconstructed image pixels instead of low-dimensional subspace data. Then, we incorporate sparse and proximal regularizers into the original CNMF to reformulate the fusion problem as a dynamical system via proximal alternating optimization. Finally, the alternating direction method of multipliers is adopted to split the variables for the closed-form solutions that are further reduced in computational complexity. The experimental results show that the proposed algorithm in this paper performs better than the state-of-the-art fusion methods in most cases, which verifies the effectiveness and efficiency of this proposed algorithm in yielding high-fidelity reconstructed images.","2169-3536","","10.1109/ACCESS.2019.2961240","Scientific Research Project of Colleges from Liaoning Department of Education (P.R.C)(grant numbers:LJ2019QL006,LJ2017QL014,LJ2019JL022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937525","Proximal regularization;coupled non-negative matrix factorization;data fusion;minimum volume;alternating optimization","Hyperspectral imaging;Tensors;Matrix decomposition;Image reconstruction;Spatial resolution;Data integration","computational complexity;geophysical image processing;image classification;image fusion;image reconstruction;image resolution;matrix decomposition;optimisation;remote sensing","multispectral images;proximal regularization;super-resolution image;high spectral resolution;spatial resolution;remote sensing image processing;hyperspectral data;multispectral data;low-dimensional subspaces;desired image;representative method;nonnegative matrix factorization;Gaussian observation model;inverse problem;matrixing process;hyperspectral cube data;multispectral cube data;structural information;performance degradation;minimum-volume expression;reconstructed image pixels;low-dimensional subspace data;regularizers;CNMF;fusion problem;proximal alternating optimization;high-fidelity reconstructed images","","3","","52","CCBY","20 Dec 2019","","","IEEE","IEEE Journals"
"Experimental Results of Spectral and Imaging from Tunable Coherent Terahertz Radiation","X. Lin; J. Zhang; Z. Zhang; Z. Dai","Key Laboratory for Advanced Optical Remote Sensing Technology of Beijing, China; Shanghai Advanced Research Insitute, Chinese Academy of Sciences, Shanghai, China; Beijing Institute of Space Mechanics and Electricity, Beijing, China; Shanghai Institute of Applied Physics, Chinese Academy of Sciences, Shanghai, China","2019 44th International Conference on Infrared, Millimeter, and Terahertz Waves (IRMMW-THz)","21 Oct 2019","2019","","","1","2","In this paper, we demonstrate the generation and observation of watt-level, coherent tunable terahertz radiation from relativistic femtosecond electron beam. Spectral content of the coherent terahertz emission from the undulator and dipole magnet is measured, and high quality terahertz imaging experimental is carried utilizing methodology of super-resolution reconstruction.","2162-2035","978-1-5386-8285-2","10.1109/IRMMW-THz.2019.8874361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8874361","","Undulators;Image reconstruction;Image resolution;Electron beams;Magnetic resonance imaging;Superconducting magnets","electron beams;high-speed optical techniques;image reconstruction;image resolution;light coherence;terahertz wave imaging;terahertz waves","coherent tunable terahertz radiation;relativistic femtosecond electron beam;spectral content;coherent terahertz emission;undulator;dipole magnet;high quality terahertz imaging;super-resolution reconstruction","","","","2","IEEE","21 Oct 2019","","","IEEE","IEEE Conferences"
"Enhanced multi-target detection for HFSWR by sparse-recovery-based 2-D MUSIC","Z. Chen; C. He; H. Zhao; F. Xie","Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China; Radio Ocean Remote Sensing, Wuhan University, Wuhan, China","OCEANS 2017 - Anchorage","25 Dec 2017","2017","","","1","5","This paper proposes using the sparse-recovery (SR) based 2-D multiple-signal classification (MUSIC) to enhance the multi-target detection capability of high-frequency surface wave radars (HFSWRs). Usually, for wide-beam HFSWRs, target detection is first conducted in the range-Doppler spectrum; bearings are then estimated by super-resolution methods, such as MUSIC. Unfortunately, this approach can easily result in unfavorable deterioration of multi-target detection by conventional cascaded methods if target signals tend to mix in the Doppler spectrum. To compensate this shortage, spatial-temporal joint estimation is used. Owing to the lack of spatial-temporal snapshots caused by the non-stationarity of target signals, the efficiency of the estimator is improved by multiple-measurement-vector-based sparse recovery, which has been used to solve many under-sampling problems in the past ten years. As a result, 2D SR-MUSIC improves multi-target detection and outperforms conventional cascaded methods. The results obtained using real data with opportune targets validate our approach. Multiple adjacent targets are detected and distinguished from one another.","","978-0-6929-4690-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8232260","Multi-target detection;spatial-temporal joint estimation;multiple-measurement-vector-based sparse recovery;MUSIC","Estimation;Radar;Multiple signal classification;Spatial resolution;Signal resolution;Object detection;Covariance matrices","Doppler radar;marine radar;radar clutter;radar detection;radar signal processing;radar tracking;signal classification;target tracking","sparse-recovery based 2D MUSIC;multiple adjacent targets;spatial-temporal joint estimation;target signals;super-resolution methods;range-Doppler spectrum;target detection;wide-beam HFSWRs;high-frequency surface wave radars;multitarget detection capability;2-D multiple-signal classification;enhanced multitarget detection","","","","11","","25 Dec 2017","","","IEEE","IEEE Conferences"
"Creating Two-Dimensional Images of Objects with High Angular Resolution","B. A. Lagovsky; A. B. Samokhin; Y. V. Shestopalov","Dept. of Applied Mathematics, Moscow Technological University, Moscow, Russian Federation; Dept. of Applied Mathematics, Moscow Technological University, Moscow, Russian Federation; Faculty of Engineering and Sustainable Development, University of Gävle, Gävle, Sweden","2018 IEEE Asia-Pacific Conference on Antennas and Propagation (APCAP)","18 Nov 2018","2018","","","114","115","A new method of digital radar signal processing for remote sensing is proposed. The technique allows one to obtain two-dimensional images of objects with super resolution. The method is based on solving a convolution-type two- dimensional linear integral equation of the first kind by algebraic methods.","2381-5523","978-1-5386-5648-8","10.1109/APCAP.2018.8538220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8538220","angular resolution;Rayleigh criterion;superresolution;two-dimensional linear integral equation","Signal resolution;Image resolution;Image reconstruction;Conferences;Integral equations;Antenna arrays;Solids","algebra;image resolution;integral equations;radar imaging;radar signal processing","high angular resolution;digital radar signal;remote sensing;super resolution;dimensional linear integral equation;algebraic methods","","4","","8","IEEE","18 Nov 2018","","","IEEE","IEEE Conferences"
"Spectral Video Compression Using Convolutional Sparse Coding","C. A. Barajas-Solano; J. -M. Ramirez; H. Arguello","Universidad Industrial de Santander, Bucaramanga, Colombia; Universidad Rey Juan Carlos, Mostoles, Spain; Universidad Industrial de Santander, Bucaramanga, Colombia","2020 Data Compression Conference (DCC)","2 Jun 2020","2020","","","253","262","Spectral Videos (SV) are datasets containing spatial-spectral-and-temporal information of a moving scene and this kind of information have been successfully used in medicine, remote sensing, and military application. However, expensive acquisition processes and difficulties in equipment manufacture lead to low-resolution datasets. Therefore, super-resolution (SR) techniques have emerged as a processing tool that recovers a high-resolution dataset by expressing the measurements as compressed versions of the desired data. Furthermore, the Convolutional Sparse Coding (CSC) has been developed as a signal model that learns a dictionary directly from the target signal, improving the reconstruction quality. This work proposes to extend the CSC formulation to consider temporal correlations in SVs, exploiting the shifting invariance property of the CSC model. The simulation results show a PSNR improvement in up to 2.5dB with respect to the state-of-the-art methods, preserving the edges and textures of the spectral video frames.","2375-0359","978-1-7281-6457-1","10.1109/DCC47342.2020.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105867","spectral video;convolutional sparse coding;data compression","","convolutional codes;data compression;image resolution;medical image processing;spatiotemporal phenomena;video coding","low-resolution datasets;super-resolution techniques;high-resolution dataset;target signal;temporal correlations;spectral video compression;moving scene;remote sensing;military application;spatial-spectral-and-temporal information;convolutional sparse coding","","2","","22","IEEE","2 Jun 2020","","","IEEE","IEEE Conferences"
"Enhanced Microwave Imaging by Bilinear Compressed Sensing","Y. Lu; W. -S. Benedix; C. Yu; J. Wang; D. Plettemeier","Chair for RF Engineering, Technische Universität Dresden, Dresden, Germany; Chair for RF Engineering, Technische Universität Dresden, Dresden, Germany; Technische Universitat Dresden, Dresden, Sachsen, DE; Technische Universitat Dresden, Dresden, Sachsen, DE; Chair for RF Engineering, Technische Universität Dresden, Dresden, Germany","2018 19th International Radar Symposium (IRS)","30 Aug 2018","2018","","","1","10","Microwave imaging (migration) and spectral analysis are widely used in the remote sensing techniques. Generally, a known signal will be transmitted and the transfer function of the observed zone will then be recovered by the received signal and the transmit signal. Nevertheless, those scenes are usually available for homogeneous setting, where the transmit signal will not be modified by e. g. the medium and the wave propagation mechanism. In inhomogeneous case, however, the transmit signal is modified by the channel. Thus, the received signal can be formulated as a bilinear function over transmit signal and channel transfer function. Additionally, the measured data in practice has relative low dimension property due to some technique as well as physical limitations. Regarding e. g. a super-resolution problem, its objective vectors exist usually in the higher dimensional space. Therefore, the corresponding inverse problem can be very ill-posed. Compressed Sensing (CS), which is popular for dealing with such ill-conditioned cases, will be introduced. Particularly, the question of how to realize the bilinear CS model in our special case will be discussed. Both theory and practical tests show its promising performance.","2155-5753","978-3-7369-9545-1","10.23919/IRS.2018.8447919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447919","","Three-dimensional displays;Imaging;Radar imaging;Frequency measurement;Two dimensional displays;Frequency modulation","compressed sensing;inverse problems;microwave imaging;spectral analysis;transfer functions","enhanced microwave imaging;bilinear compressed Sensing;spectral analysis;remote sensing techniques;received signal;transmit signal;bilinear function;channel transfer function;wave propagation mechanism;relative low dimension property;inverse problem;bilinear CS model;super-resolution problem;objective vectors","","","","5","","30 Aug 2018","","","IEEE","IEEE Conferences"
"Deep Unsupervised Blind Hyperspectral and Multispectral Data Fusion","J. Li; K. Zheng; J. Yao; L. Gao; D. Hong","College of Resources and Environment, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Computational Optical Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Computational Optical Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Computational Optical Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Computational Optical Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China","IEEE Geoscience and Remote Sensing Letters","7 Mar 2022","2022","19","","1","5","Hyperspectral images (HSIs) usually have finer spectral resolution but coarser spatial resolution than multispectral images (MSIs). To obtain a desired HSI with higher spatial resolution, great research attention has been paid to achieving hyperspectral super-resolution by fusing the observed HSI with an auxiliary MSI of the same scene. However, most of the existing HSI-MSI fusion methods rely either on prior knowledge of the degradation model or on sufficient training data, hindering their practicality and interpretability. In this letter, we propose a novel unsupervised HSI-MSI fusion network with the ability of degradation adaptive learning, namely, UDALN. Specifically, we propose three modules to straightly encode the spatial and spectral transformations across resolutions, i.e., SpaDnet, SpeUnet, and SpeDnet. Through an elaborately designed three-stage unsupervised training strategy, the estimated network parameters can exhibit clear physical meanings of degradation processes and therefore help guarantee a faithful reconstruction of the desired HSI. The experimental results on two widely used hyperspectral datasets demonstrate the effectiveness of our method in comparison to the state-of-the-art HSI-MSI fusion models. (Code available at https://github.com/JiaxinLiCAS/UDALN_GRSL.)","1558-0571","","10.1109/LGRS.2022.3151779","National Natural Science Foundation of China(grant numbers:62161160336,42030111); China Postdoctoral Science Foundation(grant numbers:2021M693234); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714360","Data fusion;deep learning;hyperspectral;multispectral;unsupervised learning","Degradation;Spatial resolution;Training;Hyperspectral imaging;Kernel;Adaptation models;Tensors","geophysical image processing;hyperspectral imaging;image classification;image colour analysis;image fusion;image resolution;image sensors;learning (artificial intelligence);remote sensing;sensor fusion;unsupervised learning","deep unsupervised blind hyperspectral;multispectral data fusion;hyperspectral images;finer spectral resolution;coarser spatial resolution;multispectral images;desired HSI;higher spatial resolution;great research attention;observed HSI;auxiliary MSI;existing HSI-MSI fusion methods;unsupervised HSI-MSI fusion network;degradation adaptive learning;spatial transformations;spectral transformations;three-stage unsupervised training strategy;estimated network parameters;degradation processes;widely used hyperspectral datasets;state-of-the-art HSI-MSI fusion models","","12","","22","IEEE","15 Feb 2022","","","IEEE","IEEE Journals"
"Iterative-SGLRT for Multiple-Scatterer Detection in SAR Tomography","H. Luo; Z. Dong; Z. Li; A. Yu","School of Engineering, Newcastle University, Newcastle upon Tyne, U.K.; College of Electronic Science, National University of Defense Technology, Changsha, China; College of Geological Engineering and Geomatics, Chang’an University, Xi’an, China; College of Electronic Science, National University of Defense Technology, Changsha, China","IEEE Geoscience and Remote Sensing Letters","23 Dec 2020","2021","18","1","122","126","This letter introduces a multiple-scatterer detection method in synthetic aperture radar tomography (TomoSAR), named iterative sequential generalized likelihood ratio test (iterative-SGLRT). In this technique, the number of scatterers is sequentially decided by the generalized likelihood ratio test (GLRT) pixel by pixel, after iteratively estimating the parameters. It is a good tradeoff of the aforeproposed methods of sup-GLRT and fast-sup-GLRT on accuracy and efficiency. Simulated comparisons showed that iterative-SGLRT outperformed fast-sup-GLRT on the performances of detection probability and accuracy without substantial computation time increase, and compared with sup-GLRT, its performance loss could be negligible with computational burden greatly reduced. In addition, both iterative-SGLRT and sup-GLRT have been applied to the TerraSAR-X data set over Shenzhen city. The 3-D reconstruction of the test site and the separation of the overlaid scatterers have been achieved. In addition, verification using light detection and radar (LiDAR) indicated a root-mean-square error (RMSE) of $ {0.1\rho _{s}}$ for both methods of the height estimated. Accordingly, iterative-SGLRT is very suitable for large urban area processing for its super-resolution, high efficiency, and robustness.","1558-0571","","10.1109/LGRS.2020.2964645","National Natural Science Foundation of China(grant numbers:61771478); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8966456","Iterative sequential generalized likelihood ratio test (iterative-SGLRT);layover;synthetic aperture radar tomography (TomoSAR)","Estimation;Urban areas;Iterative methods;Synthetic aperture radar;Spatial resolution;Tomography","geophysical image processing;geophysical techniques;image reconstruction;iterative methods;optical radar;optical tomography;parameter estimation;probability;radar imaging;remote sensing by radar;synthetic aperture radar;tomography","generalized likelihood ratio test pixel;fast-sup-GLRT;iterative-SGLRT;detection probability;multiple-scatterer detection method;synthetic aperture radar tomography;light detection and radar;iterative sequential generalized likelihood ratio test;SAR tomography;TomoSAR;parameter estimation;performance loss;TerraSAR-X data set;3D reconstruction;large urban area processing","","4","","18","IEEE","22 Jan 2020","","","IEEE","IEEE Journals"
"An Efficient Reconstruction Approach Based on Atomic Norm Minimization for Coprime Tomographic SAR","L. Yu; D. Feng; J. Wang; X. Huang","College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China","IEEE Geoscience and Remote Sensing Letters","4 Feb 2022","2022","19","","1","5","Recently, we have proposed the coprime tomographic synthetic aperture radar (TomoSAR) technique, whose baseline configuration conforms to the coprime array geometry. This technique is devoted to reducing the required number of acquisitions in the practical application where the number of flight passes is usually restricted due to cost consideration and temporal decoherence. This letter extends the tomographic reconstruction of the coprime TomoSAR to the atomic norm minimization (ANM) framework to pursue super-resolution. A compact ANM approach is proposed in this letter for the tomographic reconstruction of coprime TomoSAR in the presence of multiple looks data. Compared with the conventional ANM approach, the proposed approach compresses the dimension of the ANM model to a smaller size by two operations. One operation is that the equivalent covariance matrix is constructed to be conformed with the covariance matrix of the real acquisition data. The other operation is adopting the singular value decomposition (SVD) technique to reduce the look dimension of acquisition data. As a result, the compact approach reduces the computation complexity without performance loss. It is confirmed by simulation experiments.","1558-0571","","10.1109/LGRS.2022.3143662","National Natural Science Foundation of China(grant numbers:62101562); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9686674","Atomic norm minimization (ANM);coprime array;singular value decomposition (SVD);tomographic synthetic aperture radar (TomoSAR)","Geometry;Covariance matrices;Tomography;Sensor arrays;Minimization;Synthetic aperture radar;Computational modeling","covariance matrices;image reconstruction;image resolution;minimisation;radar imaging;remote sensing by radar;singular value decomposition;synthetic aperture radar","atomic norm minimization framework;compact ANM approach;tomographic reconstruction;coprime TomoSAR;multiple looks data;conventional ANM approach;ANM model;equivalent covariance matrix;acquisition data;singular value decomposition technique;compact approach;efficient reconstruction approach;coprime tomographic SAR;synthetic aperture radar technique;baseline configuration;coprime array geometry;flight passes;temporal decoherence","","1","","18","IEEE","19 Jan 2022","","","IEEE","IEEE Journals"
"Fusing Hyperspectral and Multispectral Images via Coupled Sparse Tensor Factorization","S. Li; R. Dian; L. Fang; J. M. Bioucas-Dias","College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; Instituto de Telecomunicacões, Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal","IEEE Transactions on Image Processing","24 May 2018","2018","27","8","4118","4130","Fusing a low spatial resolution hyperspectral image (LR-HSI) with a high spatial resolution multispectral image (HR-MSI) to obtain a high spatial resolution hyperspectral image (HR-HSI) has attracted increasing interest in recent years. In this paper, we propose a coupled sparse tensor factorization (CSTF)-based approach for fusing such images. In the proposed CSTF method, we consider an HR-HSI as a 3D tensor and redefine the fusion problem as the estimation of a core tensor and dictionaries of the three modes. The high spatial-spectral correlations in the HR-HSI are modeled by incorporating a regularizer, which promotes sparse core tensors. The estimation of the dictionaries and the core tensor are formulated as a coupled tensor factorization of the LR-HSI and of the HR-MSI. Experiments on two remotely sensed HSIs demonstrate the superiority of the proposed CSTF algorithm over the current state-of-the-art HSI-MSI fusion approaches.","1941-0042","","10.1109/TIP.2018.2836307","National Natural Science Fund of China for Distinguished Young Scholars(grant numbers:61325007); National Natural Science Fund of China for International Cooperation and Exchanges(grant numbers:61520106001); Fund of Hunan Province for Science and Technology Plan Project(grant numbers:2017RS3024); Portuguese Science and Technology Foundation(grant numbers:UID/EEA/50008/2013,ERANETMED/0001/2014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359412","Super-resolution;fusion;hyperspectral imaging;coupled sparse tensor factorization","Tensile stress;Dictionaries;Spatial resolution;Sparse matrices;Hyperspectral imaging;Estimation","hyperspectral imaging;image fusion;image resolution;image sensors;matrix decomposition;remote sensing;tensors","LR-HSI;coupled sparse tensor factorization;low spatial resolution hyperspectral image;high spatial resolution multispectral image;high spatial resolution hyperspectral image;CSTF method;spatial-spectral correlations;sparse core tensors;3D tensor;image fusion;HR-HSI model;remote sensing;HR-MSI","","248","","57","IEEE","15 May 2018","","","IEEE","IEEE Journals"
"Robust Hyperspectral Inpainting via Low-Rank Regularized Untrained Convolutional Neural Network","K. Faghih Niresi; C. -Y. Chi","Institute of Communications Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, Institute of Communications, National Tsing Hua University, Hsinchu, Taiwan","IEEE Geoscience and Remote Sensing Letters","10 Feb 2023","2023","20","","1","5","Over the past decade, many low-rank models, factorizations, or approximations have been applied to the restoration of hyperspectral images (HSIs) (e.g., denoising, inpainting, and super-resolution) from their incomplete and/or noisy measurements. Recently, deep learning (DL) has been shown to be a powerful method for solving inverse problems (including HSI restoration), but a large amount of training data is required. Since this is not possible for HSIs, unlike red green blue (RGB) images, in this work, a novel unsupervised framework for hyperspectral inpainting (HI) is proposed that can be implemented using an untrained convolutional neural network (CNN) for deep image prior (DIP), together with a recently reported differentiable regularization for the data rank and  $\ell _{2}$ -norm squared loss function. Based on the proposed framework, we come up with a novel HI algorithm [denoted as deep low-rank hyperspectral inpainting (DLRHyIn)] and a robust DLRHyIn (denoted as R-DLRHyIn) which is robust against outliers, where the latter differs from the former only in the Huber loss function (HLF) (which has been justified robust to mixed noise) used instead. Then some simulation results and real-data experiments are provided to demonstrate the effectiveness of the proposed DLRHyIn and R-DLRHyIn. Finally, we draw some conclusions.","1558-0571","","10.1109/LGRS.2023.3241161","Ministry of Science and Technology, Taiwan(grant numbers:MOST 110- 2221-E-007-048,MOST 111-2221-E-007-047-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10032531","Convolutional neural network (CNN);deep image prior (DIP);Huber loss function (HLF);hyperspectral inpainting (HI);inverse problems;low-rank regularization","Electronics packaging;Inverse problems;Hyperspectral imaging;Optimization;Image restoration;Convolutional neural networks;Tensors","","","","","","24","IEEE","31 Jan 2023","","","IEEE","IEEE Journals"
"Multi scatterer detection within tomographic SAR using a compressive sensing approach","M. Weiß; G. Fornaro; D. Reale","Fraunhofer FHR-PSR, Fraunhoferstraße 20; 53343-Wachtberg; Germany; National Research Council (CNR) - IREA, Napoli, Italy; National Research Council (CNR) - IREA, Napoli, Italy","2015 3rd International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing (CoSeRa)","19 Nov 2015","2015","","","11","15","Synthetic Aperture Radar (SAR) tomography has seen a strong evolution in the past years as it has shown to be a worthwhile tool for analysing data obtained with high range resolution interferometric SAR sensors at pixel size. In particular by transforming them into a 3-D, 4-D, and in general Multi-Dimensional SAR image. The resolution in the higher dimensions, for instance in elevation and time, depends on the size of the elevation aperture and on the temporal separation which will be spanned by the different repeat paths. However, for more recent space-borne SAR systems which has sub-meter range resolution, like COSMO-Skymed or TerraSAR-X, the orbital tracks are tightly controlled so that they show only a small variation. According to this, the tomographic resolution in elevation is an order of magnitude lower than in range or azimuth. This is normally not a problem as only the strongest reflector is of interest. However, for urban scenes or man made objects one can expect that each azimuth-range cell consists of a few point-like scatterers in the elevation direction. To resolve these scatterers super-resolution algorithms are required to improve the performance of tomographic tools. Due to the present of only a few scatterers we can use compressive sensing (CS) techniques for reconstructing the elevation for tomographic images. This paper presents an adapted CS method for 4-D tomographic SAR and compares it with classical matched filter. Super-resolution properties of the proposed CS is proven by results obtained from simulations and from real TerraSAR-X data.","","978-1-4799-7420-7","10.1109/CoSeRa.2015.7330254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7330254","Compressive Sensing (CS);SAR Tomography;Super-Resolution;Synthetic Aperture Radar (SAR);Differential SAR Tomography;DInSAR","Synthetic aperture radar;Tomography;Image resolution;Compressed sensing;Coherence;Azimuth;Signal resolution","compressed sensing;image resolution;radar imaging;synthetic aperture radar","multi scatterer detection;tomographic SAR;compressive sensing approach;synthetic aperture radar;tomographic resolution;compressive sensing techniques;tomographic images","","2","","29","IEEE","19 Nov 2015","","","IEEE","IEEE Conferences"
"EAGLE: Large-Scale Vehicle Detection Dataset in Real-World Scenarios using Aerial Imagery","S. M. Azimi; R. Bahmanyar; C. Henry; F. Kurz","Department of Aerospace, Aeronautics and Geodesy, Technical University of Munich, Munich, Germany; Remote Sensing Technology Institute, German Aerospace Center (DLR), Wessling, Germany; Remote Sensing Technology Institute, German Aerospace Center (DLR), Wessling, Germany; Remote Sensing Technology Institute, German Aerospace Center (DLR), Wessling, Germany","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","6920","6927","Multi-class vehicle detection from airborne imagery with orientation estimation is an important task in the near and remote vision domains with applications in traffic monitoring and disaster management. In the last decade, we have witnessed significant progress in object detection in ground imagery, but it is still in its infancy in airborne imagery, mostly due to the scarcity of diverse and large-scale datasets. Despite being a useful tool for different applications, current airborne datasets only partially reflect the challenges of real-world scenarios. To address this issue, we introduce EAGLE (oriEnted vehicle detection using Aerial imaGery in real-worLd scEnarios), a large-scale dataset for multi-class vehicle detection with object orientation information in aerial imagery. It features high-resolution aerial images composed of different real-world situations with a wide variety of camera sensor, resolution, flight altitude, weather, illumination, haze, shadow, time, city, country, occlusion, and camera angle. The annotation was done by airborne imagery experts with small-and large-vehicle classes. EAGLE contains 215,986 instances annotated with oriented bounding boxes defined by four points and orientation, making it by far the largest dataset to date in this task. It also supports researches on the haze and shadow removal as well as super-resolution and in-painting applications. We define three tasks: detection by (1) horizontal bounding boxes, (2) rotated bounding boxes, and (3) oriented bounding boxes. We carried out several experiments to evaluate several state-of-the-art methods in object detection on our dataset to form a baseline. Experiments show that the EAGLE dataset accurately reflects real-world situations and correspondingly challenging applications. The dataset will be made publicly available.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9412353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9412353","","Photography;Vehicle detection;Urban areas;Superresolution;Object detection;Tools;Cameras","cameras;computer vision;feature extraction;geophysical image processing;image classification;image motion analysis;object detection;object tracking;vehicles;video signal processing","aerial imagery;high-resolution aerial images;airborne imagery experts;large-vehicle classes;oriented bounding boxes;largest dataset;object detection;EAGLE dataset;correspondingly challenging applications;large-scale vehicle detection dataset;multiclass vehicle detection;orientation estimation;ground imagery;large-scale dataset;current airborne datasets;oriEnted vehicle detection;object orientation information","","6","","42","IEEE","5 May 2021","","","IEEE","IEEE Conferences"
"DeconNet: End-to-End Decontaminated Network for Vision-Based Aerial Tracking","H. Zuo; C. Fu; S. Li; J. Ye; G. Zheng","School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China","IEEE Transactions on Geoscience and Remote Sensing","30 Dec 2022","2022","60","","1","12","Vision-based aerial tracking has proven enormous potential in the field of remote sensing recently. However, challenges such as occlusion, fast motion, and illumination variation remain crucial issues for realistic aerial tracking applications. These challenges, frequently occurring from the aerial perspectives, can easily cause object feature pollution. With the contaminated object features, the credibility of trackers is prone to be substantially degraded. To address this issue, this work proposes a novel end-to-end decontaminated network, i.e., DeconNet, to alleviate object feature pollution efficiently and effectively. DeconNet mainly consists of downsampling and upsampling phases. Specifically, the decontaminated downsampling network first decreases the polluted object information with two convolution branches, enhancing the object location information. Subsequently, the decontaminated upsampling network applies the super-resolution technology to restore the object scale and shape information, with the low-to-high (LTH) encoder for further decontamination. In addition, the pooling distance (PD) loss function is carefully designed to improve the decontamination effect of the decontaminated downsampling network. Comprehensive evaluations on four well-known aerial tracking benchmarks validate the effectiveness of DeconNet. Especially, the proposed tracker has superior performance on the sequences with feature pollution. Besides, real-world tests on an aerial platform have proven the efficiency of DeconNet with 30.6 fps.","1558-0644","","10.1109/TGRS.2022.3230043","National Natural Science Foundation of China(grant numbers:62173249); Natural Science Foundation of Shanghai(grant numbers:20ZR1460100); Key Research and Development Program of Sichuan Province(grant numbers:2020YFSY0004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9991169","Downsampling-upsampling strategy;end-to-end decontaminated network (DeconNet);low-to-high (LTH) encoder;pooling distance (PD) loss;vision-based aerial tracking","Tracking;Feature extraction;Pollution;Superresolution;Decontamination;Shape;Autonomous aerial vehicles","autonomous aerial vehicles;computer vision;feature extraction;geophysical image processing;image coding;image resolution;image sampling;image sequences;object detection;object tracking;robot vision","aerial tracking benchmarks;contaminated object features;DeconNet;decontaminated downsampling network;decontaminated upsampling network;decontamination effect;downsampling phases;end-to-end decontaminated network;low-to-high encoder;object feature pollution;object location information;object scale;PD loss function;polluted object information;pooling distance;shape information;upsampling phases;vision-based aerial tracking","","","","59","IEEE","16 Dec 2022","","","IEEE","IEEE Journals"
"Hyperspectral and Multispectral Image Fusion Under Spectrally Varying Spatial Blurs – Application to High Dimensional Infrared Astronomical Imaging","C. Guilloteau; T. Oberlin; O. Berné; N. Dobigeon","Institut de Recherche en Astrophysique et Planétologie (IRAP), University of Toulouse, 9 avenue du Colonel Roche, BP 44346, 31028, Toulouse, Cedex 4, France; DISC, ISAE-SUPAERO, University of Toulouse, Toulouse, France; Institut de Recherche en Astrophysique et Planétologie (IRAP), University of Toulouse, 9 avenue du Colonel Roche, BP 44346, 31028, Toulouse, Cedex 4, France; Institut Universitaire de France (IUF)","IEEE Transactions on Computational Imaging","22 Sep 2020","2020","6","","1362","1374","Hyperspectral imaging has become a significant source of valuable data for astronomers over the past decades. Current instrumental and observing time constraints allow direct acquisition of multispectral images, with high spatial but low spectral resolution, and hyperspectral images, with low spatial but high spectral resolution. To enhance scientific interpretation of the data, we propose a data fusion method which combines the benefits of each image to recover a high spatio-spectral resolution datacube. The proposed inverse problem accounts for the specificities of astronomical instruments, such as spectrally variant blurs. We provide a fast implementation by solving the problem in the frequency domain and in a low-dimensional subspace to efficiently handle the convolution operators as well as the high dimensionality of the data. We conduct experiments on a realistic synthetic dataset of simulated observation of the upcoming James Webb Space Telescope, and we show that our fusion algorithm outperforms state-of-the-art methods commonly used in remote sensing for Earth observation.","2333-9403","","10.1109/TCI.2020.3022825","ANR-3IA Artificial; Natural Intelligence Toulouse Institute; Conseil National de la Recherche Scientifique; Centre National d’Études Spatiales; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9199293","Data fusion;hyperspectral imaging;high dimensional imaging;infrared astronomy;super-resolution;deconvolution","Spatial resolution;Instruments;Imaging;Degradation;Hyperspectral imaging;Earth","astronomical image processing;astronomical instruments;astronomical telescopes;hyperspectral imaging;image fusion;image resolution;image restoration;image sensors;inverse problems;remote sensing;sensor fusion","instrumental time constraints;spectrally varying spatial blurs;hyperspectral images;low spectral resolution;multispectral images;direct acquisition;observing time constraints;astronomers;hyperspectral imaging;high dimensional infrared astronomical;fusion algorithm;low-dimensional subspace;spectrally variant blurs;astronomical instruments;inverse problem accounts;high spatio-spectral resolution datacube;data fusion method","","11","","46","IEEE","17 Sep 2020","","","IEEE","IEEE Journals"
"Target Reconstruction From Deceptively Jammed Single-Channel SAR","B. Zhao; L. Huang; J. Li; P. Zhang","College of Information Engineering, Shenzhen University, Shenzhen, China; College of Information Engineering, Shenzhen University, Shenzhen, China; Electrical and Computer Engineering Department, University of Florida, Gainesville, FL, USA; College of Information Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Geoscience and Remote Sensing","27 Dec 2017","2018","56","1","152","167","This paper considers the problem of reconstructing true targets in a single-channel synthetic aperture radar (SAR) imaging system, which has been disturbed by deceptive jammings. Since the deceptive jammings are usually confined to the main lobe of an SAR antenna, their time-frequency distributions are different from those of the true echoes. This enables us to utilize a dynamic synthetic aperture (DSA) scheme to extract the characteristics of the true and false targets. Dictionaries about the true and false targets are constructed by taking interactions between scatterers into account. Then a sparsity-driven optimization problem is solved to reconstruct the true and false targets separately with super-resolution. Moreover, the deceptively jammed SAR data are divided into different areas to handle various scenarios efficiently, and strategies for DSA selection are addressed as well. Simulations are provided to verify the effectiveness of the proposed algorithm.","1558-0644","","10.1109/TGRS.2017.2744178","National Natural Science Foundation of China(grant numbers:U1501253,61501485,61501300,61601300,61601304); China Postdoctoral Science Foundation(grant numbers:2015M582413,2017M610547); Natural Science Foundation of Guangdong Province, China(grant numbers:2015A030311030); Foundation of Shenzhen City(grant numbers:ZDSYS201507081625213,JCYJ20160520165659418,JCYJ20170302142545828,JCYJ20150324140036835); Foundation of Nanshan District Shenzhen City(grant numbers:KC2015ZDYF0023A); Shenzhen University(grant numbers:201557); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8036400","Deceptive jamming;dynamic synthetic aperture (DSA);sparse reconstruction;synthetic aperture radar (SAR)","Jamming;Synthetic aperture radar;Doppler effect;Image reconstruction;Azimuth;Image resolution;Signal resolution","jamming;radar imaging;synthetic aperture radar","single-channel SAR;target reconstruction;deceptively jammed SAR data;optimization problem;false targets;true targets;dynamic synthetic aperture scheme;time-frequency distributions;SAR antenna;deceptive jammings;single-channel synthetic aperture radar imaging system","","28","","36","IEEE","13 Sep 2017","","","IEEE","IEEE Journals"
"On Solving SAR Imaging Inverse Problems Using Nonconvex Regularization With a Cauchy-Based Penalty","O. Karakuş; A. Achim","Visual Information Laboratory, University of Bristol, Bristol, U.K.; Visual Information Laboratory, University of Bristol, Bristol, U.K.","IEEE Transactions on Geoscience and Remote Sensing","23 Jun 2021","2021","59","7","5828","5840","Synthetic aperture radar (SAR) imagery can provide useful information in a multitude of applications, including climate change, environmental monitoring, meteorology, high dimensional mapping, ship monitoring, or planetary exploration. In this article, we investigate solutions for several inverse problems encountered in SAR imaging. We propose a convex proximal splitting method for the optimization of a cost function that includes a nonconvex Cauchy-based penalty. The convergence of the overall cost function optimization is ensured through careful selection of model parameters within a forward–backward (FB) algorithm. The performance of the proposed penalty function is evaluated by solving three standard SAR imaging inverse problems, including super-resolution, image formation, and despeckling, as well as ship wake detection for maritime applications. The proposed method is compared to several methods employing classical penalty functions such as total variation (TV) and  $L_{1}$  norms, and to the generalized minimax-concave (GMC) penalty. We show that the proposed Cauchy-based penalty function leads to better image reconstruction results when compared to the reference penalty functions for all SAR imaging inverse problems in this article.","1558-0644","","10.1109/TGRS.2020.3011631","Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/R009260/1 (AssenSAR)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9160976","Cauchy proximal operator;convex optimization;denoising;image reconstruction;nonconvex regularization;synthetic aperture radar (SAR) imaging inverse problems","Inverse problems;TV;Synthetic aperture radar;Radar polarimetry;Image reconstruction;Imaging;Transforms;Climate change","concave programming;image reconstruction;image resolution;inverse problems;optimisation;radar imaging;ships;synthetic aperture radar","synthetic aperture radar imagery;climate change;environmental monitoring;high dimensional mapping;ship monitoring;planetary exploration;convex proximal splitting method;nonconvex Cauchy-based penalty;cost function optimization;forward-backward algorithm;standard SAR imaging inverse problems;image formation;ship wake detection;maritime applications;classical penalty;generalized minimax-concave penalty;Cauchy-based penalty function;image reconstruction results;reference penalty;solving SAR imaging inverse problems;nonconvex regularization","","13","","74","IEEE","6 Aug 2020","","","IEEE","IEEE Journals"
"3-D Object Imaging Method With Electromagnetic Vortex","J. Wang; K. Liu; H. Liu; K. Cao; Y. Cheng; H. Wang","College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China","IEEE Transactions on Geoscience and Remote Sensing","13 Dec 2021","2022","60","","1","12","The electromagnetic (EM) vortex imaging has demonstrated superior performance in target detection and imaging with azimuthal super-resolution. However, the restricted elevation resolution degrades the acquisition of target spatial information, which limits the development of the radar imaging technology based on orbital angular momentum (OAM). This article offers a solution to achieve the 3-D EM vortex imaging, by effectively utilizing relative motion between radar and target in the line-of-sight (LOS) direction. First, the forward-looking radar imaging scenario is presented, the 3-D echo model is derived, and the characteristics are analyzed as well. Second, the imaging method, based on the back-projection (BP) and spectrum estimation method, is proposed to obtain the target’s 3-D focused image. Furthermore, the influence factors about the elevation resolution are analyzed by the point spread function (PSF). Finally, simulations are carried out to verify the effectiveness of the theoretical analyses.","1558-0644","","10.1109/TGRS.2021.3069914","National Natural Science Foundation of China(grant numbers:61801486,61921001); Postdoctoral Innovative Talents Support Program of China(grant numbers:BX20190092); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9399665","3-D forward-looking radar imaging;electromagnetic (EM) vortex imaging;orbital angular momentum (OAM)","Imaging;Radar imaging;Image resolution;Azimuth;Radar tracking;Target tracking;Radar antennas","","","","8","","35","IEEE","9 Apr 2021","","","IEEE","IEEE Journals"
"Reweighted-Dynamic-Grid-Based Microwave Coincidence Imaging With Grid Mismatch","K. Cao; Y. Cheng; K. Liu; J. Wang; H. Liu; H. Wang","College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China","IEEE Transactions on Geoscience and Remote Sensing","12 Jan 2022","2022","60","","1","10","Microwave coincidence imaging (MCI) is a novel staring imaging technique with high resolution in azimuth. In MCI, the continuous imaging area is discretized into fine grids and the target-scattering centers are assumed to be exactly located at the centers of prediscretized grids. Recently, parametric methods are applied to MCI as target reconstruction algorithms with resolution enhancement and quality improvement. However, in practical applications, grid mismatch will severely degrade the imaging quality of parametric methods because the target-scattering centers will not totally locate at the grid centers no matter how fine the grids are. In this article, a reweighted-dynamic-grid-based MCI (RDG-MCI) method is proposed. In RDG-MCI, grids are evolving from coarse to dense iteratively rather than being fixed, and hence, off-grid errors can be eliminated gradually. Meanwhile, the reconstructed coefficients are used as weighting factors of grids in a form of weighting matrix in the next iteration and nonkey grids will be dropped out. Hence, the dynamic grids will be focused around the positions where target scatterers are most likely to exist. Furthermore, the matrix uncertain sparse Bayesian learning (MUSBL) algorithm is adopted to eliminate the residual off-grid errors. Finally, a preferable imaging result can be obtained based on the updated nonuniform grids. Also, the theoretical expected Cramér–Rao bound (ECRB) is also derived to evaluate the performance of the proposed method. The effectiveness of the proposed method, along with the super-resolution ability of MCI, is verified by simulations and outdoor experiments.","1558-0644","","10.1109/TGRS.2021.3086264","National Natural Science Foundation of China(grant numbers:61801486,61921001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9455128","Expected Cramér–Rao bound (ECRB);grid evolution;grid mismatch;high-resolution;matrix uncertain sparse Bayesian learning (MUSBL);microwave coincidence imaging (MCI)","Imaging;Radar imaging;Image resolution;Scattering;Image reconstruction;Microwave theory and techniques;Microwave imaging","Bayes methods;image reconstruction;image resolution;iterative methods;learning (artificial intelligence);matrix algebra;microwave imaging;radar imaging","grid mismatch;continuous imaging area;target-scattering centers;prediscretized grids;parametric methods;target reconstruction algorithms;imaging quality;grid centers;RDG-MCI;nonkey grids;dynamic grids;matrix uncertain sparse Bayesian learning algorithm;residual off-grid errors;reweighted-dynamic-grid-based microwave coincidence imaging;weighting matrix;theoretical expected Cramér-Rao bound;iteration grids;resolution enhancement;quality improvement","","4","","29","IEEE","15 Jun 2021","","","IEEE","IEEE Journals"
"Geolocation of RFIs by Multiple Snapshot Difference Method for Synthetic Aperture Interferometric Radiometer","R. Jin; L. Wu; Q. Li; H. Lu; L. Feng","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; China Academy of Space Technology, Xi’an, China; Collaborative Innovation Center of Industrial Bigdata, Hubei University of Technology, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","3 Dec 2021","2022","60","","1","12","The presence of unauthorized radio frequency interference (RFI) sources seriously affects the retrieval of brightness temperature of a synthetic aperture interferometric radiometer (SAIR). Postobservation RFI geolocation is important for improving the RFI situation hereafter and mitigating the impact of the identified RFIs. Previous works have demonstrated the potential of using high-/super-resolution direction-of-arrival (DOA) estimation techniques to achieve accurate localization of RFI sources in SAIR imagery. In this article, a multiple snapshot difference method is proposed to further reduce the RFI source geolocation bias. The covariance matrices of the consecutive snapshots with power changed RFIs are picked out and subtracted to cancel out the background scene. A MUSIC-based DOA algorithm is developed. Numerical simulations validate the theoretical correctness and the practical effectiveness of the proposed method.","1558-0644","","10.1109/TGRS.2020.3045088","National Natural Science Foundation of China (NSFC)(grant numbers:61771213,61801187); Opening Foundation of Science and Technology on Electronic Information Control Laboratory(grant numbers:6142105200302); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9318525","Geolocation;radio frequency interference (RFI);synthetic aperture interferometric radiometer (SAIR)","Covariance matrices;Correlation;Geology;Antenna measurements;Multiple signal classification;Earth;Antennas","covariance matrices;direction-of-arrival estimation;radiofrequency interference;radiometers;signal classification","multiple snapshot difference method;synthetic aperture interferometric radiometer;unauthorized radio frequency interference;brightness temperature;postobservation RFI geolocation;RFI situation;RFI sources;SAIR imagery;RFI source geolocation bias;consecutive snapshots;identified RFI;power changed RFI;direction-of-arrival estimation techniques;DOA estimation techniques;covariance matrices;background scene;MUSIC-based DOA algorithm","","2","","39","IEEE","8 Jan 2021","","","IEEE","IEEE Journals"
"Tomographic SAR Inversion by Atomic-Norm Minimization—The Gridless Compressive Sensing Approach","X. Wang; F. Xu","Key Laboratory of Radar Imaging and Microwave Photonics (MoE), Nanjing University of Aeronautics and Astronautics, Nanjing, China; Key Laboratory for Information Science of Electromagnetic Waves (MoE), Fudan University, Shanghai, China","IEEE Transactions on Geoscience and Remote Sensing","1 Dec 2022","2022","60","","1","13","Synthetic aperture radar (SAR) tomography (TomoSAR) extends the synthetic aperture principle into the elevation direction for 3-D imaging. Due to the sparsity of the elevation signal, compressive sensing (CS) methods have been introduced for tomographic reconstruction. However, the limited irregular acquisitions and the dense sampling grids of the elevation cannot guarantee the sufficiently sparse reconstruction in the presence of noise. By constructing a complete set of atoms, the gridless sparse methods can directly recover the sparse signals in the continuous frequency space. In this article, we propose the atomic-norm minimization or the gridless CS approach for tomographic SAR inversion and compare it with the L1-norm-based optimization. The enhanced sparsity, the super-resolution capability, and the more accurate estimates are demonstrated using the numerical simulations and experiments with real data. A gridless CS reconstruction of an urban area of Shanghai from the TerraSAR-X data set is presented.","1558-0644","","10.1109/TGRS.2022.3223524","Natural Science Foundation of China(grant numbers:62001216,61991422); Fund of the Key Laboratory of Radar Imaging and Microwave Photonics(grant numbers:NJ20220002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955576","Atomic-norm minimization (ANM);gridless compressive sensing (CS);synthetic aperture radar (SAR) tomography (TomoSAR);TerraSAR-X (TSX)","Imaging;Tomography;Synthetic aperture radar;Radar imaging;Image reconstruction;Minimization;Reflectivity","","","","","","47","IEEE","18 Nov 2022","","","IEEE","IEEE Journals"
"Generative Building Feature Estimation From Satellite Images","L. He; J. Shan; D. Aliaga","Department of Computer Science, Purdue University, West Lafayette, IN, USA; School of Civil Engineering, Purdue University, West Lafayette, IN, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA","IEEE Transactions on Geoscience and Remote Sensing","16 Feb 2023","2023","61","","1","13","Urban and environmental researchers seek to obtain building features (e.g., building shapes, counts, and areas) at large scales. However, blurriness, occlusions, and noise from prevailing satellite images severely hinder the performance of image segmentation, super-resolution, or deep-learning-based translation networks. In this article, we combine globally available satellite images and spatial geometric feature datasets to create a generative modeling framework that enables obtaining significantly improved accuracy in per-building feature estimation and the generation of visually plausible building footprints. Our approach is a novel design that compensates for the degradation present in satellite images by using a novel deep network setup that includes segmentation, generative modeling, and adversarial learning for instance-level building features. Our method has proven its robustness through large-scale prototypical experiments covering heterogeneous scenarios from dense urban to sparse rural. Results show better quality over advanced segmentation networks for urban and environmental planning, and show promise for future continental-scale urban applications.","1558-0644","","10.1109/TGRS.2023.3242284","National Science Foundation(grant numbers:1835739,1816514,2032770,2106717); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10036454","Building features;footprint;generative modeling;procedural modeling;satellite images","Buildings;Image segmentation;Satellites;Estimation;Superresolution;Image resolution;Task analysis","","","","","","66","IEEE","3 Feb 2023","","","IEEE","IEEE Journals"
"Rapid Surrogate Modeling of Electromagnetic Data in Frequency Domain Using Neural Operator","Z. Peng; B. Yang; Y. Xu; F. Wang; L. Liu; Y. Zhang","Key Laboratory of Geoscience Big Data and Deep Resource of Zhejiang Province, School of Earth Sciences, Zhejiang University, Hangzhou, China; Key Laboratory of Geoscience Big Data and Deep Resource of Zhejiang Province, School of Earth Sciences, Zhejiang University, Hangzhou, China; Key Laboratory of Geoscience Big Data and Deep Resource of Zhejiang Province, School of Earth Sciences, Zhejiang University, Hangzhou, China; College of Big Data and Software Engineering, Zhejiang Wanli University, Ningbo, China; Key Laboratory of Geoscience Big Data and Deep Resource of Zhejiang Province, School of Earth Sciences, Zhejiang University, Hangzhou, China; Key Laboratory of Geoscience Big Data and Deep Resource of Zhejiang Province, School of Earth Sciences, Zhejiang University, Hangzhou, China","IEEE Transactions on Geoscience and Remote Sensing","1 Dec 2022","2022","60","","1","12","The efficiency of solving geophysical inverse problem largely relies on the efficiency of solving the corresponding forward problem. As for electromagnetic (EM) data forward modeling in frequency domain, the conventional numerical methods, e.g., finite difference method (FDM), discretize the governing equations resulting in a large linear system which is usually expensive to solve. Meanwhile, for inversion iteration, we normally do not need to solve the forward problem in high precision. Thus, a rapid surrogate modeling approach which uses the neural network is promising for replacing the forward modeling module in the inversion scheme. Here, we proposed an algorithm which uses the neural operator to solve the EM data modeling problem in the frequency domain. To develop a surrogate model for EM data forward problem, we introduce an extended Fourier neural operator (EFNO) that enables the calculation at least 100 times faster than the conventional FDM solver while maintaining good precision. Moreover, by adding a subnetwork the proposed neural operator has good generalization which has the capacity of predicting solution at any site locations and frequencies. Due to the discretization invariance of Fourier neural operator, the neural operator trained on coarse grids can easily transfer to fine grids with only retraining part of parameters, resulting in a super-resolution prediction capability. We test our proposed method with 2-D and 3-D magnetotelluric (MT) data modeling problems, demonstrating that the EFNO has great potentials for severing as a general rapid surrogate forward solver in EM data inversion scheme.","1558-0644","","10.1109/TGRS.2022.3222507","National Key Research and Development Program of China(grant numbers:2018YFC0603604); NSFC(grant numbers:41774079,41830212); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9953140","Electromagnetic (EM) data;Fourier neural operator (FNO);magnetotelluric (MT);surrogate model","Neural networks;Data models;Conductivity;Mathematical models;Computational modeling;Numerical models;Frequency-domain analysis","","","","","","44","IEEE","16 Nov 2022","","","IEEE","IEEE Journals"
"Structure-Guaranteed SAR Imagery via Spatially-Variant Morphology Regularization in ADMM Manner","L. Yang; S. Chen; S. Huan; H. Li; M. Xing","Tianjin Key Laboratory for Advanced Signal Processing, Civil Aviation University of China, Tianjin, China; Tianjin Key Laboratory for Advanced Signal Processing, Civil Aviation University of China, Tianjin, China; School of Electronics and Communication Engineering, Guangzhou University, Guangzhou, China; Tianjin Key Laboratory for Advanced Signal Processing, Civil Aviation University of China, Tianjin, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","21 Sep 2022","2022","60","","1","14","Conventional sparsity-driven synthetic aperture radar (SAR) imagery proceeds via  $\ell _{1}$  regularization, or named by least absolute shrinkage and selection operator (LASSO). However, followed by the enhanced sparse feature, structures of the scenes or targets of interest in weak scattering are easily lost. Therefore, it becomes difficult to make use of the high-resolution SAR data, and even high costs have been paid for the resolution. In this article, a novel structure-guaranteed SAR (SG-SAR) imaging algorithm is proposed by utilizing the morphology metric for the cluster feature of the scatterers of the scenes/targets of interest. By introducing structural priors in terms of morphology norm, the intended structure features can be highlighted via convex regularization. More specifically, to accommodate complicated scenarios or targets, the structure element (SE) in the morphology regularizer is designed to be spatially variant under structure tensor representation. Different from conventional convex optimizations, the proposed SG-SAR algorithm is solved under the alternating direction method of multipliers (ADMMs), which is flexible to incorporate with the super-resolution imagery. In such cases, both sparse and structural features can be simultaneously enhanced, even with limited measurements and in a low signal-to-noise ratio (SNR). Superior convergence and robustness can be guaranteed. Moreover, a grouping mask scheme is used to accommodate the complex-valued SAR data. Finally, both simulated and measured SAR data are applied for the validation. Comparisons with the conventions are performed in terms of phase transition analysis, so as to verify the superiority of the proposed algorithm both qualitatively and quantitatively.","1558-0644","","10.1109/TGRS.2022.3197439","National Natural Science Foundation of China(grant numbers:62271487); National Science Fund for Distinguished Young Scholars(grant numbers:61825105); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9852479","Alternating direction method of multipliers (ADMMs);morphology regularization (MR);proximity operator;structure-guaranteed synthetic aperture radar (SG-SAR)","Synthetic aperture radar;Morphology;Radar polarimetry;Convex functions;Radar imaging;Image resolution;Bayes methods","","","","","","43","IEEE","8 Aug 2022","","","IEEE","IEEE Journals"
"Sentinel-2 Sharpening Using a Single Unsupervised Convolutional Neural Network With MTF-Based Degradation Model","H. V. Nguyen; M. O. Ulfarsson; J. R. Sveinsson; M. D. Mura","Department of Electrical and Electronic Engineering, Nha Trang University, Nha Trang, Vietnam; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Institut Universitaire de France, Paris, France","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","21 Jul 2021","2021","14","","6882","6896","The Sentinel-2 (S2) constellation provides multispectral images at 10 m, 20 m, and 60 m resolution bands. Obtaining all bands at 10 m resolution would benefit many applications. Recently, many model-based and deep learning (DL)-based sharpening methods have been proposed. However, the downside of those methods is that the DL-based methods need to be trained separately for the 20 m and the 60 m bands in a supervised manner at reduced resolution, while the model-based methods heavily depend on the hand-crafted image priors. To break the gap, this article proposes a novel unsupervised DL-based S2 sharpening method using a single convolutional neural network (CNN) to sharpen the 20 and 60 m bands at the same time at full resolution. The proposed method replaces the hand-crafted image prior by the deep image prior (DIP) provided by a CNN structure whose parameters are easily optimized using a DL optimizer. We also incorporate the modulation transfer function-based degradation model as a network layer, and add all bands to both network input and output. This setting improves the DIP and exploits the advantage of multitask learning since all S2 bands are highly correlated. Extensive experiments with real S2 data show that our proposed method outperforms competitive methods for reduced-resolution evaluation and yields very high quality sharpened image for full-resolution evaluation.","2151-1535","","10.1109/JSTARS.2021.3092286","Icelandic Research Fund(grant numbers:207233-051); University of Iceland Doctoral(grant numbers:1547-154305); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9464640","Convolutional neural networks (CNNs);image fusion;MTF-based degradation;Sentinel-2 image sharpening;super-resolution;unsupervised deep learning","Spatial resolution;Pansharpening;Electronics packaging;Image fusion;Hyperspectral imaging;Degradation;Training","convolution;feature extraction;image classification;image resolution;learning (artificial intelligence);neural nets;optical transfer function;unsupervised learning","Sentinel-2 sharpening;single unsupervised convolutional neural network;MTF-based degradation model;Sentinel-2 constellation;multispectral images;deep learning-based sharpening methods;reduced resolution;model-based methods;hand-crafted image priors;novel unsupervised DL-based S2 sharpening method;single convolutional neural network;deep image;modulation transfer function-based degradation model;network layer;network input;competitive methods;reduced-resolution evaluation;yields very high quality sharpened image;full-resolution evaluation;size 10.0 m;size 20.0 m;size 60.0 m","","9","","58","CCBY","24 Jun 2021","","","IEEE","IEEE Journals"
"Graph-Based Logarithmic Low-Rank Tensor Decomposition for the Fusion of Remotely Sensed Images","F. Ma; S. Huo; F. Yang","School of Electronic and Information Engineering, Liaoning Technical University, Huludao, China; School of Electronic and Information Engineering, Liaoning Technical University, Huludao, China; School of Electrical and Control Engineering, Liaoning Technical University, Huludao, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","16 Nov 2021","2021","14","","11271","11286","Hyperspectral images with high spatial resolution play an important role in material classification, change detection, and others. However, owing to the limitation of imaging sensors, it is difficult to directly acquire images with both high spatial resolution and high spectral resolution. Therefore, the fusion of remotely sensed images is an effective way to obtain high-resolution desired data, which is usually an ill-posed inverse problem and susceptible to noise corruption. To address these issues, a low-rank model based on tensor decomposition is proposed to fuse hyperspectral and multispectral images by incorporating graph regularization, in which the logarithmic low-rank function is utilized to suppress the small components for denoising. Furthermore, this article takes advantage of the local spatial similarity of remotely sensed images to enhance the reconstruction performance by constructing spatial graphs, and also promotes signature smoothing between adjacent endmember spectra using the neighborhood-based spectral graph regularization. Finally, a set of efficient solvers is carefully designed via alternating optimization for closed-from solutions and computational reduction, in which vector-matrix operators are adapted to solve the 3-D core tensor. Experimental tests on several real datasets illustrate that the proposed fusion method yields better reconstruction performance than the current state-of-the-art methods, and can significantly suppress noise at the same time.","2151-1535","","10.1109/JSTARS.2021.3123466","Scientific Research Project of Colleges from Liaoning Department of Education(grant numbers:LJKZ0357,LJ2019QL006,LJ2019JL022); NSFC General Project(grant numbers:61971210); Discipline Innovation Team of Liaoning Technical University(grant numbers:LNTU20TD-20,LNTU20TD-25); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9591494","Graph regularization;hyperspectral image (HSI) super-resolution;image fusion;low rank;tensor decomposition","Tensors;Spatial resolution;Image reconstruction;Hyperspectral imaging;Matrix decomposition;Superresolution;Sensors","","","","1","","56","CCBY","27 Oct 2021","","","IEEE","IEEE Journals"
"Spectral Quality Evaluation of Reconstructed Hyperspectral Images","S. Tang; Z. Chen; M. Zhang","Doctoral Students, Department of Computer Science and Electrical Engineering, University of Missouri, Kansas City; Associate Professor, Department of Civil and Mechanical Engineering, University of Missouri, Kansas City; Doctoral Students, Department of Computer Science and Electrical Engineering, University of Missouri, Kansas City","2021 11th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","19 Jul 2021","2021","","","1","5","With the advance in imaging optics, hyperspectral images (or cubes) have become low-cost and real-time for acquiring images in the field, specifically thanks to the recent development of different 'snapshot' hyperspectral imaging systems. However, cameras producing high resolutions in both the spectral domains and the spatial domains are still rare or considered to be high-cost. Algorithm-based pansharpening, or in general image reconstruction methods, are often used to create high spatial-resolution cubes by fusing high-spatial gray or color images and low spatial-resolution hyperspectral images. Moreover, most of these methods emphasized achieving high visual quality in spatial resolution but not considering the spectral accuracy in the reconstructed images. This paper aims to evaluate the spectral quality of reconstructed images from multiple methods. A commercial hyperspectral camera (Cubert S185) was used to conduct the research. Important conclusions include that spectral information is lost to different degrees per different reconstruction methods when the spatial resolution is raised too high. The trade-off between spatial sharpening and retaining spectral information is important for machine learning tasks.","2158-6276","978-1-6654-3601-4","10.1109/WHISPERS52202.2021.9483970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9483970","Hyperspectral image;Super Resolution;Spectrum analysis","Support vector machines;Visualization;Vegetation mapping;Cameras;Spatial resolution;Task analysis;Image reconstruction","cameras;hyperspectral imaging;image colour analysis;image fusion;image reconstruction;image resolution;learning (artificial intelligence)","high spatial-resolution cubes;high-spatial gray image fusion;machine learning tasks;Cubert S185;low spatial-resolution hyperspectral images;snapshot hyperspectral imaging systems;algorithm-based pan sharpening;hyperspectral image reconstruction methods;spectral information;spatial sharpening;commercial hyperspectral camera;spectral accuracy;spatial resolution;high visual quality;color images;general image reconstruction methods;spatial domains;spectral domains;imaging optics;spectral quality evaluation","","","","18","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"Fusion of Panchromatic and Multispectral Images Using Multiscale Convolution Sparse Decomposition","K. Zhang; F. Zhang; Z. Feng; J. Sun; Q. Wu","School of Information Science and Engineering, Shandong Normal University, Ji'nan, China; School of Information Science and Engineering, Shandong Normal University, Ji'nan, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi'an, China; School of Information Science and Engineering, Shandong Normal University, Ji'nan, China; College of Geography and Environment, Shandong Normal University, Ji'nan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","6 Jan 2021","2021","14","","426","439","In this article, we proposed a novel image fusion method based on multiscale convolution sparse decomposition (MCSD). A unified framework based on MCSD is first utilized to decompose panchromatic (PAN) image and the spatial component of upsampled low spatial resolution multispectral (LR MS) images, which can produce the corresponding low frequencies and feature maps. By combining convolution sparse decomposition with multiscale analysis, MCSD can efficiently approximate the spatial and spectral information in images. Next, a binary map generated from gradient information is utilized to integrate the low frequencies of LR MS and PAN images. For feature maps, the fusion gain for each pixel is calculated according to the similarity between the local patches from them. Finally, the fused image is reconstructed by the sum of fused low frequency and feature maps. Some experiments are conducted on QuickBird and GeoEye-1 satellite datasets. Compared with other methods, the proposed method performs better in visual and numerical evaluations.","2151-1535","","10.1109/JSTARS.2020.3043521","National Natural Science Foundation of China(grant numbers:61901246,U1736122); China Postdoctoral Science Foundation(grant numbers:2019TQ0190,2019M662432); Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education; Xidian University(grant numbers:IPIU2019008); Natural Science Foundation of Shandong Province(grant numbers:JQ201718); State Key Program of National Natural Science of China(grant numbers:61836009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288881","Convolution sparse representation (SR);image fusion;multiscale decomposition;multispectral (MS) image;panchromatic (PAN) image","High frequency;Image reconstruction;Transforms;Spatial resolution;Filtering theory;Convolution;Image fusion","geophysical image processing;geophysical techniques;image fusion;image resolution;remote sensing","fused low frequency;multiscale convolution sparse decomposition;image fusion method;MCSD;panchromatic image;spatial component;low spatial resolution multispectral images;multiscale analysis;binary map;fusion gain;fused image;QuickBird satellite dataset;GeoEye-1 satellite dataset","","5","","63","CCBY","9 Dec 2020","","","IEEE","IEEE Journals"
"GLRT Based on Support Estimation for Multiple Scatterers Detection in SAR Tomography","A. Budillon; G. Schirinzi","Dipartimento di Ingegneria, Centro Direzionale di Napoli, Universitá degli Studi di Napoli “Parthenope,”, Napoli, Italy; Dipartimento di Ingegneria, Centro Direzionale di Napoli, Universitá degli Studi di Napoli “Parthenope,”, Napoli, Italy","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","23 Feb 2016","2016","9","3","1086","1094","In this paper, a generalized likelihood ratio test (GLRT) detector, based on support estimation (Sup-GLRT), for multiple scatterers detection in SAR Tomography, is proposed. It incorporates, in the statistical model, a sparsity assumption of the signal in the elevation direction, which is always verified in practical cases for scarcely vegetated areas. The test consists of sequential steps: first the presence of scatterers is detected; then, the determination of the number of scatterers and the estimation of their positons is performed sequentially, one by one, by means of a signal support detection-estimation operation. The test proposed follows an approach similar to SGLRT, where decisions are taken based on subspace energy measurements, but it is derived following a different testing order and is investigated both at the nominal system resolution and in the super-resolution cases, showing in the latter case, a detection gain with respect to SGLRT. Sup-GLRT performance is evaluated in terms of receiver operating characteristic (ROC) curves for different signal-to-noise ratio values. Experimental results obtained on real COSMO-SkyMed data are shown.","2151-1535","","10.1109/JSTARS.2015.2494376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7346407","Generalized likelihood ratio test (GLRT);radar detection;sparse signals;synthetic aperture radar (SAR);tomography;Generalized likelihood ratio test (GLRT);radar detection;sparse signals;synthetic aperture radar (SAR);tomography","Estimation;Signal resolution;Synthetic aperture radar;Tomography;Spatial resolution;Earth","radar detection;radar receivers;radar resolution;synthetic aperture radar;tomography","GLRT detector;generalized likelihood ratio test detector;Sup-GLRT;multiple scatterer detection;SAR tomography;signal sparsity;elevation direction;signal support detection operation;signal support estimation operation;subspace energy measurement;nominal system resolution;nominal system super-resolution;receiver operating characteristic curve;ROC curve;signal-to-noise ratio;synthetic aperture radar","","55","","21","IEEE","3 Dec 2015","","","IEEE","IEEE Journals"
"Improving the Spatial Resolution of FY-3 Microwave Radiation Imager via Fusion With FY-3/MERSI","H. Song; G. Wang; A. Cao; Q. Liu; B. Huang","Jiangsu Key Laboratory of Big Data Analysis Technology, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China; Collaborative Innovation Center on Forecast and Evaluation of Meteorological Disasters, Nanjing University of Information Science and Technology, Nanjing, China; Shanghai Institute of Satellite Engineering, Shanghai, China; Jiangsu Key Laboratory of Big Data Analysis Technology, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China; Chinese University of Hong Kong, Hong Kong","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","2 Aug 2017","2017","10","7","3055","3063","This paper proposes an effective approach to improve the spatial resolution of FengYun-3 (FY-3) microwave radiation imager (MWRI) data via fusing with FY-3 medium-resolution imager (MERSI) data. Located onboard the same satellite FY-3, the complementary properties of MWRI and MERSI, such as cloud penetrating ability and high spatial resolution, are explored to extend the applications of MWRI data to mesoscale or microscale. To this end, we make efforts to improve the spatial resolution of MWRI data by combining the spatial information and spectral information from MERSI and MWRI, respectively. The proposed fusion procedure includes two stages. In the first stage, the MERSI and MWRI images are jointly spectrally unmixed via learning a spectral dictionary pair, and then the spatial information from MERSI is transferred into MWRI by sparse coding, resulting in a spatial resolution enhanced MWRI image. In the second stage, the spectral information of the spatial resolution enhanced MWRI image is enhanced through guided filtering. To form a unified fusion framework for both the cloud-free and cloud-contaminated cases in MERSI images, we propose to leverage a learning-based single image super-resolution method in the cloud-contaminated case, which learns a spatial dictionary pair from the MWRI image pairs of low and high spatial resolutions obtained in the cloud-free case. To the best of our knowledge, the proposed method is the first fusion based one for spatial resolution enhancement of microwave radiometer images. Finally, to assess the performance of the proposed fusion framework, we choose three MERSI-MWRI image pairs to evaluate in both the cloud-free and cloud-contaminated cases. Both visual comparisons and quantitative evaluations validate the effectiveness of the proposed fusion method in preserving the spatial information of MERSI and the spectral information of MWRI. Comparisons with a state-of-the-art method that does not resort to optical data, demonstrate the superiority of the pro-posed method with better overall measurements for experimental results.","2151-1535","","10.1109/JSTARS.2017.2665524","Natural Science Foundation of China(grant numbers:41501377,41561124014,41375099,41371417); Foundation of Jiangsu Province of China(grant numbers:Grant BK20150906,Grant 15KJB170012,Grant 15KJA520001); BDAT Nanjing University of Information Science and Technology(grant numbers:KXK1406); HKRGC General Research Fund(grant numbers:14606315); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872436","FY-3 microwave radiation imager (MWRI);FY-3/medium-resolution imager (MERSI);guided filtering;spatial resolution (SR);spectral unmixing","Microwave radiometry;Spatial resolution;Microwave imaging;Microwave theory and techniques;Clouds;Optical imaging;Adaptive optics","atmospheric techniques;clouds;geophysical image processing;image fusion;image resolution;weather forecasting","optical data;visual comparisons;learning-based single image super-resolution method;cloud-free evaluation;MERSI-MWRI image fusion;microwave radiometer image;spatial resolution enhancement;cloud-free case;cloud-contaminated case;spectral information;spatial information;cloud-penetrating ability;MWRI data;FY-3 microwave radiation imager","","11","","32","IEEE","6 Mar 2017","","","IEEE","IEEE Journals"
"Deep Learning-Based Enhancement of Hyperspectral Images Using Simulated Ground Truth","A. Nikonorov; M. Petrov; S. Bibikov; V. Kutikova; P. Yakimov; A. Morozov; R. Skidanov; N. Kazanskiy","Image Processing Systems, Institute of RAS, Samara, Russia; Image Processing Systems, Institute of RAS, Samara, Russia; Image Processing Systems, Institute of RAS, Samara, Russia; Image Processing Systems, Institute of RAS, Samara, Russia; Image Processing Systems, Institute of RAS, Samara, Russia; Image Processing Systems, Institute of RAS, Samara, Russia; Image Processing Systems, Institute of RAS, Samara, Russia; Image Processing Systems, Institute of RAS, Samara, Russia","2018 10th IAPR Workshop on Pattern Recognition in Remote Sensing (PRRS)","11 Oct 2018","2018","","","1","9","The paper addresses the problem of imaging quality enhancement for the Offner hyperspectrometer using a convolutional neural network. We use a deep convolutional neural network with residual training and PReLU activation, inspired by the super-resolution task for RGB images. In the case of hyperspectral imaging, it is often a problem to find a large enough ground truth dataset for training a neural network from scratch. Transfer learning using the network pretrained for RGB images with some pre- and postprocessing is one of the possible workarounds. In this paper, we propose to simulate the necessary ground truth data using non-imaging spectrometer. The obtained dataset with partially simulated ground truth is then used to train the convolutional neural network directly for hyperspectral image quality enhancement. The proposed training approach also allows to incorporate distortions specific for hyperspectral images into the enhancement procedure. It allows to successfully remove the striping distortions inherent to the Offner scheme of image acquisition. The experimental results of the proposed approach show a significant quality gain.","2377-0198","978-1-5386-8479-5","10.1109/PRRS.2018.8486408","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8486408","imaging hyperspectrometer;convolutional neural networks;Offner scheme;training from scratch;hyperspectral image enhancement","Distortion;Optical distortion;Hyperspectral imaging;Training;Task analysis;Imaging;Neural networks","convolution;feedforward neural nets;geophysical image processing;image colour analysis;image enhancement;image resolution;learning (artificial intelligence);spectrometers","deep convolutional neural network;residual training;super-resolution task;RGB images;nonimaging spectrometer;partially simulated ground truth;hyperspectral image quality enhancement;image acquisition;deep learning-based enhancement;Offner hyperspectrometer;PReLU activation;transfer learning;striping distortions","","3","","31","IEEE","11 Oct 2018","","","IEEE","IEEE Conferences"
"Hyperspectral and Multispectral Data Fusion via Joint Local-Nonlocal Modeling and Truncation Operator","J. Jiang; Y. Feng; H. Xu; G. Shen; J. Zheng","College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","2 Aug 2022","2022","15","","5880","5893","Fusion technology has been the core strategy to obtain a high-spatial-spectral resolution hyperspectral image (HSI). In recent years, few fusion models focused on exploiting the underlying manifold structure in the spatial dimension of the high-resolution HSI. We assume that image patches of high-resolution multispectral image (HR-MSI) and high-resolution hyperspectral image (HR-HSI) share similar manifold structures. Through this bridge, a local-nonlocal low-dimensional manifold defined from HR-MSI is built to favor the patch relationship in HR-HSI, which is further utilized to build a set of orthogonal bases. Subsequently, we introduce a truncation operation based on the adaptively constructed orthogonal bases, which can efficiently preserve the low-frequency information of the image and reduce the interference of noise. Finally, we combine the local-nonlocal manifold term and the truncation operation, coined as LNTM, into a variational super-resolution framework to regularize the latent HR-HSI, leading to a strongly convex function regarding the fusion problem. The cost function is solved by a carefully designed variant of alternating direction method of multipliers algorithm. Different experiments on three public benchmarks validate our algorithm outperforms the recent start-of-the-arts concerning both visual quality and numerical metrics.","2151-1535","","10.1109/JSTARS.2022.3190935","National Key Research and Development Program of China(grant numbers:2018YFE0126100); National Natural Science Foundation of China(grant numbers:61602413,62073295); Open Research Projects of Zhejiang Lab(grant numbers:2019KD0AD01/007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9829822","Hyperspectral images (HSIs);image fusion;manifold model;patch-based method;superresolution","Manifolds;Tensors;Spatial resolution;Hyperspectral imaging;Dictionaries;Sparse matrices;Matrix decomposition","convex programming;data fusion;geophysical image processing;hyperspectral imaging;image fusion;image resolution;spectral analysis","variational super-resolution framework;multispectral data fusion;alternating direction method of multipliers algorithm;LNTM;convex function;latent HR-HSI;local-nonlocal manifold term;truncation operation;orthogonal bases;low-dimensional manifold;similar manifold structures;HR-MSI;high-resolution multispectral image;image patches;spatial dimension;high-spatial-spectral resolution hyperspectral image","","1","","43","CCBY","14 Jul 2022","","","IEEE","IEEE Journals"
"Fast Total Variation Superresolution Method for Radar Forward-Looking Imaging","Q. Zhang; Y. Zhang; Y. Zhang; Y. Huang; W. Li; J. Yang","University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China; University of Electronic Science and Technology of China, Chengdu, Sichuan, P.R. China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","6571","6574","Total variation (TV) method has been utilized to realize super-resolution and preserve contour information of target in radar forward-looking imaging. However, its real-time ability is restricted to matrix inversion. In this paper, a fast TV (FTV) superresolution method is proposed to improve the real-time superresolution ability of traditional TV method. The proposed FTV method utilizes the low displacement rank features of Toplitz matrix and realizes fast matrix inversion by Gohberg-Semencul (GS) representation. It not only effectively improves the azimuth resolution and preserve the contour information of target, but also reduced the computational complexity of traditional TV method to improve its real-time superresolution ability. The superior performance of the proposed FTV method is verified by simulation and measured data processing.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323315","National Natural Science Foundation of China(grant numbers:61901090,61901092,61671117); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323315","Superresolution;total variation;radar imaging;Gohberg-Semencul representation;Toeplitz","TV;Radar imaging;Superresolution;Imaging;Radar;Azimuth;Signal resolution","","","","","","7","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Joint Convolutional Neural Network for Small-Scale Ship Classification in SAR Images","Y. Wu; Y. Yuan; J. Guan; L. Yin; J. Chen; G. Zhang; P. Feng","College of Computer Science and Technology, Harbin Engineering University, Harbin, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, China; China Industrial Control Systems Cyber Emergency Response Team, Beijing, China; The 54th Research Institute of China Electronics Technology Group Corporation, Shijiazhuang, China; China Industrial Control Systems Cyber Emergency Response Team, Beijing, China; State Key Laboratory of Space-Ground Integrated Information Technology, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2619","2622","Ship classification using synthetic aperture radar (SAR) imagery is a challenge problem in maritime surveillance. Because of the scale limitation of ship targets in SAR image, convolutional neural networks (CNNs) can not achieve similar performance as for natural image classification. In this paper, we propose a joint CNNs framework for small-scale ship targets classification in SAR image, where a generator and a classifier are jointly connected. The generator can reconstruct the small-scale low-resolution (LR) images to large-scale super-resolution (SR) images, and the classifier is used for ship classification. A novel joint loss optimization strategy is introduced to solve the problem, where an MSE-based content loss is employed to generate high quality SR images, and a classification loss is applied to enable the generator and the classifier to be trained in a joint way. Experiments are conducted to demonstrate the superior performance of our proposed method, as compared with the state-of-the-art methods.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8897831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897831","SAR image processing;ship classification;convolutional neural networks;joint optimization","Marine vehicles;Generators;Synthetic aperture radar;Containers;Radar polarimetry;Convolutional neural networks;Training","convolutional neural nets;image classification;image resolution;mean square error methods;optimisation;radar computing;radar imaging;search radar;ships;synthetic aperture radar","small-scale ship classification;SAR imaging;synthetic aperture radar imagery;convolutional neural networks;natural image classification;joint loss optimization strategy;joint CNN framework;small-scale low-resolution imaging;large-scale superresolution imaging;LR imaging;SR imaging;MSE-based content loss","","9","","11","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"SAR Tomography of Urban Areas: 3D Regularized Inversion in the Scene Geometry","C. Rambour; L. Denis; F. Tupin; J. -M. Nicolas; H. Oriot","LTCI, Université Paris Saclay, Paris, France; Univ Lyon, Laboratoire Hubert Curien UMR 5516, SAINT-ETIENNE, France; LTCI, Université Paris Saclay, Paris, France; LTCI, Université Paris Saclay, Paris, France; ONERA, The French Aerospace Lab, Palaiseau, France","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","6095","6098","Starting from a stack of co-registered SAR images in interferometric configuration, SAR tomography performs a reconstruction of the reflectivity of scatterers in 3-D. Scatterers seen within the same resolution cell in each SAR image can be separated by jointly unmixing the SAR complex amplitude observed throughout the stack. In urban areas, Compress Sensing (CS) approaches have been applied to achieve super-resolution in the estimation of the position of the scatterers. However, even if all the local information coming from a stack at a given pixel is used, the structural information that is inherent to the image is not directly used to improve the rendering of the scene. This paper addresses the problem of adding structural constraints to sparse tomographic reconstructions of urban areas. We derive an algorithm allowing the inversion of tomographic data under structural constraints and illustrate its performances on a stack of Spotlight TerraSAR-X images.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518448","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518448","SAR tomography;structural information;spatial regularization","Tomography;Geometry;Three-dimensional displays;Urban areas;Sensors;Image resolution;Image reconstruction","image reconstruction;image resolution;radar imaging;synthetic aperture radar;tomography","compress sensing approaches;Spotlight TerraSAR-X images;tomographic reconstructions;structural constraints;structural information;local information;SAR complex amplitude;SAR image;resolution cell;interferometric configuration;co-registered SAR images;3D regularized inversion;urban areas;SAR tomography","","3","","6","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"BI-Directional Processing Algorithm with RPM and WKD Based Doppler Velocity Estimator for 3-D Doppler-Radar Imaging","T. Hayashi; S. Kidera","Graduate School of Informatics and Engineering, The University of Electro-Communications, Japan; Japan Society Science and Technology (JST), PRESTO, Japan","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","2336","2339","Super-resolution and highly accurate Doppler and imaging algorithm for microwave or millimeter wave (MMW) short range radar is presented here. As human body detection or recognition in self-driving, through-the-wall imaging, or security system, the micro-Doppler analysis is one of the promising approaches. In the previous study, we have proposed an innovative Doppler velocity estimation, named as weighted kernel density (WKD) estimator, which simultaneously achieves higher temporal and Doppler velocity resolutions. This paper focuses on bi-directional processing between the WKD based Doppler velocity estimator and the range points migration (RPM) based radar imaging, so that both estimation accuracies could be enhanced. 3-D Numerical simulation demonstrate the effectiveness of our method.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323981","JST, PRESTO(grant numbers:JP-MJPR1771); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323981","Millimeter wave (MMW) radar;Pulse Doppler-radar;Three-dimensional (3-D) imaging","Doppler effect;Radar imaging;Estimation;Doppler radar;Imaging;Millimeter wave radar;Bidirectional control","Doppler radar;image recognition;image resolution;millimetre wave radar;numerical analysis;object detection;radar imaging;radar resolution","imaging algorithm;human body detection;through-the-wall imaging;microDoppler analysis;innovative Doppler velocity estimation;weighted kernel density estimator;temporal Doppler velocity resolutions;estimation accuracies;bI-directional processing algorithm;RPM;3D Doppler-radar imaging;microwave short range radar;millimeter wave short range radar;human body recognition;security system;WKD estimator;range points migration;3D numerical simulation","","2","","6","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Inversion of Deep Networks for Modelling Variations in Spatial Distributions of Land Cover Classes Across Scales","P. V. Arun; K. M. Buddhiraju; A. Porwal","Centre of Studies in Resources Engineering, Indian Institute of Technology, Bombay; Centre of Studies in Resources Engineering, Indian Institute of Technology, Bombay; Centre of Studies in Resources Engineering, Indian Institute of Technology, Bombay","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","7129","7132","In this paper, we propose the use of network inversion for modeling the variation of class distributions with scale. Unlike the state of the art methods that predict the mapping between coarser and finer scale patches without considering the distributions at coarser scale, our approach uses coarser scale features for effective reconstruction. This is the pioneer work of using network inversion for the purpose. Analysis over the proposed framework reveals that both the computational performance and accuracy varies with the depth of the network as well as the size and number of filters in each layer. Also the performance of the approach has been found to improve with the increase in the number of input feature maps. Investigations over standard datasets indicate that the proposed approach performs much better than the recent sub-pixel classification as well as super resolution techniques.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518917","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518917","Convolution Neural Network;scale;class distribution","Convolution;Spatial resolution;Streaming media;Image reconstruction;Hyperspectral imaging;Standards","geophysical image processing;image reconstruction;land cover;learning (artificial intelligence)","input feature maps;computational performance;finer scale patches;class distributions;network inversion;land cover classes;spatial distributions;modelling variations;deep networks","","1","","13","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Deep Sparse and Low-Rank Prior for Hyperspectral Image Denoising","H. V. Nguyen; M. O. Ulfarsson; J. Sigurdsson; J. R. Sveinsson","Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1217","1220","Spectral and spatial correlation in hyperspectral images (HSIs) can be exploited in HSI processing because it directly induces a sparse and low-rank prior via linear transformations. Researchers have used the sparse and low-rank prior as an image prior for HSI restoration, such as denoising, deblurring, and super-resolution. This paper proposes a HSI denoising method that incorporates a sparse and low-rank prior with a deep image prior (DIP). The sparse and low-rank prior is obtained using the 2-dimensional discrete wavelet transform (2-D DWT), and singular value decomposition (SVD), while the DIP is provided by the structure of a convolutional neural network (CNN). The combination of a sparse and low-rank prior with a DIP views the CNN-based denoising method similar to a model-based method, inheriting the advantages of both model-based and CNN-based methods. Experimental results with simulated and real HSI datasets show that the proposed method outperforms the conventional sparse and low-rank based methods in both quantitative and qualitative performance. Codes are available at https://github.com/hvn2/DIP-SLR","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884071","Hyperspectral image;denoising;sparsity;low-rank approximation;wavelets;unsupervised CNN","Correlation;Noise reduction;Superresolution;Transforms;Discrete wavelet transforms;Convolutional neural networks;Spectral analysis","approximation theory;discrete wavelet transforms;geophysical image processing;hyperspectral imaging;image denoising;image representation;image restoration;neural nets;singular value decomposition;wavelet transforms","model-based method;CNN-based methods;simulated HSI datasets;real HSI datasets;conventional sparse rank based methods;low-rank based methods;deep sparse;hyperspectral image denoising;spectral correlation;spatial correlation;hyperspectral images;HSI processing;linear transformations;HSI restoration;HSI denoising method;deep image;2-dimensional discrete wavelet","","1","","11","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Statistical Analysis for Improvement of Double Persistent Scatterers Detection in SAR Tomography","C. DĂNIŞOR; G. Fornaro; A. Pauciullo; M. Datcu",University Politehnica of Bucharest; National Research Council of Italy; National Research Council of Italy; University Politehnica of Bucharest,"IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","6746","6749","Synthetic Aperture Radar (SAR) tomography presents the advantage of multiple stable targets detection within same pixel. Fast-sup-GLRT (generalized likelihood ratio test based on support estimation) algorithm proved to be an ideal compromise between detection capabilities and computational complexity. In this work, a multi-look version of this detector which exploits the advantages of Capon estimation is examined. Statistical analysis of estimation and detection processes are conducted to compare the performances of sequential non-linear least-squares (NLLS) search and Capon filtering of projected data for double PS identification. Main objective is to exploit the super-resolution advantages of NLLS method without the risk of multiple stable targets classification from the same scattering contribution. For the last desiderate, an additional verification is included within the detection step.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518752","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518752","SAR Tomography;fast-sup-GLRT;PS detection;Capon filtering;Non-Linear Lesast-Squares","Estimation;Filtering;Reflectivity;Histograms;Detectors;Synthetic aperture radar;Image resolution","estimation theory;filtering theory;image resolution;least squares approximations;maximum likelihood detection;radar detection;radar imaging;statistical analysis;synthetic aperture radar;tomography","synthetic aperture radar tomography;generalized likelihood ratio test based on support estimation algorithm;multilook version;nonlinear least squares search;Capon filtering;Capon estimation;computational complexity;multiple stable targets detection;SAR tomography;double persistent scatterers detection;statistical analysis","","","","8","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Retinex-Based Low-Light Hyperspectral Restoration Using Camera Response Model","N. Liu; Y. Wang; Y. Yang; W. Li; R. Tao","School of Information and Electronics, Beijing Institute of Technology; School of Information and Electronics, Beijing Institute of Technology; School of Information and Electronics, Beijing Institute of Technology; School of Information and Electronics, Beijing Institute of Technology; School of Information and Electronics, Beijing Institute of Technology","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","3323","3326","Spectral quality is one of the most critical issues that has to be considered in real hyperspectral image (HSI) application. Denoising, destriping, inpainting, deblurring and super-resolution are common techniques to improve the quality of HSIs from different aspects. These techniques have attracted much attention that a diversity of methods, algorithms, tools have been well developed to facilitate the development of HSI restoration. Although effectively improving the quality of HSIs, these technologies mainly focus on recovering an HSI captured in the normal sunlight. It is acknowledged that HSIs are captured via passive imaging mechanisms covering the spectral bands from visible& near-infrared to shortwave infrared spectral range (i.e., around 400nm to 2500nm). The imaging condition limits HSI spectrometers to capture HSIs without sunlight (e.g., in dark environments or night time). In this work, a low-light HSI restoration method is proposed, where we borrow idea of intrinsic decomposition based on Retinex theory in natural image low-light enhancement. Additionally, camera response function that describe the spectral degradation of RGB image and relationship between irradiance and pixel values are employed, respectively. The experimental results validate the effectiveness of the proposed method.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884021","Beijing Natural Science Foundation(grant numbers:JQ20021); National Natural Science Foundation of China(grant numbers:61922013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884021","hyperspectral imagery;intrinsic decomposition;low-light restoration;Retinex;low-rank tensor approximation","Reflectivity;Tensors;Laplace equations;Superresolution;Noise reduction;Cameras;Robustness","biomedical optical imaging;cameras;hyperspectral imaging;image colour analysis;image denoising;image enhancement;image resolution;image restoration;medical image processing","Retinex-based low-light hyperspectral restoration;camera response model;spectral quality;hyperspectral image application;normal sunlight;image superresolution;passive imaging mechanisms;spectral bands;shortwave infrared spectral range;imaging condition;HSI spectrometers;low-light HSI restoration method;Retinex theory;natural image low-light enhancement;camera response function;spectral degradation;image denoising;image destriping;image inpainting;image deblurring;near-infrared spectral range;visible spectral range;intrinsic decomposition;RGB image;irradiance;pixel values","","","","9","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Unsupervised Hyperspectral and Multispectral Images Fusion Based on Nonlinear Variational Probabilistic Generative Model","Z. Wang; B. Chen; H. Zhang; H. Liu","National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China","IEEE Transactions on Neural Networks and Learning Systems","3 Feb 2022","2022","33","2","721","735","Due to hardware limitations, it is challenging for sensors to acquire images of high resolution in both spatial and spectral domains, which arouses a trend that utilizing a low-resolution hyperspectral image (LR-HSI) and a high-resolution multispectral image (HR-MSI) to fuse an HR-HSI in an unsupervised manner. Considering the fact that most existing methods are restricted by using linear spectral unmixing, we propose a nonlinear variational probabilistic generative model (NVPGM) for the unsupervised fusion task based on nonlinear unmixing. We model the joint full likelihood of the observed pixels in an LR-HSI and an HR-MSI, both of which are assumed to be generated from the corresponding latent representations, i.e., the abundance vectors. The sufficient statistics of the generative conditional distributions are nonlinear functions with respect to the latent variable, realized by neural networks, which results in a nonlinear spectral mixture model. For scalability and efficiency, we construct two recognition models to infer the latent representations, which are parameterized by neural networks as well. Simultaneously inferring the latent representations and optimizing the parameters are achieved using stochastic gradient variational inference, after which the target HR-HSI is retrieved via feedforward mapping. Though without supervised information about the HR-HSI, NVPGM still can be trained based on extra LR-HSI and HR-MSI data sets in advance unsupervisedly and processes the images at the test phase in real time. Three commonly used data sets are used to evaluate the effectiveness and efficiency of NVPGM, illustrating the outperformance of NVPGM in the unsupervised LR-HSI and HR-MSI fusion task.","2162-2388","","10.1109/TNNLS.2020.3028772","Program for Oversea Talent by the Chinese Central Government; Higher Education Discipline Innovation Project(grant numbers:B18039); NSFC(grant numbers:61771361); NSFC for Distinguished Young Scholars(grant numbers:61525105); Shaanxi Innovation Team Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9246732","Hyperspectral image (HSI);multispectral image (MSI);nonlinear fusion;probabilistic generative model;super-resolution","Hyperspectral imaging;Spatial resolution;Probabilistic logic;Task analysis;Sensors","feature extraction;geophysical image processing;hyperspectral imaging;image colour analysis;image fusion;image resolution;image sensors;remote sensing;spectral analysis;unsupervised learning","nonlinear variational probabilistic generative model;spatial domains;spectral domains;low-resolution hyperspectral image;high-resolution multispectral image;linear spectral unmixing;NVPGM;unsupervised fusion task;nonlinear unmixing;generative conditional distributions;nonlinear functions;neural networks;nonlinear spectral mixture model;recognition models;stochastic gradient variational inference;target HR-HSI;extra LR-HSI;unsupervised LR-HSI;HR-MSI fusion task","","3","","52","IEEE","2 Nov 2020","","","IEEE","IEEE Journals"
"Coprime Synthetic Aperture Radar Tomography","L. Yu; X. Huang; D. Feng; J. Wang","College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China","2021 2nd China International SAR Symposium (CISS)","28 Dec 2021","2021","","","1","6","This paper presents a synthetic aperture radar tomography (TomoSAR) technique able to reduce the number of acquisitions and, at the same time, to achieve super-resolution performance. The technique consists of a new baseline geometry and of a tailored reconstruction method. The new baseline is configured according to the coprime array geometry. Naturally, we name the proposed technique as the ""coprime TomoSAR"". The coprime acquisition mode requires fewer acquisitions than the uniform one for obtaining the same baseline aperture. To further improve tomographic resolution and to reject ambiguity problem induced by sparsely sampling of the coprime acquisition mode, we perform the tomographic reconstruction using the root-multiple signal classification (Root-MUSIC) algorithm. More important is that the Root-MUSIC algorithm can exploit the difference co-baseline in the tomographic reconstruction process. The exploition of the difference co-baseline ensures that the coprime TomoSAR provides comparable tomographic performance to the uniform TomoSAR when the two TomoSAR have the same baseline aperture length. This is validated by simulation experiments.","","978-7-0000-0000-1","10.23919/CISS51089.2021.9652324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652324","Coprime array;difference co-baseline;root-mlltiple signal classification(Root-MUSIC);synthetic aperture radar tomography(TomoSAR)","Geometry;Superresolution;Pattern classification;Tomography;Apertures;Reconstruction algorithms;Approximation algorithms","direction-of-arrival estimation;image reconstruction;image resolution;radar imaging;remote sensing by radar;signal classification;synthetic aperture radar;tomography","tomographic resolution;coprime acquisition mode;root-multiple signal classification algorithm;Root-MUSIC algorithm;difference co-baseline;tomographic reconstruction process;coprime TomoSAR;comparable tomographic performance;uniform TomoSAR;baseline aperture length;coprime synthetic aperture radar tomography;synthetic aperture radar tomography technique;super-resolution performance;baseline geometry;tailored reconstruction method;coprime array geometry;fewer acquisitions","","1","","24","","28 Dec 2021","","","IEEE","IEEE Conferences"
"Resolution Transfer for Object Detection from Satellite Imagery","F. Yellin; E. Smith; M. Albright; S. McCloskey","Kitware, Inc., Clifton Park, NY, USA; Kitware, Inc., Clifton Park, NY, USA; Kitware, Inc., Clifton Park, NY, USA; Kitware, Inc., Clifton Park, NY, USA","2022 26th International Conference on Pattern Recognition (ICPR)","29 Nov 2022","2022","","","449","456","Smallsat constellations are an increasingly common source of global-scale overhead imagery that are refreshed with a higher frequency than traditional satellites. The smaller size and lower cost of smallsats enable frequent revisits, but result in images with lower resolution and quality than the high resolution (HR) images from traditional satellites. In order to benefit from the increased temporal frequency provided by smallsat constellations, new approaches are needed to automatically detect objects in their imagery. We present a super resolution (SR) approach that incorporates domain adaptation (DA) to enable object detection from low resolution (LR) images without the need for paired training data or annotations in the LR domain. Our Resolution Transfer approach addresses the resolution and quality loss for smallsats, as demonstrated via airplane detection.","2831-7475","978-1-6654-9062-7","10.1109/ICPR56361.2022.9956559","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9956559","","Training;Airplanes;Visualization;Image resolution;Annotations;Small satellites;Training data","artificial satellites;geophysical image processing;image resolution;object detection;remote sensing;terrain mapping","airplane detection;domain adaptation;global-scale overhead imagery;high resolution images;LR domain;object detection;paired training data;resolution transfer approach;satellite imagery;smallsat constellations;super resolution approach;temporal frequency;traditional satellites","","","","39","IEEE","29 Nov 2022","","","IEEE","IEEE Conferences"
"UPSNet: Unsupervised Pan-Sharpening Network With Registration Learning Between Panchromatic and Multi-Spectral Images","S. Seo; J. -S. Choi; J. Lee; H. -H. Kim; D. Seo; J. Jeong; M. Kim","Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Samsung Advanced Institute of Technology, Suwon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Aerospace Research Institute, Daejeon, South Korea; School of Electrical Engineering, Korea Aerospace Research Institute, Daejeon, South Korea; School of Electrical Engineering, Korea Aerospace Research Institute, Daejeon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Access","18 Nov 2020","2020","8","","201199","201217","Recent advances in deep learning have shown impressive performances for pan-sharpening. Pan-sharpening is the task of enhancing the spatial resolution of a multi-spectral (MS) image by exploiting the high-frequency information of its corresponding panchromatic (PAN) image. Many deep-learning-based pan-sharpening methods have been developed recently, surpassing the performances of traditional pan-sharpening approaches. However, most of them are trained in lower scales using misaligned PAN-MS training pairs, which has led to undesired artifacts and unsatisfying visual quality. In this paper, we propose an unsupervised learning framework with registration learning for pan-sharpening, called UPSNet. UPSNet can be effectively trained in the original scales, and implicitly learns the registration between PAN and MS images without any dedicatedly designed registration module involved. Additionally, we design two novel loss functions for training UPSNet: a guided-filter-based color loss between network outputs and aligned MS targets; and a dual-gradient detail loss between network outputs and PAN inputs. Extensive experimental results show that our UPSNet can generate pan-sharpened images with remarkable improvements in terms of visual quality and registration, compared to the state-of-the-art methods.","2169-3536","","10.1109/ACCESS.2020.3035802","Korea Aerospace Research Institute (KARI) under the project of ‘Super-Resolution and PAN Colorization for Satellite Imagery’; KAIST; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9248047","Pan-sharpening;pan-colorization;image restoration;deep-learning;convolutional neural networks (CNN);satellite imagery","Training;Image color analysis;Satellites;Spatial resolution;Correlation;Unsupervised learning;Testing","geophysical image processing;image colour analysis;image registration;image resolution;neural nets;remote sensing;unsupervised learning","registration learning;network outputs;PAN inputs;unsupervised pan-sharpening network;multispectral image spatial resolution;panchromatic image;deep-learning-based pan-sharpening methods;misaligned PAN-MS training pairs;unsupervised learning framework;high-frequency information;guided-filter-based color loss;aligned MS targets;dual-gradient detail loss;UPSNet training","","11","","47","CCBY","4 Nov 2020","","","IEEE","IEEE Journals"
"A Novel Wireless Leaf Area Index Sensor Based on a Combined U-Net Deep Learning Model","H. Wang; Y. Wu; Q. Ni; W. Liu","College of Information Science and Technology, Nanjing Forestry University, Nanjing, China; College of Information Science and Technology, Nanjing Forestry University, Nanjing, China; School of Computing and Communications, Lancaster University, Lancaster LA1 4WA, InfoLab21, U.K; College of Automation, Nanjing University of Aeronautics and Astronautics, Nanjing, China","IEEE Sensors Journal","16 Aug 2022","2022","22","16","16573","16585","Leaf area index (LAI) is an important parameter for forestry vegetation canopy structure investigation and ecological environment model study. Traditional ground direct measuring method is too time and labor consuming, while the remote sensing technique lacks of adequate validation and comparative analysis. Here, a novel wireless LAI sensor based on a lightweight deep learning model (LAINET) has been designed with a Raspberry Pi microcomputer and a LoRa transceiver. The mainly metering pattern of sensor system is the digital hemispherical photo-graphy (DHP) methodology based on Beer-Lambert law: firstly, the crown canopy’s image is captured and segmented by LAINET, then the vegetation gap fraction can be extracted to calculate the LAI value. Our proposed LAINET consists of a lightweight convolutional neural network (CNN) and a generative adversarial network (GAN). The average accuracy of semantic segmentation (i.e. CNN part) could reach 0.978, and the combination of GAN for image super-resolution reconstruction can improve the accuracy of gap fraction measurement more by 5.5%. In addition, LAINET effectively solves the problem of low segmentation accuracy brought by environmental effects, the separation accuracy in direct sunlight or clear weather has been improved significantly. So the ultimate LAI value can be calculated precisely and stably. Experiment results show that the proposed sensor obtains a fine measuring error of less than 4% when comparing with the commercial plant canopy analyzer HM-G20. Combined with Uninterruptible Power Supply module of 5200 mAh, the sensor can work effectively for about 8 months, principally meeting the deployment and measurement criteria of forestry LAI. Therefore, the wireless sensor presented in this paper has a great application prospect.","1558-1748","","10.1109/JSEN.2022.3188697","National Science Foundation of China (NSFC)(grant numbers:32171788,31700478); Jiangsu Provincial Government Scholarship for Overseas Studies(grant numbers:JS-2018-043); Innovation and Entrepreneurship Training Program for College Students in Jiangsu Province (design and analysis of a wireless leaf area index sensor)(grant numbers:202110298089Y); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9827932","Leaf area index;canopy fisheye image;deep learning;wireless sensor;Raspberry Pi","Sensors;Forestry;Vegetation mapping;Image segmentation;Wireless sensor networks;Wireless communication;Monitoring","deep learning (artificial intelligence);geophysical equipment;microcomputers;vegetation mapping","wireless sensor;forestry LAI;measurement criteria;commercial plant canopy analyzer HM-G20;fine measuring error;ultimate LAI value;direct sunlight;separation accuracy;environmental effects;low segmentation accuracy;gap fraction measurement;image super-resolution reconstruction;CNN part;semantic segmentation;GAN;generative adversarial network;lightweight convolutional neural network;vegetation gap fraction;crown canopy;Beer-Lambert law;digital hemispherical photo-graphy methodology;sensor system;metering pattern;LoRa transceiver;Raspberry Pi microcomputer;LAINET;lightweight deep learning model;LAI sensor;comparative analysis;adequate validation;remote sensing technique;labor consuming;traditional ground direct measuring method;ecological environment model study;forestry vegetation canopy structure investigation;combined u-net deep;novel wireless leaf area index sensor;time 8.0 month","","","","38","IEEE","12 Jul 2022","","","IEEE","IEEE Journals"
"Vertical-Array-based Contour Reconstruction Algorithm for Airborne Weather Radar","Y. Wang; D. Wu; D. Zhu; F. Meng","Key Laboratory of Radar Imaging and Microwave Photonics, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Key Laboratory of Radar Imaging and Microwave Photonics, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Key Laboratory of Radar Imaging and Microwave Photonics, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Avic Leihua Electronic Technology Research Institute, China","2020 IEEE 11th Sensor Array and Multichannel Signal Processing Workshop (SAM)","10 Jun 2020","2020","","","1","5","Aiming at meteorological target, in this paper, a new contour reconstruction algorithm is proposed against the disastrous weather. The algorithm is capable of reconstructing the specific contour of meteorological target by exploiting vertical array of airborne weather radar system. First of all, Burg algorithm is utilized for the enhancement of beam spatial resolution in elevation dimension. Then, multi-beam algorithm is employed to form multiple beams and generate multiangle echoes, which further obtains more vertical contour information about weather scenario. Consequently the proposed algorithm, combining Burg algorithm and multi-beam algorithm, distinctly retrieves the vertical contour information and delivers a super-resolution behavior simultaneously. Using simulated radar data, the processing results demonstrate the validity of the presented algorithm. Compared with the so-called interpolation-based conventional methods, the proposed algorithm can achieve more comprehensive and accurate vertical contour reconstruction.","2151-870X","978-1-7281-1946-5","10.1109/SAM48682.2020.9104364","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9104364","Vertical array;airborne weather radar;multi-beam;vertical contour reconstruction","Meteorological radar;Array signal processing;Superresolution;Airborne radar;Signal processing algorithms;Reconstruction algorithms;Spatial resolution","airborne radar;atmospheric techniques;image reconstruction;image resolution;interpolation;meteorological radar;remote sensing by radar","simulated radar data;comprehensive contour reconstruction;accurate vertical contour reconstruction;vertical-array-based;meteorological target;contour reconstruction algorithm;disastrous weather;specific contour;vertical array;airborne weather radar system;Burg algorithm;beam spatial resolution;multibeam algorithm;multiple beams;vertical contour information;weather scenario","","","","17","IEEE","10 Jun 2020","","","IEEE","IEEE Conferences"
"Deep Precipitation Downscaling","T. Yu; Q. Kuang; J. Zheng; J. Hu","Public Meteorological Service Centre, China Meteorological Administration, Beijing, China; Public Meteorological Service Centre, China Meteorological Administration, Beijing, China; Public Meteorological Service Centre, China Meteorological Administration, Beijing, China; Public Meteorological Service Centre, China Meteorological Administration, Beijing, China","IEEE Geoscience and Remote Sensing Letters","15 Dec 2021","2022","19","","1","5","Precipitation downscaling, which is similar to the mechanism of single-image super-resolution (SR), aims to improve the spatial resolution of rain maps. It is of great practical value and theoretical significance. This letter presents a new deep precipitation downscaling (DPD) method, named auxiliary guided spatial distortion (AGSD) network, motivated by SR techniques. Specifically, an auxiliary guided module (AGM), which takes multiple meteorological elements (e.g., temperature, relative humidity, and wind) as input, is proposed for getting more accurate rain map features. Meanwhile, a simple but effective spatial distortion module (SDM) is proposed. Benefitting from SDM, the DPD model can rectify the rain map via terrain correlation. Furthermore, to improve the model performance among various rain intensity (including small rain, moderate rain, heavy rain, and storm), a threat score-driven pseudo threat-score (PTS) loss is presented. Experimental results compared with state-of-the-art methods demonstrate the superiority of the proposed method.","1558-0571","","10.1109/LGRS.2021.3049673","National Key Research and Development Program of China(grant numbers:2018YFC1507801,2018YFF0300105); National Natural Science Foundation of China(grant numbers:41871020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328842","Auxiliary guidance;precipitation downscaling;pseudo threat-score (PTS) loss;spatial–temporal analysis;weather forecasting","Rain;Estimation;Spatial resolution;Humidity;Image reconstruction;Distortion;Neural networks","","","","2","","27","IEEE","20 Jan 2021","","","IEEE","IEEE Journals"
"Contrast Source Inversion-Based Multilayered Object Analysis for Terahertz Wave Imaging","H. Morimoto; Y. Yamauchi; S. Kidera","Graduate School of Informatics and Engineering, University of Electro-Communications, Tokyo, Japan; Graduate School of Informatics and Engineering, University of Electro-Communications, Tokyo, Japan; Japan Science Technology Agency, Precursory Research for Embryonic Science and Technology (PRESTO), Saitama, Japan","IEEE Geoscience and Remote Sensing Letters","31 Dec 2021","2022","19","","1","5","A complex permittivity profile reconstruction for multilayered objects was presented in this study by incorporating compressed sensing (CS)-based thickness estimation with contrast source inversion (CSI) non-linear inverse scattering (IS) method using a terahertz (THz) frequency band. Several studies investigated permittivity estimation for multiple layers. However, they require a prior knowledge of the thickness of each layer. Moreover, a critical problem in this field is the simultaneous estimation of both the dielectric constant and the thickness of each layer. To address this, a super-resolution thickness estimator using a CS filter and the CSI-based dielectric profile reconstruction scheme was used. This problem was effectively solved by introducing the cost function estimated using the CSI scheme, where the number of layers is given. The finite-difference time-domain (FDTD) numerical test indicated that the proposed method provides an accurate estimation of the thickness and dielectric profile in double-layered objects.","1558-0571","","10.1109/LGRS.2021.3099199","Japan Science Technology Agency (JST), Precursory Research for Embryonic Science and Technology (PRESTO), Japan(grant numbers:JPMJPR1771); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9521954","Compressed sensing (CS);contrast source inversion (CSI);multilayer structure analysis;terahertz time-domain spectroscopic (THz-TDS) system","Permittivity;Estimation;Time-domain analysis;Cost function;Receivers;Numerical models;Finite difference methods","compressed sensing;electromagnetic wave scattering;finite difference time-domain analysis;image reconstruction;inverse problems;object detection;permittivity;terahertz wave imaging","CSI scheme;contrast source inversion;terahertz wave imaging;permittivity profile reconstruction;compressed sensing-based thickness estimation;nonlinear inverse scattering;CS filter;dielectric profile reconstruction;multilayered object analysis;finite-difference time-domain","","1","","19","IEEE","25 Aug 2021","","","IEEE","IEEE Journals"
"A Novel DOA Estimation for Low-Elevation Target Method Based on Multiscattering Center Equivalent Model","J. Ma; H. Ma; H. Liu; W. Liu; X. Cheng","National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; Key Laboratory of Electro-Optical Countermeasures Test and Evaluation Technology, Luoyang, China; Key Laboratory of Electro-Optical Countermeasures Test and Evaluation Technology, Luoyang, China","IEEE Geoscience and Remote Sensing Letters","16 Feb 2023","2023","20","","1","5","The multipath in very high-frequency (VHF) radar will reduce the direction-of-arrival (DOA) estimation accuracy for the low-angle target following. Since the target and multipath signals have strong coherence in the spatial domain, it is challenging to distinguish them accurately. Especially in some terrain complex regions, various scattering media cause the multipath echo to exhibit multichannel and nonuniform energy distribution features. Therefore, the single-multipath DOA estimation methods will mismatch the actual signal, resulting in inaccurate DOA estimation. The current letter presents a new DOA estimation approach using a multiple scattering center model in complex terrain to solve the mentioned issue. In the presented method, multiple multipath is analogous to a single one based on the multipath signal’s spatial coherence. The equivalent model represents the DOA estimation problem with a parametric optimization problem, and accurate estimation results can be attained using the Newton optimization approach. Compared with the conventional sparse reconstruction method, the presented method is not restricted by the restricted isometry property (RIP) and employs a robust parameter estimation method to solve the angle super-resolution problem under the low signal-to-noise ratio (SNR). The experimental results reflect that the presented model and approach can efficiently promote the DOA estimation precision and calculational performance compared to conventional DOA estimation approaches.","1558-0571","","10.1109/LGRS.2023.3242977","National Natural Science Foundation of China(grant numbers:61901344,62192714); Key Laboratory of Electro-Optical Countermeasures Test and Evaluation Technology Fund(grant numbers:GKCP2021002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10038731","Direction-of-arrival (DOA) estimation;low-angle target;multipath equivalent model;parameter optimization;very high-frequency (VHF) radar","Estimation;Direction-of-arrival estimation;Optimization;Radar;Signal to noise ratio;Superresolution;Maximum likelihood estimation","","","","","","24","IEEE","6 Feb 2023","","","IEEE","IEEE Journals"
"Noise robust time of arrival estimation method using hierarchical Bayesian based compressed sensing algorithm","A. Moro; F. Shang; S. Kidera; T. Kirimoto","Graduate School of Informatics and Engineering, The University of Electro-Communications, Japan; Graduate School of Informatics and Engineering, The University of Electro-Communications, Japan; Graduate School of Informatics and Engineering, The University of Electro-Communications, Japan; Graduate School of Informatics and Engineering, The University of Electro-Communications, Japan","2016 International Symposium on Antennas and Propagation (ISAP)","19 Jan 2017","2016","","","862","863","A microwave radar system is a useful tool for all-weather type remote sensing, such as terrain surface measurement. It is well known fact that a resolution of time-of-arrival (TOA) is strictly determined by the frequency bandwidth of transmitted signal. As super-resolution technique beyond such limitation, a compressed sensing (CS) algorithm has come under spotlight because a sparse assumption is well established in typical radar situations. However, the original CS method suffers from lower TOA resolution in insufficient SNR level. To address with such problem, this paper introduces a hierarchical Bayesian based CS algorithm. This method introduces the stochastic model derived from cross-correlation response as a priori information for CS reconstruction as hyper-prior distribution. The results of numerical simulation show that the proposed method enhances an accuracy for signal reconstruction, even in lower SNR situations.","","978-4-88552-313-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821535","Radar signal processing;Compressed sensing;TOA estimation;hierarchical Bayesian model","Bayes methods;Signal to noise ratio;Time of arrival estimation;Radar;Estimation;Compressed sensing;Signal resolution","Bayes methods;compressed sensing;correlation methods;meteorological radar;numerical analysis;radar signal processing;signal reconstruction;stochastic processes;time-of-arrival estimation","signal reconstruction;superresolution technique;frequency bandwidth;terrain surface measurement;all-weather type remote sensing;microwave radar system;CS reconstruction;compressed sensing algorithm;hierarchical Bayesian;TOA;time of arrival estimation method","","","","5","","19 Jan 2017","","","IEEE","IEEE Conferences"
"Learning Enriched Features for Fast Image Restoration and Enhancement","S. W. Zamir; A. Arora; S. Khan; M. Hayat; F. S. Khan; M. -H. Yang; L. Shao","Inception Institute of Artificial Intelligence, Abu Dhabi, UAE; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE; Mohammed Bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE; Monash Univeristy, Melbourne, VIC, Australia; Mohammed Bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE; Google, Mountain View, CA, USA; Terminus Group, Beijing, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","6 Jan 2023","2023","45","2","1934","1948","Given a degraded input image, image restoration aims to recover the missing high-quality image content. Numerous applications demand effective image restoration, e.g., computational photography, surveillance, autonomous vehicles, and remote sensing. Significant advances in image restoration have been made in recent years, dominated by convolutional neural networks (CNNs). The widely-used CNN-based methods typically operate either on full-resolution or on progressively low-resolution representations. In the former case, spatial details are preserved but the contextual information cannot be precisely encoded. In the latter case, generated outputs are semantically reliable but spatially less accurate. This paper presents a new architecture with a holistic goal of maintaining spatially-precise high-resolution representations through the entire network, and receiving complementary contextual information from the low-resolution representations. The core of our approach is a multi-scale residual block containing the following key elements: (a) parallel multi-resolution convolution streams for extracting multi-scale features, (b) information exchange across the multi-resolution streams, (c) non-local attention mechanism for capturing contextual information, and (d) attention based multi-scale feature aggregation. Our approach learns an enriched set of features that combines contextual information from multiple scales, while simultaneously preserving the high-resolution spatial details. Extensive experiments on six real image benchmark datasets demonstrate that our method, named as MIRNet-v2, achieves state-of-the-art results for a variety of image processing tasks, including defocus deblurring, image denoising, super-resolution, and image enhancement. The source code and pre-trained models are available at https://github.com/swz30/MIRNetv2.","1939-3539","","10.1109/TPAMI.2022.3167175","National Science Foundation(grant numbers:1149783); National Natural Science Foundation of China(grant numbers:61929104); ARC DECRA(grant numbers:DE200101100); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9756908","Multi-scale feature representation;dual-pixel defocus deblurring;image denoising;super-resolution;low-light image enhancement;and contrast enhancement","Feature extraction;Image restoration;Streaming media;Spatial resolution;Image denoising;Cameras;Superresolution","convolutional neural nets;feature extraction;image denoising;image enhancement;image representation;image resolution;image restoration;learning (artificial intelligence)","attention based multiscale feature aggregation;CNN-based methods;complementary contextual information;computational photography;contextual information;convolutional neural networks;defocus deblurring;fast image enhancement;fast image restoration;full-low-resolution representations;high-quality image content;image denoising;MIRNet-v2;multiresolution convolution streams;multiscale residual block approach;nonlocal attention mechanism;spatially-precise high-resolution representations","","3","","135","IEEE","13 Apr 2022","","","IEEE","IEEE Journals"
"Residual HSRCNN: Residual Hyper-Spectral Reconstruction CNN from an RGB Image","X. -H. Han; B. Shi; Y. Zheng","Graduate School of Science and Technology for Innovation, Yamaguchi University, Japan; Institute of Digital Media, Peking University, China; Digital Content and Media Sciences Research Division, National Institute of Informatics, Japan","2018 24th International Conference on Pattern Recognition (ICPR)","29 Nov 2018","2018","","","2664","2669","Hyper-spectral imaging has great potential for understanding the characteristics of different materials in many applications ranging from remote sensing to medical imaging. However, due to various hardware limitations, only low-resolution hyper-spectral and high-resolution multi-spectral or RGB images can be captured at video rate. This study aims to generate a hyper-spectral image via enhancing spectral resolution of an RGB image, which might be easily obtained by a commodity camera. Motivated by the success of deep convolutional neural network (DCNN) for spatial resolution enhancement of natural images, we explore a spectral reconstruction CNN for spectral super-resolution with an available RGB image, which predicts the high-frequency content of the fine spectral wavelength in narrow band interval. Since the lost high-frequency content can not be perfectly recovered, by leveraging on the baseline CNN, we further propose a novel residual hyper-spectral reconstruction CNN framework to estimate the non-recovered high-frequency content (Residual) from the output of the baseline CNN. Experiments on benchmark hyper-spectral datasets validate that the proposed method achieves promising performances compared with the existing state-of-the-art methods.","1051-4651","978-1-5386-3788-3","10.1109/ICPR.2018.8545634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8545634","","Spatial resolution;Image reconstruction;Signal resolution;Computer architecture;Cameras;Visualization","cameras;convolution;feedforward neural nets;geophysical image processing;image colour analysis;image reconstruction;image resolution;remote sensing;spectral analysis","nonrecovered high-frequency content;DCNN;deep convolutional neural network;commodity camera;low-resolution hyper-spectral images;residual HSRCNN;residual hyper-spectral reconstruction CNN framework;spectral wavelength;RGB image;spectral resolution enhancement;high-resolution multispectral images;natural images;spatial resolution enhancement;medical imaging;hyper-spectral imaging;benchmark hyper-spectral datasets;baseline CNN","","9","","41","IEEE","29 Nov 2018","","","IEEE","IEEE Conferences"
"Compressive sensing and generalized likelihood ratio test in SAR tomography","G. Fornaro; A. Pauciullo; D. Reale; M. Weiß; A. Budillon; G. Schirinzi","National Research Council (CNR) - IREA, Napoli, Italy; National Research Council (CNR) - IREA, Napoli, Italy; National Research Council (CNR) - IREA, Napoli, Italy; Fraunhofer FHR-PSR, Fraunhoferstraße 20; 53343-Wachtberg; Germany; Università di Napoli Parthenope, Napoli, Italy; Fraunhofer FHR-PSR, Wachtberg, Germany","2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing (CoSeRa)","17 Nov 2016","2016","","","90","94","Synthetic Aperture Radar (SAR) interferometry has been the subject of an intensive development in the last years thanks to crucial applications in the area of risk monitoring. The emergence of very high resolution X-Band sensors has increased the interest in application to urban area. Advances of SAR interferometry has been provided by the extension toward SAR tomography. By transforming classical 2-D SAR imaging into higher dimensional (space-time) imaging, it offers the possibility to reconstruct the 3-D/4-D scattering distribution and to detect point clouds for reconstructing single buildings and infrastructures and for the monitoring of their long term deformation. The resolution provided by classical SAR tomographic methods may show limitations in the detection of point clouds. To improve the performance of the tomographic tools super-resolution Compressive Sensing (CS) algorithms have been recently proposed. The literature, however, lacks of an assessment of the improvement of CS over classical point could detection schemes based on classical matched filter as well as of possible indications about the development of a CS algorithm able to guarantee a fixed false alarm probability. This work aims to provide a contribution along this line.","","978-1-5090-2920-4","10.1109/CoSeRa.2016.7745706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745706","","Synthetic aperture radar;Tomography;Compressed sensing;Sensors;Three-dimensional displays;Azimuth;Coherence","compressed sensing;image reconstruction;image resolution;matched filters;probability;radar imaging;radar interferometry;scattering;synthetic aperture radar;tomography","compressive sensing algorithms;generalized likelihood ratio test;synthetic aperture radar interferometry;SAR interferometry;SAR tomographic methods;risk monitoring;high resolution X-band sensors;2D SAR imaging;space-time imaging;3D/4D scattering distribution;point clouds detection;matched filter;false alarm probability","","1","","18","IEEE","17 Nov 2016","","","IEEE","IEEE Conferences"
"Statistical Downscaling of Temperature Distributions in Southwest China by Using Terrain-Guided Attention Network","G. Liu; R. Zhang; R. Hang; L. Ge; C. Shi; Q. Liu","School of Automation, Nanjing University of Information Science and Technology, Nanjing, China; School of Computing, Jiangsu University of Science and Technology, Zhenjiang, China; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; National Meteorological Information Center, Beijing, China; National Meteorological Information Center, Beijing, China; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","8 Feb 2023","2023","16","","1678","1690","Deep learning techniques, especially convolutional neural networks (CNNs), have dramatically boosted the performance of statistical downscaling. In this study, we propose a CNN-based 2 m air temperature downscaling model named Terrain-Guided Attention Network (TGAN), which aims at rebuilding 2 m air temperature distribution from 0.0625$^{\circ }$ to 0.01$^{\circ }$ over Southwest China. More concretely, TGAN utilizes two upsampling modules to progressively reconstruct the high-resolution temperature data from the low-resolution one. Then, to better recover the spatial detail of the low-resolution temperature data, an attentive-terrain block is proposed to introduce digital terrain model (DEM) information. It aggregates the temperature data and the corresponding-scale DEM information via the attention mechanism in a multiscale manner. Ultimately, the reconstruction module is employed to obtain the high-resolution temperature data. We use the 2019 data for training, and utilize the 2018 data to verify the effectiveness of the proposed TGAN. The experimental results showed that TGAN achieved the lowest root-mean-square error (1.12$\,^\circ$C) when incorporating DEM data by attentive-terrain blocks in a multiscale manner, followed by incorporating DEM data in a multiscale manner (TGAN-land, 1.31$\,^\circ$C) and only incorporating DEM data (SRCNN-land, 1.36$\,^\circ$C). Meanwhile, TGAN showed a competitive performance when compared with several advanced deep-learning-based super-resolution algorithms and reconstructed the texture details of 2 m air temperature fields more clearly. In general, among various deep learning approaches, TGAN achieves better downscaling results for 2 m air temperature reconstruction and provides a practical method and guidance for the back-calculation of high-resolution historical meteorological grid data.","2151-1535","","10.1109/JSTARS.2023.3239109","National Key Research and Development Program of China(grant numbers:2021ZD0112200); National Natural Science Foundation of China(grant numbers:61825601,U21B2049,62206115,BK20220646); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10024787","2 m air temperature;convolutional neural network;statistical downscaling;terrain-guided attention network","Temperature distribution;Meteorology;Computational modeling;Atmospheric modeling;Data models;Task analysis;Training","","","","","","53","CCBYNCND","23 Jan 2023","","","IEEE","IEEE Journals"
"Exact Multistatic Interferometric Imaging via Generalized Wirtinger Flow","B. Yonel; I. -Y. Son; B. Yazici","Department of Electrical, Computer and Systems Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Electrical, Computer and Systems Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Electrical, Computer and Systems Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA","IEEE Transactions on Computational Imaging","13 Feb 2020","2020","6","","711","726","We present a novel, exact method to address the interferometric inversion problem for multistatic wave-based imaging based on Generalized Wirtinger Flow (GWF) [1]. Interferometric imaging is a relative of phase retrieval, which arises from crosscorrelating measurements from pairs of receivers. GWF provides a theoretical framework to process scattering data satisfying the Born approximation, and guarantees exact recovery of the underlying scene reflectivity vector from interferometric measurements if the discretized lifted forward model satisfies the restricted isometry property over rank-1, positive semi-definite matrices with a sufficiently small restricted isometry constant (RIC). To this end, we design a linear deterministic discrete lifted forward model for interferometric multistatic radar measurements such that the exact recovery conditions of GWF are satisfied. Our results identify a lower limit on the pixel spacing and the sample complexity for exact multistatic radar imaging. We provide a numerical study of our RIC and pixel spacing bounds on synthetic single scattering data, which show that GWF can achieve exact recovery with super-resolution. While our primary interest lies in radar imaging, our results are applicable to other multistatic wave-based imaging problems such as those arising in acoustics and geophysics.","2333-9403","","10.1109/TCI.2020.2967151","Air Force Office of Scientific Research(grant numbers:FA9550-16-1-0234,FA9550-19-1-0284); Office of Naval Research(grant numbers:N0001418-1-2068); National Science Foundation(grant numbers:ECCS-1809234); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8961154","Multi-static radar;radar imaging;non-convex optimization;interferometric inversion;phase retrieval;wirtinger flow","Imaging;Radar imaging;Receivers;Scattering;Image reconstruction;Approximation methods;Multistatic radar","compressed sensing;computational complexity;geophysical techniques;gradient methods;matrix algebra;radar imaging;remote sensing by radar;synthetic aperture radar;vectors","Generalized Wirtinger Flow;scene reflectivity vector;small restricted isometry constant;linear deterministic discrete;semidefinite matrices;restricted isometry property;interferometric measurements;Born approximation;phase retrieval;interferometric inversion problem;exact multistatic interferometric imaging;multistatic wave-based imaging problems;synthetic single scattering data;RIC;exact multistatic radar imaging;pixel spacing;GWF;exact recovery conditions;interferometric multistatic radar measurements;forward model","","10","","55","IEEE","16 Jan 2020","","","IEEE","IEEE Journals"
"Semi-NMF-Based Reconstruction for Hyperspectral Compressed Sensing","Z. Wang; M. He; L. Wang; K. Xu; J. Xiao; Y. Nian","Department of Electrical Engineering, Tongling University, Tongling, China; College of Biomedical Engineering and Imaging Medicine, Army Medical University (Third Military Medical University), Chongqing, China; College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China; Xinqiao Hospital, Army Medical University (Third Military Medical University), Chongqing, China; College of Biomedical Engineering and Imaging Medicine, Army Medical University (Third Military Medical University), Chongqing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","12 Aug 2020","2020","13","","4352","4368","Hyperspectral compressed sensing (HCS) is a new imaging method that effectively reduces the power consumption of data acquisition. In this article, we present a novel HCS algorithm by incorporating spatial-spectral hybrid compressed sensing, followed by a reconstruction based on spectral unmixing. At the sampling stage, the measurements are acquired by a spatial-spectral hybrid compressive sampling scheme to preserve the necessary information for the following spectral unmixing, where spatial compressive sampling mainly retains the endmember information, and spectral compressive sampling mainly retains the abundance information. Due to the limitations of the traditional linear mixed model, an improved mixed model is proposed for HCS reconstruction, which considers spectral variability, nonlinear mixing, and other factors. At the reconstruction stage, based on the improved mixed model, semi-nonnegative matrix factorization is introduced to realize spectral unmixing on the measurements to achieve the final reconstruction by using an alternate iteration manner. The proposed algorithm is tested on real hyperspectral data, and the selection of parameters is fully analyzed. Experimental results demonstrate that the proposed algorithm can significantly outperform state-of-the-art HCS algorithms in terms of reconstruction performance.","2151-1535","","10.1109/JSTARS.2020.3010332","Key Logistics Research Projects(grant numbers:BLJ18J005); National Natural Science Foundation of China(grant numbers:61701506); Chongqing Research Program of Basic Research and Frontier Technology(grant numbers:cstc2016jcyjA0539); Overseas Visiting and Research Project; Excellent Young Key Talents in Higher Education Institutions in Anhui Province(grant numbers:gxgwfx2019056); Natural Science Research of Universities of Anhui Province(grant numbers:KJ2019A0709); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144411","Compressive sensing;hyperspectral images (HSIs);nonnegative matrix factorization (NMF)","Image reconstruction;Hyperspectral imaging;Image coding;Imaging;Principal component analysis;Compressed sensing","compressed sensing;data acquisition;data compression;geophysical image processing;hyperspectral imaging;image coding;image reconstruction;iterative methods;matrix decomposition","semiNMF-based reconstruction;hyperspectral compressed sensing;data acquisition;spatial-spectral hybrid compressed sensing;spectral unmixing;spatial-spectral hybrid compressive sampling scheme;endmember information;linear mixed model;HCS reconstruction;nonlinear mixing;seminonnegative matrix factorization;alternate iteration manner","","7","","43","CCBY","20 Jul 2020","","","IEEE","IEEE Journals"
"Single Satellite Imagery Superresolution Based on Hybrid Nonlocal Similarity Constrained Convolution Sparse Coding","N. Chen; L. Sui; B. Zhang; H. He; J. Marcato Junior; J. Li","College of Geological Engineering and Geomatics, Chang'an University, Xi'an, China; College of Geological Engineering and Geomatics, Chang'an University, Xi'an, China; Geovis Spatial Technology Co.,Ltd, Xi'an, China; Department of Geography and Environmental Management, University of Waterloo, Waterloo, ON, Canada; Faculty of Engineering, Architecture and Urbanism and Geography, Federal University of Mato Grosso do Sul, Campo Grande, Brazil; Department of Geography and Environmental Management, University of Waterloo, Waterloo, ON, Canada","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","5 Aug 2021","2021","14","","7489","7505","The traditional superresolution methods based on image patches often ignore the consistency between the overlapped patches, causing block effects in produced images. The convolutional sparse coding based superresolution method uses the translation invariance of the convolution filter to directly encode the entire image, maintaining consistency and good performance. In this article, we propose a novel approach to single-image superresolution reconstruction based on hybrid nonlocal similarity constrained convolution sparse coding. We first decompose the input image into a smooth part and a texture part. The Bayesian nonparametric model can use more prior information of the original image, so we replace the previous bicubic interpolation with this method to better reconstruct the residual high-frequency information in the smooth part. When reconstructing the texture part, this article proposes a nonlocal similarity constrained convolutional sparse coding method, which transforms the reconstruction of the texture part to minimize the convolution sparse coding noise of the feature maps and classifies the image patches in the search space by using the correlation coefficients as the structural information, avoiding unnecessary weight calculation. Several methods were tested on satellite images extensively. Both visual inspection and quantitative analysis results demonstrate that our method outperforms other state-of-the-art methods and increases noise immunity effectively.","2151-1535","","10.1109/JSTARS.2020.3028774","National Natural Science Foundation of China(grant numbers:41601345,41571346,41871380,4141379); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216608","Bayesian nonparametric model;convolution sparse coding;correlation coefficient;nonlocal (NL) similarity structure;superresolution (SR) reconstruction","Image reconstruction;Satellites;Image resolution;Dictionaries;Convolution;Bayes methods;Image coding","Bayes methods;convolutional codes;geophysical image processing;image coding;image reconstruction;image representation;image resolution;interpolation","texture part;convolution sparse coding noise;image patches;satellite images;single satellite imagery superresolution;hybrid nonlocal similarity constrained convolution sparse coding;traditional superresolution methods;overlapped patches;produced images;convolutional sparse coding based superresolution method;convolution filter;single-image superresolution reconstruction;input image;smooth part;high-frequency information;convolutional sparse coding method","","1","","49","CCBY","7 Oct 2020","","","IEEE","IEEE Journals"
"Notice of Violation of IEEE Publication Principles: Ground-Based Cloud Image Recognition System Based on Multi-CNN and Feature Screening and Fusion","M. Jingyi; T. Zhang; J. Guodong; Y. Wenjun; Y. Bin","Gansu Branch, China Meteorological Administration Training Centre, Beijing, China; Institute of Arid Meteorology, China Meteorological Administration, Beijing, China; China Meteorological Administration Training Center, Beijing, China; Gansu Branch, China Meteorological Administration Training Centre, Beijing, China; Gansu Branch, China Meteorological Administration Training Centre, Beijing, China","IEEE Access","29 Sep 2020","2020","8","","173949","173960","The recognition of ground-based cloud images has rich application prospects in many aspects such as weather prediction, astronomical site selection, and meteorological observation. Affected by factors such as rotation and illumination, the traditional feature extraction method is difficult to accurately describe the features of cloud images, resulting in low accuracy of ground-based cloud image recognition, and cannot meet the requirements of practical applications. With the popularity of convolutional neural networks in image processing, ground-based cloud image recognition algorithms based on convolutional neural network have become a research focus. However, the features of the ground-based cloud image are relatively shallow, and the cloud texture and other features are seriously lost in the convolution process, and it is difficult to achieve a good recognition effect. This paper proposes a ground-based cloud image recognition system based on multi-scale convolutional neural network (Multi-CNN) and multilayer perceptron neural networks (MLP). The multi-level and multi-scale convolution feature extraction is performed through convolution layers of Multi-CNN, and the local features with strong resolving power are selected through the feature screening algorithm based on DP clustering. Finally, the local features are encoded and fused for cloud image classification based on MLP. Filed test results show that our method was superior to other tested network models in terms of the recognition accuracy of 94.8% under 9 classification. In addition, ablation experiments show that the multi-scale feature extraction, screening and local feature coding in this paper have a significant effect on improving the algorithm’s ability to distinguish different cloud images.;Notice of Violation of IEEE Publication Principles <br><br> “Ground-Based Cloud Image Recognition System Based on Multi-CNN and Feature Screening and Fusion” <br> by Ma Jingyi, Tiejun Zhang, Jing Guodong, Yan Wenjun, and Yang Bin <br> in IEEE Access, September 2020 <br> After careful and considered review of the content and authorship of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE’s Publication Principles. <br><br> This paper duplicates content from the paper cited below. The original content was copied without attribution (including appropriate references to the original author(s) and/or paper title) and without permission. <br><br> “DeepCloud: Ground-Based Cloud Image Categorization Using Deep Convolutional Features” <br> by Liang Ye, Zhiguo Cao, and Yang Xiao <br> in the IEEE Transactions on Geoscience and Remote Sensing, Vol. 55, No. 10, October 2017 <br><br> ","2169-3536","","10.1109/ACCESS.2020.3026364","Youth Science Fund Project: Research on Super-Resolution Reconstruction Method of Meteorological Satellite Cloud Image Based on Compressed Sensing(grant numbers:61602486); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9205205","","","","","","1","","19","CCBY","24 Sep 2020","","","IEEE","IEEE Journals"
"Fast Fusion of Hyperspectral and Multispectral Images: A Tucker Approximation Approach","C. Prévost; P. Chainais; R. Boyer","CNRS, Centrale Lille, UMR 9189 CRIStAL, Univ. Lille, Lille, France; CNRS, Centrale Lille, UMR 9189 CRIStAL, Univ. Lille, Lille, France; CNRS, Centrale Lille, UMR 9189 CRIStAL, Univ. Lille, Lille, France","2022 IEEE International Conference on Image Processing (ICIP)","18 Oct 2022","2022","","","2076","2080","Hyperspectral super-resolution based on coupled Tucker decomposition has been recently considered in the remote sensing community. The state-of-the-art approaches did not fully exploit the coupling of information contained in hyperspectral and multispectral images of the same scene. This paper proposes a new algorithm that overcomes this limitation. It accounts for both the high-resolution and the low-resolution information in the model by solving a set of least-squares problems. In addition, we provide exact recovery conditions for the super-resolution image in the noiseless case. Our simulations show that the proposed algorithm achieves very good reconstruction quality with a very low computational complexity.","2381-8549","978-1-6654-9620-9","10.1109/ICIP46576.2022.9898065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9898065","","Couplings;Runtime;Image color analysis;Computational modeling;Superresolution;Lakes;Approximation algorithms","","","","","","22","IEEE","18 Oct 2022","","","IEEE","IEEE Conferences"
"Statistical electromagnetic theories and applications: A review of recent advances","A. Ishimaru; Ce Zhang; Y. Kuga","University of Washington, Seattle, 98195, USA; University of Washington, Seattle, 98195, USA; University of Washington, Seattle, 98195, USA","2015 1st URSI Atlantic Radio Science Conference (URSI AT-RASC)","26 Oct 2015","2015","","","1","1","Statistical Electromagnetic Theories have been developed over many years and applied to a wide range of practical problems in remote sensing of geophysical media, biological media, medical optics, ultrasound imaging and object detection and communication in clutter. This paper gives a review of recent developments in applications of statistical wave theories. The super resolution of images occurs in random media due to the multiple scattering and the increase of apparent aperture size of the transmitter. Another interesting effect is that the scattered wave from multiple scattering remembers the direction of the incident wave and strong correlations can be observed under certain conditions. This is called the “Memory Effect”. Recent study shows that under certain conditions, the angular and frequency correlations of the scattered wave can be enhanced or reduced and this effect can be used to reduce the clutter from the rough surface. It is also noted that the coherence in multiple scattering causes the increase of radar cross sections in turbulence due to the interference between the forward and backward waves, called the “double passage effect”. This is related to the Anderson localization and the coherent backscattering.","","978-9-0900-8628-6","10.1109/URSI-AT-RASC.2015.7302918","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7302918","","","","","","","","","","26 Oct 2015","","","IEEE","IEEE Conferences"
"A probabilistic framework for dense image registration using relaxation labelling","M. Amiri; A. Ahmadifard; V. Abolghasemi","Electrical and Robotic Engineering Department, Shahrood University of Technology, Shahrood, Iran; Electrical and Robotic Engineering Department, Shahrood University of Technology, Shahrood, Iran; Electrical and Robotic Engineering Department, Shahrood University of Technology, Shahrood, Iran","2016 2nd International Conference of Signal Processing and Intelligent Systems (ICSPIS)","6 Mar 2017","2016","","","1","5","Image Registration has investigated in many researches in recent years. It is an important preprocessing step in a variety of applications such as medical images, super resolution and remote sensing. Generally, dense image registration requires several transformations and deformations such as contrast changing, scaling, rotation and displacement. However, in most recent proposed methods, only some of these transforms are considered, which results in incorrect output. In this paper we propose a new method for dense image registration based on relaxation labelling. For each pixel of a test image, we want to find the best match in a reference image, considering the intensity and geometric constraints. We use blocks of reference image as features, then we look for the closest candidate in the test image. In next step, a relaxation labelling procedure is applied to these candidates for selecting the best match between candidate pixels. Experimental results show that the proposed method achieves satisfactory performance in terms of visual quality, PSNR values and Bad pixel evaluation criteria.","","978-1-5090-5820-4","10.1109/ICSPIS.2016.7869876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869876","Dense registration;Feature matching;Stereo matching;Relaxation labelling","Image registration;Feature extraction;Labeling;Image edge detection;Mathematical model;Algorithm design and analysis;Probability","image matching;image registration;stereo image processing;transforms","dense image registration;relaxation labelling;transformations;deformations;reference image matching;intensity constraint;geometric constraint;stereo matching;feature matching","","","","13","IEEE","6 Mar 2017","","","IEEE","IEEE Conferences"
"IEEE Standard for Radar Definitions","",,"IEEE Std 686-2017 (Revision of IEEE Std 686-2008)","22 Sep 2017","2017","","","1","54","The promotion of clarity and consistency in the use of radar terminology is the purpose of the definitions provided in this guide. The consensus of a panel of radar experts are represented in the definitions herein.;The promotion of clarity and consistency in the use of radar terminology is the purpose of the definitions provided in this guide. The consensus of a panel of radar experts are represented in the definitions herein.","","978-1-5044-4062-2","10.1109/IEEESTD.2017.8048479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048479","IEEE 686™;radar;terminology","IEEE Standards;Radar;Aerospace electronics;Dictionaries;Terminology","IEEE standards;radar","IEEE standard;radar terminology","","9","","9","","22 Sep 2017","","","IEEE","IEEE Standards"
"[Title page]","",,"2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","i","i","The following topics are dealt with: SAR tomography of distributed media; hyperspectral band selection and dimensionality reduction; SAR image feature extraction and filtering; image processing techniques of detecting; ship detection; observations by the NASA Soil Moisture Active Passive Mission; multi-source remote sensing approaches to vegetation monitoring; Earth observing data science; remote sensing of land surface evapotranspiration; international spaceborne imaging spectroscopy missions; L-band microwave radiometry; radio frequency interference in microwave remote sensing and radio astronomy; TANDEM-X; atmosphere remote sensing and its application in air pollution; status and development of chinese meteorological and oceanographic series satellites; aperture synthesis radiometry; building features detection; classification of hyperspectral image; clouds and precipitation; data management and systems; detection with high resolution images; disaster and anomaly detection; feature extraction and detection algorithm; forest monitoring by radar and lidar; high resolution images classification; land cover mapping; land targets; microwave and optical calibration; microwave radiometer calibration and emerging techniques; microwave radiometry; multi-source images fusion and classification; object detection and recognition with SAR images; region based image classification; SAR and sonar image analysis and classification; SAR imaging techniques; satellite missions; urban targets and roads; vegetation monitoring by MODIS; vehicle and aircraft detection; advances on spaceborne SAR imaging; advanced interferometric processing and multidimensional SAR imaging techniques; lidar feature extraction and analysis; learning based image classification; SMAP soil moisture; remote sensing of vegetation traits and function; radar forestry; remote sensors and sensing of urban areas; geographic information science; IEEE GRSS data fusion contest; student paper contest finalists; physical models in microwave remote sensing; calibration, validation and related topics in support of spaceborne imaging spectroscopy missions; thermal and hyperspectral sensors and mapping; remote sensing using GNSS-like signals and other sensors; radiometer cross-calibration; COSMO-SKYMED mission; bistatic and digital beamforming SAR; numerical weather prediction and data assimilation; sar remote sensing for ocean applications; remote sensing of high winds; ocean surface winds; aerial images analysis and applications; analysis of multitemporal optical images; change detection applications; coastal zones; data fusion techniques; electromagnetic theory; multitemporal InSAR analysis; noise reduction techniques; optical sensors and calibration; soil properties; vegetation and tree remote sensing; pseudo pixel based image classification; Water Cycle Observation Mission (WCOM); remote sensing for ecology; advancing interoperability for geoscience information systems; lunar-based earth observation; advances in bathymetric and oceanographic lidar studies; DRAGON 3 cooperation; the Mexican perspective to the understanding of our planet through remote sensing; ALOS-2; SENTINEL-1 constellation mission; atmospheric sounding sensors; ocean waves and currents; ocean temperature and salinity; aerosols and atmospheric chemistry; air pollution; disaster assessment; droughts; earthquake; estimation and regression applications; floods; geographic information science; hazards and disasters; land cover dynamics; land use applications; ocean altimetry; POL and POLINSAR; sea ice; snow cover; neural network based classification; high resolution image analysis; global change study; forest biomass; digital terrain models; minerals and hydrocarbons; remote sensing data and policy decisions; earth remote sensing with small satellites; the China France Oceanography Satellite; agricultural parameters; big data in geoscience; differential SAR interferometry; ice sheets and glaciers; inland waters; interdisciplinary topics; remote sensing for crop yield and classification; remote sensing in mining; subsurface sensing; spectral unmixing techniques; UAV systems and sensors; super-resolution; oil spill, and; urbanization and environmental change.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7728982","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7728982","","","aerosols;air pollution;atmospheric chemistry;autonomous underwater vehicles;bathymetry;crops;disasters;earthquakes;ecology;evaporation;feature extraction;floods;geophysical image processing;geophysical signal processing;glaciology;hydrology;ice;image classification;image denoising;image fusion;land cover;marine pollution;meteorology;minerals;mining;object detection;optical radar;radiometry;rain;remote sensing by laser beam;remote sensing by radar;ships;snow;sonar;synthetic aperture radar;transpiration;vegetation mapping","IEEE International Geoscience and Remote Sensing Symposium;precipitation;disaster detection;anomaly detection;radar forest monitoring;lidar forest monitoring;land cover mapping;land targets;calibration;multisource images fusion;multisource images classification;object detection;object recognition;sonar image analysis;urban targets;urban roads;MODIS;vehicle detection;aircraft detection;SMAP soil moisture;forestry;geographic information science;GNSS like signals;COSMO-SKYMED mission;change detection;coastal zones;data fusion;noise reduction;Water Cycle Observation Mission;ecology;bathymetric lidar;oceanographic lidar;DRAGON 3 cooperation;ALOS-2;clouds;hyperspectral image classification;building features detection;aperture synthesis radiometry;air pollution;atmosphere remote sensing;TANDEM-X;radio astronomy;radio frequency interference;microwave radiometry;international spaceborne imaging spectroscopy missions;land surface evapotranspiration;Earth observing data science;vegetation monitoring;multisource remote sensing;NASA Soil Moisture Active Passive Mission;ship detection;image processing techniques;SAR image filtering;SAR image feature extraction;dimensionality reduction;hyperspectral band selection;SAR tomography;IGARSS;SENTINEL-1 constellation mission;atmospheric sounding sensors;ocean waves;ocean currents;ocean temperature;ocean salinity;aerosols;atmospheric chemistry;disaster assessment;droughts;earthquake;floods;hazards;disasters;land cover dynamics;land use;ocean altimetry;POLINSAR;sea ice;snow cover;neural network based classification;forest biomass;digital terrain models;minerals;hydrocarbons;China France Oceanography Satellite;differential SAR interferometry;ice sheets;glaciers;crop yield;oil spill","","","","","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"[Title page]","",,"2016 14th Specialist Meeting on Microwave Radiometry and Remote Sensing of the Environment (MicroRad)","4 Aug 2016","2016","","","1","1","The following topics are dealt with: generalization of the van Cittert-Zernike theorem to observers moving with respect to sources; status of Aquarius and the salinity retrieval; microwave scanner-sounder MTVZA-GY on new Russian meteorological satellite meteor-m no. 2; SMOS payload status after six years in orbit: operational and thermal performance, calibration strategy and RFI management; antenna spacing and pattern differences: their impact in MIRAS reconstruction error; Faraday rotation with the SMAP radiometer; the Ice Cloud Imager (ICI) preliminary design and performance; microwave imager instrument for METOP second generation: design and verification; requirements for a robust precipitation constellation; CUBESAT scale receivers for measurement of ice in clouds; analysis and design of mm-wave detectors in sige SOC radiometers for spaceborne observations of solar flares; development of Compact High Altitude Imager and Sounding Radiometer (CHAISR); performance of a processor for on-board RFI detection and mitigation in METOPSG radiometers; evaluation and comparison of RFI detection algorithms; comparison of time-frequency RFI mitigation techniques in microwave radiometry; performance analysis of a hardware implemented complex signal kurtosis radio-frequency interference detector; corruption of the TRMM microwave imager cold sky mirror due to RFI; monitoring boreal and Arctic freeze/thaw with the first year of SMAP brigthness temperatures; evaluation of modeled high resolution virtual brightness temperatures compared to space-borne observations for the NECKAR catchment;an assessment of SMOS version 6.20 products through triple and quadruple collocation techniques considering ASCAT, ERA/INTERIM land, ISMN and SMAP soil moisture data;sea ice thickness retrieval at L-band: comparison between results from Aquarius and SMAP data; snow on lake ice: overview of a multiyear airborne radiometer data collection program and related modeling efforts; diurnal variation of brightness temperature of terrestrial snow during snowmelt; precipitation retrievals from passive microwave cross-track sounding instruments; forward modeling of an atmospheric scenario: path characterization in terms of scattering intensity; the NWP contribution from the microwave sounder (MWS) on METOP-second generation; on the amount of information content in microwave radiometry for wet delay correction; brightness temperature spatial correlations in SMOS antenna; mitigation of cross-polar antenna pattern errors in SMOS: simplified approach; SMOS salinity retrievals enhancement in coastal areas by joint application of nodal sampling and corrected correlator efficiency; sparsity-based approaches for multispectral super-resolution of tropical cyclone imagery; morphological tools for spatial and multiscale analysis of passive microwave remote sensing data; antenna array optimization for the new GIMS demonstrator; temporal resolution enhancement of image sequences capturing evolving weather phenomena; improvements in atmospheric water vapor content retrievals over open oceans from satellite passive microwave radiometers; Global Precipitation Measurement (GPM) microwave imager (GMI) on-orbit calibration; impact of amplitude calibration errors on SMOS global images; fully polarimetric radiometer calibration: determining retardation plate's characteristics; geolocation results for the SMAP passive instrument ;advantages of calibration attitude maneuvers for spaceborne microwave radiometer missions; potential of microwave imager combined active/passive for the 191 retrieval of sea surface salinity.","","978-1-5090-2951-8","10.1109/MICRORAD.2016.7530486","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530486","","","antennas;atmospheric humidity;calibration;clouds;environmental monitoring (geophysics);geophysical image processing;image sequences;lakes;moisture;polarimetry;radiometers;remote sensing;salinity (geophysical);sea ice;snow;soil;storms","RFI detection algorithm;time-frequency RFI mitigation;microwave radiometry;signal kurtosis radiofrequency interference detector;TRMM microwave imager cold sky mirror;boreal monitoring;Arctic freeze-thaw monitoring;SMAP brigthness temperature;space-borne observation;NECKAR catchment;ASCAT data;ERA-INTERIM land data;ISMN data;SMAP soil moisture data;sea ice thickness retrieval;Aquarius data;SMAP data;lake ice;airborne radiometer data collection program;terrestrial snow;snowmelt;precipitation retrieval;passive microwave cross-track sounding instrument;atmospheric scenario modeling;NWP contribution;microwave sounder;METOP-second generation;wet delay correction;SMOS antenna;cross-polar antenna pattern error;SMOS salinity retrieval enhancement;coastal area;METOPSG radiometer;CHAISR;Compact High Altitude Imager and Sounding Radiometer;solar flare;spaceborne observation;SOC radiometer;mm-wave detector;cloud ice measurement;CUBESAT scale receiver;precipitation constellation;METOP second generation;microwave imager instrument;ICI performance;ICI design;Ice Cloud Imager;SMAP radiometer;Faraday rotation;MIRAS reconstruction error;antenna spacing;RFI management;SMOS payload status;Russian meteorological satellite meteor;microwave scanner-sounder MTVZA-GY;van Cittert-Zernike theorem;tropical cyclone imagery;passive microwave remote sensing data;antenna array optimization;GIMS demonstrator;image sequence enhancement;weather phenomena;atmospheric water vapor content retrieval;satellite passive microwave radiometer;Global Precipitation Measurement;GPM microwave imager;GMI on-orbit calibration;SMOS global images;polarimetric radiometer calibration;SMAP passive instrument;spaceborne microwave radiometer mission;sea surface salinity","","","","","IEEE","4 Aug 2016","","","IEEE","IEEE Conferences"
