"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Deepsen3: Deep Multi-Scale Learning Model For Spatial-Spectral Fusion Of Sentinel-2 And Sentinel-3 Remote Sensing Images","A. Alboody; M. Puigt; G. Roussel; V. Vantrepotte; C. Jamet; T. -K. Tran","LISIC – UR 4491, Univ. Littoral Côte d’Opale, Longuenesse, France; LISIC – UR 4491, Univ. Littoral Côte d’Opale, Longuenesse, France; LISIC – UR 4491, Univ. Littoral Côte d’Opale, Longuenesse, France; CNRS, LOG – UMR 8187, Univ. Littoral Côte d’Opale, Wimereux, France; CNRS, LOG – UMR 8187, Univ. Littoral Côte d’Opale, Wimereux, France; CNRS, LOG – UMR 8187, Univ. Littoral Côte d’Opale, Wimereux, France","2022 12th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","22 Nov 2022","2022","","","1","5","Recently, deep learning methods that integrate image features gradually became a hot development trend in fusion of multispectral and hyperspectral remote sensing images, aka multi-sharpening. Fusion of a low spatial resolution hyperspectral image (LR-HSI datacube) with its corresponding high spatial resolution multispectral image (HR-MSI datacube) to reconstruct a high spatial resolution hyperspectral image (HR-HSI) has been a significant subject in recent years. Nevertheless, it is still difficult to achieve a high quality of spatial and spectral information fusion. In this paper, we propose a Deep Multi-Scale Learning Model (called DeepSen3) of spatial-spectral information fusion based on multi-scale inception residual convolutional neural network (CNN) for more efficient hyperspectral and multispectral image fusion from ESA remote sensing satellite missions (Sentinel-2 and Sentinel-3 images). The proposed DeepSen3 fusion network was applied to Sentinel-2 MSI (13 spectral bands with a spatial resolution ranging from 10, 20 to 60 m) and Sentinel-3 OLCI (21 spectral bands with a spatial resolution of 300 m) images. Extensive experiments demonstrate that the proposed DeepSen3 network achieves the best performance (both qualitatively and quantitatively) compared with recent state-of-the-art deep learning approaches.","2158-6276","978-1-6654-7069-8","10.1109/WHISPERS56178.2022.9955139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955139","Deep Learning;Residual Convolutional Neural Network (ResNet-CNN);Multi-Scale Inception;Feature Extraction;Spatial-Spectral Image Fusion;Sentinel-2 and Sentinel-3 Remote Sensing Images;HyperSpectral Images (HSI);Multi-Spectral Images (MSI)","Deep learning;Satellites;Signal processing;Market research;Distance measurement;Convolutional neural networks;Spatial resolution","artificial satellites;convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image fusion;remote sensing","deep multiscale learning model;DeepSen3 fusion network;ESA remote sensing satellite missions;high spatial resolution hyperspectral image;low spatial resolution hyperspectral image fusion;multiscale inception residual convolutional neural network;multisharpening;multispectral remote sensing image fusion;Sentinel-2 MSI images;Sentinel-3 OLCI images;Sentinel-3 remote sensing images;spatial-spectral information fusion","","","","20","IEEE","22 Nov 2022","","","IEEE","IEEE Conferences"
"Inter-Sensor Remote Sensing Image Enhancement for Operational Sentinel-2 and Sentinel-3 Data Products","R. Fernandez; R. Fernandez-Beltran; F. Pla","Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1504","1507","The recent availability of operational data from the Sentinel-2 and Sentinel-3 missions provides widespread opportunities to generate diverse high-level remote sensing products. However, the synergies between both multi-spectral instruments are often difficult to exploit from an operational perspective. Standard pansharpening algorithms may encounter important disadvantages due to the limited intersensor data availability in actual production environments. Moreover, the lack of a real high-resolution ground-truth for super-resolution techniques may affect the radiometric quality of the final result. In this scenario, this work investigates the viability of using the Multi-Spectral Instrument of Sentinel-2 for super-resolving data products acquired by the Ocean and Land Colour Instrument of Sentinel-3. Specifically, we define an inter-sensor image enhancement framework which combines a PCA-based component substitution pansharpening scheme with a CNN-based spatial enhancing super-resolution mapping. The conducted experiments reveal the suitability of the proposed approach for generating Level-4 data products within the Copernicus programme context.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324071","Sentinel-2 (S2);Sentinel-3 (S3);super-resolution (SR);pansharpening;image fusion","Spatial resolution;Pansharpening;Principal component analysis;Instruments;Remote sensing;Image enhancement;Superresolution","geophysical image processing;image enhancement;image fusion;image resolution;remote sensing;terrain mapping","inter-sensor remote sensing image enhancement;operational Sentinel-2;Sentinel-3 data products;recent availability;operational data;Sentinel-3 missions;diverse high-level remote sensing products;multispectral instruments;operational perspective;standard pansharpening algorithms;intersensor data availability;actual production environments;high-resolution ground-truth;super-resolution techniques;MultiSpectral Instrument;inter-sensor image enhancement framework;super-resolution mapping;Level-4 data products","","","","10","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Sentinel-3 Image Super-Resolution Using Data Fusion and Convolutional Neural Networks","R. Fernandez; R. Fernandez-Beltran; F. Pla","Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2867","2870","With the increasing availability of Sentinel-2 (S2) and Sentinel-3 (S3) data, developing higher-level data products becomes a very attractive option to relieve the spatial limitations of the Ocean and Land Colour Instrument (OLCI) of S3. In this context, this paper investigates the suitability of super-resolving operational OLCI products using the Multi-Spectral Instrument (MSI) of S2 as an offline spatial reference. Specifically, the proposed approach assembles a multi -spectral data fusion scheme together with a convolutinal neural network (CNN) mapping function to project the OLCI sensor onto its corresponding spatial reference which is synthetically generated by the OLCI/MSI fusion. In this way, the trained model is able to super-resolve operational OLCI products under demand without the need of using MSI data. The experimental part of the work shows the suitability of the proposed approach in the context of the Copernicus programme.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554826","Sentinel-2 (S2);Sentinel-3 (S3);image fusion;super-resolution (SR)","Image color analysis;Instruments;Oceans;Superresolution;Neural networks;Data integration;Geoscience and remote sensing","geophysical image processing;image fusion;image resolution;image sensors;neural nets;remote sensing;sensor fusion","corresponding spatial reference;super-resolve operational OLCI products;MSI data;Sentinel-3 image super-resolution;convolutional neural networks;Sentinel-2;Sentinel-3 data;higher-level data products;spatial limitations;MultiSpectral Instrument;offline spatial reference;multi-spectral data fusion scheme;convolutinal neural network mapping function;OLCI sensor","","","","16","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"SEN23E: A Cloudless Geo-Referenced Multi-Spectral Sentinel-2/Sentinel-3 Dataset for Data Fusion Analysis","D. Ibañez; R. Fernandez-Beltran; F. Pla","Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1448","1451","The availability of geo-referenced coupled data of dif-ferent platforms is essential to train remote sensing (RS) multi-modal classification and bio-phyiscal parameter esti-mation learning methods. To properly develop a general-izing model different scenes and topographies are required. For this purpose, different multi-modal datasets have been published for the last years. Nevertheless, to our knowl-edge there is not any dataset composed of Sentinel-2 (S2) and Sentinel-3 (S3) geo-referenced images. In this paper we present SEN23, a dataset composed of 100 complete multi-spectral S2 and S3 paired images of different locations along Europe from the 2021 summer. The coupled images were obtained with a time difference of three or less days, containing less than a 1 % of cloud coverage and have a resolution difference of × 15. SEN23E is expected to help with the development of new multi-spectral, multi-resolution and multi-modal models for complex tasks which need con-text and complete images. SEN23E will be available at https://github.com/ibanezdf/SEN23E.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883867","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883867","Dataset;Data Fusion;Remote Sensing;Multi-spectral;Sentinel-2 (S2);Sentinel-3 (S3)","Learning systems;Image resolution;Biological system modeling;Europe;Data integration;Surfaces;Sensors","geophysical image processing;hydrological techniques;image classification;image fusion;learning (artificial intelligence);remote sensing;sensor fusion","data fusion analysis;geo-referenced coupled data;dif-ferent platforms;remote sensing multimodal classification;bio-phyiscal parameter esti-mation;model different scenes;topographies;different multimodal datasets;Sentinel-3 geo-referenced images;SEN23;100 complete multispectral;coupled images;time difference;resolution difference;multiresolution;multimodal models","","","","12","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Experimental Comparison of Multi-Sharpening Methods Applied To Sentinel-2 MSI and Sentinel-3 OLCI Images","A. Alboody; M. Puigt; G. Roussel; V. Vantrepotte; C. Jamet; T. K. Tran","Univ. Littoral Côte d’Opale, Longuenesse, France; Univ. Littoral Côte d’Opale, Longuenesse, France; Univ. Littoral Côte d’Opale, Longuenesse, France; Univ. Littoral Côte d’Opale, Wimereux, France; Univ. Littoral Côte d’Opale, Wimereux, France; Univ. Littoral Côte d’Opale, Wimereux, France","2021 11th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","19 Jul 2021","2021","","","1","5","Multi-spectral images are crucial to detect and to understand phenomena in marine observation. However, in coastal areas, these phenomena are complex and their analyze requires multi-spectral images with both a high spatial and spectral resolution. Unfortunately, no satellite is able to provide both at the same time. As a consequence, multi-sharpening techniques-a.k.a. fusion or super- resolution of multi-spectral and/or hyper-spectral images-were proposed and consist of combining information from at least two multi-spectral images with different spatial and spectral resolutions. The fused image then combines their best characteristics. Various methods-based on different strategies and tools-have been proposed to solve this problem. This article presents a comparative review of fusion methods applied to Sentinel-2 MSI (13 spectral bands with a spatial resolution ranging from 10 to 60 m) and Sentinel-3 OLCI (21 spectral bands with a spatial resolution of 300 m) images. Indeed, both satellites are extensively used in marine observation and, to the best of the authors' knowledge, the fusion of their data was partially investigated (and not in the way we aim to do in this paper). To that end, we provide both a quantitative analysis of the performance of some state-of-the-art methods on simulated images, and a qualitative analysis on real images.","2158-6276","978-1-6654-3601-4","10.1109/WHISPERS52202.2021.9484009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9484009","Image fusion;Remote sensing;Sentinel-2 MSI;Sentinel-3 OLCI;Simulations;Real data","Satellites;Statistical analysis;Conferences;Sea measurements;Distance measurement;Sensors;Spatial resolution","geophysical image processing;geophysical techniques;hyperspectral imaging;image fusion;image resolution;remote sensing","fusion methods;multi-sharpening techniques;multisharpening methods;multisharpening techniques;simulated images;Sentinel-3 OLCI;spectral bands;fused image;spectral resolutions;hyper-spectral images;spectral resolution;high spatial resolution;multispectral images;Sentinel-2 MSI","","2","","21","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"Water Pollution Detection in Acapulco Coasts Using Merged Data from the Sentinel-2 and Sentinel-3 Satellites","R. Lomelí-Huerta; H. Avila-George; J. P. Rivera-Caicedo; M. De-la-Torre","Departamento de Ciencias Computacionales e Ingenierías, Universidad de Guadalajara; Departamento de Ciencias Computacionales e Ingenierías, Universidad de Guadalajara; CONACyT-UAN, Secretaría de Investigation y Posgradom, Universidad Autónoma de Nayarit; Departamento de Ciencias Computacionales e Ingenierías, Universidad de Guadalajara","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","1518","1521","Acapulco coasts are occasionally contaminated by illegal discharges originated by temporary or permanent floods that disembogue to the pacific ocean. Plumes formed by contaminated water running through the ocean can be distinguished in satellite imagery, and their reflectance is related to the polluting elements. Although some spacial agencies provide data from diverse multispectral sensors, application-specific requirements are fulfilled by merging heterogeneous imagery (differences in spatial, temporal, and spectral resolutions). This paper proposes a continuous monitoring strategy to detect pollution in water discharges by combining data from Sentinel-2 and Sentinel-3 platforms. First, the region of interest to be monitored is detected using the bands with high spatial resolution. Then, distance-based supervised machine learning is employed to detect pixel-wise pollution in water. Finally, the historic detections over time are presented to detect recurrent discharges.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553929","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553929","Sentinel;satellite image fusion;contaminated water;monitoring system;remote sensing","Reflectivity;Image sensors;Satellites;Oceans;Merging;Machine learning;Water pollution","environmental monitoring (geophysics);floods;geophysical image processing;marine pollution;oceanographic regions;oceanographic techniques;remote sensing;supervised learning;water pollution measurement","water pollution detection;Sentinel-2 satellite;Sentinel-3 satellite;illegal discharges;temporary floods;permanent floods;Pacific Ocean;plumes;contaminated water;satellite imagery;diverse multispectral sensors;heterogeneous imagery;water discharges;distance-based supervised machine learning;pixel-wise pollution;Acapulco coasts;Mexico;permanent flood","","1","","11","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Sentinel-2 and Sentinel-3 Intersensor Vegetation Estimation via Constrained Topic Modeling","R. Fernandez-Beltran; F. Pla; A. Plaza","Institute of New Imaging Technologies, University Jaume I, Castelló de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castelló de la Plana, Spain; Hyperspectral Computing Laboratory, University of Extremadura, Cáceres, Spain","IEEE Geoscience and Remote Sensing Letters","25 Sep 2019","2019","16","10","1531","1535","This letter presents a novel intersensor vegetation estimation framework, which aims at combining Sentinel-2 (S2) spatial resolution with Sentinel-3 (S3) spectral characteristics in order to generate fused vegetation maps. On the one hand, the multispectral instrument (MSI), carried by S2, provides high spatial resolution images. On the other hand, the Ocean and Land Color Instrument (OLCI), one of the instruments of S3, captures the Earth's surface at a substantially coarser spatial resolution but using smaller spectral bandwidths, which makes the OLCI data more convenient to highlight specific spectral features and motivates the development of synergetic fusion products. In this scenario, the approach presented here takes advantage of the proposed constrained probabilistic latent semantic analysis (CpLSA) model to produce intersensor vegetation estimations, which aim at synergically exploiting MSI's spatial resolution and OLCI's spectral characteristics. Initially, CpLSA is used to uncover the MSI reflectance patterns, which are able to represent the OLCI-derived vegetation. Then, the original MSI data are projected onto this higher abstraction-level representation space in order to generate a high-resolution version of the vegetation captured in the OLCI domain. Our experimental comparison, conducted using four data sets, three different regression algorithms, and two vegetation indices, reveals that the proposed framework is able to provide a competitive advantage in terms of quantitative and qualitative vegetation estimation results.","1558-0571","","10.1109/LGRS.2019.2903231","Generalitat Valenciana(grant numbers:APOSTD/2017/007); Ministerio de Economía y Competitividad(grant numbers:ESP2016-79503-C2-2-P,TIN2015-63646-C5-5-R); Junta de Extremadura(grant numbers:GR18060); European Union under the H2020 EOXPOSURE project(grant numbers:734541); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674589","Constrained probabilistic latent semantic analysis (CpLSA);Sentinel-2;Sentinel-3;topic models;vegetation estimation","Vegetation mapping;Spatial resolution;Estimation;Analytical models;Instruments;Probabilistic logic;Semantics","feature extraction;geophysical image processing;image colour analysis;image fusion;image resolution;probability;regression analysis;vegetation;vegetation mapping","multispectral instrument;high spatial resolution images;MSI reflectance patterns;OLCI-derived vegetation;Sentinel-3 intersensor vegetation estimation;constrained topic modeling;fused vegetation maps;Sentinel-2 intersensor vegetation estimation;ocean and land color instrument;spectral features;constrained probabilistic latent semantic analysis;regression algorithms","","15","","21","IEEE","26 Mar 2019","","","IEEE","IEEE Journals"
"Fusion of Sun-Synchronous and Geostationary Images for Coastal and Ocean Color Survey Application to OLCI (Sentinel-3) and FCI (MTG)","C. Peschoud; A. Minghelli; S. Mathieu; M. Lei; I. Pairaud; C. Pinazo","Université de Toulon, CNRS, LSIS UMR 7296, Toulon Cedex 9, France; Université de Toulon, CNRS, LSIS UMR 7296, Toulon Cedex 9, France; Thales Alenia Space, Cannes la Bocca, France; Université de Toulon, CNRS, LSIS UMR 7296, Toulon Cedex 9, France; LERPAC Ifremer, Centre Méditerranée, Zone Portuaire de Brégaillon, La Seyne-sur-Mer Cedex, France; Université deToulon, CNRS/INSU, IRD, Mediterranean Institute of Oceanography (MIO), UM 110, La Garde, France","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20 May 2017","2017","10","1","45","56","Open ocean and coastal area monitoring requires multispectral satellite images with a middle spatial resolution (~300 m) and a high temporal repeatability (~1 h). As no current satellite sensors have such features, the aim of this study is to propose a fusion method to merge images delivered by a low earth orbit (LEO) sensor with images delivered by a geostationary earth orbit (GEO) sensor. This fusion method, called spatial spectral temporal fusion (SSTF), is applied to the future sensors- Ocean and Land Color Instrument (OLCI) (on Sentinel-3) and Flexible Combined Imager (FCI) (on Meteosat Third Generation) whose images were simulated. The OLCI bands, acquired at t0, are divided by the oversampled corresponding FCI band acquired at t0 and multiplied by the FCI bands acquired at t1. The fusion product is used for the next fusion at t1 and so on. The high temporal resolution of FCI allows its signal-to-noise ratio (SNR) to be enhanced by the means of temporal filtering. The fusion quality indicator ERGAS computed between SSTF fusion products and reference images is around 0.75, once the FCI images are filtered from the noise and 1.08 before filtering. We also compared the estimation of chlorophyll (Chl), suspended particulate matter (SPM), and colored dissolved organic matter (CDOM) maps from the fusion products with the input simulation maps. The comparison shows an average relative errors on Chl, SPM, and CDOM, respectively, of 64.6%, 6.2%, and 9.5% with the SSTF method. The SSTF method was also compared with an existing fusion method called the spatial and temporal adaptive reflectance fusion model (STARFM).","2151-1535","","10.1109/JSTARS.2016.2558819","Provence-Alpes-Côte d'Azur; Thales Alenia Space; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7487007","Fusion;image simulation;meteosat Third Generation (MTG);ocean color;Ocean and Land Color Instrument","Sensors;Atmospheric modeling;Spatial resolution;Biological system modeling;Image sensors;Sea measurements","geophysical image processing;image fusion;image resolution;ocean composition;oceanographic equipment;underwater optics","sun-synchronous image fusion;geostationary image fusion;open ocean monitoring;coastal area monitoring;multispectral satellite images;spatial resolution;high temporal repeatability;satellite sensors;low earth orbit sensor;geostationary earth orbit sensor;spatial spectral temporal fusion;Ocean and Land Color Instrument;Flexible Combined Imager;Meteosat Third Generation;Flexible Combined Imager band;signal-to-noise ratio;temporal filtering;fusion quality indicator ERGAS;SSTF fusion products;reference images;chlorophyll estimation;suspended particulate matter;colored dissolved organic matter maps;input simulation maps;average relative errors;spatial and temporal adaptive reflectance fusion model","","6","","44","IEEE","8 Jun 2016","","","IEEE","IEEE Journals"
"Data Fusion for Increasing Monitoring Capabilities of Sentinel Optical Data in Marine Environment","M. Kremezi; V. Karathanassi","Laboratory of Remote Sensing, School of Rural and Surveying Engineering, National Technical University of Athens, Athens, Greece; Laboratory of Remote Sensing, School of Rural and Surveying Engineering, National Technical University of Athens, Athens, Greece","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","31 Aug 2020","2020","13","","4809","4815","Marine monitoring constitutes one of the main thematic areas of the Sentinel mission. The Sentinel 3 OLCI (S3) sensor provides satellite data for services relevant to the ocean and land. While the spatial resolution of S3 images (300 m) is suitable for most marine applications, there are some applications such as floating debris detection, suspended mater estimation, etc., that require higher resolution. To fulfill this requirement this study applies an unmixing-based data fusion technique on S3 and BRDF-corrected Sentinel 2 (S2) images and evaluates the fused data by calculating the correlation coefficient and the spectral angle distance (SAD) indexes. Then, it explores the increased monitoring capabilities of the fused image by applying improved chlorophyll-a (Chl-a) and total suspended matter (TSM) algorithms, developed for satellite data. The fused image presents spectral similarity to S3 data and spatial similarity to S2 image. Consequently, the products provided by the fused image have much better resolution than those of S3 image, which enables detailed estimations of Chl-a and TSM concentrations. However, the dynamic nature of the marine environment that results in the formation of time-varying patterns at sea surface, in relation to the time lag between S2 and S3 image acquisitions may locally affect the accuracy of the products in the neighborhood of these patterns. This study exploits the effective elimination of directional reflectance effects in S2 ocean images, interprets the fused image and the generated ocean products, and points out the constraints regarding the synergy of Sentinel optical data for ocean areas.","2151-1535","","10.1109/JSTARS.2020.3018050","European Space Agency(grant numbers:4000131235/20/NL/GLC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171412","Bidirectional reflectance distribution function (BRDF) correction;chlorophyll-a (Chl-a);data fusion;marine monitoring;sentinel;spectral unmixing;total suspended matter (TSM)","Spatial resolution;Oceans;Cloud computing;Data integration;Monitoring;Optical imaging","environmental monitoring (geophysics);geophysical image processing;image fusion;ocean composition;oceanographic techniques;remote sensing;underwater optics","S2 image acquisitions;TSM algorithms;total suspended matter;chlorophyll-a;correlation coefficient;unmixing-based data fusion;spectral angle distance indexes;BRDF-corrected Sentinel 2 images;Sentinel 3 OLCI sensor;Sentinel mission;marine monitoring;sentinel optical data;S2 ocean images;S3 image acquisitions;marine environment;fused image","","","","29","CCBY","19 Aug 2020","","","IEEE","IEEE Journals"
