"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"From Planetscope To Worldview: Micro-Satellite Image Super-Resolution With Optimal Transport Distance","C. Shin; S. Kim; Y. Kim","Agency for Defense Development (ADD), Daejeon, South Korea; Agency for Defense Development (ADD), Daejeon, South Korea; Agency for Defense Development (ADD), Daejeon, South Korea","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","898","902","The vast majority of prior work on satellite image super-resolution (SR) assumes the availability of paired training data, and then uses low-resolution (LR) images artificially generated by simple blurring and/or down-sampling. These methods often fail to produce convincing results in real-world data since the actual degradation is much more complex than manually designed. This paper presents a deep learning framework to model the degradation process of microsatellite image. To this end, we first introduce remote sensing dataset consisting of WorldView (0.4m) and PlanetScope (3m) satellite images. They are aligned to the same coordinate, but are collected at different days/times. Using such data, we design Degradation Network (DegNet), generating realistic micro-satellite images from its high-resolution (HR) counterpart. A degradation loss using an optimal transport distance is proposed which makes the empirical distribution, i.e., histogram of outputs to be similar to that of real microsatellite images. It faithfully reflects the degradation characteristic of micro-satellite while preserving the content of an input. Finally, a SR network is trained with the generated LR-HR pairs. Extensive experiments show that the proposed method greatly improves the SR performance on real-world data.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190810","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190810","Micro-satellite image;generative models;satellite image super-resolution;optimal transport distance;degradation learning","Degradation;Remote sensing;Satellites;Histograms;Image resolution;Training;Generators","deep learning (artificial intelligence);geophysical image processing;image reconstruction;image resolution;remote sensing","low-resolution images;deep learning framework;high-resolution counterpart;optimal transport distance;degradation characteristic;LR-HR pairs;microsatellite image super-resolution;planetscope satellite images;design degradation network;SR network","","1","","27","IEEE","30 Sep 2020","","","IEEE","IEEE Conferences"
"Performance analysis of Satellite Image Super Resolution using Deep Learning Techniques","G. Rohith; L. S. Kumar","Department of Electronics and Communication Engineering, National Institute of Technology Puducherry, Karaikal, Puducherry; Department of Electronics and Communication Engineering, National Institute of Technology Puducherry, Karaikal, Puducherry","2019 IEEE Bombay Section Signature Conference (IBSSC)","30 Jan 2020","2019","","","1","6","Super-resolution has gained significant importance recently owing to its finer sampling image details. Deep learning algorithms have remarked as an entity for developing single image high-quality reconstruction. Super-resolution with Deep Learning algorithms has demonstrated state of the art approaches for reconstructing sharper and more accurate images. Satellite images are highly prone to lose minute details of the image when subjected to algorithmic modeling. Thus, it is necessary to preserve the details of image. In this paper, an attempt is made to incorporate the state of the art approaches for reconstructing the satellite images. This requires careful conditioning of validating parameters like bias value, weights, appropriate usage of filters and scaling factors. The existing super-resolution algorithms such as Bicubic interpolation, Super resolution convolutional neural network (SRCNN), fast Super resolution convolutional neural network (FSRCNN) and Deep Laplacian Pyramid (LapSRN) are simulated to reconstruct the satellite images obtained from benchmark data sets of Indian and International satellite sensors. An extensive quantitative and qualitative evaluation of the super-resolution algorithms shows that the Deep Laplacian Pyramid networks perform favorably against the other state-of-the-art methods exclusively for satellite images.","","978-1-5386-7401-7","10.1109/IBSSC47189.2019.8973105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8973105","Convolution Neural Networks;Deep Laplacian Pyramid;Super Resolution","","convolutional neural nets;geophysical image processing;image reconstruction;image resolution;interpolation;learning (artificial intelligence)","super-resolution algorithms;deep Laplacian pyramid networks;satellite image super resolution;deep learning techniques;single image high-quality reconstruction;deep learning algorithms;sharper images;sampling image details;SRCNN;LapSRN;FSRCNN;fast super resolution convolutional neural network;bicubic interpolation","","1","","11","IEEE","30 Jan 2020","","","IEEE","IEEE Conferences"
"A No-Reference Super Resolution for Satellite Image Quality Enhancement for KOMPSAT-3","Y. Choi; Y. Kim","Korea Aerospace Research Institute, Daejeon, Republic of Korea; Sangmyung University, Cheonan, Republic of Korea","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","220","223","Recently, a deep learning based super-resolution (SR) technology has been applied to satellite images to improve spatial resolution and sharpness, and to increase extractable information. In this paper, we propose a no-reference single image super-resolution method that improves the image quality by doubling spatial resolution of Korea Multi-Purpose Satellite-3 (K3), achieving a ground sampling distance (GSD) of 0.7 m. When training SR networks, the proposed method generates low-resolution (LR) images by applying the degradation model to K3 images and creates enhanced high-resolution images (HRe) by applying the top and bottom hat transformation to the original high-resolution (HRo) images. As a result of applying SR to the original K3 image, it was possible to obtain an image with improved quality. Additionally, as a result of testing the Baotou area used for satellite image quality evaluation, it was confirmed that the resolution is similar to the spatial resolution of Korea Multi-Purpose Satellite-3A (K3A), which is a GSD of 0.55 m.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324422","super-resolution;KOMPSAT-3;satellite;top and bottom hat;deep learning","Training;Degradation;Superresolution;Satellites;Spatial resolution;Remote sensing;Image edge detection","artificial satellites;deep learning (artificial intelligence);image enhancement;image resolution","satellite image quality enhancement;KOMPSAT-3;satellite images;spatial resolution;no-reference single image super-resolution method;SR networks;low-resolution images;satellite image quality evaluation;Korea multipurpose satellite-3A;K3 image;GSD;enhanced high-resolution images;HRe;original high-resolution images;HRo;LR;ground sampling distance","","1","","12","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Satellite image Super-Resolution using overlapping blocks via sparse representation","V. Alvarez-Ramos; V. Ponomaryov; R. Reyes-Reyes; F. Gallegos-Funes","Instituto Politecnico Nacional ESIME Culhuacan, Mexico City, Mexico; Instituto Politecnico Nacional ESIME Culhuacan, Mexico City, Mexico; Instituto Politecnico Nacional ESIME Culhuacan, Mexico City, Mexico; Instituto Politecnico Nacional ESIME Culhuacan, Mexico City, Mexico","2016 9th International Kharkiv Symposium on Physics and Engineering of Microwaves, Millimeter and Submillimeter Waves (MSMW)","11 Aug 2016","2016","","","1","4","In image processing the Super-Resolution (SR) has played an important role by acquiring High-Resolution (HR) images from the corresponding Low-Resolution (LR) images. In this paper, a Super-Resolution technique for satellite images is proposed but it can be used on images of different nature. In the current proposal to achieve a HR image, it is necessary an intermediate step, which consists in performing an initial interpolation, then features are extracted from this initial image, here, it is necessary to reduce the information obtained by the features extraction via principal component analysis (PCA). Patches are extracted from the initial image and the reduction via PCA. For each patch, the sparse representation is obtained and then, it is used to recover the HR image. By using the quality objective criteria PSNR and SSIM, the proposed technique is evaluated and shows a superiority in comparison against other existing proposals.","","978-1-5090-2267-0","10.1109/MSMW.2016.7538183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7538183","super-resolution;sparse representation;feature-extraction;satellite images;PCA;PSNR;SSIM","Feature extraction;Image resolution;Interpolation;Dictionaries;Matching pursuit algorithms;Satellites;Principal component analysis","feature extraction;geophysical image processing;image representation;image resolution;interpolation;principal component analysis","satellite image super resolution;overlapping blocks;sparse representation;image processing;SR;high resolution images;HR images;low resolution images;LR images;super resolution technique;satellite images;interpolation;features extraction;principal component analysis;PCA","","4","","19","IEEE","11 Aug 2016","","","IEEE","IEEE Conferences"
"On Training Deep Networks for Satellite Image Super-Resolution","M. Kawulok; S. Piechaczek; K. Hrynczenko; P. Benecki; D. Kostrzewa; J. Nalepa","Future Processing, Gliwice, Poland; Future Processing, Gliwice, Poland; Future Processing, Gliwice, Poland; Future Processing, Gliwice, Poland; Future Processing, Gliwice, Poland; Future Processing, Gliwice, Poland","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3125","3128","The capabilities of super-resolution (SR) reconstruction (i.e., techniques for enhancing image spatial resolution) have been boosted recently by the use of deep convolutional neural networks. For SR, they are learned using huge training sets composed of original images, each of which is coupled with a low-resolution counterpart. In this paper, we explore how the SR performance depends on the procedure employed to obtain the training data. Up to date, this has not been given much attention-commonly, bicubic downsampling is used. Our extensive experimental study indicates that the training data characteristics have a large impact on the reconstruction accuracy, and the widely-adopted approach is not the most effective for dealing with satellite images. Overall, we argue that developing better training data preparation routines may be pivotal in making SR suitable for real-world applications.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899098","Super-resolution reconstruction;deep learning;convolutional neural networks;satellite imaging","Image reconstruction;Satellites;Training;Artificial neural networks;Training data;Degradation","convolutional neural nets;image enhancement;image reconstruction;image resolution;learning (artificial intelligence)","satellite image super-resolution;super-resolution reconstruction;image spatial resolution enhancement;deep convolutional neural networks;huge training sets;low-resolution counterpart;SR performance;training data characteristics;training data preparation routines;SR suitable;deep network training;SR reconstruction","","5","","12","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Gradient-Based Adaptive Image Super Resolution","A. Junaidi; C. -H. Lin; Y. -H. Tseng; L. -H. Chang; S. -C. Peng","Department of Geomatics, National Cheng Kung University, Taiwan; Department of Geomatics, National Cheng Kung University, Taiwan; Department of Geomatics, National Cheng Kung University, Taiwan; Satellite Image Division, National Space Organization, Taiwan; Satellite Image Division, National Space Organization, Taiwan","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2774","2777","Super-resolution (SR) has been used in the realm of remote sensing to improve the resolution of an image and get more detailed spatial information than the original image captured by the sensor on the acquisition device. Several SR methods with different approaches, only focusing on sharpening the edges and forgetting non-edge areas. One of the SR methods that utilize prior gradients, can produce high resolution (HR) images in a short time and produce sharp images for nonhomogeneous areas. But for areas that tend to be homogeneous, a lot of noise appears. This problem will affect the remote sensing process due to the amount of noise that arises. This paper offers to use dynamic weighting on the gradient prior that will reduce the noise on the homogeneous area, while still able to maintains to produce the sharp edges in non-homogeneous areas. An experimental comparison is conducted on both homogeneous and non-homogeneous area using the previous method and the proposed method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900578","Image super-resolution;dynamic weighting;gradient-based;gradient prior;image reconstruction","Image edge detection;Image reconstruction;Correlation;Satellites;Spatial resolution","gradient methods;image resolution;remote sensing","acquisition device;SR methods;high resolution images;remote sensing process;sharp edges;nonhomogeneous area;gradient-based adaptive image super resolution;spatial information;sharp image production","","","","13","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Satellite Image Small Target Application Based on Deep Segmented Residual Neural Network","Z. Wei; Y. Liu","Changchun University of Science and Technology, Changchun, Jilin, China; Changchun University of Science and Technology, Changchun, Jilin, China","2020 IEEE International Conference on Mechatronics and Automation (ICMA)","26 Oct 2020","2020","","","100","104","This study employs a deep segmented residual neural network model to analyze the super-resolution of a single satellite image. A deep convolutional neural network model was analyzed, and its performance was improved. We proposed two residual layers to divide the deep network into two groups, the sum of the two residuals is the total residual, which can minimize the residual loss function and enhance the network performance. The experimental model achieved high peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) than networks without the proposed improvements when tested on satellite images. Considering these results, the application of this technology will be significant for further research on satellite images.","2152-744X","978-1-7281-6416-8","10.1109/ICMA49215.2020.9233819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9233819","Satellite image;Super resolution;Deep residual neural network;Mish activation function","Image segmentation;Analytical models;Satellites;PSNR;Mechatronics;Image recognition;Target recognition","aerospace computing;convolutional neural nets;image processing;prediction theory","satellite image small target application;deep segmented residual neural network model;deep convolutional neural network model;residual layers;residual loss function;network performance;structural similarity index;SSIM;peak signal-to-noise ratio;PSNR","","1","","20","IEEE","26 Oct 2020","","","IEEE","IEEE Conferences"
"GCD Based Blind Super-Resolution for Remote Sensing Applications","N. Sharma; P. P. Dash; P. Saxena","Dept. of Elecntronics and Communication Engg, Birla Institute of Technology, Mesra, Ranchi, India; Dept. of Elecntronics and Communication Engg, Birla Institute of Technology, Mesra, Ranchi, India; Dept. of Elecntronics and Communication Engg, Birla Institute of Technology, Mesra, Ranchi, India","2018 2nd International Conference on Power, Energy and Environment: Towards Smart Technology (ICEPE)","7 Mar 2019","2018","","","1","6","The importance of remote sensing imageries is growing day by day. Extraction of fine details of desired regions worth for further processing and decision making. Usually the data bases of remote sensing imageries are very huge that overburden the processor. Super-Resolution overcomes this problem and yields a high-quality output in less time consumption. This paper aims to give a brief idea about one of the approaches of super-resolution known as blind super-resolution reconstruction approach. In this approach, Greatest Common Divisor (GCD) algorithm is embedded into the blind reconstruction technique. The HR images obtained from this method is compared with the interpolated images. The results shows the efficacy of the proposed method. The paper tries to overcome the limitations of the super resolution approach and a conclusive discussion of the whole method has been discussed.","","978-1-5386-4769-1","10.1109/EPETSG.2018.8658528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658528","Remote sensing;Satellite image;Super resolution;GCD;Blind reconstruction","Image resolution;Image reconstruction;Satellites;Mathematical model;Signal to noise ratio;Remote sensing;Signal resolution","decision making;geophysical image processing;image reconstruction;image resolution;interpolation;remote sensing","super resolution approach;blind reconstruction technique;Greatest Common Divisor algorithm;blind super-resolution reconstruction approach;remote sensing imageries;remote sensing applications;GCD based blind super-resolution","","","","9","IEEE","7 Mar 2019","","","IEEE","IEEE Conferences"
"CSRDNN: An Integrated Scheme for Single Satellite Image Colorization and Super-Resolution Using Deep Neural Networks","J. Feng; Q. Jiang; X. Jin; C. -H. Tseng; S. -J. Lee; S. Yao","School of Software Yunnan University, Kunming, China; School of Software Yunnan University, Kunming, China; School of Software Yunnan University, Kunming, China; Department of computer science, University of Manchester Manchester, UK; Institute of Technology Management, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Engineering Research Center of Cyberspace, Yunnan University, Kunming, China","2021 International Joint Conference on Neural Networks (IJCNN)","23 Sep 2021","2021","","","1","9","Deep convolutional neural networks have respectively achieved significant success in image super-resolution and colorization. The DNN has a strong capability to generate high quality images. Both colorization and super-resolution (SR) can be regarded as an independent pixel mapping problem, and this work combines these two visual problems into an integrated task. In this work, we propose an end-to-end model for accomplishing single satellite image colorization and SR simultaneously. Our model comprises two phases: features extraction network and recovery network. First, the residual receptive field block structure is introduced in features extraction network to learn better feature representations for image colorization and SR. Residual Receptive Field Block(RRFB) is improved by expanding the receptive field and enhancing the context connection from inception model. Second, the extracted features are transformed to a color high-resolution image by a recovery architecture. In this work, U-net is employed as the key structure of the recovery architecture. Besides, the squeeze-and-excitation blocks and complex residual blocks are incorporated into the proposed model to increase the reconstruction performance. To verify the performance, our method is compared with the state-of-the-art methods of SR and colorization. The experiments show that proposed method can get competitive in visual effect and evaluation index compared with the existing methods. In the end, the panchromatic dataset is also used to validate our model, and a good color high-resolution image can be obtained by giving a gray and low-resolution panchromatic image.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9534383","National Natural Science Foundation of China(grant numbers:62002313,61863036); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534383","Deep neural network;single image super-resolution;image colorization;satellite image processing","Deep learning;Satellites;Image color analysis;Superresolution;Computer architecture;Feature extraction;Visual effects","convolutional neural nets;deep learning (artificial intelligence);feature extraction;image colour analysis;image reconstruction;image representation;image resolution","single satellite image colorization;deep neural networks;convolutional neural networks;image super-resolution;high quality images;independent pixel mapping problem;feature extraction network;recovery network;residual receptive field block structure;feature representations;recovery architecture;complex residual blocks;high-resolution image;low-resolution panchromatic image;CSRDNN;gray panchromatic image;U-net;squeeze-and-excitation blocks;visual effect;evaluation index","","","","27","IEEE","23 Sep 2021","","","IEEE","IEEE Conferences"
"Fused Recurrent Network Via Channel Attention For Remote Sensing Satellite Image Super-Resolution","X. Li; D. Zhang; Z. Liang; D. Ouyang; J. Shao","University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China","2020 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2020","2020","","","1","6","Remote sensing satellite images often suffer from low spatial resolution. Image super-resolution plays an important role in remote sensing image processing. However, existing methods show that increasing network depth will inevitably lead to the dramatic increase of model parameters and the over-fitting problem. Besides, most methods treat different types of information (low-frequency and high-frequency) equally. Motivated by these observations, we propose a fused recurrent network via channel attention (CA-FRN) in this paper. The basic module, recursive channel attention block (RCAB), pays enough attention to the high-frequency information and diminishes the low-frequency information adaptively through channel attention. Based on RCAB, we render our model effective by retaining and fusing hierarchical local information of both low-resolution and high-resolution, and we enhance the network performance simply by increasing the number of RCABs without adding extra parameters. We evaluate the proposed model on satellite images from different datasets, and the proposed CA-FRN is superior to the state-of-the-art methods. Code is available at https://github.com/lxy0922/CAFRN.","1945-788X","978-1-7281-1331-9","10.1109/ICME46284.2020.9102948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102948","Satellite image super-resolution;fused recurrent network;channel attention","Satellites;Remote sensing;Spatial resolution;Recurrent neural networks;Feature extraction;Image reconstruction","artificial satellites;geophysical image processing;image fusion;image resolution;recurrent neural nets;remote sensing","remote sensing satellite image super-resolution;low spatial resolution;remote sensing image processing;fused recurrent network;recursive channel attention block;RCAB;high-frequency information;low-frequency information;hierarchical local information;CA-FRN","","1","","23","IEEE","9 Jun 2020","","","IEEE","IEEE Conferences"
"Multiframe Video Satellite Image Super-Resolution via Attention-Based Residual Learning","Z. He; J. Li; L. Liu; D. He; M. Xiao","Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), Guangdong Provincial Key Laboratory of Urbanization and Geo-Simulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), Guangdong Provincial Key Laboratory of Urbanization and Geo-Simulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Department of Geography, University of Cincinnati (UC), Cincinnati, OH, USA; City College of Dongguan University of Technology, Dongguan, China; Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), Guangdong Provincial Key Laboratory of Urbanization and Geo-Simulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China","IEEE Transactions on Geoscience and Remote Sensing","4 Jan 2022","2022","60","","1","15","Video satellite can generate video image sequences with rich dynamic information, thus providing a new way for monitoring moving objects. However, to maintain high temporal resolution, video satellite images usually sacrifice their spatial resolution. Therefore, super-resolution (SR) plays a vital role in improving the quality of video satellite images. In this article, we propose a multiframe video SR neural network (MVSRnet) for video satellite image SR reconstruction. The proposed MVSRnet consists of three main subnetworks: an optical flow estimation subnetwork (OFEnet), an upscaling subnetwork (Upnet) and an attention-based residual learning subnetwork (ARLnet). The OFEnet aims to estimate low-resolution (LR) optical flow of multiple image frames. Upnet is then constructed to enhance the resolution of both input frames and the estimated LR optical flows. Motion compensation is subsequently performed according to the high-resolution (HR) optical flows. Finally, the compensated HR cube is fed to the ARLnet to generate SR results. Different from existing video satellite image SR methods, the proposed MVSRnet is a multiframe-based method with an attention mechanism, which can merge the motion information among adjacent frames and highlight the importance of extracted features. Experiments conducted on Jilin-1 and OVS-1 video satellite images demonstrate that the proposed MVSRnet significantly outperforms some state-of-the-art SR methods.","1558-0644","","10.1109/TGRS.2021.3072381","National Key Research and Development Program of China(grant numbers:2020YFA0714103,2018YFB0505503,2017YFC1502706); Innovation Group Project of Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai)(grant numbers:311021018); National Key Laboratory of Science and Technology on Automatic Target Recognition(grant numbers:WDZC20205500205); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2019A1515011877); Fundamental Research Funds for the Central Universities(grant numbers:19lgzd10); Guangzhou Science and Technology Planning Project(grant numbers:202002030240); Key-Area Research and Development Program of Guangdong Province(grant numbers:2020B0202010002); 2018 Key Research Platforms and Research Projects of Ordinary Universities in GuangDong Province(grant numbers:2018KQNCX360); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442915","Attention;multiframe super-resolution (SR);optical flow estimation;remote sensing;residual learning;video satellite","Satellites;Optical imaging;Satellite broadcasting;Optical sensors;Spatial resolution;Image reconstruction;Convolution","feature extraction;geophysical image processing;image reconstruction;image resolution;image sequences;learning (artificial intelligence);motion compensation;neural nets;video signal processing","video image sequences;high temporal resolution;spatial resolution;multiframe video SR neural network;MVSRnet;video satellite image SR reconstruction;attention-based residual learning subnetwork;low-resolution optical flow;image frames;high-resolution optical flows;video satellite image SR methods;OVS-1 video satellite images;multiframe video satellite image superresolution;OFEnet;upscaling subnetwork;Upnet;ARLnet;motion compensation;feature extraction;Jilin-1 video satellite images;LR optical flow estimation;HR cube compensation","","4","","53","IEEE","27 May 2021","","","IEEE","IEEE Journals"
"A Super-Resolution Mapping Using a Convolutional Neural Network","T. Kasetkasem","Department of Electrical Engineering, Kasetsart University, Bangkok, Thailand","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3077","3080","In this paper, we propose an approach for super-resolution land cover mapping on remote sensing images based on a Convolutional Neural Network (CNN). Here, the CNN is trained to match the input subimages to the super resolution map around the training pixels. Since there are so many possible configurations of super-resolution map on a given set of pixels, a large number of training samples are required. To reduce the number of training samples, we converted the super-resolution to a set of level set functions and used the minimum mean square error between the predicted and actual level set functions as the training objective. The QUICKBIRD satellite image data cover a part of Kasetsart University's Bangkhen campus was used for evaluation. Experimental results showed that the proposed method has achieved superior accuracy than both Hopfield and Pixel-Swapping methods.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898537","super-resolution mapping;convolutional neural network;level set function","Training;Level set;Remote sensing;Spatial resolution;Convolutional neural networks","geophysical image processing;image classification;image resolution;neural nets;terrain mapping","convolutional neural network;super-resolution land cover mapping;training pixels;minimum mean square error;QUICKBIRD satellite image data;Hopfield method;Pixel-Swapping method;Kasetsart University;Bangkhen campus;input subimages","","1","","7","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"A Two-step Spatio-Temporal satellite image Fusion Model for temporal changes of various LULC under one-pair prior images scenario","Yongquan Zhao; B. Huang","Department of Geography and Resource Management, The Chinese University of Hong Kong, Hong Kong, China; Department of Geography and Resource Management, The Chinese University of Hong Kong, Hong Kong, China","2016 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","24 Nov 2016","2016","","","1","5","This paper proposes a two-step spatio-temporal fusion model (TSTFM) for generating synthetic satellite remote sensing images with high-spatial and high-temporal resolution (HSaHTeR) based on one pair of prior images, which contain one low-spatial but high-temporal resolution (LSaHTeR) image and one high-spatial but low-temporal resolution (HSaLTeR) image. Considering both phenology and type surface temporal changes, the two steps in TSTFM are adopted to handle these two kinds of changes respectively, which are based on weighted mean and example-based image super-resolution approaches accordingly. In addition, a relative radiometric normalization process is conducted before performing the two-step spatio-temporal fusion (STF) process, which aims to calibrate radiometric differences of different kinds of satellite sensors. The proposed method was tested on two sets of test data: surface with mainly LULC phenology changes and surface with primarily LULC type changes. Experimental results show that TSTFM can capture both phenology and type changes efficiently and precisely even with one-pair prior images, and it can also maintain its robustness when facing extremely complex LULC.","","978-1-5090-2708-8","10.1109/ICSPCC.2016.7753699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7753699","Spatio-temporal fusion;weighted mean;image super-resolution;phenology change;type change;various LULC","MODIS;Satellites;Remote sensing;Earth;Spatial resolution;Satellite broadcasting","geophysical image processing;image fusion;image resolution;land use;radiometry;remote sensing","two-step spatio-temporal satellite image fusion model;LULC;one-pair prior images scenario;synthetic satellite remote sensing images;high-spatial and high-temporal resolution image;low-spatial but high-temporal resolution image;high-spatial but low-temporal resolution image;type surface temporal changes;phenology changes;TSTFM;weighted mean;example-based image super-resolution;relative radiometric normalization process;STF process;HSaHTeR image;LSaHTeR image;HSaLTeR image","","","","9","IEEE","24 Nov 2016","","","IEEE","IEEE Conferences"
"Improved SRCNN for super-resolution reconstruction of retinal images","Y. Lv; H. Ma","College of Electronic Engineering, Heilongjiang University, Harbin, China; College of Electronic Engineering, Heilongjiang University, Harbin, China","2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP)","26 Apr 2021","2021","","","595","598","Image super-resolution reconstruction means to recover high resolution image from low resolution image. It is widely used in satellite image, city monitoring, medical treatment and other fields. Medical image processing usually requires a high level of image detail. We designed an improved SRCNN for super-resolution reconstruction of retinal images (ISRCNN). In the image reconstruction part of this network, deconvolution was adopted for up-sampling to reconstruct high-resolution retinal images. Secondly, we deepened the layers of the network and adopted dense connections to improve the ability of network feature extraction. Finally, we adopted ReZero residue learning method, which could not only avoid the gradient disappearance or explosion caused by excessively deep network, but also help to reconstruct the detailed information of retinal image. We test models on DRIVE data sets, the results showed that our approach was effective in reconstructing retinal images.","","978-1-6654-0413-6","10.1109/ICSP51882.2021.9408850","Heilongjiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408850","super-resolution;ReZero residue;retinal images","Satellites;Superresolution;Urban areas;Neural networks;Medical treatment;Retina;Feature extraction","eye;feature extraction;image enhancement;image reconstruction;image resolution;medical image processing","improved SRCNN;super-resolution reconstruction;retinal image;high resolution image;low resolution image;satellite image;medical image processing;image reconstruction part;high-resolution retinal images","","1","","10","IEEE","26 Apr 2021","","","IEEE","IEEE Conferences"
"MSISR : Modified Single Image Super-Resolution Using Relu Based 2D CNN For Satellite Images","S. R. Soni; K. Pandey; V. Sharma","Department of Computer Science (CSE), T.I.T, Bhopal (M.P.), INDIA; Department of Computer Science (CSE), T.I.T, Bhopal (M.P.), INDIA; Department of Computer Science (CSE), T.I.T, Bhopal (M.P.), INDIA","2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT)","26 Dec 2022","2022","","","1","7","In this research, we presented a Modified Single Image Super-Resolution (MSISR) using enhanced very deep super resolution (VDSR). The suggested technique is based on convolutional neural networks and uses up-sampling and residual inputs for training (an essential part of SISR) with a level of 20. The proposed method hybrid fusion of the enhanced bi-cubic method. The proposed MSISR shows better result in terms of peak signal to noise ratio as well as structural similarity index measurement. The proposed method also show good visual outcomes as compare to other previous techniques in terms of butter and resolution. These two factors play a significant role in the outcome analysis of image super resolution (ISR). For the analysis of proposed method use standard data sets like the UC Mecred Field. Data Set are available for the training and testing of the proposed approach. For the simulation of proposed method used well know tool that is matrix laboratory version R2020B.","","978-1-6654-5262-5","10.1109/ICCCNT54827.2022.9984280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9984280","Deep neural network;Satellite Image;synthetic aperture radar (SAR);Remote Sensing Image;up sampling;Residual;Relu;CNN and hybrid fusion","Training;Visualization;Satellites;Spaceborne radar;Superresolution;Sensors;Convolutional neural networks","convolutional neural nets;geophysical image processing;gradient methods;image resolution;regression analysis","convolutional neural networks;deep super resolution;enhanced bi-cubic method;image super resolution;modified single image super-resolution;MSISR;Relu based 2D CNN;satellite images;UC mecred field;very deep super resolution","","","","28","IEEE","26 Dec 2022","","","IEEE","IEEE Conferences"
"Fusion of Deep and Non-Deep Methods for Fast Super-Resolution of Satellite Images","G. Kumar Nayak; S. Jain; R. Venkatesh Babu; A. Chakraborty","Department of Computational and Data Sciences, Indian Institute of Science, Bangalore, India; Department of Computational and Data Sciences, Indian Institute of Science, Bangalore, India; Department of Computational and Data Sciences, Indian Institute of Science, Bangalore, India; Department of Computational and Data Sciences, Indian Institute of Science, Bangalore, India","2020 IEEE Sixth International Conference on Multimedia Big Data (BigMM)","20 Oct 2020","2020","","","267","271","In the emerging commercial space industry there is a drastic increase in access to low cost satellite imagery. The price for satellite images depends on the sensor quality and revisit rate. This work proposes to bridge the gap between image quality and the price by improving the image quality via super-resolution (SR). Recently, a number of deep SR techniques have been proposed to enhance satellite images. However, none of these methods utilize the region-level context information, giving equal importance to each region in the image. This, along with the fact that most state-of-the-art SR methods are complex and cumbersome deep models, the time taken to process very large satellite images can be impractically high. We, propose to handle this challenge by designing an SR framework that analyzes the regional information content on each patch of the low-resolution image and judiciously chooses to use more computationally complex deep models to super-resolve more structure-rich regions on the image, while using less resource-intensive non-deep methods on non-salient regions. Through extensive experiments on a large satellite image, we show substantial decrease in inference time while achieving similar performance to that of existing deep SR methods over several evaluation measures like PSNR, MSE and SSIM.","","978-1-7281-9325-0","10.1109/BigMM50055.2020.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9232612","Fast Super-Resolution;Satellite Imagery;Deep Neural Networks","Image edge detection;Satellites;Interpolation;Spatial resolution;Training;Feature extraction;Task analysis","artificial satellites;geophysical image processing;image resolution;learning (artificial intelligence)","fast super-resolution;satellite image resolution;low cost satellite imagery;image quality;deep SR techniques;state-of-the-art SR methods;low-resolution image;complex deep models;resource-intensive nondeep methods;deep SR methods;sensor quality;regional information content;nonsalient regions;inference time","","1","","17","IEEE","20 Oct 2020","","","IEEE","IEEE Conferences"
"Super-Resolution of Satellite Images Based on Two-Dimensional RRDB and Edge-Enhanced Generative Adversarial Network","Y. -Z. Chen; T. -J. Liu; K. -H. Liu","Department of Electrical Engineering, Graduate Institute of Communication Engineering, National Chung Hsing University, Taichung, Taiwan; Department of Electrical Engineering, Graduate Institute of Communication Engineering, National Chung Hsing University, Taichung, Taiwan; Department of Computer Science and Information Engineering, National Taichung University of Science and Technology, Taichung, Taiwan","2022 IEEE International Conference on Consumer Electronics (ICCE)","15 Mar 2022","2022","","","1","4","With the increasing demand for high-resolution images, image super-resolution (SR) technology has become one of the focuses in related research fields. Generally speaking, high resolution is usually achieved by increasing the density and accuracy of the sensor. However, such an approach is quite expensive for equipment and design. In particular, increasing the density of satellite sensors must be undertaken great risks. Inspired by EEGAN and based on it, the Ultra-Dense Subnet (UDSN) and Edge Enhanced Network (EEN) were modified. Among them, the UDSN is used for feature extraction and obtains high-resolution results that look clear in the intermediate but are deteriorated by artifacts, and the Edge-Enhanced Subnet (EESN) is used to purify, extract and enhance the image contour and use mask processing to eliminate images contaminated by noise. Finally, the restored intermediate image and the enhanced edge are combined to produce a high-resolution image with high credibility and clear content. We use Kaggle open experimental dataset to test and compare the results among different methods. It proves the performance of the proposed model is better than other SR methods.","2158-4001","978-1-6654-4154-4","10.1109/ICCE53296.2022.9730339","Ministry of Science and Technology, Taiwan(grant numbers:MOST 107-2221-E-005-068-MY2,MOST 109-2221-E-005-059); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9730339","Super-resolution(SR);satellite images;generative adversarial network (GAN);residual in residual dense block (RRDB)","Visualization;Satellites;Image edge detection;Superresolution;Network architecture;Feature extraction;Generative adversarial networks","feature extraction;image enhancement;image resolution","image contour;use mask processing;intermediate image restoration;high-resolution image;satellite image super-resolution;satellite sensors;edge-enhanced generative adversarial network;obtains high-resolution results;two-dimensional RRDB;edge-enhanced subnet;EEN;EESN;SR methods","","","","20","IEEE","15 Mar 2022","","","IEEE","IEEE Conferences"
"Arbitrary scale super resolution network for satellite imagery","J. Fang; J. Xiao; X. Wang; D. Chen; R. Hu","National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan 430072, China; Collaborative Innovation Center of Geospatial Technology, Wuhan 430079, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan 430072, China; Collaborative Innovation Center of Geospatial Technology, Wuhan 430079, China; National University of Defense Technology, Wuhan 430015, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan 430072, China; Collaborative Innovation Center of Geospatial Technology, Wuhan 430079, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan 430072, China; Collaborative Innovation Center of Geospatial Technology, Wuhan 430079, China","China Communications","18 Aug 2022","2022","19","8","234","246","Recently, satellite imagery has been widely applied in many areas. However, due to the limitations of hardware equipment and transmission bandwidth, the images received on the ground have low resolution and weak texture. In addition, since ground terminals have various resolutions and real-time playing requirements, it is essential to achieve arbitrary scale super-resolution (SR) of satellite images. In this paper, we propose an arbitrary scale SR network for satellite image reconstruction. First, we propose an arbitrary upscale module for satellite imagery that can map low-resolution satellite image features to arbitrary scale enlarged SR outputs. Second, we design an edge reinforcement module to enhance the high-frequency details in satellite images through a two-branch network. Finally, extensive upsample experiments on WHU-RS19 and NWPU-RESISC45 datasets and subsequent image segmentation experiments both show the superiority of our method over the counterparts.","1673-5447","","10.23919/JCC.2022.08.017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9861276","satellite imagery;super resolution;arbitrary upscale;edge reinforcement;video satellite","Satellites;Image edge detection;Feature extraction;Image resolution;Representation learning;Image reconstruction;Tensors","geophysical image processing;image reconstruction;image resolution;image segmentation","arbitrary scale super resolution network;satellite imagery;hardware equipment;transmission bandwidth;ground terminals;real-time playing requirements;arbitrary scale super-resolution;satellite images;arbitrary scale SR network;satellite image reconstruction;arbitrary upscale module;map low-resolution satellite image features;subsequent image segmentation experiments;WHU-RS19;NWPU-RESISC45 datasets","","","","","","17 Aug 2022","","","IEEE","IEEE Magazines"
"Fast Unsupervised Spatiotemporal Super-Resolution for Multispectral Satellite Imaging Using Plug-and-Play Machinery Strategy","C. -H. Lin; C. -Y. Sie; P. -Y. Lin; J. -T. Lin","Miin Wu School of Computing, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2568","2571","Acquiring high-spatial-resolution (HSR) images at high temporal sampling rate is not economical and even not achievable using contemporary multispectral satellite imaging hardware. An alternative is to fuse a set of HSR images acquired at low sampling rate, with another set of low-spatial-resolution images acquired at high sampling rate, and such fusion problem is referred to as spatiotemporal super-resolution (STSR). We mitigate the ill-posedness of the STSR problem by incorporating the image self-similarity prior (S2P), which is the key behind the design of several state-of-the-art imaging inverse problems. Unlike most super-resolution works in the computer vision area, our method does not rely on collecting big data. Instead, we propose a fully unsupervised STSR method by adopting the popular strategy in machine learning, known as plug-and-play optimization, and by carefully refining the required matrix computation/inversion. We term our method as STSRS2P, whose superiority and low computational complexity will be experimentally verified.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554710","Einstein Program (Young Scholar Fellowship Program) of Ministry of Science and Technology (MOST), Taiwan(grant numbers:MOST 109-2636-E-006-022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554710","Multispectral satellite;image fusion;spatiotemporal super-resolution;image self-similarity;plug-and-play","Computer vision;Satellites;Superresolution;Refining;Imaging;Big Data;Benchmark testing","","","","1","","14","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Remote sensing recognition of residential areas based on GF-4 satellite image","W. Wu; W. Liu","National Disaster Reduction Center of China, Ministry of Civil Affairs, Beijing, China; 12th department, Beijing Institute of Space Mechanics & Electricity, Beijing, China","2018 Fifth International Workshop on Earth Observation and Remote Sensing Applications (EORSA)","3 Jan 2019","2018","","","1","4","Residential area is an important place for human habitation and life. Using remote sensing technology to identify residential areas is of great value for land resources planning and utilization, disaster prevention and relief and other fields. As the world's first high resolution optical remote sensing satellite for geosynchronous orbit, GF-4 satellite has high time resolution, medium spatial resolution and multispectral land detection capability, which provides a new data resource for residential monitoring. Closely combining with the detection characteristics of the GF-4 satellite, this paper proposes a remote sensing identification method based on GF-4 satellite, and the recognition ability of the GF-4 satellite to the residential area is analyzed. The remote sensing recognition of residential areas is mainly divided into four steps. First, Super-resolution image enhancement technology is used to improve the spatial resolution of GF-4 satellite PMS image. Then, the resolution enhanced image is processed by geometric correction, radiometric calibration and atmospheric correction. Third, the existing land use and land cover data are selected as prior knowledge to select typical sample areas. Based on the spectral characteristics and spectral relationship of different objects in GF-4 satellite image, decision tree classification method is used to eliminate the obvious non-residential areas such as cloud, vegetation, water and shadow, so as to reduce the subsequent data processing and reduce the false recognition rate in residential area. Finally, SVM classifier is selected for the classification of residential areas. Taking GF-4 satellite data in Jiashan county as experiment, the result shows that the user accuracy of resident recognition by this method is 89.96%, which is significantly higher than that without resolution enhancement in the same method. Besides, the spatial scope of the county and township residents can be effectively identified in GF-4 enhanced image.","","978-1-5386-6642-5","10.1109/EORSA.2018.8598622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598622","GF-4;Residential area recognition;Remote sensing information extraction","Spatial resolution;Remote sensing;Satellites;Satellite broadcasting;Reflection;Image recognition","decision trees;disasters;geophysical image processing;image classification;image enhancement;land cover;land use;land use planning;remote sensing;support vector machines","residential area;GF-4 satellite image;remote sensing technology;disaster prevention;remote sensing identification method;remote sensing recognition;Super-resolution image enhancement technology;GF-4 satellite PMS image;resolution enhanced image;land cover data;nonresidential areas;GF-4 satellite data;GF-4 enhanced image;land use;decision tree classification method;residential monitoring;SVM classifier","","1","","7","IEEE","3 Jan 2019","","","IEEE","IEEE Conferences"
"TransRes: A Deep Transfer Learning Approach to Migratable Image Super-Resolution in Remote Urban Sensing","Y. Zhang; R. Zong; J. Han; D. Zhang; T. Rashid; D. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA","2020 17th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)","4 Aug 2020","2020","","","1","9","Recent advances in remote sensing provide a powerful and scalable sensing paradigm to capture abundant visual information about the urban environments. We refer to such a sensing paradigm as remote urban sensing. In this paper, we focus on a migratable satellite image super-resolution problem in remote urban sensing applications. Our goal is to reconstruct satellite images of a high resolution in a target area where the high-resolution training data is not available by transferring a super-resolution model learned in a source area where such data is available. This problem is motivated by the limitation of current solutions that primarily rely on a rich set of high-resolution satellite images in the studied area that are not always available. Two important challenges exist in solving our problem: i) the target and source areas often have very different urban characteristics that prevent the direct application of a super-resolution model learned from the source area to the target area; ii) it is not a trivial task to ensure effective model migration with desirable quality without sufficient high quality training data. To address the above challenges, we develop TransRes, a deep adversarial transfer learning framework, to effectively reconstruct high-resolution satellite images without requiring any ground-truth training data from the studied area. We evaluate the TransRes framework using the real-world satellite imagery data collected from three different cities in Europe. The results show that TransRes consistently outperforms the state-of-the-art baselines by achieving the lowest perception errors under various application scenarios.","2155-5494","978-1-7281-6630-8","10.1109/SECON48991.2020.9158410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9158410","Urban Sensing;Remote Sensing;Migratable Image Super-Resolution;Transfer Learning","Satellites;Sensors;Image reconstruction;Spatial resolution;Urban areas;Training data","geophysical image processing;geophysical signal processing;image classification;image reconstruction;image resolution;image sensors;learning (artificial intelligence);remote sensing","TransRes;deep transfer;migratable image super-resolution;remote sensing;powerful sensing paradigm;scalable sensing paradigm;abundant visual information;urban environments;migratable satellite image super-resolution problem;remote urban sensing applications;high-resolution training data;super-resolution model;source area;high-resolution satellite images;source areas;different urban characteristics;effective model migration;sufficient high quality training data;deep adversarial transfer learning framework;ground-truth training data;real-world satellite imagery data","","7","","39","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Video Satellite Imagery Super Resolution via Convolutional Neural Networks","Y. Luo; L. Zhou; S. Wang; Z. Wang","Collaborative Innovation Centre of Geospatial Technology, School of Remote Sensing Information Engineering, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, Computer School, Wuhan University, Wuhan, China; Division of Imaging Sciences and Biomedical Engineering Research, Kings College London, London, U.K; National Engineering Research Center for Multimedia Software, Computer School","IEEE Geoscience and Remote Sensing Letters","4 Dec 2017","2017","14","12","2398","2402","Video satellite imagery is a new technique for earth dynamic observation and has a wide range of uses in environmental fields. Despite its capability of dynamic targets' detection, it sustains a serious restriction of the image quality due to the degradation and compression in its imaging process. Hence, the super-resolution (SR) reconstruction on these compressed low-spatial-resolution images is of significance to afterward ground objects recognition and detection tasks. Based on the recent proposed state-of-the-art convolutional neural networks (CNNs) SR methods, we proposed an SR method which could get more precise reconstructed high-spatial-resolution images. Trained with Gaofen-2 satellite images, a robust CNN model specified in satellite image SR is obtained. Experimentally, the reconstruction results on Jilin-1 mission satellite images validate the effectiveness of our method.","1558-0571","","10.1109/LGRS.2017.2766204","National Natural Science Foundation of China(grant numbers:61671332); National Key Research and Development Program of China(grant numbers:2016YFB0100901); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8101498","Convolutional neural network (CNN);deep learning;super resolution (SR);video satellite","Satellites;Image reconstruction;Training;Spatial resolution;Neural networks;Remote sensing","cellular neural nets;data compression;geophysical image processing;image classification;image coding;image reconstruction;image resolution;neural nets;object recognition;remote sensing","earth dynamic observation;environmental fields;serious restriction;image quality;degradation;compression;imaging process;afterward ground objects recognition;detection tasks;convolutional neural networks SR methods;SR method;high-spatial-resolution images;Gaofen-2 satellite images;satellite image SR;reconstruction results;Jilin-1 mission satellite images;dynamic target detection;video satellite imagery superresolution;superresolution reconstruction;low-spatial-resolution image compression;reconstructed high-spatial-resolution images;robust CNN model","","68","","24","IEEE","9 Nov 2017","","","IEEE","IEEE Journals"
"Monte-Carlo Siamese Policy on Actor for Satellite Image Super Resolution","L. Rout; S. Shah; S. M. Moorthi; D. Dhar","Signal and Image Processing Group, Indian Space Research Organisation; Space Applications Centre; Signal and Image Processing Group, Indian Space Research Organisation; Signal and Image Processing Group, Indian Space Research Organisation","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","757","767","In the past few years supervised and adversarial learning have been widely adopted in various complex computer vision tasks. It seems natural to wonder whether another branch of artificial intelligence, commonly known as Reinforcement Learning (RL) can benefit such complex vision tasks. In this study, we explore the plausible usage of RL in super resolution of remote sensing imagery. Guided by recent advances in super resolution, we propose a theoretical framework that leverages the benefits of supervised and reinforcement learning. We argue that a straightforward implementation of RL is not adequate to address ill-posed super resolution as the action variables are not fully known. To tackle this issue, we propose to parameterize action variables by matrices, and train our policy network using Monte-Carlo sampling. We study the implications of parametric action space in a model-free environment from theoretical and empirical perspective. Furthermore, we analyze the quantitative and qualitative results on both remote sensing and non-remote sensing datasets. Based on our experiments, we report considerable improvement over state-of-the-art methods by encapsulating supervised models in a reinforcement learning framework.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150726","","Image resolution;Remote sensing;Learning (artificial intelligence);Mathematical model;Task analysis;Machine learning;Feature extraction","computer vision;geophysical image processing;image resolution;learning (artificial intelligence);Monte Carlo methods;remote sensing","reinforcement learning framework;nonremote sensing datasets;parametric action space;Monte-Carlo sampling;policy network;remote sensing imagery;complex vision tasks;RL;adversarial learning;satellite image super resolution;Monte-Carlo Siamese policy","","3","","57","IEEE","28 Jul 2020","","","IEEE","IEEE Conferences"
"Enhancing the Resolution of Satellite Imagery Using a Generative Model","M. Tayba; P. Rivas","Department of Computer Science, School of Engineering and Computer Science, Baylor University; Department of Computer Science, School of Engineering and Computer Science, Baylor University","2021 International Conference on Computational Science and Computational Intelligence (CSCI)","22 Jun 2022","2021","","","20","25","Recent breakthroughs in deep learning algorithms introduced the image super-resolution technique that maps the low-resolution image to generate a high-resolution image. These techniques increase various surveillance applications by providing finer spatial details than data from original sensors. Satellite images obtained from Moderate Resolution Imaging Spectroradiometer (MODIS) observation offer essential information about the earths landscape, ocean, and ecosystem, contributing to monitoring various applications in the scientific field. The spatial resolution of satellite images has a significant impact on image accuracy. This paper focuses on improving image resolution by training a convolutional neural network to produce super-resolution images from low-resolution images. We present an implementation of Super Resolution Generative Adversarial Network (SRGAN), a GAN-based approach that uses a perceptual loss function that includes an adversarial loss and a content loss. Using a discriminator network that is designed for discerning between super-resolved images and original photo-realistic images, the adversarial loss drives the solution of this architecture to natural images. Moreover, the content loss is driven by perceptual similarity rather than pixel space similarity. We used this architecture to satellite images collected from NASA MODIS devices and found satisfactory results. Our key finding is that our systems result can now be used to improve a variety of low-resolution images.","","978-1-6654-5841-2","10.1109/CSCI54926.2021.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799082","image resolution;GAN;satellite image;deep neural network;super resolution","Training;Satellites;Surveillance;Superresolution;Generative adversarial networks;Spatial databases;Sensors","convolutional neural nets;deep learning (artificial intelligence);image enhancement;image resolution;radiometers","spatial resolution;satellite images;image accuracy;image resolution;super-resolution images;low-resolution image;super resolution generative adversarial network;adversarial loss;super-resolved images;original photo-realistic images;natural images;image super-resolution technique;high-resolution image;moderate resolution imaging spectroradiometer observation;generative model;deep learning algorithms;MODIS observation;convolutional neural network;GAN-based approach;perceptual loss function;discriminator network;perceptual similarity;NASA MODIS devices","","","","23","IEEE","22 Jun 2022","","","IEEE","IEEE Conferences"
"Combined Model Color-Correction Method Utilizing External Low-Frequency Reference Signals for Large-Scale Optical Satellite Image Mosaics","H. Cui; G. Zhang; T. -Y. Wang; X. Li; J. Qi","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Geosciences and Info-Physics, Central South University, Changsha, China","IEEE Transactions on Geoscience and Remote Sensing","21 May 2021","2021","59","6","4993","5007","Optical satellites are affected by factors such as seasonal and atmospheric variation, illumination, and sensor distortion. Thus, satellite images covering large-scale area often show conspicuous color differences, resulting in poor color continuity of the mosaicked satellite image. This study proposes a novel combined model color correction (CMCC) method for high-resolution optical satellite images, which constructively combines a defogging model with a radiation correction model. First, this study analyzed the feasibility of using easily available low-resolution satellite images as external references to correct the color of high-resolution images and describes the selection criteria for external references. Second, considering the negative effects of atmosphere on the color and clarity of remote sensing images, we proposed an optical satellite image enhancement method, which is based on the content characteristics of remote sensing images and the dark channel prior defogging method. Finally, we designed a two-stage color correction process: 1) correcting the color of downsampled images via low-frequency modeling and replacement and 2) mapping the color of downsampled images to original images through local modeling and super-resolution color correction. Furthermore, this study proposes an indicator of quality considered mean absolute error (QCMAE) for quantitative evaluation of the color correction result. We selected 328 Gaofen-1 (GF-1) high-resolution images for the experiments. Visual effects and statistical results of images after being processed by the proposed CMCC are both superior to the three state-of-the-art methods, which verifies the effectiveness and reliability of the proposed method.","1558-0644","","10.1109/TGRS.2020.3018591","Key Research and Development Program of Ministry of Science and Technology(grant numbers:2018YFB0504905,2016YFB0500801); Quality Improvement of Chinese Satellite Data and Comprehensive Application Demonstration of Geology and Mineral Resources, National Natural Science Foundation of China(grant numbers:91538106,41501503,41601490,41501383); Open Research Fund of State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing(grant numbers:15E02); Fundamental Research Funds for the Central University(grant numbers:2042016kf0163); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9193955","Color correction;image enhancement;image mosaic;low frequency signal","Image color analysis;Satellites;Remote sensing;Atmospheric modeling;Adaptive optics;Optical imaging;Optical sensors","geophysical image processing;image colour analysis;image enhancement;image resolution;image segmentation;remote sensing","model color-correction method utilizing external low-frequency reference signals;large-scale optical satellite image mosaics;optical satellites;seasonal variation;atmospheric variation;large-scale area;conspicuous color differences;poor color continuity;mosaicked satellite image;combined model color correction method;high-resolution optical satellite images;defogging model;radiation correction model;low-resolution satellite images;external references;high-resolution images;remote sensing images;optical satellite image enhancement method;two-stage color correction process;downsampled images;low-frequency modeling;original images;local modeling;super-resolution color correction;color correction result","","3","","46","IEEE","10 Sep 2020","","","IEEE","IEEE Journals"
"PQA-CNN: Towards Perceptual Quality Assured Single-Image Super-Resolution in Remote Sensing","Y. Zhang; X. Dong; M. T. Rashid; L. Shang; J. Han; D. Zhang; D. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA","2020 IEEE/ACM 28th International Symposium on Quality of Service (IWQoS)","6 Oct 2020","2020","","","1","10","Recent advances in remote sensing open up unprecedented opportunities to obtain a rich set of visual features of objects on the earth's surface. In this paper, we focus on a single-image super-resolution (SISR) problem in remote sensing, where the objective is to generate a reconstructed satellite image of high quality (i.e., a high spatial resolution) from a satellite image of relatively low quality. This problem is motivated by the lack of high quality satellite images in many remote sensing applications (e.g., due to the cost of high resolution sensors, communication bandwidth constraints, and historic hardware limitations). Two important challenges exist in solving our problem: i) it is not a trivial task to reconstruct a satellite image of high quality that meets the human perceptual requirement from a single low quality image; ii) it is challenging to rigorously quantify the uncertainty of the results of an SISR scheme in the absence of ground truth data. To address the above challenges, we develop PQA-CNN, a perceptual quality-assured conventional neural network framework, to reconstruct a high quality satellite image from a low quality one by designing novel uncertainty-driven neural network architectures and integrating an uncertainty quantification model with the framework. We evaluate PQA-CNN on a real-world remote sensing application on land usage classifications. The results show that PQA-CNN significantly outperforms the state-of-the-art super-resolution baselines in terms of accurately reconstructing high-resolution satellite images under various evaluation scenarios.","1548-615X","978-1-7281-6887-6","10.1109/IWQoS49365.2020.9212942","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212942","Super-Resolution;Perceptual Quality;Uncertainty-Aware;Convolutional Neural Network","Satellites;Image reconstruction;Remote sensing;Uncertainty;Sensors;Spatial resolution","convolutional neural nets;geophysical image processing;image classification;image reconstruction;image resolution;image sensors;remote sensing","perceptual quality-assured conventional neural network framework;PQA-CNN;single-image superresolution problem;high spatial resolution;remote sensing applications;perceptual quality assured single-image superresolution;satellite image reconstruction;single low quality imaging;SISR scheme;uncertainty quantification model;land usage classifications;high-resolution satellite image reconstruction","","7","","46","IEEE","6 Oct 2020","","","IEEE","IEEE Conferences"
"Super-resolution land cover mapping based on deep learning and level set method","W. Bupphawat; T. Kasetkasem; I. Kumazawa; P. Rakwatin; T. Chanwimaluang","Department of Electrical Engineering, Kasetsart University, Bangkok, Thailand; Department of Electrical Engineering, Kasetsart University, Bangkok, Thailand; Imaging Science and Engineering Laboratory, Tokyo Institute of Technology, Yokohama, Japan; GISTDA, The Government Complex, Bangkok, Thailand; Knowledge Elicitation and Archiving Lab Laboratory, NECTEC, Pathumthani, Thailand","2017 14th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","7 Nov 2017","2017","","","557","560","In this paper, we proposed an approach for super-resolution land cover mapping on remote sensing images based on the deep learning technique, namely Convolutional Neural Network (CNN) by combining with the level set method (LSM). Here, the CNN is used to find the probabilities that a subpixel belonging to a land cover class, and the LSM is employed to fine tune the boundaries among land cover classes. The QUICKBIBD satellite image data cover a part of Kasetsart University was used for evaluation. Experimental result showed that the proposed method has achieved superior accuracy than both Hopfield and Pixel-Swapping methods.","","978-1-5386-0449-6","10.1109/ECTICon.2017.8096298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8096298","Supper-resolution mapping;Deep Learning;Level set method","Image resolution;Level set;Neural networks;Machine learning;Training;Electronic mail;Convolution","geophysical techniques;land cover;neural nets;remote sensing;terrain mapping","convolutional neural network;QUICKBIBD satellite image data cover;Kasetsart University;Hopfield method;pixel-swapping method;deep learning technique;remote sensing images;level set method;super-resolution land cover mapping;land cover class;CNN","","2","","9","IEEE","7 Nov 2017","","","IEEE","IEEE Conferences"
"A SpectralSpatial Jointed Spectral Super-Resolution and Its Application to HJ-1A Satellite Images","X. Han; H. Zhang; J. -H. Xue; W. Sun","Department of Electronic Engineering, Institute for Ocean Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Institute for Ocean Engineering, Tsinghua University, Beijing, China; Department of Statistical Science, University College London, London, U.K.; Department of Electronic Engineering, Institute for Ocean Engineering, Tsinghua University, Beijing, China","IEEE Geoscience and Remote Sensing Letters","30 Dec 2021","2022","19","","1","5","To generate a high-spatial-resolution hyperspectral (HHS) image from a high-spatial-resolution multispectral (HMS) image, both spatial information and spectral information should be considered simultaneously if we want to build a more accurate mapping from HMS to HHS. To this end, a spectral and spatial jointed spectral super-resolution method is proposed in this letter using an end-to-end learning strategy for each subspace with the cluster-based multibranch backpropagation neural network (BPNN). More specifically, in addition to the spectra similarity, a modified superpixel segmentation is introduced to jointly take spatial contextual information into account, and a new framework with it is given. Comparisons on the Columbia University Automated Vision Environment (CAVE) data set show that our proposed method outperforms other relative state-of-the-art methods more than 0.3 in the root mean squared error (RMSE) and more than 1.0 in the spectral angle mapper (SAM) index. Especially, an exemplary application is demonstrated using the synchronized observation data collected by the multispectral and hyperspectral sensors mounted on the HJ-1A satellite at the same time.","1558-0571","","10.1109/LGRS.2021.3073501","National Nature Science Foundation of China(grant numbers:41971294); China Postdoctoral Science Foundation(grant numbers:2020M680560); Cross-Media Intelligent Technology Project of Beijing National Research Center for Information Science and Technology(grant numbers:BNR2019TD01022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9420149","HJ-1A satellite image;spectral and spatial jointed;spectral super-resolution;subspace-based learning","Superresolution;Satellites;Image segmentation;Training;Image reconstruction;Neural networks;Sun","backpropagation;geophysical image processing;geophysical signal processing;geophysical techniques;image classification;image resolution;image segmentation;mean square error methods;neural nets;remote sensing;spectral analysis","spatial information;spectral information;HMS;HHS;spectral resolution method;spatial jointed spectral super-resolution method;end-to-end learning strategy;cluster-based multibranch backpropagation neural network;spatial contextual information;Columbia University Automated Vision Environment data;spectral angle mapper index;spectral-spatial jointed spectral super-resolution;satellite images;high-spatial-resolution hyperspectral image;high-spatial-resolution multispectral image;current 1.0 A","","5","","23","IEEE","30 Apr 2021","","","IEEE","IEEE Journals"
"Satellite Image Target Super-Resolution With Adversarial Shape Discriminator","C. Shin; S. Kim; Y. Kim","Agency for Defence Development (ADD), Institute of Defense Advanced Technology Research, Daejeon, South Korea; Agency for Defence Development (ADD), Institute of Defense Advanced Technology Research, Daejeon, South Korea; Agency for Defence Development (ADD), Institute of Defense Advanced Technology Research, Daejeon, South Korea","IEEE Geoscience and Remote Sensing Letters","24 Dec 2021","2022","19","","1","5","Substantial progress in generative modeling has facilitated the development of perceptual-driven methods for image super-resolution (SR), which shows superior visual quality as rated by human observers. However, we discover that most existing methods are biased to synthesize fake details or enhanced textures and fail to learn representations of object shape. They are often misguided to recover the shape of small objects and focus on generating less meaningful high-frequency components. This is problematic when super-resolving satellite imagery since it contains many relatively small and clustered objects in a broad area. In this letter, we propose a new perceptual-driven SR method that has a stronger preference toward shape information. We integrate the scale-space filtering with the discriminator to attenuate high-frequency components in its decision space. It effectively encourages our discriminator to concentrate on structural shape information in differentiating real and fake images. We also devise a cross-scale aggregation network for the generator architecture. Experiments on WorldView data set demonstrate that our method achieves state-of-the-art performance compared to recent perceptual-driven methods.","1558-0571","","10.1109/LGRS.2020.3042238","Next Generation Research and Development Program through the Institute of Defense Advanced Technology Research; Agency for Defense Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302745","Cross-scale aggregation (CSA) network;image target super-resolution (SR);scale-space filtering;shape discriminator","Shape;Image reconstruction;Satellites;Generators;Feature extraction;Streaming media;Visualization","","","","1","","30","IEEE","22 Dec 2020","","","IEEE","IEEE Journals"
"Generation of Super-Resolution Images from Satellite Images Based on Improved RCAN","F. Morishima; H. Lu; T. Kamiya","Kyushu Institute of Technology, 1-1 Sensui, Tobata, Kitakyushu, Fukuoka, Japan; Kyushu Institute of Technology, 1-1 Sensui, Tobata, Kitakyushu, Fukuoka, Japan; Kyushu Institute of Technology, 1-1 Sensui, Tobata, Kitakyushu, Fukuoka, Japan","2022 22nd International Conference on Control, Automation and Systems (ICCAS)","9 Jan 2023","2022","","","213","216","Satellite images can be analyzed and used for a variety of purposes. In the future, satellite image analysis will become more important since the number of satellites launches, and the amount of satellite data increase every year. Under these circumstances, there are some problems to be solved. One is the existence of low-resolution satellite images. To analyze the lower resolution of satellite images there are some technical issues such as reduction of noise, misclassification of object recognition. Therefore, high-resolution images are necessary. However, high-resolution satellite images are expensive, and its images may not be available in the past satellite images. Super-resolution which is introduced in image processing is a method to solve these problems. Convolutional neural network (CNN)-based methods are effective, and there is a need for models that can perform super-resolution with higher accuracy. In this paper, we propose a method for super-resolving satellite images, based on the improved the RCAN (residual channel attention network) model with SRM (style-based recalibration module). The proposed method improves the PSNR (peak signal to noise ratio) by 0.0181 dB compared to the conventional RCAN model.","2642-3901","978-89-93215-24-3","10.23919/ICCAS55662.2022.10003856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10003856","Satellite Images;Super-Resolution;Convolutional Neural Network;Residual Channel Attention Network;Style-based Recalibration Module","Satellites;PSNR;Image analysis;Automation;Superresolution;Control systems;Object recognition","convolutional neural nets;geophysical image processing;image resolution;object recognition","CNN;convolutional neural network-based methods;high-resolution satellite images;image processing;low-resolution satellite images;object recognition;peak signal to noise ratio;PSNR;RCAN;residual channel attention network model;SRM;style-based recalibration module;super-resolving satellite images","","","","14","","9 Jan 2023","","","IEEE","IEEE Conferences"
"Remote Sensing Image Super-Resolution via Mixed High-Order Attention Network","D. Zhang; J. Shao; X. Li; H. T. Shen","Center for Future Media, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Sichuan Artificial Intelligence Research Institute, Yibin, China; Center for Future Media, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Sichuan Artificial Intelligence Research Institute, Yibin, China","IEEE Transactions on Geoscience and Remote Sensing","21 May 2021","2021","59","6","5183","5196","Recently, remote sensing images have become increasingly popular in a number of tasks, such as environmental monitoring. However, the observed images from satellite sensors often suffer from low-resolution (LR), making it difficult to meet the requirements for further analysis. Super-resolution (SR) aims to increase the image resolution while providing finer spatial details, which perfectly remedies the weakness of satellite images. Therefore, in this article, we propose an innovative mixed high-order attention network (MHAN) for remote sensing SR. It comprises two components: a feature extraction network for feature extraction, and a feature refinement network with high-order attention (HOA) mechanism for detail restoration. In the feature extraction network, we replace the elementwise addition with weighted channelwise concatenation in all skip connections, which greatly facilitates the information flow. In the feature refinement network, rather than exploring the first-order statistics (spatial or channel attention), we introduce the HOA module to restore the missing details. Finally, to fully exploit hierarchical features, we introduce the frequency-aware connection to bridge the feature extraction and feature refinement networks. Experiments on two widely used remote sensing image data sets demonstrate that our MHAN not only obtains better accuracy than the state-of-the-art methods but also shows the superiority in terms of running time and GPU cost. Code is available at https://github.com/ZhangDY827/MHAN.","1558-0644","","10.1109/TGRS.2020.3009918","National Natural Science Foundation of China(grant numbers:61672133,61832001,61632007); Sichuan Science and Technology Program(grant numbers:2019YFG0535); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9151234","Attention;image super-resolution (SR);satellite image","Remote sensing;Feature extraction;Image resolution;Image restoration;Image reconstruction;Task analysis;Satellites","feature extraction;geophysical image processing;geophysical techniques;image reconstruction;image resolution;remote sensing","high-order attention mechanism;feature extraction network;feature refinement network;first-order statistics;hierarchical features;remote sensing image data sets;sensing image super-resolution;image resolution;finer spatial details;satellite images;innovative mixed high-order attention network;remote sensing SR","","44","","54","IEEE","28 Jul 2020","","","IEEE","IEEE Journals"
"Super-Resolving Commercial Satellite Imagery Using Realistic Training Data","X. Zhu; H. Talebi; X. Shi; F. Yang; P. Milanfar",Google Inc.; Google Inc.; Google Inc.; Google Inc.; Google Inc.,"2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","498","502","In machine learning based single image super-resolution, the degradation model is embedded in training data generation. However, most existing satellite image super-resolution methods use a simple down-sampling model with a fixed kernel to create training images. These methods work fine on synthetic data, but do not perform well on real satellite images. We propose a realistic training data generation model for commercial satellite imagery products, which includes not only the imaging process on satellites but also the post-process on the ground. We also propose a convolutional neural network optimized for satellite images. Experiments show that the proposed training data generation model is able to improve super-resolution performance on real satellite images.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190746","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190746","Remote sensing;satellite imagery;super-resolution","Satellites;Training data;Data models;Kernel;Spatial resolution;Degradation","convolutional neural nets;image resolution;learning (artificial intelligence)","satellite image super resolution;super resolving commercial satellite imagery;machine learning;training data generation model;downsampling model;convolutional neural network","","4","","21","IEEE","30 Sep 2020","","","IEEE","IEEE Conferences"
"Comparison of Optimized Mathematical Methods in the Improvement of Raster Data and Map Display Resolution of Sentinel-2 Images","E. Bratsolis; A. Panagiotopoulou; M. Stefouli; E. Charou; N. Madamopoulos; S. Perantonis","Institute of Informatics and Telecommunications, NCSR Demokritos, Ag. Paraskevi, Greece; Institute of Informatics and Telecommunications, NCSR Demokritos, Ag. Paraskevi, Greece; Greek Institute of Geology and Mineral Exploration (I.G.M.E.), Acharne, Greece; Institute of Informatics and Telecommunications, NCSR Demokritos, Ag. Paraskevi, Greece; Department of Aeronautical Sciences, TGA, Dhekeleia, Greece; Institute of Informatics and Telecommunications, NCSR Demokritos, Ag. Paraskevi, Greece","2018 25th IEEE International Conference on Image Processing (ICIP)","6 Sep 2018","2018","","","2521","2525","High-Resolution (HR) satellite images are a prerequisite in many applications such as astronomy, remote sensing, geoscience and geographical information systems, not only for providing better visualization but also for extracting extra information details. In the present work a comparative study of different single image resolution enhancement techniques is carried out on Sentinel-2 images of bands B2, B3, B4 and B8. The authors describe the stochastic regularized super-resolution (SR) reconstruction technique and compare with others. The techniques under comparison are stochastic regularized SR reconstruction (SRSR), spatial-wavelet SR reconstruction (SWSR) and the conventional interpolation techniques nearest neighbor (NN), bilinear (BL), bicubic (BC) and spline (SP). These techniques are tested against each other in terms of Root Mean Square Error (RMSE), Xydeas and Petrovich (XP), and Correlation Coefficient (CC). Simulated experiments of single image resolution increase take place.","2381-8549","978-1-4799-7061-2","10.1109/ICIP.2018.8451729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451729","Stochastic regularized technique;spatial-wavelet transform;super-resolution reconstruction;interpolation;satellite image resolution enhancement","Image reconstruction;Spatial resolution;Satellites;Interpolation;Imaging;Task analysis","geographic information systems;geophysical image processing;image enhancement;image reconstruction;image resolution;interpolation;mean square error methods;remote sensing;splines (mathematics);stochastic processes","RMSE;Root Mean Square Error;spline;spatial-wavelet SR reconstruction;stochastic regularized super-resolution;interpolation techniques nearest neighbor;image resolution enhancement techniques;high-resolution satellite images;geographical information systems;geoscience;Sentinel-2 images;map display Resolution;raster data;optimized mathematical methods","","3","","25","IEEE","6 Sep 2018","","","IEEE","IEEE Conferences"
"A Unified Network for Arbitrary Scale Super-Resolution of Video Satellite Images","Z. He; D. He","Guangdong Provincial Key Laboratory of Urbanization and Geo-Simulation, Center of Integrated Geographic Information Analysis, Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; City College, Dongguan University of Technology, Dongguan, China","IEEE Transactions on Geoscience and Remote Sensing","24 Sep 2021","2021","59","10","8812","8825","Super-resolution (SR) has attracted increasing attention as it can improve the quality of video satellite images. Most previous studies only consider several integer magnification factors and focus on obtaining a specific SR model for each scale factor. However, in the real world, it is a common requirement to zoom the videos arbitrarily by rolling the mouse wheel. In this article, we propose a unified network for arbitrary scale SR (ASSR) of video satellite images. The proposed ASSR consists of two modules, i.e., feature learning module and arbitrary upscale module. The feature learning module accepts multiple low-resolution (LR) frames and extracts useful features of those frames by using many 3-D residual blocks. The arbitrary upscale module takes the extracted features as input and enhances the spatial resolution by subpixel convolution and bicubic-based adjustment. Different from existing video satellite image SR methods, ASSR can continuously zoom LR video satellite images with arbitrary integer and noninteger scale factors in a single model. Experiments have been conducted on real video satellite images acquired by Jilin-1 and OVS-1. Quantitative and qualitative results have demonstrated that ASSR has superior reconstruction performance compared with the state-of-the-art SR methods.","1558-0644","","10.1109/TGRS.2020.3038653","National Key Research and Development Program of China(grant numbers:2018YFB0505500,2018YFB0505503); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2019A1515011877); Fundamental Research Funds for the Central Universities(grant numbers:19lgzd10); Guangzhou Science and Technology Planning Project(grant numbers:202002030240); National Natural Science Foundation of China(grant numbers:41501368); Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai)(grant numbers:99147-42080011); 2018 Key Research Platforms and Research Projects of Ordinary Universities in Guangdong Province(grant numbers:2018KQNCX360); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277650","Arbitrary scale;deep learning;super-resolution (SR);video satellite","Satellites;Convolution;Feature extraction;Spatial resolution;Image reconstruction;Image edge detection;Training","image reconstruction;image resolution;learning (artificial intelligence);video signal processing","video satellite image SR methods;ASSR;LR video satellite images;noninteger scale factors;unified network;arbitrary scale super-resolution;specific SR model;scale factor;arbitrary scale SR;feature learning module;arbitrary upscale module;low-resolution frames","","6","","46","IEEE","2 Dec 2020","","","IEEE","IEEE Journals"
"Super-resolution: Sparse dictionary design method using quantitative comparison","M. Moustafa; H. M. Ebeid; A. Helmy; T. M. Nazamy; M. F. Tolba","Data Reception Analysis and Receiving Station Affairs, National Authority for Remote Sensing and Space Science, Cairo, Egypt; Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Data Reception Analysis and Receiving Station Affairs, National Authority for Remote Sensing and Space Science, Cairo, Egypt; Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt; Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt","2015 IEEE Seventh International Conference on Intelligent Computing and Information Systems (ICICIS)","4 Feb 2016","2015","","","383","389","Single image super resolution (SISR) is the process that obtains a high resolution image from a single low resolution (LR) image by increasing the high frequency information and removing the degradation of the noise. Sparse representation of signal assumes linear combinations of a few atoms from a pre -specified dictionary. Sparse representation has been used successfully as a prior in signal reconstruction. Dictionary design is crucial for the success of reconstruction high resolution images. This paper evaluates the performance of dictionary design models in both mathematical and learning based models, it also compares the wavelet method, Haar method, DCT method, MOD method and K-SVD method. Various experiments are conducted using a real SPOT-4 satellite image. Experimental results demonstrate that the learning based approaches are very effective in increasing resolution and compare favorably to mathematical based approaches.","","978-1-5090-1950-2","10.1109/IntelCIS.2015.7397249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7397249","Shift Estimation;SPOT-5 Images;Super Resolution","Image resolution;Signal resolution;Dictionaries;IP networks;Image coding;Discrete cosine transforms;Encoding","artificial satellites;discrete cosine transforms;geophysical image processing;Haar transforms;image denoising;image reconstruction;image representation;image resolution;learning (artificial intelligence);singular value decomposition;wavelet transforms","sparse dictionary design method;quantitative analysis;single-image super-resolution;SISR;high-resolution image;single-low-resolution image;single-LR image;high-frequency information;noise degradation removal;sparse representation;signal reconstruction;high-resolution image reconstruction;performance evaluation;mathematical-based model;learning-based model;wavelet method;Haar method;DCT method;MOD method;K-SVD method;SPOT satellite image","","2","","27","IEEE","4 Feb 2016","","","IEEE","IEEE Conferences"
"From Artifact Removal to Super-Resolution","J. Wang; Z. Shao; X. Huang; T. Lu; R. Zhang; Y. Li","State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Department of Geosciences, University of Arkansas, Fayetteville, AR, USA; School of Computer Science and Engineering, Wuhan Institute of Technology, Wuhan, China; Institute of Photogrammetry and Remote Sensing, Chinese Academy of Surveying and Mapping, Beijing, China; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","23 Aug 2022","2022","60","","1","15","Deep-learning-based super-resolution (SR) methods have been extensively studied and have achieved significant performance with deep convolutional neural networks. However, the results still suffer from the ringing effect, especially in satellite image SR tasks, due to the loss of image details in the satellite degradation process. In this article, we build a novel satellite SR framework by decomposing a high-resolution image into three components, i.e., low-resolution (LR), artifact, and high-frequency information. Specifically, we propose an artifact removal network with a self-adaption difference convolution (SDC) to fully exploit the structure prior in the LR image and predict the artifact map. Considering that the artifact map and the high-frequency map share a similar pattern, we introduce the supervised structure correction (SSC) block that establishes a bridge between the high-frequency generation process and the artifact removal process. Experimental results on satellite images demonstrate that the proposed method owns an improved tradeoff between the performance and the computational cost compared to existing state-of-the-art satellite and natural SR methods. The source code is available at https://github.com/jiaming-wang/ARSRN.","1558-0644","","10.1109/TGRS.2022.3196709","National Natural Science Foundation of China(grant numbers:42090012); Guangxi Science and Technology Program(grant numbers:GuiKe 2021AB30019); 03 Special Research and 5G Project of Jiangxi Province in China(grant numbers:20212ABC03A09); Zhuhai Industry University Research Cooperation Project of China(grant numbers:ZH22017001210098PWC); Sichuan Science and Technology Program(grant numbers:2022YFN0031); Zhizhuo Research Fund on Spatial-Temporal Artificial Intelligence(grant numbers:ZZJJ202202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9851467","Artifact removal;difference convolution;remote sensing;super-resolution (SR)","Satellites;Image edge detection;Task analysis;Convolution;Superresolution;Image reconstruction;Generative adversarial networks","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image resolution","deep convolutional neural networks;ringing effect;satellite image SR tasks;image details;satellite degradation process;high-resolution image;high-frequency information;artifact removal network;self-adaption difference convolution;LR image;artifact map;supervised structure correction block;high-frequency generation process;deep-learning-based super-resolution methods;low-resolution","","","","59","IEEE","5 Aug 2022","","","IEEE","IEEE Journals"
"Detection of Military Targets from Satellite Images using Deep Convolutional Neural Networks","H. Bandarupally; H. R. Talusani; T. Sridevi","Computer Science and Engineering, Chaitanya Bharathi Institute of Technology, Hyderabad, India; Computer Science and Engineering, Chaitanya Bharathi Institute of Technology, Hyderabad, India; Computer Science and Engineering, Chaitanya Bharathi Institute of Technology, Hyderabad, India","2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA)","10 Nov 2020","2020","","","531","535","Due to the varying size, orientation, and background of images in the defense sector, it is a daunting task to discern and distinguish the military targets in them. Multitudes of solutions have been proposed in this arena, yet there is a significant need for much better and flawless outputs. In this chapter, we expound on a two-level solution-Edge Boxes and Convolutional Neural Network (CNN) for the detection of targets in satellite imagery, Super resolution of the image using Dense-skip-connections. In the first level, the military objects are detected from the satellite image using Edge Boxes. In satellite imagery, the edge data of targets contains very prominent and concise attributes. The traditionally engineered features such as Histogram of Oriented Gradients, Hough transform and Gabor feature do not work well for huge datasets. However, the Edge Boxes technique generates contours around the target objects and discards the remaining. The output of this level is fed to the second level, wherein, the proposed targets undergo image super resolution. The presented deep learning model tends to inherently learn an end-to-end mapping between images of lower resolution and higher resolution. This level can be portrayed as one which takes a low-resolution input image and constructs an up-sampled high-resolution image as the output. Unlike traditional methods (sparse coding based method, bicubic method) that handle each component separately, this method aims to optimize all the layers at once. Furthermore, for assuaging the vanishing gradient problem that is common to very deep networks, Dense-skip-connections are employed. These enable the building of shorter paths directly within multiple layers. Though the proposed model has a light weighted structure, it exhibits state-of-the-art restoration quality.","2642-7354","978-1-7281-6324-6","10.1109/ICCCA49541.2020.9250864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250864","Super resolution of image;Dense-skipconnections;EdgeBoxes;Deep CNN;HOG;Gabor feature;Hough transform","Deep learning;Image resolution;Satellites;Image edge detection;Transforms;Convolutional neural networks;Military satellites","convolutional neural nets;feature extraction;geophysical image processing;image representation;image resolution;learning (artificial intelligence);military computing;object detection","satellite image;deep convolutional neural networks;defense sector;military objects;image super resolution;deep learning model;low-resolution input image;high-resolution image;sparse coding based method;deep networks;military targets detection;dense-skip-connections;edge boxes technique","","","","18","IEEE","10 Nov 2020","","","IEEE","IEEE Conferences"
"A Multi-Cooperative Deep Convolutional Neural Network for Spatiotemporal Satellite Image Fusion","W. Li; C. Yang; Y. Peng; X. Zhang","Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15 Oct 2021","2021","14","","10174","10188","Remote sensing satellite images with high temporal and high spatial resolution play a critical role in earth science applications. However, it is difficult for a single satellite to obtain such images due to technical and cost constraints. Therefore, spatiotemporal image fusion based on deep learning has received extensive attention in recent years. This article proposes a multicooperative deep convolutional neural network (MCDNet) for spatiotemporal satellite image fusion. This method is a new multinetwork model in which multiple networks work together to reconstruct the predicted image. The multinetwork model consists of a super-resolution network, a difference reconstruction network, and a collaborative training network. First, the super-resolution network uses the combination of a novel multiscale mechanism and dilated convolutions to make full use of the spectral information of the coarse image and upgrade it to a transitional image that matches the fine image. The difference reconstruction network uses structural relevance to complete the reconstruction of the fine difference image. The collaborative training network extracts the hidden information from the fine image and uses the time relevance to restrict the training of the difference reconstruction network. Finally, the fine difference image and the known fine image are combined to complete the image fusion. The new compound loss function can help multinetwork models better complete cooperative training. Through experiments on two datasets and comparison with existing fusion algorithms, the subjective and objective results prove that MCDNet can effectively reconstruct higher-quality prediction images.","2151-1535","","10.1109/JSTARS.2021.3113163","National Natural Science Foundation of China(grant numbers:61972060,U1713213,62027827); National Key R&D Program of China(grant numbers:2019YFE0110800); Natural Science Foundation of Chongqing(grant numbers:cstc2020jcyj-zdxmX0025,cstc2019cxcyljrc-td0270); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9540272","Convolutional neural network (CNN);dilated convolution;multiscale mechanism;spatiotemporal fusion","Image reconstruction;Convolutional neural networks;Spatiotemporal phenomena;Spatial resolution;Feature extraction;Satellites;Training","convolutional neural nets;deep learning (artificial intelligence);feature extraction;image fusion;image reconstruction;image resolution;remote sensing","multicooperative deep convolutional neural network;spatiotemporal satellite image fusion;remote sensing satellite images;temporal resolution;spatial resolution;deep learning;super-resolution network;difference reconstruction network","","4","","45","CCBY","16 Sep 2021","","","IEEE","IEEE Journals"
"Deep-Learning-Based Super-Resolution of Video Satellite Imagery by the Coupling of Multiframe and Single-Frame Models","H. Shen; Z. Qiu; L. Yue; L. Zhang","Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China; School of Resource and Environmental Sciences, Wuhan University, Wuhan, China; School of Geography and Information Engineering, China University of Geosciences, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","8 Feb 2022","2022","60","","1","14","Image super-resolution (SR) is an effective solution to the limitation of the spatial resolution of video satellite images, which is caused by the degradation and compression in the imaging phase. For the processing of satellite videos, the commonly employed deep-learning-based single-frame SR (SFSR) framework has limited performance without using complementary information between the video frames. On the other side, the multiframe SR (MFSR) can utilize temporal subpixel information to super-resolve the high-resolution (HR) imagery. However, although deeper and wider deep learning network provides powerful feature representations for SR methods, it has always been a challenge to accurately reconstruct the boundaries of ground objects in video satellite images. In this article, to address these issues, we propose an edge-guided video SR (EGVSR) framework for video satellite image SR, which couples the MFSR model and the edge-SFSR (E-SFSR) model in a unified network. The EGVSR framework is composed of an MFSR branch and an edge branch. The MFSR branch is used to extract the complementary features from the consecutive video frames. Concurrently, the edge branch acts as an SFSR model to translate the edge maps from the low-resolution modality to the HR one. At the final SR stage, the DBFM is built to focus on the promising inner representations of the features of the two branches and fuse them. Extensive experiments on video satellite imagery show that the proposed EGVSR method can achieve superior performance compared to the representative deep-learning-based SR methods.","1558-0644","","10.1109/TGRS.2021.3121303","National Key Research and Development Program of China(grant numbers:2019YFB2102900); National Natural Science Foundation of China(grant numbers:41801263); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9579427","Deep learning;edge prior;super-resolution (SR);video satellite","Satellites;Image edge detection;Image reconstruction;Spatial resolution;Feature extraction;Remote sensing;Deep learning","deep learning (artificial intelligence);feature extraction;image reconstruction;image representation;image resolution;remote sensing;video signal processing","image super-resolution;single-frame SR framework;multiframe SR;temporal subpixel information;high-resolution imagery;deep learning network;edge-guided video SR framework;MFSR branch;edge branch;video frames;SFSR;low-resolution modality;video satellite imagery;EGVSR;boundaries reconstruction;satellite videos processing","","","","67","IEEE","18 Oct 2021","","","IEEE","IEEE Journals"
"Spatiotemporal Satellite Image Fusion Using Deep Convolutional Neural Networks","H. Song; Q. Liu; G. Wang; R. Hang; B. Huang","Jiangsu Key Laboratory of Big Data Analysis Technology, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Big Data Analysis Technology, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China; Collaborative Innovation Center on Forecast and Evaluation of Meteorological Disasters, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Big Data Analysis Technology, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China; Chinese University of Hong Kong, Hong Kong","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","12 Mar 2018","2018","11","3","821","829","We propose a novel spatiotemporal fusion method based on deep convolutional neural networks (CNNs) under the application background of massive remote sensing data. In the training stage, we build two five-layer CNNs to deal with the problems of complicated correspondence and large spatial resolution gaps between MODIS and Landsat images. Specifically, we first learn a nonlinear mapping CNN between MODIS and low-spatial-resolution (LSR) Landsat images and then learn a super-resolution CNN between LSR Landsat and original Landsat images. In the prediction stage, instead of directly taking the outputs of CNNs as the fusion result, we design a fusion model consisting of high-pass modulation and a weighting strategy to make full use of the information in prior images. Specifically, we first map the input MODIS images to transitional images via the learned nonlinear mapping CNN and further improve the transitional images to LSR Landsat images via the fusion model; then, via the learned SR CNN, the LSR Landsat images are supersolved to transitional images, which are further improved to Landsat images via the fusion model. Compared with the previous learning-based fusion methods, mainly referring to the sparse-representation-based methods, our CNNs-based spatiotemporal method has the following advantages: 1) automatically extracting effective image features; 2) learning an end-to-end mapping between MODIS and LSR Landsat images; and 3) generating more favorable fusion results. To examine the performance of the proposed fusion method, we conduct experiments on two representative Landsat-MODIS datasets by comparing with the sparse-representation-based spatiotemporal fusion model. The quantitative evaluations on all possible prediction dates and the comparison of fusion results on one key date in both visual effect and quantitative evaluations demonstrate that the proposed method can generate more accurate fusion results.","2151-1535","","10.1109/JSTARS.2018.2797894","National Natural Science Foundation of China(grant numbers:41501377,61532009,91546117); Foundation of Jiangsu Province of China(grant numbers:BK20150906,15KJA520001); National Social and Scientific Fund Program(grant numbers:16ZDA047); HKRGC General Research Fund(grant numbers:14606315); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291042","Convolutional neural network (CNN);nonlinear mapping (NLM);spatial resolution;temporal resolution","Remote sensing;Earth;Artificial satellites;Spatial resolution;MODIS;Spatiotemporal phenomena;Training","feature extraction;feedforward neural nets;geophysical image processing;image fusion;image representation;image resolution;learning (artificial intelligence);remote sensing","Landsat-MODIS datasets;end-to-end mapping learning;automatic effective image feature extraction;MODIS images;massive remote sensing data;low-spatial-resolution Landsat images;accurate fusion results;spatiotemporal fusion model;representative Landsat-MODIS datasets;spatiotemporal method;sparse-representation-based methods;learned SR CNN;LSR Landsat images;learned nonlinear mapping CNN;transitional images;prior images;super-resolution CNN;spatial resolution gaps;spatiotemporal fusion method;deep convolutional neural networks;spatiotemporal satellite image fusion","","170","","35","IEEE","13 Feb 2018","","","IEEE","IEEE Journals"
"Self-supervised multi-image super-resolution for push-frame satellite images","N. L. Nguyen; J. Anger; A. Davy; P. Arias; G. Facciolo","CNRS, ENS Paris-Saclay, Centre Borelli, Universit Paris-Saclay, France; Kayrros SAS; CNRS, ENS Paris-Saclay, Centre Borelli, Universit Paris-Saclay, France; CNRS, ENS Paris-Saclay, Centre Borelli, Universit Paris-Saclay, France; CNRS, ENS Paris-Saclay, Centre Borelli, Universit Paris-Saclay, France","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1 Sep 2021","2021","","","1121","1131","Recent constellations of optical satellites are adopting multi-image super-resolution (MISR) from bursts of push-frame images as a way to increase the resolution and reduce the noise of their products while maintaining a lower cost of operation. Most MISR techniques are currently based on the aggregation of samples from registered low resolution images. A promising research trend aimed at incorporating natural image priors in MISR consists in using data-driven neural networks. However, due to the unavailability of ground truth high resolution data, these networks cannot be trained on real satellite images. In this paper, we present a framework for training MISR algorithms from bursts of satellite images without requiring high resolution ground truth. This is achieved by adapting the recently proposed frame-to-frame framework to process bursts of satellite images. In addition we propose an architecture based on feature aggregation that allows to fuse a variable number of frames and is capable of handling degenerate samplings while also reducing noise. On synthetic datasets, the proposed self-supervision strategy attains results on par with those obtained with a supervised training. We applied our framework to real SkySat satellite image bursts leading to results that are more resolved and less noisy than the L1B product from Planet.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522764","","Training;Satellites;Planets;Superresolution;Neural networks;Computer architecture;Optical imaging","artificial satellites;geophysical equipment;geophysical image processing;image resolution;image sampling;learning (artificial intelligence);neural nets;remote sensing","self-supervised multiimage super-resolution;push-frame satellite images;optical satellites;push-frame images;MISR techniques;registered low resolution images;natural image priors;data-driven neural networks;ground truth high resolution data;MISR algorithms;high resolution ground truth;frame-to-frame framework;SkySat satellite image bursts","","7","","69","IEEE","1 Sep 2021","","","IEEE","IEEE Conferences"
"S3: A Spectral-Spatial Structure Loss for Pan-Sharpening Networks","J. -S. Choi; Y. Kim; M. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Artificial Intelligence Research Division, Korea Aerospace Research Institute, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Geoscience and Remote Sensing Letters","22 Apr 2020","2020","17","5","829","833","Recently, many deep-learning-based pan-sharpening methods have been proposed for generating high-quality pan-sharpened (PS) satellite images. These methods focused on various types of convolutional neural network (CNN) structures, which were trained by simply minimizing a spectral loss between network outputs and the corresponding high-resolution (HR) multi-spectral (MS) target images. However, owing to different sensor characteristics and acquisition times, HR panchromatic (PAN) and low-resolution MS image pairs tend to have large pixel misalignments, especially for moving objects in the images. Conventional CNNs trained with only the spectral loss with these satellite image data sets often produce PS images of low visual quality including double-edge artifacts along strong edges and ghosting artifacts on moving objects. In this letter, we propose a novel loss function, called a spectral-spatial structure (S3) loss, based on the correlation maps between MS targets and PAN inputs. Our proposed S3 loss can be very effectively used for pan-sharpening with various types of CNN structures, resulting in significant visual improvements on PS images with suppressed artifacts.","1558-0571","","10.1109/LGRS.2019.2934493","National Research Foundation of Korea (NRF); Ministry of Science, ICT and Future Planning through the Basic Science Research Program(grant numbers:2017R1A2A2A05001476); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812763","Convolutional neural network (CNN);deep learning;pan colorization;pan-sharpening;satellite imagery;spectral-spatial structure;super-resolution (SR)","Training;Satellites;Correlation;Spatial resolution;Visualization;Convolutional neural networks","convolutional neural nets;geophysical image processing;image classification;image fusion;image resolution;learning (artificial intelligence);remote sensing","spectral-spatial structure loss;MS targets;PAN inputs;CNN structures;PS images;deep-learning-based pan-sharpening methods;high-quality pan-sharpened satellite images;convolutional neural network structures;spectral loss;network outputs;multispectral target images;HR panchromatic;moving objects;satellite image data sets;double-edge artifacts;strong edges;ghosting artifacts;loss function","","11","","32","IEEE","26 Aug 2019","","","IEEE","IEEE Journals"
