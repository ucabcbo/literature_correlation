"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Crops Classification from Sentinel-2A Multi-spectral Remote Sensing Images Based on Convolutional Neural Networks","Z. Zhou; S. Li; Y. Shao","Key Laboratory of Space Utilization, Chinese Academy of Sciences, Beijing; Key Laboratory of Space Utilization, Chinese Academy of Sciences, Beijing; Key Laboratory of Space Utilization, Chinese Academy of Sciences, Beijing","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","5300","5303","Deep learning technology such as convolutional neural networks (CNN) can extract the distinguishable and representative features of different land cover from remote sensing images in a hierarchical way to classify. However, in the field of agriculture, there are few application of crops classification from multi-spectral remote sensing images based on deep learning. In this context, we compared the classification methods of CNN and support vector machines (SVM) in extracting the spatial distribution of crops planting area from Sentineal-2A multi-spectral remote sensing images in Yuanyang county, China. For the region of study, both methods obtained reasonable spatial distribution of different crops, the verification results show that the overall accuracy of CNN is 95.6% which is superior to SVM.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518860","crops classification;multi-spectral;CNN;remote sensing;Sentinel-2A","Agriculture;Remote sensing;Feature extraction;Support vector machines;Graphical models;Distribution functions","agriculture;crops;feature extraction;geophysical image processing;geophysical techniques;image classification;learning (artificial intelligence);neural nets;remote sensing;support vector machines","crops classification;multispectral remote sensing images;convolutional neural networks;CNN","","8","","5","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Flood Mapping with SAR and Multi-Spectral Remote Sensing Images Based on Weighted Evidential Fusion","X. Chen; Y. Cui; C. Wen; M. Zheng; Y. Gao; J. Li","School of Earth and Space Sciences, Peking University, Beijing, China; School of Earth and Space Sciences, Peking University, Beijing, China; Information Center of Ministry of Civil Affairs of the People's Republic of China, Beijing, China; Information Center of Ministry of Civil Affairs of the People's Republic of China, Beijing, China; Information Center of Ministry of Civil Affairs of the People's Republic of China, Beijing, China; Faculty of Geographical Science, Beijing Normal University, Beijing, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","2519","2522","Synthetic Aperture Radar (SAR) and Multi-spectral (MS) remote sensing images are commonly used for flood mapping. SAR images can provide valid backscattering measurements of inundated areas through cloud cover, while MS data is able to monitor the spectral changes of ground surface, but usually affected by clouds. The complementary characteristics of the two data indicate the potential of their combining application for flood monitoring in emergency. This paper proposes a novel weighted evidential fusion method to take full advantages of the SAR and MS data for change detection during the flood. First, pre-processing and classification are performed with the SAR and MS data, independently. Second, a modified PCR6 rule for evidential fusion is proposed, which introduces the confusion matrixes to calculate the weight of evidences so that the conflicting degree in the fusion process can be reduced. Then, the flood inundating, standing and receding patterns are identified, which can be used to describe the flooding process in details. Practically, the proposed method is applied to flood mapping of the Typhoon Rumbia in 2018, in Shouguang City, China. The experiments show that the proposed fusion scheme efficiently use both of the SAR and MS data, and improve the flood mapping accuracy.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324158","SAR;multi-spectral;change detection;evidential fusion;flood monitoring;remote sensing","Floods;Synthetic aperture radar;Remote sensing;Land surface;Earth;Radar polarimetry;Monitoring","floods;geophysical image processing;hydrological techniques;image classification;image fusion;radar imaging;remote sensing by radar;synthetic aperture radar","modified PCR6 rule;confusion matrixes;AD 2018;Typhoon Rumbia;China;Shouguang City;flooding process;flood inundating;fusion process;evidential fusion method;flood monitoring;spectral changes;cloud cover;backscattering measurements;SAR images;multispectral remote sensing images;flood mapping accuracy;MS data;fusion scheme","","","","6","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Multi-spectral radar measurements of ice and snow using manned and unmanned aircraft","F. Rodriguez-Morales; E. Arnold; R. Hale; S. Keshmiri; C. Leuschen; J. Li; J. Paden","Center for Remote Sensing of Ice Sheets, University of Kansas, Lawrence, KS, USA; Center for Remote Sensing of Ice Sheets, University of Kansas, Lawrence, KS, USA; Center for Remote Sensing of Ice Sheets, University of Kansas, Lawrence, KS, USA; Center for Remote Sensing of Ice Sheets, University of Kansas, Lawrence, KS, USA; Center for Remote Sensing of Ice Sheets, University of Kansas, Lawrence, KS, USA; Center for Remote Sensing of Ice Sheets, University of Kansas, Lawrence, KS, USA; Center for Remote Sensing of Ice Sheets, University of Kansas, Lawrence, KS, USA","2017 First IEEE International Symposium of Geoscience and Remote Sensing (GRSS-CHILE)","31 Jul 2017","2017","","","1","4","We present an overview of a set of radar instruments developed at the University of Kansas for multi-spectral measurements of ice and snow properties. The systems operate at different frequency bands ranging from 14 MHz to 38 GHz, onboard manned and unmanned aircraft. The data collected with these systems are used to estimate parameters such as ice thickness, ice surface and bedrock topography, snow cover thickness on sea ice, and annual snow accumulation. We give a summary of recent field programs (including operations out of Punta Arenas, Chile) and discuss current collaborations with Chilean institutions.","","978-1-5386-0740-4","10.1109/GRSS-CHILE.2017.7996024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7996024","Airborne radar;UAS-borne radar;radio echo sounding;cryospheric remote sensing","Ice;Snow;Radar remote sensing;Instruments;Remote sensing;Airborne radar","hydrological equipment;hydrological techniques;ice;remote sensing by radar;snow","ice multispectral radar measurements;snow multispectral radar measurements;unmanned aircraft;radar instruments;ice properties;snow properties;ice thickness;ice surface;bedrock topography;snow cover;annual snow accumulation;Chilean institutions;Punta Arenas;Chile","","3","","15","IEEE","31 Jul 2017","","","IEEE","IEEE Conferences"
"A new method for automatic fine registration of multi-spectral remote sensing images","Y. Li; Y. Chen; Z. Xue; Y. Cao; W. He; L. Tong","School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Electric Power Research Institute of Sichuan, Chengdu, China; Electric Power Research Institute of Sichuan, Chengdu, China; Sichuan Academy of Agricultural Sciences, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","4829","4831","Fine registration is a fundamental step for further application of remote sensing images. Focused on deficiencies in traditional manual registration, this paper presents a new method for automatic fine registration of multi-spectral images. To make the most of image information, the algorithm detects and matches feature points in the selected bands. Then pick up the common control points which contain more reliability relative to others after eliminating wrong matching points. The last registration model can be built based on common control points and the points selected by common ones. Experimental results with Landsat TM5 images demonstrate that the method is more accurate and suitable for automatic batch processing.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326911","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326911","Fine registration;multi-spectral images;common control points;batch processing","Remote sensing;Reliability;Batch production systems;Feature extraction;Yttrium;Satellites;Earth","geophysical techniques;remote sensing","common control points;automatic batch processing;Landsat TM5 images;automatic fine registration;multispectral remote sensing images","","","","6","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Study on multi-spectral remote sensing image restoration based on sparse representation","Z. Qin; R. Yang; J. Zhang","School of Mathmatics and Computer Science, Panzhihua college, Panzhihua, China; School of Civil and Architectural Engineering, Panzhihua college, Panzhihua, China; School of Mathmatics and Computer Science, Panzhihua college, Panzhihua, China","2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","26 Feb 2018","2017","","","1","4","The multispectral remote sensing image sensor is expensive, and it will cause part of the pixels of the defect in the process of acquisition and transmission, it would be of great importance to be able to restore the defective pixels at the receiver. According to the latest research results of optimization, this paper presents a new multi-spectral remote sensing image restoration method based on sparse representation. The method can divide three-dimensional image into different blocks and model the problem of multi-spectral remote sensing image, and the multi-spectral pixel blocks of the study area is restored by sparse approximation. The experiment proves the efficiency of the algorithm, and the proposed method is very important in remote sensing image processing.","","978-1-5386-1937-7","10.1109/CISP-BMEI.2017.8302034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302034","multi-spectral remote sensing image;dictionary learning;sparse representation;restoration;optimization","Image restoration;Hyperspectral imaging;Signal processing algorithms;Machine learning;Mathematical model","geophysical image processing;hyperspectral imaging;image representation;image restoration;image sensors;optimisation;remote sensing","multispectral remote sensing image restoration;remote sensing image processing;multispectral pixel blocks;three-dimensional image;sparse representation;multispectral remote sensing image sensor","","","","21","IEEE","26 Feb 2018","","","IEEE","IEEE Conferences"
"AN IMPROVED FEATURE EXTRACTION METHOD BASED ON CONTEXT FEATURES FOR MULTI-SPECTRAL REMOTE SENSING IMAGERY","N. Li; R. Wang; H. Zhao; H. Zhao; W. Wei","School of Instrumentation and Optoelectronic Engineering, Beihang University, Beijing, China; School of Instrumentation and Optoelectronic Engineering, Beihang University, Beijing, China; School of Instrumentation and Optoelectronic Engineering, Beihang University, Beijing, China; School of Instrumentation and Optoelectronic Engineering, Beihang University, Beijing, China; Beijing Mechanical and Electrical Engineering, Design Institute","2019 IEEE International Conference on Signal, Information and Data Processing (ICSIDP)","21 Aug 2020","2019","","","1","4","Feature extraction methods of multi-spectral remote sensing images is of great significance for remote sensing image analysis, but it still faces some challenges. The ability of traditional feature extraction methods based on artificial features or shallow machine learning have some shortcomings and limitations. Recently, a series of proposed R-CNN networks, especially Faster R-CNN, have achieved excellent results in the field of target recognition. However, Faster R-CNN for multi-spectral imagery object detection has several drawbacks: (1) the object spectral information cannot be fully utilized in Faster R-CNN used to process RGB images; (2) the spatial semantic relationship information which could not be mined by Faster R-CNN among remote sensing image features can improve the feature extraction ability of the network; (3) objects occupy relatively few pixels because of the low resolution of multi-spectral images, and Faster R-CNN has poor detection performance for small objects. To address the above problems, we propose an effective and novel object detection method for multi-spectral images with small objects. First, we design a feature extractor by adopting a 3D convolution neural network which can simultaneously extract spectral information and spatial information. Secondly, an object relation module for mining context information is introduced into the network. Finally, in order to solve the problem of small targets, a multi-scale object proposal network for generating regions of objects from several intermediate layers is used. We conducted a set of controlled trials on the satellite imagery feature detection dataset released by Dstl on the Kaggle website and the results showed that our approach was very effective.","","978-1-7281-2345-5","10.1109/ICSIDP47821.2019.9172952","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9172952","multi-spectral remote sensing images;feature extraction;3D convolution network;context information;small objects","","convolutional neural nets;data mining;feature extraction;image colour analysis;learning (artificial intelligence);object detection;remote sensing;spectral analysis","context features;multispectral remote sensing imagery;multispectral remote sensing images;remote sensing image analysis;artificial features;R-CNN networks;Faster R-CNN;multispectral imagery object detection;object spectral information;RGB images;spatial semantic relationship information;remote sensing image features;feature extraction;multispectral images;feature extractor;object relation module;multiscale object proposal network;satellite imagery feature detection;context information mining;spectral information extraction;spatial information extraction;shallow machine learning;target recognition;3D convolution neural network","","","","14","IEEE","21 Aug 2020","","","IEEE","IEEE Conferences"
"Deep Networks Under Block-Level Supervision for Pixel-Level Cloud Detection in Multi-Spectral Satellite Imagery","W. Chen; Y. Li; Y. Zhang; X. Hao","School of Remote Sensing and Information Engineering, Wuhan University, China; School of Remote Sensing and Information Engineering, Wuhan University, China; School of Remote Sensing and Information Engineering, Wuhan University, China; Beijing Tracking and Communication Technology Research Institute, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1612","1615","Cloud cover hinders the usability of optical remote sensing imagery. Existing cloud detection methods either require hand-crafted features or utilize deep networks. Generally, deep networks perform better than hand-crafted features. However, deep networks for cloud detection need massive and expensive pixel-level annotation labels. To alleviate that, this paper proposes a weakly supervised deep learning-based cloud detection method using only block-level labels, with a new global convolutional pooling operation and a local pooling pruning strategy to improve the performance. For evaluating, we collect a training dataset containing over 160,000 image blocks with block-level labels and a testing dataset including ten large image scenes with pixel-level labels. Even under extremely weak supervision, our method performed well with the average overall accuracy reached 97.2 %. Experiments demonstrate that our proposed method obviously outperforms the state-of-the-art methods.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324486","National Natural Science Foundation of China(grant numbers:41971284 and 41601352); China Postdoctoral Science Foundation(grant numbers:2016M590716,2017T100581); Hubei Provincial Natural Science(grant numbers:2018CFB501); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324486","Cloud detection;weakly supervised deep learning;global convolutional pooling;local pooling pruning;high-resolution remote sensing imagery","Training;Feature extraction;Satellites;Remote sensing;Deep learning;Testing;Image segmentation","clouds;feature extraction;geophysical image processing;image classification;image segmentation;learning (artificial intelligence);object detection;remote sensing","deep networks;block-level supervision;pixel-level cloud detection;multispectral satellite imagery;cloud cover;optical remote sensing imagery;cloud detection methods;hand-crafted features;pixel-level annotation labels;weakly supervised deep learning-based cloud detection method;block-level labels;160 image blocks;000 image blocks;pixel-level labels","","","","11","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Multimodal Urban Remote Sensing Image Registration Via Roadcross Triangular Feature","K. Yu; X. Zheng; B. Fang; P. An; X. Huang; W. Luo; J. Ding; Z. Wang; J. Ma","National Key Laboratory of Science, and Technology on Multi-spectral Information Processing, School of Artificial Intelligence, and Automation, Huazhong University of Science, and Technology, Wuhan, China; Wuhan Institute of Marine Electric Propulsion, Wuhan, China; National Key Laboratory of Science, and Technology on Multi-spectral Information Processing, School of Artificial Intelligence, and Automation, Huazhong University of Science, and Technology, Wuhan, China; National Key Laboratory of Science, and Technology on Multi-spectral Information Processing, School of Artificial Intelligence, and Automation, Huazhong University of Science, and Technology, Wuhan, China; Development and Design Center, China Ship Development, and Design Center, Wuhan, China; Development and Design Center, China Ship Development, and Design Center, Wuhan, China; National Key Laboratory of Science, and Technology on Multi-spectral Information Processing, School of Artificial Intelligence, and Automation, Huazhong University of Science, and Technology, Wuhan, China; National Key Laboratory of Science, and Technology on Multi-spectral Information Processing, School of Artificial Intelligence, and Automation, Huazhong University of Science, and Technology, Wuhan, China; National Key Laboratory of Science, and Technology on Multi-spectral Information Processing, School of Artificial Intelligence, and Automation, Huazhong University of Science, and Technology, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","14 May 2021","2021","14","","4441","4451","Automatic image registration of multimodal urban remote sensing images remains a critical challenging task in remote sensing image analysis due to significant nonlinear radiation distortions between multimodal image pairs; most of the traditional methods focus on the feature point detection and its local description and ignore the robust road information in multimodal urban remote sensing images. Motivated by this, we propose a fast and robust registration method for multimodal urban remote sensing images via road intersection triangular features. The proposed method obtains three main stages: Road lines extraction from images, intersection triangular feature construction, and triangular feature matching. The qualitative and quantitative experimental results show that the proposed method significantly outperforms other state-of-the-art methods, even when others completely fail to achieve the registration task of cross-modal images, our method still maintains good robustness and matching efficiency.","2151-1535","","10.1109/JSTARS.2021.3073573","National Natural Science Foundation of China(grant numbers:61991412,U1913602); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9405400","Image matching;multimodal image registration;road intersection triangular feature;urban remote sensing","Feature extraction;Roads;Remote sensing;Data mining;Optical sensors;Optical distortion;Image registration","feature extraction;geophysical image processing;image matching;image registration;remote sensing;roads;traffic engineering computing","automatic image registration;multimodal urban remote sensing images;remote sensing image analysis;multimodal image pairs;feature point detection;fast registration method;robust registration method;road intersection triangular features;intersection triangular feature construction;cross modal images;multimodal urban remote sensing image registration;roadcross triangular feature","","2","","38","CCBY","15 Apr 2021","","","IEEE","IEEE Journals"
"Benchmarking server-side software modules for handling and processing remote sensing data through Rasdaman","A. Karmas; K. Karantzalos","Remote Sensing Laboratory, National Technical University of Athens, Athens, Greece; Remote Sensing Laboratory, National Technical University of Athens, Athens, Greece","2015 7th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","23 Oct 2017","2015","","","1","4","There is a current need for novel remote sensing frameworks with the ability to handle, retrieve, process and publish efficiently big earth observation data and maps through online geospatial services. In this paper, we benchmark recently developed services which are based on the Rasdaman Array Database Management System framework. In particular, server-side software modules for processing multispectral and hyperspectral satellite data of medium, high and very high spatial resolution were quantitatively compared. Different implementations were extensively benchmarked for the online and real-time harvesting of remote sensing data. The performed evaluation indicated the efficiency, scalability and effectiveness in processing online both multispectral and hyperspectral imagery from various sensors.","2158-6276","978-1-4673-9015-6","10.1109/WHISPERS.2015.8075376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8075376","remote sensing;earth observation;multi-spectral;hyperspectral;WCPS","Satellites;Geospatial analysis;Hyperspectral sensors;Vegetation mapping;Earth;Sensors","data handling;database management systems;geophysical image processing;geophysics computing;hyperspectral imaging;image resolution;image retrieval;remote sensing","maps;online geospatial services;multispectral imagery;hyperspectral imagery;big earth observation data;spatial resolution;server-side software module benchmarking;remote sensing data processing;remote sensing data handling;Rasdaman array database management system framework;multispectral satellite data processing;hyperspectral satellite data processing;real-time data harvesting","","1","","10","IEEE","23 Oct 2017","","","IEEE","IEEE Conferences"
"Semi-automatic building extraction from very high resolution remote sensing imagery via energy minimization model","Y. Tan; Y. Yu; S. Xiong; J. Tian","National Key Laboratory of Science & Technology on Multi-spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science & Technology on Multi-spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science & Technology on Multi-spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science & Technology on Multi-spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","657","660","Extraction of objects such as buildings from very high resolution(VHR) remote sensing imagery is an important task nowadays. In practical application, the extraction precision is normally satisfied through interactive manual input. Therefore, we propose a semi-automatic building extraction framework with an energy minimization model, which includes two stages: the first stage generates the coarse information of foreground and background, and the second stage extracts the building object by applying energy minimization model. More specifically, in the first stage, the VHR imagery is grouped into small superpixels which are roughly merged into background or foreground according to a line drawn manually. Based on the coarse information of the first stage, we apply the energy minimization model to obtain the precise building object using graph cut optimization. Experimental results indicate our building extraction framework can precisely extract the buildings with different shapes.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729165","Energy minimization model;region merge;graph cut;building extraction","Buildings;Shape;Minimization;Image edge detection;Image segmentation;Feature extraction;Remote sensing","buildings (structures);geophysical image processing;image resolution;remote sensing","very high resolution remote sensing imagery;extraction precision;interactive manual input;semiautomatic building extraction framework;energy minimization model;superpixels;coarse information;graph cut optimization","","5","","16","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Joint Inversion Algorithm of Sea Surface Temperature From Microwave and Infrared Brightness Temperature","Z. Chen; R. Jin; Q. Li; G. Zhao; C. Xiao; Z. Lei; Y. Huang","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","9 May 2022","2022","60","","1","13","The demand for high-precision sea surface temperature (SST) has been growing rapidly in recent years because SST is one of the key parameters to describe the thermal state of the sea surface. This article analyzes the differences between microwave remote sensing and infrared remote sensing for SST, including the spatial resolution difference and the penetration depth difference. In order to improve the accuracy of retrieved SST, this article proposes a joint inversion algorithm for SST from combining microwave brightness temperature (BT) and infrared BT, which has also taken the influence of wind speed and atmosphere into consideration. Experiments confirm that SST data obtained from the joint inversion algorithm are more accurate than those obtained from the existing inversion algorithms.","1558-0644","","10.1109/TGRS.2022.3168984","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760436","Infrared remote sensing;joint inversion algorithm;microwave remote sensing;sea surface temperature (SST)","Microwave radiometry;Ocean temperature;Electromagnetic heating;MODIS;Temperature measurement;Remote sensing;Microwave measurement","ocean temperature;oceanographic techniques;remote sensing","penetration depth difference;retrieved SST;joint inversion algorithm;microwave brightness temperature;SST data;infrared brightness temperature;high-precision sea surface temperature;thermal state;microwave remote sensing","","","","45","IEEE","20 Apr 2022","","","IEEE","IEEE Journals"
"Unsupervised Ship Detection Based on Saliency and S-HOG Descriptor From Optical Satellite Images","S. Qi; J. Ma; J. Lin; Y. Li; J. Tian","National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","5 Jun 2015","2015","12","7","1451","1455","With the development of high-resolution imagery, ship detection in optical satellite images has attracted a lot of research interest because of the broad applications in fishery management, vessel salvage, etc. Major challenges for this task include cloud, wave, and wake clutters, and even the variability of ship sizes. In this letter, we propose an unsupervised ship detection method toward overcoming these existing issues. Visual saliency, which focuses on highlighting salient signals from scenes, is applied to extract candidate regions followed by a homogeneous filter presented to confirm suspected ship targets with complete profiles. Then, a novel descriptor, ship histogram of oriented gradient, which characterizes the gradient symmetry of ship sides, is provided to discriminate real ships. Experimental results on numerous panchromatic satellite images demonstrate the good performance of our method compared to state-of-the-art methods.","1558-0571","","10.1109/LGRS.2015.2408355","National Natural Science Foundation of China (NSFC)(grant numbers:61273279,61371339); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7059210","Histogram of oriented gradient (HOG);remote sensing;ship detection;visual saliency;Histogram of oriented gradient (HOG);remote sensing;ship detection;visual saliency","Marine vehicles;Satellites;Clutter;Optical imaging;Optical sensors;Remote sensing;Histograms","artificial satellites;geophysical image processing;object detection;optical images;remote sensing;ships","unsupervised ship detection;S-HOG descriptor;visual saliency descriptor;optical satellite image;homogeneous filter;ship histogram of oriented gradient;gradient symmetry;panchromatic satellite images","","118","","15","IEEE","12 Mar 2015","","","IEEE","IEEE Journals"
"MAS-V: Experimental System of Mirrored Aperture Synthesis at V BAND","Q. Li; H. Dou; L. Gui; L. Chen; K. Chen; Y. Wu; Z. Lei; Y. Li; L. Lang; W. Guo","Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; School of Information Engineering, Nanchang University, Nanchang, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","1013","1016","Mirrored Aperture Synthesis (MAS) was proposed to improve spatial resolution for passive microwave remote sensing. However, the MAS theory needs experimental verification. In this paper, an Experimental System of MAS (MAS-V) at V frequency band is introduced, which is developed for verifying the principle and performance of MAS. MAS-V is composed of an antenna array, reflectors, a receiving channel array, a synchronous acquisition subsystem, a computing server, and a rotatory platform. The initial experimental results demonstrate that the principle of MAS is valid. The experimental spatial resolutions are consistent with the theoretic spatial resolutions.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518080","Mirrored Aperture Synthesis (MAS);passive microwave remote sensing;radiometer;brightness temperature;spatial resolution","Spatial resolution;Apertures;Microwave radiometry;Microwave imaging;Linear antenna arrays;Polarization","antenna arrays;geophysical techniques;remote sensing","theoretic spatial resolutions;rotatory platform;computing server;synchronous acquisition subsystem;receiving channel array;reflectors;antenna array;experimental spatial resolutions;initial experimental results;V frequency band;experimental verification;MAS theory;passive microwave remote sensing;Mirrored Aperture Synthesis;Experimental System;MAS-V","","7","","10","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"ESMAS: Experiment system of Mirrored Aperture Synthesis","Q. Li; K. Chen; W. Guo; H. Dou; M. Hu; C. Huang; M. Zhu","Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","2028","2031","Mirrored Aperture Synthesis (MAS) was proposed to improve spatial resolution with fewer antennas for passive microwave remote sensing. In this paper, an Experiment System of MAS (ESMAS) at 36.4GHz is introduced, which is designed for verifying the principle and performance of MAS. ESMAS is composed of an antenna array, four reflectors, a receiving channel array, a synchronous acquisition subsystem, a processor, and a rotatory platform. The initial experiment results are given.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729523","Mirrored Aperture Synthesis (MAS);passive microwave remote sensing;radiometer;brightness temperature","Antenna arrays;Apertures;Microwave radiometry;Correlation;Receiving antennas;Reflector antennas","aperture antennas;remote sensing","ESMAS;Mirrored Aperture Synthesis;passive microwave remote sensing;antenna array;reflectors;receiving channel array;synchronous acquisition subsystem;rotatory platform","","1","","11","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"SEN23E: A Cloudless Geo-Referenced Multi-Spectral Sentinel-2/Sentinel-3 Dataset for Data Fusion Analysis","D. Ibañez; R. Fernandez-Beltran; F. Pla","Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1448","1451","The availability of geo-referenced coupled data of dif-ferent platforms is essential to train remote sensing (RS) multi-modal classification and bio-phyiscal parameter esti-mation learning methods. To properly develop a general-izing model different scenes and topographies are required. For this purpose, different multi-modal datasets have been published for the last years. Nevertheless, to our knowl-edge there is not any dataset composed of Sentinel-2 (S2) and Sentinel-3 (S3) geo-referenced images. In this paper we present SEN23, a dataset composed of 100 complete multi-spectral S2 and S3 paired images of different locations along Europe from the 2021 summer. The coupled images were obtained with a time difference of three or less days, containing less than a 1 % of cloud coverage and have a resolution difference of × 15. SEN23E is expected to help with the development of new multi-spectral, multi-resolution and multi-modal models for complex tasks which need con-text and complete images. SEN23E will be available at https://github.com/ibanezdf/SEN23E.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883867","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883867","Dataset;Data Fusion;Remote Sensing;Multi-spectral;Sentinel-2 (S2);Sentinel-3 (S3)","Learning systems;Image resolution;Biological system modeling;Europe;Data integration;Surfaces;Sensors","geophysical image processing;hydrological techniques;image classification;image fusion;learning (artificial intelligence);remote sensing;sensor fusion","data fusion analysis;geo-referenced coupled data;dif-ferent platforms;remote sensing multimodal classification;bio-phyiscal parameter esti-mation;model different scenes;topographies;different multimodal datasets;Sentinel-3 geo-referenced images;SEN23;100 complete multispectral;coupled images;time difference;resolution difference;multiresolution;multimodal models","","","","12","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"The research of multispectral remote sensing image classification based on unmixing for the Loess Plateau","X. -b. Kong; Li Li; Weiying Sun; Guanju Wei","Key Laboratory of the Loess Plateau Soil Erosion and Water Loss Process and Control, Yellow River Institute of Hydraulic Research, Zhengzhou Henan, China; Key Laboratory of the Loess Plateau Soil Erosion and Water Loss Process and Control, Yellow River Institute of Hydraulic Research, Zhengzhou Henan, China; Key Laboratory of the Loess Plateau Soil Erosion and Water Loss Process and Control, Yellow River Institute of Hydraulic Research, Zhengzhou Henan, China; College of Water Resources and Electric Power, Qinghai University, Xining Qinghai, China","2016 4th International Workshop on Earth Observation and Remote Sensing Applications (EORSA)","29 Aug 2016","2016","","","461","464","The ecological environment of the Loess Plateau in China is the most vulnerable area, and also one of most serious soil erosion areas. Medium-resolution and multi-spectral remote sensing image, such as Landsat Imagery, plays an important role in the study of the ecological environment monitoring and soil erosion, especially for medium and large scale or watershed level. However, how to improve the accuracy of remote sensing image classification, and to extracte more accurate covering feature information, has become a key problem preventing remote sensing applications in the study of soil erosion, ecological environment, and other related disciplines.","","978-1-5090-1479-8","10.1109/EORSA.2016.7552851","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552851","Multispectral remote sensing;Spectral Umixing;Image Criteria classification","Remote sensing;Soil;Agriculture;Earth;Conferences;Image classification;Water resources","calibration;environmental monitoring (geophysics);erosion;feature extraction;image classification;image fusion;radiometry;remote sensing","image classification;Loess plateau;China;soil erosion areas;ecological environment monitoring;feature information;medium-resolution image;multispectral remote sensing image;spatial resolution;Chabagou watershed;landsat8 OLI image;radiometric calibration;atmospheric correction;image fusion;linear mixed pixel decomposition;sub-pixel level distribution;surface features","","","","9","IEEE","29 Aug 2016","","","IEEE","IEEE Conferences"
"Multiple Scattering Effect on Forest Physiological Parameters of Multi-Spectral Lidar Canopy Waveforms","X. Yang; C. Wang; X. Xi","Key Laboratory of Digital Earth Science, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Digital Earth Science, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Digital Earth Science, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","8467","8469","Multispectral LiDAR systems have been proved to have potential for retrieving forest structural and physiological parameters from waveforms of various wavelengths. However, multiple scattering occurring in complex forest canopy directly affects the waveform shape. This study combined a leaf optical model, a forest structure model, and a LiDAR process model to simulate multispectral LiDAR waveforms in single and multiple scattering cases and then assessed the effect of multiple scattering on forest physiological indicators. Results showed that 1) multiple scattering increases the waveform intensity, especially at near-infrared wavelength; 2) multiple scattering greatly affects the retrieval of physiological parameters of the understory; 3) when leaf chlorophyll content is low, forest physiological indicator was relative-seriously overestimated due to the multiple scattering effect. These findings may shed some light on our understanding of multiple scattering mechanism and accurately retrieving forest physiological parameters from multi-spectral LiDAR waveforms.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898303","Multispectral LiDAR;multiple scattering;PROSPECT model;DART model;physiological parameters","Forestry;Laser radar;Physiology;Vegetation;Remote sensing;Optical scattering","forestry;optical radar;remote sensing by laser beam;remote sensing by radar;vegetation;vegetation mapping","forest physiological indicator;waveform intensity;multiple scattering effect;multiple scattering mechanism;forest physiological parameters;multispectral LiDAR waveforms;multispectral lidar canopy waveforms;multispectral LiDAR systems;forest structural;complex forest canopy;waveform shape;leaf optical model;forest structure model;LiDAR process model","","4","","6","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Multiple Multi-Spectral Remote Sensing Data Fusion and Integration for Geological Mapping","M. K. Pal; T. M. Rasmussen; M. Abdolmaleki","Division of Geosciences and Environmental Engineering, Luleå University of Technology, Norrbotten county, Sweden; Division of Geosciences and Environmental Engineering, Luleå University of Technology, Norrbotten county, Sweden; Division of Geosciences and Environmental Engineering, Luleå University of Technology, Norrbotten county, Sweden","2019 10th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","5 Dec 2019","2019","","","1","5","This paper investigates spaceborne multiple multispectral data-fusion and blending to generate an integrated data with higher spatio-spectral resolution and spectral coverage in order to obtain improved geological mapping. A hybrid approach using Gram-Schmidt pan-sharpening and Inverse Distance Weighting (IDW) based downsampling technique is developed to generate integrated data from multiple multispectral data. In this study, Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER), Landsat 8, and Sentinel-2 data have been used to evaluate the developed approach for lithological mapping. Liikavaara to Puoltikasvaara including Nautanen and nearby-mining area, in the Gällivare district of Norrbotten county, Sweden, is chosen as a case study. Lithological map of the study area is produced using Support Vector Machine (SVM) classifier. Bedrock geological map from the Geological Survey of Sweden (SGU) is used for classification accuracy assessment. The results show that integrated data produced better accuracy than original individual spaceborne multispectral data for lithological mapping of the study area.","2158-6276","978-1-7281-5294-3","10.1109/WHISPERS.2019.8921142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8921142","Multispectral;spatial and spectral resolution;data fusion and integration;classification;geological mapping SVM","Remote sensing;Geology;Artificial satellites;Earth;Spatial resolution;Data integration;Support vector machines","radiometry;remote sensing;sensor fusion;terrain mapping","Sweden;Support Vector Machine classifier;Norrbotten county;Gällivare district;Nautanen;Liikavaara;Puoltikasvaara;Landsat 8;ASTER;Advanced Spaceborne Thermal Emission and Reflection Radiometer;inverse distance weighting based downsampling technique;hybrid approach;spaceborne multiple multispectral data-fusion;multiple multispectral remote sensing data fusion;Geological Survey;bedrock geological map;nearby-mining area;Sentinel-2 data;Advanced Spaceborne Thermal Emission;Gram-Schmidt pan-sharpening;improved geological mapping;spectral coverage;higher spatio-spectral resolution;integrated data;lithological mapping;original individual spaceborne multispectral data;classification accuracy assessment","","1","","10","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Dual-Branch Fusion Network for Residential Area Extraction from a Ziyuan-3 Multi-Spectral and Multi-View Data Set","D. Li; J. Li; X. Huang","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2722","2725","The accurate extraction of residential area is of great significance to disaster assessment, urban management, and climate change research. Deep learning-based methods are limited by annotations acquisition and single data source. In this paper, a dual-branch encoder is proposed to extract the features of different inputs, and a multi-attention fusion module is proposed to effectively fuse dual-branch features. Furthermore, we propose a novel encoder-decoder architecture, called the dual-branch fusion network (DBNet). In addition, we propose a large-scale residential area extraction data set (ZRA) containing 43 Ziyuan-3 (ZY3) multi-spectral (MS) and multi-view (MV) images. Experiments on ZRA, our DBNet achieve state-of-the-art performance with a F1 score of 84.6% and an IoU of 73.3%.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883483","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883483","Residential Area Extraction;High-Resolution Remote Sensing;Convolutional Neural Network;Ziyuan-3 Satellite Images","Training;Satellites;Fuses;Annotations;Image edge detection;Soft sensors;Urban areas","decoding;disasters;feature extraction;geophysical image processing;image fusion;learning (artificial intelligence);remote sensing;sensor fusion;town and country planning","multiview data set;disaster assessment;climate change research;deep learning-based methods;annotations acquisition;single data source;dual-branch encoder;multiattention fusion module;dual-branch features;novel encoder-decoder architecture;dual-branch fusion network;large-scale residential area extraction data;Ziyuan-3 multispectral;multiview images","","","","15","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"A New Orientation Estimation Method Based on Rotation Invariant Gradient for Feature Points","W. Xu; S. Zhong; W. Zhang; J. Wang; L. Yan","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","22 Apr 2021","2021","18","5","791","795","For many remote sensing image applications, orientation estimation is a crucial step for feature points extraction and matching, but it has attracted little attention. Due to the intensity differences between remote sensing image pairs, it is difficult to estimate the orientations of corresponding points accurately, resulting in performance degradation of feature matching. Thus, encountering the intensity differences, a robust spatial structure description for feature regions, and an effective calculation manner from description to orientation play a key role in accurate orientation estimation. To this end, in this letter, we first define a plausible orientation for feature points by the total gradient, offering an effective way to convert the gradient trend of the feature region to orientation. Therefore, we further propose a novel orientation estimation method, in which the rotation invariant gradient is introduced to improve the accuracy of gradient calculation and robustness of spatial structure description. Experimental results on multisensor remote sensing images demonstrate that our method increases the orientation estimation accuracy remarkably and outperforms other orientation estimation methods by a large margin, and effectively improves the performance of feature matching.","1558-0571","","10.1109/LGRS.2020.2985358","National Natural Science Foundation of China(grant numbers:61971460); Hubei Provincial Natural Science Foundation of China(grant numbers:2018CFA089); National Science Foundation for Young Scientists of China(grant numbers:61806081); China Postdoctoral Science Foundation(grant numbers:2018M632858); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9090871","Feature point;image registration;orientation estimation;remote sensing","Feature extraction;Remote sensing;Robustness;Estimation error;Degradation;Market research","feature extraction;geophysical image processing;image fusion;image matching;remote sensing","new orientation estimation method;orientation estimation methods;orientation estimation accuracy;multisensor remote sensing images;robustness;gradient calculation;rotation invariant gradient;novel orientation estimation method;gradient trend;total gradient;plausible orientation;accurate orientation estimation;orientation play;effective calculation manner;feature region;robust spatial structure description;feature matching;performance degradation;remote sensing image pairs;intensity differences;feature points extraction;remote sensing image applications","","4","","17","IEEE","11 May 2020","","","IEEE","IEEE Journals"
"A multi-tier higher order conditional random field for land cover classification of multi-temporal multi-spectral landsat imagery","B. P. Salmon; W. Kleynhans; J. C. Olivier; C. P. Schwegmann; W. C. Olding","School of Engineering and ICT, University of Tasmania, Australia; Department of Electrical, Electronic and Computer Engineering, University of Pretoria, South Africa; School of Engineering and ICT, University of Tasmania, Australia; Department of Electrical, Electronic and Computer Engineering, University of Pretoria, South Africa; School of Engineering and ICT, University of Tasmania, Australia","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","4372","4375","In this paper we present a 2-tier higher order Conditional Random Field which is used for land cover classification. The Conditional Random Field is based on probabilistic messages being passed along a graph to compute efficiently the conditional probability for a land cover class. Conventionally the information is passed among direct spatial neighbors to improve classification accuracy. The inclusion of higher order descriptive structures in the graphs allow for more information to be pass along to further improve classification accuracy. Unfortunately this increases the computational cost beyond what is feasible to classify a large geographical area. In this work we investigate a spatially based cluster potential to improve classification accuracy while keeping the computational costs tractable. We also expand the typical 1-tier proto-graph used in conventional CRFs to a 2-tier graph to encapsulate the temporal dimension. This further improves the classification accuracy by modeling the seasonal variations experienced throughout the year. The conventional and higher order CRF are compared to a Random Forest on monthly composited Landsat images. These two CRFs are then compared to the same CRFs expanded to a 2-tier graph. An overall improvement between 2-4% is observed in our study area which is located near the city of Vryheid, South Africa.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326795","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326795","Context awareness;Graphical Models;Image classification;Remote Sensing;Satellites;Statistics","Satellites;Remote sensing;Accuracy;Earth;Cities and towns;Markov random fields;Probabilistic logic","geophysical image processing;image classification;land cover;probability;remote sensing","multitier higher order conditional random field;land cover classification;multitemporal multispectral Landsat imagery;classification accuracy;random forest;Vryheid city;South Africa","","","","7","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Road network extraction and vectorization of remote sensing images based on deep learning","Z. Gong; L. Xu; Z. Tian; J. Bao; D. Ming","National Key Laboratory of Science and Technology on Multi-spectral Information Processing Technology, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Beijing Aerospace Automatic Control Institute, Beijing, China; Beijing Aerospace Automatic Control Institute, Beijing, China; Wuhan of the naval equipment department, The Second Navy Representative Office, Wuhan, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing Technology, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China","2020 IEEE 5th Information Technology and Mechatronics Engineering Conference (ITOEC)","16 Jul 2020","2020","","","303","307","The road in the remote sensing image has the characteristics of slender and tortuous shape, complex connectivity, large road span, strong connectivity, complex ground information of the remote sensing image, occlusion, and different scales, etc. Based on these characteristics, this paper will do some change in Unet, included three parts: encoding, center feature extraction, decoding. The encoding part is aimed at problems that Unet can't extract rich feature for few samples. We proposes to use a pre-trained VGG model as an encoding module to improve network performance, reduce the risk of overfitting, and extract rich feature; the center feature extraction part, for the problems of occlusion, scale change, connectivity, etc., extracts the dense Dilation convolution module to maintain the resolution while expanding the receptive field to extract more distinguishing features; the decoding part In view of the different importance of features at different scales, a channel attention module is proposed to realize the fusion of high and low features. Through experimental comparison and analysis, the model has a significant effect on solving the road extraction problem of remote sensing images. Then the skeleton is extracted from the segmentation results and processed by denoising and straight line connection. The road network map is extracted from the skeleton map and vectorized to realize the automatic grid. Grid data vectorization.","","978-1-7281-4323-1","10.1109/ITOEC49072.2020.9141903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141903","remote sensing image;Unet;dense dilation convolution;channel attention module;feature fusion;Raster vectorization","Roads;Feature extraction;Convolution;Remote sensing;Image segmentation;Decoding;Encoding","feature extraction;geophysical image processing;image segmentation;learning (artificial intelligence);remote sensing;roads","vectorization;remote sensing image;complex connectivity;road span;encoding part;rich feature;center feature extraction part;distinguishing features;high features;low features;road extraction problem;road network map;road network extraction;deep learning;pre-trained VGG model;dense dilation convolution module;grid data vectorization","","1","","13","IEEE","16 Jul 2020","","","IEEE","IEEE Conferences"
"Deepsen3: Deep Multi-Scale Learning Model For Spatial-Spectral Fusion Of Sentinel-2 And Sentinel-3 Remote Sensing Images","A. Alboody; M. Puigt; G. Roussel; V. Vantrepotte; C. Jamet; T. -K. Tran","LISIC – UR 4491, Univ. Littoral Côte d’Opale, Longuenesse, France; LISIC – UR 4491, Univ. Littoral Côte d’Opale, Longuenesse, France; LISIC – UR 4491, Univ. Littoral Côte d’Opale, Longuenesse, France; CNRS, LOG – UMR 8187, Univ. Littoral Côte d’Opale, Wimereux, France; CNRS, LOG – UMR 8187, Univ. Littoral Côte d’Opale, Wimereux, France; CNRS, LOG – UMR 8187, Univ. Littoral Côte d’Opale, Wimereux, France","2022 12th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","22 Nov 2022","2022","","","1","5","Recently, deep learning methods that integrate image features gradually became a hot development trend in fusion of multispectral and hyperspectral remote sensing images, aka multi-sharpening. Fusion of a low spatial resolution hyperspectral image (LR-HSI datacube) with its corresponding high spatial resolution multispectral image (HR-MSI datacube) to reconstruct a high spatial resolution hyperspectral image (HR-HSI) has been a significant subject in recent years. Nevertheless, it is still difficult to achieve a high quality of spatial and spectral information fusion. In this paper, we propose a Deep Multi-Scale Learning Model (called DeepSen3) of spatial-spectral information fusion based on multi-scale inception residual convolutional neural network (CNN) for more efficient hyperspectral and multispectral image fusion from ESA remote sensing satellite missions (Sentinel-2 and Sentinel-3 images). The proposed DeepSen3 fusion network was applied to Sentinel-2 MSI (13 spectral bands with a spatial resolution ranging from 10, 20 to 60 m) and Sentinel-3 OLCI (21 spectral bands with a spatial resolution of 300 m) images. Extensive experiments demonstrate that the proposed DeepSen3 network achieves the best performance (both qualitatively and quantitatively) compared with recent state-of-the-art deep learning approaches.","2158-6276","978-1-6654-7069-8","10.1109/WHISPERS56178.2022.9955139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955139","Deep Learning;Residual Convolutional Neural Network (ResNet-CNN);Multi-Scale Inception;Feature Extraction;Spatial-Spectral Image Fusion;Sentinel-2 and Sentinel-3 Remote Sensing Images;HyperSpectral Images (HSI);Multi-Spectral Images (MSI)","Deep learning;Satellites;Signal processing;Market research;Distance measurement;Convolutional neural networks;Spatial resolution","artificial satellites;convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image fusion;remote sensing","deep multiscale learning model;DeepSen3 fusion network;ESA remote sensing satellite missions;high spatial resolution hyperspectral image;low spatial resolution hyperspectral image fusion;multiscale inception residual convolutional neural network;multisharpening;multispectral remote sensing image fusion;Sentinel-2 MSI images;Sentinel-3 OLCI images;Sentinel-3 remote sensing images;spatial-spectral information fusion","","","","20","IEEE","22 Nov 2022","","","IEEE","IEEE Conferences"
"Psgan: A Generative Adversarial Network for Remote Sensing Image Pan-Sharpening","X. Liu; Y. Wang; Q. Liu","Beijing Advanced Innovation Center for Big Data and Brain Computing; Beijing Advanced Innovation Center for Big Data and Brain Computing; Beijing Key Laboratory of Digital Media, Beihang University, Beijing, China","2018 25th IEEE International Conference on Image Processing (ICIP)","6 Sep 2018","2018","","","873","877","Remote sensing image fusion (also known as pan-sharpening) aims to generate a high resolution multi -spectral image from inputs of a high spatial resolution single band panchromatic (PAN) image and a low spatial resolution multi-spectral (MS) image. In this paper, we propose PSGAN, a generative adversarial network (GAN) for remote sensing image pansharpening. To the best of our knowledge, this is the first attempt at producing high quality pan-sharpened images with GANs. The PSGAN consists of two parts. Firstly, a two-stream fusion architecture is designed to generate the desired high resolution multi -spectral images, then a fully convolutional network serving as a discriminator is applied to distinct “real” or “pan-sharpened” MS images. Experiments on images acquired by Quickbird and GaoFen-1 satellites demonstrate that the proposed PSGAN can fuse PAN and MS images effectively and significantly improve the results over the state of the art traditional and CNN based pan-sharpening methods.","2381-8549","978-1-4799-7061-2","10.1109/ICIP.2018.8451049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451049","Image fusion;pan-sharpening;GAN;deep learning;remote sensing","Generators;Gallium nitride;Spatial resolution;Remote sensing;Task analysis;Training","geophysical image processing;image fusion;image resolution;remote sensing","two-stream fusion architecture;Quickbird and GaoFen-1 satellites;high resolution multi-spectral images;MS images;high quality pan-sharpened images;remote sensing image pansharpening;PSGAN;low spatial resolution multispectral;high spatial resolution single band panchromatic image;sensing image fusion;remote sensing image pan-sharpening;generative adversarial network;psgan","","61","","25","IEEE","6 Sep 2018","","","IEEE","IEEE Conferences"
"Unsupervised Remote Sensing Image Super-Resolution Using Cycle CNN","P. Wang; H. Zhang; F. Zhou; Z. Jiang","Image Processing Center, School of Astronautics, Beihang University, Beijing, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China; DFH Satellite Co., Ltd., Beijing, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3117","3120","Single image super-resolution (SISR) is a useful procedure for many remote sensing applications. However, paired high-resolution and low-resolution remote sensing images are actually hard to acquire for supervised learning SR methods. In this paper, we propose an unsupervised network named Cycle-CNN to handle this problem. Our network consists of two generative CNNs for down-sampling and super-resolution separately, and can be trained with unpaired data. Experiments on panchromatic and multi-spectral images of GaoFen-2 satellite indicate that our method achieves state-of-the-art SR results and is robust against noise and blur in the remote sensing images.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898648","super-resolution;unsupervised learning;CNN;remote sensing image","Remote sensing;Training;Satellites;Computer vision;Unsupervised learning","convolutional neural nets;image resolution;learning (artificial intelligence);remote sensing","single image super-resolution;low-resolution remote sensing images;supervised learning SR methods;multispectral images;unsupervised remote sensing image super-resolution;cycle-CNN;GaoFen-2 satellite;panchromatic images","","15","","10","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"4D Convolutional Neural Networks for Multi-Spectral and Multi-Temporal Remote Sensing Data Classification","M. Giannopoulos; G. Tsagkatakis; P. Tsakalides","Foundation for Research and Technology Hellas (FORTH), Heraklion, Greece; Foundation for Research and Technology Hellas (FORTH), Heraklion, Greece; Foundation for Research and Technology Hellas (FORTH), Heraklion, Greece","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","1541","1545","Multi-temporal remotely sensed observations acquired by multi-spectral sensors contain a wealth of information related to the Earth’s state. Deep learning methods have demonstrated a great potential in analyzing such observations. Traditional 2D and 3D approaches are unable to effectively extract valuable information encoded across all available dimensions. In this work, we propose the extension of current fully-convolutional models for multi-temporal remote sensing data classification to their high-dimensional analogs, which can naturally capture multi-dimensional dependencies and correlations. Experimental analysis on recently released observations from Landsat-8 reveals that our proposed high-dimensional fully-convolutional approach exhibits a clear classification performance improvement over state of the art low-order fully-convolutional models.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746777","Hellenic Foundation for Research and Innovation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746777","Convolutional Neural Networks;Time-series;Remote Sensing;Land-Cover Classification","Representation learning;Earth;Deep learning;Three-dimensional displays;Data models;Sensors;Convolutional neural networks","convolutional neural nets;geophysical image processing;image classification;remote sensing;spectral analysis","4D convolutional neural networks;multitemporal remote sensing data classification;multispectral sensors;multispectral remote sensing data classification;deep learning;high-dimensional analogs","","","","20","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"An adaptive image fusion rule for remote sensing images based on the particle swarm optimization","R. Gharbia; A. H. El Baz; A. E. Hassanien","Nuclear Materials Authority, Egypt; Faculty of Science, Damietta University, Egypt; Faculty of Computers and Information, Cairo University, Cairo, Egypt","2016 International Conference on Computing, Communication and Automation (ICCCA)","16 Jan 2017","2016","","","1080","1085","This paper proposes an adaptive remote sensing image fusion technique based on the particle swarm optimization (PSO) to get the optimum fused image. Firstly, the principal component analysis (PCA) is applied such as feature extraction. The PCA is applied to the multi-spectral (MS) images to concentrate the spatial resolution. Secondly, the discrete cosine transform (DCT) transforms the images into the frequency domain. Thirdly, the particle swarm optimization (PSO) is used to obtain an adaptive weight of the fusion rule. Then, the adaptive fusion rule is applied to the DCT coefficients. Finally, the fused image is obtained through the inverse of principal component analysis (IPCA) and the inverse of the discrete cosine transform (IDCT). The different satellite sensors have different characteristics in reflecting spectral and spatial information of the same scene. Therefore, the proposed technique was implemented on many satellite images such as MODIS, ETM+, SPOT, ASTER and MSS satellite. The experimental results demonstrated that the adaptive remote sensing image fusion technique based on the PSO preserves the spectral resolution and improves the spatial information.","","978-1-5090-1666-2","10.1109/CCAA.2016.7813903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7813903","Remote sensing;Multi-sensor image fusion;Adaptive image fusion rule;principal component analysis (PCA);discrete cosine transform (DCT);the particle swarm optimization (PSO);panchromatic (Pan) and multi-spectral(MS) image;image fusion quality metrics","Image fusion;Discrete cosine transforms;Principal component analysis;Remote sensing;Satellites;Particle swarm optimization","discrete cosine transforms;feature extraction;geophysical image processing;image fusion;image resolution;inverse transforms;particle swarm optimisation;principal component analysis;remote sensing;spectral analysis","adaptive image fusion rule;particle swarm optimization;adaptive remote sensing image fusion;PSO;feature extraction;multispectral images;MS images;spatial resolution;discrete cosine transform transforms;DCT transforms;inverse principal component analysis;IPCA;inverse discrete cosine transform;IDCT;satellite sensors;satellite images;spatial information","","4","","20","IEEE","16 Jan 2017","","","IEEE","IEEE Conferences"
"Evaluation of multi-spectral cube from multi-sensor imagery corresponding to hyperspectral imagery","D. Varade; A. Sure; O. Dikshit","Geoinformatics, Indian Institute of Technology, Kanpur, India; Geoinformatics, Indian Institute of Technology, Kanpur, India; Geoinformatics, Indian Institute of Technology, Kanpur, India","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","656","659","In this paper, we evaluate the incorporation of open source multi-spectral imagery from Landsat-8 and Sentinel-2 to form a multi-spectral cube that represents the surface reflectance in near full wave spectra for various distinct natural objects from two study areas. The results from the integration are evaluated with respect to EO-1: Hyperion hyperspectral imagery. A three-stage evaluation strategy is proposed based on the spectral response, classification and endmember identification using spectral unmixing.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127039","Multi-sensor;Data fusion;Multi-spectral","Remote sensing;Indexes;Correlation coefficient;Optical sensors","geophysical image processing;hyperspectral imaging;image classification;remote sensing","image classification;Landsat-8;Sentinel-2;full wave spectra;EO-1;spectral unmixing;Hyperion hyperspectral imagery;open source multispectral imagery;multisensor imagery;multispectral cube","","3","","9","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Unsupervised Categorization of Forest-Cover Using Multi-Spectral and Hybrid Polarimetric Sar Images","S. M. Aswatha; R. Mahapatra; J. Mukhopadhyay; P. K. Biswas; S. Aikat; A. Misra","Indian Institute of Technology, Kharagpur, India; Indian Institute of Technology, Kharagpur, India; Indian Institute of Technology, Kharagpur, India; Indian Institute of Technology, Kharagpur, India; Indian Institute of Technology, Kharagpur, India; Space Applications Centre, Ahmedabad, India","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2603","2606","In this paper, we propose to distinguish forest-cover in an unsupervised fashion by a combination of passive multi-spectral imagery and active hybrid polarized SAR data. At first, multi-spectral imagery (MSI) is used to separate general vegetation region (e.g., forest, mature grassland, and pre-harvest agricultural fields) from the imaged scene using spectral slopes based rules and support vector machine technique. Then, hybrid polarimetric SAR image of the same region (acquired with a common time stamp) is clustered into three scatter classes, namely, surface, volume, and dihedral, using Stokes parameters based m - δ decomposition. Forest cover is extracted by bi-labeled pixels of the study site that correspond to vegetation (in MSI) and volume scatter (in SAR), which forms a community level classification of forest region. Further, using Wishart derived mean-shift clustering technique, we segregate possible categories of forest clusters within the mapped forest region to obtain a sub-community level classification. Discernible spectral and scattering characteristics of remotely sensed images are explored in our work for identifying forest regions and their possible categories. The proposed method is automated by freeing the manual supervision in selecting seed pixels for training any machine learning technique.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898870","Forest classification;hybrid polarimetric SAR image;multi-spectral image;unsupervised classification;Wishart mean-shift","Forestry;Radar polarimetry;Vegetation mapping;Remote sensing;Covariance matrices;Synthetic aperture radar;Manuals","agriculture;forestry;geophysical image processing;image classification;learning (artificial intelligence);radar imaging;radar polarimetry;remote sensing by radar;synthetic aperture radar;vegetation mapping","machine learning technique;community level classification;volume scatter;bi-labeled pixels;mature grassland;pre-harvest agricultural fields;separate general vegetation region;active hybrid polarized SAR data;passive multispectral imagery;unsupervised fashion;forest-cover;unsupervised categorization;remotely sensed images;scattering characteristics;discernible spectral characteristics;mapped forest region;forest clusters;Wishart derived mean-shift clustering technique;MSI;Stokes parameters;hybrid polarimetric SAR image;support vector machine technique;spectral slopes;imaged scene","","1","","11","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Remote sensing monitoring of changes potentially associated to obstacles to air navigation","G. Pinelli; T. Veracini","Ingegneria dei Sistemi (IDS) S.p.A. Via Enrica Calabresi, Pisa, Italy; Ingegneria dei Sistemi (IDS) S.p.A. Via Enrica Calabresi, Pisa, Italy","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","3041","3044","Correct identification of obstacles at the periphery of airports is an important issue to secure the safety of takeoff, flight, and landing to aircrafts. This work is carried on as part of the obstacle risk assessment and risk mitigation operations in the aviation security context. Specifically, this paper presents a novel methodology to change detection (CD) in pairs of high resolution (HR) ortho-rectified multi-spectral satellite images acquired on the same geographical area at different times. Within this framework, orograph-ic/topographic changes potentially associated with variations in the obstacles to air navigation in wide areas are addressed. In fact, the developed CD strategy consists in a pre-screening technique offering a low-cost and fast solution to strongly reduce the terrain area to be deeply investigated through more expensive very HR imagery or/and detailed ground surveys.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326457","Change detection;multi-spectral imagery;photogrammetry","Vegetation mapping;Satellites;Remote sensing;Aircraft;Context;Image registration;Performance evaluation","aerospace safety;airports;entry, descent and landing (spacecraft);geophysical image processing;image resolution;risk management;spectral analysis;terrain mapping","remote sensing monitoring;air navigation;airport;aircraft landing;obstacle risk assessment;risk mitigation operation;aviation security context;change detection;CD;high resolution orthorectified multi-spectral satellite image;HR orthorectified multispectral satellite image;screening technique;terrain area reduction","","","","5","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Rotating mirrored aperture synthesis (RMAS) for passive microwave remote sensing","Q. Li; K. Chen; W. Guo; Y. Li; H. Dou","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications Huazhong University of Science and Technology (HUST), Wuhan, China; Huazhong University of Science and Technology, Wuhan, Hubei, CN; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications Huazhong University of Science and Technology (HUST), Wuhan, China; Huazhong University of Science and Technology, Wuhan, Hubei, CN; Huazhong University of Science and Technology, Wuhan, Hubei, CN","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","3481","3484","Aperture synthesis technique can provide high spatial resolution without requiring very large and massive real aperture. However, large aperture synthesis systems are very complicated. In this paper, Rotating Mirrored Aperture Synthesis (RMAS) is proposed, which combines rotating and mirrored aperture synthesis to improve spatial resolution with fewer antennas. The principle of RMAS is presented. The initial simulation result shows the RMAS system can approximately reproduce the brightness temperature image of the observed scene.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326570","Rotating mirrored aperture synthesis (RMAS);passive microwave remote sensing;radiometer","Antenna arrays;Microwave radiometry;Aperture antennas;Arrays;Spatial resolution","antenna arrays;geophysical equipment;microwave imaging;remote sensing","brightness temperature image;RMAS system;antenna arrays;spatial resolution;aperture synthesis system;aperture synthesis technique;Passive Microwave Remote Sensing;rotating mirrored aperture synthesis","","3","","14","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"UAV Based Remote Sensing for Tassel Detection and Growth Stage Estimation of Maize Crop Using Multispectral Images","A. Kumar; M. Taparia; P. Rajalakshmi; W. Guo; B. N. B; B. Marathi; U. B. Desai","Department of Electrical Engineering, Indian Institute of Technology, Hyderabad, India; Department of Electrical Engineering, Indian Institute of Technology, Hyderabad, India; Department of Electrical Engineering, Indian Institute of Technology, Hyderabad, India; International Field Phenomics Research Laboratory, The University of Tokyo, Tokyo, Japan; Professor Jayashankar Telangana State Agricultural University (PJTSAU), Hyderabad, Telangana, India; Professor Jayashankar Telangana State Agricultural University (PJTSAU), Hyderabad, Telangana, India; Department of Electrical Engineering, Indian Institute of Technology, Hyderabad, India","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1588","1591","The monitoring of growth stages of a crop is vital for farmers to optimize the use of agronomic inputs and crop-management. Manual observation of the growth stages of a crop in large fields is a time consuming and labor-intensive task. To reduce human efforts in this tedious work, Unmanned Aerial Vehicle (UAV)-based remote sensing with the emergence of different technologies like deep learning is helping in monitoring the health of a crop. However, Convolutional Neural Network (CNN) based models need a lot of labeled data and computations to get trained to automate the process. In this paper, a pixel-based segmentation method has been proposed for tassel detection, and estimation of growth stages like tasseling, and day to 50% tasseling of maize crop. The performance analysis shows that the proposed method reduces time in developing the dataset for the training of CNN models. It also gives an advantage over training-time and computational complexity when compared to CNN models like YOLO and Faster-RCNN.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323266","Japan Science and Technology (JST)(grant numbers:MST/IBCD/EEIF066/2016-17G48); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323266","Multi-spectral images;UAV based remote sensing;high throughput plant phenotyping;growth stages;crop monitoring","Agriculture;Image segmentation;Soil;Monitoring;Indexes;Computational modeling;Cameras","agriculture;autonomous aerial vehicles;convolutional neural nets;crops;deep learning (artificial intelligence);geophysical image processing;image segmentation;remote sensing;robot vision","tasseling;maize crop;CNN models;UAV based remote sensing;tassel detection;growth stage estimation;multispectral images;crop-management;labor-intensive task;unmanned aerial vehicle-based remote sensing;convolutional neural network based models;pixel-based segmentation method;YOLO model;faster-RCNN model","","1","","17","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"One-Dimensional Mirrored Aperture Synthesis With Rotating Reflector","H. Dou; Q. Li; L. Gui; K. Chen; Y. Li; C. Huang; M. Hu","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","23 Jan 2018","2018","15","2","197","201","In this letter, 1-D mirrored aperture synthesis with a rotating reflector (1-D MAS-R) is proposed to improve the spatial resolution and reduce the number of required antennas for passive microwave remote sensing. The principle of the 1-D MAS-R with an antenna array is given, and from the principle, the 1-D MAS-R with only one antenna can also reconstruct the image of the scene. Simulation results demonstrate the validity of the 1-D MAS-R even with only one antenna, and the spatial resolution is improved by increasing the distance between the reflector and the antenna or antenna array.","1558-0571","","10.1109/LGRS.2017.2779561","National Natural Science Foundation of China(grant numbers:41176156); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8245912","Brightness temperature;mirrored aperture synthesis;rotating reflector","Antenna arrays;Spatial resolution;Receiving antennas;Aperture antennas;Correlation","antenna arrays;image reconstruction;remote sensing","spatial resolution;passive microwave remote sensing;antenna array;rotating reflector;one-dimensional mirrored aperture synthesis;1D mirrored aperture synthesis;1D MAS-R principle;image reconstruction","","4","","5","IEEE","3 Jan 2018","","","IEEE","IEEE Journals"
"A simulation study on remote sensing of quasi-Gaussian sea wave slopes by the wave scatterometer SWIM","P. Chen; D. Hauser; Q. Meng; Q. Yin","Science and Technology on Multi - spectral Information Processing Laboratory, Wuhan, China; CNRS, Universite Paris 06, Guyancourt, France; Science and Technology on Multi - spectral Information Processing Laboratory, Wuhan, China; Science and Technology on Multi - spectral Information Processing Laboratory, Wuhan, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","5812","5815","Knowledge of the distribution of wave slopes in the sea is important for understanding a number of processes occurring at or near the air-sea interface. The sea slope probability density function (pdf) of sea waves is quasi-Gaussian, being able to be expressed as a Gram-Charlier expansion to fourth-order. However, the method is absent for remote sensing the sea slope pdf in a large scale. SWIM (Surface Waves Investigation and Monitoring), used on the CFOSAT (China-France Oceanography Satellite) mission, the first space borne wave scatterometer in the world can obtain two dimensional (2D) scattering measurements of sea surface in the incidence and azimuth direction with high resolution, which made it possible to measure 2D slope pdf with high accuracy. In the paper, the feasibility of remote sensing quasi-Gaussian sea slope by SWIM is studied by the simulation.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730518","slope probability density of the sea surface;ocean wave scatterometer;quasi-Gaussian sea;inversion error","Sea measurements;Sea surface;Two dimensional displays;Scattering;Spaceborne radar;Surface waves;Market research","Gaussian processes;ocean waves;oceanographic techniques;probability;remote sensing","remote sensing;quasiGaussian sea wave slope;SWIM;wave slope distribution;air-sea interface;2D sea slope probability density function;Gram-Charlier expansion;Surface Waves Investigation and Monitoring;CFOSAT mission;China-France Oceanography Satellite;space borne wave scatterometer;2D scattering measurements;sea surface","","1","","7","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Realistic 3D-simulation of large-scale forest scene based on individual tree detection","J. Qi; D. Xie; G. Yan","State Key Laboratory of Remote Sensing Science, Beijing Normal University, Beijing, China; State Key Laboratory of Remote Sensing Science, Beijing Normal University, Beijing, China; State Key Laboratory of Remote Sensing Science, Beijing Normal University, Beijing, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","728","731","Reconstructing a realistic and large-scale 3D forest scene has potential applications in visual representations and scientific research. Forest scene with explicitly described branches and leaves can provide a more accurate interpretation of interactions between light and canopy. In this study, a large-scale 3D forest scene reconstruction and simulation method is proposed. A series of individual trees with high level of details are generated using parameters derived from allometric equation, which populates plot leaf area index (LAI) into each individual tree. Based on the airborne laser scanning (ALS) data, the height, crown diameter and position of each individual tree are extracted by watershed segmentation algorithm. Finally, an emulation system based on ray-tracing is developed. It provides the capability to simulate RGB and multi-spectral images. These simulated datasets with “ground truth” can be used as benchmark for a variety of applications in remote sensing, forest investigation and computer graphic.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729183","image simulation;3D reconstruction;forest;allometric equation","Vegetation;Three-dimensional displays;Remote sensing;Solid modeling;Mathematical model;Image reconstruction;Reflectivity","forestry;remote sensing by radar","large-scale forest scene;individual tree detection;large-scale 3D forest scene;visual representations;-scale 3D forest scene reconstruction;allometric equation;leaf area index;airborne laser scanning;watershed segmentation algorithm;ray-tracing;multi-spectral images;remote sensing;computer graphic","","1","","11","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Semi-Supervised Representation Learning for Remote Sensing Image Classification Based on Generative Adversarial Networks","P. Yan; F. He; Y. Yang; F. Hu","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China","IEEE Access","24 Mar 2020","2020","8","","54135","54144","In the existing studies on remote sensing image scene classification, the supervised learning methods which are fine-tuned from pre-trained model require a large amount of labeled training data and parameters, while unsupervised learning methods do not make full use of label information, and the classification performance could be improved. In this paper, we introduced semi-supervised learning into generative adversarial network (GAN), so the discriminator learned more discriminative features from labeled data and unlabeled data. Moreover, the mixup data augmentation method was introduced into our classification model to augment the data and stabilized the training process. We carried out extensive experiments for both UC-Merced and NWPU-RESISC45 datasets with a 5-fold cross-validation protocol using a linear SVM as classifier. We trained the proposed method on UC-Merced dataset and achieve an average overall accuracy of 94.05% under 80% training ratio. When trained on NWPU-RESISC45 dataset, the proposed method reached an average overall accuracy of 83.12% and 92.78% under the training ratios of 20% and 80% respectively, which achieves the state-of-the-art deep learning methods without pre-training.","2169-3536","","10.1109/ACCESS.2020.2981358","Fundamental Research Funds for the Central Universities(grant numbers:HUST-2018KFYYXJJ141); National Natural Science Foundation of China(grant numbers:61871438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9039665","Remote sensing scene classification;semi-supervised learning;generative adversarial networks;data augmentation","Training;Gallium nitride;Remote sensing;Feature extraction;Generative adversarial networks;Generators;Data models","geophysical image processing;image classification;learning (artificial intelligence);remote sensing;support vector machines","semisupervised representation learning;remote sensing image classification;generative adversarial network;remote sensing image scene classification;supervised learning methods;labeled training data;unsupervised learning methods;label information;classification performance;semisupervised learning;discriminative features;unlabeled data;mixup data augmentation method;classification model;training process;NWPU-RESISC45 dataset;cross-validation protocol;UC-Merced dataset;average overall accuracy;training ratios;deep learning methods","","23","","29","CCBY","17 Mar 2020","","","IEEE","IEEE Journals"
"Crop Classification from Multi-Temporal and Multi-spectral Remote Sensing Images","F. Kizilirmak; E. Aptoula","Bilgisayar Bilimi ve Mühendisliği, Sabancı Üniversitesi, İstanbul, Türkiye; Bilişim Teknolojileri Enstitüsü, Gebze Teknik Üniversitesi, Kocaeli, Türkiye","2021 29th Signal Processing and Communications Applications Conference (SIU)","19 Jul 2021","2021","","","1","4","The number of satellites, equipped with various sensors, aiming to observe agricultural activities have been progressively increasing. Satellite technology advances have enabled the acquisition of multispectral images of a region with small temporal intervals. Consequently, changes over a region can be observed, yield forecast can be made and the type of crops can be determined. In this work, it is aimed to classify 13 different crops by processing the multi temporal and multispectral data consisting of surface reflectance values. To this end, a siamese recurrent neural network structure, that processes time series information with deep metric learning approaches and providing easier classification, is proposed. A convolutional neural network that processes the multi temporal and multispectral information like an image is proposed to reduce the effect of class imbalance problem. These models are then combined under an ensemble neural network structure in order to leverage both networks' strengths. The proposed method outperforms other studies on the literature on BreizhCrops dataset.","2165-0608","978-1-6654-3649-6","10.1109/SIU53274.2021.9477900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9477900","Deep metric learning;Recurrent neural network;Convolutional neural network;Ensemble neural network","Agriculture;Satellites;Remote sensing;Recurrent neural networks;Measurement;Time series analysis;Surface treatment","agriculture;convolutional neural nets;crops;deep learning (artificial intelligence);image classification;learning (artificial intelligence);recurrent neural nets;remote sensing;spectral analysis;time series","ensemble neural network structure;crop classification;multitemporal remote sensing images;multispectral remote sensing images;agricultural activities;satellite technology;yield forecast;surface reflectance;time series information;convolutional neural network;Siamese recurrent neural network structure;deep metric learning","","1","","","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"Synergetic potentials of C-band SAR and multi-spectral imagery for tropical classifications in Northern Mato Grosso (BR)","R. Hagensieker; B. Waske","Institute of Geographical Scienes, Freie Universität Berlin; Institute of Geographical Scienes, Freie Universität Berlin","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","5486","5489","Using monthly as well as annual statistics, we investigate the potentials of synergetic utilization of multispectral and C-band SAR data for the classification of a study site in the central Brazilian state of Mato Grosso. We aim at the classification of five tropical land cover classes (primary forests, secondary vegetation, pasture, agricultural, water), and highlight the potentials of standalone S1 classification, as well as the synergetic potentials using two sensors. The overall size of the study site is about 300.000 km2, encompassing multiple tiles of S1 and LS-8. Results show S1 classification alone to yield accuracies of up to 88% (not accounting for secondary vegetation), and synergetic approaches to pass area adjusted overall accuracies of 95 %. While we were not able to sufficiently separate primary from secondary forests, forests overall as well as water yielded UA's and PA's just below 100 %.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8128246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128246","SAR;Multi-Spectral;Classification;Multi-temporal","Sensors;Remote sensing;Vegetation mapping;Artificial satellites;Earth;Training;Image resolution","forestry;geophysical image processing;image classification;land cover;remote sensing by radar;synthetic aperture radar;vegetation","northern Mato Grosso;central Brazilian state;multispectral data;forests;vegetation;multispectral imagery;tropical land cover classification;C-band SAR data","","","","7","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Cropnet: Deep Spatial-Temporal-Spectral Feature Learning Network for Crop Classification from Time-Series Multi-Spectral Images","C. Luo; S. Meng; X. Hu; X. Wang; Y. Zhong","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","4187","4190","The Deep Learning (DL) methods can automatically extract features without artificial prior, provides an effective solution for multi-temporal crop classification. Convolutional Neural Networks (CNNs) have superb spatial-spectral feature extraction capabilities, but often lack consideration of the temporal relationship of multi-temporal images, while Recurrent Neural Networks (RNNs) can better learn the sequential variation pattern. This paper designed a deep spatial-temporal-spectral feature learning network (CropNet) combining the advantages of a deep spatial-spectral feature learning module and a deep temporal-spectral feature learning module for better feature extraction in crop classification from time-series remote sensing images. From the results, the proposed method has better crop classification effects from time-series multispectral images in our experimental areas compared with some common traditional machine learning approaches and common DL methods.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324097","National Key Research and Development Program of China(grant numbers:2017YFB0504202); National Natural Science Foundation of China(grant numbers:41771385); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324097","Crop classification;deep learning;spatial-spectral feature;temporal-spectral feature","Agriculture;Feature extraction;Convolution;Remote sensing;Support vector machines;Deep learning;Radio frequency","","","","2","","6","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Collaborative Mapping Rice Planting Areas Using Multisource Remote Sensing Data","P. Zhai; S. Li; Z. He; Y. Deng; Y. Hu","School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; The Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou, China; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5969","5972","Recent satellite missions have provided a variety of high spatial resolution, multi-spectral, and high-frequency revisit remote sensing datasets. The collaborative use of optical and synthetic aperture radar (SAR) imagery in remote sensing applications attracts considerable attention. The purpose of this paper is to investigate the contribution of both data to the rice planting area mapping. In particular, the red-edge band was introduced to construct a red-edge vegetation index based on Sentinel-2 data. C-band quad-pol Radarsat-2 data was also used. We finally used the random forest algorithm, collaborating with optical and radar data to map rice planting area. We found that the red-edge band and red-edge vegetation index can improve the classification accuracy compared to the classifier using NIR (near-infrared) band and NDVI (Normalized Difference Vegetation Index). The result shows that the jointly use of optical and radar data is feasible to map rice planting area. The overall accuracy, recall and F-measure are 0.9441, 0.9598 and 0.9680, respectively.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553245","National Natural Science Foundation of China(grant numbers:2020YFG0033,41871247); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553245","red edge;SAR;rice mapping;random forest;Sentinel-2;Radarsat-2","Radar remote sensing;Laser radar;Spaceborne radar;Vegetation mapping;Optical imaging;Adaptive optics;Optical sensors","crops;geophysical image processing;image classification;radar imaging;radar polarimetry;remote sensing;remote sensing by radar;synthetic aperture radar;vegetation;vegetation mapping","Sentinel-2 data;c-band quad-pol Radarsat-2 data;optical radar data;map rice planting area;red-edge band;red-edge vegetation index;NIR band;Normalized Difference Vegetation Index;red edge;rice mapping;collaborative mapping rice planting areas;multisource remote sensing data;recent satellite missions;high spatial resolution;high-frequency revisit remote sensing datasets;remote sensing applications;rice planting area mapping","","1","","12","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Retrieval of AOD over land surface using directional multi-spectral polarized data and precision analysis","Q. Lan; X. Zhu","China center of Resources Satellite Data and Application, Beijing, China; China center of Resources Satellite Data and Application, Beijing, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","6078","6081","In this paper, we developed an algorithm to retrieve aerosols over land surfaces in China from directional multi-spectral polarized data of PARASOL (Polarization and Anisotropy of Reflectances for Atmospheric Science coupled with Observations from a LIDAR). On the assumption of spherical aerosol, after removing the polarized contribution of molecules and land surfaces from TOA (Top of Atmosphere) polarized reflectance of PARASOL, the aerosol scattered polarized radiance was obtained and interpolated into the LUT (Look Up Table), the AODs (Aerosol Optical Depth) are retrieved by best fitting method. The algorithm was validated with parasol Level 2 product. In addition, we analyzed some radiative and geometric parameters which influence the precision of the retrieval.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730588","aerosols;directional polarization;PARASOL;remote sensing;precision","Aerosols;Land surface;Optical polarization;Optical scattering;Atmospheric measurements;Optical reflection","aerosols;atmospheric optics;atmospheric radiation;atmospheric techniques;data analysis;remote sensing by laser beam","AOD retrieval;aerosol optical depth;land surface;directional multispectral polarized data analysis;directional multi-spectral polarized precision analysis;aerosol retrieval algorithm;China;directional multispectral polarized data;lidar observations;spherical aerosol assumption;molecule polarized contribution;TOA polarized reflectance;aerosol scattered polarized radiance;LUT;look up table;best fitting method;PARASOL level 2 product;radiative parameter;geometric parameter","","","","7","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Urban Impervious Surface Extraction Based on the Integration of Remote Sensing Images and Social Media Data","Y. YU; W. Wei; J. Li; Y. Zhang","Guangdong Provincial Key Laboratory of Urbanization and Geo-simulation, Sun Yat-sen University, Guangzhou, China; ShaanXi Provincial Key Laboratory of Speech and Image Information Processing, Northwestern Polytechnical University, Xi’ an, China; Guangdong Provincial Key Laboratory of Urbanization and Geo-simulation, Sun Yat-sen University, Guangzhou, China; ShaanXi Provincial Key Laboratory of Speech and Image Information Processing, Northwestern Polytechnical University, Xi’ an, China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","8861","8864","This paper presents an inspiring approach for accurate estimation of impervious surfaces, which exploits the strength of two kind of heterogeneous features, i.e., physical features derived from satellite images and social features derived from social media datasets, respectively. On the one hand, we use a morphological attribute profiles guided spectral mixture analysis model to achieve estimates of physical features. On the other hand, we mine the social features from textual information of social media datasets. Then, a multivariable linear regression model is conducted to obtain the impervious surfaces. Experiment results, conducted with multi-spectral images collected by LANDSAT-8 and social media datasets scraped from Sina Weibo of Guangzhou city, suggest that our approach could lead to reliable and good estimation of the imperviousness.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518740","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518740","Impervious surface;remote sensing;social media;TF-IDF","Remote sensing;Social network services;Feature extraction;Estimation;Urban areas;Surface morphology;Kernel","feature extraction;geophysical image processing;image classification;regression analysis;remote sensing;social networking (online)","LANDSAT-8;Sina Weibo;Guangzhou city;spectral mixture analysis model;social features;satellite images;heterogeneous features;impervious surfaces;social media data;remote sensing images;urban impervious surface extraction;imperviousness;social media datasets;multispectral images","","","","20","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Improving mosquito population predictions in the Greater Toronto Area using remote sensing imagery","S. DeMets; A. Ziemann; C. Manore; C. Russell","Intelligence and Space Research Division, Los Alamos National Laboratory, Los Alamos, NM, USA; Intelligence and Space Research Division, Los Alamos National Laboratory, Los Alamos, NM, USA; Analytics, Intelligence and Technology Division, Los Alamos National Laboratory, Los Alamos, NM, USA; Communicable Diseases and Emergency Preparedness and Response, Public Health Ontario, Toronto, Canada","2020 IEEE Southwest Symposium on Image Analysis and Interpretation (SSIAI)","18 May 2020","2020","","","78","81","West Nile Virus (WNV) and St. Louis Encephalitis (SLE) are two of the most common mosquito-borne diseases in North America. WNV and SLE have sporadic spatial and temporal outbreaks, making their outbreaks difficult to predict. However, recent studies have found that mosquito abundance is correlated with WNV and SLE transmission, providing researchers with a starting point for the development of mosquito-borne disease forecasting systems. Mosquito populations are controlled by a variety of environmental variables, including humidity, temperature, vegetation, and available water habitat for breeding. Current mosquito population forecasting models heavily weigh precipitation and temperature inputs, as they are traditionally seen as the best estimates of available breeding space in a region of interest. Although rainfall data are easy to acquire, precipitation data may not actually be the best estimates of mosquito habitat, as water does not flow evenly across landscapes. Furthermore, precipitation data generally come at a spatial resolution of 800 m to 2,500 m, and while this resolution can help predict mosquito abundances on large spatial scales, it inhibits the estimation of mosquito populations in urban areas with granular landscape heterogeneity. To overcome these limitations, this research explores the use of multispectral imagery for predicting mosquito populations, specifically in the Greater Toronto Area. Multispectral imagery is an attractive data source for predicting mosquito abundance due to its consistent collection and comparatively high spatial resolution (e.g., 30 m for Landsat). We derive a monthly time series of standard spectral indices from multispectral imagery over the Greater Toronto Area from 2004 to 2011. We then explore how spectral indices perform as a predictor for combined Cx. restuans and Cx. pipiens mosquito populations, with the ultimate aim of using multispectral imagery to forecast mosquito-borne diseases in highly urbanized areas.","2473-3598","978-1-7281-5745-0","10.1109/SSIAI49293.2020.9094591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9094591","Mosquito populations;remote sensing;multi-spectral;disease forecasting","Sociology;Statistics;Remote sensing;Vegetation mapping;Predictive models;Spatial resolution;Artificial satellites","diseases;geophysical image processing;microorganisms;rain;remote sensing;time series;vegetation","breeding space;precipitation data;mosquito habitat;mosquito abundance;multispectral imagery;Greater Toronto Area;comparatively high spatial resolution;pipiens mosquito populations;remote sensing imagery;WNV;SLE;sporadic spatial outbreaks;temporal outbreaks;mosquito-borne disease forecasting systems;water habitat;mosquito population forecasting models","","","","13","USGov","18 May 2020","","","IEEE","IEEE Conferences"
"Automatic Extraction of Built-Up Areas From Panchromatic and Multispectral Remote Sensing Images Using Double-Stream Deep Convolutional Neural Networks","Y. Tan; S. Xiong; Y. Li","National Key Laboratory of Science & Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science & Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; Department of Photogrammetry, School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","3 Dec 2018","2018","11","11","3988","4004","As the central area of human activities, built-up area has been one of the most important objects that are recognized from a remote sensing image. Built-up area in different regions has characteristics as follows: the structure and texture of the built-up area are complex and diverse; the buildings have multitudinous materials; the vegetation distribution and background around the built-up area are changeable. The existing built-up area detection methods still face the challenge to achieve favorable precision and generalization ability. In this paper, a double-stream convolutional neural network (DSCNN) model is proposed to extract the built-up area automatically, which can combine the complementary cues of high-resolution panchromatic and multispectral image. Some postprocessing steps are adopted to make the results more reasonable. We manually annotated a large-scale dataset for training and testing DSCNN. Experiments demonstrate that the proposed method has a higher overall accuracy as well as better generalization ability compared to the state-of-the-art techniques.","2151-1535","","10.1109/JSTARS.2018.2871046","National Natural Science Foundation of China(grant numbers:41371339,41601352); China Postdoctoral Science Foundation(grant numbers:2016M590716,2017T100581); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8477097","Built-up areas extraction;double-stream convolutional neural network (DSCNN);multispectral image;panchromatic image","Remote sensing;Indexes;Feature extraction;Vegetation mapping;Data mining;Buildings;Machine learning","feature extraction;feedforward neural nets;geophysical image processing;image classification;image resolution;image texture;learning (artificial intelligence);neural nets;object detection;remote sensing","DSCNN;double-stream convolutional neural network model;built-up area;remote sensing image;central area;double-stream deep convolutional neural networks;multispectral remote sensing images","","21","","47","IEEE","30 Sep 2018","","","IEEE","IEEE Journals"
"Multispectral image and fullcolor remote sensing image processing technology","J. Cai; J. -x. Ma; J. -x. Wang","School of Information Science & Engineering, Hebei University of Science and Technology, China; School of Computer Science &Technology, Hebei University, China; School of Information Science & Engineering, Hebei University of Science and Technology, China","2017 9th International Conference on Modelling, Identification and Control (ICMIC)","22 Mar 2018","2017","","","551","555","Putting GF1. into use is a significant achievement of high scores, which is of great significance to promote the localization of high resolution earth observation data and serve the national economy. In this paper, the author introduces the processing technology of remote sensing image which was sent back from high score number satellite. The remote sensing image is divided into multi - spectral and full - color remote sensing image. This paper describes these two kinds of graphs by orthophoto correction and image registration. With the spectral quality and spatial resolution of the image processing, and such data were compared to infer the occurrence of the real significance of the changes.","","978-1-5090-6575-2","10.1109/ICMIC.2017.8321705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8321705","Multispectral image;Panchromatic image;Remote Sensing Image","Remote sensing;Satellites;Spatial resolution;Image fusion;Earth","geophysical image processing;image registration;remote sensing","multispectral-color remote sensing image;full-color remote sensing image;image registration;orthophoto correction;high score number satellite;high resolution earth observation data;high scores;significant achievement;GF1;remote sensing image processing technology;multispectral image","","1","","10","IEEE","22 Mar 2018","","","IEEE","IEEE Conferences"
"Woodland Segmentation of Gaofen-6 Remote Sensing Images Based on Deep Learning","Y. Gui; W. Li; M. Zhang; A. Yue","Beijing Key Lab of Fractional Signals and Systems, Beijing, China; Beijing Key Lab of Fractional Signals and Systems, Beijing, China; Beijing Key Lab of Fractional Signals and Systems, Beijing, China; Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5409","5412","Gaofen-6 (GF-6) is a geostationary, earth-observation satellite, rely on it's multi-spectral images, GF-6 has the ability to support the monitoring of woodland resources. In this paper, the multi-spectral images sent by GF-6 are studied as dataset, and a model called Infrared Attention Network (InfAttNet) which based on semantic segmentation method is proposed to distinguish woodland from other land types to achieve the purpose of woodland extraction. To make full use of the spectral information, InfAttNet has an additional encoder to extract the features of infrared bands independently. Besides, infrared attention blocks help InfAttNet to enhance the characteristics of woodland. The experimental results proved that InfAttNet improves the accuracy of woodland extraction, and the segmentation effect is strengthened compared with classical networks.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554398","Beijing Natural Science Foundation(grant numbers:JQ20021); National Natural Science Foundation of China(grant numbers:61922013,61421001,U1833203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554398","Deep Learning;Woodland Segmentation;Remote Sensing Image;Infrared Spectrums;Attention Block","Deep learning;Image segmentation;Satellites;Semantics;Feature extraction;Sensors;Data mining","deep learning (artificial intelligence);feature extraction;geophysical image processing;image segmentation;remote sensing","woodland segmentation;deep learning;geostationary earth-observation satellite;multispectral images;woodland resources;GF-6;InfAttNet;semantic segmentation method;woodland extraction;spectral information;infrared attention blocks;Gaofen-6 remote sensing images;Infrared Attention Network","","1","","8","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Semantic Segmentation Algorithm of Remote Sensing Images Based on Improved Panoptic","T. Zheng; L. Liu; Q. Chen; Z. Chen; L. Yu; Z. Zhao","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China","2022 International Conference on Automation, Robotics and Computer Engineering (ICARCE)","22 Feb 2023","2022","","","1","5","Semantic segmentation of images can play an important role in land use, building extraction, road extraction and vehicle detection using remote sensing images. In the scenario of applying Panoptic FPN algorithm for remote sensing images, we found that the decoder of this algorithm is not robust in feature extraction and cannot do weighted enhancement of key spaces and channels, and its encoder loses a lot of high-dimensional semantic features when simply fusing semantic information at all levels by simple addition. To address these two problems, we propose the Se-Resnext encoder based on the attention mechanism and the Concat-based feature fusion mechanism, respectively, and verify the effectiveness of the methods through experiments. The accuracy of semantic segmentation is improved in both suichang dataset and posdam dataset.","","978-1-6654-7548-8","10.1109/ICARCE55724.2022.10046443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10046443","remote sensing image;semantic segmentatio;attention;feature fusion","Training;Fuses;Semantic segmentation;Vehicle detection;Roads;Semantics;Feature extraction","","","","","","11","IEEE","22 Feb 2023","","","IEEE","IEEE Conferences"
"Cauchy Graph Embedding Optimization for Built-Up Areas Detection From High-Resolution Remote Sensing Images","Y. Li; Y. Tan; J. Deng; Q. Wen; J. Tian","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; Key Laboratory of Disaster Reduction and Emergency Response Engineering, National Disaster Reduction Center of China, Ministry of Civil Affairs, Beijing, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","19 May 2017","2015","8","5","2078","2096","Automatic built-up areas detection from remote sensing images has attracted considerable research interest, due to its crucial roles in various applications. As far as built-up areas detection, the corner density map to predict the presence of the built-up areas has been widely adopted, but the calculation is generally time-consuming. In addition, the density map is just segmented by a statistical threshold, resulting in that the accurate boundaries of the built-up areas are unachievable. In order to address these issues, this paper proposes a novel built-up areas detection approach. Instead of pixel units, our approach takes the superpixel-based image partitions as the primary calculation units, which benefits to improve the computational efficiency and visual organization performance. Based on the superpixel-based units, this paper first proposes a sparse corner voting method for accelerating the production of corner density map. Then, Cauchy graph embedding optimization is presented to cope with the problem of segmenting the density map, which can preserve the well-defined boundaries of built-up areas. A diverse and representative test set including 2.1-m resolution ZY3 imagery, 2.0-m resolution GF1 imagery, 1.0-m resolution IKONOS imagery, and 0.61-m resolution QUICKBIRD imagery is collected. Experimental results on these test images show that our proposed approach is robust to sensor and resolution variation, and can outperform state-of-the-art approaches remarkably.","2151-1535","","10.1109/JSTARS.2015.2394504","National Natural Science Foundation of China(grant numbers:41371399,61273279); National Science and Technology Major Project of Earth Observation System; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7038172","Built-up areas detection;Cauchy graph optimization;sparse corner voting;superpixel-based image partition;Built-up areas detection;Cauchy graph optimization;sparse corner voting;superpixel-based image partition","Optimization;Remote sensing;Visualization;Image resolution;Image segmentation;Indexes;Feature extraction","geophysical image processing;image segmentation;optimisation;remote sensing","Cauchy graph embedding optimization;built-up areas detection;high-resolution remote sensing images;corner density map;statistical threshold;superpixel-based image partition;visual organization performance;superpixel-based unit;sparse corner voting method;image segmentation;ZY3 imagery;GF1 imagery;IKONOS imagery;QUICKBIRD imagery","","31","","42","IEEE","10 Feb 2015","","","IEEE","IEEE Journals"
"SETHI / RAMSES-NG: New performances of the flexible multi-spectral airborne remote sensing research platform","R. Baqué; O. Ruault du Plessis; N. Castet; P. Fromage; J. Martinot-Lagarde; J. -F. Nouvel; H. Oriot; S. Angelliaume; F. Brigui; H. Cantalloube; M. Chanteclerc; P. Dubois-Fernandez; X. Dupuis; P. Martineau","Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE","2017 European Radar Conference (EURAD)","8 Jan 2018","2017","","","191","194","SETHI is an airborne SAR/GMTI system developed by the French Aerospace Lab. ONERA, and integrating various sensors. In 2016 ONERA invested in upgrade and improvement of all SETHI components. The microwave ones cover from VHF-UHF to X Band, full polarimetric and very high resolution, along track and cross track interferometry and very high precision multi-baseline capacity for interferometry and tomography applications. The optronic sensors offer very high spatial resolution visible images and fine spectral scene analysis in VNIR and SWIR bands. This paper presents the upgrade and new performances of this flexible platform and the qualification campaign results with various sensor configurations.","","978-2-87487-049-1","10.23919/EURAD.2017.8249179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249179","Remote sensing;SAR;Very High Resolution;Moving target detection and tracking;Optronic","Image resolution;Radar antennas;Synthetic aperture radar;Optical sensors;Trajectory","airborne radar;artificial satellites;image sensors;radar interferometry;remote sensing by radar;synthetic aperture radar","airborne SAR-GMTI system;high-spatial resolution visible images;SETHI-RAMSES-NG;sensor configurations;fine spectral scene analysis;optronic sensors;tomography applications;high precision multibaseline capacity;cross track interferometry;very high resolution;polarimetric resolution;VHF-UHF;SETHI components;flexible multispectral airborne remote sensing research platform","","5","","4","","8 Jan 2018","","","IEEE","IEEE Conferences"
"SETHI and RAMSES-NG flexible multi-spectral airborne remote sensing research platforms","R. Baqué; O. R. du Plessis; P. Dreuillet; Y. -M. Frédéric","Electromagnetism and Radar Department, ONERA, France; Electromagnetism and Radar Department, ONERA, France; Electromagnetism and Radar Department, ONERA, France; Optronic Department, ONERA, France","2016 CIE International Conference on Radar (RADAR)","5 Oct 2017","2016","","","1","5","SEHI and RAMSES-NG are airborne SAR systems developed by the French Aerospace Lab. ONERA, and integrating various sensors. The microwave ones cover from VHF-UHF to X Band, full polarimetric and very high resolution, along track and cross track interferometry and very high precision multi-baseline capacity for interferometry and tomography applications. The optronic sensors offer very high spatial resolution visible images and fine spectral scene analysis in VNIR and SWIR bands. This paper presents the flexible capacity of these platforms and last campaign results with various sensor configurations.","","978-1-5090-4828-1","10.1109/RADAR.2016.8059303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8059303","Remote sensing;SAR;Very High Resolution;Moving target detection and tracking;Optronic","Synthetic aperture radar;Trajectory;Image resolution;Optical sensors;Optical receivers","airborne radar;geophysical equipment;geophysical techniques;image sensors;radar antennas;radar imaging;radar interferometry;radar polarimetry;remote sensing;synthetic aperture radar","French Aerospace Lab;polarimetric resolution;very high resolution;cross track interferometry;high precision multibaseline capacity;fine spectral scene analysis;flexible capacity;SWIR band;optronic sensor;high spatial resolution visible image;tomography application;VHF-UHF microwave;flexible multispectral airborne remote sensing research platform;airborne SAR system","","5","","5","IEEE","5 Oct 2017","","","IEEE","IEEE Conferences"
"SETHI/RAMSES-NG new performances of the flexible multi-spectral airborne remote sensing research platform","R. Baqué; O. Ruault du Plessis; N. Castet; P. Fromage; J. Martinot-Lagarde; J. -F. Nouvel; H. Oriot; S. Angelliaume; F. Brigui; H. Cantalloube; M. Chanteclerc; P. Dubois-Fernandez; X. Dupuis; P. Martineau","Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR","International Conference on Radar Systems (Radar 2017)","28 May 2018","2017","","","1","4","SETHI is an airborne SAR/GMTI system developed by the French Aerospace Lab. ONERA, and integrating various sensors. In 2016 ONERA invested in upgrade and improvement of all SETHI components. The microwave ones cover from VHF-UHF to X Band, full polarimetric and very high resolution, along track and cross track interferometry and very high precision multi-baseline capacity for interferometry and tomography applications. The optronic sensors offer very high spatial resolution visible images and fine spectral scene analysis in VNIR and SWIR bands. This paper presents the upgrade and new performances of this flexible platform and the qualification campaign results with various sensor configurations.","","978-1-78561-672-3","10.1049/cp.2017.0407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367492","Remote sensing;SAR;Very High Resolution;Moving target detection and tracking;Optronic","","airborne radar;geophysical equipment;geophysical techniques;image sensors;radar antennas;remote sensing;synthetic aperture radar","SETHI / RAMSES;flexible multispectral airborne remote sensing research platform;airborne SAR/GMTI system;French Aerospace Lab;2016 ONERA;SETHI components;microwave ones;VHF-UHF;polarimetric resolution;very high resolution;cross track interferometry;high precision multibaseline capacity;tomography applications;optronic sensors;high spatial resolution visible images;fine spectral scene analysis;flexible platform;sensor configurations","","1","","","","28 May 2018","","","IET","IET Conferences"
"Framework Design of Storage and Visualization System for Massive Unmanned Aerial Vehicle (UAV) Remote Sensing Data","D. Guo; G. Li; S. Wang","School of Mechanical, Electrical and Information Engineering, Shandong University, Weihai, Shandong, P. R. China; School of Mechanical, Electrical and Information Engineering, Shandong University, Weihai, Shandong, P. R. China; Shandong Provincial Key Laboratory of Computer Networks, National Supercomputer Center in Jinan, Jinan, Shandong, P. R. China","2018 7th International Conference on Agro-geoinformatics (Agro-geoinformatics)","30 Sep 2018","2018","","","1","5","With the wide application of Unmanned Aerial Vehicles (UAVs) in remote sensing, the magnitude of the images obtained by UAVs has increased dramatically. How to manage and utilize those massive images effectively is challenging work. In order to provide a basic platform for agricultural analysis, this study aims to develop a systematical framework for efficient storage and web-based interactive display of UAV remote sensing data. In the framework, we deal with the massive tile-data with high performance clusters based on distributed storage and then establish an effective cache mechanism. Meanwhile, Node.js is used to develop the system's backend, as its event-driven asynchronous IO model is beneficial to concurrence. Additionally, based on the rich-client technology, the application services such as dynamic combination of multi-spectral images are completed in the browser to relieve the pressure of the server. This framework is easy to migrate to the cloud platform, which shows advantages of high storage efficiency, short data query time, strong scalability, and high concurrency performance.","","978-1-5386-5038-7","10.1109/Agro-Geoinformatics.2018.8476092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476092","UAV;multi-spectral image;Tile Pyramid;distributed technology;high concurrency","Remote sensing;Servers;Unmanned aerial vehicles;Data visualization;Spatial databases;Throughput","autonomous aerial vehicles;cache storage;cloud computing;data visualisation;geophysical image processing;remote sensing;storage management","visualization system;massive Unmanned Aerial vehicle remote sensing data;web-based interactive display;UAV remote sensing data;massive tile-data;distributed storage;event-driven asynchronous IO model;multispectral images;short data query time;cache mechanism","","1","","21","IEEE","30 Sep 2018","","","IEEE","IEEE Conferences"
"RTC-GAN: REAL-TIME CLASSIFICATION OF SATELLITE IMAGERY USING DEEP GENERATIVE ADVERSARIAL NETWORKS WITH INFUSED SPECTRAL INFORMATION","R. Gandikota; R. K. K; A. Sharma; M. M; V. M. Bothale","National Remote Sensing Center (NRSC), Indian Space Research Organisation (ISRO), Hyderabad, India; National Remote Sensing Center (NRSC), Indian Space Research Organisation (ISRO), Hyderabad, India; National Remote Sensing Center (NRSC), Indian Space Research Organisation (ISRO), Hyderabad, India; National Remote Sensing Center (NRSC), Indian Space Research Organisation (ISRO), Hyderabad, India; National Remote Sensing Center (NRSC), Indian Space Research Organisation (ISRO), Hyderabad, India","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","6993","6996","This paper implements a deep learning-based Convolutional Neural Network (CNN) with adversarial training and infused pixel information to classify multi-spectral data into 4 LULC classes and cloud. The network is capable of classifying the image on a real-time basis at acquisition time in pixel level by considering the various spectral band values at the pixel and a spatial region around the pixel to collect the spatial features. This way, both spatial information, and spectral information are considered to classify the image. This novel GAN architecture named RTC-GAN is generalized over all the satellites that have their sensors in and around standard NIR, R and G spectral bands while being able to classify the images in realtime. This network is realized and tested on data obtained from satellites Landsat 8 Sentinel2 and Indian Remote Sensing (IRS) satellites like Cartosat-2S, Resourcesat-2/2A. The dataset is not open-sourced and hence very minimal information is provided regarding the IRS data.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323363","Generative Adversarial Networks;Real-Time Analysis;Satellite Imagery;Landsat8;Cartosat;LULC","Satellites;Feature extraction;Remote sensing;Generative adversarial networks;Gallium nitride;Training;Real-time systems","convolutional neural nets;geophysical image processing;image classification;learning (artificial intelligence);remote sensing","RTC-GAN;real-time classification;satellite imagery;deep generative adversarial networks;infused spectral information;deep learning-based Convolutional Neural Network;CNN;adversarial training;pixel information;multispectral data;cloud;real-time basis;acquisition time;pixel level;spectral band values;spatial region;spatial features;spatial information;novel GAN architecture;satellites Landsat 8 Sentinel2;open-sourced information;IRS data;standard NIR;Indian Remote Sensing satellites;Cartosat-2S;Resourcesat-2/2A","","1","","5","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Accurate Video-Rate Multi-Spectral Imaging Using IMEC Snapshot Sensors","K. Vunckx; W. Charle","imec vzw, Leuven, Belgium; imec vzw, Leuven, Belgium","2021 11th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","19 Jul 2021","2021","","","1","7","Imec's pixel-level integration of spectral filters enables video-rate multi-spectral imaging with very compact cameras which are well-suited for precision agriculture and remote sensing. Current data processing techniques were limited to the reconstruction of spectral reflectance or transmittance and required the subsequent measurement of a spectrally uniform reference target covering the full field-of-view. In this paper, we present a new data processing flow to reconstruct both spectrally and spatially accurate spectral irradiance and reflectance, transmittance or exitance images even when only a small patch of a reference target is visible in only one of the acquired frames or when only a spectrometer measurement of the illumination spectrum is available. The accuracy is illustrated on lab and outdoor measurements. The presented data processing flow facilitates the use of the imec snapshot cameras for nearly any application, from disease detection in an orchard over coastal water quality inspection to accurate object tracking in spectral videos.","2158-6276","978-1-6654-3601-4","10.1109/WHISPERS52202.2021.9483975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9483975","video-rate;multi-spectral;snapshot;imaging;camera","Reflectivity;Image sensors;Sea measurements;Water quality;Data processing;Cameras;Sensors","agriculture;cameras;image colour analysis;image resolution;image sensors;inspection;object tracking;optical filters;remote sensing;video signal processing;water quality","accurate video-rate multispectral imaging;IMEC snapshot sensors;spectral filters;current data processing techniques;spectral reflectance;spectrally uniform reference target;transmittance;presented data processing flow;imec snapshot cameras;spectral videos","","2","","10","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"Incorporating Texture into SLIC Super-pixels Method for High Spatial Resolution Remote Sensing Image Segmentation","L. Lu; C. Wang; X. Yin","school of earth sciences, Zhejiang University, Hangzhou, China; school of earth sciences, Zhejiang University, Hangzhou, China; school of earth sciences, Zhejiang University, Hangzhou, China","2019 8th International Conference on Agro-Geoinformatics (Agro-Geoinformatics)","2 Sep 2019","2019","","","1","5","Super-pixel methods cluster spatially connected similar pixels into perceptually meaningful regions, which are generally used as basic units instead of the original pixels in pre-processing and segmentation of high spatial resolution images for the object-oriented image classification. Among a number of super-pixel methods, the simple linear iterative clustering (SLIC) has been widely applied due to its simplicity, efficiency, and ability to adhere to image boundaries. SLIC itself, however, was originally designed to group black-white or three-color common images rather than multi-spectral/ hyperspectral remote sensing ones into super-pixels. In order to better apply SLIC to segmenting remote sensing images at high spatial resolution, the SLIC algorithm was modified by incorporating grey-level co-occurrence matrix texture with color features and expanding measure approach for weighted distance of texture and color similarity and spatial proximity between super-pixel center and neighboring pixels. Gaofen-2 panchromatic, multispectral and fused images were used to valid the modified SLIC (MSLIC) algorithm. Both completeness (CPS) and correctness (CRS) were used to quantitatively evaluate both MSLIC and SLIC algorithms. Visually interpreting approach was also applied to compare the segmentation and classification maps from the two algorithms. The experimental results indicate MSLIC achieves higher CPS and CRS than SLIC.","","978-1-7281-2116-1","10.1109/Agro-Geoinformatics.2019.8820692","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820692","Super-pixel;Simple linear iterative clustering (SLIC);Segmentation;Object-oriented classification (OOC);Remote sensing image;High spatial resolution","Image segmentation;Image color analysis;Spatial resolution;Remote sensing;Feature extraction;Mathematical model;Classification algorithms","feature extraction;geophysical image processing;geophysical techniques;image classification;image colour analysis;image resolution;image segmentation;image texture;remote sensing","color similarity;spatial proximity;super-pixel center;neighboring pixels;classification maps;incorporating texture;SLIC super-pixels method;super-pixel methods;original pixels;high spatial resolution images;object-oriented image classification;simple linear iterative clustering;image boundaries;three-color common images;remote sensing images;co-occurrence matrix texture;color features;hyperspectral remote sensing;remote sensing image segmentation;modified SLIC algorithm","","5","","21","IEEE","2 Sep 2019","","","IEEE","IEEE Conferences"
"Remote sensing and GIS based watershed prioritization","M. Pandey; P. K. Sharma","Department of Civil Engineering, Indian Institute of Technology, Roorkee, India; Department of Civil Engineering, Indian Institute of Technology, Roorkee, India","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","6182","6185","Identification of runoff generation areas and erosion prone zones of a watershed are important for the efficient and effective implementation of the greatest management practices for preserving the natural resources. In the present study, an effort is completed to recognize the critical erosion-prone zones of the study area by using the spatially distributed parameters liable for hazards of erosion. Remote sensing and GIS techniques were used for generating parameters with soil erodibility factor, slope factor of stream power index, Universal Soil Loss Equation, topographic wetness index for water conservation, curve number value and sediment transport index. By using supervised classification technique with a maximum likelihood technique was applied to three multi spectral bands to create the land use/land cover map and classified into six land use land cover classes. The soil-erodibility factor map was made by using soil map and K-factor values and thus divided from low priority to high.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8128420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128420","GIS;Remote sensing;stream power index;wetness index;Watershed prioritization and sediment transport index","Indexes;Soil;Sediments;Software;Remote sensing;Water resources;Standards","erosion;geographic information systems;hydrological techniques;hydrology;remote sensing;sediments;soil;water conservation","natural resources;critical erosion-prone zones;soil erodibility factor;slope factor;stream power index;Universal Soil Loss Equation;topographic wetness index;water conservation;curve number value;sediment transport index;supervised classification technique;maximum likelihood technique;multispectral bands;land use/land cover map;land use land cover classes;soil-erodibility factor map;soil map;K-factor values;watershed prioritization;runoff generation areas;erosion prone zones;efficient implementation;effective implementation;management practices","","3","","10","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Inter-Sensor Remote Sensing Image Enhancement for Operational Sentinel-2 and Sentinel-3 Data Products","R. Fernandez; R. Fernandez-Beltran; F. Pla","Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1504","1507","The recent availability of operational data from the Sentinel-2 and Sentinel-3 missions provides widespread opportunities to generate diverse high-level remote sensing products. However, the synergies between both multi-spectral instruments are often difficult to exploit from an operational perspective. Standard pansharpening algorithms may encounter important disadvantages due to the limited intersensor data availability in actual production environments. Moreover, the lack of a real high-resolution ground-truth for super-resolution techniques may affect the radiometric quality of the final result. In this scenario, this work investigates the viability of using the Multi-Spectral Instrument of Sentinel-2 for super-resolving data products acquired by the Ocean and Land Colour Instrument of Sentinel-3. Specifically, we define an inter-sensor image enhancement framework which combines a PCA-based component substitution pansharpening scheme with a CNN-based spatial enhancing super-resolution mapping. The conducted experiments reveal the suitability of the proposed approach for generating Level-4 data products within the Copernicus programme context.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324071","Sentinel-2 (S2);Sentinel-3 (S3);super-resolution (SR);pansharpening;image fusion","Spatial resolution;Pansharpening;Principal component analysis;Instruments;Remote sensing;Image enhancement;Superresolution","geophysical image processing;image enhancement;image fusion;image resolution;remote sensing;terrain mapping","inter-sensor remote sensing image enhancement;operational Sentinel-2;Sentinel-3 data products;recent availability;operational data;Sentinel-3 missions;diverse high-level remote sensing products;multispectral instruments;operational perspective;standard pansharpening algorithms;intersensor data availability;actual production environments;high-resolution ground-truth;super-resolution techniques;MultiSpectral Instrument;inter-sensor image enhancement framework;super-resolution mapping;Level-4 data products","","","","10","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Perormance evaluation of radiative transfer models of satellite atmospheric microwave sounding for data assimilation","G. Li; K. Chen; A. J. Gasiewski; K. Zhang; Q. Li; L. Zhang; Y. He; A. Cao","Science and Technology on Multi-spectral Information Processing Laboratory, Huazhong University of Science and Technology; Science and Technology on Multi-spectral Information Processing Laboratory, Huazhong University of Science and Technology; Department of Electrical, Computer, and Energy Engineering, University of Colorado; Department of Electrical, Computer, and Energy Engineering, University of Colorado; Science and Technology on Multi-spectral Information Processing Laboratory, Huazhong University of Science and Technology; Science and Technology on Multi-spectral Information Processing Laboratory, Huazhong University of Science and Technology; Science and Technology on Multi-spectral Information Processing Laboratory, Huazhong University of Science and Technology; Shanghai Institute of Satellite Engineering","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","2189","2192","To assimilate satellite-based passive microwave observation over heavy clouds and precipitation into numerical weather prediction (NWP) systems and thus to improve the performance of it has become an intensely studied topic. These attempts rely on the development of a radiative transfer (RT) model that accounts for particle scattering and accurately simulates the observation process at an acceptable computational speed. In this paper, two existing RT models (the RTTOV and the DOTLRT) are tested and the accuracies are evaluated by comparing the simulated brightness temperature with real observational data of a satellite-based sounder ATMS. RTTOV is much more well-known and widely applied, however, since these two models use different solvers to deal with the scattering effect, whether it is possible to improve the performance of RT model is still open to discussion.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729565","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729565","Data assimilation;microwave remote sensing;radiative transfer model;atmospheric sounding","Atmospheric modeling;Brightness temperature;Data models;Computational modeling;Satellites;Microwave theory and techniques;Storms","atmospheric precipitation;clouds;data assimilation;radiative transfer;remote sensing;weather forecasting","radiative transfer model;satellite atmospheric microwave sounding;data assimilation;satellite-based passive microwave observation;cloud;atmospheric precipitation;numerical weather prediction;NWP system;particle scattering;RTTOV model;DOTLRT model;satellite-based sounder ATMS","","","","4","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Cotton Leaf Area Index Estimation Using Unmanned Aerial Vehicle Multi-Spectral Images","P. Chen","State Key Laboratory of Resources and Environment Information System, Chinese Academy of Sciences, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","6251","6254","The objective of this study is to estimating cotton leaf area index (LAI) using multi-spectral images acquired by Unmanned Aerial Vehicle (UAV). For this purpose, cotton nitrogen and irrigation experiment was conducted with four N treatments and four irrigation treatments in the suburbs of Shihezi city, Xinjiang province. A five bands multi-spectral senor was carried on a four rotors UAV and used to acquire images. Meantime, field campaigns were conducted to measure LAI in each plot. Based on above data, commonly used spectral indices were selected and used to design LAI estimation model. During this process, three quarters of samples were used to make model, and the reminders were used to validation. The results showed images acquired by UAV can be used to monitor cotton LAI. Among the spectral indices, Ratio Vegetation Index (RVI) is the best index for LAI estimation, with R2 value of 0.70 and RMSE value of 0.59 during calibration, and R2 value of 0.65 and RMSE value of 0.62 during validation.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898946","Unmanned Aerial Vehicle (UAV);leaf area index;cotton;multi-spectral image","Cotton;Indexes;Unmanned aerial vehicles;Irrigation;Estimation;Vegetation mapping;Remote sensing","autonomous aerial vehicles;cotton;crops;geophysical image processing;hyperspectral imaging;irrigation;vegetation;vegetation mapping","LAI estimation model;Ratio Vegetation Index;cotton leaf area Index estimation;Unmanned Aerial Vehicle multispectral images;cotton nitrogen;irrigation experiment;irrigation treatments;bands multispectral senor;image acquisition;cotton LAI monitoring;UAV multispectral images","","","","22","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Semi-supervised Method with Spatial Weights based Possibilistic Fuzzy c-Means Clustering for Land-cover Classification","D. -S. Mai; L. T. Ngo","Institute of Techniques for Special Engineering Le Quy Don Technical University, Hanoi, Vietnam; Institute of Simulation Technology Le Quy Don Technical University, Hanoi, Vietnam","2018 5th NAFOSTED Conference on Information and Computer Science (NICS)","10 Jan 2019","2018","","","406","411","In remote sensing image analysis, the accuracy of the results depends not only on the accuracy of the image acquisition process but also on the segmentation and classification accuracy of the image. The fuzzy classification technique works by dividing the pixels of the image into sets of fuzzy clusters by iteratively optimizing the objective function to update the cluster membership and center centroid. This technique overcomes the disadvantages of hard clustering; However, this method is quite sensitive to interference and extraneous elements. In this paper, we propose a novel semi-supervised clustering method with spatial weights (SPFCM-W) for multi-spectral remote sensing image land-cover classification by the extension of the possibilistic fuzzy c-means (PFCM) algorithm, in which spatial weights of the pixels and labeled data are used to increase the accuracy of clustering results when the data structure of input patterns is non-spherical and complex. Results obtained on two kinds of multi-spectral remote sensing images (Landsat-7 ETM+, Sentinel-2A) by comparing the proposed technique with some variations of the fuzzy clustering algorithm demonstrate the good efficiency and high accuracy of the proposed method.","","978-1-5386-7983-8","10.1109/NICS.2018.8606801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8606801","semi-supervised;spatial weights;multi-spectral;remote sensing image","Clustering algorithms;Remote sensing;Linear programming;Indexes;Partitioning algorithms;Approximation algorithms;Phase change materials","fuzzy set theory;geophysical image processing;geophysical signal processing;image classification;image segmentation;iterative methods;learning (artificial intelligence);pattern classification;pattern clustering;remote sensing;terrain mapping","novel semisupervised clustering method;extraneous elements;interference;hard clustering;center centroid;cluster membership;fuzzy clusters;fuzzy classification technique works;classification accuracy;segmentation;image acquisition process;remote sensing image analysis;semisupervised method;fuzzy clustering algorithm;multispectral remote sensing images;multispectral remote sensing image land-cover classification;spatial weights;current 2.0 A;W","","3","","25","IEEE","10 Jan 2019","","","IEEE","IEEE Conferences"
"Analysis and Correction of the Phase and Amplitude Errors for Mirrored Aperture Synthesis","H. Dou; H. Li; Z. He; Y. Wu; R. Lv; Y. Li; G. Song; Q. Li; K. Chen; L. Gui; Z. Lei","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; China Academy of Space Technology, Xi’an, China; China Academy of Space Technology, Xi’an, China; China Academy of Space Technology, Xi’an, China; China Academy of Space Technology, Xi’an, China; China Academy of Space Technology, Xi’an, China; China Academy of Space Technology, Xi’an, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","30 Dec 2021","2022","19","","1","5","Mirrored aperture synthesis (MAS) has been proposed as a novel interferometry to achieve higher spatial resolution in passive microwave remote sensing. The phase and amplitude errors for MAS are a crucial problem that has yet to be analyzed. In this letter, a model for the phase and amplitude errors is established. A correction method based on an external source is proposed to correct the phase and amplitude errors. An analysis of the position of the external source is performed by computing its impact on the radiometric accuracy of a reference scene. The imaginary parts of the cross correlations for MAS are analyzed for the first time. Simulations and experiments are carried out to demonstrate the effectiveness of the correction method.","1558-0571","","10.1109/LGRS.2021.3084698","Qian Xuesen Youth Innovation Fund; National Natural Science Foundation of China (NSFC)(grant numbers:NSFC 61771213); Opening Foundation of Science and Technology on Electronic Information Control Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9453774","Correction;mirrored aperture synthesis (MAS);phase and amplitude errors","Brightness temperature;Correlation;Image reconstruction;Antenna arrays;Apertures;Receiving antennas;Rails","image resolution;light interferometry;radiometry;remote sensing","amplitude errors;mirrored aperture synthesis;MAS;higher spatial resolution;passive microwave remote sensing;correction method;external source","","3","","8","IEEE","14 Jun 2021","","","IEEE","IEEE Journals"
"Large Scale Crop Classification from Multi-temporal and Multi-spectral Satellite Images","İ. Yılmaz; M. İmamoğlu; G. Özbulak; F. Kahraman; E. Aptoula","BİLGEM, TÜBİTAK, Kocaeli, Türkiye; BİLGEM, TÜBİTAK, Kocaeli, Türkiye; BİLGEM, TÜBİTAK, Kocaeli, Türkiye; BİLGEM, TÜBİTAK, Kocaeli, Türkiye; Bilişim Teknolojileri Enstitüsü, Gebze Teknik Üniversitesi, Kocaeli, Türkiye","2020 28th Signal Processing and Communications Applications Conference (SIU)","7 Jan 2021","2020","","","1","4","Crop classification is one of the foremost and most challenging applications of remote sensing. Crops exhibit both high intra-class variance across geographical locations, as well as low inter-class variance especially across seasons. As such, they require both spectral and temporal input, both of which are provided by the Sentinel 2 satellites. In this paper, we present the preliminary results of our multispectral and multitemporal crop classification analysis, on a region-wide scale, encompassing multiple climatological conditions and a high number of crop types. We have experimented using the ground-truth provided by the Farmer Registration System, with both well-known spectral and spatial shallow features and classifiers, at both pixel and field level, as well as with state of the art 3D convolutional neural networks. Our results show that Sentinel 2 imagery exhibit a strong potential as input for a systematic crop classification infrastructure.","2165-0608","978-1-7281-7206-4","10.1109/SIU49456.2020.9302176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302176","crop classification;remote sensing;deep learning;random forest","Agriculture;Remote sensing;Deep learning;Satellites;Nanoelectromechanical systems;Earth;Vegetation mapping","climatology;crops;geophysical image processing;image classification;neural nets;remote sensing","Sentinel 2 satellites;multispectral crop classification analysis;multitemporal crop classification analysis;region-wide scale;multiple climatological conditions;Farmer Registration System;spatial shallow features;Sentinel 2 imagery;systematic crop classification infrastructure;scale crop classification;multispectral satellite images;remote sensing;crops;high intra-class variance;geographical locations;low inter-class variance;spectral input;temporal input","","1","","","IEEE","7 Jan 2021","","","IEEE","IEEE Conferences"
"Initial Results of Microwave Radiometric Imaging With Mirrored Aperture Synthesis","H. Dou; L. Gui; Q. Li; L. Chen; X. Bi; Y. Wu; Z. Lei; Y. Li; K. Chen; L. Lang; W. Guo","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Shenzhen Institute, Huazhong University of Science and Technology, Shenzhen, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Information Engineering, Nanchang University, Nanchang, China; School of Optical and Electronic Information, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","25 Sep 2019","2019","57","10","8105","8117","The concept, principle, and method of microwave radiometric imaging with mirrored aperture synthesis (MAS) were proposed by the Huazhong University of Science and Technology (HUST), Wuhan, China. MAS can achieve higher spatial resolution without extending the size of the antenna array. However, the MAS principle has not been sufficiently validated by practical experiments. To solve this problem, an innovative experiment system of MAS at the V-band (MAS-V) has been developed by HUST. Experiments on the interference fringe pattern, spatial resolution, as well as the imaging of an electric warmer and the absorbing material in the styrofoam box filled with liquid nitrogen are performed. The initial experimental results demonstrate that MAS can achieve higher spatial resolution with the same antenna array compared with the conventional AS. For MAS, the experimental results are consistent with theory and simulation results.","1558-0644","","10.1109/TGRS.2019.2918308","Fundamental Research Funds for the Central Universities(grant numbers:2016JCTD203); National Basic Research Program of China (973 Program)(grant numbers:2016YFC1401005); National Natural Science Foundation of China(grant numbers:41176156,41505015,61771213); Shanghai Aerospace Science and Technology Innovation Fund(grant numbers:SAST2015032,SAST2016087,SAST2017113); Innovation Foundation of Shenzhen Government(grant numbers:JCYJ20160531194547792); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736031","Mirrored aperture synthesis (MAS);passive microwave remote sensing;spatial resolution","Antenna arrays;Spatial resolution;Microwave radiometry;Apertures;Brightness temperature;Interference","image resolution;interference;microwave absorption;microwave antenna arrays;microwave imaging;microwave materials;mirrors;radiometry","microwave radiometric imaging;mirrored aperture synthesis;HUST;antenna array;Huazhong University of Science and Technolog;MAS-V principle;Wuhan;China;MAS at the V-band principle;interference fringe pattern;electric warmer imaging;absorbing material;styrofoam box","","24","","16","IEEE","12 Jun 2019","","","IEEE","IEEE Journals"
"Multi-Spectral Image Classification with Quantum Neural Network","P. Gawron; S. Lewiński","AstroCeNT Nicolaus Copernicus Astronomical Center, Polish Academy of Sciences, Warsaw, Poland; Space Research Center, Polish Academy of Sciences, Warsaw, Poland","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","3513","3516","Processing Earth observation images to obtain land cover classification is an important task allowing to track changes on the Earth's surface resulting from natural processes, human activity, and climate change. The amount of data acquired from Earth observation satellites is very large and their processing takes large amount of computational resources. We investigate application of quantum circuit based neural network classifiers for multi-spectral data classification aimed at obtaining the land cover information. We show a proof-of-concept of our approach.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323065","ERDF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323065","land cover classification;multi-spectral imagery;quantum machine learning","Climate change;Qubit;Earth;Spatial resolution;Satellite broadcasting;Neural networks;Quantum circuit;Machine learning;Multispectral imaging","geophysical image processing;geophysical signal processing;geophysics computing;image classification;land cover;neural nets;pattern classification;remote sensing;terrain mapping","human activity;climate change;Earth observation satellites;quantum circuit;neural network classifiers;multispectral data classification;land cover information;multispectral image classification;quantum neural network;Processing Earth observation images;land cover classification;Earth's surface;natural processes","","8","","6","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Investigating Multi-Spectral Lidar Radiometry: An Overview of the Experimental Framework","M. Okhrimenko; C. Coburn; C. Hopkinson","Department of Geography, University of Lethbridge, Lethbridge, Alberta, Canada; Department of Geography, University of Lethbridge, Lethbridge, Alberta, Canada; Department of Geography, University of Lethbridge, Lethbridge, Alberta, Canada","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","8745","8748","In this paper, we present a framework of experiments carried out during summer 2016 with Teledyne Optech Titan sensor to investigate multi-spectral (ms) lidar radiometry. A novel low-cost diffuse reflectance coating was adopted for creating radiometric targets. Comparability of reflectance values derived from ms lidar data to available spectral libraries is shown. The consistency of spectral vegetation indices (SVIs) through a variety of altitudes was investigated, and it is demonstrated that by filtering only single echoes it is possible to derive stable SVIs product. A practical approach to experimental atmospheric correction with non-constant extinction coefficient is discussed. Finally, a criterion is proposed for comparing different lidar acquisitions over vegetated areas.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517922","multi-spectral lidar;radiometric normalization;atmospheric correction;NDVI;forest","Laser radar;Reflectivity;Radiometry;Coatings;Vegetation mapping;Backscatter;Extinction coefficients","optical radar;radiometry;remote sensing by laser beam;vegetation mapping","multispectral lidar radiometry;experimental framework;Teledyne Optech Titan sensor;novel low-cost diffuse reflectance coating;radiometric targets;reflectance values;ms lidar data;available spectral libraries;spectral vegetation indices;stable SVIs product;experimental atmospheric correction;different lidar acquisitions;AD 2016;vegetated areas","","","","11","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Semi-Automated Technique for Vegetation Analysis in Sentinel-2 Multi-Spectral remote sensing images using Python","S. Barma; S. Damarla; S. K. Tiwari",NA; NA; APSAC,"2020 4th International Conference on Electronics, Communication and Aerospace Technology (ICECA)","28 Dec 2020","2020","","","946","953","Satellite imagery provides a lot of information that can be analysed for a variety of objectives. The vegetation analysis in a region for a particular period of time to process a large amount of data is remaining as a bottleneck and involves a series of timeconsuming steps that delay the output. To overcome this challenge, this study aims to automate the process and estimate the area of sparse and dense vegetation of a certain area of interest and to assess the vegetation dynamics in this region by using the Sentinel-2 data. Python with its opensource libraries are utilized for downloading and processing the satellite data. Mandal (sub-district) level Mean NDVI, area under sparse and dense vegetation are estimated at the peak vegetative growth stage in Rabi season (February) from 2017 to 2020. In the assessment of satellite data, it was observed that the Godavari delta region has shown a decrease in the sparse vegetative area (11094 ha.) and an increase in dense vegetation area (3272 ha.) in 2018 as compared with 2019 assessment. However, in the Krishna delta region, it was observed that the sparse vegetation area was decreased (90600 ha) and an increased dense area (161915 ha.) in 2020 as compared with 2017. The process involves downloading Sentinel-2 data using SentinelHub and SentinelSat API, pre-processing and segmenting NDVI images to classify vegetation areas and the calculation of Mandal (sub-district) level statistics.","","978-1-7281-6387-1","10.1109/ICECA49313.2020.9297369","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9297369","NDVI;K-means clustering;Python process automation;multi-spectral remote sensing image processing;multi-temporal vegetation analysis;sentinel-2","Vegetation mapping;Remote sensing;Python;Libraries;Satellites;Image segmentation;Tools","geophysical image processing;image segmentation;remote sensing;vegetation;vegetation mapping","vegetation analysis;Sentinel-2 multispectral remote sensing images;python;satellite imagery;vegetation dynamics;satellite data;Mandal level Mean NDVI;peak vegetative growth stage;Godavari delta region;sparse vegetative area;dense vegetation area;Krishna delta region;sparse vegetation area;downloading Sentinel-2 data;vegetation areas;time 2018.0 as;time 2020.0 as","","","","22","IEEE","28 Dec 2020","","","IEEE","IEEE Conferences"
"High-Frequency Jitter Detection by Registration Error Curve of High-Resolution Multi-Spectral Satellite Image","K. Hu; Y. Zhang; W. Liu","Processing and Application System, Key Laboratory of Technology in Geo-Spatial Information, Beijing, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Department of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China","2018 26th International Conference on Geoinformatics","6 Dec 2018","2018","","","1","6","With improvement of spatial resolution of the satellite optical sensors, the influence of high-frequency attitude jitter of the satellite platform on image geometric and radiometric quality has become more and more seriously. It will obviously decrease the image absolute positioning accuracy, the charge coupled device (CCD) geometric splicing accuracy and the image clarity. Based on the design features of time-division multi-spectral sensor of the Chinese Mapping Satellite-I, a high-frequency jitter detection method by dense matching and image registration error curve is proposed in this paper. The technique processing of jitter detection, the modeling and solution method of registration error curve and construction method of high-frequency jitter model are illustrated in details. Experiments and result analysis of dense matching, image registration and jitter curve extraction are conducted on the multi-spectral image of Chinese Mapping Satellite-I to validate the correctness of the proposed approach.","2161-0258","978-1-5386-7619-6","10.1109/GEOINFORMATICS.2018.8557172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8557172","high-frequency jitter detection;multi-spectral image;dense matching;registration error curve;jitter model construction","","CCD image sensors;geophysical image processing;image registration;image resolution;image sensors;jitter;optical sensors;remote sensing","high-frequency jitter model;solution method;image registration error curve;dense matching;high-frequency jitter detection method;time-division multispectral sensor;image clarity;device geometric splicing accuracy;image absolute positioning accuracy;radiometric quality;satellite platform;high-frequency attitude jitter;satellite optical sensors;spatial resolution;high-resolution multispectral satellite image;Chinese Mapping Satellite-I;multispectral image;jitter curve extraction","","2","","15","IEEE","6 Dec 2018","","","IEEE","IEEE Conferences"
"The Landsat soil composite mapping processor (SCMAP): AN OPUS product","D. Rogge; J. Zeidler; A. Bauer; A. Müller; T. Esch; U. Heiden","German Remote Sensing Data Center (DFD), Germany; German Remote Sensing Data Center (DFD), Germany; German Remote Sensing Data Center (DFD), Germany; German Remote Sensing Data Center (DFD), Germany; German Remote Sensing Data Center (DFD), Germany; German Remote Sensing Data Center (DFD), Germany","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","4497","4500","The primary objective of the SCMaP is to supply value added information about soils at three levels: 1) the spatial distribution of exposed soils; 2) temporal statistics of those soils; and, 3) a reflectance soil composite map. The SCMaP is designed for temperate climatic regions that comprise areas of extensive crop based agriculture where soils are commonly covered by vegetation. For the SCMaP satellite based multi-temporal optical imagery is used to generate per-pixel composite images that reflect maximum and minimum photosynthetically active vegetativion. Applying pre-determined thresholds to the maximum and minimum composites an exposed soil mask generated that can be used to build a reflectance soil composite image. The SCMaP has been designed towards free and open access high spatial muti-spectral Landsat and Sentinel 2 data, with results shown here for archived Landsat (4,5,7) imagery from 2010-2014 for all of Germany.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8128000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128000","Soil mapping;multi-spectral imagery;pixel-based composites;processing chains","Soil;Remote sensing;Artificial satellites;Earth;Reflectivity;Vegetation mapping;Agriculture","crops;geophysical image processing;image classification;soil;statistical analysis;terrain mapping;vegetation mapping","multitemporal optical imagery;per-pixel composite images;minimum composites an exposed soil mask;reflectance soil composite image;Landsat soil composite mapping processor;OPUS product;value added information;spatial distribution;reflectance soil composite map;temperate climatic regions;SCMaP satellite","","","","4","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"A Practical Method for Surface Water High-Precision and Fast Extraction Nationwide Based on High-Resolution Satellite Images","L. Du; X. Mu; Z. Luo; Z. Wang; K. Liu; Y. He; S. You; Y. Gan","Land Satellite Remote Sensing Application Center, MNR, Beijing; Land Satellite Remote Sensing Application Center, MNR, Beijing; Land Satellite Remote Sensing Application Center, MNR, Beijing; Land Satellite Remote Sensing Application Center, MNR, Beijing; Land Satellite Remote Sensing Application Center, MNR, Beijing; Land Satellite Remote Sensing Application Center, MNR, Beijing; Land Satellite Remote Sensing Application Center, MNR, Beijing; Land Satellite Remote Sensing Application Center, MNR, Beijing","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","6320","6323","Surface water is an irreplaceable strategic resource for human survival and social development. It is of great significance to fully grasp the quantity, spatial distribution and dynamic changes of surface water in China accurately, quickly and timely. With the rapid development of Chinese remote sensing satellite industry, monitoring surface water in whole China quarterly has become a task of challenge but achievable. This paper analyzes and compares the advantages and disadvantages of existing algorithms for surface water extraction. And a practical and useful algorithm workflow is proposed. Based on 2-meter resolution multi-spectral satellite images, the paper adopts the regional fast-growing water extraction algorithm combined with water element buffers. 1,265 above level 3 rivers, their associated 2,128 reservoirs and 2,953 above-1-km2 natural lakes in China have been fast extracted quarterly with high-precision. Practice has shown that the automatic extraction algorithm is one of the most effective algorithms for realizing the automatic monitoring of large-scale surface water.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884890","High-resolution;Satellite Image;Surface Water;Automatic Extraction","Industries;Satellites;Image resolution;Heuristic algorithms;Lakes;Reservoirs;Rivers","environmental monitoring (geophysics);feature extraction;hydrological techniques;image resolution;lakes;remote sensing;rivers","surface water high-precision;extraction nationwide;high-resolution satellite images;irreplaceable strategic resource;Chinese remote sensing satellite industry;surface water extraction;practical algorithm workflow;useful algorithm workflow;2-meter resolution multispectral satellite images;water extraction algorithm;water element buffers;953 above-1-km2 natural lakes;automatic extraction algorithm;large-scale surface water","","","","11","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Effective Classification of Local Climate Zones Based on Multi-Source Remote Sensing Data","H. Jing; Y. Feng; W. Zhang; Y. Zhang; S. Wang; K. Fu; K. Chen","Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Department of Electrical and Computer Engineering, Northeastern University; Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Institute of Electronics, Chinese Academy of Sciences, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2666","2669","The local climate zone (LCZ) classification divides the urban areas into 17 categories, which are composed of 10 manmade structures and 7 natural landscapes. Though originally designed for temperature study, LCZ classification can be used for studies on economy and population. In this paper, we achieve a LCZ classification with convolutional neural networks based on the multi-source remote sensing data, including the polarimetric synthetic aperture radar (PolSAR) data and the corresponding multi-spectral imagery (MSI). Through experiments we attempt to reveal the contributions of the SAR data and the MSI to the classification performance. Furthermore, we emphasize the crucial importance of the preprocessing on the training data to derive a balanced dataset. We are ranked second in the Tianchi competition rankings when we submit our results.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898475","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898475","Multi-modality;local climate zone (LCZ) classification;convolutional neural networks;SAR;multispectral imagery","Meteorology;Training;Urban areas;Synthetic aperture radar;Remote sensing;Convolutional neural networks;Feature extraction","atmospheric techniques;climatology;image classification;radar imaging;radar polarimetry;remote sensing by radar;synthetic aperture radar","classification performance;SAR data;MSI;multispectral imagery;polarimetric synthetic aperture radar data;multisource remote sensing data;convolutional neural networks;economy;LCZ classification;temperature study;natural landscapes;manmade structures;urban areas;local climate zone classification;training data","","6","","10","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Monitoring Threatened Irish Habitats Using Multi-Temporal Multi-Spectral Aerial Imagery and Convolutional Neural Networks","S. Perez-Carabaza; O. Boydell; J. O'Connell","Ireland's Centre for Applied AI University College, Dublin, Ireland; Ireland's Centre for Applied AI University College, Dublin, Ireland; ProvEye, Dublin, Ireland","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2556","2559","The monitoring of threatened habitats is a key objective of European environmental policy. Due to the high cost of current field-based habitat mapping techniques there is a strong research interest in proposing solutions that reduce the cost of habitat monitoring through increasing their level of automation. Our work is motivated by the opportunities that recent advances in machine learning and Unmanned Aerial Vehicles (UAVs) offer to the habitat monitoring problem. In this paper, a deep learning based solution is proposed to classify four priority Irish habitats types present in the Maharees (Ireland) using UAV aerial imagery. The proposed method employs Convolutional Neural Networks (CNNs) to classify multi-temporal multi-spectral images of the study area corresponding to three different dates in 2020, obtaining an overall classification accuracy of 93%. A comparison of the proposed method with a multi-spectral 2D-CNN model demonstrates the advantage of including temporal information enabled by the proposed multi-temporal multi-spectral CNN model.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553472","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553472","Habitat mapping;Convolutional neural networks;Multi-temporal imagery;Aerial imagery","Deep learning;Costs;Automation;Geoscience and remote sensing;Europe;Unmanned aerial vehicles;Convolutional neural networks","autonomous aerial vehicles;deep learning (artificial intelligence);environmental monitoring (geophysics);geophysical image processing;image classification;remote sensing;remotely operated vehicles;social sciences computing","monitoring threatened Irish habitats;threatened habitats;European environmental policy;current field-based;strong research interest;machine learning;unmanned aerial vehicles;habitat monitoring problem;deep learning based solution;UAV aerial imagery;convolutional neural networks;temporal information;multitemporal multispectral CNN model;Irish habitats types;multitemporal multispectral images","","","","8","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"The inversion of the non-Gaussian slope probability density function of the ocean waves by KuROS radar measurements","L. Wang; D. Hauser; P. Chen","Science and Technology on Multi-spectral Information Processing Laboratory; LATMOS-IPSL, CNRS, Guyancourt, France; Science and Technology on Multi-spectral Information Processing Laboratory","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","4661","4664","It is known that the slope probability density function (pdf) of the sea surface is non-Gaussian and can be expressed as a Gram-Charlier to fouth-order expension, including seven parameters: slope variances in upwind and crosswind direction, two skewness coefficients and three peakedness coefficients. Cox and Munk[1] had gotten all the seven parameters varying with the wind speed using optical data. However, those parameters for the sea surface at optical band and microwave band are different, and until now it is not clear for microwave band what values the seven parameters are. Wave scatterometer is a kind of microwave sensor specially designed for wave spectrum remote sensing and could provide σ0 in high resolution of the range and azimuthal direction so that it is possible to remote sense the slope pdf for a certain space-time. In this paper, firstly, the accuracy of Geometric Optical (GO) model is evaluated, which is used for confirming the valid range of incidence angle to invert; then, a two dimensional (2D) inversion method is developed for remote sensing all the seven parameters in non-Gaussian slope pdf by the wave scatterometer based on GO model; finally those parameters are inverted by the method using the Ku-band airborne wave scatterometer KuROS measurements.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730216","slope probability density of sea surface;ocean wave;wave scatterometer;non-Gaussian;GO","Wind speed;Radar measurements;Spaceborne radar;Sea surface;Two dimensional displays;Remote sensing;Sea measurements","inverse problems;ocean waves;probability;remote sensing by radar;wind","nonGaussian slope probability density function;ocean wave;KuROS radar measurement;sea surface;Gram-Charlier model;upwind direction;crosswind direction;skewness coefficient;peakedness coefficient;wind speed;optical data;optical band;microwave band;wave scatterometer;microwave sensor;wave spectrum remote sensing;geometric optical model;2D inversion method","","","","8","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Fusion detection of ship targets in low resolution multi-spectral images","Y. Liu; L. Yao; W. Xiong; Z. Zhou","School of Electronic Science and Engineering, National University of Defense Technology, Hunan, China; Research Institute of Information Fusion, Naval Aeronautical Engineering Institute, Yantai, Shandong, China; Research Institute of Information Fusion, Naval Aeronautical Engineering Institute, Yantai, Shandong, China; School of Electronic Science and Engineering, National University of Defense Technology, Hunan, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","6545","6548","Aiming at ship detection in multi-spectral images at low resolution, this paper proposes a new method for ship detection based on fusion detection which combines spectral feature with thermal feature. Firstly, it selects infrared band instead of visible band image to detect cloud according to size feature. With cloud available, it does segmentation work in thermal infrared image for the removal of cloud pixels. Then, the result is mapped to the IR images and cloud masking is completed. Next, the fusion of two kinds of images using wavelet transform is adopted. At last, the fused image is used to detect ships and morphological operations are used to discriminate ships. The experiment result on multi-spectral data of Landsat 8 shows that the proposed method which is robust against clutter can detect ships effectively.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730710","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730710","Ship detection;Landsat 8;Image fusion;Wavelet Transform","Marine vehicles;Clouds;Satellites;Remote sensing;Image resolution;Earth;Clutter","image fusion;image segmentation;object detection;remote sensing;ships;wavelet transforms","ship target fusion detection;multispectral images;ship detection;spectral feature;thermal feature;visible band image;cloud detection;image segmentation;thermal infrared images;cloud pixel removal;cloud masking;image fusion;wavelet transform;Landsat 8 spectral data","","9","","8","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Field of View of Mirrored Aperture Synthesis Radiometers","Y. Li; Q. Li; L. Gui; L. Feng; H. Dou; Y. Wu; Z. Lei","Science and Technology on Multi-Spectral Information Processing Laboratory School of Electronic Information and Communications Huazhong, University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory School of Electronic Information and Communications Huazhong, University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory School of Electronic Information and Communications Huazhong, University of Science and Technology (HUST), Wuhan, China; Collaborative Innovation Center of Industrial Bigdata, Hubei University of Technology; Science and Technology on Multi-Spectral Information Processing Laboratory School of Electronic Information and Communications Huazhong, University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory School of Electronic Information and Communications Huazhong, University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory School of Electronic Information and Communications Huazhong, University of Science and Technology (HUST), Wuhan, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","8905","8908","Aperture synthesis technique is able to provide high spatial resolution without requiring very large and massive real aperture. Recently, in addition to the well-known aperture synthesis radiometer, the concept of mirrored aperture synthesis has been proposed, and the experiments has been carried out to validate this technique. However, the field of view (FOV) of a mirrored aperture synthesis radiometer (MASR) has not been analyzed. In this paper, the FOV of an one-dimensional MASR is analyzed based on the symmetric convolution. A simulation and experiment are carried out to validate the derived FOV. The FOV of a two-dimensional MASR can be analyzed in the same way.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898593","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898593","Mirrored aperture synthesis radiometer;field of view;array factor;symmetric convolution","Apertures;Convolution;Antenna arrays;Image reconstruction;Radiometers;Remote sensing;Spatial resolution","convolution;radiometers","mirrored aperture synthesis radiometer;spatial resolution;massive real aperture;FOV;field of view;1D MASR;symmetric convolution;2D MASR","","1","","7","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Array configuration optimization for Rotating mirrored aperture synthesis (RMAS)","Y. Li; Q. Li; R. Jin; F. Li; H. Dou; H. Liu","Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","853","856","Aperture synthesis with high spatial resolution would seriously increase the hardware requirements and system complexity. To reduce the system complexity, Rotating mirrored aperture synthesis (RMAS) that combines the antenna array rotation with mirrored aperture synthesis was proposed to reduce the number of antennas. In this paper, the sieving method is presented to optimize the array configuration for RMAS. The initial simulation results demonstrate the validity of the proposed method and the optimized array of RMAS can reconstruct the brightness temperature of the observed scene with fewer antennas.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729216","Rotating mirrored aperture synthesis (RMAS);uniform spatial frequency sampling;sieving method;array configuration optimization","Antenna arrays;Apertures;Image reconstruction;Brightness temperature;Remote sensing;Microwave radiometry","antenna arrays;radiometry","array configuration optimization;rotating mirrored aperture synthesis;RMAS;high spatial resolution;antenna array rotation;sieving method","","1","","16","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Practice and Experience in Using Parallel and Scalable Machine Learning in Remote Sensing from HPC Over Cloud to Quantum Computing","M. Riedel; G. Cavallaro; J. A. Benediktsson","Jülich Supercomputing Centre, Forschungszentrum, Jülich, Germany; Jülich Supercomputing Centre, Forschungszentrum, Jülich, Germany; School of Engineering and Natural Sciences, University of Iceland, Iceland","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","1571","1574","Using computationally efficient techniques for transforming the massive amount of Remote Sensing (RS) data into scientific understanding is critical for Earth science. The utilization of efficient techniques through innovative computing systems in RS applications has become more widespread in recent years. The continuously increased use of Deep Learning (DL) as a specific type of Machine Learning (ML) for data-intensive problems (i.e., ‘big data’) requires powerful computing resources with equally increasing performance. This paper reviews recent advances in High-Performance Computing (HPC), Cloud Computing (CC), and Quantum Computing (QC) applied to RS problems. It thus represents a snapshot of the state-of-the-art in ML in the context of the most recent developments in those computing areas, including our lessons learned over the last years. Our paper also includes some recent challenges and good experiences by using Europeans fastest supercomputer for hyper-spectral and multi-spectral image analysis with state-of-the-art data analysis tools. It offers a thoughtful perspective of the potential and emerging challenges of applying innovative computing paradigms to RS problems.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554656","Center of Excellence (CoE) Research on AI- and Simulation-Based Engineering at Exascale (RAISE); EU's Horizon 2020 Research and Innovation Framework Programme H2020-INFRAEDI-2019-1(grant numbers:951733); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554656","High performance computing;cloud computing;quantum computing;machine learning;deep learning;parallel and distributed algorithms;remote sensing","Training;Cloud computing;Quantum computing;Transfer learning;Tools;Supercomputers;Real-time systems","Big Data;cloud computing;data analysis;learning (artificial intelligence);mainframes;parallel machines;parallel processing;remote sensing","scalable Machine Learning;HPC;Quantum Computing;computationally efficient techniques;Remote Sensing data;scientific understanding;Earth science;innovative computing systems;RS applications;ML;data-intensive problems;big data;powerful computing resources;equally increasing performance;paper reviews recent advances;High-Performance Computing;Cloud Computing;RS problems;computing areas;recent challenges;good experiences;state-of-the-art data analysis tools;innovative computing paradigms","","4","","17","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A Semisupervised GAN-Based Multiple Change Detection Framework in Multi-Spectral Images","F. Jiang; M. Gong; T. Zhan; X. Fan","School of Electronic Engineering, Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi’an, China; School of Electronic Engineering, Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi’an, China; School of Electronic Engineering, Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi’an, China; School of Electronic Engineering, Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","23 Jun 2020","2020","17","7","1223","1227","Effectively highlighting multiple changes in the earth surface from multi-temporal remote sensing images is a meaningful but challenging task. In order to reduce costs and ensure the performance, it is advisable to employ a semisupervised strategy to achieve this goal. As a discriminative joint classification task, semisupervised change detection aims to extract useful and discriminative features from a large amount of unlabeled data in addition to limited labeled samples. The discriminator of a well-trained generative adversarial network (GAN) is just right for this. Therefore, in this letter, we proposed a semisupervised GAN-based multiple change detection framework for multi-spectral images. First, the GAN is trained by all data without any prior information. Then, we combine two identical trained discriminators to construct a dual-pipeline joint classifier. Finally, the classifier is fine-tuned by a very small amount of labeled data to detect multiple changes. The superior performance of the proposed model over both real multi-spectral data sets demonstrates its robustness and effectiveness.","1558-0571","","10.1109/LGRS.2019.2941318","National Natural Science Foundation of China(grant numbers:61772393); Key Research and Development Program of Shaanxi Province(grant numbers:2018ZDXM-GY-045); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854295","Generative adversarial network (GAN);multi-spectral images;multiple change detection;semisupervised","Feature extraction;Gallium nitride;Task analysis;Training;Remote sensing;Data mining;Generative adversarial networks","feature extraction;geophysical image processing;image classification;neural nets;object detection;remote sensing","multispectral images;multitemporal remote sensing images;discriminative joint classification task;semisupervised change detection;discriminative features;identical trained discriminators;multispectral data sets;semisupervised GAN-based multiple change detection","","14","","19","IEEE","1 Oct 2019","","","IEEE","IEEE Journals"
"Multi-element quantitative extraction of mining area of laterite nickel mine combined deep learning with object-oriented method","X. Zhang; L. Chen; W. Li; Y. Li","Key Laboratory of Airborne Geophysics and Remote Sensing Geology, Ministry of Natural Resources, Beijing, China; China Aero Geophysical Survey and Remote Sensing Center for Natural Resources, Beijing, China; Key Laboratory of Airborne Geophysics and Remote Sensing Geology, Ministry of Natural Resources, Beijing, China; China Aero Geophysical Survey and Remote Sensing Center for Natural Resources, Beijing, China","2022 3rd International Conference on Geology, Mapping and Remote Sensing (ICGMRS)","18 Aug 2022","2022","","","24","28","Remote sensing technology has great advantages in timely and rapid monitoring of open-pit mining conditions. Based on Worldview-2 multi-spectral satellite remote sensing images, we took a typical lateritic nickel deposit in Indonesia as an example, and 9 types elements which are mining area, dump, collection sump, tailings pond, buildings, roads, smelter, vegetation and bare soil in mining active areas were extracted. Firstly, a deep learning method based on TensorFlow framework was used to extract the main roads and mining areas from the pre-processed images to obtain vector data. Secondly, according to the vector data, our study area can be divided into two areas, center and outskirts, by FNEA coarse segmentation, and the local variance change rates of the two areas are calculated, so as to select appropriate segmentation scales for each factor type and establish a bottom-up multi-scale segmentation hierarchy. Thirdly, the spectral difference index (SDI) and PCA-based GLCM texture features were proposed to expand the feature base. The FSO algorithm and SEaTH algorithm were combined to select the optimal features and separation thresholds. At last, the multi-element extraction of laterite nickel ore area was completed hierarchically. The overall accuracy reached 90.12%. Our results indicated that the proposed method takes into account the spatial differences of various elements, ensuring the accuracy of segmentation and element extraction. Furthermore, method of selecting scales and thresholds avoids multiple experiments and reduces the time and labor cost of trial and error, which ensures objectivity and improves the selection efficiency. In addition, the PCA-based texture features can shorten the feature calculation time from 6.25 min to 14 s, reducing the operation time of the algorithm and greatly saving the operation time while ensuring the correlation effectively.","","978-1-6654-8595-1","10.1109/ICGMRS55602.2022.9849354","Ministry of Natural Resources; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849354","laterite type nickel ore;multi-feature extraction;Worldview-2;OBIA;local variance;SEaTH","Deep learning;Image segmentation;Quantization (signal);Costs;Roads;Feature extraction;Nickel","deep learning (artificial intelligence);feature extraction;geophysical image processing;image segmentation;image texture;minerals;mining;nickel;object-oriented methods;principal component analysis;remote sensing;soil;vegetation","multielement quantitative extraction;mining area;laterite nickel mine;object-oriented method;open-pit mining;lateritic nickel deposit;vegetation;bare soil;deep learning;vector data;FNEA coarse segmentation;local variance change rates;multiscale segmentation hierarchy;feature base;optimal features;separation thresholds;laterite nickel ore area;element extraction;feature calculation time;Worldview-2 multispectral satellite remote sensing images;Indonesia;collection sump;tailing pond;TensorFlow;image pre-processing;spectral difference index;SDI;PCA-based GLCM texture features;FSO;SEaTH","","","","20","IEEE","18 Aug 2022","","","IEEE","IEEE Conferences"
"Spectral Analysis Based Green Tide Identification in High-suspended Sediment Wasters in South Yellow Sea of China","X. Wang; X. -X. Wang; X. Su; J. -C. Fan; L. Wang; Q. -H. Meng","Depart. of Marine Remote Sensing, National Mar. Environ. Monitor. Cent., Dalian, China; Depart. of Marine Remote Sensing, National Mar. Environ. Monitor. Cent., Dalian, China; Depart. of Marine Remote Sensing, National Mar. Environ. Monitor. Cent., Dalian, China; Depart. of Marine Remote Sensing, National Mar. Environ. Monitor. Cent., Dalian, China; Depart. of Marine Remote Sensing, National Mar. Environ. Monitor. Cent., Dalian, China; Depart. of Marine Remote Sensing, National Mar. Environ. Monitor. Cent., Dalian, China","2019 Tenth International Conference on Intelligent Control and Information Processing (ICICIP)","27 Feb 2020","2019","","","70","75","Spectral features of the green tide of inshore high-suspended sediment waters in the South Yellow Sea of China were analyzed. A Multi-spectral identification coupling filtering algorithm (MIF) for green tide recognition is proposed. The method is applied to three typical areas based on GF-l satellite WFV data and compared with the identification outcomes of VB-FAI, MGTI, IGAG and SABI. Result showed that performance of the MIF and IGAG methods are significantly better than the others in both high-noise and clear seawaters; In high-suspended sediment waters, the MIF method can effectively improve the identification accuracy of green tide about 8%. Meanwhile, the MIF method has a stronger noise suppression capability.","","978-1-7281-0015-9","10.1109/ICICIP47338.2019.9012193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9012193","Multi-spectrum;High-suspended sediment waters;Green tide;Remote sensing;South Yellow Sea","Tides;Green products;Sediments;Reflectivity;Remote sensing;Algae;Monitoring","geophysical image processing;oceanographic regions;oceanographic techniques;remote sensing;seawater;sediments;spectral analysis;tides","high-suspended sediment wasters;spectral analysis;MIF method;IGAG methods;GF-l satellite WFV data;green tide recognition;Multispectral identification coupling;South Yellow Sea;high-suspended sediment waters","","","","16","IEEE","27 Feb 2020","","","IEEE","IEEE Conferences"
"Forest cover change detection method using bi-temporal GF-1 multi-spectral data","R. Hao; E. Chen; Z. Li","College of Geomatics, Xi'an University of Science and Technology; Institute of Forest Resources Information Technique, Chinese Academy of Forestry; Institute of Forest Resources Information Technique, Chinese Academy of Forestry","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","3762","3765","Forest cover will be changed by natural disaster, deforest and other activities. Remote sensing has the ability to monitor the change of forest cover in large area. However, in order to obtain the change information of forest cover, the method for getting the change information from remote sensing images is needed. China has launched GF-1 satellite in 2013, the 16m spatial resolution multi-spectral data of it should be suitable for forest cover detection applications. In this paper, I describe a set of procedures that automate forest cover change detection using a pair of GF-1 images. The proposed method was tailored to work with high spatial resolution images acquired over forest in large area. To achieve a high level of automation, automatic optimum threshold selection algorithm were applied in the processing steps. In this study, an overall change recognition accuracy of 83% has been achieved.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729975","GF-1;change detection;forest cover;kernel minimum noise fraction (MNF)","Remote sensing;Satellites;Change detection algorithms;Kernel;Radiometry;Feature extraction;Signal to noise ratio","vegetation mapping","forest cover change detection method;bi-temporal GF-1 multispectral data;natural disaster;remote sensing images;automatic optimum threshold selection algorithm","","1","","6","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Retrieval of High Resolution Aerosol Optical Depth by Synergetic Use of GF-1 WFV and Aqua Modis Data Over Land","R. Bai; Y. Xue; X. Jiang; C. Jin; N. Li; X. Zhang","Institute of Energy and Environmental Big Remote Sensing Data, School of Environmental Science and Spatial Informatics, China University of Mining and Technology, Xuzhou, Jiangsu, China; Institute of artificial intelligence, School of Environmental Science and Spatial Informatics, China University of Mining and Technology, Xuzhou, Jiangsu, China; Institute of Energy and Environmental Big Remote Sensing Data, School of Environmental Science and Spatial Informatics, China University of Mining and Technology, Xuzhou, Jiangsu, China; Institute of Energy and Environmental Big Remote Sensing Data, School of Environmental Science and Spatial Informatics, China University of Mining and Technology, Xuzhou, Jiangsu, China; Institute of Energy and Environmental Big Remote Sensing Data, School of Environmental Science and Spatial Informatics, China University of Mining and Technology, Xuzhou, Jiangsu, China; Institute of Energy and Environmental Big Remote Sensing Data, School of Environmental Science and Spatial Informatics, China University of Mining and Technology, Xuzhou, Jiangsu, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","6248","6251","Aerosol optical depth (AOD) is an important factor to estimate the effect of aerosol on light, and an accurate retrieval of it can make great contribution to monitor atmosphere. Therefore, retrieval of AOD has been a frontier topic and attracted much attention from researchers at home and abroad. In 2013, China launched Gaofen-1 satellite, improving the scale and timeliness of remote sensing data acquisition and making up for the shortcomings of lacking multi-spectral satellite with medium and high spatial resolution. In this paper, we calculated AOD at 100m from Gaofen-1 and AQUA data based on the Synergetic Retrieval of Aerosol Properties (SRAP) algorithm over Beijing, China. The experimental results are compared with the Aerosol Robotic Network (AERONET) for preliminary validation. The correlation coefficient is about 0.9 and a root-mean-square error (RMSE) of about 0.13. The experimental results show that the method have higher accuracy, and further validation work is continuing.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554320","aerosol optical depth (AOD);GaoFen-1;MODIS;SRAP","Correlation coefficient;Satellites;Data acquisition;Aerosols;Adaptive optics;Optical sensors;Spatial resolution","aerosols;atmospheric optics;atmospheric techniques;data acquisition;geophysical image processing;remote sensing","Aerosol Robotic Network;high resolution Aerosol optical depth;Synergetic use;GF-1 WFV;aqua modis data over land;AOD;accurate retrieval;great contribution;frontier topic;Gaofen-1 satellite;remote sensing data acquisition;lacking multispectral satellite;high spatial resolution;AQUA data;Synergetic Retrieval;Aerosol Properties algorithm;size 100.0 m","","","","11","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Sidelobe Level Analysis for Mirrored Aperture Synthesis","Z. Lei; Q. Li; G. Zhao","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","2021 46th International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz)","20 Oct 2021","2021","","","1","2","Mirrored aperture synthesis (MAS) is a new method for passive microwave remote sensing after aperture synthesis (AS). In this paper, the relationship among the array factor (AF) for the two-dimensional (2-D) MAS, one-dimensional (1-D) MAS, and 1-D AS is established. Based on the relationship, the sidelobe level (SLL) of MAS is analyzed. The SLL of MAS is spatially variant compared to that of AS. Despite this, a set of directions can still be selected, in which the maximum SLLs of MAS are almost equal to those of AS. This is verified by the simulations and experiments based on a system working at 51.6GHz.","2162-2035","978-1-7281-9424-0","10.1109/IRMMW-THz50926.2021.9567230","China Aerospace Science and Technology Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9567230","","Passive microwave remote sensing;Two dimensional displays;Apertures","remote sensing","MAS;sidelobe level analysis;mirrored aperture synthesis;passive microwave remote sensing;array factor;frequency 51.6 GHz","","","","5","IEEE","20 Oct 2021","","","IEEE","IEEE Conferences"
"Classification of an 8-Band Multi-Spectral Dataset Using DCNNs with Weight Initializations Derived from Pre-Trained RGB Networks","T. M. Bajkowski; J. A. Hurt; C. H. Davis; G. J. Scott","Dept. of Electrical Engineering & Computer Science, University of Missouri, Columbia, MO, USA; Dept. of Electrical Engineering & Computer Science, University of Missouri, Columbia, MO, USA; Dept. of Electrical Engineering & Computer Science, University of Missouri, Columbia, MO, USA; Dept. of Electrical Engineering & Computer Science, University of Missouri, Columbia, MO, USA","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","187","190","Modern satellite sensors can capture reflected optical energy from wavelengths well outside of the range of human perception. Indeed, it is well known that electromagnetic energy from the “non-visible” spectrum can be used to identify materials in geological, oceanographic, and agricultural contexts. What is less understood, however, is if and how this additional spectral information can be leveraged to aid in difficult computer vision tasks, e.g., classification or detection of man-made objects. Thus, we present the results from a series of experiments that evaluate the benefits that Deep Convolutional Neural Networks (DCNN) can garner through the inclusion of more spectral information. For training and testing these networks in image classification, we extract image tiles from the xView multi-spectral dataset. These images contain eight channels of spectral data including five wavelengths bands beyond the three bands traditionally used in computer vision researcher (red, green, and blue). In this work, we report the results of experiments that use an 80–20 train-test split with four DCNN architectures on full 8-band Multispectral Imagery (MSI) and various subsets of this eight banded imagery. The results show that networks trained on MSI have an average testing F1-score around 1.0 point higher than RGB networks trained with the same methods.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884492","Convolutional neural networks;image classification;Multispectral Imagery;remote sensing","Training;Computer vision;Satellites;Optical imaging;Optical sensors;Convolutional neural networks;Optical reflection","agriculture;computer vision;feature extraction;geophysical image processing;image classification;image colour analysis;learning (artificial intelligence);neural nets;remote sensing","8-band multispectral dataset;dcnns;weight initializations;pre-trained rgb networks;modern satellite sensors;optical energy;human perception;electromagnetic energy;nonvisible spectrum;geological contexts;oceanographic, contexts;agricultural contexts;additional spectral information;man-made objects;Deep Convolutional Neural Networks;image classification;image tiles;xView multispectral dataset;spectral data;wavelengths bands;computer vision researcher;80-20 train-test split;8-band Multispectral Imagery;banded imagery;average testing F1-score","","","","17","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"A Multiclass Deep Learning Approach for LULC Classification of Multispectral Satellite Images","D. Sathyanarayanan; D. Anudeep; C. A. Keshav Das; S. Bhanadarkar; U. D; R. Hebbar; K. G. Raj","Department of Computer Science, PES University, Bengaluru, Karnataka, India; Department of Computer Science, PES University, Bengaluru, Karnataka, India; Department of Computer Science, PES University, Bengaluru, Karnataka, India; Department of Computer Science, PES University, Bengaluru, Karnataka, India; Department of Computer Science, PES University, Bengaluru, Karnataka, India; RRSC-South National Remote Sensing Centre, ISRO, Bengaluru, Karnataka, India; RRSC-South National Remote Sensing Centre, ISRO, Bengaluru, Karnataka, India","2020 IEEE India Geoscience and Remote Sensing Symposium (InGARSS)","23 Feb 2021","2020","","","102","105","In general, a visual interpretation technique is adopted for mapping of Land Use / Land Cover (LULC) using temporal satellite data. Although highly accurate, the process is tedious, time consuming and requires a significant amount of domain knowledge. This limitation introduces a scope for partial automation to reduce manual effort involved in interpretation, while maintaining baseline accuracy. The research explores a novel multi-class training approach using a Deep Learning (DL) model to generate major LULC classes. Five spectral bands, namely Blue, Green, Red, Near-Infrared (NIR) and Short wave Infrared (SWIR) from the Sentinel-2A satellite, covering Mandya, Karnataka, India was used to train the model. An existing LULC map of the region was used as an input for automatically generating labeled training samples and a modified SegNet was implemented for classification. Four major LULC classes of interest - water bodies, forest lands, croplands, built-up were classified with an average F1 score of 0.84. The trained model applied to other regions has shown encouraging results which makes this an effective method to explore the generation of LULC maps.","","978-1-7281-3114-6","10.1109/InGARSS48198.2020.9358947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9358947","Sentinel 2A;Satellite Imagery;Multi-spectral Images;Remote Sensing;Land Use Land Cover (LULC);Deep Learning (DL);Segmentation;Classification;SegNet","Training;Deep learning;Visualization;Satellites;Automation;Forestry;Sensors","geophysical image processing;geophysical signal processing;image classification;land cover;land use;learning (artificial intelligence);pattern classification;remote sensing;terrain mapping","Sentinel-2A;spectral bands;novel multiclass training approach;baseline accuracy;manual effort;partial automation;domain knowledge;temporal satellite data;visual interpretation technique;multispectral satellite images;LULC classification;multiclass Deep Learning approach;LULC maps;trained model;forest lands;LULC classes;labeled training samples;existing LULC map","","2","","10","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"Semi-Supervised Multi-Spectral Land Cover Classification With Multi-Attention and Adaptive Kernel","K. Zhang; H. Yang","Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai, China; Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai, China","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","1881","1885","Land cover classification is one vital and challenging task in remote sensing (RS) field. Tackling the limited labeled training data and for exploiting abundant information of multispectral bands, we proposed a novel semi-supervised multispectral classification network with multi-attention and adaptive kernel. We select 10 land cover related bands and combine them into different spectral groups. To further extract discriminating feature in spectral and spatial dimension, we design one multi-attention block. Furthermore, the adaptive receptive field mechanism is introduced to dynamically adjust kernel size in convolution layer and aggregate multi-scale information. Experiments on EuroSAT dataset demonstrate that the proposed method can outperform greatly state-of-the-art methods, especially when the number of labeled data is relatively small.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190850","Multi-Spectral;Land Cover Classification;Semi-Supervised;Adaptive Kernel;Multi-Attention","Feature extraction;Kernel;Remote sensing;Training;Generators;Convolution;Agriculture","feature extraction;geophysical image processing;image classification;terrain mapping","semisupervised multispectral classification network;land cover related bands;aggregate multiscale information;adaptive receptive field mechanism;multiattention block;remote sensing field;adaptive kernel;semisupervised multispectral land cover classification","","4","","20","IEEE","30 Sep 2020","","","IEEE","IEEE Conferences"
"Quantitative and non-destructive evaluation of ground beef based on multi-spectral imaging","O. Gutierrez-Navarro; D. U. Campos-Delgado; R. A. C. Peñuelas; C. U. H. Segura","Department of Biomedical Engineering, Centro de Ciencias de la Ingenieria, Universidad Autónoma de Aguascalientes, Aguascalientes, Mexico; Faculty of Sciences, Universidad Autonoma de San Luis Potosi, San Luis Potosi, Mexico; Department of Food Science, Centro de Ciencias de Agropecuarias, Universidad Autónoma de Aguascalientes, Aguascalientes, Mexico; Department of Veterinary Science, Centro de Ciencias de Agropecuarias, Universidad Autónoma de Aguascalientes, Aguascalientes, Mexico","2020 IEEE International Conference on Industrial Technology (ICIT)","16 Apr 2020","2020","","","680","685","The quality of meat-based products is usually tested by subjective and analytical methods. There are laboratory tests which can accurately estimate the content of a sample. Yet, they imply the sample destruction. In addition, they are time consuming and not suitable for industrial applications. Spectral unmixing is wide popular in remote sensing and biomedical applications for a quantitative analysis of an image. In this study, we apply an optical characterization of a ground-beef sample by blind linear unmixing. We prepare samples of ground beef with fixed fat/protein content. The samples are employed to evaluate the characterization provided by linear unmixing of multi-spectral data. We use an eight-band multi-spectral camera and halogen lamps as illumination source. A constrained quadratic optimization algorithm is employed to estimate end-members and their abundances in the sample. The linear unmixing was applied to estimate four end-members and their abundances in the ground beef samples. These abundances match the visual characteristics of the sample such as positions with high concentration of fat.","2643-2978","978-1-7281-5754-2","10.1109/ICIT45562.2020.9067300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9067300","spectral unmixing;multispectral imaging;nondestructive evaluation","Fats;Cameras;Image color analysis;Pigments;Visualization;Remote sensing","cameras;food products;image processing;nondestructive testing;product quality;production engineering computing;proteins;quadratic programming;remote sensing;spectral analysis","multispectral imaging;sample destruction;industrial applications;spectral unmixing;biomedical applications;optical characterization;blind linear unmixing;halogen lamps;ground beef;nondestructive evaluation;meat-based products quality;remote sensing;image analysis;fat-protein content;eight-band multispectral camera;constrained quadratic optimization algorithm","","","","21","IEEE","16 Apr 2020","","","IEEE","IEEE Conferences"
"Oil Spill Impacts on Mangrove Forest from Satellite Remote Sensing","S. S. Farhana Ahmad; N. Hazrina Idris","Department of Geoinformation, Faculty of Built Environment and Surveying, Universiti Teknologi Malaysia, Johor Darul Takzim, Malaysia; Tropical Resource Mapping Research Group, Department of Geoinformation, Faculty of Built Environment and Surveying, Universiti Teknologi Malaysia, Johor Darul Takzim, Malaysia","2021 7th International Conference on Space Science and Communication (IconSpace)","9 May 2022","2021","","","60","64","The mangrove forest has been continuously threatened by oil spills occurring on the sea surfaces. The oil spills pose and cause severe and long-term effect havoc on mangrove forests that sustain them. Previous research has found that satellite remote sensing technologies are one of the most effective techniques to detect oil spills and assess the health of mangrove forests in contaminated areas. This study utilized the Synthetic-Aperture Radar (SAR) images from dualpolarized Sentinel-1 and Multi-Spectral Instrument (MSI) from Sentinel-2 to study the impact of oil spills on Mangrove Forest in Pantai Cermin, Negeri Sembilan. The Random Forest classification was used to detect the oil spill areas, while vegetation indices were used to assess the impact of oil pollution on mangrove forests in the early stages. Analysis from Sentinel1 imagery shows that the oil spill could be accurately detected using the Random Forest classifer with accuracy of 76%. Spectral indices: the normalized difference vegetation index (NDVI) was explored and evaluated to study the health of mangrove forest after the oil spills event. It is found that the oil spills have caused physical suffocation as well as toxicological effects to the mangrove forests.","2165-431X","978-1-6654-2523-0","10.1109/IconSpace53224.2021.9768774","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768774","oil spill;remote sensing;sentinel 1;sentinel 2","Sea surface;Radar remote sensing;Satellites;Oils;Surface contamination;Spaceborne radar;Vegetation mapping","geophysical image processing;image classification;marine pollution;oil pollution;radar imaging;remote sensing;remote sensing by radar;synthetic aperture radar;toxicology;vegetation;vegetation mapping","Random Forest classifer;mangrove forest;oil spill impacts;Random Forest classification;oil spill areas","","","","4","IEEE","9 May 2022","","","IEEE","IEEE Conferences"
"Simulation and analysis on the influence of different types of soil background on the remote sensing information of wheat NDVI of farmland","Y. Fang; P. Wang; J. Chen; Q. Tian","International Institute for Earth System Science, Nanjing University, Nanjing, China; International Institute for Earth System Science, Nanjing University, Nanjing, China; Department of Geography, University of Toronto, Toronto, Ontario, Canada; International Institute for Earth System Science, Nanjing University, Nanjing, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","4462","4465","It is quite confusing to effectively monitor and precisely evaluate growing conditions of wheat by using normalized differential vegetation index based on pixel size (NDVIp) as they are significantly different when acquired by the wheat of same growth status with different types of soil background. The wheat canopy normalized differential vegetation index(NDVIc) acquired by one scene of multi-spectral remote sensing image with no soil disturbance, pure black background are similar while soil backgrounds are often different. In view of this situation, based on the fixed wheat canopy spectrum which means the NDVIc is a constant value, this paper selects 9 typical soil types in our country as background in order to study the influence of different soil background types on NDVIp of wheat and analyze the sensitivity of NDVIp of wheat to the vegetation coverage simulated by diverse liner mixed ratio of wheat canopy and soil background on the remote-sensing's pixel scale. The results show that: (1)wheat NDVIp of farmland increases along with the increment of vegetation coverage under the same type of soil background, and vice versa; (2)wheat NDVIp of farmland varies greatly with different soil background types, and the difference decreases while the vegetation coverage exceeds 25%; (3) NDVIp sensitivity also shows a quite difference to vegetation coverage under the diverse soil background types. The influence of soil background on NDVIp sensitivity is the lowest when the vegetation coverage ranges from 25% to 35%.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730163","NDVI;Spectra;Wheat;Soil;Sensitivity","Soil;Vegetation mapping;Sensitivity;Reflectivity;Remote sensing;Satellites;Earth","crops;geophysical image processing;soil;vegetation mapping","remote sensing information;NDVIp sensitivity;farmland;remote-sensing pixel scale;wheat canopy;liner mixed ratio;vegetation coverage;NDVIp;soil background types;NDVIc;fixed wheat canopy spectrum;soil backgrounds;pure black background;soil disturbance;multispectral remote sensing image;wheat canopy normalized differential vegetation index;growth status;normalized differential vegetation index based on pixel size;growing conditions","","2","","9","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Passive millimeter-wave scene imaging simulation based on fast ray-tracing","B. Qi; L. Lang; Y. Cheng; S. Liu; F. Hu; X. He; P. Deng; L. Gui","School of Electronic Information and Communications, National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","2642","2645","Scene imaging simulation is an indispensable work in passive millimeter-wave object detection and remote sensing. In this paper, a 3-D scene simulation model of passive millimeter-wave imaging based on ray-tracing is presented, with consideration of the essential affecting factors such as multiple reflections, sky radiation, polarization rotation and antenna pattern smoothing. In order to accelerate the ray-tracing process in simulation model, a fast ray-triangle intersection algorithm is adopted. The outdoor imaging experiment and scene imaging simulation are carried out to validate the presented method at 94GHz. From the results, it is shown that the speed of scene imaging simulation process is significantly improved and the simulated image is in good agreement with the measured brightness temperature image.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729682","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729682","Passive millimeter-wave (PMMW) imaging;Ray tracing;Ray-triangle intersection;Imaging simulation","Imaging;Brightness temperature;Millimeter wave technology;Radiometry;Ray tracing;Atmospheric modeling;Temperature measurement","millimetre wave imaging;object detection;ray tracing","passive millimeter-wave scene imaging simulation;fast ray-tracing;3-D scene simulation model;multiple reflections;sky radiation;polarization rotation;antenna pattern smoothing;fast ray-triangle intersection algorithm;outdoor imaging experiment;brightness temperature image;frequency 94 GHz","","6","","10","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Error and Uncertainty in Earth Observation Value Chains","A. Siddiqi; S. Baber; O. de Weck; C. Durell","Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Labsphere Inc., North Sutton, NH, USA","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","3158","3161","Earth observation systems are providing a growing amount of high resolution and multi-spectral data including agricultural crop yield predictions, local weather forecasts, wild fire tracking, and water quality monitoring. With the advent of multiple elements and sophisticated processing and modeling, there are also increasing avenues for introduction of errors. It is important to quantify and characterize these errors in the remotely sensed data as it gets increasingly used to inform vital decisions. Here, a data value-chain approach is presented for conceptualizing introduction and propagation of errors in remote sensing data acquisition, processing, and decisions. A detailed case of calibration errors and their propagation to higher level data products is then discussed. An NDVI analysis is used as an example, and it is shown (for the selected region), that a 3% error in reflectance ratio of red and NIR bands translates into a difference of 60 % for category 5 NDVI classification (representing high vegetation). This amplification of errors along the data value chain is caused by nonlinear operators such as the application of quotients to differences of reflectance values as well as the use of classifiers based on fixed color thresholding.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323463","Remote Sensing Errors;Uncertainty;Error Propagation;Calibration;Value of Information;NDVI","Sensors;Calibration;Uncertainty;Vegetation mapping;Reflectivity;Data models;Remote sensing","calibration;data acquisition;geophysical techniques;remote sensing","data value-chain approach;calibration errors;higher level data products;NDVI analysis;red NIR bands;category 5 NDVI classification;high vegetation;data value chain;reflectance values;earth observation value chains;earth observation systems;multispectral data;agricultural crop yield predictions;local weather forecasts;wild fire tracking;water quality monitoring;multiple elements;sophisticated processing;remote sensing data acquisition;remote sensing data processing","","1","","13","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Shadow Cast Tracking for Deduction of Elevation Data Through Affine Matching Methods on Optical Satellite Imagery","B. Altena; B. Wouters","Institute for Marine and Atmospheric Research, Utrecht University, the Netherlands; Department of Geoscience & Remote Sensing, Delft University of Technology, the Netherlands","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5623","5626","Cast shadow from mountain ridges can be tracked over time. Through simple trigonometry this can give a clue about relative elevation change. These shadow ridges can be easily identified in multi -spectral satellite imagery as they are strong illumination changes in all spectral bands. Following shadow cast can be more complicated, due to different sun angles and changes in terrain slope. This results in a deformed appearance, which complicate tracking when simple pattern matching techniques are used. In this contribution we explore two affine matching methods in both the spatial and frequency domain, to increase the matching success of shadow cast on mountain glaciers.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9555075","Dutch research counsel (NWO); Netherlands space office(grant numbers:ALWGO.2018.044); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555075","glacier elevation retrieval;Sentinel- 2;pattern matching;affine Fourier;least squares matching","Satellites;Frequency-domain analysis;Lighting;Geoscience and remote sensing;Optical imaging;Optical sensors;Sun","feature extraction;geophysical image processing;glaciology;image matching;pattern matching;remote sensing;terrain mapping;topography (Earth)","shadow cast tracking;deduction;elevation data;affine matching methods;optical satellite imagery;cast shadow;mountain ridges;simple trigonometry;relative elevation change;shadow ridges;multi-spectral satellite imagery;strong illumination changes;spectral bands;different sun angles;terrain slope;simple pattern matching techniques;matching success;mountain glaciers","","","","9","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Optimization of statistical learning algorithm for crop discrimination using remote sensing data","A. Khobragade; P. Athawale; M. Raguwanshi",NA; GHRCE; YCCE,"2015 IEEE International Advance Computing Conference (IACC)","13 Jul 2015","2015","","","570","574","Agriculture is backbone of Indian economy, where agricultural production is estimated based upon its sown area. The probable reasons for not having accurate and transparent statistics on Indian agronomy would be the existing inadequate facilities, unstable mechanism, and sluggish government functionaries. With the advent of remote sensing technologies, researchers are optimistic towards addressing such problems. It would be great challenge to classify multi-spectral satellite images due to its complexity, processing skills, and classification. The reviews on problems and prospects of supervised and unsupervised classification techniques, is highlighted in this paper. Literatures stated that one of such statistical learning model is support vector machine algorithm, which reveals to be the best suitable algorithm for vegetation discrimination using remote sensing images. In this paper, an attempt is made in order to enhance the performance of SVM by optimizing its training part. The approach aims at investigating improvement corners on SVM classification for estimating agricultural area using remote sensing data and explores futuristic research in this domain too. Several attempts have been made using supervised SVM model, but use of EA for enhancement of SVM is the novelty that distinguishes this research weigh against the traditional approaches. Findings of such intermingling is put forth through this approach in constructive way so as to address crop identification for reducing the manual efforts taken to measure the agricultural area covered by the specific crops.","","978-1-4799-8047-5","10.1109/IADCC.2015.7154771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7154771","support vector machine;SVM;evolutionay algorithm;GA;kappa;EA;optimization;SMO;OSH;GIS","Training;Support vector machines;Accuracy;Remote sensing;Agriculture;Satellites;Classification algorithms","crops;geophysical image processing;image classification;learning (artificial intelligence);optimisation;remote sensing;statistical analysis;support vector machines","optimization;statistical learning algorithm;crop discrimination;Indian economy;agricultural production;sown area;Indian agronomy;remote sensing technologies;multispectral satellite image classification;unsupervised classification techniques;statistical learning model;support vector machine algorithm;vegetation discrimination;remote sensing images;SVM classification;agricultural area estimation;remote sensing data","","3","","18","IEEE","13 Jul 2015","","","IEEE","IEEE Conferences"
"Joint Image Registration and Fusion for Panchromatic and Multispectral Images","Q. Zhang; Z. Cao; Z. Hu; Y. Jia; X. Wu","National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; Shenzhen Key Laboratory of Spatial Smart Sensing and Services, Mapping and GeoInformation, College of Civil Engineering, Shenzhen University, Shenzhen, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Division of Mathematics, Informatics and Statistics, Commonwealth Scientific and Industrial Research Organization, North Ryde, N.S.W., Australia","IEEE Geoscience and Remote Sensing Letters","16 Sep 2014","2015","12","3","467","471","Both image registration and fusion are essential steps to produce high-resolution multispectral images in remote sensing. Traditionally, they are viewed as two independent processes. As a result, the registration errors ignored in the fusion process can significantly affect the fusion quality. In this context, an iterative optimization approach, which jointly considers the registration and fusion processes, is proposed for panchromatic (PAN) and multispectral (MS) images. Given a registration method and a fusion method, the joint optimization process is described as finding the optimal registration parameters to gain the optimal fusion performance. In our approach, the downhill simplex algorithm is adopted to refine the registration parameters iteratively. Experiments on a set of PAN and MS images of ZY-3 and GeoEye-1 show that the proposed approach outperforms several competing ones in terms of registration accuracy and fusion quality.","1558-0571","","10.1109/LGRS.2014.2346398","National Natural Science Foundation of China(grant numbers:41001260); Fundamental Research Funds for the Central Universities(grant numbers:201121302020003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6880780","Image fusion;image fusion quality;image registration;iterative optimization;registration accuracy;Image fusion;image fusion quality;image registration;iterative optimization;registration accuracy","Joints;Optimization;Image registration;Remote sensing;Accuracy;Indexes;Linear programming","geophysical image processing;hyperspectral imaging;image fusion;image registration;iterative methods;optimisation;remote sensing","image registration;panchromatic images;high resolution multispectral images;remote sensing;registration errors;image fusion quality;iterative optimization approach;registration method;fusion method;optimal registration parameters;optimal fusion performance;ZY-3 images;GeoEye-1 images","","32","","22","IEEE","20 Aug 2014","","","IEEE","IEEE Journals"
"Multi-spectral registration fusion based on laser point cloud","H. Yuan; Y. He; L. Dong; L. Chen; Y. Zhang; J. Yao; Q. Tan","Zhaoqing Power Supply Bureau, Guangdong Power Grid Company Limited, Zhaoqing, China; Zhaoqing Power Supply Bureau, Guangdong Power Grid Company Limited, Zhaoqing, China; Zhaoqing Power Supply Bureau, Guangdong Power Grid Company Limited, Zhaoqing, China; Zhaoqing Power Supply Bureau, Guangdong Power Grid Company Limited, Zhaoqing, China; Zhaoqing Power Supply Bureau, Guangdong Power Grid Company Limited, Zhaoqing, China; Zhaoqing Power Supply Bureau, Guangdong Power Grid Company Limited, Zhaoqing, China; Zhaoqing Power Supply Bureau, Guangdong Power Grid Company Limited, Zhaoqing, China","2022 IEEE International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA)","6 Apr 2022","2022","","","50","53","Airborne laser scanning and ranging technology (Light Detection And Ranging, LiDAR) can reliably and quickly directly obtain the three-dimensional coordinate point cloud of the measured object. It is the research and application of typical tree species identification and ranging positioning of transmission line corridors One of the important technical means. Completing the precise geometric registration of multi-spectral images and LiDAR point clouds is an important foundation for subsequent work such as power line extraction, tree species classification, and tree crown extraction in related research applications. This research focuses on the related research content of the geometric registration of lidar point cloud and multispectral image of transmission line corridor, and carried out the research of image/point cloud geometric registration technology based on the idea of minimizing the distance between the intersection point of photogrammetry and the surface of the laser point cloud. The precise registration of multi-spectral image and LiDAR point cloud data has been completed.","","978-1-6654-1606-1","10.1109/EEBDA53927.2022.9744957","Science and Technology Project of China Southern Power Grid Corporation(grant numbers:031200KK52190099,GDKJXM20198220); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9744957","LiDAR point cloud;Multi-spectral;geometric registration;UAV","Point cloud compression;Laser radar;Surface emitting lasers;Vegetation;Laser modes;Cameras;Transmission line measurements","clouds;feature extraction;geophysical image processing;geophysical signal processing;image registration;optical radar;photogrammetry;remote sensing;remote sensing by laser beam","multispectral registration fusion;laser point cloud;airborne laser scanning;ranging technology;typical tree species identification;ranging positioning;transmission line corridor;important technical means;precise geometric registration;multispectral image;lidar point cloud;power line extraction;tree species classification;tree crown extraction;related research applications;related research content;precise registration","","","","6","IEEE","6 Apr 2022","","","IEEE","IEEE Conferences"
"Oil Spills Tracking Through Texture Analysis from MODIS Imagery","F. Lei; W. Wang; W. Zhang; K. Li; Z. Xu","CSSC Systems Engineering Research Institute, Beijing, China; CSSC (Zhe Jiang) Ocean Technology CO., LTD, Zhoushan, China; CSSC (Zhe Jiang) Ocean Technology CO., LTD, Zhoushan, China; CSSC Systems Engineering Research Institute, Beijing, China; College of Geoscience and Surveying Engineering, China University of Mining & Technology, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","9768","9771","Detection and tracking of oil spills using Moderate Resolution Imaging Spectroradiometer (MODIS) have received a considerable attention over the past few years, notably due to the wide area coverage, short revisit frequency and free of charge. Oil spills appear different signatures from the normal seawater depending on the spectral and spatial characteristics of remote sensing image. This paper uses a local difference box-counting (DBC) algorithm to construct the textural fractal map (TFM) from the MODIS imagery. Based on that, the oil spills can be highlighted, thus to be easily extracted. The DBC approach is verified over Mediterranean Sea on MODIS images in sun glint condition. Results show that the sun glint effects on the MODIS imagery have been removed from its fractal textural map. Following that, two oil slicks can be easily extracted from temporal MODIS TFMs for mapping their trajectories.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898595","Oil spill detection;Multi-spectral optical remotely sensed images;Local difference box-counting (DBC) algorithm;Texture fractal map (TFM)","Oils;MODIS;Fractals;Sun;Remote sensing;Sea surface;Sensors","fractals;geophysical image processing;image texture;marine pollution;oil pollution;radiometry;remote sensing","temporal MODIS TFMs;oil spills;texture analysis;MODIS imagery;tracking;Moderate Resolution Imaging Spectroradiometer;remote sensing image;local difference box-counting algorithm;textural fractal map;MODIS images;fractal textural map;oil slicks","","","","15","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Semi-automated land/water segmentation of multi-spectral imagery","B. Cook; S. Graceffo","Areté Associates, Arlington, USA; Areté Associates, Arlington, USA","OCEANS 2015 - MTS/IEEE Washington","11 Feb 2016","2015","","","1","7","Segmentation of land and water regions is necessary in many applications involving analysis of remote sensing imagery. Not only is manual segmentation of these regions prone to considerable subjective variability, but the large volume of imagery collected by modern platforms makes manual segmentation extremely tedious to perform, particularly in applications that require frequent re-measurement. This paper examines a robust, semi-automated approach that utilizes simple and efficient machine learning algorithms to perform supervised classification of multi-spectral image data into land and water regions. By combining the four wavelength bands widely available in imaging platforms such as IKONOS, QuickBird, and GeoEye-1 with basic texture metrics, high quality segmentation can be achieved. An efficient workflow was created by constructing a Graphical User Interface (GUI) to these machine learning algorithms.","","978-0-9339-5743-5","10.23919/OCEANS.2015.7401875","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7401875","Segmentation;machine learning;remote sensing","Image segmentation;Image edge detection;Training data;Graphical user interfaces;Classification algorithms;Machine learning algorithms;Histograms","geophysical image processing;image classification;image segmentation;learning (artificial intelligence);remote sensing","graphical user interface;supervised classification;machine learning algorithm;remote sensing image;multispectral image;water image segmentation;semiautomated land image segmentation","","","","","","11 Feb 2016","","","IEEE","IEEE Conferences"
"Airborne Aperture Synthesis Radiometers with Conformal Antenna Arrays","L. Feng; L. Wei; Y. Li; F. Li; P. Gong; J. Li","Collaborative Innovation Center of Industrial Bigdata, Hubei University of Technology, Wuhan, China; Collaborative Innovation Center of Industrial Bigdata, Hubei University of Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Collaborative Innovation Center of Industrial Bigdata, Hubei University of Technology, Wuhan, China; Collaborative Innovation Center of Industrial Bigdata, Hubei University of Technology, Wuhan, China; Collaborative Innovation Center of Industrial Bigdata, Hubei University of Technology, Wuhan, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","9125","9128","Airborne passive remote sensing is an important method for Earth observation. In the airborne platform, it is difficult to mount an aperture synthesis radiometer (ASR) with a large co-plane antenna array due to the limitation of aerodynamic drag. In this situation, a conformal antenna array has the advantage of achieving large antenna array to improve the spatial resolution in low frequencies. In this paper, the basic principle of an ASR with a conformal array is analyzed. To reconstruct images with large field of view (FOV), the reconstruction method is introduced. The numerical simulation is conducted to validate the proposed method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898373","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898373","Conformal antenna array;aperture synthesis radiometers;passive remote sensing;image reconstruction","Antenna arrays;Image reconstruction;Apertures;Radiometers;Aircraft;Remote sensing;Spatial resolution","antenna arrays;aperture antennas;conformal antennas;image reconstruction;numerical analysis;radioastronomy;radiometers","airborne aperture synthesis radiometers;airborne passive remote sensing;Earth observation;ASR;aerodynamic drag;conformal antenna array;spatial resolution;reconstruction method;coplane antenna array;field of view;FOV;numerical simulation","","1","","4","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Unsupervised change detection analysis to multi-channel scenario based on morphological contextual analysis","N. Falco; G. Cavallaro; P. R. Marpu; J. A. Benediktsson","University of Iceland, Faculty of Electrical and Computer Engineering, Reykjavik, Iceland; University of Iceland, Faculty of Electrical and Computer Engineering, Reykjavik, Iceland; Institute Center for Water and Environment, Masdar Institute of Science and Technology, Abu Dhabi, UAE; University of Iceland, Faculty of Electrical and Computer Engineering, Reykjavik, Iceland","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","3374","3377","A novel unsupervised change detection approach for multi-spectral remote sensing data based on morphological transformation is presented. Profiles obtained by attribute filters can provide a rich multi-level analysis of the contextual information. The proposed method is based on the assumption that pixels belonging to changed areas exhibit profiles with significant differences due to a variation in their geometry, whereas pixels within unchanged areas result in similar profiles due to their similar spatial characteristics. The extension to the multi-spectral scenario is performed by applying the morphological analysis on the available bands that compose a given data set. In such scenario radiometric normalization results mandatory in order to minimize the effect due to different acquisition's conditions. To this purpose, IR-MAD is performed as pre-processing. In the paper, preliminary results obtained considering a multi-temporal Landsat ETM+ data set acquired over an agriculture area are shown.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729872","Change detection;mathematical morphology;IR-MAD;attribute profiles;remote sensing","Shape;Agriculture;Urban areas;Remote sensing;Radiometry;Geometry;Earth","geomorphology;geophysical techniques;remote sensing","unsupervised change detection analysis;multichannel scenario;morphological contextual analysis;multispectral remote sensing data;morphological transformation;contextual information multilevel analysis;radiometric normalization;IR-MAD pre-processing;multitemporal Landsat ETM+ data set;agriculture area","","6","","13","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Two-Stage Cross-Modality Transfer Learning Method for Military-Civilian SAR Ship Recognition","Y. Song; J. Li; P. Gao; L. Li; T. Tian; J. Tian","School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","18 Apr 2022","2022","19","","1","5","Military-civilian attribute recognition of ships in synthetic aperture radar (SAR) imagery plays an important role in marine surveillance. However, high-quality labeled data are hard to obtain for SAR ships, which hinder the development of deep learning models. Considering that models directly transferred from labeled optical images cannot achieve satisfactory performance for SAR applications due to the great discrepancy of different modalities, we propose a two-stage transfer learning method by combining the data-level and feature-level knowledge transfer. First, CycleGAN is adopted in the first stage to transfer the labeled optical image domain to the intermediate SAR-like image domain with the attribute labels. Then, a novel network called Domain Transfer using Adversarial learning and Metric learning (DTAM) is proposed to realize the task of military-civilian ship recognition by the domain adaption of the intermediate domain and the target SAR domain with joint adversarial learning and metric learning. To validate the proposed method, we establish a high-resolution SAR ship recognition dataset (HRSSRD), containing SAR and optical images of military and civilian ships. The experimental results show that the proposed two-stage architecture exhibits promising performance on the problem of SAR military-civilian ship recognition.","1558-0571","","10.1109/LGRS.2022.3162707","National Natural Science Foundation of China(grant numbers:42071339); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9743385","Domain adaption;military-civilian ship recognition;optical remote sensing images;synthetic aperture radar (SAR) imagery;transfer learning","Optical imaging;Synthetic aperture radar;Marine vehicles;Optical sensors;Image recognition;Task analysis;Radar polarimetry","image classification;learning (artificial intelligence);object detection;radar imaging;ships;synthetic aperture radar","military-civilian SAR ship recognition;synthetic aperture radar imagery;marine surveillance;high-quality labeled data;SAR ships;deep learning models;labeled optical images;SAR applications;two-stage transfer learning method;data-level;feature-level knowledge transfer;labeled optical image domain;intermediate SAR-like image domain;attribute labels;Domain Transfer;metric learning;domain adaption;intermediate domain;target SAR domain;joint adversarial learning;high-resolution SAR ship recognition dataset;military ships;civilian ships;two-stage architecture;SAR military-civilian ship recognition;stage cross-modality Transfer learning method","","3","","18","IEEE","28 Mar 2022","","","IEEE","IEEE Journals"
"Sparse Representation of Injected Details for MRA-Based Pansharpening","M. Maneshi; H. Ghassemian; M. Imani","Image Processing and Information Analysis Lab. Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran; Image Processing and Information Analysis Lab. Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran; Image Processing and Information Analysis Lab. Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran","2020 IEEE India Geoscience and Remote Sensing Symposium (InGARSS)","23 Feb 2021","2020","","","86","89","Pansharpening is a notable remote sensing topic in which high spatial resolution panchromatic image and low spatial resolution multi-spectral image are being fused in order to receive the high spatial resolution multi-spectral image. This paper presents a hybrid pansharpening method based on MRA framework and the sparse representation of injected details. To add spatial details of the panchromatic image into the multispectral image more effectively, the injection gains are computed through an iterative full-scale model in which the gains are updated at each iteration relying on its previous iteration's fusion product. The proposed method is compared with five pansharpening approaches to investigate the effectiveness. Experiments have been implemented on two data sets from the Pleiades and GeoEye-1 satellites both at reduced and full scale. In terms of visual and quantity assessment, the high-resolution MS image produced by the proposed method is more acceptable than those images fused by other rival approaches.","","978-1-7281-3114-6","10.1109/InGARSS48198.2020.9358956","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9358956","Sparse representation;Image fusion;Pansharpening;Remote sensing","Visualization;Satellites;Computational modeling;Pansharpening;Sensors;Spatial resolution;Remote sensing","geophysical image processing;image fusion;image resolution;remote sensing","hybrid pansharpening method;MRA framework;sparse representation;injected details;spatial details;injection gains;iterative full-scale model;high-resolution MS image;MRA-based pansharpening;high spatial resolution panchromatic image;low spatial resolution multispectral image;high spatial resolution multispectral image;remote sensing topic;Pleiades satellite;GeoEye-1 satellite","","1","","16","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"DO-Net: Dual-Output Network for Land Cover Classification From Optical Remote Sensing Images","W. Kang; Y. Xiang; F. Wang; H. You","School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences,Huairou, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences,Huairou, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences,Huairou, Beijing, China","IEEE Geoscience and Remote Sensing Letters","4 Jan 2022","2022","19","","1","5","Land cover classification is the basic task of remote sensing image interpretation. Related methods have developed rapidly, especially the branch based on deep learning (DL). For high-resolution remote sensing images, the smaller inter-class difference and greater intra-class difference are two obstacles to improving the classification accuracy. For the former, the DL models generally use a deeper encoder to extract more powerful classification features. Considering that the scale of different land cover categories varies greatly, multi-scale feature extraction modules are also used to improve the classification accuracy. While the latter is always overlooked, and thus we propose a dual-output model, which uses a dense spatial pyramid pooling (DSPP) module to generate both the pixel-level and region-level predictions, to reduce the influence of intra-class differences. To further increase the classification accuracy, we investigate the band selection technique to apply the pre-trained encoder from the natural red green blue (RGB) dataset to multi-spectral remote sensing images. Extensive experiments on two datasets demonstrate the effectiveness of our model.","1558-0571","","10.1109/LGRS.2021.3114305","National Natural Science Foundation of China(grant numbers:61901439); Key Research Program of Frontier Sciences, Chinese Academy of Science(grant numbers:ZDBS-LY-JSC036); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9570140","Deep learning (DL);dual-output;land cover classification;pre-trained model","Feature extraction;Remote sensing;Training;Residual neural networks;Image resolution;Automobiles;Optical sensors","feature extraction;geophysical image processing;image classification;learning (artificial intelligence);remote sensing;terrain mapping","dual-output network;land cover classification;optical remote sensing;basic task;remote sensing image interpretation;high-resolution remote sensing images;smaller inter-class difference;greater intra-class difference;classification accuracy;powerful classification features;different land cover categories;multiscale feature extraction modules;dual-output model;dense spatial pyramid pooling module;intra-class differences;multispectral remote sensing images","","3","","14","IEEE","13 Oct 2021","","","IEEE","IEEE Journals"
"A compressed-sensing-based approach for remote sensing image fusion","M. Khateri; H. Ghassemian","Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran; Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran","2016 24th Iranian Conference on Electrical Engineering (ICEE)","10 Oct 2016","2016","","","1809","1814","Remote sensing image pan-sharpening is an image fusion process which fuses a low-resolution multi-spectral (LRMS) image with its corresponding high-resolution panchromatic (HRP) image to create a high-resolution multi-spectral (HRMS) image. In this paper, pan-sharpening methods based on compressed sensing (CS) theory are proposed. In the proposed methods, the HRP and LRMS dictionaries are learned from the input images (HRP, LRMS). Moreover, this paper proposes a new algorithm to reconstruct the unknown HRMS image by considering remote sensing physics. The proposed algorithm extracts non-overlapping patches from input images and provides an initial estimation of HRMS dictionary. Then, the initial HRMS dictionary and LRMS image are used to reconstruct unknown HRMS image. The algorithm neither needs to extract overlapping patches, nor training dataset. So, it makes the proposed methods fast and practical. Furthermore a high-pass filter is used to preserve more details in the fusion process. The proposed methods are tested on WorldView-2 and QuickBird satellite images and these results are compared with several popular and state-of-the-art methods quantitatively and visually.","","978-1-4673-8789-7","10.1109/IranianCEE.2016.7585815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7585815","Remote sensing;pan-sharpening;image fusion;compressed sensing (CS);dictionary learning","","compressed sensing;geophysical image processing;image fusion;image reconstruction;image resolution;remote sensing","remote sensing image fusion;compressed-sensing-based approach;low-resolution multispectral image;high-resolution panchromatic image;high-resolution multispectral image;compressed sensing theory;unknown HRMS image reconstruction;remote sensing image pan-sharpening;remote sensing physics;nonoverlapping patches;HRMS dictionary;LRMS dictionary;QuickBird satellite images;WorldView-2 images","","1","","23","IEEE","10 Oct 2016","","","IEEE","IEEE Conferences"
"Agriculture Multispectral Uav Image Registration Using Salient Features and Mutual Information","S. Stempliuk; D. Menotti","Department of Informatics, UFPR - Federal University of Paraná, Curitiba, PR, Brazil; Department of Informatics, UFPR - Federal University of Paraná, Curitiba, PR, Brazil","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","4108","4111","Multimodal image registration has been studied for a long time as a necessary pre-processing step to extract relevant information from the studied images. In this direction, agriculture remote sensing has evolved to use multispectral sensors and faces challenges since the application of classic solutions is not suitable. This paper preliminarily explores the benefits of applying Mutual Information (MI) based on SIFT points for image registration to agriculture remote sensing multi-spectral evaluated on a self-developed public database of images through a fixed-wing Unmanned Aerial Vehicle (UAV) equipped with a multispectral sensor operating within parameters that would apply to crops inspection in real life. Our preliminary results have shown a marginal improvement of MI after registration highlighting that we may apply it to improve the registration of agriculture remotely sensed images. This small variation of MI shows that there is room for improvement.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323325","Multimodal sensors;Multispectral sensor;Camera displacement;Remote sensing;Mutual Information","Sensors;Image sensors;Histograms;Remote sensing;Image registration;Two dimensional displays;Agriculture","agriculture;autonomous aerial vehicles;feature extraction;geophysical image processing;image classification;image registration;remote sensing;remotely operated vehicles","agriculture multispectral UAV image registration;salient features;mutual information;multimodal image registration;multispectral sensor;classic solutions;agriculture remote sensing multispectral;registration highlighting;agriculture remotely sensed images","","","","26","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Correction of SMOS data in coastal area of South China Sea based on land contamination analysis","L. Yan; L. Qingxia; L. Lang; R. Jin; Z. Chen","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, CN; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, CN; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, CN; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, CN; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology (HUST), Wuhan, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","7667","7670","For SMOS data, significant errors exist in coastal areas because of the contamination by the nearby land. In this paper, the analysis of SMOS brightness temperature (TB) data in coastal area of South China Sea (SCS) reveals a decreasing trend with the increase of the distance to coast. A SMOS TB measurement model according to geophysical parameters and SMOS/MIRAS antenna array is established. The simulation shows that TB is large within 40 km since land is much warmer than ocean and is observed by the mainlobe of the antenna array. Then the simulation result of land contamination is used for correction of SMOS measured TB data in coastal area of SCS. Then the corrected TB is applied for sea surface salinity (SSS) retrieval, which reduces SSS outliers and improves the accuracy of SSS in coastal area of SCS.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730999","Land contamination;SMOS;brightness temperature (TB);sea surface salinity (SSS);coastal area;South China Sea (SCS)","Sea measurements;Pollution measurement;Antenna arrays;Antenna measurements;Contamination;Area measurement","antenna arrays;data analysis;marine pollution;oceanographic regions;remote sensing;salinity (geophysical)","sea surface salinity retrieval;SMOS-MIRAS antenna array;geophysical parameters;data analysis;SMOS brightness temperature;land contamination analysis;South China Sea;coastal area;SMOS data","","","","8","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Monitoring LULC dynamics in the Sao Paulo region through landsat and C-band SAR time series","L. Iannini; R. Molijn; A. Mousivand; R. Hanssen","Geoscience and Remote Sensing Department, Delft University of Technology; Geoscience and Remote Sensing Department, Delft University of Technology; Geoscience and Remote Sensing Department, Delft University of Technology; Geoscience and Remote Sensing Department, Delft University of Technology","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","90","93","The paper debates a novel approach for sugarcane identification and characterization based on multi-spectral and multi-temporal profile matching. A parametric model aimed at identifying sugarcane among pasture/grasses/shrubs, annual crops and forest is proposed. Differently from other supervised and unsupervised classification techniques, the discussed profile-based parametric model accounts for variability in growth date, that becomes valuable information to be extracted, rather than simply a nuisance parameter, and delivers an effective extrapolation of the cane vigor. The approach is then applied to Landsat 5 TM and ERS/ENVISAT SAR time-series over the Orindiuva area attaining preliminary promising although perfectible results.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7325705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325705","Crop identification;sugarcane mapping;multi-sensor analysis;curve fitting","Remote sensing;Agriculture;Satellites;Synthetic aperture radar;Earth;Vegetation mapping;Sensors","remote sensing by radar;time series;vegetation mapping","sugarcane identification;multispectral profile matching;multitemporal profile matching;C-band SAR time series;LandSAT;ERS/ENVISAT SAR time-series;Orindiuva area;monitoring LULC dynamics","","1","","6","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"A Multi-Scale Progressive Collaborative Attention Network for Remote Sensing Fusion Classification","W. Ma; Y. Li; H. Zhu; H. Ma; L. Jiao; J. Shen; B. Hou","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi'an 710071, China (e-mail: haozhu@xidian.edu.cn); Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi'an 710071, China.","IEEE Transactions on Neural Networks and Learning Systems","","2021","PP","99","1","15","With the development of remote sensing technology, panchromatic images (PANs) and multispectral images (MSs) can be easily obtained. PAN has higher spatial resolution, while MS has more spectral information. So how to use the two kinds of images' characteristics to design a network has become a hot research field. In this article, a multi-scale progressive collaborative attention network (MPCA-Net) is proposed for PAN and MS's fusion classification. Compared to the traditional multi-scale convolution operations, we adopt an adaptive dilation rate selection strategy (ADR-SS) to adaptively select the dilation rate to deal with the problem of category area's excessive scale differences. For the traditional pixel-by-pixel sliding window sampling strategy, the patches which are generated by adjacent pixels but belonging to different categories contain a considerable overlap of information. So we change original sampling strategy and propose a center pixel migration (CPM) strategy. It migrates the center pixel to the most similar position of the neighborhood information for classification, which reduces network confusion and increases its stability. Moreover, due to the different spatial and spectral characteristics of PAN and MS, the same network structure for the two branches ignores their respective advantages. For a certain branch, as the network deepens, characteristic has different representations in different stages, so using the same module in multiple feature extraction stages is inappropriate. Thus we carefully design different modules for each feature extraction stage of the two branches. Between the two branches, because the strong mapping methods of directly cascading their features are too rough, we design collaborative progressive fusion modules to eliminate the differences. The experimental results verify that our proposed method can achieve competitive performance.","2162-2388","","10.1109/TNNLS.2021.3121490","State Key Program of National Natural Science of China(grant numbers:61836009); National Natural Science Foundation of China(grant numbers:U1701267,61671350,62006179); China Postdoctoral Science Special Foundation(grant numbers:2020T130492); China Postdoctoral Science Foundation funded project(grant numbers:2019M663634); Fundamental Research Funds for the Central Universities(grant numbers:JB211909); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9594516","Deep neural network;fusion classification;multi-spectral images (MSs);panchromatic images (PANs);remote sensing.","Feature extraction;Convolution;Remote sensing;Kernel;Collaboration;Deep learning;Data mining","","","","4","","","IEEE","29 Oct 2021","","","IEEE","IEEE Early Access Articles"
"Unsupervised Change Detection in Very High Resolution Multi-Spectral Images","A. Chouhan; A. Agrawal; A. Sur","Indian Institute of Technology, Guwahati, Assam; Indian Institute of Technology, Guwahati, Assam; Indian Institute of Technology, Guwahati, Assam","2021 IEEE International India Geoscience and Remote Sensing Symposium (InGARSS)","13 Jun 2022","2021","","","293","296","Change detection for remote sensing images is a critical task especially for the applications including monitoring the environment, urban planning, investigating agriculture, disaster management, etc. Although most of the exiting deep models for change detection are supervised in nature, unsupervised learning-based models are also gaining popularity because of the scarcity of the annotated training examples. In this paper, we have pro-posed an unsupervised change detection algorithm for VHR (Very High Resolution) multispectral images. It uses a deep CNN model [6] to generate the deep change vector which is then subjected to Slow Feature Analysis (SFA) module [2] to suppress the unchanged components and highlight the transformed features’ changed components. An appropriate thresholding technique is then applied to generate the required binary changed map. Experimental observation reveals that the proposed unsupervised model shows competitive performance with the state-of-the-art methods. Our proposed approach has achieved fifth place 1 in Dynamic Earth Net Challenge Track 1 of EARTHVISION 2021.","","978-1-6654-4249-7","10.1109/InGARSS51564.2021.9791474","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9791474","","Training;Earth;Image resolution;Heuristic algorithms;Urban planning;Disaster management;Feature extraction","convolutional neural nets;geophysical image processing;image resolution;remote sensing;unsupervised learning","remote sensing images;very high resolution multispectral images;urban planning;disaster management;unsupervised learning;annotated training examples;unsupervised change detection;VHR multispectral images;deep CNN model;deep change vector;feature analysis","","","","10","IEEE","13 Jun 2022","","","IEEE","IEEE Conferences"
"Harmonized Landsat/Sentinel-2 Products for Land Monitoring","J. Masek; J. Ju; J. -C. Roger; S. Skakun; M. Claverie; J. Dungan","NASA GSFC, Biospheric Sciences Laboratory, Greenbelt, MD, USA; Earth System Science, Interdisciplinary University of Maryland, MD, USA; Dept. Geographical Sciences, University of Maryland, MD, USA; Dept. Geographical Sciences, University of Maryland, MD, USA; Earth and Life Institute, Universite Catholique de Louvain, Louvain, Belgium; Earth Science Division, NASA Ames Research Center Moffitt Field, CA, USA","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","8163","8165","The Harmonized Landsat-8 and Sentinel-2 (HLS) project is a NASA initiative aiming to produce a seamless, harmonized surface reflectance record from the Operational Land Imager (OLI) and Multi-Spectral Instrument (MSI) aboard Landsat-8 and Sentinel-2 remote sensing satellites, respectively. The HLS products are based on a set of algorithms to obtain seamless products from both sensors (OLI and MSI): atmospheric correction, cloud and cloud-shadow masking, geographic co-registration and common gridding, bidirectional reflectance distribution function normalization and bandpass adjustment. As of version 1.3, the HLS v1.3 data set covers 9.12 million km2 and spans from first Landsat-8 data (2013) to present. HLS products provide near-daily surface reflectance information with a common geometric framework, and are suitable for a variety of agricultural and vegetation monitoring tasks, including analysis of crop type, condition, and phenology.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517760","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517760","land remote sensing;Landsat;Sentinel-2;atmospheric correction","Remote sensing;Earth;Artificial satellites;Reflectivity;Monitoring;NASA;Cloud computing","geophysical image processing;geophysical techniques;remote sensing;vegetation","near-daily surface reflectance information;Landsat-8 data;HLS v;bandpass adjustment;bidirectional reflectance distribution function normalization;cloud-shadow masking;seamless products;HLS products;Sentinel-2 remote sensing satellites;MSI;MultiSpectral Instrument;Operational Land Imager;harmonized surface reflectance record;seamless surface reflectance record;NASA initiative;Sentinel-2 project;Harmonized Landsat-8;Land monitoring;Harmonized Landsat/Sentinel-2 products","","6","","11","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"High-Resolution BRDF and Albedo Parameters Inversion from Sentinel-2 Multispectral Instrument Data","F. Chen; Y. Li; Q. Ma; X. Li; J. Chen; M. Li; C. Gao; X. Yang","School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, Jiangsu, P. R. China; School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, Jiangsu, P. R. China; School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, Jiangsu, P. R. China; School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, Jiangsu, P. R. China; School of Geospatial Engineering and Science, Sun Yat-Sen University, Guangzhou, Guandong, P. R. China; School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, Jiangsu, P. R. China; School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, Jiangsu, P. R. China; School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, Jiangsu, P. R. China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","6694","6697","In this paper, an algorithm of the land surface bidirectional reflectance distribution function (BRDF) and albedo parameters inversion is proposed based on a simplified atmospheric radiative transfer model coupling with the BRDF model. The algorithm is applied to the Sentinel-2 Multi-Spectral Instrument (MSI) data. To validate the inversion, the BRDF/ albedo parameters derived from the MODerate Resolution Imaging Spectroradiometer (MODIS) were collected and resampled to match the MSI data. The preliminary validation shows a good consistency between the two datasets with the correlative coefficient (R) greater than 0.8 and the root-mean-square error (RMSE) less than 0.05 for the red and near infrared bands. The advantage of this algorithm is that the spatial resolution of the satellite-derived BRDF/albedo parameters can be improved as high as 20 m, which has great potential in quantitative remote sensing applications.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323591","Jiangsu Normal University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323591","Albedo;bidirectional reflectance distribution function;quantitative remote sensing;Sentinel-2","MODIS;Atmospheric modeling;Satellites;Remote sensing;Land surface;Scattering;Reflectivity","albedo;atmospheric radiation;geophysical image processing;radiative transfer;reflectivity;remote sensing","albedo parameters inversion;Sentinel-2 multispectral instrument data;land surface bidirectional reflectance distribution function;Moderate Resolution Imaging Spectroradiometer;MSI data;simplified atmospheric radiative transfer model;high-resolution BRDF parameters;MODIS;satellite-derived BRDF-albedo parameters;remote sensing","","","","16","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"One-Dimensional Mirrored Aperture Synthesis With Two Tilted Reflectors","H. Dou; H. Li; Y. Wu; G. Song; R. Lv; Y. Li; Z. Wen; Q. Li; K. Chen; L. Gui; Z. Lei","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; China Academy of Space Technology (Xi’an), Xi’an, China; China Academy of Space Technology (Xi’an), Xi’an, China; China Academy of Space Technology (Xi’an), Xi’an, China; China Academy of Space Technology (Xi’an), Xi’an, China; China Academy of Space Technology (Xi’an), Xi’an, China; China Academy of Space Technology (CAST), Institute of Remote Sensing Satellite, Beijing, China; School of Electronic Information and Communications (Science and Technology on Multi-spectral Information Processing Laboratory), Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications (Science and Technology on Multi-spectral Information Processing Laboratory), Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications (Science and Technology on Multi-spectral Information Processing Laboratory), Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications (Science and Technology on Multi-spectral Information Processing Laboratory), Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","31 Dec 2021","2022","19","","1","5","In this letter, 1-D mirrored aperture synthesis with two tilted reflectors (1-D MAS-T) is proposed to improve the spatial resolution of an antenna array without extending its size. The principle of 1-D MAS-T is given. The size of the reflector is analyzed, and detailed calculation formulae is derived. Numerical simulations and experiments are carried out to illustrate the performance of 1-D MAS-T. The results demonstrate that 1-D MAS-T can achieve a higher spatial resolution than conventional aperture synthesis with the same antenna array.","1558-0571","","10.1109/LGRS.2021.3098617","Qian Xuesen Youth Innovation Fund(grant numbers:QXSCXJJ2020-504); National Natural Science Foundation of China(grant numbers:NSFC 61771213); Opening Foundation of Science and Technology on Electronic Information Control Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9507557","Brightness temperature;mirrored aperture synthesis (MAS);spatial resolution;tilted reflectors","Antennas;Antenna arrays;Spatial resolution;Aperture antennas;Correlation;Brightness temperature;Antenna accessories","antenna arrays;mirrors;numerical analysis","antenna array;one-dimensional mirrored aperture synthesis;tilted reflectors;1D mirrored aperture synthesis;spatial resolution;conventional aperture synthesis;1D MAS-T;numerical simulations;reflector size","","2","","10","IEEE","5 Aug 2021","","","IEEE","IEEE Journals"
"Monitoring land-cover changes by combining a detection step with a classification step","F. Harrou; N. Zerrouki; Y. Sun; L. Hocini","CEMSE Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; DIIM Laboratory, Center for Development of Advanced Technology (CDTA), Algiers, Baba-Hassen, Algeria; CEMSE Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Faculty of Electronic Engineering and Computer Science, Laboratory of Analysis and Modeling of the Random Phenomena, Mouloud Mammeri University (UMMTO), Tizi-Ouzou, Algeria","2018 IEEE Symposium Series on Computational Intelligence (SSCI)","31 Jan 2019","2018","","","1651","1655","An approach merging the HotellingT2 control scheme with weighted random forest classifier is proposed and used in the context of detecting land cover changes via remote sensing and radiometric measurements. HotellingT2 procedure is introduced to identify features corresponding to changed areas. However, T2 scheme is not able to separate real from false changes. To tackle this limitation, the weighted random forest algorithm, which is an efficient classification technique for unbalanced problems, has been successfully applied on features of the detected pixels to recognize the type of change. The performance of the algorithm is evaluated using SZTAKI AirChange benchmark data, results show that the proposed detection scheme succeeds to appropriately identify changes to land cover. Also, we compared the proposed approach to that of the conventional algorithms (i.e., neural network, random forest, support vector machine and k-nearest neighbors) and found improved performance.","","978-1-5386-9276-9","10.1109/SSCI.2018.8628774","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8628774","Land cover change detection;multi-spectral sensors;multi-date measurements;remote sensing;multivariate statistical approach;Random Forest classification","Feature extraction;Monitoring;Remote sensing;Vegetation;Radiometry;Training;Benchmark testing","feature extraction;geophysical image processing;image classification;image resolution;land cover;object detection;random forests;remote sensing","classification step;weighted random forest classifier;remote sensing;radiometric measurements;HotellingT2 control scheme;land-cover change monitoring;land cover change detection;detection step;SZTAKI AirChange benchmark data;unbalanced problems;efficient classification technique;weighted random forest algorithm","","2","","16","IEEE","31 Jan 2019","","","IEEE","IEEE Conferences"
"Cosine Visibility Extension of 1-D Mirrored Aperture Synthesis by a CNN for Spatial Resolution Enhancement","G. Zhao; Q. Li; Z. Lei; C. Xiao; Z. Chen; Y. Huang","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","6 Feb 2023","2023","20","","1","5","To increase the spatial resolution of passive microwave radiometry, mirrored aperture synthesis (MAS) was presented. In this letter, the method of cosine visibility extension (CVE) is proposed to further enhance the spatial resolution of 1-D MAS. In the CVE method, a convolutional neural network (CNN) is used to learn the distribution of the cosine visibility (CV), specifically the relationship between the low- and high-frequency CV distributions of various scenes. Then, the high-frequency CVs are estimated by the CNN according to the low-frequency CVs obtained by MAS. The high- and low-frequency CVs are combined in MAS image reconstruction to enhance the spatial resolution of MAS. The simulation and experiment indicate that the CVE method can effectively enhance the spatial resolution of MAS.","1558-0571","","10.1109/LGRS.2023.3238051","National Natural Science Foundation of China(grant numbers:62271218); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10021588","Convolutional neural network (CNN);mirrored aperture synthesis (MAS);resolution enhancement;spatial frequency domain","Spatial resolution;Training;Convolutional neural networks;Image reconstruction;Microwave radiometry;Cutoff frequency;Correlation","","","","","","11","IEEE","19 Jan 2023","","","IEEE","IEEE Journals"
"Impact of UAV Time-of-Flight on Rice Nitrogen Uptake Models","J. Brinkhoff; B. W. Dunn; J. Hart; T. Dunn","Applied Agricultural Remote Sensing Centre, University of New England, Armidale, NSW, Australia; NSW Department of Primary Industries, Yanco, NSW, Australia; NSW Department of Primary Industries, Yanco, NSW, Australia; NSW Department of Primary Industries, Yanco, NSW, Australia","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","4355","4358","This work examines the impact of image acquisition time on rice paddy remote sensing data in Yanco, NSW, Australia. The normalized difference red edge (NDRE) is an important vegetation index for rice paddy N status. Models of midseason N uptake were extracted using physical samples and NDRE data taken at multiple times of day from a UAV with multi-spectral camera. The best prediction error was 15.8 kg/ha. With a model extracted at 13:00 on 1 January, model predictions from 27 December to 11 January, at image times from 11:00 to 16:00, N uptake prediction errors were less than 28.5 kg/ha. Predictions from images acquired at times very different from the one used to extract the model are more erroneous.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323619","AgriFutures Australia(grant numbers:PRJ-011058,PRJ-009772); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323619","Rice;nitrogen management;UAV;multispectral imagery","Data models;Predictive models;Remote sensing;Nitrogen;Agriculture;Vegetation mapping;Australia","agricultural engineering;autonomous aerial vehicles;crops;geophysical image processing;nitrogen;remote sensing;vegetation;vegetation mapping","multispectral camera;model predictions;N uptake prediction errors;UAV time-of-flight on rice nitrogen uptake models;image acquisition time;rice paddy remote sensing data;normalized difference red edge;vegetation index;rice paddy N status;midseason N uptake;NDRE data","","","","11","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Image Reconstruction With Deep CNN for Mirrored Aperture Synthesis","C. Xiao; Q. Li; Z. Lei; G. Zhao; Z. Chen; Y. Huang","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","12 Apr 2022","2022","60","","1","11","In mirrored aperture synthesis (MAS), the existing brightness temperature image reconstruction methods include inverse cosine transform and impulse matrix reconstruction methods. However, the quality of the MAS brightness temperature images reconstructed by the existing methods is still poor and needs to be improved. This article proposes a method of MAS brightness temperature image reconstruction with deep convolutional neural network (CNN). The network includes two fully connected (FC) layers, multiple convolutional layers, and deconvolutional layers, which realize the image reconstruction for MAS. This method uses deep CNN to learn the MAS image reconstruction mapping and system errors, so as to improve the performance of the brightness temperature image reconstruction. Both simulation and experimental results verify that the performance of the proposed MAS-CNN method is better than the existing MAS image reconstruction methods.","1558-0644","","10.1109/TGRS.2022.3157870","Fund of the 8th Research Institute of China Aerospace Science and Technology Corporation(grant numbers:SAST2020-033); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9739076","Brightness temperature;deep convolutional neural network (deep CNN);image reconstruction;mirrored aperture synthesis (MAS) image;MAS;passive microwave remote sensing","Image reconstruction;Brightness temperature;Correlation;Convolutional neural networks;Feature extraction;Transforms;Aperture antennas","brightness;convolutional neural nets;deep learning (artificial intelligence);image reconstruction","deep CNN;mirrored aperture synthesis;MAS brightness temperature image reconstruction;deep convolutional neural network;fully connected layers;multiple convolutional layers;MAS-CNN method;deconvolutional layers","","18","","25","IEEE","21 Mar 2022","","","IEEE","IEEE Journals"
"Analysis and Correction of the Rank-Deficient Error for 2-D Mirrored Aperture Synthesis","H. Dou; K. Chen; Q. Li; R. Jin; Y. Wu; Z. Lei","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; China Academy of Space Technology (Xi’an), Xi’an, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","24 Feb 2021","2021","59","3","2222","2230","In two-dimensional mirrored aperture synthesis (2-D MAS), the rank of the transformation matrix can affect the accuracy of the solved cosine visibilities; therefore, it has an impact on the accuracy of the reconstructed brightness temperature image. In this article, the influence of the rank deficient on the accuracy of the reconstructed brightness temperature image of 2-D MAS is discussed. An analysis of the rank-deficient error is performed by computing its impact on the radiometric accuracy for a reference scene. Two correction methods based on multiple measurements are proposed to correct the rank-deficient error. The simulations and experiments are carried out to demonstrate the effectiveness of the proposed methods.","1558-0644","","10.1109/TGRS.2020.3005142","National Key Research and Development Program of China(grant numbers:2016YFC1401005); Fundamental Research Funds for the Central Universities(grant numbers:2016JCTD203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9143495","Mirrored aperture synthesis (MAS);passive microwave remote sensing;rank-deficient error","Image reconstruction;Brightness temperature;Mathematical model;Temperature measurement;Antenna arrays;Apertures","atmospheric techniques;radiometry","rank-deficient error;2-D mirrored aperture synthesis;two-dimensional mirrored aperture synthesis;2-D MAS;solved cosine visibilities;reconstructed brightness temperature image;radiometric accuracy","","7","","13","IEEE","17 Jul 2020","","","IEEE","IEEE Journals"
"Machine Learning Techniques in Land Cover Classification using Remote Sensing Data","M. B. Mayani; R. Itagi","Dept. of E & C, Govt. Polytechnic, Belagavi, India; Dept. of E & C, KLEIT, Hubballi, India","2021 International Conference on Intelligent Technologies (CONIT)","4 Aug 2021","2021","","","1","5","Replacement of traditional farming by modern tools and techniques is the need of the hour. To orient Indian agriculture system towards technology, a support system is required to give a better economy growth of the country. Hyper spectral data collected from a device can be analyzed on periodic basis by exploring the huge data collected in the area of interest. Various remote sensing satellite data in hyperspectral bands can be an advantage in monitoring very tiny variations in soil, land, water etc. Remote sensing data are often degraded by many issues that may include the failure of on-board hardware, signal downlink, atmospheric conditions and overall quality of the sensors in terms of signal noise ratio or sharpness. These factors reduce the quality of the acquired data, making it often difficult or sometimes impossible to extract relevant information. Hence there is need for adaptive algorithms in the areas of data modelling and optimization. Using such data and design of a Deep Learning Network can provide a solution to farming, not only in detecting anomalies but also keep them prepared to handle effectively. This paper makes an attempt to bring an experimental outcome of selection of an efficient algorithm, tool and data to be used for land cover classification. A good spatial and temporal resolution remote sense data, open-source platform, deep learning techniques and different spectral indices recorded by a greater number of bands say hyper spectra range can be a boon to revolutionize farming and alleviate poverty line by improvement in sustainability factor. Satellite imagery converged with digital image processing can be a simple and cost-efficient solution for scientists, researchers, and developers to detect changes, map trends, and quantify differences on the Earth’s surface.","","978-1-7281-8583-5","10.1109/CONIT51480.2021.9498434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9498434","Hyperspectral;Machine learning;Deep learning;Multi spectral;Autonomy;Smart farming;spectral;temporal;Landsat;Spectroradiometer;CNN;RNN;MLP;RF","Earth;Deep learning;Machine learning algorithms;Satellite broadcasting;Training data;Tools;Feature extraction","agriculture;deep learning (artificial intelligence);geophysical image processing;geophysics computing;image classification;land cover;public domain software;remote sensing","land cover classification;remote sensing data;traditional farming;orient Indian agriculture system;hyper spectral data;remote sensing satellite data;signal noise ratio;data modelling;optimization;Deep Learning Network;temporal resolution remote sense data;deep learning techniques;machine learning techniques;efficient algorithm;open-source platform;poverty line;satellite imagery;digital image processing","","1","","20","IEEE","4 Aug 2021","","","IEEE","IEEE Conferences"
"The design requirements for Libyan imaging mini-satellite (LibyaSat-1)","F. E. M. Tubbal; A. Elarabi; A. Etabeb; H. Marah; K. Beneljankou; M. Bellid; R. El-bouaishi; A. Amer; W. Shita; S. Srabet; A. Alkaseh; A. Turkman","University of Wollongong, Australia; Kyoto University, Japan; Technological Projects Department, Libyan Center for Remote Sensing and Space Science, Tripoli, Libya; Technological Projects Department, Libyan Center for Remote Sensing and Space Science, Tripoli, Libya; Libyan Center for Remote Sensing and Space Science, Tripoli, LY; Libyan Center for Remote Sensing and Space Science, Tripoli, LY; Technological Projects Department, Libyan Center for Remote Sensing and Space Science, Tripoli, Libya; Technological Projects Department, Libyan Center for Remote Sensing and Space Science, Tripoli, Libya; Technological Projects Department, Libyan Center for Remote Sensing and Space Science, Tripoli, Libya; Technological Projects Department, Libyan Center for Remote Sensing and Space Science, Tripoli, Libya; Technological Projects Department, Libyan Center for Remote Sensing and Space Science, Tripoli, Libya; Technological Projects Department, Libyan Center for Remote Sensing and Space Science, Tripoli, Libya","2015 1st International Conference on Wireless and Telematics (ICWT)","9 Apr 2016","2015","","","1","7","In this paper we present the conceptual design of Libyan remote sensing satellite (LibyaSat-1) and its sub-systems requirements. LibyaSat-1 is a 300 kg mini satellite, which will be used to support high resolution multi-spectral earth imaging camera to fulfill the civilian needs. This satellite will operate at LEO of 775 km and will provide a resolution of 2.5 m for the panchromatic band and 10 m for the VIS/NIR bands with 30 km swath. We have presented the mission overview, mission operation concept and mission requirements. Moreover, the System Tool Kit (STK) simulation is used to show the ground trucks of LibyaSat-1 for three days and to find the contact numbers between LibyaSat-1 and both Murezeq and Tripoli stations. We have also presented the design of telemetry and command subsystem, code and data handling subsystem, electrical power subsystem, altitude orbit control subsystem, and structure subsystem.","","978-1-4673-8434-6","10.1109/ICWT.2015.7449261","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449261","mini-satellite;large satellie;sub-systems;Low Earth Orbit (LEO);payload","Satellites;Remote sensing;Space vehicles;Orbits;Downlink;Propagation losses;Batteries","artificial satellites;cameras;data handling;geophysical image processing;geophysical techniques;image resolution;remote sensing;space telemetry","Libyan imaging minisatellite;Libyan remote sensing satellite conceptual design;high resolution multispectral earth imaging camera;LEO;panchromatic band;VIS-NIR band;mission operation concept;mission overview;system tool kit simulation;STK simulation;LibyaSat-1 ground truck;Murezeq station;Tripoli station;telemetry and command subsystem;data handling subsystem;electrical power subsystem;altitude orbit control subsystem;structure subsystem;low Earth orbit","","1","","7","IEEE","9 Apr 2016","","","IEEE","IEEE Conferences"
"Assessing Radiometric Corrections for UAS Multi-Spectral Imagery in Horticultural Environments","Y. -H. Tu; S. Phinn; K. Johansen; A. Robson",The University of Queensland; The University of Queensland; King Abdullah University of Science and Technology; University of New England,"IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","5449","5452","UAS-based multi-spectral imagery is becoming ubiquitous for monitoring and managing various horticultural crops. To accurately measure and monitor their structure and condition and estimate yields, appropriately corrected data must be used to drive the necessary algorithms. There are several popular radiometric correction methods commonly used for UAS-based data correction. However, their relative and absolute accuracies are not known. This study used three flight datasets, including along- and across-tree-row flight patterns in an avocado orchard. Four correction methods were applied to produce at-surface reflectance image mosaics for each flight pattern as well as the grid pattern and the results were compared to assess the reflectance consistency. Results show that no method provided consistently correct at-surface reflectance for the same features. A BRDF correction workflow was being developed to address these limitations. Preliminary application of the BRDF correction shows that it significantly improves the brightness consistency of features across different images.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517703","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517703","radiometric correction;UAS;multi-spectral imagery;reflectance;BRDF;horticulture","Reflectivity;Cameras;Analysis of variance;Radiometry;Sun;Calibration;Agriculture","crops;geophysical image processing;horticulture;image segmentation;radiometry;vegetation mapping","radiometric corrections;UAS multispectral imagery;horticultural environments;UAS-based multispectral imagery;horticultural crops;UAS-based data correction;relative accuracies;absolute accuracies;flight datasets;across-tree-row flight patterns;at-surface reflectance image mosaics;flight pattern;grid pattern;reflectance consistency;BRDF correction workflow;radiometric correction methods","","","","8","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Random Forest Outperformed Convolutional Neural Networks for Shrub Willow Above Ground Biomass Estimation Using Multi-Spectral UAS Imagery","H. Tamiminia; B. Salehi; M. Mahdianpari; C. M. Beier; D. J. Klimkowski; T. A. Volk","Department of Environmental Resources Engineering, State University of New York College of Environmental Science and Forestry (ESF), NY, USA; Department of Environmental Resources Engineering, State University of New York College of Environmental Science and Forestry (ESF), NY, USA; Department of Electrical and Computer Engineering, C-CORE, Memorial University of Newfoundland, St. John's, NL, Canada; Sustainable Resources Management, State University of New York College of Environmental Science and Forestry (ESF), NY, USA; Sustainable Resources Management, State University of New York College of Environmental Science and Forestry (ESF), NY, USA; Sustainable Resources Management, State University of New York College of Environmental Science and Forestry (ESF), NY, USA","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","8269","8272","Shrub willow is a valuable source of hardwood biomass feedstock which is used for the production of bioenergy, biofuels, and renewable bio-based products. The biomass produced from this short-rotation woody plant can be used for heat and electricity generation. Thus, an accurate estimation of shrub willow above-ground biomass (AGB) is of paramount importance. This paper aimed to estimate shrub willow AGB using multi-spectral unmanned aerial system (UAS) imagery and machine learning techniques. To accomplish this goal, a machine learning model (i.e., random forest (RF)) and a deep learning method (i.e., convolutional neural network (CNN)) were applied to the spectral bands and some vegetation indices over a site in Camillus, NY, US in July 2019. The results demonstrated the superiority of the RF model (RMSE of 1.73 Mg/ha and R2 of 0.95) compared to the CNN (RMSE of 2.69 Mg/ha and R2 of 0.89) technique. Adding vegetation indices to spectral bands and using a convolutional approach for training purposes could significantly improve the modeling efficiency.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553515","USDA NIFA(grant numbers:2018-68005-27925); Honeywell International; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553515","Above-ground biomass;machine learning;deep learning;multi-spectral imagery;UAS","Radio frequency;Deep learning;Training;Biological system modeling;Estimation;Vegetation mapping;Training data","","","","","","16","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Research on Digital Image Scaling Based on Bicubic Filter Algorithm","C. Yun; W. Yan; L. Qi","Beijing Institute of Space Mechanics & Electricity, Key Laboratory of Advanced Optical Remote Sensing Technology, Beijing, China; Beijing Institute of Space Mechanics & Electricity, Key Laboratory of Advanced Optical Remote Sensing Technology, Beijing, China; Beijing Institute of Space Mechanics & Electricity, Key Laboratory of Advanced Optical Remote Sensing Technology, Beijing, China","2018 IEEE 3rd International Conference on Image, Vision and Computing (ICIVC)","18 Oct 2018","2018","","","225","229","As the development of Semiconductors and sensor manufacture technology, to solve the problem of low responsibility in CCD multi-spectral image, in recent years BINNING technique appears on CCD Chip. The analogue binning pixels are simple addition and the part of high frequency information has been lost. In this paper, a new digital pixel binning based on bicubic filtering algorithm is processed. This method can overcome the analog Pixel Binning technology of CCD chip. The digital pixel binning method can preserve high requency information through bicubic filtering algorithm, which can improve the contrast and MTF of the remote sensing image. This algorithm can achieve pixel binning by low computational complexity and also it has the well Real-time Capability for the large-scale remote sensing image.","","978-1-5386-4991-6","10.1109/ICIVC.2018.8492839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8492839","CCD;BINNING;bicubic filter","Interpolation;Signal processing algorithms;Filtering algorithms;Charge coupled devices;Remote sensing;Information filters","CCD image sensors;computational complexity;geophysical image processing;image resolution;interpolation;remote sensing","bicubic filtering algorithm;large-scale remote sensing image;digital image scaling;bicubic filter algorithm;CCD multispectral image;analogue binning pixels;CCD chip;digital pixel binning method;analog pixel binning technology","","2","","5","IEEE","18 Oct 2018","","","IEEE","IEEE Conferences"
"A method integrating GF-1 multi-spectral and modis multi-temporal NDVI data for forest land cover classification","Z. Li; X. Li; E. Chen; S. Li","Institute of Forest Resources Information Technique, Chinese Academy of Forestry; Institute of Forest Resources Information Technique, Chinese Academy of Forestry; Institute of Forest Resources Information Technique, Chinese Academy of Forestry; Institute of Forest Resources Information Technique, Chinese Academy of Forestry","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","3742","3745","In this paper a method was demonstrated that GF-1 multi-spectral and MODIS multi-temporal NDVI data were integrated for forest land cover classification. The test site is located in the central of the Xiaoxing'anling region in Heilongjiang province where covered the area of one scene of GF-1 image. The random forests algorithm was adopted to select the best features automatically which contains spectral, texture and shape features from GF-1 multi-spectral data and phenological features from multi-temporal MODIS NDVI data. A decision tree was used to supervise the classification result. Experimental results show that the overall classification accuracy and Kappa coefficient of the developed method combing multi-sources data can reach 89.46% and 0.874 respectively, with significant improvement compared with that using either GF-1 multi-spectral data or MODIS NDVI time series data alone, especially for the classification of evergreen forest.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729970","GF-1 image;MODIS NDVI data;Random Forest;phenological features;forest land cover classification","MODIS;Remote sensing;Time series analysis;Satellites;Feature extraction;Vegetation mapping;Spatial resolution","decision trees;geophysical image processing;image classification;image texture;land cover;time series;vegetation mapping","forest land cover classification;GF-1 multispectral data;MODIS multitemporal NDVI data;forest land cover classification;test site;Xiaoxinganling region;Heilongjiang province;GF-1 image;random forest algorithm;spectral feature;texture feature;shape feature;multitemporal MODIS NDVI data;decision tree;classification accuracy;Kappa coefficient;multisource data;MODIS NDVI time series data;evergreen forest classification","","1","","6","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Multi Spectral Image Fusion with Deep Convolutional Network","S. Eghbalian; H. Ghassemian","Image processing and Information Analysis Laboratory Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran; Image processing and Information Analysis Laboratory Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran","2018 9th International Symposium on Telecommunications (IST)","7 Mar 2019","2018","","","173","177","A new multispectral image fusion method is proposed, based on deep convolutional neural networks. For pan-sharpening problem, the proposed method utilize the both super-resolution fusion methods and deep convolutional neural network. By the spatial information from the panchromatic (PAN) image the Multi-Spectral (MS) image is enhanced. In the other hand, the proposed method is independent from the number of MS bands because the spatial information directly estimated from PAN image. Experiments on images of the representative database are shown, proposed method can achieve better result competitive with the current well known methods.","","978-1-5386-8274-6","10.1109/ISTEL.2018.8661137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8661137","Multi-spectral;Image fusion;Pansharpening;Convolutional neural networks;Super-resolution","Image fusion;Remote sensing;Spatial resolution;Convolutional neural networks;Transforms;Principal component analysis","convolutional neural nets;image colour analysis;image enhancement;image fusion;image resolution","multispectral image fusion;superresolution fusion methods;multispectral image enhancement;panchromatic image;pan-sharpening problem;deep convolutional neural network;PAN image","","4","","27","IEEE","7 Mar 2019","","","IEEE","IEEE Conferences"
"SMOS RFI mitigation using array factor synthesis of synthetic aperture interferometric radiometry","J. Li; F. Hu; F. He; L. Wu; X. Peng","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","820","823","Radio frequency interference (RFI) is one of the most significant limiting factors in the retrieval of geophysical parameters measured by microwave radiometers. In this work, based on the measured visibilities of European Space Agency's Soil Moisture and Ocean Salinity (SMOS) mission, RFI mitigation results are presented using two approaches of array factor synthesis of synthetic aperture interferometric radiometry, i.e., RFI mitigation based on null control and low sidelobe synthesis. Results show that, for the approach of array factor synthesis with null control, the Gibbs-like contamination of weak and moderate RFIs can be mitigated very well, but it is not enough effective for strong RFIs because of instrument errors. On the other hand, for strong RFIs, at the cost of spatial resolution degradation which may be not critical for ocean salinity retrieval, result shows the approach of low sidelobe synthesis can be effective to mitigate the Gibbs-like contamination of strong RFIs.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729207","Array factor synthesis;microwave radiometry;Radio Frequency Interference (RFI);Soil Moisture and Ocean Salinity (SMOS) mission;aperture synthetic radiometry","Apertures;Microwave radiometry;Radiometers;Geophysical measurements;Pollution measurement;Remote sensing","error analysis;geophysical techniques;Monte Carlo methods;radar interferometry;radiofrequency interference;radiometers;radiometry;remote sensing","SMOS RFI mitigation;array factor synthesis;synthetic aperture interferometric radiometry;radio frequency interference;geophysical parameter;microwave radiometer;European space agency;soil moisture-and-ocean salinity mission;RFI mitigation;synthetic aperture interferometric radiometry;sidelobe synthesis;Gibbs-like contamination;spatial resolution degradation","","2","","12","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Unrolled Projected Gradient Descent for Multi-spectral Image Fusion","S. Lohit; D. Liu; H. Mansour; P. T. Boufounos","Arizona State University, Tempe, AZ, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","7725","7729","In this paper, we consider the problem of fusing low spatial resolution multi-spectral (MS) aerial images with their associated high spatial resolution panchromatic image. To solve this problem, various methods have been proposed, using either model-based or model-agnostic algorithms such as deep learning techniques. In this paper, we aim to utilize more interpretable architectures to solve the MS fusion problem by integrating existing ideas from image processing with deep learning. In particular, we develop a signal processing-inspired learning solution, where we unroll the iterations of the projected gradient descent (PGD) algorithm, and each iteration contains a projection operation carried out by a deep convolutional neural network. We observe that our proposed method provides a new perspective on existing deep-learning solutions, and under certain circumstance it reduces to current black-box deep learning methods. Our extensive experimental results show significant improvements of the proposed approach over several baselines.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683124","multi-spectral image fusion;deep learning;projected gradient descent","Deep learning;Image fusion;Spatial resolution;Signal processing algorithms;Imaging;Inverse problems","convolutional neural nets;geophysical image processing;gradient methods;image fusion;image resolution;learning (artificial intelligence);remote sensing","unrolled projected gradient descent;model-agnostic algorithms;deep learning techniques;MS fusion problem;image processing;signal processing-inspired learning solution;iteration;projected gradient descent algorithm;projection operation;deep convolutional neural network;black-box deep learning methods;high spatial resolution panchromatic image;low spatial resolution multispectral aerial image fusion;model-based algorithms","","11","","17","IEEE","17 Apr 2019","","","IEEE","IEEE Conferences"
"Object-based urban land cover mapping using high-resolution airborne imagery and LiDAR data","Q. Li; L. Lu; H. Jiang; J. Huang; Z. Liu","Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; School of Architectural and Surveying & Mapping, Engineeringt Jiangxi University of Science and Technology, Ganzhou, Jiang Xi, China; School of Architectural and Surveying & Mapping, Engineeringt Jiangxi University of Science and Technology, Ganzhou, Jiang Xi, China","2018 Fifth International Workshop on Earth Observation and Remote Sensing Applications (EORSA)","3 Jan 2019","2018","","","1","5","Urban land cover information is important for a number of applications. In recent years, the availability of airborne light detection and ranging (LiDAR) and high spatial resolution (HSR) imagery makes it possible to generate land cover information at fine scales. In this study, we proposed an object-based image analysis (OBIA) method to derive 1m resolution land cover classification from airborne LiDAR and multi-spectral image data. A series of rules were developed for identifying 7 land cover features (low impervious cover, buildings, shrub/tree, grass, soil/rock, rivers/lakes, and swimming pool). Experiments were performed in two sites in Richland County, South Carolina, USA. The classification results yielded an overall accuracy of 92.23% and a kappa coefficient of 0.8996. Confusion occurs between soil/rock and grass land and low impervious surface due to their spectral similarity. The algorithm shows promise for large-area classification in forested urban landscapes with similar datasets.","","978-1-5386-6642-5","10.1109/EORSA.2018.8598566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598566","urban land cover;LiDAR;high spatial resolution;classification;OBIA","Laser radar;Remote sensing;Land surface;Vegetation mapping;Radiometry;Soil;Image resolution","geophysical image processing;image classification;image resolution;land cover;optical radar;remote sensing by laser beam;terrain mapping;vegetation","high-resolution airborne imagery;urban land cover information;high spatial resolution imagery;object-based image analysis method;multispectral image data;grass land;forested urban landscapes;land cover classification;airborne LiDAR data;land cover features;airborne light detection-and-ranging;soil;object-based urban land cover mapping;OBIA method;buildings;rivers;shrub;lakes;tree;rock;Richland County;South Carolina;USA","","1","","27","IEEE","3 Jan 2019","","","IEEE","IEEE Conferences"
"Remote sensing image data fusion using spatial PCA and average block-DCT","A. Saboori; J. Birjandtalab","Islamic Azad University, Tehran, Tehran, IR; University of Texas at Dallas, Richardson, TX, US","2016 10th International Conference on Signal Processing and Communication Systems (ICSPCS)","6 Feb 2017","2016","","","1","7","Recently, with rapid development of imaging technology, there is a need for integrating images from different sources and extracting useful information. Remote sensing provides high quality multi-spectral and panchromatic images in terms of spectral and spatial information, respectively. So it is quite important to develop robust techniques to integrate images of the same scene with different characteristics in order to extract maximum spectral and spatial information. In this work, we provide a novel image fusion technique by combining block Discrete Cosine Transform (DCT) and spatial Principal Component Analysis (PCA) to improve the spectral quality of multi-spectral images while preserving the spatial resolution. We compare our technique with existing image fusion methods using different quality measures. The experimental results show that block-DCT based image fusion visually and quantitatively outperforms other techniques in terms of preserving spectral quality.","","978-1-5090-0941-1","10.1109/ICSPCS.2016.7843352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7843352","","Principal component analysis;Spatial resolution;Image fusion;Discrete cosine transforms;Remote sensing;Satellites","discrete cosine transforms;image fusion;principal component analysis;remote sensing","remote sensing image data fusion;spatial PCA;average block-DCT;quality multispectral images;panchromatic images;spectral information;spatial information;discrete cosine transform;principal component analysis;spectral quality;spatial resolution","","1","","19","IEEE","6 Feb 2017","","","IEEE","IEEE Conferences"
"Optical Design of a Multi-Spectral Imager for LWIR","S. M. Neverov","Scientific and Technological Center of Unique Instrumentation of the Russian Academy of Sciences, Moscow, Russia","2020 Wave Electronics and its Application in Information and Telecommunication Systems (WECONF)","2 Jul 2020","2020","","","1","4","The task of this study was to create an optical system that creates an image on 16 separate sectors of a bolometric detector. The aberration of the far-infrared multispectral camera has been minimized. We developed a layout of a multi-spectral camera in the range of 8-12 microns that provides sufficiently high quality of spectral images in the entire range. Aberrations are minimized in the ZEMAX program using the procedure for optimizing the geometric parameters of the optical elements of the circuit.","","978-1-7281-4944-8","10.1109/WECONF48837.2020.9131151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9131151","multi-spectral camera;bolometric detector;remote sensing;gas leak;LWIR","Visualization;Optical design;Wearable computers;Production;Cameras;Optical imaging;Geometrical optics","aberrations;bolometers;cameras;image sensors;infrared imaging;optical design techniques","optical system;bolometric detector;aberration;far-infrared multispectral camera;optical elements;optical design;multispectral imager;LWIR;ZEMAX program;wavelength 8.0 micron to 12.0 micron","","","","8","IEEE","2 Jul 2020","","","IEEE","IEEE Conferences"
"Machine Learning in Indian Crop Classification of Temporal Multi-Spectral Satellite Image","R. Koppaka; T. -S. Moh","Department of Computer Science, San José State University, San José, CA, USA; Department of Computer Science, San José State University, San José, CA, USA","2020 14th International Conference on Ubiquitous Information Management and Communication (IMCOM)","20 Feb 2020","2020","","","1","8","Recently, there has been a remarkable growth in Artificial Intelligence (AI) with the development of efficient AI models and high-power computational resources for processing complex datasets. There have been a growing number of applications of machine learning in satellite remote sensing image data processing. In India, agriculture has a huge impact on the national economy and most of the critical decisions are dependent on agricultural statistics. In this work, machine learning models have been applied for crop classification of Sentinel-2 satellite temporal remote sensing image data. Guntur district region of Andhra Pradesh, India has been used as the study area. The main reasons for selecting this region are the diversity of agricultural crops and the availability of ground truth. The performance of machine learning models Support Vector Machine (SVM), Random Forest (RF), Convolution Neural Network (CNN), Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM) and RNN with Gated Recurrent Unit (GRU) have been evaluated for crop classification. Classification accuracies are generally evaluated by using test data. In most cases the classification accuracy from test data is not commensurate to estimated crop areas from the classified image. Such methods limit the estimated crop areas acceptance for official purposes. The uniqueness of this work is the classification accuracy is evaluated by estimated crop areas. The results show that SVM has the best F1 score of 0.99 and estimated major crop areas have 95.9% agreement with the ground surveyed crop area.","","978-1-7281-5453-4","10.1109/IMCOM48794.2020.9001718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9001718","Artificial Intelligence;classification;crop-wise area statistics;remote sensing;and multi-spectral satellite image","Agriculture;Machine learning;Remote sensing;Satellites;Vegetation mapping;Support vector machines;Training data","convolutional neural nets;crops;geophysical image processing;image classification;learning (artificial intelligence);recurrent neural nets;statistical analysis;support vector machines;vegetation mapping","national economy;critical decisions;agricultural statistics;Sentinel-2 satellite temporal remote sensing image data;agricultural crops;machine learning models;recurrent neural network;long short-term memory;gated recurrent unit;ground surveyed crop area;temporal multispectral satellite image;artificial intelligence;efficient AI models;high-power computational resources;support vector machine;satellite remote sensing image data processing;Guntur district region;convolution neural network;Indian crop classification;SVM","","3","","33","IEEE","20 Feb 2020","","","IEEE","IEEE Conferences"
"Eutrophication Analysis of Water Reservoirs by Remote Sensing and Neural Networks","H. A. Nascimento Silva; M. Panella","Department of Information Engineering, Electronics and Telecommunications, University of Rome “La Sapienza”, Rome, Italy; Department of Information Engineering, Electronics and Telecommunications, University of Rome “La Sapienza”, Rome, Italy","2018 Progress in Electromagnetics Research Symposium (PIERS-Toyama)","3 Jan 2019","2018","","","458","463","Algal blooms of the water are an important variable for the analysis of freshwater ecosystems, which are relevant not only for human populations but also for plant and animal diversity. Monitoring algal blooms from space allows for a continuous and automatic control without the necessity of water sampling and human intervention. However, it is a very challenging task, which becomes particularly difficult when dealing with cyanobacteria blooms. Water limnology, satellite imagery and neural networks can be used as an ensemble of remote sensing and machine learning technologies in order to estimate the concentration of algal blooms from space. This paper describes empirical algorithms to this end, which incorporate information from the multi-spectral instrument of Sentinel-2 satellite. This approach is applied to the Cefni Reservoir (Anglesey, U.K.), by using spatial and temporal scales. Algae estimation is accomplished using different types of neural and fuzzy neural networks and the experimental results are very accurate, therefore proving the reliability and accuracy of the proposed approach for monitoring water reservoirs by using remote sensing and neural networks tools.","1559-9450","978-4-8855-2316-8","10.23919/PIERS.2018.8597731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8597731","","Reservoirs;Biological system modeling;Remote sensing;Predictive models;Neural networks;Satellites","ecology;environmental monitoring (geophysics);fuzzy neural nets;geophysical image processing;learning (artificial intelligence);microorganisms;remote sensing;reservoirs;water pollution measurement;water quality","eutrophication analysis;remote sensing;freshwater ecosystems;human populations;plant;animal diversity;water sampling;cyanobacteria blooms;water limnology;satellite imagery;machine learning technologies;multispectral instrument;Sentinel-2 satellite;Cefni Reservoir;fuzzy neural networks;neural networks tools;algal bloom monitoring;water reservoir monitoring;Anglesey","","3","","17","","3 Jan 2019","","","IEEE","IEEE Conferences"
"Sea Snots in the Marmara Sea as Observed From Medium-Resolution Satellites","C. Hu","College of Marine Science, University of South Florida, St. Petersburg, FL, USA","IEEE Geoscience and Remote Sensing Letters","24 May 2022","2022","19","","1","5","Multisensor medium-resolution satellite images from Moderate Resolution Imaging Spectroradiometer (MODIS), Visible Infrared Imaging Radiometer Suite (VIIRS), Ocean and Land Color Imager (OLCI), and Medium Resolution Imaging Spectrometer (MERIS) are used to study spatial and temporal distributions of sea snot features in the Marmara Sea between 2000 and 2021. Suspicious image slicks are identified in most years, and spectral diagnostics indicate sea snot features in 2007, 2008, and 2021, with the record-high sea snot event occurring in spring–summer 2021. In other years, when similar image slicks are found, they appear to be from surface scums of red Noctiluca scintillans, a heterotrophic dinoflagellate responsible for red tides. Based on the medium-resolution images, the 2021 sea snot event started from March 14 and ended on June 27, with its peak time around May 4 when the sea snot features are found in the entire Marmara Sea covering an area of 1160 km2. When all sea snots are aggregated together, the estimated areal coverage during the peak time is 50 km2, suggesting significant patchiness in the surface scums.","1558-0571","","10.1109/LGRS.2022.3173997","U.S. NASA(grant numbers:80NSSC20M0264,80NSSC21K0422); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771415","Floating matters;marine debris;marine mucilage;Marmara Sea;Medium Resolution Imaging Spectrometer (MERIS);Moderate Resolution Imaging Spectroradiometer (MODIS);Multi-Spectral Instrument (MSI);Ocean and Land Color Imager (OLCI);plastics;remote sensing;sea snot;Visible Infrared Imaging Radiometer Suite (VIIRS)","MODIS;Sea surface;Spectral shape;Satellites;Image resolution;Ocean temperature;Time series analysis","infrared imaging;oceanographic regions;oceanographic techniques;oceanography;radiometers;remote sensing;tides","spring-summer 2021;similar image slicks;medium-resolution images;sea snot features;entire Marmara Sea;sea snots;Medium-Resolution satellites;multisensor medium-resolution satellite images;Moderate Resolution Imaging Spectroradiometer;Medium Resolution Imaging Spectrometer;spatial distributions;temporal distributions;suspicious image slicks;record-high sea","","2","","25","IEEE","10 May 2022","","","IEEE","IEEE Journals"
"Building Extraction from Remote Sensing Images: A Survey","Shaloni; M. Dixit; S. Agarwal; P. Gupta","Department of Compute Science & Engineering, Galgotias college of Engineering & Technology, Greater Noida, India; Department of Compute Science & Engineering, Galgotias college of Engineering & Technology, Greater Noida, India; Department of Compute Science & Engineering, Galgotias college of Engineering & Technology, Greater Noida, India; Department of Compute Science & Engineering, Galgotias college of Engineering & Technology, Greater Noida, India","2020 2nd International Conference on Advances in Computing, Communication Control and Networking (ICACCCN)","1 Mar 2021","2020","","","966","971","The extraction of building structures with the help of remote sensing pictures is an open analysis space in digital photogrammetry. The automated extraction of buildings has been a vital space of analysis in remote sensing. it's been tributary to numerous applications akin to land-use land cowl mapping, urban planning, disaster management, and lots of different socio-economic activities. This work does the surveys of assorted ways that are developed for automatic extraction of building from completely different information sources like aerial pictures, digital surface/elevation models, LIDAR data, multi-spectral pictures, artificial aperture measuring system pictures. Here, we have done a thorough literature survey on previous various works done in this area which identifies the various datasets that are used for remote sensing images analysis, key methodologies, and various evaluation metrics used for the extraction of buildings from remote sensing imagery used. Apart from this, the challenges that are still existing in this area are mentioned. Overall, this paper gives a quick introduction and existing challenges in the field of extraction of buildings with the help of remote sensing images.","","978-1-7281-8337-4","10.1109/ICACCCN51052.2020.9362894","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9362894","Building Extraction;Remote Sensing Images;Deep learning;Survey;Challenges","Measurement;Laser radar;Image analysis;Buildings;Urban planning;Sensors;Remote sensing","feature extraction;geophysical image processing;optical radar;photogrammetry;remote sensing;town and country planning","building extraction;remote sensing pictures;open analysis space;digital photogrammetry;automated extraction;buildings;land-use land cowl mapping;different socio-economic activities;automatic extraction;completely different information sources;aerial pictures;multispectral pictures;system pictures;remote sensing images analysis;remote sensing imagery","","","","17","IEEE","1 Mar 2021","","","IEEE","IEEE Conferences"
"Miniature K-Band Radar for Agricultural Remote Sensing","G. Peterson","Electrical and Computer Engineering, Kansas State University, Manhattan, United States","2021 IEEE 21st Annual Wireless and Microwave Technology Conference (WAMICON)","3 Jun 2021","2021","","","1","4","Remote sensing for agricultural applications employs multi-spectral data collection. While optical-wavelength normalized difference vegetation index (NDVI) is the most common, smart agriculture can benefit from the addition of longer wavelengths to the sensing techniques. A radar operating in the 12.5 cm band (23 to 25 GHz spectrum) is described. The design leverages low-cost commercial ICs and coherent calibration cancellation techniques to sense at standoff distances as short as 10 cm, while providing a small size, weight, and power (SWaP) solution suitable for a variety of platforms. Field trials are overviewed on crops ranging from soybean to grain sorghum validating the ability to measure crop height and structure with high spatial resolution.","","978-1-7281-5176-2","10.1109/WAMICON47156.2021.9443626","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9443626","radar;sensing;agriculture;short-range;FMCW;CWFM;SFCW;CCC","Wireless communication;Radar remote sensing;Wireless sensor networks;Microwave technology;Vegetation mapping;Radar;Agriculture","agriculture;calibration;crops;geophysical image processing;remote sensing;vegetation;vegetation mapping","miniature k-band radar;agricultural remote sensing;agricultural applications;multispectral data collection;optical-wavelength normalized difference vegetation index;NDVI;smart agriculture;sensing techniques;design leverages low-cost commercial ICs;coherent calibration cancellation techniques;frequency 23.0 GHz to 25.0 GHz","","1","","9","IEEE","3 Jun 2021","","","IEEE","IEEE Conferences"
"Auto-extraction method of farmland irrigation and drainage system based on domestic high-resolution satellite images","W. Zhang; Z. Zhang; Z. Huang","School of remote sensing and information engineering, Wuhan University, Wuhan, China; School of remote sensing and information engineering, Wuhan University, Wuhan, China; School of remote sensing and information engineering, Wuhan University, Wuhan, China","2016 Fifth International Conference on Agro-Geoinformatics (Agro-Geoinformatics)","29 Sep 2016","2016","","","1","6","Farmland irrigation and drainage system is one of the key hydraulic engineering facilities on farmland, large-scale, fast and accurate auto-extraction method for farmland irrigation and drainage system is a significant direction for remote sensing application. This paper proposes an intelligent extraction method for farmland irrigation and drainage system based on domestic high resolution satellite GF-2 images, which has considered both spectral features and geometry features of farmland irrigation and drainage system, and could be divided into four parts as: image scale converting, spectral model for canal identification, data extraction by spatial features and breakpoint connecting with morphology. The first step is to fuse the 1 meter panchromatic image and 4 meter multi-spectral image by Nearest Neighbor Diffusion pan sharpening algorithm that will output a high resolution multi-spectral image in 1meter. Then, construct a model of spectral relationship by red, green, blue and NIR (Near Infrared Reflection) bands, which will extract irrigation canals initially from images. Then, in order to distinguish roads with irrigation canals, we need to analyze the spatial features of them and design spatial rules to separate these two targets. The last problem is that there would be many disconnected irrigation channels as limited by the resolution of remote sensing images, the mathematical morphology method would be used for judging the topological relationships between breakpoints, which will be connected by dilation operators. This paper chose the Sanhulianjiang reservoir irrigation area to be experimental area, which is located in Hubei's Jiayu County. The main irrigation and drainage facilities in experimental area have been extracted through our method, and are contrasted to the water resource survey data. The comparison shows the accuracy of this method is credible; it could satisfy the needs as large-scale, fast extraction for irrigation and drainage system, which has huge potential in agriculture and water conservancy fields.","","978-1-5090-2350-9","10.1109/Agro-Geoinformatics.2016.7577606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577606","auto-extraction;farmland irrigation and drainage system;Canal Enhancement Index;GF-2;remote sensing","Irrigation;Feature extraction;Spatial resolution;Roads;Data mining;Remote sensing","agriculture;feature extraction;image resolution;irrigation;vegetation mapping","image autoextraction method;farmland irrigation;drainage system;domestic high resolution satellite images;multispectral image;Nearest Neighbor Diffusion;remote sensing;Hubei Jiayu county","","3","","10","IEEE","29 Sep 2016","","","IEEE","IEEE Conferences"
"Automatic change detection of urban land-cover based on SVM classification","W. Li; M. Lu; X. Chen","Institute of Remote Sensing and Geographical Information System, Peking University, Beijing, China; School of Remote Sensing & Information Engineering, Wuhan University, Wuhan, China; Institute of Remote Sensing and Geographical Information System, Peking University, Beijing, China","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","1686","1689","The reliability of support vector machines for classifying multi-spectral images of remote sensing has been proven in various studies. In this paper, we investigate their applicability for urban land cover in Wuhan, Hubei province of China. Firstly, radiation rectification, normalization processing and geometry registration are made between the bi-temporal images. Secondly, SVM approach is used in our study to classify sorts and land use types from bi-temporal images. Thirdly, build matrix of change detection in basis of the potential types of change. Post-classification compare are proposed pixel-by-pixel. According to the sort of change of every pixel, new value is assigned on the base of change matrix. The output is image of change. Lastly, the process and pattern of the urban land use change in the Wuhan district was finally revealed from 2009 to 2013 in our study.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326111","SVM;change detection;classification;matrix of change","Remote sensing;Support vector machines;Urban areas;Accuracy;Rivers;Kernel;Satellites","geophysical image processing;land cover;land use;land use planning;support vector machines","automatic change detection;urban land-cover;SVM classification;support vector machines;multispectral images;remote sensing;Wuhan district;Hubei province;China;geometry registration;radiation rectification;normalization processing;bitemporal images;urban land use;AD 2009 to 2013","","5","","12","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"UCDNet: A Deep Learning Model for Urban Change Detection From Bi-Temporal Multispectral Sentinel-2 Satellite Images","K. S. Basavaraju; N. Sravya; S. Lal; J. Nalini; C. S. Reddy; F. Dell’Acqua","Department of Electronics and Communication Engineering, National Institute of Technology Karnataka, Mangaluru, India; Department of Electronics and Communication Engineering, National Institute of Technology Karnataka, Mangaluru, India; Department of Electronics and Communication Engineering, National Institute of Technology Karnataka, Mangaluru, India; Aerial Services and Digital Mapping, National Remote Sensing Centre, Indian Space Research Organisation, Balanagar, Hyderabad, India; Forest Biodiversity and Ecology Division, National Remote Sensing Centre, Indian Space Research Organisation, Balanagar, Hyderabad, India; Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy","IEEE Transactions on Geoscience and Remote Sensing","12 Apr 2022","2022","60","","1","10","Change detection (CD) from satellite images has become an inevitable process in earth observation. Methods for detecting changes in multi-temporal satellite images are very useful tools when characterization and monitoring of urban growth patterns is concerned. Increasing worldwide availability of multispectral images with a high revisit frequency opened up more possibilities in the study of urban CD. Even though there exists several deep learning methods for CD, most of these available methods fail to predict the edges and preserve the shape of the changed area from multispectral images. This article introduces a deep learning model called urban CD network (UCDNet) for urban CD from bi-temporal multispectral Sentinel-2 satellite images. The model is based on an encoder–decoder architecture which uses modified residual connections and the new spatial pyramid pooling (NSPP) block, giving better predictions while preserving the shape of changed areas. The modified residual connections help locate the changes correctly, and the NSPP block can extract multiscale features and will give awareness about global context. UCDNet uses a proposed loss function which is a combination of weighted class categorical cross-entropy (WCCE) and modified Kappa loss. The Onera Satellite Change Detection (OSCD) dataset is used to train, evaluate, and compare the proposed model with the benchmark models. UCDNet gives better results from the reference models used here for comparison. It gives an accuracy of 99.3%, an  $F1$  score ( $F1$ ) of 89.21%, a Kappa coefficient (Ka) of 88.85%, and a Jaccard index (JI) of 80.53% on the OSCD dataset.","1558-0644","","10.1109/TGRS.2022.3161337","RESPOND Scheme of Indian Space Research Organization (ISRO), Government of India (December 30, 2019)(grant numbers:ISRO/RES/4/683/19-20); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9740122","Change detection (CD);deep learning;multi-spectral satellite images;spatial pyramid pooling (SPP)","Feature extraction;Convolution;Satellites;Remote sensing;Deep learning;Streaming media;Shape","deep learning (artificial intelligence);entropy;feature extraction;geophysical image processing;image classification;image segmentation;object detection;remote sensing;town and country planning","JI;Jaccard index;Kappa coefficient;OSCD dataset;F1 score;Onera satellite change detection dataset;modified Kappa loss;WCCE;weighted class categorical cross-entropy;NSPP block;new spatial pyramid pooling block;encoder-decoder architecture;earth observation;urban change detection;modified residual connections;bi-temporal multispectral Sentinel-2 satellite images;UCDNet;urban CD network;deep learning model;multitemporal satellite images","","1","","55","IEEE","23 Mar 2022","","","IEEE","IEEE Journals"
"Antenna array optimaization for mirrored aperture synthesis with autocorrelation","H. Dou; Q. Li; K. Chen; G. Li; G. Zhao; C. Ye","Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","2024","2027","Mirrored aperture synthesis (MAS) can improve spatial resolution compared with conventional aperture synthesis (AS). In this paper, for 1D MAS and 2D MAS, the array optimization models with the autocorrelation are established. The optimal array configurations based on the models are presented. The simulation results demonstrate that the optimal array configurations have good performance in imaging and can achieve higher spatial resolution than other MAS array configurations with the same antenna number.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729522","Array configuration;mirrored aperture synthesis (MAS);autocorrelation","Antenna arrays;Correlation;Apertures;Reflector antennas;Two dimensional displays;Spatial resolution;Radiometers","aperture antennas;optimisation;reflectarray antennas","antenna array optimization;mirrored aperture synthesis;autocorrelation;spatial resolution improvement;1D MAS;2D MAS;optimal array configuration","","5","","12","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"An improved method of compensating the mutual coupling effect for aperture synthesis radiometers","H. Lu; Q. Li; W. Zheng; Y. Li; Q. Zhang; Y. Li; Y. Yuan","Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","414","417","In aperture synthesis radiometers (ASRs), the mutual coupling effect between antennas is a key problem, which degrades the performance of ASRs and should be compensated. In this paper, an improved compensation method is proposed for ASRs, which is based on the receiving mutual impedance. The proposed method is verified by a one-dimension 5-channel L-band ASR. The experimental results show that the proposed method is superior over the existing method based on the transmitting mutual impedance, and is more appropriate to compensate the mutual coupling effect for ASRs.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729102","Aperture synthesis radiometers;mutual impedance;compensate;receiving mode","Mutual coupling;Antenna measurements;Antenna arrays;Receiving antennas;Impedance;Aperture antennas","aperture antennas;radiometers","mutual coupling effect compensation;aperture synthesis radiometers;receiving mutual impedance;improved compensation method;ASR;one-dimension 5-channel L-band ASR;antennas","","","","10","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Wavelet-based 1/f-Noise elimination in millimeter-wave radiometer","M. Huang; L. Gui; M. Liu; Y. Cheng; L. Lang; F. Hu","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","2897","2900","The output signal of millimeter-wave (MMW) radiometer is usually affected by 1/f-noise that is characterized by self-similarity and non-stationary. Wavelet thresholding techniques are widely used to de-noise. However, soft-thresholding has good de-noising effect but is poor in details preservation, and hard-thresholding is good in details preservation but has poor de-noising effect. To eliminate 1/f-noise from white Gauss noise (WGN), an improved thresholding function is introduced in this paper. This method overcomes the permanent bias in soft-thresholding and the discontinuous point in hard-thresholding. Additionally, a least square estimation (LSE) is introduced to estimate 1/f-type parameters. Simulations and experiments have been carried out to validate this method.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729748","1/f-noise elimination;thresholding;wavelet;least square estimation (LSE);MMW radiometer","Noise reduction;Estimation;Wavelet transforms;Microwave radiometry;Millimeter wave technology","geophysical techniques","noise elimination;millimeter-wave radiometer;wavelet thresholding techniques;de-noising effect;white Gauss noise;thresholding function;least square estimation","","","","10","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Maximum-Rank Arrays for Two-Dimensional Mirrored Aperture Synthesis","H. Dou; K. Chen; Q. Li; Y. Wu; Z. Lei","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","24 Feb 2021","2021","18","3","499","503","In 2-D mirrored aperture synthesis (2-D MAS), the array configuration determines the rank of the transformation matrix, which can affect the accuracy of the solved cosine visibilities. Ultimately, errors in solved cosine visibilities degrade the quality of reconstructed brightness temperature images. In this letter, the maximum rank of the transformation matrix is analyzed and proven by mathematical induction. An array optimization model of 2-D MAS based on the “maximum-rank” criterion is established, and optimal arrays are presented. Finally, the simulations and experiments are carried out to demonstrate the effectiveness of the optimization model.","1558-0571","","10.1109/LGRS.2020.2978013","National Key Research and Development Program of China(grant numbers:2016YFC1401005); Fundamental Research Funds for the Central Universities(grant numbers:2016JCTD203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9057433","Array design;mirrored aperture synthesis (MAS);rank deficiency","Correlation;Mathematical model;Antenna arrays;Optimization;Apertures;Brightness temperature;Image reconstruction","calibration;geophysical equipment;image reconstruction;matrix algebra;optimisation;radiometers;radiometry","maximum-rank arrays;two-dimensional mirrored aperture synthesis;2-D mirrored aperture synthesis;2-D MAS;array configuration;transformation matrix;solved cosine visibilities;reconstructed brightness temperature images;maximum rank;array optimization model;maximum-rank criterion;optimal arrays","","4","","8","IEEE","6 Apr 2020","","","IEEE","IEEE Journals"
"Initial Results of H-Matrix Reconstruction Method for 1-D Mirrored Aperture Synthesis Radiometers","Y. Li; Q. Li; K. Chen; L. Gui; L. Feng; Z. Lei","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Hubei Collaborative Innovation Center for High Efficiency Utilization of Solar Energy, Hubei University of Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","30 Dec 2021","2022","19","","1","5","The mirrored aperture synthesis radiometer (MASR) has been proposed for high-resolution observation in recent years. Since the MASR is a kind of linear system, the matrix reconstruction method should be an alternative for image reconstruction of a practical MASR. However, the matrix reconstruction method is neither theoretically analyzed nor experimentally validated at present, and the performance of the matrix reconstruction method for a MASR in practical applications is still unknown. In this letter, the H-matrix reconstruction method including the truncated singular value decomposition (SVD) and Tikhonov regularization, not yet applied to a MASR, is introduced. Then, the numerical simulations and imaging experiments are performed to validate the presented method, and the performance of the presented method is also shown. Finally, the comparisons between the presented method and the cosine-transform-based iterative method are made in the view of imaging experiments. The H-matrix reconstruction method is more convenient in the situation of a small MASR with a small alias-free field of view (FOV).","1558-0571","","10.1109/LGRS.2020.3046003","China Postdoctoral Science Foundation(grant numbers:2018M642812); National Natural Science Foundation of China(grant numbers:61771213,41601399); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9337895","Mirrored aperture synthesis radiometer (MASR);reconstruction method;tikhonov regularization;truncated singular value decomposition (TSVD)","Antenna arrays;Image reconstruction;Reconstruction algorithms;Matrix decomposition;Numerical simulation;Imaging;Apertures","geophysical image processing;image reconstruction;iterative methods;radiometers;singular value decomposition","H-matrix reconstruction method;aperture synthesis radiometers;image reconstruction;practical MASR;1D mirrored aperture synthesis radiometer;linear system;truncated singular value decomposition;Tikhonov regularization;numerical simulation;cosine-transform-based iterative method;alias-free field of view","","2","","8","IEEE","28 Jan 2021","","","IEEE","IEEE Journals"
"Channel Compressive Aperture Synthesis","T. Zheng; F. Hu; H. Hu; P. Fu","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","21 May 2020","2020","17","6","1027","1031","Aperture synthesis (AS) passive imaging technique has been proven effective in remote sensing for high resolution. Generally, a synthetic aperture radiometer needs the same number of channels as the antennas. As a consequence, the system complexity, volume, and cost increase rapidly as the size of the array expands. In this letter, the channel compressive AS (CCAS) method is proposed to reduce the receiver channels and correlators. Every channel connects to several different antennas by a selected connection network, and the visibilities are rebuilt from the cross correlation between output signals of the channels. Also, the principles of choosing connection network are discussed to guarantee the performance of the reconstructed brightness temperature (BT) images. Simulation results have shown the validation of the proposed method. It is of great application potential for very large-scale array in the future.","1558-0571","","10.1109/LGRS.2019.2937984","National Natural Science Foundation of China(grant numbers:61871438); China International Joint Research Center of Green Communications and Networking(grant numbers:2015B01008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848489","Channel compressive;connection network;synthetic aperture radiometer","Correlation;Apertures;Microwave radiometry;Antenna arrays;Image reconstruction;Redundancy","geophysical equipment;image reconstruction;radar interferometry;radiometers;radiometry;remote sensing;synthetic aperture radar","receiver channels;antennas;cross correlation;reconstructed brightness temperature images;channel compressive aperture synthesis;passive imaging technique;remote sensing;synthetic aperture radiometer","","4","","11","IEEE","25 Sep 2019","","","IEEE","IEEE Journals"
"Multispectral Misregistration of Sentinel-2A Images: Analysis and Implications for Potential Applications","S. Skakun; E. Vermote; J. -C. Roger; C. Justice","Department of Geographical Sciences, University of Maryland, College Park, MD, USA; NASA Goddard Space Flight Center, Terrestrial Information Systems Laboratory (Code 619), Greenbelt, MD, USA; Department of Geographical Sciences, University of Maryland, College Park, MD, USA; Department of Geographical Sciences, University of Maryland, College Park, MD, USA","IEEE Geoscience and Remote Sensing Letters","4 Dec 2017","2017","14","12","2408","2412","This letter aims at analyzing subpixel misregistration between multispectral images acquired by the Multi Spectral Instrument (MSI) aboard Sentinel-2A remote sensing satellite, and exploring its potential for moving target and cloud detection. By virtue of its hardware design, MSI's detectors exhibit a parallax angle that leads to subpixel shifts that are corrected with special preprocessing routines. However, these routines do not correct shifts for moving and/or high-altitude objects. In this letter, we apply a phase correlation approach to detect subpixel shifts between B2 (blue), B3 (green), and B4 (red) Sentinel-2A/MSI images. We show that shifts of more than 1.1 pixels can be observed for moving targets, such as airplanes and clouds, and can be used for cloud detection. We demonstrate that the proposed approach can detect clouds that are not identified in the built-in cloud mask provided within the Sentinel-2A Level-1C product.","1558-0571","","10.1109/LGRS.2017.2766448","National Aeronautics and Space Administration through “Support for the Harmonized Landsat-Sentinel-2 Project”(grant numbers:NNX16AN88G); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8103334","Cloud detection;moving target;multispectral misregistration;phase correlation;Sentinel-2;subpixel","Correlation;Spatial resolution;Clouds;Airplanes;Remote sensing;Satellites","clouds;geophysical image processing;geophysical signal processing;image registration;image sensors;remote sensing","special preprocessing routines;high-altitude objects;phase correlation approach;subpixel shifts;B4 Sentinel-2A/MSI;moving target;clouds;cloud detection;cloud mask;Sentinel-2A Level-1C product;multispectral misregistration;subpixel misregistration;multispectral images;MultiSpectral Instrument aboard Sentinel-2A;remote sensing satellite;hardware design;parallax angle;MSIs detectors","","19","","20","IEEE","10 Nov 2017","","","IEEE","IEEE Journals"
"Efficient Airport Detection Using Line Segment Detector and Fisher Vector Representation","Ü. Budak; U. Halıcı; A. Şengür; M. Karabatak; Y. Xiao","Department of Electrical and Electronics Engineering, Bitlis Eren University, Bitlis, Turkey; Department of Electrical and Electronics Engineering, Middle East Technical University, Ankara, Turkey; Technology Faculty, Firat University, Elaziğ, Turkey; Technology Faculty, Firat University, Elaziğ, Turkey; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","20 Jul 2016","2016","13","8","1079","1083","In this letter, a two-stage method for airport detection on remote sensing images is proposed. In the first stage, a new algorithm composed of several line-based processing steps is used for extraction of candidate airport regions. In the second stage, the scale-invariant feature transformation and Fisher vector coding are used for efficient representation of the airport and nonairport regions and support vector machines employed for classification. In order to evaluate the performance of the proposed method, extensive experiments are conducted on airports around the world with different layouts. The measures used in the evaluation are accuracy, sensitivity, and specificity. The proposed method achieved an accuracy of 94.6%, which was benchmarked with two previous methods to prove its superiority.","1558-0571","","10.1109/LGRS.2016.2565706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7480830","Airport detection;Fisher vector (FV);line segment detector (LSD);remote sensing images (RSIs);scale-invariant feature transform (SIFT) features;support vector machines (SVMs)","Airports;Feature extraction;Image segmentation;Support vector machines;Encoding;Atmospheric modeling;Detectors","feature extraction;geophysical image processing;image representation;support vector machines;terrain mapping","airport detection;line segment detector;fisher vector representation;remote sensing image;line-based processing step;support vector machine;nonairport region;airport regions;scale-invariant feature transformation;Fisher vector coding","","40","","17","IEEE","30 May 2016","","","IEEE","IEEE Journals"
"UFN-GAN: An unsupervised generative adversarial network for remote sensing image fusion","H. Dai; X. Liu; Y. Qiao; K. Zheng; X. Xiao; Z. Cai","School of Automation China, University of Geosciences, Whuhan, China; School of Automation China, University of Geosciences, Whuhan, China; School of Automation China, University of Geosciences, Whuhan, China; School of Automation China, University of Geosciences, Whuhan, China; School of Automation China, University of Geosciences, Whuhan, China; School of Computer Science, China University of Geosciences, Whuhan, China","2021 China Automation Congress (CAC)","14 Mar 2022","2021","","","1803","1808","Different sensors acquire different images in the same area, such as multi-spectral (MS) images and panchromatic (PAN) images. Normally, the MS images possess high spectral resolution but low spatial resolution, while PAN images are opposite in the distribution of spectral and spatial information. Image fusion is a common method to obtain the information of PAN and MS images simultaneously. To generate clearer fusion image with abundant information, we design an unsupervised fusion net based on generative adversarial network (GAN), named UFNGAN for remote sensing image fusion. In our proposed UFNGAN, an adversarial net is designed between our generator and two discriminators to adequately retain the spectral and spatial information of original images without supervision. MS images and PAN images are fused by our generator, which consists of an encoder and a decoder. Our encoder is used to extract deeper feature maps of the original images, and the decoder is applied to rebuild images. Furthermore, the Spatial-Information-Enhancement (SIE) model is utilized to obtain spatial information of MS images for enhancing PAN image, and the Edge-Detection-Registration (EDR) method is applied to register the original images to avoid fused images distortion. At last, experiments are performed on QuickBird and GaoFen-2 datasets.","2688-0938","978-1-6654-2647-3","10.1109/CAC53003.2021.9727490","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9727490","Unsupervised learning;Image fusion;Generative adversarial network;Deep learning;Remote sensing images","Image edge detection;Generative adversarial networks;Feature extraction;Distortion;Generators;Decoding;Sensors","geophysical image processing;image fusion;image resolution;neural nets;remote sensing;unsupervised learning","remote sensing image fusion;multispectral images;panchromatic images;MS images;high spectral resolution;PAN images;spatial information;fusion image;unsupervised fusion net;spectral information;original images;fused images distortion;unsupervised generative adversarial network;spatial-information-enhancement model;UFNGAN;QuickBird;GaoFen-2 datasets;encoder","","","","10","IEEE","14 Mar 2022","","","IEEE","IEEE Conferences"
"An Object-Based River Extraction Method via Optimized Transductive Support Vector Machine for Multi-Spectral Remote-Sensing Images","X. Li; X. Lyu; Y. Tong; S. Li; D. Liu","College of Computer and Information, Hohai University, Nanjing, China; College of Computer and Information, Hohai University, Nanjing, China; Industrial Technology Research Institute, Zhengzhou University, Zhengzhou, China; Information Center, Yellow River Conservancy Commission, Zhengzhou, China; Information Center, Yellow River Conservancy Commission, Zhengzhou, China","IEEE Access","15 Apr 2019","2019","7","","46165","46175","The accurate extraction of rivers is closely related to agriculture, socio-economic, environment, and ecology. It helps us to pre-warn serious natural disasters such as floods, which leads to massive losses of life and property. With the development and popularization of remote-sensing and information technologies, a great number of river-extraction methods have been proposed. However, most of them are vulnerable to noise interference and perform inefficient in a big data environment. To address these problems, a river extraction method is proposed based on adaptive mutation particle swarm optimization (PSO) support vector machine (AMPSO-SVM). First, three features, the spectral information, normalized difference water index (NDWI), and spatial texture entropy, are considered in feature space construction. It makes the objects with the same spectrum more distinguishable, then the noise interference could be resisted effectively. Second, in order to address the problems of premature convergence and inefficient iteration, a mutation operator is introduced to the PSO algorithm. This processing makes transductive SVM obtain optimal parameters quickly and effectively. The experiments are conducted on GaoFen-1 multispectral remote-sensing images from Yellow River. The results show that the proposed method performs better than the existed ones, including PCA, KNN, basic SVM, and PSO-SVM, in terms of overall accuracy and the kappa coefficient. Besides, the proposed method achieves convergence rate faster than the PSO-SVM method.","2169-3536","","10.1109/ACCESS.2019.2908232","National Basic Research Program of China (973 Program)(grant numbers:2018YFC0407105); National Natural Science Foundation of China(grant numbers:61272543); NSF-China and Guangdong Province Joint Project(grant numbers:U1301252); Fundamental Research Funds for the Central Universities(grant numbers:2019B64314); Postgraduate Research and Practice Innovation Program of Jiangsu Province(grant numbers:SJKY19_0446); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8676210","River extraction;particle swarm optimization;SVM;GaoFen-1 remote-sensing image","Support vector machines;Remote sensing;Feature extraction;Rivers;Particle swarm optimization;Classification algorithms;Training","feature extraction;geophysical image processing;image texture;nearest neighbour methods;particle swarm optimisation;principal component analysis;support vector machines;vegetation mapping","noise interference;big data environment;adaptive mutation particle swarm optimization;spectral information;normalized difference water index;feature space construction;transductive SVM;PSO-SVM method;object-based river extraction method;information technologies;multispectral remote-sensing images;transductive support vector machine optimization;natural disasters;mutation operator;spatial texture entropy;PCA;KNN;kappa coefficient","","13","","38","OAPA","29 Mar 2019","","","IEEE","IEEE Journals"
"Marine Plastic Detection Using Optical Data","S. Vitale; G. Ferraioli; M. Ali; V. Pascazio; L. Ricciotti; G. Roviello; G. Schirinzi","Dipartimento di Scienze e Tecnologie, Università degli Studi di Napoli Parthenope; Dipartimento di Scienze e Tecnologie, Università degli Studi di Napoli Parthenope; Dipartimento di Ingegneria, Università degli Studi di Napoli Parthenope; Dipartimento di Ingegneria, Università degli Studi di Napoli Parthenope; Dipartimento di Ingegneria, Università degli Studi di Napoli Parthenope; Dipartimento di Ingegneria, Università degli Studi di Napoli Parthenope; Dipartimento di Ingegneria, Università degli Studi di Napoli Parthenope","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2662","2665","A fast and precise detection of floating plastics debris is necessary for monitoring and saving the sea ecosystem. Recent studies have demonstrated how remote sensing (and in particular satellites) can be helpful in such detection. In particular, data provided by satellite sensors allow to continuously monitoring wide areas of our planet interested by plastic litters. In this work, the possibility of exploiting different optical remote sensing satellite methods is investigated: the analysis is conducted starting from multi-spectral data and moving tom hyperspectral one. Data acquired from Sentinel 2 and from PRISMA sensors are considered showing the added value of these systems in the detection of marine litter within marine areas.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884610","CUP(grant numbers:B96G18000440005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884610","Marine Plastic;Optical Data;Multi-spectral imaging;Hyperspectral imaging","Satellites;Planets;Ecosystems;Optical imaging;Sensor systems;Plastics;Optical sensors","ecology;marine pollution;remote sensing","marine plastic detection;optical data;fast detection;plastics debris;sea ecosystem;particular satellites;satellite sensors;wide areas;plastic litters;different optical remote sensing satellite methods;multispectral data;moving tom hyperspectral;PRISMA sensors;marine areas","","","","10","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Time-Space Tradeoff in Deep Learning Models for Crop Classification on Satellite Multi-Spectral Image Time Series","V. S. F. Garnot; L. Landrieu; S. Giordano; N. Chehata","LASTIG-STRUDEL, IGN-ENSG, Univ. Paris-Est, Saint-Mandé, France; LASTIG-STRUDEL, IGN-ENSG, Univ. Paris-Est, Saint-Mandé, France; LASTIG-STRUDEL, IGN-ENSG, Univ. Paris-Est, Saint-Mandé, France; LASTIG-STRUDEL, IGN-ENSG, Univ. Paris-Est, Saint-Mandé, France","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","6247","6250","In this article, we investigate several structured deep learning models for crop type classification on multi-spectral time series. In particular, our aim is to assess the respective importance of spatial and temporal structures in such data. With this objective, we consider several designs of convolutional, recurrent, and hybrid neural networks, and assess their performance on a large dataset of freely available Sentinel-2 imagery. We find that the best-performing approaches are hybrid configurations for which most of the parameters (up to 90%) are allocated to modeling the temporal structure of the data. Our results thus constitute a set of guidelines for the design of bespoke deep learning models for crop type classification.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900517","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900517","Deep learning;Crop type classification;Multi-temporal;Sentinel-2","Agriculture;Hidden Markov models;Computer architecture;Time series analysis;Convolution;Kernel;Neural networks","convolutional neural nets;crops;geophysical image processing;image classification;learning (artificial intelligence);recurrent neural nets;remote sensing;time series;vegetation mapping","convolutional networks;recurrent networks;hybrid neural networks;freely available Sentinel-2 imagery;hybrid configurations;temporal structure;bespoke deep learning models;crop type classification;time-space tradeoff;crop classification;satellite multispectral image time series;structured deep learning models;multispectral time series;respective importance;spatial structures;temporal structures","","16","","16","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"A self-learning approach for pan-sharpening of multispectral images","M. Khateri; H. Ghassemian","Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran; Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran","2017 IEEE International Conference on Signal and Image Processing Applications (ICSIPA)","30 Nov 2017","2017","","","199","204","Due to the importance of high-resolution multi-spectral (HRM) images in many remote sensing applications, pan-sharpening techniques have been proposed to increase the spatial resolution of a low-resolution multi-spectral (LRM) image using a high-resolution panchromatic (HRP) image. In this paper, we propose a self-learning approach to pan-sharpen the LRM images. Many structures in a natural image redundantly tend to repeat in the same scale as well as different scales. These similar structures in different levels can be used to reconstruct the HRM bands with more details; in this perspective, we can construct the HRM data from the available HRP and LRM data by using self-similarity in a multi-scale procedure. The proposed method has been applied on GeoEye-1 data and DEIMOS-2 data, and then fused images compared with some popular and state-of-the-art methods in terms of several assessment indexes. The experimental results demonstrate that the proposed method can retain spectral and spatial information of the source images efficiently.","","978-1-5090-5559-3","10.1109/ICSIPA.2017.8120606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8120606","Pan-sharpening;image fusion;superresolution;multi-scale;self-learning;panchromatic data;multi-spectral data","Image reconstruction;Spatial resolution;Remote sensing;Conferences;Image fusion","geophysical image processing;geophysical techniques;image fusion;image resolution;remote sensing","self-learning approach;high-resolution multispectral images;remote sensing applications;pan-sharpening techniques;spatial resolution;low-resolution multispectral image;high-resolution panchromatic image;LRM images;natural image;HRM bands;multiscale procedure;GeoEye-1 data;DEIMOS-2 data;spectral information;spatial information;source images","","2","","30","IEEE","30 Nov 2017","","","IEEE","IEEE Conferences"
"Change Detection in Vegetation Cover Using Deep Learning","Y. Katta; N. Datla; S. S. Kilaru; T. Anuradha","Department of Information Technology, V.R. Siddhartha Engineering College, Kanuru, Vijayawada-7; Department of Information Technology, V.R. Siddhartha Engineering College, Kanuru, Vijayawada-7; Department of Information Technology, V.R. Siddhartha Engineering College, Kanuru, Vijayawada-7; Department of Information Technology, V.R. Siddhartha Engineering College, Kanuru, Vijayawada-7","2019 International Conference on Communication and Electronics Systems (ICCES)","20 Feb 2020","2019","","","621","625","Because of man-made occasions and regular causes, numerous areas on the land are experiencing quick and wide-running changes in vegetation spread. Vegetation is the significant piece of land spread and its progressions have a significant effect on the vitality and mass biochemical cycles. It is also a key marker of territorial natural condition change. Change discovery alludes to the way toward recognizing contrasts in the condition of a state by watching it at various occasions. The Multi Spectral Remote Sensing pictures are proficient for acquiring a superior comprehension of the earth condition and its changes. A Convolution Neural Network (CNN) plays a prominent role in classifying the images more accurately, compared to other Machine Learning algorithms. This paper concentrates on identifying the vegetation change in Bapatla region of Andhra Pradesh state, India between the years 2015 to 2017 using multi spectral Landsat images and deep learning techniques and the experimental results shown a decrease in vegetation land in approximately 240 square kilo meters.","","978-1-7281-1261-9","10.1109/ICCES45898.2019.9002581","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9002581","Change Detection;Convolution Neural Network;Multi spectral;Vegetation Cover","Vegetation mapping;Conferences;Satellites;Earth;Remote sensing;Training;Machine learning","convolutional neural nets;geophysical image processing;geophysical techniques;image classification;learning (artificial intelligence);remote sensing;vegetation;vegetation mapping","change detection;vegetation cover;vegetation spread;land spread;mass biochemical cycles;territorial natural condition change;MultiSpectral Remote Sensing pictures;earth condition;machine learning algorithms;vegetation change;Andhra Pradesh state;multispectral Landsat images;deep learning techniques;vegetation land;convolution neural network;change discovery","","","","19","IEEE","20 Feb 2020","","","IEEE","IEEE Conferences"
"DARK: Few-shot remote sensing colorization using label conditioned color injection","R. Bose; A. S. B. Banerjee; S. Chaudhuri","Centre of Studies in Resources Engineering (CSRE), Indian Institute of Technology Bombay, India. (e-mail: boserupak1@gmail.com); Centre of Studies in Resources Engineering (CSRE), Indian Institute of Technology Bombay, India.; Electrical Engineering Department, Indian Institute of Technology Bombay, India.","IEEE Geoscience and Remote Sensing Letters","","2022","PP","99","1","1","Satellite image colorization is a broad challenging problem in the domain of remote sensing (RS) having huge potential applications. The problem becomes even more complicated under the few-shot setting yet it has barely been studied to date. In this paper, we propose a colorization framework for the RS scene for synthesizing optical images from their panchromatic (PAN) counterparts using color injection and attention fusion mechanism. Our proposed model ensures that the synthesized optical images are coherent with the structural variability of panchromatic images while constraining the realistic appearance in the optical domain from a few training image pairs. To accomplish the same, we introduce a novel Dual Attention fusion of Receptive Kernels (DARK) which considers the spatial nuances along with color injection conditioned on prior label allocation. DARK is a multi spectral-spatial feature generator that selectively accentuates important cross-spatial features based on attention fusion. We also employ a prior distribution constraint on color embedding generation for introducing vibrant yet diverse variance in a color generation. Our approach achieves state-of-the-art results on the publicly available EuroSAT and PatternNet datasets while demonstrating significant speedups. We showcase our results quantitatively by comparing the PSNR, mean squared error(MSE), and cosine similarity of generated images and qualitatively via visual perception.","1558-0571","","10.1109/LGRS.2022.3141465","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9674906","Image colorization;Panchromatic;Optical;Few-shot;Data Fusion;Attention;Remote Sensing","Image color analysis;Optical imaging;Training;Optimized production technology;Optical sensors;Kernel;Testing","","","","1","","","IEEE","7 Jan 2022","","","IEEE","IEEE Early Access Articles"
"Unsupervised Classification Using Gravity Centers from Scatter Plot","A. K. Khare","Department of Information Technology, National Institute for Smart Government, Shimla, HP, India","2016 Second International Conference on Computational Intelligence & Communication Technology (CICT)","18 Aug 2016","2016","","","140","145","Unsupervised classification creates clusters by grouping pixels based on the reflectance properties of pixels. This paper presents a new approach to classify multi-spectral remotely sensed image using pixels' density in N-dimensional scatterplot. It first finds the densely populated clusters in N-dimensional scatter plot and then finds gravity centers of these densely populated clusters. Later, multispectral image is classified using minimum distance to gravity classifier. At the beginning of classification, this approach neither makes extreme assumption of considering each pixel as a different cluster nor goes to the other extreme by considering all the pixels in a single cluster. It follows the middle path by making assumption of some pixels as gravity centers of different clusters before classifying the image. It creates clusters of equal size in N-dimensional scatter plot and picks up the densely populated clusters. All these clusters are recursively iterated for self-adjustment of gravity centers using mathematical algorithm. The approach uses gravitational force for merging two nearby clusters. Here, gravity center of a cluster is calculated by summing up the spectral bands' values and dividing it by number of pixels within that cluster. When two nearby clusters are merged, their gravity centers are also adjusted accordingly. This provides the most densely populated clusters and their gravity centers. Now, these gravity centers can be used to classify the remotely sensed image using minimum distance to gravity center classifier.","","978-1-5090-0210-8","10.1109/CICT.2016.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546590","Clustering;Multi-Spectral;Remote Sensing;Scatter Plot;Unsupervised Classification","Gravity;Remote sensing;Merging;Clustering algorithms;Reflectivity;Classification algorithms;Radiometry","geophysical image processing;image classification;pattern clustering;remote sensing","unsupervised classification;gravity centers;clusters;pixel reflectance properties;multispectral remotely sensed image classification;pixel density;n-dimensional scatter plot;mathematical algorithm;gravitational force;spectral band values;gravity center classifier","","","","12","IEEE","18 Aug 2016","","","IEEE","IEEE Conferences"
"Multiple-Valued and Fuzzy Logics Application to Remote Sensing Data Analysis","E. Zaitseva; I. Piestova; J. Rabcan; P. Rusnak","Universuty of Zilina, Zilina, Slovakia; Scientific Centre for Aerospace Research of the Earth Institute of Geological Science National Academy of Sciences of Ukraine, Kyiv, Ukraine; Universuty of Zilina, Zilina, Slovakia; Universuty of Zilina, Zilina, Slovakia","2018 26th Telecommunications Forum (TELFOR)","17 Jan 2019","2018","","","1","4","The main goal of this paper is to justify the use of multiple-valued and fuzzy logics for the problem of increasing the spatial resolution of multi-spectral satellite images. Additionally, we present our solution based on the fuzzy clastering of the image by spectral signatures and the subpixel's values reallocating. In our solution, we are taking into account spatial topology relationships for each study type of land cover.","","978-1-5386-7171-9","10.1109/TELFOR.2018.8612109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8612109","multispectral imagery superresolution;multivalued logic;fuzzy clustering;subpixel reallocating","Spatial resolution;Clustering algorithms;Image segmentation;Partitioning algorithms;Satellites;Remote sensing","data analysis;fuzzy logic;geophysical image processing;geophysical signal processing;land cover;remote sensing","fuzzy logics;sensing data analysis;spatial resolution;multispectral satellite images;fuzzy clastering;spectral signatures;spatial topology relationships;multiple-valued logics application;remote sensing data analysis;land cover","","4","","21","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"Deep residual learning for remote sensed imagery pansharpening","Y. Wei; Q. Yuan","State Key Laboratory of Information Engineering, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China","2017 International Workshop on Remote Sensing with Intelligent Processing (RSIP)","26 Jun 2017","2017","","","1","4","We proposed a deep convolutional network for multi-spectral image pan-sharpening to overcome the drawbacks of traditional methods and improve the fusion accuracy. To break the performance limitation of deep networks, residual learning with specific adaption to image fusion tasks is applied to optimize the architecture of proposed network. Results of adequate experiments support that our model can yield high resolution multi-spectral images with state-of-the-art qualities, as the information in both spatial and spectral domains has been accurately preserved.","","978-1-5386-1990-2","10.1109/RSIP.2017.7958794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7958794","Pansharpening;image fusion;convolutional neural network;residual learning","Spatial resolution;Neural networks;Remote sensing;Machine learning;Feature extraction;Image fusion","computer vision;image fusion;learning (artificial intelligence);remote sensing","deep residual learning;remote sensed imagery pansharpening;deep convolutional network;multi-spectral image pan-sharpening;image fusion tasks;spatial domains;spectral domains","","15","","17","IEEE","26 Jun 2017","","","IEEE","IEEE Conferences"
"Sentinel-3 Image Super-Resolution Using Data Fusion and Convolutional Neural Networks","R. Fernandez; R. Fernandez-Beltran; F. Pla","Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2867","2870","With the increasing availability of Sentinel-2 (S2) and Sentinel-3 (S3) data, developing higher-level data products becomes a very attractive option to relieve the spatial limitations of the Ocean and Land Colour Instrument (OLCI) of S3. In this context, this paper investigates the suitability of super-resolving operational OLCI products using the Multi-Spectral Instrument (MSI) of S2 as an offline spatial reference. Specifically, the proposed approach assembles a multi -spectral data fusion scheme together with a convolutinal neural network (CNN) mapping function to project the OLCI sensor onto its corresponding spatial reference which is synthetically generated by the OLCI/MSI fusion. In this way, the trained model is able to super-resolve operational OLCI products under demand without the need of using MSI data. The experimental part of the work shows the suitability of the proposed approach in the context of the Copernicus programme.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554826","Sentinel-2 (S2);Sentinel-3 (S3);image fusion;super-resolution (SR)","Image color analysis;Instruments;Oceans;Superresolution;Neural networks;Data integration;Geoscience and remote sensing","geophysical image processing;image fusion;image resolution;image sensors;neural nets;remote sensing;sensor fusion","corresponding spatial reference;super-resolve operational OLCI products;MSI data;Sentinel-3 image super-resolution;convolutional neural networks;Sentinel-2;Sentinel-3 data;higher-level data products;spatial limitations;MultiSpectral Instrument;offline spatial reference;multi-spectral data fusion scheme;convolutinal neural network mapping function;OLCI sensor","","","","16","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Spatio-Temporal Assessment of Fire Severity in a Protected and Mountainous Ecosystem","G. E. Adagbasa; S. A. Adelabu; T. W. Okello","Department of Geography, QwaQwa Campus, Republic of South Africa; Department of Geography, QwaQwa Campus, Republic of South Africa; Department of Geography, QwaQwa Campus, Republic of South Africa","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","6572","6575","Wildfires are one of the major threats to the biodiversity of protected and mountainous landscapes. The severity of these fires is an important factor that influence vegetation recovery. Several remote sensing techniques has been used in previous studies to assess fire severity, but the Normalized Burn Ratio (NBR) has become the standard SI approach to assess burn severity. The Normalized Burn Ratio (NBR) demarcates burnt and unburned pixels in the pre-/post-fire season and, then creates an index of the severity of a burn using multi-spectral sensors, which establishes an ideal tool for fire severity assessment. In this study, the fire severity level is computed using the NBR Index from LANDSAT image. The images of pre-and postfire are used to evaluate the severity level, which is defined as a difference in NBR Index of pre- and post-fire. Results shows that in year 2000, 30704.22 ha of area burned with low to high severity, 31352.13 ha in year 2005,4697 ha in year 2013 and 30009.33 ha in 2017. A hundred field plots and fire records were used to validate the fire severity map for 2013 and 2017 with an accuracy of 74% which supports the use of NBR for assessing fire severity.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518268","Fire severity;Remote Sensing;Normalized Burn Ratio","Fires;Vegetation mapping;Remote sensing;Indexes;Earth;Artificial satellites;Soil","geophysical image processing;remote sensing;vegetation;vegetation mapping;wildfires","spatio-temporal assessment;protected landscapes;mountainous landscapes;burn severity;fire severity assessment;fire severity level;NBR Index;field plots;fire records;fire severity map;normalized burn ratio;AD 2013;AD 2017;LANDSAT image;pre-fire season;post-fire season","","8","","19","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"A Dynamics Trend Analysis Method of Thermokarst Lakes Based on the Machine Learning Algorithm","H. Chen; T. Liqiang; G. Zhaocheng; T. Jienan; W. Hua; H. Peng","China Aero Geophysical Survey and Remote Sensing Center for Nature Resources, Beijing; China Aero Geophysical Survey and Remote Sensing Center for Nature Resources, Beijing; China Aero Geophysical Survey and Remote Sensing Center for Nature Resources, Beijing; China Aero Geophysical Survey and Remote Sensing Center for Nature Resources, Beijing; University of Chinese Academy of Sciences, Beijing, China; China Aero Geophysical Survey and Remote Sensing Center for Nature Resources, Beijing","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","6484","6487","The thermokarst lake is one of the most typical thermal and thawing disasters, and also an key sign of permafrost degradation. It has a strong impact on the study of global climate change. In this paper, the Beilu river basin in Qinghai Tibet Plateau was selected as an example. With the global availability Landsat data (TM, ETM+, OLI), we obtained the multi-spectral indices, which is closely related to the state of thermokarst lakes rich area. Then, the longterm change trend parameter sets of the multi-spectral indices from 2000 to 2020 are taken as the input data sets of machine learning method to accurately characterize the change state of the thermokarst lakes. Based on the proposed machine learning method, the dynamic change results of the thermokarst lake rich area were obtained pixel by pixel. The results show that it is an effective way for thermokarst lake dynamics analysis within the permafrost region. It is not only helpful to predict and control the change of thermokarst lakes, but also has important practical significance for the study of global climate change.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554435","National Natural Science Foundation of China(grant numbers:41901308); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554435","thermokarst lakes;machine learning;trend analysis;dynamic change","Climate change;Time series analysis;Machine learning;Lakes;Market research;Rivers;Indexes","lakes;learning (artificial intelligence);remote sensing;rivers;water quality","dynamics trend analysis method;typical thermal thawing disasters;global climate change;global availability Landsat data;multispectral indices;thermokarst lakes rich area;longterm change trend parameter sets;machine learning method;change state;dynamic change results;thermokarst lake rich area;thermokarst lake dynamics analysis","","","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Multitemporal data mining: From biomass monitoring to nuclear proliferation detection","R. R. Vatsavai","Department of Computer Science, North Carolina State University, Raleigh, NC","2015 8th International Workshop on the Analysis of Multitemporal Remote Sensing Images (Multi-Temp)","10 Sep 2015","2015","","","1","4","We are living in an era of unprecedented population growth and migration, expanding urban and agriculture lands, depleting forests and portable water resources, and natural hazards and climate changes that are changing the face of the planet Earth. Multitemporal remote sensing observations provide a powerful means to monitor the Earth to identify and characterize these changes in near-real time. Data mining is proven to be highly useful in analyzing multi-resolution, multi-spectral, multisensor, and multi-temporal remote sensing data. In this paper we describe the state-of-the-art data mining approaches with applications in biomass and critical infrastructure monitoring.","","978-1-4673-7119-3","10.1109/Multi-Temp.2015.7245751","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7245751","","Remote sensing;Monitoring;Feature extraction;Data mining;Biomass;Semantics;Statistics;Climate change","data mining;geophysics computing;remote sensing;renewable materials;water resources","multitemporal data mining;biomass monitoring;nuclear proliferation detection;agriculture lands;urban lands;climate changes;water resources;natural hazards;multitemporal remote sensing observation;data mining;multisensor;multitemporal remote sensing data;multispectral data;multiresolution data;state-of-the-art data mining approaches","","","","22","IEEE","10 Sep 2015","","","IEEE","IEEE Conferences"
"A Machine Learning-Based Approach for Land Cover Change Detection Using Remote Sensing and Radiometric Measurements","N. Zerrouki; F. Harrou; Y. Sun; L. Hocini","DIIM Laboratory, Center for Development of Advanced Technology (CDTA), Algiers, Algeria; Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Laboratory of Analysis and Modeling of the Random Phenomena, Mouloud Mammeri University (UMMTO), Tizi-Ouzou, Algeria","IEEE Sensors Journal","19 Jun 2019","2019","19","14","5843","5850","An approach combining the Hotelling T2 control method with a weighted random forest classifier is proposed and used in the context of detecting land cover changes via remote sensing and radiometric measurements. Hotelling T2 procedure is introduced to identify features corresponding to changed areas. Nevertheless, T2 scheme is not able to separate real from false changes. To tackle this limitation, the weighted random forest algorithm, which is an efficient classification technique for imbalanced problems, has been successfully applied to the features of the detected pixels to recognize the type of change. The feasibility of the proposed procedure is verified using SZTAKI AirChange benchmark data. Results proclaim that the proposed detection scheme succeeds to effectively identify land cover changes. Also, the comparisons with other methods (i.e., neural network, random forest, support vector machine, and k-nearest neighbors) highlight the superiority of the proposed method.","1558-1748","","10.1109/JSEN.2019.2904137","King Abdullah University of Science and Technology(grant numbers:OSR-2015-CRG4-2582); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664182","Land cover change detection;multi-spectral sensors;multi-date measurements;remote sensing;multivariate statistical approach;random forest classification","Remote sensing;Monitoring;Feature extraction;Sensors;Radiometry;Agriculture;Support vector machines","geophysical image processing;image classification;learning (artificial intelligence);pattern classification;remote sensing;statistical analysis;support vector machines;terrain mapping","false changes;weighted random forest algorithm;detected pixels;detection scheme;land cover change detection;remote sensing;radiometric measurements;weighted random forest classifier;SZTAKI AirChange benchmark data;Hotelling T2 control method","","18","","33","IEEE","10 Mar 2019","","","IEEE","IEEE Journals"
"Multi-scale-and-depth convolutional neural network for remote sensed imagery pan-sharpening","Y. Wei; Q. Yuan; X. Meng; H. Shen; L. Zhang; M. Ng","State Key Laboratory of Information Engineering, Survey Mapping and Remote Sensing, Wuhan University, P. R. China; School of Geodesy and Geomatics, Wuhan University, P. R. China; School of Resource and Environmental Science, Wuhan University, P. R. China; School of Resource and Environmental Science, Wuhan University, P. R. China; State Key Laboratory of Information Engineering, Survey Mapping and Remote Sensing, Wuhan University, P. R. China; Department of Mathematics, Hong Kong Baptist University","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","3413","3416","Pan-sharpening is a fundamental and significant task in the field of remote sensed imagery fusion, which demands fusion of panchromatic and multi-spectral images with the rich information accurately preserved in both spatial and spectral domains. In this paper, to overcome the drawbacks of traditional pan-sharpening methodologies, we employed the advanced concept of deep learning to propose a Multi-Scale-and-Depth Convolutional Neural Network (MSDCNN) as an end-to-end pan-sharpening model. By the results of a large number of quantitative and visual assessments, the qualities of images fused by the proposed network have been confirmed superior to compared state-of-the-art methods.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127731","Remote Sensing;Pan-sharpening;Deep learning;Convolutional neural network;Residual Learning","","image fusion;learning (artificial intelligence);neural nets;remote sensing","multiscale-and-depth convolutional neural network;remote sensed imagery pan-sharpening;remote sensed imagery fusion;panchromatic image;multispectral image;deep learning;MSDCNN model;end-to-end pan-sharpening model;image quality","","1","","17","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"THE Development of a Standardised Validation Approach for Surface Reflectance Data","C. Ong; T. Malthus; I. C. Lau; M. Thankappan; G. Byrne","Commonwealth Scientific Industrial Research Organisation (CSIRO), Australia; Commonwealth Scientific Industrial Research Organisation (CSIRO), Australia; Commonwealth Scientific Industrial Research Organisation (CSIRO), Australia; Geoscience Australia (GA), Australia; Geoscience Australia (GA), Australia","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","6456","6459","Earth Observation (EO) satellite data are the single most important and richest source of environmental information for Australia. Data from operational missions, such as the USA Landsat and the EU Copernicus missions, are important data sources underpinning a range of research and operational uses across the continent. To provide confidence in the data from these active EO missions, work is currently underway in Australia to develop a national framework for the validation of these data. Specifically, data that has been reduced to surface reflectance (SR) will be comprehensively validated to provide a standardised well-calibrated dataset for the Australian EO user community. This paper reports on an approach for continental-scale validation of the Digital Earth Australia (DEA) SR product using field-based measurements that will be acquired near-synchronous to satellite observations over multiple sites across Australia.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518624","validation;reflectance;standards;multi-spectral;data cubes;NBAR;Digital Earth Australia","Australia;Earth;Satellites;Remote sensing;Artificial satellites;Calibration;Reflectivity","calibration;environmental monitoring (geophysics);geophysical techniques;geophysics computing;remote sensing","standardised validation approach;surface reflectance data;Earth Observation satellite data;USA Landsat;EU Copernicus missions;active EO missions;standardised well-calibrated dataset;Australian EO user community;continental-scale validation;Digital Earth Australia SR product using field-based measurements;satellite observations;data sources","","1","","18","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"3D Semantic Segmentation from Multi-View Optical Satellite Images","P. d’Angelo; D. Cerra; S. M. Azimi; N. Merkle; J. Tian; S. Auer; M. Pato; R. de los Reyes; X. Zhuo; K. Bittner; T. Krauss; P. Reinartz","Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen; Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen; Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen; Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen; Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen; Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen; Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen; Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen; Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen; Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen; Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen; Remote Sensing Technology Institute, German Aerospace Center (DLR), Oberpfaffenhofen","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","5053","5056","This paper describes the winning contribution to the 2019 IEEE GRSS Data Fusion Contest Multi-view Semantic Stereo Challenge. In this challenge, a digital surface model (DSM) and a semantic segmentation should be derived from a large number of multi-spectral WorldView-3 images. Results from 50 stereo pairs matched using Semi-Global Matching (SGM) are fused into a DSM. Semantic segmentation is performed with an ensemble of FCN networks taking as input RGB, multi-spectral and height data. Their results are then merged with pixel-wise detectors for the classes water and high vegetation. Compared to the second and third placed teams (mIOU-3 scores of 0.73 and 0.7295), our contribution reached a significantly higher score of 0.745.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899795","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899795","","Semantics;Vegetation mapping;Feature extraction;Buildings;Image segmentation;Three-dimensional displays;Satellites","geophysical image processing;image matching;image segmentation;sensor fusion;stereo image processing","semantic segmentation;Multiview optical satellite images;winning contribution;2019 IEEE GRSS Data Fusion Contest Multiview Semantic Stereo Challenge;digital surface model;DSM;multispectral WorldView-3 images;stereo pairs;SemiGlobal Matching;height data;mIOU-3 scores;FCN networks;pixel-wise detectors;classes water;vegetation","","3","1","13","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Modelling Leaf Chlorophyll Content in Coffee (Coffea Arabica) Plantations Using Sentinel 2 Msi Data","A. Chemura; O. Mutanga; J. Odindi","Discipline of Geography, University of KwaZulu-Natal, Pietermaritzburg, South Africa; Discipline of Geography, University of KwaZulu-Natal, Pietermaritzburg, South Africa; Discipline of Geography, University of KwaZulu-Natal, Pietermaritzburg, South Africa","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","8228","8231","Coffee leaf chlorophyll (ChI) is an important proxy for coffee plant photosynthetic rates, nitrogen content, leaf health and yield potential. Whereas the recently launched Sentinel 2 multi -spectral instrument (MSI) data has great potential for plant condition assessment, the value of its spectral settings at variable spatial resolutions in relation to crop canopy cover on ChI content prediction remains largely unexplored. In this study, we apply an empirical model to estimate coffee leaf ChI with Sentinel 2 MSI data. Results showed that coffee biophysical parameters (height and canopy cover) are significantly influenced by stand age while plant water concentration and total ChI are age invariant. Results further showed that the best modelling results (R2=0.69, RMSE=64.4) were achieved when all the bands at 10m spatial resolution with all data were used. We concluded that Sentinel 2 MSI is a valuable dataset for predicting coffee leaf ChI, however, based on our findings, we suggest that finer spatial resolutions of 10m on mature coffee stands should be adopted for better prediction results.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518848","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518848","Leaf chlorophyll;Crop condition assessment;Random forest;Spectral resolution;Spatial resolution","Spatial resolution;Data models;Agriculture;Biological system modeling;Nitrogen;Remote sensing;Reflectivity","geophysical techniques;photosynthesis;remote sensing;vegetation","modelling leaf chlorophyll content;coffee plantations;sentinel 2 MSI data;Sentinel 2 multi-spectral instrument data;mature coffee stands;finer spatial resolutions;plant water concentration;coffee biophysical parameters;Sentinel 2 MSI data;empirical model;crop canopy cover;variable spatial resolutions;plant condition assessment;leaf health;nitrogen content;coffee plant photosynthetic rates;coffee leaf chlorophyll","","2","","13","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Unsupervised domain adaptation in land-cover classification under neural approach using feature-level ensemble","S. Chakraborty; I. Kalita; M. Roy","Department of Computer Science & Engineering, Indian Institute of Information Technology Guwahati, Assam, India; Department of Computer Science & Engineering, Indian Institute of Information Technology Guwahati, Assam, India; Department of Computer Science & Engineering, Indian Institute of Information Technology Guwahati, Assam, India","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","724","727","In this manuscript, a feature level ensemble based technique has been proposed using artificial neural networks (ANNs) for an unsupervised domain adaptation (DA) in land-cover classification. Here, ANNs in form of an auto-encoder (AE) and a restricted Boltzman machine (RBM) have been used to learn the sample distribution of both source and target domains together during training. The trained ANNs are then used to find new features suitable for adaptive learning across the two domains having different sample distributions. Finally, the new features obtained from AE and RBM are fused to obtain the final train and test set. Experimentation has been carried out using patterns collected from Landsat-8 multi-spectral satellite images captured over various regions of India. The prediction accuracies of target classes obtained for the proposed scheme show encouraging results when compared with that of other state-of-the-art DA techniques.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898237","Domain adaptation;artificial neural networks;feature-level ensemble;restricted Boltzman machine;auto-encoding","Neurons;Training;Feature extraction;Remote sensing;Earth;Satellites;Artificial satellites","Boltzmann machines;geophysical image processing;image classification;land cover;learning (artificial intelligence);remote sensing;unsupervised learning","land-cover classification;neural approach;feature-level ensemble;artificial neural networks;unsupervised domain adaptation;auto-encoder;restricted Boltzman machine;sample distribution;target domains;trained ANNs;adaptive learning;final train;test set;Landsat-8 multi-spectral satellite image capture","","1","","13","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Prototype of a multi-platform remote sensing service for fishing forecasting","K. Tijani; A. Morea; M. T. Chiaradia; R. Nutricato; L. Guerriero","Department of Physics, Technical University of Bari Bari, Bari, Italy; Department of Physics, Technical University of Bari Bari, Bari, Italy; Department of Physics, Technical University of Bari Bari, Bari, Italy; Geophysical Applications Processing (GAP) s.r.l., Bari, Italy; Geophysical Applications Processing (GAP) s.r.l., Bari, Italy","2016 IEEE Workshop on Environmental, Energy, and Structural Monitoring Systems (EESMS)","7 Jul 2016","2016","","","1","6","The present work concerns the development of an automatic Fishing Forecasting System (FiFoS) where satellite observations, ancillary data and in situ measurements (Catch Per Unit Effort) are used to set up, calibrate and validate a fishing forecasting model. Multi-temporal and multi-sensor data fusion techniques are applied to multi-spectral data in order to detect chlorophyll and sea temperature fronts that according to physical models of the upwelling phenomena are related to areas rich of phytoplankton nutrients where a high concentration of pelagic fish is expected.","","978-1-5090-2370-7","10.1109/EESMS.2016.7504846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504846","Satellite Remote Sensing;Potential Fishing Zone (PFZ);Ocean Color Analysis;Multi-sensor data fusion;Fishing Forecasting System (FiFoS)","Ocean temperature;MODIS;Satellites;Forecasting;Sea surface;Data integration;Sensors","calibration;forecasting theory;microorganisms;oceanographic techniques;remote sensing;sensor fusion;temperature measurement;temperature sensors","multi-platform remote sensing service;automatic fishing forecasting system;FiFoS;satellite observation;catch per unit effort;calibration;multitemporal data fusion technique;multisensor data fusion technique;multispectral data application;chlorophyll detection;sea temperature detection;phytoplankton nutrient;pelagic fish concentration","","","","29","IEEE","7 Jul 2016","","","IEEE","IEEE Conferences"
"Development Of Algorithms For The Estimation Of Hydrological Parameters Combining Cosmo-Skymed And Sentinel Time Series With In Situ Measurements","D. Tapete; F. Cigna; S. Paloscia; E. Santi; S. Pettinato; G. Fontanelli; E. Chiarito; C. Notarnicola; G. Cuozzo; A. Jacob; L. De Gregorio; M. Rossi","Italian Space Agency (ASI), Via del Politecnico s.n.c., Rome, Italy; Italian Space Agency (ASI), Via del Politecnico s.n.c., Rome, Italy; Institute of Applied Physics - National Research Council of Italy (IFAC–CNR), Sesto Fiorentino, Italy; Institute of Applied Physics - National Research Council of Italy (IFAC–CNR), Sesto Fiorentino, Italy; Institute of Applied Physics - National Research Council of Italy (IFAC–CNR), Sesto Fiorentino, Italy; Institute of Applied Physics - National Research Council of Italy (IFAC–CNR), Sesto Fiorentino, Italy; Institute of Applied Physics - National Research Council of Italy (IFAC–CNR), Sesto Fiorentino, Italy; Institute for Applied Remote Sensing, Bolzano, Italy; Institute for Applied Remote Sensing, Bolzano, Italy; Institute for Applied Remote Sensing, Bolzano, Italy; Institute for Applied Remote Sensing, Bolzano, Italy; Institute for Applied Remote Sensing, Bolzano, Italy","2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium (M2GARSS)","2 Jun 2020","2020","","","53","56","The collaborative research project “ALGORITHMS” (20192021) between the Italian Space Agency (ASI) and the Institute of Applied Physics of the National Research Council of Italy (IFAC–CNR) aims to develop innovative algorithms to estimate the main hydrological parameters (e.g. soil moisture content, vegetation properties, snow water equivalent). The proposed algorithms combine Synthetic Aperture Radar (SAR), multispectral and hyperspectral satellite data with in-situ measurements. First results are presented based on retrieval analyses and surveys over the test sites in northern and central Italy, using exceptionally long, consistent and multi-polarized C- and X-band SAR time series from the Copernicus Sentinel-1 and ASI’s COSMO-SkyMed missions, as well as Copernicus Sentinel2 high resolution multi-spectral imagery.","","978-1-7281-2190-1","10.1109/M2GARSS47143.2020.9105313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105313","Soil moisture content;snow water equivalent;sensitivity analysis;Artificial Neural Networks;COSMO-SkyMed;Sentinels","Water;Satellites;Soil measurements;Snow;Time series analysis;Soil moisture;Vegetation mapping","radar imaging;radar interferometry;remote sensing by radar;snow;synthetic aperture radar;vegetation;vegetation mapping","C-band SAR time series;Copernicus Sentinel-2 high resolution multispectral imagery;ASI COSMO-SkyMed mission;ALGORITHMS;National Research Council of Italy;Italian Space Agency;collaborative research project;Sentinel time series;Copernicus Sentinel-1 mission;X-band SAR time series;central Italy;northern Italy;hyperspectral satellite data;snow water equivalent;vegetation properties;moisture content;hydrological parameters;IFAC-CNR;Institute of Applied Physics","","11","","3","IEEE","2 Jun 2020","","","IEEE","IEEE Conferences"
"A Modified STARFM Method for Heterogeneous Area Based on Multi-Spectral Data","Y. Meng; B. Ping","National Marine Data and Information Service, Tianjin, China; Institute of Surface-Earth System Science, Tianjin University, Tianjin, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","5940","5943","Recently, it is still difficult to obtain satellite data with both high spatial resolution and frequent coverage simultaneously and spatio-temporal fusion is an effective way to solve this problem. The Spatial and Temporal Adaptive Reflectance Fusion Model (STARFM), one of the spatio-temporal fusion methods, has been widely used in many applications. In the original STARFM method, the fusion procedure is implemented band by band, which means information from other bands is ignored. To take information from other bands into account, a modified STARFM method was proposed in this study. Instead of using the pixels from one given band, the vectors formed from all bands were used; and the difference between two pixels in the STARFM algorithm was replaced by the distance between two vectors. Five quantitative indices were used to make comparisons between the modified and original STARFM methods. The results show the proposed method can get better fusion accuracies with different band combinations.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900645","STARFM;spatio-temporal fusion;MODIS;Landsat","Remote sensing;Earth;Artificial satellites;MODIS;Prediction algorithms;Spatial resolution;Reflectivity","geophysical techniques","Spatial and Temporal Adaptive Reflectance Fusion Model;fusion procedure;original STARFM method;spatio-temporal fusion methods;frequent coverage;high spatial resolution;satellite data;multispectral data;heterogeneous area;modified STARFM method;band combinations;fusion accuracies;modified STARFM methods;STARFM algorithm","","","","7","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Multi temporal and multi spectral images based change detection of mine wastes in Northern Tunisia","N. Mezned; B. Dkhala; S. Abdeljaouad","Faculté des Sciences, Campus Universitaire du Belvédère, Tunis, Tunisie; Faculté des Sciences, Campus Universitaire du Belvédère, Tunis, Tunisie; Faculté des Sciences, Campus Universitaire du Belvédère, Tunis, Tunisie","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","3426","3429","Abandoned mines cause critical problems which are among the most challenging environmental ones. This is the case in Tunisia, were effects of mining activity are well illustrated particularly in Mejerda and Mellag river watersheds. Mapping is the first step for the inventory, characterization and survey of mine wastes elsewhere. Particularly, detecting changes in images of the same scene taken at different time series is of special interest in this application domain. In this context, we applied a based MAD (Multivariate Alteration Detection) transformation method for multi temporal classification and change detection of mine wastes. For these purposes we used Landsat ETM+ time-series data.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326556","Mine wastes;Landsat ETM+ data;change detection;MAD","Remote sensing;Satellites;Earth;Radiometry;Correlation;Image color analysis;Rivers","mining;water pollution;water resources","mine Landsat ETM+ time-series data;detection ETM+;Multivariate Alteration Detection;mine wastes;Mejerda river watersheds;Mellag river watersheds;abandoned mines;critical problems;Northern Tunisia;multispectral images","","","","8","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Evaluation on BJ-2 Image Fusion Algorithms for Satellite Images of Coastal Aquaculture Sea Areas","J. Chu; Y. Chen; J. Zhao; F. Wang","National Marine Environmental Monitoring Center, Dalian, China; National Marine Environmental Monitoring Center, Dalian, China; National Marine Environmental Monitoring Center, Dalian, China; National Marine Environmental Monitoring Center, Dalian, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2826","2829","Coastal aquaculture sea areas is of great significance to monitor these aquaculture sea areas through the means of a remote sensing technology. The images after fusion are provided with both the high-resolution feature of panchromatic images and the spectral characteristics of multi-spectral images, thereby strengthening the image information and facilitating its application. According to the characteristics of the aquaculture sea area in concern, five fusion algorithms, namely, Brovey Transform, Gram-Schmidt Transform, Principal Component Analysis, Pan Sharp, and Nearest Neighbor Diffusion PanSharpening were adopted to fuse the BJ-2 multi-spectral and panchromatic image data of the areas in the shallow sea raft culture, cage culture, and reclamation culture acquired in Zhangzhou coastal aquaculture sea area of the Fujian Province. Then the fusion images are evaluated subjectively and objectively to provide the best fusion scheme for monitoring aquaculture by remote sensing. The results showed that: (1) the five fusion algorithms are able to significantly improve both the spatial resolution and the utilization ratio of the BJ-2 satellite images; (2) the fusion effects of PSH method can provide the most optimum solution in terms of spectral retentivity and detail expression, and are the best in all the three fusion experiments on aquaculture sea information; (3) the acquired bright-color and high-contrast images make the fusion effects of NNDiffuse the best in terms of image contrast and information enhancement; (4) PSH algorithm is appropriate for use when BJ-2 is used for visual interpretation and thematic charting of shallow sea raft culture, cage culture and reclamation culture and other information; on the other hand, it is recommended to use NNDiffuse for automatic classification and identification.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898091","BJ-2;Image fusion;Aquaculture sea area;Quality evaluation.","Aquaculture;Remote sensing;Sea measurements;Satellites;Image fusion;Principal component analysis;Transforms","aquaculture;geophysical image processing;geophysical techniques;image fusion;image resolution;principal component analysis;remote sensing","remote sensing technology;panchromatic images;spectral characteristics;multispectral images;image information;panchromatic image data;shallow sea raft culture;cage culture;reclamation culture;Zhangzhou coastal aquaculture sea area;fusion images;fusion scheme;monitoring aquaculture;BJ-2 satellite images;fusion effects;fusion experiments;aquaculture sea information;high-contrast images;BJ-2 Image Fusion Algorithms;coastal aquaculture sea areas;Brovey Transform;Gram-Schmidt Transform;Principal Component Analysis;Nearest Neighbor Diffusion PanSharpening","","2","","11","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Remote Sensing: An Automated Methodology for Olive Tree Detection and Counting in Satellite Images","A. Khan; U. Khan; M. Waleed; A. Khan; T. Kamal; S. N. K. Marwat; M. Maqsood; F. Aadil","Department of Computer Systems Engineering, University of Engineering and Technology, Peshawar, Pakistan; Department of Computer Systems Engineering, University of Engineering and Technology, Peshawar, Pakistan; Department of Computer Systems Engineering, University of Engineering and Technology, Peshawar, Pakistan; Department of Mechanical Engineering, University of Engineering and Technology, Peshawar, Pakistan; Department of Computer Systems Engineering, University of Engineering and Technology, Peshawar, Pakistan; Department of Computer Systems Engineering, University of Engineering and Technology, Peshawar, Pakistan; Department of Computer Science, COMSATS University Islamabad at Attock, Attock, Pakistan; Department of Computer Science, COMSATS University Islamabad at Attock, Attock, Pakistan","IEEE Access","23 Dec 2018","2018","6","","77816","77828","Cultivation of olive trees for the past few years has been widely spread across Mediterranean countries, including Spain, Greece, Italy, France, and Turkey. Among these countries, Spain is listed as the largest olive producing country with almost 45% of olive oil production per year. Dedicating land of over 2.4 million hectares for the olive cultivation, Spain is among the leading distributors of olives throughout the world. Due to its high significance in the country's economy, the crop yield must be recorded. Manual collection of data over such expanded fields is humanly infeasible. Remote collection of such information can be made possible through the utilization of satellite imagery. This paper presents an automated olive tree counting method based on image processing of satellite imagery. The images are pre-processed using the unsharp masking followed by improved multi-level thresholding-based segmentation. Resulting circular blobs are detected through the circular Hough transform for identification. Validation has been performed by evaluating the proposed scheme for the dataset formed by acquiring images through the “El Sistema de Información Geográfica de Parcelas Agrícolas”viewer over the region of Spain. The proposed algorithm achieves an accuracy of 96% in detection. Computation time was recorded as 24 ms for an image size of 300 × 300 pixels. The less spectral information is used in our proposed methodology resulting in a competitive accuracy with low computational cost in comparison to the state-of-the-art technique.","2169-3536","","10.1109/ACCESS.2018.2884199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8558485","Remote sensing;olive;Hough transform;crop estimation;satellite imagery;multi-spectral imagery","Vegetation;Satellites;Image segmentation;Agriculture;Remote sensing;Blob detection;Tools","agriculture;crops;geophysical image processing;Hough transforms;image segmentation;object detection;remote sensing","remote sensing;automated methodology;olive tree detection;satellite images;Mediterranean countries;Spain;olive oil production;olive cultivation;crop yield;expanded fields;remote collection;satellite imagery;automated olive tree counting method;image processing;multilevel thresholding-based segmentation;image size;circular blobs;olive producing country;time 24.0 ms","","24","","28","OAPA","4 Dec 2018","","","IEEE","IEEE Journals"
"Image Matching via Feature Fusion and Coherent Constraint","K. Sun; L. Liu; W. Tao","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; School of Biomedical Engineering, South-Central University for Nationalities, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","19 May 2017","2017","14","3","289","293","The Gaussian mixture model (GMM)-based methods have achieved great success in point set registration. However, they cannot be directly applied to image matching, because the features extracted from two images usually contain a large portion of outliers. In this letter, we propose a new method to extend the powerful GMM to the field of image feature points matching. The algorithm consists of two main steps. In the first step, points extracted from the images are mapped into a new subspace, in which feature similarity information is fused to get the new representation of the points. The second step performs an improved progressive process with the GMM to find correspondences satisfying the coherent constraint. In this way, finding correspondences among large outliers is feasible and the iteration converges faster. Experimental results on benchmark data sets show that the proposed method can find more correct matches with high accuracy.","1558-0571","","10.1109/LGRS.2016.2631165","National Natural Science Foundation of China(grant numbers:61371140,61305044); National Natural Science Foundation of Hubei Province(grant numbers:2015CFA062,2015BAA133); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7831456","Coherent constraint;image matching;subspace mapping","Feature extraction;Robustness;Image matching;Kernel;Sun;Acceleration;Remote sensing","convergence of numerical methods;feature extraction;Gaussian processes;image fusion;image matching;image registration;image representation;iterative methods;mixture models","Gaussian mixture model;GMM-based method;point set registration;feature extraction;image feature point matching;point mapping;feature similarity information fusion;point representation;improved progressive process;coherent constraint;iteration convergence;benchmark data sets","","10","","18","IEEE","24 Jan 2017","","","IEEE","IEEE Journals"
"SEFEPNet: Scale Expansion and Feature Enhancement Pyramid Network for SAR Aircraft Detection With Small Sample Dataset","P. Zhang; H. Xu; T. Tian; P. Gao; L. Li; T. Zhao; N. Zhang; J. Tian","School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","10 May 2022","2022","15","","3365","3375","Aircraft detection in synthetic aperture radar (SAR) images is still a challenging research task because of the insufficient public data, the difficulty of multiscale target detection, and the complexity of background interference. In this article, we construct a public SAR aircraft detection dataset (SADD) with complex background and interference objects to facilitate the research in SAR aircraft detection. Then, we propose the scale expansion and feature enhancement pyramid network as the SADD baseline. It uses a four-scale fusion method to combine the shallow position information with the deep semantic information, effectively adapting to the multiscale target detection in SAR images, significantly improving the detection effect of small targets. The feature enhancement pyramid structure is connected behind the backbone network to weaken the background texture and highlight the target to achieve feature enhancement, improving the ability to extract target features in complex backgrounds. Finally, to further improve the detection performance of the small-scale SAR aircraft dataset, we propose a domain adaptive transfer learning method. Experiments on SADD show that this method can significantly improve the recall rate and F1 score. At the same time, we find that the transfer effect of using homologous but different types of targets as the source domain is better than those of heterologous but same types of targets in SAR aircraft detection, which is instructive for future research.","2151-1535","","10.1109/JSTARS.2022.3169339","National Natural Science Foundation of China(grant numbers:42071339); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761751","Feature enhancement pyramid (FEP);synthetic aperture radar (SAR) aircraft detection;transfer learning","Aircraft;Feature extraction;Synthetic aperture radar;Transfer learning;Atmospheric modeling;Object detection;Data models","aircraft;feature extraction;image enhancement;learning (artificial intelligence);neural nets;object detection;radar detection;radar imaging;synthetic aperture radar","target features;scale expansion;feature enhancement pyramid network;multiscale target detection;public SAR aircraft detection dataset;interference objects;four-scale fusion method;SAR images;feature enhancement pyramid structure;SEFEPNet;SAR aircraft detection;small sample dataset;aircraft detection;SADD;complex background objects;deep semantic information;backbone network;background texture;recall rate improvement;F1 score improvement;adaptive transfer learning method","","3","","44","CCBY","21 Apr 2022","","","IEEE","IEEE Journals"
"Multi-spectral echo signal processing for improved detection and classification of radar targets","M. Vogt; T. Neumann; M. Gerding; C. Dahl; I. Rolfes","Dept. of Electrical Engineering and Information Technology, Ruhr-University Bochum, Bochum, Germany; Dept. of Electrical Engineering and Information Technology, Ruhr-University Bochum, Bochum, Germany; Dept. of Electrical Engineering and Information Technology, Ruhr-University Bochum, Bochum, Germany; Dept. of Electrical Engineering and Information Technology, Ruhr-University Bochum, Bochum, Germany; Dept. of Electrical Engineering and Information Technology, Ruhr-University Bochum, Bochum, Germany","2016 German Microwave Conference (GeMiC)","2 May 2016","2016","","","309","312","A major challenge in radar based remote sensing and imaging is to identify and to detect radar targets, and also to accurately determine their locations and sizes. This especially applies in the case of multiple, spatially distributed radar targets, as for example in radar imaging, automotive radars, and others. Previously, we have proposed a concept for multi-spectral analysis and processing of echo signals for radar level measurement of bulk solids in silos using a spatially fixed antenna beam. This approach has now also been utilized for scanning radar applications. The basic technique is to filter the radar echo signals in multiple frequency sub-bands and to incoherently combine the filtered signals. Furthermore, the variance of envelope signals is analyzed in order to allow for a differentiation between echoes from distributed, randomly arranged scatterers and from spatially isolated single scatterers. The mean over the standard deviation of the envelope signals obtained from the different sub-bands is suggested to be used as an amplitude-invariant parameter for the classification of radar targets. Results of an experimental evaluation of the concept using a mechanically scanning 75 to 80 GHz Frequency Modulated Continuous Wave (FMCW) radar system are presented. It will be shown that the proposed technique enables to largely suppress the echo signal fluctuations, which are given in scenarios of spatially distributed radar targets, and also to distinguish between different kinds of radar targets.","","978-3-9812-6687-0","10.1109/GEMIC.2016.7461618","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7461618","Radar signal processing;scanning radar;imaging radar;level measurement","Radar imaging;Radar antennas;Radar measurements;Radar signal processing;Radar scattering;Fluctuations","CW radar;electromagnetic wave scattering;filtering theory;FM radar;image classification;millimetre wave radar;object detection;radar imaging;remote sensing by radar","echo signal fluctuation suppression;FMCW radar system;frequency modulated continuous wave radar system;amplitude-invariant parameter;envelope signal variance analysis;frequency subbands;radar echo signal filtering;scanning radar applications;radar target identification;radar based imaging;radar based remote sensing;improved radar target classification;improved radar target detection;multispectral echo signal processing;frequency 75 GHz to 80 GHz","","2","","5","","2 May 2016","","","IEEE","IEEE Conferences"
"Remote sensing image fusion using Hausdorff fractal dimension in shearlet domain","B. Biswas; A. Dey; K. N. Dey","Department of Computer Science and Engineering, University of Calcutta; Department of Computer Science and Engineering, University of Calcutta; Department of Computer Science and Engineering, University of Calcutta","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","28 Sep 2015","2015","","","2180","2185","Preservation of spectral information and enhancement of spatial resolution is the most important issue in remote sensing image fusion. In this paper, a new remote sensing satellite image fusion method using shearlet transform (ST) with Hausdorff fractal dimension(HFD) estimation method is proposed. Firstly, ST is used in each high-spatial-resolution panchromatic (PAN) image and multi-spectral image (MS). Then, the low frequency sub-band coefficients from different images are combined according to the HFD method which estimates and selects the modified low-pass band automatically. The composition of different high-pass sub-band coefficients achieved by the ST decomposition is discussed in detail. Finally, we achieve fusion results from the inverse transformation of ST. Experimental results show that the proposed method outperforms many state-of-the-art techniques in both subjective and objective evaluation measures.","","978-1-4799-8792-4","10.1109/ICACCI.2015.7275939","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275939","Remote sensing image fusion;Shearlet Transform;Hausdorff fractal dimension;mutual information","Image fusion;Remote sensing;Fractals;Image edge detection;Satellites;Discrete wavelet transforms","image colour analysis;image enhancement;image fusion;image resolution;inverse transforms;remote sensing","Hausdorff fractal dimension estimation method;shearlet domain;spectral information preservation;spatial resolution enhancement;remote sensing image fusion;HFD estimation method;remote sensing satellite image fusion method;high-spatial resolution panchromatic image;high-spatial resolution PAN image;multispectral image;MS image;modified low-pass band automatic selection;high-pass subband coefficients;ST decomposition","","","","20","IEEE","28 Sep 2015","","","IEEE","IEEE Conferences"
"Estimation of sunflower yield using multi-spectral satellite data (optical or radar) in a simplified agro-meteorological model","R. Fieuzal; F. Baup","Centre d'Etudes Spatiales DE la Biosphère (CESBIO), Université DE Toulouse, France; Centre d'Etudes Spatiales DE la Biosphère (CESBIO), Université DE Toulouse, France","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","4001","4004","This paper aims to compare the crop yield retrieval performances, obtained by assimilating the leaf area index derived from multi-temporal satellite signatures (i.e. reflectances and backscattering coefficients) into an agro-meteorological model. The study is based on the Multispectral Crop Monitoring experimental campaign, conducted in 2010 by the CESBIO laboratory. During the agricultural season of sunflower, regular satellite images were quasi-synchronously acquired by 6 sensors (Formosat-2, Spot-4/5, TerraSAR-X, Radarsat-2 and Alos), over a region located in the south west of France. Calibration and validation steps take advantage of the dense network of monitored fields. Among the wide range of the tested image configurations (multi-frequency and multi-polarization), promising results are offered by optical and co-polarized C-band (i.e. HH and VV) data for yield estimate, with correlation superior to 0.74.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326702","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326702","Sunflower;SAR;multi-frequency;multi-polarization;optical;crop modeling;leaf area index;dry biomass;yield","Satellites;Agriculture;Optical sensors;Biomedical optical imaging;Optical imaging;Biological system modeling;Laser radar","geophysical techniques;remote sensing by radar","sunflower yield;multispectral satellite data;agrometeorological model;Multispectral Crop Monitoring experimental campaign;CESBIO laboratory;TerraSAR-X;Radarsat-2","","4","","9","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Towards a Sentinel-2 Based Human Settlement Layer","P. Helber; B. Bischke; J. Hees; A. Dengel","University of Kaiserslautern, Germany; University of Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Germany; University of Kaiserslautern, Germany","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","5936","5939","In this paper, we present how multi-spectral Sentinel-2 satellite images can be used in a machine learning approach based on an encoder-decoder semantic segmentation network to map human settlements. We show the effectiveness of the proposed CNN approach for the mapping of settlements in experiments with 785 European cities. The proposed approach to learn a settlement mapping with noisy ground truth data results in an effective settlement segmentation network with a mean intersection over union of 80.55% and a pixel accuracy of 87.40%.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898172","Machine Learning;Deep Learning;Computer Vision;Convolutional Neural Network;Remote Sensing;Satellite Images;Sentinel-2;Human Settlements","Satellites;Urban areas;Image segmentation;Earth;Europe;Task analysis;Remote sensing","convolutional neural nets;geophysical image processing;hyperspectral imaging;image denoising;image segmentation;learning (artificial intelligence);remote sensing;terrain mapping","Sentinel-2 based human settlement layer;multispectral Sentinel-2 satellite images;encoder-decoder semantic segmentation network;human settlement mapping;CNN;noisy ground truth data;settlement segmentation network;machine learning","","2","","9","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Detection and Identification of Surface Cover in Coalbed Methane Enrichment Area Based on Spectral Unmixing","S. Zhao; Q. Qin","School of AI and Advanced Computing, Xi'an Jiaotong-Liverpool University; Institute of Remote Sensing and GIS, School of Earth and Space Sciences, Peking University","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","3732","3735","Based on the existing geological data and a large amount of research data in the study area, the article compared and analyzed the difference in hyperspectral reflectance between the potential enrichment area and the reference area. The use of Sentinel-2 multispectral images has been investigated to construct the surface recognition model of coalbed methane enrichment areas from two aspects: vegetation covered area and bare areas. Firstly, semi-automatic endmember extraction is implemented by adopting a more pratical spectral un-mixing method. And the vegetation research area and min-eral research area are separated accordingly. In the vegetation research area, the rich red edge information of Sentinel-2 is used to construct an anomaly recognition model. While in bare soil areas, advanced information processing technology is used to extract weak mineral alteration anomalies. The re-sults are validated with field data.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883648","Multi-spectral image;Endmember Ex-traction;Spectral Un-mixing;Anomaly detection","Methane;Reflectivity;Computational modeling;Vegetation mapping;Land surface;Information processing;Soil","geophysical image processing;geophysical prospecting;image classification;minerals;remote sensing;soil;spectral analysis;vegetation","surface cover;coalbed methane enrichment area;spectral unmixing;existing geological data;potential enrichment area;reference area;Sentinel-2 multispectral images;surface recognition model;vegetation covered area;bare areas;pratical spectral un-mixing method;vegetation research area;min-eral research area;bare soil areas","","","","5","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Artifact-Free Thin Cloud Removal Using Gans","T. Toizumi; S. Zini; K. Sagi; E. Kaneko; M. Tsukada; R. Schettini","NEC corporation; University of Milano-Bicocca, Milan, Italy; NEC corporation; NEC corporation; NEC corporation; University of Milano-Bicocca, Milan, Italy","2019 IEEE International Conference on Image Processing (ICIP)","26 Aug 2019","2019","","","3596","3600","This paper proposes a framework to train an artifact-free thin cloud removal model using Generative Adversarial Nets (GANs) with thick cloud masks. Satellite images are useful in various applications, however their exploitation is often limited by a presence of clouds. The proposed model can safely remove thin clouds for cloudy images while preserving thick clouds areas without creating undesired artifacts. In order to train the model, we propose a following framework divided in three blocks: generation of thick cloud masks for training images based on texture and spectrum analysis, selection of input-target couples of training images and training of the model using the GAN framework. The use of cloud masks for the training images allows the training of a model for clouds removal, robust to artifact generation in areas with thick clouds. Experimental results show that our model can actually avoid the generation of artifacts, and outperforms the conventional method in terms of SSIM index in testing.","2381-8549","978-1-5386-6249-6","10.1109/ICIP.2019.8803652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8803652","Remote sensing;Generative adversarial nets;Multi-spectral image;Cloud removal.","Clouds;Training;Gallium nitride;Generators;Remote sensing;Agriculture;Feature extraction","clouds;feature extraction;geophysical image processing;geophysical signal processing;image classification;image colour analysis;learning (artificial intelligence);remote sensing","artifact-free;GANs;cloud removal model;Generative Adversarial Nets;cloud masks;satellite images;cloudy images;clouds areas;undesired artifacts;training images;GAN framework;artifact generation","","3","1","17","IEEE","26 Aug 2019","","","IEEE","IEEE Conferences"
"Image Classification Using Humps of Histogram","A. K. Khare","Department of Information Technology, National Institute for Smart Government, Shimla, HP, India","2016 Second International Conference on Computational Intelligence & Communication Technology (CICT)","18 Aug 2016","2016","","","146","154","Classification techniques classify the remotely sensed image by using reflectance properties of pixels. This paper presents a new approach to classify multispectral remotely sensed image. This approach classifies the multispectral image using frequencies of spectral bands' grey level values (DN values) in Histogram. It draws histogram for different spectral bands of the image. Then, it finds and separates the humps in histograms. This approach yields more meaningful classification for multi-modal or bi-modal histograms. It creates 3 potential centroids in each hump for each spectral band. More the number of humps, more would be potential centroids for classification. Different spectral bands have different peaks in their humps of histograms. It reads all the pixels of one peak of one band and draw the local histogram of other bands' grey level values using pixels read. This way, peak of one hump of one band can find corresponding peaks in local histogram and these peaks make a pixel that can be a potential centroid and some of these peak frequencies is the actual frequency of that centroid. Now, I choose extreme left and extreme right grey level values whose frequency is greater than or equal to the average frequency of that hump. As each hump of each spectral band has three grey level values, I can find three centroids for each hump of each spectral band. Duplicate centroids are eliminated from the list of centroids. The rest of the centroids are recursively iterated and centroids with lesser frequencies than the nearby centroids are eliminated. Later, algorithm uses gravitational force to find out two nearby centroids.","","978-1-5090-0210-8","10.1109/CICT.2016.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546591","Clustering;Multi-Spectral;Remote Sensing;Histogram;Classification;Hump","Histograms;Remote sensing;Clustering algorithms;Classification algorithms;Gravity;Computational intelligence;Communications technology","image classification;remote sensing","centroids;spectral bands grey level values;multispectral image;reflectance properties;remotely sensed image;histogram;humps;image classification","","","","20","IEEE","18 Aug 2016","","","IEEE","IEEE Conferences"
"Artifact-Free RFI Localization Based on Spatial Smoothing Music in Synthetic Aperture Interferometric Radiometers","T. Zheng; F. Hu; H. Hu; P. Fu","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","6423","6426","Radio-frequency interference (RFI) contaminations hamper the retrieval of geophysical parameters from brightness temperature maps in Synthetic Aperture Imaging Radiometers (SAIRs). This paper is concerned with RFI localization by one snapshot, and an artifact-free detection algorithm based on virtual array and spatial smoothing MUSIC has been proposed. The virtual array is composed of the baseline coverage of the SAIRs. The spatial smoothing method is applied to enhance the rank of the covariance matrix. And the classical MUSIC algorithm is used for direction finding. Experiments on SMOS data are carried out, and the results show better performance than the existing RFI localization algorithms in terms of artifact reduction, which is helpful to make sure whether there are relative weaker RFI sources around a strong RFI source.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323217","RFI localization;spatial smoothing;MU-SIC;soil moisture and ocean salinity (SMOS);synthetic aperture radiometers","Antenna arrays;Multiple signal classification;Covariance matrices;Apertures;Smoothing methods;Location awareness;Spatial resolution","","","","","","6","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"A Wavenumber Domain Imaging Algorithm for Synthetic Aperture Interferometric Radiometry in Near-Field","P. Fu; F. Hu; H. Hu; T. Zheng","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","6511","6514","This paper presents a passive-millimeter imaging algorithnm for synthetic aperture interferometric radiometry (SAIR) in near-field. The SAIR measures the visibility function of the scene by antenna arrays. In the far field, according to the Van Cittert-Zernike theorem, there is a Fourier transform between visibility function and scene brightness temperature. However, in the near field, because of the cross-coupling of azimuth direction and distance direction, Van Cittert-Zernike theorem is not valid. In this paper, the visibility function is transformed into wave number domain using spherical wave decomposition. After compensating the phase term related to the distance, the SAIR near-field imaging is realized.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323395","spherical wave decomposition;passive-millimeter imaging;synthetic aperture interferometric radiometry;near-field imaging","Imaging;Fourier transforms;Apertures;Microwave radiometry;Brightness temperature;Antennas;Antenna measurements","antenna arrays;Fourier transforms;millimetre wave imaging;radar imaging;radiometers;radiometry;synthetic aperture radar","synthetic aperture interferometric radiometry;passive-millimeter imaging algorithnm;SAIR;visibility function;Van Cittert-Zernike theorem;scene brightness temperature;wave number domain;near-field imaging;wavenumber domain imaging algorithm","","1","","5","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Accurate Aerial Object Localization Using Gravity and Gravity Gradient Anomaly","Z. Yan; J. Ma; J. Tian","National Key Laboratory of Science and Technology on Multi-spectral Information Processing Technology, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing Technology, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing Technology, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","19 May 2017","2015","12","6","1214","1217","Autonomous underwater vehicles (AUVs) have been widely used in diverse contexts, especially military affairs. The smooth operation of the AUV requires accurate localization of surrounding objects, especially the aerial objects. In this letter, a novel and practical method is presented for aerial object localization by using gravity and gravity gradient anomaly. Different from the state-of-the-art methods, such as GPS, radar, and laser, the proposed method runs in a passive manner and achieves AUV invisibility without energy emission. Compared with the object localization methods based on gravity and gravity gradient inversion, the proposed method is more practical as no large area gravity and gravity gradient measurements are needed to estimate the object mass. Experimental results demonstrate that the proposed method performs better than the existing methods.","1558-0571","","10.1109/LGRS.2015.2388772","National Natural Science Foundation of China(grant numbers:61074156); Fundamental Research Funds for the Central Universities(grant numbers:CXY12Q039); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7047701","Autonomous underwater vehicles (AUVs);gravity anomaly;gravity gradient anomaly;object localization;Autonomous underwater vehicles (AUVs);gravity anomaly;gravity gradient anomaly;object localization","Gravity;Underwater vehicles;Measurement errors;Sea measurements;Laser radar;Measurement by laser beam;Navigation","autonomous underwater vehicles;gravimeters;object detection;oceanographic techniques","autonomous underwater vehicles;AUV;accurate aerial object localization;gravity gradient anomaly;gravity anomaly;gravity inversion;gravity gradient inversion","","11","","13","IEEE","24 Feb 2015","","","IEEE","IEEE Journals"
"Complex Permittivity Estimation From Millimeter-Wave Radiometry","Y. Hu; F. Hu; Z. Yang; Y. Cheng; C. Wang","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Department of Engineering Physics, Tsinghua University, Beijing, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","23 Jun 2021","2021","18","7","1254","1258","Millimeter-wave (MMW) radiation characteristic has been used in object classification and recognition. Complex permittivity is a key factor affecting the radiation characteristic. Previous study has shown that estimation values of complex permittivity based on multipolarization measurements spread around a special curve (called “C-curve”). In this letter, we analyzed the influence of complex permittivity on MMW radiation. We find that “C-curve” is the manifestation of the solution instability and can be avoided by our new estimation method based on the measurements of multiple incident angles. The simulation and experiment have proved the validity of our method. During research, we also find that objects whose complex permittivities are near the “C-curve” are hard to distinguish by MMW radiometry, unless we measure their radiation of vertical polarization near the Brewster angle. This finding has the guiding significance for object classification, recognition, and information acquisition.","1558-0571","","10.1109/LGRS.2020.2996380","National Natural Science Foundation of China (NSFC)(grant numbers:61871438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106371","Complex permittivity;information acquisition;passive millimeter-wave (PMMW);polarimetric measurement","Permittivity;Radiometry;Estimation;Permittivity measurement;Millimeter wave technology;Extraterrestrial measurements;Temperature measurement","angular measurement;estimation theory;millimetre wave measurement;permittivity measurement;radiometry","C-curve;MMW radiometry;object classification;complex permittivity estimation method;millimeter-wave radiometry;millimeter-wave radiation characteristics;MMW radiation characteristics;vertical polarization radiation;Brewster angle;multipolarization measurements;multiple incident angle measurement","","3","","16","IEEE","2 Jun 2020","","","IEEE","IEEE Journals"
"Evaluation of Multi- and Hyper- Spectral Chl-A Algorithms in the RÍo De La Plata Turbid Waters During a Cyanobacteria Bloom","A. I. Dogliotti; J. I. Gossn; C. Gonzalez; L. Yema; M. Sanchez; I. L. O'Farrell","Instituto de Astronomía y Física del Espacio (IAFE) CONICET/UBA, Argentina; Instituto de Astronomía y Física del Espacio (IAFE) CONICET/UBA, Argentina; Centro de Investigaciones Agua y Saneamientos Argentinos, Buenos Aires, Argentina; Dep. de Ecología, Genética y Evolución, Facultad de Ciencias Exactas y Naturales, Instituto de Ecología, Genética y Evolución (IEGEBA-CONICET), Universidad de Buenos Aires, Argentina; Dep. de Ecología, Genética y Evolución, Facultad de Ciencias Exactas y Naturales, Instituto de Ecología, Genética y Evolución (IEGEBA-CONICET), Universidad de Buenos Aires, Argentina; Dep. de Ecología, Genética y Evolución, Facultad de Ciencias Exactas y Naturales, Instituto de Ecología, Genética y Evolución (IEGEBA-CONICET), Universidad de Buenos Aires, Argentina","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","7442","7445","The Río de la Plata estuary, located in the eastern coast of South America, has large social, ecological and economical importance for Argentina and Uruguay, in which margins their capital cities (Buenos Aires and Montevideo) and a number of harbours, resorts and industrial centres are located. Being the estuary the main source of drinking water for the millions of inhabitants in the region and a recreational area, the increasing occurrence of cyanobacteria blooms, consistently composed of Microcystis and Dolichospermum complex, is worrying and the need for a monitoring tool like remote sensing is highly desirable. In the present study we evaluated existing multi- and hyper-spectral red/NIR chlorophyll-a (chl-$a$) algorithms using radiometric and bio-optical field measurements. Empirically derived multi-spectral algorithms showed poor results, while hyper-spectral algorithms showed better and promising results. S3B/OLCI and CHRIS-PROBA chl-a maps were generated using fitted models derived using the existing in situ dataset.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553148","EU H2020 programme(grant numbers:775983); BELSPO STEREO III programme(grant numbers:SR/00/335); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553148","Rio de la Plata;Cyanobacteria;Chl-a;Multispectral;Hyperspectral;CHRIS;OLCI","South America;Urban areas;Tools;Radiometry;Calibration;Optical sensors;Indexes","ecology;microorganisms;remote sensing;turbidity;water quality","multi spectral Chl-a algorithms;hyperspectral Chl-a algorithms;bio-optical field measurements;remote sensing;industrial centres;Montevideo;Buenos Aires;capital cities;South America;eastern coast;Río de la Plata estuary;cyanobacteria bloom","","2","","15","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A residual convolutional neural network for pan-shaprening","Y. Rao; L. He; J. Zhu","School of Automation Science and Engineering South, China University of Technology, Guangzhou, China; School of Automation Science and Engineering South, China University of Technology, Guangzhou, China; School of Automation Science and Engineering South, China University of Technology, Guangzhou, China","2017 International Workshop on Remote Sensing with Intelligent Processing (RSIP)","26 Jun 2017","2017","","","1","4","Pan-sharpening has become an important tool in remote sensing, which normally aims at fusing a multi-spectral image with high spectral resolution and a panchromatic image with high spatial resolution. However, some problems, such as spectral distortion, are facing pan-sharpening methods. Inspired by the applications of convolutional neural network (CNN) in many areas, we adopt an effective CNN model to fulfill pan-sharpening. In our method, only the sparse residuals between the interpolated MS and the pan-sharpened image are learned, which achieves fast convergence and high pan-sharpening quality. The experimental results on real-world data validate the effectiveness of the method.","","978-1-5386-1990-2","10.1109/RSIP.2017.7958807","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7958807","Residuals;pan-sharpening;CNN;spectral distortion","Spatial resolution;Remote sensing;Neural networks;Convolution;Distortion;Signal resolution","geophysical image processing;image resolution;interpolation;learning (artificial intelligence);neural nets;remote sensing","residual convolutional neural network;remote sensing;multispectral imaging;high spectral resolution;panchromatic imaging;high spatial resolution;high spectral distortion;pan-sharpening method;CNN model;MS interpolation","","28","","","IEEE","26 Jun 2017","","","IEEE","IEEE Conferences"
"Ocean Color Net (OCN) for the Barents Sea","M. Asim; C. Brekke; A. Mahmood; T. Eltoft; M. Reigstad","Department of Physics and Technology, UiT The Arctic University of Norway, Tromsø, Norway; Department of Physics and Technology, UiT The Arctic University of Norway, Tromsø, Norway; Department of Computer Science, Information Technology University, Lahore, Pakistan; Department of Physics and Technology, UiT The Arctic University of Norway, Tromsø, Norway; Department of Arctic and Marine Biology, UiT The Arctic University of Norway, Tromsø, Norway","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","5881","5884","Over recent years, rapid environmental changes in the Arctic and subarctic regions have caused significant alterations in the ecosystem structure and seasonality, including the primary productivity of the Barents Sea. This work aims at improving methodology for studying these features, by estimating chlorophyll-a (chl-a) concentrations in the transitional Barents Sea by remotely sensing its optical properties, in order to better understand the large-scale algal bloom dynamics in the region. The in-situ measurements of chl-a are collected from the year 2016 to 2018 over a wide area of the Barents Sea to cover the spatial and temporal variations in chl-a concentration. Optical images of the Barents Sea are captured by the Multi-Spectral Imager Instrument on Sentinel-2. Using these remotely sensed optical images and the in-situ measurements, we propose a match-up dataset creation method based on the distribution of the remotely sensed reflectance spectra. Different Machine Learning (ML) techniques are assessed to estimate concentration of chl-a using the match-up dataset. Most of these techniques have not been investigated before in the subarctic region such as the Barents Sea. The Ocean Color Net (OCN) regression model proposed in this study has outperformed other ML-based techniques including Support Vector Regression, Gaussian Process Regression, and the globally trained Case-2 Regional/Coast Colour (C2RCC) processing chain model C2RCC-Nets, as well as empirical methods based on spectral band ratios. A wide range of experiments has demonstrated the effectiveness of the proposed OCN for ocean color remote sensing in the subarctic region. The performance of the OCN is also presented spatially by computing chl-a maps in the Barents Sea.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323687","Research Council of Norway(grant numbers:276730); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323687","Barents Sea;Ocean Color;chl-a Monitoring","Arctic;Oceans;Image color analysis;Sea measurements;Optical sensors;Remote sensing;Monitoring","ecology;geophysical image processing;image colour analysis;oceanographic techniques;optical images;remote sensing;underwater optics","subarctic region;Ocean Color Net regression model;OCN;ocean color remote sensing;chl-a;transitional Barents Sea;optical images;chlorophyll-a concentrations;MultiSpectral Imager Instrument;Sentinel-2;Machine Learning techniques;Support Vector Regression","","2","","13","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Spatio-temporal characterization in satellite image time series","A. Radoi; M. Datcu","University Politehnica of Bucharest (UPB), Bucharest, Romania; German Aerospace Center (DLR), Wessling, Germany","2015 8th International Workshop on the Analysis of Multitemporal Remote Sensing Images (Multi-Temp)","10 Sep 2015","2015","","","1","4","Last years have witnessed an increased interest in the analysis of evolution of spatio-temporal structures in large data volumes. The current satellite remote sensing missions allow the recording of long Satellite Image Time Series (SITS) with passive and active sensors. However, the spatio-temporal characteristics of SITS imply different approaches. This paper aims at presenting an overview of these issues, and also some recent results based on Gibbs Markov Random Fields models that are used to describe the spatio-temporal patterns. In addition, in order to obtain an automatic analysis of these patterns, the problem of determining the optimal number of spatio-temporal clusters is also discussed. The experiments are carried on Landsat 7 multi-temporal and multi-spectral images and on Envisat ASAR images, both at 30 meters spatial resolution.","","978-1-4673-7119-3","10.1109/Multi-Temp.2015.7245805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7245805","","Satellites;Remote sensing;Earth;Rate-distortion;Laser radar;Markov random fields;Optical sensors","image processing;Markov processes;remote sensing by radar;sensors;synthetic aperture radar;time series","synthetic aperture radar;advanced SAR;Envisat ASAR image;Landsat 7 multispectral image;Landsat 7 multitemporal image;spatiotemporal pattern;Gibbs Markov random fields model;active sensor;passive sensor;satellite remote sensing mission;large data volume;spatiotemporal structure evolution analysis;satellite image time series;SITS spatiotemporal characterization","","2","","9","IEEE","10 Sep 2015","","","IEEE","IEEE Conferences"
"Segmentation of Sentinel-2 Images on SNAP – an Evaluation with SITEF","A. R. S. Marcal","Departamento de Matemática, Faculdade de Ciências, Universidade do Porto, Portugal","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3872","3875","Image segmentation is widely used in image processing, particularly when there is one or few objects of interest. The segmentation of multi-spectral remote sensing images is more challenging due to the large number and diversity of the objects of interest, and the difficulty in having ground truth to tune the segmentation algorithm parameters and to evaluate the results produced. The Synthetic Image TEsting Framework (SITEF) is a tool to address these issues. As the shape and location of the objects in a synthetic image are known, it provides references to be used for quantitative evaluation of the segmentation results. This paper presents SITEF with an experiment to evaluate the segmentation of a SENTINEL-2 image using the software SNAP.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900044","Image segmentation;synthetic images;similarity indices;segmentation evaluation;SNAP","Image segmentation;Remote sensing;Shape;Indexes;Matlab;Fitting;Tools","geophysical image processing;image segmentation;remote sensing","image processing;multispectral remote sensing images;segmentation algorithm parameters;SITEF;quantitative evaluation;SENTINEL-2 image;image segmentation;synthetic image testing framework;SNAP software","","1","","11","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Open Multi-Processing Acceleration for Unsupervised Land Cover Categorization Using Probabilistic Latent Semantic Analysis","S. Bernabé; C. García; R. Fernández-Beltrán; M. E. Paoletti; J. M. Haut; J. Plaza; A. Plaza","Department of Computer Architecture and Automation, Complutense University, Madrid, Spain; Department of Computer Architecture and Automation, Complutense University, Madrid, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón, Spain; Hyperspectral Computing Laboratory, University of Extremadura, Cáceres, Spain; Hyperspectral Computing Laboratory, University of Extremadura, Cáceres, Spain; Hyperspectral Computing Laboratory, University of Extremadura, Cáceres, Spain; Hyperspectral Computing Laboratory, University of Extremadura, Cáceres, Spain","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","9835","9838","The probabilistic Latent Semantic Analysis (pLSA) model has recently shown a great potential to uncover highly descriptive semantic features from limited amounts of remote sensing data. Nonetheless, the high computational cost of this algorithm often constraints its operational application for land cover categorization tasks. In this scenario, this paper presents an Open Multi-Processing (OpenMP) implementation of the pLSA algorithm for unsupervised Synthetic Aperture Radar (SAR) and Multi-Spectral Imaging (MSI) image categorization. The experimental results suggest that multi-core systems are an important architecture for the efficient processing of both SAR and MSI datasets. Specifically, the proposed approach is able to cover a real scenario exhibiting good results in both accuracy and performance terms.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898507","Open Multi-Processing (OpenMP);multi-core processors;probabilistic Latent Semantic Analysis (pLSA);land cover categorization","Remote sensing;Semantics;Probabilistic logic;Synthetic aperture radar;Agriculture;Buildings;Forestry","geophysical image processing;image classification;radar imaging;remote sensing by radar;synthetic aperture radar","semantic features;probabilistic latent semantic analysis;remote sensing data;land cover categorization tasks;pLSA algorithm;multicore systems;unsupervised land cover categorization;open multiprocessing acceleration;pLSA model;descriptive semantic features;multispectral imaging;MSI;image categorization","","","","16","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"A Desktop-Based Methodology for Collecting Wetland Reference data over Inaccessible Arctic Landscapes","M. Merchant; B. Brisco; M. Mahdianpari; J. Granger; F. Mohammadimanesh; B. DeVries; A. Berg","The Canada Centre for Mapping and Earth Observation, Ottawa, ON, Canada; The Canada Centre for Mapping and Earth Observation, Ottawa, ON, Canada; Department of Electrical and Computer Engineering, Memorial University of Newfoundland, St. John's, NL, Canada; C-CORE, St. John's, NL, Canada; C-CORE, St. John's, NL, Canada; Department of Geography, Environment and Geomatics, University of Guelph, Guelph, ON, Canada; Department of Geography, Environment and Geomatics, University of Guelph, Guelph, ON, Canada","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","5893","5896","Arctic environments are remote and inaccessible, making conventional field-based data collection challenging. Thus, this study describes an efficient desktop-based methodology for deriving reference data to support large-scale remote sensing classification focusing on wetland ecosystems. Our study area was Canada's Southern Arctic Ecozone. Various Earth observation (EO) datasets, including optical, multi-spectral, and topographic, were used as a base to support a photointerpretation process for collecting reference data. Ten 30-by-30-kilometer sampling plots were established across the ecozone for this activity based on a suite of minimum criteria. Reference polygons were assigned to one of the five major wetland classes of the Canadian Wetland Classification System (CWCS), along with a detailed wetland type definition. It is anticipated this methodology will be applied later to other northern ecozones to support large-scale wetland classification updates and status and trends reporting.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883985","Arctic;Machine learning;Google Earth Engine;photointerpretation;CWIM","Training;Earth;Data collection;Market research;Arctic;Optical sensors;Remote sensing","ecology;geophysical image processing;image classification;remote sensing;terrain mapping;vegetation;vegetation mapping","collecting Wetland reference data;inaccessible Arctic landscapes;Arctic environments;conventional field-based data collection challenging;efficient desktop-based methodology;large-scale remote sensing classification;wetland ecosystems;Canada's Southern Arctic Ecozone;Earth observation datasets;30-by-30-kilometer sampling plots;reference polygons;wetland classes;Canadian Wetland Classification System;detailed wetland type definition;northern ecozones;large-scale wetland classification updates","","","","9","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Land cover blending: A new framework to generate high spatial and temporal resolution land cover maps from remotely sensed images","X. Li; F. Ling; Y. Du","Chinese Academy of Sciences, Institute of Geodesy and Geophysics, Wuhan, PR China; Chinese Academy of Sciences, Institute of Geodesy and Geophysics, Wuhan, PR China; Chinese Academy of Sciences, Institute of Geodesy and Geophysics, Wuhan, PR China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","3418","3421","The development of remote sensing has enabled the acquisition of land cover classes and their changes at different scales. The high-spatial-resolution images are usually acquired infrequently, whereas the low-spatial-resolution images which have high repetition rates cannot capture the land cover spatial detail information. A novel spatial-temporal land cover blending method (STLCB) is proposed to produce land cover maps at both high spatial and temporal resolutions, using a single or a series of low-spatial-resolution images and two high-spatial-resolution land cover maps which pre-date and post-date the low-spatial-resolution images as input. A spatial-temporal Markov-random-field based method, which integrates spatial and temporal links of pixels, is proposed in STLCB. The proposed STLCB method is validated based on synthetic and Landsat multi-spectral images. Results show that the overall accuracies of STLCB were higher than 90% in both experiments.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729883","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729883","Spatial-temporal blending;superresolution mapping;Markov-random-field","Remote sensing;Spatial resolution;Satellites;Earth;Reflectivity;MODIS","land cover;remote sensing","land cover maps;remotely sensed images;remote sensing development;high-spatial-resolution images;high repetition rates;land cover spatial detail information;spatial-temporal land cover blending method;spatial-temporal Markov-random-field based method;STLCB method;Landsat multispectral images","","","","9","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"AI Opportunities and Challenges for Crop Type Mapping Using Sentinel-2 and Drone Data","A. Nowakowski; D. Spiller; N. Cremer; R. Bonifacio; M. Marszalek; M. Garcia-Herranz; P. P. Mathieu; D. -H. Kim","Ф-Lab, EOP, European Space Agency, ESRIN, Frascati, Rome, Italy; Italian Space Agency, Rome, Italy; Ф-Lab, EOP, European Space Agency, ESRIN, Frascati, Rome, Italy; Geospatial Team, Analysis and Trends Service, World Food Programme HQ; Ф-Lab, EOP, European Space Agency, ESRIN, Frascati, Rome, Italy; Office of Innovation, UNICEF, New York, USA; Ф-Lab, EOP, European Space Agency, ESRIN, Frascati, Rome, Italy; Office of Innovation, UNICEF, New York, USA","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","258","261","Crop type mapping represents one of the most challenging problems in remote sensing. Spatial, spectral, and temporal information are required in order to obtain a unambiguous distinction among the types of crop. This paper presents a multi-sensor approach, where labelled high-resolution images from drones, limited to small areas, are used to enhance the classification ability of machine learning models based on Sentinel 2 time series. The project described in this paper is organized into three major activities. The first part focused on the exploitation of RGB drone images by using transfer learning and convolutional networks, and it has already been described in a previous work by the team. The second part deals with preliminary analysis of multi-spectral Sentinel 2 time-series using the labelled data from the drones campaign and trees-based machine learning algorithms. Finally, the third ongoing part deals with the combination of drones and satellite data in order to show how drones data can help the Sentinel 2 classification by reducing the effort needed to collect reference crop type information.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553609","Crop-type mapping;Sentinel 2;drones;transfer learning;multi-resolution image analysis","Satellites;Machine learning algorithms;Image analysis;Transfer learning;Time series analysis;Crops;Remote sensing","crops;geophysical image processing;image classification;image resolution;learning (artificial intelligence);remote sensing;time series","unambiguous distinction;multisensor approach;high-resolution images;machine learning models;Sentinel 2 time series;RGB drone images;transfer learning;multispectral Sentinel 2 time-series;labelled data;drones campaign;trees-based machine learning algorithms;satellite data;drones data;Sentinel 2 classification;reference crop type information;crop type mapping;drone data;remote sensing;spatial information;spectral, information;temporal information","","","","20","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Multi Spectral Image Retrieval in Remote Sensing Big Data using Fast Recurrent Convolutional Neural Network","B. Sathiyaprasad; B. S. Kumar","Department of Computer Science and Engineering, Annamalai University, Annamalainagar, Tamilnadu, India; Department of Computer Science and Engineering, Annamalai University, Annamalainagar, Tamilnadu, India","2022 International Conference for Advancement in Technology (ICONAT)","10 Mar 2022","2022","","","1","7","The retrieval of Multispectral image is vast area in machine learning which has input data which is not static as per consideration. They has disadvantages in communication, memory in remote sensing area and compression over the lossy data which is very important, still it cannot be avoided for unnecessary objects. Because of the intricacies (spatial, ghastly, unique information sources, and fleeting irregularities) in on the web and time-arrangement multispectral picture investigation, there is a high event likelihood in varieties of otherworldly groups from an information stream, which decays the experiments in classification (in terms of accuracy) else can change as inefficient. For handling these problems with big data, deep learning is specifically efficient. By all accounts there is an extraordinary possibility for misusing the possibilities of such complex big data. The complex of retrieving remote sensed data with higher resolution in terms of effectiveness and accuracy, this research proposed architecture of neural network in feature extractionofimages collected from satellite using fast recurrent convolutional neural network (FRCNN). Here FRCNN is designed for retrieving the image collected by satellite without any loss of data and to identify objects and accurately locate them. Using the accuracy, precision, recall and F1 score the relevance of the results are computed.","","978-1-6654-2577-3","10.1109/ICONAT53423.2022.9725921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9725921","Multispectral image retrieval;multispectral image analysis;deep learning;big Data;RS;FRCNN","Satellites;Image resolution;Image coding;Multimedia systems;Image retrieval;Big Data;Feature extraction","Big Data;geophysical image processing;image retrieval;learning (artificial intelligence);neural nets;remote sensing","fleeting irregularities;time-arrangement;high event likelihood;information stream;deep learning;complex big data;remote sensed data;fast recurrent convolutional neural network;multispectral image retrieval;remote sensing big data;vast area;machine learning;remote sensing area;lossy data;unnecessary objects;spatial information sources;ghastly information sources;unique information sources","","","","19","IEEE","10 Mar 2022","","","IEEE","IEEE Conferences"
"Deep density estimation based on multi-spectral remote sensing data for in-field crop yield forecasting","L. Baghdasaryan; R. Melikbekyan; A. Dolmajain; J. Hobbs","Intelinair, Inc., Yerevan, Am; Intelinair, Inc., Yerevan, Am; Intelinair, Inc., Yerevan, Am; Intelinair, Inc, Chicago, IL, USA","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","23 Aug 2022","2022","","","2013","2022","Yield forecasting has been a central task in computational agriculture because of its impact on agricultural management from the individual farmer to the government level. With advances in remote sensing technology, computational processing power, and machine learning, the ability to forecast yield has improved substantially over the past years. However, most previous work has been done leveraging low-resolution satellite imagery and forecasting yield at the region, county, or occasionally farm-level. In this work, we use high-resolution aerial imagery and output from high-precision harvesters to predict in-field harvest values for corn-raising farms in the US Midwest. By using the harvester information, we are able to cast the problem of yield-forecasting as a density estimation problem and predict a harvest rate, in bushels/acre, at every pixel in the field image. This approach provides the farmer with a detailed view of which areas of the farm may be performing poorly so he can make the appropriate management decisions in addition to providing an improved prediction of total yield. We evaluate both traditional machine learning approaches with hand-crafted features alongside deep learning methods. We demonstrate the superiority of our pixel-level approach based on an encoder-decoder framework which produces a 5.41% MAPE at the field-level.","2160-7516","978-1-6654-8739-9","10.1109/CVPRW56347.2022.00219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9856943","","Deep learning;Satellites;Conferences;Government;Estimation;Crops;Pattern recognition","agriculture;crops;geophysical image processing;learning (artificial intelligence);regression analysis;remote sensing","traditional machine learning approaches;deep learning methods;pixel-level approach;field-level;deep density estimation;multispectral remote sensing data;in-field crop yield forecasting;central task;computational agriculture;agricultural management;individual farmer;government level;remote sensing technology;computational processing power;leveraging low-resolution satellite imagery;forecasting yield;farm-level;high-resolution aerial imagery;high-precision harvesters;in-field harvest values;corn-raising farms;harvester information;yield-forecasting;density estimation problem;harvest rate;field image;appropriate management decisions;improved prediction;total yield","","","","52","IEEE","23 Aug 2022","","","IEEE","IEEE Conferences"
"A Remote-Sensing Image Pan-Sharpening Method Based on Multi-Scale Channel Attention Residual Network","X. Li; F. Xu; X. Lyu; Y. Tong; Z. Chen; S. Li; D. Liu","College of Computer and Information, Hohai University, Nanjing, China; College of Computer and Information, Hohai University, Nanjing, China; College of Computer and Information, Hohai University, Nanjing, China; School of Information Engineering, Zhengzhou University, Zhengzhou, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Information Center, Yellow River Conservancy Commission, Zhengzhou, China; Information Center, Yellow River Conservancy Commission, Zhengzhou, China","IEEE Access","11 Feb 2020","2020","8","","27163","27177","Pan-sharpening is a significant task that aims to generate high spectral- and spatial- resolution remote-sensing image by fusing multi-spectral (MS) and panchromatic (PAN) image. The conventional approaches are insufficient to protect the fidelity both in spectral and spatial domains. Inspired by the robust capability and outstanding performance of convolutional neural networks (CNN) in natural image super-resolution tasks, CNN-based pan-sharpening methods are worthy of further exploration. In this paper, a novel pan-sharpening method is proposed by introducing a multi-scale channel attention residual network (MSCARN), which can represent features accurately and reconstruct a pan-sharpened image comprehensively. In MSCARN, the multi-scale feature extraction blocks comprehensively extract the coarse structures and high-frequency details. Moreover, the multi-residual architecture guarantees the consistency of feature learning procedure and accelerates convergence. Specifically, we introduce a channel attention mechanism to recalibrate the channel-wise features by considering interdependencies among channels adaptively. The extensive experiments are implemented on two real-datasets from GaoFen series satellites. And the results show that the proposed method performs better than the existing methods both in full-reference and no-reference metrics, meanwhile, the visual inspection displays in accordance with the quantitative metrics. Besides, in comparison with pan-sharpening by convolutional neural networks (PNN), the proposed method achieves faster convergence rate and lower loss.","2169-3536","","10.1109/ACCESS.2020.2971502","National Basic Research Program of China (973 Program)(grant numbers:2018YFC0407105); Technology Project of China Huaneng Group(grant numbers:MW 2017/P28); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8981952","Pan-sharpening;deep learning;multi-scale feature extraction;multi-residual learning;channel-attention mechanism;convergence acceleration","Feature extraction;Remote sensing;Spatial resolution;Computer architecture;Convolution;Convolutional neural networks","convolutional neural nets;feature extraction;geophysical image processing;image fusion;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","remote-sensing image pan-sharpening method;multiscale channel attention residual network;spectral domains;spatial domains;convolutional neural networks;natural image super-resolution tasks;CNN-based pan-sharpening methods;pan-sharpened image;multiscale feature extraction blocks;multiresidual architecture;channel attention mechanism;channel-wise features;spatial-resolution remote-sensing image","","16","","52","CCBY","4 Feb 2020","","","IEEE","IEEE Journals"
"FY-3D/MERSI-II Meteorological Satellite Image Fusion Method and its Application","Z. Yunyu; C. Yingying; W. Ming; H. Mingqiong; T. Jing","School of Resource and Environmental Science, Wuhan University, Wuhan, China; Hubei Meteorological Service Center, Wuhan, China; Institute of Heavy Rain, CMA, Wuhan, China; Hubei Meteorological Service Center, Wuhan, China; Hubei Meteorological Service Center, Wuhan, China","2020 IEEE 3rd International Conference on Information Systems and Computer Aided Education (ICISCAE)","2 Nov 2020","2020","","","237","240","In order to solve the problem that the spatial resolution of some channels of the FY-3D satellite medium-resolution spectral imager (MERSI-II) is not high enough, 19 channel images with a spatial resolution of 1000 meters are merged and enhanced. Based on the geometric correction of the original data, the Gram-Schimidt Transform remote sensing fusion algorithm is selected, and the panchromatic image extracted from the MERSI-II 250-meter spatial resolution image is used. Then selected the WMO “natural color” synthesis scheme is to display RGB three-color synthesis on the fused image. The result of FY-3D satellite image data fusion shows that the fused image has clear colors, which not only retains the multi-spectral characteristics of 1000-meter channel data, but also has the high-resolution advantage of 250-meter channel data. The comparison experiment found that compared with the original image, the fused image has greatly improved the ability to recognize the topography of rivers, lakes, land and sea boundaries, and mountain range trends. And the ability to recognize snow, vegetation cover, and structural features of cloud has also been significantly enhanced. The fusion algorithm can greatly improve the remote sensing fine analysis capability of FY-3D / MERSI - II images in the fields of disaster prevention and mitigation and ecological civilization construction.","","978-1-7281-8304-6","10.1109/ICISCAE51034.2020.9236890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9236890","FY-3D;Image fusion;spatial resolution;remote sensing","Spatial resolution;Remote sensing;Satellites;Monitoring;Image fusion;Snow;Image color analysis","ecology;geophysical image processing;geophysical techniques;image colour analysis;image fusion;image resolution;remote sensing;sensor fusion","FY-3D satellite medium-resolution spectral imager;channel images;Gram-Schimidt Transform remote sensing fusion algorithm;panchromatic image;spatial resolution image;WMO natural color synthesis scheme;FY-3D satellite image data fusion;channel data;high-resolution advantage;MERSI-II meteorological satellite image fusion method;RGB three-color synthesis;topography;rivers;lakes;sea boundaries;land boundaries;snow;mountain range trends;vegetation cover;structural features","","","","24","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
"Image Simulations for the Advanced Optical Satellite (ALOS-3)","T. Tadono; A. Oka; H. Watarai; J. Takaku; F. Ohgushi; M. Doutsu",Japan Aerospace Exploration Agency (JAXA); Japan Aerospace Exploration Agency (JAXA); Japan Aerospace Exploration Agency (JAXA); Remote Sensing Technology Center of Japan (RESTEC); Remote Sensing Technology Center of Japan (RESTEC); Remote Sensing Technology Center of Japan (RESTEC),"IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","7731","7734","The “Advanced Optical Satellite” (nicknamed “ALOS-3”) is the next high-resolution optical mission as a successor of the Advanced Land Observing Satellite (ALOS) in Japan Aerospace Exploration Agency (JAXA), and now conducting the Critical Design Review (CDR) phase. The mission objectives of ALOS-3 are (1) to contribute safe and secure social including provisions for natural disasters, and (2) to create and update geo-spatial information. The “wide-swath and high-resolution optical imager” is designed to be achieved the missions, which consists of the panchromatic band with 0.8 m ground sampling distance (GSD) and multi-spectral six bands with 3.2 m GSD, and the observation swath width is 70 km at nadir. In addition, the satellite has the body pointing capability within 60 deg. from nadir that will contribute to an emergency observation. In this study, the simulated images generation is introduced to investigate the feasibility of the missions as a part of pre- flight phase study.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517726","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517726","ALOS;optical;image processing;ALOS-3","Optical imaging;Satellites;Optical sensors;Monte Carlo methods;Satellite broadcasting;Instruments;Orbits","artificial satellites;disasters;geophysical image processing;remote sensing by radar","emergency observation;geospatial information;natural disaster;Advanced Land Observing Satellite;high-resolution optical mission;Advanced Optical Satellite;image simulations;high-resolution optical imager;ALOS-3;Japan Aerospace Exploration Agency","","5","","4","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Mapping Snow Cover Extent Using Optical and SAR Data","A. Wendleder; A. J. Dietz; K. Schork","Land surface Applications (LAX), German Remote Sensing Data Center (DFD), Wessling; Land surface Applications (LAX), German Remote Sensing Data Center (DFD), Wessling; Land surface Applications (LAX), German Remote Sensing Data Center (DFD), Wessling","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","5104","5107","Snow cover plays an important role both globally and regionally as it is fundamental for local water availability, river run-off, and groundwater recharge. Hence, the exact knowledge of extent and dynamic of the snow coverage is essential. This study combines synergetic optical and SAR data with the main object to map the snow cover extent. As the Sentinel-Mission provides a wide swath width and a high revisit time (2-3 days at mid-latitudes with same acquisition geometry), the Sentinel-1 Interferometric Wide Swath Mode (IW) SAR data and Sentinel-2 multi-spectral data are used. Additionally, the TanDEM-X DEM is applied for the exact determination of the snow line as well as for snow classification. The mapping of the snow cover extent is applied on the three test sites Devon Island in Canada, Nordenskiöld, Svalbard, and French Alps, France which are characterized by different topography and land cover. The classification achieved an overall accuracy of 85% for Devon Island, 60% for Nordenskiöld and 88% for the French Alps.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518374","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518374","Snow Cover Extent;optical data;SAR;NDSI;Sentinel-1;Sentinel-2","Snow;Synthetic aperture radar;Backscatter;Ice;Optical sensors;Integrated optics;Optical interferometry","groundwater;hydrological techniques;radar imaging;radar interferometry;remote sensing;snow;synthetic aperture radar;terrain mapping","land cover;local water availability;snow cover extent;TanDEM-X DEM;Canada;Nordenskiöld;Svalbard;French Alps;Devon Island;river run-off;groundwater recharge;snow classification;snow line;Sentinel-2 multispectral data;Sentinel-1 Interferometric Wide Swath Mode SAR data;wide swath width;Sentinel-Mission;snow coverage","","1","","6","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Deep Learning for Monitoring Glacial Lakes Formation using Sentinel 2 Multispectral Data","A. Basit; M. K. Bhatti; M. Ali; T. Fatima; B. Minchew; M. A. Siddique","Remote Sensing and Spatial Analytics Lab, Information Technology University (ITU), Pakistan; Remote Sensing and Spatial Analytics Lab, Information Technology University (ITU), Pakistan; Intelligent Machines Lab, Information Technology University (ITU), Pakistan; Water & Agriculture Division, National Engineering Services Pakistan, Lahore, Pakistan; Glacier Dynamics and Remote Sensing Group, D-EAPS MIT, USA; Remote Sensing and Spatial Analytics Lab, Information Technology University (ITU), Pakistan","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","179","182","Glacial lake outburst floods (GLOFs) are a major threat to the local communities and important infrastructures in the high mountain regions. This paper focuses on the development of a benchmark dataset for glacial lakes classification in Sentinel 2 multi-spectral data and subsequent detection of glacial lakes prior to a glacial lake outburst flood (GLOF). Towards this end, we collected Sentinel 2 true color scenes of High-Mountain Asia (HMA) region using glacial lakes inventory of this region. It covers an area of 2080.12 km2 with nearly 30,121 glacial lakes. After data collection, we retained 1200 cloud free true color images and manually generated their ground truth masks. The dataset covers lakes with different shapes, sizes and radiometric signatures. For detection of glacial lakes, we used an encoder-decoder based convolutional neural network (CNN). The model is trained on the labelled dataset of glacial lakes for semantic segmentation of true color images into two relevant classes: lake and no lake. The performance of the proposed model is evaluated using intersection over union (IoU) score. It classifies glacial lakes correctly with an IoU score of 79.90%, which is quite good as far as complexity of the problem is concerned.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883150","Glacial lake outburst floods (GLOFs);deep learning;Sentinel 2;semantic segmentation;disaster management","Image segmentation;Shape;Image color analysis;Semantics;Color;Lakes;Radiometry","floods;geophysical image processing;glaciology;hydrological techniques;image classification;image segmentation;lakes;learning (artificial intelligence);neural nets;remote sensing","glacial lakes classification;Sentinel 2 multispectral data;glacial lake outburst flood;Sentinel 2 true color scenes;glacial lakes inventory;30 lakes;121 glacial lakes;monitoring glacial lakes formation","","","","14","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Blue Noise Sampling and Nystrom Extension for Graph Based Change Detection","D. A. Jimenez-Sierra; H. D. Benítez-Restrepo; G. R. Arce; J. F. Florez-Ospina","Departamento de Electrónica y Ciencias de la Computación, Pontificia Universidad Javeriana Cali; Departamento de Electrónica y Ciencias de la Computación, Pontificia Universidad Javeriana Cali; Multimodal Imaging and Spectroscopy Laboratory, University of Delaware; Multimodal Imaging and Spectroscopy Laboratory, University of Delaware","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2895","2898","In this paper, we address the problem of sampling on graphs for change detection in large multi-spectral (MS) and synthetic aperture radar (SAR) images by proposing a graph-based data-driven framework. The main steps of the proposed approach are: (i) the segmentation of regions that enclose the change; (ii) the use of smoothness prior for learning a graph of the regions; (iii) the integration of blue-noise sampling (BN) in the change detection scheme. We validate our approach in 14 real cases of remote sensing according to quantitative analyses. The results confirm that using a structured sampling such as BN outperforms recent state-of-the-art methods in change detection for multimodal data.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9555107","The World Bank; Colombian Ministry of Science, Technology and Innovation; Colombian Ministry of Industry and Tourism, and ICETEX(grant numbers:FP44842-217-2018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555107","Blue-noise;change detection;data fusion;graph;remote sensing images;sampling;smoothness","Measurement;Statistical analysis;Signal processing algorithms;Tools;Signal processing;Sampling methods;Radar polarimetry","graph theory;image sampling;image segmentation;radar detection;radar imaging;remote sensing by radar;synthetic aperture radar","multimodal data;quantitative analyses;remote sensing;MS images;multispectral images;SAR images;synthetic aperture radar images;graph-based data-driven framework;graph based change detection;Nystrom extension;blue noise sampling;structured sampling","","1","","17","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Multi-sensor data fusion for long range demining area reduction","S. Savastano; R. Guida","Surrey Space Centre, University of Surrey, Guildford, UK; Surrey Space Centre, University of Surrey, Guildford, UK","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","1909","1912","Multisensor data fusion is getting more importance with the increasing number of available satellite sensors. The aim of data fusion is to take advantages of combining different types of data to improve accuracies. However features extracted from different sensors will often have different statistical properties, and therefore combining data in an efficient way is not a trivial task. This paper proposes a new algorithm for data fusion between classification maps separately derived by application of clustering algorithms to PolSAR and Multi-spectral datasets. The expected new output is a map where all the classes identified with each single dataset will be present. The pixels assigned to the same class with both datasets will be characterized by a higher likelihood to belong to that class. The application for which the data fusion has been developed is that of hazardous areas reduction in land mines clearing operation. At this purpose a demonstration site has been set up in Poland within the FP7 D-BOX project and the fusion framework tested on it with acquisition of remote sensing imagery.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326167","Multispectral;PolSAR;Clustering;Data fusion;Remote Sensing","Clustering algorithms;Data integration;Landmine detection;Hazards;Image resolution;Satellites;Sensors","geophysical techniques;remote sensing by radar;sensors","multisensor data fusion;long range demining area reduction;satellite sensors;classification maps;PolSAR clustering algorithms;hazardous areas reduction;FP7 D-BOX project;remote sensing imagery","","","","7","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"A Fusion Method of Multi-spectral Image and Panchromatic Image Based on NSCT Transform and Adaptive Gamma Correction","L. Jiahuan; Z. Jian; D. Yunfei","UCAS Beijing, China, Xi'an, China; Chinese Academy of Science, Institute of Optics and Precision Mechanics, Xi'an, China; Chinese Academy of Science, Xi'an Institute of Optics and Precision Mechanics, Xi'an, China","2018 3rd International Conference on Information Systems Engineering (ICISE)","17 Jan 2019","2018","","","10","15","The purpose of remote sensing images fusion is to produce a fused image that contains more clear, accurate and comprehensive information than any single image. an image fusion algorithm incorporating gamma-corrected is proposed based on non-subsampled Contourlet transform (NSCT). Firstly, the multispectral image is transformed to intensity-hue-saturation (IHS) system. Secondly, the panchromatic image and the component intensity of the multispectral image are decomposed by NSCT. Then the NSCT coefficients of high and low frequency subbands are fused by different rules, respectively. For the low frequency subbands, an adaptive gamma correction was used and mutual information as the threshold for the weighted coefficient fusion. The max-abs-based fusion rule is used to fuse the high frequency coefficients. Finally, the fusion image can be obtained by performing inverse NSCT and inverse IHS transform. Experiment results demonstrate that the fused image contains abundant detailed contents and preserves the saliency structure. Our proposed method achieves better visual quality than the current methods.","2160-1291","978-1-5386-6259-5","10.1109/ICISE.2018.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8614472","Multispectral and panchromatic images;image fusion;NSCT;gamma correction","Image fusion;Filter banks;Spatial resolution;Discrete wavelet transforms;Mutual information","geophysical image processing;image colour analysis;image enhancement;image fusion;remote sensing;transforms","low frequency subbands;adaptive gamma correction;weighted coefficient fusion;max-abs-based fusion rule;high frequency coefficients;fusion image;inverse NSCT;fused image;fusion method;multispectral image;panchromatic image;NSCT transform;remote sensing images fusion;nonsubsampled Contourlet;intensity-hue-saturation system;NSCT coefficients;image fusion algorithm","","3","","14","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"Mapping Crop Leaf Area Index from Multi-Spectral Imagery Onboard an Unmanned Aerial Vehicle","W. Zhu; Y. Huang; Z. Sun","Chinese Academic of Science, Observation and Modeling Institute of Geographic Sciences and Natural Resources Research, Beijing, China; Chinese Academic of Science, LREIS Institute of Geographic Sciences and Natural Resources Research, Beijing, China; Chinese Academic of Science, Observation and Modeling Institute of Geographic Sciences and Natural Resources Research, Beijing, China","2018 7th International Conference on Agro-geoinformatics (Agro-geoinformatics)","30 Sep 2018","2018","","","1","5","Leaf area index (LAI) is a significant biophysical parameter used in many agronomic and ecological models. In comparison with satellite remote sensing, unmanned aerial vehicles(UAV) technology can obtain imagery with high spatial resolution for better accuracy of LAI estimation. This study conducted global sensitivity of input variables in PROSAIL model by the extended Fourier amplitude sensitivity test (EFAST) method and determined the most sensitive bands and vegetation indices (VIs) to LAI. Estimation accuracy of five input variable combinations in cost-functions was compared. Results of global sensitivity analysis show that green and red band are sensitive to LAI, and the correlation coefficient between measured LAI and estimated LAI from combination of these two bands as input variables in cost-functions is 0.85. For VIs, the most sensitive input variables are LAI, average leaf angle(ALA) and chlorophyll content(Chl). VIs of NDVI, RVI and MSR are sensitive to LAI with corresponding total sensitivity of 0.80, 0.69 and 0.72 respectively. The correlation coefficient between measured LAI and estimated LAI from VIs is over 0.75, indicating that it may be an alternative way for LAI inversion in PROSAIL model through LUT method.","","978-1-5386-5038-7","10.1109/Agro-Geoinformatics.2018.8475985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8475985","unmanned aerial vehicle;leaf area index;PROSAIL model;crops;vegetation index;winter wheat;global sensitivity analysis","Input variables;Indexes;Vegetation mapping;Sensitivity analysis;Analytical models;Biological system modeling","autonomous aerial vehicles;crops;ecology;geophysical image processing;radiative transfer;remote sensing;sensitivity analysis;vegetation mapping","LAI inversion;sensitive input variables;measured LAI;correlation coefficient;red band;green band;global sensitivity analysis show;cost-functions;input variable combinations;estimation accuracy;vegetation indices;extended Fourier amplitude sensitivity test method;PROSAIL model;LAI estimation;high spatial resolution;satellite remote sensing;ecological models;agronomic models;significant biophysical parameter;unmanned aerial vehicle;multispectral imagery onboard;mapping crop leaf area index","","2","","13","IEEE","30 Sep 2018","","","IEEE","IEEE Conferences"
"Multi-spectral sensors monitoring of the epidemic of Xylella Fastidiosa in the Apulia Region","S. Dell’Anna; G. Mansueto; P. Boccardo; E. Arco","Politecnico di Torino, Corso Duca degli Abruzzi 24, Turin, Italy; ITHACA, Via Pier Carlo Boggio 61, Turin, Italy; DIST, Politecnico di Torino, Viale Mattioli 39, Turin, Italy; DIST, Politecnico di Torino, Viale Mattioli 39, Turin, Italy","2022 IEEE 21st Mediterranean Electrotechnical Conference (MELECON)","3 Aug 2022","2022","","","610","615","In October 2013, the Apulia Region in Italy, unexpectedly, had to find itself to face the epidemic of Xylella Fastidiosa which in less than 10 years has decimated millions of olive trees, endangering the 40% of the regional olive-growing heritage. Taking into account the fact that there is not a definitive cure discovered yet, the only solution is the prevention linked to constant monitoring in the so-called buffer areas with diligent efforts to delimitate the phenomenon on a very local scale. Back then, remote sensing and, in particular, multispectral and hyperspectral sensors, seemed to be the key to depicting the problem to a multidimensional extent and coming up with the most adequate ways to tackle it. This research work focuses on the analysis of 4 olive groves (of the Ogliarola cultivar) in the province of Brindisi (Italy), with different symptomatic states, using a multispectral sensor mounted on a UAV system. Among a number of different vegetation indexes (IVs) calculated, the GNDVI and the BNDVI outperform to identify the effects of the Xylella Fastidiosa infection, which was further confirmed by the laboratory analyses. This confirmation has affirmed the validity of the approach used aiming at identifying “anomalies” on non-symptomatic trees and establishing a first early warning system for a subsequent more in-depth investigation in the field. Further developments will investigate the implementation of a segmentation algorithm, according to the threshold values of the IVs defined in this work, and the use of hyperspectral sensors, in order to identify anomalies on the foliage, attributable to a potential Xylella Fastidiosa infection on the trees.","2158-8481","978-1-6654-4280-0","10.1109/MELECON53508.2022.9843049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9843049","Xylella Fastidiosa;Olive groves;Multispectral;Early warning","Epidemics;Electric potential;Hyperspectral sensors;Conferences;Vegetation mapping;Vegetation;Indexes","agriculture;crops;geophysical image processing;image segmentation;remote sensing;vegetation;vegetation mapping","definitive cure;constant monitoring;buffer areas;diligent efforts;local scale;remote sensing;hyperspectral sensors;multidimensional extent;adequate ways;4 olive groves;Ogliarola cultivar;different symptomatic states;multispectral sensor;UAV system;different vegetation indexes;IVs;nonsymptomatic trees;early warning system;potential Xylella Fastidiosa infection;multispectral sensors monitoring;epidemic;Apulia Region;October 2013;olive trees;time 10.0 year","","","","12","IEEE","3 Aug 2022","","","IEEE","IEEE Conferences"
"Land Cover Map Production of the Sakarya Basin from Multi-Temporal Satellite Images","M. S. Aydemir; A. N. Keyik; F. Kahraman; E. Aptoula","BİLGEM TÜBİTAK, Kocaeli, Türkiye; BİLGEM TÜBİTAK, Kocaeli, Türkiye; BİLGEM TÜBİTAK, Kocaeli, Türkiye; Bilgisayar Mühendisliği Bölümü, Gebze Teknik Üniversitesi, Kocaeli, Türkiye","2020 28th Signal Processing and Communications Applications Conference (SIU)","7 Jan 2021","2020","","","1","4","The proliferation of multi-temporal remote sensing imagery, especially through Sentinel 2 satellites, has reinforced efforts towards the processing of multi-spectral and multi-temporal images. In this paper, we present the results of our study on the production of land cover/land use of the Sakarya basin, employing CORINE ground truths. The main contribution of our study is the exploitation of the temporal dimension through 3 dimensional convolutional neural networks, motivated by their capacity to process data across the temporal dimension of the input patch cube. Our experiments spanning 26 classes at a region-wide scale, show that 3D convolutional neural networks possess a strong potential in this regard.","2165-0608","978-1-7281-7206-4","10.1109/SIU49456.2020.9302466","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302466","Remote sensing;convolutional neural networks;land cover;land use;CORINE","Convolutional neural networks;Satellites;Production;Three-dimensional displays;Sensors;Remote sensing;Art","geophysical image processing;image classification;land cover;neural nets;remote sensing;terrain mapping","land cover map production;Sakarya basin;multitemporal satellite images;multitemporal remote sensing imagery;Sentinel 2 satellites;multitemporal images;CORINE ground truths;temporal dimension;3 dimensional convolutional neural networks;3D convolutional neural networks","","","","","IEEE","7 Jan 2021","","","IEEE","IEEE Conferences"
"Self-Supervised Learning for Invariant Representations From Multi-Spectral and SAR Images","P. Jain; B. Schoen-Phelan; R. Ross","School of Computer Science, Technological University Dublin, Dublin, Ireland; School of Computer Science, Technological University Dublin, Dublin, Ireland; School of Computer Science, Technological University Dublin, Dublin, Ireland","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","21 Sep 2022","2022","15","","7797","7808","Self-supervised learning (SSL) has become the new state of the art in several domain classification and segmentation tasks. One popular category of SSL are distillation networks, such as Bootstrap Your Own Latent (BYOL). This work proposes RS-BYOL, which builds on BYOL in the remote sensing (RS) domain where data are nontrivially different from natural RGB images. Since multispectral (MS) and synthetic aperture radar (SAR) sensors provide varied spectral and spatial resolution information, we utilize them as an implicit augmentation to learn invariant feature embeddings. In order to learn RS-based invariant features with SSL, we trained RS-BYOL in two ways, i.e., single channel feature learning and three channel feature learning. This work explores the usefulness of single channel feature learning from random 10 MS bands of 10–20 m resolution and VV-VH of SAR bands compared to the common notion of using three or more bands. In our linear probing evaluation, these single channel features reached a 0.92 F1 score on the EuroSAT classification task and 59.6 mIoU on the IEEE Data Fusion Contest segmentation task for certain single bands. We also compare our results with ImageNet weights and show that the RS-based SSL model outperforms the supervised ImageNet-based model. We further explore the usefulness of multimodal data compared to single modality data, and it is shown that utilizing MS and SAR data allows better invariant representations to be learnt than utilizing only MS data.","2151-1535","","10.1109/JSTARS.2022.3204888","Science Foundation Ireland(grant numbers:13/RC/2106_P2); ADAPT SFI Research Centre at Technological University Dublin ADAPT; SFI Research Centre for AI-Driven Digital Content Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9880533","Optical-synthetic aperture radar (SAR) fusion;satellite images;self-supervised learning (SSL);unsupervised learning","Synthetic aperture radar;Task analysis;Optical sensors;Optical imaging;Representation learning;Remote sensing;Satellites","feature extraction;geophysical image processing;image classification;image fusion;image resolution;image segmentation;radar imaging;remote sensing by radar;supervised learning;synthetic aperture radar","segmentation tasks;RS-BYOL;remote sensing domain;natural RGB images;synthetic aperture radar;spectral resolution information;spatial resolution information;invariant feature embeddings;RS-based invariant features;single channel feature learning;random 10 MS bands;SAR bands;single channel features;single bands;RS-based SSL model;supervised ImageNet-based model;single modality data;invariant representations;MS data;multispectral;SAR images;self-supervised learning;domain classification;IEEE data fusion contest segmentation task;size 10.0 m to 20.0 m","","3","","70","CCBY","7 Sep 2022","","","IEEE","IEEE Journals"
"Multi-Spectral Satellite Image Analysis for Feature Identification and Change Detection VAST Challenge 2017: Honorable Mention for Good Facilitation of Single Image Analysis","S. Malla; A. Tuladhar; G. J. Quadri; P. Rosen","Department of Computer Science and Engineering, University of South Florida, Tampa, Florida; Department of Computer Science and Engineering, University of South Florida, Tampa, Florida; Department of Computer Science and Engineering, University of South Florida, Tampa, Florida; Department of Computer Science and Engineering, University of South Florida, Tampa, Florida","2017 IEEE Conference on Visual Analytics Science and Technology (VAST)","23 Dec 2018","2017","","","205","206","Satellite images are helpful in remote sensing of land features. However, such multi-spectral images cannot be displayed using readily available imaging tools. We developed a tool in Processing that is able to read in multi-spectral images and display each band as a grayscale image. This tool also allows for mapping of any of the bands to red, green or blue channel of the displayed image. In this paper, we describe how such tool can be used in identifying land features as well as assist in finding changes over time. We used our tool to successfully solve the VAST challenge 2017 mini-challenge 3.","","978-1-5386-3163-8","10.1109/VAST.2017.8585482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8585482","H.5.2 [Information Interfaces and Presentation]: User Interfaces—;Graphical User Interfaces (GUI);H.1.2 [Models and Principles]: User/Machine Systems—;Visual Analytics","Tools;Vegetation mapping;Color;Roads;Satellites;Image color analysis;Gray-scale","geophysical image processing;image colour analysis;land cover;remote sensing","multispectral satellite image analysis;feature identification;change detection;satellite images;land features;grayscale image;displayed image;single image analysis","","","","2","IEEE","23 Dec 2018","","","IEEE","IEEE Conferences"
"An improved clean algorithm for RFI mitigation in aperture synthesis radiometers","X. Peng; F. Hu; F. He; D. Zhu; Y. Cheng; H. Hu; T. Zheng","School of Electronic Information and Communications, HuaZhong University of Science and Technology, Wuhan, China; The National Key Laboratory of Science and Technology on Multi-spectral Information Processing, Wuhan, China; The National Key Laboratory of Science and Technology on Multi-spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, HuaZhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, HuaZhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, HuaZhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, HuaZhong University of Science and Technology, Wuhan, China","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","3448","3451","The SMOS mission is developed for monitoring the surface soil moisture and ocean salinity by a two dimensional L-band synthetic aperture interferometric radiometer. However, artificial sources emitting in the protected L-band are contaminating the retrievals of the soil moisture and ocean salinity from the measurements. To mitigate the RFIs' impacts, the classical CLEAN algorithm was introduced and works well for most isolated point RFI sources. However, in presence of interactions between different RFI sources, the performance of the classical CLEAN algorithm will deteriorate. Thus, in this work, we present an improved CLEAN algorithm to compensate for the RFIs' impacts more accurately in presence of interactions from adjacent RFI sources. It adds back one previously detected RFI to the cleaned map and then reestimates the parameter of this RFI source. Numerical studies using synthetic SMOS data have been carried out to demonstrate that the proposed algorithm outperforms the classical CLEAN algorithm in presence of interactions between RFI sources.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127740","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127740","RFI mitigation;aperture synthesis radiometers (ASR);improved CLEAN algorithm","Earth;Apertures;Extraterrestrial measurements;Pollution measurement;Interference;SMOS mission;Parameter estimation","geophysical signal processing;hydrological techniques;oceanographic equipment;radiofrequency interference;radiometers;radiometry;remote sensing by radar;salinity (geophysical);soil;synthetic aperture radar","classical CLEAN algorithm;improved clean algorithm;surface soil moisture;dimensional L-band synthetic aperture interferometric radiometer;protected L-band;aperture synthesis radiometer;artificial ocean salinity source;RFI source mitigation detection;synthetic SMOS mission data","","1","","8","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"A new vegetation index for cooperative inversion of winter wheat covered surface soil moisture based on sentinel-1/2 remote sensing data","B. Zhang; J. Zhao; N. Li; Z. Guo","College of Computer and Information Engineering, Henan University, Kaifeng, China; College of Computer and Information Engineering, Henan University, Kaifeng, China; College of Computer and Information Engineering, Henan University, Kaifeng, China; College of Computer and Information Engineering, Henan University, Kaifeng, China","IET International Radar Conference (IET IRC 2020)","22 Sep 2021","2020","2020","","445","449","Aiming at the problem of the interfere of winter wheat on radar backscattering coefficient in surface soil moisture inversion, a new vegetation index called Fusion Vegetation Index (FVI) is defined in this study. Based on the Multi-Spectral Imager (MSI) data of Sentinel-2, and the Synthetic Aperture Radar (SAR) data of Sentinel-1, using FVI to retrieve water content of winter wheat, combined with Water Cloud model, the interference of winter wheat in soil moisture inversion was reduced. The results show that good soil moisture retrieval results can be obtained by combining with FVI.","","","10.1049/icp.2021.0636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9545596","","","backscatter;geophysical image processing;moisture;remote sensing by radar;soil;synthetic aperture radar;vegetation;vegetation mapping","winter wheat covered surface soil moisture;radar backscattering coefficient;surface soil moisture inversion;Fusion Vegetation Index;FVI;MultiSpectral Imager data;Sentinel-2;Synthetic Aperture Radar data;soil moisture retrieval results;Sentinel-1;Water Cloud model","","","","","","22 Sep 2021","","","IET","IET Conferences"
"Fast and High-Quality Blind Multi-Spectral Image Pansharpening","L. Yu; D. Liu; H. Mansour; P. T. Boufounos","Department of Electrical and Computer Engineering, Rice University, Houston, TX, USA; Signal Processing Group, Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Signal Processing Group, Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Signal Processing Group, Mitsubishi Electric Research Laboratories, Cambridge, MA, USA","IEEE Transactions on Geoscience and Remote Sensing","14 Jan 2022","2022","60","","1","17","Blind pansharpening addresses the problem of generating a high spatial-resolution multi-spectral (HRMS) image given a low spatial-resolution multi-spectral (LRMS) image with the guidance of its associated spatially misaligned high spatial-resolution panchromatic (PAN) image without parametric side information. In this article, we propose a fast approach to blind pansharpening and achieve the state-of-the-art image reconstruction quality. Typical blind pansharpening algorithms are often computationally intensive since the blur kernel and the target HRMS image are often computed using iterative solvers and in an alternating fashion. To achieve fast blind pansharpening, we decouple the solution of the blur kernel and of the HRMS image. First, we estimate the blur kernel by computing the kernel coefficients with minimum total generalized variation that blur a downsampled version of the PAN image to approximate a linear combination of the LRMS image channels. Then, we estimate each channel of the HRMS image using local Laplacian prior (LLP) to regularize the relationship between each HRMS channel and the PAN image. Solving the HRMS image is accelerated by both parallelizing across the channels and by fast numerical algorithms for each channel. Due to the fast scheme and the powerful priors we used on the blur kernel coefficients (total generalized variation) and on the cross-channel relationship (LLP), numerical experiments demonstrate that our algorithm outperforms the state-of-the-art model-based counterparts in terms of both computational time and reconstruction quality of the HRMS images.","1558-0644","","10.1109/TGRS.2021.3091329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9491792","Blind image fusion;local Laplacian prior (LLP);pansharpening;total generalized variation","Kernel;Pansharpening;Numerical models;Channel estimation;Spatial resolution;Optimization;Convolution","computational complexity;geophysical image processing;image fusion;image reconstruction;image resolution;image restoration;iterative methods;remote sensing","low spatial-resolution multispectral image;image reconstruction quality;HRMS image;PAN image;LRMS image;blur kernel coefficients;fast blind multispectral image pansharpening;high spatial-resolution multispectral image;low spatial-resolution panchromatic image;high spatial-resolution panchromatic image;local Laplacian prior;LLP;computational time;high-quality blind multispectral image pansharpening;blind image fusion;total generalized variation","","","","34","IEEE","20 Jul 2021","","","IEEE","IEEE Journals"
"A High-efficiency and wideband tunable converter based on a petal metasurface","F. Li; H. Chen; Y. Zhou; L. Zhang; H. Lu; L. Deng","National Engineering Research Center of Electromagnetic Radiation Control Materials, Key Laboratory of Multi-spectral Absorbing Materials and Structures, Ministry of Education, University of Electronic Science and Technology of China, Chengdu, China; National Engineering Research Center of Electromagnetic Radiation Control Materials, Key Laboratory of Multi-spectral Absorbing Materials and Structures, Ministry of Education, University of Electronic Science and Technology of China, Chengdu, China; National Engineering Research Center of Electromagnetic Radiation Control Materials, Key Laboratory of Multi-spectral Absorbing Materials and Structures, Ministry of Education, University of Electronic Science and Technology of China, Chengdu, China; National Engineering Research Center of Electromagnetic Radiation Control Materials, Key Laboratory of Multi-spectral Absorbing Materials and Structures, Ministry of Education, University of Electronic Science and Technology of China, Chengdu, China; National Engineering Research Center of Electromagnetic Radiation Control Materials, Key Laboratory of Multi-spectral Absorbing Materials and Structures, Ministry of Education, University of Electronic Science and Technology of China, Chengdu, China; National Engineering Research Center of Electromagnetic Radiation Control Materials, Key Laboratory of Multi-spectral Absorbing Materials and Structures, Ministry of Education, University of Electronic Science and Technology of China, Chengdu, China","2019 International Conference on Microwave and Millimeter Wave Technology (ICMMT)","13 Feb 2020","2019","","","1","3","In this paper, a high-efficiency and wideband converter based on a petal metasurface is proposed. This polarization converter can convert the linearly polarized incident electromagnetic wave to its orthogonal counterpart upon the reflection mode at resonance frequencies of 7.55 GHz, 14.15 GHz, 22.23 GHz, and at these three frequencies, the cross-polarization coefficient is almost 100%. The efficiency of the converter is higher than 90% from 6.81 GHz to 23.03 GHz. Moreover, its parameters of periodic and thickness are tunable. The physical mechanism is revealed by further analysis. Such a scheme of the linear polarization converter has potential applications in microwave communications, remote sensing, and imaging.","","978-1-7281-2168-0","10.1109/ICMMT45702.2019.8992085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8992085","wideband;tunable;high-efficiency;polarization;metasurface","","antenna radiation patterns;electromagnetic wave polarisation;electromagnetic wave reflection;microwave frequency convertors;microwave metamaterials","petal metasurface;wideband converter;linearly polarized incident electromagnetic wave;reflection mode;resonance frequencies;cross-polarization coefficient;linear polarization converter;wideband tunable converter;high-efficiency tunable converter;frequency 6.81 GHz to 23.03 GHz","","","","19","IEEE","13 Feb 2020","","","IEEE","IEEE Conferences"
"Combined Use of Optical and SAR Images for Mapping Coastal Erosion Risk","M. Bresciani; N. Ghirardi; G. Fornaro; V. Zamparelli; F. De Santi; G. De Carolis; D. Tapete; M. Palandri; C. Giardino","CNR - Institute for Electromagnetic Sensing of the Environment, Italy; CNR - Institute for Electromagnetic Sensing of the Environment, Italy; CNR - Institute for Electromagnetic Sensing of the Environment, Italy; CNR - Institute for Electromagnetic Sensing of the Environment, Italy; CNR - Institute for Electromagnetic Sensing of the Environment, Italy; CNR - Institute for Electromagnetic Sensing of the Environment, Italy; ASI - Italian Space Agency (ASI); e-GEOS S.p.A.; CNR - Institute for Electromagnetic Sensing of the Environment, Italy","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","7549","7552","This study demonstrates the use of a novel satellite remote sensing approach to map coastal erosion vulnerability in the Italian site of Piscinas (Sardinia). We focused on the land/water transitional ecosystem, to identify potential coastal erosion phenomena. For this analysis, a synergistic approach between multi-spectral satellite data (Sentinel-2) and SAR imagery (COSMO-SkyMed and Sentinel-1B) was exploited. Two vulnerability maps were created: one longterm (2016–2018) and one short-term (wind event). The results confirm how the coastal vulnerability of this site seems to be linked to episodic events, consequently, the dune system of Piscinas might be considered safe from coastal erosion processes.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554000","Italian Space Agency (ASI); ASI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554000","Remote sensing;Coastal zones;Vulnerability maps;Optical images;Radar images","Satellites;Ecosystems;Sea measurements;Optical imaging;Radar polarimetry;Optical fiber communication;Optical sensors","erosion;geophysical image processing;radar imaging;remote sensing;remote sensing by radar;synthetic aperture radar","map coastal erosion vulnerability;Italian site;Piscinas;potential coastal erosion phenomena;synergistic approach;multispectral satellite data;Sentinel-2;SAR imagery;COSMO-SkyMed;Sentinel-1B;vulnerability maps;short-term;coastal vulnerability;coastal erosion processes;SAR images;mapping coastal erosion risk;satellite remote","","2","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Assessment of a Random Forest Classifier in Urban Local Climate Zone Classification Using Sentinel-2 and PALSAR-2","C. Chen; H. Bagan; X. Xie; L. Tan; Y. Yamagata","School of Environmental and Geographical Sciences, Shanghai Normal University, Shanghai, China; Center for Global Environmental Research, National Institute for Environmental Studies, Ibaraki, Japan; School of Environmental and Geographical Sciences, Shanghai Normal University, Shanghai, China; School of Environmental and Geographical Sciences, Shanghai Normal University, Shanghai, China; Center for Global Environmental Research, National Institute for Environmental Studies, Ibaraki, Japan","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","6797","6800","This study evaluated different input features for the local climate zone (LCZ) classification using a random forest (RF) classifier. The input features included spectral reflectance and textural features from Sentinel-2 multi-spectral imagery and polarimetric features from dual-polarized ($\text{HH}+\text{HV}$) PALSAR-2 data. The analysis of the feature importance for the RF classifier was measured by Gini and permutation importance. The analysis of the feature contributions to each LCZ class was performed by a feature contribution method based on decision paths in the RF. The results showed that the multi-spectral bands from Sentinel-2 imagery played a dominant role in LCZ classification, especially Band 12 (short-wave infrared-2). The contributions of the PALSAR-2 HV polarization band were higher in land cover LCZ types than in built LCZ types. The combined analysis of feature importance and contribution would provide a reference for the performance of RF classifiers in terms of LCZ mapping.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553260","National Natural Science Foundation of China(grant numbers:41771372); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553260","Local climate zone;Random forest;Feature importance;Feature contribution;Nanchang","Radio frequency;Reflectivity;Geoscience and remote sensing;Forestry;Random forests;Meteorology","geophysical image processing;image classification;image texture;land cover;radar polarimetry;remote sensing;remote sensing by radar;synthetic aperture radar","LCZ mapping;built LCZ types;land cover LCZ types;PALSAR-2 HV polarization band;LCZ classification;Sentinel-2 imagery;multispectral bands;feature contribution method;LCZ class;feature contributions;permutation importance;RF classifier;feature importance;PALSAR-2 data;dual-polarized;polarimetric features;Sentinel-2 multispectral imagery;textural features;spectral reflectance;different input features;urban local climate zone classification;random forest classifier","","","","11","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Towards a seamless, scalable world of 3D mineralogy","T. Cudahy","CSIRO, ARRC, Kensington, Western Australia","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","5406","5409","Imagine a world where geoscientists are empowered through easy web access to seamless, scalable, three-dimensional (3D) mineralogy of the Earth and solving challenges such as understanding the nature of any regolith cover or recognizing the distal footprints to hidden economic mineral systems. An easy first step in building such a global 3D mineral map could begin with a suite of “multi-spectral” mineral group products, especially as there already exists a complete global archive of satellite ASTER reflectance-emissivity data. Here we show how one example of a 3D multi-spectral product, namely “clay composition”, is being assembled for Australia using publicly-available satellite, airborne, field and drill core data. This clay product is revealing new information and knowledge about the connectivity of mineralogy from “fresh rock to space” and the driving genetic processes that operate at scales from the entire crust down to hydrothermal mineral deposits (partly) obscured by weathering and vegetation cover.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730408","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730408","3D;mineral mapping;scalable;drill core;field;airborne;satellite;multi-spectral;hyperspectral;VNIR;SWIR;TIR;geology;hydrothermal alteration;regolith cover;global;crust;deposit","Minerals;Australia;Three-dimensional displays;Vegetation mapping;Satellites;Hyperspectral sensors","geophysical techniques;minerals;remote sensing","3D mineralogy scalable world;geoscientists;regolith cover;economic mineral systems;global 3D mineral map;multispectral mineral group products;satellite ASTER reflectance-emissivity data;3D multispectral product;Australia;publicly-available satellite data;drill core data;airborne data;field data;clay product;genetic processes;hydrothermal mineral deposits","","","","13","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"A Near-Field Imaging Algorithm Based on Angular Spectrum Theory for Synthetic Aperture Interferometric Radiometer","P. Fu; D. Zhu; F. Hu; Y. Xu; H. Xia","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing and the School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing and the School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing and the School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing and the School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing and the School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Microwave Theory and Techniques","1 Jul 2022","2022","70","7","3606","3616","For the near-field synthetic aperture interferometric radiometer (SAIR), the Fourier transform relationship between the visibility function and the near-field brightness temperature (BT) distribution is not valid. It is a challenging task for near-field SAIR imaging to realize very close-range accurate imaging with a large field of view (FOV). This article presents a new SAIR near-field imaging algorithm based on the angular spectrum theory to realize the passive millimeter-wave (PMMW) imaging, called synthetic-angular-spectrum imaging (SASI) algorithm. This SASI algorithm mainly addresses data samples of a 4-D visibility function acquired from planar arrays. First, we invert 4-D visibility samples into the angular spectrum domain via the Fourier transformation. The obtained angular spectrum data cannot be directly used to estimate the near-field BT distribution. Second, a dedicated phase factor compensation is adopted for handling this problem. The dimension-reducing accumulation is employed to generate the synthetic angular spectrum (SAS) of near-field BT distribution. Finally, we reconstruct the BT image by using the generated SAS data. Simulation and experiment results show that the presented SASI algorithm has the superiority on image reconstruction quality, especially for the off-axis regions, compared with the existing near-field SAIR imaging methods.","1557-9670","","10.1109/TMTT.2022.3175156","National Natural Science Foundation of China(grant numbers:61901244,61871438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9782134","Near field;synthetic angular spectrum (SAS);synthetic aperture interferometric radiometer (SAIR)","Imaging;Synthetic aperture sonar;Fourier transforms;Calibration;Apertures;Microwave radiometry;Directive antennas","Fourier transforms;geophysical image processing;image reconstruction;millimetre wave imaging;radar imaging;radiometers;radiometry;remote sensing by radar;synthetic aperture radar","image reconstruction quality;near-field SAIR;near-field imaging algorithm;angular spectrum theory;near-field synthetic aperture interferometric radiometer;Fourier transform relationship;visibility function;near-field brightness temperature distribution;close-range accurate imaging;passive millimeter-wave imaging;called synthetic-angular-spectrum imaging algorithm;4-D visibility samples;angular spectrum domain;Fourier transformation;angular spectrum data;synthetic angular spectrum;BT image;presented SASI algorithm","","","","23","IEEE","25 May 2022","","","IEEE","IEEE Journals"
"A Imaging Algorithm Based on Angular Spectrum Theory for Synthetic Aperture Interferometric Radiometer","P. Fu; F. Hu; D. Zhu; Y. Xu","National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","7610","7613","For near-field synthetic aperture interferometric radiometer (SAIR), the Fourier transform relationship between the visi-bility function and the near-field brightness temperature (BT) distribution is not valid. It is a challenging task for near-field SAIR imaging to realize very-close range accurate imaging with large field of view (FOV). In this paper, we present a new SAIR near-field imaging algorithm based on angular spec-trum theory to realize the passive millimeter-wave (PMMW) imaging, called synthetic-angular-spectrum imaging (SASI) algorithm. This SASI algorithm mainly addresses data sam-ples of a 4-D visibility function acquired from planar arrays. First, we invert the 4-D visibility samples into the angular spectrum domain via the Fourier transformation. Second, a dedicated phase factor compensation is adopted and the dimension-reducing accumulation is employed to generate the synthetic angular spectrum (SAS) of near-field BT distri-bution. Finally, we reconstruct the BT image by making use of the generated SAS data. Experiment results show that the presented SASI algorithm can reconstruct the BT image.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883866","National Natural Science Foundation of China(grant numbers:61901244,61871438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883866","Synthetic aperture interferometric ra-diometer (SAIR);near field;synthetic angular spectrum","Fourier transforms;Imaging;Planar arrays;Apertures;Radiometry;Brightness temperature;Arrays","Fourier transforms;image reconstruction;millimetre wave imaging;radar imaging;radiometers;radiometry;synthetic aperture radar","near-field brightness temperature distribution;near-field SAIR;range accurate imaging;near-field imaging algorithm;angular spec-trum theory;passive millimeter-wave imaging;called synthetic-angular-spectrum imaging algorithm;4-D visibility function;4-D visibility samples;angular spectrum domain;Fourier transformation;synthetic angular spectrum;BT image;presented SASI algorithm;angular spectrum theory;near-field synthetic aperture interferometric radiometer;Fourier transform relationship;visi-bility function","","","","7","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"A Novel Imaging Method Using Fractional Fourier Transform for Near-Field Synthetic Aperture Radiometer Systems","H. Hu; D. Zhu; F. Hu","School of Electronic Information and Communications and the National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications and the National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications and the National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","22 Apr 2022","2022","19","","1","5","In the domain of synthetic aperture radiometry, a Fourier transform (FT) relationship can be established between the brightness temperature of the target in the far-field region and the visibility function output by the system. However, when the target is in the near-field range of the imaging system, the existing far-field imaging methods cannot be used directly for the inversion of the near-field visibility function, because the target radiation signal cannot simply be regarded as a plane wave signal. In this letter, we propose a novel imaging method for synthetic aperture radiometer systems on the basis of the characteristics of the near-field target radiation signal. We introduce the near-field error term to reformulate the relationship between visibility function and brightness temperature in near field. Based on the reestablished signal model, we present an image reconstruction algorithm via fractional Fourier transformation, named near-field fractional FT (NF-FRFT), to estimate the near-field brightness temperature. Compared with the conventional near-field imaging method, the proposed NF-FRFT method can achieve better image reconstruction quality without extra hardware consumption. Furthermore, another advantage of this approach is that no additional array layout design is required. The validity of this method is demonstrated by a series of simulations and experiments.","1558-0571","","10.1109/LGRS.2022.3166219","National Natural Science Foundation of China(grant numbers:61901244); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9754577","Fractional Fourier transformation;inversion method;synthetic aperture","Imaging;Brightness temperature;Antenna arrays;Mathematical models;Apertures;Fourier transforms;Radiometry","Fourier transforms;image reconstruction;microwave imaging;millimetre wave imaging;radar imaging;radiometers;radiometry;synthetic aperture radar","fractional Fourier transformation;named near-field fractional FT;near-field brightness temperature;conventional near-field imaging method;NF-FRFT method;image reconstruction quality;novel imaging method;fractional Fourier transform;near-field synthetic aperture radiometer systems;synthetic aperture radiometry;far-field region;visibility function output;near-field range;imaging system;existing far-field imaging methods;near-field visibility function;plane wave signal;near-field target radiation signal;near-field error term;reestablished signal model;image reconstruction algorithm","","","","13","IEEE","11 Apr 2022","","","IEEE","IEEE Journals"
"Convolutional Neural Network Approach for Mapping Arctic Vegetation Using Multi-Sensor Remote Sensing Fusion","Z. L. Langford; J. Kumar; F. M. Hoffman","University of Tennessee, Knoxville, TN, USA; Oak Ridge National Laboratory, Oak Ridge, TN, USA; Oak Ridge National Laboratory, Oak Ridge, TN, USA","2017 IEEE International Conference on Data Mining Workshops (ICDMW)","18 Dec 2017","2017","","","322","331","Accurate and high-resolution maps of vegetation are critical for projects seeking to understand the terrestrial ecosystem processes and land-atmosphere interactions in Arctic ecosystems, such as U.S. Department of Energy's Next Generation Ecosystem Experiment (NGEE) Arctic. However, most existing Arctic vegetation maps are at a coarse resolution and with a varying degree of detail and accuracy. Remote sensing-based approaches for mapping vegetation, while promising, are challenging in high latitude environments due to frequent cloud cover, polar darkness, and limited availability of high-resolution remote sensing datasets (e.g., ~ 5 m). This study proposes a new remote sensing based multi-sensor data fusion approach for developing high-resolution maps of vegetation in the Seward Peninsula, Alaska. We focus detailed analysis and validation study around the Kougarok river, located in the central Seward Peninsula of Alaska. We seek to evaluate the integration of hyper-spectral, multi-spectral, radar, and terrain datasets using unsupervised and supervised classification techniques over a ~343.72 km2 area for generating vegetation classifications at a variety of resolutions (5 m and 12.5 m). We fist applied a quantitative goodness-of-fit method, called Mapcurves, that shows the degree of spatial concordance between the public coarse resolution maps and k-means clustering values and relabels the k values based on the best overlap. We develop a convolutional neural network (CNN) approach for developing high resolution vegetation maps for our study region in Arctic. We compare two CNN approaches: (1) breaking up the images into small patches (e.g., 6 × 6) and predict the vegetation class for entire patch and (2) semantic segmentation and predict the vegetation class for every pixel. We also perform accuracy assessments of the developed data products and evaluate varying CNN architectures. The fusion of hyperspectral and optical datasets performed the best, with accuracy values increased from 0.64 to 0.96-0.97 when using a training map produced by unsupervised clustering and Mapcurves labeling for both CNN models.","2375-9259","978-1-5386-3800-2","10.1109/ICDMW.2017.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8215680","Multi-Sensor;Fusion;Remote Sensing;Vegetation Classificaiton","Vegetation mapping;Remote sensing;Arctic;Earth;Biological system modeling;Artificial satellites;Meteorology","geophysical image processing;image classification;image fusion;image segmentation;neural nets;pattern clustering;sensor fusion;terrain mapping;vegetation;vegetation mapping","US Department of Energy;Arctic vegetation mapping;Next Generation Ecosystem Experiment;Mapcurves labeling;unsupervised clustering;hyperspectral-optical dataset fusion;k values;training map;developed data products;vegetation class;CNN approaches;high resolution vegetation maps;public coarse resolution maps;vegetation classifications;unsupervised classification techniques;central Seward Peninsula;validation study;Alaska;multisensor data fusion approach;high-resolution remote sensing datasets;frequent cloud cover;high latitude environments;existing Arctic vegetation maps;Arctic ecosystems;land-atmosphere interactions;terrestrial ecosystem processes;multisensor remote sensing fusion;convolutional neural network approach;size 343.72 km","","5","","44","IEEE","18 Dec 2017","","","IEEE","IEEE Conferences"
"Power Lines Detection and Segmentation In Multi-Spectral Uav Images Using Convolutional Neural Network","M. Hota; S. Rao B; U. Kumar","Samsung Semiconductor India R&D Center, Samsung Electronics, Bangalore, India; Samsung Semiconductor India R&D Center, Samsung Electronics, Bangalore, India; Spatial Computing Laboratory, Center for Data Sciences, International Institute of Information Technology (IIIT), Bangalore, India","2020 IEEE India Geoscience and Remote Sensing Symposium (InGARSS)","23 Feb 2021","2020","","","154","157","In this paper, detection, and segmentation of power line in Unmanned Aerial Vehicles (UAV) multi-spectral images using convolutional neural network is proposed. Initially, the multi-spectral images captured from UAV were calibrated and pre-processed, following which they were fed into deep CNN for semantic segmentation to perform a binary classification; each pixel was assigned either of the two classes - ""power line"" or ""no power line"". Semantic segmentation was performed with different networks such as U-Net, SegNet and PSPNet. Qualitative (visual inspection) and quantitative analysis of the results showed that U-Net outperformed other networks with an overall accuracy of around 99% with a competitive execution latency, making it useful for real time analysis of power lines from UAV data.","","978-1-7281-3114-6","10.1109/InGARSS48198.2020.9358967","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9358967","Unmanned aerial vehicle;convolutional neural network;semantic segmentation;U-Net;SegNet;PSPNet","Image segmentation;Visualization;Statistical analysis;Semantics;Unmanned aerial vehicles;Real-time systems;Convolutional neural networks","autonomous aerial vehicles;convolutional neural nets;feature extraction;image classification;image segmentation;remotely operated vehicles;robot vision","convolutional neural network;semantic segmentation;power line;UAV data;power lines detection;multispectral UAV images;unmanned aerial vehicles multispectral images;U-Net;SegNet;PSPNet","","1","","7","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"High-Resolution RFI Localization Using Covariance Matrix Augmentation in Synthetic Aperture Interferometric Radiometry","J. Li; F. Hu; F. He; L. Wu","Huawei Technologies Co., Ltd., Shenzhen, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","26 Jan 2018","2018","56","2","1186","1198","Radio frequency interference (RFI) is a significant limiting factor in the retrieval of geophysical parameters measured by microwave radiometers. RFI localization is crucial to mitigate or remove the RFI impacts. In this paper, a novel RFI localization approach using covariance matrix augmentation in synthetic aperture interferometric radiometry (SAIR) is proposed. It utilizes the property of the sparse array configuration, which is commonly used in SAIR, where the sparse array can be viewed as a virtual filled array with much larger number of antenna elements. The approach can be applied in SAIR with a sparse array configuration, such as the European Space Agency Soil Moisture and Ocean Salinity (SMOS) mission. Results on real SMOS data show that, compared with the previous approach, the presented approach has an improved performance of RFI localization with comparable accuracy of localization, such as improved spatial resolution, lower sidelobes, and larger identifiable number of RFIs.","1558-0644","","10.1109/TGRS.2017.2761261","National Natural Science Foundation of China(grant numbers:61172100); Fundamental Research Funds for the Central Universities(grant numbers:HUST 2015QN093); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8085390","Beamforming;direction-of-arrival (DOA) estimation;microwave radiometry;radio frequency interference (RFI);Soil Moisture and Ocean Salinity (SMOS);sparse array antennas;synthetic aperture radiometry","Antenna arrays;Covariance matrices;Arrays;Array signal processing;Apertures;Microwave radiometry;Instruments","geophysical signal processing;radar interferometry;radiofrequency interference;radiometers;radiometry;remote sensing by radar;synthetic aperture radar","SMOS mission;European Space Agency Soil Moisture and Ocean Salinity mission;virtual filled array;sparse array configuration;SAIR;microwave radiometers;radio frequency interference;synthetic aperture interferometric radiometry;covariance matrix augmentation;high-resolution RFI localization","","18","","42","IEEE","26 Oct 2017","","","IEEE","IEEE Journals"
"A Remapping Technique of FY-3D MWRI Based on a Convolutional Neural Network for the Reduction of Representativeness Error","K. Chen; X. Fan; W. Han; H. Xiao","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; CMA Earth System Modeling and Prediction Centre (CEMC), and the State Key Laboratory of Severe Weather (LaSW), China Meteorological Administration, Beijing, China; CMA Earth System Modeling and Prediction Centre (CEMC), and the State Key Laboratory of Severe Weather (LaSW), China Meteorological Administration, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","8 Mar 2022","2022","60","","1","11","The assimilation of spaceborne passive microwave measurements often suffers from representativeness errors due to the mismatch between the observation footprints and numerical weather prediction (NWP) model grids. In this article, a new brightness temperature remapping technique based on a deep convolutional neural network (CNN) is proposed to reduce the representativeness error in FengYun-3D (FY-3D) microwave radiation imager (MWRI) observation data assimilation. The remapping technique uses an adapted dataset construction method in which the training data consist of synthetic NWP-model-grid-based MWRI brightness temperature ( $T_{B}$ ) images and synthetic MWRI-observed antenna temperature ( $T_{A}$ ) images. The synthetic  $T_{A}$  and  $T_{B}$ , which are generated through radiative transfer for TOVS (RTTOV) model and MWRI degradation model, make the network learn the spatial remapping relationship between observation and background  $T_{B}$  in data assimilation. In addition, land–sea mask information is input into the CNN to help the network better analyze the coastline area data. The CNN-based remapped MWRI observation data are evaluated through observation minus background (OMB) diagnosis with the Global/Regional Assimilation and PrEdiction System (GRAPES) four-dimensional variational (4D-Var) system. The experimental results illustrate that the bias and standard deviation of OMB with the CNN-based remapped MWRI observation are quantitatively reduced compared with the raw measurements in GRAPES 4D-Var.","1558-0644","","10.1109/TGRS.2021.3138395","National Key Research and Development Program(grant numbers:2019YFC1510400); National Natural Science Foundation of China(grant numbers:42075155); Second Tibetan Plateau Scientific Expedition and Research (STEP) Program(grant numbers:2019QZKK0105); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9663193","Brightness temperature remapping;convolutional neural network (CNN);microwave radiation imager (MWRI);representativeness error","Microwave radiometry;Brightness temperature;Mathematical models;Microwave imaging;Convolutional neural networks;Antenna measurements;Earth","atmospheric techniques;data assimilation;hydrological techniques;learning (artificial intelligence);microwave measurement;neural nets;radiative transfer;remote sensing;weather forecasting","remapping technique;FY-3D MWRI;representativeness error;spaceborne passive microwave measurements;observation footprints;numerical weather prediction model grids;deep convolutional neural network;FengYun-3D;adapted dataset construction method;training data;synthetic NWP-model-grid-based MWRI brightness temperature;synthetic MWRI-observed antenna temperature;spatial remapping relationship;data assimilation;coastline area data;CNN-based;MWRI observation data;observation minus background diagnosis;PrEdiction System four-dimensional","","1","","24","IEEE","24 Dec 2021","","","IEEE","IEEE Journals"
"Minnaert Topographic Correction of Mars Color Camera Images from Mars Orbiter Mission","I. Misra; S. M. Moorthi; D. Dhar","Multi Spectral Data Processing Division, Space Applications Centre (ISRO), Ahmedabad; Multi Spectral Data Processing Division, Space Applications Centre (ISRO), Ahmedabad; Multi Spectral Data Processing Division, Space Applications Centre (ISRO), Ahmedabad","2015 International Conference on Information Technology (ICIT)","24 Mar 2016","2015","","","76","81","Mars Color Camera (MCC) images obtained from Mars Orbiter Mission (MOM) are gaining scientific popularity since MOM insertion into an elliptical orbit around Mars on 24th Sep, 2014. Planetary remotely sensed images are corrected for topographic effects to normalize the radiance measures before considering the data for science analysis. It is proposed here to use non Lambertian Minnaert semi empirical approach for correcting MCC images that are used for deriving results for Mars surface science. The methodology outlined here uses terrain parameters such as slope and aspect derived from Mars Orbiter Laser Altimeter (MOLA) digital elevation model (DEM). Topographically corrected images were evaluated for the improvement in its radiometry quantitatively and it is found to reduce topographic shading and improve the image quality.","","978-1-5090-0487-4","10.1109/ICIT.2015.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7437594","Topographic Correction;Mars Color Camera;Digital Elevation Model;Data Processing","Mars;Surface topography;Lighting;Orbits;Spatial resolution;Mathematical model;Image color analysis","astronomical image processing;Mars;planetary remote sensing;planetary surfaces;radiometry","Mars Color Camera image quality;Mars Orbiter Mission;MOM insertion;elliptical orbit;planetary remotely sensed images;topographic effects;science analysis;Lambertian Minnaert semiempirical approach;Mars surface science;terrain parameters;Mars Orbiter Laser Altimeter digital elevation model;topographically corrected images;radiometry;topographic shading;Minnaert topographic correction","","","","12","IEEE","24 Mar 2016","","","IEEE","IEEE Conferences"
"Remote sensing image registration with spatial restraint based on moment invariants and fast generalized fuzzy clustering","W. Yue; G. Maoguo; J. Jia; W. Ma","Xidian University, Xian, Shaanxi, CN; Xidian University, Xian, Shaanxi, CN; Xidian University, Xian, Shaanxi, CN; Xidian University, Xian, Shaanxi, CN","2015 Conference on Technologies and Applications of Artificial Intelligence (TAAI)","15 Feb 2016","2015","","","97","104","Image registration is a key component in remote sensing image processing. In this paper, we present a remote sensing image registration method by incorporating spatial restraint based on moment invariants and fast generalized fuzzy clustering. Seven moment invariants are extracted as features of objects obtained by the fast generalized fuzzy c-means (FGFCM) algorithm. The objects are matched through these features. Then, we detect the keypoints in corresponding matching regions. Through the spatial restraint, the outliers are removed and the correct matches are increased. The proposed algorithm is evaluated on multi-spectral images, multi-temporal images, and multi-sensor images. Extensive experimental studies prove that the proposed algorithm is promising.","2376-6824","978-1-4673-9606-6","10.1109/TAAI.2015.7407062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7407062","Image registration;remote sensing;spatial restraint;moment invariants;FCM","Image segmentation;Adaptation models","fuzzy set theory;geophysical image processing;image fusion;image matching;image registration;object detection;pattern clustering;remote sensing","multisensor image;multitemporal images;multispectral image;keypoint detection;object matching;FGFCM algorithm;fast generalized fuzzy c-means algorithm;remote sensing image processing;fast generalized fuzzy clustering;moment invariants;spatial restraint;remote sensing image registration","","","","27","IEEE","15 Feb 2016","","","IEEE","IEEE Conferences"
"Retrieval of Gas Temperature and Pressure Based on Rayleigh–Brillouin Spectrum","P. Zhang; J. Xu; R. Zhang; Q. Sun; H. Wu; Y. Xu; B. Zhou; K. Liang","Department of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; Department of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; Department of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; Beijing Institute of Space Mechanics and Electricity, Beijing, China; Third Department, China Ship Research and Development Academy, Wuhan, China; Department of Electronic Information and Communication, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology, Wuhan, China","IEEE Access","10 Feb 2020","2020","8","","22964","22975","Optical detection methods such as Rayleigh–Brillouin scattering spectrum can be used for physical parameter measurement in solids, liquids, and gas. In this paper, a new method based on spectral characteristics is proposed to realize temperature and pressure retrieval simultaneously in gas. The characteristics of Rayleigh–Brillouin spectrum are firstly utilized to establish the retrieval model by fitting Tenti-S6 line shape with 3Voigt model at different temperatures and pressures, and then deriving the retrieval equations via regression fitting procedure. Through theoretical and measured error analyses, the characteristic retrieval model based on Rayleigh linewidth and the whole linewidth of Rayleigh–Brillouin scattering spectrum is shown to be optimal. Afterward, the retrieval model is verified using the experimental Rayleigh-Brillouin scattering spectra of N2 and air. The results indicate that, compared with the current method based on the whole linewidth or line shape of spectrum, the proposed method not only produces lower theoretical and retrieval errors but also can simultaneously retrieve the temperature and pressure of gases. The novel retrieval method provides a new idea for obtaining valuable information on gas parameters and promotes the application of Brillouin lidar remote sensing in meteorology and space science.","2169-3536","","10.1109/ACCESS.2020.2965643","Joint Research Project between China and The Netherlands(grant numbers:530-5CDP05); Guangxi Innovative Development(grant numbers:GuiKe AA 18118038); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8955781","Deconvolution;pressure measurement;Rayleigh–Brillouin spectrum;retrieval model;remote sensing;temperature measurement","Scattering;Temperature measurement;Temperature;Mathematical model;Atmospheric modeling;Analytical models;Shape","atmospheric techniques;Brillouin spectra;measurement errors;optical radar;Rayleigh scattering;regression analysis;remote sensing by laser beam;spectral line breadth","novel retrieval method;experimental Rayleigh-Brillouin scattering spectra;Rayleigh linewidth;characteristic retrieval model;measured error analyses;theoretical error analyses;retrieval equations;Tenti-S6 line shape;pressure retrieval;spectral characteristics;physical parameter measurement;Rayleigh-Brillouin scattering spectrum;optical detection methods;Rayleigh-Brillouin spectrum;gas temperature;Brillouin lidar remote sensing;gas parameters","","","","34","CCBY","10 Jan 2020","","","IEEE","IEEE Journals"
"Sea Fog Detection Using U-Net Deep Learning Model Based On Modis Data","Z. Chunyang; W. Jianhua; L. Shanwei; S. Hui; X. yanfang","China University of Petroleum, Qingdao, China; China University of Petroleum, Qingdao, China; China University of Petroleum, Qingdao, China; China University of Petroleum, Qingdao, China; The First Institute of Oceanography MNR, Qingdao, China","2019 10th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","5 Dec 2019","2019","","","1","5","Sea fog can have both negative and positive impacts on humans life. At present, remote sensing has become the main means of long-term and large-scale observation of sea fog. With the improvement of spectral resolution and increase of data volume, the traditional threshold method is simple and convenient as the main method of current sea fog detection, but it’s not flexible and accurate enough which causes people need a more automated and intelligent algorithm to achieve efficient sea fog detection. In this article, we use the U-Net deep learning model to construct the sea fog detection model for MODIS multi-spectral images. The main steps include? (1) Data preprocessing, including the PCA method for dimensionality reduction of data; (2) Manual samples extraction with CALIPSO data assist; (3) Construction and training of U-Net sea fog detection model. The experimental results show that the U-Net model can effectively and machine learning method has good potential in sea fog detection.","2158-6276","978-1-7281-5294-3","10.1109/WHISPERS.2019.8920979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920979","Sea fog;MODIS;CALIPSO;Detection;Deep Learning","Clouds;MODIS;Machine learning;Remote sensing;Training;Atmospheric modeling;Sea surface","atmospheric techniques;fog;geophysical image processing;geophysical signal processing;learning (artificial intelligence);principal component analysis;radiometry;remote sensing","CALIPSO data;U-Net sea fog detection model;machine learning method;u-net deep learning model;modis data;negative impacts;large-scale observation;spectral resolution;data volume;traditional threshold method;MODIS multispectral images","","4","","16","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Landcover classification with self-taught learning on archetypal dictionaries","R. Roscher; C. Römer; B. Waske; L. Plümer","Division of Remote Sensing and Geoinformatics, Institute of Geographical Sciences Freie Universitat Berlin, Berlin; Department of Geoinformation, University of Bonn, Bonn; Division of Remote Sensing and Geoinformatics, Institute of Geographical Sciences Freie Universitat Berlin, Berlin; Department of Geoinformation, University of Bonn, Bonn","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","2358","2361","This paper introduces archetypal dictionaries for a self-taught learning framework for the application of landcover classification. Self-taught learning, an unsupervised representation learning method, is exploited to learn low-dimensional and discriminative higher-level features, which are used as input into a classification algorithm. Experiments are conducted using a multi-spectral Landsat 5 TM image of a study area in the north of Novo Progresso located in South America. Our results confirm that self-taught learning with archetypal dictionaries provide features, which can be used as input into a linear logistic regression classifier. The obtained classification accuracies are comparable to kernel-based classifier using the original features.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326282","self-taught learning;archetypal analysis;landcover classification","Dictionaries;Accuracy;Logistics;Support vector machines;Remote sensing;Earth;Feature extraction","geophysical image processing;image classification;land cover;regression analysis;terrain mapping;unsupervised learning","archetypal dictionaries;self-taught learning framework;land cover classification algorithm;unsupervised representation learning method;low-dimensional discriminative higher-level features;multispectral Landsat 5 TM image;Novo Progresso;South America;linear logistic regression classifier;classification accuracies;kernel-based classifier","","3","","10","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Classification of Quickbird imagery over urban area using convolutional neural network","K. Djerriri; M. S. Karoui","Centre des Techniques Spatiales, CTS Arzew, Algeria; Centre des Techniques Spatiales, CTS Arzew, Algeria","2017 Joint Urban Remote Sensing Event (JURSE)","11 May 2017","2017","","","1","4","During the past decades significant efforts have been made in developing various methods for Very high spatial resolution (VHSR) remotely sensed image classification; most of them are based on handcrafted learning-based features. Recently deep learning-based techniques have demonstrated excellent performance in remote sensing applications. In this paper we address the problem of urban imagery classification by developing a convolutional neural network (CNN) approach, which are the most popular deep learning approach for image classification. We design a custom CNN that operates on local patches in order to produce pixel-level classification map. The performance of the proposed model is validated on an exhaustive experimental comparison on a set of 20 QuickBird pansharpened multi-spectral images in urban zones. The obtained results outperform those obtained by different classification approaches on the same dataset.","","978-1-5090-5808-2","10.1109/JURSE.2017.7924631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7924631","Deep learning;Convolutional neural networks;Classification;VHSR imagery;Urban area","Feature extraction;Computer architecture;Urban areas;Remote sensing;Machine learning;Neurons","geophysical image processing;image classification;image resolution;neural nets;remote sensing","quickbird imagery classification;Urban Area;convolutional neural network;very high spatial resolution remotely sensed image classification;deep learning-based techniques;urban imagery classification;convolutional neural network approach;local patches;pixel-level classification map","","4","","17","IEEE","11 May 2017","","","IEEE","IEEE Conferences"
"Object-based land cover mapping using adaptive scale segmentation from ZY-3 satellite images","Y. Zhou; L. Feng; Y. Chen; J. Li","School of Earth Science and Engineering, Hohai University, Nanjing, China; School of Earth Science and Engineering, Hohai University, Nanjing, China; School of Earth Science and Engineering, Hohai University, Nanjing, China; College of Geoscience and Surveying Engineering, China University of Mining and Technology, Beijing, China","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","63","66","With increasing of the spatial resolution of satellite imaging sensors, object-based image analysis (OBIA) has been gaining prominence in remote sensing applications. However, scale selection in multi-scale segmentation and OBIA remains a challenge, which directly reduces efficiency of land cover mapping. In this study, we presented an object-based land cover mapping using adaptive scale segmentation. Central to our method is the use of inherent features of segmented objects to determine whether an object should be segmented with a small scale in a top-down segmentation procedure. We firstly used inherent features of a segmented object to determine whether this object should be segmented with a smaller scale in a top-down segmentation procedure, producing a segmentation map with optimal scales. Then, an object-based SVM classifier was applied on the adaptive-scale segmentation map to yield a land-cover map. We have applied this method on a ZY-3 multi-spectral satellite image to produce land cover map, compared with the results using the traditional mean shift algorithm with fixed scales. The experimental results illustrate that the proposed method is practically helpful and efficient to improve the performance of land cover mapping.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8126894","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8126894","OBIA;LUCC;ZY-3 satellite image;scale selection;multi-scale segmentation","Image segmentation;Complexity theory;Feature extraction;Satellites;Shape;Remote sensing;Spatial resolution","geophysical image processing;image classification;image segmentation;image sensors;land cover;remote sensing;support vector machines;terrain mapping","object-based land cover mapping;adaptive scale segmentation;ZY-3 satellite images;satellite imaging sensors;object-based image analysis;scale selection;multiscale segmentation;inherent features;segmented object;segmentation procedure;smaller scale;optimal scales;adaptive-scale segmentation map;land-cover map;multispectral satellite image;land cover map;fixed scales","","2","","18","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Comparative analysis of different fusion rules for SAR and multi-spectral image fusion based on NSCT and IHS transform","X. J. Chong; C. Xuejiao","College of Earth Science and Engineering, Hohai University, Nanjing, China; College of Earth Science and Engineering, Hohai University, Nanjing, China","2015 International Conference on Computer and Computational Sciences (ICCCS)","21 Dec 2015","2015","","","271","274","In order to improve the fusion quality of SAR and multi-spectral image, this paper proposes an image fusion method based on nonsubsampled contourlet transform (NSCT) and IHS transform. Since the fusion rule plays a very important role during the fusion process, four fusion rules are analyzed and compared. Three fusion rules are commonly used in previous works and a new fusion rule is proposed in this paper. To evaluate the performance of different fusion rules, fusion experiments are carried on COSMO-SkyMed SAR and Landsat OLI image. The experimental results indicate that the proposed rule is more effective than the other three regular fusion rules.","","978-1-4799-1819-5","10.1109/ICCACS.2015.7361364","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7361364","Iimage fusion;NSCT;IHS transform;fusion rule","Transforms;Synthetic aperture radar;Image fusion;Remote sensing;Satellites;Filter banks;Image resolution","image fusion;radar imaging;synthetic aperture radar;transforms","multispectral image fusion;nonsubsampled contourlet transform;NSCT;intensity hue saturation;IHS transform;fusion rule;COSMO-SkyMed SAR;Landsat OLI image","","1","","11","IEEE","21 Dec 2015","","","IEEE","IEEE Conferences"
"Mapping snow cover using HJ-1B infrared remote sensing(IRS) spectroradiometer images","Y. Zhou; H. Jiang","UESTC, Big Data Research Center, Chengdu, China; School of Resources and Environment, University of Electric Science and Technology of China(UESTC), China Chengdu, Sichuan, China","2015 8th International Congress on Image and Signal Processing (CISP)","18 Feb 2016","2015","","","782","787","Snow plays an important role in global hydrologic and climate changes. After 40 years of research on using multi-spectral remote-sensing data to monitor snow, researchers developed a large number of algorithms and products, such as snow mapping, snow depth inversion and snow albedo. However, algorithms for snow cover extraction from Chinese satellite images are yet to be developed. In this study, we firstly verified the accuracy of HJ-MNDSI snow cover mapping method, and then determined the appropriate thresholds by comparing with the results with the Landsat Thematic Mapper (TM) data. Then we produce snow cover products nearly seven years and calculate snow pixels and its proportion. Finally, according to the historical data, we give a forecast method by using MATLAB to fit the curve based on Fourier. The results provide scientific basis for the rational using of water resources and climate or environment change researches of the Tianshan Mountain.","","978-1-4673-9098-9","10.1109/CISP.2015.7407983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7407983","NDSI;snow cover mapping;HJ-1B;Fourier","Snow;Clouds;Reflectivity;Remote sensing;Satellites;Earth;Monitoring;Climate change","albedo;Fourier analysis;geophysical image processing;hydrological techniques;mathematics computing;radiometers;remote sensing;snow;water resources","HJ-1B infrared remote sensing spectroradiometer image;snow cover mapping;global hydrologic change;global climate change;multispectral remote-sensing data;snow albedo;snow depth inversion;Chinese satellite image;HJ-MNDSI snow cover mapping method;snow cover product;MATLAB;Fourier curve;water resource;Tianshan mountain;environment change research;snow pixels","","","","25","IEEE","18 Feb 2016","","","IEEE","IEEE Conferences"
"Mapinwild: A Dataset for Global Wilderness Mapping","B. Ekim; M. Schmitt","Department of Aerospace Engineering, University of the Bundeswehr Munich, Germany; Department of Aerospace Engineering, University of the Bundeswehr Munich, Germany","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","231","234","This paper introduces the MapInWild dataset, a multi-modal dataset tailored to mapping wilderness areas from satellite imagery and auxiliary geodata. MapInWild accommodates freely and globally available geodata layers that emerged from various remote sensing sensors, such as dualpol Sentinel-1 imagery, multi-spectral Sentinel-2 data, Visible Infrared Imaging Radiometer Suite night-time light data, and the ESA WorldCover map. Each sample of the Map-InWild dataset is annotated with labels derived from the World Database on Protected Areas, a most up-to-date and comprehensive global database on conservation areas. Protected areas are filtered through a sophisticated sampling process to ensure a representative coverage of the natural areas of the Earth. With MapInWild dataset, we hope to foster further research on deep learning applied to environmental remote sensing and conservation. MapInWild dataset is publicly available at https://dataverse.harvard.edu/dataverse/mapinwild.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883217","German Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883217","Wilderness;Conservation;Biodiversity;Environment;Multi-Source;Multi-Temporal;Deep Learning;Dataset;Remote Sensing;Earth Observation","Earth;Deep learning;Databases;Satellite broadcasting;Infrared imaging;Infrared image sensors;Radiometry","geographic information systems;geophysical image processing;infrared imaging;remote sensing","global wilderness;MapInWild dataset;multimodal dataset;mapping wilderness areas;MapInWild accommodates;globally available geodata layers;dualpol Sentinel-1 imagery;multispectral Sentinel-2 data;Visible Infrared Imaging Radiometer Suite night-time light data;ESA WorldCover map;Map-InWild dataset;Protected Areas;comprehensive global database;conservation areas;Protected areas","","","","6","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"DeepCloud: Ground-Based Cloud Image Categorization Using Deep Convolutional Features","L. Ye; Z. Cao; Y. Xiao","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","25 Sep 2017","2017","55","10","5729","5740","Accurate ground-based cloud image categorization is a critical but challenging task that has not been well addressed. One of the essential issues that affect the performance is to extract the representative visual features. Nearly all of the existing methods rely on the hand-crafted descriptors (e.g., local binary patterns, CENsus TRsansform hISTogram, and scale-invariant feature transform). Their limited discriminative power indeed leads to the unsatisfactory performance. To alleviate this, we propose “DeepCloud” as a novel cloud image feature extraction approach by resorting to the deep convolutional visual features. In the recent years, the deep convolutional neural network (CNN) has achieved the promising results in lots of computer vision and image understanding fields. Nevertheless, it has not been applied to cloud image classification yet. Thus, we actually pay the first effort to fill this blank. Since cloud image classification can be attributed to a multi-instance learning problem, simply employing the convolutional features within CNN cannot achieve the promising result. To address this, Fisher vector encoding is applied to executing the spatial feature aggregation and high-dimensional feature mapping on the raw deep convolutional features. Moreover, the hierarchical convolutional layers are used simultaneously to capture the fine textural characteristics and high-level semantic information in the unified manner. To further leverage the performance, a cloud pattern mining and selection method are also proposed. It targets at finding the discriminative local patterns to better distinguish the different kinds of clouds. The experiments on a challenging ground-based cloud image data set demonstrate the superiority of the proposition over the state-of-the-art methods.","1558-0644","","10.1109/TGRS.2017.2712809","National Natural Science Foundation of China(grant numbers:61502187); National High-tech R&D Program of China (863 Program)(grant numbers:2015AA015904); Chinese Fundamental Research Funds for the Central Universities(grant numbers:HUST 2014QNRC035,2015QN036); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7964703","Convolutional neural network (CNN);deep learning;Fisher vector (FV);ground-based cloud image categorization;pattern mining","Feature extraction;Clouds;Visualization;Semantics;Meteorology;Encoding;Convolutional codes","geophysical image processing;geophysical techniques","DeepCloud;ground-based cloud image categorization;deep convolutional features;cloud image feature extraction approach;CNN;multiinstance learning problem","","59","","59","IEEE","30 Jun 2017","","","IEEE","IEEE Journals"
"Supervised Fine-Grained Cloud Detection and Recognition in Whole-Sky Images","L. Ye; Z. Cao; Y. Xiao; Z. Yang","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; Hubei Meteorological Bureau, China Meteorological Administration, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","25 Sep 2019","2019","57","10","7972","7985","The whole-sky imager has been increasingly used for ground-based cloud automatic observation. Many approaches based on image processing have been applied to detect or classify clouds in whole-sky images (WSIs). However, most of the studies only focus on image segmentation for cloud detection or image classification for cloud recognition separately. The cloud detection only does the binary segmentation (sky and cloud) without cloud types, while the cloud recognition only gives the single image-level label without cloud coverage. In this paper, a fine-grained cloud detection and recognition task with a solution is proposed to fill the gap, which can simultaneously detect and classify clouds in a WSI. It can be regarded as a pixel-level fine-grained dense prediction for images. First, a new data set is built with pixel-level annotation of nine different types. Then, a solution based on supervised learning is proposed, in which the pixel-level prediction problem is converted to a superpixel classification problem. Multiview features are extracted, including color, inside texture, neighbor texture, and global relation, to represent the superpixels. Moreover, a class-specific feature space transformation method based on metric learning and subspace alignment is proposed to overcome the challenge brought by the high similarity among cloud types and the feature shifting. Finally, several experiments have verified that our approach is effective to the challenging new task and also outperforms some other methods in the normal tasks of cloud detection and cloud classification, respectively.","1558-0644","","10.1109/TGRS.2019.2917612","National Natural Science Foundation of China(grant numbers:61502187); National High-tech R&D Program of China (863 Program)(grant numbers:2015AA015904); Chinese Fundamental Research Funds for the Central Universities (HUST)(grant numbers:2014QNRC035,2015QN036); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736493","Cloud detection;dense prediction;domain adaptation;fine-grained classification;metric learning (ML)","Clouds;Image segmentation;Task analysis;Image recognition;Feature extraction;Image color analysis;Supervised learning","clouds;feature extraction;image classification;image colour analysis;image segmentation;image texture;object detection;supervised learning","pixel-level fine-grained dense prediction;pixel-level prediction problem;cloud types;cloud classification;fine-grained cloud detection;whole-sky images;whole-sky imager;ground-based cloud automatic observation;image processing;image segmentation;image classification;cloud recognition;single image-level label;cloud coverage;binary segmentation;pixel-level annotation;supervised learning;superpixel classification problem;multiview feature extraction;image color;image texture;class-specific feature space transformation method;metric learning;subspace alignment","","21","","50","IEEE","13 Jun 2019","","","IEEE","IEEE Journals"
"Geolocation of RFIs by Multiple Snapshot Difference Method for Synthetic Aperture Interferometric Radiometer","R. Jin; L. Wu; Q. Li; H. Lu; L. Feng","Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; China Academy of Space Technology, Xi’an, China; Collaborative Innovation Center of Industrial Bigdata, Hubei University of Technology, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","3 Dec 2021","2022","60","","1","12","The presence of unauthorized radio frequency interference (RFI) sources seriously affects the retrieval of brightness temperature of a synthetic aperture interferometric radiometer (SAIR). Postobservation RFI geolocation is important for improving the RFI situation hereafter and mitigating the impact of the identified RFIs. Previous works have demonstrated the potential of using high-/super-resolution direction-of-arrival (DOA) estimation techniques to achieve accurate localization of RFI sources in SAIR imagery. In this article, a multiple snapshot difference method is proposed to further reduce the RFI source geolocation bias. The covariance matrices of the consecutive snapshots with power changed RFIs are picked out and subtracted to cancel out the background scene. A MUSIC-based DOA algorithm is developed. Numerical simulations validate the theoretical correctness and the practical effectiveness of the proposed method.","1558-0644","","10.1109/TGRS.2020.3045088","National Natural Science Foundation of China (NSFC)(grant numbers:61771213,61801187); Opening Foundation of Science and Technology on Electronic Information Control Laboratory(grant numbers:6142105200302); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9318525","Geolocation;radio frequency interference (RFI);synthetic aperture interferometric radiometer (SAIR)","Covariance matrices;Correlation;Geology;Antenna measurements;Multiple signal classification;Earth;Antennas","covariance matrices;direction-of-arrival estimation;radiofrequency interference;radiometers;signal classification","multiple snapshot difference method;synthetic aperture interferometric radiometer;unauthorized radio frequency interference;brightness temperature;postobservation RFI geolocation;RFI situation;RFI sources;SAIR imagery;RFI source geolocation bias;consecutive snapshots;identified RFI;power changed RFI;direction-of-arrival estimation techniques;DOA estimation techniques;covariance matrices;background scene;MUSIC-based DOA algorithm","","2","","39","IEEE","8 Jan 2021","","","IEEE","IEEE Journals"
"Cloud Extraction Scheme for Multi-Spectral Images Using Landsat-8 OLI Images With High Brightness Reflectivity Covered","T. Wu; L. Han","School of Geology Engineering and Geomatics, Chang’an University, Xi’an, China; Shaanxi Key Laboratory of Land Consolidation and Rehabilitation, Chang’an University, Xi’an, China","IEEE Access","8 Jan 2020","2020","8","","3387","3396","Cloud extraction is a vital step in remote sensing image processing. Although many advanced cloud extraction methods have been proposed and confirmed to be effective in recent years, there are still difficulties in cloud extraction in areas of high brightness reflectivity covered. High brightness reflectivity cover can have similar spectral characteristics as clouds, and thus, it is easily confused with clouds in cloud extraction schemes. This work presents a novel scheme designed to extract clouds in satellite imagery with high brightness reflectivity covered. The fractal summation method and spatial analysis are used to extract the clouds in the Landsat 8 Operational Land Imager (OLI) images containing high brightness reflectivity covered. The scheme consists of three main steps: cloud extraction based on pixel values, Anselin Local Moran's I value, and anisotropy. Pixel values were applied to extract the clouds associated with anomalies, and the last two steps were conducted to eliminate false anomalies. The findings showed that the cloud-associated anomaly pixel-values well approximate a power-law function, but both the real and fake anomaly patches (e.g., snow/ice, desert, etc.) routinely coexist within the same (fractal) scaleless segments, and that the latter seems to be more significant than the former. Consequently, these results indicate that the diagnostic difference between true and false anomalies must lie in their spatial distribution patterns. Furthermore, experiments confirmed that the fractal dimension and spatial distribution (i.e. Anselin Local Moran's I index and anisotropy) difference between the real and false anomalies displayed a certain universality. The proposed scheme effectively reduces the confusion and misclassification caused by cloud, snow and the highlighted underlying surface. It is of great significance for cloud restoration processing, image analysis, image matching, target detection and extraction, and effective extraction and utilization of remote sensing data.","2169-3536","","10.1109/ACCESS.2019.2962871","National Natural Science Foundation of China(grant numbers:2017JZ009); Project of the Open Fund for Key Laboratory of Land and Resources Degenerate and Unused Land Remediation(grant numbers:SXDJ2017-7); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945137","Cloud extraction;spatial information;fractal summation method;Anselin Local Moran’s I;anisotropic analysis","Remote sensing;Clouds;Cloud computing;Satellites;Earth;Fractals;Snow","atmospheric techniques;clouds;geophysical image processing;image classification;image matching;remote sensing","effective extraction;target detection;image analysis;cloud restoration processing;snow;cloud-associated anomaly pixel-values;Landsat 8 Operational Land Imager images;high brightness reflectivity cover;advanced cloud extraction methods;remote sensing image processing;Landsat-8 OLI images;multispectral images;cloud extraction scheme","","2","","50","CCBY","30 Dec 2019","","","IEEE","IEEE Journals"
"Integration and Assimilation of Meteorological (ECMWF) Aerosol Estimates into Sen2Cor Atmospheric Correction","J. Louis; B. Pflug; M. Main-Knorn; V. Debaecker; U. Mueller-Wilm; F. Gascon","Telespazio France, Toulouse, Cedex 1, France; German Aerospace Centre, Remote Sensing Technology Institute; German Aerospace Centre, Remote Sensing Technology Institute; Telespazio France, Toulouse, Cedex 1, France; TPZV-D - Telespazio Vega Deutschland - A Leonardo, Thales Company; European Space Agency, ESRIN, Italy","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","1894","1897","Sen2Cor is a Level-2A processor designed to correct Sentinel-2 Level-1C products from the effects of the atmosphere in order to deliver a Level-2A surface reflectance product. A key-parameter for accurate atmospheric correction is the knowledge of the spatially and temporally very variable aerosol content of the atmosphere The multi-spectral instrument on board Sentinel-2 has the appropriate spectral bands to derive the aerosol optical thickness (AOT) of the atmosphere, provided the image contains reference areas of known reflectance behavior, preferably dense dark vegetation (DDV). If the granule contains no DDV pixels, a fallback solution is required. The former solution was to generate an AOT map based on the start visibility set in the configuration file. In this updated Sen2Cor version, meteorological AOT estimates are retrieved from ECMWF ftp server and pre-processed. The integration and assimilation of ECMWF aerosol estimates into Sen2Cor atmospheric correction is described and recent validation results are presented.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517562","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517562","Atmospheric correction;Sentinel-2;Sen2Cor;aerosol;meteorological;model","Aerosols;Cams;Adaptive optics;Optical imaging;Atmospheric modeling;Reflectivity;Optical reflection","aerosols;atmospheric optics;atmospheric techniques;reflectivity;remote sensing;vegetation;weather forecasting","Level-2A surface reflectance product;Sen2Cor version;Sentinel-2 Level-1C products;meteorological aerosol estimates;Sen2Cor atmospheric correction;ECMWF aerosol;meteorological AOT estimates;aerosol optical thickness;variable aerosol content;accurate atmospheric correction","","2","","12","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Retrieving LAI and LCC Simultaneously from Sentinel-2 Data Using Prosail and PSO-Coupled BI-Lut","Z. Wu; Q. Qin","Institute of Remote Sensing and Geographical Information Systems, Peking University, Beijing, China; Institute of Remote Sensing and Geographical Information Systems, Peking University, Beijing, China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","2895","2897","The PROSAIL (Prospect+SAIL) canopy radiation transfer model is the most widely used physical model in vegetation parameter inversion, however, it is hard to achieve a balance between the accuracy and efficiency of the retrieval. In this paper, a PSO-coupled (particle swarm optimization) bi-LUT (look-up table) was used to retrieve LAI (leaf area index) and LCC (leaf chlorophyll content) from Sentinel-2 MSI (multi-spectral instrument) images, which largely reduced the time consumption of the inversion. The results were validated with ground measurements. The RMSE of retrieved LAI and LCC were 0.79 m2/m2 and 7.1 μg/cm2, separately.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517839","Leaf Area Index;Leaf Chlorophyll Content;Sentinel-2;Look-Up Table;Particle Swarm Optimization","Table lookup;Biological system modeling;Vegetation mapping;Particle swarm optimization;Data models;Indexes;Numerical models","particle swarm optimisation;radiative transfer;radiometry;remote sensing;vegetation;vegetation mapping","Sentinel-2 data;PSO-coupled bi-LUT;PROSAIL canopy radiation transfer model;Prospect+SAIL;widely used physical model;vegetation parameter inversion;particle swarm optimization;LAI;leaf area index;LCC;leaf chlorophyll content;Sentinel-2 MSI;multispectral instrument;mass 7.1 mug;size 0.79 m","","","","5","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Multi-Spectral Image Change Detection Based on Band Selection and Single-Band Iterative Weighting","L. Ma; Z. Jia; Y. Yu; J. Yang; N. K. Kasabov","College of Information Science and Engineering, Xinjiang University, Ürümqi, China; College of Information Science and Engineering, Xinjiang University, Ürümqi, China; College of Information Science and Engineering, Xinjiang University, Ürümqi, China; Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, Shanghai, China; Knowledge Engineering and Discovery Research Institute, Auckland University of Technology, Auckland, New Zealand","IEEE Access","13 Mar 2019","2019","7","","27948","27956","Iteratively reweighted multivariate alteration detection algorithm has the phenomena of broken patches, much noise, and small change area that are difficult to detect, and the overall detection rate is low. In order to solve this problem, this paper proposes a multi-spectral image change detection algorithm based on band selection and single-band iterative weighting. Because the change information of the multi-spectral image is concentrated in some bands, the background and noise information of the rest bands are more, which may have a negative effect on the final result. Therefore, the band with more change information is selected first, and the iterative weighting of a single band can better suppress the noise and background information, so as to obtain a higher band correlation and facilitate the extraction of change information. This method is used to obtain the characteristic difference graph of the selected band with more change information. After Gaussian denoising of each characteristic difference graph, the Euclidean distance formula is used to fuse the difference graph of each band into a change intensity graph. Finally, the unsupervised $k$ -means clustering algorithm is used to perform binary-valued clustering on the fused difference graph to obtain the change detection results. As a practical application, the superior performance of our proposed method was demonstrated through a large number of comparative tests.","2169-3536","","10.1109/ACCESS.2019.2901286","National Natural Science Foundation of China(grant numbers:61665012,U1803261); Ministry of Education of the People's Republic of China(grant numbers:DICE 2016–2196); Natural Science Foundation of Xinjiang Province(grant numbers:2015211C288); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658068","Multi-spectral change detection;IR-MAD;band selection","Change detection algorithms;Correlation;Remote sensing;Time complexity;Correlation coefficient;Feature extraction;Iterative algorithms","geophysical image processing;image denoising;image fusion;iterative methods;object detection;pattern clustering;terrain mapping","multispectral image change detection algorithm;detection rate;change area;multivariate alteration detection algorithm;band selection;change detection results;change intensity graph;characteristic difference graph;higher band correlation;background information;rest bands;change information;single-band iterative weighting","","5","","30","OAPA","4 Mar 2019","","","IEEE","IEEE Journals"
"Ship Classification from Multi-Spectral Satellite Imaging by Convolutional Neural Networks","R. Grasso","NATO STO CMRE, La Spezia, Italy","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","This work investigates the use of convolutional neural networks for classifying ship targets from images acquired by the Multi-Spectral Instrument sensor on board Sentinel-2 satellites. An automatic procedure, requiring a minimum amount of supervision, is applied to extract labeled target images which are used for training. The data set consists of top of the atmosphere reflectance images in three visible channels and one near-infrared band. The performance of the classifier is evaluated by the receiver operating characteristic curve and the area under the curve statistics. The results show good classification performance with area under the curve greater than 0.95. Future work will be focused on investigating the impact of image atmospheric corrections and on comparing with other methods.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8902822","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902822","Machine Learning;Ship classification;Satellite imaging","Marine vehicles;Artificial intelligence;Training;Feature extraction;Data mining;Satellite broadcasting;Navigation","convolutional neural nets;geophysical equipment;geophysical image processing;image classification;remote sensing;ships","MultiSpectral satellite imaging;convolutional neural networks;MultiSpectral Instrument sensor;board Sentinel-2 satellites;automatic procedure;labeled target images;classifier;image atmospheric corrections;ship classification","","4","","14","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Semi-supervised Classification of Land Cover in Multi-spectral Images Using Spectral Slopes","S. M. Aswatha; J. Mukhopadhyay; P. K. Biswas","Advanced Technology Development Centre, Indian Institute of Technology Kharagpur, Kharagpur, India; Computer Science & Engg., Indian Institute of Technology Kharagpur, Kharagpur, India; Electronics and Electrical Communication Engg., Indian Institute of Technology Kharagpur, Kharagpur, India","2017 Ninth International Conference on Advances in Pattern Recognition (ICAPR)","30 Dec 2018","2017","","","1","6","We propose a spectral-slope based technique to classify land-cover using spectral angle mapper (SAM) classifier, which is a semi-supervised process of labeling the land surface. Initial reference samples for SAM are obtained from spectral-slopes based rules, which are tailored to classify multispectral images obtained by Indian Space Research Organization`s (ISRO) Linear Imaging Self-Scanning Sensor 3 (LISS-III) and Advanced Wide Field Sensor (AWiFS). All the pixels in the are classified by using these reference samples, which are subsequently used in a SAM algorithm. The rules for selecting the reference samples from the multi-spectral imageries are defined by using the properties of spectral-profiles. The land-cover is classified into five broad classes, namely, water, grass land, built-up, vegetation, and bare land. The classification results are validated using very high resolution (VHR) satellite images.","","978-1-5386-2241-4","10.1109/ICAPR.2017.8593093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593093","spectral slopes;spectral angle mapper;land cover classification;LISS- III;AWiFS","Vegetation mapping;Indexes;Labeling;Support vector machines;Market research;Imaging;Meters","geophysical image processing;geophysical signal processing;image classification;land cover;remote sensing;terrain mapping;vegetation;vegetation mapping","spectral angle mapper classifier;semisupervised process;spectral-slope based technique;spectral slopes;land cover;semisupervised classification;high resolution satellite images;bare land;grass land;spectral-profiles;multispectral imageries;SAM algorithm;Advanced Wide Field Sensor;Indian Space Research Organization's Linear Imaging Self-Scanning Sensor;multispectral images;spectral-slopes based rules;initial reference samples;land surface","","2","","21","IEEE","30 Dec 2018","","","IEEE","IEEE Conferences"
"Multi-Spectral Analysis of Dry Alpine Seasonal Snowpack","M. Lodigiani; L. Silvestri; R. Barella; C. Marin; B. Di Mauro; R. Colombo; C. Notarnicola; M. Pasian","Dept. of Electrical, Computer and Biomedical Engineering, University of Pavia, Italy; Dept. of Electrical, Computer and Biomedical Engineering, University of Pavia, Italy; EURAC Research - Institute for Earth Observation, Italy; EURAC Research - Institute for Earth Observation, Italy; Institute of Polar Sciences, National Research Council of Italy (ISP-CNR), Italy; Earth and Environmental Sciences Department, University of Milano-Bicocca, Italy; EURAC Research - Institute for Earth Observation, Italy; Dept. of Electrical, Computer and Biomedical Engineering, University of Pavia, Italy","2022 52nd European Microwave Conference (EuMC)","31 Oct 2022","2022","","","76","79","Seasonal Alpine snowpack is an important reservoir of fresh water useful for human and agricultural purposes and for hydroelectric power generation. Thus, monitoring the evolution of the snow is very useful to control this important factor. To do this, different approaches are used. Among them, microwave-based devices are used, but show some limitations due to the impossibility to retrieve the parameters without a priori assumptions or complementary information about the snowpack, or complex data processing. This paper present a portable radar architecture able to overcome this limitation by using a dual-receiver system. The device was already tested for the S-band. Now, a multi-spectral analysis is tested for the first time to retrieve values of depth, density and snow water equivalent (SWE), for dry snow. The system was tested in real field sites in the Italian Alps during late winter 2022. The overall results were in good agreement with manual measurements.","","978-2-8748-7069-9","10.23919/EuMC54642.2022.9924395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9924395","snow monitoring;multi-frequency;snow water equivalent (SWE);radar;Alpine snowpack","Snow;Hydroelectric power generation;Europe;Manuals;Microwave devices;Reservoirs;Data processing","hydrological techniques;remote sensing by radar;snow;spectral analysis","Italian Alps;AD 2022;late winter;snow water equivalent;dual-receiver system;portable radar architecture;complex data processing;microwave-based devices;hydroelectric power generation;fresh water reservoir;dry Alpine seasonal snowpack;multispectral analysis","","","","15","","31 Oct 2022","","","IEEE","IEEE Conferences"
"SOF-UNet: SAR and Optical Fusion Unet for Land Cover Classification","D. Zhang; M. Gade; J. Zhang","Fachbereich Informatik, Universität Hamburg, Hamburg, Germany; Universität Hamburg, Institut für Meereskunde, Hamburg, Germany; Fachbereich Informatik, Universität Hamburg, Hamburg, Germany","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","907","910","We propose a SAR and Optical Fusion Network based on the UNet framework (SOF-UNet) for multi-modal land cover classification. The two-stream SOF-UNet consists of three parts: two encoders to extract features, a sharing decoder to upsample the feature maps and specially designed skip connections to fuse multi-modal features. The qualitative and quantitative experimental results show that SOF-UNet has a promising capability to identify different land cover classes and can retain fine details in the prediction maps. Symmetric Cross Entropy (SCE) loss is also verified useful in this framework.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884504","National Science Foundation of China (NSFC)(grant numbers:61621136008/DFG TRR-169); German Research Foundation (DFG); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884504","land cover classification;SAR;multi-spectral;multi-modal fusion;UNet","Optical losses;Fuses;Geoscience and remote sensing;Optical fiber networks;Feature extraction;Entropy;Decoding","decoding;entropy;feature extraction;image classification;image fusion;pattern classification;sensor fusion","SAR;Optical Fusion unet;Optical Fusion Network;UNet framework;multimodal land cover classification;sharing decoder;feature maps;skip connections;multimodal features;qualitative results;quantitative experimental results;SOF-UNet;different land cover classes","","","","9","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Estimation and Spatial Analysis of Heavy Metals in Metal Tailing Pond Based on Improved PLS With Multiple Factors","W. Rui; W. Shuang; W. Kan; H. Shiqiao; W. Ruijie; L. Bo; L. Min; L. Liang; Z. Dawei; D. Xinpeng","Jiangsu Key Laboratory of Resources and Environmental Information Engineering, China University of Mining and Technology, Xuzhou, China; School of Environment Science and Spatial Informatics, China University of Mining and Technology, Xuzhou, China; School of Environment Science and Spatial Informatics, China University of Mining and Technology, Xuzhou, China; School of Foreign Languages, Jiangxi University of Science and Technology, Ganzhou, China; Tate Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Hubei, China; College of Applied Science, Jiangxi University of Science and Technology, Ganzhou, China; Anhui Lujiang Longqiao Mining Company Ltd., Lujiang, China; Jiangsu Key Laboratory of Resources and Environmental Information Engineering, China University of Mining and Technology, Xuzhou, China; Jiangsu Key Laboratory of Resources and Environmental Information Engineering, China University of Mining and Technology, Xuzhou, China; Jiangsu Key Laboratory of Resources and Environmental Information Engineering, China University of Mining and Technology, Xuzhou, China","IEEE Access","4 May 2021","2021","9","","64880","64894","With the exploitation of mineral resources, pollution of the ecological environment in mines has garnered public attention. Particularly,erosion of the surrounding ecological environment re-sulting from heavy metals in tailings pond could be highly concerning. Instead of traditional field sampling and laboratory analysis method, remote sensing can be used to high-precisi es-timation soil heavy metal with less time and effort. soil heavy metal content is generally low, the spectral sensitivities of various heavy metals are insignificant, and the surface landscape is complex, there exist difficulties associated with heavy metal content estimation. Therefore, herein, we propose optimization of the commonly used partial least-square regression (PLS) method. In the optimized method, a variety of remote sensing indices and the modeled heavy metals were added as modeling factors to indirect estimation soil heavy metal. The method was validated via inversion experiments of heavy metals (Ni, Cu, and Zn) in the tailing pond and its surrounding environment,it improve the goodness-of-fit of Ni, Cu, and Zn by 0.0852,0.2291, and 0.2919 compared with traditional PLS. Spatia l analysis was then conducted on the entire studied area using the estimation model of the three heavy metals. It was shown that the results were essentially consistent with the actual heavy metal distribution in the area. Therefore, the indirect PLS model with multiple factors proves effective for the estimation of soil heavy metals. It also provides technical support for treatment and evaluation of ecological environments in mining areas.","2169-3536","","10.1109/ACCESS.2021.3073933","Science and Technology Project of Jiangxi Education Department(grant numbers:GJJ191594); Ningxia Key Research and Development Project(grant numbers:2020BFG03009); National Natural Science Foundation of China(grant numbers:51604266); Natural Science Foundation of Jiangsu Province(grant numbers:BK20190642); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9406793","Multi-spectral remote sensing image;heavy metals in soil;partial least-squares regression;fusion of multiple factors;spatial evolution analysis;GF-2","Soil;Metals;Vegetation mapping;Indexes;Estimation;Atmospheric modeling","copper;ecology;erosion;geochemistry;least squares approximations;minerals;mining;nickel;regression analysis;remote sensing;soil;soil pollution;zinc","metal tailing pond;ecological environment;laboratory analysis method;heavy metal distribution;soil heavy metals;mineral resources;erosion;partial least-square regression;remote sensing indices;mining areas;spatial analysis;Cu;Ni;Zn","","3","","45","CCBY","19 Apr 2021","","","IEEE","IEEE Journals"
"SSCNET: Spectral-Spatial Consistency Optimization of CNN for Pansharpening","K. Doi; A. Iwasaki","Department of Aeronautics and Astronautics, the University of Tokyo, Tokyo, Japan; Department of Aeronautics and Astronautics, the University of Tokyo, Tokyo, Japan","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3141","3144","Recently, convolutional neural network (CNN) has achieved great results in pansharpening. Most pansharpening methods with CNN are based on PNN [1] inspired by super-resolution methods with CNN and learn the pansharpening of downsampled images. In this work, we presented a novel framework for pansharpening based on two desired property of pansharpened images: downsampled pansharpened images become low-resolution multi-spectral images (spectral consistency) and panchromatic images are approximated by weighted addition of each bands of pansharpened images (spatial consistency). Our framework train CNN to learn this spectral-spatial consistency. The advantage of our framework is that there is no scale mismatch between training and test data. We applied our method to Landsat-8 images and compared it with some previous methods.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8897928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897928","Pansharpening;convolutional neural network;deep learning;data fusion","Remote sensing;Artificial satellites;Earth;Spatial resolution;Principal component analysis;Optimization","convolutional neural nets;geophysical image processing;image resolution;image sampling;learning (artificial intelligence)","pansharpening methods;super-resolution methods;downsampled pansharpened images;spectral consistency;panchromatic images;CNN;Landsat-8 images;spectral-spatial consistency optimization;convolutional neural network;multi-spectral images","","4","","8","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"A Multi-Sensor Approach to Separate Palm Oil Plantations from Forest Cover Using NDFI and a Modified Pauli Decomposition Technique","M. Erith; Z. Alfonso; L. Erik","Forestry Department, The Food and Agriculture Organization of the United Nations, Rome, Italy; Forestry Department, The Food and Agriculture Organization of the United Nations, Rome, Italy; Forestry Department, The Food and Agriculture Organization of the United Nations, Rome, Italy","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","4481","4484","In this work, a multi-sensor approach to separate oil palm plantations from forest cover using NDFI and a modified Pauli Decomposition technique is presented. The main contribution of this research is the potential to reduce misclassification of both classes, in the context of automated-base supervised classification algorithms, to decrease uncertainties derived through the detection and mapping process of forest cover. The hereby proposed method includes the generation of a primary forest map cover defining thresholds from a high resolution multi -spectral satellite image, and then the palm oil plantation will be filtered out from this classification using scattering mechanisms by a Pauli Decomposition approach. Preliminary results shown the capabilities of this approach in order to generate complementary information to separate the oil palm plantations from the forest cover classification.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324567","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324567","NDFI;Pauli Decomposition;Forest Cover Change;SAR Polarimetry;REDD+","Forestry;Oils;Remote sensing;Scattering;Uncertainty;Synthetic aperture radar;Satellites","forestry;geophysical image processing;image classification;terrain mapping;vegetation mapping","palm oil plantation;Pauli Decomposition approach;multisensor approach;separate palm oil plantations;forest cover;NDFI;modified Pauli Decomposition technique;separate oil palm plantations;automated-base supervised classification algorithms;mapping process;high resolution multi-spectral satellite image;primary forest map cover","","3","","9","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Deep Neural Networks Based Semantic Segmentation for Optical Time Series","W. Yao; M. Datcu","Department of EO Data Science, German Aerospace Center (DLR), Germany; Department of EO Data Science, German Aerospace Center (DLR), Germany","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","4403","4406","Semantic segmentation or classification for satellite image time series (SITS) is a rarely touched topic, partly due to the difficulty in having the data, but more due to the unreachable task. In this research, we propose a dataset which consists of the Landsat image time series, with the purpose of performing multi-spectral semantic segmentation. As there is no ground truth information, we used unsupervised clustering to group time series into clusters, then Long short term memory (LSTM) unit based Recurrent neural networks (RNN) has been trained. We investigate the accuracy values for our test image patches, around 40% accuracy has been achieved for the sequence classification.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518708","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518708","Satellite image time series;RNN;LSTM;Temporal pattern","Time series analysis;Recurrent neural networks;Remote sensing;Artificial satellites;Earth;Indexes;Semantics","artificial satellites;geophysical image processing;image classification;image segmentation;pattern clustering;recurrent neural nets;time series;unsupervised learning","unsupervised clustering;test image patches;deep neural networks;optical time series;satellite image time series;Landsat image time series;long short term memory unit;recurrent neural networks;multi-spectral semantic segmentation;SITS classification","","1","","6","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"The Potential of Sentinel Satellites for Large Area Aboveground Forest Biomass Mapping","A. Haywood; C. Stone; S. Jones","School of Mathematical and Geospatial Sciences, RMIT University, Melbourne, Australia; New South Wales Department of Industry - Lands, Sydney, Australia; School of Mathematical and Geospatial Sciences, RMIT University, Melbourne, Australia","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","9030","9033","Estimation of aboveground forest biomass is critical for regional carbon policies and sustainable forest management. Both passive optical remote sensing and active microwave remote sensing can play an important role in the monitoring of forest biomass. In this study, the recently launched Sentinel-2 Multi Spectral Instrument satellite and Sentinel-1 SAR satellite systems were evaluated and integrated to investigate the relative strengths of each sensor for mapping aboveground forest biomass at a regional scale. The Australian state of Victoria, with its wide range of forest vegetation was chosen as the study area to demonstrate the scalability and transferability of the approach. In this study aboveground forest biomass (AGB) was defined as the tons of carbon per hectare for the aboveground components (stem, branches, leaves) of all live large trees greater than 10 cm in diameter at breast height (DBHOB). Sentinel-2 and Sentinel-1 data were fused within a machine learning framework using a boosted regression tree model and high-quality ground survey data. Multicriteria evaluations showed the use of the two independent and fundamentally different Sentinel satellite systems were able to provide robust estimates (R2 of 0.62, RMSE of 32.2 t.C.ha-1) of aboveground forest biomass, with each sensor compensating for the weakness (cloud perturbations and spectral saturation for Sentinel 2, and sensitivity to ground moisture for Sentinel 1) of each other. As archives for Sentinel-2 and Sentinel-1 continue to grow, mapping aboveground forest biomass and dynamics at moderate resolution over large regions should become increasingly feasible.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517597","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517597","biomass estimation;Sentinel-1;Sentinel-2;machine learning;boosted regression tree model;data fusion;Victoria;Australia","Forestry;Biomass;Vegetation;Meteorology;Satellites;Surfaces;Carbon","forestry;geophysical techniques;regression analysis;remote sensing by radar;synthetic aperture radar;vegetation;vegetation mapping","Sentinel satellite systems;Sentinel-2 MultiSpectral Instrument satellite;diameter at breast height;ground moisture;Australian state;Victoria;high-quality ground survey data;boosted regression tree model;Sentinel-1 data;aboveground components;forest vegetation;Sentinel-1 SAR satellite systems;active microwave remote sensing;passive optical remote sensing;sustainable forest management;area aboveground forest biomass mapping","","1","","11","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Assessment Of The Radiometric Accuracy In A Target Less Work Flow Using Pix4D Software","M. Cubero-Castan; K. Schneider-Zapp; M. Bellomo; D. Shi; M. Rehak; C. Strecha","Pix4D SA, EPFL Innovation Park -Building F, Lausanne, Switzerland; Pix4D SA, EPFL Innovation Park -Building F, Lausanne, Switzerland; Pix4D SA, EPFL Innovation Park -Building F, Lausanne, Switzerland; Pix4D SA, EPFL Innovation Park -Building F, Lausanne, Switzerland; Pix4D SA, EPFL Innovation Park -Building F, Lausanne, Switzerland; Pix4D SA, EPFL Innovation Park -Building F, Lausanne, Switzerland","2018 9th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","27 Jun 2019","2018","","","1","4","To compute reflectance from images taken by multispectral sensors aboard UAVs, most users perform radiometric calibration using a target with known reflectance. This workflow is error-prone and not practical for large data acquisitions. With recent advances in multispectral cameras, sensors which measure the sky down-welling irradiance have become available. This enables radiometric calibration without using a target. In this paper, we assess the radiometric accuracy of target less acquisition using a Sequoia + camera1 for both at-ground and in-flight measurements. Most of the measured control points exhibit a high correlation of 0.98 in the computed reflectance factor with respect to the expected values.","2158-6276","978-1-7281-1581-8","10.1109/WHISPERS.2018.8746910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8746910","UAVs;target less workflow;radiometric calibration;multi spectral cameras;Pix4D;Sequoia + camera","Cameras;Radiometry;Sea measurements;Sensors;Calibration;Soil measurements;Extraterrestrial measurements","autonomous aerial vehicles;calibration;cameras;data acquisition;image sensors;radiometry;remote sensing","Pix4D software;multispectral sensors;UAVs;radiometric calibration;error-prone;data acquisitions;multispectral cameras;sky down-welling irradiance;Sequoia + camera;in-flight measurements;measured control points;computed reflectance factor;targetless workflow;reflectance;radiometric accuracy assessment","","4","","7","IEEE","27 Jun 2019","","","IEEE","IEEE Conferences"
"A Fractal Dimension Estimator For Multispectral Images","M. Ivanovici","Electronics and Computers Department, MIV Imaging and Vision Laboratory, Transilvania University of Braşov, România","2022 12th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","22 Nov 2022","2022","","","1","4","We propose a fractal dimension estimator for multispectral images. The estimator is based on the probabilistic box-counting classical approach extended to the multivariate domain of multiband images. In order to validate the estimator, we propose a fractal model for multispectral images based on the fractional Brownian motion. The generated synthetic multispectral fractal images have 7 statistically-independent spectral bands at specific wavelengths in the visible domain. We apply the proposed approach for the complexity characterization of a widely-known remotely-sensed data set and conclude the article.","2158-6276","978-1-6654-7069-8","10.1109/WHISPERS56178.2022.9955091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955091","fractal dimension;box counting;multi-spectral fractal images;multispectral images","Image segmentation;Conferences;Signal processing algorithms;Color;Signal processing;Probabilistic logic;Fractals","Brownian motion;fractals;geophysical image processing;hyperspectral imaging;remote sensing by laser beam","fractal dimension estimator;fractal model;fractional Brownian motion;multiband images;probabilistic box-counting classical approach;remotely-sensed data set;synthetic multispectral fractal images","","","","26","IEEE","22 Nov 2022","","","IEEE","IEEE Conferences"
"Image Fusion Based on Discrete Cosine Transform with High Compression","E. Alhatami; U. A. Bhatti; M. Huang; S. L. Feng","School of Information and Communication Engineering, Hainan University, Haikou, China; School of Information and Communication Engineering, Hainan University, Haikou, China; School of Information and Communication Engineering, Hainan University, Haikou, China; School of Information and Communication Engineering, Hainan University, Haikou, China","2022 7th International Conference on Signal and Image Processing (ICSIP)","19 Sep 2022","2022","","","606","610","The fusion of images is defined as an alignment of important information from diverse sensors using various mathematical models to generate a single compound image. The fusion of images is used for integrating the complementary multi-temporal, multi-view, and multi-sensor information into a single image with improved image quality and by keeping the integrity of essential features. It is considered a vital pre-processing phase for several applications such as robot vision, aerial, satellite imaging, medical imaging, and robot or vehicle guidance. This paper proposed an enhancement image compression algorithm on a discrete cosine transform (DCT). Then it uses the DCT transformation in the remote sensing image fusion domain and a remote sensing image fusion method with an improved proposed algorithm. The method in this paper has an acceptable compromise between enhancing the spatial resolution of the fused image and maintaining the spectral information. Besides, it is shown that there is no need for codec operations when performing image fusion in the compressed domain such as JPEG. This reduces the time to obtain the fused image and effectively suppresses the problem of dealing with blocky image processing; blockage often occurs. Furthermore, the improved algorithm has better spectral retention capability under the premise of more explicit fusion images and is more suitable for applications requiring higher spectral fidelity.","","978-1-6654-9563-9","10.1109/ICSIP55141.2022.9887300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9887300","Image Fusion;DCT;Multi-Spectral Image (MSI);Panchromatic image (PAN)","Image coding;Satellites;Transform coding;Signal sampling;Sensor fusion;Sensors;Discrete cosine transforms","data compression;discrete cosine transforms;image coding;image enhancement;image fusion;image processing;image resolution;medical image processing;remote sensing;robot vision;sensor fusion","discrete cosine transform;high compression;single compound image;complementary multitemporal;multiview;multisensor information;single image;improved image quality;vital pre-processing phase;satellite imaging;medical imaging;enhancement image compression algorithm;DCT transformation;remote sensing image fusion domain;remote sensing image fusion method;fused image;blocky image processing;explicit fusion images","","","","15","IEEE","19 Sep 2022","","","IEEE","IEEE Conferences"
"Estimation of an Aerosol Plume Mass Balance from Plume Property Retrievals Computed by the Combination of the Sentinel-2 Data with Hyperspectral Data Coupled with an Optimal Estimation Method","G. Calassou; P. -Y. Foucher; J. -F. Léon","ONERA “The French Aerospace Lab”, Toulouse, France; ONERA “The French Aerospace Lab”, Toulouse, France; Laboratoire d’ Aérologie, Université Toulouse, Toulouse, France","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","7123","7126","Particulate emissions from industrial sector are a concern for human health and air quality. In this paper we investigate the use of a hyperspectral image to retrieve plume mass concentration and its flow rate from the plume optical properties. The method uses the combination of Sentinel-2 and hyperspectral data to classify, correct and segment surface reflectances below the plume. The retrieval of plume properties is based on a statistical framework called the “Optimal estimation method” (OEM) initialized by using first a sequential method. The method is applied to a particulate matter plume observed by the airborne HYSPEX sensor in February 2016 over a steel plant in the south-east of France. The HYSPEX image was taken in the solar reflective domain between 410 and 2500 nm. The retrieved parameters are the modal radius, the surface reflectance and the aerosol optical thickness (AOT). From optimal estimation method retrievals, the plume particulate matter column mass enhancement are computed for each pixel where the plume is detected. Plume particulate matter column mass enhancement vary between 200 and 1300 mg/pixel and the retrieved mean flow rate per wind speed meter per second is 1.6 g s−1 (m s−1)−1.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554132","Hyperspectral;Multi-spectral;Aerosol plume","Satellites;Uncertainty;Wind speed;Estimation;Optical imaging;Steel;Optical sensors","aerosols;air pollution;atmospheric composition;atmospheric optics;atmospheric techniques;geophysical image processing;remote sensing;wind","hyperspectral data;particulate emissions;human health;air quality;hyperspectral image;plume mass concentration;plume optical properties;correct segment surface;plume properties;sequential method;particulate matter plume;retrieved parameters;surface reflectance;aerosol optical thickness;optimal estimation method retrievals;plume particulate matter column mass enhancement;retrieved mean flow rate;aerosol plume mass balance;plume property retrievals computed;Sentinel-2 data;size 410.0 nm to 2500.0 nm","","","","12","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Automatic Cloud Detection in Resourcesat LISS-3 Data using Spectral Angle Similarity and Mode Seeking Reference Spectra","I. Misra; S. M. Moorthi; D. Dhar","Signal and Image Processing Group Space Applications Centre Indian Space Research Organisation, Ahmedabad, India; Signal and Image Processing Group Space Applications Centre Indian Space Research Organisation, Ahmedabad, India; Signal and Image Processing Group Space Applications Centre Indian Space Research Organisation, Ahmedabad, India","2020 IEEE 15th International Conference on Industrial and Information Systems (ICIIS)","8 Feb 2021","2020","","","280","284","Optical remote sensing images contain cloud pixels, which need to be detected and masked for different earth observation studies and applications. In literature, various algorithms are reported which can detect cloud in multi-spectral remote sensing images. In this paper, we have developed an approach based on spectral angle computation that measures the radiometric gap between a reference pixel and input image pixels. Reference spectra is determined using mode seeking technique by taking multiple cloud pixels from multi-temporal images covering different land terrain. The processing chain is developed and tested in Resourcesat LISS-3 surface reflectance data. Result section shows that technique developed can determine thick cloud pixels with high confidence interval and compared with other novel cloud detection methods.","2164-7011","978-1-7281-8524-8","10.1109/ICIIS51140.2020.9342700","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9342700","Cloud;Spectral angle;Mode Seeking;Multitemporal;Resourcesat;LISS-3","Reflectivity;Radiometry;Optical imaging;Optical sensors;Optical reflection;Remote sensing;Surface treatment","clouds;geophysical image processing;remote sensing","automatic cloud detection;Resourcesat LISS-3 data;spectral angle similarity;mode seeking reference spectra;optical remote sensing images;earth observation studies;multispectral remote sensing images;spectral angle computation;reference pixel;input image pixels;multiple cloud pixels;multitemporal images;land terrain;Resourcesat LISS-3 surface reflectance data;cloud detection methods","","","","12","IEEE","8 Feb 2021","","","IEEE","IEEE Conferences"
"End to End Simulation Study of Geostaionary Passive Microwave Atmospheric Sounding","K. Chen; A. Gasiewski; K. Zhang; L. Lang; L. Gui; Q. Li; Y. He","Science and Technology on Multi-spectral Information Processing Laboratory, Wuhan, China; Department of Electrical, Computer, and Energy Engineering, University of Colorado at Boulder; Department of Electrical, Computer, and Energy Engineering, University of Colorado at Boulder; School of Electronic Information and Communications, Huazhong University of Science and Technology; School of Electronic Information and Communications, Huazhong University of Science and Technology; School of Electronic Information and Communications, Huazhong University of Science and Technology; School of Electronic Information and Communications, Huazhong University of Science and Technology","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","6010","6013","A numerical simulator for analysis of the geostationary orbit multispectral passive microwave (Geo-MW) mapping and sounding is described, which mainly includes upwelling brightness temperatures forward, microwave radiometer payload simulation and atmospheric profile retrieval. This simulator allows evaluation and optimization of the ability of microwave sensors to retrieve atmospheric temperature and humidity profile. In this paper, end to end simulation study of a Geo-MW radiometer observation at selected frequencies from 50 to 425 GHz with a real-aperture antenna is performed and the accuracy of the brightness temperature measurement and the atmospheric temperature and humidity profile sounding are quantitatively analyzed and evaluated.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518115","GEO microwave imagers;atmospheric sounding;observation system simulation;microwave radiative transfer;atmospheric profile retrieval","Atmospheric modeling;Microwave radiometry;Brightness temperature;Microwave imaging;Microwave antennas;Computational modeling;Microwave communication","atmospheric humidity;atmospheric techniques;atmospheric temperature;radiometry;remote sensing;temperature measurement","geostaionary passive microwave atmospheric sounding;humidity profile sounding;brightness temperature measurement;Geo-MW radiometer observation;atmospheric temperature;microwave sensors;atmospheric profile retrieval;microwave radiometer payload simulation;numerical simulator;frequency 50.0 GHz to 425.0 GHz","","","","6","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Automatic road detection from gray-level images in Wide Area Surveillance","O. Can; Y. Z. Gürbüz; A. A. Alatan","Center for Image Analysis, Middle East Technical University, Ankara, Turkey; Department of Electrical & Electronics Engineering, Middle East Technical University, Ankara, Turkey; Department of Electrical & Electronics Engineering, Middle East Technical University, Ankara, Turkey","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","1603","1606","Wide Area Surveillance (WAS) systems are capable of providing continuous surveillance of critical areas as wide as city center (approximately 20 km square), mostly as a gray-level video. Utilization of road information for WAS systems increases moving vehicle tracking performance, while reducing the false alarm rates that might occur due to tall buildings, shadows or terrain. Two different novel approaches for automatic road detection from gray values images are presented in this paper. In the first approach, a probabilistic model for the road pixels of a gray-scale WAS image is obtained by utilizing parallel line detection and tubularity estimation. In the second approach, these road probabilities are converted into a graph representation for local areas. These graphs are solved by using graph cut formulation which exploits min-cut, max-flow algorithm. As a result of this solution, the road mask is extracted by applying a hierarchical model that results with a transition from local to global representation. Although the methods in literature mostly utilize multi-spectral images that result wih a smaller resolution yielding surveillance of a limited region, the proposed method uses gray-scale images which enable surveillance of much wider areas. The proposed method was tested some high resolution WAS images and resulted with promising results.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729409","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729409","Road extraction from gray-scale image;parallel line detection;tubularity estimation;graph cut;SLIC","Roads;Estimation;Surveillance;Gray-scale;Image resolution;Satellites;Simulation","remote sensing;terrain mapping","automatic road detection;gray-level images;wide area surveillance;road information;WAS systems;vehicle tracking performance;probabilistic model;tubularity estimation;hierarchical model;multi-spectral images","","","","9","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Temporal Vegetation Modelling Using Long Short-Term Memory Networks for Crop Identification from Medium-Resolution Multi-spectral Satellite Images","M. Rußwurm; M. Körner","Remote Sensing Technology, Technical University of Munich, Germany; Remote Sensing Technology, Technical University of Munich, Germany","2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","24 Aug 2017","2017","","","1496","1504","Land-cover classification (LCC) is one of the central problems in earth observation and was extensively investigated over recent decades. In many cases, existing approaches concentrate on single-time and multi- or hyper-spectral reflectance measurements observed by spaceborne and airborne sensors. However, land-cover classes, such as crops, change their reflective characteristics over time, thus complicating a classification at one particular observation time. Opposed to that, these characteristics change in a systematic and predictive manner, which should be utilized in a multi-temporal approach.,,,,,,We employ long short-term memory (LSTM) networks to extract temporal characteristics from a sequence of SENTINEL 2A observations. We compared the performance of LSTM networks with other architectures and a support vector machine (SVM) baseline and show the effectiveness of dynamic temporal feature extraction. For our experiments, a large study area together with rich ground truth annotations provided by public authorities was used for training and evaluation. Our rather straightforward LSTM variant achieved state-of-the art classification performance, thus opening promising potential for further research.","2160-7516","978-1-5386-0733-6","10.1109/CVPRW.2017.193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8014927","","Agriculture;Satellites;Remote sensing;Earth;Logic gates;Recurrent neural networks;Vegetation mapping","geographic information systems;land cover;support vector machines","temporal vegetation modelling;long short-term memory networks;crop identification;medium-resolution multispectral satellite images;land-cover classification;LCC;earth observation;hyper-spectral reflectance measurements;spaceborne sensors;airborne sensors;land-cover classes;LSTM networks;SENTINEL 2A observations;support vector machine;SVM baseline;dynamic temporal feature extraction;public authorities","","47","2","23","IEEE","24 Aug 2017","","","IEEE","IEEE Conferences"
"Mediterranean shrublands biomass estimation using Sentinel-1 and Sentinel-2","J. Chang; M. Shoshany","Department of Civil and Environment Engineering, Technion-Israel Institute of Technology, Haifa, Israel; Department of Civil and Environment Engineering, Technion-Israel Institute of Technology, Haifa, Israel","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","5300","5303","Potential for synergetic use of Sentinel- 1 and Sentinel-2 for mapping biomass of Mediterranean shrublands is investigated. As preliminary research, backscatter and its ratio from Sentinel-1 (C-band dual polarization SAR), and NDVI from Sentinel-2 (13 bands multi-spectral data) are assessed by using the NDVIR biomass model. Then the fusion biomass model is proposed based on shrub volume formations. The fusion model is verified by filed survey data which measured shrub height and diameter applied into the allometric model. The proposed fusion model shows around 14 % improvement of accuracy compared to the single sensor model (r-square: from 0.72 to 0.86, RMSE: from 0.158 to 0.109).","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730380","Biomass;C-band SAR;Mediterranean;Fusion;Semi-arid;Sentinel;Shrublands","Biomass;Biological system modeling;Remote sensing;Data models;Estimation;Vegetation mapping;Mathematical model","remote sensing by radar;synthetic aperture radar;vegetation mapping","Mediterranean shrubland biomass estimation;Sentinel-1;Sentinel-2;biomass mapping;C-band dual polarization SAR;multispectral data;NDVIR biomass model;fusion biomass model;shrub volume formation;proposed fusion model;allometric model;single sensor model","","24","","11","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Rice yield estimation using multispectral data from UAV: A preliminary experiment in northern Italy","D. Stroppiana; M. Migliazzi; V. Chiarabini; A. Crema; M. Musanti; C. Franchino; P. Villa","IREA-CNR, Milano, Italy; GLOBI Hi-Tech Srl, Genova, Italy; KIM-RemoteSensing GmbH, Azienda Agricola Carlo Franchino, Klagenfurt Rosasco, Wortherse PV, Austria Italy; IREA-CNR, Milano, Italy; IREA-CNR, Milano, Italy; KIM-RemoteSensing GmbH, Azienda Agricola Carlo Franchino, Klagenfurt Rosasco, Wortherse PV, Austria Italy; IREA-CNR, Milano, Italy","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","4664","4667","UAVs platforms are promising for agricultural monitoring since they offer operating flexibility, very high spatial resolution and acquisition costs suitable for frequent on demand monitoring of crop field. In this work we carried out an experimental flight over a rice field in Lombardy region, northern Italy, to test the correlation between reflectance in the spectral channels and vegetation indices derived from imagery acquired with a multi-spectral sensor on board an UAV. Results show that UAV images can be used to map the within-field spatial variability and crop yield (R2~0.42-0.54 between NIR reflectance and/or spectral VIs and rice grain yield) and can successfully complement more traditional technologies for precision farming applications.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326869","UAV;Rice monitoring;Italy","Reflectivity;Agriculture;Monitoring;Radiometry;Vegetation mapping;Remote sensing;Correlation","agricultural engineering;autonomous aerial vehicles;crops;image resolution;infrared imaging;production engineering computing;remote sensing;telerobotics;vegetation","rice yield estimation;multispectral data;Northern Italy;UAV platforms;agricultural monitoring;spatial resolution;crop field monitoring;Lombardy region;northern Italy;vegetation indices;spectral channels;multispectral sensor;UAV images;within-field spatial variability;NIR reflectance;spectral VI;rice grain yield","","19","","11","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Sen2like, A Tool To Generate Sentinel-2 Harmonised Surface Reflectance Products - First Results with Landsat-8","S. Saunier; J. Louis; V. Debaecker; T. Beaton; E. G. Cadau; V. Boccia; F. Gascon","Telespazio VEGA UK Ltd, Luton Bedfordshire, United Kingdom; Telespazio France, Toulouse Cedex 1, France; Telespazio France, Toulouse Cedex 1, France; Telespazio VEGA UK Ltd, Luton Bedfordshire, United Kingdom; Serco SpA, Italy; European Space Agency, ESRIN, Italy; European Space Agency, ESRIN, Italy","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","5650","5653","Sen2Like is a processor designed to produce harmonized Level 2 surface reflectance dataset considering as reference Sentinel-2 data. Sen2Like fits with the on-going and growing expectations of the Earth Observation (EO) Community for the merging of an increasing number of input data streams from the various Multi-Spectral (MS) High Resolution (HR) EO mission instruments. The harmonization is an essential processing stage in order to fully exploit all the potential of physical data in the context of land use /land change classification/detection. However, because harmonization addresses several issues in the field of atmospheric/geometric/directional effects/spectral difference corrections, there is not a standard way to achieve this objective. To initiate this project, the Landsat 8 (LS8) mission has been considered as the most appropriate. The Sen2Like processor is now delivering S2/LS8 Analysis Ready Data (ARD) on S2 tiling system at a map resolution of 30 m and 10 m. After a description of the algorithms involved in Sen2Like, this paper discusses testing and validation results.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899213","Analysis Ready Data;Sentinel-2;Landsat- 8;Sen2Like;processing;harmonization","Earth;Artificial satellites;Remote sensing;Reflectivity;Atmospheric modeling;Spatial resolution;Monitoring","geophysical image processing;geophysical signal processing;remote sensing","Sentinel-2 harmonised surface reflectance products;harmonized Level 2 surface reflectance;reference Sentinel-2 data;MultiSpectral High Resolution EO mission instruments;Landsat 8 mission;S2 tiling system","","6","","21","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Pan-Sharpening Via RoG-Based Filtering","Z. -Y. Zhang; T. -Z. Huang; L. -J. Deng; J. Huang; H. -X. Dou","School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2790","2793","In this paper, a pan-sharpening approach based on RoG filtering is proposed. This approach follows the framework of classic methods of pan-sharpening, i.e., component substitution and multi-resolution analysis. The filtering technique based on Relativity-of-Gaussian (RoG) regularization is first used in the process of upsampling the original multi-spectral image, and then in the detail extraction phase to obtain spatial details from the panchromatic image. Experiments on datasets acquired by Quickbird and IKONOS demonstrate that the proposed approach obtains competitive performance comparing with several popular pan-sharpening methods.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899330","Pan-sharpening;RoG;classical methods","Principal component analysis;Remote sensing;Spatial resolution;Visualization;Kernel;Image edge detection","Gaussian processes;geophysical image processing;geophysical signal processing;image filtering;image resolution;remote sensing","pan-sharpening methods;RoG filtering;component substitution;multiresolution analysis;filtering technique;Relativity-of-Gaussian regularization;multispectral image;RoG regularization;Quickbird;IKONOS","","4","","20","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Evaluating Sentinel-2A atmospherically corrected reflectance using the 6SV model","Y. Li; Q. Ma","School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, Jiangsu, China; School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, Jiangsu, China","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","2078","2081","In this study, the Bottom-Of-Atmosphere (BOA) reflectance over Egbert, Ontario, Canada on September 24, 2016, as obtained by the Sentinel-2A Multi-Spectral Imager and corrected by the Sentinel-2 atmospheric Correction (Sen2Cor) software, was evaluated based on the 6SV atmospherically corrected reflectance. The aerosol and water vapor parameters used in the 6SV model were obtained from the AERONET data. The evaluation results showed that for the visible bands, the Sen2Cor BOA reflectance was lower than the 6SV BOA reflectance, with a maximum relative bias of -36.5%, due to an overestimation of the aerosol optical depth retrieved by Sen2Cor. The bias of the BOA reflectance could also affect the vegetation index (VI) calculation. Four VIs were calculated and compared using the different BOA reflectance. The maximum relative bias was 18.2%. The study shows that the BOA reflectance corrected by Sen2Cor should be treated with some degree of caution, especially for the visible bands and VIs.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127391","AERONET;Atmospheric Correction;Sentinel-2A;6SV Model","Reflectivity;Atmospheric modeling;Vegetation mapping;Aerosols;Indexes;Remote sensing;Data models","aerosols;atmospheric optics;atmospheric techniques;geophysical image processing;radiative transfer;remote sensing;vegetation","Bottom-Of-Atmosphere reflectance;Sentinel-2A MultiSpectral Imager;Sentinel-2 atmospheric Correction software;aerosol;water vapor parameters;Sen2Cor BOA reflectance;Sentinel-2A atmospherically corrected reflectance;AD 2016 09 24;6SV model;Egbert;Ontario;Canada;AERONET data;6SV BOA reflectance;aerosol optical depth;vegetation index calculation","","2","","8","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Preliminary Altimetry Results of the Malygnss Instrument in the Humit Project","R. Onrubia; D. Pascual; J. Querol; J. Castellvi-Esturi; J. Corbera; H. Park; A. Camps","Department of Signal Theory and Communications, Universitat Politècnica de Catalunya and IEEC/UPC, Barcelona, Spain; Department of Signal Theory and Communications, Universitat Politècnica de Catalunya and IEEC/UPC, Barcelona, Spain; Department of Signal Theory and Communications, Universitat Politècnica de Catalunya and IEEC/UPC, Barcelona, Spain; Institut Cartogràfic i Geològic de Catalunya, Barcelona, Spain; Institut Cartogràfic i Geològic de Catalunya, Barcelona, Spain; Department of Signal Theory and Communications, Universitat Politècnica de Catalunya and IEEC/UPC, Barcelona, Spain; Department of Signal Theory and Communications, Universitat Politècnica de Catalunya and IEEC/UPC, Barcelona, Spain","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","3331","3334","In order to provide high resolution soil moisture maps, the Institut Cartografic i Geológic de Catalunya (ICGC) in colab-oration with Universitat Politecnica de Catalunya are planing to deploy the 3Cat-3 picosatellite, which aims to estimate soil moisture from space using Global Navigation Satellite Systems - Reflectometry (GNSS-R) and to downscale it using data fusion with a multi-spectral camera. As a proof of concept, a field campaign is being carried out in Lleida, Catalunya. MALYGNSS is a GNSS reflectometer flying as an opportunity sensor that will validate the main reflectometer of the project: the CORTO instrument.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518636","GNSS;Reflectometry;HUMIT;MA-LYGNSS;topography;soil;moisture","Instruments;Global navigation satellite system;Soil moisture;Antennas;Delays;Remote sensing","artificial satellites;atmospheric humidity;digital elevation models;height measurement;hydrological techniques;moisture;photogrammetry;radar interferometry;reflectometry;remote sensing by radar;satellite navigation;sensor fusion;sky brightness;soil","field campaign;Catalunya;GNSS reflectometer;CORTO instrument;preliminary altimetry results;malygnss instrument;humit project;high resolution soil moisture maps;Institut Cartografic i Geológic;ICGC;colab-oration;Universitat Politecnica;3 Cat-3 picosatellite;Global Navigation Satellite Systems - Reflectometry;GNSS-R;data fusion;multispectral camera","","1","","13","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Coral Bleaching Detection Using Sentinel-2B/MSI Images","B. Liu; L. Guan","College of Information Science and Engineering, Ocean University of China, China; Laboratory for Regional Oceanography and Numerical Modeling, Qingdao National Laboratory for Marine Science and Technology, Qingdao, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3777","3780","In recent years, affected by global warming and human factors, global coral bleaching events have occurred frequently. According to the reports, severe coral bleaching events occurred in the northwestern of Hainan Island, South China Sea in 2020. In this paper, based on the normalized difference images of 10-meter spatial resolution Sentinel-2B/MSI (Multi Spectral Imager) visible bands, the coral bleaching area was detected. In the images of July and September, a large area of coral reef was found to be bleached. Compared with July, the area of bleaching in September increased, which was consistent with field survey.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554495","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554495","Coral bleaching;Sentinel-2B/MSI;change detection;difference composite image","Bleaching;Ecosystems;Geoscience and remote sensing;Human factors;Global warming;Spatial resolution","agriculture;data acquisition;geophysical techniques;global warming;ocean temperature;oceanographic regions;remote sensing;vegetation","South China Sea;normalized difference images;coral bleaching area;coral reef;global warming;human factors;global coral bleaching events;severe coral bleaching events;Hainan Island;memory size 2.0 Byte","","1","","11","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Atmospheric Correction Icor and Integration in Operational Workflows","A. Stefan; S. Sindy; L. De Keukelaere; R. Van De Kerchove; E. Knaeps","VITO NV, Mol, Belgium; VITO NV, Mol, Belgium; VITO NV, Mol, Belgium; VITO NV, Mol, Belgium; VITO NV, Mol, Belgium","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","3524","3526","iCOR is a scene and sensor generic atmospheric correction algorithm which can process images containing land and coastal, inland or transitional water pixels. The tool is adaptable with minimal efforts to hyper- or multi-spectral sensors. iCOR has been extensively validated for Landsat-8 OLI, Sentinel-2 MSI and Proba-V and is now being developed for Sentinel-3 OLCI. It has been developed in such a way that it can be easily integrated in an operational workflow. Three examples of the integration in an operational workflow are presented, the Highroc processor for coastal waters, the Belgian collaborative ground segment TERRASCOPE and the WATCHITGROW service for the potato industry.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518044","iCOR;atmospheric;correction;workflow;Sentinel-2;Landsat-8;Sentinel-3;Proba-V","Remote sensing;Sea measurements;Artificial satellites;Earth;Atmospheric modeling;Reflectivity;Collaboration","geophysical image processing;geophysics computing;oceanographic techniques;remote sensing","hyperspectral sensor;sensor generic atmospheric correction algorithm;Highroc processor;multispectral sensor;coastal waters;Sentinel-3;Landsat-8;operational workflow;atmospheric correction ICOR","","1","","3","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Leaf chlorophyll content estimation from sentinel-2 MSI data","Q. Ma; J. M. Chen; Y. Li; H. Croft; X. Luo; T. Zheng; S. Zamaria","School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, Jiangsu, China; Department of Geography and Planning, University of Toronto, Toronto, Ontario, Canada; School of Geography, Geomatics and Planning, Jiangsu Normal University, Xuzhou, Jiangsu, China; Department of Geography and Planning, University of Toronto, Toronto, Ontario, Canada; Department of Geography and Planning, University of Toronto, Toronto, Ontario, Canada; Department of Geography and Planning, University of Toronto, Toronto, Ontario, Canada; Department of Geography and Planning, University of Toronto, Toronto, Ontario, Canada","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","2915","2918","The Sentinel-2A (S2A) Multi-Spectral Imager (MSI) is a new remote sensor launched on 23 June 2015 that provides unprecedented Earth observation with high spatial, spectral and temporal resolutions. It has high potential for chlorophyll content estimation. Chlorophyll content plays a crucial role in plant photosynthesis affecting the terrestrial carbon cycle. In this research, a physical retrieval algorithm is proposed for leaf chlorophyll content from the S2A MSI data based on 4-Scale and PROSPECT models. Satellite and ground data were collected and processed in a mixed temperate forest near Borden, Ontario, Canada from May to October 2016. Preliminary validation shows an agreement between the inverted and ground measured leaf chlorophyll contents, with r = 0.77 and RMSE = 8.82 μg/cm2, which is an improvement over those generated by the Sentinel Application Platform (SNAP). Further research is ongoing, and the algorithm will be improved in the future.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127608","Chlorophyll;Sentinel-2;PROSPECT;4-Scale","Reflectivity;Biological system modeling;Atmospheric modeling;Remote sensing;Satellites;Vegetation mapping;Optical reflection","atmospheric techniques;forestry;photosynthesis;remote sensing;vegetation;vegetation mapping","leaf chlorophyll content estimation;sentinel-2 MSI data;remote sensor;unprecedented Earth observation;high spatial resolutions;plant photosynthesis;terrestrial carbon cycle;physical retrieval algorithm;mixed temperate forest;inverted ground measured leaf chlorophyll contents;Sentinel Application Platform;AD 2015 06 23","","1","","19","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"A Fully Automatic Method for on-Orbit Sharpness Assessment: a Case Study Using Prisma Hyperspectral Satellite Images","V. Pampanoni; L. Cenci; G. Laneve; C. Santella; V. Boccia","DIAEE, Sapienza University of Rome, Rome, Italy; Serco Italia SpA, Frascati, Italy; SIA, Sapienza University of Rome, Rome, Italy; SIA, Sapienza University of Rome, Rome, Italy; European Space Agency (ESA), Frascati, Italy","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","7226","7229","The recent surge in interest towards hyperspectral imagery has the potential to unlock a new range of applications for the scientific community. However, compared to traditional multi-spectral images, the workload required to process such high-dimensional data is dramatically increased, to the point that new and more flexible strategies must be developed in order to properly monitor the quality of this type of products. In the particular case of sharpness assessment, traditional procedures based on the edge method tend to be extremely time-consuming due to their reliance on visual analysis performed by human operators, and would make proper processing of all bands a daunting task to perform on a large scale. In this paper we propose a flexible and fully automatic approach to edge method-based sharpness assessment that can be applied inde-pendently from the number of spectral bands. We then present the results of the application of the methodology on the visible and near-infrared and shortwave infrared spectral cubes of a selection of PRISMA L2D images, which confirm the relia-bility of the methodology and suggest further improvements.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883186","satellite image quality;sharpness;hyper-spectral;PRISMA;edge method","Visualization;Satellites;Image edge detection;Geoscience and remote sensing;Task analysis;Surges;Monitoring","artificial satellites;data handling;edge detection;geophysical image processing;remote sensing","fully automatic method;prisma hyperspectral satellite images;recent surge;hyperspectral imagery;scientific community;traditional multispectral images;high dimensional data;flexible strategies;edge method;visual analysis;human operators;flexible approach;fully automatic approach;spectral bands;infrared spectral cubes;PRISMA L2D images;sharpness assessment","","1","","9","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Change detection of coral reef habitats from multi-temporal and multi-source satellite imagery in Bunaken, Indonesia","C. Iovan; E. Ampou; S. Andréfouët; S. Ouillon; P. Gaspar","Institut de Recherche pour le Développement (IRD), Nouméa, New-Caledonia; Institut de Recherche pour le Développement (IRD), Nouméa, New-Caledonia; Institut de Recherche pour le Développement (IRD), Nouméa, New-Caledonia; Institut de Recherche Pour le Développement (IRD), Cau Giay, Hanoi, Vietnam; Collecte Localisation Satellite (CLS), Ramonville, France","2015 8th International Workshop on the Analysis of Multitemporal Remote Sensing Images (Multi-Temp)","10 Sep 2015","2015","","","1","4","This paper presents a framework for change detection of coral reef habitats in muti-temporal and multi-spectral satellite imagery acquired by multiple sensors. Our specific goal is to analyze the evolution coral reef habitats from images acquired over a period of twelve years. Our study area is located in the centre of the Coral Triangle, a hotspot of biodiversity in the Bunaken Island, Indonesia. In-situ data is used in a supervised classification approach to build classification models for eleven habitat types. Radiometric calibration is pairwise performed between each image in the data set and the reference one, and habitat models built on the reference image are used to classify the entire time series. Results obtained are discussed and the influential factors are put forward.","","978-1-4673-7119-3","10.1109/Multi-Temp.2015.7245758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7245758","","Radiometry;Sensors;Time series analysis;Satellites;Satellite broadcasting;Image sensors;Remote sensing","geophysical image processing;image classification;remote sensing;time series","coral reef habitat change detection;multitemporal satellite imagery;multisource satellite imagery;Indonesia;multiple sensor;coral reef habitat evolution;Coral Triangle;Bunaken island;image classification model;radiometric calibration;time series","","","","11","IEEE","10 Sep 2015","","","IEEE","IEEE Conferences"
"Large Scale Forest Parameter Estimation Through a Deep Learning-Based Fusion of Sentinel-2 and Tandem-X Data","D. Carcereri; P. Rizzoli; D. Ienco; J. -L. Bueso-Bello; C. González; S. Puliti; L. Brurzone","Universitá degli studi di Trento (UNITN), Italy; German Aerospace Center (DLR), Microwaves and Radar Institute; National Research Institute for Agriculture, Food and the Environment (INRAE), France; German Aerospace Center (DLR), Microwaves and Radar Institute; German Aerospace Center (DLR), Microwaves and Radar Institute; Norwegian Institute of Bioeconomy Research (NIBIO), Norway; Universitá degli studi di Trento (UNITN), Italy","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","5773","5776","The estimation of forest parameters, such as canopy height model (CHM) and above ground biomass (AGB), is of ut-most importance for forest monitoring, carbon-cycle modelling, disturbance analysis, resource inventorying and natural disaster prevention. In this work, we profit from the most recent advancements in deep learning research to propose a convolutional neural network (CNN) architecture for frequent forest parameter estimation at large scale. Our technique consists of a fully convolutional, multi-modal framework, which works on a single set of complementary multi-spectral and interferometric SAR data, acquired by ESA's Sentinel-2 and DLR's TanDEM-X missions, respectively. The regression performance of our framework has been tested over four tropical forest test sites in Gabon, Africa. The estimation of CHM shows promising early results when compared to state-of-the-art methods and has the advantage of requiring only a single input image pair instead of a longer time-series, as commonly done for state-of-the-art model-based techniques.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884872","forest monitoring;forest height;deep learning;sensor fusion;Sentinel-2;TanDEM-X","Deep learning;Analytical models;Parameter estimation;Biological system modeling;Estimation;Geoscience and remote sensing;Forestry","forestry;learning (artificial intelligence);neural nets;radar interferometry;remote sensing by radar;synthetic aperture radar;vegetation;vegetation mapping","scale forest parameter estimation;deep learning-based fusion;tandem-X data;forest parameters;canopy height model;CHM;ground biomass;ut-most importance;forest monitoring;carbon-cycle modelling;disturbance analysis;resource inventorying;natural disaster prevention;deep learning research;convolutional neural network architecture;frequent forest parameter estimation;multimodal framework;complementary multispectral;ESA's Sentinel-2;DLR's TanDEM-X missions;tropical forest test sites;state-of-the-art model-based techniques","","","","18","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Retrieval of Aerosol Optical Depth in Beijing Area from Sentinel-2 Multispectral Instrument Data","F. Chen; Y. Li; Q. Ma; P. Cui; J. Qiao","Geomatics and Planning, School of Geography, Jiangsu Normal University, Tongshan District, Xuzhou Jiangsu, China; Geomatics and Planning, School of Geography, Jiangsu Normal University, Tongshan District, Xuzhou Jiangsu, China; Geomatics and Planning, School of Geography, Jiangsu Normal University, Tongshan District, Xuzhou Jiangsu, China; Geomatics and Planning, School of Geography, Jiangsu Normal University, Tongshan District, Xuzhou Jiangsu, China; Geomatics and Planning, School of Geography, Jiangsu Normal University, Tongshan District, Xuzhou Jiangsu, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","6702","6705","Aerosol is one of the important factors leading to atmospheric pollution, but there are still relatively few studies on the variation of AOD at high resolution, which brings some influence on the study of the variation of small-scale aerosol such as cities. Based on Sentinel-2 Multi-Spectral Instrument (MSI) data, aerosol inversion is carried out by using structure function method and 6SV model, and the AOD inversion results with 500m resolution in Beijing urban area are obtained. The results show that the pixel interval has an obvious impact on aerosol inversion. Using the structure function method and the distance value of 15, the AOD accuracy of B07 band is the best, but the accuracy of other bands is poor, so the more data need to be collected later to improve and verify the algorithm.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883138","Aerosol optical depth (AOD);Sentinel-2;Structure function method;6SV;Beijing","Pollution;Sensitivity analysis;Instruments;Urban areas;Geoscience and remote sensing;Aerosols;Data models","aerosols;air pollution;atmospheric optics;atmospheric techniques;geophysical image processing;remote sensing","structure function method;AOD inversion results;Beijing urban area;aerosol inversion;AOD accuracy;aerosol optical depth;Beijing area;Sentinel-2 multispectral Instrument data;atmospheric pollution;small-scale aerosol;Sentinel-2 MultiSpectral Instrument data;size 500.0 m","","","","9","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Capturing Corn and Soybean Yield Variability at Field Scale Using Very High Spatial Resolution Satellite Data","S. Skakun; M. G. L. Brown; J. . -C. Roger; E. Vermote","NASA Goddard Space Flight Center Code 619, Greenbelt, MD, USA; Department of Geographical Sciences, University of Maryland, College Park, MD, USA; NASA Goddard Space Flight Center Code 619, Greenbelt, MD, USA; NASA Goddard Space Flight Center Code 619, Greenbelt, MD, USA","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","3723","3726","In this work, we focus on exploring very high spatial resolution (1-3 m) satellite imagery for capturing crop yield variability at field scale. In-field yields of soybean and corn were collected in Iowa, USA, and were correlated with multi-spectral satellite data acquired by WorldView-3 (at 1.25 m) and PlanetScope (Dove-Classic) (at 3 m). Results show that the most important spectral bands explaining corn and soybean yield variability are green/yellow, red edge and NIR. High temporal frequency of Planet data allowed identification of best suitable date for yield assessment: PlanetScope's spectral bands at 3 m explained 10% to 75% of in-field corn and soybean yield variability.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324033","National Aeronautics and Space Administration (NASA)(grant numbers:80NSSC18K0336); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324033","Yield;Planet;WorldView-3;corn;soybean","Spatial resolution;Agriculture;Satellites;Reflectivity;Remote sensing;Earth;NASA","crops;geophysical image processing;image resolution;remote sensing","WorldView-3;soybean yield variability;PlanetScope's spectral bands;in-field corn;crop yield variability;multispectral satellite data;very high spatial resolution satellite imagery;Iowa;USA","","","","9","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Contextural feature evaluation of multi-resolution imagery","Q. Yu; R. Engstrom; J. Graesser","Department of Geography, George Washington University; Department of Geography, George Washington University; Department of Geography, McGill University","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","6782","6785","Spatial information pertaining to the neighborhood mapping can only be available at the scales of centimeters to meters. In this study, we utilize spatial, structural and contextural features calculated at multiple spatial scales to assess feature-based urban mapping using two different high-spatial resolution sensors (SPOT versus Quickbird) and evaluate the difference in describing neighborhood at these scales. We compared the features that include PanTex, Histogram of Oriented Gradients, Line Support Regions, Hough transformations and others on two selected images that were orthorectified and coregistered. We ran a classification based on the stacks of features for each of the two panchromatic high-spatial resolution images. Our results showed that without using vegetation index as an input, SPOT and Quickbird accomplished comparable classification results, while adding NDVI in Quickbird classification, SPOT image alone does not accomplish comparable classification accuracy using Quickbird image mainly due to lack of vegetation information represented by Normalized Difference Vegetation Index (NDVI), which correlates substantial difference among neighborhoods. The future work can incorporate other multi-spectral information into classification while using SPOT imagery.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730770","spatial features;SPOT;Quickbird;neighborhood;urban mapping","Feature extraction;Spatial resolution;Vegetation mapping;Remote sensing;Urban areas;Indexes","geophysical image processing;image classification;image registration;remote sensing","contextural feature evaluation;multiresolution imagery;spatial information;neighborhood mapping;multiple spatial scales;feature-based urban mapping;high-spatial resolution sensors;PanTex;Oriented Gradient Histogram;Line Support Regions;Hough transformations;panchromatic high-spatial resolution images;vegetation index;Quickbird classification;SPOT image;Quickbird image;Normalized Difference Vegetation Index;NDVI","","","","12","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Burn Severity Estimation in Northern Australia Tropical Savannas Using Radiative Transfer Model and Sentinel-2 Data","C. Yin; B. He; M. Yebra; X. Quan; A. C. Edwards; X. Liu; Z. Liao; K. Luo","School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; Fenner School of Environment and Society, Australian National University, Canberra, Australia; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; Bushfire & Natural Hazards Cooperative Research Centre, Melbourne, VIC, Australia; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","6712","6715","In this study, the burn severity of several wildfires ignited at northern Australian tropical savannas area were estimated using the Forest Reflectance and Transmittance (FRT) radiative transfer model (RTM) and Sentinel-2A Multi-Spectral Instrument (MSI) satellite data. To alleviate the spectral confusion between severe (SV) and not-severe (NSV) burnt levels caused by sparse tree distribution, the MODIS Vegetation Continuous Fields (VCF) tree cover percentage data was used to constrain the inversion. The results showed that the accuracy of burn severity estimation significantly improves when considering the tree coverage, with overall accuracy for two study sites increasing from 65% to 81% and kappa coefficient from 0.35 to 0.55. Future work will focus on extending the methodology to other ecosystems.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899857","Burn severity;tree cover;Radiative transfer model;Sentinel-2A","Vegetation;Remote sensing;Reflectivity;Estimation;Australia;Forestry;Vegetation mapping","radiative transfer;remote sensing;vegetation;vegetation mapping;wildfires","burn severity estimation;northern australia tropical savannas;radiative transfer model;northern Australian tropical savannas area;MultiSpectral Instrument satellite data;spectral confusion;not-severe burnt levels;sparse tree distribution;MODIS Vegetation Continuous Fields tree cover percentage data;wildfires;Sentinel-2A;kappa coefficient;ecosystems","","","","8","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"A new variational method for pan-sharpening","P. Liu; L. Xiao; S. Tang","School of Computer Science and Engineering, Nanjing University of Science and Technology, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, China","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","597","600","In this paper, we present a new variational method for pan-sharpening, which aims to obtain a high resolution multi-spectral (MS) image from a low resolution MS image and a high resolution panchromatic (PAN) image. Firstly, we assume that the desired high resolution MS image after down-sampling should be close to the low resolution MS image. More specifically, the intensity maps of PAN image and high resolution MS image bands are treated as three-dimensional (3D) differential surfaces. Then, we constrain that the surfaces of PAN image and high resolution MS image band should have the same bending directions at each point in 3D space. Based on these assumptions, a variational model is proposed and an efficient algorithm is designed to solve this variational model. Experimental results demonstrate that the proposed method outperforms various pan-sharpening methods in terms of both excellent spatial and spectral qualities.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7325834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325834","pan-sharpening;variational method;differential surface;bending direction","Spatial resolution;Three-dimensional displays;Principal component analysis;Distortion;Energy resolution;Remote sensing","hyperspectral imaging;image resolution;remote sensing","high resolution multispectral image;low resolution multispectral image;high resolution panchromatic image;PAN image intensity map;3D differential surface;PAN image surface;pan-sharpening method","","","","10","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Valuing Radiometric Quality of Remote Sensing Data for Decisions","A. Siddiqi; S. Baber; O. De Weck","Department of Aeronautics and Astronautics; Department of Earth and Planetary Sciences, Massachusetts Institute of Technology; Department of Aeronautics and Astronautics","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5724","5727","High resolution, high frequency, multi-spectral remotely-sensed Earth Observation (EO) data is increasingly available. Challenges of ensuring radiometric data quality and consistency of data products, however, have not been widely recognized. As new products and applications rapidly emerge, and decisions linked to public safety, well-being, and environmental assessments are at stake, the issue of EO data quality and quantification of errors and their impacts has gained increasing salience. This paper presents a generalizable decision-theoretic framework for quantifying the value of data quality (partly through improved calibration), and demonstrates its application for a water quality monitoring case. Results from the particular case of freshwater monitoring show that after 30% or more probability of occurrence of a harmful algal bloom, remote sensing is useful to have regardless of the data quality level. However, factors such as cost of remote sensing data (in this case, comparing internal processing vs. external processing of tasked satellite imagery) will affect the threshold at which remote sensing value is positive regardless of data quality level.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553916","earth observation;data quality;radiometric calibration;data value;decision analysis","Earth;Costs;Systematics;Sensitivity analysis;Data integrity;Water quality;Radiometry","","","","2","","16","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Weed Identification using K-Means Clustering with Color Spaces Features in Multi-Spectral Images Taken by UAV","R. Agarwal; S. Hariharan; M. Nagabhushana Rao; A. Agarwal","Department of Information Technology, UIET, CSJM University; University of Madras; Department of Information Technology, Vidya Jyothi Institute of Technology, Hyderabad; Department of Computer Science Engineering, IIIT Bhubaneshwar, Bhubaneshwar","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","7047","7050","Food security is a pertinent global challenge that has plagued the nations over time immemorial. Maize is one of the world's most significant consumption crop, based on production volume. Maize supply can vary according to the cultivation area, climatic condition, and disease. Modern precision weed management relies on site-specific management tactics to maximize resource use efficiency and yield, while reducing unintended environmental impacts caused by herbicides. Recent advancements in Unmanned Aircraft Systems (UAS)-based tools and geospatial information technology have created enormous applications for efficient and economical assessment of weed infestations as well as site-specific weed management. This paper explores the possibility of extracting features from color spaces and combining them with vegetation indices (NDVI, VARI, and TGI) to be clustered using K-means classifier to identify the weed population from a multispectral imagery. The results give a clear indication that the NDVI performance is better than VARI; It also shows that TGI is not acceptable for the classification.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554097","Weed;Color spaces;UAV;Maize;K-means Clustering;NDVI;VARI;TGI","Measurement;Image color analysis;Supervised learning;Sociology;Vegetation mapping;Production;Tools","","","","1","","9","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Serial Bus as Communication Between Microcontroller and AD9824 for Multi Spectral Camera","G. Hasan Zam Bahari; A. Hadi Syafrudin; Khairunnisa","Research Center for Satellite Technology, National Research and Innovation Agency, Bogor, Indonesia; Research Center for Satellite Technology, National Research and Innovation Agency, Bogor, Indonesia; Research Center for Satellite Technology, National Research and Innovation Agency, Bogor, Indonesia","2022 IEEE International Conference on Aerospace Electronics and Remote Sensing Technology (ICARES)","30 Dec 2022","2022","","","1","5","A multispectral camera for LAPAN-A4 microsatellite will be developed using charge-coupled device (CCD) to capture image and 16 ADCs to convert the CCD's analog yields into digital signals. To connect the ADCs and the camera, design of embedded system connection is needed with microcontroller as the main processor and serial bus as the communication protocol. This research aims to integrate 16 ADCs of AD9824 with ATMega128 microcontroller using serial bus communication. Tests are conducted by using collimator and by executing different ADCs with different gain values, resulting in several images with distinctive characteristics. From the test data, the microcontroller can execute commands and make telemetry requests to ADCs. In addition, it can be seen that the maximum value of digital number of each image is different, ranging from 7934 to 9212, when each ADC is separately activated with maximum gain input value of 36 dB and the digital number reaches maximum value of 3581 when all ADCs are deactivated.","","978-1-6654-6191-7","10.1109/ICARES56907.2022.9993468","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9993468","Satellite Technology;Serial Communication;Embedded System;ADC","Collimators;Protocols;Embedded systems;Microcontrollers;Small satellites;Cameras;Distance measurement","analogue-digital conversion;cameras;CCD image sensors;charge-coupled devices;embedded systems;microcontrollers;telemetry","16 ADCs;AD9824;ADC;ATMega128 microcontroller;CCD's analog yields;charge-coupled device;communication protocol;different ADCs;different gain values;digital number;embedded system connection;LAPAN-A4 microsatellite;multispectral camera;noise figure 36.0 dB;serial bus communication","","","","14","IEEE","30 Dec 2022","","","IEEE","IEEE Conferences"
"A Conditional Generative Adversarial Network to Fuse Sar And Multispectral Optical Data For Cloud Removal From Sentinel-2 Images","C. Grohnfeldt; M. Schmitt; X. Zhu","Signal Processing in Earth Observation, Technical University of Munich (TUM), Munich, Germany; Signal Processing in Earth Observation, Technical University of Munich (TUM), Munich, Germany; Signal Processing in Earth Observation, Technical University of Munich (TUM), Munich, Germany","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","1726","1729","In this paper, we present the first conditional generative adversarial network (cGAN) architecture that is specifically designed to fuse synthetic aperture radar (SAR) and optical multi-spectral (MS) image data to generate cloud- and haze-free MS optical data from a cloud-corrupted MS input and an auxiliary SAR image. Experiments on Sentinel-2 MS and Sentinel-l SAR data confirm that our extended SAR-Opt-cGAN model utilizes the auxiliary SAR information to better reconstruct MS images than an equivalent model which uses the same architecture but only single-sensor MS data as input.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8519215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519215","SAR;optical remote sensing;data fusion;deep learning;generative adversarial network (GAN);cloud-removal","Synthetic aperture radar;Optical sensors;Optical imaging;Clouds;Remote sensing;Adaptive optics;Generative adversarial networks","geophysical image processing;image fusion;radar imaging;synthetic aperture radar","cloud-free MS optical data;Sentinel-l SAR data;single-sensor MS data;reconstruct MS images;auxiliary SAR information;extended SAR-Opt-cGAN model;auxiliary SAR image;cloud-corrupted MS input;haze-free MS optical data;multispectral image data;synthetic aperture radar;conditional generative adversarial network architecture;Sentinel-2;cloud removal;multispectral optical data","","51","3","12","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Region Growing based Automatic Localized Adaptive Thresholding Algorithm for Water Extraction using Sentinel-2 MSI Imagery","B. K. R. Kadapala; K. Abdul Hakeem","National Remote Sensing Centre, Indian Space Research Organisation, Hyderabad, Telangana, India; National Remote Sensing Centre, Indian Space Research Organisation, Hyderabad, Telangana, India","IEEE Transactions on Geoscience and Remote Sensing","","2023","PP","99","1","1","Water is a distinct land cover feature on the earth. Water can easily be extracted from satellite data under known/controlled conditions using simple thresholding techniques. However, these pixel thresholding techniques fail when applied over large regions because they cannot adapt the thresholds based on local variability. Although region-growing methods are available to overcome this issue, there is a limitation in using a global threshold value determined for a satellite scene. Such thresholds fail to adapt to the variations within the scene. Hence, this study proposed a new region-growing-based approach for improved classification of water features using Sentinel-2 Multi-Spectral Instrument (MSI) data. The significant difference between this approach and other region-growing methods is that this technique uses dynamic thresholding for localized adaption. The local image statistics of the Normalized Different Water Index (NDWI) layer are used for adding new pixels to the region, and the threshold is adjusted for every new pixel added. This technique also minimizes manual intervention in water classification, thus enabling total process automation in near-real-time. The thresholds are dynamically determined not only for each scene but also for each new pixel being classified for the accurate delineation of the water pixels. A rigorous quality evaluation was done on the resultant water layer. This technique achieved an overall accuracy of 84.04% in challenging conditions.","1558-0644","","10.1109/TGRS.2023.3246540","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10049083","Adaptive thresholding;region growing;normalized difference water index (NDWI);water monitoring;water spread area","Water resources;Water;Feature extraction;Indexes;Seeds (agriculture);Reflectivity;Remote sensing","","","","","","","IEEE","20 Feb 2023","","","IEEE","IEEE Early Access Articles"
"CNN-based multi-band fused boundary detection for remotely sensed images","E. Basaeed; H. Bhaskar; M. Al-Mualla","Khalifa University of Science and Technology, Abu Dhabi, Abu Dhabi, AE; Khalifa University of Science and Technology, Abu Dhabi, Abu Dhabi, AE; Khalifa University of Science and Technology, Abu Dhabi, Abu Dhabi, AE","6th International Conference on Imaging for Crime Prevention and Detection (ICDP-15)","12 Nov 2015","2015","","","1","6","This paper introduces a boundary detection technique for remotely sensed images using a CNN-based multi-band fusion architecture. Conventional edge detection techniques fail to cope with the improvements in spatial, spectral, and radiometric resolutions of remote sensing images. While current approaches have handled each complexity in a mutually exclusive manner through specific adaptation of boundary detection parameters, there have been limited techniques that are feature-independent and parameter-free. The proposed approach attempts to integrate complementary and redundant information from the various multi-spectral bands of remotely sensed images to provide a composite image which could enhance perception and reinforce common interpretation while facilitating self-learning and customization capabilities for detection and fusion respectively. First, the technique associates a confidence map on the location of region boundaries with each multi-spectral band individually using a Convolutional Neural Network (CNN). Further, a weighted decision-based fusion framework is applied to integrate the contributions of individual confidence maps into one unified boundary detected output. Systematic experiments are conducted on publicly available datasets in order to evaluate the performance of the method and benchmark it against competing baselines.","","978-1-78561-131-5","10.1049/ic.2015.0109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7317997","","","edge detection;geophysical image processing;neural nets;remote sensing","CNN-based multi-band fused boundary detection technique;remotely sensed images;conventional edge detection techniques;remote sensing images;multi-spectral bands;composite image;self-learning;convolutional neural network;weighted decision-based fusion framework","","","","","","12 Nov 2015","","","IET","IET Conferences"
"RFI Mitigation in Aperture Synthesis Radiometers Using a Modified CLEAN Algorithm","F. Hu; X. Peng; F. He; L. Wu; J. Li; Y. Cheng; D. Zhu","National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Electronic Information and Communications, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Electronic Information and Communications, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","19 May 2017","2017","14","1","13","17","For aperture synthesis radiometers, sparse samplings on the $u$ -$v$ frequency plane cause undesirable sidelobes in the synthesized beam. Through these sidelobes, artificial sources emitting in the protected 1400-1427 MHz band contaminate the retrievals of the soil moisture and ocean salinity (SMOS) from MIRAS measurements. One effective way to correct the artificial interferences is to create a synthetic signal to compensate for the interference's impact. Based on the similar idea, in this letter, we describe an algorithm to compensate for the interference's impact by constructing an artificial signal as close as possible to the Gaussian beam. Numerical studies using synthetic and real SMOS data have been carried out to demonstrate that the proposed algorithm outperforms the classical CLEAN algorithm in correcting the impact of the extended radio frequency interference source.","1558-0571","","10.1109/LGRS.2016.2622760","Fundamental Research Funds for the Central Universities(grant numbers:HUST 2015QN093); Special Program for applied Research on Super Computation of the National Natural Science Foundation of China (NSFC)-Guangdong Joint Fund (the second phase); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7748545","Aperture synthesis radiometers (ASR);modified CLEAN algorithm;radio frequency interference (RFI) mitigation","Extraterrestrial measurements;Radiometers;Apertures;Pollution measurement;Sea measurements;Earth","Gaussian distribution;oceanographic techniques;particle beam dynamics;radiofrequency interference;radiometers;salinity (geophysical);sampling methods","RFI mitigation;aperture synthesis radiometer;modified CLEAN algorithm;sparse sampling;u-v frequency plane;sidelobe;MIRAS measurement;Gaussian beam;extended radiofrequency interference source;ocean salinity;artificial interference","","8","","20","IEEE","18 Nov 2016","","","IEEE","IEEE Journals"
"Discriminative archetypal self-taught learning for multispectral landcover classification","R. Roscher; S. Wenzel; B. Waske","Photogrammetry Lab, University of Bonn, Bonn, Germany; Photogrammetry Lab, University of Bonn, Bonn, Germany; Division of Remote Sensing and Geoinformatics, Freie Universität Berlin, Berlin, Germany","2016 9th IAPR Workshop on Pattern Recogniton in Remote Sensing (PRRS)","2 Mar 2017","2016","","","1","5","Self-taught learning (STL) has become a promising paradigm to exploit unlabeled data for classification. The most commonly used approach to self-taught learning is sparse representation, in which it is assumed that each sample can be represented by a weighted linear combination of elements of a unlabeled dictionary. This paper proposes discriminative archetypal self-taught learning for the application of landcover classification, in which unlabeled discriminative archetypal samples are selected to build a powerful dictionary. Our main contribution is to present an approach which utilizes reversible jump Markov chain Monte Carlo method to jointly determine the best set of archetypes and the number of elements to build the dictionary. Experiments are conducted using synthetic data, a multi-spectral Landsat 7 image of a study area in the Ukraine and the Zurich benchmark data set comprising 20 multispectral Quickbird images. Our results confirm that the proposed approach can learn discriminative features for classification and show better classification results compared to self-taught learning with the original feature representation and compared to randomly initialized archetypal dictionaries.","","978-1-5090-5041-3","10.1109/PRRS.2016.7867022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7867022","","Dictionaries;Training;Remote sensing;Distributed databases;Feature extraction;Optimization;Markov processes","geophysical image processing;image classification;image representation;land cover;Markov processes;Monte Carlo methods;terrain mapping;unsupervised learning","discriminative archetypal self-taught learning;multispectral landcover classification;unlabeled data;sparse representation;weighted linear combination;unlabeled dictionary;unlabeled discriminative archetypal samples;reversible jump Markov chain Monte Carlo;multispectral Landsat 7 image;Ukraine;Zurich benchmark data set;multispectral Quickbird images;discriminative features;feature representation","","1","","20","IEEE","2 Mar 2017","","","IEEE","IEEE Conferences"
"Status of the Earthcare Mission Optical Payloads: A Year From Launch","K. Ghose; G. Tzeremes; K. Wallace; D. Bernaerts","ESTEC, European Space Agency, AG Noordwijk, The Netherlands; ESTEC, European Space Agency, AG Noordwijk, The Netherlands; ESTEC, European Space Agency, AG Noordwijk, The Netherlands; ESTEC, European Space Agency, AG Noordwijk, The Netherlands","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","7190","7193","EarthCARE is the sixth Earth Explorer mission of the European Space Agency's (ESA) Living Planet Programme. It is being developed in collaboration with the Japan Aerospace Exploration Agency (JAXA). It has the fundamental objective of improving understanding of the processes involving clouds, aerosols and radiation in the Earth's atmosphere. The payload of EarthCARE consists of two active and two passive instruments. ESA is developing three of the instruments, an ATmospheric LIDar (ATLID), a Multi-Spectral Imager (MSI) and a Broad-Band Radiometer (BBR). JAXA is developing the Cloud Profiling Radar (CPR). The four instruments will provide co-located data from a single platform, which may be processed individually and in a synergistic manner, to provide a range of products, such as the vertical structure of aerosols and clouds, the corresponding broad-band and narrow-band radiances at the top of the atmosphere, and complementary information for scene identification. ATLID is a backscatter LIDAR, operating at a wavelength of 355 nm, that will record atmospheric echoes from an altitude of 40 km to ground. It incorporates a high resolution spectral filter, which enables the relative separation of aerosol and molecular backscatter. It also measures cross and co-polar components of the Mie backscatter on separate channels. The BBR instrument will make separate measurements of reflected solar radiation and radiated thermal emission from the scene. The MSI instrument will make measurements in seven bands ranging from the visible spectrum, near infrared, short wave infrared, down to thermal infrared, across a 150 km swath. This will aid in scene identification and provide some aerosol information. This paper will provide an overview of the design and function of the instruments and the current progress achieved in their integration and calibration.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884178","","Optical filters;Laser radar;Atmospheric measurements;Instruments;Clouds;European Space Agency;Aerosols","aerosols;atmospheric measuring apparatus;atmospheric optics;atmospheric radiation;atmospheric techniques;calibration;clouds;optical radar;radiometers;radiometry;remote sensing;remote sensing by laser beam;remote sensing by radar","ATLID;MultiSpectral Imager;JAXA;Cloud Profiling Radar;synergistic manner;aerosols;backscatter LIDAR;atmospheric echoes;Mie backscatter;BBR instrument;MSI instrument;Japan Aerospace Exploration Agency;Earthcare Mission Optical Payloads;EarthCARE;clouds;Earth atmosphere;passive instrument;active instrument","","","","4","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Learning Soft Estimator of Keypoint Scale and Orientation with Probabilistic Covariant Loss","P. Yan; Y. Tan; S. Xiong; Y. Tai; Y. Li","National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China; School of Remote Sensing and Information Engineering, Wuhan University, China","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","19384","19393","Estimating keypoint scale and orientation is crucial to extracting invariant features under significant geometric changes. Recently, the estimators based on self-supervised learning have been designed to adapt to complex imaging conditions. Such learning-based estimators generally predict a single scalar for the keypoint scale or orientation, called hard estimators. However, hard estimators are difficult to handle the local patches containing structures of different objects or multiple edges. In this paper, a Soft Self-Supervised Estimator (S3Esti) is proposed to overcome this problem by learning to predict multiple scales and orientations. S3Esti involves three core factors. First, the estimator is constructed to predict the discrete distributions of scales and orientations. The elements with high confidence will be kept as the final scales and orientations. Second, a probabilistic covariant loss is proposed to improve the consistency of the scale and orientation distributions under different transformations. Third, an optimization algorithm is designed to minimize the loss function, whose convergence is proved in theory. When combined with different keypoint extraction models, S3Esti generally improves over 50% accuracy in image matching tasks under significant viewpoint changes. In the 3D reconstruction task, S3Esti decreases more than 10% reprojection error and improves the number of registered images. [code release]","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9878787","Representation learning; Low-level vision; Self-& semi-& meta- & unsupervised learning","Point cloud compression;Three-dimensional displays;Image matching;Self-supervised learning;Probabilistic logic;Feature extraction;Prediction algorithms","feature extraction;image matching;image reconstruction;learning (artificial intelligence);object detection;object tracking","Soft Estimator;keypoint scale;probabilistic covariant loss;extracting invariant features;significant geometric changes;self-supervised learning;complex imaging conditions;learning-based estimators;called hard estimators;Soft Self-Supervised Estimator;S3Esti;final scales;different keypoint extraction models","","","","42","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Change Detection on Multi-Spectral Images Based on Feature-level U-Net","W. Wiratama; J. Lee; D. Sim","Department of Computer Engineering, Kwangwoon University, Seoul, South Korea; Department of Computer Engineering, Kwangwoon University, Seoul, South Korea; Department of Computer Engineering, Kwangwoon University, Seoul, South Korea","IEEE Access","22 Jan 2020","2020","8","","12279","12289","This paper proposes a change detection algorithm on multi-spectral images based on feature-level U-Net. A low-complexity pan-sharpening method is proposed to employ not only panchromatic images, but also multi-spectral images for enhancing the performance of the deep neural network. The high-resolution multi-spectral (HRMS) images are then fed into the proposed feature-level U-Net. The proposed feature-level U-Net consists of two-stages: a feature-level subtracting network and U-Net. The feature-level subtracting network is used to extract dynamic difference images (DI) for the use of low-level and high-level features. By employing this network, the performance of change detection algorithms can be improved with a smaller number of layers for U-Net with a low computational complexity. Furthermore, the proposed algorithm detects small changes by taking benefits of both geometrical and spectral resolution enhancement and adopting an intensity-hue-saturation (IHS) pan-sharpening method. A modified of IHS pan-sharpening algorithm is introduced to solve spectral distortion problem by applying mean filtering in high frequency. We found that the proposed change detection on HRMS images gives a better performance compared to existing change detection algorithms by achieving an average F-1 score of 0.62, a percentage correct classification (PCC) of 98.78%, and a kappa of 61.60 for test datasets.","2169-3536","","10.1109/ACCESS.2020.2964798","MSIT (Ministry of Science and ICT), South Korea, through the ITRC (Information Technology Research Center) support program(grant numbers:IITP-2019-2016-0-00288); Institute for Information and communications Technology Promotion; National Research Foundation of Korea; Ministry of Science, ICT and Future Planning(grant numbers:NRF-2018R1A2B2008238); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952681","Convolutional neural network;deep learning;remote sensing;satellite images;change detection","Feature extraction;Image segmentation;Spatial resolution;Change detection algorithms;Distortion;Detection algorithms","feature extraction;geophysical image processing;image colour analysis;image fusion;image resolution;neural nets;remote sensing","dynamic difference images;high-level features;change detection algorithm;geometrical resolution enhancement;spectral resolution enhancement;intensity-hue-saturation pan-sharpening method;IHS pan-sharpening algorithm;spectral distortion problem;HRMS images;existing change detection algorithms;low-complexity pan-sharpening method;panchromatic images;high-resolution multispectral images;U-Net;feature-level subtracting network","","9","","41","CCBY","8 Jan 2020","","","IEEE","IEEE Journals"
"Spectral Rule-Based Expert System for Automatic Near Real-Time Thermal Anomalies Detection in Geostationary GOES-16 ABI Imagery","L. F. R. de Carvalho; G. Laneve; A. Baraldi; G. Santilli",Luiss Guido Carli University; Sapienza University of Rome; Italian Space Agency; University of Brasilia,"2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","8408","8411","Typical advantages and limitations of prior knowledge-based (deductive, top-down) expert systems are well known in literature: they typically score “high” in efficiency and interpretability, but they tend to score “low” in transferability/robustness to changes in input data. To benefit from these advantages while overcoming their typical shortcomings, an original expert system, based on a priori purely spectral-domain knowledge, is proposed for per-pixel (spatial context-insensitive) automatic near real-time detection of thermal anomalies in geostationary GOES-16 ABI multi-spectral (MS) imagery. Unable to learn-from-data, the proposed static decision-tree for MS signature recognition (classification) requires neither training data nor human-machine interaction to run. Its degrees of novelty pertain to the Marr levels of system understanding known as information/knowledge representation, system design (architecture) and implementation. Input with day and night ABI imagery acquired every 15 minutes, the proposed expert system detected 680 pixels with thermal anomalies in ABI images of the North and South Americas acquired from 30/01/2018 (15:00 UTC) to 31/01/2018 (01:30 UTC).","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553625","Sapienza University of Rome; University of Brasilia; Italian Space Agency and Visiona Space Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553625","Remote Sensing;Thermal Anomalies Detection;Spectral Rule-Based System;GOES-16;Geostationary Satellite and Real Time System","South America;Satellites;Training data;Real-time systems;Expert systems;System analysis and design;Spectral analysis","decision trees;expert systems;geophysical image processing;image classification;knowledge based systems;knowledge representation;remote sensing","spectral rule-based expert system;automatic near real-time thermal anomalies detection;geostationary GOES-16 ABI imagery;original expert system;spectral-domain knowledge;spatial context-insensitive;real-time detection;geostationary GOES-16 ABI multispectral imagery;learn-from-data;static decision-tree;MS signature recognition;training data;ABI images","","","","14","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Learning Deep Features on Multiple Scales for Coffee Crop Recognition","R. Baeta; K. Nogueira; D. Menotti; J. A. dos Santos","Department of Computer Science, Universidade Federal de Minas Gerais, Brazil; Department of Computer Science, Universidade Federal de Minas Gerais, Brazil; Department of Informatics, Federal University of Paraná, Brazil; Department of Computer Science, Universidade Federal de Minas Gerais, Brazil","2017 30th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)","7 Nov 2017","2017","","","262","268","Geographic mapping of coffee crops by using remote sensing images and supervised classification has been a challenging research subject. Besides the intrinsic problems caused by the nature of multi-spectral information, coffee crops are non-seasonal and usually planted in mountains, which requires encoding and learning a huge diversity of patterns during the classifier training. In this paper, we propose a new approach for automatic mapping coffee crops by combining two recent trends on pattern recognition for remote sensing applications: deep learning and fusion/selection of features from multiple scales. The proposed approach is a pixel-wise strategy that consists in the training and combination of convolutional neural networks designed to receive as input different context windows around labeled pixels. Final maps are created by combining the output of those networks for a non-labeled set of pixels. Experimental results show that multiple scales produces better coffee crop maps than using single scales. Experiments also show the proposed approach is effective in comparison with baselines.","2377-5416","978-1-5386-2219-3","10.1109/SIBGRAPI.2017.41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8097321","Deep Learning;Remote Sensing;Coffee Crops;High-resolution Images;Agriculture","Agriculture;Remote sensing;Feature extraction;Image segmentation;Training;Semantics","crops;feature extraction;geophysical image processing;image classification;learning (artificial intelligence);neural nets;remote sensing","supervised classification;intrinsic problems;multispectral information;classifier training;automatic mapping coffee crops;pattern recognition;remote sensing applications;pixel-wise strategy;final maps;coffee crop maps;coffee crop recognition;geographic mapping;remote sensing images;deep features learning","","7","","33","IEEE","7 Nov 2017","","","IEEE","IEEE Conferences"
"Lake Urmia Water Salinity Mapping using Sentinel-2 Multi-Spectral Imagery","S. Lotfi; S. Ranjbar; M. Amani; A. Zarei","College of Engineering, University of Tehran, Tehran, Iran; Biological Systems Engineering, University of Wisconsin-Madison, Madison, WI, USA; Wood Environment and Infrastructure Solutions, Ottawa, Ontario, Canada; College of Engineering, University of Tehran, Tehran, Iran","2022 10th International Conference on Agro-geoinformatics (Agro-Geoinformatics)","23 Aug 2022","2022","","","1","5","Water salinity is one of the most critical water properties which considerably affects the lives of marine flora and fauna. In this study, the water salinity of Lake Urmia was mapped using sentinel-2 Multispectral Images (MSI). A Support Vector Regression (SVR) was developed to predict the water salinity using sentinel-2 spectral bands and indices. Three main scenarios were considered when input features were used in the SVR model. In scenario 1, the SVR was fed by all the features generated from Sentinel-2 data, and in the other two scenarios, a Genetic Algorithm (GA) and a Sequential Feature Selection (SFS) were applied to select the optimum input features to be used in the SVR model. The results showed that the salinity of Lake Urmia was estimated with a relatively reliable accuracy using GA along with the SVR model, where the R2 of 65.7% and the Root Mean Square Error (RMSE) of 11.5 PSU were obtained when the results were compared with in-situ data. Overall, this study showed that Sentinel-2 provides valuable high spatial-temporal datasets for continuous monitoring of water salinity over Lake Urmia.","","978-1-6654-7078-0","10.1109/Agro-Geoinformatics55649.2022.9859146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859146","Water salinity;Lake Urmia;Sentinel-2 MSI;Support Vector Regression;Genetic algorithm","Water;Support vector machines;Satellites;Salinity (geophysical);Lakes;Data models;Reliability","genetic algorithms;geophysical image processing;hydrological techniques;lakes;mean square error methods;regression analysis;remote sensing;support vector machines","Sentinel-2 multispectral imagery;critical water properties;sentinel-2 Multispectral Images;sentinel-2 spectral bands;SVR model;Sentinel-2 data;Sequential Feature Selection;optimum input features;Lake Urmia water salinity mapping","","","","30","IEEE","23 Aug 2022","","","IEEE","IEEE Conferences"
"Multi-view Learning for Impervious Surface Mapping using High-resolution Multi-spectral Imagery and LiDAR Data","H. Luo; F. Yang; X. Feng; Y. Dong; Y. Zhang; G. Min; J. Li","School of Computer Science, China University of Geosciences, Wuhan, China; State Grid Guyuan Power Supply Compamy, China; School of Computer Science, China University of Geosciences, Wuhan, China; Institute of Geophysics and Geomatics, China University of Geosciences, Wuhan, China; Institute of Geophysics and Geomatics, China University of Geosciences, Wuhan, China; Department of Computer Science, University of Exeter, Exeter, U.K.; School of Information Technology, Deakin University, Geelong, Australia","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2022","PP","99","1","21","The use of multi-source remote sensing data to obtain urban impervious surface has become a popular research topic. Multi-source remote sensing data fusion techniques can provide object interpretation with a higher accuracy. However, most decision-level fusion methods make insufficient use of the complementary information and degree of association between similar object data. To fill this gap, in this paper, we propose a dual-view learning fusion classification method (DvLF) based on multi-view learning. First, DvLF uses co-training algorithm to combine multiple data sources for accurate classification, extracting easy-to-classify area while separating difficult-to-classify regions for further analysis. Secondly, a canonical correlation analysis method is adopted to mine the degree of association of similar object data for constructing a subspace projection field of each object sample. The data in the difficult-to-classify regions are classified in the projection field of each object, and then the results of each classification are fused by voting. Finally, the classification results of the two regions are combined into the classification results of the whole image to achieve impervious surface mapping. The proposed method is applied to the dual-sensor (high-resolution image and LiDAR) Buffalo dataset and the dual-sensor (RGB and multispectral LiDAR) Houston dataset. The experimental results show that our method achieved a significant improvement in classification accuracy compared to other methods. The overall classification accuracy of this new DvLF fusion method on the Buffalo and Houston datasets is 83.35% and 88.84%, respectively leading to accurate high-resolution impervious surface mapping.","2151-1535","","10.1109/JSTARS.2022.3221625","National Natural Science Foundation of China(grant numbers:41801285,62171417); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9966508","Impervious surface;data fusion;Multi-view learning","Remote sensing;Feature extraction;Laser radar;Classification algorithms;Data mining;Optical imaging;Correlation","","","","","","","CCBYNCND","29 Nov 2022","","","IEEE","IEEE Early Access Articles"
"Evaluation of Fuzzy Integral Data Fusion Methods for Rare Object Detection in High-Resolution Satellite Imagery","A. B. Cannaday; C. H. Davis; A. J. Maltenfort","Center for Geospatial Intelligence, University of Missouri, Columbia, MO; Center for Geospatial Intelligence, University of Missouri, Columbia, MO; National Geospatial - Intelligence Agency, Springfield, VA, USA","2020 IEEE International Conference on Big Data (Big Data)","19 Mar 2021","2020","","","1","10","Here we demonstrate how the results from multiple Deep Neural Networks (DNN) can be fused to improve detections and reduce error when searching for scarce or rare objects in high-resolution satellite imagery. A wide variety of experiments were conducted using the xView dataset to develop and evaluate multiple fusion strategies to improve the detection of Engineering Vehicles (e.g. excavators, cranes, bulldozers, etc.). The results demonstrate that fusion of multiple DNNs can increase the absolute True Positive Rate (TPR) by up to 5% while reducing the total error by ~20-60%. The best results were obtained by partitioning 8-band multi-spectral imagery into three sets of 3-band images to utilize existing RGB models for transfer learning. The multi-DNN results were then fused using fuzzy integrals that also included DNN detections from multiple scales. This multi-DNN fusion approach can be easily extended to a variety of other challenging rare or scarce object detection problems in large remote sensing image datasets.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9377990","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377990","data fusion;remote sensing;object detection;deep learning;multi-spectral imagery;fuzzy measure","Satellites;Transfer learning;Object detection;Big Data;Search problems;Sensors;Remote sensing","feature extraction;fuzzy set theory;geophysical image processing;image colour analysis;image fusion;image sensors;learning (artificial intelligence);neural nets;object detection;remote sensing;sensor fusion","fuzzy integral data fusion methods;high-resolution satellite imagery;multiple Deep Neural Networks;scarce objects;rare objects;multiple fusion strategies;multiple DNNs;total error;8-band multispectral imagery;multiDNN results;fuzzy integrals;DNN detections;multiDNN fusion approach;challenging rare object detection problems;scarce object detection problems","","","","26","IEEE","19 Mar 2021","","","IEEE","IEEE Conferences"
"Use of Multi-Spectral High Repetition Rate LED Systems for High Bandwidth Underwater Optical Communications, and Communications to Surface and Aerial Systems","P. A. McGillivary; V. Chirayath; J. Baghdady","US Coast Guard PACAREA, Alameda, California, USA; Laboratory for Advanced Sensing NASA Ames Research Center, Moffett Field, California, USA; Applied Research Laboratory University of Hawai’i, Honolulu, Hawai’i, USA","2018 Fourth Underwater Communications and Networking Conference (UComms)","18 Oct 2018","2018","","","1","5","A variety of both existing and developing sensors would benefit from near real time communication of high bandwidth data. To cite just one example, sensors that could more accurately report real-time positions of marine mammals would be useful in reducing whale-ship collisions. Similar considerations are relevant for maritime port and harbor security, including detection and alerts for divers or autonomous underwater vehicles (AUVs) that could pose a risk to ships. Especially in ports and harbors, field experiments have confirmed that acoustic communication in these cluttered and noisy shallow water environments, compounded with vertical reflecting surfaces formed by piers and pilings, can limit the reliability and utility of underwater acoustic communications. Moreover, many sensors have greater bandwidth requirements than acoustic communications are able to provide. We here discuss the development of high repetition rate multispectral LED optical systems initially developed for imaging, but also capable of simultaneous data transmission at rates of ~100 kbps. Results are discussed for the multispectral images from coral reefs in Guam, and data transmission experiments from underwater to surface vessels. Subsequent field efforts will extend data transmission from AUVs to unmanned aircraft systems (UAS).","","978-1-5386-6442-1","10.1109/UComms.2018.8493228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493228","Optical communications;remote sensing;MiDAR;maritime security;AUV;UAS;ocean observing systems","Optical transmitters;Image color analysis;Optical fiber communication;Receivers;Bandwidth;Signal to noise ratio;Optical sensors","autonomous aerial vehicles;autonomous underwater vehicles;collision avoidance;light emitting diodes;marine engineering;marine safety;ships;underwater acoustic communication;underwater optics;underwater sound","multispectral high repetition rate;high bandwidth underwater optical communications;aerial systems;high bandwidth data;marine mammals;whale-ship collisions;maritime port;harbor security;autonomous underwater vehicles;ships;cluttered water environments;noisy shallow water environments;underwater acoustic communications;high repetition rate multispectral LED optical systems;simultaneous data transmission;unmanned aircraft systems;real time communication;AUV","","3","","25","IEEE","18 Oct 2018","","","IEEE","IEEE Conferences"
"Structured prediction for urban scene semantic segmentation with geographic context","M. Volpi; V. Ferrari","CALVIN, University of Edinburgh, Scotland (UK); CALVIN, University of Edinburgh, Scotland (UK)","2015 Joint Urban Remote Sensing Event (JURSE)","11 Jun 2015","2015","","","1","4","In this work we address the problem of semantic segmentation of urban remote sensing images into land cover maps. We propose to tackle this task by learning the geographic context of classes and use it to favor or discourage certain spatial configuration of label assignments. For this reason, we learn from training data two spatial priors enforcing different key aspects of the geographical space: local co-occurrence and relative location of land cover classes. We propose to embed these geographic context potentials into a pairwise conditional random field (CRF) which models them jointly with unary potentials from a random forest (RF) classifier. We train the RF on a large set of descriptors which allow to properly account for the class appearance variations induced by the high spatial resolution. We evaluate our approach by an exhaustive experimental comparisons on a set of 20 QuickBird pansharpened multi-spectral images.","2334-0932","978-1-4799-6652-3","10.1109/JURSE.2015.7120490","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120490","","Context;Accuracy;Semantics;Context modeling;Vegetation;Training;Image segmentation","geophysical image processing;geophysical techniques;image segmentation;land cover;remote sensing","structured prediction;urban scene semantic segmentation;geographic context;urban remote sensing images;land cover maps;land cover classes;pairwise conditional random field;random forest classifier;QuickBird pansharpened multispectral images","","9","","15","IEEE","11 Jun 2015","","","IEEE","IEEE Conferences"
"On-Board Characterization Of Hyperspectral Image Exposure And Cloud Coverage By Compression Ratio","R. Birkeland; S. Berg; M. Orlandic; J. L. Garrett","Department of Electronic Systems, O. S. Bragstad plass 2A, Norwegian University of Science and Technology, Trondheim, Norway; Department of Electronic Systems, O. S. Bragstad plass 2A, Norwegian University of Science and Technology, Trondheim, Norway; Department of Electronic Systems, O. S. Bragstad plass 2A, Norwegian University of Science and Technology, Trondheim, Norway; Department of Electronic Systems, O. S. Bragstad plass 2A, Norwegian University of Science and Technology, Trondheim, Norway","2022 12th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","22 Nov 2022","2022","","","1","5","Hyperspectral images are useful for remote sensing applications due to the fine spectral resolution relative to regular RGB- and multi-spectral images. The images can be used to study what is observed, rather than just that a given feature is observed. The high spectral resolution comes with a challenge for both small and big satellites: the data volume per observation. For a small earth observation satellite, the time and energy to downlink data is one of the main driving factors behind data latency and imaging capacity.Effective use of satellite time calls for a smart imaging pipeline, both when it comes to planning, execution, and processing of data from observations. The imaging and processing pipeline needs to utilize both on-board and on-ground processing tools and steps. In this paper, a set of the first observations from the HYPSO-1 satellite is analyzed to evaluate how quickly and effectively the compression ratio can be used to identify observations that should be prioritized for downlinking, and which data sets seem to be of less value due to over/under exposure or cloud coverage.","2158-6276","978-1-6654-7069-8","10.1109/WHISPERS56178.2022.9955117","Equinor; DNV GL; KT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955117","HYPSO-1;CubeSat;CCSDS-123;Operations","Measurement;Satellites;Image coding;Image resolution;Pipelines;Imaging;Signal processing","artificial satellites;geophysical image processing;geophysical signal processing;geophysical techniques;image colour analysis;image sensors;remote sensing","big satellites;board characterization;cloud coverage;compression ratio;data sets;data volume;downlink data;earth observation satellite;fine spectral resolution;given feature;high spectral resolution;hyperspectral image exposure;hyperspectral images;HYPSO-1 satellite;main driving factors;multispectral images;on-ground processing tools;processing pipeline;regular RGB;remote sensing applications;satellite time;smart imaging pipeline","","1","","10","IEEE","22 Nov 2022","","","IEEE","IEEE Conferences"
"Detection of Aerosols Above Clouds BASED on GCOM-C/SGLI Measurements","S. Mukai; T. Fujito; M. Nakata; I. Sano","The Kyoto College of Graduate Studies for Informatics, Kyoto, Japan; The Kyoto College of Graduate Studies for Informatics, Kyoto, Japan; Kindai University, Higashi-Osaka, Japan; Kindai University, Higashi-Osaka, Japan","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","5489","5492","The Japanese mission GCOM-C launched in 2017 loads only SGLI imager. SGLI is multi-spectral sensor including near-UV and two polarization channels. This work enhanced the advantages of SGLI feature in aerosol remote sensing. It was shown that the near-UV data not only detected absorbing aerosols such as biomass burning aerosols (BBA) or mineral dust (DUST), but was also used to distinguish between BBA and DUST with short-IR data. For leading issues such as aerosols above clouds, the detection of optically thick clouds was challenged in a similar manner to aerosol classification as well as utilization of polarization measurements. As a result, some scenes concerned with DUST or BBA above water clouds were practically detected.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324664","JAXA(grant numbers:JX-PSPC-434796,19h04242); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324664","polraization;near-UV;color ratio;BBA;DUST","Aerosols;Cloud computing;Clouds;Optical sensors;Optical polarization;Optical imaging;Biomedical optical imaging","aerosols;atmospheric optics;clouds;dust;remote sensing","polarization measurements;BBA;water clouds;clouds BASED;Japanese mission GCOM-C;SGLI imager;multispectral sensor;polarization channels;SGLI feature;aerosol remote sensing;near-UV data;mineral dust;short-IR data;aerosol classification;biomass burning aerosols","","","","16","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Estimating Forest Canopy Height With Multi-Spectral and Multi-Temporal Imagery Using Deep Learning","S. Oehmcke; T. Nyegaard-Signori; K. Grogan; F. Gieseke","Department of Computer Science, University of Copenhagen; DHI GRAS; DHI GRAS; Department of Information Systems, University of Münster","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","4915","4924","Canopy height is a vital indicator to asses carbon uptake and productivity of forests. However, precise measurements, such as from airborne or spaceborne 3D laser scanning (LiDAR), are expensive and usually cover only small areas. In this work, we propose a novel deep learning model that can generate detailed maps of tree canopy heights. In contrast to previous approaches that use a single image as input, we process multi-temporal data via a an adaptation of the popular U-Net architecture that is based on the EfficientNet and 3D convolution operators. To that end, our model receives multi-spectral Landsat satellite imagery as input and can predict continuous height maps. As labeled data, we resort to spatially sparse LiDAR data from ICESat-2. Thus, with such a model, one can produce dense canopy height maps given only multi-spectral Landsat data. Our experimental evaluation shows that our our model outperforms existing and improved single-temporal models. To test generalizability, we created a non-overlapping dataset to evaluate our approach and further tested the model performance on out-of-distribution data. The results show that our model can successfully learn drastic changes in distribution.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9672018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9672018","Neural Networks;Spatio-Temporal Data;Canopy Height Prediction;Landsat;ICESat-2","Earth;Deep learning;Adaptation models;Artificial satellites;Satellites;Atmospheric modeling;Forestry","deep learning (artificial intelligence);geophysical image processing;image classification;optical radar;remote sensing by laser beam;remote sensing by radar;vegetation;vegetation mapping","dense canopy height maps;multispectral Landsat data;single-temporal models;out-of-distribution data;forest canopy height;multitemporal imagery;carbon uptake;airborne D laser scanning;spaceborne 3D laser scanning;deep learning model;detailed maps;tree canopy heights;single image;process multitemporal data;U-Net architecture;3D convolution operators;multispectral Landsat satellite imagery;continuous height maps;spatially sparse LiDAR data","","","","32","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"S2A: Wasserstein GAN with Spatio-Spectral Laplacian Attention for Multi-Spectral Band Synthesis","L. Rout; I. Misra; S. M. Moorthi; D. Dhar","Signal and Image Processing Group, Indian Space Research Organisation; Signal and Image Processing Group, Indian Space Research Organisation; Signal and Image Processing Group, Indian Space Research Organisation; Signal and Image Processing Group, Indian Space Research Organisation","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","727","736","Intersection of adversarial learning and satellite image processing is an emerging field in remote sensing. In this study, we intend to address synthesis of high resolution multi-spectral satellite imagery using adversarial learning. Guided by the discovery of attention mechanism, we regulate the process of band synthesis through spatio-spectral Laplacian attention. Further, we use Wasserstein GAN with gradient penalty norm to improve training and stability of adversarial learning. In this regard, we introduce a new cost function for the discriminator based on spatial attention and domain adaptation loss. We critically analyze the qualitative and quantitative results compared with state-of-the-art methods using widely adopted evaluation metrics. Our experiments on datasets of three different sensors, namely LISS-3, LISS-4, and WorldView-2 show that attention learning performs favorably against state-of-the-art methods. Using the proposed method we provide an additional data product in consistent with existing high resolution bands. Furthermore, we synthesize over 4000 high resolution scenes covering various terrains to analyze scientific fidelity. At the end, we demonstrate plausible large scale real world applications of the synthesized band.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150919","","Spatial resolution;Signal resolution;Generators;Gallium nitride;Remote sensing;Laplace equations","geophysical image processing;image resolution;learning (artificial intelligence);remote sensing","attention mechanism;spatio-spectral Laplacian attention;Wasserstein GAN;adversarial learning;spatial attention;high resolution bands;high resolution scenes;multispectral band synthesis;satellite image processing;high resolution multispectral satellite imagery;LISS-3 dataset;LISS-4 dataset;WorldView-2 dataset","","1","","45","IEEE","28 Jul 2020","","","IEEE","IEEE Conferences"
"Simplified Reflectivity Model and Its Application in Millimeter-Wave Radiometry","Y. Hu; J. Su; F. Hu; H. Wu","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","7 Sep 2022","2022","15","","7203","7221","Millimeter-wave radiative sensing has been used in several close-range applications, such as security checks, military detection, terrain modeling, etc. Obtaining target information through radiometry is the goal of the above applications. However, there was no method to recover stable material information and complete geometric information through radiometry. The common problem of physically model-based information recovery is the solution to underdetermined equations. In this article, we analyze the multipolarization brightness temperature model and propose the equivalent permittivity (EP) to characterize the material information and simplify the reflectivity model. With the simplified reflectivity model, we solve the underdetermined problem in information inversion and realize the material classification and surface normal vector (SNV) reconstruction. Simulations and experiments are conducted to analyze the error and suitable range of the simplified reflectivity model and to verify the validity and accuracy of our methods of material classification and normal vector reconstruction. The results show that our classification method is suitable for most objects at an incident angle of 20°∼60°, and our SNV estimation method is effective at all incident angles. The possible applications include liquid composition analysis, target detection, road perception, and three-dimensional reconstruction.","2151-1535","","10.1109/JSTARS.2022.3201092","National Natural Science Foundation of China(grant numbers:61871438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9865167","Information acquisition;material classification;passive millimeter-wave (MMW);polarimetric measurement;three-dimensional reconstruction","Radiometry;Permittivity;Estimation;Polarization;Polarimetry;Analytical models;Three-dimensional displays","Bayes methods;image reconstruction;object detection;permittivity;radiometry;remote sensing","simplified reflectivity model;millimeter-wave radiometry;millimeter-wave radiative sensing;close-range applications;terrain modeling;target information;stable material information;complete geometric information;information recovery;multipolarization brightness temperature model;information inversion;material classification;surface normal vector reconstruction","","","","45","CCBY","23 Aug 2022","","","IEEE","IEEE Journals"
"Crop Classification using Multi-spectral and Multitemporal Satellite Imagery with Machine Learning","L. Viskovic; I. N. Kosovic; T. Mastelic","Ericsson Nikola Tesla, Split, Croatia; Ericsson Nikola Tesla, Split, Croatia; Ericsson Nikola Tesla, Split, Croatia","2019 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)","21 Nov 2019","2019","","","1","5","Satellite images are highly utilized for detecting land usage, while in recent years a finer-grade crop classification has become important in the context of precision agriculture. However, such classification brings new challenges, which aside from multi-spectral images require exploitation of their multi-temporal properties as well, with pixel-based analysis and larger number of classes. In this paper, we apply several machine learning algorithms on multi-spectral and multi-temporal satellite images and derive crop classification models. The models are applied only on agricultural fields, which can be singled out with the existing land usage classification models. Results show that the random forest outperforms other algorithms with accuracy score of 0.8420 and Kappa score of 0.8157. Detailed analysis of recall and precision scores is given for each crop separately, followed by a comprehensive discussion.","1847-358X","978-953-290-088-0","10.23919/SOFTCOM.2019.8903738","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903738","remote sensing;satellite images;land usage;crop classification;machine learning","","crops;geophysical image processing;image classification;land cover;learning (artificial intelligence);neural nets;remote sensing","machine learning algorithms;finer-grade crop classification;precision agriculture;multispectral images;pixel-based analysis;agricultural fields;multitemporal satellite imagery;land usage classification models;random forest","","8","","19","","21 Nov 2019","","","IEEE","IEEE Conferences"
"Development of unmanned aerial systems for use in precision agriculture: The AggieAir experience","A. Torres-Rua; M. A. Arab; L. Hassan-Esfahani; A. Jensen; M. McKee","Institute of Life Science, Scuola Superiore Sant’Anna, Pisa, Italy; Institute of Clinical Physiology, National Research Council; Institute of Clinical Physiology, National Research Council; Institute of Clinical Physiology, National Research Council; Institute of Clinical Physiology, National Research Council","2015 IEEE Conference on Technologies for Sustainability (SusTech)","2 Nov 2015","2015","","","77","82","Researchers at the Utah Water Research Laboratory at Utah State University have developed a small unmanned aerial system (UAS) called ""AggieAir"" for use as a precision remote sensing tool. The AggieAirTM UAS platform can be launched and landed almost anywhere. It carries scientific-grade cameras that capture imagery in the visual (red/green/blue), near infrared, and infrared (thermal) spectra. It has been applied in several western states to provide high-resolution imagery in support of research on water, natural resources, and agricultural problems. This paper focuses on uses of AggieAir in the generation of information for use in agricultural operations, especially with respect to precision agriculture. Examples of the use of AggieAir multi-spectral imagery include high-resolution estimation of, evapotranspiration rates, crop tissue nitrogen and chlorophyll, surface and root-zone soil moisture, and crop leaf canopy volume.","","978-1-4799-1802-7","10.1109/SusTech.2015.7314326","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7314326","High-resolution imagery;precision agriculture;soil moisture;evapotranspiration rates;leaf nitrogen content;chlorophyll content","Agriculture;Nitrogen;Soil moisture;Remote sensing;Estimation;Image resolution","agricultural engineering;autonomous aerial vehicles;crops;evaporation;image capture;image resolution;precision engineering;remote sensing;transpiration","Utah Water Research Laboratory;Utah State University;small unmanned aerial system;precision remote sensing tool;AggieAir UAS platform;scientific-grade cameras;visual spectra;near infrared spectra;thermal spectra;high-resolution imagery capture;information generation;agricultural operations;precision agriculture;AggieAir multispectral imagery;high-resolution estimation;evapotranspiration rates;crop tissue nitrogen;chlorophyll;root-zone soil moisture;surface soil moisture;crop leaf canopy volume","","5","","7","IEEE","2 Nov 2015","","","IEEE","IEEE Conferences"
"Development of Spectral Signature of Land Cover and Feature Extraction using Artificial Neural Network Model","S. Kumar; S. Shwetank; K. Jain","Dept. of Computer Science, Gurukula Kangri (Deemed to be University), Haridwar, India; Dept. of Computer Science, Gurukula Kangri (Deemed to be University), Haridwar, India; Civil Engineering, IIT, Roorkee, India","2021 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS)","12 Apr 2021","2021","","","113","118","The remote sensing (RS) imagery is important to the development of the spectral signature of mango orchards, vegetation, and other land-use features, and to geospatial feature extraction using artificial neural networks (ANNs). The geospatial information is useful for monitoring vegetation growth, urban development, and land-use / land-cover (LU/LC) change detection. The objective of this study to develop a spectral signature and feature extraction of land-use classes using the multi-temporal and multi-spectral (MTMS) Landsat imagery dataset. The imagery dataset has obtained three images from various sensors of the Landsat satellite system from the years 2003 to 2017. The pre-processing of the imagery is crucial for geospatial feature extraction and analysis of land-use features. The vegetation index (VI) is used in this study to monitor the health and growth of orchards, vegetation, and crop. The resulting accuracy of classification using ANNs method for different years (2017, 2010, and 2003) are 90.10%, 75.75%, and 78.37%. The results of the presented study indicated that significant changes have occurred in the study region, which has affected the environment and human activities. The information of LU/LC's situation in the region will help the urban planners and decision-makers to plan for effectively managing future LU/LC change.","","978-1-7281-8529-3","10.1109/ICCCIS51004.2021.9397172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397172","geospatial;LU/LC;MTMS;vegetation index","Earth;Vegetation mapping;Feature extraction;Geospatial analysis;Indexes;Remote sensing;Monitoring","crops;feature extraction;geographic information systems;geophysical image processing;image classification;land cover;neural nets;remote sensing;vegetation;vegetation mapping","spectral signature;land cover;artificial neural network model;remote sensing imagery;mango orchards;land-use features;geospatial feature extraction;artificial neural networks;geospatial information;vegetation growth;urban development;land-use classes;Landsat satellite system;vegetation index","","1","","19","IEEE","12 Apr 2021","","","IEEE","IEEE Conferences"
"Spatio-Spectral Image Fusion Using Local Embeddings","P. Saxena; A. Jain","Department of Computer Science and Engineering, Maulana Azad National Institute of Technology, Bhopal, India; Department of Computer Science and Engineering, Maulana Azad National Institute of Technology, Bhopal, India","2020 IEEE International Students' Conference on Electrical,Electronics and Computer Science (SCEECS)","7 May 2020","2020","","","1","3","Image fusion is extensively used in remote sensing to combine multiple images into a more informative single image, which is more suitable for human and machine perception. The purpose of image fusion algorithms is to achieve a single image with high spatial resolution and high spectral resolution. The major challenges faced by existing algorithms are of output image quality in terms of colour distortion and blurring. This paper models the spatio-spectral image fusion as a problem of non-linear dimensionality reduction. The aim is to define each point of fused image as a linear combination of its neighbours in multi spectral image and the corresponding pixel values from down scaled panchromatic image. The assumption here is that the spectral behaviour of fused image is similar to that of multispectral image. The performance of the model is compared with existing state of the art methods for same-sensor dataset.","2688-0288","978-1-7281-4862-5","10.1109/SCEECS48394.2020.215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9087080","fusion;multisensor fusion;spatio-spectral fusion;pansharpening;non-linear dimensionality reduction;local embeddings.","Image quality;Image color analysis;Nonlinear distortion;Spatial resolution;Image fusion;Remote sensing;Signal to noise ratio","geophysical image processing;hyperspectral imaging;image colour analysis;image fusion;image resolution;image restoration;remote sensing","high spatial resolution;high spectral resolution;output image quality;image colour distortion;image blurring;remote sensing;down scaled panchromatic image;local embeddings;multispectral image;spatio-spectral image fusion","","","","10","IEEE","7 May 2020","","","IEEE","IEEE Conferences"
"Land cover classification based on NDVI using LANDSAT8 time series: A case study Tirupati region","D. Jeevalakshmi; S. N. Reddy; B. Manikiam","Sri Venkateswara University, Tirupati, Andhra Pradesh, IN; Coordinator, Centre of Excellence, Sri Venkateswara University, Tirupati, Andhra Pradesh, India; Indian Space Research Organisation (ISRO), and is with Bangalore University, Sir MV - ISRO Chair Professor Bangalore University, Jnanabharathi Campus, Bangalore","2016 International Conference on Communication and Signal Processing (ICCSP)","24 Nov 2016","2016","","","1332","1335","The Normalized Difference Vegetation Index (NDVI) is one of the most widely used numerical indicator that uses the visible (VIS) and near-infrared bands (NIR) of the electromagnetic spectrum, and is utilized to analyze remote sensing images and assess whether the target contains live green vegetation or not. This paper analyses the utility of NDVI for mapping the land cover characteristics over Tirupati Region, Chittoor District, Andhra Pradesh, India. Images of level-1 data of Landsat8 were collected for three different seasons of the same region and derived the NDVI values. For land cover classification, various band combinations of the remote sensed data are treated and the spatial distribution such as water bodies, built-up area, vegetation and dense vegetation are easily examined by computing their normalized difference vegetation index from multi-spectral data. On-going portion of present study focuses on making out the difference between the vegetation indexes of different land cover types by performing supervised classification.","","978-1-5090-0396-9","10.1109/ICCSP.2016.7754369","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7754369","Remote Sensing;Image Classification;Multispectral Image;Normalized Difference Vegetation Index (NDVI)","Vegetation mapping;Remote sensing;Satellites;Earth;Indexes;Urban areas;Time series analysis","geophysical image processing;image classification;land cover;time series;vegetation","land cover classification;NDVI;LANDSAT8 time series;Tirupati region;normalized difference vegetation index;electromagnetic spectrum;remote sensing images;live green vegetation;land cover characteristics mapping;Chittoor district;Andhra Pradesh;India;spatial distribution;water bodies;built-up area;dense vegetation;multispectral data;supervised classification","","32","","8","IEEE","24 Nov 2016","","","IEEE","IEEE Conferences"
"Land Use Land Cover Change Detection using LANDSAT images: A Case Study","S. Mishra; S. Jabin","Department of Computer Science, Jamia Millia Islamia, New Delhi, India; Department of Computer Science, Jamia Millia Islamia, New Delhi, India","2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA)","10 Nov 2020","2020","","","730","735","Land Use Land Cover change analysis has proven useful in studying the impact of an event on a region. Changes in a region due to urbanization, deforestation, or due to a disaster can be easily assessed using LULC change detection analysis. Remote Sensing, and Geographic Information System (GIS) tools have been used to study long and short-term biodiversity and LULC changes in an area. We present a case study on 2013 flash floods of Uttarakhand that uses multi-spectral Landsat satellite images to analyze the Spatio-temporal changes in the LULC of the region. Landsat 7 and 8 images are used to classify using the Maximal Likelihood Algorithm which is further improved by NDVI. The region is categorized into 5 major classes; mountain, settlement, vegetation, water, and glacier with accuracy more than 92%. The LULC maps are analyzed to reveal significant changes in the region after the disaster.","2642-7354","978-1-7281-6324-6","10.1109/ICCCA49541.2020.9250801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250801","LANDSAT images;2013 Uttarakhand Flash Floods;Remote sensing;LULC change;GIS","Remote sensing;Earth;Artificial satellites;Vegetation mapping;Floods;Geographic information systems;Rivers","geographic information systems;geophysical image processing;image classification;land cover;land use;maximum likelihood estimation;terrain mapping","Land use;urbanization;Remote Sensing;Maximal Likelihood Algorithm;LULC maps;Landsat 7;Spatio-temporal changes;multispectral Landsat satellite images;LULC changes;short-term biodiversity;Geographic Information System tools;LULC change detection analysis;disaster;deforestation;Land Cover change analysis;LANDSAT images;land cover change detection","","1","","16","IEEE","10 Nov 2020","","","IEEE","IEEE Conferences"
"Computational spectral imaging with photon sieves","F. S. Öktem; F. Kamalabadi; J. M. Davila","Orta Dogu Teknik Universitesi, Ankara, Ankara, TR; University of Illinois College of Law, Champaign, IL, US; NASA Goddard Space Flight Center, Greenbelt, MD, US","2016 24th Signal Processing and Communication Application Conference (SIU)","23 Jun 2016","2016","","","425","428","Spectral imaging, the sensing of spatial information as a function of wavelength, is a widely used diagnostic technique in diverse fields such as physics, chemistry, biology, medicine, astronomy, and remote sensing. In this paper, we present a novel computational imaging modality that enables high-resolution spectral imaging by distributing the imaging task between a photon sieve system and a computer. The photon sieve system, coupled with a moving detector, provides measurements from multiple planes. Then an inverse problem is solved in a Bayesian estimation framework to reconstruct the multi-spectral images from these superimposed and blurred measurements. The results illustrate that this technique enables higher spatial and spectral resolution than conventional filtered-based spectral imagers.","","978-1-5090-1679-2","10.1109/SIU.2016.7495768","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495768","spectral imaging;inverse problems;computational imaging;image formation;remote sensing","Imaging;Photonics;Computers;Remote sensing;Extraterrestrial measurements;Inverse problems;Sensors","Bayes methods;estimation theory;image reconstruction;image resolution;image sensors","computational spectral imaging;spatial information sensing;remote sensing;astronomy field;medicine field;chemistry field;biology field;physics field;computational imaging modality;high-resolution spectral imaging;photon sieve system;inverse problem;estimation framework;multispectral image reconstruction;filtered-based spectral imager","","","","","IEEE","23 Jun 2016","","","IEEE","IEEE Conferences"
"DeepSight: Land Use and Land Cover Classification Using Satellite Images","S. Ghavat; P. Kodnani; H. Singh; J. Hajgude","Information Technology VESIT, Mumbai, India; Information Technology VESIT, Mumbai, India; Information Technology VESIT, Mumbai, India; Information Technology VESIT, Mumbai, India","2021 2nd International Conference for Emerging Technology (INCET)","22 Jun 2021","2021","","","1","5","Remote Sensing data is constantly on the rise with launches of various satellites around the world, generating a huge amount of data. This data is raw i.e. it lacks semantics. Due to the lack of semantics, this data is untapped. To fully utilize this data, we propose a classification method based on deep learning, deployed as a web service- DeepSight. DeepSight uses a convolutional neural network- SpectrumNet to effectively classify land use and land cover. After training the model over 27,000 images, an accuracy of 96.3% is achieved for the testing set whereas the validation set gives us an accuracy of 95.1%. Thus, the results show a fairly high accuracy rate of classifying the multi-spectral images and this can be further used by multiple domains requiring Remote Sensing data semantics relating to land use and land cover.","","978-1-7281-7029-9","10.1109/INCET51464.2021.9456155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9456155","Remote Sensing;Web Service;API;Deep Learning;Convolutional Neural Network","Deep learning;Training;Satellites;Web services;Semantics;Neural networks;Convolutional neural networks","geophysical image processing;geophysical signal processing;image classification;learning (artificial intelligence);neural nets;remote sensing;Web services","fairly high accuracy rate;multispectral images;Remote Sensing data semantics;land use;land cover;satellite images;launches;satellites;classification method;deep learning;web service- DeepSight;convolutional neural network","","","","5","IEEE","22 Jun 2021","","","IEEE","IEEE Conferences"
"Remote sensing image fusion using machine learning and deep learning: a systematic review","A. Tawade; S. Virnodkar","Department of Computer Engineering, Mumbai University, Mumbai, India; Department of Computer Engineering, Mumbai University, Mumbai, India","7th International Conference on Computing in Engineering & Technology (ICCET 2022)","20 Jun 2022","2022","2022","","36","46","Modern Remote Sensing (RS) technologies have emerged and picked up a substantial momentum as a valuable source of data for environmental, economic, and social applications over the past few years. RS has given birth to few other beneficial processes like image fusion that extracts & registers relevant important knowledge from satellite images to make them more useful before subjecting to future applications. Image Fusion is typically performed with three broader techniques: Pixel level, Feature Level and Decision Level. With the help of proper image fusion methods, the concerned information is extracted from various images, which can then be utilized for everyday applications, ranging from weather forecasts to reports on natural disasters or climate change. This study talks about a practice of applying Artificial Intelligence (AI) to the great extent considering its recent advancement in the domain of image processing. In a nutshell, this paper explores and analyses the key remote sensing data fusion techniques based on Machine Learning and Deep Learning with respect to multi-satellite images and single satellite multi-spectral band images and reviews the theory, principles, applications, constraints, and benefits of each technique with a goal of discussing a potential future direction of this study.","","978-1-83953-704-2","10.1049/icp.2022.0589","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9800303","","","artificial intelligence;geophysical image processing;image fusion;image processing;learning (artificial intelligence);remote sensing;sensor fusion","social applications;beneficial processes;relevant important knowledge;satellite images;Pixel level;Feature Level;Decision Level;proper image fusion methods;everyday applications;image processing;key remote sensing data fusion techniques;machine learning;deep learning;multisatellite images;single satellite multispectral band images;sensing image fusion;systematic review;Modern Remote Sensing technologies;substantial momentum;environmental applications;economic, applications","","","","","","20 Jun 2022","","","IET","IET Conferences"
"Retrieval and multi-temporal characterization of oil spills from multi-sensor earth observation imagery","R. Pelich; T. V. La; M. Chini; P. Matgen","Environmental Research and Innovation department, Luxembourg Institute of Science and Technology, Belvaux, Luxembourg; Environmental Research and Innovation department, Luxembourg Institute of Science and Technology, Belvaux, Luxembourg; Environmental Research and Innovation department, Luxembourg Institute of Science and Technology, Belvaux, Luxembourg; Environmental Research and Innovation department, Luxembourg Institute of Science and Technology, Belvaux, Luxembourg","2022 IEEE International Workshop on Metrology for the Sea; Learning to Measure Sea Health Parameters (MetroSea)","24 Nov 2022","2022","","","388","392","In this study we propose an image classification method that allows to delineate oil spills from multi-sensor earth observation (EO) data, i.e. Synthetic Aperture Radar (SAR) and multi-spectral imagery. By making use of the SAR intensity and an index derived from multi-spectral data, we perform a multiscale-based bimodal distribution classification, represented in our case by the oil spill and sea clutter, respectively. The proposed method is applied to a sequence of images acquired with a daily frequency allowing to characterise the temporal and spatial of evolution of the oil spill. In addition, we address the surface wind and currents corresponding to each satellite image in order to investigate their impact on the oil spill evolution. The experimental results are focused on two different oil spill events: one in the waters around Mauritius after a Japanese bulk carrier, MV Wakashio, ran aground on a coral reef, and one in the Persian golf which is the largest offshore oil development area.","","978-1-6654-9942-2","10.1109/MetroSea55331.2022.9950927","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9950927","multi-spectral;multi-temporal;oil spill;Synthetic Aperture Radar (SAR)","Earth;Sea surface;Satellites;Radar measurements;Oils;Spaceborne radar;Soft sensors","geophysical image processing;geophysical techniques;image classification;marine pollution;oceanographic techniques;oil pollution;radar imaging;remote sensing;remote sensing by radar;synthetic aperture radar","different oil spill events;image classification method;largest offshore oil development area;multiscale-based bimodal distribution classification;multisensor earth observation data;multisensor earth observation imagery;multispectral data;multispectral imagery;multitemporal characterization;oil spill evolution;Synthetic Aperture Radar","","","","9","IEEE","24 Nov 2022","","","IEEE","IEEE Conferences"
"Unsupervised classification of remote sensing imagery using multi-sensor data fusion","A. K. Agarwalla; S. Minz","TERI University, New Delhi; JNU, School of Computer & Systems Sciences, New Delhi","2017 International Conference on Signal Processing and Communication (ICSPC)","5 Mar 2018","2017","","","227","233","Remotely sensed imagery accounts for sensor specific information. The following paper deals with making use of data from multiple sources with similar temporal resolution to improve classification accuracy. This was done by clustering five masks or samples of 100 × 100 pixels selected randomly from multispectral data from Landsat TM and evaluation of cluster quality to find the number of naturally occurring clusters. This was followed by clustering the entire study area Landsat TM data using k-means algorithm and evaluation of the resulting cluster quality using silhouette coefficient to identify loosely classified pixels and mean silhouette value (threshold of the scene). Hyper-spectral data from Hyperion was used for only the loosely classified pixels identified above and was clustered using the k-means algorithm. Finally, soft decision level fusion method was applied to the clustering output from HS data with good quality clusters (clusters with silhouette coefficient above the mean) from the multi-spectral imagery to produce final classification maps. In the fused imagery, the overall Classification accuracy and Kappa Statistics increased significantly as compared to the multispectral imagery. Cluster validity indices like Silhouette coefficient is used to evaluate cluster quality and predict naturally occurring clusters. The decision level fusion of selective data from multiple sources has exhibited better classification results at reduced computational overheads.","","978-1-5090-6730-5","10.1109/CSPC.2017.8305844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8305844","Unsupervised Classification;Cluster Validity Index;Silhouette Coefficient;Data fusion;Decision-fusion","Clustering algorithms;Signal processing algorithms;Remote sensing;Classification algorithms;Data integration;Prediction algorithms;Signal processing","feature extraction;geophysical image processing;geophysical signal processing;geophysical techniques;image classification;image fusion;pattern classification;pattern clustering;remote sensing;sensor fusion","Kappa Statistics;Hyperion;k-means algorithm;remotely sensed imagery accounts;hyperspectral data;cluster quality;Landsat TM data;multisensor data fusion;remote sensing imagery;cluster validity indices;fused imagery;multispectral imagery;soft decision level fusion method;mean silhouette value;loosely classified pixels;silhouette coefficient;multispectral data;classification accuracy","","","","31","IEEE","5 Mar 2018","","","IEEE","IEEE Conferences"
"Automatic mass function estimation based Fuzzy-C-Means algorithm for remote sensing images change detection","F. Haouas; B. Solaiman; Z. B. Dhiaf; A. Hamouda","Faculté des Sciences de Tunis Laboratory: LIPAH, LR11ES14, Université de Tunis El Manar, Tunis, Tunisie; Department of Image and Information Processing Technopôle Brest-Iroise - CS 83818-, IMT Atlantique Bretagne-Pays de la Loire, Ecoles Mines-Telecom, Brest Cedex 3, France; Faculté des Sciences de Tunis Laboratory: LIPAH, LR11ES14, Université de Tunis El Manar, Tunis, Tunisie; Faculté des Sciences de Tunis Laboratory: LIPAH, LR11ES14, Université de Tunis El Manar, Tunis, Tunisie","2018 25th International Conference on Mechatronics and Machine Vision in Practice (M2VIP)","6 Jan 2019","2018","","","1","6","In this paper, we present a new method for automatic mass function estimation and focal elements selection as a fundamental step to apply the Dempster-Shafer Theory (DST). The idea is to use the centroids and membership distributions obtained by applying the Fuzzy-C-Means algorithm (FCM) to define the mass function. The proposed method allows finding composite focal elements that represent the highest uncertainty and ambiguity. Experiments were conduced on multi-spectral and multi-temporal images for the purpose of change detection by integrating the proposed method of mass function estimation in a process of post-classification by DST. The proposed system of change detection is characterised by a multi-level of imperfection handling where the ambiguity is modelled firstly by FCM, then the uncertainty and the imprecision are handled in the step of mass function estimation. The effectiveness of the proposed methodology is demonstrated by applying it to find transformed region within two landsat images where we obtained high rates of classifications.","","978-1-5386-7544-1","10.1109/M2VIP.2018.8600912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8600912","Dempster-Shafer theory;Mass function estimation;focal elements;Fuzzy-C-Means;change detection;postclassification","Estimation;Clustering algorithms;Uncertainty;Mechatronics;Machine vision;Remote sensing;Change detection algorithms","fuzzy set theory;geophysical image processing;image classification;image segmentation;remote sensing;uncertainty handling","remote sensing images change detection;focal elements selection;Dempster-Shafer Theory;DST;centroids;membership distributions;composite focal elements;multitemporal images;multispectral images;fuzzy-C-means algorithm;automatic mass function estimation","","","","29","IEEE","6 Jan 2019","","","IEEE","IEEE Conferences"
"Research on adaptation criteria generation based on large data mining","H. -Q. Yun; L. Xu; H. Dou; D. -L. Ming","National Key Laboratory of Science and Technology on Aerospace Intelligence Control, Beijing Aerospace Automatic Control Institute, China; Nat. Key Lab. of Sci. & Technol. on Aerosp. Intell. Control, Beijing Aerosp. Autom. Control Inst., China; State Key Lab. for Multi-spectral Inf. Process. Technol., Huazhong University of Science and Technology, Wuhan, Hubei, CN; State Key Lab. for Multi-spectral Inf. Process. Technol., Huazhong University of Science and Technology, Wuhan, Hubei, CN","2016 IEEE Chinese Guidance, Navigation and Control Conference (CGNCC)","23 Jan 2017","2016","","","1311","1316","This paper performs research on adaptation analysis based on large amount of multi-source remote sensing data. In view of different demands from different task background, the research is firstly focused on how to analyze the data in computer language. To achieve this, the feature parameters of target areas are extracted from different target area geographic data. In combination of ORACLE database engine, data mining technology is used to carry out the target area adaptation assessment, and extract corresponding adaptation criteria. We test the trained adaptation criteria on multi-source geographic information data of different target areas. Experimental results show that the resulting criterion has certain coincidence rate and robustness.","","978-1-4673-8318-9","10.1109/CGNCC.2016.7828978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7828978","","Image edge detection;Decision trees;Stability criteria;Pattern matching;Guidelines;Real-time systems","data mining;feature extraction;geographic information systems;remote sensing","adaptation criteria generation;large data mining;adaptation analysis;multi-source remote sensing data;data analysis;computer language;feature extraction;multisource geographic information data","","","","12","IEEE","23 Jan 2017","","","IEEE","IEEE Conferences"
"The ESA EarthCARE mission development status","A. Lefebvre; A. Hélière; K. Wallace; H. Nakatsuka; E. Tomita","European Space Agency, ESTEC, Noordwijk, The Netherlands; European Space Agency, ESTEC, Noordwijk, The Netherlands; European Space Agency, ESTEC, Noordwijk, The Netherlands; Japan Aerospace Exploration Agency, Tsukuba, Ibaraki, Japan; Japan Aerospace Exploration Agency, Tsukuba, Ibaraki, Japan","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","4234","4237","The Earth Explorer Core Missions are an element of the European Space Agency Earth Observation Envelope Programme. They are defined as major missions led by ESA to cover primary research objectives set out in the Living Planet Program. EarthCARE, the Earth Clouds Aerosols and Radiation Explorer, has been selected for implementation as the third Earth Explorer Core Mission and is being developed in cooperation with the Japan Aerospace Exploration Agency (JAXA) who provides one of the active instruments. The fundamental objective of EarthCARE is to improve the understanding of the processes involving clouds, aerosols and radiation in the Earth's atmosphere. In order to fulfill this objective, the EarthCARE payload is composed of four instruments, a High Spectral Resolution UV Atmospheric LIDar (ATLID), a 94GHz Cloud Profiling Radar (CPR) with Doppler capability, a Multi-Spectral Imager (MSI) and a Broad-Band Radiometer (BBR). The four instruments will provide, in a synergetic manner, information on cloud and aerosol vertical structure of the atmosphere along the satellite track as well as information about the horizontal structures of clouds and radiant flux from sub-satellite cells.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127937","clouds;aerosols;radar;lidar;spectral imager;radiation budget","Instruments;Clouds;Satellites;Aerosols;Payloads;Atmospheric measurements;Cameras","aerosols;artificial satellites;atmospheric measuring apparatus;atmospheric optics;atmospheric techniques;clouds;geophysical signal processing;optical radar;radiometers;radiometry;remote sensing;remote sensing by laser beam;remote sensing by radar","EarthCARE payload;High Spectral Resolution UV Atmospheric LIDar;94GHz Cloud Profiling Radar;ESA EarthCARE mission development status;Earth Explorer Core Mission;European Space Agency Earth Observation Envelope Programme;primary research objectives;Earth Clouds Aerosols;Radiation Explorer;Japan Aerospace Exploration Agency;frequency 94.0 GHz","","","","6","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Multispectral image classification based on neural network ensembles","X. Fu","Department of Computer Science and Technology, Zhuhai College of Jilin University, Zhuhai, China","2016 Eighth International Conference on Advanced Computational Intelligence (ICACI)","9 Apr 2016","2016","","","275","277","In this paper, we investigate neural network ensemble (NNE) classifier and its application to multi-spectral image classification. The effectiveness of the NNE classifier is demonstrated on SPOT multi-spectral image data. Compared with standard classifiers, such as Bayes maximum-likelihood classifier, k-NN classifier, it has shown that the NNE classifier can have better performance on multi-spectral image classification.","","978-1-4673-7782-9","10.1109/ICACI.2016.7449838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449838","Multi-spectral Image;neural network ensembles;pattern classification","Artificial neural networks;Training;Classification algorithms;Testing;Correlation;Remote sensing","geophysical image processing;image classification;neural nets","multispectral image classification;neural network ensemble;NNE;SPOT multispectral image data","","","","11","IEEE","9 Apr 2016","","","IEEE","IEEE Conferences"
"CalCROP21: A Georeferenced multi-spectral dataset of Satellite Imagery and Crop Labels","R. Ghosh; P. Ravirathinam; X. Jia; A. Khandelwal; D. Mulla; V. Kumar","University of Minnesota, Minneapolis, US; University of Minnesota, Minneapolis, US; University of Pittsburgh, Pittsburgh, US; University of Minnesota, Minneapolis, US; University of Minnesota, St. Paul, US; University of Minnesota, Minneapolis, US","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","1625","1632","Mapping and monitoring crops is a key step to-wards sustainable intensification of agriculture and addressing global food security. A dataset like ImageNet that revolutionized computer vision applications can accelerate development of novel crop mapping techniques. Currently, the United States Department of Agriculture (USDA) annually releases the Cropland Data Layer (CDL) which contains crop labels at 30m resolution for the entire United States of America. While CDL is state of the art and is widely used for a number of agricultural applications, it has a number of limitations (e.g., pixelated errors, labels carried over from previous years and errors in classification of minor crops). In this work, we create a new semantic segmentation benchmark dataset, which we call CalCROP21, for the diverse crops in the Central Valley region of California at 10m spatial resolution using a Google Earth Engine based robust image processing pipeline and a novel attention based spatio-temporal semantic segmentation algorithm STATT. STATT uses re-sampled (interpolated) CDL labels for training, but is able to generate a better prediction than CDL by leveraging spatial and temporal patterns in Sentinel2 multi-spectral image series to effectively capture phenologic differences amongst crops and uses attention to reduce the impact of clouds and other atmospheric disturbances. We also present a comprehensive evaluation to show that STATT has significantly better results when compared to the resampled CDL labels. We have released the dataset and the processing pipeline code for generating the benchmark dataset.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671569","Remote Sensing;Spatio-temporal data;Semantic Segmentation;Large Scale dataset","Training;Image segmentation;Pipelines;Semantics;Crops;Big Data;Benchmark testing","agriculture;computer vision;crops;food security;geophysical image processing;hyperspectral imaging;image resolution;image segmentation;interpolation;phenology;remote sensing;vegetation mapping","crop labels;crop monitoring;global food security;computer vision;crop mapping;United States Department of Agriculture;CalCROP21;robust image processing pipeline;Sentinel2 multispectral image series;georeferenced multispectral dataset;satellite imagery;STATT;Google Earth Engine;spatio-temporal semantic segmentation algorithm;Cropland Data Layer;CDL","","3","","23","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Monitoring of Rice Leaf Folder Damage Based on Remote Sensing Methods","J. Wang; K. Yu; X. Zhu; F. Zhu; M. Tian; Z. Wang","Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China; Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China; Jiangsu Province Plant Protection and Plant Quarantine Station, Nanjing, China; Jiangsu Province Plant Protection and Plant Quarantine Station, Nanjing, China; Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China; Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China","2018 7th International Conference on Agro-geoinformatics (Agro-geoinformatics)","30 Sep 2018","2018","","","1","4","Rice leaf folder (Cnaphalocrocis medinalis Guenée) is one of the most important pests that endanger rice development and yield, which has characteristics of large outbreak areas, high occurrence frequencies and heavy damages. At present, the monitoring methods of rice leaf folder damage is based on artificial investigation, which has the advantages of objective truth and high reliability, while there is a drawback of time-consuming, and it cannot used for a wide range of rice damage monitoring. An ASD (Analytical Spectral Devices, Inc.) Hand-held Spectroradiometer was used at jointing stage of rice. The results showed that, reflectance from rice canopy significantly decreased in the green (530-570 nm) and near infrared (700-1000 nm) regions, and significantly increased in the blue (450-520 nm) and red (580-700 nm) regions as the rice leaf folder population increased. Reflectance from rice canopy significantly decreased in the spectral regions from 737 to 1000 nm as the infestation scale of pest population increased, and the most correlation appeared at 941 nm. The more the numbers of rice leaf folder, the higher the changes of such characteristic parameters. The positive correlations were found between the damage of rice leaf folder and the discrepancy of characteristic parameters in these experimental fields. With China Remote Sensing career advancement, a large number of independent researches and development satellites have launched. Among a new generation of high-resolution satellites, GaoFen-1 (GF-1) stands out. It sets high spatial resolution (2 m-16 m), multi-spectral and high temporal resolution (4-day) with 60 km-800 km swath in a fusion technology with strategic significance. In order to explore the adaptability of Chinese GF-1 images in monitoring rice damage from rice leaf folder, nine rice fields were selected by damage severity in Xinghua City, Jiangsu Province at full heading stage in 2015, and the Ratio Vegetation Index (RVI), Normalized Difference Vegetation Index (NDVI), Enhanced Vegetation Index (EVI), 2-band Enhanced Vegetation Index (EVI2), Soil Adjusted Vegetation Index (SAVI), Optimized Soil Adjusted Vegetation Index (OSAVI) were used to characterize the occurrence of rice leaf folder damages, which were calculated from the satellite GF-1 retrieval data. A series of analyses were performed to disclose the relationship among these six indices and the severity of rice leaf folder. Quantitative correlation analyses showed that NDVI, EVI, EVI2, SAVI, OSAVI and leaf folding population had a highly significant correlation (P<;0.01), and SAVI had a highest correlation of 0.94. While there was no significant correlation between RVI and leaf folding population. Therefore, it was feasible to using hyperspectral data and GF-1 satellite images to monitor and warn the outbreak and development of rice leaf folder, which provided a new possible method to monitor dynamically the damage of rice leaf folder.","","978-1-5386-5038-7","10.1109/Agro-Geoinformatics.2018.8476138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476138","rice leaf folder damage;pest population;spectral characteristics;GF-1 WFV image","Sociology;Correlation;Monitoring;Vegetation mapping;Spatial resolution;Satellites","radiometry;vegetation mapping","2-band enhanced vegetation index;soil adjusted vegetation index;optimized soil adjusted vegetation index;hyperspectral data;GF-1 satellite images;normalized difference vegetation index;ratio vegetation index;AD 2015;Jiangsu Province;Xinghua City;Chinese GF-1 images;fusion technology;temporal resolution;multispectral resolution;spatial resolution;GaoFen-1;high-resolution satellites;China remote sensing career advancement;pest population;ASD hand-held spectroradiometer;Analytical Spectral Devices Inc.;Cnaphalocrocis medinalis;remote sensing methods;leaf folding population;monitoring rice damage;rice leaf folder population;rice canopy;rice damage monitoring;rice leaf folder damage;size 2.0 m to 16.0 m;size 60.0 km to 800.0 km;size 700.0 nm to 1000.0 nm","","","","5","IEEE","30 Sep 2018","","","IEEE","IEEE Conferences"
"European Space agency (ESA) Landsat MSS/TM/ETM+/OLI archive: 42 years of our history","S. Saunier; A. Northrop; S. Lavender; L. Galli; R. Ferrara; S. Mica; R. Biasutti; P. Goryl; F. Gascon; M. Meloni; B. Desclee; B. Altena","IDEAS+, Telespazio VEGA UK Ltd, Luton, Bedfordshire, United Kingdom; IDEAS+, Telespazio VEGA UK Ltd, Luton, Bedfordshire, United Kingdom; IDEAS+, Telespazio VEGA UK Ltd, Luton, Bedfordshire, United Kingdom; Advanced Computer Systems (ACS) – IDEAS+, Rome, Italy; Advanced Computer Systems (ACS) – IDEAS+, Rome, Italy; Advanced Computer Systems (ACS) – IDEAS+, Rome, Italy; ESA-ESRIN, European Space Agency – Earth Observation Programme, Frascati, Italy; ESA-ESRIN, European Space Agency – Earth Observation Programme, Frascati, Italy; ESA-ESRIN, European Space Agency – Earth Observation Programme, Frascati, Italy; Serco – DSI, Frascati, Italy; SIRS, Parc de la Cimaise, France; Department of Geosciences, University of Oslo, Blindern, Norway","2017 9th International Workshop on the Analysis of Multitemporal Remote Sensing Images (MultiTemp)","14 Sep 2017","2017","","","1","9","Whilst recent years have witnessed the development and exploitation of operational Earth Observation (EO) satellite constellation data, the valorisation of historical archives has been a challenge. The ESA Multi Spectral Scanner (MSS) products cover Greenland, Iceland, Continental Europe and North Africa representing an archive of over 600,000 Level 1 (L1) scenes that join the 1 million ESA Thematic Mapper (TM) and Enhanced Thematic Mapper Plus (ETM+) products already available. This paper presents the L1 MSS product functionality, and how the dataset will be fit for multi temporal purposes. For example, a quality assurance traceability concept is implemented through an innovative pixel based Quality Assurance Band (BQA) that includes land, cloud and anomaly flagging. Land cover application areas are showcased, including vegetation monitoring and snow cover monitoring on glaciers.","","978-1-5386-3327-4","10.1109/Multi-Temp.2017.8035252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8035252","Landsat;Bulk-processing;time-series;multi-temporal","Earth;Satellites;Remote sensing;Calibration;Radiometry;Europe;Geology","glaciology;remote sensing;snow","operational Earth Observation satellite constellation data;historical archives;ESA Multi Spectral Scanner products;Greenland;Iceland;Continental Europe;North Africa;Enhanced Thematic Mapper Plus products;quality assurance traceability;snow cover monitoring","","4","","26","IEEE","14 Sep 2017","","","IEEE","IEEE Conferences"
"Efficient automated U - Net based tree crown delineation using UAV multi-spectral imagery on embedded devices","K. Blekos; S. Nousias; A. S. Lalos","Industrial Systems Institute, ATHENA Research Center, Patras, Greece; Industrial Systems Institute, ATHENA Research Center, Patras, Greece; Industrial Systems Institute, ATHENA Research Center, Patras, Greece","2020 IEEE 18th International Conference on Industrial Informatics (INDIN)","7 Jun 2021","2020","1","","541","546","Delineation approaches provide significant benefits to various domains, including agriculture, environmental and natural disasters monitoring. Most of the work in the literature utilize traditional segmentation methods that require a large amount of computational and storage resources. Deep learning has transformed computer vision and dramatically improved machine translation, though it requires massive dataset for training and significant resources for inference. More importantly, energy-efficient embedded vision hardware delivering real-time and robust performance is crucial in the aforementioned application. In this work, we propose a U-Net based tree delineation method, which is effectively trained using multi-spectral imagery but can then delineate single-spectrum images. The deep architecture that also performs localization, i.e., a class label corresponds to each pixel, has been successfully used to allow training with a small set of segmented images. The ground truth data were generated using traditional image denoising and segmentation approaches. To be able to execute the proposed DNN efficiently in embedded platforms designed for deep learning approaches, we employ traditional model compression and acceleration methods. Extensive evaluation studies using data collected from UAV s equipped with multi-spectral cameras demonstrate the effectiveness of the proposed methods in terms of delineation accuracy and execution efficiency.","2378-363X","978-1-7281-4964-6","10.1109/INDIN45582.2020.9442183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442183","CNN;Accelerated CNN;Deep learning;U-net;Image segmentation","Training;Deep learning;Location awareness;Image segmentation;Vegetation;Real-time systems;Machine translation","autonomous aerial vehicles;deep learning (artificial intelligence);geophysical image processing;image classification;image denoising;image resolution;image segmentation;neural net architecture;remote sensing;robot vision;vegetation","computer vision;machine translation;deep architecture;image denoising;image segmentation;embedded platforms;deep learning;model compression;multispectral cameras;UAV multispectral imagery;automated u-net based tree crown delineation;energy efficient embedded vision hardware;remote sensing","","","","26","IEEE","7 Jun 2021","","","IEEE","IEEE Conferences"
"Scalable nearest neighbor based hierarchical change detection framework for crop monitoring","Z. Chen; R. R. Vatsavai; B. Ramachandra; Q. Zhang; N. Singh; S. Sukumar","North Carolina State University, Raleigh, NC; North Carolina State University, Raleigh, NC; North Carolina State University, Raleigh, NC; North Carolina State University, Raleigh, NC; Oak Ridge National Laboratory, Oak Ridge, TN; Oak Ridge National Laboratory, Oak Ridge, TN","2016 IEEE International Conference on Big Data (Big Data)","6 Feb 2017","2016","","","1309","1314","Monitoring biomass over large geographic regions for changes in vegetation and cropping patterns is important for many applications. Changes in vegetation happen due to reasons ranging from climate change and damages to new government policies and regulations. Remote sensing imagery (multi-spectral and multi-temporal) is widely used in change pattern mapping studies. Existing bi-temporal change detection techniques are better suited for multi-spectral images and time series based techniques are more suited for analyzing multi-temporal images. A key contribution of this work is to define change as hierarchical rather than boolean. Based on this definition of change pattern, we developed a novel time series similarity based change detection framework for identifying inter-annual changes by exploiting phenological properties of growing crops from satellite time series imagery. The proposed framework consists of three components: hierarchical clustering tree construction, nearest neighbor based classification, and change detection using similarity hierarchy. Though the proposed approach is unsupervised, we present evaluation using manually induced change regions embedded in the real dataset. We compare our method with the widely used K-Means clustering and evaluation shows that K-Means over-detects changes in comparison to our proposed method.","","978-1-4673-9005-7","10.1109/BigData.2016.7840735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7840735","Hierarchical Clustering;k-Nearest Neighbors;Change Detection;Remote Sensing;MODIS;NDVI","Time series analysis;Agriculture;Vegetation mapping;Clustering algorithms;Remote sensing;Indexes;MODIS;Climate change","crops;geographic information systems;image processing;monitoring;pattern classification;pattern clustering;remote sensing;time series;trees (mathematics)","scalable nearest neighbor;hierarchical change detection framework;crop monitoring;biomass monitoring;geographic regions;vegetation;remote sensing imagery;change pattern mapping;bitemporal change detection;multispectral images;time series;hierarchical clustering tree construction;nearest neighbor based classification;K-means clustering","","3","","9","IEEE","6 Feb 2017","","","IEEE","IEEE Conferences"
"Array configuration optimization for one-dimensional nonuniform aperture synthesis radiometers","L. Feng; Q. Li; M. Wu; Y. Li; D. Wang; P. Gong; J. Li","Hubei Collaborative Innovation Center for High-efficiency Utilization of Solar Energy, Hubei University of Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Hubei Collaborative Innovation Center for High-efficiency Utilization of Solar Energy, Hubei University of Technology, Wuhan, China; Science and Technology on Multi-Spectral Information Processing Laboratory, Huazhong University of Science and Technology (HUST), Wuhan, China; Hubei Collaborative Innovation Center for High-efficiency Utilization of Solar Energy, Hubei University of Technology, Wuhan, China; Hubei Collaborative Innovation Center for High-efficiency Utilization of Solar Energy, Hubei University of Technology, Wuhan, China; Hubei Collaborative Innovation Center for High-efficiency Utilization of Solar Energy, Hubei University of Technology, Wuhan, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","850","852","For one dimensional large aperture synthesis radiometers (ASRs), the low redundancy linear arrays (LRLAs) are usually the choice for the reason of the lowest system complexity. However, the number of LRLAs is very few, which makes the antenna arrangement of LRLAs inflexible. In this paper, the array configuration optimization for AFF-based nonuniform array is proposed. The AFF-based nonuniform array after the array configuration optimization is called the optimized nonuniform array (ONA). The method how to find out the ONAs is introduced. In numerical results, some examples of ONA are given. The numerical result demonstrates that the performance of ONAs is almost equivalent to LRLAs. Since the antenna positions of ONA are non-integers, in fact, the number of ONAs is infinite in theory, which can be a supplement to the LRLAs in practical applications.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729215","Aperture synthesis radiometer;array configuration optimization;nonuniform array;low redundancy linear array","Antenna arrays;Optimization;Apertures;Radiometers;Redundancy;Image reconstruction","aperture antennas;linear antenna arrays;optimisation;radiometers","array configuration optimization;one-dimensional nonuniform aperture synthesis radiometers;low redundancy linear arrays;optimized nonuniform array","","1","","6","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"RFI mitigation of SMOS image based on CLEAN algorithm","X. Peng; F. Hu; F. He; L. Wu; J. Li; D. Zhu; Z. Liao; C. Qian","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; The National Key Laboratory of Science and Technology on Multi-spectral Information Processing, Wuhan, China; The National Key Laboratory of Science and Technology on Multi-spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Sichuan Institute of Aerospace Electronic Equipment, Chengdu, China; Sichuan Institute of Aerospace Electronic Equipment, Chengdu, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","816","819","Aperture synthesis measurements, also termed complex visibilities, are the sparse samplings in the (u,v) frequency plane, which causes undesirable side lobes in the synthesized beam. Through the side lobes, artificial sources emitting in the protected 1400-1427MHz band are contaminating the retrievals of the soil moisture and ocean salinity (SMOS) satellite launched by the European Space Agency (ESA) in November 2009. An effective way to correct the artificial interferences is to create a synthetic signal as close as possible to the interference and subtract it from the measured data. Based on the same idea, in this paper, we describe an approach to compensate for the effect of interference iteratively, which uses the CLEAN algorithm that was first developed to deconvolve a map made up of some point sources in radio astronomy. It works by finding the brightest point and then removing its contribution iteratively. Experiments based on real SMOS data have been carried out to demonstrate that the proposed algorithm is effective in correcting the influence of RFIs.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729206","aperture synthesis radiometers (ASR);radio frequency interference (RFI) mitigation;CLEAN algorithm","Pollution measurement;Apertures;Extraterrestrial measurements;Sea measurements;Interference;Frequency measurement","geophysical image processing;radiofrequency interference","RFI mitigation;SMOS image;CLEAN algorithm;aperture synthesis measurements;sparse samplings;Soil Moisture and Ocean Salinity satellite;European Space Agency;AD 2009 11;artificial interference;frequency 1400 MHz to 1427 MHz","","1","","7","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"The research on modeling dielectric constant of lunar regolith for microwave band","C. Liu; P. Chen",Science and Technology on Multi-spectral Information Processing Laboratory; Science and Technology on Multi-spectral Information Processing Laboratory,"2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","2688","2691","One of the scientific objects for Chang'E (CE) project is estimating the regolith depth from brightness temperature (TB) measured by a multi-channel radiometer at 3GHz, 7.8GHz, 19.35GHz and 37GHz. To establish the accurate microwave radiation or scattering model of lunar surface, firstly we need to determine an accurate model of dielectric constant of lunar regolith. However, until now there is no model of dielectric constant suitable for microwave band between 3GHz-37GHz. In this paper, we extract the normalized temperature deviation τ from CE-1 TB data, which filter out the diurnal variation and the impact of latitude. Then we established a new dielectric constant model for microwave band, through analyzing the different relationship that between τ and the content of iron and titanium. The parameters in the model are inverted by comparing the TB measured and the TB calculated. At last, we compared the proposed dielectric constant model with the measured results of lunar regolith samples.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729694","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729694","Brightness temperature;dielectric constant;lunar regolith;Chang'E-1;dielectric constant model","Moon;Dielectric constant;Temperature measurement;Dielectric measurement;Microwave bands;Data models;Calibration","lunar surface","lunar regolith dielectric constant;microwave band;Chang'E project;regolith depth;brightness temperature;multichannel radiometer;lunar surface scattering model;lunar surface microwave radiation;normalized temperature deviation;CE-1 TB data","","","","7","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Mapping urban impervious surfaces by fusing optical and SAR data at decision level","Y. Bai; G. Sun; Y. Ge; Y. Zhang; Y. Li","Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; National Astronomical Observatories, Chinese Academy of Sciences, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","6336","6339","The extraction of urban impervious surface information plays a key role in the studies of urbanization and its related environmental issues. Optical and SAR remote sensing provides complementary information to improve the accuracy of impervious mapping. However, the fusing of information acquired by different sensors is challenging. Optical and SAR features have distinct characteristics, and require different classification strategy and classification types. In this study, a strategy of fusing multi-spectral optical and polarimetric SAR data at decision-level is proposed. Features are extracted from optical and SAR data, then staked auto-encoder is applied to achieve the land use and land cover classification separately. D-S evidence theory is used to fuse the classification result and the imperious surface map is derived. The experiment was conducted in a highly complex urban area of Hong Kong and the results proves the soundness of the method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898039","impervious surface;decision-level fusion;land use and land cover;multi-spectrum;synthetic aperture radar","","geophysical image processing;geophysical signal processing;image classification;image fusion;radar polarimetry;remote sensing;remote sensing by radar;synthetic aperture radar;terrain mapping","related environmental issues;complementary information;impervious mapping;different classification strategy;classification types;polarimetric SAR data;decision-level;optical SAR data;land use;land cover classification;classification result;imperious surface map;highly complex urban area;urban impervious surfaces;decision level;urban impervious surface information","","","","8","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Characterization of Sentinel-MSI and Landsat-OLI Filters Responsivities Differences for Soil Salinity Dynamic Monitoring in an Arid Landscape","A. Bannari; N. Hameid","Department of Geoinformatics, Arabian Gulf University, Manama, Kingdom of Bahrain; Department of Geoinformatics, Arabian Gulf University, Manama, Kingdom of Bahrain","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","7140","7143","The Multi Spectral Instrument (MSI) onboard Sentinel satellites and the Operational Land Imager (OLI) installed on Landsat-8 satellite are designed to be similar. However, relative spectral response profiles characterizing the filters responsivities of the both instruments are not identical between the homologous bands, so some differences are probably expected in the recorded land-surface reflectance values. This paper analyse and compare the difference between the reflectances of the homologous spectral bands in the VNIR and SWIR of MSI and OLI sensors for soil salinity dynamic monitoring in arid landscapes. In addition, comparisons were carried out in term of conversion of these surface reflectances to the Soil Salinity and Sodicity Index (SSSI) and in term of the Semi-Empirical Predictive Model (SEPM) for salt-affected soil mapping. Analyses were performed on two images acquired with 1 day difference over the same area for a wide range of soil salinity degrees. The images were radiometrically calibrated, atmospherically corrected, and BRDF normalized. To generate data for comparison analysis, similarly to OLI, MSI images were resampled systematically in 30-m pixel size considering UTM projection and WGS84 datum. The comparisons were undertaken using regression analysis and root mean square difference (RMSD). The results obtained demonstrate that the two used images exhibited very significant fits (R2 of 0.93 for the costal and R2 ≥ 0.96 for the other bands of land-surface reflectances, and R2 of 0.95 for SSSI and SEPM). Moreover, excellent consistency was observed between the products of the two sensors, yielding a RMSD values less than 0.029 (reflectance units) for the bands and less than 0.004 for SSSI. For the SEPM, the calculated RMSD was varied between 0.12 and 2.65 dS.m-1, respectively, of non-saline and extreme salinity classes. While, the relative errors were varied between 0.046 and 0.005 for the considered soil salinity classes. Therefore, MSI and OLI sensors can be used jointly to characterize and to monitor accurately the soil salinity and it's dynamic in time and space in arid landscape; indicating that rigorous preprocessing issues must be addressed before.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898953","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898953","Remote sensing;Landsat-OLI;Sentinel-MSI;Soil salinity index;Semi-empirical predictive model;Arid landscape","Salinity (geophysical);Soil;Sensors;Monitoring;Atmospheric modeling;Satellite broadcasting;Remote sensing","geochemistry;geophysical techniques;remote sensing;soil","soil salinity dynamic monitoring;arid landscape;MultiSpectral Instrument onboard Sentinel satellites;Operational Land Imager;Landsat-8 satellite;relative spectral response profiles;homologous bands;homologous spectral bands;OLI sensors;SemiEmpirical Predictive Model;salt-affected soil mapping;soil salinity degrees;MSI images;reflectance units;extreme salinity classes;soil salinity classes;land-surface reflectance values;Landsat-OLI filters;sentinel-MSI filters;Soil Salinity and Sodicity Index","","","","25","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Robust Mutual Information-Based Multi-Image Registration","D. Liu; H. Mansour; P. T. Boufounos","Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","915","918","Image registration is of crucial importance in image fusion such as pan-sharpening. Mutual information (MI)-based methods have been widely used and demonstrated effectiveness in registering multi-spectral or multi-modal images. However, MI-based methods may fail to converge in searching registration parameters, resulting mis-registration. In this paper, we propose an outlier robust method to improve the robustness of MI-based registration for multiple rigid transformed images. In particular, we first generate registration parameter matrices using a MI-based approach, then we decompose each parameter matrix into a low-rank matrix of inlier registration parameters and a sparse matrix corresponding to outlier parameter errors. Results of registering multi-spectral images with random rigid transformations show significant improvement and robustness of our method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898834","Image registration;multi-spectral image;mutual information;sparsity constraint","Image registration;Sparse matrices;Mutual information;Registers;Robustness;Image resolution;Matrix decomposition","image fusion;image registration;matrix algebra","robust mutual information-based multiimage registration;image fusion;multimodal images;MI-based methods;outlier robust method;MI-based registration;inlier registration parameters;pan-sharpening;multiple rigid images transformation;parameter matrices registration;low-rank matrix;multispectral images registration","","3","","10","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Multispectral Image Fusion Using Fractional-Order Differential and Guided Filtering","J. Li; G. Yuan; H. Fan","School of Computer Science and Technology, Shandong Technology and Business University, Yantai, China; School of Computer Science and Technology, Shandong Technology and Business University, Yantai, China; School of Computer Science and Technology, Shandong Technology and Business University, Yantai, China","IEEE Photonics Journal","25 Oct 2019","2019","11","6","1","18","Remote sensing satellites can provide a large number of multispectral images. However, due to the limitations of optical sensors embedded in satellites, the spatial resolution of multispectral images is relatively low. Pansharpening aims to combine high-resolution panchromatic and multi-spectral images to generate high-resolution multi-spectral images. In this paper, we propose a pansharpening method based on a component substitution framework. We use fractional-order differential operators and guided filter to balance the spectral distortion and spatial information loss that occur when remote sensing image fusion. Fractional-order differentiation can better define the detailed map, and the guided filter can enhance the spectral information of the detailed map. Experiments show that the proposed method in this paper can better combine the spectral information and spatial information, as well as obtain satisfactory results in both subjective visual perception and objective object evaluation.","1943-0655","","10.1109/JPHOT.2019.2943489","National Science Foundation(grant numbers:EEC-0310717); National Natural Science Foundation of China(grant numbers:61772319,61976125,61976124,61602277,61773244); Shandong Natural Science Foundation of China(grant numbers:ZR2017MF049); Key Research and Development Program of Yantai City(grant numbers:2017ZH065); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848440","Pansharpening;component substitution framework;fractional order differential operators;guided filter","Spatial resolution;Remote sensing;Distortion;Ultraviolet sources;Imaging;Satellites","geophysical image processing;image filtering;image fusion;image resolution;remote sensing","guided filter;spectral information;multispectral image fusion;remote sensing satellites;optical sensors;spatial resolution;high-resolution multispectral images;pansharpening method;component substitution framework;fractional-order differential operators;spectral distortion;spatial information loss;remote sensing image fusion;fractional-order differentiation","","2","","50","CCBY","25 Sep 2019","","","IEEE","IEEE Journals"
"Temporal Attention Networks for Multitemporal Multisensor Crop Classification","Z. Li; G. Chen; T. Zhang","School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Wireless Technology Laboratory, Ericsson Research, Beijing, China; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, Wuhan, China","IEEE Access","26 Sep 2019","2019","7","","134677","134690","Crop classification based on multitemporal multisensor remote sensing imagery has a great significance. As more and more Earth observation satellites are launched, it becomes easier to obtain increasingly dense multitemporal data, and the category patterns hidden in multitemporal data can be more and more finely mined and expressed. However, the traditional classification methods treat the features of different temporal periods consistently, so the classification performances are not well enough, especially for the categories with subtle phenological differences. In this paper, we propose a temporal-attention CNN-GRU (Convolutional Neural Networks and Gated Recurrent Unit Networks) approach to distinguish subtle crop differences, and the temporal attention mechanism introduced in the model can achieve the effect of enhancing phenological differences and suppressing phenological similarity. Firstly, we use the GRU networks to model the temporal correlation of the multitemporal data. And then, the temporal attention layer utilize a query module to retrieve “what is the important information” over the whole temporal sequence, so we can obtain the attention weights for each temporal period. In the experiments, multitemporal samples are collected from Sentinel-2A/B and Landsat-8. Due to the different spatial resolutions of multiband images, transposed convolution which can extract the raw spatial structure information is used for multiband features fusion. Experimental results on multitemporal data show that the proposed approach achieve the best performance compared with conventional methods, especially for the categories with similar phenological laws.","2169-3536","","10.1109/ACCESS.2019.2939152","National Natural Science Foundation of China(grant numbers:61227007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822931","CNN-GRU;crop classification;multiresolution fusion;multitemporal multisensor;temporal attention","Agriculture;Remote sensing;Earth;Artificial satellites;Spatial resolution;Satellites;Feature extraction","convolutional neural nets;crops;feature extraction;geophysical image processing;image classification;image fusion;recurrent neural nets;remote sensing;vegetation mapping","multitemporal multisensor crop classification;multitemporal multisensor remote sensing imagery;Earth observation satellites;temporal-attention CNN-GRU;Gated Recurrent Unit Networks;GRU networks;classification methods;convolutional neural networks;gated recurrent unit networks;Sentinel-2A/B;Landsat-8;multiband features fusion;temporal attention networks","","10","","38","CCBY","3 Sep 2019","","","IEEE","IEEE Journals"
"Advanced Semi-Supervised Possibilistic Fuzzy C-means Clustering Using Spatial-Spectral Distance for Land-Cover Classification","D. -S. Mai; L. T. Ngo; L. -H. Trinh","Le Quy Don Technical University, Hanoi, Vietnam; Le Quy Don Tech. Univ., Hanoi, Vietnam; Le Quy Don Technical University, Hanoi, Vietnam","2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","17 Jan 2019","2018","","","4375","4380","With the explosion of information, characteristics of increasingly complex data, the use of traditional methods in data processing has proved ineffective. Computer applications are increasingly becoming important and essential in many areas such as biology, medicine, psychology, economics, image processing and many other disciplines. A variety of multi-spectral satellite image classification, clustering algorithms have been developed and applied to analyze the surface of the earth. In this paper, we propose a novel semi-supervised possibilistic fuzzy c-means clustering on spatial-spectral distance (SPFCM-SS) for multi-spectral image land-cover classification by the extension of the possibilistic fuzzy C-means (PFCM) algorithm, in which spectral information and spatial information of the pixels are used coupled with labelled data to increase the accuracy of clustering results when the data structure of input patterns is non-spherical and complex. Experiments were performed for multi-spectral satellite image data and clustering efficiency indexes were used to compare the performance of the proposed algorithm with other similar algorithms.","2577-1655","978-1-5386-6650-0","10.1109/SMC.2018.00739","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8616736","semi-supervised;PFCM;spatial information;multi-spectral image","Clustering algorithms;Linear programming;Satellites;Partitioning algorithms;Change detection algorithms;Phase change materials;Image color analysis","fuzzy set theory;geophysical image processing;image classification;image segmentation;learning (artificial intelligence);pattern clustering;remote sensing","spatial-spectral distance;data processing;image processing;multispectral satellite image classification;multispectral image land-cover classification;spectral information;spatial information;labelled data;clustering results;data structure;multispectral satellite image data;clustering efficiency indexes;PFCM algorithm;possibilistic fuzzy C-means algorithm","","5","","15","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"Errors Analysis and Improvement on Measurement Method for Microwave/Millimeter-Wave Emissivity of Small Targets by Radiometer","J. Su; Y. Tian; F. Hu; Y. Cheng; Z. Zhang","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Access","8 Aug 2019","2019","7","","103427","103432","When using traditional methods to measure the microwave/millimeter-wave emissivity of small targets, errors arise due to that the antenna’s main lobe and side lobe cannot be completely covered by the target. To eliminate the errors exist in traditional measurement methods, this paper first analyzes the main sources of errors and gives the analytical expression of the errors. On this basis, an improved method named voltage method is proposed. To test the effectiveness of the improved method, the horizontal polarization emissivity and the vertical polarization emissivity of a metal plate coat with stealthy nano-materials were measured at different observation angles by voltage method and traditional method, respectively. A dick radiometer working in 35 GHz is used in the experiments. Simultaneously, the accurate emissivities of the target are obtained by standard arch method. The results show that the voltage method improves the measurement accuracy largely compared to the traditional method.","2169-3536","","10.1109/ACCESS.2019.2930300","National Natural Science Foundation of China(grant numbers:61871438); Key Laboratory Fund(grant numbers:6142113180111); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8768287","Microwave/millimeter-wave;emissivity measurement;radiometer;error correction","Temperature measurement;Voltage measurement;Antenna measurements;Measurement uncertainty;Metals;Radiometry;Uncertainty","calibration;electromagnetic wave polarisation;emissivity;error analysis;radiometry;remote sensing","measurement method;improved method named voltage method;horizontal polarization emissivity;vertical polarization emissivity;standard arch method;measurement accuracy;voltage method;Radiometer;Microwave/Millimeter-Wave Emissivity;frequency 35.0 GHz","","","","16","CCBY","22 Jul 2019","","","IEEE","IEEE Journals"
"Multiclass support vector machine for classification spatial data from satellite image","K. Tangthaikwan; N. Keeratipranon; A. Agsornintara","Department of Computer, Kasetsart University, Nakonpathom, Thailand; Department of Computer Engineering and Telecommunications, Dhurakij Pundit University, Bangkok, Thailand; Department of Computer Engineering and Telecommunications, Dhurakij Pundit University, Bangkok, Thailand","2017 9th International Conference on Knowledge and Smart Technology (KST)","27 Mar 2017","2017","","","111","115","This paper presents a method for the classification of Landsat Multi-Spectral Scanner (MSS) satellite images to identify the areas of land use. The image is pre-processed and classified using Support Vector Machine (SVM) with the Radial Basis Function (RBF) Kernel as it is an efficient supervised-classification technique. In this research, pixel - base classification method is performed according to the value of spectral pixels with Multi-Spectral Scanner satellite image and used data corresponds to a 3×3 square neighborhoods. The research work consists of two main stages. At the first stage, the optimal parameter, sigma value of RBF kernel, for SVM is studied. At the second stage, the obtained classification result is compared with other classification methods. In this study, sigma value, a parameter of RBF kernel, is varied between 1.0 and 2.0. The sigma value at 1.7 lead to the best classification result which has over 90% accuracy. The result from this SVM method has a higher accuracy compared to other methods.","","978-1-4673-9077-4","10.1109/KST.2017.7886107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886107","Landsat Multi-Spectral Scanner;Satellite Images;Support Vector Machine;Machine Learning","Satellites;Support vector machines;Kernel;Remote sensing;Earth;Soil;Agriculture","geophysical image processing;image classification;land use;radial basis function networks;support vector machines","multiclass support vector machine;spatial data classification;Landsat multispectral scanner satellite image classification;land use;radial basis function kernel;supervised-classification technique;pixel-base classification;spectral pixels;RBF kernel sigma value","","7","","13","IEEE","27 Mar 2017","","","IEEE","IEEE Conferences"
"Three phase segmentation algorithm for high resolution satellite images","T. V. Sai Krishna; A. Y. Babu","Dept. of CSE, QIS College of Engineering and Technology, Ongole, Andhra Pradesh, IN; Dept. of CSE, Sir C.R.R College of Engineering, Eluru, India","2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)","15 Sep 2016","2016","","","2217","2223","To segment multi-spectral remote sensor images, feature extraction and object classification is an essential step that performs region-based segmentation instead of a pixel-based segmentation. Spectral based segmentation methods like K-Means, Mean-shift segmentation fail to extract optimal regions from multi-spectral images. In high-resolution multi-spectral images, segmentation main aim is to divide the image into set of non overlapping regions based on spatial features. In this proposed scheme, three phases are used to segment the remote sensing images. In the first phase, remote sensing image is divided into spatial blocks by applying the filter method. After the preprocessing step, watershed segmentation method is applied to get the initial segmented marked regions. In the second phase, noisy segmented regions are identified and then eliminated using statistical threshold method. In the third phase, area based reduced segmentation method is proposed to reduce the number of segmented regions. Experimental result shows the proposed approach has better performance compared to the traditional segmentation techniques in terms of time, noise and over segmentation.","","978-1-4673-9338-6","10.1109/WiSPNET.2016.7566536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7566536","Watershed Segmentation algorithm;Noise;FCM;Statistical threshold","Image segmentation;Remote sensing;Noise measurement;Classification algorithms;Feature extraction;Conferences;Clustering algorithms","feature extraction;geophysical image processing;image classification;image filtering;image resolution;image segmentation;remote sensing;spatial filters;statistical analysis","three phase segmentation algorithm;high resolution satellite imaging;multispectral remote sensor image segmentation;feature extraction;object classification;region-based segmentation;pixel-based segmentation;spectral based segmentation method;k-means segmentation;mean-shift segmentation;image filter method;watershed segmentation method;statistical threshold method;reduced segmentation method","","2","","15","IEEE","15 Sep 2016","","","IEEE","IEEE Conferences"
"Fusion of genetic-programming-based indices in hyperspectral image classification tasks","J. F. Hernández Albarracín; E. Ferreira; J. A. dos Santos; R. d. S. Torres","Institute of Computing, University of Campinas, Campinas, SP, BR; Department of Computer Science, Universidade Federal de Minas Gerais, Belo Horizonte, MG; Department of Computer Science, Universidade Federal de Minas Gerais, Belo Horizonte, MG; Institute of Computing, Universidade Estadual de Campinas, Campinas, SP, BR","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","554","557","This paper introduces a two-step hyper- and multi-spectral image classification approach. The first step relies on the use of a genetic programming (GP) framework to both select and combine appropriate bands. The second step is concerned with the image classification itself. We present two strategies for multi-class classification problems based on the combination of GP-based indices defined in binary classification scenarios. Performed experiments involving well-known and widely-used datasets demonstrate that the proposed approach yields comparable or better effectiveness performance when compared to several traditional baselines.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127013","hyper- and multi-spectral images;genetic programming;fusion of classifiers","Hyperspectral imaging;Radio frequency;Training;Principal component analysis;Genetic programming","genetic algorithms;geophysical image processing;hyperspectral imaging;image classification","two-step hyperspectral image classification approach;GP-based indices;multiclass classification problems;genetic programming framework;multispectral image classification approach;hyperspectral image classification tasks;binary classification scenarios","","1","","21","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Pan-Sharpening Via High-Pass Modification Convolutional Neural Network","J. Wang; Z. Shao; X. Huang; T. Lu; R. Zhang; J. Ma","State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University; Department of Geosciences, University of Arkansas; Wuhan Institute of Technology; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University; the Electronic Information School, Wuhan University","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","1714","1718","Most existing deep learning-based pan-sharpening methods have several widely recognized issues, such as spectral distortion and insufficient spatial texture enhancement, we propose a novel pan-sharpening convolutional neural network based on a high-pass modification b lock. Different from existing methods, the proposed block is designed to learn the high-pass information, leading to enhance spatial information in each band of the multi-spectral-resolution images. To facilitate the generation of visually appealing pan-sharpened images, we propose a perceptual loss function and further optimize the model based on high-level features in the near-infrared space. Experiments demonstrate the superior performance of the proposed method compared to the state-of the-art pan-sharpening methods, both quantitatively and qualitatively. The proposed model is open-sourced at https://github.com/jiaming-wang/HMB.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506568","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506568","Residual enhancement;pan-sharpening;image fusion;deep neural networks","Image edge detection;Conferences;Neural networks;Distortion;Image restoration;Convolutional neural networks","geophysical image processing;geophysical signal processing;image fusion;image resolution;learning (artificial intelligence);neural nets;remote sensing","high-pass modification convolutional neural network;existing deep learning-based pan-sharpening methods;widely recognized issues;spectral distortion;insufficient spatial texture enhancement;pan-sharpening convolutional neural network;high-pass modification b lock;high-pass information;spatial information;multispectral-resolution images;visually appealing pan-sharpened images;high-level features;the-art pan-sharpening methods","","2","","19","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Remote Sensing Image Haze Removal Using Gamma-Correction-Based Dehazing Model","M. Ju; C. Ding; Y. J. Guo; D. Zhang","Global Big Data Technologies Centre, University of Technology Sydney, Sydney, NSW, Australia; Global Big Data Technologies Centre, University of Technology Sydney, Sydney, NSW, Australia; Global Big Data Technologies Centre, University of Technology Sydney, Sydney, NSW, Australia; School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, China","IEEE Access","16 Jan 2019","2019","7","","5250","5261","Haze is evident in most remote sensing (RS) images, particularly for the RS scenes captured in inclement weather, which severely hinders image interpretation. In this paper, two simple yet effective visibility restoration formulas are proposed for RGB-channel RS (RRS) images and multi-spectral RS (MSRS) images, respectively. More specifically, a robust gamma-correction-based dehazing model (RGDM) is first defined, which can better address the non-uniform illumination problem in hazy images. Then, the scene albedo restoration formula (SARF) used for the RRS images is obtained by imposing the existing prior knowledge on this RGDM, which enables us to simultaneously eliminate the interferences of haze and non-uniform illumination. In subsequence, according to Rayleigh’s law, an expanded restoration formula (E-SARF) is further developed for MSRS data. Using the proposed E-SARF, the spatially varying haze in each band can be thoroughly removed without using any extra information. The experiments are conducted on the challenging RRS and MSRS images, including images with non-uniform illumination, non-uniform haze distribution, and heavy haze. The results reveal that the SARF and the E-SARF are superior to most other state-of-the-art techniques in terms of both the recover quality and the implementation efficiency.","2169-3536","","10.1109/ACCESS.2018.2889766","National Natural Science Foundation of China(grant numbers:61571241,61872423); Research Innovation Program for College Graduates of Jiangsu Province(grant numbers:KYLX16 0665); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8588980","Heavy haze;image dehazing;implementation efficiency;non-uniform haze;non-uniform illumination;remote sensing","Atmospheric modeling;Image restoration;Image color analysis;Remote sensing;Scattering;Meteorology;Lighting","","","","5","","34","OAPA","25 Dec 2018","","","IEEE","IEEE Journals"
"Classification Based on Spectral Characterization and Analysis of Land Cover Change in Dhaka","F. R. Wasee; A. Amin; Z. T. Raisa; S. Chowdhury; T. N. Alam; R. M. Rahman","Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh","2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS)","20 Sep 2018","2018","","","86","91","This study focuses on the temporally evolving geo-environmental characteristics of Dhaka. Dhaka is located at the center of Bangladesh. In the last few decades, it has undergone rapid development in terms of infrastructure and economy. The land use pattern in Dhaka is not the same as it had been previously. The focus has been to analyze the changes that have occurred in Dhaka, which consists of six smaller cities inside it. Using remote sensing techniques and various satellite images, the objects are classified into different categories. Multi spectral characteristics and spectral response patterns are analyzed and studied. Using the information extracted across different decades, changes in land use have been derived. Furthermore, changes in different features e.g. built up, crops, water bodies etc. are analyzed and studied across years to factor out the zones that are experiencing recent urban growth. This generalized pattern of urban growth can be a valuable finding for urban planning and policy for the government of Bangladesh.","","978-1-5386-5892-5","10.1109/ICIS.2018.8466545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466545","Urbanization;Remote Sensing;Satellite Images;Multispectral Characteristics","Urban areas;Vegetation mapping;Satellites;Remote sensing;Earth;Optical surface waves;Agriculture","crops;geophysical image processing;image classification;land cover;land use;remote sensing;town and country planning","Bangladesh;remote sensing techniques;satellite images;crops;built up;water bodies;urban growth;urban planning;urban policy;geo-environmental characteristics;land cover change;land use;different decades;spectral response patterns;multispectral characteristics;Dhaka","","1","","12","IEEE","20 Sep 2018","","","IEEE","IEEE Conferences"
"Characterization and Classification of Vegetation Canopy Structure and Distribution within the Great Smoky Mountains National Park Using LiDAR","J. Kumar; J. Weiner; W. W. Hargrove; S. P. Norman; F. M. Hoffman; D. Newcomb","Oak Ridge National Laboratory, Oak Ridge, TN, USA; University of California Berkeley, Berkeley, CA, USA; USDA Forest Service, Southern Research Station, Asheville, NC, USA; USDA Forest Service, Southern Research Station, Asheville, NC, USA; Oak Ridge National Laboratory, Oak Ridge, TN, USA; U.S. Fish and Wildlife Service, Raleigh, NC, USA","2015 IEEE International Conference on Data Mining Workshop (ICDMW)","4 Feb 2016","2015","","","1478","1485","Vegetation canopy structure is a critically important habitat characteristic for many threatened and endangered birds and other animal species, and it is key information needed by forest and wildlife managers for monitoring and managing forest resources, conservation planning and fostering biodiversity. Advances in Light Detection and Ranging (LiDAR) technologies have enabled remote sensing-based studies of vegetation canopies by capturing three-dimensional structures, yielding information not available in two-dimensional images of the landscape provided by traditional multi-spectral remote sensing platforms. However, the large volume data sets produced by airborne LiDAR instruments pose a significant computational challenge, requiring algorithms to identify and analyze patterns of interest buried within LiDAR point clouds in a computationally efficient manner, utilizing state-of-art computing infrastructure. We developed and applied a computationally efficient approach to analyze a large volume of LiDAR data and characterized the vegetation canopy structures for 139,859 hectares (540 sq. miles) in the Great Smoky Mountains National Park. This study helps improve our understanding of the distribution of vegetation and animal habitats in this extremely diverse ecosystem.","2375-9259","978-1-4673-8493-3","10.1109/ICDMW.2015.178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7395844","Spatial Data Mining;Clustering analysis;LiDAR;Great Smoky Mountains National Park;Vegetation map","Laser radar;Vegetation mapping;Three-dimensional displays;Vegetation;Remote sensing;Ecosystems;Surfaces","ecology;forestry;geophysical image processing;image classification;optical radar;remote sensing by laser beam;vegetation","extremely diverse ecosystem;animal habitat;airborne LiDAR instrument;multispectral remote sensing platform;2D landscape image;remote sensing-based study;Light Detection and Ranging;fostering biodiversity;forest resources;forest monitoring;United States of America;Great Smoky Mountains National Park;vegetation canopy distribution;3D vegetation canopy structure;vegetation canopy classification;vegetation canopy characterization","","7","","27","IEEE","4 Feb 2016","","","IEEE","IEEE Conferences"
"Yield Loss Estimation of Verticillium Wilt Cotton Field Based on UAV Multi-spectral and Regression Model","B. Chen; J. Wang; Q. Wang; Y. Yu; Y. Song; L. Sun; H. Han; F. Wang","Xinjiang Academy of Agricultural and Reclamation Science, Shihezi, China; Institute of Water Conservation and Architectural Engineering, Xinjiang Shihezi Vocational College, Shihezi, China; Xinjiang Academy of Agricultural and Reclamation Science, Shihezi, China; Xinjiang Academy of Agricultural and Reclamation Science, Shihezi, China; Xinjiang Academy of Agricultural and Reclamation Science, Shihezi, China; Xinjiang Academy of Agricultural and Reclamation Science, Shihezi, China; Xinjiang Academy of Agricultural and Reclamation Science, Shihezi, China; Xinjiang Academy of Agricultural and Reclamation Science, Shihezi, China","2022 Global Conference on Robotics, Artificial Intelligence and Information Technology (GCRAIT)","4 Oct 2022","2022","","","62","67","otton Verticillium wilt, as one of the important diseases of cotton, poses a huge threat to the yield and quality of cotton fields. Estimate the yield loss caused by Verticillium wilt of cotton by using the UAV(Unmanned Aerial Vehicle) multispectral model can provide reference for estimating yield loss caused by crop diseases. This study used UAV multi-spectral platform to obtain the image of cotton disease in the experimental area, combined with the ground data by manual investigation, to select the vegetation index and the best band combination with the strongest correlation and optimum exponential factor with cotton disease, then construct the UAV multispectral index. Four classes regression models which from multiple linear regression (MLR), partial least squares regression (PLSR), principal component analysis (PCA) and support vector machine (SVM) were constructed to estimate the cotton yield loss caused by cotton disease based on UAV multispectral index and cotton disease yield loss data. The UAV multispectral images to identify disease of cotton best vegetation index, the best band combination were DVI (I r |=0.86), and (B3-B5-B8) (OIF value = 153.44), respectively. and build the best UAV multispectral index was (RB3-B5-BS + DVI). The four regression models constructed based on UAV multispectral index (RB3-B5-Bs+DVI) can better estimate the yield loss of cotton field with disease. The R2 of four regression monitoring models was between 0.57–0.64, RMSE difference was 6.02, R2 of the validation set was between 0.66 and 0.84.RMSE difference was 15.32, the difference was small. The multivariate linear regression model constructed by UAV multi-spectral index (RB3-B5-Bs+DV)I had the highest verification accuracy (R2=0.84, RMSE=30.73), which could be used as the best estimation model for U A V multi-spectral monitoring of cotton yield loss caused by diseases.","","978-1-6654-8192-2","10.1109/GCRAIT55928.2022.00022","National Natural Science Foundation of China(grant numbers:41961054,41971321); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9898395","otton;Verticillium wilt;UAV;Multi-spectroscopic remote sensing;Yield loss;Models","Support vector machines;Linear regression;Estimation;Autonomous aerial vehicles;Cotton;Indexes;Monitoring","autonomous aerial vehicles;cotton;crops;plant diseases;regression analysis;robot vision;vegetation","cotton yield loss;UAV multispectral index;cotton disease yield loss data;UAV multispectral images;vegetation index;band combination;cotton field;regression monitoring models;multivariate linear regression model;otton Verticillium wilt;crop diseases;UAV multispectral platform;multiple linear regression;principal component analysis","","","","22","IEEE","4 Oct 2022","","","IEEE","IEEE Conferences"
"Experimental Comparison of Multi-Sharpening Methods Applied To Sentinel-2 MSI and Sentinel-3 OLCI Images","A. Alboody; M. Puigt; G. Roussel; V. Vantrepotte; C. Jamet; T. K. Tran","Univ. Littoral Côte d’Opale, Longuenesse, France; Univ. Littoral Côte d’Opale, Longuenesse, France; Univ. Littoral Côte d’Opale, Longuenesse, France; Univ. Littoral Côte d’Opale, Wimereux, France; Univ. Littoral Côte d’Opale, Wimereux, France; Univ. Littoral Côte d’Opale, Wimereux, France","2021 11th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","19 Jul 2021","2021","","","1","5","Multi-spectral images are crucial to detect and to understand phenomena in marine observation. However, in coastal areas, these phenomena are complex and their analyze requires multi-spectral images with both a high spatial and spectral resolution. Unfortunately, no satellite is able to provide both at the same time. As a consequence, multi-sharpening techniques-a.k.a. fusion or super- resolution of multi-spectral and/or hyper-spectral images-were proposed and consist of combining information from at least two multi-spectral images with different spatial and spectral resolutions. The fused image then combines their best characteristics. Various methods-based on different strategies and tools-have been proposed to solve this problem. This article presents a comparative review of fusion methods applied to Sentinel-2 MSI (13 spectral bands with a spatial resolution ranging from 10 to 60 m) and Sentinel-3 OLCI (21 spectral bands with a spatial resolution of 300 m) images. Indeed, both satellites are extensively used in marine observation and, to the best of the authors' knowledge, the fusion of their data was partially investigated (and not in the way we aim to do in this paper). To that end, we provide both a quantitative analysis of the performance of some state-of-the-art methods on simulated images, and a qualitative analysis on real images.","2158-6276","978-1-6654-3601-4","10.1109/WHISPERS52202.2021.9484009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9484009","Image fusion;Remote sensing;Sentinel-2 MSI;Sentinel-3 OLCI;Simulations;Real data","Satellites;Statistical analysis;Conferences;Sea measurements;Distance measurement;Sensors;Spatial resolution","geophysical image processing;geophysical techniques;hyperspectral imaging;image fusion;image resolution;remote sensing","fusion methods;multi-sharpening techniques;multisharpening methods;multisharpening techniques;simulated images;Sentinel-3 OLCI;spectral bands;fused image;spectral resolutions;hyper-spectral images;spectral resolution;high spatial resolution;multispectral images;Sentinel-2 MSI","","2","","21","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"Estimation of rice key phenology date using Chinese HJ-1 vegetation index time-series images","J. Wang; K. Yu; M. Tian; Z. Wang","Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China; Department of International Cooperation, Jiangsu Academy of Agricultural Sciences, Nanjing, China; Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China; Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China","2019 8th International Conference on Agro-Geoinformatics (Agro-Geoinformatics)","2 Sep 2019","2019","","","1","4","Accurate estimation of rice phenology is of critical importance for agricultural practices and studies. However, the accuracy of key phenological parameters extracted by remote sensing data cannot be guaranteed because of the influence of climate, e.g. the monsoon season, and limited available remote sensing data. With China Remote Sensing career advancement, a large number of independent researches and development satellites have launched. Among a new generation of middle to high resolution satellites, HJ-1 stands out. It sets fine spatial resolution (30 m), multi-spectral and high temporal resolution (2-day for constellation) with 360 km swath in a fusion technology with strategic significance. The time-series vegetation indices (VIs), such as the Normalized Difference Vegetation Index (NDVI) and the 2-band Enhanced Vege-tation Index (EVI2) are widely used in the studies of crop land classification, plant productivity, phenology, and crop growth monitoring. It has been shown that VIs values are relatively insensitive to the differences in angular viewing factors and atmospheric disturbances and thereby can be used as a benchmark for direct comparison between sensors. In order to explore the adaptability of Chinese HJ-1 images in rice phenological parameters extraction, two widely used VIs, NDVI and EVI2, were adopted to minimize the influence of environmental factors and the intrinsic difference among the sensor. Savitzky-Golay (S-G) filters were applied to construct continuous VI profiles per pixel. Before phenological parameters extraction, the planting area of single-cropped rice was estimated using a stepwise classification strategy. Divided by the heading date, the growth phases of single-cropped rice can be classified into vegetative growth and reproductive growth. Because the maximum VI usually appears around the heading date, we defined the heading date as the date of the maximum VI on the VI profile. In general, the rice fields are flooded before transplanting and the VI of rice fields decreases during this period and then increases after rice planting. Therefore, we defined the transplanting date of rice as the minimal point along the VI profile. Due to the etiolation and senescence of the rice leaves, the VI decreases after the heading, and the maturation date of rice is identified by the maximum slope method. The results were validated with the field survey data collected by the local agro-meteorological station. The results showed that, compared with NDVI, EVI2 was more stable. Compared with the observed phenological data of the single-cropped rice, the VI time-series had a low root mean square error (RMSE), and EVI2 showed higher accuracy compared with NDVI. We also demonstrate the application of phenology extraction of the single-cropped rice in a spatial scale in the study area. While the work is of general value, it can also be extrapolated to other regions where qualified remote sensing data are the bottleneck but where complementary data are occasionally available.","","978-1-7281-2116-1","10.1109/Agro-Geoinformatics.2019.8820262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820262","rice phenological parameters;vegetation index;HJ-1 images;time-series","Remote sensing;Agriculture;Data mining;Vegetation mapping;Indexes;Meteorology;Monitoring","agriculture;crops;geophysical image processing;image classification;phenology;vegetation;vegetation mapping","rice fields;rice planting;rice leaves;NDVI;phenology extraction;rice key phenology date;Chinese HJ-1 vegetation index time-series images;time-series vegetation indices;Normalized Difference Vegetation Index;2-band Enhanced Vege-tation Index;crop land classification;crop growth monitoring;Chinese HJ-1 images;rice phenological parameters extraction;single-cropped rice;vegetative growth;phenological data;remote sensing data;China Remote Sensing;stepwise classification strategy","","2","","14","IEEE","2 Sep 2019","","","IEEE","IEEE Conferences"
"Internal Learning for Sequence-to-Sequence Cloud Removal via Synthetic Aperture Radar Prior Information","P. Ebel; M. Schmitt; X. X. Zhu","Data Science in Earth Observation(SiPEO), Technical University of Munich (TUM), Munich, Germany; Department of Geoinformatics, Munich University of Applied Sciences, Munich, Germany; Remote Sensing Technology Institute (IMF), German Aerospace Center (DLR), Wessling, Germany","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2691","2694","Many observations acquired via optical satellites are polluted by cloud coverage, impeding a continuous and on-demand monitoring of the Earth. Recent advances in the field of cloud removal consider multi-temporal data to reconstruct pixels covered by clouds at a time point of interest. Yet, the limitation of preceding work is that information gets integrated over time, removing any temporal resolution from the de-clouded end products. In this work we consider a sequence-to-sequence approach, translating cloudy time series to a series of cloud-free multi-spectral images without the need of any external cloud-free data set. Our network is guided by synthetic aperture radar (SAR) information providing a strong prior for the reconstruction of cloud-covered information. We analyze the proposed method by visual inspection of predictions and in terms of error metrics to highlight its benefits. Finally, an ablation study is conducted in which the our network is compared against a baseline model and the effectiveness of the proposed SAR prior is demonstrated.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554268","synthetic aperture radar;optical imagery;cloud removal;time series;data fusion;deep learning","Laser radar;Satellites;Clouds;Time series analysis;Predictive models;Optical imaging;Adaptive optics","","","","2","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A Morphological-Long Short Term Memory Network Applied to Crop Classification","H. K. Teloglu; E. Aptoula","Computer Engineering Department, Gebze Technical University, Turkey; Institute of Information Technologies, Gebze Technical University, Turkey","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","3151","3154","The combination of Convolutional Neural Networks (CNN) with Long Short Term Memory (LSTM) networks in the form of CNN-LSTMs, is one of the currently widely used temporal data series processing approaches. It harnesses the CNN's feature extraction ability along with the LSTM's capacity to account for sequential dependencies. Mathematical morphology on the other hand is known for its spatial analysis potential. In this study, we explore the combination of morphological neural networks (MNNs) with LSTMs, in the form of MNN-LSTMs, and apply it to the problem of crop classification from multi-spectral/temporal remote sensing images. The explored method is tested with two real datasets, where it exhibits either superior or comparable performance to CNN-LSTMs and other state-of-the-art alternative approaches.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883069","Scientific and Technological Research Council of Turkey(grant numbers:118E258); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883069","Morphological neural network;long short term memory network;crop classification;multi-temporal image analysis","Image analysis;Time series analysis;Neural networks;Crops;Morphology;Feature extraction;Convolutional neural networks","crops;feature extraction;geophysical image processing;image classification;mathematical morphology;neural nets;recurrent neural nets;remote sensing","CNN-LSTMs;morphological-Long Short Term Memory network applied;crop classification;Convolutional Neural Networks;Long Short Term Memory networks;currently widely used temporal data series processing approaches;CNN's feature extraction ability;LSTM's capacity;mathematical morphology;spatial analysis potential;morphological neural networks;MNN-LSTMs","","","","15","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Spectral Super-Resolution for Hyperspectral Image Reconstruction Using Dictionary and Machine Learning","S. Bhattacharya; K. Remane; B. Kindel; G. Tang","Department of Electrical, Computer and Energy Engineering, University of Colorado, Boulder, USA; Department of Electrical, Computer and Energy Engineering, University of Colorado, Boulder, USA; Laboratory for Atmospheric and Space Physics, University of Colorado, Boulder, USA; Department of Electrical, Computer and Energy Engineering, University of Colorado, Boulder, USA","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1764","1767","Hyperspectral sensors measure the radiance spectrum across hundreds of wavelength channels with a resolution typically on the order of 10 nm represented by the full-width-half-maximum (FWHM). The spectra are used in the study of surface materials in the biological, geological and oceanographic sciences to name a few, utilizing quantitative spectroscopic techniques. The instruments developed to measure such data are expensive due to the increased number of bands, and create large datasets that can be difficult to downlink for a given instance. Repeat cycle of space-borne hyperspectral observations of the earth surface is also less than those of multi-spectral sensors. It becomes incumbent to develop mechanisms that could be cost-effective and give desired results. With this aim, spectral Super-Resolution (SR) is attempted on the Airborne Visible and Infra-Red Imaging Spectrometer (AVIRIS) data to reconstruct the hyperspectral band radiance from equally-spaced narrow multi-spectral bands using dictionary learning, followed by denoising using machine learning. The hyperspectral band radiance are first estimated from 30 selected input multi-spectral bands using dictionary trained through K-Singular Value Decomposition (K-SVD), followed by denoising using Random Forest Regression. An overall Signal-to-Noise Ratio (SNR) of 31.58dB is observed from reconstruction after denoising using Random Forest.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883055","Spectral Super-Resolution;Signal and Image Processing;Image Reconstruction;Dictionary Learning","Surface reconstruction;Sea surface;Dictionaries;Wavelength measurement;Noise reduction;Superresolution;Sea measurements","geophysical image processing;geophysical signal processing;hyperspectral imaging;image classification;image reconstruction;image resolution;image sensors;learning (artificial intelligence);regression analysis;remote sensing;singular value decomposition;spectral analysis;spectrometers","hyperspectral image reconstruction;hyperspectral sensors;radiance spectrum;wavelength channels;biological sciences;geological sciences;oceanographic sciences;quantitative spectroscopic techniques;space-borne hyperspectral observations;earth surface;multispectral sensors;Infra-Red Imaging Spectrometer data;hyperspectral band radiance;equally-spaced narrow multispectral bands;dictionary learning;machine learning;input multispectral bands","","","","16","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"A texture-based classification algorithm with histograms of oriented gradients for ALOS/PRISM panchromatic imagery","T. Anahara","Earth Observation Research Center, Japan Aerospace Exploration Agency","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","3061","3064","Panchromatic (PAN) satellite imagery comprises only a single band but it has finer resolution in comparison to the multi-spectral band imagery. In the case of feature extraction and classification, although the multi-spectral imagery has an advantage in availability of the different aspect of spectral properties of the ground coverage, the recent studies introducing intelligent classification and feature extraction increases interest of using object-based classification of PAN imagery, e.g., texture analysis. Wavelet-based method is one of the widely used methods that have been studied in satellite-borne imagery but the classification accuracy is still developing. In this paper, the recent feature extraction method developed in computer vision field, the Histograms of Oriented Gradients (HOG), is newly introduced in classification of satellite-borne PAN imagery. It is tested with the PAN image to evaluate its effectiveness in the case with classification and image recognition of ground objects on PAN image with HOG features. The wavelet-based method, feature extraction with the Gabor filter, is compared with intelligent classifiers, Neural Network and k-Nearest Neighbor algorithm. The test with ALOS/PRISM image demonstrates higher performance of the HOG feature with approximately +10 % increase of over all accuracy, +29 % and +27 % of the producer's and user's accuracy at highest and mere -4% decrease of the both accuracy at lowest.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326462","Panchromatic;Classification;HOG;Texture-based feature;ALOS/PRISM","Feature extraction;Accuracy;Classification algorithms;Neural networks;Histograms;Image resolution;Remote sensing","geophysical image processing;geophysical techniques;image recognition;wavelet neural nets","texture-based classification algorithm;histograms-of-oriented gradients;ALOS-PRISM panchromatic satellite imagery;multispectral band imagery;spectral properties;object-based classification;texture analysis;wavelet-based method;satellite-borne imagery;extraction method;computer vision field;HOG;satellite-borne PAN imagery;image recognition;Gabor filter;neural network;k-nearest neighbor algorithm","","1","","15","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Urban road network extraction from IKONOS imagery based on multi-resolution analysis","X. Wu; H. Xu; H. Li","Department of Spatial Information Science and Engineering, Xiamen University of Technology, Xiamen, CN; College of Environment and Resource, Fuzhou University, Fuzhou, Fujian, CN; Department of Spatial Information Science and Engineering, Xiamen University of Technology, Xiamen, CN","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","1262","1265","The width of urban road is various. Roads with different width have different appearance in an image. Multi-resolution analysis-based method for road extraction was proposed. Firstly, some wide roads in IKONOS multi-spectral imagery were extracted through using level set-based method. While some narrow roads, which are non-salient in 4m multi-spectral imagery, were extracted from 1m fusion imagery. Because the central green belt and some continuously arranged road-side trees can imply a road existence, this vegetation information has also been extracted, which effectively assist the road extraction. Finally, the accuracy of the road extraction result was quantitatively assessed. The assessment result shows that this proposed method has a good performance. This method not only can effectively extract salient road network from urban image, but also can extract some non-salient narrow roads.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729320","Road network extraction;IKONOS;Multi-resolution;High spatial resolution","Roads;Feature extraction;Remote sensing;Data mining;Spatial resolution;Transforms","road building;town and country planning;vegetation","urban road network extraction;IKONOS imagery;multiresolution analysis;multispectral imagery;vegetation information;fusion imagery;road extraction;salient road network","","","","13","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Agricultural Analysis and Crop Yield Prediction of Habiganj using Multispectral Bands of Satellite Imagery with Machine Learning","F. Shahrin; L. Zahin; R. Rahman; A. J. Hossain; A. H. Kaf; A. K. M. Abdul Malek Azad","Department of EEE, Brac University, Dhaka, Bangladesh; Department of EEE, Brac University, Dhaka, Bangladesh; Department of EEE, Brac University, Dhaka, Bangladesh; Department of EEE, Brac University, Dhaka, Bangladesh; Department of EEE, Brac University, Dhaka, Bangladesh; Department of EEE, Brac University, Dhaka, Bangladesh","2020 11th International Conference on Electrical and Computer Engineering (ICECE)","5 Apr 2021","2020","","","21","24","Bangladesh is predominately an agriculture based country where an extensive part of its population is primarily employed in its agriculture sector. However, uncertain crop yields and inefficient farming infrastructure causes adverse effect in food security. Habiganj is selected as the study area because of its vulnerability to floods and drought due to its unique terrain. This paper presents a combination of agricultural mapping and monitoring of Habiganj with crop growth and yield prediction. Multi-spectral band images of Habiganj from Landsat-8 are processed and remote sensing indices, correlating to crop growth and yield are extracted. With options of K-means and Mask R-CNN methods, the change over the years is evaluated for crop growth estimation in both Python and Matlab. Then using two type machine learning algorithms crop yield of Habiganj is predicted from its existing parameters and for better accuracy future values of its datasets are predicted by using two type of time series analysis model. Such analytical reports and prediction allows monitoring crop growth dynamic and identifying early signs of reduction in crop productivity. Furthermore, comparative studies are concluded between two platforms, algorithms and time series analysis to determine the most suited environment and model for this research purpose.","","978-1-6654-2254-3","10.1109/ICECE51571.2020.9393066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9393066","agriculture;satellite;k-means segmentation;crop monitoring;crop yield prediction;machine learning;time series forecast","Analytical models;Machine learning algorithms;Time series analysis;Agriculture;Mathematical model;Monitoring;Remote sensing","agriculture;crops;geophysical image processing;learning (artificial intelligence);remote sensing;time series;vegetation mapping","agricultural analysis;crop yield prediction;Habiganj;multispectral bands;satellite imagery;machine learning;agriculture sector;uncertain crop yields;inefficient farming infrastructure;agricultural mapping;multispectral band images;crop growth estimation;algorithms crop yield;time series analysis model;crop growth dynamic;crop productivity","","2","","6","IEEE","5 Apr 2021","","","IEEE","IEEE Conferences"
"Hyperspectral And Multispectral Image Fusion Based On Deep Attention Network","Q. Yang; Y. Xu; Z. Wu; Z. Wei","Nanjing University of Science and Technology, Nanjing, China; Nanjing University of Science and Technology, Nanjing, China; Nanjing University of Science and Technology, Nanjing, China; Nanjing University of Science and Technology, Nanjing, China","2019 10th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","5 Dec 2019","2019","","","1","5","Hyperspectral (HS) images have rich spectral information and can provide attribute information. High spatial resolution images, such as multispectral (MS) images and panchromatic (PAN) images, can provide fine geometric features. Thus, the fusion of the two images can achieve information complementarity and increase the accuracy and reliability of information. In this paper, we propose a hyperspectral and multispectral image fusion method based on deep attention network. Our model consists of two parts. One is the fusion network, which is used to fuse images. The other part is the spatial attention network, which is used to extract tiny textures and enhance the spatial structure. Experimental results compared with some state-of-the-art methods illustrate that our method is outstanding in both visual and numerical results.","2158-6276","978-1-7281-5294-3","10.1109/WHISPERS.2019.8920825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920825","Hyperspectral image;multi-spectral image;image fusion;spatial attention;deep learning","Feature extraction;Spatial resolution;Image reconstruction;Hyperspectral sensors;Machine learning","image fusion;image resolution","high spatial resolution images;panchromatic images;fine geometric features;information complementarity;hyperspectral image fusion method;multispectral image fusion method;deep attention network;fusion network;spatial attention network;spatial structure;hyperspectral images;rich spectral information;attribute information","","6","","14","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"Learning Relevant Features of Optical Water Types","K. Blix; A. B. Ruescas; J. E. Johnson; G. Camps-Valls","Department of Physics and Technology, University of Tromsø—The Arctic University of Norway, Tromso, Norway; Image Processing Laboratory (IPL), Universitat de València, Valencia, Spain; Image Processing Laboratory (IPL), Universitat de València, Valencia, Spain; Image Processing Laboratory (IPL), Universitat de València, Valencia, Spain","IEEE Geoscience and Remote Sensing Letters","15 Dec 2021","2022","19","","1","5","This work introduces a novel method that makes use of machine learning (ML) techniques to classify hyper- and multi spectral observations into optical water types (OWTs). Classification was done using  $k$ -means clustering, which was followed by a feature relevance step based on the sensitivity analysis (SA) of the predictive mean and variance function of a Gaussian process (GP) regression model. The method was used both in training and predictive mode. The latter allows applying the approach for new unlabeled observations, so that the OWTs and the associated relevant features can automatically be assessed. The methods were studied on hyperspectral synthesized and in situ Arctic data, and were further evaluated on a test image acquired over Arctic seas. Good empirical results encourage wide adoption of the methodology to be applied in operational processing and assessment of water types.","1558-0571","","10.1109/LGRS.2021.3072049","Centre for Integrated Remote Sensing and Forecasting for Arctic Operations (CIRFA) [The Research Council of Norway (RCN)](grant numbers:237906); The Nansen Legacy(grant numbers:276730); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9415736","Chlorophyll;explainability;Gaussian processes (GPs);machine learning (ML);ocean;Ocean and Land Color Instrument (OLCI);onboard the Sentinel-3B (S3B);optical water types (OWTs);XAI","Arctic;Training;Optical sensors;Sensitivity;Sea measurements;Optical imaging;Training data","","","","","","28","IEEE","26 Apr 2021","","","IEEE","IEEE Journals"
"Statistical regularization in synthetic aperture imaging radiometry","L. Wu; F. Hu; F. He; J. Li; X. Peng; D. Zhu","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, CN; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, CN; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, CN; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, Hubei, CN","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","4726","4729","Synthetic aperture imaging radiometers (SAIRs) are powerful instruments for high-resolution observation of planetary surface at microwave band. In order to reconstruct the brightness temperature maps from the inteferometric measurements stably and uniquely, it has been recommended to cure the corresponding ill-posed problem with the aid of regularization framework. However, the performances of such numerical regularized solutions highly depend on manually choosing the regularized parameters. In this study, we proposed a statistical regularization method to estimate the optimal regularized parameter of the SAIR inversion adaptively. Furthermore, we have carried out some numerical simulations in reference to the SAIR inversion, and relative comparative analysis has been accomplished to validate the proposed method.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326885","Synthetic aperture imaging radiometers;inverse problem;statistical regularization","Brightness temperature;Apertures;Imaging;Image reconstruction;Receiving antennas;Radiometers;Antenna measurements","brightness;geophysical techniques;numerical analysis;radiometry","statistical regularization;synthetic aperture imaging radiometry;high-resolution planetary surface observation;brightness temperature maps;inteferometric measurements;regularization framework;ill-posed problem;regularized parameters;optimal regularized parameter;SAIR inversion;numerical simulation;comparative analysis","","3","","7","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Rice growth monitoring using multi-temporal GF-1 images","J. Wang; B. Lu; K. Yu; M. Tian; X. Huang; Z. Wang","Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China; Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China; Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China; Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China; Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China; Jiangsu Academy of Agricultural Sciences, Institute of Agricultural Information, Nanjing, China","2017 6th International Conference on Agro-Geoinformatics","21 Sep 2017","2017","","","1","5","With China Remote Sensing career advancement, a large number of independent researches and development satellites have launched. Among a new generation of high-resolution satellites, GaoFen-1 (GF-1) stands out. It sets high spatial resolution (2 m-16 m), multi-spectral and high temporal resolution (4-day) with 60 km-800 km swath in a fusion technology with strategic significance. In order to explore the adaptability of Chinese GF-1 images in rice growth monitoring, aboveground biomass (AGB) was considered as plant growth indicator. Multi-temporal GF-1 WFV images of Xinghua City, Jiangsu Province were selected for rice growth parameter retrieval. An extensive field campaign was carried out during the rice growing season in 2015. Six rice sample plots with areas larger than 200 × 200 m2 in Xinghua City were randomly chosen in order to measure the vegetation characteristics. Only cloud-free images were selected for AGB modeling. Using Savitzky-Golay filters, daily vegetation indices (VIs) time series were created from all the GF-1 images. For modeling of AGB from GF-1, there were 42 matching AGB sample sites. The matched cumulative VIs were calculated from 10-day composite data and were adopted for the estimation of AGB. Five traditional regression equations (linear, exponential, power, logarithmic, and quadratic polynomial regression) were applied in model construction. The leave-one-out cross-validation method was implemented to test the prediction capability of the models. The cumulative NDVI-based quadratic polynomial fit function was adopted for the prediction of AGB at all stages. In this paper, the application provided an important reference of field management and decision-making information. Indicated that GF-1 satellite's high time resolution provides chances to get cloudless data, and high spatial and spectral resolution features can replace the traditional medium resolution remote sensing of agricultural growth monitoring data to a certain extent, but a lot of ground survey data still needed to improve model and monitoring accuracy. This research shows that GF-1 WFV is an important data source and the data's application in other areas of agriculture is the focus of future research.","","978-1-5386-3884-2","10.1109/Agro-Geoinformatics.2017.8047018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8047018","rice growth monitoring;aboveground biomass (AGB);cumulative vegetation indices;GF-1 WFV images","Mathematical model;Agriculture;Remote sensing;Spatial resolution;Biomass;Monitoring;Vegetation mapping","geophysical image processing;regression analysis;time series;vegetation mapping","AGB model;high spatial resolution feature;spectral resolution feature;medium resolution remote sensing;China remote sensing;high-resolution GaoFen-1 satellite;multitemporal GF-1 WFV image;rice sample plot;cloud-free image;AGB sample site;image matching;multitemporal Chinese GF-1 image;quadratic polynomial regression;10-day composite data;daily vegetation indices time series;rice growing season;extensive field campaign;rice growth parameter retrieval;Xinghua City;plant growth indicator;rice growth monitoring;quadratic polynomial fit function","","","","13","IEEE","21 Sep 2017","","","IEEE","IEEE Conferences"
"Fast RFI localization using virtual array in synthetic aperture interferometric radiometers","H. Hu; F. Hu; F. He; J. Li; T. Zheng; X. Peng","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; The National Key Laboratory of Science and Technology on Multi-spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","1277","1280","Radio frequency interference (RFI) has becoming a seriously limitation in the retrieval of geophysical parameters from the measurements of microwave radiometers. In this work, a novel RFI localization approach is presented here to improve the computationally complexity by using virtual arrays and direction of arrival (DOA) estimations techniques. The proposed RFI localization method utilizes the underlying rotational invariance among signal subspaces induced by the virtual array, which is expanded by the sparse array in synthetic aperture interferometric radiometer (SAIR). Estimating Signal Parameters via Rotational Invariance Techniques (ESPRIT) manifests remarkable performance and computational advantages in the test result over the proceeding approach like MUSIC without searching over parameter space.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127194","radio frequency interference (RFI);virtual arrays;direction of arrival (DOA);rotational invariance;synthetic aperture interferometric radiometer","Antenna arrays;Multiple signal classification;Arrays;Covariance matrices;Apertures;Signal processing algorithms;Array signal processing","array signal processing;direction-of-arrival estimation;radiofrequency interference;radiometers","geophysical parameters retrieval;direction of arrival estimation;RFI localization;estimating signal parameters via rotational invariance techniques;computationally complexity;microwave radiometers;radio frequency interference;synthetic aperture interferometric radiometer","","","","7","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"U-Net Ensemble for Semantic and Height Estimation Using Coarse-Map Initialization","S. Kunwar","NestAI, Nepal","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","4959","4962","This is our submission to the IEEE GRSS Data Fusion Single-view Semantic 3D Challenge. The task of this track was to predict semantic labels and normalized DSM (nDSM) aboveground heights from a single-view imagery. RGB and Multi-Spectral Satellite data, along with semantic labels and corresponding height ground-truth were provided for training. We show, in this paper, that an ensemble of a few varied backbones employed in a U-Net architecture, is best at the semantic segmentation and height prediction tasks. Specific band combination from the Multi-Spectral Imagery and the use of hybrid of binary cross-entropy and Jaccard loss proved key in higher semantic accuracy. For height prediction, we show that the addition of a coarse-map initialized from either the global mean or median heights, specific to that particular class label to be valuable for fast convergence and accuracy.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899861","Semantic Segmentation;IEEE GRSS Data Fusion;normalized DSM;Semantic 3D","Semantics;Bridges;Training;Task analysis;Buildings;Vegetation;Data integration","entropy;geophysical image processing;image classification;image colour analysis;image fusion;image segmentation;learning (artificial intelligence);neural net architecture;remote sensing;terrain mapping","U-Net ensemble;height estimation;coarse-map initialization;IEEE GRSS Data Fusion Single-view Semantic 3D Challenge;semantic labels;normalized DSM;single-view imagery;MultiSpectral Satellite data;U-Net architecture;semantic segmentation;MultiSpectral Imagery;semantic estimation;nDSM;RGB data;binary cross-entropy;Jaccard loss","","6","","12","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Pan-Sharpening Performance Comparison for Land Use Classification Application, and Its Effect on LISA LAPAN-A3 in Accuracy Improvement","A. Wahyudiono; E. Asti Anggari; A. Herawan; P. Rachman Hakim; A. Hadi Syafrudin; E. Rachim","Research Center for Satellite Technology, National Research and Innovation Agency (BRIN), Bogor, Indonesia; Research Center for Satellite Technology, National Research and Innovation Agency (BRIN), Bogor, Indonesia; Research Center for Satellite Technology, National Research and Innovation Agency (BRIN), Bogor, Indonesia; Research Center for Satellite Technology, National Research and Innovation Agency (BRIN), Bogor, Indonesia; Research Center for Satellite Technology, National Research and Innovation Agency (BRIN), Bogor, Indonesia; Research Center for Satellite Technology, National Research and Innovation Agency (BRIN), Bogor, Indonesia","2022 IEEE International Conference on Aerospace Electronics and Remote Sensing Technology (ICARES)","30 Dec 2022","2022","","","1","6","Pan-sharpening is one data fusion application that aims to increase the spatial resolution of the multi-spectral image by merging a low-resolution multispectral image with a high-resolution panchromatic image. This process is commonly used to increase the quality of images in the application of land use classification. This research aims to see and learn about the performance of the pan-sharpening method in terms of Land Use Classifications. 5 different methods are compared to see each performance in classification. Moreover, not only using a single-platform data, which is multi-spectral (MS) and panchromatic (Pan) image from Landsat 8, this research also tries to fuse 2 data from a different platform, which are MS from LISA LAPAN-A3 and Pan from Landsat 8. It found that each pan-sharpening method has a different result in terms of accuracy when applied to single-platform data and cross-platform data, nevertheless, some improvements in accuracy were slightly found in pan-sharpened LISA's product to a 9.31% increase.","","978-1-6654-6191-7","10.1109/ICARES56907.2022.9993548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9993548","pan-sharpening;image fusion;land use classification;lapan-a3;Lisa;Landsat","Earth;Artificial satellites;Fuses;Merging;Data integration;Aerospace electronics;Spatial resolution","geophysical image processing;geophysical signal processing;image fusion;image resolution;remote sensing;sensor fusion","5 different methods;cross-platform data;data fusion application;different platform;high-resolution panchromatic image;Land Use Classifications;Landsat 8;LISA LAPAN-A3;low-resolution multispectral image;pan-sharpened LISA's product;pan-sharpening method;Pan-sharpening performance comparison;single-platform data;spatial resolution","","","","19","IEEE","30 Dec 2022","","","IEEE","IEEE Conferences"
"Soil / crop segmentation from remotely sensed data acquired by Unmanned Aerial System","A. Mancini; J. Dyson; E. Frontoni; P. Zingaretti","Dipartimento di Ingegneria dell’ Informazione, Universita Politecnica delle Marche, Ancona, ITALY; Dipartimento di Ingegneria dell’ Informazione, Universita Politecnica delle Marche, Ancona, ITALY; Dipartimento di Ingegneria dell’ Informazione, Universita Politecnica delle Marche, Ancona, ITALY; Dipartimento di Ingegneria dell’ Informazione, Universita Politecnica delle Marche, Ancona, ITALY","2017 International Conference on Unmanned Aircraft Systems (ICUAS)","27 Jul 2017","2017","","","1410","1417","Today Unmanned Aerial Systems (UAS) are widely used for many applications that involve advanced payload as is found to be the case for mounted remote sensing apparatus. Remote sensing from UAS platforms is now common and the use of light and smart multi/hyper-spectral cameras has opened the field to novel applications. These sensors can operate in cloudy conditions ensuring ultra high resolution images while at the same time overcoming the limitations of satellite photography. In this paper we focus on just one such advanced payload application, namely, the segmentation of treecover / canopies over soil terrain. This task is mandatory in order to mask-out areas that are not of direct interest. The approaches studied are based on both supervised and unsupervised algorithms which take into account multi-spectral as well as synthetic features derived from the Digital Surface Model (DSM). We process the DSM by testing 2D convolution kernels together with a pseudo-random image slicing that tries to derive/model the ground/soil profile. Global thresholding is not able the segment tree / canopy area over the soil because the terrain slope is subject to significant change over small areas as is often seen to be the case with vineyards. The proposed approach takes into account such local variability to ensure a correct segmentation analysis in presence of slopes or other undulatory terrain variations. The results obtained show that the proposed method enables the segmentation of tree / canopy vs soil with an overall accuracy greater than 95%.","","978-1-5090-4495-5","10.1109/ICUAS.2017.7991526","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7991526","Segmentation;multi-spectral camera;soil;crop;UAV application","Soil;Agriculture;Vegetation;Image segmentation;Kernel;Convolution;Correlation","crops;remote sensing;soil","soil-crop segmentation;remotely sensed data;unmanned aerial system;UAS;advanced payload;remote sensing apparatus;smart multihyper-spectral cameras;ultra high resolution images;satellite photography;advanced payload application;treecover;mask-out areas;supervised-unsupervised algorithms;ground-soil profile;global thresholding;segmentation analysis;undulatory terrain variations","","4","","24","IEEE","27 Jul 2017","","","IEEE","IEEE Conferences"
"Pan-Sharpening with a CNN-Based Two Stage Ratio Enhancement Method","H. Zhou; Q. Liu; Q. Xu; Y. Wang","The State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; Hangzhou Innovation Institute, Beihang University, Hangzhou, China; Beijing University of Chemical Technology, Beijing, China; The State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","216","219","We propose a hybrid method combining the deep learning technique and the ratio enhancement (RE) method for pansharpening. The intuition behind is to utilize the deep learning technique to synthesize a panchromatic (PAN) image for the RE method to reduce the spectral distortion while keeping the spatial details. The method consists of two stages. First, the CNN synthesizer is optimized to generate the downsampled PAN image to guarantee the network have a good initialization. Second, CNN is integrated into the RE method and supervised by the ground truth multi-spectral (MS) to produce an ideal synthesized PAN for the RE method. We conduct experiments on various datasets and compare with widely used methods to demonstrate the superiority of the proposed method.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323505","National Natural Science Foundation of China(grant numbers:41871283); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323505","Image fusion;pan-sharpening;Convolutional Neural Network (CNN);deep learning","Training;Spatial resolution;Measurement;Image resolution;Testing;Satellites;Remote sensing","geophysical image processing;image fusion;image resolution;image sampling;learning (artificial intelligence);spectral analysis","RE method;ground truth multispectral;ideal synthesized PAN;pan-sharpening;CNN-based two stage ratio enhancement method;hybrid method;deep learning technique;pansharpening;panchromatic image;spectral distortion;CNN synthesizer;downsampled PAN image","","2","","18","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Extended GIHS fusion for pan-sharpening based on image model","Z. Zhou; Y. Meng; P. Yang; B. Hu; C. Chen","Institute of Meteorology and Oceanography, PLA University of Science and Technology, Nanjing, China; Institute of Meteorology and Oceanography, PLA University of Science and Technology, Nanjing, China; Institute of Meteorology and Oceanography, PLA University of Science and Technology, Nanjing, China; Institute of Meteorology and Oceanography, PLA University of Science and Technology, Nanjing, China; Institute of Meteorology and Oceanography, PLA University of Science and Technology, Nanjing, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","2598","2601","An extended GIHS (EGIHS) fusion approach is presented for merging the panchromatic (PAN) image and the multi-spectral (MS) image with model-based optimization (MBO). The pan-sharpened MS image is posed as the optimization solution of the proposed functional, which consists of two energy terms. The first energy term injects the details of the PAN image into the MS image with the generalized IHS (GIHS) fusion model and the second energy term preserves the spectral contents of the MS image by enforcing the low-pass version of the pan-sharpened image should be close to the original up-sampled MS image, in which the low-pass filter is developed based on the modulation transfer function (MTF) of the different MS band. The pan-sharpened MS images are decoupled in the proposed method, which allows an efficient implementation. Experiments on IKONOS and QuickBird datasets demonstrate that the proposed approach outperforms the state-of-the-art fusion models including IHS-based GIHS, GIHSA, IHS-BT, MBO-based Adaptive IHS and MRA-based AWLP.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729671","pansharpening;GIHS fusion;variational fusion;gradient descend flow","Low-pass filters;Remote sensing;Merging;Optimization;Adaptation models;Image resolution;Distortion","geophysical techniques;low-pass filters;optical transfer function","MRA-based AWLP;MBO-based adaptive IHS;IHS-BT;GIHSA;IHS-based GIHS;QuickBird dataset;IKONOS dataset;pansharpened multispectral image method;modulation transfer function;low-pass filter;low-pass pan-sharpened image;multispectral image spectral contents;model-based optimization solution;multispectral image merging;panchromatic image merging;EGIHS fusion approach;extended GIHS fusion approach;pan-sharpening based image model;generalized intensity-hue-saturation fusion model","","1","","20","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Corn Crops Identification Using Multispectral Images from Unmanned Aircraft Systems","F. Trujillano; J. Gonzalez; C. Saito; A. Flores; D. Racoceanu","Pontifical Catholic University of Peru, Lima, Peru; Leipzig University, Leipzig, Germany; Pontifical Catholic University of Peru, Lima, Peru; Pontifical Catholic University of Peru, Lima, Peru; Sorbonne University, Paris Brain Institute, Inria, Paris, France","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","4712","4715","Corn is cultivated by smallholder farmers in Ancash - Peru and it is one of the most important crops of the region. Climate change and migration from rural to urban areas are affecting agricultural production and therefore, food security. Information about the cultivated extension is needed for the authorities in order to evaluate the impact in the region. The present study proposes corn areas segmentation in multi-spectral images acquired from Unmanned Aerial Vehicles (UAV), using convolutional neural networks. U-net and U-net using VGG11 encoder were compared using dice and IoU coefficient as metrics. Results show that with the second model, 81.5% dice coefficient can be obtained in this challenging task, allowing envisaging an effective and efficient use of this technology, in this hard context.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553826","UAV;climate change;corn identification;semantic segmentation","Measurement;Image segmentation;Urban areas;Crops;Geoscience and remote sensing;Production;Unmanned aerial vehicles;Climate change","agriculture;autonomous aerial vehicles;climate mitigation;convolutional neural nets;crops;food security;geophysical image processing;image segmentation","corn crops identification;multispectral images;unmanned aircraft systems;smallholder farmers;urban areas;agricultural production;food security;cultivated extension;corn areas segmentation;unmanned aerial vehicles;convolutional neural networks;U-net;VGG11 encoder;IoU coefficient;dice coefficient;Peru;Ancash;climate change;UAV","","","","12","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Analysis of Bucharest'S Land Cover Evolution Over A Period Of 33 Years Using Multi-Sensor Data","A. . -C. Grivei; M. Datcu","University Politehnica of Bucharest (UPB), Romania; University Politehnica of Bucharest (UPB), Romania","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","1680","1683","Past and current EO (Earth Observation) satellite missions have gathered huge amount of data during the past decades. This offers the opportunity to retrieve significant information concerning the evolution of land cover for almost any point of interest (POI) on Earth's surface. This paper presents the evolution of land cover in the administrative area of Bucharest, Romania, over a time span of 33 years. In order to achieve this goal we use data acquired by multiple EO missions such as: Landsat 5 TM (Thematic Mapper), 7 ETM+ (Enhanced Thematic Mapper Plus), 8 OLI/TIRS (Operational Land Im-ager/Thermal InfraRed Sensor) and Sentinel-2 MSI (Multi-Spectral Instrument). We compute several spectral indexes in order to obtain information regarding the surface coverage evolution for categories such as vegetation, water bodies and build up.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518615","Landsat;Sentinel-2;land cover evolution","Earth;Remote sensing;Artificial satellites;Vegetation mapping;Land surface;Indexes;Spatial resolution","land cover;terrain mapping","Earth surface;Operational Land Imager;Bucharest land cover evolution;Thermal InfraRed Sensor;Sentinel-2 MSI;EO satellite missions;Romania;Bucharest administrative area;surface coverage evolution;MultiSpectral Instrument;Enhanced Thematic Mapper Plus;multiple EO missions;time span;Earth Observation;MultiSensor data;time 33.0 year","","","","14","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Identification and delineation of individual tree crowns using Lidar and multispectral data fusion","L. Gulbe",Ventspils University College,"2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","3294","3297","The aim of this study is to propose and evaluate methodology for identification and delineation of individual tree crowns, using Lidar and multispectral data fusion. Methods implementing data fusion are based on image binarization (thresholding) and region growing segmentation algorithm. Results were compared with template matching method for multi-spectral data and region growing algorithm using just one data source. For a sample set, data fusion approach provided 78 % tree identification accuracy with 5 false positives, but template matching provided 72 % accuracy with 25 false positives. Data fusion approach in the delineation helped to overcome illumination effects.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326522","individual tree crowns;Lidar;multispectral imaging;data fusion","Vegetation;Data integration;Laser radar;Remote sensing;Accuracy;Lighting;Spatial resolution","geophysical image processing;geophysical techniques;image segmentation;optical radar","individual tree crowns;Lidar;multispectral data fusion;image binarization;region growing segmentation algorithm;template matching method;data source;data fusion approach;overcome illumination effect","","","","10","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Improving SAR and Optical Image Fusion for Lulc Classification with Domain Knowledge","K. R. Prabhakar; V. H. Nukala; J. Gubbi; A. Pal; B. P","TCS Research, INDIA; TCS Research, INDIA; TCS Research, INDIA; TCS Research, INDIA; TCS Research, INDIA","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","711","714","Fusing SAR and multi-spectral images to generate a precise land cover map in a weakly supervised setting is a challenging yet essential problem. The inaccurate, noisy, and inexact ground truth labels pose difficulty training any machine learning models. In this paper, we make a fundamental and pivotal contribution towards improving the ground truth label quality using domain knowledge. We present a simple yet effective mechanism to refine the low-resolution noisy ground truth labels. The proposed approach is trained and tested on a publicly available DFC2020 dataset. Through experiments, we show the effectiveness of our method by training a deep learning model on the refined labels that outperform even the models trained with clean ground truth.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884283","CNN;SAR;multispectral;image fusion","Training;Deep learning;Training data;Geoscience and remote sensing;Optical imaging;Noise measurement;Reliability","geophysical image processing;image classification;image fusion;land cover;learning (artificial intelligence);optical images;radar imaging;synthetic aperture radar;terrain mapping","SAR;multispectral images;precise land cover map;weakly supervised setting;challenging yet essential problem;inaccurate ground truth labels;noisy, ground truth labels;inexact ground truth labels;machine learning models;fundamental contribution;pivotal contribution;domain knowledge;simple yet effective mechanism;low-resolution noisy ground truth labels;publicly available DFC2020 dataset;deep learning model;refined labels;clean ground truth;optical image fusion;lulc classification","","","","8","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Remote Sensing Alteration Information Extraction of Manganese Mineralization in Postmasburg, South Africa","H. Shao; D. Yang; H. Chang; X. Wang",NA; NA; NA; NA,"EEI 2022; 4th International Conference on Electronic Engineering and Informatics","17 Feb 2023","2022","","","1","4","In this paper, alteration information of ferric contamination, hydroxylate, carbonatization and manganese mineralization in Postmasburg area of South Africa was extracted by using ASTER multi-spectral satellite remote sensing data and principal component analysis algorithm according to spectral characteristics of alteration minerals related to manganese ore. The results of alteration extraction are compared with the data of regional geological survey and geochemical survey in the study area, and the distribution law of remote sensing alteration anomaly in regional space is summarized, and the spatial coupling relationship between remote sensing alteration anomaly and regional geology is discussed, which fully verifies the accuracy and reliability of the alteration information extracted in this paper. It can provide technical support for remote sensing alteration information extraction of subsequent mineral exploitation. In addition, the results obtained in this study are mutually interpreted with the existing research results, providing strong remote sensing evidence for the study of manganese ore geology in Postmasburg area.","","978-3-8007-5922-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10048164","","","","","","","","","","17 Feb 2023","","","VDE","VDE Conferences"
"3D Habitat Mapping Using High-Resolution Optical Satellite and Lidar Data","M. Amani; F. Foroughnia; A. Moghimi; S. Mahdavi","Wood Environment and Infrastructure Solutions, Ottawa, Ontario, Canada; Department of Geoscience and Engineering, Delft University of Technology, Delft, The Netherlands; Institut for Photogrammetriy and GeoInformation, Leibniz University, Honnover, Germany; Wood Environment and Infrastructure Solutions, Ottawa, Ontario, Canada","2022 10th International Conference on Agro-geoinformatics (Agro-Geoinformatics)","23 Aug 2022","2022","","","1","5","Remote sensing datasets are great resources to map habitat types. In this study, 3D habitat maps were generated using high-resolution multispectral imagery and a LiDAR-derived digital surface model (DSM). Two study areas in the United Kingdom (UK) were selected to investigate the potential of the developed models in habitat classification. The overall classification accuracies for the two study areas were high (91% and 82%), indicating the satisfactory performance of the developed approach for habitat mapping in the study areas. Overall, it was observed that a synergy of high-resolution multi-spectral imagery and LiDAR data could provide reliable 3D information on habitat types.","","978-1-6654-7078-0","10.1109/Agro-Geoinformatics55649.2022.9859127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859127","habitat;3D habitat mapping;Worldview-2;LiDAR","Solid modeling;Three-dimensional displays;Laser radar;Satellites;Optical imaging;Reliability;Optical sensors","geophysical image processing;image classification;image resolution;optical radar;remote sensing;remote sensing by laser beam;terrain mapping","habitat mapping;high-resolution optical satellite;lidar data;remote sensing datasets;great resources;map habitat types;3D habitat maps;high-resolution multispectral imagery;LiDAR-derived digital surface model;habitat classification;classification accuracies;reliable 3D information","","","","11","IEEE","23 Aug 2022","","","IEEE","IEEE Conferences"
"Impact of hybrid pansharpening approaches applied to hyperspectral images","G. Licciardi; M. A. Veganzones; G. Vivone; L. Loncan; J. Chanussot","Grenoble-INP, GIPSA-Iab, Saint Martin d'Heres, France; Institut Polytechnique de Grenoble, Grenoble, RhÃ´ne-Alpes, FR; Universita degli Studi Salerno, Italy; Grenoble-INP, GIPSA-Iab, Saint Martin d'Heres, France; Grenoble-INP, GIPSA-Iab, Saint Martin d'Heres, France","2015 7th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","23 Oct 2017","2015","","","1","4","Pansharpening techniques can be divided into component substitution (CS) and multi-resolution analysis (MRA) based methods. Generally, the CS methods result in fused images having high spatial quality but the fused images suffer from spectral distortions. On the other hand, images obtained using MRA techniques are not as sharp as CS methods but they are spectrally consistent. Both substitution and filtering approaches are considered adequate when applied to multi-spectral and PAN images, but have many drawbacks when the low-resolution image is a hyperspectral image. Based on these findings, the use of a hybrid approach, combining the better spatial information of CS and the more accurate spectral information of MRA techniques, may result in an improvement in terms of spectral quality, spatial sharpness as well as computational time.","2158-6276","978-1-4673-9015-6","10.1109/WHISPERS.2015.8075402","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8075402","Pansharpening;Hyperspectral;multiresolution analysis;component substitution","Spatial resolution;Hyperspectral imaging;Principal component analysis;Indexes;Nonlinear distortion","hyperspectral imaging;image filtering;image fusion;remote sensing","spectral quality;hyperspectral image;pansharpening techniques;CS methods;spectral distortions;MRA techniques;PAN images;component substitution method;image filtering approaches;spectral information;image fusion;multiresolution analysis method","","1","","11","IEEE","23 Oct 2017","","","IEEE","IEEE Conferences"
"Hyperspectral-Multispectral Image Fusion Using Nndiffuse: Performance Assessment Using A Pixel Classification Task","R. Ducay; D. Messinger","Rochester Institute of Technology Chester F. Carlson Center for Imaging Science 54 Lomb Memorial Dr, Rochester, NY, U.S.A; Rochester Institute of Technology Chester F. Carlson Center for Imaging Science 54 Lomb Memorial Dr, Rochester, NY, U.S.A","2022 12th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","22 Nov 2022","2022","","","1","5","The spatial resolution of a hyperspectral image (HSI) can be enhanced using a higher-resolution co-registered multi-spectral image and an image fusion algorithm. Assessing the quality of the fused image is traditionally done by way of Wald’s protocol using image-wide quality metrics but these indices alone may not be enough to predict whether or not the enhanced image results in better performance on a task such as target detection or pixel classification. In this paper we demonstrate hyperspectral-multispectral image fusion using NNDIFFUSE (nearest neighbor-based diffusion algorithm) and assessment of fusion performance via pixel classification. Three classifiers are used (SVM and two 3D deep learning-based classifiers) and their performance on the reference HSI and fused imagery are compared using three post-classification metrics: overall accuracy, mean per-class F1 score, and kappa coefficient. Results show that among fusion algorithms compared, NNDIFFUSE provides the best image fusion product for a pixel classification task.","2158-6276","978-1-6654-7069-8","10.1109/WHISPERS56178.2022.9955122","National Geospatial-Intelligence Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955122","Hyperspectral;multispectral;image fusion;NNDIFFUSE;classification","Measurement;Support vector machines;Three-dimensional displays;Signal processing algorithms;Prediction algorithms;Classification algorithms;Task analysis","deep learning (artificial intelligence);geophysical image processing;hyperspectral imaging;image classification;image fusion;image registration;image resolution;image sensors;object detection;pattern classification;remote sensing;support vector machines","3D deep learning-based classifiers;fusion algorithms;hyperspectral image;hyperspectral-multispectral image fusion;image fusion algorithm;image fusion product;image-wide quality metrics;nearest neighbor-based diffusion algorithm;NNDIFFUSE;pixel classification task;post-classification metrics;spatial resolution;SVM","","","","14","IEEE","22 Nov 2022","","","IEEE","IEEE Conferences"
"Fishing forecasting system in Adriatic sea — A model approach based on a normalized scalar product of the SST gradient and CHL gradient vectors","K. Tijani; M. T. Chiaradia; A. Morea; R. Nutricato; L. Guerriero; G. Pasquariello","Politecnico di Bari, Bari, Puglia, IT; Politecnico di Bari, Bari, Puglia, IT; Politecnico di Bari, Bari, Puglia, IT; Geophysical Applications Processing, GAP srl, Bari, Italy; Politecnico di Bari, Bari, Puglia, IT; Consiglio Nazionale delle Ricerche, Roma, Lazio, IT","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","2257","2260","By mapping the concentration of chlorophyll-a (CHL) and the temperature of the sea surface (SST), satellite images reveal the complex dynamics of marine waters and prove to be a very powerful tool when used to detect potential fishing areas, significantly reducing the time of the search, the fuel consumption and the human effort, and simultaneously increasing the CPUE (catch per unit effort). In the present work, various techniques of multi-sensor, multi-resolution and multi-temporal data fusion are applied to multi-spectral satellite image data of MODIS-AQUA, MODIS-TERRA and VIIRS sensors, in order to detect ""fronts"" of chlorophyll concentration and temperature on the sea surface. According to the physical model of the phenomena, these fronts are generated by the upwelling of cold waters rich of nutrients (phytoplankton) which correspond to areas with a high concentration of pelagic fish and are characterized by high values of local gradients of SST and CHL with anti-parallel orientation. An automatic procedure has been developed to calibrate and validate the production in near-real time of daily maps of expected good fishing grounds to be provided to the FEDERPESCA fleet. The same procedure could be optimized also for other seas.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326256","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326256","Potential Fishing Zones (PFZ);Upwelling;Ocean Color Analysis;Multi-sensor data fusion","Ocean temperature;MODIS;Sea surface;Forecasting;Satellites;Data integration","geophysical image processing;gradient methods;image fusion;microorganisms;ocean temperature;oceanographic regions;oceanographic techniques;remote sensing by radar;seawater;sensor fusion","fishing forecasting system;Adriatic sea;normalized scalar product;SST gradient vector;CHL gradient vector;chlorophyll-a concentration;surface temperature;marine water;complex dynamics;potential fishing area;CPUE;multitemporal data fusion;MODIS-TERRA sensor;MODIS-AQUA sensor;VIIRS sensor;sea water upwelling;phytoplankton;antiparallel orientation;near-real daily map time production;FEDERPESCA;high pelagic fish concentration;fishing grounds","","4","","9","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Validation of the DigitalGlobe surface reflectance product","F. Pacifici","DigitalGlobe, Inc., Colorado, USA","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","1973","1975","This paper illustrated the work done in 2014 and 2015 to validate AComp, the DigitalGlobe proprietary method to atmospherically compensate very high spatial resolution multi-spectral and panchromatic images. The algorithm has been validated against ground measurements on six locations in North America with different climates: rural, urban, semi-arid, and semi-tropical. In addition, aerosol optical depth and water vapor values from AERONET stations (where available) and MODIS were used to compare to the AComp retrievals.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729508","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729508","AComp;atmospheric compensation;sensor calibration;surface reflectance","Reflectivity;MODIS;Spatial resolution;Sun;Atmospheric measurements;Meteorology;Optical imaging","aerosols;atmospheric humidity;geophysical image processing;remote sensing","DigitalGlobe surface reflectance product;AD 2014 to 2015;AComp;multispectral images;panchromatic images;ground measurements;North America;climate;aerosol optical depth;water vapor values;AERONET stations;MODIS","","4","","4","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Robust Deep Hyperspectral Imagery Super-Resolution","J. Nie; L. Zhang; C. Wang; W. Wei; Y. Zhang","School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","847","850","Fusing a low spatial resolution (LR) hyperspectral image (HSI) with a high spatial resolution (HR) multi-spectral image (MSI) is an effective way for HSI super-resolution. When the input LR HSI and the HR MSI are clean, most of existing fusion based methods can produce pleasing results. However, the input HSI and MSI are often corrupted with random noise in practice, which can greatly degrade the performance of these methods. To address this problem, we present a robust deep HSI super-resolution method in this study. In contrast to leveraging a heuristic shallow sparsity or low-rank prior in previous methods, we propose to employ a deep convolution neural network as the prior of the latent HR HSI. With such a prior, the fusion based HSI super-resolution can be formulated as an end-to-end deep learning problem, which can be effectively solved with the back-propagation algorithm. Due to the deep structure, the proposed image prior is able to capture more powerful statistics of the latent HR HSI, and thus can still produce pleasing results with noisy input images. Experimental results on two benchmark datasets demonstrate the effectiveness of the proposed method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900117","Hyperspectral image super-resolution;deep convolution neural networks;unsupervised learning","Noise measurement;Image reconstruction;Spatial resolution;Convolution;Neural networks","convolutional neural nets;geophysical image processing;hyperspectral imaging;image fusion;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","robust deep hyperspectral imagery super-resolution;low spatial resolution hyperspectral image;high spatial resolution multispectral image;MSI;input LR HSI;fusion based methods;input HSI;robust deep HSI super-resolution method;heuristic shallow sparsity;deep convolution neural network;end-to-end deep learning problem;deep structure;noisy input images","","3","","12","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"A Multi-Scale Densely Deep Learning Method for Pansharpening","Z. Xiang; L. Xiao; P. Liu; Y. Zhang","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2786","2789","Pansharpening aims to produce a higher resolution multi-spectral (HRMS) image by fusing the spectral information in lower resolution multispectral (LRMS) image and the spatial information in corresponding high resolution panchromatic (PAN) image. In this work, we propose a multi-scale densely deep learning based pansharpening method. Following an end-to-end learning architecture, the proposed deep neural network contains three modules: 1) a parallel multi-scale convolutional layer is used to extract multiscale features of PAN image; 2) a global identity branch structure is adopted to preserve spectral structures; and 3) a dense learning block is integrated to improve the spectral-spatial expressive power. Compared with other state-of-the-art methods, experimental results obtained with our proposed method achieve high pansharpening quality in visualization and quantification.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898095","Pansharpening;Multiscale feature extraction;dense connection","Spatial resolution;Feature extraction;Indexes;Distortion;Kernel;Deep learning","convolutional neural nets;feature extraction;geophysical image processing;geophysical techniques;image fusion;image resolution;learning (artificial intelligence);neural net architecture;remote sensing","multiscale densely deep learning method;spectral information fusion;lower resolution multispectral image;spatial information;high resolution panchromatic image;multiscale densely deep learning based pansharpening method;end-to-end learning architecture;deep neural network;PAN image;higher resolution multispectral image;parallel multiscale convolutional layer;multiscale feature extraction;HRMS image;LRMS image","","3","","11","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"The ESA Earthcare Mission: Approaching Launch","A. Lefebvre; A. Helière; K. Wallace; J. P. do Carmo; H. Nakatsuka; E. Tomita","European Space Agency, ESTEC, AG Noordwijk, The Netherlands; European Space Agency, ESTEC, AG Noordwijk, The Netherlands; European Space Agency, ESTEC, AG Noordwijk, The Netherlands; European Space Agency, ESTEC, AG Noordwijk, The Netherlands; Japan Aerospace Exploration Agency, Tsukuba, Ibaraki, Japan; Japan Aerospace Exploration Agency, Tsukuba, Ibaraki, Japan","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","1841","1844","The Earth Explorer Core Missions are an element of the European Space Agency Earth Observation Envelope Programme. They are defined as major missions led by ESA to cover primary research objectives set out in the Living Planet Program. EarthCARE, the Earth Clouds Aerosols and Radiation Explorer, has been selected for implementation as the third Earth Explorer Core Mission and is being developed in cooperation with the Japan Aerospace Exploration Agency (JAXA) who provides one of the active instruments. The fundamental objective of EarthCARE is to improve the understanding of the processes involving clouds, aerosols and radiation in the Earth's atmosphere. In order to fulfill this objective, the EarthCARE payload is composed of four instruments, a High Spectral Resolution UV ATmospheric LIDar (ATLID), a 94GHz Cloud Profiling Radar (CPR) with Doppler capability, a Multi-Spectral Imager (MSI) and a Broad-Band Radiometer (BBR). The four instruments will provide, in a synergetic manner, information on cloud and aerosol vertical structure of the atmosphere along the satellite track as well as information about the horizontal structures of clouds and radiant flux from sub-satellite cells. All the four EarthCARE instruments are now approaching their final development stages and are all scheduled to be delivered for integration into the satellite platform in 2018.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518662","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518662","clouds;aerosols;radar;lidar;spectral imager;radiation budget","Instruments;Clouds;Optical transmitters;Aerosols;Satellite broadcasting;Earth;Laser radar","aerosols;artificial satellites;atmospheric measuring apparatus;atmospheric techniques;clouds;optical radar;radiometers;radiometry;remote sensing by radar","ESA earthcare Mission;Earth Explorer Core Mission;European Space Agency Earth Observation Envelope Programme;primary research objectives;Earth Clouds Aerosols;Radiation Explorer;Japan Aerospace Exploration Agency;EarthCARE payload;High Spectral Resolution UV ATmospheric LIDar;EarthCARE instruments;Cloud Profiling Radar;frequency 94.0 GHz","","2","","8","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Valuing New Earth Observation Missions for System Architecture Trade-Studies","A. Siddiqi; E. Magliarditi; O. d. Week","Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","5297","5300","New earth observation missions are being implemented and conceptualized with architectures employing multiple spacecraft and novel observing strategies that combine distributed, multi-platform systems. These new types of missions are enabling earth observation with multi-angular, multi-spectral data acquisition at high resolution and high revisit frequencies. The architectural choices have grown exponentially in such distributed systems, and there is a need for quantitative measures, that go beyond cost estimation, and assess value (or scientific return) over a mission's operational life-cycle. Here, we formulate a novel metric, Net Architecture Value (NAV), that can be used in early stage conceptual mission design and architecture trade studies. We propose that useful data of adequate quality, obtained over regions of interest, acquired by a system over its lifetime can be used as a proxy measure of value. We demonstrate the application of this approach for a distributed space mission.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899126","Mission Value;Architecture Value;Science Return;Value of Information;Distributed Space Mission;Graceful Degradation;Space Systems Architecture","Space vehicles;Earth;Space missions;Extraterrestrial measurements;Orbits;Instruments","aerospace computing;data acquisition;remote sensing;space vehicles","new earth observation missions;multiple spacecraft;novel observing strategies;multiplatform systems;multispectral data acquisition;high revisit frequencies;architectural choices;distributed systems;early stage conceptual mission design;architecture trade studies;distributed space mission;system architecture trade-studies","","2","","14","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Geospatial 2D and 3D object-based classification and 3D reconstruction of ISO-containers depicted in a LiDAR data set and aerial imagery of a harbor","D. Tiede; S. d'Oleire-Oltmanns; A. Baraldi","Department of Geoinformatics - Z GIS, University of Salzburg, Austria; Department of Geoinformatics - Z GIS, University of Salzburg, Austria; Department of Geoinformatics - Z GIS, University of Salzburg, Austria","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","4181","4184","Within the 2015 IEEE GRSS Data Fusion Contest, an extremely high-resolution 3D LiDAR point cloud of a harbor test site must be “fused” with a 2D multi-spectral aerial image, featuring no radiometric calibration metadata file, of the same surface area. In this scenario we propose an innovative geospatial 2D and 3D object-based classification system, capable of counting instances of two populations of ISO-containers, whose standard dimensions are known a priori based on the ISO 668 - Series 1 freight containers documentation, detected in the 2D and 3D datasets at hand. The degree of novelty of the proposed classification system is twofold. First, it combines inductive (bottom-up, data-driven) and deductive (top-down, prior knowledge-based) inference mechanisms, where the latter initializes the former in a hybrid inference framework. Second, it is provided with feedback loops, which increase its robustness to changes in input data and augment its degree of automation. The geospatial outcome consists of tangible vector objects, which allow estimation of statistics per container together with a detailed reconstruction of the 3D scene in a geographic information system.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326747","Color naming;object-based image analysis (OBIA);hybrid inference;inductive data learning;prior knowledge","Containers;Three-dimensional displays;Image color analysis;Laser radar;Image segmentation;Geospatial analysis;Data integration","feedback;geographic information systems;geophysical image processing;image classification;image reconstruction;optical radar;remote sensing by laser beam;sensor fusion","geographic information system;feedback loop;freight container documentation;radiometric calibration metadata file;2D multispectral aerial image;harbor test site;3D high resolution LiDAR point cloud;IEEE GRSS data fusion contest;AD 2015;aerial imagery;LiDAR dataset;3D ISO-container reconstruction;3D geospatial object-based classification;2D geospatial object-based classification","","1","","7","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Fractional order variational pan-sharpening","P. Liu; L. Xiao; S. Tang; L. Sun","School of Computer Science and Engineering, Nanjing University of Science and Technology, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, China; College of Information and Communication Engineering, Sungkyunkwan University, Korea","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","2602","2605","In this paper, we propose a new fractional order variational method for pan-sharpening, which aims to obtain a high resolution multi-spectral (MS) image from a low resolution MS image and a high resolution panchromatic (PAN) image. On one hand, we use the data generative constraint for preserving the spectral information. More specifically, on the other hand, we exploit the fractional order gradient feature consistence between the high resolution MS image and PAN image for preserving the spatial information. Based on these assumptions, a new fractional order variational model is proposed and an efficient algorithm is designed to solve the proposed model. Experimental results show that the proposed method outperforms various well-known pan-sharpening methods in terms of higher spatial and spectral qualities.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729672","Pan-sharpening;variational methods;fractional order gradient feature","Spatial resolution;Digital TV;Distortion;Image edge detection;Algorithm design and analysis;Geometry","hyperspectral imaging;image processing;remote sensing","fractional order variational pansharpening method;high-resolution multispectral image;low-resolution multispectral image;high-resolution panchromatic image;fractional order gradient feature","","1","","14","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"From Supervised to Unsupervised Learning for Land Cover Analysis of Sentinel-2 Multispectral Images","J. Saha; Y. Khanna; J. Mukhopadhyay; S. Aikat","Indian Institute of Technology, Kharagpur; Indian Institute of Technology, Kharagpur; Indian Institute of Technology, Kharagpur; Indian Institute of Technology, Kharagpur","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1965","1968","Sentinel-2 provides a large volume of the multi-spectral multi-resolution dataset. Training deep convolutional architecture with such a dataset is still a challenging task in land cover classification due to the absence of ground truth. Also, the selection of appropriate deep architecture for handling the Sentinel-2 dataset is another challenging task. In this paper, we propose a convolutional neural network (CNN) architecture to extract the information from various combinations of bands in Sentinel-2 imagery. We use a loss function, proposed in an earlier work, to train our model in an unsupervised manner. Recent advances in deep learning allow for transferring knowledge from one data set to another. Thus, in our study, we aim at analyzing the “transfer learning” capabilities of our proposed network to land cover classification in Sentinel-2 images. Pre-trained weights of a deep neural architecture, which is trained with very high-resolution optical satellite imagery from Aviris is transferred to a network of almost similar architecture for processing Sentinel-2 data. We used Salinas, a publicly available hyper-spectral dataset, to train this architecture in a supervised fashion and, finally, use transfer learning and fine-tuning on the architecture handling Sentinel-2 data for clustering. Experiments show that bands of 60m resolution have a positive combining effect with bands of 20m resolution for segregating waterbody, urban settlement, and tree canopies distinctly.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323985","Convolutional neural network;Land-cover classification;Clustering;Aviris Hyperspectral images;Sentinel-2 Multispectral Images","Feature extraction;Vegetation;Hyperspectral imaging;Image segmentation;Convolutional neural networks;Convolution;Task analysis","geophysical image processing;geophysical signal processing;geophysical techniques;image classification;image resolution;image segmentation;image sensors;land cover;land use;learning (artificial intelligence);neural nets;remote sensing;terrain mapping;unsupervised learning","unsupervised learning;land cover analysis;Sentinel-2 multispectral images;multispectral multiresolution dataset;deep convolutional architecture;land cover classification;Sentinel-2 dataset;convolutional neural network architecture;Sentinel-2 imagery;unsupervised manner;deep learning;transfer learning capabilities;pre-trained weights;deep neural architecture;high-resolution optical satellite imagery;Sentinel-2 data;hyper-spectral dataset","","1","","6","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Innovative Multi Pcnn Based Network for Green Area Monitoring - Identification and Description of Nearly Indistinguishable Areas - In Hyperspectral Satellite Images","S. -. V. Carata; M. -G. Constantin; V. Ghenescu; M. Chindea; M. Ghenescu",Institute of Space Science; University Politehnica of Bucharest; Institute of Space Science; UTI Grup; Institute of Space Science,"IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","2639","2642","The paper presents an original neural network approach for region of interest detection and classification in multi-spectral satellite images. The proposed method uses a sequence of Pulse Coupled Neural Networks that identifies plausible regions of interest. These regions are passed to a dimension reduction algorithm, Principle Component Analysis, in order to generate the input data for a Support Vector Machine classifier, that validates the data. The algorithm's parameters are optimized using a Genetic Algorithm. The algorithm is designed to distinguish regions that are extremely similar, such as parks in a city that has entire districts made up of houses with yards. The algorithm has been tested on images provided by the Sentinel-2 satellite, and it proved that it can recall 76.85% of the pixels marked as park in the ground truth data, which was obtained from Open Street Map.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518138","Pulse Coupled Neural Network (PCNN);Principle Component Analysis (PCA);Support Vector Machine (SVM);Genetic Algorithm (GA)","Genetic algorithms;Satellites;Support vector machines;Neural networks;Urban areas;Training;Prediction algorithms","feature extraction;genetic algorithms;geophysical image processing;image classification;image segmentation;neural nets;remote sensing;support vector machines","ground truth data;Sentinel-2 satellite;Genetic Algorithm;Support Vector Machine classifier;Principle Component Analysis;dimension reduction algorithm;plausible regions;Pulse Coupled Neural Networks;multispectral satellite images;classification;original neural network approach;hyperspectral satellite images;green area monitoring - identification;innovative multipcnn","","1","","15","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Exploring the Fusion of Sentinel-1 SAR and Sentinel-2 MSI Data for Built-Up Area Mapping Using Deep Learning","S. Hafner; Y. Ban; A. Nascetti","Division of Geoinformatics, KTH Royal Institute of Technology; Division of Geoinformatics, KTH Royal Institute of Technology; Division of Geoinformatics, KTH Royal Institute of Technology","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","4720","4723","This research explores the potential of combining Sentinel-1 C-band Synthetic Aperture Radar (SAR) and Sentinel-2 MultiSpectral Instrument (MSI) data for Built-Up Area (BUA) mapping using deep learning. A lightweight U-Net model is trained using openly available building footprint reference data in North America and tested in four cities across three additional continents. The best test performance in terms of F1 score was achieved by the joint use of SAR and multispectral data (0.676), followed by multi-spectral (0.611) and SAR data (0.601). The developed fusion approach is particularly promising to distinguish BUA in low-density residential neighborhoods. Furthermore, our fusion approach compares favorably to the state-of-the-art in BUA mapping in the selected cities. However, associated with the diverse characteristics of human settlements around the world, considerable differences in accuracy among the test cities were observed. This indicates the need for more sophisticated fusion techniques to improve CNN model generalization and for adding more diverse training data.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553448","Swedish National Space Agency; ESA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553448","Sentinel-1;Sentinel-2;Built-up area mapping;data fusion;deep learning","Deep learning;Instruments;Urban areas;Training data;Optical imaging;Data models;Internet","convolutional neural nets;geophysical image processing;image fusion;learning (artificial intelligence);radar imaging;remote sensing by radar;synthetic aperture radar","Sentinel-1 SAR;Sentinel-2 MSI data;Built-Up Area mapping;deep learning;SAR data;BUA mapping;fusion techniques;diverse training data;building footprint reference data;Sentinel-1 C-band synthetic aperture radar;lightweight U-Net model;Sentinel-2 multispectral instrument data;F1 score","","1","","8","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Validation of Fine Resolution Land-Surface Energy Fluxes Derived with Combined Sentinel-2 and Sentinel-3 Observations","R. Guzinski; H. Nieto; T. El-Madany; M. Migliavacca; A. Carrara","European Space Agency, ESA Centre for Earth Observation (ESRIN), Frascati (Roma), ITALY; Efficient Use of Water Programme, Research & Technology Food & Agriculture IRTA, Lleida, SPAIN; Max Planck Institute for Biogeochemistry, Jena, GERMANY; Max Planck Institute for Biogeochemistry, Jena, GERMANY; Centro de Estudios Ambientales del Mediterrneo (CEAM), Valencia, SPAIN","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","8711","8714","A methodology for deriving land-surface energy fluxes estimated with the use of Sentinel-2 and Sentinel-3 observations is validated in a savannah landscape in central Spain. The fluxes are derived at two spatial resolution: fine (20 m) and coarse (around 1 km). At both resolutions the thermal observations from Sea and Land Surface Temperature Radiometer (SLSTR) on Sentinel-3 and optical observations from Multi-Spectral Instrument (MSI) on Sentinel-2 are used within a Two-Source Energy Balance (TSEB) modelling scheme. For the fine resolution estimates, the thermal observations acquired by SLSTR at around 1 km resolution are sharpened using high-resolution (20 m) optical observations taken by MSI and a machine learning algorithm. The results indicate that it is possible to derive fluxes with similar accuracy at both spatial scales, while obtaining more detailed separation of fluxes originating from individual landscape features at the fine scale.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518229","land-surface energy fluxes;thermal sharpening;machine learning;Sentinel-2;Sentinel-3","Spatial resolution;Land surface temperature;Atmospheric modeling;Energy resolution;Heating systems;Ocean temperature;Temperature measurement","atmospheric techniques;geophysical image processing;land surface temperature;radiometers;remote sensing","Sentinel-2 observations;Sea and Land Surface Temperature Radiometer;Land-Surface Energy fluxes;machine learning algorithm;high-resolution optical observations;fine resolution estimates;Two-Source Energy Balance modelling scheme;thermal observations;spatial resolution;Sentinel-3 observations;size 20.0 m;size 1.0 km","","1","","12","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Mission Overview of the Advanced Optical Satellite (Alos-3)","T. Tadono; Y. Mizukami; A. Oka; H. Watarai; M. Sagisaka",Japan Aerospace Exploration Agency (JAXA); Japan Aerospace Exploration Agency (JAXA); Japan Aerospace Exploration Agency (JAXA); Japan Aerospace Exploration Agency (JAXA); Japan Aerospace Exploration Agency (JAXA),"IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","5883","5886","The ""Advanced Optical Satellite"" (nicknamed ""ALOS-3"") is the next high-resolution optical mission as a successor of the Advanced Land Observing Satellite (ALOS) in Japan Aerospace Exploration Agency (JAXA), and now conducting the Critical Design Review (CDR) phase. The mission objecttives of ALOS-3 are (1) to contribute safe and secure social including provisions for natural disasters, and (2) to create and update geo-spatial information. The ""wide-swath and high-resolution optical imager"" is designed to be achieved the missions, which consists of the panchromatic band with 0.8 m ground sampling distance (GSD) and multi-spectral six bands with 3.2 m GSD, and the observation swath width is 70 km at nadir. In this study, mission overview, and planned- and expected-products of ALOS-3 are introduced.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899187","ALOS-3;optical;image processing","Optical imaging;Optical sensors;Satellites;Satellite broadcasting;Sea measurements;Instruments;Standards","artificial satellites;geophysical equipment;geophysical image processing;image resolution;remote sensing","Advanced Land Observing Satellite;Japan Aerospace Exploration Agency;Critical Design Review phase;mission objecttives;ALOS-3;high-resolution optical imager;mission overview;high-resolution optical mission;ground sampling distance;distance 70.0 km;distance 3.2 m;distance 0.8 m","","1","","5","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Automatic Road Delineation Using Deep Neural Network","M. Singh; M. Shekher; N. Jacob; Radhadevi; V. R. Venkataraman","Department of Space Government of India, Advanced Data Processing Research Institute (ADRIN), Secunderabad; Department of Space Government of India, Advanced Data Processing Research Institute (ADRIN), Secunderabad; Department of Space Government of India, Advanced Data Processing Research Institute (ADRIN), Secunderabad; Department of Space Government of India, Advanced Data Processing Research Institute (ADRIN), Secunderabad; Department of Space Government of India, Advanced Data Processing Research Institute (ADRIN), Secunderabad","2020 IEEE India Geoscience and Remote Sensing Symposium (InGARSS)","23 Feb 2021","2020","","","94","97","Road extraction from high resolution satellite imagery has been a challenging task. The problem has been attempted by many people employing different methods and techniques and many have been able to solve it to a large extent. The novelty of this paper is to reach the end goal of providing a final product which can be used to generate semantically meaningful applications like vehicle detection, vehicle counting and determining the size of vehicle on the road. In this paper, an approach of road delineation in high resolution multi-spectral satellite imagery is proposed using Deep Neural Networks to generate a road binary mask. The binary mask comprising of objects is further processed with image processing techniques. Whereas to reduce the non-road objects, which are classified as road, object attributes such as object size and shape are used. The refined objects are converted into a shape file of road. Various challenges faced along the way and some useful observations and algorithmic strategies to achieve the end goal have been discussed in this paper.","","978-1-7281-3114-6","10.1109/InGARSS48198.2020.9358928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9358928","Road Delineation;Deep Neural Networks;High Resolution Satellite Imagery;Vector Shape File","Satellites;Image resolution;Shape;Roads;Vehicle detection;Neural networks;Task analysis","convolutional neural nets;deep learning (artificial intelligence);feature extraction;geophysical image processing;image resolution;object detection;remote sensing;roads;traffic engineering computing","automatic road delineation;road extraction;high resolution satellite imagery;vehicle detection;vehicle counting;high resolution multispectral satellite imagery;deep neural networks;road binary mask;image processing techniques;nonroad objects","","","","6","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"3CAT-3/MOTS, an Experimental Nanosatellite for Multispectral and GNSS-R Earth Observation: Airborne Optical and GNSS-R Campaign","J. Castellvi-Esturi; A. Camps; J. Corbera; R. Onrubia; R. Alamús; D. Pascual; J. Querol; H. Park","Institut Cartogràfic i Geològic de Catalunya, Barcelona, Spain; Departament de Teoria del Senyal i Comunicacions, CommSensLab, Barcelona, Spain; Institut Cartogràfic i Geològic de Catalunya, Barcelona, Spain; Departament de Teoria del Senyal i Comunicacions, CommSensLab, Barcelona, Spain; Institut Cartogràfic i Geològic de Catalunya, Barcelona, Spain; Departament de Teoria del Senyal i Comunicacions, CommSensLab, Barcelona, Spain; Departament de Teoria del Senyal i Comunicacions, CommSensLab, Barcelona, Spain; Departament de Teoria del Senyal i Comunicacions, CommSensLab, Barcelona, Spain","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","1414","1417","The 3Cat-3/MOTS mission is a joint initiative between the Institut Cartogràfic i Geològic de Catalunya (ICGC) and the Universitat Politècnica de Catalunya-BarcelonaTech (UPC) to foster new and innovative technologies on Earth Observation (EO) based on the data fusion of Global Navigation Satellite Systems Reflectometry (GNSS-R) and optical payloads on a 6U CubeSat platform. The final objective of the mission is to provide soil moisture mapping through the GNSS-R payload and improve its resolution by data fusion with the multi-spectral optical data acquired. This technique has been successfully applied to SMOS, but never performed from a 6U CubeSat carrying both payloads. An airborne optical and GNSS-R field experiment has been carried out to test/develop the algorithm and to analyze the results both separately (GNSS-R + optical data) and as a soil moisture product, once performed the data fusion.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518216","","Soil moisture;Radiometry;Instruments;Optical reflection;Integrated optics;Temperature measurement;Global navigation satellite system","hydrological techniques;reflectometry;remote sensing;satellite navigation;sensor fusion;soil","experimental nanosatellite;GNSS-R Earth Observation;GNSS-R campaign;innovative technologies;data fusion;optical payloads;6U CubeSat platform;soil moisture mapping;GNSS-R payload;multispectral optical data;Universitat Politecnica de Catalunya-BarcelonaTech;Institut Cartografic i Geologic de Catalunya;3 Cat-3-MOTS mission;airborne optical experiment;GNSS-R field experiment;Global Navigation Satellite Systems Reflectometry","","","","9","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"On the Characterization of Sen2Like Surface Reflectance Data Harmonization and Fusion Processes","S. Saunier; V. Debaecker; J. Louis; K. Garcia; C. Cuny; E. G. Cadau; V. Boccia; F. Gascon","Telespazio, France; Telespazio, France; Telespazio, France; Telespazio, France; Telespazio, France; Serco SpA c/o ESRIN, Italy; European Space Agency, ESRIN, Italy; European Space Agency, ESRIN, Italy","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","4636","4639","There are growing and evolving expectations from the Earth Observation (EO) Community for merging an increasing number of input data streams recorded with the various space based Multi-Spectral (MS) High Resolution (HR) EO mission instruments. The various agencies and industries are now delivering Analysis Ready Data (ARD) aiming at stacking together multi source data. One critical objective of ARD is to enable the monitoring of rapid and subtle changes. This category of applications sets some strong requirements regarding the quality of the surface reflectance harmonization in the time series. In the context of Sentinel-2 / Landsat 8, this paper proposes a comprehensive analysis of the Sen2Like processing. It shows that it is possible to increase significantly the geometric coregistration accuracy and to ensure an appropriate cross calibration. However, some issues persist and are due to directional effects. These are partially corrected with the current approach but remain a major source of noise in time series.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553037","Analysis Ready Data;Sentinel-2;Landsat- 8;Sen2Like;processing;harmonization;validation","Reflectivity;Earth;Space missions;Time series analysis;Stacking;Software algorithms;Production","calibration;geophysical image processing;image fusion;image resolution;remote sensing;sensor fusion;time series","input data streams;space based MultiSpectral;Analysis Ready Data;multisource data;rapid changes;strong requirements;surface reflectance harmonization;time series;Sentinel-2;Sen2Like;surface reflectance data harmonization;fusion processes;Earth Observation Community;EO","","","","19","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Development of a Cooled Infrared Camera for Measuring Volcanic SO2 Gas Concentration and Temperature Distributions","T. Jitsufuchi","National Research Institute for Earth Science and Disaster Resilience, Tsukuba, Ibaraki, Japan","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","7860","7863","The volcanic surface phenomena (e.g., ground-surface brightness temperature distribution, volcanic gases, and volcanic ashes) provide useful information to evaluate the current status of volcanic activities. We are planning to develop a new observation device called a surface phenomena imaging camera with a cooled longwave infrared camera (SPIC-C (LWIR)). The SPIC-C (LWIR) is a multiband camera (multi-spectral camera) system used to measure the temperature and SO2 gas concentration. To realize the SPIC-C (LWIR), we prototype cooled LWIR camera (SPIC-C (LWIR) Camera 3) by adopting a VGA ($640\times 512$) cooled T2SL sensor head unit. The performance evaluations indicate that this system can achieve a NETD of approximately 0.1 K. The evaluation of SO2 measurement accuracy by simulation using the same SO2 gas concentration distribution conditions as our original airborne hyperspectral sensor's (ARTS) actual observation on Apr. 8 2008 reveals that the developed cooled LWIR camera can detect SO2 gas concentration distributions ranging approximately 0.2 - 0.4 ppmv in the background conditions at a temperature of 50 °C with errors of ±0.1 ppmv. These results indicate that the developed cooled LWIR camera can be a sensor head unit for the prototype SPIC-C (LWIR) system.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553531","Ministry of Education, Culture, Sports, Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553531","Cooled longwave infrared camera;Volcanic SO2 gas concentration distribution;Thermal distribution;Volcano;Airborne imager","Temperature measurement;Temperature sensors;Temperature distribution;Head;Volcanic ash;Volcanic activity;Subspace constraints","atmospheric composition;cameras;cooling;focal planes;geophysical equipment;image sensors;infrared detectors;infrared imaging;remote sensing;volcanology","multispectral camera;LWIR camera;T2SL sensor head unit;SO2 measurement accuracy;SO2 gas concentration distribution conditions;original airborne hyperspectral sensor;prototype SPIC-C system;cooled infrared Camera;Measuring Volcanic SO2 Gas Concentration;volcanic surface phenomena;ground-surface brightness temperature distribution;volcanic gases;volcanic ashes;volcanic activities;cooled longwave infrared camera;multiband camera;SPIC-C;airborne hyperspectral sensor","","","","6","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"UPSNet: Unsupervised Pan-Sharpening Network With Registration Learning Between Panchromatic and Multi-Spectral Images","S. Seo; J. -S. Choi; J. Lee; H. -H. Kim; D. Seo; J. Jeong; M. Kim","Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Samsung Advanced Institute of Technology, Suwon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Aerospace Research Institute, Daejeon, South Korea; School of Electrical Engineering, Korea Aerospace Research Institute, Daejeon, South Korea; School of Electrical Engineering, Korea Aerospace Research Institute, Daejeon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Access","18 Nov 2020","2020","8","","201199","201217","Recent advances in deep learning have shown impressive performances for pan-sharpening. Pan-sharpening is the task of enhancing the spatial resolution of a multi-spectral (MS) image by exploiting the high-frequency information of its corresponding panchromatic (PAN) image. Many deep-learning-based pan-sharpening methods have been developed recently, surpassing the performances of traditional pan-sharpening approaches. However, most of them are trained in lower scales using misaligned PAN-MS training pairs, which has led to undesired artifacts and unsatisfying visual quality. In this paper, we propose an unsupervised learning framework with registration learning for pan-sharpening, called UPSNet. UPSNet can be effectively trained in the original scales, and implicitly learns the registration between PAN and MS images without any dedicatedly designed registration module involved. Additionally, we design two novel loss functions for training UPSNet: a guided-filter-based color loss between network outputs and aligned MS targets; and a dual-gradient detail loss between network outputs and PAN inputs. Extensive experimental results show that our UPSNet can generate pan-sharpened images with remarkable improvements in terms of visual quality and registration, compared to the state-of-the-art methods.","2169-3536","","10.1109/ACCESS.2020.3035802","Korea Aerospace Research Institute (KARI) under the project of ‘Super-Resolution and PAN Colorization for Satellite Imagery’; KAIST; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9248047","Pan-sharpening;pan-colorization;image restoration;deep-learning;convolutional neural networks (CNN);satellite imagery","Training;Image color analysis;Satellites;Spatial resolution;Correlation;Unsupervised learning;Testing","geophysical image processing;image colour analysis;image registration;image resolution;neural nets;remote sensing;unsupervised learning","registration learning;network outputs;PAN inputs;unsupervised pan-sharpening network;multispectral image spatial resolution;panchromatic image;deep-learning-based pan-sharpening methods;misaligned PAN-MS training pairs;unsupervised learning framework;high-frequency information;guided-filter-based color loss;aligned MS targets;dual-gradient detail loss;UPSNet training","","11","","47","CCBY","4 Nov 2020","","","IEEE","IEEE Journals"
"DynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation","A. Toker; L. Kondmann; M. Weber; M. Eisenberger; A. Camero; J. Hu; A. P. Hoderlein; Ç. Şenaras; T. Davis; D. Cremers; G. Marchisio; X. X. Zhu; L. Leal-Taixé",Technical University of Munich; German Aerospace Center; Technical University of Munich; Technical University of Munich; German Aerospace Center; German Aerospace Center; Technical University of Munich; Planet Labs; Planet Labs; Technical University of Munich; Planet Labs; German Aerospace Center; Technical University of Munich,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","21126","21135","Earth observation is a fundamental tool for monitoring the evolution of land use in specific areas of interest. Observing and precisely defining change, in this context, requires both time-series data and pixel-wise segmentations. To that end, we propose the DynamicEarthNet dataset that consists of daily, multi-spectral satellite observations of 75 selected areas of interest distributed over the globe with imagery from Planet Labs. These observations are paired with pixel-wise monthly semantic segmentation labels of 7 land use and land cover (LULC) classes. DynamicEarthNet is the first dataset that provides this unique combination of daily measurements and high-quality labels. In our experiments, we compare several established baselines that either utilize the daily observations as additional training data (semi-supervised learning) or multiple observations at once (spatio-temporal learning) as a point of reference for future research. Finally, we propose a new evaluation metric SCS that addresses the specific challenges associated with time-series semantic change segmentation. The data is available at: https://mediatum.ub.tum.de/1650201.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.02048","Humboldt Foundation(grant numbers:ZT-I-PF-5-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879359","Datasets and evaluation","Image segmentation;Satellites;Protocols;Annotations;Semantics;Training data;Semisupervised learning","geophysical image processing;geophysical signal processing;image classification;image segmentation;land cover;learning (artificial intelligence);remote sensing;time series","daily multispectral satellite dataset;earth observation;observing change;precisely defining change;time-series data;pixel-wise segmentations;DynamicEarthNet dataset;multispectral satellite observations;Planet Labs;pixel-wise monthly semantic segmentation labels;7 land use;land cover classes;daily measurements;high-quality labels;daily observations;additional training data;semisupervised learning;time-series semantic change segmentation","","3","","48","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Shape from Thermal Radiation: Passive Ranging Using Multi-spectral LWIR Measurements","Y. Nagase; T. Kushida; K. Tanaka; T. Funatomi; Y. Mukaigawa","Nara Institute of Science and Technology (NAIST), Japan; Nara Institute of Science and Technology (NAIST), Japan; Ritsumeikan University, Japan; Nara Institute of Science and Technology (NAIST), Japan; Nara Institute of Science and Technology (NAIST), Japan","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","12651","12661","In this paper, we propose a new cue of depth sensing using thermal radiation. Our method realizes passive, texture independent, far range, and dark scene applicability, which can broaden the depth sensing subjects. A key ob-servation is that thermal radiation is attenuated by the air and is wavelength dependent. By modeling the wavelength-dependent attenuation by the air and building a multi-spectral LWIR measurement system, we can jointly estimate the depth, temperature, and emissivity of the target. We analytically show the capability of the thermal radiation cue and show the effectiveness of the method in real-world scenes using an imaging system with a few bandpass filters.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01233","JST(grant numbers:JP-MJCR1764,JPMJSC2003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9878826","Physics-based vision and shape-from-X; Computational photography","Temperature measurement;Temperature sensors;Shape;Atmospheric modeling;Wavelength measurement;Shape measurement;Attenuation","band-pass filters;calibration;image texture;infrared imaging;reflectivity;remote sensing","depth sensing subjects;key ob-servation;wavelength-dependent attenuation;multispectral LWIR measurement system;thermal radiation cue;passive ranging;multispectral LWIR measurements;dark scene applicability","","","","67","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"On Variational Model in Sobolev-Orlicz Spaces for Spatiotemporal Interpolation of Multi-Spectral Satellite Images","P. Kogut; O. Kupenko; R. Manzo; C. Pipino","Department of Differential Equations, Oles Honchar Dnipro National University EOS Data Analytics Ukraine, Dnipro, Ukraine; Department of System Analysis and Control, NTU ”Dnipro University of Technology”, Dnipro, Ukraine; Department of Information Engineering, Electrical Engineering and Applied Mathematics, University of Salerno, Italy; Dipartimento di Scienze Aziendali ȃ Management and Innovation Systems, University of Salerno, Italy","2022 IEEE 3rd International Conference on System Analysis & Intelligent Computing (SAIC)","25 Oct 2022","2022","","","1","6","We propose a new two-level variational model in Sobolev-Orlicz spaces with non-standard growth conditions of the objective functional and discuss its applications to the spatiotemporal interpolation of multi-spectral satellite images. At the first level, we deal with the temporal interpolation problem that can be cast as a state constrained optimal control problem for anisotropic convection-diffusion equation, whereas at the second level we solve a constrained minimization problem with a nonstandard growth energy functional that lives in variable Sobolev-Orlicz spaces. The characteristic feature of the proposed model is the fact that the variable exponent, which is associated with non-standard growth in spatial interpolation problem, is unknown a priori and it depends on the solution of the first-level optimal control problem. It makes this spatiotemporal interpolation problem rather challenging. In view of this, we discuss the consistency of the proposed model, study the existence of optimal solutions, and derive the corresponding optimality systems. In particular, we apply this approach to the well-known prediction problem of the Daily MODIS Surface Reflectance at the Landsat-Like Resolution.","","979-8-3503-9674-4","10.1109/SAIC57818.2022.9922923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9922923","Data fusion;variational approach;time series;image reconstruction;spatiotemporal interpolation;constrained minimization problems;Sobolev-Orlicz space","Interpolation;Surface reconstruction;Satellites;Computational modeling;Optimal control;Aerospace electronics;Minimization","convection;diffusion;elliptic equations;interpolation;minimisation;optimal control;optimisation;remote sensing","constrained minimization problem;nonstandard growth energy;variable Sobolev-Orlicz spaces;spatial interpolation problem;first-level optimal control problem;spatiotemporal interpolation problem;optimal solutions;corresponding optimality systems;prediction problem;multispectral satellite images;two-level variational model;nonstandard growth conditions;temporal interpolation problem;anisotropic convection-diffusion equation","","","","14","IEEE","25 Oct 2022","","","IEEE","IEEE Conferences"
"Multispectral Snapshot Imagers Onboard Small Satellite Formations for Multi-Angular Remote Sensing","S. Nag; T. Hewagama; G. T. Georgiev; B. Pasquale; S. Aslam; C. K. Gatebe","Bay Area Environmental Research Institute, Petaluma, CA, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; Instrument Systems and Technology Division, NASA Goddard Space Flight Center, Greenbelt, MD, USA; Solar System Exploration Division, NASA Goddard Space Flight Center, Greenbelt, MD, USA; Universities Space Research Association, Columbia, MD, USA","IEEE Sensors Journal","21 Jul 2017","2017","17","16","5252","5268","Multispectral snapshot imagers are capable of producing 2-D spatial images with a single exposure at selected, numerous wavelengths using the same camera, therefore, operate differently from push broom or whiskbroom imagers. They are payloads of choice in multi-angular, multi-spectral imaging missions that use small satellites flying in controlled formation, to retrieve Earth science measurements dependent on the target's bidirectional reflectance-distribution function. Narrow fields of view are needed to capture images with moderate spatial resolution. This paper quantifies the dependencies of the imager's optical system, spectral elements, and camera on the requirements of the formation mission and their impact on performance metrics, such as spectral range, swath, and signal-to-noise ratio (SNR). All variables and metrics have been generated from a comprehensive, payload design tool. The baseline optical parameters selected (a diameter of 7 cm, a focal length of 10.5 cm, a pixel size of 20 μm, and a field of view of 1.15°) and snapshot imaging technologies are available. The spectral components shortlisted were waveguide spectrometers, acoustooptic tunable filters (AOTF), electronically actuated Fabry-Perot interferometers, and integral field spectrographs. Qualitative evaluation favored AOTFs, because of their low weight, small size, and flight heritage. Quantitative analysis showed that the waveguide spectrometers perform better in terms of achievable swath (10-90 km) and SNR (>20) for 86 wavebands, but the data volume generated will need very high bandwidth communication to downlink. AOTFs meet the external data volume caps well as the minimum spectral (wavebands) and radiometric (SNR) requirements, therefore, are found to be currently feasible and design changes to improve swath suggested.","1558-1748","","10.1109/JSEN.2017.2717384","Schlumberger Faculty for the Future Fellowship; MIT Zakhartchenko Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953994","Small satellites;BRDF;imager design","Satellites;Payloads;Satellite broadcasting;Imaging;Measurement;NASA;Instruments","acousto-optical filters;angular measurement;artificial satellites;cameras;Fabry-Perot interferometers;image sensors;interference spectrometers;optical sensors;optical waveguide filters;remote sensing;sensor fusion","multispectral snapshot imaging technology;onboard small satellite formation;multiangular remote sensing;2D spatial imaging;camera;push broom imager;whiskbroom imager;multiangular multispectral imaging mission;Earth science measurement;bidirectional reflectance-distribution function;image resolution;optical system;spectral element;signal to-noise ratio;SNR;payload design tool;baseline optical parameter;waveguide spectrometer;acoustooptic tunable filter;AOTF;electronically actuated Fabry-Perot interferometer;integral field spectrograph;radiometry;size 7 cm;size 10.5 cm;size 20 mum;distance 10 km to 90 km","","14","","59","IEEE","20 Jun 2017","","","IEEE","IEEE Journals"
"Pansharpening via Super-Resolution Iterative Residual Network With a Cross-Scale Learning Strategy","S. Chen; H. Qi; K. Nan","Sichuan Highway Planning, Survey, Design and Research Institute Ltd., Chengdu, China; Faculty of Geosciences and Environmental Engineering, Southwest Jiaotong University, Chengdu, China; Sichuan Highway Planning, Survey, Design and Research Institute Ltd., Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","8 Mar 2022","2022","60","","1","16","Pansharpening exploits the high-spatial-resolution panchromatic (HR PAN) images to restore the spatial resolution of the corresponding low-spatial-resolution multi-spectral (LR MS) image, producing a fused image and high-spatial-resolution multi-spectral (HR MS) image. Recently, many methods based on convolutional neural networks (CNNs) have been put forth for the pansharpening task, but most of them still have some limitations, such as the simple stacked convolutional architectures resulting in information distortion, and some scale-related problems caused by the supervised learning strategy. Therefore, we propose a method named super-resolution iterative residual (SRIR) network with a cross-scale (CS) learning strategy to overcome these drawbacks. Regarding the SRIR we propose, we design an upsampling network based on a sub-pixel convolution structure to replace the traditional upsampling pre-processing. We adopt the iterative networks framework and design a new spatial information injection module to continuously inject spatial and spectral features into the network, which can enhance the information flow and transmission. We produce approximate HR MS with a guidance filter and map the residual information between the approximate HR MS and the reference HR MS by SRIR to enhance the quality of fused images. Regarding the CS we propose, we train the network at degraded scale, which is named deep prior, and then design a finer-scale unsupervised fine-tuning loss function to refine the network parameters with deep priors, to overcome the scale effect. Experiments show the following: 1) SRIR-based pansharpening method can obtain the best result at the degraded scale; 2) the scale-effect is negatively correlated with the depth of the network, meaning that the deeper the network, the stronger the robustness to scale effect; 3) the CS learning strategy can widely improve the performance of CNNs-based pansharpening methods in full-resolution; and 4) our method can produce better results at full-resolution scale than all the other traditional and deep learning methods.","1558-0644","","10.1109/TGRS.2021.3138096","Key Research and Development Projects in Sichuan, China(grant numbers:2021YFS0334); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9662300","A super-resolution iterative residual (SRIR) network;cross-scale (CS) learning strategy;finer-scale unsupervised fine-tuning loss function;pansharpening","Pansharpening;Supervised learning;Superresolution;Spatial resolution;Residual neural networks;Convolutional neural networks;Convolution","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image enhancement;image fusion;image resolution;image sampling;iterative methods;remote sensing","super-resolution iterative residual network;cross-scale learning strategy;high-spatial-resolution panchromatic images;low-spatial-resolution multispectral image;LR MS;image fusion;high-spatial-resolution multispectral image;convolutional neural networks;convolutional architectures;information distortion;supervised learning strategy;upsampling network;sub-pixel convolution structure;iterative networks framework;spatial information injection module;spatial features;spectral features;information flow;residual information;finer-scale unsupervised fine-tuning loss function;network parameters;CS learning strategy;CNNs-based pansharpening methods;full-resolution scale;deep learning methods;HR MS;SRIR-based pansharpening method;upsampling pre-processing","","","","61","IEEE","23 Dec 2021","","","IEEE","IEEE Journals"
"Classification of Hyperspectral Image for Property Analysis","A. Verma; K. Gupta","Department of Computer Science and Engineering, Amity University Uttar Pradesh, Noida, India; Department of Computer Science and Engineering, Amity University Uttar Pradesh, Noida, India","2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS)","10 Mar 2019","2018","","","1","4","For the detection of the sea ice SAR algorithm has been utilized in order to avoid any damage to ship. This will identify whether there is any obstruction in the way of ice or not so that ship does not strike with ice. The desired results are obtained when SAR algorithm is connected on RADARl imagery data. They also studied the algorithm for the segmentation of ice known as pixel based segmentation which helps to differentiate ice based on its properties. Large number of methods has been utilized for multi temporal segmentation from the MODIS data which is known as TempoSeg strategy for multiyear sea ice. Synthetic Aperture Radar utilized the RADARSATl imagery data in order to detect the ice of sea at different regions of the seas. With the help of Rl imagery data better outcomes are provided by the automated algorithm. In present work, the automated SAR algorithm is required to execute in order to detect sea ice.","","978-1-5386-2842-3","10.1109/ICCONS.2018.8663049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663049","Hyperspectral;multi-spectral;SAR;Image property","Hyperspectral imaging;Ice;Feature extraction;Image segmentation;Synthetic aperture radar","geophysical image processing;image segmentation;oceanographic techniques;radar imaging;remote sensing by radar;sea ice;synthetic aperture radar","automated SAR algorithm;hyperspectral image;property analysis;sea ice SAR algorithm;pixel based segmentation;multitemporal segmentation;MODIS data;multiyear sea ice;RADARSATl imagery data;Rl imagery data","","","","12","IEEE","10 Mar 2019","","","IEEE","IEEE Conferences"
"Geometric Validation Algorithms for DMSAT-1","H. Harikrishnan; A. A. AlMaazmi; A. Panthakkan; S. Almansoori; H. Alahmad","College of Engineering and IT, University of Dubai; Mohammed Bin Rashid Space Centre (MBRSC), Dubai, UAE; College of Engineering and IT, University of Dubai; Mohammed Bin Rashid Space Centre (MBRSC), Dubai, UAE; College of Engineering and IT, University of Dubai","2021 4th International Conference on Signal Processing and Information Security (ICSPIS)","27 Dec 2021","2021","","","21","24","DMSAT-1 (Dubai Municipality Satellite) is a high-performance small microsatellite designed to perform multi - spectral observations in visual and near-infrared bands for aerosol and greenhouse gas monitoring. DMSAT-1 has two independent imaging sensors (one with 0-degree polarization and the second with 90-degree polarization) each containing a linear polarizer. The polarizers are mounted perpendicularly. DMSAT-1 captures images in three bands-Blue, Red, and Near-Infrared. This paper puts forward customized algorithms for Mohammed Bin Rashid Space Centre (MBRSC), which are developed on Python for the geometric validation and tested on images captured by the primary instrument (polarimeters) on the DMSAT-1 microsatellite. Geometric validation includes the validation of Ground Sampling Distance and Band Alignment of the images. The proposed method validates the images across different bands as well as different polarizers and confirms that satellite images can be readily used.","","978-1-6654-3796-7","10.1109/ICSPIS53734.2021.9652418","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652418","Geometric Validation;DMSAT-1;Band Alignment;Ground Sampling Distance","Image sensors;Visualization;Greenhouse effect;Instruments;Small satellites;Signal processing algorithms;Information security","aerosols;artificial satellites;image sensors;polarimeters;remote sensing","high-performance small microsatellite;multi- spectral observations;aerosol;greenhouse gas monitoring;independent imaging sensors;linear polarizer;DMSAT-1 captures images;bands-Blue;Mohammed Bin Rashid Space Centre;DMSAT-1 microsatellite;different polarizers;satellite images;geometric validation algorithms;Dubai Municipality Satellite","","1","","8","IEEE","27 Dec 2021","","","IEEE","IEEE Conferences"
"Hyperspectral Image Compression and Super-Resolution Using Tensor Decomposition Learning","A. Aidini; M. Giannopoulos; A. Pentari; K. Fotiadou; P. Tsakalides","Department of Computer Science, University of Crete; Department of Computer Science, University of Crete; Department of Computer Science, University of Crete; Department of Computer Science, University of Crete; Department of Computer Science, University of Crete","2019 53rd Asilomar Conference on Signals, Systems, and Computers","30 Mar 2020","2019","","","1369","1373","As the field of remote sensing for Earth Observation is rapidly evolving, there is an increasing demand for developing suitable methods to store and transmit the massive amounts of the generated data. At the same time, as multiple sensors acquire observations with different dimensions, super-resolution methods come into play to unify the framework for upcoming statistical inference tasks. In this paper, we employ a tensor-based structuring of multi-spectral image data and we propose a low-rank tensor completion scheme for efficient image-content compression and recovery. To address the problem of low-resolution imagery, we further provide a robust algorithmic scheme for super-resolving satellite images, followed by a state-of-the-art convolutional neural network architecture serving the classification task of the employed images. Experimental analysis on real-world observations demonstrates the detrimental effects of image compression on classification, an issued successfully addressed by the proposed recovery and super-resolution schemes.","2576-2303","978-1-7281-4300-2","10.1109/IEEECONF44664.2019.9048735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9048735","Multi-Spectral Image Classification;Compression;Tensor Unfoldings;Super Resolution;Alternating Direction Method of Multipliers","Tensors;Image coding;Task analysis;Spatial resolution;Signal resolution","convolutional neural nets;data compression;geophysical image processing;geophysical techniques;hyperspectral imaging;image classification;image coding;image resolution;learning (artificial intelligence);remote sensing;tensors","hyperspectral image compression;remote sensing;Earth Observation;super-resolution methods;statistical inference tasks;multispectral image data;low-rank tensor completion scheme;low-resolution imagery;robust algorithmic scheme;super-resolving satellite images;super-resolution schemes;convolutional neural network architecture;image-content compression","","2","","18","IEEE","30 Mar 2020","","","IEEE","IEEE Conferences"
"Design of Short-Range S-band Radar Sensing System for Autonomous Object Classification","F. Turčinović; M. Erny; V. Zoričić; N. Poletan; M. Bosiljevac","Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia","2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)","15 Nov 2021","2021","","","17","21","Remote environmental and industrial sensing based on multi-spectral or radar imaging today plays an important role in ensuring sustainability and protection of natural resources, in saving time and energy in industry and agriculture, and in many other applications. Numerous examples of such systems exist which provide information like product quality to manufacturers, crops growth parameters to farmers or structural integrity details to civil engineers. With recent developments in electromagnetic millimetre-wave (mm-wave) technology and artificial intelligence implementation, short range mm-wave remote sensing is experiencing strong growth with the market dictating new applications with increasingly higher levels of system autonomy. The objective of this paper is to demonstrate methodology and hardware used in short-range radar sensing and use it to build-up a database of scattering images which will allow us the extraction of key signal parameters for particular objects and subsequently allow autonomous object classification using machine learning principles.","2623-8764","978-953-233-101-1","10.23919/MIPRO52101.2021.9596910","Croatian Science Foundation (HRZZ)(grant numbers:IP-2019-04-1064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9596910","short-range radar;FMCW radar;radar imaging;object classification","Charge coupled devices;Databases;Scattering;Terrain mapping;Radar imaging;Radar antennas;Sensors","feature extraction;geophysical image processing;image classification;learning (artificial intelligence);millimetre wave radar;radar imaging;remote sensing by radar","remote sensing;system autonomy;short-range radar sensing;scattering images;autonomous object classification;short-range s-band radar sensing system;remote environmental sensing;industrial sensing;multispectral imaging;radar imaging;sustainability;natural resources;agriculture;product quality;crops growth parameters;structural integrity details;artificial intelligence implementation;electromagnetic millimetre-wave technology;machine learning principles;short range mm-wave remote sensing","","","","29","","15 Nov 2021","","","IEEE","IEEE Conferences"
"Fusion of RADARSAT-2 imagery with LANDSAT-8 multispectral data for improving land cover classification performance using SVM","C. Sukawattanavijit; J. Chen","School of Electronics and Information Engineering, Beihang University Beijing, CHINA; School of Electronics and Information Engineering, Beihang University Beijing, CHINA","2015 IEEE 5th Asia-Pacific Conference on Synthetic Aperture Radar (APSAR)","29 Oct 2015","2015","","","567","572","Study of the land cover classification using multi-source data are very important for eco-environment monitoring, land use planning and climatic change detection. In this study, the utility of multi-source RADARSAT-2 and LANDSAT-8 multi-spectral images for improving land cover classification performance using Support Vector Machine (SVM) classifier. HH polarized C band RADARSAT-2 images were fused with the three band (6, 5, and 4) LANDSAT-8 multispectral image for land cover classification. Wavelet-based fusion (WT) techniques are implemented in the data fusion process. The Radial Basic Function (RBF) kernel function were used for SVM classifier in order to classify land cover types in the study area. The results of the SVM classification were compared with those using standard method Maximum Likelihood (ML) classifier, and it demonstrates a higher accuracy. Finally, it was indicated by the study that the fusion of SAR and optical images can significantly improve the classification accuracy with respect to use single dataset, and the SVM classifier could clearly outperform the standard method the ML classifier.","","978-1-4673-7297-8","10.1109/APSAR.2015.7306273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7306273","image fusion;RADARSAT-2;LANDSAT-8;land cover classification;Support Vector Machine (SVM)","Support vector machines;Remote sensing;Satellites;Earth;Accuracy;Kernel;Training","climatology;environmental monitoring (geophysics);geophysical image processing;image classification;image fusion;land cover;land use planning;radar imaging;radial basis function networks;remote sensing by radar;satellite communication;support vector machines;wavelet transforms","HH polarized C band RADARSAT-2 imagery fusion;LANDSAT-8 multispectral data;land cover classification performance improvement;SVM classifier;support vector machine classifier;multisource data;eco-environment monitoring;land use planning;climatic change detection;wavelet-based fusion techniques;WT techniques;data fusion process;radial basic function kernel function;RBF kernel function","","5","","27","IEEE","29 Oct 2015","","","IEEE","IEEE Conferences"
"Enhanced quality LANDSAT image processing based on 4-level Sub-Band Replacement DWT","A. Mulla; J. Baviskar; R. Naik; A. Baviskar","Department of Electrical Engineering, Veermata Jijabai Technological Institute (VJTI), Mumbai, India; Department of Electrical Engineering, Veermata Jijabai Technological Institute (VJTI), Mumbai, India; BNP Paribas, Mumbai, India; Department of Electronics Engineering, Universal College of Engineering (UCOE), Vasai, India","2015 IEEE Aerospace Conference","8 Jun 2015","2015","","","1","7","Satellite images are multi-spectral in nature that operate over wavelengths of wide range frequencies known as bands. Hence, they need to be processed cautiously. This paper presents a 4-Level DWT based Sub-Band Replacement (SR-DWT) Image Compression scheme, for LANDSAT satellite images. The algorithm is designed to compress various color band images captured by the satellite payload. By performing compression on these images and converting them to unique textured images, it exploits the sub-bands generated by the wavelet transform. Since the algorithm is a reversible process, it facilitates retrieval of the images back to colored format at the receiver. Due to the property of possessing spatial-frequency decomposition, the recovered images are of high quality with improved Peak Signal to Noise Ratio (PSNR) of 20dB and correspondingly very low MSE value. Using an astrophysical image database, the performance analysis of the 4-Level SR-DWT algorithm is illustrated.","1095-323X","978-1-4799-5380-6","10.1109/AERO.2015.7118964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7118964","","Discrete wavelet transforms;Image coding;Satellites;Color;Image color analysis;Remote sensing","discrete wavelet transforms;geophysical image processing;image coding;image texture;remote sensing","astrophysical image database;4-level SR-DWT algorithm;spatial-frequency decomposition;image retrieval;wavelet transform;image texture;color band images;LANDSAT satellite images;SR-DWT iImage compression scheme;4-level subband replacement DWT;LANDSAT image processing","","3","","8","IEEE","8 Jun 2015","","","IEEE","IEEE Conferences"
"Effect of cirrus cloud on normalized difference Vegetation Index (NDVI) and Aerosol Free Vegetation Index (AFRI): A study based on LANDSAT 8 images","K. Rajitha; M. M. Prakash Mohan; M. R. R. Varma","Civil Engineering Department, BITS Pilani Hyderabad Campus, India; Civil Engineering Department, BITS Pilani Hyderabad Campus, India; Civil Engineering Department, BITS Pilani, Hyderabad, India","2015 Eighth International Conference on Advances in Pattern Recognition (ICAPR)","2 Mar 2015","2015","","","1","5","The present study is an attempt to identify the influence of cirrus cloud on NDVI and AFRI values and to check the scope of replacing NDVI with AFRI in cirrus affected satellite images. Multi-spectral channels of LANDSAT-8 satellite image collected for two different dates of acquisition are used in the current study. Reflectance values of cirrus band are used for correcting red and near infra-red spectral channels based on standard cirrus correction algorithm. The NDVI values obtained after cirrus correction is found to be significantly more than that of NDVI values without cirrus correction. In the case of AFRI(2.1m), the difference in values between before and after cirrus correction is found to be considerably lower than that of NDVI variation. These outcomes show the suitability of AFRI(2.1m) over NDVI for cirrus affected satellite images. The results of analysis also reveal that NDVI difference is directly proportionate with optical thickness and ice particle size distribution of cirrus clouds.","","978-1-4799-7458-0","10.1109/ICAPR.2015.7050710","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050710","NDVI;AFRI;cirrus clouds;LANDSAT 8","Clouds;Satellites;Remote sensing;Earth;Adaptive optics;Integrated optics;Optical imaging","aerosols;atmospheric optics;clouds;remote sensing;vegetation","cirrus cloud effect;Normalized Difference Vegetation Index;NDVI values;Aerosol Free Vegetation Index;AFRI values;multispectral channels;LANDSAT-8 satellite image;cirrus band reflectance values;near infra-red spectral channels;standard cirrus correction algorithm;cirrus cloud optical thickness;cirrus cloud ice particle size distribution","","3","","6","IEEE","2 Mar 2015","","","IEEE","IEEE Conferences"
"An Ensemble Approach to Transfer Learning for Classification of Habitat Mapping","P. Manandhar; P. R. Marpu; Z. Aung","Department of Electrical and Computer Engineering, Khalifa University, Abu Dhabi, UAE; Department of Electrical and Computer Engineering, Khalifa University, Abu Dhabi, UAE; Department of Computer Science, Khalifa University, Abu Dhabi, UAE","2018 International Conference on Signal Processing and Information Security (ICSPIS)","17 Feb 2019","2018","","","1","4","The Environment Agency- Abu Dhabi developed extensive habitat, land cover, land use maps in 2015 using a very high resolution satellite imagery acquired between 2011 and 2013. This map can be used as a baseline map to allow efficient monitoring. In this work, we aim to establish a framework for short term updates to the maps to quickly enable efficient planning. With the availability of multi-spectral images, various spectral bands apart from visible (Red, Green and Blue) bands can be used in habitat mapping. This paper presents the work of land cover classification in the region of Abu Dhabi, UAE using a Worldview-2 satellite image. The proposed approach makes use of Random Forest algorithm, applied on the Fully-Connected features obtained from AlexNet framework using a 20% training samples on a 3-band input. Then, ensemble of outputs of Random Forest over different 3-bands combination is used to make the final prediction. The results are validated against the ground truth obtained from Environment Agency, Abu Dhabi. Eventually, our aim is to develop a robust classification approach and then adapt automatic change detection approaches to temporally update the baseline maps.","","978-1-7281-0257-3","10.1109/CSPIS.2018.8642722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642722","","Remote sensing;Satellites;Monitoring;Image resolution;Deep learning;Signal processing;Information security","geophysical image processing;image classification;land cover;land use;learning (artificial intelligence);remote sensing;terrain mapping","multispectral images;habitat mapping;land cover classification;Worldview-2 satellite image;Random Forest algorithm;AlexNet framework;ensemble approach;extensive habitat;very high resolution satellite imagery;Environment Agency-Abu Dhabi;AD 2015;land use maps;AD 2011;AD 2013;UAE","","2","","12","IEEE","17 Feb 2019","","","IEEE","IEEE Conferences"
"Unsharp masking based pansharpening of high resolution satellite imagery","M. Teke; E. San; E. Koç","TÜBİTAK Uzay Teknolojileri Araştırma Enstitüsü, Ankara, Türkiye; TOBB ETÜ Ekonomi ve Teknoloji Üniversitesi, Elektrik ve Elektronik Mühendisliği Bölümü, Ankara, Türkiye; TOBB ETÜ Ekonomi ve Teknoloji Üniversitesi, Elektrik ve Elektronik Mühendisliği Bölümü, Ankara, Türkiye","2018 26th Signal Processing and Communications Applications Conference (SIU)","9 Jul 2018","2018","","","1","4","Pan sharpening is a pixel-level fusion technique for increasing the spatial resolution of low-resolution multi-spectral satellite imagery using high-resolution panchromatic imagery. In this work, the performance of various pansharpening algorithms in improving the 2.5m resolution of Göktürk-2 satellite imagery is compared. Eight different pansharpening algorithms are tested on seven different Göktürk-2 images and evaluated using eight different metrics which measures spectral and spatial quality of pansharpened images. We developed a preprocessing method, which is based on unsharp masking of pan band. Proposed method replace high pass filtering of Optimized HPF method instead it used sharpened image from unsharp masking of pan band. Then this information is added multispectral bands based on their standard deviation ratios. Pan band carries highest resolution spatial information while it lacks color. Unsharp masking is applied pan band to improve spatial contribution from this band. Then other pansharpening methods are applied to the image. Unsharp based preprocessing ofpan bands improves sharpness of the images without degraded image quality. Unsharpening increases sharpness of pansharpened images which performs poorly persevering spatial features. Our results show that the Optimized High Pass Filter (HPF) yields the sharpest pan sharpened image, while the hyper spherical Color Space (HCS) method preserves the truest colors while preserving sharpness to a certain degree.","","978-1-5386-1501-0","10.1109/SIU.2018.8404403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8404403","Göktürk-2;Unsharp;pansharpening;HPF;HCS","Satellites;Remote sensing;Optimized production technology;Spatial resolution;Image color analysis;Principal component analysis","high-pass filters;image classification;image colour analysis;image enhancement;image filtering;image fusion;image resolution;remote sensing","unsharp masking based pansharpening;high resolution satellite imagery;pan sharpening;pixel-level fusion technique;spatial resolution;low-resolution multispectral satellite imagery;high-resolution panchromatic imagery;Göktürk-2 satellite imagery;spectral quality;spatial quality;pansharpened images;high pass filtering;multispectral bands;pansharpening methods;ofpan bands;degraded image quality;spatial features;sharpest pan sharpened image;pansharpening algorithms;spatial information;optimized HPF method;optimized high pass filter;size 2.5 m","","2","","","IEEE","9 Jul 2018","","","IEEE","IEEE Conferences"
"Residual Clustering Based Lossless Compression for Remotely Sensed Images","Z. Wang","Department of Electrical Engineering and Computer Science, Texas AM University-Kingsville, Kingsville, Texas, USA","2018 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)","17 Feb 2019","2018","","","536","539","In the K-means algorithm, every pixel in a super-space is required to calculate Euclidean distance for clustering, so it is time-consuming computing when there are a great many class centers. Improved K-means clustering algorithm presented here could save initial clustering time by making initial division based on previous clustering results, and maintain the relationship among stable classes. Only calculating and comparing distances with neighbor centers, near to the pixel except those far away from it, accelerates clustering process with more and more classes becoming stable. Clustering lossless compression algorithm can efficiently eliminate the inter-spectral and intra-spectral redundancy at high convergent speed through enhancing intra-class redundancy. The multi-level clustering process can not only remove the spatial redundancy but also delete the residue redundancy, whose importance in lossless compression was overlooked previously, realizing a breakthrough lossless compression ratio at 2.882 for multi-spectral images. The comparison of the parameter analysis of the TM (Landsat Thematic Mapper) images with other lossless compression algorithms shows that this multilevel clustering lossless compression algorithm is more efficient.","2162-7843","978-1-5386-7568-7","10.1109/ISSPIT.2018.8642684","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642684","Multispectral images;lossless compression;clustering;K-means;residue redundancy;entropy","Redundancy;Image coding;Clustering algorithms;Compression algorithms;Remote sensing;Standards;Euclidean distance","data compression;geophysical image processing;image coding;pattern clustering;remote sensing","Landsat thematic mapper images;intraclass redundancy;TM images;multispectral images;multilevel clustering process;high convergent speed;clustering lossless compression algorithm;neighbor centers;initial division;initial clustering time;improved K-means clustering algorithm;Euclidean distance;super-space;remotely sensed images;residual clustering","","1","","9","IEEE","17 Feb 2019","","","IEEE","IEEE Conferences"
"Multi-spectral detection and tracking in cluttered urban environments","C. Demars; M. Roggemann; P. Zulch","Electrical and Computer Engineering, Michigan Tech University, Houghton, MI; Electrical and Computer Engineering, Michigan Tech University, Houghton, MI; AFRL/RI, Air Force Research Laboratory, Rome, NY","2015 IEEE Aerospace Conference","8 Jun 2015","2015","","","1","7","Automatic detection and tracking of moving targets in full motion video (FMV) from aerial imaging systems has significant interest in the defense and security community. However often times performance is degraded in a given spectral band due to environmental conditions and poor target response in a given band. The overall goal of this work is to increase the probability of detection and track association in cluttered urban environments while simultaneously suppressing false alarms by fusing the detection results and features from different spectral bands. We use a Gaussian mixture model (GMM) to detect background pixels, and define potential targets as being in regions that are found to be non-background. Detections from each spectral band are fused to form multi-spectral target candidates. Detected target candidates are associated with targets from a tracking database by matching features from the scale-invariant feature transform (SIFT). We create tracking profiles consisting of location history and vector velocity history for all targets in the scene. This algorithm was evaluated with synthetically generated datasets from the Digital Imaging and Remote Sensing Image Generation (DIRSIG) software model producing visible, near infrared, mid-wave infrared and long-wave infrared FMV that include moving vehicles in an urban environment. The proposed fusion algorithm provides a detection rate over 82%, while decreasing incorrect associations in cluttered areas such as intersections or partial occlusions where a portion of the vehicle is hidden from sensor view. This paper will describe the approach and demonstrate the performance with simulated DIRSIG FMV data.","1095-323X","978-1-4799-5380-6","10.1109/AERO.2015.7119006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119006","","Target tracking;Vehicles;Image segmentation;Feature extraction;Urban areas;Imaging","aerospace instrumentation;Gaussian processes;geophysical image processing;image motion analysis;mixture models;target tracking","multispectral tracking;multispectral detection;cluttered urban environments;full motion video;aerial imaging system;Gaussian mixture model;GMM;background pixels;scale-invariant feature transform;SIFT;digital imaging and remote sensing image generation software model;DIRSIG software model","","6","","16","IEEE","8 Jun 2015","","","IEEE","IEEE Conferences"
"Multi Spectral-Spatial Gabor Feature Fusion Based On End-To-End Deep Learning For Hyperspectral Image Classification","R. Hanachi; A. Sellami; I. R. Farah; M. D. Mura","RIADI laboratory, ENSI, University of Manouba, Manouba, Tunisia; LORIA laboratory, University of Lorraine and INRIA/CNRS, UMR 7503, Campus Scientifique, 615 Rue du Jardin-Botanique, Vandæuvre-lès-Nancy, France; ITI Department, IMT Atlantique, 655 Avenue du Technopôle, Plouzané, France; Grenoble INP, GIPSA-lab Univ. Grenoble Alpes, CNRS, Grenoble, France","2022 12th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","22 Nov 2022","2022","","","1","6","The use of low-level spatial information, in addition to the rich spectral information of Hyperspectral Image (HSI) with the potential of deep learning-based methods, has provided high performance in improving the HSI classification. With this regard, Gabor Filtering has been successfully applied for HSI pixels analysis due to its ability in extracting representative spatial features. Therefore, a novel methodology based on Gabor filtering and multi-view Convolutional Neural Networks (multi-view CNNs) was proposed in this paper. Firstly, Gabor texture features at different scales and orientations performed on the first three principal components of HSI were extracted. Then, spectral and spatial features are introduced separately through spectral, and spatial CNN, respectively. Afterward, their learned feature maps are combined and fed into our spectral-spatial CNN (SSCNN) to learn a fused multi-view representation. Experiments applied on two real HSI datasets, including Indian Pines, and Salinas yield competitive classification performances compared to other state-of-the-art deep learning methods.","2158-6276","978-1-6654-7069-8","10.1109/WHISPERS56178.2022.9955105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955105","Gabor Filtering;Multi-view representation learning;CNN;HSI classification","Representation learning;Deep learning;Learning systems;Filtering;Signal processing;Feature extraction;Convolutional neural networks","convolution;feature extraction;Gabor filters;geophysical image processing;hyperspectral imaging;image classification;image representation;image texture;learning (artificial intelligence);neural nets","competitive classification performances;deep learning-based methods;End-To-End Deep Learning;fused multiview representation;Gabor Filtering;Gabor filtering;Gabor texture features;HSI classification;HSI datasets;HSI pixels analysis;Hyperspectral Image classification;learned feature maps;low-level spatial information;multispectral-spatial Gabor feature fusion;multiview CNNs;multiview Convolutional Neural Networks;representative spatial features;rich spectral information;spectral features;spectral-spatial CNN;state-of-the-art deep learning methods","","","","15","IEEE","22 Nov 2022","","","IEEE","IEEE Conferences"
"Preprocessing and fusion analysis of GF-2 satellite Remote-sensed spatial data","D. -D. Zhang; F. Xie; L. Zhang","Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China; Shanghai Institute of Technical Physics, East China Normal University, Shanghai, China; MOE International Joint Lab of Trustworthy Software, East China Normal University, China","2018 International Conference on Information Systems and Computer Aided Education (ICISCAE)","14 Mar 2019","2018","","","24","29","There is no pansharpening method that can be applied to all kinds of images at present due to the principle of fusion processing and the characteristics of sensors that acquire images. In order to explore the suitable fusion method for the "" Gaofen-2 "" satellite image, PCA, HPF, Gram-Schmidt and NNDiffuse four kinds of fusion methods were selected to merge the panchromatic and multi spectral data of Gaofen-2 satellite images, the fusion results of the image were synthetically compared and evaluated with subjective evaluation and quantitative analysis. The test results show that the NNDiffuse transform method has the best combination effect and is very prominent in the fusion effect of the visible light band; And in the fusion of near-infrared band, Gram-Schmidt method can be considered. The research results of this paper can provide reference for the fusion processing and application of Gaofen-2 satellite image data.","","978-1-5386-5738-6","10.1109/ICISCAE.2018.8666873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8666873","Pansharpening;Gaofen-2;NNDiffuse;subjective evaluation;quantitative analysis","Spatial resolution;Satellites;Principal component analysis;Transforms;Distortion;Remote sensing","geophysical image processing;geophysical techniques;image fusion;remote sensing","NNDiffuse transform method;fusion effect;Gram-Schmidt method;fusion processing;Gaofen-2 satellite image data;pansharpening method;suitable fusion method;fusion methods;fusion results;fusion analysis;GF-2 satellite Remote-sensed spatial data preprocessing;PCA;HPF;panchromatic data;multi spectral data;quantitative analysis;visible light band;near-infrared band","","5","","21","IEEE","14 Mar 2019","","","IEEE","IEEE Conferences"
"Modular supercomputing design supporting machine learning applications","E. Erlingsson; G. Cavallaro; A. Galonska; M. Riedel; H. Neukirchen","University of Iceland, School of Natural Sciences and Engineering, Reykjavik, Iceland; Forschungszentrum Juelich, Juelich Supercomputing Centre, Juelich, Germany; Forschungszentrum Juelich, Juelich Supercomputing Centre, Juelich, Germany; University of Iceland, School of Natural Sciences and Engineering, Reykjavik, Iceland; Forschungszentrum Juelich, Juelich Supercomputing Centre, Juelich, Germany","2018 41st International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","2 Jul 2018","2018","","","0159","0163","The DEEP-EST (DEEP - Extreme Scale Technologies) project designs and creates a Modular Supercomputer Architecture (MSA) whereby each module has different characteristics to serve as blueprint for future exascale systems. The design of these modules is driven by scientific applications from different domains that take advantage of a wide variety of different functionalities and technologies in High Performance Computing (HPC) systems today. In this context, this paper focuses on machine learning in the remote sensing application domain but uses methods like Support Vector Machines (SVMs) that are also used in life sciences and other scientific fields. One of the challenges in remote sensing is to classify land cover into distinct classes based on multi-spectral or hyper-spectral datasets obtained from airborne and satellite sensors. The paper therefore describes how several of the innovative DEEP-EST modules are co-designed by this particular application and subsequently used in order to not only improve the performance of the application but also the utilization of the next generation of HPC systems. The paper results show that the different phases of the classification technique (i.e. training, model generation and storing, testing, etc.) can be nicely distributed across the various cluster modules and thus leverage unique functionality such as the Network Attached Memory (NAM).","","978-953-233-095-3","10.23919/MIPRO.2018.8400031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8400031","","Support vector machines;Training;Computational modeling;Machine learning;Data models;Load modeling;Remote sensing","geophysical image processing;image classification;land cover;learning (artificial intelligence);mainframes;parallel machines;remote sensing;support vector machines","DEEP-EST modules;HPC systems;Modular Supercomputer Architecture;remote sensing application domain;Support Vector Machines;hyper-spectral datasets;machine learning applications;High Performance Computing systems;DEEP-Extreme Scale Technologies;airborne sensor;satellite sensor;land cover classification","","1","","17","","2 Jul 2018","","","IEEE","IEEE Conferences"
"RFI Source Detection Based on Reweighted ℓ1-Norm Minimization for Microwave Interferometric Radiometry","D. Zhu; H. Lu; Y. Cheng","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; China Academy of Space Technology, Xian, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Geoscience and Remote Sensing","17 Jan 2022","2022","60","","1","15","Radio frequency interference (RFI) seriously deteriorates the quality of the retrieval of geophysical parameters, e.g., Earth surface moisture and ocean salinity, measured in microwave interferometric radiometry (MIR). The accurate detection of RFI sources is crucial for locating these illegal sources and mitigating their impact. In this article, we propose a new method based on reweighted  $\ell _{1}$ -norm minimization to detect RFI sources. First, we exploit the sparsity of RFI sources in the spatial domain and formulate the RFI detection as a problem of reweighted  $\ell _{1}$ -norm minimization, by which the RFI signals can be well recovered and the background noises can be suppressed. Then, we present two algorithms, termed RL1 and NRL1, to achieve RFI source detection. The RL1 algorithm employs a fast iterative shrinkage thresholding (FIST) technique, and the NRL1 algorithm combines the FIST with a neighbor-reweighting strategy that helps to further enhance the RFI target regions. Finally, simulations and experiments using Soil Moisture and Ocean Salinity (SMOS) satellite data demonstrate the superiority of the proposed method on the RFI-signal-to-background ratio (RSBR) in recovered images and the detection performance of RFI sources, compared with the existing RFI processing methods in MIR.","1558-0644","","10.1109/TGRS.2021.3096318","National Natural Science Foundation of China(grant numbers:61901244,61901242); China Postdoctoral Science Foundation(grant numbers:2019M660643); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9503109","Fast iterative shrinkage thresholding (FIST);microwave interferometric radiometry (MIR);neighbor reweighting;radio frequency interference (RFI);reweighted ℓ₁-norm minimization;RFI source detection","Minimization;Microwave radiometry;Covariance matrices;Antenna arrays;Microwave theory and techniques;Task analysis;Receiving antennas","geophysical techniques;radiofrequency interference;radiometry","RFI sources;RFI detection;norm minimization;RFI signals;termed RL1;RFI source detection;RL1 algorithm;NRL1 algorithm;RFI target regions;RFI-signal-to-background ratio;microwave interferometric radiometry;ocean salinity;illegal sources;RFI processing methods","","3","","45","IEEE","2 Aug 2021","","","IEEE","IEEE Journals"
"Source Localization Based on Hybrid Coarray for 1-D Mirrored Interferometric Aperture Synthesis","D. Zhu; G. Li; X. -P. Zhang","School of Electronic Information and Communications and the National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electrical, Computer and Biomedical Engineering, Ryerson University, Toronto, ON, Canada","IEEE Transactions on Geoscience and Remote Sensing","29 Dec 2021","2022","60","","1","14","The mirrored interferometric aperture synthesis (MIAS) is a promising technique for high-resolution observation in microwave radiometry. In this article, we present a new source localization method based on a novel hybrid coarray that can be constructed from the 1-D MIAS. The new method, named MA-SS method, employs the spatial smoothing (SS) technique on the hybrid coarray of mirrored array (MA) in the MIAS. We show that it has the ability to resolve more sources than physical sensors. The theoretical analysis gives an upper bound on degrees of freedom (DOF) of  $O(N^{2})$  order using  $N$  physical sensors. Simulation and experiment results demonstrate that, compared with the discrete cosine transform (DCT) approach commonly utilized in the MIAS, the presented MA-SS method shows the superiorities on spatial resolution, sidelobe reduction, localization accuracy, and detection performance.","1558-0644","","10.1109/TGRS.2021.3061447","National Natural Science Foundation of China(grant numbers:61901244,61790551,61925106); China Postdoctoral Science Foundation(grant numbers:2019M660643); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9434390","Coarray;mirrored array (MA);mirrored interferometric aperture synthesis (MIAS);source localization","Location awareness;Sensors;Covariance matrices;Array signal processing;Manifolds;Discrete cosine transforms;Apertures","antenna arrays;aperture antennas;radiometry;radiowave interferometry;smoothing methods","source localization method;named MA-SS method;spatial smoothing technique;mirrored array;spatial resolution;localization accuracy;mirrored interferometric aperture synthesis;high-resolution observation;microwave radiometry;hybrid coarray;1D interferometric aperture synthesis;1D MIAS;sidelobe reduction;detection performance","","3","","43","IEEE","18 May 2021","","","IEEE","IEEE Journals"
"Deterministic Array Configurations for Radiometric Sensitivity Optimization in Microwave Interferometric Radiometers","D. Zhu; L. Wu; Y. Cheng; H. Lu","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; 9th Designing of China Aerospace Science Industry Corporation, Wuhan, China; Department of Engineering Physics, Tsinghua University, Beijing, China; China Academy of Space Technology, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","12 Jan 2022","2022","60","","1","12","Radiometric sensitivity is crucially important for microwave interferometric radiometers. To pursue optimum performance of radiometric sensitivity, the minimum-degradation arrays (MDAs) or low-degradation arrays (LDAs) are usually employed. In this article, we propose a deterministic method for designing low-degradation linear arrays (LDLAs), which exploits the multiple-fold redundancy property of baseline coverage (i.e.,  $u$ – $v$  coverage) of interferometric arrays and further devises analytical patterns for closed-form geometric construction. The proposed method can not only attain LDLAs with satisfactory radiometric sensitivity in significantly low computational complexity, given any number of sensor elements, but also has easy adoption on large array synthesis and configuration expansion scenarios. In addition, such analytically designed LDLAs also have the advantage of array robustness (or system reliability) in the sense of  $u$ – $v$  coverage shrinking and “hole” occurrence (resulted from sensor failures). Numerical results are given to demonstrate the effectiveness of the proposed LDLA design method through comparison with stochastic algorithms based on heuristic search and combinatorial approaches uniting specific integer sequences, e.g., cyclic difference sets.","1558-0644","","10.1109/TGRS.2021.3068143","National Natural Science Foundation of China(grant numbers:61901244,61901242,41706204); China Postdoctoral Science Foundation(grant numbers:2019M660643,2019M660640,2020T130338); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9449624","Deterministic method;low-degradation linear array (LDLA);microwave interferometric radiometer (MIR);radiometric sensitivity;system reliability","Sensitivity;Microwave radiometry;Sensor arrays;Redundancy;Antenna measurements;Geometry;Reliability","computational complexity;interferometry;optimisation;radiometers;stochastic processes","hole occurrence;LDLA design method;deterministic array configurations;radiometric sensitivity optimization;microwave interferometric radiometers;minimum-degradation arrays;low-degradation arrays;deterministic method;low-degradation linear arrays;multiple-fold redundancy property;baseline coverage;interferometric arrays;devises analytical patterns;closed-form geometric construction;satisfactory radiometric sensitivity;low computational complexity;array synthesis;configuration expansion scenarios;array robustness;analytically designed LDLA;radiometric sensitivity;computational complexity;sensor elements;system reliability;u-v coverage shrinking;heuristic search;combinatorial approaches;specific integer sequence;cyclic difference sets","","1","","48","IEEE","9 Jun 2021","","","IEEE","IEEE Journals"
"FGF-GAN: A Lightweight Generative Adversarial Network for Pansharpening via Fast Guided Filter","Z. Zhao; J. Zhan; S. Xu; K. Sun; L. Huang; J. Liu; C. Zhang","School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China","2021 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2021","2021","","","1","6","Pansharpening is a widely used image enhancement technique for remote sensing. Its principle is to fuse the input high-resolution single-channel panchromatic (PAN) image and low-resolution multi-spectral image and to obtain a high-resolution multi-spectral (HRMS) image. The existing deep learning pansharpening method has two shortcomings. First, features of two input images need to be concatenated along the channel dimension to reconstruct the HRMS image, which makes the importance of PAN images not prominent, and also leads to high computational cost. Second, the implicit information of features is difficult to extract through the manually designed loss function. To this end, we propose a generative adversarial network via the fast guided filter (FGF) for pansharpening. In generator, traditional channel concatenation is replaced by FGF to better retain the spatial information while reducing the number of parameters. Meanwhile, the fusion objects can be highlighted by the spatial attention module. In addition, the latent information of features can be preserved effectively through adversarial training. Numerous experiments illustrate that our network generates high-quality HRMS images that can surpass existing methods, and with fewer parameters.","1945-788X","978-1-6654-3864-3","10.1109/ICME51207.2021.9428272","National Key Research and Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9428272","Pansharpening;Fast guided filter;Generative adversarial network;Image fusion","Training;Earth;Fuses;Pansharpening;Feature extraction;Information filters;Generative adversarial networks","deep learning (artificial intelligence);geophysical image processing;image enhancement;image fusion;image resolution;remote sensing","lightweight generative adversarial network;fast guided filter;image enhancement technique;remote sensing;input high-resolution single-channel panchromatic image;low-resolution multispectral image;high-resolution multispectral image;channel dimension;PAN images;high computational cost;channel concatenation;adversarial training;high-quality HRMS images;FGF-GAN;deep learning pansharpening method","","3","","20","IEEE","9 Jun 2021","","","IEEE","IEEE Conferences"
"Degree of Linear Polarization of Land Surfaces: Analyses Using POLDER/PARASOL Measurements","S. Liu; L. Yan; B. Yang","Beijing Key Laboratory of Spatial Information Integration and 3S Application, Institute of Remote Sensing and Geographic Information System, School of Earth and Space Sciences, Peking University, Beijing, China; Guangxi Key Laboratory of Remote Measuring System, Guilin University of Aerospace Technology, Guilin, China; College of Electrical and Information Engineering, Hunan University, Changsha, China","IEEE Access","12 Nov 2020","2020","8","","200561","200572","Polarized reflectance (Rp) and degree of linear polarization (DOLP) provide essential information about polarized characteristics of land surfaces. For a given target, DOLP determines the magnitude of Rp. It has been proved that DOLP can be used for some remote monitoring cases that cannot be well detected with either non-polarized or polarized reflectance. Several bidirectional polarization distribution function (BPDF) models have been proposed in the last several decades to reproduce the angular distribution of Rp, but much less attention has been devoted to modeling and analyzing of DOLP. In this study, the Nadal-Bréon BPDF model was transferred for calculating the DOLP of earth targets, and characteristics of DOLP were analyzed based on the modeling results. To evaluate the model's feasibility, two experiments were executed: a fitting and a a priori modeling. The results showed good correlations (r>0.9) between estimated and measured DOLP when the model was fitted with POLDER/PARASOL (a space-borne multi-angle multi-spectral polarimetric sensor) measurements. An increase of accuracy from 490 nm to 865 nm for fitting modeling was achieved and the highest accuracy was found at 865 nm for both experiments, with overall relative root mean square errors of 1.1 and 1.3 for fitting and a priori modeling, respectively. Class-based free parameters can be used for the a priori model of DOLP. The dispersion of the target-based free parameters controls the correlation of the a priori modeling results. Moreover, the maximum DOLP was found to be strongly determined by the corresponding bidirectional reflectance factor for every surface type (R2=0.86). This study provides an additional approach for obtaining DOLP from remote sensing platform and is helpful for studies of typical land surfaces.","2169-3536","","10.1109/ACCESS.2020.3033981","Natural Science Foundation of Hunan Province, China(grant numbers:2019JJ50047); National Natural Science Foundation of China(grant numbers:41801227); National Key Research and Development Program of China(grant numbers:2017YFB0503004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240922","Degree of linear polarization (DOLP);bidirectional polarization distribution function (BPDF);POLDER/PARASOL;BRDF-BPDF database","Land surface;Analytical models;Biological system modeling;Atmospheric modeling;Databases;Forestry;Earth","geophysical techniques;polarimetry;remote sensing","linear polarization;polarized reflectance;polarized characteristics;bidirectional polarization distribution function models;Nadal-Bréon BPDF model;space-borne multiangle multispectral polarimetric sensor;fitting modeling;a priori model;target-based free parameters;maximum DOLP;corresponding bidirectional reflectance factor;land surfaces;POLDER/PARASOL measurements;size 490.0 nm to 865.0 nm","","2","","33","CCBY","27 Oct 2020","","","IEEE","IEEE Journals"
"Analysis Machine Learning Approach and Model on Hyper Spectral (Sentinel-2) Images for Land Cover Classification: Using SVM","R. Sharma; D. Pantola; S. D. Kalony; R. Agarwal","CCSIT, Teerthanker Mahaveer University, Moradabad, India; School of Engineering and Applied Sciences, Bennet University, Greater Noida, India; Teerthanker Mahaveer University, Moradabad, Uttar Pradesh, India; Teerthanker Mahaveer University, Moradabad, Uttar Pradesh, India","2021 10th International Conference on System Modeling & Advancement in Research Trends (SMART)","18 Jan 2022","2021","","","680","684","The goal of this research study will be to research different machine learning algorithm via context oriented methodology with or without entropy for sub-pixel categorization utilizing Sentinel 2, multi-Spectral data extract reasonably accurate information for different land cover classes. To study the capabilities of Machine Learning Applications for Crop Identification and Use of temporal data information for crop planning in Machine Learning Algorithm this exploration will supportive to check Capability of Red Edge band to consolidate Crop phenology in crop recognizable proof. In this analysis work knowledge classification approach are going to be applied whereas getting ready land use and land covered map victimization for multi-spectral remote sensing knowledge sets (Sentinel-2/ Land sat). The data sets to be used in this research work will be fine spatial resolution data, to ensure classify approaches towards spatial data set and classification.","2767-7362","978-1-6654-3970-1","10.1109/SMART52563.2021.9676331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9676331","Soft Classification;Machine Algorithm;Accuracy;Gps;Machine Vision System Support Vector Machine(SVM)","Support vector machines;Machine learning algorithms;Crops;Support vector machine classification;Machine learning;Spatial databases;Systems support","crops;geophysical image processing;image classification;land cover;learning (artificial intelligence);remote sensing;support vector machines;terrain mapping;vegetation mapping","land cover classification;SVM;different machine learning algorithm;context oriented methodology;sub-pixel categorization;reasonably accurate information;different land cover classes;Crop Identification;temporal data information;crop planning;Algorithm this exploration;Red Edge band;Crop phenology;crop recognizable proof;analysis work knowledge classification approach;ready land use;land covered map victimization;multispectral remote sensing knowledge sets;data sets;fine spatial resolution data;classify approaches;spatial data;analysis machine;hyper spectral","","","","18","IEEE","18 Jan 2022","","","IEEE","IEEE Conferences"
"Recognization of rice damage area on UAV ortho-images","W. C. Hsuan; L. S. Hao; Y. C. Kuo","Department of Applied Geoinformatics, Chia-Nan University, Tainan, Taiwan ROC; Department of Applied Geoinformatics, Chia-Nan University, Tainan, Taiwan ROC; Department of Applied Geoinformatics, Chia-Nan University, Tainan, Taiwan ROC","2018 IEEE International Conference on Applied System Invention (ICASI)","25 Jun 2018","2018","","","1092","1094","The following research uses Yuanli Township, Miaoli County as an example. The Multi-spectral UAV aerial images used have high spectral, spatial and temporal definition, which provides High-resolution DEM, which can be applied through height bias to recognize the rice damage Range and type. Furthermore, due to the chlorophyll in the crops having higher NIR reflection, when applied with NDVI, the crop growth range and stadium can be clearly explained more easily. The image processing technique is done by Pix4D and e-GPS measure Ground Control Points to produce a RGB Orthomosaic and NIR Orthomosaic, then using Arc gis to produce interpretation attribute data which is then derived through MATLAB input range values. The result of rice damage will be interpretated by using NDVI images as a major factor and human judgement as a supporting factor.","","978-1-5386-4342-6","10.1109/ICASI.2018.8394470","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8394470","Remote sensing UAV;NDVI","Agriculture;Photography;Satellites;Meteorology;Monitoring;Vegetation mapping;Manuals","autonomous aerial vehicles;crops;digital elevation models;geographic information systems;geophysical image processing;Global Positioning System;remote sensing","crop growth range;image processing technique;RGB Orthomosaic;NIR Orthomosaic;MATLAB input range values;NDVI images;rice damage area;UAV ortho-images;Yuanli Township;Miaoli County;NIR reflection;high-resolution DEM;multispectral UAV aerial images;chlorophyll;Pix4D;e-GPS;Taiwan;Arc GIS","","2","","4","IEEE","25 Jun 2018","","","IEEE","IEEE Conferences"
"Analysis of land use and land cover change in Nadowli District, Ghana","L. B. Prosper; Q. Guan","School of Environment, China University of Geosciences, Wuhan, Hubei, P. R. China; Faculty of Information Engineering, China University of Geosciences, Wuhan, Hubei, P. R. China","2015 23rd International Conference on Geoinformatics","14 Jan 2016","2015","","","1","6","There is a growing environmental concern and interest in land at the Nadowli District, Ghana since the influx of legal and illegal miners in the area. Analysis of these concerns requires the assessment of the Land use and land cover dynamics of the area. Geographic information systems and satellite remote sensing information are latest technologies in land-cover change assessment. Their strengths lie in providing insights into land-cover change properties through the use of spatio-temporal and multi spectral data. Landsat satellite imageries of three different time periods, i.e., 1990, 2000 and 2014 were used to quantify the land use and land cover changes in the area. Supervised classification using Maximum Likelihood technique was used resulting in the classes: Water, Open Savannah and Closed savannah woodlands, Agricultural/Fallow Land, Settlement and bare lands. A post-classification change detection method was employed and a LULC change matrix obtained. The study shows that between the years 1991 and 2000 the changes in the LULC changes were not as significant as in the years between 2000 and 2014. There was a decrease in Water and closed Savannah woodlands although Open Savannah has increased marginally. The felling of trees for fuel wood is also depleting the closed Savannah wood lot. Agriculture has increased especially along the Black Volta River. Settlements/bare areas may have decreased probably due to the clamp down of illegal mining activities and easy access to markets along the North Eastern part close to the District Capital, Nadowli.","2161-024X","978-1-4673-7663-1","10.1109/GEOINFORMATICS.2015.7378647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7378647","Land Use and Land Cover;Mines;Satellite Imagery;Vegetation","Vegetation;Vegetation mapping;Distance measurement;Satellites;Remote sensing;Sociology;Statistics","geographic information systems;geophysical image processing;image classification;land cover;land use;matrix algebra;maximum likelihood estimation;temporal databases;visual databases","land use analysis;Nadowli District;Ghana;illegal miners;land use assessment;land cover dynamics;geographic information systems;satellite remote sensing information;land-cover change assessment;land-cover change properties;spatio-temporal data;multispectral data;Landsat satellite imageries;supervised classification;maximum likelihood technique;open Savannah woodlands;closed Savannah woodlands;agricultural land;fallow land;settlement lands;bare lands;post-classification change detection method;LULC change matrix","","1","","15","IEEE","14 Jan 2016","","","IEEE","IEEE Conferences"
"CloudNet: A Deep Learning Approach for Mitigating Occlusions in Landsat-8 Imagery using Data Coalescence","P. Khandelwal; S. Armstrong; A. Matin; S. Pallickara; S. L. Pallickara","Department of Computer Science, Colorado State University, Fort Collins, Colorado; Department of Computer Science, Colorado State University, Fort Collins, Colorado; Department of Computer Science, Colorado State University, Fort Collins, Colorado; Department of Computer Science, Colorado State University, Fort Collins, Colorado; Department of Computer Science, Colorado State University, Fort Collins, Colorado","2022 IEEE 18th International Conference on e-Science (e-Science)","14 Dec 2022","2022","","","117","127","Multi-spectral satellite images that remotely sense the Earth's surface at regular intervals are often contaminated due to occlusion by clouds. Remote sensing imagery captured via satellites, drones, and aircraft has successfully influenced a wide range of fields such as monitoring vegetation health, tracking droughts, and weather forecasting, among others. Researchers studying the Earth's surface are often hindered while gathering reliable observations due to contaminated reflectance values that are sensitive to thin, thick, and cirrus clouds, as well as their shadows. In this study, we propose a deep learning network architecture, CloudNet, to alleviate cloud-occluded remote sensing imagery captured by Landsat-8 satellite for both visible and non-visible spectral bands. We propose a deep neural network model trained on a distributed storage cluster that leverages historical trends within Landsat-8 imagery while complementing this analysis with high-resolution Sentinel-2 imagery. Our empirical benchmarks profile the efficiency of the CloudNet model with a range of cloud-occluded pixels in the input image. We further compare our CloudNet's performance with state-of-the-art deep learning approaches such as SpAGAN and Resnet. We propose a novel method, dynamic hierarchical transfer learning, to reduce computational resource requirements while training the model to achieve the desired accuracy. Our model regenerates features of cloudy images with a high PSNR accuracy of 34.28 dB.","","978-1-6654-6124-5","10.1109/eScience55777.2022.00026","National Science Foundation(grant numbers:OAC-1931363,ACI-1553685); National Institute of Food and Agriculture(grant numbers:COLO-FACT-2019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9973485","remote sensing;deep learning;cloud removal;convolution network","Earth;Deep learning;Training;Satellites;Artificial satellites;Clouds;Computational modeling","clouds;deep learning (artificial intelligence);geophysical image processing;remote sensing","aircraft;cirrus clouds;cloud-occluded remote sensing imagery;CloudNet model;data coalescence;deep learning network;deep neural network model;drones;droughts;Landsat-8 imagery;Landsat-8 satellite;multispectral satellite images;occlusion;Resnet;Sentinel-2 imagery;SpAGAN;transfer learning;vegetation health;weather forecasting","","","","40","IEEE","14 Dec 2022","","","IEEE","IEEE Conferences"
"Determination of Open Pit Mining Zones Through Digital Processing of Multi-Spectral Images and PPI Method - A Case Study of Southern Ecuador","M. V. Cepeda-Velastegui; M. C. López Estévez; O. Padilla-Almeida; T. Toulkeridis","Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador; Instituto Espacial Ecuatoriano, Quito, Ecuador; Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador; Universidad de las Fuerzas Armadas ESPE, Sangolquí, Ecuador","2019 Sixth International Conference on eDemocracy & eGovernment (ICEDEG)","13 Jun 2019","2019","","","188","193","In the current study, the identification of open pit mining areas has been conducted using multispectral satellite images of medium (Landsat 8)and high (Sentinel 2B)spatial resolution of the province of Zamora Chinchipe in southern Ecuador. Such research involved several digital processes such as atmospheric correction, image fusion through the Brovey algorithm, noise elimination among others. We worked simultaneously with spatial and spectral patterns through the application of algorithms in order to increase spatial resolution., and spectral indices that enhance variables of interest. In addition, the Pixel Purity Index (PPI)methodology has been applied in order to obtain the classes involved in the study area based on the pure pixels and the results were compared between the two methodologies. The zones considered open-pit mining have been obtained in both cases.","2573-1998","978-1-7281-1704-1","10.1109/ICEDEG.2019.8734455","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8734455","open pit mining;spectral indexes;Brovey algorithm;PPI;endmembers","Indexes;Earth;Satellites;Artificial satellites;Spatial resolution;Hyperspectral imaging","geophysical image processing;geophysical techniques;image fusion;image resolution;mining;remote sensing","Brovey algorithm;noise elimination;spatial patterns;spectral patterns;spatial resolution;spectral indices;Pixel Purity Indexmethodology;open pit mining zones;digital processing;multispectral images;PPI method;southern Ecuador;open pit mining areas;multispectral satellite images;highspatial resolution;Sentinel 2B;Zamora Chinchipe;digital processes;atmospheric correction;image fusion","","2","","36","IEEE","13 Jun 2019","","","IEEE","IEEE Conferences"
"Classification of Multi-Spectral Satellite Image Using Hierarchical Clustering Algorithms","S. Kulkarni; J. Senthilnath; J. A. Benediktsson","Tiger Analytics, Chennai, India; Institute for Infocomm Research A*STAR, Singapore; Faculty of Electrical and Computer Engineering, University of Iceland, 101, Reykjavik, Iceland","2018 IEEE Symposium Series on Computational Intelligence (SSCI)","31 Jan 2019","2018","","","1664","1669","This work presents hierarchical clustering algorithms for solving the task of crop classification using a multispectral satellite image. The hierarchical clustering algorithms uses splitting and merging techniques, where splitting is used to obtain ideal possible clusters along with its centers. The clusters with its centers are then merged based on a parametric method. Three hierarchical clustering algorithms, namely, the Niche Hierarchical Artificial Immune System (NHAIS), Niche Particle Swarm optimization (NPSO), and Niche Genetic Algorithm (NGA) are applied here for classification. To demonstrate the robustness of the proposed algorithm, results are presented for a real-time multispectral satellite image and an additional benchmark data set from the University of California, Irvine (UCI) repository. A performance comparison between all the three hierarchical clustering algorithms are presented and analyzed. The obtained results show that the NHAIS is most efficient among presented approaches.","","978-1-5386-9276-9","10.1109/SSCI.2018.8628698","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8628698","hierarchical clustering;multispectral;niche genetic algorithm;niche hierarchical immune system;niche particle swarm optimization","Agriculture;Clustering algorithms;Immune system;Satellites;Biological cells;Classification algorithms;Genetic algorithms","artificial immune systems;crops;genetic algorithms;hyperspectral imaging;image classification;particle swarm optimisation;pattern clustering;remote sensing","multispectral satellite image classification;crop classification;merging techniques;splitting techniques;parametric method;NHAIS;niche particle swarm optimization;NPSO;niche genetic algorithm;NGA;benchmark data set;Niche Hierarchical Artificial Immune System;hierarchical clustering algorithms","","","","23","IEEE","31 Jan 2019","","","IEEE","IEEE Conferences"
"Detection of ringforts from aerial photography using machine learning","K. Phelan; D. Riordan","IMaR Research Center, Institute of Technology Tralee, Tralee, Ireland; IMaR Research Center, Institute of Technology Tralee, Tralee, Ireland","2020 31st Irish Signals and Systems Conference (ISSC)","31 Aug 2020","2020","","","1","6","Ringforts are one of the most populous field monuments in Ireland with approximately 45000 examples surviving to date. Their distribution and dispersal patterns are key to our understanding of the habitation patterns of our ancestors. Due to the nature of these structures and the construction materials used, centuries of abandonment means that they often go unnoticed at ground level, while being easily identified from an aerial perspective. The increased requirements of land use for the development of urban areas, infrastructure and increased industrialised farming practices means that these monuments are under threat. Recent developments in the field of machine learning coupled with access to hi-resolution multi-spectral satellite imagery from Open Data sources, presents the opportunity to investigate the development of a system for the automated detection of these features. If successful, such a system could provide an automated, efficient and cost effective tool for the detection of interference or destruction of known sites as well as the discovery of new ones.","2688-1454","978-1-7281-9418-9","10.1109/ISSC49989.2020.9180159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9180159","Archaeology;Machine Learning;Convolutional Neural Network;Remote Sensing;Deep Learning;Aerial Archaeology;Open Data;Geographic Information Systems;GIS;Earth Observation;Ringforts","Machine learning;Earth;Remote sensing;Satellites;Portals;Biological neural networks;Noise measurement","geophysical image processing;learning (artificial intelligence);remote sensing","ringforts;aerial photography;machine learning;populous field monuments;Ireland;dispersal patterns;habitation patterns;ancestors;construction materials;ground level;aerial perspective;land use;urban areas;increased industrialised farming practices;hi-resolution multispectral satellite imagery;open data sources;automated detection","","1","","28","IEEE","31 Aug 2020","","","IEEE","IEEE Conferences"
"Estimation of Individual Potato Plants Area and Volume From Uav-Based Multispectral Images","V. A. Morales; J. Rodriguez Galvis; E. G. Garcia; I. Lizarazo Salcedo","Universidad Distrital Francisco José de Caldas, Bogotá, Colombia; Universidad Nacional de Colombia, Bogota, Colombia; Universidad Distrital Francisco José de Caldas, Bogotá, Colombia; Universidad Nacional de Colombia, Bogota, Colombia","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","6259","6262","This article proposes a method for the estimation of individual plant volume in potato crop fields from images obtained using unmanned aerial vehicles (UAV). Unlike conventional methods, which require significant fieldwork and human effort, the approach to the detection of morphological characteristics and the calculation of automatic structural attributes is neither expensive nor time-consuming. The main components of the method are: (i) image acquisition from UAV, (ii) detection of potato plants and (iii) calculation of the area and volume of individual potato plants. Results show that the proposed method allows accurate detection as good as the methods based on field sampling.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898199","UAV;Computer vision;Precision agriculture;Multiespectral images","Agriculture;Unmanned aerial vehicles;Image color analysis;Estimation;Computer vision;Meters;Digital elevation models","autonomous aerial vehicles;crops;geophysical image processing","potato crop fields;unmanned aerial vehicles;fieldwork;morphological characteristics;automatic structural attributes;image acquisition;field sampling;UAV-based multi-spectral images;human effort;potato plants detection","","1","","11","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Enhanced Multi-Dimensional and Multi-Grained Cascade Forest for Cloud/Snow Recognition Using Multispectral Satellite Remote Sensing Imagery","M. Xia; Z. Wang; F. Han; Y. Kang","College of Information Science and Technology, Donghua University, Shanghai, China; College of Information Science and Technology, Donghua University, Shanghai, China; College of Information Science and Technology, Donghua University, Shanghai, China; College of Information Science and Technology, Donghua University, Shanghai, China","IEEE Access","28 Sep 2021","2021","9","","131072","131086","Cloud/snow recognition is one application of satellite remote sensing imagery in natural disaster monitoring. Deep learning technology has contributed to the improvement of the performance of cloud/snow recognition. However, deep learning-based methods cannot well balance the performance and efficiency of cloud/snow recognition. In this paper, an augmented multi-dimensional and multi-grained Cascade Forest is proposed for cloud/snow recognition. The multi-dimensional deep forest structure with the representation learning ability allows it to capture the spatial and spectral information of cloud/snow satellite imagery accordingly equipped with good recognition efficiency. Besides, a simple augmentation Random Erasing method is introduced for enhancing the robustness of cloud/snow recognition. The experimental results on the HJ-1A/1B dataset show that the proposed method improves the performance of cloud/snow recognition by extracting spectral information from multi-spectral satellite imagery. In addition, based on the tree-based structure, the proposed method well balances the performance and efficiency of cloud/snow recognition, which can be considered as an alternative to the Neural Network for cloud/snow recognition.","2169-3536","","10.1109/ACCESS.2021.3114185","National Natural Science Foundation of China(grant numbers:11972115,11572084); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9541358","Cloud/snow recognition;multi-dimensional and multi-grained;random erasing;representation learning","Feature extraction;Snow;Remote sensing;Image recognition;Satellites;Deep learning;Training","","","","1","","38","CCBY","20 Sep 2021","","","IEEE","IEEE Journals"
"UAV trials for multi-spectral imaging target detection and recognition in maritime environment","H. Silva; J. M. Almeida; F. Lopes; J. P. Ribeiro; S. Freitas; G. Amaral; C. Almeida; A. Martins; E. Silva","INESC TEC Institute for Systems and Computer Engineering of Porto, Porto Polytechnic Institute, Porto, Portugal; INESC TEC Institute for Systems and Computer Engineering of Porto, Porto Polytechnic Institute, Porto, Portugal; INESC TEC Institute for Systems and Computer Engineering of Porto, Porto Polytechnic Institute, Porto, Portugal; INESC TEC Institute for Systems and Computer Engineering of Porto, Porto Polytechnic Institute, Porto, Portugal; INESC TEC Institute for Systems and Computer Engineering of Porto, Porto Polytechnic Institute, Porto, Portugal; INESC TEC Institute for Systems and Computer Engineering of Porto, Porto Polytechnic Institute, Porto, Portugal; INESC TEC Institute for Systems and Computer Engineering of Porto, Porto Polytechnic Institute, Porto, Portugal; INESC TEC Institute for Systems and Computer Engineering of Porto, Porto Polytechnic Institute, Porto, Portugal; INESC TEC Institute for Systems and Computer Engineering of Porto, Porto Polytechnic Institute, Porto, Portugal","OCEANS 2016 MTS/IEEE Monterey","1 Dec 2016","2016","","","1","6","This paper addresses the use of heterogeneous sensors for target detection and recognition in maritime environment. An Unmanned Aerial Vehicle payload was assembled using hyperspectral, infrared, electro-optical, AIS and INS information to collect synchronized sensor data with vessel ground-truth position for conducting air and sea trials. The data collected is used to develop automated robust methods for detect and recognize vessels based on their exogenous physical characteristics and their behaviour across time. Data Processing preliminary results are also presented.","","978-1-5090-1537-5","10.1109/OCEANS.2016.7761259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7761259","Target Detection;Target Tracking;Hyperspectral Imaging;Infrared Imaging;Unmanned Aerial Vehicle;remote sensing;georeferencing","Cameras;Hyperspectral imaging;Payloads;Artificial intelligence;Global Positioning System;Robot sensing systems","autonomous aerial vehicles;control engineering computing;geophysical image processing;marine engineering;object detection;object recognition","UAV trials;multispectral imaging target detection;target recognition;maritime environment;unmanned aerial vehicle payload;AIS information;INS information;electrooptical information;hyperspectral information;infrared information;exogenous physical characteristics;data processing","","4","","12","IEEE","1 Dec 2016","","","IEEE","IEEE Conferences"
"Proba-V cloud detection Round Robin: Validation results and recommendations","R. Q. Iannone; F. Niro; P. Goryl; S. Dransfeld; B. Hoersch; K. Stelzer; G. Kirches; M. Paperin; C. Brockmann; L. Gómez-Chova; G. Mateo-García; R. Preusker; J. Fischer; U. Amato; C. Serio; U. Gangkofner; B. Berthelot; M. . -D. Iordache; L. Bertels; E. Wolters; W. Dierckx; I. Benhadj; E. Swinnen","Serco S.p.A., Frascati, Italy; Serco S.p.A., Frascati, Italy; ESAIESRIN, Via Galileo Galilei, Frascati, Italy; ESAIESRIN, Via Galileo Galilei, Frascati, Italy; ESAIESRIN, Via Galileo Galilei, Frascati, Italy; Brockmann Consult GmbH, Geesthacht, Germany; Brockmann Consult GmbH, Geesthacht, Germany; Brockmann Consult GmbH, Geesthacht, Germany; Brockmann Consult GmbH, Geesthacht, Germany; University of Valencia, Paterna, Spain; University of Valencia, Paterna, Spain; Carl-Heinrich-Becker-Weg 6–10, Freie Universität Berlin, Berlin, Germany; Carl-Heinrich-Becker-Weg 6–10, Freie Universität Berlin, Berlin, Germany; CNR, Napoli, Italy; Universita’ degli studi della Basilicata, Potenza, Italy; eoConsultancy, Frax 516, A-6232 Münster, Austria; Magellium Rue Hermes, Ramonville-Saint-Agne, France; Flemish Institute for Technological Research (VITO), MOLBelgium; Flemish Institute for Technological Research (VITO), MOLBelgium; Flemish Institute for Technological Research (VITO), MOLBelgium; Flemish Institute for Technological Research (VITO), MOLBelgium; Flemish Institute for Technological Research (VITO), MOLBelgium; Flemish Institute for Technological Research (VITO), MOLBelgium","2017 9th International Workshop on the Analysis of Multitemporal Remote Sensing Images (MultiTemp)","14 Sep 2017","2017","","","1","8","This paper discusses results from 12 months of a Round Robin exercise aimed at the inter-comparison of different cloud detection algorithms for Proba-V. Clouds detection is a critical issue for satellite optical remote sensing, since potential errors in cloud masking directly translates into significant uncertainty in the retrieved downstream geophysical products. Cloud detection is particularly challenging for Proba-V due to the presence of a limited number of spectral bands and the lack of thermal infrared bands. The main objective of the project was the inter-comparison of several cloud detection algorithms for Proba-V over a wide range of surface types and environmental conditions. Proba-V Level 2a products have been distributed to six different algorithm providers representing companies and research institutes in several European countries. The considered cloud detection approaches are based on different strategies: Neural Network, Discriminant Analysis, Multi-spectral and Multi-textural Thresholding, Self-Organizing Feature Maps, Dynamic Thresholding, and physically-based retrieval of Cloud Optical Thickness. The results from all algorithms were analysed and compared against a reference dataset, consisting of a large number (more than fifty thousands) of visually classified pixels. The quality assessment was performed according to a uniform methodology and the results provide clear indication on the potential best-suited approach for next Proba-V cloud detection algorithm.","","978-1-5386-3327-4","10.1109/Multi-Temp.2017.8035219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8035219","Proba-V;Cloud Detection Algorithm;Round Robin","Clouds;Land surface;Round robin;Detection algorithms;Reflectivity;MODIS;Satellites","atmospheric techniques;clouds;remote sensing","Proba-V cloud detection Round Robin;satellite optical remote sensing;cloud masking;downstream geophysical products;spectral bands;thermal infrared bands;surface types;environmental conditions;Proba-V level 2a products;European countries;cloud detection approaches;neural network;discriminant analysis;multispectral thresholding;multitextural thresholding;self-organizing feature maps;cloud optical thickness;Proba-V cloud detection algorithm","","5","","31","IEEE","14 Sep 2017","","","IEEE","IEEE Conferences"
"Evaluation of Sentinel-2 Data for Automatic Maasai Boma Mapping","K. Cheng; T. M. Bajkowski; G. J. Scott","Deptartment of Electrical Engineering & Computer Science, University of Missouri, Columbia, MO, USA; Deptartment of Electrical Engineering & Computer Science, University of Missouri, Columbia, MO, USA; Deptartment of Electrical Engineering & Computer Science, University of Missouri, Columbia, MO, USA","2021 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)","26 Apr 2022","2021","","","1","5","Currently, mapping and accounting of certain sub-populations for public health matters is still a prevalent challenge in underdeveloped countries in sub-Sahara Africa, where necessary resources and technologies are still not widely available. This is especially true for the Maasai people in Tanzania. International non-profit groups are leading projects to map the Maasailand boma homesteads in northern Tanzania and provide targeted support for their health on specific matters, such as clean water initiatives, women's and children's health, and basic health clinics. To assist the non-profit group to map the locations of Maasailand boma, we have investigated different types of remote sensing data and deep neural networks that can be applied for broad area search through satellite imagery. Our area of interest encompasses over 3900 square kilometers of Maasailand, where we have manually identified 635 boma homesteads for ground-truth. In this work, we evaluated the application of Sentinel-2 Multispectral Imagery on automatic boma mapping using the ProxylessNAS model. Specifically, we evaluated Sentinel-2 data at different scales for level-1C and level-2A products. Additionally, we extended the ProxylessNAS model to accommodate 4-band full multi-spectral imagery from the sensor. We investigated the 4-band variations that add the near infrared channel to the traditional RGB using the extended ProxylessNAS model. The highest preliminary cross-validation scores using Sentinel-2-1C data and Sentinel-2-2A data are 73.42% and 73.19% respectively. This gives us insight into the utility of medium resolution Sentinel-2 imagery compared to high-resolution imagery in terms of broad area search and localization of boma in Maasailand.","2332-5615","978-1-6654-2471-4","10.1109/AIPR52630.2021.9762131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9762131","","Training;Time-frequency analysis;Image resolution;Satellites;Time series analysis;Data models;Task analysis","geophysical image processing;image classification;image resolution;neural nets;remote sensing","remote sensing data;deep neural networks;broad area search;satellite imagery;3900 square kilometers;635 boma homesteads;Sentinel-2 Multispectral Imagery;automatic boma mapping;Sentinel-2 data;extended ProxylessNAS model;Sentinel-2-1C;Sentinel-2-2A;medium resolution Sentinel-2 imagery;high-resolution imagery;automatic Maasai boma;public health matters;prevalent challenge;underdeveloped countries;sub-Sahara Africa;necessary resources;Maasai people;international nonprofit groups;Maasailand boma homesteads;northern Tanzania;targeted support;specific matters;clean water initiatives;children;basic health clinics;nonprofit group;wavelength 2.0 A","","","","10","IEEE","26 Apr 2022","","","IEEE","IEEE Conferences"
"Study of multispectral polarization visible light propagation properties under smog conditions","Q. Fu; D. Jin; J. Zhan; S. Zhang; Y. Li; Y. Liu; Z. Tao; L. Han; H. Jiang","Institute of Space Optoelectronic Technology, Changchun University of Science and Technology; Institute of Space Optoelectronic Technology, Changchun University of Science and Technology; Institute of Space Optoelectronic Technology, Changchun University of Science and Technology; Institute of Space Optoelectronic Technology, Changchun University of Science and Technology; Institute of Space Optoelectronic Technology, Changchun University of Science and Technology; College of Optical, Changchun University of Science and Technology; College of Optical, Changchun University of Science and Technology; College of Optical, Changchun University of Science and Technology; Institute of Space Optoelectronic Technology, Changchun University of Science and Technology","2017 16th International Conference on Optical Communications and Networks (ICOCN)","30 Nov 2017","2017","","","1","3","Polarization imaging technology has shown great advantages in military reconnaissance, vegetation remote sensing and aerosol detection, and the study of the properties of the polarized light transmission can better promote the development of technology. In this paper, according to the characteristics of multi-spectral polarized light transmission in smog environment, an experimental test device of multiple spectral bands of visible light is built in the smog simulation environment, experiments show that when the wavelength changes between 0.5–0.73um, the polarized light of the circularly polarized light is larger than that of the linearly polarized light, and the linearly polarized light exhibits better polarization characteristics in the other wavelengths of the visible light.","","978-1-5386-3273-4","10.1109/ICOCN.2017.8121274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8121274","Multispectral Polarization;Propagation Properties;Smog Conditions;Visible Light","Polarization;Integrated optics;Optical polarization;Optical attenuators;Optical receivers;Imaging;Meters","aerosols;light polarisation;light propagation;light transmission;polarisation;remote sensing;vegetation mapping","multispectral polarization visible light propagation properties;smog conditions;polarization imaging technology;military reconnaissance;vegetation remote sensing;aerosol detection;multispectral polarized light transmission;multiple spectral bands;smog simulation environment;linearly polarized light exhibits better polarization characteristics;test device;polarized light","","","","9","IEEE","30 Nov 2017","","","IEEE","IEEE Conferences"
"Automatic Land Cover Reconstruction From Historical Aerial Images: An Evaluation of Features Extraction and Classification Algorithms","R. Ratajczak; C. F. Crispim-Junior; E. Faure; B. Fervers; L. Tougne","Laboratoire d’Informatique en Image et Systèmes d’information, University of Lyon, University of Lyon 2, Lyon, France; Laboratoire d’Informatique en Image et Systèmes d’information, University of Lyon, University of Lyon 2, Lyon, France; Leon Bérard Center, Lyon, France; Lyon 1 University, France; Laboratoire d’Informatique en Image et Systèmes d’information, University of Lyon, University of Lyon 2, Lyon, France","IEEE Transactions on Image Processing","22 May 2019","2019","28","7","3357","3371","The land cover reconstruction from monochromatic historical aerial images is a challenging task that has recently attracted an increasing interest from the scientific community with the proliferation of large-scale epidemiological studies involving retrospective analysis of spatial patterns. However, the efforts made by the computer vision community in remote-sensing applications are mostly focused on prospective approaches through the analysis of high-resolution multi-spectral data acquired by the advanced spatial programs. Hence, four contributions are proposed in this paper. They aim at providing a comparison basis for the future development of computer vision algorithms applied to the automation of the land cover reconstruction from monochromatic historical aerial images. First, a new multi-scale multi-date dataset composed of 4.9 million non-overlapping annotated patches of the France territory between 1970 and 1990 has been created with the help of geography experts. This dataset has been named HistAerial. Second, an extensive comparison study of the state-of-the-art texture features extraction and classification algorithms, including deep convolutional neural networks (DCNNs), has been performed. It is presented in the form of an evaluation. Third, a novel low-dimensional local texture filter named rotated-corner local binary pattern (R-CRLBP) is presented as a simplification of the binary gradient contours filter through the use of an orthogonal combination representation. Finally, a novel combination of low-dimensional texture descriptors, including the R-CRLBP filter, is introduced as a light combination of local binary patterns (LCoLBPs). The LCoLBP filter achieved state-of-the-art results on the HistAerial dataset while conserving a relatively low-dimensional feature vector space compared with the DCNN approaches (17 times shorter).","1941-0042","","10.1109/TIP.2019.2896492","French Environment and Energy Management Agency (ADEME)(grant numbers:TEZ17-42); Rhône-Alpes Health-Environment Interface Platform (ENVITERA); Labex(grant numbers:ANR-10-LABX-0088/ANR-11-IDEX-0007); Léon Bérard Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8630683","Features extraction;texture filters;deep convolutional neural networks;deep learning;machine learning;land cover;historical aerial images","Satellites;Earth;Remote sensing;Image reconstruction;Feature extraction;Image resolution;Image segmentation","computer vision;convolutional neural nets;feature extraction;filtering theory;geophysical image processing;image classification;image reconstruction;image resolution;image texture;land cover;remote sensing","automatic land cover reconstruction;classification algorithms;monochromatic historical aerial images;scientific community;large-scale epidemiological studies;retrospective analysis;spatial patterns;computer vision community;remote-sensing applications;high-resolution multispectral data;advanced spatial programs;computer vision algorithms;multiscale multidate dataset;nonoverlapping annotated patches;novel low-dimensional local texture filter;rotated-corner local binary pattern;low-dimensional texture descriptors;local binary patterns;low-dimensional feature vector space;texture features extraction;LCoLBP filter;HistAerial dataset;deep convolutional neural networks","","22","","65","IEEE","31 Jan 2019","","","IEEE","IEEE Journals"
"Single Satellite Optical Imagery Dehazing using SAR Image Prior Based on conditional Generative Adversarial Networks","B. Huang; Z. Li; C. Yang; F. Sun; Y. Song","Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Tsinghua University; Shanghai University Of Engineering Science; Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Tsinghua University; Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Tsinghua University; Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Tsinghua University","2020 IEEE Winter Conference on Applications of Computer Vision (WACV)","14 May 2020","2020","","","1795","1802","Satellite image dehazing aims at precisely retrieving the real situations of the obscured parts from the hazy remote sensing (RS) images, which is a challenging task since the hazy regions contain both ground features and haze components. Many approaches of removing haze focus on processing multi-spectral or RGB images, whereas few of them utilize multi-sensor data. The multi-sensor data fusion is significant to provide auxiliary information since RGB images are sensitive to atmospheric conditions. In this paper, a dataset called SateHaze1k is established and composed of 1200 pairs clear Synthetic Aperture Radar (SAR), hazy RGB, and corresponding ground truth images, which are divided into three degrees of the haze, i.e. thin, moderate, and thick fog. Moreover, we propose a novel fusion dehazing method to directly restore the haze-free RS images by using an end-to-end conditional generative adversarial network(cGAN). The proposed network combines the information of both RGB and SAR images to eliminate the image blurring. Besides, the dilated residual blocks of the generator can also sufficiently improve the dehazing effects. Our experiments demonstrate that the proposed method, which fuses the information of different sensors applied to the cloudy conditions, can achieve more precise results than other baseline models.","2642-9381","978-1-7281-6553-0","10.1109/WACV45572.2020.9093471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093471","","Synthetic aperture radar;Satellites;Remote sensing;Gallium nitride;Task analysis;Optical imaging;Optical sensors","image colour analysis;image enhancement;image restoration;neural nets;radar imaging;remote sensing by radar;sensor fusion;spaceborne radar;synthetic aperture radar","synthetic aperture radar;hazy RGB;fusion dehazing method;haze-free RS images;image blurring;dehazing effects;cloudy conditions;single satellite optical imagery dehazing;SAR image;conditional generative adversarial networks;hazy remote sensing images;ground features;RGB images;multisensor data fusion;ground truth images;cGAN;SateHaze1k;multispectral images","","14","","39","IEEE","14 May 2020","","","IEEE","IEEE Conferences"
"Wildland Fire Detection and Monitoring Using a Drone-Collected RGB/IR Image Dataset","X. Chen; B. Hopkins; H. Wang; L. O’Neill; F. Afghah; A. Razi; P. Fulé; J. Coen; E. Rowell; A. Watts","School of Computing, Clemson University, Clemson, SC, USA; Department of Electrical and Computer Engineering, Clemson University, Clemson, SC, USA; School of Computing, Clemson University, Clemson, SC, USA; School of Forestry, Northern Arizona University, Flagstaff, AZ, USA; Department of Electrical and Computer Engineering, Clemson University, Clemson, SC, USA; School of Computing, Clemson University, Clemson, SC, USA; School of Forestry, Northern Arizona University, Flagstaff, AZ, USA; National Center for Atmospheric Research, Boulder, CO, USA; Desert Research Institute, Reno, NV, USA; U.S. Forest Service, Pacific Wildland Fire Science Laboratory, Seattle, WA, USA","IEEE Access","24 Nov 2022","2022","10","","121301","121317","Current forest monitoring technologies including satellite remote sensing, manned/piloted aircraft, and observation towers leave uncertainties about a wildfire’s extent, behavior, and conditions in the fire’s near environment, particularly during its early growth. Rapid mapping and real-time fire monitoring can inform in-time intervention or management solutions to maximize beneficial fire outcomes. Drone systems’ unique features of 3D mobility, low flight altitude, and fast and easy deployment make them a valuable tool for early detection and assessment of wildland fires, especially in remote forests that are not easily accessible by ground vehicles. In addition, the lack of abundant, well-annotated aerial datasets – in part due to unmanned aerial vehicles’ (UAVs’) flight restrictions during prescribed burns and wildfires – has limited research advances in reliable data-driven fire detection and modeling techniques. While existing wildland fire datasets often include either color or thermal fire images, here we present (1) a multi-modal UAV-collected dataset of dual-feed side-by-side videos including both RGB and thermal images of a prescribed fire in an open canopy pine forest in Northern Arizona and (2) a deep learning-based methodology for detecting fire and smoke pixels at accuracy much higher than the usual single-channel video feeds. The collected images are labeled to “fire” or “no-fire” frames by two human experts using side-by-side RGB and thermal images to determine the label. To provide context to the main dataset’s aerial imagery, the included supplementary dataset provides a georeferenced pre-burn point cloud, an RGB orthomosaic, weather information, a burn plan, and other burn information. By using and expanding on this guide dataset, research can develop new data-driven fire detection, fire segmentation, and fire modeling techniques.","2169-3536","","10.1109/ACCESS.2022.3222805","Air Force Office of Scientific Research(grant numbers:FA9550-20-1-0090); National Science Foundation(grant numbers:CNS-2232048,CNS-2204445,CNS-2038741,CNS-2038759); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9953997","Data-driven fire detection;prescribed fire;fire modeling;fire data;unmanned aerial vehicle (UAV);deep learning","Data models;Fires;Autonomous aerial vehicles;Deep learning;Forests;Monitoring;Satellite navigation systems;Remote sensing","autonomous aerial vehicles;deep learning (artificial intelligence);forestry;geophysical image processing;image colour analysis;image fusion;infrared imaging;object detection;remote sensing;robot vision;video signal processing;wildfires","3D mobility;beneficial fire outcomes;burn information;deep learning-based methodology;drone systems;drone-collected RGB-IR image dataset;dual-feed side-by-side videos;fire modeling techniques;fire segmentation;forest monitoring technologies;georeferenced pre-burn point cloud;ground vehicles;guide dataset;in-time intervention;low flight altitude;multimodal UAV-collected dataset;no-fire frames;Northern Arizona;observation towers;open canopy pine forest;prescribed burns;prescribed fire;real-time fire monitoring;reliable data-driven fire detection;remote forests;RGB orthomosaic;satellite remote sensing;smoke pixels;thermal images;unmanned aerial vehicles;well-annotated aerial datasets;wildland fire datasets;wildland fire detection","","","","84","CCBY","17 Nov 2022","","","IEEE","IEEE Journals"
"CCAD-Net: A Cascade Cloud Attribute Discrimination Network for Cloud Genera Segmentation in Whole-Sky Images","L. Ye; Z. Cao; Z. Yang; H. Min","School of Information Science and Engineering/School of Artificial Intelligence, Institute of Robotics and Intelligent Systems, Wuhan University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; Hubei Meteorological Bureau of China Meteorological Administration, Wuhan, China; School of Information Science and Engineering/School of Artificial Intelligence, Institute of Robotics and Intelligent Systems, Wuhan University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","30 Jun 2022","2022","19","","1","5","Cloud detection and recognition are two important tasks usually referring to image binary segmentation and image-level classification individually. Cloud genera segmentation has more practical significance but is much more challenging as a fine-grained pixel-level dense prediction problem. In this letter, a cascade cloud attribute discrimination network (CCAD-Net) is proposed. Based on an improved encoding–decoding model, CCAD-Net adds a binary segmentation branch for cloud detection and an attribute discrimination branch for cloud attribute feature learning in the decoding stage. Especially, in the attribute discrimination branch, several visual attributes are selected to design the attribute discrimination constraint according to prior professional knowledge and the corresponding loss function is defined. These two additional branches and the final cloud genera segmentation branch extract their task-specific features successively and form a cascade structure. Due to the fusion of raw feature, binary segmentation feature, attribute discrimination feature, and cloud genera feature, CCAD-Net can achieve significantly better performance than the state-of-the-art methods in cloud genera segmentation in whole-sky images.","1558-0571","","10.1109/LGRS.2022.3184961","China Postdoctoral Science Foundation(grant numbers:2020M672426); National Natural Science Foundation of China(grant numbers:62073249); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9802517","Cloud detection;cloud type recognition;convolutional neural network;image segmentation","Feature extraction;Image segmentation;Task analysis;Integrated circuits;Decoding;Clouds;Semantics","clouds;feature extraction;geophysical image processing;image classification;image segmentation;learning (artificial intelligence)","CCAD-net;cascade cloud;discrimination network;whole-sky images;cloud detection;image binary segmentation;image-level;fine-grained pixel-level dense prediction problem;CCAD-Net;binary segmentation branch;attribute discrimination branch;cloud attribute feature;visual attributes;attribute discrimination constraint;final cloud genera segmentation branch;binary segmentation feature;discrimination feature;cloud genera feature","","","","21","IEEE","21 Jun 2022","","","IEEE","IEEE Journals"
"Study on panchromatic and multispectral image fusion based on SFIM and CA transform","Guiqing He; Zhuqiang Shao; Siyuan Xing; DanDan Dong; Xiaoyi Feng","School of Electronics and Information, Northwestern Polytechnical University, Xi'an, Shaanxi, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, Shaanxi, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, Shaanxi, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, Shaanxi, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, Shaanxi, China","2016 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","24 Nov 2016","2016","","","1","6","With the successive launch and rapid development of the new satellite WorldView-2 and WorldView-3, panchromatic and multispectral image fusion become a hot research topic. To resolve the dilemma of the currently existing methods for panchromatic and multispectral image fusion, viz. unavoidable spectral distortion or the need to introduce cumbersome frequency analysis and reconstruction, a method has been proposed which is based on SFIM (Smoothing Filter-based Intensity Modulation) and CA (Correspondence Analysis). Firstly, the weighted gradient adaptive filtering SFIM model is introduced, whose simple calculation feature has been utilized to extract the spatial information of panchromatic images. Secondly, the statistical CA transform has been brought in and its multivariable analysis feature has been used to process the infusion of spatial information. As a result of the above two processes the novel fusion method has been proposed which is based on SFIM and CA transform. Theoretical and experimental studies show that the proposed method can not only significantly maintain spectral characteristics, in absence of frequency decomposition and reconstruction, but also effectively infuse detailed spatial information, along with the elegancy of simple calculation and real time. In the scenario of panchromatic and multi-spectral image fusion such as similar lighting conditions and physical properties, the proposed method is more suitable for the fusion systems which require fast interactive processing and real-time visualization, and is better than those which are based upon multi-scale analysis.","","978-1-5090-2708-8","10.1109/ICSPCC.2016.7753705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7753705","Image fusion;SFIM;CA;Gradient weighted adaptive filtering","Transforms;Smoothing methods;Satellites;Spatial resolution;Information filters;Image fusion","adaptive filters;geophysical image processing;image filtering;image fusion;remote sensing;smoothing methods;transforms","multispectral image fusion;panchromatic image fusion;smoothing filter-based intensity modulation;correspondence analysis;weighted gradient adaptive filtering SFIM model;statistical CA transform;multivariable analysis feature;spatial information infusion;satellite remote sensing","","","","10","IEEE","24 Nov 2016","","","IEEE","IEEE Conferences"
"S3: A Spectral-Spatial Structure Loss for Pan-Sharpening Networks","J. -S. Choi; Y. Kim; M. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Artificial Intelligence Research Division, Korea Aerospace Research Institute, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Geoscience and Remote Sensing Letters","22 Apr 2020","2020","17","5","829","833","Recently, many deep-learning-based pan-sharpening methods have been proposed for generating high-quality pan-sharpened (PS) satellite images. These methods focused on various types of convolutional neural network (CNN) structures, which were trained by simply minimizing a spectral loss between network outputs and the corresponding high-resolution (HR) multi-spectral (MS) target images. However, owing to different sensor characteristics and acquisition times, HR panchromatic (PAN) and low-resolution MS image pairs tend to have large pixel misalignments, especially for moving objects in the images. Conventional CNNs trained with only the spectral loss with these satellite image data sets often produce PS images of low visual quality including double-edge artifacts along strong edges and ghosting artifacts on moving objects. In this letter, we propose a novel loss function, called a spectral-spatial structure (S3) loss, based on the correlation maps between MS targets and PAN inputs. Our proposed S3 loss can be very effectively used for pan-sharpening with various types of CNN structures, resulting in significant visual improvements on PS images with suppressed artifacts.","1558-0571","","10.1109/LGRS.2019.2934493","National Research Foundation of Korea (NRF); Ministry of Science, ICT and Future Planning through the Basic Science Research Program(grant numbers:2017R1A2A2A05001476); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812763","Convolutional neural network (CNN);deep learning;pan colorization;pan-sharpening;satellite imagery;spectral-spatial structure;super-resolution (SR)","Training;Satellites;Correlation;Spatial resolution;Visualization;Convolutional neural networks","convolutional neural nets;geophysical image processing;image classification;image fusion;image resolution;learning (artificial intelligence);remote sensing","spectral-spatial structure loss;MS targets;PAN inputs;CNN structures;PS images;deep-learning-based pan-sharpening methods;high-quality pan-sharpened satellite images;convolutional neural network structures;spectral loss;network outputs;multispectral target images;HR panchromatic;moving objects;satellite image data sets;double-edge artifacts;strong edges;ghosting artifacts;loss function","","11","","32","IEEE","26 Aug 2019","","","IEEE","IEEE Journals"
"SAR-to-Optical Image Translation Using Supervised Cycle-Consistent Adversarial Networks","L. Wang; X. Xu; Y. Yu; R. Yang; R. Gui; Z. Xu; F. Pu","Collaborative Sensing Laboratory, School of Electronic Information, Wuhan University, Wuhan, China; Collaborative Sensing Laboratory, School of Electronic Information, Wuhan University, Wuhan, China; Collaborative Sensing Laboratory, School of Electronic Information, Wuhan University, Wuhan, China; Collaborative Sensing Laboratory, School of Electronic Information, Wuhan University, Wuhan, China; Collaborative Sensing Laboratory, School of Electronic Information, Wuhan University, Wuhan, China; Electrical Engineering Department, Stanford University, Stanford, CA, USA; Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China","IEEE Access","19 Sep 2019","2019","7","","129136","129149","Optical remote sensing (RS) data suffer from the limitation of bad weather and cloud contamination, whereas synthetic aperture radar (SAR) can work under all weather conditions and overcome this disadvantage of optical RS data. However, due to the imaging mechanism of SAR and the speckle noise, untrained people are difficult to recognize the land cover types visually from SAR images. Inspired by the excellent image-to-image translation performance of Generative Adversarial Networks (GANs), a supervised Cycle-Consistent Adversarial Network (S-CycleGAN) was proposed to generate large optical images from the SAR images. When the optical RS data are unavailable or partly unavailable, the generated optical images can be alternative data that aid in land cover visual recognition for untrained people. The main steps of SAR-to-optical image translation were as follows. First, the large SAR image was split to small patches. Then S-CycleGAN was used to translate the SAR patches to optical image patches. Finally, the optical image patches were stitched to generate the large optical image. A paired SAR-optical image dataset which covered 32 Chinese cities was published to evaluate the proposed method. The dataset was generated from Sentinel-1 (SEN-1) SAR images and Sentinel-2 (SEN-2) multi-spectral images. S-CycleGAN was applied to two experiments, which were SAR-to-optical image translation and cloud removal, and the results showed that S-CycleGAN could keep both the land cover and structure information well, and its performance was superior to some famous image-to-image translation models.","2169-3536","","10.1109/ACCESS.2019.2939649","National Basic Research Program of China (973 Program)(grant numbers:2016YFB0502600); Thirteen-Five Civil Aerospace Planning Project — Integration of Communication, Navigation and Remote Sensing Comprehensive Application Technology; Chinese Technology Research and Development of the Major Project of High-Resolution Earth Observation System(grant numbers:03-Y20A10-9001-15/16); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8825802","SAR-to-optical image translation;visualization;GAN;Sentinel;cloud removal","Radar polarimetry;Optical imaging;Clouds;Optical sensors;Adaptive optics;Optical polarization;Gallium nitride","geophysical image processing;optical images;radar imaging;remote sensing by radar;synthetic aperture radar;terrain mapping","SAR-to-optical image translation;supervised Cycle-Consistent Adversarial Networks;optical remote sensing data;optical RS data;imaging mechanism;generated optical images;SAR patches;optical image patches;paired SAR-optical image dataset;Sentinel-1 SAR images;multispectral images;image-to-image translation models;S-CycleGAN;Chinese cities;land cover;Generative Adversarial Networks;weather conditions;cloud contamination;bad weather","","59","","58","CCBY","5 Sep 2019","","","IEEE","IEEE Journals"
"Kluster: Application of k-means clustering to multidimensional GEO-spatial data","M. Alkathiri; J. Abdul; M. B. Potdar","Bhaskaracharya Institute for Space Applications and Geo-informatics (BISAG), Gandhinagar, India; Bhaskaracharya Institute for Space Applications and Geo-informatics (BISAG), Gandhinagar, India; Bhaskaracharya Institute for Space Applications and Geo-informatics (BISAG), Gandhinagar, India","2017 International Conference on Information, Communication, Instrumentation and Control (ICICIC)","5 Feb 2018","2017","","","1","7","There have been several developments both in hardware and softwares for capturing and processing geographic information. The results yield by the processing of geo-spatial data helps for efficient planning and strategic decision making. Due to the amount of geo-spatial data captured and stored every day, it has become of utmost importance that the data be processed and the results be delivered in time. With the increasing amount of data, application of distributed and parallel frameworks which have been proven capable of processing large amounts of data in other domains has become necessary. These frameworks have to be extended to support geo-spatial data and related geo-processing operations. In this paper, we have extended the regular k-means clustering to support processing of multi spectral geo-spatial raster data over Hadoop. By performing clustering on multiple dimensions (multiple spectrums) simultaneously over a distributed processing framework, Apache Hadoop, our approach allows detailed clustering. Our approach in addition to considering n-dimensional data also allows processing it by utilizing heterogeneous and distributed resources for faster processing and delivery results.","","978-1-5090-6313-0","10.1109/ICOMICON.2017.8279080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279080","multi-spectral data;geo-spatial data processing;distributed geo-processing;k-means clustering;spatial processing","Distributed databases;Data mining;Earth;Distributed processing;Remote sensing;Big Data;Sensors","data analysis;distributed processing;geographic information systems;geophysics computing;pattern clustering","geographic information processing;multiple spectrums;Apache Hadoop;distributed resources;heterogeneous resources;n-dimensional data;distributed processing framework;multispectral geo-spatial raster data;related geo-processing operations;multidimensional geo-spatial data","","1","","15","IEEE","5 Feb 2018","","","IEEE","IEEE Conferences"
"Residual Dense Network for Pan-Sharpening Satellite Data","D. S. Vinothini; B. S. Bama","Department of Electronics and Communication Engineering, Thiagarajar College of Engineering, Madurai, India; Department of Electronics and Communication Engineering, Thiagarajar College of Engineering, Madurai, India","IEEE Sensors Journal","4 Dec 2019","2019","19","24","12279","12285","Pan-sharpening is a multi-sensor fusion task that aims to enhance the spatial resolution of spectral data using panchromatic data of the same scene. This work proposes a deep Residual Dense Model (RDM) for Pan-Sharpening (PS) of satellite data which learns hierarchical features that can efficiently represent the local complex structures from panchromatic data. This work addresses the two general problems emphasized in pan-sharpening application viz., spectral and spatial preservation. The proposed Residual Dense Model for Pan-Sharpening network (RDMPSnet), preserves the spectral information by spectral mapping of Low-Resolution Multi-Spectral data (LRMS) while the spatial preservation is achieved by learning the hierarchical structural features from High-Resolution Panchromatic data (HRP). To extract this structural feature RDMPSnet is trained end to end with Low Resolution (LR) panchromatic patches and High Resolution (HR) residue patches to learn a non-linear mapping. The trained non-linear mapping network is capable to generate structural feature for any LRMS data which is injected into the mapped spectral data. The network is experimentally evaluated with Worldview2 and IKONOS2 satellite data and shows that the proposed RDMPS achieves favorable performance both visually and quantitatively against state-of-the-art methods.","1558-1748","","10.1109/JSEN.2019.2939844","University Grants Commission(grant numbers:F117.1/201516/MANF201517TAM-55205); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8826277","Satellite data;pan-sharpening;multi-spectral image;panchromatic image;deep learning","Training;Image reconstruction;Spatial resolution;Feature extraction;Satellites;Convolution;Sensors","feature extraction;geophysical image processing;image classification;image fusion;image reconstruction;image resolution;learning (artificial intelligence);remote sensing;sensor fusion;terrain mapping","pan-sharpening application viz;spatial preservation;Pan-Sharpening network;spectral information;spectral mapping;Low-Resolution MultiSpectral data;hierarchical structural features;High-Resolution Panchromatic data;structural feature RDMPSnet;Low Resolution panchromatic patches;High Resolution residue patches;nonlinear mapping network;LRMS data;mapped spectral data;IKONOS2 satellite data;Residual Dense network;Pan-Sharpening satellite data;multisensor fusion task;spatial resolution;deep Residual Dense Model;hierarchical features;local complex structures","","1","","20","IEEE","6 Sep 2019","","","IEEE","IEEE Journals"
"Detecting Pine Trees Damaged by Wilt Disease Using Deep Learning Techniques Applied to Multi-Spectral Images","R. Zhang; J. You; J. Lee","Department of Computer Science and Engineering, Artificial Intelligence Laboratory, Jeonbuk National University, Jeoju, South Korea; Department of Computer Science and Engineering, Artificial Intelligence Laboratory, Jeonbuk National University, Jeoju, South Korea; Department of Computer Science and Engineering, Artificial Intelligence Laboratory, Jeonbuk National University, Jeoju, South Korea","IEEE Access","18 Apr 2022","2022","10","","39108","39118","Pine wilt disease (PWD) is responsible for significant damage to East Asia’s pine forests, including those in Korea, Japan, and China. Preventing the spread of wilt disease requires early detection and removal of damaged trees. This paper proposes a method of detecting disease-damaged pines using ortho-images corrected from 5-band multi-spectral images captured by unmanned aviation vehicles. The proposed method relies on a ResNet18 backbone network connected to a modified DenseNet module, classifies the 5-band multispectral (RGB, NIR, Red_Edge) ortho-image patches, and visualizes the results as a heat map. The patch-based classifier was retrained with hard negative examples, after which it achieved 98.66% accuracy, an improvement over the 96.0% accuracy associated with the same method applied to RGB images. The resulting heat map reflects the approximate distribution, and movement of the disease. Disease locations are also predicted by local maximums in the heat map. When the distance between a ground truth and the predicted location is less than visible distance, e.g. about 5m, it is counted as a correct detection. The proposed detection which consists of heat map generation followed by localization achieves Recall of 93.39%, Precision of 88.26%, and F1-score of 90.75%.","2169-3536","","10.1109/ACCESS.2022.3155531","Korea Land and Geospatial Informatix Corporation (lxsiri)(grant numbers:2019-506); 2021 Cangzhou Science and Technology Plan Program(grant numbers:213102007); 2022 Scientific Research Projects of Colleges and Universities in Hebei Province(grant numbers:QN2022200); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723042","Pine wilt disease;multispectral ortho-image;heat map;deep learning classification","Diseases;Vegetation;Deep learning;Training;Heating systems;Forestry;Random forests","deep learning (artificial intelligence);forestry;geophysical image processing;image classification;image colour analysis;object detection;plant diseases;vegetation;vegetation mapping","5-band multispectral images;unmanned aviation vehicles;ResNet18 backbone network;modified DenseNet module;ortho-image patches;patch-based classifier;hard negative examples;RGB images;heat map;disease locations;heat map generation;pine trees;deep learning techniques applied;pine wilt disease;East Asia's pine forests;damaged trees;disease-damaged pines;ortho-images;size 5.0 m","","2","","38","CCBY","28 Feb 2022","","","IEEE","IEEE Journals"
"A multi/hyper-spectral imaging system for land use/land cover using unmanned aerial systems","A. Mancini; E. Frontoni; P. Zingaretti","Dipartimento di Ingegneria dell'Informazione, Università Politecnica delle Marche, Ancona, ITALY; Dipartimento di Ingegneria dell'Informazione, Università Politecnica delle Marche, Ancona, ITALY; Dipartimento di Ingegneria dell'Informazione, Università Politecnica delle Marche, Ancona, ITALY","2016 International Conference on Unmanned Aircraft Systems (ICUAS)","4 Jul 2016","2016","","","1148","1155","During last years the automated classification enabled by Unmanned Aerial System (UASs) captured the interest of many investors and researchers. Several applications could be explored ranging from precision agriculture to Land Use / Land Cover (LU/LC) thematic mapping. The use of UASs is novel when we consider the very high resolution (VHR) multi-hyper spectral sensing of a given area. Remote sensing and LU/LC have a strong intersection from many years even if only in the last period VHR images over several bands are applicable considering the technological progress. Today it is possible to acquire data in Visible (VIS) - Near InfraRed (NIR)-Short Wave InfraRed (SWIR) by using compact and low cost sensors that could be integrated into small size UAS. These sensors overcame the main limitations of classical remote sensed data from satellite increasing the spectral, spatial and temporal resolution also reducing the influence of clouds and water vapor on atmospheric absorption. In particular, in this paper we propose an imaging system to perform analysis from thematics maps derived from hyper-spectral radiometers and multi-spectral cameras mounted on UAS. The high spectral and geometric resolution enhance the level of details of a LU/LC maps. We propose also a novel method to fast classify data by using an improved version of the k-means algorithm. The proposed method significantly reduces the computational time especially for very large high-resolution data-set. Comparison of k-means over regular grid and quadtree decomposition are discussed.","","978-1-4673-9334-8","10.1109/ICUAS.2016.7502662","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7502662","","Indexes;Sensors;Remote sensing;Payloads;Imaging;Spatial resolution","autonomous aerial vehicles;cameras;cartography;geophysical image processing;hyperspectral imaging;image classification;image resolution;land cover;land use;remote sensing","hyperspectral imaging system;multispectral imaging system;land use-land cover;unmanned aerial systems;unmanned aerial system;UASs;LU-LC thematic mapping;very high resolution multihyper spectral sensing;VHR images;visible-near infrared data;VIS-NIR data;short wave infrared data;SWIR data;classical remote sensed data;temporal resolution;spatial resolution;satellite;spectral resolution;water vapor;cloud influence reduction;atmospheric absorption;hyper-spectral radiometers;multispectral cameras;geometric resolution;k-means algorithm;data classification;high-resolution dataset;regular grid;quadtree decomposition;automated classification;low cost sensors","","8","","34","IEEE","4 Jul 2016","","","IEEE","IEEE Conferences"
"Surface Normal Vector Estimation From Passive Millimeter-Wave Polarimetric Imaging","Y. Hu; F. Hu; Y. Cheng; Y. Xu; J. Su","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Engineering Laboratory for Dangerous Articles and Explosives Detection Technologies, Beijing, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","6 Jan 2020","2019","12","11","4554","4562","Surface normal vector is essential for object recognition and three-dimensional reconstruction. This article establishes a passive millimeter-wave polarization observation model of object thermal radiation. Then, a polarization-based method is proposed to acquire the surface normal vector from multipolarization measurements. The simulation results show that our method has high accuracy and robustness. The outdoor imaging experiment was conducted, and the polarization characteristics of several typical objects in the imaging were analyzed. Experimental results show that our method can successfully estimate the surface normal vector. The possible applications of our method include object recognition and pavement inspection.","2151-1535","","10.1109/JSTARS.2019.2950102","National Natural Science Foundation of China(grant numbers:61871438,61901242); China Postdoctoral Science Foundation(grant numbers:2019M660640); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920191","Information acquisition;passive millimeter-wave (PMMW);polarimetric measurement;radiation imaging;surface orientation estimation","Object recognition;Radiation imaging;Radiometry;Surface impedance;Millimeter wave technology;Azimuth;Polarization","image reconstruction;millimetre wave imaging;object recognition;polarimetry","pavement inspection;three-dimensional reconstruction;passive millimeter-wave polarization observation model;object recognition;passive millimeter-wave polarimetric imaging;surface normal vector estimation;outdoor imaging experiment;polarization-based method;object thermal radiation","","6","","25","IEEE","3 Dec 2019","","","IEEE","IEEE Journals"
"Sparse fusion based on SAM elective sample dictionary establishment","X. Sun","Department of Geography, Minjiang College, Fuzhou, Fujian, China","2016 IEEE International Conference on Mechatronics and Automation","5 Sep 2016","2016","","","68","72","In the paper, it is proposed that multi-spectral image pure pixel is utilized for completing SAM classification. The classified samples are utilized for electively constructing sparse dictionary, thereby improving the representativeness of the dictionary. Eight surface feature types are set in Landsat8 image. PPI index is used for calculating pure pixel index of each pixel. Pure pixel of each surface feature is further extracted through N-D visualizer, which is used for SAM calculation. Eight kinds of surface feature samples are selected from SAM image for online dictionary learning. Multi-spectral image sparse dictionary is generated. Multi-spectral image sparse coefficient is calculated through dictionary and OMP. Meanwhile, online dictionary and OMP are utilized for obtaining panchromatic image sparse coefficient. Fusion sparse coefficient is generated by maximum values both sparse coefficients. Multi-spectral image sparse dictionary is combined for reconstructing and generating fusion image. Eight quantitative fusion evaluation indicators are adopted for comparing algorithm fusion and weighted fusion in the paper. Fusion method proposed in the paper contains more information, fusion image texture detail information is improved, and better image multi-spectral information is kept.","2152-744X","978-1-5090-2396-7","10.1109/ICMA.2016.7558536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7558536","Sparse dictionary;Online dictionary learning algorithm;OMP algorithm;SAM","Dictionaries;Indexes;Feature extraction;Hyperspectral imaging;Image resolution;Classification algorithms","feature extraction;geophysical image processing;image classification;image fusion;image reconstruction;image texture;learning (artificial intelligence);remote sensing;sparse matrices;spectral analysis","sparse fusion;SAM elective-sample dictionary establishment;multispectral image pure pixel;SAM classification;dictionary representativeness;Landsat8 image;surface feature types;PPI index;pure-pixel index;surface feature extraction;N-D visualizer;online dictionary learning;multispectral image sparse dictionary;multispectral image sparse coefficient;online dictionary;OMP;panchromatic image sparse coefficient;fusion sparse coefficient;maximum sparse coefficient values;fusion image reconstruction;fusion image generation;quantitative fusion evaluation indicators;algorithm fusion;weighted fusion;image texture detail information improvement;image multispectral information","","","","14","IEEE","5 Sep 2016","","","IEEE","IEEE Conferences"
"Bidimentional emphirical mode decomposition based image fusion","A. Khan; P. Agrawal; H. Sainthiya","Digital and Communication Department, Jaipur Institute of Technology, Jaipur; Digital and Communication Department, Jaipur Institute of Technology, Jaipur; Electronics and Comm. Department, BIET, Jhansi","2017 International Conference on Recent Innovations in Signal processing and Embedded Systems (RISE)","11 Jun 2018","2017","","","212","217","The image fusion plays a crucial role in many fields such as remote sensing, medical and robotics applications. This paper is focused on image fusion of images of different focus depth. The aim is to study these concepts and provide simulations and evaluations on various implementations. When performing image fusion the images are decomposed by bi-dimensional Empirical mode decomposition (BEMD) to obtain high frequency coefficients which is used to determine which parts of the input images that makes it into the fused image. The same technique is tested on images of different modality. In this thesis, a novel bi-dimensional Empirical mode decomposition (BEMD) based image fusion scheme is proposed. The BEMD decomposes the source images into intrinsic mode functions (IMFs) and residual components. IMF components of the first signal in the decomposition of the source images are used to generate the fused images using appropriate fusion rule. Performance evaluation of fused images is done by computing fusion quality metrics and the fusion results are compared with other existing fusion schemes. It is seen that the performance of the proposed scheme is better as compared with the existing fusion schemes.","","978-1-5090-4760-4","10.1109/RISE.2017.8378156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8378156","Image fusion;BEMD;Medical images;Multi-spectral images;Multifocus image","Image fusion;Image edge detection;Empirical mode decomposition;Biomedical imaging;Loss measurement","Hilbert transforms;image fusion","BEMD;input images;fused image;source images;residual components;fusion quality metrics;focus depth;bidimensional Empirical mode decomposition based image fusion scheme;intrinsic mode functions;fusion rule;high frequency coefficients","","1","","","IEEE","11 Jun 2018","","","IEEE","IEEE Conferences"
"Low-cost multispectral imaging system for crop monitoring","A. M. de Oca; L. Arreola; A. Flores; J. Sanchez; G. Flores","Perception and Robotics Laboratory, Centro de Investigaciones en Óptica, León, Guanajuato, Mexico; Perception and Robotics Laboratory, Centro de Investigaciones en Óptica, León, Guanajuato, Mexico; Perception and Robotics Laboratory, Centro de Investigaciones en Óptica, León, Guanajuato, Mexico; Perception and Robotics Laboratory, Centro de Investigaciones en Óptica, León, Guanajuato, Mexico; Perception and Robotics Laboratory, Centro de Investigaciones en Óptica, León, Guanajuato, Mexico","2018 International Conference on Unmanned Aircraft Systems (ICUAS)","2 Sep 2018","2018","","","443","451","This work presents the design and development of a multispectral imaging system to precision agriculture tasks. The imaging system features two small digital cameras controlled by a microcomputer embedded in a drone. One of the cameras has been modified to be sensitive to near-infrared radiation reflected by the vegetation, whereas the other one remains as a common RGB camera. In order to determine the health status of the crop, the Normalized Difference Vegetation Index (NDVI) is computed in a developed software. Once the aerial imagery is obtained by the drone, it is processed to eliminate image distortions and insert specific metadata needed for generating the orthomosaics with the health information of the plant or soil of interest. Finally, the vegetation index will be computed from the visible and near-infrared orthomosaics for a better interpretation of the user. Experiments are presented to show the effectiveness of the system.","2575-7296","978-1-5386-1354-2","10.1109/ICUAS.2018.8453426","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453426","UAV;Drone;Precision Agriculture;Multi-spectral Imaging;Image georeferencing;Normalized Difference Vegetation Index;Aerial photogrammetry","Cameras;Agriculture;Software;Microcomputers;Vegetation mapping;Drones;Indexes","agriculture;cameras;crops;environmental monitoring (geophysics);geophysical image processing;meta data;remote sensing","RGB camera;aerial imagery;metadata;crop monitoring;low-cost multispectral imaging system;near-infrared orthomosaics;visible infrared orthomosaics;health information;image distortions;Normalized Difference Vegetation Index;health status;drone;digital cameras;precision agriculture tasks","","17","","28","IEEE","2 Sep 2018","","","IEEE","IEEE Conferences"
"Improving Variable Rate Treatments by Integrating Aerial and Ground Remotely Sensed Data","A. Mancini; E. Frontoni; P. Zingaretti","Dipartimento di Ingegneria dell'Informazione, Università Politecnica delle Marche, Ancona, ITALY; Dipartimento di Ingegneria dell'Informazione, Università Politecnica delle Marche, Ancona, ITALY; Dipartimento di Ingegneria dell'Informazione, Università Politecnica delle Marche, Ancona, ITALY","2018 International Conference on Unmanned Aircraft Systems (ICUAS)","2 Sep 2018","2018","","","856","863","The problem of tree/plant volume and health estimation plays a key role in precision agriculture applications especially for Variable Rate Treatments (VRT). Today VRTs are available at reasonable costs and most of the platforms are able to apply a given rate in a given position by using a prescription map that is usually designed by an agronomist basing on historical data and scouting on the field. In this scenario several technologies are involved at different stages as the acquisition of data to take decision by using ground and/or aerial vehicles, data analytics to derive prescriptions and variable rate controller also aided by auto-steering to apply the desired quantity. This pipeline works if and only if all the stages are trustable. In particular, it is import to acquire data at different times in order to evaluate the best rate considering the phenological phase and the previous/current status. Aerial (unmanned) vehicles are currently used to map the status but for complex crops as vineyards, it is necessary to properly segment soil vs crop/tree. Moreover aerial images offer a partial view that in case of vineyards it is not sufficient considering that only upper canopy could be sensed. In this case, it is necessary to integrate top view with lateral ones that could be acquired also by using tractors during the application of treatments. In this paper we present an integrated approach where ground data are collected and processed in real-time also showing how these data could be integrated with aerial data. Data are collected by using LiDAR sensor and processed by a set of algorithms deployed as ROS nodes to estimate the volume and health of a plant/tree to support the creation of management zones.","2575-7296","978-1-5386-1354-2","10.1109/ICUAS.2018.8453327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453327","Plant volume;multi-spectral;LiDAR;UAV application","Three-dimensional displays;Estimation;Laser radar;Soil;Indexes;Vegetation mapping;Agriculture","agriculture;crops;optical radar;remote sensing;soil;vegetation mapping","LiDAR sensor;variable rate controller;data analytics;aerial vehicles;historical data;prescription map;precision agriculture applications;health estimation;tree/plant volume;ground remotely sensed data;Variable Rate Treatments;aerial data;ground data;integrated approach;aerial images","","5","","35","IEEE","2 Sep 2018","","","IEEE","IEEE Conferences"
"Cost-Effective Multispectral Imaging System For Precision Agriculture","A. Rajapu; S. A. Madisetty; S. Thokala; P. R. Mahendra; V. V. R. Raju; C. S. V. Reddy","Electrical and Electronics Engineering Dept, Gokaraju Rangaraju Institute of Engineering and Technology, Hyderabad, India; Electrical and Electronics Engineering Dept, Gokaraju Rangaraju Institute of Engineering and Technology, Hyderabad, India; Electrical and Electronics Engineering Dept, Gokaraju Rangaraju Institute of Engineering and Technology, Hyderabad, India; Electrical and Electronics Engineering Dept, Gokaraju Rangaraju Institute of Engineering and Technology, Hyderabad, India; Electrical and Electronics Engineering Dept, Gokaraju Rangaraju Institute of Engineering and Technology, Hyderabad, India; Electrical and Electronics Engineering Dept, Gokaraju Rangaraju Institute of Engineering and Technology, Hyderabad, India","2022 IEEE 2nd International Conference on Sustainable Energy and Future Electric Transportation (SeFeT)","10 Oct 2022","2022","","","1","8","Drone-collected aerial photography of agriculture fields provides quick and accurate information. By computing the so-called vegetation indices, this data may be used to estimate the health state of a crop. One of these indices, the Normalized Difference Vegetation Index (NDVI), has grown in prominence as a result of the precise information that can be gleaned from it. Our effort in developing this project was to make a precision agricultural imaging system has been designed and developed with the help of Two miniature digital action cameras that are operated by a microprocessor integrated in a drone in the imaging system. Nonetheless, only one of the cameras has been adjusted to identify close infrared light transmitted by plants. The harvest’s wellbeing is measured utilizing the Normalized Difference Vegetation Index (NDVI), which is determined utilizing a series of processes and softwares. Our objective was initially To create orthomosaics including wellbeing data for the plant or soil of interest, the elevated photographs are handled to dispose of picture contortions and incorporate explicit metadata. The vegetation record will be recieved from the apparent and close infrared Orthomosaics to furnish farmers with a more precise image of the vegetation type. The effectiveness of the system is shown via experiments.","","978-1-6654-8057-4","10.1109/SeFeT55524.2022.9908611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9908611","UAV;Drone;Precision Agriculture;Multi-spectral Imaging;Image georeferencing;Normalized Difference Vegetation Index;Aerial photogrammetry","Image sensors;Soil measurements;Vegetation mapping;Transportation;Soil;Solids;Software","agriculture;crops;image classification;photography;remote sensing;soil;vegetation;vegetation mapping","agriculture fields;cost-effective multispectral imaging system;drone-collected aerial photography;health state;miniature digital action cameras;NDVI;Normalized Difference Vegetation Index;precise image;precision agricultural imaging system;precision agriculture;quick information;vegetation indices;vegetation record;vegetation type;wellbeing data","","","","20","IEEE","10 Oct 2022","","","IEEE","IEEE Conferences"
"Change detection analysis of tornado disaster using conditional copulas and Data Fusion for cost-effective disaster management","B. Gokaraju; A. C. Turlapaty; D. A. Doss; R. L. King; N. H. Younan",The University of West Alabama; VR Siddhartha Engineering College; The University of West Alabama; Mississippi State University; Mississippi State University,"2015 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)","31 Mar 2016","2015","","","1","8","The up-to-date results are presented from an ongoing study of the Data Fusion of multi-temporal and multi-sensor satellite datasets for near real time damage and debris assessment after a tornado disaster event. The space-borne sensor datasets comprising of: (i) C-band SAR dataset from RADARSAT-2; (ii) Multi-Spectral (MS) optical dataset including NIR from RapidEye; (iii) MS and panchromatic dataset of Advanced Linear Imaging (ALI), are studied for multi-sensor data fusion. A combined approach of multi-polarized radiometric and textural feature extraction, and statistical learning based feature classification is devised for fine tuning of the complex and generalized change detection model. We also investigated the use of multi-variate conditional copula as a classifier technique, by formulating the change and no-change as a binary-class classification problem in this study. The classification results from the above technique are used for assessment of damage and debris cover after the tornado disaster event. The performance of the above approach yields a very significant Kappa accuracy up to 75%. A 10-fold cross validation strategy is used for quantitative analysis of the performance of the classification model. This study will be further extended for modelling the effect of incidence angle discrepancies or climatic condition variances, which will address the heterogeneity factor in terms of local statistics of the dataset.","2332-5615","978-1-4673-9558-8","10.1109/AIPR.2015.7444537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7444537","change detection;machine learning;conditional Copula;disaster management;data fusion","Tornadoes;Data integration;Spatial resolution;Synthetic aperture radar;Feature extraction;Remote sensing;Disaster management","emergency management;feature extraction;image classification;learning (artificial intelligence);radar imaging;remote sensing;sensor fusion;statistical distributions;storms","change detection analysis;tornado disaster management;conditional copula;multisensor data fusion;C-band SAR dataset;RADARSAT-2;NIR;RapidEye;advanced linear imaging;ALI;feature extraction;statistical learning;feature classification","","10","","19","IEEE","31 Mar 2016","","","IEEE","IEEE Conferences"
"A Random Forest-Based Algorithm to Distinguish Ulva prolifera and Sargassum From Multispectral Satellite Images","Y. Xiao; R. Liu; K. Kim; J. Zhang; T. Cui","First Institute of Oceanography, Ministry of Natural Resources, Qingdao, China; First Institute of Oceanography, Ministry of Natural Resources, Qingdao, China; Korea Ocean Satellite Center, Korea Institute of Ocean Science and Technology, Busan, South Korea; First Institute of Oceanography, Ministry of Natural Resources, Qingdao, China; School of Atmospheric Sciences, Sun Yat-sen University, Zhuhai, China","IEEE Transactions on Geoscience and Remote Sensing","20 Dec 2021","2022","60","","1","15","In 2017, large-scale macroalgae blooms with different dominant species of Ulva prolifera and Sargassum occurred concurrently in the Yellow and East China Seas, which poses a challenge to the cognition and control of macroalgae disaster. Therefore, it is necessary to develop an algorithm to distinguish U. prolifera and Sargassum from satellite images. In this study, the spectral difference between U. prolifera and Sargassum and the capability of several multispectral satellite missions to distinguish them is first analyzed. The results show that the reflectance peak in visible wavelength is always in ~550 nm for U. prolifera whether it is floating in clear open water or turbid nearshore water. However, the reflectance of Sargassum floating in clear and turbid water shows totally different characteristics, because most of Sargassum body is submerged in the water and the observed Sargassum reflectance is seriously affected by water reflectance. Compared with Landsat 8 Operational Land Imager (OLI), HuanJing-1, Charge-Coupled Devices (HJ-1 CCD), Aqua Moderate-resolution Imaging Spectroradiometer (MODIS), and Sentinel 2 Multi-Spectral Instrument (MSI), GaoFen-1, Wide Field of View (GF-1 WFV) can preferably capture the spectral difference between U. prolifera and Sargassum. Based on the spectral difference analysis, we propose a random forest-based algorithm to distinguish U. prolifera and Sargassum from GF-1 WFV images with an overall accuracy of 97.6% except when U. prolifera and Sargassum mix together. The algorithm is more robust than the existing ones as it allowed more Sargassum samples from different ocean regions to be used in the training; in addition, it avoids negative effects caused by the selection of a threshold. The proposed algorithm is proved effective in distinguishing U. prolifera and Sargassum in the Yellow and East China Seas in May and June 2017 and in detecting Sargassum in the Atlantic Ocean. Thus, this method can be used in researches including floating macroalgae traceability and competition and succession between different macroalgae species in different regions of the ocean with similar environments.","1558-0644","","10.1109/TGRS.2021.3071154","National Key Research and Development Program of China(grant numbers:2017YFC1405300); National Natural Science Foundation of China(grant numbers:61890964,41506203,U1906217); China–Korea Joint Ocean Research Project(grant numbers:PI-2019-1-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9406171","Machine learning algorithms;multispectral imaging;remote monitoring;tide","Satellites;Atmospheric modeling;Sea measurements;Hyperspectral imaging;Sea surface;Object oriented modeling;Algae","geophysical image processing;oceanographic techniques;vegetation","multispectral satellite images;U. prolifera;spectral difference;Sargassum body;observed Sargassum reflectance;random forest-based algorithm;GF-1 WFV images;Sargassum mix;Sargassum samples;macroalgae species;distinguish Ulva prolifera;AD 2017;multispectral satellite missions;Yellow Sea;east China Sea;wavelength 550.0 nm","","2","","65","IEEE","16 Apr 2021","","","IEEE","IEEE Journals"
"Pan-Sharpening With Color-Aware Perceptual Loss And Guided Re-Colorization","J. L. G. Bello; S. Seo; M. Kim",Korea Advanced Institute of Science and Technology (KAIST); Korea Advanced Institute of Science and Technology (KAIST); Korea Advanced Institute of Science and Technology (KAIST),"2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","908","912","In remote sensing, “pan-sharpening” is the task of enhancing the spatial resolution of a multi-spectral (MS) image by exploiting the high-frequency information in a panchromatic (PAN) reference image. We present a novel color-aware perceptual (CAP) loss for learning the task of pan-sharpening. Our CAP loss is designed to focus on the deep features of a pre-trained VGG network that are more sensitive to spatial details and ignore color information to allow the network to extract the structural information from the PAN image while keeping the color from the lower resolution MS image. Additionally, we propose “guided re-colorization”, which generates a pan-sharpened image with real colors from the MS input by “picking” the closest MS pixel color for each pan-sharpened pixel, as a human operator would do in manual colorization. Such a re-colorized (RC) image is completely aligned with the pan-sharpened (PS) network output and can be used as a self-supervision signal during training, or to enhance the colors in the PS image during test. We present several experiments where our network trained with our CAP loss generates naturally looking pan-sharpened images with fewer artifacts and outperforms the state-of-the-arts on the WorldView3 dataset in terms of ERGAS, SCC, and QNR metrics.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190785","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190785","Pan-sharpening;pan-colorization;deep convolutional neural network (DCNN);perceptual loss;satellite imagery.","Image color analysis;Task analysis;Spatial resolution;Satellites;Training;Network architecture","geophysical image processing;image colour analysis;image fusion;image resolution;remote sensing","color-aware perceptual loss;guided re-colorization;spatial resolution;multispectral image;high-frequency information;panchromatic reference image;CAP loss;pre-trained VGG network;color information;PAN image;lower resolution MS image;pan-sharpened image;closest MS pixel color;pan-sharpened pixel;manual colorization;image re-colorization;pan-sharpened network output;PS image;self-supervision signal","","2","","25","IEEE","30 Sep 2020","","","IEEE","IEEE Conferences"
"Spectral Unmixing of Time Series Data to Provide Initial Object Seeds for Change Detection on Google Earth Engine","M. Kakooei; Y. Baleghi","Electrical Engineering Department, Babol University of Technology, Babol, Iran; Electrical Engineering Department, Babol University of Technology, Babol, Iran","2019 27th Iranian Conference on Electrical Engineering (ICEE)","5 Aug 2019","2019","","","1402","1407","Nowadays satellite and aerial imagery provide High Resolution (HR) and Very High Resolution (VHR) time series orthophotos. Image classification and object detection is an important and challenging task in urban areas. Object matching in time series images is more challenging and hard to acquire. Accurate object detection is important in change detection methods and plays a significant role in damage assessment algorithms. This issue brought us to develop a method to create initial seeds to improve the change detection in time series images. A part of next to last image is clustered into specified number of clusters. Time series images will construct a multi-spectral image including all images, except the last one. Cluster geometry is utilized to find endmembers in the multispectral image. Space reconstruction is applied to the multispectral image to find initial seeds. Our method could be a part of many conventional image processing algorithms to improve their capability in time-series image analysis. It is implemented on Google Earth Engine, a cloud computing platform for remote sensing. The proposed method is evaluated by comparing the result of change detection in seeded and non-seeded algorithms.","2642-9527","978-1-7281-1508-5","10.1109/IranianCEE.2019.8786494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786494","Initial seeds;Spectral Unmixing;Change detection;High resolution;Google Earth Engine","Image segmentation;Buildings;Time series analysis;Feature extraction;Image resolution;Mathematical model;Change detection algorithms","geophysical image processing;geophysics computing;image classification;image segmentation;object detection;remote sensing;time series","time series data;initial object seeds;Google earth engine;High Resolution time series orthophotos;object matching;change detection methods;conventional image processing algorithms;time-series image analysis;Google Earth Engine;object detection;multispectral image","","2","","20","IEEE","5 Aug 2019","","","IEEE","IEEE Conferences"
"Self-adaptive hybrid PSO-GA method for change detection under varying contrast conditions in satellite images","H. Kusetogullari; A. Yavariabdi","Department of Computer Science and Engineering, Blekinge Institute of Technology, Karlskrona, Sweden; Department of Mechatronics Engineering, KTO Karatay University, Konya, Turkey","2016 SAI Computing Conference (SAI)","1 Sep 2016","2016","","","361","368","This paper proposes a new unsupervised satellite change detection method, which is robust to illumination changes. To achieve this, firstly, a preprocessing strategy is used to remove illumination artifacts and results in less false detection than traditional threshold-based algorithms. Then, we use the corrected input data to define a new fitness function based on the difference image. The purpose of using Self-Adaptive Hybrid Particle Swarm Optimization-Genetic Algorithm (SAPSOGA) is to combine two meta-heuristic optimization algorithms to search and find the feasible solution in the NP-hard change detection problem rapidly and efficiently. The hybrid algorithm is employed by letting the GA and PSO run simultaneously and similarities of GA and PSO have been considered to implement the algorithm, i.e. the population. In the SAPSOGA employed, in each iteration/generation the two population based algorithms share different amount of information or individual(s) between themselves. Thus, each algorithm informs each other about their best optimum results (fitness values and solution representations) which are obtained in their own population. The fitness function is minimized by using binary based SAPSOGA approach to produce binary change detection masks in each iteration to obtain the optimal change detection mask between two multi temporal multi spectral landsat images. The proposed approach effectively optimizes the change detection problem and finds the final change detection mask.","","978-1-4673-8460-5","10.1109/SAI.2016.7556007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556007","Remote sensing;Image processing;Optimization;Self-adaptive hybrid algorithm;Genetic algorithm;Binary particle swarm optimization","Satellites;Change detection algorithms;Sociology;Statistics;Lighting;Genetic algorithms;Cost function","computational complexity;feature extraction;genetic algorithms;image processing;particle swarm optimisation;remote sensing","self-adaptive hybrid particle swarm optimization-genetic algorithm;SAPSOGA;unsupervised satellite change detection;contrast condition;satellite image;illumination change;illumination artifact removal;metaheuristic optimization algorithm;NP-hard change detection problem","","7","","21","IEEE","1 Sep 2016","","","IEEE","IEEE Conferences"
"3D and snapshot hyperspectral cameras based on continuously variable filters","O. Pust; H. Fabricius","Delta Optical Thin Film A/S, Venlighedsvej 4, Hørsholm, Denmark; Delta Optical Thin Film A/S, Venlighedsvej 4, Hørsholm, Denmark","2018 9th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","27 Jun 2019","2018","","","1","4","Hyperspectral imaging (HSI) has been used for a couple of decades in applications such as satellite imaging, air reconnaissance and other not overly price sensitive markets. Still, there is no clear definition of the term hyperspectral imaging. Sometimes techniques that produce 2D images with more than the typical three RGB colours (or spectral channels) - for example by inclusion of a near-infrared channel - are already called hyperspectral. Mostly though, this is not considered sufficient. Typically, even ten spectral channels are still to be called multi-spectral rather than hyperspectral.","2158-6276","978-1-7281-1581-8","10.1109/WHISPERS.2018.8747244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8747244","","Optical filters;Band-pass filters;Hyperspectral imaging;Cameras;Detectors","cameras;hyperspectral imaging;image colour analysis;image sensors;optical filters;optical images;photodetectors;spectral analysis","continuously variable filters;spectral channels;snapshot hyperspectral cameras;satellite imaging applications;hyperspectral imaging;2D images;RGB colours;air reconnaissance applications;near-infrared channel;3D hyperspectral cameras","","","","6","IEEE","27 Jun 2019","","","IEEE","IEEE Conferences"
"OpenSentinelMap: A Large-Scale Land Use Dataset using OpenStreetMap and Sentinel-2 Imagery","N. Johnson; W. Treible; D. Crispell",Vision Systems Inc; Vision Systems Inc; Vision Systems Inc,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","23 Aug 2022","2022","","","1332","1340","Remote sensing data is plentiful, but downloading, organizing, and transforming large amounts of data into a format readily usable by modern machine learning methods is a challenging and labor-intensive task. We present the OpenSentinelMap dataset, which consists of 137,045 unique 3.7 km2 spatial cells, each containing multiple multispectral Sentinel-2 images captured over a 4 year time period and a set of corresponding per-pixel semantic labels derived from OpenStreetMap data. The labels are not necessarily mutually exclusive, and contain information about roads, buildings, water, and 12 land-use categories. The spatial cells are selected randomly on a global scale over areas of human activity, without regard to OpenStreetMap data availability or quality, making the dataset ideal for both supervised, semi-supervised, and un-supervised experimentation. To demonstrate the effectiveness of the dataset, we a) train an off-the-shelf convolutional neural network with minimal modification to predict land-use and building and road location from multi-spectral Sentinel-2 imagery and b) show that the learned embeddings are useful for downstream fine-grained classification tasks without any fine-tuning. The dataset is publicly available at https://visionsystemsinc.github.io/open-sentinel-map/.","2160-7516","978-1-6654-8739-9","10.1109/CVPRW56347.2022.00139","Office of the Director; Intelligence Advanced Research Projects Activity; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9856983","","Training;Annotations;Roads;Semantics;Buildings;Pattern recognition;Task analysis","geophysical image processing;image classification;learning (artificial intelligence);neural nets;remote sensing","modern machine learning methods;downloading;remote sensing data;large-scale land;downstream fine-grained classification tasks;learned embeddings;multispectral Sentinel-2 imagery;road location;building;off-the-shelf convolutional neural network;un-supervised experimentation;dataset ideal;human activity;global scale;land-use categories;OpenStreetMap data;per-pixel semantic labels;4 year time period;containing multiple multispectral Sentinel-2 images;2 spatial cells;OpenSentinelMap dataset;challenging labor-intensive task;time 4.0 year","","2","","25","IEEE","23 Aug 2022","","","IEEE","IEEE Conferences"
"Compressive Sampling Using a Pushframe Camera","S. Bennett; Y. Noblet; P. F. Griffin; P. Murray; S. Marshall; J. Jeffers; D. Oi","Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, U.K.; Department of Physics, University of Strathclyde, Glasgow, U.K.; Department of Physics, University of Strathclyde, Glasgow, U.K.; Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, U.K.; Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, U.K.; Department of Physics, University of Strathclyde, Glasgow, U.K.; Department of Physics, University of Strathclyde, Glasgow, U.K.","IEEE Transactions on Computational Imaging","20 Oct 2021","2021","7","","1069","1079","The recently described pushframe imager, a parallelized single pixel camera capturing with a pushbroom-like motion, is intrinsically suited to both remote-sensing and compressive sampling. It optically applies a 2D mask to the imaged scene, before performing light integration along a single spatial axis, but previous work has not made use of the architecture's potential for taking measurements sparsely. In this paper we develop a strongly performing static binarized noiselet compressive sampling mask design, tailored to pushframe hardware, allowing both a single exposure per motion time-step, and retention of 2D correlations in the scene. Results from simulated and real-world captures are presented, with performance shown to be similar to that of immobile — and hence inappropriate for satellite use — whole-scene imagers. A particular feature of our sampling approach is that the degree of compression can be varied without altering the pattern, and we demonstrate the utility of this for efficiently storing and transmitting multi-spectral images.","2333-9403","","10.1109/TCI.2021.3114980","UK Space Agency; Centre for Earth Observation Instrumentation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9547723","Compressive sampling;pushframe imaging;columnar block compressed sensing (BCS);parallel single pixel camera (SPC)","Image reconstruction;Cameras;Image coding;Imaging;Computer architecture;Optical variables measurement;Optical sensors","cameras;compressed sensing;image reconstruction;image resolution;image sampling;image sensors;remote sensing","pushbroom-like motion;remote-sensing;imaged scene;light integration;single spatial axis;static binarized noiselet compressive sampling mask design;single exposure;motion time-step;real-world captures;whole-scene imagers;sampling approach;multispectral images;pushframe camera;parallelized single pixel camera;pushframe imager;2D mask","","2","","43","IEEE","24 Sep 2021","","","IEEE","IEEE Journals"
"Subsystem support feasibility for formation flight measuring Bi-directional Reflectance","S. Nag; K. Cahoy; O. de Weck","Massachusetts Institute of Technology, Cambridge, MA; Massachusetts Institute of Technology, Cambridge, MA; Massachusetts Institute of Technology, Cambridge, MA","2015 IEEE Aerospace Conference","8 Jun 2015","2015","","","1","20","Distributed Spacecraft Missions can be used to improve science performance in earth remote sensing by increasing the sampling in one or more of five dimensions: spatial, temporal, angular, spectral and radiometric. This paper identifies a gap in the angular sampling abilities of traditional monolithic spacecraft and proposes to address it using small satellite clusters in formation flight. The angular performance metric chosen to be Bi-directional Reflectance Distribution Function (BRDF), which describes the directional and spectral variation of reflectance of a surface element at any time instant. Current monolithic spacecraft sensors estimate it by virtue of their large swath (e.g. MODIS, POLDER), multiple forward and aft sensors (e.g. MISR, ATSR) and autonomous maneuverability (e.g. CHRIS, SPECTRA). However, their planes of measurement and angular coverage are limited. This study evaluates the technical feasibility of using clusters of nanosatellites in formation flight, each with a VNIR (visible and near infra-red) imaging spectrometer, to make multi-spectral reflectance measurements of a ground target, at different zenith and azimuthal angles simultaneously. Feasibility is verified for the following mission critical, inter-dependent modules that need to be customized to fit specific angular and spectral requirements: cluster geometry (and global orbits), guidance, navigation and control systems (GNC), payload, onboard processing and communication. Simulations using an integrated systems engineering and science evaluation tool indicate initial feasibility of all listed subsystems.","1095-323X","978-1-4799-5380-6","10.1109/AERO.2015.7119247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119247","","Optical variables measurement;Payloads;Spatial resolution;Area measurement;Power measurement;Q measurement","artificial satellites;geophysical techniques;radiometry;remote sensing;space vehicles;spectrometers","subsystem support feasibility;formation flight measuring bi-directional reflectance;distributed spacecraft mission;Earth remote sensing science performance;spatial dimension;temporal dimension;angular dimension;spectral dimension;radiometric dimension;angular sampling ability;traditional monolithic spacecraft;small satellite cluster;angular performance metric;Bi-directional Reflectance Distribution Function;BRDF;surface element reflectance directional variation;surface element reflectance spectral variation;monolithic spacecraft sensor;MODIS;POLDER;multiple forward sensor;aft sensor;MISR;ATSR;autonomous maneuverability;CHRIS;SPECTRA;measurement plane;angular coverage plane;nanosatellite cluster technical feasibility;VNIR;visible and near infra-red imaging spectrometer;ground target multispectral reflectance measurement;azimuthal angle;zenith angle;inter-dependent module;specific angular requirement;spectral requirement;cluster geometry;global orbit;guidance navigation and control system;GNC;integrated systems engineering;science evaluation tool;initial subsystem feasibility","","1","","49","IEEE","8 Jun 2015","","","IEEE","IEEE Conferences"
"An improved SAM algorithm for red blood cells and white blood cells segmentation","X. Hou; Q. Li; Q. Wang; M. Zhou; H. Liu","Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China; Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China","2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","16 Feb 2017","2016","","","651","655","The segmentation of red blood cells and white blood cells has important research value in the field of rheological properties of blood and the pathogenesis of some diseases. And it is the reflection of bone hematopoietic state, blood diseases and other diseases. Especially for the diagnosis of blood diseases, the detection and prevention of treatment process, there is high value of clinical research. The separation of red blood cells and white blood cells using hyperspectral remote sensing image processing is a new field that it is essentially different from traditional multi spectral classification. Because of the different chemical composition and molecular space structure of red blood cells and white blood cells, it results in different spectrum. Each pixel of hyperspectral image can obtain a unique continuous spectral curve, and it can be compared with the spectral curves which are known to obtain target object. So the author designs a new analytical method which is based on the various processing methods of hyperspectral image. First of all, using the BandMax wizard to lock target image and band based on target detection; secondly, conducting differential search algorithm based on the blind signal; thirdly, using an improved algorithm-based on SAM combined with SID algorithm; finally, using advanced filtering method to get clearer image information. In this paper, it focuses on the effective extraction and improves the classification accuracy of white blood cells.","","978-1-5090-3710-0","10.1109/CISP-BMEI.2016.7852790","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852790","hyperspectral imaging;image processing;spectral angle mapping;segmentation;blood cell","White blood cells;Red blood cells;Hyperspectral imaging;Diseases;Classification algorithms","blind source separation;blood;bone;diseases;evolutionary computation;hyperspectral imaging;image segmentation;medical image processing;object detection;remote sensing;rheology","SAM algorithm;red blood cell segmentation;white blood cell segmentation;blood rheological properties;disease pathogenesis;bone hematopoietic state;blood disease diagnosis;hyperspectral remote sensing image processing;multispectral classification;spectral curve;BandMax wizard;image locking;target detection;differential search algorithm;blind signal;SID algorithm;image information","","1","","12","IEEE","16 Feb 2017","","","IEEE","IEEE Conferences"
"Mapping Human Settlements with Multi-seasonal Sentinel-2 Imagery and Attention-based ResNeXt","C. Qiu; M. Schmitt; H. Taubenböck; X. X. Zhu","Signal Processing in Earth Observation, Technical University of Munich (TUM), Munich, Germany; Signal Processing in Earth Observation, Technical University of Munich (TUM), Munich, Germany; Earth Observation Center (EOC), German Aerospace Center (DLR), Wessling, Germany; Signal Processing in Earth Observation, Technical University of Munich (TUM), Munich, Germany","2019 Joint Urban Remote Sensing Event (JURSE)","22 Aug 2019","2019","","","1","4","This paper explores the potential of multi-spectral Sentinel-2 imagery for human settlement mapping, using deep learning based methods. We show first results of a study area in central Europe, with an attention-based ResNeXt to better exploit the spectral information. Reasonable mapping accuracy has been achieved, compared to the state-of-the-art products. Based on the results and comparison with the existing products, we discuss two interesting questions: how can human settlement mapping be made consistent with or complementary to the existing human settlement maps and how can further improvement in human settlement mapping be achieved by exploring deep learning-based approaches?","2642-9535","978-1-7281-0009-8","10.1109/JURSE.2019.8809009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809009","Sentinel-2;classification;attention;convolutional neural network (CNN);human settlement (HS) mapping","Buildings;Urban areas;Satellites;Roads;Meters;Europe;Earth","geophysical image processing;learning (artificial intelligence);terrain mapping","multispectral Sentinel-2 imagery;human settlement mapping;deep learning based methods;attention-based ResNeXt;reasonable mapping accuracy;deep learning-based approaches;multiseasonal Sentinel-2 imagery;central Europe;spectral information","","6","","15","IEEE","22 Aug 2019","","","IEEE","IEEE Conferences"
"Multi-Discriminator Generative Adversarial Network for High Resolution Gray-Scale Satellite Image Colorization","F. Li; L. Ma; J. Cai","Institute of Automation, Chinese Academy of Science; Institute of Automation, Chinese Academy of Science; Institute of Automation, Chinese Academy of Science","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","3489","3492","Automatic colorization for grayscale satellite images can help with eliminating lighting differences between multi-spectral captures, and provides strong prior information for ground type classification and object detection. In this paper, we introduced a novel generative adversarial network with multiple discriminators for colorizing gray-scale satellite images with pseudo-natural appearances. Although being powerful, deep generative model in its common form with a single discriminator could be unstable for achieving spatial consistency on local textured regions, especially highly textured ones. To address this issue, the generator in our proposed structure produces a group of colored outputs from feature maps at different scale levels of the network, each being supervised by an independent discriminator to fit the original colored training input in discrete Lab color space. The final colored output is a cascaded ensemble of these preceding by-products via summation, thus the fitting errors are reduced by a geometric series form. Quantitative and qualitative comparisons with the sole-discriminator version have been performed on high-resolution satellite images in experiments, where significant reductions in prediction errors have been observed.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517930","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517930","Pseudo-natural colorization;gray-scale satellite images;generative adversarial network;multiple discriminators","Image color analysis;Generative adversarial networks;Gallium nitride;Training;Satellites;Generators;Visualization","image colour analysis;image resolution;image segmentation;image texture;object detection","scale levels;object detection;ground type classification;strong prior information;multispectral captures;lighting differences;grayscale satellite images;automatic colorization;high resolution gray-scale satellite image colorization;multidiscriminator generative adversarial network;high-resolution satellite images;sole-discriminator version;final colored output;discrete Lab color space;original colored training input;independent discriminator;colored outputs;local textured regions;single discriminator;deep generative model;pseudonatural appearances;gray-scale satellite images","","5","","8","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Multi-Class Segmentation of Urban Floods from Multispectral Imagery Using Deep Learning","A. V. Potnis; R. C. Shinde; S. S. Durbha; K. R. Kurte","Centre of Studies in Resources Engineering, Indian Institute of Technology Bombay, Mumbai, India; Centre of Studies in Resources Engineering, Indian Institute of Technology Bombay, Mumbai, India; Centre of Studies in Resources Engineering, Indian Institute of Technology Bombay, Mumbai, India; Centre of Studies in Resources Engineering, Indian Institute of Technology Bombay, Mumbai, India","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","9741","9744","Natural disasters such as floods, earthquakes, hurricanes, etc. have a huge impact on a society-causing destruction of life and property in their wake. During disasters such as flood, it is crucial to understand the dynamics of the situation as it occurs for effective response. In this paper, we address the problem of satellite image classification for urban floods using deep learning. We propose an encoder-decoder neural network based on the Efficient Residual Factorized Convnet(ERFNet), for multi-class segmentation of urban floods from multi-spectral satellite imagery. The ERFNet architecture capitalizes on skip connections and one dimensional convolutions to achieve the best possible trade-off between accuracy and efficiency. Since time is of essence during a disaster, the choice of the ERFNet architecture on a high performance computing (HPC) platform is apt. Satellite imagery from WorldView-2 of floods in Srinagar, India during September 2014 have been used for this study. The tool `markGT' has been developed to assist end-to-end annotation of satellite imagery. The urban flood dataset used for this study has been generated using markGT. The proposed deep learning model over urban flood satellite imagery gives promising results on Nvidia Tesla K80 GPU. We envisage that the proposed model could be extended and improved for real-time classification of urban floods, thereby aiding disaster response personnel in making informed decisions.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900250","segmentation;flood;multi-class;classification;neural networks","Satellites;Floods;Image segmentation;Deep learning;Computer architecture;Tools;Neural networks","disasters;floods;geophysical image processing;hydrological techniques;image classification;image segmentation;learning (artificial intelligence);neural net architecture;neural nets","deep learning model;urban flood satellite imagery;disaster response personnel;multiclass segmentation;multispectral imagery;natural disasters;satellite image classification;multispectral satellite imagery;ERFNet architecture capitalizes;urban flood dataset;Srinagar;Nvidia Tesla K80 GPU;high performance computing","","4","","8","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Use of Sentinel-l and Sentinel-2 for Monitoring Illegal Fishing Off Ghana","A. Kurekin; B. Loveday; O. Clements; G. Quartly; P. Miller; G. Wiafe; K. A. Agyekum","Plymouth Marine Laboratory, Plymouth, UK; Plymouth Marine Laboratory, Plymouth, UK; Plymouth Marine Laboratory, Plymouth, UK; Plymouth Marine Laboratory, Plymouth, UK; Plymouth Marine Laboratory, Plymouth, UK; Coastal & Marine Resources Management Centre, College of Basic and Applied Sciences, Legon, Ghana; Coastal & Marine Resources Management Centre, College of Basic and Applied Sciences, Legon, Ghana","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","6875","6878","An efficient and inexpensive service has been developed for the monitoring of fishing vessels in West Africa using Earth Observation (EO) data. The service makes use of fast-delivery data from the Synthetic Aperture Radar (SAR) instrument on Sentinel-l and the Multi Spectral Imager (MSI) on Sentinel-2, detecting objects that differ markedly from their immediate background using a constant false alarm rate (CFAR) test. The selected objects are then discounted from further analysis if they fall within the bespoke land mask or can be shown from time series analysis to be static (signals associated with jetties, oil platforms and “ghost objects” arising from very bright land targets). Detections are matched to, and verified by, AIS data, which provides location and dimensions of ships that are legally in the region. Both matched and un-matched data are then displayed on a web portal for use by the Gulf of Guinea (GoG) state authorities.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8519539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519539","Synthetic Aperture Radar;vessel detection;illegal fishing;automatic identification system","Artificial intelligence;Synthetic aperture radar;Monitoring;Cloud computing;Marine vehicles;Aquaculture;Optical sensors","object detection;radar detection;radar imaging;ships;synthetic aperture radar;time series","illegal fishing;Gulf of Guinea state authorities;Synthetic Aperture Radar;constant false alarm rate test;MultiSpectral Imager;Synthetic Aperture Radar instrument;fast-delivery data;Earth Observation data;West Africa;fishing vessels;inexpensive service;Sentinel-2;Sentinel-1;un-matched data;AIS data;ghost objects;time series analysis;bespoke land mask","","3","","9","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Time series from hyperion to track productivity in pivot agriculture in saudi arabia","R. Houborg; M. F. McCabe; Y. Angel; E. M. Middleton","King Abdullah University of Science and Technology (KAUST), Biological and Environmental Science and Engineering (BESE), Saudi Arabia; King Abdullah University of Science and Technology (KAUST), Biological and Environmental Science and Engineering (BESE), Saudi Arabia; King Abdullah University of Science and Technology (KAUST), Biological and Environmental Science and Engineering (BESE), Saudi Arabia; NASA Goddard Space Flight Center (GSFC), Greenbelt, Maryland, U.S.A.","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","3047","3050","The hyperspectral satellite sensing capacity is expected to increase substantially in the near future with the planned deployment of hyperspectral systems by both space agencies and commercial companies. These enhanced observational resources will offer new and improved ways to monitor the dynamics and characteristics of terrestrial ecosystems. This study investigates the utility of time series of hyperspectral imagery, acquired by Hyperion onboard EO-1, for quantifying variations in canopy chlorophyll (Chlc), plant productivity, and yield over an intensive farming area in the desert of Saudi Arabia. Chlc is estimated on the basis of predictive multi-variate empirical models established via a machine learning approach using a training dataset of in-situ measured target variables and explanatory hyperspectral indices. Resulting time series of Chlc are translated into Gross Primary Productivity (GPP) and Yield based on semi-empirical relationships, and evaluated against ground-based observations. Results indicate significant benefit in utilizing the full suite of hyperspectral indices over multi-spectral indices constructible from Landsat-8 and Sentinel-2.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127641","Chlorophyll;Hyperion;Productivity;Yield","Hyperspectral imaging;Productivity;Earth;Predictive models;Biological system modeling","terrain mapping;time series;vegetation;vegetation mapping","pivot agriculture;hyperspectral satellite sensing capacity;planned deployment;hyperspectral systems;space agencies;commercial companies;enhanced observational resources;terrestrial ecosystems;hyperspectral imagery;Hyperion onboard EO-1;canopy chlorophyll;plant productivity;intensive farming area;predictive multivariate empirical models;in-situ measured target variables;explanatory hyperspectral indices;resulting time series;Gross Primary Productivity;semiempirical relationships;multispectral indices;Saudi Arabia desert;machine learning approach","","3","","32","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Multi-Modal Self-Supervised Representation Learning for Earth Observation","P. Jain; B. Schoen-Phelan; R. Ross","School of Computer Science, Technological University Dublin, Dublin, Ireland; School of Computer Science, Technological University Dublin, Dublin, Ireland; School of Computer Science, Technological University Dublin, Dublin, Ireland","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3241","3244","Self-Supervised learning (SSL) has reduced the performance gap between supervised and unsupervised learning, due to its ability to learn invariant representations. This is a boon to the domains like Earth Observation (EO), where labelled data availability is scarce but unlabelled data is freely available. While Transfer Learning from generic RGB pre-trained models is still common-place in EO, we argue that, it is essential to have good EO domain specific pre-trained model in order to use with downstream tasks with limited labelled data. Hence, we explored the applicability of SSL with multi-modal satellite imagery for downstream tasks. For this we utilised the state-of-art SSL architectures i.e. BYOL and SimSiam to train on EO data. Also to obtain better invariant representations, we considered multi-spectral (MS) images and synthetic aperture radar (SAR) images as separate augmented views of an image to maximise their similarity. Our work shows that by learning single channel representations through non-contrastive learning, our approach can outperform ImageNet pre-trained models significantly on a scene classification task. We further explored the usefulness of a momentum encoder by comparing the two architectures i.e. BYOL and SimSiam but did not identify a significant improvement in performance between the models.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553741","Science Foundation Ireland(grant numbers:13/RC/2106); European Regional Development Fund(grant numbers:13/RC/2106); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553741","self-supervised learning;unsupervised learning;satellite images","Earth;Training;Satellites;Image analysis;Transfer learning;Data models;Radar polarimetry","image classification;image sensors;learning (artificial intelligence);pattern classification;synthetic aperture radar;unsupervised learning","multimodal self-Supervised representation Learning;Earth Observation;self-Supervised learning;performance gap;unsupervised learning;invariant representations;labelled data availability;Transfer Learning;generic RGB pre-trained models;common-place;good EO domain specific pre-trained model;downstream tasks;multimodal satellite imagery;state-of-art SSL architectures i.e;EO data;multispectral images;synthetic aperture radar images;single channel representations;noncontrastive learning;ImageNet pre-trained models;scene classification task","","2","","15","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Fusion of Sentinel-2 Data with High Resolution Open Access Planet Basemaps for Grazing Lawn Detection in Southern African Savannahs","K. T. Awuah; P. Aplin","Department of Geography and Geology, Edge Hill University, Ormskirk, UK; Department of Geography and Geology, Edge Hill University, Ormskirk, UK","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","1409","1412","Short grass grazing lawn patches are significant components of habitat heterogeneity in southern African savannah ecosystems. Accurate maps of grazing lawn distribution is essential to enhance understanding of important ecosystem processes such as mega-herbivore population dynamics, nutrient cycling and plant community composition. The inherent heterogeneity of savannah landscapes however creates significant challenges for accurate discrimination of vegetation components and thus grazing lawn detection. Recent studies favour very high spatial resolution (VHR) multi-spectral imagery for dealing with this challenge. However, such data are costly for use in operational management. Planet Labs, through Norway's International Climate and Forests Initiative (NICFI), now grant free access to high-resolution, analysis-ready mosaics over the tropics, with great potential for fine-scale vegetation mapping. However, the spectral characteristics of these data are limited and fail to resolve the spectral similarity of different savannah vegetation components. We address these issues using Gram-Schmidt transformation to fuse Planet Basemaps and Sentinel-2A images for grazing lawn detection within the Lower Sabie region of Kruger National Park, South Africa. The original and fused images were classified using a random forest approach. Overall, the fused image achieved the best grazing lawn detection accuracy (0.85) and general map accuracy (0.72) results compared to Sentinel-2 (0.67 and 0.62) and Planet basemap (0.64 and 0.62 respectively). Our findings provide a foundation for cost-effective and accurate high spatial resolution vegetation mapping in heterogenous savannah landscapes. Further studies will investigate the potential of multi-temporal fused data and object-based approaches for enhanced savannah vegetation mapping","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554156","Edge Hill University; Royal Geographical Society; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554156","Image fusion;Sentinel-2;Planet basemaps;Random forest;savannah;grazing lawn","Planets;Open Access;Fuses;Ecosystems;Sociology;Vegetation mapping;Forestry","ecology;geophysical image processing;image fusion;image resolution;vegetation;vegetation mapping","Sentinel-2 data;high resolution open access Planet Basemaps;southern African savannahs;lawn patches;southern African savannah ecosystems;grazing lawn distribution;ecosystem processes;nutrient cycling;plant community composition;high spatial resolution multispectral imagery;fine-scale vegetation mapping;grazing lawn detection accuracy;Planet basemap;heterogenous savannah landscapes;multitemporal fused data;enhanced savannah vegetation mapping;high spatial resolution vegetation mapping;savannah vegetation components;International Climate and Forests Initiative;Kruger National Park","","1","","9","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A Novel Technique for Building Roof Mapping in Very-High-Resolution Multispectral Satellite Data","A. Andreoni; F. D. Acqua; R. Freddi","Department of Electrical, University of Pavia, Pavia, italy; Department of Electrical, University of Pavia, Pavia, italy; OHB Italia, Milan, Italy","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","1256","1259","The long-time technological trend towards ever-finer ground resolution in space-borne multispectral data has opened the doors to finer levels of urban mapping and monitoring. Single buildings and their features can nowadays be detected and mapped starting from nadiral data; yet, despite a large body of research results, an exhaustive solution to space-based building mapping is still to be found. In this paper, we give our contribution by proposing a novel approach to the extraction of rooftop shapes of buildings from very-high-resolution (VHR) optical multi-spectral data. The approach is derived from existing work, namely an automatic rooftop extraction method intended for aerial imagery. Because of the very different nature of the data, it was necessary to rearrange the reference method, modifying and adding new constraints, applying both spectral and spatial conditions. This work was developed in the framework of the EU H2020 Satellite Swarm Sensor Network (S3NET) project.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518329","","Feature extraction;Buildings;Satellites;Image color analysis;Lighting;Clustering algorithms;Training","feature extraction;geophysical image processing;roofs;terrain mapping","single buildings;space-based building mapping;urban mapping;space-borne multispectral data;ever-finer ground resolution;very-high-resolution multispectral Satellite data;building roof mapping;EU H2020 Satellite Swarm Sensor Network project;automatic rooftop extraction method;very-high-resolution optical multispectral data","","1","","19","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Non-Linear co-registration in UAVs’ images using deep learning","L. H. F. P. Silva; J. D. D. Jünior; J. F. Mari; M. C. Escarpinati; A. R. Backes","Federal University of Viçosa, Campus Rio Paranaíba,, MG, Brazil; School of Computer Science, Federal University of Uberlândia Av. João Naves de Ávila, 2121, Uberlândia, MG, Brazil; Federal University of Viçosa, Campus Rio Paranaíba,, MG, Brazil; School of Computer Science, Federal University of Uberlândia Av. João Naves de Ávila, 2121, Uberlândia, MG, Brazil; School of Computer Science, Federal University of Uberlândia Av. João Naves de Ávila, 2121, Uberlândia, MG, Brazil","2022 35th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)","26 Dec 2022","2022","1","","1","6","Unmanned Aerial Vehicles (UAVs) has stood out for assisting, enhancing, and optimizing agricultural production. Images captured by UAVs allow a detailed view of the analyzed region since the flight occurs at low and medium altitudes (50m to 400m). In addition, there is a wide variety of sensors (RGB cameras, heat capture sensors, multi and hyperspectral cameras, among others), each with its own characteristics and capable of producing different information. In multi-spectral images acquisition, we use a distinct sensor to capture each image band and at different time, leading to misalignments. To tackle this problem we propose to train a deep neural network to predict the vector deformation fields to perform the registration between bands of a multi-spectral image. The proposed approach has an accuracy ranging from 89.90% to 93.79% in the task of estimating the displacement field between bands. With this field estimated by the network, it is possible to register between the bands without the need for manual marking of points.","2377-5416","978-1-6654-5385-1","10.1109/SIBGRAPI55357.2022.9991781","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9991781","","Training;Deep learning;Visualization;Vegetation mapping;Manuals;Sensor phenomena and characterization;Cameras","autonomous aerial vehicles;cameras;deep learning (artificial intelligence);geophysical image processing;image colour analysis;image registration;image sensors;mobile robots;remote sensing","agricultural production;deep learning;deep neural network;heat capture sensors;hyperspectral cameras;multispectral images acquisition;nonlinear co-registration;RGB cameras;UAVs images;unmanned aerial vehicles;vector deformation fields","","","","20","IEEE","26 Dec 2022","","","IEEE","IEEE Conferences"
"Selection of Landsat 8 OLI Band Combinations for Land Use and Land Cover Classification","Z. Yu; L. Di; R. Yang; J. Tang; L. Lin; C. Zhang; M. S. Rahman; H. Zhao; J. Gaigalas; E. G. Yu; Z. Sun","Center for Spatial Information Science and Systems, George Mason University, Fairfax, VA, USA; Center for Spatial Information Science and Systems, George Mason University, Fairfax, VA, USA; Center for Spatial Information Science and Systems, George Mason University, Fairfax, VA, USA; Center for Spatial Information Science and Systems, George Mason University, Fairfax, VA, USA; Center for Spatial Information Science and Systems, George Mason University, Fairfax, VA, USA; Center for Spatial Information Science and Systems, George Mason University, Fairfax, VA, USA; Center for Spatial Information Science and Systems, George Mason University, Fairfax, VA, USA; Center for Spatial Information Science and Systems, George Mason University, Fairfax, VA, USA; Center for Spatial Information Science and Systems, George Mason University, Fairfax, VA, USA; Center for Spatial Information Science and Systems, George Mason University, Fairfax, VA, USA; Center for Spatial Information Science and Systems, George Mason University, Fairfax, VA, USA","2019 8th International Conference on Agro-Geoinformatics (Agro-Geoinformatics)","2 Sep 2019","2019","","","1","5","Land use and land cover (LULC) classification using satellite images is an important approach to monitor changes on earth. To produce LULC maps, supervised classification methods are often used. For many supervised classification algorithms, independence of features is an implied assumption. However, this assumption is rarely tested. For LULC classification, using all bands as input features to models is the default approach. However, some of the bands may be highly correlated, which may cause model performances unstable. In this research, correlations and multicollinearity among multi-spectral bands are analyzed for four major LULC types, i.e. cropland, forest, developed area and water bodies. Guided by the correlation analysis, different band combinations were used to train Support Vector Machines (SVM) for four-class LULC classification and the results were compared. From our experiments, band 4, 5, 6 is the best three-band combination and band 1, 2, 5, 7 is the best four-band combination which achieved almost identical performance as using all bands for LULC classification.","","978-1-7281-2116-1","10.1109/Agro-Geoinformatics.2019.8820595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820595","Landsat 8;Land use land cover;feature selection","Remote sensing;Earth;Artificial satellites;Correlation;Forestry;Support vector machines;Feature extraction","geophysical image processing;image classification;land cover;land use;terrain mapping","landsat 8 OLI band combinations;land use;land cover classification;satellite images;LULC maps;supervised classification methods;supervised classification algorithms;default approach;multicollinearity;multispectral bands;LULC types;correlation analysis;four-class LULC classification;four-band combination;band combinations;cropland;forest;developed area;water bodies;support vector machines","","4","","13","IEEE","2 Sep 2019","","","IEEE","IEEE Conferences"
"Hybrid Change Detection Based on ISFA for High-Resolution Imagery","J. Xu; C. Zhao; B. Zhang; Y. Lin; D. Yu","Zhengzhou Institute of Surveying and Mapping, Zhengzhou, China; Zhengzhou Institute of Surveying and Mapping, Zhengzhou, China; Zhengzhou Institute of Surveying and Mapping, Zhengzhou, China; Zhengzhou Institute of Surveying and Mapping, Zhengzhou, China; Zhengzhou Institute of Surveying and Mapping, Zhengzhou, China","2018 IEEE 3rd International Conference on Image, Vision and Computing (ICIVC)","18 Oct 2018","2018","","","76","80","Hybrid change detection (HCD) for high-resolution imagery usually adopt decision-level method and rely on artificial design. To address this issue, we propose a novel feature-level fusion strategy for HCD based on iterative slow feature analysis (ISFA). First, objects are obtained by multiresolution segmentation of bi-temporal images respectively, and corresponding feature sets are constructed through stacking pixel- and object-level spectral features. Then, slow feature analysis (SFA) is used for transforming the feature sets into a new feature space at the first time. And iteration method with variable weights is introduced to get the last slow feature fusion map, where the changed pixels and unchanged pixels can be separated more easily. At last, K-means cluster is adopted to separate changed area and unchanged area automatically and generate final change result. Experiments were conducted on bi-temporal multi-spectral images, demonstrating the good performance of the proposed approach.","","978-1-5386-4991-6","10.1109/ICIVC.2018.8492758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8492758","hybrid change detection;feature-level fusion;iterative slow feature analysis;multi-scale fusion","Image segmentation;Feature extraction;Eigenvalues and eigenfunctions;Remote sensing;Spatial resolution;Iterative methods","feature extraction;image fusion;image resolution;iterative methods;set theory","slow feature fusion map;bi-temporal multispectral images;hybrid change detection;ISFA;high-resolution imagery;HCD;decision-level method;artificial design;iterative slow feature analysis;multiresolution segmentation;bi-temporal images;object-level spectral features;feature sets;feature-level fusion strategy;stacking pixel-level spectral features;K-means cluster","","2","","16","IEEE","18 Oct 2018","","","IEEE","IEEE Conferences"
"Novel vegetation estimation index computation in arid environments","H. Hajjdiab; S. Ali; M. Ghazal","College of Engineering, Abu Dhabi University, Abu Dhabi, UAE; College of Engineering, Abu Dhabi University, Abu Dhabi, UAE; College of Engineering, Abu Dhabi University, Abu Dhabi, UAE","2015 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)","1 Feb 2016","2015","","","338","343","This paper proposes a novel vegetation index for the monitoring and study of vegetation in arid environments. Our aim is to help maintain a record of the area of vegetation available in relation to the total area of the specified region and provide an understanding of vegetation growth. The study uses JAI AD-080GE multi-spectral 2-channel CCD camera for multispectral image sample collection and computer vision techniques for automatic vegetation detection and segmentation. Compared with traditional vegetation indices, this index is less computationally complex while still supplying a robust approximation of the vegetation in the environment with an 96% accuracy. This vegetation index has many promising uses for vegetation estimation and its simplicity allows for continuous monitoring of vegetation growth among other applications.","","978-1-5090-0481-2","10.1109/ISSPIT.2015.7394355","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7394355","Arid Environments;Computer Vision;NDVI;Vegetation Index","Vegetation mapping;Indexes;Cameras;Estimation;Image segmentation;Remote sensing;Distortion","botany;CCD image sensors;computer vision;environmental monitoring (geophysics);estimation theory;geophysical techniques;geophysics computing;image segmentation;object detection;vegetation","vegetation estimation index computation;vegetation growth;JAI AD-080GE multispectral 2-channel CCD camera;multispectral image sample collection;computer vision techniques;automatic vegetation detection","","1","","17","IEEE","1 Feb 2016","","","IEEE","IEEE Conferences"
"Pansharpening Multispectral Images Based on Unconstrained Least Square Spectral Unmixing","M. A. Bendoumi; T. Benlefki; R. Saadi","Ecole Militaire Polytechnique (EMP), Bordj el Bahri, Algiers, Algeria; Ecole Militaire Polytechnique (EMP), Bordj el Bahri, Algiers, Algeria; Ecole Militaire Polytechnique (EMP), Bordj el Bahri, Algiers, Algeria","2018 International Conference on Signal, Image, Vision and their Applications (SIVA)","7 Mar 2019","2018","","","1","6","A new fusion framework for pansharpening multi-spectral (MS) image is suggested in this paper. The introduced method relies on linear spectral unmixing, and employs unconstrained least square (ULS) estimation for combining the high spatial features of the panchromatic (PAN) image and the rich spectral features of the MS image (MSI), in one single high spatial-spectral image. Applied to real coincident MS and PAN data sets with different texture complexity, the proposed approach can fuse the spatial and the spectral characteristics in a single image with the minimum of spectral distortion in comparison to some famous methods. Moreover, incorporating the ULS in the unmixing process is quite simple to formulate and straightforward to implement.","","978-1-5386-7120-7","10.1109/SIVA.2018.8660988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8660988","","Remote sensing;Spatial resolution;Principal component analysis;Artificial satellites;Earth;Measurement;Distortion","geophysical image processing;geophysical techniques;image fusion;image texture","unconstrained least square spectral unmixing;fusion framework;multispectral image;introduced method;unconstrained least square estimation;ULS;high spatial features;rich spectral features;MS image;spatial-spectral image;spectral characteristics;single image;spectral distortion;famous methods;unmixing process;texture complexity;pansharpening multispectral images;linear spectral unmixing;real coincident MS data set;real coincident PAN data set","","","","16","IEEE","7 Mar 2019","","","IEEE","IEEE Conferences"
"PanFormer: A Transformer Based Model for Pan-Sharpening","H. Zhou; Q. Liu; Y. Wang","The State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; Hangzhou Innovation Institute, Beihang University, Hangzhou, China; The State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China","2022 IEEE International Conference on Multimedia and Expo (ICME)","26 Aug 2022","2022","","","1","6","Pan-sharpening aims at producing a high-resolution (HR) multi-spectral (MS) image from a low-resolution (LR) multi-spectral (MS) image and its corresponding panchromatic (PAN) image acquired by a same satellite. Inspired by a new fashion in recent deep learning community, we propose a novel Transformer based model for pan-sharpening. We explore the potential of Transformer in image feature extraction and fusion. Following the successful development of vision transformers, we design a two-stream network with the self-attention to extract the modality-specific features from the PAN and MS modalities and apply a cross-attention module to merge the spectral and spatial features. The pan-sharpened image is produced from the enhanced fused features. Extensive experiments on GaoFen-2 and WorldView-3 images demonstrate that our Transformer based model achieves impressive results and outperforms many existing CNN based methods, which shows the great potential of introducing Transformer to the pan-sharpening task. Codes are available at https://github.com/zhysora/PanFormer.","1945-788X","978-1-6654-8563-0","10.1109/ICME52920.2022.9859770","NSFC(grant numbers:62176017,41871283); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859770","Pan-sharpening;transformer;attention mechanism;remote sensing","Deep learning;Satellites;Codes;Fuses;Transformers;Feature extraction;Sensors","cellular neural nets;correlation methods;feature extraction;filtering theory;geophysical image processing;image classification;image enhancement;image fusion;image resolution;learning (artificial intelligence)","novel Transformer based model;image feature extraction;vision transformers;modality-specific features;cross-attention module;spectral features;spatial features;pan-sharpened image;enhanced fused features;WorldView-3 images;existing CNN based methods;pan-sharpening task;pan-sharpening aims;MS;low-resolution multispectral image;corresponding panchromatic image;recent deep learning community","","1","","27","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"Hyper-spectral Image Super-resolution Using Non-negative Spectral Representation with Data-Guided Sparsity","X. -H. Han; J. Wang; B. Shi; Y. Zheng; Y. -W. Chen","Graduate School of Science and Technology for Innovation, Yamaguchi University, Yamaguchi, Japan; Ritsumeikan Univerity, Kusatsu, Shiga, Japan; The Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan; National Institute of Informatics, Tokyo, Japan; Ritsumeikan Univerity, Kusatsu, Shiga, Japan","2017 IEEE International Symposium on Multimedia (ISM)","1 Jan 2018","2017","","","500","506","Hyperspectral imaging has great potential for understanding the characteristics of different materials in many applications ranging from remote sensing to medical imaging. However, due to various hardware limitations, only low-resolution hyperspectral and high-resolution multi-spectral images can be available using existing imaging techniques. This study aims to generate a high-resolution hyperspectral image via fusion of the available LR-HS and HR-MS images. We propose a novel hyperspectral image superresolution method via non-negative sparse representation of reflectance spectral with adaptive sparsity constraint. By analyzing local content similarity of a focused pixel in the available high-resolution multi-spectral image, which can measure pixel material purity according to surrounding pixels, we generate a sparsity map for guiding non-negative sparse coding optimization procedure of the spectral representation called non-negative spectral representation with data-guided sparsity. Since the proposed method adaptively adjust the sparsity in the spectral representation based on the local content of the available high-resolution multi-spectral image, it can produce more robust spectral representation for recovering the target high-resolution hyper-spectral image. Comprehensive experiments on two public hyperspectral datasets validate that the proposed method achieves promising performances compared with the existing state of the art methods.","","978-1-5386-2937-6","10.1109/ISM.2017.99","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241665","","Hyperspectral imaging;Dictionaries;Spatial resolution;Sparse matrices;Cameras","geophysical image processing;hyperspectral imaging;image reconstruction;image representation;image resolution;optimisation;remote sensing","hyper-spectral image super-resolution;nonnegative spectral representation;medical imaging;low-resolution hyperspectral;high-resolution multispectral image;high-resolution hyperspectral image;HR-MS images;nonnegative sparse representation;nonnegative sparse coding optimization procedure;robust spectral representation;target high-resolution hyper-spectral image;hyperspectral image superresolution method","","3","","35","IEEE","1 Jan 2018","","","IEEE","IEEE Conferences"
"A Deep Learning Hybrid CNN Framework Approach for Vegetation Cover Mapping Using Deep Features","R. Nijhawan; H. Sharma; H. Sahni; A. Batra","Deptt.of Earthquake Engg., IIT Roorkee, Roorkee, India; CSE, Quantum School of Tech., Roorkee, India; CSE, COER Roorkee, India; CSE, Quantum School of Tech., Roorkee, India","2017 13th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","12 Apr 2018","2017","","","192","196","Vegetation cover mapping is an imperative task of monitoring the change in vegetation as it can help us meet sustenance requirements. In this study, we explore the future potential of multilayer Deep learning framework (DL) that comprises of hybrid of CNN's, for mapping vegetation cover area as DL is a congenial state-of-art algorithm for implementing image processing. This study proposes a novel DL framework exploiting hybrids of CNN's with Local binary pattern and GIST features. Every CNN is fed with disparate combination of multi-spectral Sentinel 2 satellite imagery bands (spatial resolution of 10m), texture and topographic parameters of Uttarakhand (30° 15' N, 79° 15' E) region, India. Our proposed DL framework outperformed the state-of-art algorithms with a classification accuracy of 88.43%.","","978-1-5386-4283-2","10.1109/SITIS.2017.41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8334746","Deep Learning;CNN;Hybrid;Vegetation Cover;Sentinel 2","Vegetation mapping;Satellites;Machine learning;Support vector machines;Radio frequency;Classification algorithms;Convolutional neural networks","feature extraction;feedforward neural nets;geophysical image processing;image classification;learning (artificial intelligence);remote sensing;vegetation;vegetation mapping","multilayer Deep learning framework;GIST features;multispectral Sentinel 2 satellite imagery bands;DL framework;image processing;Local binary pattern;spatial resolution;topographic parameters;Uttarakhand;India;classification accuracy;vegetation cover mapping","","24","","16","IEEE","12 Apr 2018","","","IEEE","IEEE Conferences"
"Sharpening the WBSI Imagery of Tiangong-II: Gram-Schmidt and Principal Components Transform in Comparison","Q. Liu","State Key Laboratory of Resources and Environmental Information System, Chinese Academy of Sciences, Beijing, China","2018 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","11 Apr 2019","2018","","","511","518","With an increasing number of remotely sensed sensors acquired multi-spectral images over several separate wavelength ranges at various spectral resolutions, many sharpening techniques were developed to improve the lower spatial resolution imagery to become a same high spatial resolution multispectral dataset for meeting the demands of numerous applications. In this work, two well known sharpening techniques namely Gram-schmidt (GS) and Principal Components Transform (PC) were used to sharpen two shortwave infrared (SWIR) bands with the visible and near-infrared (VNIR) spectral bands of the Wide Band Spectral Imager (WBSI) on board the Tiangong-II space lab. It had been proved that the vegetation proportion of the image affected the CC value between the resized and the sharpened SWIR images when the different VNIR bands were used as the high spatial resolution band during the GS procedure. When the VNIR Band 1 was used as the high spatial resolution band, the quality of the sharpened SWIR images from the GS and PC sharpening method was similar. From the visual comparison of the sharpened results, the necessity of compromise between spatial resolution enhancement and spectral similarity was accepted, and for the different applications, the different sharpening techniques should be used.","","978-1-5386-8097-1","10.1109/FSKD.2018.8687270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8687270","component;sharpening;Tiangong-II;GS;PC","","geophysical image processing;image resolution;image sensors;principal component analysis;remote sensing;vegetation","WBSI imagery;Principal Components Transform;remotely sensed sensors;multispectral images;spectral resolutions;high spatial resolution multispectral dataset;Wide Band Spectral Imager;Tiangong-II space lab;sharpened SWIR images;high spatial resolution band;VNIR Band 1;PC sharpening method;spatial resolution enhancement;Gram-Schmidt process;spatial resolution imagery;sharpening techniques;SWIR bands;vegetation proportion","","6","","26","IEEE","11 Apr 2019","","","IEEE","IEEE Conferences"
"Comparison of Several Hyperspectral Image Fusion Methods for Superresolution","H. Lin; J. Chen","Department of Information System, Dalian Naval Academy, Dalian, China; Department of Information System, Dalian Naval Academy, Dalian, China","2018 IEEE 3rd International Conference on Image, Vision and Computing (ICIVC)","18 Oct 2018","2018","","","448","452","Hyperspectral image applications have been explored in various areas, but they are often suffered from coarser spatial resolutions. In recent years, many hyperspectral image fusion approaches which merge hyperspectral image with multi-spectral or panchromatic one have been presented to improve the spatial resolution of hyperspectral image. In this paper, we compared four state-of-the-art hyperspectral fusion methods, namely coupled nonnegative matrix factorization (CNMF) method, sparse matrix factorization (SPMF) method, hyperspectral Image superresolution (HySure) method and sparse representation (SPRE) method. The main idea of each method is depicted briefly, five statistical assessment parameters, namely cross correlation (CC), root-mean-square error (RMSE), spectral angle mapper (SAM), universal image quality index (UIQI), and relative dimensionless global error in synthesis (ERGAS) are adopted to comparatively analyze the fusion results. The experimental results show that the effect of method based on sparse representation is superior to the others one.","","978-1-5386-4991-6","10.1109/ICIVC.2018.8492889","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8492889","hyperspectral image;multicalspectral image;fusion;superresolution","Spatial resolution;Hyperspectral imaging;Sparse matrices;Dictionaries;Image fusion","hyperspectral imaging;image fusion;image resolution;image sampling;matrix decomposition;mean square error methods;remote sensing;spectral analysis","hyperspectral image superresolution method;image quality index;hyperspectral fusion method;hyperspectral image fusion approach;coupled nonnegative matrix factorization;spectral angle mapper;sparse representation method;sparse matrix factorization method;nonnegative matrix factorization method;spatial resolution;hyperspectral image applications","","2","","8","IEEE","18 Oct 2018","","","IEEE","IEEE Conferences"
"Aerial Investigations Corroboration for Archaeology and Monuments","A. Chelmus; R. Radvan; L. Angheluta","Advanced methods and techniques for artwork restoration & conservation, The National R&D Institute for Optoelectronics - INOE2000, Magurele, Romania; Advanced methods and techniques for artwork restoration & conservation, The National R&D Institute for Optoelectronics - INOE2000, Magurele, Romania; Adv. Methods & Tech. for Artwork Restoration & Conservation, Nat. R&D Inst. for Optoelectron., Magurele, Romania","2018 11th International Conference on Developments in eSystems Engineering (DeSE)","24 Feb 2019","2018","","","113","116","This paper presents the applications and improvements that aerial investigations bring to the cultural heritage. These techniques can be used for archaeology (to identify or to map archaeological remains) or monuments (to analyze their conservation status). As a case study, data gathered at the Monumental ensemble ""Calea Eroilor"" from Romania are presented. The investigation was conducted using a thermal camera, LIDAR, a high resolution camera and a multi spectral camera mounted on a 8 propellers UAV. The data is corroborated as layers in a pack using a GIS software.","2161-1351","978-1-5386-6712-5","10.1109/DeSE.2018.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648595","UAV;cultural heritage;GIS","Cameras;Unmanned aerial vehicles;Logic gates;Cultural differences;Soil;Laser radar;Vegetation mapping","archaeology;autonomous aerial vehicles;cameras;geographic information systems;geophysical image processing;geophysical techniques;history;optical radar;remote sensing by laser beam","LIDAR;GIS software;archaeological map;multispectral camera;high resolution camera;thermal camera;Calea Eroilor;conservation status;cultural heritage;archaeology;aerial investigations corroboration","","2","","5","IEEE","24 Feb 2019","","","IEEE","IEEE Conferences"
"Challenges in water stress quantification using small unmanned aerial system (sUAS): Lessons from a growing season of almond","T. Zhao; B. Stark; Y. Chen; A. L. Ray; D. Doll","Mechatronics, Embedded Systems and Automation Lab, University of California, Merced, CA, USA; Mechatronics, Embedded Systems and Automation Lab, University of California, Merced, CA, USA; Mechatronics, Embedded Systems and Automation Lab, University of California, Merced, CA, USA; Cooperative Extension (UCCE) Merced County, University of California, Merced, CA; Cooperative Extension (UCCE) Merced County, University of California, Merced, CA","2016 International Conference on Unmanned Aircraft Systems (ICUAS)","4 Jul 2016","2016","","","1366","1370","With water shortages and drought affecting many regions of the world, it becomes urgent to increase water use efficiency (WUE) by optimizing irrigation schedule. Proper irrigation scheduling, which includes integrating of soil moisture monitoring, surface evapotranspiration loss calculation, and plant based measurements is required for high WUE. Stem water potential (SWP) has become one of the more common methods to measure water status. It is, however, labor intensive and time consuming, and adoption has been slow. This study aims to build the link between SWP and canopy normalized difference vegetation index (NDVI) based on aerial multi-spectral images and ground-truth measurement of an almond orchard. Data suggests that the correlation between SWP and canopy NDVI can be improved by tuning canopy NDVI threshold, as indicated by the coefficient of determination (R2). Also, NDVI shows good correlation with SWP in different growing stages - fruit development and post-harvest. Finally, it is demonstrated canopy NDVI distribution from different missions are significantly different, even if the interval between two flights is less than one hour. This poses the challenge that further calibration is needed to conduct quantitative measurement in long flight missions. Meanwhile, quantitative consideration of characteristic of bi-directional reflectance distribution function makes it necessary to obtain stable performance of canopy NDVI.","","978-1-4673-9334-8","10.1109/ICUAS.2016.7502642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7502642","small unmanned aerial system (sUAS);canopy normalized difference vegetation index (NDVI);water stress detection;stem water potential (SWP)","Stress;Vegetation;Cameras;Irrigation;Spatial resolution;Soil","agricultural products;autonomous aerial vehicles;hyperspectral imaging;image processing;irrigation;remote sensing;scheduling;vegetation;water supply","water stress quantification;small unmanned aerial system;sUAS;water shortages;almond season;water use efficiency;WUE;irrigation schedule optimization;soil moisture monitoring;surface evapotranspiration loss calculation;plant based measurements;stem water potential;SWP;water status measurement;canopy normalized difference vegetation index;NDVI;aerial multispectral images;ground-truth measurement;almond orchard;canopy NDVI threshold tuning;coefficient of determination;fruit development;post-harvest;long flight missions;bidirectional reflectance distribution function characteristic;water drought","","1","","26","IEEE","4 Jul 2016","","","IEEE","IEEE Conferences"
"An SVM approach for Pixel Identification of Multispectral Remotely Sensed Data","S. Hazra; S. Ghosh; S. Bala; D. Chakraborty","Asansol Engineering College, Computer Science and Engineering, Asansol, India; Asansol Engineering College, Computer Science and Engineering, Asansol, India; Asansol Engineering College, Computer Science and Engineering, Asansol, India; Asansol Engineering College, Computer Science and Engineering, Asansol, India","2021 2nd International Conference for Emerging Technology (INCET)","22 Jun 2021","2021","","","1","6","This paper presents support vector machines (SVMs) approach for identifying the problem of pixel identification of multi-spectral remotely sensed (RS) data. SVM is a supervised algorithm that uses statistical learning framework. The performance of SVMs is either comparable or better than the other classification techniques including k-NN and naive Bayes. A comparative study has been conducted among SVM, k-NN and naive Bayes algorithms applied on two labeled RS data as well as two very large unlabeled RS datasets of Kolkata and Mumbai having a set of features and subsequently recognizing various ground cover territories in RS data. The experimental results indicate that using SVMs can significantly outperform other two algorithms on RS data. Comparison is made in terms of number of training examples, kappa value, accuracy and cluster validity indices.","","978-1-7281-7029-9","10.1109/INCET51464.2021.9456237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9456237","Pixel;RS imagery;Quadratic Programming;SVM;Kernel function","Support vector machines;Training;Software algorithms;Statistical learning;Clustering algorithms;Prediction algorithms;Software","geophysical image processing;image classification;learning (artificial intelligence);pattern clustering;remote sensing;statistical analysis;support vector machines","SVM;pixel identification;multispectral remotely sensed data;support vector machines;supervised algorithm;statistical learning;k-NN;naive Bayes;labeled RS data;unlabeled RS datasets;Kolkata;Mumbai;ground cover territories;kappa value;cluster validity indices;classification techniques","","","","20","IEEE","22 Jun 2021","","","IEEE","IEEE Conferences"
"Classification of high-resolution satellite images from urban areas based hybrid supporting vector machines and Multi-instance learning","M. S. A. Mahmoud","Computer Science Dept., Faculty of Computers and Informatics, Suez Canal University, Ismailia, Egypt","2021 International Telecommunications Conference (ITC-Egypt)","20 Aug 2021","2021","","","1","4","Remotely sensed image grading advanced considerably; takes into account the availability and abundance of various resolution image grading algorithms. Several works were successful by the fusion of space-spectrum knowledge with supporting vector machines (SVM). To incorporate all these data with the composite approach, we suggest a technique using a hybrid multi-spectral and multi-instance procedure. This paper introduces a groundbreaking approach to exploring urban buildings through the implementation of the SVM-based support classification and Multi-instance learning (MIL). In this paper, we present the use of this model, the classification of images. Use high-resolution technology from Quickbird. This practice and archery have contributed to the performance, efficiency, and power. The suggested solution was tested in traditional urban imagery scenes. The results show a major improvement the classification performance compared to the two separately used attributes. The results of the experiments indicate a very promising accuracy of 91, 24%.","","978-1-6654-4574-0","10.1109/ITC-Egypt52936.2021.9513882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9513882","Multi-Instance Learning (MIL);Support Vector Machines (SVM);Quickbird Satellite images;textural and spatial metrics","Measurement;Satellites;Image resolution;Urban areas;Buildings;Support vector machine classification;Telecommunications","geophysical image processing;image classification;learning (artificial intelligence);remote sensing;support vector machines","urban buildings;SVM-based support classification;multiinstance learning;high-resolution technology;traditional urban imagery scenes;classification performance;high-resolution satellite images;hybrid supporting vector machines;resolution image grading algorithms;space-spectrum knowledge;multiinstance procedure;MIL","","","","18","IEEE","20 Aug 2021","","","IEEE","IEEE Conferences"
"Surrogate ML/AI Model Benchmarking for FAIR Principles' Conformance","P. Luszczek; C. Brown","EECS, University of Tennessee, Knoxville, TN, USA; EECS, University of Tennessee, Knoxville, TN, USA","2022 IEEE High Performance Extreme Computing Conference (HPEC)","1 Nov 2022","2022","","","1","5","We present benchmarking platform for surrogate ML/AI models that enables the essential properties for open science and allow them to be findable, accessible, interoperable, and reusable. We also present a use case of cloud cover modeling, analysis, and experimental testing based on a large dataset of multi-spectral satellite sensor data. We use this particular evaluation to highlight the plethora of choices that need resolution for the life cycle of supporting the scientific workflows with data-driven models that need to be first trained to satisfactory accuracy and later monitored during field usage for proper feedback into both computational results and future data model improvements. Unlike traditional testing, performance, or analysis efforts, we focus exclusively on science-oriented metrics as the relevant figures of merit.","2643-1971","978-1-6654-9786-2","10.1109/HPEC55821.2022.9926401","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9926401","","Measurement;Cloud computing;Analytical models;Satellites;Computational modeling;Benchmark testing;Data models","clouds;data models;geophysical image processing;oceanographic techniques;remote sensing","experimental testing;multispectral satellite sensor data;life cycle;data-driven models;future data model improvements;traditional testing;science-oriented metrics;FAIR principles;benchmarking platform;cloud cover modeling","","","","33","IEEE","1 Nov 2022","","","IEEE","IEEE Conferences"
"Shallow Search of a 10-Mile Swath with a Flight of Ship-Based UAVs","A. v. Flotow; V. Tom Q. Donaldson; S. John","Hood Technology Corporation, Hood River, OR, USA; Rear Admiral USN (Ret), Greenville, SC, USA; Hood Technology Corporation, Hood River, OR, USA","OCEANS 2022, Hampton Roads","19 Dec 2022","2022","","","1","6","This paper introduces an airborne system that was conceptualized and designed to detect submerged objects, day and night, optically from manned and unmanned aircraft. This system was designed with strict size, weight and power constraints and to work with ship-based Tier2/Tier3 UAVs. Daytime detection is accomplished through multi-spectral imaging mixing methods, and nighttime imaging capability is reliant on sensing the light signatures from disturbed marine bioluminescent organisms. This paper describes the methodology used to determine the detector, lens and filters, the mechanical design and associated calibration techniques, and the image processing method used. It also presents the data obtained from preliminary field tests and discusses planned future work based on these results. This system could potentially be useful for protecting both ships and marine mammals from inadvertent collisions, particularly at night, as well bring additional capability to the USCG in their maritime, counter-drug missions.","0197-7385","978-1-6654-6809-1","10.1109/OCEANS47191.2022.9976965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9976965","Submerged object detection;ship and marine mammal collision avoidance;optical sensing;image processing","Optical filters;Optical design;Multispectral imaging;Roads;Oceans;Optical mixing;Search problems","autonomous aerial vehicles;bioluminescence;calibration;image processing;image sensors;oceanographic techniques;remote sensing;ships","airborne system;associated calibration techniques;daytime detection;disturbed marine bioluminescent organisms;image processing method;light signatures;manned aircraft;marine mammals;mechanical design;multispectral imaging mixing methods;nighttime imaging capability;power constraints;shallow search;ship-based Tier2-Tier3 UAV;ship-based UAV;submerged objects;unmanned aircraft","","","","9","IEEE","19 Dec 2022","","","IEEE","IEEE Conferences"
"Classifying Dominant Tree Species Over a Large Mountainous Area Based On Multitemporal Sentinel-2 Data","P. Zheng; P. Fang; P. Liu; Q. Dai; J. Li","Faculty of Forestry, Southwest Forestry University, SWFU, Kunming, Yunnan; Faculty of Forestry, Southwest Forestry University, SWFU, Kunming, Yunnan; Institute of Big Data and Artificial Intelligence, Southwest Forestry University, SWFU, Kunming, Yunnan; Art and Design College, Southwest Forestry University, SWFU, Kunming, Yunnan; Faculty of Forestry, Southwest Forestry University, SWFU, Kunming, Yunnan","2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","30 May 2022","2021","","","1755","1760","Trees are vital to the quality of the urban ecological environment. It can improve the quality of air, absorb and reduce carbon dioxide and alleviate urban heat islands. Previous studies that employ multi-spectral imagery have already evaluated different classification algorithms to identify tree species. But often the researches were conducted on small areas and a single image scene. In this study, the study area (Diqing Tibetan Autonomous Prefecture) covered by 73.95% forests, of which approximately 18000 km2. Based on the GEE (Google Earth Engine) cloud computing platform, combined multi-temporal Sentinel-2 imagery with topography information, three machine learning classifiers, including Regression Tree, Random Forest, Gradient Boosting Decision Tree, were used to obtain nine tree species 10m meters of mapping products. An overall accuracy of 81.4% (a Cohen's kappa of 78.5%) was obtained for nine tree species classes. The addition of multi-temporal images improved the OA (over all accuracy) by 8.01%∼12.40%, and Kappa by 8.91%∼12.96%. After combining the terrain features, OA is improved by 9.39%∼14.72%, and Kappa by 10.95%∼18.19%. Obtaining high-quality cloud-free images is difficult for the cloudy and rainy southwest of China, so the composites of multi-temporal images and the combination of other morphoclimatic characteristics are of great significance for large-scale tree species classification.","","978-1-6654-9457-1","10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00258","National Natural Science Foundation of China(grant numbers:31860182,31860181,41961053,3216140376); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9781145","Tree species;Multi-temporal;Google Earth Engine;Machine Learning","Earth;Radio frequency;Cloud computing;Smart cities;Forestry;Surfaces;Thermal pollution","atmospheric temperature;cloud computing;decision trees;ecology;geophysical image processing;image classification;learning (artificial intelligence);regression analysis;remote sensing;terrain mapping;vegetation;vegetation mapping","dominant tree species;mountainous area;multitemporal sentinel-2 data;trees;urban ecological environment;carbon dioxide;urban heat islands;multispectral imagery;single image scene;Diqing Tibetan Autonomous Prefecture;Google Earth Engine;combined multitemporal Sentinel-2 imagery;classifiers;Regression Tree;Random Forest;Gradient Boosting Decision Tree;tree species classes;multitemporal images;Kappa;high-quality cloud-free images;large-scale tree species classification","","","","14","IEEE","30 May 2022","","","IEEE","IEEE Conferences"
"SVMIRE - An Open Source SVM Image Retrieval with Relevance Feedback System For Earth Observation Data Classification","A. -C. Grivei","CECTI, Military Technical Academy “Ferdinand I”, Bucharest, Romania","2020 13th International Conference on Communications (COMM)","16 Jul 2020","2020","","","171","176","The continuous increase of Earth Observation image acquisitions requires new weakly supervised algorithms for classification and image retrieval. In this paper, we present the architecture of SVMIRE (SVM Image REtrieval with Relevance Feedback) which is a flexible, modular, and fast data mining system based on a relevance feedback approach that increases the performance of the Support Vector Machine (SVM) classifiers. The proposed system has the capability of storing and reusing the obtained classification model, and results. The functionalities of the SVMIRE system are tested on two datasets: one Landsat 8 OLI/TIRS (Operational Land Imager/Thermal Infrared Sensor) and one Sentinel-2 MSI (Multi-Spectral Instrument).","","978-1-7281-5611-8","10.1109/COMM48946.2020.9141975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141975","land cover;framework;earth observation;machine learning;open source","Support vector machines;Feature extraction;Training;Classification algorithms;Image retrieval;Earth;Kernel","data acquisition;data mining;geophysical image processing;image classification;image retrieval;relevance feedback;remote sensing;support vector machines","SVMIRE system;classification model;Support Vector Machine classifiers;relevance feedback approach;fast data;flexible data;weakly supervised algorithms;Earth Observation image acquisitions;Earth Observation data classification;Relevance Feedback system;open source SVM Image retrieval","","","","13","IEEE","16 Jul 2020","","","IEEE","IEEE Conferences"
"Quantitative and Qualitative Analysis of PCC-based Change detection methods over Agricultural land using Sentinel-2 Dataset","G. Singh; G. K. Sethi; S. Singh","Department of Computer Science, Punjabi University, Patiala, India; Department of Computer Science, Multani Mal Modi College, Patiala, India; Chitkara University School of Engineering and Technology, Chitkara University, Himachal Pradesh, India","2022 3rd International Conference on Computing, Analytics and Networks (ICAN)","13 Jan 2023","2022","","","1","5","To plan production, the sowing, and harvesting of a particular crop, and the performance of marketing activities information about yields is important for both the traders and producers. In this study, various efforts have been made to extract critical information for agriculture land use classification areas using Sentinel-2 datasets, which was not possible with the help of multi-spectral datasets. As part of the current work, the artificial neural networks (ANN) classifier is combined with the post-classification comparison (PCC), thereby predicting seasonal variability from satellite imagery. The ANN classifier is incorporated into the post-classification comparison procedure, called ANN-based change detection. As part of the demonstration, the datasets were acquired using Sentinel-2 datasets during the period 2017 – 2018 over the agricultural land in Block Khamanon, District Fatehgarh Sahib, Punjab State, India. This process cross-validated the performance of ANN with a conventional maximum likelihood classifier (MLC) for confirmation. In comparison with the conventional PCC-MLC model (classified maps have an average of 86 – 88.8%, and change maps have an average of 83.6 – 84.2%), the PCC-ANN model achieved accuracy (classified maps have an average of 90.4 – 93.4%, and change maps have an average of 87.4 – 90%). In addition to identifying water surfaces, crop types, and man-made features, this study can also help in performing a wide range of land-use patterns.","","978-1-6654-9944-6","10.1109/ICAN56228.2022.10007391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10007391","ANN classifier;MLC classifier;PCC-based change detection technique;Sentinel-2 dataset","Maximum likelihood estimation;Maximum likelihood detection;Satellites;Statistical analysis;Crops;Artificial neural networks;Production","agriculture;crops;geophysical image processing;image classification;neural nets;remote sensing;terrain mapping","agricultural land;agriculture land use classification areas;ANN classifier;artificial neural networks classifier;called ANN-based change detection;change maps have an average;conventional maximum likelihood classifier;conventional PCC-MLC model;critical information;marketing activities information;multispectral datasets;PCC-ANN model;PCC-based change detection methods;post-classification comparison procedure;qualitative analysis;quantitative analysis;Sentinel-2 dataset","","","","29","IEEE","13 Jan 2023","","","IEEE","IEEE Conferences"
"Deep Learning for Agricultural Land Detection in Insular Areas","E. Charou; G. Felekis; D. B. Stavroulopoulou; M. Koutsoukou; A. Panagiotopoulou; Y. Voutos; E. Bratsolis; P. Mylonas; L. Likforman-Sulem","NCSR Demokritos, Institute of Informatics and Telecommunication, Athens, Greece; Department of Mathematics, Kapodistrian University of Athens, Athens, Greece; Rural and Surveying Engineering, National and Technical University of Athens, Athens, Greece; Department of Physics, Kapodistrian University of Athens, Athens, Greece; NCSR Demokritos, Institute of Informatics and Telecommunication, Athens, Greece; Department of Informatics, Ionian University, Corfu, Greece; Department of Informatics and Computer Engineering, University of West Attica, Athens, Greece; Department of Informatics, Ionian University, Corfu, Greece; Institute Mines-Télécom/ Télécom ParisTech, University Paris-Saclay, Paris, France","2019 10th International Conference on Information, Intelligence, Systems and Applications (IISA)","14 Nov 2019","2019","","","1","4","Nowadays, governmental programs like ESA’s Copernicus provide freely available data that can be easily utilized for earth observation. In the present work, the problem of detecting agricultural and non-agricultural land cover is addressed. The methodology is based on classification with convolutional neural networks (CNNs) and transfer learning using AlexNet. The study area is located at the Ionian Islands, which include several land cover classes according to Copernicus CORINE Land Cover 2018 (CLC 2018). Furthermore, the dataset consists of natural color images acquired by Sentinel-2A multi-spectral instrument. Experimentation proves that extra addition of training data from foreign grounds, unfamiliar to the Greek data, serves much as a confusing agent regarding network performance.","","978-1-7281-4959-2","10.1109/IISA.2019.8900670","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900670","Deep learning;Transfer learning;Ionian Sea;Agricultural land;CORINE database;Remote Sensing;Satellite Image Classification;Deep Convolutional Neural Networks","Training;Agriculture;Testing;Satellites;Informatics;Convolutional neural networks;Deep learning","agriculture;convolutional neural nets;geophysical techniques;geophysics computing;land cover;learning (artificial intelligence)","agricultural Land detection;insular areas;governmental programs;ESA's Copernicus;freely available data;earth observation;nonagricultural land cover;transfer learning;Ionian Islands;land cover classes;Copernicus CORINE Land Cover 2018;CLC 2018;natural color images;training data;Greek data;deep learning;convolutional neural networks;AlexNet;Sentinel-2A multispectral instrument","","2","","12","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Thermal Anomaly Level Algorithm for Active Fire Mapping by Means of Sentinel-2 Data","S. Liangrocapart; S. Khetkeeree; B. Petchthaweetham","Department of Physics, Mahanakorn University of Technology, Bangkok, Thailand; Department of Physics, Mahanakorn University of Technology, Bangkok, Thailand; R V Connex Co., Ltd., Pathum Thani, Thailand","2020 17th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","4 Aug 2020","2020","","","687","690","In this study, we propose a new approach to detect and map active fire area by means of Sentinel-2 data. Sentinel-2 Multi-Spectral Instrument (MSI) is comprised of visible spectral bands, near infrared (NIR), and short wave infrared (SWIR) spectral bands. These spectral bands, band 8A (865 nm), band 11 (at 1.61 μm), and band 12 (at 2.19 μm), are employed to roughly approximate the temperature within the forest fire range (400 - 1500°C) using Planck's blackbody radiation law. The Normalised Difference Indices (NDI) of band 11 with 8A and band 12 with 11 are formulated, namely NDI1 and NDI2, respectively. The criteria of NDI1, NDI2, and band 12 ranges are estimated empirically to identify forest fire area into four thermal anomaly levels, i.e., high-temperature crown fire, typical crown fire, surface fire or smoldering area and remains of the fire. For the high-temperature crown fire area, band 12 value is very high, all indices are positive, and the NDI2 is lower than NDI1, following Planck's curve for temperature higher than 1200 K. For the typical crown fire area, the band 12 value is high, and the NDI2 can be higher than NDI1. For the smolder area, the band 12 value is in the middle range, and the NDI2 must be larger than 0.2. Finally, for remains area, the band 12 value is in the lower range, and NDI1 must be higher than -0.27. This work shows that the active fire area can be identified and mapped into four thermal anomaly levels. This approach can be employed for rapid fire management as soon as the image data is obtained.","","978-1-7281-6486-1","10.1109/ECTI-CON49241.2020.9158262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9158262","active fire mapping;Sentinel-2;fire management;forest fire;Planck’s law;remote sensing","Fires;Forestry;Temperature distribution;Satellites;Instruments;Earth;Telecommunications","atmospheric temperature;fires;geophysical techniques;terrain mapping","active fire mapping;Sentinel-2 data;map active fire area;Sentinel-2 MultiSpectral Instrument;visible spectral bands;NDI1;NDI2;band 12 ranges;forest fire area;high-temperature crown fire area;band 12 value;smoldering area;surface fire;normalised difference indices;Planck blackbody radiation law;short wave infrared spectral band;near infrared spectral band;thermal anomaly level algorithm;size 865.0 nm;size 1.61 mum;size 2.19 mum;temperature 1200.0 K;temperature 400.0 degC to 1500.0 degC","","1","","6","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Diagnosis of Nitrogen Concentration of Maize Based on Sentinel-2 Images: A Case Study of the Hetao Irrigation District","R. Lin; H. Chen; Z. Wei; Y. Li; N. Han","State Key Laboratory of Simulation and Regulation of Water Cycle in River Basin, China Institute of Water Resources and Hydropower Research, Beijing, China; State Key Laboratory of Simulation and Regulation of Water Cycle in River Basin, China Institute of Water Resources and Hydropower Research, Beijing, China; State Key Laboratory of Simulation and Regulation of Water Cycle in River Basin, China Institute of Water Resources and Hydropower Research, Beijing, China; State Key Laboratory of Simulation and Regulation of Water Cycle in River Basin, China Institute of Water Resources and Hydropower Research, Beijing, China; College of Water Conservancy Engineering, Tianjin Agricultural University, Tianjing, China","2022 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI)","17 Aug 2022","2022","","","163","167","The rapid diagnosis of nitrogen concentration in maize growth period in the Hetao Irrigation District were carried out to provide reference for fertilization decision and non-point source pollution research. Based on the UAV multi-spectral data and measured nitrogen concentration values, a variety of spectral indices were used to quantitatively characterize plant nitrogen content, and a diagnostic model of nitrogen concentration during maize growth period was established. According to the validation results of spectral index diagnostic models, the spectral index diagnostic models in different growth periods were evaluated, and the nitrogen concentration diagnosis in growth periods was carried out. The optimal nitrogen diagnostic model was established by GBNDVI, RVI, NRI, and NDVI at jointing, small trumpet, large trumpet, and flowering stage of maize in the Hetao Irrigation District, respectively. The planting area of maize in the Hetao irrigation district in 2020 was 4127800 mu. The nitrogen concentration was lower in small trumpet and flowering stage, and higher in jointing and large trumpet stage. The spatial distribution of nitrogen concentration based on maize plant nitrogen diagnostic model can provide reference for fertilization decision and agricultural non-point source pollution research.","","978-1-6654-6803-9","10.1109/ICCEAI55464.2022.00042","National Key R&D Program of China(grant numbers:2019YFC0409203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9853434","nitrogen concentration;maize;Sentinel-2;the unmanned aerial vehicle remote sensing;the Hetao Irrigation District","Irrigation;Pollution;Graphical models;Plants (biology);Data models;Pollution measurement;Nitrogen","agricultural engineering;agriculture;crops;fertilisers;geophysical image processing;irrigation;nitrogen","maize growth period;spectral index diagnostic models;different growth periods;nitrogen concentration diagnosis;optimal nitrogen diagnostic model;Hetao Irrigation District;Hetao irrigation district;maize plant nitrogen diagnostic model;nonpoint source pollution research;UAV multispectral data;measured nitrogen concentration values;plant nitrogen content","","","","16","IEEE","17 Aug 2022","","","IEEE","IEEE Conferences"
"Land Cover Satellite Image Classification Using NDVI and SimpleCNN","T. T. Sasidhar; S. K.; V. M.T.; S. V.; S. K.P.","Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India; Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India; Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India; Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India; Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India","2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)","30 Dec 2019","2019","","","1","5","Image classification and prediction is a task which is embedded with quite a lot of challenges. Introduction of deep learning gave a rapid rise in this area of research. The efficient and the simplest deep learning algorithm that has helped researchers to make immense contributions in the field of image classification is Convolutional Neural Network (CNN). One of the important applications of image classification is in remote sensing, where it is used for land cover classification. In this paper we developed a SimpleCNN architecture for the classification of multi-spectral images from SAT-4 and SAT-6 airborne datasets. Two sets of experiments are conducted using the model by feeding it with different features. First level of experiment is done by providing the model with Near-Infrared (NIR) band information as it can sense vegetation health. The domain knowledge of Normalized Difference Vegetation Index (NDVI) motivated us to utilize Red and NIR spectral bands together in the second level of experimentation for the classification. It is observed from the experiment that the two band information gave better results for land cover classification.","","978-1-5386-5906-9","10.1109/ICCCNT45670.2019.8944840","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944840","Convolutional Neural Network;Normalized Difference Vegetation Index;Near- Infrared;Trainable Parameters","","convolutional neural nets;geophysical image processing;image classification;land cover;learning (artificial intelligence);vegetation mapping","SAT-6 airborne dataset;near-infrared band information;vegetation health;normalized difference vegetation index;red spectral band;NIR spectral band;SAT-4 airborne dataset;remote sensing;convolutional neural network;SimpleCNN;multispectral images;simplest deep learning algorithm;land cover satellite image classification","","7","","15","IEEE","30 Dec 2019","","","IEEE","IEEE Conferences"
"SAR Target Recognition with Deep Learning","R. J. Soldin","Lockheed Martin Space, King of Prussia, Pennsylvania","2018 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)","9 May 2019","2018","","","1","8","The automated detection and classification of objects in imagery is an important topic for many applications in remote sensing. These can include the counting of cars and ships and the tracking of military vehicles for the defense and intelligence industry. Synthetic aperture radar (SAR) provides day/night and all-weather imaging capabilities. SAR is a powerful data source for Deep Learning (DL) algorithms to provide automatic target recognition (ATR) capabilities. DL classification was shown to be extremely effective on multi-spectral satellite imagery during the IARPA Functional Map of the World (fMoW). In our work we look to extend these techniques to SAR. We start by applying ResNet-18 to the Moving and Stationary Target Acquisition and Recognition (MSTAR) dataset. The MSTAR program, sponsored by DARPA and AFRL, consists of SAR collections of military style targets using an aerial X-band radar with one-foot resolution. We achieved an overall classification accuracy of 99% on 10 different classes of targets, confirming previously published results. We then extend this classifier to investigate an emerging target and the effects of limited training data on system performance.","2332-5615","978-1-5386-9306-3","10.1109/AIPR.2018.8707419","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8707419","ATR;target recognition;artificial intelligence;AI;deep learning;CNN;neural networks;machine learning;image understanding;recognition;classification;synthetic aperture radar","Training;Synthetic aperture radar;Classification algorithms;Data models;Target recognition;Imaging;Image resolution","learning (artificial intelligence);military computing;military radar;military vehicles;object detection;radar imaging;radar target recognition;synthetic aperture radar","SAR target recognition;deep learning;remote sensing;military vehicles;intelligence industry;synthetic aperture radar;DL classification;multispectral satellite imagery;MSTAR program;SAR collections;aerial X-band radar;all-weather imaging;automatic target recognition;recognition dataset;automated classification;IARPA functional map;ResNet-18","","4","","15","IEEE","9 May 2019","","","IEEE","IEEE Conferences"
"Bioinspired Micro-Optics and Applications to Imaging Polarimetry","S. Pau",University of Arizona,"2018 IEEE Research and Applications of Photonics In Defense Conference (RAPID)","25 Oct 2018","2018","","","1","1","Study of structural colors has led to optical filter designs using liquid crystal polymer that has microscopic structure similar to exoskeleton of many animals. The optical filters are utilized in novel multi-spectral and polarization cameras with applications in medical imaging, remote sensing, surveillance, and metrology.","","978-1-5386-5349-4","10.1109/RAPID.2018.8508999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8508999","","Microscopy","bio-inspired materials;cameras;liquid crystal polymers;micro-optics;optical filters;polarimetry","bioinspired microoptics;imaging polarimetry;structural colors;optical filter designs;liquid crystal polymer;metrology;surveillance;remote sensing;medical imaging;polarization cameras;microscopic structure","","","","0","IEEE","25 Oct 2018","","","IEEE","IEEE Conferences"
"Method of Multispectral Image Denoising Based on Whole and Sub-Sparsity","W. Zeng; X. Zhang","School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China","IEEE Access","6 May 2021","2021","9","","65967","65976","Multi-Spectral Image(MSI) denoising is an important preprocessing procedure to improve the performance of high-level processing. Tensor-based approach is one of the most popular methods for MSI denoising, since MSIs can be seen as multi-dimension arrays containing both spatial and spectral information. There are two main information in MSI, Global Correlation along Spectrum(GCS) and Nonlocal Self Similarity across space(NSS). Most tensor based approaches exploited these two characteristics by low-rank regularizations, mainly based on CANDERCOMP/PARAFAC(CP) decomposition and Tucker decomposition. However, they did not show a clear physical meaning. In this paper, we exploit the fact that pixels in MSI often cover several different materials and so that tensor data is mixed. Based on this, we divide tensor into several sub-tensors and propose a novel low rank regularization called Whole and Sub-Sparsity(WSS): GCS is modeled in the sub-tensors and NSS is modeled in the original tensor, which shows a clear physical meaning. Besides, to solve our model, we develop the corresponding algorithm by employing alternating direction method of multipliers(ADMM) framework. Experiment results show that our method is competitive compared to all state of the art MSI denoising methods.","2169-3536","","10.1109/ACCESS.2021.3076786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9420100","Sparsity measurement;tensor;alternating direction method of multipliers (ADMM);multi-spectral images (MSI)","Tensors;Correlation;Matrix decomposition;Noise reduction;Noise measurement;Nuclear measurements","computer vision;convex programming;higher order statistics;image denoising;image representation;tensors","multispectral Image denoising;preprocessing procedure;high-level processing;tensor-based approach;multidimension arrays;spatial information;spectral information;main information;global correlation;nonlocal self similarity;low-rank regularizations;clear physical meaning;tensor data;subtensors;novel low rank regularization;original tensor;alternating direction method of multipliers framework;MSI denoising;ADMM;CANDERCOMP-PARAFAC;whole and subsparsity;WSS;GCS;NSS","","","","47","CCBY","30 Apr 2021","","","IEEE","IEEE Journals"
"Deep Gradient Projection Networks for Pan-sharpening","S. Xu; J. Zhang; Z. Zhao; K. Sun; J. Liu; C. Zhang","School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","1366","1375","Pan-sharpening is an important technique for remote sensing imaging systems to obtain high resolution multi-spectral images. Recently, deep learning has become the most popular tool for pan-sharpening. This paper develops a model-based deep pan-sharpening approach. Specifically, two optimization problems regularized by the deep prior are formulated, and they are separately responsible for the generative models for panchromatic images and low resolution multispectral images. Then, the two problems are solved by a gradient projection algorithm, and the iterative steps are generalized into two network blocks. By alternatively stacking the two blocks, a novel network, called gradient projection based pan-sharpening neural network, is constructed. The experimental results on different kinds of satellite datasets demonstrate that the new network out-performs state-of-the-art methods both visually and quantitatively. The codes are available at https://github.com/xsxjtu/GPPNN.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.00142","Research and Development; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9578619","","Image resolution;Satellites;Stacking;Neural networks;Tools;Iterative algorithms;Pattern recognition","correlation methods;filtering theory;geophysical image processing;gradient methods;image enhancement;image fusion;image resolution;learning (artificial intelligence);remote sensing","deep learning;model-based deep pan-sharpening approach;panchromatic images;low resolution multispectral images;gradient projection algorithm;network blocks;called gradient projection;pan-sharpening neural network;network out-performs state-of-the-art methods;gradient projection networks;high resolution multispectral images","","39","","41","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Multiple-Scattering Microphysics Tomography","A. Levis; Y. Y. Schechner; A. B. Davis","Viterbi Faculty of Electrical Engineering, Technion - Israel Institute of Technology, Haifa, Israel; Viterbi Faculty of Electrical Engineering, Technion - Israel Institute of Technology, Haifa, Israel; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA","2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","9 Nov 2017","2017","","","5797","5806","Scattering effects in images, including those related to haze, fog and appearance of clouds, are fundamentally dictated by microphysical characteristics of the scatterers. This work defines and derives recovery of these characteristics, in a three-dimensional (3D) heterogeneous medium. Recovery is based on a novel tomography approach. Multi-view (multi-angular) and multi-spectral data are linked to the underlying microphysics using 3D radiative transfer, accounting for multiple-scattering. Despite the nonlinearity of the tomography model, inversion is enabled using a few approximations that we describe. As a case study, we focus on passive remote sensing of the atmosphere, where scatterer retrieval can benefit modeling and forecasting of weather, climate and pollution.","1063-6919","978-1-5386-0457-1","10.1109/CVPR.2017.614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8100097","","Scattering;Three-dimensional displays;Atmospheric modeling;Tomography;Computational modeling;Mathematical model;Clouds","atmospheric optics;clouds;fog;geophysical image processing;radiative transfer;remote sensing;tomography","multiple-scattering microphysics;haze;clouds;scatterer microphysical characteristics;scatterer retrieval;tomography model;3D radiative transfer;underlying microphysics;multispectral data;multiview;novel tomography approach;three-dimensional heterogeneous medium;fog;scattering effects","","21","","51","IEEE","9 Nov 2017","","","IEEE","IEEE Conferences"
"Residual HSRCNN: Residual Hyper-Spectral Reconstruction CNN from an RGB Image","X. -H. Han; B. Shi; Y. Zheng","Graduate School of Science and Technology for Innovation, Yamaguchi University, Japan; Institute of Digital Media, Peking University, China; Digital Content and Media Sciences Research Division, National Institute of Informatics, Japan","2018 24th International Conference on Pattern Recognition (ICPR)","29 Nov 2018","2018","","","2664","2669","Hyper-spectral imaging has great potential for understanding the characteristics of different materials in many applications ranging from remote sensing to medical imaging. However, due to various hardware limitations, only low-resolution hyper-spectral and high-resolution multi-spectral or RGB images can be captured at video rate. This study aims to generate a hyper-spectral image via enhancing spectral resolution of an RGB image, which might be easily obtained by a commodity camera. Motivated by the success of deep convolutional neural network (DCNN) for spatial resolution enhancement of natural images, we explore a spectral reconstruction CNN for spectral super-resolution with an available RGB image, which predicts the high-frequency content of the fine spectral wavelength in narrow band interval. Since the lost high-frequency content can not be perfectly recovered, by leveraging on the baseline CNN, we further propose a novel residual hyper-spectral reconstruction CNN framework to estimate the non-recovered high-frequency content (Residual) from the output of the baseline CNN. Experiments on benchmark hyper-spectral datasets validate that the proposed method achieves promising performances compared with the existing state-of-the-art methods.","1051-4651","978-1-5386-3788-3","10.1109/ICPR.2018.8545634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8545634","","Spatial resolution;Image reconstruction;Signal resolution;Computer architecture;Cameras;Visualization","cameras;convolution;feedforward neural nets;geophysical image processing;image colour analysis;image reconstruction;image resolution;remote sensing;spectral analysis","nonrecovered high-frequency content;DCNN;deep convolutional neural network;commodity camera;low-resolution hyper-spectral images;residual HSRCNN;residual hyper-spectral reconstruction CNN framework;spectral wavelength;RGB image;spectral resolution enhancement;high-resolution multispectral images;natural images;spatial resolution enhancement;medical imaging;hyper-spectral imaging;benchmark hyper-spectral datasets;baseline CNN","","9","","41","IEEE","29 Nov 2018","","","IEEE","IEEE Conferences"
"The PAN and MS Image Pansharpening Algorithm Based on Adaptive Neural Network and Sparse Representation in the NSST Domain","X. Wang; S. Bai; Z. Li; R. Song; J. Tao","College of Computer and Information Technology, Liaoning Normal University, Dalian, China; College of Computer and Information Technology, Liaoning Normal University, Dalian, China; Dalian Hausen Software Co. Ltd., Dalian, China; School of Urban and Environmental Sciences, Liaoning Normal University, Dalian, China; School of Urban and Environmental Sciences, Liaoning Normal University, Dalian, China","IEEE Access","26 Apr 2019","2019","7","","52508","52521","How to improve the spatial resolution as much as possible while maintaining the spectral information of multi-spectral (MS) image in the field of image fusion is of great significance for practical applications, such as map updating, feature classification, and target recognition. To analyze the coefficients of the subband distribution characteristics, in this paper, we propose a new panchromatic (PAN) and MS image pansharpening model based on an adaptive neural network and sparse representation in the non-subsample shearlet transform (NSST) domain. First, this algorithm is specific to regional directional characteristics in the high-frequency subband of PAN and MS images, and we propose an adaptive pulse coupled neural network (PCNN) model. The model can adaptively calculate the link strength of a neural cell based on the region energy. Furthermore, we apply the model to the high-frequency fusing process with the corresponding fusion rule, and the rule can distinguish the high-frequency coefficients by ignition times, which can more effectively capture the geometric texture information and detailed information in the PAN image, enhancing the spatial resolution of the fused image. Second, because of the low-frequency sub-bands from the PAN image and I component obtained by intensity-hue-saturation (IHS) transformation of the MS images with high similarity to the original image but poor sparsity, we select a set of PAN images for learning, a more targeted over-complete dictionary for low-frequency sub-band sparse representation is obtained. Then, the larger absolute value of the sparse matrix is selected to obtain the low-frequency coefficients for the fusion image while maintaining the MS spectral information effectively, and the representation of characteristic information of low-frequency subband is more effective. A large number of simulation experiments verify the effectiveness of the proposed method.","2169-3536","","10.1109/ACCESS.2019.2910656","National Natural Science Foundation of China(grant numbers:41671439); Innovation Team Support Program of Liaoning Higher Education Department(grant numbers:LT2017013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693681","Image;MS image;image fusion;NSST;neuron connection intensity;sparse representation","Transforms;Spatial resolution;Image fusion;Remote sensing;Adaptive systems;High frequency;Signal processing algorithms","geophysical image processing;image denoising;image fusion;image representation;image resolution;image texture;neural nets;sparse matrices;wavelet transforms","MS spectral information;characteristic information;low-frequency subband;adaptive neural network;NSST domain;spatial resolution;multispectral image;image fusion;subband distribution characteristics;regional directional characteristics;high-frequency subband;MS images;adaptive pulse;neural network model;neural cell;high-frequency fusing process;corresponding fusion rule;high-frequency coefficients;PAN image;fused image;original image;low-frequency coefficients;low-frequency subbands;low-frequency subband sparse representation","","20","","41","OAPA","17 Apr 2019","","","IEEE","IEEE Journals"
"Growth Monitoring of Weak Gluten Wheat Using Visible and Multispectral UAV Imagery","S. Du; X. Liu; D. Zhang; X. Zhang; L. Huang; X. Zhao; L. Xu; Y. Xu","Academy of Agricultural Sciences, Institute of Crops. Anhui, Hefei, China; Anhui Engineering Laboratory of Agro-Ecological Big Data, Anhui University, Hefei, China; Anhui Engineering Laboratory of Agro-Ecological Big Data, Anhui University, Hefei, China; Academy of Agricultural Sciences, Institute of Crops. Anhui, Hefei, China; Anhui Engineering Laboratory of Agro-Ecological Big Data, Anhui University, Hefei, China; Anhui Engineering Laboratory of Agro-Ecological Big Data, Anhui University, Hefei, China; Anhui Engineering Laboratory of Agro-Ecological Big Data, Anhui University, Hefei, China; Anhui Engineering Laboratory of Agro-Ecological Big Data, Anhui University, Hefei, China","2018 7th International Conference on Agro-geoinformatics (Agro-geoinformatics)","30 Sep 2018","2018","","","1","6","The quality of weak-gluten wheat is easily affected by management methods of field cultivation. U nmanned aerial vehicle (UAV) remote sensing technology can provide technical support for the optimization of cultivation management plan by dynamically monitoring the growth of wheat canopy. In this study, the digital and multispectral cameras mounted on UAV were used to capture canopy images of wheat during key growth stages. The visible and multispectral vegetation indexes of 10 kind of wheat varieties were calculated. The correlation between 13 vegetation indexes and ground-measured chlorophyll content SPAD was analyzed. The results showed that the vegetation index can effectively monitor the change of wheat growth. Among these vegetation indexes, the correlation between the visible light Excess Green index (ExG) and SPAD value is the highest, the determination coefficient R2 is 0.659. The multi-spectral normalized difference vegetation index (NDVI) has the best correlation with SPAD value, the R2 is 0.692. To choose the more suitable sensor for effective assessing the change of wheat growth, the ExG-SPAD and NDVI-SPAD inversion models were established based on the optimal vegetation indexes of these two sensors in midterm and late growth stage. The results shown that the R2 and RMSE of SPAD inversion model at the midterm growth stage were superior than those of late developmental period. Moreover, NDVI-SPAD model obtained more accurate result at midterm growth stage, the R2 and the root mean square error (RMSE) are 0.717 and 1.878, respectively. In summary, the results of this study can provide important technical support for the production plan of weak-gluten wheat in the middle and lower reaches of the Yangtze River. It also helps to promote the further application of remote sensing technology in wheat breeding and cultivation management.","","978-1-5386-5038-7","10.1109/Agro-Geoinformatics.2018.8476080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476080","UAV;Vegetation index;SPAD;Weak gluten wheat","","autonomous aerial vehicles;vegetation mapping","ground-measured chlorophyll content SPAD;visible light Excess Green index;vegetation indexes;Yangtze River;wheat varieties;multispectral vegetation indexes;visible vegetation indexes;key growth stages;multispectral cameras;digital cameras;wheat canopy;cultivation management plan;aerial vehicle remote sensing technology;multispectral UAV imagery;visible UAV imagery;weak Gluten wheat;growth monitoring;wheat breeding;weak-gluten wheat;midterm growth stage;SPAD inversion model;late growth stage;optimal vegetation indexes;NDVI-SPAD inversion models;ExG-SPAD;wheat growth;multispectral normalized difference vegetation index;SPAD value","","","","27","IEEE","30 Sep 2018","","","IEEE","IEEE Conferences"
"Spectral-spatial information extraction and classification of mangrove species using joint sparse representation","Jie Geng; Jianchao Fan; Xiu Su; Xiaorui Ma; Hongyu Wang","School of Information and Communication Engineering, Dalian University of Technology, Dalian, P.R. China; National Marine Environmental Monitoring Center, Dalian, P.R. China; National Marine Environmental Monitoring Center, Dalian, P.R. China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, P.R. China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, P.R. China","2015 4th International Conference on Computer Science and Network Technology (ICCSNT)","16 Jun 2016","2015","01","","1311","1315","Classification of mangrove species is very important for monitoring and protecting the coastal ecosystem. In this paper, we present a new spectral-spatial classifier that uses multi-spectral image captured by the ZY-3 satellite to distinguish seven mangrove species in the Beihai ecological monitoring area, Guangxi, China. In order to extract the spatial information, a correlative filter is designed to incorporate neighborhood correlative information before classification. Moreover, a feature optimization algorithm based on dictionary learning is applied to reduce the noise and improve the discrimination of sample features. Finally, a classification method using joint sparse representation is proposed to extract the mangrove region and recognize seven mangrove species. The classification results show that the major species in the study area are Aegiceras corniculatum and Avicenna marina that conform to field investigations. The overall accuracy reaches 95.62% and the kappa coefficient achieves the value of 0.9380. Hence, the accuracy and efficiency of our proposed method are demonstrated in mangrove species classification.","","978-1-4673-8173-4","10.1109/ICCSNT.2015.7490971","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490971","spectral-spatial classification;multispectral image;mangrove species classification;joint sparse representation","Dictionaries;Feature extraction;Matching pursuit algorithms;Training;Atmospheric modeling;Optimization;Remote sensing","ecology;geophysical image processing;image classification;image denoising;image filtering;image representation;information retrieval;vegetation;vegetation mapping","spectral-spatial information extraction;spectral-spatial classifier;multispectral image;ZY-3 satellite;Beihai ecological monitoring area;Guangxi;China;correlative filter;neighborhood correlative information;feature optimization algorithm;dictionary learning;noise reduction;joint sparse representation;mangrove species recognition;Aegiceras corniculatum;Avicenna marina;kappa coefficient;mangrove species classification","","","","13","IEEE","16 Jun 2016","","","IEEE","IEEE Conferences"
"A Variational Pan-Sharpening With Local Gradient Constraints","X. Fu; Z. Lin; Y. Huang; X. Ding","School of Information Science and Technology, University of Science and Technology of China, China; Fujian Key Laboratory of Sensing and Computing for Smart City, Xiamen University, China; Fujian Key Laboratory of Sensing and Computing for Smart City, Xiamen University, China; Fujian Key Laboratory of Sensing and Computing for Smart City, Xiamen University, China","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","10257","10266","Pan-sharpening aims at fusing spectral and spatial information, which are respectively contained in the multispectral (MS) image and panchromatic (PAN) image, to produce a high resolution multi-spectral (HRMS) image. In this paper, a new variational model based on a local gradient constraint for pan-sharpening is proposed. Different with previous methods that only use global constraints to preserve spatial information, we first consider gradient difference of PAN and HRMS images in different local patches and bands. Then a more accurate spatial preservation based on local gradient constraints is incorporated into the objective to fully utilize spatial information contained in the PAN image. The objective is formulated as a convex optimization problem which minimizes two leastsquares terms and thus very simple and easy to implement. A fast algorithm is also designed to improve efficiency. Experiments show that our method outperforms previous variational algorithms and achieves better generalization than recent deep learning methods.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.01051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953524","Low-level Vision","","geophysical image processing;image fusion;image resolution;learning (artificial intelligence);optimisation;remote sensing;variational techniques","variational pan-sharpening;local gradient constraint;pan-sharpening aims;spatial information;multispectral image;panchromatic image;high resolution multispectral image;variational model;use global constraints;gradient difference;different local patches;accurate spatial preservation;PAN image;variational algorithms;HRMS image;convex optimization problem;least squares terms","","61","","33","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"An Efficient Pansharpening Method Based On Conditional Random Fields","Y. Yang; H. Lu; S. Huang; W. Tu","School of Information Technology, Jiangxi University of Finance and Economics, Nanchang, China; School of Information Technology, Jiangxi University of Finance and Economics, Nanchang, China; School of Software and Internet of Things Engineering, Jiangxi University of Finance and Economics, Nanchang, China; School of Information Technology, Jiangxi University of Finance and Economics, Nanchang, China","2020 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2020","2020","","","1","6","Pansharpening is to fuse the existing low spatial resolution multi-spectral (MS) image with high spatial resolution panchromatic (PAN) image, so as to obtain high spatial resolution MS (HRMS) image. An efficient pansharpening model based on conditional random fields (CRFs) is proposed in this paper. In the model, a state feature function is designed to force the blurred HRMS image in accordance with the upsampled MS (UPMS) image to keep the spectral fidelity. Meanwhile, a transition feature function is defined to keep the sharpness of fused image. Besides, a new Gaussian filter acquisition algorithm is proposed to effectively satisfy the blur function in the model. To improve the efficiency of algorithm, a new initialization method based on fitting normal distribution is presented. Experiments are conducted on both reduced-scale images and full-scale images. Compared with some classical and state-of-art pansharpening methods, the proposed method achieves the best results in terms of fusion quality and efficiency.","1945-788X","978-1-7281-1331-9","10.1109/ICME46284.2020.9102885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102885","pansharpening;CRFs;filter acquisition;feature function","Fuses;Computational modeling;Pansharpening;Transforms;Filtering algorithms;Gaussian distribution;Spatial resolution","filtering theory;geophysical image processing;image enhancement;image fusion;image resolution;remote sensing;wavelet transforms","conditional random fields;existing low spatial resolution multispectral;high spatial resolution panchromatic image;high spatial resolution MS image;efficient pansharpening model;state feature function;blurred HRMS image;upsampled MS image;spectral fidelity;transition feature function;fused image;Gaussian filter acquisition algorithm;blur function;initialization method;reduced-scale images;full-scale images;classical state-of-art pansharpening methods;fusion quality","","2","","24","IEEE","9 Jun 2020","","","IEEE","IEEE Conferences"
"Online Multi-resolution Fusion of Space-borne Multispectral Images","H. Li; B. Duvvuri; R. Borsoi; T. Imbiriba; E. Beighley; D. Erdoğmuş; P. Closas","Department of ECE, Northeastern University, Boston, MA; Department of CEE, Northeastern University, Boston, MA; Department of EE, Federal University of Santa Catarina, Florianópolis, SC, Brazil; Department of ECE, Northeastern University, Boston, MA; Department of CEE, Northeastern University, Boston, MA; Department of ECE, Northeastern University, Boston, MA; Department of ECE, Northeastern University, Boston, MA","2022 IEEE Aerospace Conference (AERO)","10 Aug 2022","2022","","","1","12","Satellite imaging has a central role in monitoring, detecting and estimating the intensity of key natural phenomena. One important feature of satellite images is the trade-off between spatial/spectral resolution and their revisiting time, a consequence of design and physical constraints imposed by satellite orbit among other technical limitations. In this paper, we focus on fusing multi-temporal, multi-spectral images where data acquired from different instruments with different spatial resolutions is used. We leverage the spatial relationship between images at multiple modalities to generate high-resolution image sequences at higher revisiting rates. To achieve this goal, we formulate the fusion method as a recursive state estimation problem and study its performance in filtering and smoothing contexts. The proposed strategy clearly outperforms competing methodologies, which is shown in the paper for real data acquired by the Landsat and MODIS instruments.","1095-323X","978-1-6654-3760-8","10.1109/AERO53065.2022.9843578","National Geographic(grant numbers:NGS-86713T-21); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9843578","","Satellites;Smoothing methods;Instruments;Orbits;Spatial resolution;State estimation;Image fusion","geophysical image processing;geophysical techniques;image fusion;image resolution;image sequences;remote sensing;sensor fusion;state estimation;terrain mapping;vegetation mapping","online multiresolution fusion;space-borne multispectral images;satellite imaging;key natural phenomena;satellite images;revisiting time;physical constraints;satellite orbit;fusing multitemporal;different instruments;spatial relationship;high-resolution image sequences;higher revisiting rates;fusion method;recursive state estimation problem","","","","42","IEEE","10 Aug 2022","","","IEEE","IEEE Conferences"
"Mutual Information-driven Pan-sharpening","M. Zhou; K. Yan; J. Huang; Z. Yang; X. Fu; F. Zhao","University of Science and Technology of China, China; University of Science and Technology of China, China; University of Science and Technology of China, China; University of Science and Technology of China, China; University of Science and Technology of China, China; University of Science and Technology of China, China","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","1788","1798","Pan-sharpening aims to integrate the complementary information of texture-rich PAN images and multi-spectral (MS) images to produce the texture-rich MS images. Despite the remarkable progress, existing state-of-the-art Pansharpening methods don't explicitly enforce the complementary information learning between two modalities of PAN and MS images. This leads to information redundancy not being handled well, which further limits the performance of these methods. To address the above issue, we propose a novel mutual information-driven Pan-sharpening framework in this paper. To be specific, we first project the PAN and MS image into modality-aware feature space independently, and then impose the mutual information minimization over them to explicitly encourage the complementary information learning. Such operation is capable of reducing the information redundancy and improving the model performance. Extensive experimental results over multiple satellite datasets demonstrate that the proposed algorithm outperforms other state-of-the-art methods qualitatively and quantitatively with great generalization ability to real-world scenes.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.00184","National Natural Science Foundation of China (NSFC)(grant numbers:61901433); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879770","Photogrammetry and remote sensing","Computer vision;Satellites;Redundancy;Pansharpening;Minimization;Pattern recognition;Mutual information","correlation methods;filtering theory;geophysical image processing;image enhancement;image fusion;image resolution;learning (artificial intelligence);minimisation","Pan-sharpening aims;texture-rich PAN images;multispectral images;texture-rich MS images;state-of-the-art Pansharpening methods;complementary information learning;information redundancy;novel mutual information-driven Pan-sharpening framework;modality-aware feature space;mutual information minimization","","3","","58","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Deep CNN Prior Based Image Reconstruction for Multispectral Imaging","İ. Manisalı; R. M. Çam; C. D. Bezek; F. S. Oktem","Elektrik ve Elektronik Mühendisliği Bölümü, Orta Doğu Teknik Üniversitesi (ODTÜ), Ankara, Türkiye; Elektrik ve Elektronik Mühendisliği Bölümü, Orta Doğu Teknik Üniversitesi (ODTÜ), Ankara, Türkiye; Elektrik ve Elektronik Mühendisliği Bölümü, Orta Doğu Teknik Üniversitesi (ODTÜ), Ankara, Türkiye; Elektrik ve Elektronik Mühendisliği Bölümü, Orta Doğu Teknik Üniversitesi (ODTÜ), Ankara, Türkiye","2020 28th Signal Processing and Communications Applications Conference (SIU)","7 Jan 2021","2020","","","1","4","Spectral imaging is a widely used diagnostic technique in various fields such as physics, chemistry, biology, medicine, astronomy, and remote sensing. In this work, we focus on a multi-spectral imaging technique with a diffractive lens, which relies on computational imaging, and we develop a novel image reconstruction method that exploits convolutional neural networks. To reconstruct the spectral images from the measurements of the imaging system, the inverse problem is first formulated as a proper optimization problem with regularization. This optimization problem is then divided to subproblems by using the alternating direction method of multipliers, and the subproblem corresponding to a denoising problem is solved with a learning-based convolutional denoising neural network instead of an analytical method. The obtained results illustrate that the proposed method can achieve promising reconstruction performance.","2165-0608","978-1-7281-7206-4","10.1109/SIU49456.2020.9302259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302259","convolutional neural networks;spectral imaging;inverse problems;image reconstruction","Imaging;Lenses;Image reconstruction;TV;Optimization;Noise reduction;Neural networks","convolutional neural nets;image denoising;image reconstruction;inverse problems;learning (artificial intelligence);optimisation","deep CNN prior based image reconstruction;multispectral imaging technique;computational imaging;image reconstruction method;convolutional neural networks;spectral images;imaging system;inverse problem;learning-based convolutional denoising neural network;alternating direction method of multipliers","","","","","IEEE","7 Jan 2021","","","IEEE","IEEE Conferences"
"A Patch-Image Based Classification Approach for Detection of Weeds in Sugar Beet Crop","S. I. Moazzam; U. S. Khan; W. S. Qureshi; M. I. Tiwana; N. Rashid; W. S. Alasmary; J. Iqbal; A. Hamza","Robot Design and Development Laboratory, National Centre of Robotics and Automation (NCRA), National University of Sciences and Technology, Islamabad, Pakistan; Robot Design and Development Laboratory, National Centre of Robotics and Automation (NCRA), National University of Sciences and Technology, Islamabad, Pakistan; Robot Design and Development Laboratory, National Centre of Robotics and Automation (NCRA), National University of Sciences and Technology, Islamabad, Pakistan; Robot Design and Development Laboratory, National Centre of Robotics and Automation (NCRA), National University of Sciences and Technology, Islamabad, Pakistan; Robot Design and Development Laboratory, National Centre of Robotics and Automation (NCRA), National University of Sciences and Technology, Islamabad, Pakistan; Department of Computer Science, Umm Al Qura University, Makkah, Saudi Arabia; Robot Design and Development Laboratory, National Centre of Robotics and Automation (NCRA), National University of Sciences and Technology, Islamabad, Pakistan; Robot Design and Development Laboratory, National Centre of Robotics and Automation (NCRA), National University of Sciences and Technology, Islamabad, Pakistan","IEEE Access","9 Sep 2021","2021","9","","121698","121715","Weeds affects crops health as it shares water and nutrients from the soil, as a result it decreases crop yield. Manual weedicide spray through bag-pack is hazardous to human health. Localized autonomous weedicide spray through aerial spraying units can help save water, weedicide chemical and effect less on human health. Such systems require multi-spectral cues to classify crop, weed, and soil surface. Our focus in this paper is on the detection of weeds in the sugar beet crop, using air-borne multispectral camera sensors, which is considered as an alternative crop to sugarcane to obtain sugar in Pakistan. We developed a new framework for weed identification; a patch-based classification approach as appose to semantic segmentation that is more realistic for real-time intelligent aerial spraying systems. Our approach converts 3-class pixel classification problem into a 2-class crop-weed patch classification problem which in turns improves crop and weed classification accuracy. For classification, we developed a new VGG-Beet convolutional neural network (CNN), which is based on generic VGG16 (visual graphics group) CNN model with 11 convolutional layers. For experiments, we captured a sugar beet dataset with 3-channel multispectral sensor with a ground sampling distance (GSD) of 0.2 cm/pixel and a height of 4 meters. For better comparison, we used two publicly available sugar beet crop aerial imagery datasets, captured using a 5-channel multispectral sensor and a 4-Channel multispectral sensor with a ground sampling distance of 1cm and a height of 10 meters. We observed that patch-based method is more robust to different lighting conditions. To produce low cost weed detection system usage of Agrocam sensor is recommended, for higher accuracy Red Edge and Sequoia multispectral sensors with more channels should be deployed. We observed higher crop-weed accuracy and lower testing time for our patch-based approach as compared to U-Net and Deeplab based semantic segmentation networks.","2169-3536","","10.1109/ACCESS.2021.3109015","Robot Design and Development Laboratory through the National Centre of Robotics and Automation(grant numbers:PSDP–261,DF 1009-0031); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9525394","Autonomous weed detection;drone weed detection;deep learning in agriculture;multispectral image processing","Agriculture;Sugar industry;Semantics;Drones;Spraying;Sensors;Convolutional codes","agrochemicals;cameras;crops;geophysics computing;image classification;image resolution;image segmentation;neural nets;soil","patch-image;crops health;crop yield;manual weedicide spray;human health;localized autonomous weedicide spray;aerial spraying units;weedicide chemical;soil surface;air-borne multispectral camera sensors;weed identification;patch-based classification approach;real-time intelligent aerial spraying systems;3-class pixel classification problem;2-class crop-weed patch classification problem;classification accuracy;VGG-Beet convolutional neural network;sugar beet dataset;3-channel multispectral sensor;ground sampling distance;publicly available sugar beet crop aerial imagery datasets;5-channel multispectral sensor;4-Channel multispectral sensor;patch-based method;low cost weed detection system usage;higher crop-weed accuracy;patch-based approach","","5","","21","CCBYNCND","30 Aug 2021","","","IEEE","IEEE Journals"
