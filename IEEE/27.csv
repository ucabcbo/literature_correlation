"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Generation of Lidar-Predicted Forest Biomass Maps from Radar Backscatter with Conditional Generative Adversarial Networks","S. Björk; S. N. Anfinsen; E. Næsset; T. Gobakken; E. Zahabu","Department of Physics and Technology, UiT The Arctic University of Norway, Tromsø, Norway; Department of Physics and Technology, UiT The Arctic University of Norway, Tromsø, Norway; Faculty of Environmental Sciences and Natural Resource Management, Norwegian University of Life Sciences, Ås, Norway; Faculty of Environmental Sciences and Natural Resource Management, Norwegian University of Life Sciences, Ås, Norway; Department of Forest Resources Assessment and Management, Sokoine University of Agriculture, Morogoro, Tanzania","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","4327","4330","This paper studies the generation of LiDAR-predicted aboveground biomass (AGB) maps from synthetic aperture radar (SAR) intensity images by use of conditional generative adversarial networks (cGANs). The purpose is to improve on traditional regression models based on SAR intensity, which are trained with a limited amount of AGB in situ measurements. Although they are costly to collect, data from airborne laser scanning (ALS) sensors are highly correlated with AGB and can replace in situ measurements as the regression target. Thus, the amount of training data increases dramatically, and we can learn an expressive two-stage regression model for SAR backscatter intensity. We propose to model the regression function between SAR intensity and ALS-predicted AGB with a Pix2Pix convolutional neural network for image translation that uses a ResNet-5-based cGAN architecture with the Wasserstein GAN gradient penalty (WGAN-GP) objective function. The synthesized ALS-predicted AGB maps are evaluated qualitatively and quantitatively against real ALS-predicted AGB maps. Our results show that the proposed architecture manages to capture characteristics of the real data, which suggests further use of the ResNet-5 for a SAR intensity regression model of AGB.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324296","Tanzania Forest Services (TFS) Agency; Norwegian University of Life Sciences; Swedish University of Agricultural Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324296","","Gallium nitride;Training;Synthetic aperture radar;Linear programming;Generative adversarial networks;Laser radar;Forestry","forestry;neural nets;optical radar;regression analysis;remote sensing by laser beam;remote sensing by radar;synthetic aperture radar;vegetation mapping","synthesized ALS-predicted AGB maps;SAR intensity regression model;lidar-predicted forest biomass maps;radar backscatter;conditional generative adversarial networks;LiDAR-predicted aboveground biomass maps;synthetic aperture radar intensity images;traditional regression models;airborne laser scanning sensors;regression target;two-stage regression model;SAR backscatter intensity;regression function;Pix2Pix convolutional neural network;image translation;ResNet-5-based;Wasserstein GAN gradient penalty objective function","","2","","10","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Simpler is Better: Spectral Regularization and Up-Sampling Techniques for Variational Autoencoders","S. Björk; J. N. Myhre; T. Haugland Johansen",UiT The Arctic University of Norway; UiT The Arctic University of Norway; UiT The Arctic University of Norway,"ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","3778","3782","Full characterization of the spectral behavior of generative models based on neural networks remains an open issue. Recent research has focused heavily on generative adversarial networks and the high-frequency discrepancies between real and generated images. The current solution to avoid this is to either replace transposed convolutions with bilinear up-sampling or add a spectral regularization term in the generator. We propose a 2D Fourier transform-based spectral regularization loss and evaluate it on the variational autoencoder. We show that it can achieve results equal to, or better than, the current state-of-the-art in frequency-aware losses for generative models. In addition, we experiment with altering the up-sampling procedure in the generator network and investigate how it influences the spectral performance of the model. We include experiments on synthetic and real data sets to demonstrate our results.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746027","","Convolution;Conferences;Neural networks;Generative adversarial networks;Generators;Acoustics;Speech processing","convolutional neural nets;Fourier transforms;image sampling","variational autoencoder;spectral behavior;neural networks;generative adversarial networks;transposed convolutions;bilinear up-sampling;spectral regularization loss;frequency-aware losses;generated image;real image;2D Fourier transform","","","","38","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"DeepSynthBody: the beginning of the end for data deficiency in medicine","V. Thambawita; S. A. Hicks; J. Isaksen; M. H. Stensen; T. B. Haugen; J. Kanters; S. Parasa; T. de Lange; H. D. Johansen; D. Johansen; H. L. Hammer; P. Halvorsen; M. A. Riegler","Oslo Metropolitan University, Norway; Oslo Metropolitan University, Norway; University of Copenhagen, Denmark; Fertilitetssenteret, Norway; Oslo Metropolitan University, Norway; University of Copenhagen, Denmark; Swedish Medical Center, USA; Sahlgrenska University Hospital-Mölndal Hospital, Sweden; UIT The Arctic University of Norway; UIT The Arctic University of Norway; SimulaMet, Norway; Oslo Metropolitan University, Norway; SimulaMet, Norway","2021 International Conference on Applied Artificial Intelligence (ICAPAI)","29 Jun 2021","2021","","","1","8","Limited access to medical data is a barrier on developing new and efficient machine learning solutions in medicine such as computer-aided diagnosis, risk assessments, predicting optimal treatments and home-based personal healthcare systems. This paper presents DeepSynthBody: a novel framework that overcomes some of the inherent restrictions and limitations of medical data by using deep generative adversarial networks to produce synthetic data with characteristics similar to the real data, so-called DeepSynth (deep synthetic) data. We show that DeepSynthBody can address two key issues commonly associated with medical data, namely privacy concerns (as a result of data protection rules and regulations) and the high costs of annotations. To demonstrate the full pipeline of applying DeepSynthBody concepts and user-friendly functionalities, we also describe a synthetic medical dataset generated and published using our framework. DeepSynthBody opens a new era of machine learning applications in medicine with a synthetic model of the human body.","","978-1-7281-5934-8","10.1109/ICAPAI49758.2021.9462062","Research Council of Norway(grant numbers:270053); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9462062","DeepSynthBody;synthetic medical data;deep synthetic human body;synthetic data;GAN;DeepSynth augmentation;privacy issue;medical data privacy;multi-model DeepSynth;DeepSynth explainable AI;explainable DeepSynth","Biological system modeling;Pipelines;Data protection;Machine learning;Medical services;Generative adversarial networks;Regulation","data privacy;health care;learning (artificial intelligence);medical information systems;patient monitoring;telemedicine","machine learning applications;user-friendly functionalities;DeepSynth data;DeepSynthBody concepts;synthetic medical dataset;data protection rules;deep synthetic;deep generative adversarial networks;home-based personal healthcare systems;optimal treatments;computer-aided diagnosis;medicine;data deficiency","","3","","62","IEEE","29 Jun 2021","","","IEEE","IEEE Conferences"
"Airborne Snow Radar Data Simulation With Deep Learning and Physics-Driven Methods","M. Yari; O. Ibikunle; D. Varshney; T. Chowdhury; A. Sarkar; J. Paden; J. Li; M. Rahnemoonfar","Computer Vision and Remote Sensing Laboratory (Bina Lab), University of Maryland, Baltimore County, MD, USA; University of Kansas, Lawrence, KS, USA; Computer Vision and Remote Sensing Laboratory (Bina Lab), University of Maryland, Baltimore County, MD, USA; Computer Vision and Remote Sensing Laboratory (Bina Lab), University of Maryland, Baltimore County, MD, USA; Computer Vision and Remote Sensing Laboratory (Bina Lab), University of Maryland, Baltimore County, MD, USA; University of Kansas, Lawrence, KS, USA; University of Kansas, Lawrence, KS, USA; Computer Vision and Remote Sensing Laboratory (Bina Lab), University of Maryland, Baltimore County, MD, USA","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","7 Dec 2021","2021","14","","12035","12047","Monitoring properties of ice sheets in polar regions is one of the main challenges in glaciology. There is a large amount of heterogeneous radar data from the polar regions that have been gathered through expensive missions. However, retrieving meaningful information from this large volume of data is still a great challenge. With the advancement of machine learning techniques in recent years, many scientists are eager to take advantage of these algorithms and techniques to explore and mine Arctic and Antarctic data. These advancements, however, have happened mainly in the area of supervised learning where the models are data hungry and require large amounts of annotated data. Generating simulated data can be an effective and inexpensive approach to provide large labeled datasets for training machine learning models. In this work, we explore two approaches to simulate arctic snow radar echogram images, namely a radar scattering physics based approach combined with some statistical measures and a purely data-driven approach based on a conditional generative adversarial network. Using several image comparison metrics, we analyze the utility of both methods for the purpose of simulating echograms. Our results show that the physics simulator generates images with good structural similarities, while the purely data-driven approach achieves better textural similarities for simulated image. Finally, we also show that by augmenting our real dataset by the simulated echograms, we can improve our deep learning model for tracking internal layers of snow.","2151-1535","","10.1109/JSTARS.2021.3126547","NSF BIGDATA(grant numbers:IIS-1838230,IIS-1947584); NSF HDR Institute(grant numbers:OAC-2118285); IBM; Amazon Catalyst; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622135","Generative adversarial networks (GANs);remote sensing;simulation;snow radar","Snow;Radar;Generative adversarial networks;Radar imaging;Radar tracking;Data models;Radar remote sensing","airborne radar;geophysical image processing;glaciology;hydrological techniques;learning (artificial intelligence);radar imaging;remote sensing by radar;snow","airborne snow radar data simulation;physics-driven methods;monitoring properties;ice sheets;polar regions;heterogeneous radar data;Antarctic data;supervised learning;annotated data;effective approach;inexpensive approach;training machine learning models;arctic snow radar echogram images;radar scattering physics;purely data-driven approach;conditional generative adversarial network;simulating echograms;physics simulator;simulated image;simulated echograms;deep learning model","","","","48","CCBY","19 Nov 2021","","","IEEE","IEEE Journals"
"Semi-Supervised Fine-Grained Image Categorization Using Transfer Learning With Hierarchical Multi-Scale Adversarial Networks","P. Chen; P. Li; Q. Li; D. Zhang","Key Laboratory of Knowledge Automation for Industrial Processes, Ministry of Education, University of Science and Technology Beijing, Beijing, China; Beijing Key Laboratory of Knowledge Engineering for Materials Science, University of Science and Technology Beijing, Beijing, China; Key Laboratory of Knowledge Automation for Industrial Processes, Ministry of Education, University of Science and Technology Beijing, Beijing, China; Beijing Key Laboratory of Knowledge Engineering for Materials Science, University of Science and Technology Beijing, Beijing, China","IEEE Access","30 Aug 2019","2019","7","","118650","118668","Fine-grained image categorization is still a challenging computer vision problem in recent years. Most of existing methods highly rely on massive labeled data which are scarce in many real world applications. It should also be noticed that progressive learning demands of existing data is very common today. That is, we may pay attention to more fine-grained information (like arctic tern, black tern, buttercup or tulip) in an existing data set with labels like “bird” and “flower”. It is reasonable to believe that the existing labels and model with transferable knowledge would be helpful to another related but different, fine-grained recognition task. In this context, an improved transfer deep learning approach with hierarchical multi-adversarial networks is proposed in this paper. With this approach, cross domain features are extracted by advanced deep encoders coarsely. After that, we annotate a small amount of images in the target domain, thereby creating the “active labels” which can provide instructions for adversarial learning. Then, the GAN-based hierarchical model is utilized to select cross domain categories and enhance related features so as to facilitate an effective transfer. In order to exploit useful local features, a novel adaptive attention mechanism, Region Adversarial Network (RAN) which can select attention regions during adversarial learning and generate valuable fine-grained features, is introduced in the article. We call the proposed hierarchical framework “Attentional Multi-Adversarial Networks (AMAN)”. Experimental results show that AMAN is able to augment cross domain features well-directly and build an effective classifier for fine-grained categorization in the target domain with fewer training samples and higher accuracies.","2169-3536","","10.1109/ACCESS.2019.2934476","Key Research and Development Program of Ningxia Hui Autonomous Region (Research and Application Demonstration of Key Technologies in High-Resolution Remote Sensing based Intelligent Monitoring for Spatial Planning)(grant numbers:2019BFG02009); Ministry of Information Industry of the People's Republic of China; National Natural Science Foundation of China(grant numbers:61801019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794503","Fine-grained classification;transfer learning;deep learning;domain adaption;generative adversarial networks;attention","Feature extraction;Generative adversarial networks;Task analysis;Training;Computational modeling;Deep learning;Generators","computer vision;feature extraction;image recognition;learning (artificial intelligence);neural nets","transfer learning;massive labeled data;progressive learning demands;fine-grained information;transferable knowledge;fine-grained recognition task;improved transfer deep learning approach;cross domain features;advanced deep encoders;target domain;active labels;adversarial learning;GAN-based hierarchical model;cross domain categories;fine-grained features;hierarchical framework;computer vision problem;local features;adaptive attention mechanism;semisupervised fine-grained categorization;hierarchical multiscale adversarial networks;region adversarial network;attentional multiadversarial networks;AMAN","","5","","71","CCBY","12 Aug 2019","","","IEEE","IEEE Journals"
"Learning-Assisted Inversion for Solving Nonlinear Inverse Scattering Problem","K. Xu; Z. Qian; Y. Zhong; J. Su; H. Gao; W. Li","School of Mechatronic Engineering, China University of Mining and Technology, Xuzhou, China; Ministry of Education, Engineering Research Center of Smart Microsensors and Microsystems, Hangzhou Dianzi University, Hangzhou, China; Department of Physics and Technology, UiT The Arctic University of Norway, Tromso, Norway; Ministry of Education, College of Electronics and Information, Key Laboratory of RF Circuit and System, Hangzhou Dianzi University, Hangzhou, China; Ministry of Education, College of Electronics and Information, Key Laboratory of RF Circuit and System, Hangzhou Dianzi University, Hangzhou, China; Ministry of Education, College of Electronics and Information, Key Laboratory of RF Circuit and System, Hangzhou Dianzi University, Hangzhou, China","IEEE Transactions on Microwave Theory and Techniques","","2022","PP","99","1","12","Solving inverse scattering problems (ISPs) is challenging because of its intrinsic ill-posedness and the nonlinearity. When dealing with highly nonlinear ISPs, i.e., those scatterers with high contrast and/or electrically large size, the traditional iterative nonlinear inversion methods converge slowly and take lots of computation time, even maybe trapped into local wrong solution. To alleviate the above challenges, a learning-assisted (LA) inversion approach termed as the LA inversion method (LAIM) with advanced generative adversarial network (GAN) in virtue of a new recently established contraction integral equation for inversion (CIE-I) is proposed to achieve a good balance between the computational efficiency and the accuracy of solving highly nonlinear ISPs. The preliminary profiles composed of only small amount of low-frequency components can be got efficiently by the Fourier bases expansion of CIE-I inversion (FBE-CIE-I). The physically exacted information can be taken as the input of the neural network to recover super-resolution image with more high-frequency components. A weighted loss function composed of the adversarial loss, mean absolute percentage error (MAPE), and structural similarity (SSIM) is used under the pix2pix GAN framework. In addition, the self-attention module is used at the end of the generator network to capture the physical distance information between two pixels and enhance the inversion accuracy of the feature scatterers. To further improve the inversion efficiency, the data-driven method (DDM) is used to achieve real-time imaging by cascading U-net and pix2pix GAN, where U-net is used to replace FBE-CIE-I in the LAIM. Compared with other LA inversion, both the synthetic and experimental examples have validated the merits of the proposed LAIM and DDM.","1557-9670","","10.1109/TMTT.2022.3228945","China Postdoctoral Science Foundation(grant numbers:2019M661984); National Natural Science Foundation of China(grant numbers:61971174,62293493); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9996181","Highly nonlinear;inverse scattering;pix2pix generative adversarial network (GAN);real-time imaging;self-attention;structural similarity (SSIM)","Generative adversarial networks;Imaging;Scattering;Real-time systems;Mathematical models;Iterative methods;Image reconstruction","","","","","","","IEEE","21 Dec 2022","","","IEEE","IEEE Early Access Articles"
