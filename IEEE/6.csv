"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Research on Super-resolution Reconstruction Algorithm of Remote Sensing Image Based on Generative Adversarial Networks","J. Wenjie; L. Xiaoshu","School of Electronic Engineering, Guangxi Normal University, Guilin, China; School of Electronic Engineering, Guangxi Normal University, Guilin, China","2019 IEEE 2nd International Conference on Automation, Electronics and Electrical Engineering (AUTEEE)","12 Mar 2020","2019","","","438","441","Due to natural conditions and hardware manufacturing processes, the resolution of remote sensing images is generally low. Obtaining high-definition remote sensing images by simply improving hardware and manufacturing processes is not only costly and technically challenging but also cannot be deployed on a large scale. Aiming at the limitations of the traditional methods, this paper studies the image super-resolution reconstruction method for improving the generated anti-network. Firstly, the generator network is optimized, and an RRDB (Residual-in-Residual Dense without BN (Batch Normalization) is used. Block) module; secondly, the related idea of relativistic GAN (relativistic generative adversarial network) is introduced, the relative value of the discriminator is not the absolute value; finally, the sensation loss is improved, and the feature is used before the function is activated. The test results show that the proposed algorithm is better than SRGAN (Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network), SRCNN (Super-Resolution Convolutional Neural Network) and FSRCNN (Fast Super-Resolution Convolutional Neural Network). The clarity of the reconstructed image is improved, and the reconstructed image quality is significantly improved.","","978-1-7281-5030-7","10.1109/AUTEEE48671.2019.9033352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9033352","Aerial image;Super-resolution;Generative Adversarial Networks","Image reconstruction;Image resolution;Generators;Remote sensing;Gallium nitride;Generative adversarial networks;Reconstruction algorithms","geophysical image processing;image reconstruction;image resolution;neural nets;remote sensing","generator network;generated anti-network;image super-resolution reconstruction method;high-definition remote sensing images;hardware manufacturing processes;natural conditions;Generative Adversarial networks;remote sensing Image;Super-resolution reconstruction algorithm;reconstructed image quality;Fast Super-Resolution Convolutional;Super-Resolution Convolutional Neural Network;Photo-Realistic Single Image Super-Resolution;relativistic generative adversarial network","","","","19","IEEE","12 Mar 2020","","","IEEE","IEEE Conferences"
"Super-resolution Generative Adversarial Networks Based on Attention Model","B. Yang; K. Xie; Z. Yang; M. Yang","Beijing Key Laboratory of Signal and Information Processing for High-end Printing Equipment, Beijing Institute of Graphic Communication, Beijing, China; Beijing Key Laboratory of Signal and Information Processing for High-end Printing Equipment, Beijing Institute of Graphic Communication, Beijing, China; Beijing Key Laboratory of Signal and Information Processing for High-end Printing Equipment, Beijing Institute of Graphic Communication, Beijing, China; Beijing Key Laboratory of Signal and Information Processing for High-end Printing Equipment, Beijing Institute of Graphic Communication, Beijing, China","2020 IEEE 6th International Conference on Computer and Communications (ICCC)","12 Feb 2021","2020","","","781","786","The purpose of super-resolution reconstruction is to reconstruct a high-resolution image from one or more low resolution images. In this paper, we propose an improved super-resolution generative adversarial networks based on the attention model. The attention model can be used to extract the important features and suppress the unimportant features, so as to ensure the quality of network reconstruction and optimize the network structure of the generator in the generative adversarial networks (GAN). The experimental results show that on the Set5 datasets, we could use less residual block to train and the spending time of reconstruction is less by using the attention model. That also means the fewer parameters and the less calculation. The images selected on Set14 and BSD100 datasets are reconstructed, and the reconstructed time is also shortened.","","978-1-7281-8635-1","10.1109/ICCC51575.2020.9345044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9345044","generative adversarial networks;super-resolution;attention model","Training;Computational modeling;Superresolution;Generative adversarial networks;Feature extraction;Generators;Image reconstruction","image reconstruction;image resolution;neural nets","super-resolution generative adversarial networks;attention model;super-resolution reconstruction;high-resolution image;low resolution images;network reconstruction;network structure;Set14;BSD100 datasets;GAN;Set5 datasets;residual block","","","","15","IEEE","12 Feb 2021","","","IEEE","IEEE Conferences"
"Face Image Super-resolution Based On Relative Average Generative Adversarial Networks","Y. Liu; L. Zhu","Center for image and information processing, Xi'an university of posts and telecommunications, Xi'an, Shaanxi, China; Center for image and information processing, Xi'an university of posts and telecommunications, Xi'an, Shaanxi, China","2021 2nd Asia Symposium on Signal Processing (ASSP)","30 Mar 2022","2021","","","38","43","Face image plays an important role in visual perception and various computer vision tasks. However, due to the influence factors of equipment and environment, the image often has the problem of low resolution. In order to relieve this problem, this paper proposes a face image super-resolution reconstruction algorithm based on Relative average Generative Adversarial Networks. Different from the standard discriminator D in Generative Adversarial Networks(GAN), which estimates the probability that one input image is real and natural, a relativistic average discriminator tries to predict on average the probability that a real image is relatively more realistic than a fake one. At the same time, the loss function used to measure the spatial similarity of image pixels is combined with the perceptual loss function used to measure the similarity of image feature spaces, so that the network pays attention to the reconstruction of image pixel information while taking into account the feature information of the image. Experimental results demonstrate the effectiveness of the proposed method in multi-scale face image super-resolution, and the evaluation indicators (PSNR and SSIM) tested on common test sets are better than those of the contrast algorithm, it also has better visual perception and more detailed information.","","978-1-7281-9883-5","10.1109/ASSP54407.2021.00014","National Natural Science Foundation of China(grant numbers:61802305); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9743235","Face image super-resolution;Deep residual network;deep convolutional neural network;Relative average generative adversarial networks","Superresolution;Signal processing algorithms;Reconstruction algorithms;Generative adversarial networks;Loss measurement;Time measurement;Faces","computer vision;face recognition;feature extraction;image classification;image reconstruction;image representation;image resolution","Relative average Generative Adversarial Networks;visual perception;computer vision tasks;face image super-resolution reconstruction algorithm;one input image;relativistic average discriminator;image pixels;image feature spaces;image pixel information;multiscale face image super-resolution","","","","18","IEEE","30 Mar 2022","","","IEEE","IEEE Conferences"
"Super-Resolution for Music Signals Using Generative Adversarial Networks","J. Dai; Y. Zhang; P. Xie; X. Xu","School of Internet of Things Nanjing, University of Posts and Telecommunications, Nanjing, P. R. China; School of Internet of Things Nanjing, University of Posts and Telecommunications, Nanjing, P. R. China; School of Internet of Things Nanjing, University of Posts and Telecommunications, Nanjing, P. R. China; School of Internet of Things Nanjing, University of Posts and Telecommunications, Nanjing, P. R. China","2021 IEEE 4th International Conference on Big Data and Artificial Intelligence (BDAI)","20 Aug 2021","2021","","","1","5","Super-Resolution (SR) refers to increasing the resolution of a signal in a variety of ways, conventionally employed in the field of image enhancement. Compared with the endeavors for super-resolution in image processing, music signals require supper-resolution to improve their quality or adapt to communication in narrow-band channel, which is also regarded as bandwidth expansion. To this end, we shed light on super-resolution for music signals using the deep learning strategy of Generative Adversarial Networks (GANs). The proposed approach feeds Shot-Time Fourier Transform (STFT) features of low-band signals to the GAN, expecting to obtain their high-band information through jointly considering content and adversarial losses. Then, we carry out experiments on MUSDB18 dataset using mixtures of music sources, in order to show the performance of the proposed approach. The experimental results indicate that the proposed approach achieves better super-resolution performances compared with interpolation and some conventional deep-learning strategies.","","978-1-6654-1270-4","10.1109/BDAI52447.2021.9515219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9515219","super-resolution;generative adversarial networks;music processing;bandwidth extension","Deep learning;Interpolation;Fourier transforms;Superresolution;Bandwidth;Generative adversarial networks;Multiple signal classification","deep learning (artificial intelligence);Fourier transforms;music;neural nets;signal resolution;spectral analysis","bandwidth expansion;high-band information;low-band signals;Shot-Time Fourier Transform features;deep learning strategy;narrow-band channel;image processing;image enhancement;Generative Adversarial Networks;music signals;deep-learning strategies;super-resolution performances;music sources;adversarial losses;content losses","","1","","27","IEEE","20 Aug 2021","","","IEEE","IEEE Conferences"
"A comparison of Generative Adversarial Networks for image super-resolution","P. Cobelli; S. Nesmachnow; J. Toutouh","Universidad de la República, Uruguay; Universidad de la República, Uruguay; ITIS, Universidad de Málaga Málaga, Spain","2022 IEEE Latin American Conference on Computational Intelligence (LA-CCI)","21 Dec 2022","2022","","","1","6","This article presents a comparison of Generative Adversarial Networks for the image super-resolution problem. This is a relevant problem in several research areas and many real-world applications. The research consists of four steps: selecting successful Generative Adversarial Networks architectures, implementing two promising models, evaluating their image quality results, and analyzing their transfer learning capabilities. The main results indicate that both models are able to compute accurate results, with a reasonable deviation from state-of-the-art results and good transfer capabilities.","","978-1-6654-8858-7","10.1109/LA-CCI54402.2022.9981850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9981850","generative adversarial networks;image processing;super-resolution;empirical analysis","Image quality;Analytical models;Computational modeling;Superresolution;Transfer learning;Computer architecture;Generative adversarial networks","image resolution;learning (artificial intelligence);neural nets","generative adversarial networks architectures;image quality results;image super-resolution problem;transfer learning capabilities","","","","23","IEEE","21 Dec 2022","","","IEEE","IEEE Conferences"
"Super Resolution Approach for the Satellite Data Based on the Generative Adversarial Networks","M. Lavreniuk; N. Kussul; A. Shelestov; A. Lavrenyuk; L. Shumilo","Space Research Institute NASU-SSAU, Kyiv, Ukraine; National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, Kyiv, Ukraine; National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, Kyiv, Ukraine; National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, Kyiv, Ukraine; National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, Kyiv, Ukraine","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1095","1098","In the past few years, medium and high-resolution data became freely available for downloading. It provides great opportunity for researchers not to select between solving the task with high-resolution data on small territory or on global scale, but with low-resolution satellite images. Due to high spectral and spatial resolution of the data, Sentinel-1 and Sentinel-2 are very popular sources of information. Nevertheless, in practice if we would like to receive final product in 10 m resolution we should use bands with 10 m resolution. Sentinel-2 has four such bands, but also has other bands, especially red-edge 20 m resolution bands that are useful for vegetation analysis and often are omitted due to lower resolution. Thus, in this study we propose methodology for enhancing resolution (super-resolution) of the existing low-resolution images to higher resolution images. The main idea is to use advanced methods of deep learning - Generative Adversarial Networks (GAN) and train it to increase the resolution for the satellite images. Experimental results for the Sentinel-2 data showed that this approach is efficient and could be used for creating high resolution products.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884460","deep learning;Generative Adversarial Networks;GAN;super-resolution;Sentinel-2","Deep learning;Image resolution;Satellites;Superresolution;Vegetation mapping;Generative adversarial networks;Spatial resolution","geophysical image processing;image resolution;remote sensing;vegetation","high-resolution data;low-resolution satellite images;high spectral resolution;spatial resolution;Sentinel-1;enhancing resolution;existing low-resolution images;higher resolution images;Generative Adversarial Networks;Sentinel-2 data;high resolution products;super resolution approach;satellite data;size 10.0 m;size 20.0 m","","","","23","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"High-quality face image super-resolution based on Generative Adversarial Networks","X. Zhong; X. Qu; C. Chen","College of Information and Electronics, Beijing Institute of Technology; College of Information and Electronics, Beijing Institute of Technology; College of Information and Electronics, Beijing Institute of Technology","2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)","13 Feb 2020","2019","","","1178","1182","Face image super-resolution has received increasing attention. However, since the face has a lot of fine textures, it is very difficult to rebuild for large upscaling factors. We propose a new method for face image SR, using residul dense block(RDB) as the basic unit and the Inception architecture is combined in the low layers. We use the relativistic GAN and the improved perceptual loss defined by the features before activation.For the large scaling factors, our GAN is progressive both in architecture and training. The network proposed achieves excellent performance in the reconstruction of low-resolution face images, especially under large scaling factors such as 4x and 8x.","2381-0947","978-1-7281-1907-6","10.1109/IAEAC47372.2019.8998075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8998075","face image super-resolution;relativistic Generative Adversarial Networks;progressive trainging","Training;Image resolution;Face;Gallium nitride;Generators;Signal resolution;Generative adversarial networks","face recognition;image reconstruction;image resolution;learning (artificial intelligence);neural net architecture","high-quality face image super-resolution;generative adversarial networks;upscaling factors;face image SR;Inception architecture;improved perceptual loss;scaling factors;GAN;low-resolution face image reconstruction","","1","","29","IEEE","13 Feb 2020","","","IEEE","IEEE Conferences"
"Medical Image Super Resolution Using Improved Generative Adversarial Networks","X. Bing; W. Zhang; L. Zheng; Y. Zhang","School of Computer Science and Technology, Harbin Engineering University, Harbin, China; School of Computer Science and Technology, Harbin Engineering University, Harbin, China; School of Computer Science and Technology, Harbin Engineering University, Harbin, China; School of Computer Science and Technology, Harbin Engineering University, Harbin, China","IEEE Access","16 Oct 2019","2019","7","","145030","145038","Details of small anatomical landmarks and pathologies, such as small changes of the microvasculature and soft exudates, are critical to accurate disease analysis. However, actual medical images always suffer from limited spatial resolution, due to imaging equipment and imaging parameters (e.g. scanning time of CT images). Recently, machine learning, especially deep learning techniques, have brought revolution to image super resolution reconstruction. Motivated by these achievements, in this paper, we propose a novel super resolution method for medical images based on an improved generative adversarial networks. To obtain useful image details as much as possible while avoiding the fake information in high frequency, the original squeeze and excitation block is improved by strengthening important features while weakening non-important ones. Then, by embedding the improved squeeze and excitation block in a simplified EDSR model, we build a new image super resolution network. Finally, a new fusion loss that can further strengthen the constraints on low-level features is designed for training our model. The proposed image super resolution model has been validated on the public medical images, and the results show that visual effects of the reconstructed images by our method, especially in the case of high upscaling factors, outperform state-of-the-art deep learning-based methods such as SRGAN, EDSR, VDSR and D-DBPN.","2169-3536","","10.1109/ACCESS.2019.2944862","National Natural Science Foundation of China(grant numbers:61771155); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854062","Generative adversarial network;medical image reconstruction;squeeze and excitation block;super resolution","Generative adversarial networks;Medical diagnostic imaging;Training;Image reconstruction;Spatial resolution","computerised tomography;diseases;image reconstruction;image resolution;learning (artificial intelligence);medical image processing","super resolution method;improved generative adversarial networks;excitation block;nonimportant ones;improved squeeze;image super resolution network;image super resolution model;public medical images;reconstructed images;medical image super resolution;anatomical landmarks;microvasculature;soft exudates;disease analysis;actual medical images;spatial resolution;imaging equipment;imaging parameters;CT images;machine learning;deep learning techniques;image super resolution reconstruction","","12","","27","CCBY","1 Oct 2019","","","IEEE","IEEE Journals"
"Enhancing Image Resolution with Generative Adversarial Networks","B. Yildiz","Department of Software Engineering, Atilim University, Ankara, Turkey","2022 7th International Conference on Computer Science and Engineering (UBMK)","28 Oct 2022","2022","","","104","109","Super-resolution is the process of generating high-resolution images from low-resolution images. There are a variety of practical applications used in real-world problems such as high-definition content creation, surveillance imaging, gaming, and medical imaging. Super-resolution has been the subject of many researches over the past few decades, as improving image resolution offers many advantages. Going beyond the previously presented methods, Generative Adversarial Networks offers a very promising solution. In this work, we will use the Generative Adversarial Networks-based approach to obtain 4x resolution images that are perceptually better than previous solutions. Our extensive experiments, including perceptual comparison, Peak Signal-to-Noise Ratio, and classification success metrics, show that our approach is quite promising for image super-resolution.","2521-1641","978-1-6654-7010-0","10.1109/UBMK55850.2022.9919520","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9919520","Generative Adversarial Networks;Image Processing;Machine Learning;Deep Learning;Super Resolution","Measurement;Computer science;PSNR;Computational modeling;Surveillance;Superresolution;Generative adversarial networks","image enhancement;image resolution;neural nets","image resolution enhancement;generative adversarial networks-based approach;4x resolution images;image super-resolution;high-resolution images;low-resolution images;peak signal-to-noise ratio;classification success metrics","","","","34","IEEE","28 Oct 2022","","","IEEE","IEEE Conferences"
"SRWGANTV: Image Super-Resolution Through Wasserstein Generative Adversarial Networks with Total Variational Regularization","J. Shao; L. Chen; Y. Wu","The Fujian Provincial Engineering, Technology Research Center of Photoelectric Sensing Application College of Photonic and Elec.Eng Fujian, Normal University, Fuzhou, China; The Fujian Provincial Engineering, Technology Research Center of Photoelectric Sensing Application College of Photonic and Elec.Eng Fujian, Normal University, Fuzhou, China; The Fujian Provincial Engineering, Technology Research Center of Photoelectric Sensing Application College of Photonic and Elec.Eng Fujian, Normal University, Fuzhou, China","2021 IEEE 13th International Conference on Computer Research and Development (ICCRD)","29 Mar 2021","2021","","","21","26","The study of generative adversarial networks (GAN) has enormously promoted the research work on single image super-resolution (SISR) problem. SRGAN firstly apply GAN to SISR reconstruction, which has achieved good results. However, SRGAN sacrifices the fidelity. At the same time, it is well known that the GANs are difficult to train and the improper training fails the SISR results easily. Recently, Wasserstein Generative Adversarial Network with gradient penalty (WGAN-GP) has been proposed to alleviate these issues at the expense of performance of the model with a relatively simple training process. However, we find that applying WGAN-GP to SISR still suffers from training instability, leading to failure to obtain a good SR result. To address this problem, we present an image super resolution framework base on enhanced WGAN (SRWGAN-TV). We introduce the total variational (TV) regularization term into the loss function of WGAN. The total variational (TV) regularization term can stabilize the network training and improve the quality of generated images. Experimental results on public datasets show that the proposed method achieves superior performance in both quantitative and qualitative measurements.","","978-1-6654-2260-4","10.1109/ICCRD51685.2021.9386518","Natural Science Foundation of Fujian Province; Technology Development; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9386518","Wasserstein Generative Adversarial Network (WGAN);single image super-resolution;total variational regularization;gradient penalty","Training;TV;Superresolution;Benchmark testing;Generative adversarial networks;Task analysis;Research and development","edge detection;image denoising;image reconstruction;image resolution;maximum likelihood estimation","SRWGANTV;Wasserstein Generative Adversarial networks;GAN;single image super-resolution problem;SRGAN;SISR reconstruction;improper training;SISR results;Wasserstein Generative Adversarial Network;relatively simple training process;applying WGAN-GP;training instability;good SR result;image super resolution framework base;SRWGAN-TV;total variational regularization term;network training","","1","","24","IEEE","29 Mar 2021","","","IEEE","IEEE Conferences"
"Laplacian Generative Adversarial Networks for Multi-Scale Super-Resolution","H. Xia; Y. Yang; X. Hu","College of Information and Communication Engineering, Communication University of China; College of Information and Communication Engineering, Communication University of China; Academy of Broadcasting Science, NTRA","2020 IEEE 5th Information Technology and Mechatronics Engineering Conference (ITOEC)","16 Jul 2020","2020","","","1543","1547","Single-image super-resolution, aims to reconstruct images from low-resolution to high-resolution and super-high-resolution, so as to improve image clarity and visual effects. Based on the principles of generating adversarial networks and image pyramids, a LapSRGAN is proposed to compromise the merits of Laplacian Pyramid Generative Adversarial Network(LapGAN) and Laplacian Pyramid Super-Resolution Network(LapSRN). LapSRGAN is an end-to-end image reconstruction network, which can achieve double and quadruple high-quality, high-resolution reconstruction of the original image. The proposed LapSRGAN is trained with multiscale discriminators and perceptual loss which calculated on feature maps of image. Extensive quantitative and qualitative evaluations on bench mark datasets confirm the effectiveness of the proposed algorithm.","","978-1-7281-4323-1","10.1109/ITOEC49072.2020.9141731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141731","image super-resolution;generative adversarial network;Laplace pyramid;image reconstruction network","Image resolution;Image reconstruction;Generators;Feature extraction;Generative adversarial networks;Training;Interpolation","image reconstruction;image resolution;neural nets","multiscale super-resolution;single-image super-resolution;image clarity;image pyramids;LapSRGAN;end-to-end image reconstruction network;high-resolution reconstruction;Laplacian generative adversarial networks;visual effects;LapGAN;Laplacian pyramid super-resolution network;quadruple high-quality high-resolution reconstruction;double quality high-quality high-resolution reconstructio;multiscale discriminators;perceptual loss;feature maps","","1","","21","IEEE","16 Jul 2020","","","IEEE","IEEE Conferences"
"Generative Adversarial Networks based method for Generating Photo-Realistic Super Resolution Images","D. A. Naik; V. Sangeetha; G. Sandhya","Department of Computer Science & Engg., Ramaiah Institute of Technology, Bengaluru, India; Department of Computer Science & Engg., Ramaiah Institute of Technology, Bengaluru, India; Department of Computer Science & Engg., Nagarjuna College of Engineering & Technology, Bengaluru, India","2021 Emerging Trends in Industry 4.0 (ETI 4.0)","1 Dec 2021","2021","","","1","6","Since the word picture was coined, resolution has always been a challenge. Many studies have been conducted to generate high-resolution photographs, but none have been able to develop a process that is both time and quality effective. As a result, the super resolution issue is discussed in this paper using single-processing techniques. Deep learning methods are used to solve the same problem. The method suggested here will transform a low-resolution image into a high-resolution image of a pleasant and satisfactory quality. This can be accomplished using GANs (Generative Adversarial Networks) with significant up scaling factors.","","978-1-6654-2237-6","10.1109/ETI4.051663.2021.9619393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9619393","Super resolution image;Discriminator;Generator;Generative Models;adversarial process","Measurement;Deep learning;Image resolution;Transforms;Generative adversarial networks;Market research;High frequency","deep learning (artificial intelligence);image resolution","generative adversarial networks;photo-realistic super resolution images;word picture;high-resolution photographs;low-resolution image;high-resolution image;image quality;deep learning;GANs;up scaling factors","","","","11","IEEE","1 Dec 2021","","","IEEE","IEEE Conferences"
"Super Resolution of Medical Images Using Generative Adversarial Networks","A. O. A. Mohamed; K. H. M. Salih; H. H. S. M. Ali","Electronics and Electrical Engineering Department, University of Khartoum, Khartoum, Sudan; Electronics and Electrical Engineering Department, University of Khartoum, Khartoum, Sudan; Electronics and Electrical Engineering Department, University of Khartoum, Khartoum, Sudan","2020 International Conference on Computer, Control, Electrical, and Electronics Engineering (ICCCEEE)","17 May 2021","2021","","","1","6","This paper aims to present a new model called SRMIGAN that performs super-resolution for MRI and CT medical images to help doctors reach a better diagnosis. This model, SRMIGAN adopts deep learning by applying generative adversarial networks technique. It is developed using MSE loss and by exploiting different optimization techniques. This model is compared to other adopted models by using both objective and subjective metrics. Hence PSNR, SSIM, and mean opinion score results are included. The results show that our model beats the other examined models.","","978-1-7281-9111-9","10.1109/ICCCEEE49695.2021.9429656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9429656","Super Resolution;Convolutional Neural Networks;Generative Adversarial Networks","Measurement;Digital control;Computational modeling;Magnetic resonance imaging;Superresolution;Neural networks;Medical services","biomedical MRI;computerised tomography;image resolution;learning (artificial intelligence);mean square error methods;medical image processing","super resolution;medical images;SRMIGAN;super-resolution;deep learning;generative adversarial networks technique;MSE loss;adopted models;examined models","","","","34","IEEE","17 May 2021","","","IEEE","IEEE Conferences"
"Generative Adversarial Networks for Medical Image Super-resolution","M. Zhao; A. Naderian; S. Sanei","Electrical and Electronic Engineering Department, Imperial College, London, UK; Computer Science Department, Nottingham Trent University, Nottingham, UK; Computer Science Department, Nottingham Trent University, Nottingham, UK","2021 International Conference on e-Health and Bioengineering (EHB)","30 Dec 2021","2021","","","1","4","Super-resolution (SR) techniques are very useful in enhancing low resolution images. This becomes even more effective when the clinicians and radiologists need to detect tiny bone fractures in some low-resolution medical images such as X-Rays. In this short paper, the application of new deep learning single-image SR techniques to medical bone X-Ray images have been investigated. The quality of the results, when applied to plain hand X-Rays, are assessed based on peak signal-to-noise ratio and mean opinion score (MOS) and the superiority of generative adversarial networks (GANs), particularly in terms of MOS, has been verified for such applications.","2575-5145","978-1-6654-4000-4","10.1109/EHB52898.2021.9657651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9657651","GAN;generative adversarial networks;MOS;X-Ray super-resolution","Training;Three-dimensional displays;PSNR;Magnetic resonance imaging;Superresolution;X-rays;Visual systems","bone;image reconstruction;image resolution;medical image processing","tiny bone fractures;low-resolution medical images;deep learning single-image SR techniques;medical bone X-Ray images;plain hand X-Rays;generative adversarial networks;medical image super-resolution;super-resolution techniques;low resolution images;radiologists","","","","14","IEEE","30 Dec 2021","","","IEEE","IEEE Conferences"
"Single Image Super-Resolution with U-Net Generative Adversarial Networks","Y. Wang","College of Computer Science and Technology, Chongqing University of Posts and Telecommunication, Chongqing, China","2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)","19 Jul 2021","2021","4","","1835","1840","It is very challenging to recover a High Resolution (HR) image with real texture from a single Low Resolution (LR) image. SRGAN[1] first applied GAN(Generative Adversarial Network) in the field of image Super-Resolution, and restored a relatively real texture HR. However, SRGAN's reconstructed HR often contains unreal artifacts and distortions. Subsequently ESRGAN[2] has improved this problem, but it still has the shortcomings of not sharp edges of objects and slow reconstruction speed. To further improve the perception quality and accelerate the reconstruction speed, we proposed an image super-resolution algorithm (SR) based on U-Net GAN [3]. As the basic block, we introduced the Residual-in-Residual Self-calibrated Convolution with Pixel Attention block(RRSCPA) [4]. From [5] to heuristic, we design the discriminator into a U-shaped structure, which can provide per-pixel feedback to the generator and promote the generator to generate a more realistic HR. Finally, we replaced the VGG-based perceptual loss[6] with the LPIPS perceptual loss[7] function. Our proposed U-Net SRGAN achieves consistently better visual quality with more realistic and natural textures than ESRGAN.","2693-2776","978-1-7281-8535-4","10.1109/IMCEC51613.2021.9482317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9482317","Generative Adversarial Network;U-Net;perceived loss;Super-Resolution","Visualization;Convolution;Image edge detection;Superresolution;Generative adversarial networks;Distortion;Generators","image reconstruction;image resolution;image texture;neural nets","U-Net SRGAN;realistic textures;natural textures;ESRGAN;single image super-resolution;U-net generative adversarial networks;high resolution image;single low resolution image;unreal artifacts;slow reconstruction speed;image super-resolution algorithm;U-Net GAN;VGG-based perceptual loss;residual-in-residual self-calibrated convolution with pixel attention block","","","","25","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"An Application of Generative Adversarial Networks for Super Resolution Medical Imaging","R. Sood; B. Topiwala; K. Choutagunta; R. Sood; M. Rusu",Korea Aerospace University; Korea Aerospace University; Korea Aerospace University; NA; NA,"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)","17 Jan 2019","2018","","","326","331","Acquiring High Resolution (HR) Magnetic Resonance (MR) images requires the patient to remain still for long periods of time, which causes patient discomfort and increases the probability of motion induced image artifacts. A possible solution is to acquire low resolution (LR) images and to process them with the Super Resolution Generative Adversarial Network (SRGAN) to create an HR version. Acquiring LR images requires a lower scan time than acquiring HR images, which allows for higher patient comfort and scanner throughput. This work applies SRGAN to MR images of the prostate to improve the in-plane resolution by factors of 4 and 8. The term 'super resolution' in the context of this paper defines the post processing enhancement of medical images as opposed to 'high resolution' which defines native image resolution acquired during the MR acquisition phase. We also compare the SRGAN to three other models: SRCNN, SRResNet, and Sparse Representation. While the SRGAN results do not have the best Peak Signal to Noise Ratio (PSNR) or Structural Similarity (SSIM) metrics, they are the visually most similar to the original HR images, as portrayed by the Mean Opinion Score (MOS) results.","","978-1-5386-6805-4","10.1109/ICMLA.2018.00055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8614080","medical imaging;machine learning;generative adversarial networks;super resolution;MRI","Image resolution;Generators;Training;Biomedical imaging;Dictionaries;Loss measurement;PSNR","biomedical MRI;convolutional neural nets;image enhancement;image motion analysis;image reconstruction;image representation;image resolution;medical image processing","structural similarity metrics;PSNR;peak signal to noise ratio;sparse representation;SRResNet;SRCNN;medical image post processing enhancement;SRGAN;generative adversarial networks;High Resolution Magnetic Resonance images;Super Resolution medical imaging;native image resolution;in-plane resolution;MR images;LR images;Super Resolution Generative Adversarial Network;low resolution images","","10","","17","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"Transfer Learning Based Super Resolution of Aerial Images","A. Ahmet Haykır; İ. Öksüz","Bilgisayar Mühendisliği Bölümü, İstanbul Teknik Üniversitesi, İstanbul, Türkiye; Bilgisayar Mühendisliği Bölümü, İstanbul Teknik Üniversitesi, İstanbul, Türkiye","2022 30th Signal Processing and Communications Applications Conference (SIU)","29 Aug 2022","2022","","","1","4","Images created using the Super Resolution method can generate more information compared to their low resolution counterparts. A super-resolved image, which is created using an original image captured by an imaging source is not only more meaningful to human perception but also has advantages on downstream tasks such as object detection and pattern recognition. In this work, we aim to apply the Super Resolution method to the Aerial Images captured for surveillance to enable more information about the original scenes. To achieve this Super Resolution Generative Adversarial Network (SRGAN), which is based on the Generative Adversarial Networks architecture is used. We also applied transfer learning methodology to achieve better image quality. Public xView and DOTA datasets which contain images mostly captured by satellites around the world are used to train a generative model via SRGAN architecture. Furthermore, DIV2K dataset is used to pre-train a generative model, and then the transfer learning technique is used to train separate models on xView and DOTA validation datasets. Perceptual Index (PI) and Root Mean Squared Error (RMSE) which are used on European Conference on Computer Vision -Perceptual Image Restoration and Manipulation Workshop 2018 are computed as the performance metrics. We have seen that the model which gives the best PI results, i.e. better perceptual quality, on xView and DOTA validation datasets is the one trained using the DIV2K dataset and the model which gives the best RMSE results, i.e. better reconstruction quality, is the one trained using the transfer learning technique.","2165-0608","978-1-6654-5092-8","10.1109/SIU55565.2022.9864797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9864797","Super Resolution;Deep Learning;Generative Adversarial Networks;Aerial Images","Image resolution;Satellites;Computational modeling;Surveillance;Transfer learning;Computer architecture;Generative adversarial networks","deep learning (artificial intelligence);image reconstruction;image resolution;mean square error methods;surveillance;visual perception","super-resolved image;imaging source;object detection;pattern recognition;super resolution method;aerial images;super resolution generative adversarial network;generative adversarial networks architecture;image quality;DOTA datasets;generative model;SRGAN architecture;DIV2K dataset;transfer learning technique;perceptual index;root mean squared error;Public xView","","","","0","IEEE","29 Aug 2022","","","IEEE","IEEE Conferences"
"Micro-Ct Synthesis and Inner Ear Super Resolution via Generative Adversarial Networks and Bayesian Inference","H. Li; R. G. N. Prasad; A. Sekuboyina; C. Niu; S. Bai; W. Hemmert; B. Menze","Department of Computer Science, Technical University of Munich; Department of Computer Science, Technical University of Munich; Department of Computer Science, Technical University of Munich; Department of Medical Imaging, First Affiliated Hospital of Xi’an Jiaotong University, China; School of Bioengineering, Technical University of Munich; School of Bioengineering, Technical University of Munich; Department of Computer Science, Technical University of Munich","2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)","25 May 2021","2021","","","1500","1504","Existing medical image super-resolution methods rely on pairs of low- and high-resolution images to learn a mapping in a fully supervised manner. However, such image pairs are often not available in clinical practice. In this paper, we address super resolution problem in a real-world scenario using unpaired data and synthesize linearly eight times higher resolved Micro-CT images of temporal bone structure embedded in the inner ear. We explore cycle-consistency generative adversarial networks for super-resolution and equip the model with Bayesian inference. We further introduce Hu Moments distance as the evaluation metric to quantify the shape of the temporal bone. We evaluate our method on a public inner ear CT dataset and have seen both visual and quantitative improvement over state-of-the-art supervised deep-learning based methods. Further, we conduct a multi-rater visual evaluation experiment and find that three inner-ear researchers consistently rate our method highest quality scores among three methods. Furthermore, we are able to quantify uncertainty in the unpaired translation task and the uncertainty map can provide structural information of the temporal bone.","1945-8452","978-1-6654-1246-9","10.1109/ISBI48211.2021.9434061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9434061","","Visualization;Uncertainty;Shape;Superresolution;Ear;Bones;Generative adversarial networks","Bayes methods;bone;computerised tomography;ear;image reconstruction;image resolution;learning (artificial intelligence);medical image processing","Microct synthesis;inner ear super resolution;Bayesian inference;medical image super-resolution methods;high-resolution images;fully supervised manner;image pairs;clinical practice;super resolution problem;synthesize linearly eight times higher resolved MicroCT images;temporal bone structure;cycle-consistency generative adversarial networks;Hu Moments distance;public inner ear CT dataset;deep-learning based methods;multirater visual evaluation experiment;inner-ear researchers","","2","","21","IEEE","25 May 2021","","","IEEE","IEEE Conferences"
"Accurate License Plate Recognition and Super-Resolution Using a Generative Adversarial Networks on Traffic Surveillance Video","Y. Lee; J. Yun; Y. Hong; J. Lee; M. Jeon",Gwangju Institute of Science and Technology; Gwangju Institute of Science and Technology; Gwangju Institute of Science and Technology; Gwangju Institute of Science and Technology; Gwangju Institute of Science and Technology,"2018 IEEE International Conference on Consumer Electronics - Asia (ICCE-Asia)","29 Nov 2018","2018","","","1","4","Automatic License Plate Recognition (ALPR) is one of the most important methods of intelligent traffic surveillance applications. Some existing ALPR systems are developed for near-frontal plate images in a single lane. However, most surveillance cameras have a challenging environment: small size object, poor resolution and blurred image. We propose a new method that can be applied in the ALPR challenged environments by using super-resolution (SR) module based on Generative Adversarial Networks (GAN). We also used the state-of-the-art and real-time object detection method, You Only Look Once (YOLO), for license plate detection and character recognition. We collected a challenging dataset at low resolution and small object less than 60*60 size and evaluate our approach on it. The achieved mean accuracy of recognition of license plate is above 2% better than other methods in our dataset. Our implementation demonstrate the superiority over the state-of-the-art.","","978-1-5386-5807-9","10.1109/ICCE-ASIA.2018.8552121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552121","Visual Surveillance;Super-Resolution;License Plate Recognition;Generative Adversarial Networks","License plate recognition;Image resolution;Surveillance;Cameras;Gallium nitride;Character recognition","character recognition;image recognition;image resolution;object detection;object recognition;object tracking;traffic engineering computing;video signal processing;video surveillance","traffic surveillance video;intelligent traffic surveillance applications;near-frontal plate images;surveillance cameras;super-resolution module;real-time object detection method;license plate detection;character recognition;generative adversarial networks;automatic license plate recognition;ALPR systems;blurred image;You Only Look Once","","10","","17","IEEE","29 Nov 2018","","","IEEE","IEEE Conferences"
"Super-Resolution Deblurring Algorithm for Generative Adversarial Networks","B. Tian; W. Yan; W. Wang; Q. Su; Y. Liu; G. Liu; W. Wang","Information &Telecommunications Company State Grid Shandong Electric Power Company, Jinan, Shandong, China; Information &Telecommunications Company State Grid Shandong Electric Power Company, Jinan, Shandong, China; Information &Telecommunications Company State Grid Shandong Electric Power Company, Jinan, Shandong, China; Information &Telecommunications Company State Grid Shandong Electric Power Company, Jinan, Shandong, China; Information &Telecommunications Company State Grid Shandong Electric Power Company, Jinan, Shandong, China; Shandong Luneng Intelligence Technology Co. Ltd., Jinan, Shandong, China; Shandong Luneng Intelligence Technology Co. Ltd., Jinan, Shandong, China","2017 Second International Conference on Mechanical, Control and Computer Engineering (ICMCCE)","29 Jan 2018","2017","","","135","140","Image quality improvement has a significant impact on target detection and recognition. Generative Adversarial Nets are inspired by two-person zero-sum game in game theory. It can learn to automatically generate images, which can be conditional learning, a guide to the image generation. In this paper, we analyze the characteristics of motion blur, and propose a method to add the defocused fuzzy kernel and multi-direction motion fuzzy kernel to the training samples, and use the super-resolution anti-network method to exercise blur and carry out the fuzzy image data recorded by the UAV experiment analysis.","","978-1-5386-2628-3","10.1109/ICMCCE.2017.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269907","generative adversarial networks;defocused fuzzy kernel;motion fuzzy kernel;super-resolution","Kernel;Image resolution;Training;Image restoration;Convolution;Cost function;Unmanned aerial vehicles","fuzzy set theory;game theory;image enhancement;image motion analysis;image resolution;image restoration;image texture;learning (artificial intelligence);object detection;object recognition","super-resolution deblurring algorithm;generative Adversarial networks;image quality improvement;target detection;two-person zero-sum game;game theory;conditional learning;image generation;defocused fuzzy kernel;multidirection motion fuzzy kernel;super-resolution anti-network method;fuzzy image data;generative adversarial nets;UAV experiment analysis;motion blur characteristic analysis","","1","","15","IEEE","29 Jan 2018","","","IEEE","IEEE Conferences"
"Super-resolution Reconstruction of Infrared Images of Internal Defective Metal Plates Based on Generative Adversarial Networks","X. Feng; Z. Li; S. Wu","Beijing University of Chemical Technology, Beijing, China; Beijing University of Chemical Technology, Beijing, China; Beijing University of Chemical Technology, Beijing, China","2020 IEEE 5th International Conference on Signal and Image Processing (ICSIP)","4 Feb 2021","2020","","","292","297","Infrared thermal imaging non-destructive testing technology has made great progress and has been used in the field of defect detection. However, due to the internal noise of the infrared imaging equipment and the influence of the surrounding environment interference, the infrared images used for defect recognition have the disadvantages of low contrast, low resolution, and low signal-to-noise ratio. Our article first briefly introduces the basic principle of infrared thermal imaging detection technology and the development status at home and abroad, then we builds an infrared image acquisition system that uses long-pulsed thermal method to collect internal defects of a metal plate. In order to solve the problem of noises, our paper first adopts Gaussian blur and homomorphic filtering on the acquired infrared images. Then we use Laplacian operator to process the filtered images and obtained second-order differential images. Finally, we use GAN for super-resolution reconstruction of the filtered second-order differential images. The results show that the super-resolution reconstructed images have higher PSNR and SSIM. What's more, it retains detailed information about defects in the original infrared images.","","978-1-7281-6896-8","10.1109/ICSIP49896.2020.9339408","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9339408","infrared non-destructive testing;homomorphic filtering;laplacian operator;super-resolution;GAN","Superresolution;Metals;Photothermal effects;Reconstruction algorithms;Generative adversarial networks;Information filters;Image reconstruction","computerised instrumentation;image filtering;image reconstruction;image resolution;infrared imaging;neural nets","Laplacian operator;homomorphic filtering;Gaussian blur;SSIM;PSNR;second-order differential imaging;super-resolution reconstructed imaging;infrared image acquisition system;infrared thermal imaging detection technology;low signal-to-noise ratio;environment interference;infrared imaging equipment;thermal imaging nondestructive testing technology;generative adversarial networks;internal defective metal plates;image filtering","","","","14","IEEE","4 Feb 2021","","","IEEE","IEEE Conferences"
"Single Image Super-Resolution Based on Self-Attention","L. Zong; L. Chen","China Jiliang University, Hangzhou, China; China Jiliang University, Hangzhou, China","2019 IEEE International Conference on Unmanned Systems and Artificial Intelligence (ICUSAI)","25 Jun 2020","2019","","","56","60","Single image super-resolution (SISR) is a challenging task and has collected extensive attention in both industry and academia. The most challenging problem in super-resolution is how to recover the finer texture details. And we find the generated images usually have low-scale contrast. In this paper, we present a novel super-resolution method based on generative adversarial networks (GAN). Our model is based on SRGAN, instead, we remove most of the batch normalization layers in generator to get higher-scale contrast images and accelerate training speed. Because batch normalization layers can get rid of range flexibility from networks, this causes the generated images have lower-scale contrast compared to the origin images. We also add the self-attention module into generator to get more global dependencies when convolution operations can capture enough local dependencies but little global dependencies. We take advantage of both local dependencies and global dependencies to improve super-resolved texture details and structural, we call our model SASRGAN. The images generated by our model have higher Structural Similarity Index Measure (SSIM), it proves that our model has available performance.","","978-1-7281-5859-4","10.1109/ICUSAI47366.2019.9124791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9124791","super-resolution;generative adversarial networks;batch normalization;self-attention","Training;Industries;PSNR;Convolution;Superresolution;Generative adversarial networks;Generators","convolutional neural nets;image reconstruction;image resolution;image texture","single image super-resolution;finer texture details;low-scale contrast;novel super-resolution method;generative adversarial networks;batch normalization layers;higher-scale contrast images;global dependencies;local dependencies;super-resolved texture details;lower-scale contrast images;structural similarity index measure;SSIM;SASRGAN model","","2","","15","IEEE","25 Jun 2020","","","IEEE","IEEE Conferences"
"Ret-GAN: Retinal Image Enhancement using Generative Adversarial Networks","K. C. Santosh; S. Ghosh; M. Bose","KC's PAMI Research Lab - Computer Science, University of South Dakota, Vermillion, SD, USA; Department of Electronics Engineering, KIIT University, Bhubaneswar, India; Department of Electronics Engineering, KIIT University, Bhubaneswar, India","2021 IEEE 34th International Symposium on Computer-Based Medical Systems (CBMS)","12 Jul 2021","2021","","","79","84","With over 200K cases in the U.S. alone, retinal disorders are the most common cause of irreversible blindness. This serves as a primary aim to analyze automated screening tools to detect retinal disorders. We analyze the OCT dataset (84, 484 images) and enhance the images by using Generative Adversarial Networks (GANs). This work specifically focuses on enhancing the quality of source (training) images for better algorithm validatiorr/testing11Authors contributed equally to the work.. We synthesize super resolution-based images using generators, discriminators and the adversarial nature of the GANs. The performance of the Ret-GAN is validated by PSNR, SSIM, and loss functions. To test the Ret-GAN generated images, we train a convolutional neural network (CNN) with the original dataset images and super-resolution images. We achieve an accuracy of 0.9825 on Ret-GAN generated image data, and 0.9525 on the original data. We statistically analyze the CNN with a number of evaluation metrics to further validate the results. The proposed scheme is compared to benchmark research findings on the same dataset. Our results are encouraging.","2372-9198","978-1-6654-4121-6","10.1109/CBMS52027.2021.00082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9474782","Ret-GAN;Retinal disorders;Generative Adversarial Networks","Training;Measurement;Superresolution;Tools;Retina;Generative adversarial networks;Generators","biomedical optical imaging;convolutional neural nets;eye;image enhancement;image resolution;medical image processing;optical tomography","CNN;superresolution-based images;image data;superresolution images;dataset images;convolutional neural network;adversarial nature;source images;retinal disorders;generative adversarial networks;retinal image enhancement;Ret-GAN;temperature 200.0 K","","3","","20","IEEE","12 Jul 2021","","","IEEE","IEEE Conferences"
"A Composite Discriminator for Generative Adversarial Network based Video Super-Resolution","X. Wang; A. Lucas; S. Lopez-Tapia; X. Wu; R. Molina; A. K. Katsaggelos","Dept. of Electrical Engineering and Computer Science Northwestern University Evanston, IL, USA; Dept. of Electrical Engineering and Computer Science Northwestern University Evanston, IL, USA; Depto. de Ciencias de la Computación e I.A., University of Granada, Granada, Spain; Dept. of Electrical Engineering and Computer Science Northwestern University Evanston, IL, USA; Depto. de Ciencias de la Computación e I.A., University of Granada, Granada, Spain; Dept. of Electrical Engineering and Computer Science Northwestern University Evanston, IL, USA","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","Generative Adversarial Networks (GANs) have been used for solving the video super-resolution problem. So far, video super-resolution GAN-based methods use the traditional GAN framework which consists of a single generator and a single discriminator that are trained against each other. In this work we propose a new framework which incorporates two collaborative discriminators whose aim is to jointly improve the quality of the reconstructed video sequence. While one discriminator concentrates on general properties of the images, the second one specializes on obtaining realistically reconstructed features, such as, edges. Experiments results demonstrate that the learned model outperforms current state of the art models and obtains super-resolved frames, with fine details, sharp edges, and fewer artifacts.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8903072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903072","Video Super-Resolution;Spatially Adaptive;Generative Adversarial Networks;the Composite Discriminator","Generators;Training;Gallium nitride;Image edge detection;Generative adversarial networks","image reconstruction;image resolution;image sequences;learning (artificial intelligence);video signal processing","composite discriminator;generative adversarial networks;video super-resolution problem;video super-resolution GAN-based methods;reconstructed video sequence;super-resolved frames;collaborative discriminators;GAN framework","","","","17","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Recent Advances of Generative Adversarial Networks","Z. Liu; T. Yuan; Y. Lin; B. Zeng","Fuzhou No.8 High School Sino-US Program, Fuzhou, China; American Heritage School, Boca Delray, Delray Beach, FL, US; DuPont Manual High School, Louisville, KT, US; College of Engineering, Texas A&M University, TX, US","2022 IEEE 2nd International Conference on Electronic Technology, Communication and Information (ICETCI)","25 Jul 2022","2022","","","558","562","Generative adversarial networks (GANs) have received great attention recently. GAN is an unsupervised learning method that learns representations without highly relying on annotations. GAN comprises two networks called generator and discriminator that training in a competitive process. GANs have made notable progress and promising performance in various applications including image inpainting, image super-resolution, and face synthesis. This paper aims to introduce an overview of GAN, including fundamentals, several up-to-date variants, applications, and challenges of GAN. Finally, we also provide readers with some solutions to mitigate issues existing in GANs.","","978-1-7281-8115-8","10.1109/ICETCI55101.2022.9832194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9832194","deep learning;generative adversarial networks;unsupervised learning","Training;Deep learning;Sensitivity;Superresolution;Network architecture;Generative adversarial networks;Generators","image resolution;image restoration;learning (artificial intelligence);unsupervised learning;video signal processing","GAN;generative adversarial networks;unsupervised learning method;generator;applications including image inpainting","","","","21","IEEE","25 Jul 2022","","","IEEE","IEEE Conferences"
"Multi-Resolution Generative Adversarial Networks for Tiny-Scale Pedestrian Detection","R. Yin","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China","2019 IEEE International Conference on Image Processing (ICIP)","26 Aug 2019","2019","","","1665","1669","Although pedestrian detection techniques have achieved great success recently, the accurate tiny-scale pedestrian detection remains challenging with low resolution. The existing CNN based detection methods are limited in terms of in-line mechanism when encountering tiny-scale pedestrian detection, because the embedded convolution and pooling operations tend to weaken the features' representation of tiny scales objects. To ameliorate, we propose a newly-designed Multi-Resolution Generative Adversarial Network (MRGAN) to simultaneously conduct multi-resolution pedestrian detection by directly generating a high-resolution pedestrian image from low-resolution image. The key idea is to explore the intrinsic relations between high-resolution pedestrians and low-resolution pedestrians to enhance the representation of low-resolution pedestrians. The classification loss will be used to conduct the training process of super-resolution generative adversarial network, so that the generated super-resolution images can benefit the tiny-scale pedestrian detection. Besides, we also define a segmentation-based perceptual loss by incorporating a pre-trained image segmentation sub-network to refine the detail information. Extensive experiments and comprehensive evaluations on public challenging benchmarks confirm that our method outperforms the state-of-the-art methods.","2381-8549","978-1-5386-6249-6","10.1109/ICIP.2019.8803030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8803030","Pedestrian detection;Super-resolution;Generative adversarial network","Image resolution;Generators;Image segmentation;Generative adversarial networks;Training;Detectors;Feature extraction","computer vision;convolutional neural nets;image representation;image resolution;image segmentation;learning (artificial intelligence);object detection;pedestrians","MultiResolution Generative Adversarial networks;pedestrian detection techniques;detection methods;encountering tiny-scale pedestrian detection;tiny scales objects;MultiResolution Generative Adversarial Network;multiresolution pedestrian detection;high-resolution pedestrian image;low-resolution image;low-resolution pedestrians;super-resolution generative adversarial network;super-resolution images","","7","","24","IEEE","26 Aug 2019","","","IEEE","IEEE Conferences"
"Large-Factor Super-Resolution of Remote Sensing Images With Spectra-Guided Generative Adversarial Networks","Y. Meng; W. Li; S. Lei; Z. Zou; Z. Shi","Shanghai Artificial Intelligence Laboratory, Shanghai, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China; AVIC Chengdu Aircraft Industrial (Group) Company Ltd., Chengdu, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China","IEEE Transactions on Geoscience and Remote Sensing","23 Nov 2022","2022","60","","1","11","Large-factor image super-resolution (SR) is a challenging task due to the high uncertainty and incompleteness of the missing details to be recovered. In remote sensing images, the subpixel spectral mixing and semantic ambiguity of ground objects make this task even more challenging. In this article, we propose a novel method for large-factor SR of remote sensing images named spectra-guided generative adversarial networks (SpecGANs). In response to the above problems, we explore whether introducing additional hyperspectral images (HSIs) to GAN as conditional input can be the key to solving the problems. Different from previous approaches that mainly focus on improving the feature representation of a single source input, we propose a dual-branch network architecture to effectively fuse low-resolution (LR) red, green, blue (RGB) images and corresponding HSIs, which fully exploit the rich hyperspectral information as conditional semantic guidance. Due to the spectral specificity of ground objects, the semantic accuracy of the generated images is guaranteed. To further improve the visual fidelity of the generated output, we also introduce the Latent Code Bank with rich visual priors under a generative adversarial training framework so that high-resolution, detailed, and realistic images can be progressively generated. Extensive experiments show the superiority of our method over the state-of-art image SR methods in terms of both quantitative evaluation metrics and visual quality. Ablation experiments also suggest the necessity of adding spectral information and the effectiveness of our designed fusion module. To our best knowledge, we are the first to achieve up to 32x SR of remote sensing images with high visual fidelity under the premise of accurate ground object semantics. Our code can be publicly available at https://github.com/YapengMeng/SpecGAN.","1558-0644","","10.1109/TGRS.2022.3222360","National Key Research and Development Program of China (Titled “Brain-inspired General Vision Models and Applications”); National Natural Science Foundation of China(grant numbers:62125102); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9950553","Deep convolutional neural networks (CNNs);generative adversarial networks (GANs);hyperspectral image (HSI);remote sensing image;super-resolution (SR)","Superresolution;Hyperspectral imaging;Semantics;Task analysis;Visualization;Generative adversarial networks;Image reconstruction","geophysical image processing;image classification;image fusion;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","accurate ground object semantics;additional hyperspectral images;factor super-resolution;generative adversarial training framework;ground objects;large-factor image super-resolution;large-factor SR;realistic images;remote sensing images;spectra-guided generative adversarial networks;state-of-art image SR methods","","","","63","IEEE","14 Nov 2022","","","IEEE","IEEE Journals"
"Positron Image Super-Resolution Using Generative Adversarial Networks","F. Xiong; J. Liu; M. Zhao; M. Yao; R. Guo","Nondestructive Detection and Monitoring Technology for High Speed Transportation Facilities, Key Laboratory of Ministry of Industry and Information Technology, Nanjing, China; Nondestructive Detection and Monitoring Technology for High Speed Transportation Facilities, Key Laboratory of Ministry of Industry and Information Technology, Nanjing, China; Nondestructive Detection and Monitoring Technology for High Speed Transportation Facilities, Key Laboratory of Ministry of Industry and Information Technology, Nanjing, China; Nondestructive Detection and Monitoring Technology for High Speed Transportation Facilities, Key Laboratory of Ministry of Industry and Information Technology, Nanjing, China; Nondestructive Detection and Monitoring Technology for High Speed Transportation Facilities, Key Laboratory of Ministry of Industry and Information Technology, Nanjing, China","IEEE Access","9 Sep 2021","2021","9","","121329","121343","Positron images generated by positron non-destructive testing technology under rapid detection scenes such as low concentration dose, low exposure time and short imaging time, which have some problems like low-resolution and poor definition. These issues cannot be solved for the being time. To solves these problems, this research super-resolves the low-resolution positron images to generate images with high-resolution and clear details. To make the generated super-resolution images more capable of restoring the features of low- resolution images, this research proposed a positron image super-resolution reconstruction method based on generative adversarial networks. In order to improve the input information utilization rate, long skip connections were added into the generator. In addition, the discriminant model, where composed of an image discriminator and a feature discriminator, can stimulate the generator to generate clearer super-resolution images which contain more details. In attempting to solve the problem of dataset matching, a special positron image super-resolution dataset is constructed for network application scenarios. In the adversarial training stage, perceptual similarity loss and adversarial loss are used to replace the traditional mean squared error loss to improve the images perception quality. Experimental results show that the proposed model can reconstruct low-resolution images by four times super-resolution in 0.16 seconds. The super-resolution images obtained are superior to other algorithms in visual effect, which have clearer detail structure and higher objective performance values. Hence this model can meet the requirements of rapid non-destructive testing of industrial parts.","2169-3536","","10.1109/ACCESS.2021.3109634","Natural Science Foundation of China(grant numbers:62071229,51875289,61873124); Aeronautical Science Foundation of China(grant numbers:2020Z060052001,20182952029); Fundamental Research Funds for the Central Universities(grant numbers:NJ2020014,NS2019017); Nondestructive Detection and Monitoring Technology for High Speed Transportation Facilities, Key Laboratory of Ministry of Industry and Information Technology, Graduate Innovation Base (Laboratory) Open Fund(grant numbers:kfjj20200303); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9527232","Super-resolution reconstruction;deep learning;generative adversarial networks;positron image","Positrons;Superresolution;Image reconstruction;Testing;Hydraulic systems;Generative adversarial networks;Generators","image reconstruction;image resolution;neural nets","short imaging time;low-resolution positron images;super-resolution images;positron image super-resolution reconstruction method;generative adversarial networks;image discriminator;image perception quality;positron nondestructive testing technology;low concentration dose;low exposure time;positron image super-resolution dataset","","","","48","CCBY","1 Sep 2021","","","IEEE","IEEE Journals"
"Image Quality Improve by Super Resolution Generative Adversarial Networks","X. Hou; T. Liu; S. Wang; L. Zhang","Wuhan Britain-China School, Wuhan, China; International Department, Gaomi No.1 High School of Shandong Province, Weifang, China; Dulwich International High School-Suzhou, Suzhou, China; Suzhou Foreign Language School, Suzhou, China","2021 2nd International Conference on Intelligent Computing and Human-Computer Interaction (ICHCI)","21 Feb 2022","2021","","","117","121","In this research, we analyze the methods to improve the quality of the pictures. Machine learning technique is used to achieve the effect of converting low-pixeled pictures into high pixeled ones. It is convenient and can be used in many circumstances, such as engineering projects and medical surveys. This study uses the SRGAN to train the model, which has the generator network and the discriminator network. The generator network is used to generate high-resolution images, and the discriminator network is used to judge the authenticity of the image generated. Our network has trained the network with 8× upscaling factors and eventually obtains predominant achievement for dealing with detailed textures like trees, cars, and animal fur. Our network can recover low-quality pictures perpetual satisfying, and the loss of this model is low. Our research provides model-based strategic support for image quality improvement and gets a good picture resolution increase in the tests.","","978-1-6654-0764-9","10.1109/ICHCI54629.2021.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9708650","Super Resolution Generative Adversarial Networks (SRGAN);Image Super Resolution;Image Processing","Image quality;Training;Human computer interaction;Chemistry;Biological system modeling;Superresolution;Machine learning","image resolution;image texture;learning (artificial intelligence);neural nets","superresolution generative adversarial networks;machine learning;generator network;discriminator network;high-resolution images;low-quality pictures;image quality improvement;picture resolution;SRGAN;image authenticity;image textures","","","","28","IEEE","21 Feb 2022","","","IEEE","IEEE Conferences"
"Generative Adversarial Networks and Perceptual Losses for Video Super-Resolution","A. Lucas; A. K. Katsaggelos; S. Lopez-Tapuia; R. Molina","Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Computer Science and Artificial Intelligence Department, Universidad de Granada, Spain; Computer Science and Artificial Intelligence Department, Universidad de Granada, Spain","2018 25th IEEE International Conference on Image Processing (ICIP)","6 Sep 2018","2018","","","51","55","Recent research on image super-resolution (SR) has shown that the use of perceptual losses such as feature-space loss functions and adversarial training can greatly improve the perceptual quality of the resulting SR output. In this paper, we extend the use of these perceptual-focused approaches for image SR to that of video SR. We design a 15-block residual neural network, VSRResNet, which is pre-trained on a the traditional mean -squared -error (MSE) loss and later fine-tuned with a feature-space loss function in an adversarial setting. We show that our proposed system, VSRRes-FeatGAN, produces super-resolved frames of much higher perceptual quality than those provided by the MSE-based model.","2381-8549","978-1-4799-7061-2","10.1109/ICIP.2018.8451714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451714","Video;Superresolution;Convolutional Neuronal Networks;Generative Adversarial Networks;Perceptual Loss Functions","Training;Spatial resolution;Mathematical model;Loss measurement;Gallium nitride;Neural networks","image resolution;mean square error methods;neural nets;video signal processing","generative adversarial networks;perceptual losses;video super-resolution;image super-resolution;feature-space loss function;adversarial training;15-block residual neural network;error loss;perceptual quality;VSRResNet;mean-squared-error;MSE;VSRRes-FeatGAN system;super-resolved frames","","22","1","22","IEEE","6 Sep 2018","","","IEEE","IEEE Conferences"
"Image Super-Resolution Using Complex Dense Block on Generative Adversarial Networks","B. -X. Chen; T. -J. Liu; K. -H. Liu; H. -H. Liu; S. -C. Pei","Dept. of Electrical Engineering, National Chung Hsing University, Taichung, Taiwan; Dept. of Electrical Engineering, National Chung Hsing University, Taichung, Taiwan; Dept. of Computer Science and Information Engineering, National Taichung University of Science and Technology, Taichung, Taiwan; Graduate Institute of Communication Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Communication Engineering, National Taiwan University, Taipei, Taiwan","2019 IEEE International Conference on Image Processing (ICIP)","26 Aug 2019","2019","","","2866","2870","The recent super-resolution (SR) techniques are divided into two directions. One is to improve PSNR and the other is to improve visual quality. We believe improving visual quality is more important and practical than blindly improving PSNR. In this paper we employ a generative adversarial network (GAN) and a new perceptual loss function for photo-realistic single image super-resolution (SISR). Our main contributions are as follows: we propose a new dense block which uses complex connections between each layer to build a more powerful generator. Next, to improve the perceptual quality, we found a new set of feature maps to compute the perceptual loss, which would make the output image look more real and natural. Finally, we compare our results with other methods by subjective evaluation. The subjects rank the image generated by various methods from good to bad. The final results show that our method can generate a more natural and realistic SR image than other state-of-the-art methods.","2381-8549","978-1-5386-6249-6","10.1109/ICIP.2019.8803711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8803711","Super-resolution (SR);dense block;generative adversarial network (GAN);visual quality.","Visualization;Image resolution;Generators;Generative adversarial networks;Network architecture;Feature extraction;Signal resolution","image reconstruction;image resolution","PSNR;visual quality;generative adversarial network;perceptual loss function;photo-realistic single image super-resolution;complex connections;perceptual quality;output image;natural image;realistic SR image;complex dense block;super-resolution techniques","","21","","29","IEEE","26 Aug 2019","","","IEEE","IEEE Conferences"
"RankSRGAN: Super Resolution Generative Adversarial Networks With Learning to Rank","W. Zhang; Y. Liu; C. Dong; Y. Qiao","ShenZhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Beijing, China; ShenZhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Beijing, China; ShenZhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Beijing, China; Shanghai AI Lab, Shanghai, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","14 Sep 2022","2022","44","10","7149","7166","Generative Adversarial Networks (GAN) have demonstrated the potential to recover realistic details for single image super-resolution (SISR). To further improve the visual quality of super-resolved results, PIRM2018-SR Challenge employed perceptual metrics to assess the perceptual quality, such as PI, NIQE, and Ma. However, existing methods cannot directly optimize these indifferentiable perceptual metrics, which are shown to be highly correlated with human ratings. To address the problem, we propose Super-Resolution Generative Adversarial Networks with Ranker (RankSRGAN) to optimize generator in the direction of different perceptual metrics. Specifically, we first train a Ranker which can learn the behaviour of perceptual metrics and then introduce a novel rank-content loss to optimize the perceptual quality. The most appealing part is that the proposed method can combine the strengths of different SR methods to generate better results. Furthermore, we extend our method to multiple Rankers to provide multi-dimension constraints for the generator. Extensive experiments show that RankSRGAN achieves visually pleasing results and reaches state-of-the-art performance in perceptual metrics and quality. Project page: https://wenlongzhang0517.github.io/Projects/RankSRGAN.","1939-3539","","10.1109/TPAMI.2021.3096327","National Natural Science Foundation of China(grant numbers:61906184); Science and Technology Service Network Initiative of Chinese Academy of Sciences(grant numbers:KFJ-STS-QYZX-092); Shanghai Committee of Science and Technology, China(grant numbers:21DZ1100100); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9497054","Image super resolution;generative adversarial network;learning to rank","Measurement;Generative adversarial networks;Generators;Visualization;Superresolution;Feature extraction;Training","image resolution;learning (artificial intelligence);neural nets","single image super-resolution;visual quality;super-resolved results;PIRM2018-SR Challenge;perceptual quality;indifferentiable perceptual metrics;Super-Resolution Generative Adversarial Networks;RankSRGAN;SR methods;Super Resolution Generative Adversarial Networks;SISR;human ratings;multidimension constraints","Algorithms;Benchmarking;Humans;Image Processing, Computer-Assisted","9","","63","IEEE","26 Jul 2021","","","IEEE","IEEE Journals"
"Image Generation by Residual Block Based Generative Adversarial Networks","K. -H. Liu; C. -C. Lin; T. -J. Liu","National Taichung University of Science and Technology, Taichung, Taiwan; National Taichung University of Science and Technology, Taichung, Taiwan; National Chung Hsing University, Taichung, Taiwan","2022 IEEE International Conference on Consumer Electronics (ICCE)","15 Mar 2022","2022","","","1","4","Generative adversarial network is a popular deep learning technique for solving artificial intelligence tasks, and it has been widely studied and applied for processing images, voices, texts and so on. Especially, generative adversarial network is adopted in the field of image processing, such as image style transfer, image restoration, image super-resolution and so on. Although generative adversarial networks show remarkable success in image generation, training process is usually unstable and trained models collapse where many of the generated images may contain the same color or texture pattern. In this paper, the network of generator and discriminator are modified, and the residual block is added to the generative adversarial network architecture to learn better image features. To reduce the loss of image feature during training and get more features to stabilize image generation, we use feature matching to minimize feature loss between the real and generated images for stable training. In the experiment, performance improvement can be obtained by adopting our proposed method, which is also better than some state-of-the-art methods.","2158-4001","978-1-6654-4154-4","10.1109/ICCE53296.2022.9730533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9730533","Artificial intelligence;deep learning;image gen-eration;generative adversarial networks;residual block","Training;Image synthesis;Image color analysis;Superresolution;Learning (artificial intelligence);Generative adversarial networks;Generators","artificial intelligence;deep learning (artificial intelligence);feature extraction;image matching;image resolution;image restoration;image texture","real image generation;generative adversarial network architecture;image feature;image processing;image style;image restoration;image super-resolution;feature matching;artificial intelligence","","","","22","IEEE","15 Mar 2022","","","IEEE","IEEE Conferences"
"Video Quality Enhancement using Generative Adversarial Networks-based Super-Resolution and Noise Removal","M. Ahmad; M. Abdullah; D. Han","Sejong University, Seoul, South Korea; Sejong University, Seoul, South Korea; Sejong University, Seoul, South Korea","2021 36th International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC)","18 Oct 2021","2021","","","1","4","Video quality enhancement is a challenging task as it not only involves super-resolution but also there is underlying noise in most of the real-world videos recorded almost a decade ago. Existing literature focuses on image super-resolution-based methods which fail to deliver satisfactory results in real-world scenario due to lack of high-resolution and low-resolution pairs. We propose a method based on image translation methodology coupled with super-resolution architecture. This does not require high-resolution, low-resolution pair, and learns the underlying noise automatically, Furthermore, it can learn the style of a High-Definition video and apply it on a low-resolution video. We present qualitative results that show excellent performance on unseen dataset.","","978-1-6654-3553-6","10.1109/ITC-CSCC52171.2021.9568313","Rural Development Administration(grant numbers:PJ015686); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9568313","Super resolution;Noise removal;GAN","Computers;Superresolution;Computer architecture;Quality assessment;Task analysis;Video recording","image resolution;learning (artificial intelligence);video signal processing","video quality enhancement;underlying noise;real-world videos;image super-resolution-based methods;real-world scenario;low-resolution pair;image translation methodology;super-resolution architecture;High-Definition video;low-resolution video;generative adversarial networks-based super-resolution;noise removal","","","","19","IEEE","18 Oct 2021","","","IEEE","IEEE Conferences"
"An Approach To Super-Resolution Of Sentinel-2 Images Based On Generative Adversarial Networks","K. Zhang; G. Sumbul; B. Demir",Shanghai Jiao Tong University; Technische Universität Berlin; Technische Universität Berlin,"2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium (M2GARSS)","2 Jun 2020","2020","","","69","72","This paper presents a generative adversarial network based super-resolution (SR) approach (which is called as S2GAN) to enhance the spatial resolution of Sentinel-2 spectral bands. The proposed approach consists of two main steps. The first step aims to increase the spatial resolution of the bands with 20m and 60m spatial resolutions by the scaling factors of 2 and 6, respectively. To this end, we introduce a generator network that performs SR on the lower resolution bands with the guidance of the bands associated to 10m spatial resolution by utilizing the convolutional layers with residual connections and a long skip-connection between inputs and outputs. The second step aims to distinguish SR bands from their ground truth bands. This is achieved by the proposed discriminator network, which alternately characterizes the high level features of the two sets of bands and applying binary classification on the extracted features. Then, we formulate the adversarial learning of the generator and discriminator networks as a min-max game. In this learning procedure, the generator aims to produce realistic SR bands as much as possible so that the discriminator incorrectly classifies SR bands. Experimental results obtained on different Sentinel-2 images show the effectiveness of the proposed approach compared to both conventional and deep learning based SR approaches.","","978-1-7281-2190-1","10.1109/M2GARSS47143.2020.9105165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105165","Sentinel-2 images;super-resolution;generative adversarial network;remote sensing","Image color analysis;Superresolution;Neural networks;Geoscience and remote sensing;Games;Generative adversarial networks;Feature extraction","convolutional neural nets;feature extraction;game theory;geophysical image processing;image classification;image resolution;learning (artificial intelligence);minimax techniques","generative adversarial network;super-resolution approach;S2GAN;spatial resolution;Sentinel-2 spectral bands;generator network;lower resolution bands;ground truth bands;discriminator network;binary classification;adversarial learning;realistic SR bands;Sentinel-2 images;convolutional layers;feature extraction;min-max game;size 20.0 m;size 10.0 m;size 60.0 m","","3","","10","IEEE","2 Jun 2020","","","IEEE","IEEE Conferences"
"Improving resolution of images using Generative Adversarial Networks","S. Dhawan; S. Kumar","Dept. of Computer Science and Engineering, Delhi Technological University, Delhi, India; Dept. of Computer Science and Engineering, Delhi Technological University, Delhi, India","2020 4th International Conference on Electronics, Communication and Aerospace Technology (ICECA)","28 Dec 2020","2020","","","880","887","Even with all the achievements in precision and speed of various image super-resolution models, such as better and more accurate Convolutional Neural Networks (CNN), the results have not been satisfactory. The high-resolution images produced are generally missing the finer and frequent texture details. The majority of the models in this area focus on such objective functions which minimize the Mean Square Error (MSE). Although, this produces images with better Peak Signal to Noise Ratio (PSNR) such images are perceptually unsatisfying and lack the fidelity and high-frequency details when seen at a high-resolution. Generative Adversarial Networks (GAN), a deep learningmodel, can be usedfor such problems. In this article, the working of the GAN is shown and described about the production satisfying images with decent PSNR score as well as good Perceptual Index (P1) when compared to other models. In contrast to the existing Super Resolution GAN model, various modifications have been introduced to improve the quality of images, like replacing batch normalization layer with weight normalization layer, modified the dense residual block, taking features for comparison before they are fed in activation layer, using the concept of a relativistic discriminator instead of a normal discriminator that is used in vanilla GAN and finally, using Mean Absolute Error in the model.","","978-1-7281-6387-1","10.1109/ICECA49313.2020.9297414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9297414","Deep learning;Generative adversarial networks;Neural network;Image super resolution","Generative adversarial networks;Feature extraction;Generators;PSNR;Measurement;Interpolation;Distributed databases","convolutional neural nets;image resolution;image texture;mean square error methods","perceptual index;batch normalization layer;weight normalization layer;vanilla GAN;mean absolute error;improving resolution;generative Adversarial Networks;image super-resolution models;convolutional neural networks;high-resolution images;frequent texture details;objective functions;mean square error;high-frequency details;generative adversarial networks;decent PSNR score;finer texture details;MSE;peak signal to noise ratio;super resolution GAN model;activation layer;relativistic discriminator","","2","","46","IEEE","28 Dec 2020","","","IEEE","IEEE Conferences"
"Research on GAN-based Image Super-Resolution Method","X. Xue; X. Zhang; H. Li; W. Wang","College of Information Science and Technology, Northeast Normal University, Changchun, China; College of Information Science and Technology, Northeast Normal University, Changchun, China; College of Information Science and Technology, Northeast Normal University, Changchun, China; College of Information Science and Technology, Northeast Normal University, Changchun, China","2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)","1 Sep 2020","2020","","","602","605","Super-Resolution (SR) refers to the reconstruction of high-resolution image from low-resolution image, which has important application value in object detection, medical imaging, satellite remote sensing and other fields. In recent years, with the rapid development of deep learning, the image super-resolution reconstruction method based on deep learning has made remarkable progress. In this paper, R-SRGAN (Residual Super-Resolution Generative Adversarial Networks) is used to build the model and realize image super-resolution. By adding residual blocks between adjacent convolutional layers of the GAN generator, more detailed information is retained. At the same time, the Wassertein distance is used as a loss function to enhance the training effect and achieve image super-resolution.","","978-1-7281-7005-3","10.1109/ICAICA50127.2020.9182617","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9182617","Super-Resolution;Image Processing;Generative Adversarial Networks","Image resolution;Signal resolution;Training;Generative adversarial networks;Generators;Interpolation;Gallium nitride","image reconstruction;image resolution;learning (artificial intelligence);neural nets;object detection","deep learning;image superresolution reconstruction method;GAN-based image superresolution method;residual superresolution generative adversarial networks;R-SRGAN","","3","","17","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Images super-resolution using improved generative adversarial networks","Y. Hu; M. Jing; Y. Jiao; K. Sun","Shaanxi Provincial Key Lab of Oil and Gas Well Measurement and Control Technology, Xi'an, China; Shaanxi Provincial Key Lab of Oil and Gas Well Measurement and Control Technology, Xi'an, China; Shaanxi Provincial Key Lab of Oil and Gas Well Measurement and Control Technology, Xi'an, China; Shaanxi Provincial Key Lab of Oil and Gas Well Measurement and Control Technology, Xi'an, China","2021 3rd International Conference on Intelligent Control, Measurement and Signal Processing and Intelligent Oil Field (ICMSP)","20 Aug 2021","2021","","","254","258","Image super-resolution (ISR) is an important image processing technology to improve image resolution in computer vision tasks. The purpose of this paper is to study the super-resolution reconstruction of single image based on the depth learning method. Aiming at the problem that the existing pixel loss-based super-resolution image reconstruction algorithms have poor reconstruction effect on high-frequency details, such as textures, a lighter algorithm is proposed on the basis of the existing deep learning method (SRGAN). Firstly, the feedback structure is applied in the generator to process the feedback information and enhance the high frequency information of the image. Secondly, a general residual feature aggregation framework (RFA), is applied to make full use of the residual information of each layer to improve the quality of the SR image. Finally, the solution space of the function is further reduced and the image quality is improved by using a new loss function. The algorithms are implemented on pytorch framework. The experimental results on VOC2012 data sets show that, compared with the original SRGAN algorithm, the peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) of the proposed algorithm on the benchmark data set Set5 are improved by 0.83dB and 0.028, respectively, on Set14, the PSNR and SSIM of the proposed algorithm are improved by 0.56dB and 0.009, on Urban100, the PSNR and SSIM of the proposed algorithm are improved by 0.51dB and 0.031, on BSD100, the PSNR and SSIM of the proposed algorithm are improved by 0.33dB and 0.014, and compared with other improved algorithms, the effect of this algorithm is also better than other algorithms.","","978-1-6654-3715-8","10.1109/ICMSP53480.2021.9513225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9513225","image super-resolution;deep learning;convolutional neural networks (CNN);generative adversarial network (GAN);pytorch","PSNR;Superresolution;Neural networks;Signal processing algorithms;Predictive models;Prediction algorithms;Visual effects","computer vision;feature extraction;image reconstruction;image representation;image resolution;learning (artificial intelligence);neural nets","improved generative adversarial networks;image super-resolution;image processing technology;super-resolution reconstruction;single image;depth learning method;poor reconstruction effect;high-frequency details;lighter algorithm;deep learning method;high frequency information;general residual feature aggregation framework;SR image;image quality;original SRGAN algorithm;PSNR;structural similarity;pixel loss-based super-resolution image reconstruction algorithms","","","","23","IEEE","20 Aug 2021","","","IEEE","IEEE Conferences"
"Transfer-Gan: Multimodal Ct Image Super-Resolution Via Transfer Generative Adversarial Networks","Y. Xiao; K. R. Peters; W. C. Fox; J. H. Rees; D. A. Rajderkar; M. M. Arreola; I. Barreto; W. E. Bolch; R. Fang","Department of Biomedical Engineering, University of Florida, Gainesville, FL, USA; Department of Radiology, University of Florida, Gainesville, FL, USA; Department of Neurosurgery, University of Florida, Gainesville, FL, USA; Department of Radiology, University of Florida, Gainesville, FL, USA; Department of Radiology, University of Florida, Gainesville, FL, USA; Department of Radiology, University of Florida, Gainesville, FL, USA; Department of Radiology, University of Florida, Gainesville, FL, USA; Department of Biomedical Engineering, University of Florida, Gainesville, FL, USA; Department of Biomedical Engineering, University of Florida, Gainesville, FL, USA","2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)","22 May 2020","2020","","","195","198","Multimodal CT scans, including non-contrast CT, CT perfusion, and CT angiography, are widely used in acute stroke diagnosis and therapeutic planning. While each imaging modality has its advantage in brain cross-sectional feature visualizations, the varying image resolution of different modalities hinders the ability of the radiologist to discern consistent but subtle suspicious findings. Besides, higher image quality requires a high radiation dose, leading to increases in health risks such as cataract formation and cancer induction. In this work, we propose a deep learning-based method Transfer-GAN that utilizes generative adversarial networks and transfer learning to improve multimodal CT image resolution and to lower the necessary radiation exposure. Through extensive experiments, we demonstrate that transfer learning from multimodal CT provides substantial visualization and quantity enhancement compare to the training without learning the prior knowledge.","1945-8452","978-1-5386-9330-8","10.1109/ISBI45749.2020.9098322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098322","Image Super-Resolution;Multimodal CT;Transfer Learning;Generative Adversarial Network","Computed tomography;Image resolution;Visualization;Image quality;Gallium nitride;Reactive power;Training","brain;cancer;computerised tomography;diagnostic radiography;image resolution;learning (artificial intelligence);medical image processing","multimodal ct image super-resolution via Transfer generative adversarial;multimodal CT scans;noncontrast CT;CT perfusion;CT angiography;acute stroke diagnosis;imaging modality;brain cross-sectional feature visualizations;varying image resolution;consistent but subtle suspicious findings;higher image quality;deep learning-based method Transfer-GAN;generative adversarial networks;transfer learning;multimodal CT image resolution","","2","","13","IEEE","22 May 2020","","","IEEE","IEEE Conferences"
"Fine-Grained Attention and Feature-Sharing Generative Adversarial Networks for Single Image Super-Resolution","Y. Yan; C. Liu; C. Chen; X. Sun; L. Jin; X. Peng; X. Zhou","School of Software Engineering, South China University of Technology, Guangzhou, China; School of Software Engineering, South China University of Technology, Guangzhou, China; Department of Computer Science and Engineering, University at Buffalo, State University, New York, NY, USA; School of Computer Science, Informatics Cardiff University, U.K.; School of Software Engineering, South China University of Technology, Guangzhou, China; School of Software Engineering, South China University of Technology, Guangzhou, China; School of Data Science and Department of Mathematics at College of Science, City University of Hong Kong, Hong Kong","IEEE Transactions on Multimedia","29 Mar 2022","2022","24","","1473","1487","Traditional super-resolution (SR) methods by minimize the mean square error usually produce images with over-smoothed and blurry edges, due to the lack of high-frequency details. In this paper, we propose two novel techniques within the generative adversarial network framework to encourage generation of photo-realistic images for image super-resolution. Firstly, instead of producing a single score to discriminate real and fake images, we propose a variant, called Fine-grained Attention Generative Adversarial Network (FASRGAN), to discriminate each pixel of real and fake images. FASRGAN adopts a UNet-like network as the discriminator with two outputs: an image score and an image score map. The score map has the same spatial size as the HR/SR images, serving as the fine-grained attention to represent the degree of reconstruction difficulty for each pixel. Secondly, instead of using different networks for the generator and the discriminator, we introduce a feature-sharing variant (denoted as Fs-SRGAN) for both the generator and the discriminator. The sharing mechanism can maintain model express power while making the model more compact, and thus can improve the ability of producing high-quality images. Quantitative and visual comparisons with state-of-the-art methods on benchmark datasets demonstrate the superiority of our methods. We further apply our super-resolution images for object recognition, which further demonstrates the effectiveness of our proposed method. The code is available at https://github.com/Rainyfish/FASRGAN-and-Fs-SRGAN.","1941-0077","","10.1109/TMM.2021.3065731","Pearl River Technology Nova Project(grant numbers:201710010020); National Natural Science Foundation of China(grant numbers:61300135); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377002","Feature-sharing;fine-grained attention;generative adversarial network;image super-resolution","Generators;Feature extraction;Superresolution;Gallium nitride;Generative adversarial networks;Image reconstruction;Standards","image reconstruction;image resolution;neural nets;object recognition;realistic images","feature-sharing variant;sharing mechanism;high-quality images;super-resolution images;fine-grained attention;single image super-resolution;traditional super-resolution methods;mean square error;high-frequency details;generative adversarial network framework;photo-realistic images;single score;fake images;attention generative adversarial network;FASRGAN;UNet-like network;image score map;feature-sharing generative adversarial networks;HR-SR images;object recognition","","6","","51","IEEE","12 Mar 2021","","","IEEE","IEEE Journals"
"Ship Deck Segmentation In Engineering Document Using Generative Adversarial Networks","M. S. Uddin; R. Pamie-George; D. Wilkins; A. Sousa-Poza; M. Canan; S. Kovacic; J. Li","Depanment of Electrical and Computer Engineering, Old Dominion University, Norfolk, Virginia, USA; Depanment of Electrical and Computer Engineering, Old Dominion University, Norfolk, Virginia, USA; Depanment of Electrical and Computer Engineering, Old Dominion University, Norfolk, Virginia, USA; Departmentt of Engineering Management & Systems Engineering, Old Dominion University, Norfolk, Virginia, USA; Department of Information Sciences, Naval Postgraduate School, Monterey, California, USA; Departmentt of Engineering Management & Systems Engineering, Old Dominion University, Norfolk, Virginia, USA; Depanment of Electrical and Computer Engineering, Old Dominion University, Norfolk, Virginia, USA","2022 IEEE World AI IoT Congress (AIIoT)","13 Jul 2022","2022","","","207","212","Generative adversarial networks (GANs) have become very popular in recent years. GANs have proved to be successful in different computer vision tasks including image-translation, image super-resolution etc. In this paper, we have used GAN models for ship deck segmentation. We have used 2D scanned raster images of ship decks provided by US Navy Military Sealift Command (MSC) to extract necessary information including ship walls, objects etc. Our segmentation results will be helpful to get vector and 3D image of a ship that can be later used for maintenance of the ship. We applied the trained models to engineering documents provided by MSC and obtained very promising results, demonstrating that GANs can be potentially good candidates for this research area.","","978-1-6654-8453-4","10.1109/AIIoT54504.2022.9817355","U.S. Department of Defense(grant numbers:SERC WRT-1045,HQ0034-13-D-0004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817355","GAN;Pix2Pix GAN;ship deck segmentation","Training;Image segmentation;Three-dimensional displays;Superresolution;Training data;Generative adversarial networks;Data models","computer vision;image resolution;image segmentation;military computing;military vehicles;naval engineering computing;neural nets;ships","GANs;ship deck segmentation;engineering document;generative adversarial networks;computer vision tasks;image super-resolution;GAN models;raster images;ship decks;US Navy Military Sealift Command;ship walls;image translation","","2","","18","USGov","13 Jul 2022","","","IEEE","IEEE Conferences"
"ID Preserving Face Super-Resolution Generative Adversarial Networks","J. Li; Y. Zhou; J. Ding; C. Chen; X. Yang","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science, National University of Singapore, Singapore; Department of Electronic Engineering, School of Information Science and Engineering, Fudan University, Shanghai, China; Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore; Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore","IEEE Access","4 Aug 2020","2020","8","","138373","138381","We propose an ID Preserving Face Super-Resolution Generative Adversarial Networks (IP-FSRGAN) to reconstruct realistic super-resolution face images from low-resolution ones. Inspired by the success of generative adversarial networks (GAN), we introduce a novel ID preserving module to help the generator learn to infer the facial details and synthesize more realistic super-resolution faces. Our method produces satisfactory visual results and also quantitatively outperforms state-of-the-art super-resolution methods on the face datasets including CASIA-Webface, CelebA, and LFW datasets under the metrics of PSNR, SSIM, and cosine similarity. In addition, we propose a framework to apply IP-FSRGAN model to address the face verification task on low-resolution face images. The synthesized  $4\times $  super-resolution faces achieve a verification accuracy of 97.6%, improved from 92.8% of low resolution faces. We also prove by experiments that the proposed IP-FSRGAN model demonstrates excellent robustness under different downsample scaling factors and extensibility to various face verification models.","2169-3536","","10.1109/ACCESS.2020.3011699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146819","ID preserving;face super-resolution;generative adversarial networks;face verification","Face;Image resolution;Gallium nitride;Task analysis;Face recognition;Feature extraction;Image reconstruction","face recognition;feature extraction;image reconstruction;image resolution;neural nets","face datasets;IP-FSRGAN model;face verification task;low-resolution face images;face verification models;synthesized super-resolution faces;ID preserving module;ID preserving face super-resolution generative adversarial networks;IP-FSRGAN;realistic super-resolution face image reconstruction;satisfactory visual results;CASIA-Webface dataset;CelebA dataset;LFW dataset;SNR similarity;SSIM similarity;cosine similarity;downsample scaling factors","","2","","33","CCBY","24 Jul 2020","","","IEEE","IEEE Journals"
"Optimizing Generative Adversarial Networks for Low-Resolution Image Enhancement","J. Hall; M. G. Bocanegra; R. J. Haddad","Department of Electrical and Computer Engineering, Georgia Southern University, Statesboro, United States; Department of Electrical and Computer Engineering, Georgia Southern University, Statesboro, United States; Department of Electrical and Computer Engineering, Georgia Southern University, Statesboro, United States","2020 SoutheastCon","25 Mar 2021","2020","2","","1","6","Current high-resolution camera and video systems require expensively complex equipment and an excessive amount of digital storage to function, effectively limiting their practicality and availability. The research seeks to address this issue by optimizing Generative Adversarial Networks (GANs) for image super-resolution using an evolutionary-based scheme for successive network modification. The capability of GANs to selectively enhance the resolution of a desired image without increasing costs is extremely significant for a substantial range of industries and practices. The network's capabilities are expressed in terms of produced image quality and network metrics, with preference given to increases in image quality. Using the DIV2K dataset as common input, the highest performing network achieved a comparative increase of 2.22 dB PSNR (29.1%) over the base model, the Super-Resolution Generative Adversarial Network (SRGAN). The most notable contribution to network enhancement with regards to image quality was caused by removing the batch normalization layers from the Generator network. Network performance with regards to subjective image quality was most affected by the inclusion of a second convolutional layer in each residual block of the modified SRGAN Generator. Possible applications of the improved system include enhancing images of license plates for traffic monitoring systems and improving still images from body camera footage to reveal crucial details. Beyond the scope of surveillance, resolution-enhancing GANs may be applied to develop media content or national defense capabilities.","1558-058X","978-1-7281-6861-6","10.1109/SoutheastCon44009.2020.9368265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9368265","GAN;SRGAN;Optimization;Super Resolution;Image Enhancement;Network Architecture;PSNR;SSIM;Deep Learning;Training Parameters;DIV2K;Pytorch","Image quality;Surveillance;Superresolution;Generative adversarial networks;Cameras;Generators;Image enhancement","image enhancement;image resolution;neural nets;video signal processing","video systems;image super-resolution;network metrics;comparative increase;super-resolution generative adversarial network;network enhancement;subjective image quality;low-resolution image enhancement;SRGAN generator;resolution-enhancing GAN;DIV2K dataset","","","","12","IEEE","25 Mar 2021","","","IEEE","IEEE Conferences"
"Anisotropic Super Resolution In Prostate Mri Using Super Resolution Generative Adversarial Networks","R. Sood; M. Rusu","Electrical Engineering, Stanford University; Radiology, Stanford University","2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)","11 Jul 2019","2019","","","1688","1691","Acquiring High Resolution (HR) Magnetic Resonance (MR) images requires the patient to remain still for long periods of time, which causes patient discomfort and increases the probability of motion induced image artifacts. A possible solution is to acquire low resolution (LR) images and to process them with the Super Resolution Generative Adversarial Network (SRGAN) to create a super-resolved version. This work applies SRGAN to MR images of the prostate and performs three experiments. The first experiment explores improving the in-plane MR image resolution by factors of 4 and 8, and shows that, while the PSNR and SSIM (Structural SIMilarity) metrics are lower than the isotropic bicubic interpolation baseline, the SRGAN is able to create images that have high edge fidelity. The second experiment explores anisotropic super-resolution via synthetic images, in that the input images to the network are anisotropically downsampled versions of HR images. This experiment demonstrates the ability of the modified SRGAN to perform anisotropic super-resolution, with quantitative image metrics that are comparable to those of the anisotropic bicubic interpolation baseline. Finally, the third experiment applies a modified version of the SRGAN to super-resolve anisotropic images obtained from the through-plane slices of the volumetric MR data. The output super-resolved images contain a significant amount of high frequency information that make them visually close to their HR counterparts. Overall, the promising results from each experiment show that super-resolution for MR images is a successful technique and that producing isotropic MR image volumes from anisotropic slices is an achievable goal.","1945-8452","978-1-5386-3641-1","10.1109/ISBI.2019.8759237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759237","Magnetic Resonance Imaging;Machine Learning;Super Resolution;Generative Networks;Anisotropic","Image resolution;Interpolation;Image edge detection;Magnetic resonance imaging;Biomedical imaging;Generators;Three-dimensional displays","biomedical MRI;image reconstruction;image resolution;interpolation;medical image processing","in-plane MR image resolution;synthetic images;input images;HR images;anisotropic super-resolution;quantitative image metrics;anisotropic bicubic interpolation baseline;super-resolve anisotropic images;output super-resolved images;isotropic MR image volumes;motion induced image artifacts;high-resolution magnetic resonance images;low-resolution images;super resolution generative adversarial network;anisotropic super resolution;SRGAN images","","7","","13","IEEE","11 Jul 2019","","","IEEE","IEEE Conferences"
"MRI Super-Resolution using Generative Adversarial Network and Discrete Wavelet Transform","A. Balasubramanian; H. Dhanasekaran; B. Raghu; K. Kumarasamy","Department of Computer Science, Loyola-ICAM College of Engineering and Technology, Chennai, India; Department of Computer Science, Loyola-ICAM College of Engineering and Technology, Chennai, India; Department of Electronics and Communication Engineering, Loyola-ICAM College of Engineering and Technology, Chennai, India; Department of Electronics and Communication Engineering, Loyola-ICAM College of Engineering and Technology, Chennai, India","2022 International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)","16 Jan 2023","2022","","","1314","1318","Deep Learning Approaches have brought in major advances in super-resolution. Deep Learning architectures like convolutional neural networks or auto-encoders are trained to beget high-resolution (HR) images from the low-resolution (LR) images. Discrete wavelet transformations (DWT) is used to bring out the high frequency (HF) sub-bands of the image, which is further used to reduce the error while synthesizing super-resolution images. The proposed architecture combines the features generated by the DWT and Super-Resolution Generative Adversarial Networks (SRGAN) to produce images of high resolution. The implemented topology initially applies DWT to the image and separates out the image into two fundamental bands (HF and LF sub-bands). The features are then generated by separate generators and then Combined by inverse 2d discrete wavelet transformation (IDWT) which is then passed on to the discriminator to evaluate the generated image. A key feature of this design is that each feature is given importance and is generated by separate generators which makes the reconstruction and improvising the quality of the image more feasible. From the experiments conducted on medical images such as magnetic resonance imaging (MRI), the proposed design is computationally simpler and yet produces competitive and often improved results than state-of-the-art alternatives in terms of peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM).","","978-1-6654-8962-1","10.1109/ICAISS55157.2022.10010995","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10010995","Biomedical image processing;Image Super-resolution;Generative adversarial network","Visualization;PSNR;Magnetic resonance imaging;Superresolution;Transforms;Generative adversarial networks;Generators","biomedical MRI;convolutional neural nets;discrete wavelet transforms;image coding;image reconstruction;image representation;image resolution;learning (artificial intelligence);medical image processing","autoencoders;convolutional neural networks;deep learning approaches;discrete wavelet transform;DWT;fundamental bands;generative adversarial network;high frequency sub-bands;high-resolution images;inverse 2d discrete wavelet transformation;low frequency sub-bands;low-resolution images;magnetic resonance imaging;MRI super-resolution;peak signal-to-noise ratio;super-resolution generative adversarial networks;super-resolution images","","","","20","IEEE","16 Jan 2023","","","IEEE","IEEE Conferences"
"Super-Resolution of Thermal Images Using GAN Network","S. Deepak; S. Sahoo; D. Patra","Dept. Of Electrical Engineering, NIT, Rourkela, INDIA; Dept. Of Electrical Engineering, NIT, Rourkela, INDIA; Dept. Of Electrical Engineering, NIT, Rourkela, INDIA","2021 Advanced Communication Technologies and Signal Processing (ACTS)","17 Feb 2022","2021","","","1","5","Super-resolution (SR) reconstruction of thermal images has been one of the most active research areas specifically for industrial applications. However, most of the conventional RGB SR models available in the literature are not necessarily applicable to thermal images due to their difference in characteristics when compared to normal camera images. The recent advancement in the field of deep learning-based SR has helped achieve unbelievable results. Despite the advancement in models like deep convolution neural networks (CNN) and Generative adversarial networks, there remain multiple problems unsolved that will help improve the spatial resolution of thermal images. Not only the developed model should be computationally efficient but also easily implementable in industrial applications. Motivated to overcome the said limitations, in this work a generative adversarial network (GAN) based single images super-resolution architecture is proposed for thermal camera images. The developed model not only generates at par results with the other model but also is easy to implement and computationally efficient. The modified architecture has an identical layout inspired by SRGAN. In order to make the model faster to train while having less training parameters, the number of residual blocks was reduced to 5. The batch normalization layers were excluded from the residual blocks of both the Generator and Discriminator networks to remove the redundancy. Before each convolution layer, reflective padding is utilized at the edges to preserve the size of the feature maps. The comparative results revealed that the proposed network trained on thermal images produced high-quality images with enhanced details, while still maintaining image features and perspective throughout. The experimental results show that the proposed model has achieved a reduction in computation time compared to the State-of-the-Art method. The suggested strategy has outperformed the SOTA methods with the improvement of approximately 2dB in PSNR along with 0.9825 of SSIM.","","978-1-6654-2337-3","10.1109/ACTS53447.2021.9708340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9708340","Super Resolution;Thermal Images;Generative Adversarial Networks","Training;Convolution;Computational modeling;Superresolution;Computer architecture;Generative adversarial networks;Cameras","convolutional neural nets;deep learning (artificial intelligence);image colour analysis;image reconstruction;image resolution;infrared imaging","GAN;thermal camera image super resolution reconstruction;industrial applications;deep learning-based SR;deep convolution neural networks;generative adversarial network;thermal camera image SR reconstruction;RGB SR;deep CNN;generator network;discriminator network;computational time","","","","12","IEEE","17 Feb 2022","","","IEEE","IEEE Conferences"
"TAGAN: Texture and Attention Guided Generative Adversarial Network for Image Super Resolution","H. Wang; J. Sun; W. Diao; J. Li; K. Zhang","School of Information science and Engineering, Shandong Normal University, Jinan, China; School of Information science and Engineering, Shandong Normal University, Jinan, China; School of Information science and Engineering, Shandong Normal University, Jinan, China; School of Journalism and Communication, Shandong Normal University, Jinan, China; School of Information science and Engineering, Shandong Normal University, Jinan, China","2022 IEEE International Symposium on Circuits and Systems (ISCAS)","11 Nov 2022","2022","","","1","5","Super Resolution (SR) methods based on Generative Adversarial Networks (GANs) accomplish predominant execution in visual perception and image quality. These methods are mainly generated by traditional Peak-Signal-to-Noise-Ratio (PSNR)oriented or perceptual-driven. As the reconstruction process usually loses high frequency information, various methods aim to preserve more details. To make the details of the generated image richer, the Gradient Weight (GW) loss is introduced in the proposed method, because the gradient can reflect the texture of the image to a certain extent. The GW loss function is helpful to improve the edge and detailed texture of the generated image. Furthermore, we introduce attention mechanism to the image reconstruction block via Squeeze and Excitation Net (SENet). Attention mechanism can effectively aggregate the global features obtained by the nonlinear mapping network, and improve the channel sensitivity of the model. With the help of GW and attention mechanism, the proposed method can achieve better performance and visual quality in image texture detail restoration. The performance comparison between the state-of-the-art methods and our proposed method verifies the feasibility and reliability of the proposed method.","2158-1525","978-1-6654-8485-5","10.1109/ISCAS48785.2022.9937622","Natural Science Foundation of Shandong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9937622","Single Image Super Resolution;Generative Adversarial Networks;Attention Mechanism;Gradient Weight","Image quality;Visualization;Image texture;Image resolution;Sensitivity;Generative adversarial networks;Image restoration","gradient methods;image reconstruction;image resolution;image restoration;image texture;neural nets;visual perception","image super resolution;visual perception;GW loss function;attention mechanism;image reconstruction block;nonlinear mapping network;visual quality;TAGAN;texture and attention guided generative adversarial network;image texture detail restoration;gradient weight loss function;squeeze and excitation net;SENet","","","","25","IEEE","11 Nov 2022","","","IEEE","IEEE Conferences"
"Multiple Cycle-in-Cycle Generative Adversarial Networks for Unsupervised Image Super-Resolution","Y. Zhang; S. Liu; C. Dong; X. Zhang; Y. Yuan","Graduate School at Shenzhen, Tsinghua University, Shenzhen, China; Department of Automation, Tsinghua University, Beijing, China; Shenzhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; School of Computer Science and Technology, University of the Chinese Academy of Sciences, Beijing, China; National Engineering Laboratory for Big Data System Computing Technology, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Image Processing","4 Nov 2019","2020","29","","1101","1112","With the help of convolutional neural networks (CNN), the single image super-resolution problem has been widely studied. Most of these CNN based methods focus on learning a model to map a low-resolution (LR) image to a highresolution (HR) image, where the LR image is downsampled from the HR image with a known model. However, in a more general case when the process of the down-sampling is unknown and the LR input is degraded by noises and blurring, it is difficult to acquire the LR and HR image pairs for traditional supervised learning. Inspired by the recent unsupervised imagestyle translation applications using unpaired data, we propose a multiple Cycle-in-Cycle network structure to deal with the more general case using multiple generative adversarial networks (GAN) as the basis components. The first network cycle aims at mapping the noisy and blurry LR input to a noise-free LR space, then a new cycle with a well-trained x2 network model is orderly introduced to super-resolve the intermediate output of the former cycle. The number of total cycles depends on the different up-sampling factors (x2, x4, x8). Finally, all modules are trained in an end-to-end manner to get the desired HR output. Quantitative indexes and qualitative results show that our proposed method achieves comparable performance with the state-of-the-art supervised models.","1941-0042","","10.1109/TIP.2019.2938347","National Natural Science Foundation of China(grant numbers:61571254); Natural Science Foundation of Guangdong Province(grant numbers:2017A030313353); Shenzhen Fundamental Research Fund(grant numbers:JCYJ20170817161409809); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8825849","Super resolution;unsupervised learning;generative adversarial networks","Training;Kernel;Degradation;Interpolation;Deep learning","convolutional neural nets;image resolution;image restoration;learning (artificial intelligence)","image blurring;supervised learning;multiple generative adversarial networks;noise-free LR space;cycle-in-cycle generative adversarial networks;unsupervised image super-resolution;convolutional neural networks;multiple cycle-in-cycle network structure","","42","","51","IEEE","5 Sep 2019","","","IEEE","IEEE Journals"
"DPSRGAN: Dilation Patch Super-Resolution Generative Adversarial Networks","K. Mirchandani; K. Chordiya","Department of Electronics and Telecommunication Engineering, Pune Institute of Computer Technology, Pune, India; Department of Computer Engineering, Pune Institute of Computer Technology, Pune, India","2021 6th International Conference for Convergence in Technology (I2CT)","10 May 2021","2021","","","1","7","Single Image Super-Resolution (SISR) has proven itself as a highly challenging and ill-posed problem. Multiple methods have been applied to this problem in the past, with varying degrees of success. Recently, methods using deep learning such as Generative Adversarial Networks (GAN) and Variational Auto-Encoders (VAE) in particular have proven to be extremely effective. However, most of the present methods either create a blurry output, lacking fine details, or use extremely heavy models to achieve better results. We introduce a novel, lightweight GAN architecture for 4× super-resolution of images, which builds on previous methods, showing high quality of features both qualitatively and quantitatively. To achieve this, we use dilated convolutions in our generator architecture, a Markovian discriminator, a modified loss function and a training process more typical of a conditional GAN (cGAN). For testing our results qualitatively, we use Mean Opinion Score (MOS). The obtained MOS show the effectiveness of our model at generating visually superior images. Our code is available at https://www.github.com/kushalchordiya216/Super-Resolution.","","978-1-7281-8876-8","10.1109/I2CT51068.2021.9417903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417903","Super-Resolution;Generative Adversarial Network;SRGAN","Training;Measurement;Deep learning;Convolutional codes;Superresolution;Benchmark testing;Generative adversarial networks","deep learning (artificial intelligence);feature extraction;image resolution;image restoration;Markov processes;neural net architecture","single image super resolution;deep learning;lightweight GAN architecture;dilated convolutions;conditional GAN;dilation patch super resolution generative adversarial networks;DPSRGAN;variational autoencoders;image resolution;Markovian discriminator","","","","31","IEEE","10 May 2021","","","IEEE","IEEE Conferences"
"Deep Learning Super Resolution of Sea Surface Temperature on South China Sea","J. J. D. Khoo; K. H. Lim; P. K. Pang","Department of Electrical and Computer Engineering, Curtin University Malaysia CDT 250, Miri, Malaysia; Department of Electrical and Computer Engineering, Curtin University Malaysia CDT 250, Miri, Malaysia; Department of Electrical and Computer Engineering, Curtin University Malaysia CDT 250, Miri, Malaysia","2022 International Conference on Green Energy, Computing and Sustainable Technology (GECOST)","12 Jan 2023","2022","","","176","180","Surface temperature is one of the key observations to analyse the greenhouse effect on the Earth. The surface of the ocean can be captured using satellite sensors and transmitted to a meteorological center for real-time analysis. The use of the deep learning paradigm in super resolution has its potential in geoscience applications to increase the data transmission latency and enhance low-quality observation from remote sensing data. In this paper, the deployment of Generative Adversarial Network (GAN) architecture is studied to apply resolution reconstruction using the South China Sea sea surface temperature data. In addition, the development of spectral normalization is added to the Enhanced Super Resolution Generative Adversarial Network (ESRGAN) architecture to improve the training mechanism of generator and discriminator. This improved ESRGAN is compared with its super resolution performance against peak signal-to-noise ratio and structural similarity index evaluation metrics. The experiment shows that the low resolution of South China Sea data can be inferred to obtain a higher resolution with a more realistic resolution as compared to the conventional upsampling approaches.","","978-1-6654-8663-7","10.1109/GECOST55694.2022.10010371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10010371","Sea Surface Temperature;Deep Learning;Super Resolution;Generative Adversarial Networks","Temperature sensors;Deep learning;Sea surface;Temperature distribution;Surface reconstruction;Computer architecture;Generative adversarial networks","image enhancement;image reconstruction;image resolution;learning (artificial intelligence);ocean temperature;oceanographic regions;oceanographic techniques;remote sensing","data transmission;deep learning paradigm;Enhanced Super Resolution Generative Adversarial Network architecture;greenhouse effect;key observations;low-quality observation;realistic resolution;remote sensing data;resolution reconstruction;South China Sea data;South China Sea sea surface temperature data;super resolution performance","","","","23","IEEE","12 Jan 2023","","","IEEE","IEEE Conferences"
"Gan-Based Video Super-Resolution With Direct Regularized Inversion of the Low-Resolution Formation Model","S. Lopez-Tapia; A. Lucas; R. Molina; A. K. Katsaggelos","Dpto. de Ciencias de la Computación e Inteligencia Artificial, Universidad de Granada, Granada, Spain; Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Dpto. de Ciencias de la Computación e Inteligencia Artificial, Universidad de Granada, Granada, Spain; Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA","2019 IEEE International Conference on Image Processing (ICIP)","26 Aug 2019","2019","","","2886","2890","While high and ultra high definition displays are becoming popular, most of the available content has been acquired at much lower resolutions. In this work we propose to pseudo-invert with regularization the image formation model using GANs and perceptual losses. Our model, which does not require the use of motion compensation, utilizes explicitly the low resolution image formation model and additionally introduces two feature losses which are used to obtain perceptually improved high resolution images. The experimental validation shows that our approach outperforms current video super resolution learning based models.","2381-8549","978-1-5386-6249-6","10.1109/ICIP.2019.8803709","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8803709","Video;Super-resolution;Convolutional Neuronal Networks;Generative Adversarial Networks;Perceptual Loss Functions","Image resolution;Training;Gallium nitride;Generators;Generative adversarial networks;Video sequences;Adaptation models","image resolution;learning (artificial intelligence);motion compensation;neural net architecture;video signal processing","video super resolution;perceptually improved high resolution images;feature losses;low resolution image formation model;perceptual losses;GAN;available content;ultra high definition displays;low-resolution formation model;direct regularized inversion;gan-based video super-resolution","","1","","19","IEEE","26 Aug 2019","","","IEEE","IEEE Conferences"
"Tile Art Image Generation Using Conditional Generative Adversarial Networks","N. Matsumura; H. Tokura; Y. Kuroda; Y. Ito; K. Nakano","Department of Information Engineering, Hiroshima University, Higashi-Hiroshima, 739-8527, Japan; Department of Information Engineering, Hiroshima University, Higashi-Hiroshima, 739-8527, Japan; Department of Information Engineering, Hiroshima University, Higashi-Hiroshima, 739-8527, Japan; Department of Information Engineering, Hiroshima University, Higashi-Hiroshima, 739-8527, Japan; Department of Information Engineering, Hiroshima University, Higashi-Hiroshima, 739-8527, Japan","2018 Sixth International Symposium on Computing and Networking Workshops (CANDARW)","27 Dec 2018","2018","","","209","215","Image-to-image translation is a task of mapping an image in one domain to a corresponding image in another domain. The task includes various types of problems such as super-resolution, colorization, and artistic style transfer. In recent years, with the advent of deep learning, the technology has been rapidly advanced. The main purpose of this paper is to propose a tile art image generation method using machine learning approach based on conditional generative adversarial networks. To make the training data set of tile art images, we adopted a square-pointillism image generation method using the greedy approach. After training, the proposed network can generate tile art images that have the structure of tiles and reproduce the original images well. As regards generating time, the greedy approach takes 1322 seconds to generate tile art image of size 4096×3072, while the proposed machine learning approach takes 0.593 seconds.","","978-1-5386-9184-7","10.1109/CANDARW.2018.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8590901","tile art;machine learning;image-to-image translation;conditional GAN","Art;Image generation;Generators;Gallium nitride;Training;Machine learning;Generative adversarial networks","approximation theory;art;Gaussian distribution;greedy algorithms;image colour analysis;image resolution;learning (artificial intelligence)","tile art image generation method;machine learning approach;conditional generative adversarial networks;square-pointillism image generation method;image-to-image translation;deep learning;training data set;greedy approach","","11","","21","IEEE","27 Dec 2018","","","IEEE","IEEE Conferences"
"DepthwiseGANs: Fast Training Generative Adversarial Networks for Realistic Image Synthesis","M. Ngxande; J. -R. Tapamo; M. Burke","CSIR Defence, Peace, Safety and Security, Optronic Sensor Systems, Pretoria, South Africa; School of Computer Engineering, University of Kwa-Zulu Natal, Durban, South Africa; Mobile Intelligent Autonomous Systems, Council for Scientific and Industrial Research, Pretoria, South Africa","2019 Southern African Universities Power Engineering Conference/Robotics and Mechatronics/Pattern Recognition Association of South Africa (SAUPEC/RobMech/PRASA)","2 May 2019","2019","","","111","116","Recent work has shown significant progress in the direction of synthetic data generation using Generative Adversarial Networks (GANs). GANs have been applied in many fields of computer vision including text-to-image conversion, domain transfer, super-resolution, and image-to-video applications. In computer vision, traditional GANs are based on deep convolutional neural networks. However, deep convolutional neural networks can require extensive computational resources because they are based on multiple operations performed by convolutional layers, which can consist of millions of trainable parameters. Training a GAN model can be difficult and it takes a significant amount of time to reach an equilibrium point In this paper, we investigate the use of depthwise separable convolutions to reduce training time while maintaining data generation performance. Our results show that a DepthwiseGAN architecture can generate realistic images in shorter training periods when compared to a StarGan architecture, but that model capacity still plays a significant role in generative modelling. In addition, we show that depthwise separable convolutions perform best when only applied to the generator. For quality evaluation of generated images, we use the Fréchet Inception Distance (FID), which compares the similarity between the generated image distribution and that of the training dataset.","","978-1-7281-0369-3","10.1109/RoboMech.2019.8704766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8704766","Synthetic Data;GANs;Depthwise Separable Convolution;FID","Generators;Training;Face;Generative adversarial networks;Computational modeling;Computer architecture","computer vision;convolutional neural nets;realistic images","realistic image synthesis;synthetic data generation;image-to-video applications;deep convolutional neural networks;convolutional layers;GAN model;depthwise separable convolutions;data generation performance;realistic images;generative modelling;generated images;generated image distribution;generative adversarial networks;computer vision;depthwiseGAN architecture;text-to-image conversion","","3","","31","IEEE","2 May 2019","","","IEEE","IEEE Conferences"
"Deep EEG super-resolution: Upsampling EEG spatial resolution with Generative Adversarial Networks","I. A. Corley; Y. Huang","Engineer at Southwest Research Institute (SwRI), the University of Texas at San Antonio, San Antonio, TX, USA; Department of Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, TX, USA","2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)","9 Apr 2018","2018","","","100","103","Electroencephalography (EEG) activity contains a wealth of information about what is happening within the human brain. Recording more of this data has the potential to unlock endless future applications. However, the cost of EEG hardware is increasingly expensive based upon the number of EEG channels being recorded simultaneously. We combat this problem in this paper by proposing a novel deep EEG super-resolution (SR) approach based on Generative Adversarial Networks (GANs). This approach can produce high spatial resolution EEG data from low resolution samples, by generating channel-wise upsampled data to effectively interpolate numerous missing channels, thus reducing the need for expensive EEG equipment. We tested the performance using an EEG dataset from a mental imagery task. Our proposed GAN model provided ~104 fold and ~102 fold reduction in mean-squared error (MSE) and mean-absolute error (MAE), respectively, over the baseline bicubic interpolation method. We further validate our method by training a classifier on the original classification task, which displayed minimal loss in accuracy while using the super-resolved data. The proposed SR EEG by GAN is a promising approach to improve the spatial resolution of low density EEG headset.","","978-1-5386-2405-0","10.1109/BHI.2018.8333379","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8333379","","Electroencephalography;Generators;Gallium nitride;Brain modeling;Convolution;Training;Spatial resolution","brain;electroencephalography;image resolution;interpolation;mean square error methods;medical image processing","generative adversarial networks;channel-wise upsampled data;mental imagery task;GAN model;mean-squared error;mean-absolute error;baseline bicubic interpolation method;EEG spatial resolution;electroencephalography activity;human brain;EEG equipment;deep EEG super-resolution approach","","26","","20","IEEE","9 Apr 2018","","","IEEE","IEEE Conferences"
"Generative Adversarial Networks for Spectral Super-Resolution and Bidirectional RGB-To-Multispectral Mapping","K. G. Lore; K. K. Reddy; M. Giering; E. A. Bernal","United Technologies Research Center, E. Hartford, CT; United Technologies Research Center, E. Hartford, CT; United Technologies Research Center, E. Hartford, CT; University of Rochester, Rochester, NY","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","9 Apr 2020","2019","","","926","933","Acquisition of multi-and hyperspectral imagery imposes significant requirements on the hardware capabilities of the sensors involved. In order to keep costs manageable, and due to limitations in the sensing technology, tradeoffs between the spectral and the spatial resolution of hyperspectral images are usually made. Such tradeoffs are usually not necessary when considering acquisition of traditional RGB imagery. We investigate the use of statistical learning, and in particular, of conditional generative adversarial networks (cGANs) to estimate mappings from three-channel RGB to 31-band multispectral imagery. We demonstrate the application of the proposed approach to (i) RGB-to-multispectral image mapping, (ii) spectral super-resolution of image data, and (iii) recovery of RGB imagery from multispectral data.","2160-7516","978-1-7281-2506-0","10.1109/CVPRW.2019.00122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9025450","","Spatial resolution;Image reconstruction;Task analysis;Training;Hyperspectral imaging","geophysical image processing;hyperspectral imaging;image colour analysis;image resolution;image sensors;remote sensing;spectral analysis","sensing technology;hardware capabilities;significant requirements;hyperspectral imagery;Bidirectional RGB-To-Multispectral;multispectral data;spectral super-resolution;RGB-to-multispectral image mapping;31-band multispectral imagery;three-channel RGB;conditional generative adversarial networks;traditional RGB imagery;considering acquisition;hyperspectral images;spatial resolution","","10","","30","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"Infrared Image Super Resolution with Deep Neural Networks","K. Vassilo; T. Taha; A. Mehmood","University of Dayton, Dayton, OH; University of Dayton, Dayton, OH; Air Force Research Laboratory, Wright-Patterson AFB, OH","2021 11th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)","19 Jul 2021","2021","","","1","5","Recent studies have shown that Deep Learning (DL) algorithms can significantly improve Super Resolution (SR) performance. Single image SR is useful in producing High Resolution (HR) images from their Low Resolution (LR) counterparts. The motivation for SR is the potential to assist algorithms such as object detection, localization, and classification. Insufficient work has been conducted using Generative Adversarial Networks (GANs) for SR on infrared (IR) images despite its promising ability to increase object detection accuracy by extracting more precise features from a given image. This work adopts the idea of a relativistic GAN that utilizes Residual in Residual Dense blocks (RRDBs) for feature ex- traction, a novel residual image addition, and a Pixel Transposed Convolutional Layer (PixelTCL) for up-sampling. Recent work has validated the use of GANs for Visible Light (VL) images, making them a strong candidate. The inclusion of these components produce more realistic and natural features while also receiving superior metric values.","2158-6276","978-1-6654-3601-4","10.1109/WHISPERS52202.2021.9484045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9484045","Deep Learning;Super Resolution;Generative Adversarial Network;Infrared Imaging","Deep learning;Image resolution;Object detection;Generative adversarial networks;Feature extraction;Generators;Classification algorithms","convolutional neural nets;deep learning (artificial intelligence);image resolution;object detection","residual in residual dense blocks;PixelTCL;VL images;residual image addition;pixel transposed convolutional layer;natural features;realistic features;visible light images;feature extraction;residual dense blocks;relativistic GAN;object detection accuracy;infrared images;GANs;generative adversarial networks;low resolution images;high resolution images;single image SR;super resolution performance;deep neural networks;image super resolution","","","","14","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"Semantic Prior Based Generative Adversarial Network for Video Super-Resolution","X. Wu; A. Lucas; S. Lopez-Tapia; X. Wang; Y. H. Kim; R. Molina; A. K. Katsaggelos","Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Depto. de Ciencias de la Computación e I.A., University of Granada, Granada, Spain; Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Depto. de Ciencias de la Computación e I.A., University of Granada, Granada, Spain; Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","Semantic information is widely used in the deep learning literature to improve the performance of visual media processing. In this work, we propose a semantic prior based Generative Adversarial Network (GAN) model for video super-resolution. The model fully utilizes various texture styles from different semantic categories of video-frame patches, contributing to more accurate and efficient learning for the generator. Based on the GAN framework, we introduce the semantic prior by making use of the spatial feature transform during the learning process of the generator. The patch-wise semantic prior is extracted on the whole video frame by a semantic segmentation network. A hybrid loss function is designed to guide the learning performance. Experimental results show that our proposed model is advantageous in sharpening video frames, reducing noise and artifacts, and recovering realistic textures.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8902987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902987","Video Super-Resolution;Generative Adversarial Networks;Semantic Segmentation;Spatial Feature Transform;Hybrid loss function","Semantics;Training;Generators;Gallium nitride;Generative adversarial networks;Transforms;Image segmentation","image resolution;image segmentation;image texture;learning (artificial intelligence);video signal processing","video super-resolution;semantic information;deep learning;visual media processing;video-frame patches;semantic segmentation network;semantic prior based generative adversarial network model","","2","","18","","18 Nov 2019","","","IEEE","IEEE Conferences"
"A Super Resolution Method for Remote Sensing Images Based on Cascaded Conditional Wasserstein GANs","B. Liu; H. Li; Y. Zhou; Y. Peng; A. Elazab; C. Wang","Northwest China Research Institute of Electronics Equipment, Xi’an, China; Northwest China Research Institute of Electronics Equipment, Xi’an, China; Northwest China Research Institute of Electronics Equipment, Xi’an, China; Shenzhen Institutes of Adavanced Technology, Chinese Academy of Sciences, Shenzhen, China; Computer Science Department, Misr Higher Institute for Commerce and Computers, Mansoura City, Egypt; University of Science and Technology of China, Hefei, P.R.China","2020 IEEE 3rd International Conference on Information Communication and Signal Processing (ICICSP)","20 Oct 2020","2020","","","284","289","High-resolution (HR) remote sensing imagery is quite beneficial for subsequent interpretation. Obtaining HR images can be achieved by upgrading the imaging device. Yet, the cost to perform this task is very huge. Thus, it is necessary to obtain HR images from low-resolution (LR) ones. In the literature, the super-resolution image reconstruction methods based on deep learning have unparalleled advantages in comparison to traditional reconstruction methods. This work is inspired by these current mainstream methods and proposes a novel cascaded conditional Wasserstein generative adversarial network (CCWGAN) architecture with the residual dense block to generate high quality remote sensing images. We validate the proposed method on the NWPU VHR-10 dataset. Experimental results show our CCWGAN method has superior performance compared with the state-of-the-art GAN methods.","","978-1-7281-8823-2","10.1109/ICICSP50920.2020.9232066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9232066","remote sensing images;cascaded conditional generative adversarial networks;wasserstein generative adversarial networks;residual dense block","Gallium nitride;Image edge detection;Remote sensing;Generative adversarial networks;Training;Generators;Deep learning","convolutional neural nets;geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","super-resolution image reconstruction methods;conditional Wasserstein generative adversarial network architecture;high quality remote sensing images;CCWGAN method;super resolution method;high-resolution remote sensing imagery;HR images;imaging device;cascaded conditional Wasserstein GAN;NWPU VHR-10 dataset","","","","18","IEEE","20 Oct 2020","","","IEEE","IEEE Conferences"
"Resolution-Preserving Generative Adversarial Networks for Image Enhancement","D. Lee; S. Lee; H. Lee; K. Lee; H. -J. Lee","Inter-university Semiconductor Research Center (ISRC), Department of Electrical Engineering and Computer Science, Seoul National University, Seoul, South Korea; Inter-university Semiconductor Research Center (ISRC), Department of Electrical Engineering and Computer Science, Seoul National University, Seoul, South Korea; Inter-university Semiconductor Research Center (ISRC), Department of Electrical Engineering and Computer Science, Seoul National University, Seoul, South Korea; Department of Electronic Engineering, Sun Moon University, Asan, South Korea; Inter-university Semiconductor Research Center (ISRC), Department of Electrical Engineering and Computer Science, Seoul National University, Seoul, South Korea","IEEE Access","19 Aug 2019","2019","7","","110344","110357","Generative adversarial networks (GANs) are used for image enhancement such as single image super-resolution (SISR) and deblurring. The conventional GANs-based image enhancement suffers from two drawbacks that cause a quality degradation due to a loss of detailed information. First, the conventional discriminator network adopts strided convolution layers which cause a reduction in the resolution of the feature map, and thereby resulting in a loss of detailed information. Second, the previous GANs for image enhancement use the feature map of the visual geometry group (VGG) network for generating a content loss, which also causes visual artifacts because the maxpooling layers in the VGG network result in a loss of detailed information. To overcome these two drawbacks, this paper presents a proposal of a new resolution-preserving discriminator network architecture which removes the strided convolution layers, and a new content loss generated from the VGG network without maxpooling layers. The proposed discriminator network is applied to the super-resolution generative adversarial network (SRGAN), which is called a resolution-preserving SRGAN (RPSRGAN). Experimental results show that RPSRGAN generates more realistic super-resolution images than SRGAN does, and consequently, RPSRGAN with the new content loss improves the average peak signal-to-noise ratio (PSNR) by 0.75 dB and 0.32 dB for super-resolution images with the scale factors of 2 and 4, respectively. For deblurring, the visual appearance is also significantly improved, and the average PSNR is increased by 1.54 dB when the proposed discriminator and content loss are applied to the deblurring adversarial network.","2169-3536","","10.1109/ACCESS.2019.2934320","LG Display; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8793240","Single image super-resolution;deblurring;generative adversarial networks;image enhancement","Generative adversarial networks;Three-dimensional displays;Convolution;Image enhancement;Iron;Gallium nitride","convolutional neural nets;image enhancement;image resolution;image restoration","single image super-resolution;conventional discriminator network;visual geometry group network;maxpooling layers;super-resolution generative adversarial network;resolution-preserving SRGAN;deblurring adversarial network;PSNR;peak signal-to-noise ratio;RPSRGAN;discriminator network architecture;SISR;VGG network;convolution layers","","12","","48","CCBY","9 Aug 2019","","","IEEE","IEEE Journals"
"Organ-Branched CNN for Robust Face Super-Resolution","J. Li; B. Bare; S. Zhou; B. Yan; K. Li","School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China","2021 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2021","2021","","","1","6","In this paper, we present a novel organ-branched CNN method for face super-resolution, named OBC-FSR. It is the first work focusing on facial-part-specific face SR, which consists of a local (facial part) network and a global network. Specifically, local network enhances the five key regions of human faces separately by Wasserstein generative adversarial networks (WGAN). Simultaneously, it also predicts five key regions’ masks, namely, eyes, eyebrows, mouth, nose, and other parts. The output of the local network is obtained by merging super-resolved five key regions. In order to alleviate boundary effects and distortions in the result of local network, our proposed network also includes a global network, which learns the direct mapping between LR and HR human faces. The final HR result of our FSR method is a fusion of the out-puts of local and global networks. Experimental results verify the superior performance of our method compared to the state-of-the-art.","1945-788X","978-1-6654-3864-3","10.1109/ICME51207.2021.9428152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9428152","Face super-resolution;Face key regions;WGAN;Organ-branched-CNN","Superresolution;Merging;Nose;Mouth;Focusing;Distortion;Generative adversarial networks","convolutional neural nets;face recognition;image resolution","key regions;local network;global network;human faces;FSR method;local networks;global networks;robust face super-resolution;organ-branched CNN method;facial-part-specific face SR;facial part;Wasserstein generative adversarial networks;OBC-FSR;facial-part-specific face;key regions masks;super-resolved five key regions;boundary effects;direct mapping;LR human faces;HR human faces","","3","","14","IEEE","9 Jun 2021","","","IEEE","IEEE Conferences"
"Real-World DEM Super-Resolution Based on Generative Adversarial Networks for Improving InSAR Topographic Phase Simulation","Z. Wu; Z. Zhao; P. Ma; B. Huang","Institute of Space and Earth Information Science, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Institute of Space and Earth Information Science, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Shenzhen Research Institute, The Chinese University of Hong Kong, Shenzhen, China; Institute of Space and Earth Information Science, The Chinese University of Hong Kong, Hong Kong, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","3 Sep 2021","2021","14","","8373","8385","Topographic phase simulation is important for deformation estimation in differential synthetic aperture radar (SAR) interferometry. The most commonly used 30 m resolution shuttle radar topography mission (SRTM) digital elevation model (DEM) is usually required to be resampled due to its relatively low resolution (LR) comparing to the high resolution (HR) SAR images. Although the WorldDEM with a 12 m resolution achieves global coverage, it is not available freely. Consequently, it is useful to evaluate the practicability of the super-resolution (SR) from LR SRTM DEMs to HR WorldDEM ones, which has not been investigated. Most existing DEM SR models are trained with synthetic datasets in which the LR DEMs are downsampled from their HR counterparts. However, these models become less effective when applied to real-world scenarios due to the domain gap between the synthetic and real LR DEMs. In this article, we constructed a real-world DEM SR dataset, where the LR and HR DEMs were collected from SRTM and WorldDEM, respectively. An enhanced SR generative adversarial network model was adapted to train on the dataset. Considering that the real LR-HR pairs may suffer from misalignment, we introduced the perceptual loss for better optimizing the model. Moreover, a logarithmic normalization was proposed to compress the wide elevation range and adjust the uneven distribution. We also pretrained the model using natural images since collecting sufficient HR DEMs is costly. Experiments demonstrate that the proposed method achieves near 0.69 dB improvement of peak signal-to-noise ratio. In addition, our method is also validated to improve the topographic phase simulation by 23.42% of MSE.","2151-1535","","10.1109/JSTARS.2021.3105123","National Natural Science Foundation of China(grant numbers:41971278); Research Grants Council of Hong Kong(grant numbers:CUHK14504219,CUHK14206818,AoE/E-603/18); National Key R&D Program of China(grant numbers:2019YFC1510400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516888","Deep learning;digital elevation model;generative adversarial network;InSAR topographic phase simulation;super resolution (SR)","Generative adversarial networks;Synthetic aperture radar;Adaptation models;Training;Superresolution;Earth;Satellites","digital elevation models;geophysical image processing;image resolution;radar imaging;radar interferometry;remote sensing by radar;synthetic aperture radar;topography (Earth)","synthetic datasets;LR DEMs;real-world DEM;SR dataset;enhanced SR generative adversarial network model;LR-HR pairs;world DEM super-resolution;generative adversarial networks;improving InSAR topographic phase simulation;deformation estimation;differential synthetic aperture radar interferometry;relatively low resolution comparing;high resolution SAR images;LR SRTM DEMs;HR WorldDEM ones;DEM SR models;30 m resolution shuttle radar topography mission digital elevation model;HR DEMs","","5","","54","CCBY","18 Aug 2021","","","IEEE","IEEE Journals"
"DSRGAN: Detail Prior-Assisted Perceptual Single Image Super-Resolution via Generative Adversarial Networks","Z. Liu; Z. Li; X. Wu; Z. Liu; W. Chen","Hangzhou Innovation Institute, Beihang University, Hangzhou, China; SRO Department, Institute for Infocomm Research, Fusionopolis Way, Singapore; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; College of Electrical Engineering and Automation, Shandong University of Science and Technology, Qingdao, China","IEEE Transactions on Circuits and Systems for Video Technology","28 Oct 2022","2022","32","11","7418","7431","The generative adversarial network (GAN) is successfully applied to study the perceptual single image super-resolution (SISR). However, since the GAN is data-driven, it has a fundamental limitation on restoring real high frequency information for an unknown instance (or image) during test. On the other hand, the conventional model-based methods have a superiority to achieve instance adaptation as they operate by considering the statistics of each instance (or image) only. Motivated by this, we propose a novel model-based algorithm, which can extract the detail layer of an image efficiently. The detail layer represents the high frequency information of image and it is constituted of image edges and fine textures. It is seamlessly incorporated into the GAN and serves as a prior knowledge to assist the GAN in generating more realistic details. The proposed method, named DSRGAN, takes advantages from both the model-based conventional algorithm and the data-driven deep learning network. Experimental results demonstrate that the DSRGAN outperforms the state-of-the-art SISR methods on perceptual metrics, meanwhile achieving comparable results in terms of fidelity metrics. Following the DSRGAN, it is feasible to incorporate other conventional image processing algorithms into a deep learning network to form a model-based deep SISR.","1558-2205","","10.1109/TCSVT.2022.3188433","Special Funding for Top Talents of Shandong Province; Key Research and Development Program of Zhejiang Province(grant numbers:2020C01109,2021C03050); National Natural Science Foundation of China(grant numbers:61620106012,61573048); Foundation of Strengthening Program Technology Fund Projects(grant numbers:2019-JCJQ-JJ-268); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815113","Single image super-resolution;generative adversarial networks;detail prior;model-based and data-driven","Generative adversarial networks;Image edge detection;High frequency;Image restoration;Measurement;Image reconstruction;Deep learning","deep learning (artificial intelligence);image reconstruction;image resolution","conventional image processing algorithms;data-driven deep learning network;DSRGAN;GAN;generative adversarial network;high frequency information;image edges;instance adaptation;model-based algorithm;model-based conventional algorithm;model-based deep SISR;model-based methods;perceptual single image super-resolution;unknown instance","","","","49","IEEE","4 Jul 2022","","","IEEE","IEEE Journals"
"Hierarchical Generative Adversarial Networks for Single Image Super-Resolution","W. Chen; Y. Ma; X. Liu; Y. Yuan","NetEase Fuxi AI Lab, Hangzhou, China; State Key Lab of Software Development Environment, Beihang University, China; State Key Lab of Software Development Environment, Beihang University, China; NetEase Fuxi AI Lab, Hangzhou, China","2021 IEEE Winter Conference on Applications of Computer Vision (WACV)","14 Jun 2021","2021","","","355","364","Recently, deep convolutional neural network (CNN) have achieved promising performance for single image super-resolution (SISR). However, they usually extract features on a single scale and lack sufficient supervision information, leading to undesired artifacts and unpleasant noise in super-resolution (SR) images. To address this problem, we first propose a hierarchical feature extraction module (HFEM) to extract the features in multiple scales, which helps concentrate on both local textures and global semantics. Then, a hierarchical guided reconstruction module (HGRM) is introduced to reconstruct more natural structural textures in SR images via intermediate supervisions in a progressive manner. Finally, we integrate HFEM and HGRM in a simple yet efficient end-to-end framework named hierarchical generative adversarial networks (HSR-GAN) to recover consistent details, and thus obtain the semantically reasonable and visually realistic results. Extensive experiments on five common datasets demonstrate that our method shows favorable visual quality and superior quantitative performance compared to state-of-the-art methods for SISR.","2642-9381","978-1-6654-0477-8","10.1109/WACV48630.2021.00040","Research and Development; National Natural Science Foundation of China; Beijing Nova Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9423174","","Measurement;Visualization;Conferences;Superresolution;Semantics;Feature extraction;Generative adversarial networks","convolutional neural nets;feature extraction;image reconstruction;image representation;image resolution;image texture;learning (artificial intelligence)","hierarchical generative adversarial networks;single image super-resolution;deep convolutional neural network;single scale;lack sufficient supervision information;super-resolution images;hierarchical feature extraction module;hierarchical guided reconstruction module;SR images;end-to-end framework;SISR;HGRM;HSR-GAN;HFEN","","7","","37","IEEE","14 Jun 2021","","","IEEE","IEEE Conferences"
"Spatial Transformer Generative Adversarial Network for Robust Image Super-Resolution","H. M. Kasem; K. -W. Hung; J. Jiang","Faculty of Engineering, Tanta University, Tanta, Egypt; Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University, Shenzhen, China; Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University, Shenzhen, China","IEEE Access","24 Dec 2019","2019","7","","182993","183009","Recently, there have been significant advances in image super-resolution based on generative adversarial networks (GANs) to achieve breakthroughs in generating more images with high subjective quality. However, there are remaining challenges needs to be met, such as simultaneously recovering the finer texture details for large upscaling factors and mitigating the geometric transformation effects. In this paper, we propose a novel robust super-resolution GAN (i.e. namely RSR-GAN) which can simultaneously perform both the geometric transformation and recovering the finer texture details. Specifically, since the performance of the generator depends on the discreminator, we propose a novel discriminator design by incorporating the spatial transformer module with residual learning to improve the discrimination of fake and true images through removing the geometric noise, in order to enhance the super-resolution of geometric corrected images. Finally, to further improve the perceptual quality, we introduce an additional DCT loss term into the existing loss function. Extensive experiments, measured by both PSNR and SSIM measurements, show that our proposed method achieves a high level of robustness against a number of geometric transformations, including rotation, translation, a combination of rotation and scaling effects, and a cobmination of rotaion, transalation and scaling effects. Benchmarked by the existing state-of-the-arts SR methods, our proposed delivers superior performances on a wide range of datasets which are publicly available and widely adopted across research communities.","2169-3536","","10.1109/ACCESS.2019.2959940","National Natural Science Foundation of China(grant numbers:61620106008,61602312); Science, Technology and Innovation Commission of Shenzhen Municipality(grant numbers:JCYJ20160226191842793); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933156","Super-resolution;generative adversarial networks;spatial transformer network;robust image super-resolution;robust generative adversarial network","Generators;Generative adversarial networks;Gallium nitride;Deep learning;Discrete cosine transforms","discrete cosine transforms;image resolution;image texture","PSNR measurements;SSIM measurements;DCT loss term;geometric noise;RSR-GAN;robust super-resolution GAN;finer texture details;robust image super-resolution;spatial transformer generative adversarial network","","15","","55","CCBY","16 Dec 2019","","","IEEE","IEEE Journals"
"Semi-Cycled Generative Adversarial Networks for Real-World Face Super-Resolution","H. Hou; J. Xu; Y. Hou; X. Hu; B. Wei; D. Shen","College of Intelligence and Information Engineering and the Center for Medical Artificial Intelligence, Shandong University of Traditional Chinese Medicine, Jinan, China; School of Biomedical Engineering, ShanghaiTech University, Shanghai, China; School of Information Science and Technology, Taishan University, Taian, China; College of Computer Science, Nankai University, Tianjin, China; Center for Medical Artificial Intelligence, Shandong University of Traditional Chinese Medicine, Jinan, China; Shanghai Clinical Research and Trial Center, Shanghai, China","IEEE Transactions on Image Processing","13 Feb 2023","2023","32","","1184","1199","Real-world face super-resolution (SR) is a highly ill-posed image restoration task. The fully-cycled Cycle-GAN architecture is widely employed to achieve promising performance on face SR, but is prone to produce artifacts upon challenging cases in real-world scenarios, since joint participation in the same degradation branch will impact final performance due to huge domain gap between real-world and synthetic LR ones obtained by generators. To better exploit the powerful generative capability of GAN for real-world face SR, in this paper, we establish two independent degradation branches in the forward and backward cycle-consistent reconstruction processes, respectively, while the two processes share the same restoration branch. Our Semi-Cycled Generative Adversarial Networks (SCGAN) is able to alleviate the adverse effects of the domain gap between the real-world LR face images and the synthetic LR ones, and to achieve accurate and robust face SR performance by the shared restoration branch regularized by both the forward and backward cycle-consistent learning processes. Experiments on two synthetic and two real-world datasets demonstrate that, our SCGAN outperforms the state-of-the-art methods on recovering the face structures/details and quantitative metrics for real-world face SR. The code will be publicly released at https://github.com/HaoHou-98/SCGAN.","1941-0042","","10.1109/TIP.2023.3240845","National Natural Science Foundation of China(grant numbers:62002176,62176068,61872225); Natural Science Foundation of Shandong Province(grant numbers:ZR2020MF038,ZR2020KF013,ZR2020ZD44); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10036448","Real-world face super-resolution;semi-cycled architecture;cycle-consistent generative adversarial networks","Faces;Face recognition;Image restoration;Degradation;Generative adversarial networks;Superresolution;Task analysis","","","","1","","82","IEEE","3 Feb 2023","","","IEEE","IEEE Journals"
"White-Light Interference Microscopy Image Super-Resolution Using Generative Adversarial Networks","H. Li; C. Zhang; H. Li; N. Song","Institute of Optics and Electronics, School of Instrumentation and Opto-electronics Engineering, Beihang University, Beijing, China; Institute of Optics and Electronics, School of Instrumentation and Opto-electronics Engineering, Beihang University, Beijing, China; Institute of Optics and Electronics, School of Instrumentation and Opto-electronics Engineering, Beihang University, Beijing, China; Institute of Optics and Electronics, School of Instrumentation and Opto-electronics Engineering, Beihang University, Beijing, China","IEEE Access","11 Feb 2020","2020","8","","27724","27733","To reduce external disturbances and achieve high vertical resolution, the scanning time for white-light interference microscopy is very short. Because capturing high-resolution (HR) images is time consuming, low-resolution (LR) images are acquired instead. However, HR images are more desirable because they contain more details. To ensure high vertical resolution and high image resolution, one feasible solution is to process the scanned LR images to HR images by single image super-resolution (SISR). In this paper, an interference image super-resolution (IISR) model based on a generative adversarial network (GAN) is proposed. The generator is based on the enhanced super-resolution generative adversarial network (ESRGAN) architecture. With the aim of acquiring more realistic images, the discriminator network is designed using a modified DenseNet architecture, in which the pooling layers are replaced with dilated convolutional layers. The perceptual loss is optimized, and the content loss is upgraded to a continuously differentiable piecewise function. Various microscopy images are tested, including images with and without interference fringes. The IISR model has been proven to restore LR images to HR images. The comparative experiments prove that the proposed model achieves better visual quality than other models, preserving more realistic details.","2169-3536","","10.1109/ACCESS.2020.2971841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8984295","White-light interference microscopy;single image super-resolution;generative adversarial network;visual quality","Feature extraction;Convolution;Interference;Generators;Generative adversarial networks","computerised instrumentation;image resolution;image restoration;light interference;neural nets;optical microscopy","scanning time;high-resolution images;low-resolution images;HR images;scanned LR images;single image super-resolution;interference image super-resolution model;enhanced super-resolution generative adversarial network architecture;realistic images;discriminator network;microscopy images;interference fringes;high vertical resolution;white-light interference microscopy image super-resolution","","4","","36","CCBY","5 Feb 2020","","","IEEE","IEEE Journals"
"RTSRGAN: Real-Time Super-Resolution Generative Adversarial Networks","X. Hu; X. Liu; Z. Wang; X. Li; W. Peng; G. Cheng","School of Cyber Science & Engineering, Southeast University, Nanjing, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; School of Computer Science and Engineering, Southeast University, Nanjing, China; School of Cyber Science & Engineering, Southeast University, Nanjing, China","2019 Seventh International Conference on Advanced Cloud and Big Data (CBD)","28 Nov 2019","2019","","","321","326","The Enhanced Super-Resolution Generative Adver-sarial Networks (ESRGAN) is the state of the art deep learning based image Super-Resolution (SR) and has the best performance in perceptual quality. However, we find it is time-consuming, which makes it impractical for SR at clients' side during video delivery since SR usually uses clients' computing resources (the computational power at the clients' side should not be as powerful as GPU) and videos often require real-time playback. While Efficient Sub-Pixel Convolutional Neural Network (ESPCN) has the best real-time performance, it is still not capable of offering a smooth watching experience and has much lower perceptual quality. In order to simultaneously meet the demands on the real-time performance and the resulting pleasant artifacts of SR at the clients' side, we propose RTSRGAN to exploit the advantages of ESRGAN in image perceptual quality and ESPCN in real-time performance. Our experimental results indicate that RTSRGAN has the fastest reconstruction speed, on the average, 15 images per second on a single 2.3GHz CPU (only 6 images per second by ESPCN), and reconstructs images of a relatively acceptable perceptual quality, which validates that our proposed RTSRGAN can be used for SR at clients' side to enhance the real-time performance and ensure the image perceptual quality.","","978-1-7281-5141-0","10.1109/CBD.2019.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8916480","Image super-resolution, real-time, ESRGAN, ESPCN, network structure","Image reconstruction;Streaming media;Real-time systems;Image resolution;Convolution;Generative adversarial networks;Machine learning","convolutional neural nets;image reconstruction;image resolution;learning (artificial intelligence);real-time systems;video signal processing","RTSRGAN;ESPCN;image perceptual quality;deep learning based image super-resolution;efficient subpixel convolutional neural network;real-time superresolution generative adversarial networks;video delivery;image reconstruction","","3","","26","IEEE","28 Nov 2019","","","IEEE","IEEE Conferences"
"Research for Face Image Super-Resolution Reconstruction Based on Wavelet Transform and SRGAN","M. Cao; Z. Liu; X. Huang; Z. Shen","School of Artificial Intelligence, Jianghan University, Wuhan, China; School of Artificial Intelligence, Jianghan University, Wuhan, China; School of Artificial Intelligence, Jianghan University, Wuhan, China; School of Artificial Intelligence, Jianghan University, Wuhan, China","2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)","5 Apr 2021","2021","5","","448","451","Super-resolution face image is the basis of high detection rate in face recognition. In order to meet the requirements of super-resolution image in face recognition, aiming at the problem of texture loss of super-resolution image under high-frequency features, a face image reconstruction method based on wavelet transform and super-resolution generative adversarial network (SRGAN) is proposed to reduce the impact of low-resolution image caused by imaging hardware, network bandwidth and sampling environment on face recognition accuracy. Firstly, the wavelet transform algorithm is used to preprocess the low-resolution face image to extract the detailed texture features of the face image under different frequencies. Then, GAN is used to learn the prior knowledge of wavelet coefficients, and the identity preserving constraint is applied to the output image, and the perceptual loss function of the fusion wavelet coefficients is realized. Finally, the deep learning model based on SRGAN is used to obtain high-resolution face images. Experimental results show that the method can achieve super-resolution restoration of low-resolution face images and meet the requirements of face recognition accuracy.","2689-6621","978-1-7281-8028-1","10.1109/IAEAC50856.2021.9390748","Jianghan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9390748","super-resolution;wavelet transform;super-resolution generative adversarial network(SRGAN)","Face recognition;Superresolution;Reconstruction algorithms;Generative adversarial networks;Feature extraction;Image reconstruction;Wavelet coefficients","face recognition;image reconstruction;image resolution;image restoration;image texture;learning (artificial intelligence);wavelet transforms","face image super-resolution reconstruction;SRGAN;super-resolution face image;super-resolution image;high-frequency features;face image reconstruction method;super-resolution generative adversarial network;low-resolution image;imaging hardware;face recognition accuracy;wavelet transform algorithm;low-resolution face image;output image;high-resolution face images;super-resolution restoration","","3","","10","IEEE","5 Apr 2021","","","IEEE","IEEE Conferences"
"Infrared Image Super Resolution Using GAN With Infrared Image Prior","S. Liu; Y. Yang; Q. Li; H. Feng; Z. Xu; Y. Chen; L. Liu","State Key Laboratory of Modern Optical Instrumentation Zhejiang University, Zhejiang University, Hangzhou, China; State Key Laboratory of Modern Optical Instrumentation Zhejiang University, Zhejiang University, Hangzhou, China; State Key Laboratory of Modern Optical Instrumentation Zhejiang University, Zhejiang University, Hangzhou, China; State Key Laboratory of Modern Optical Instrumentation Zhejiang University, Zhejiang University, Hangzhou, China; State Key Laboratory of Modern Optical Instrumentation Zhejiang University, Zhejiang University, Hangzhou, China; State Key Laboratory of Modern Optical Instrumentation Zhejiang University, Zhejiang University, Hangzhou, China; Infrared R&D Center Zhejiang Dali Technology CO.,LTD, Hangzhou, China","2019 IEEE 4th International Conference on Signal and Image Processing (ICSIP)","17 Oct 2019","2019","","","1004","1009","Super-resolution reconstruction technology based on deep-learning is rarely used in the field of infrared image. This paper will apply the Generative Adversarial Network super-resolution approach to the infrared super-resolution task. The natural image gradient prior is introduced into the super-resolution algorithm, and the visible image of the corresponding scene and the field of view is innovatively used as the style map, and the corresponding shallow network perceptual loss and deep network perceptual loss are added to the super-resolution objective function. The reconstructed image is more abundant and more detailed in the subjective visual reconstruction of the image texture than the existing algorithm in the simulation experiment.","","978-1-7281-3660-8","10.1109/SIPROCESS.2019.8868566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868566","Component;infrared super-resolution;natural image prior;Generative Adversarial Network","Generative adversarial networks;Gallium nitride;Conferences;Training","image reconstruction;image resolution;image texture;infrared imaging;learning (artificial intelligence)","image super resolution;infrared image;super-resolution reconstruction technology;deep-learning;super-resolution task;natural image gradient;super-resolution algorithm;visible image;corresponding shallow network perceptual loss;deep network perceptual loss;super-resolution objective function;reconstructed image;image texture;generative adversarial network super-resolution approach","","7","","20","IEEE","17 Oct 2019","","","IEEE","IEEE Conferences"
"Self Supervised Super-Resolution PET Using A Generative Adversarial Network","T. -A. Song; S. Roy Chowdhury; F. Yang; J. Dutta","Department of Electrical and Computer Engineering, University of Massachusetts Lowell, Lowell, MA, USA; Department of Electrical and Computer Engineering, University of Massachusetts Lowell, Lowell, MA, USA; Department of Electrical and Computer Engineering, University of Massachusetts Lowell, Lowell, MA, USA; Geriatric Research, Education and Clinical Center, Edith Nourse Rogers Memorial Veterans Hospital, MA, USA","2019 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC)","9 Apr 2020","2019","","","1","3","Resolution limitations pose a continuing challenge for PET quantitation. While deep learning architectures based on convolutional neural networks (CNNs) have produced unprecedented accuracy at generating super-resolution (SR) PET images, most existing approaches are based on supervised learning. The latter requires training datasets with paired (low- and high-resolution) images, which are often unavailable for clinical applications. In this paper, we present a self-supervised SR (SSSR) technique for PET based on dual generative adversarial networks (GANs), which obviate the need for paired training data, ensuring wider applicability and adoptability. Our network receives as inputs a low-resolution PET image, a high-resolution anatomical MR image, and spatial information. An imperfect SR image generated by a separately-trained auxiliary CNN serves as an additional input to the network. This CNN is trained in a supervised manner using paired simulation datasets. The loss function for training the dual GANs consists of two adversarial loss terms, a cycle consistency term, and a total variation penalty on the SR image. The method was validated on clinical data by comparing the SSSR results with those generated from a supervised approach and from deconvolution stabilized by a total variation penalty. Our results show that SSSR, while weaker than its supervised counterpart, noticeably outperforms deconvolution as indicated by the peak signal-to-noise-ratio and structural similarity index measures.","2577-0829","978-1-7281-4164-0","10.1109/NSS/MIC42101.2019.9059947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9059947","","Training;Signal resolution;Gallium nitride;Spatial resolution;Generative adversarial networks;Imaging","convolutional neural nets;deconvolution;image resolution;medical image processing;positron emission tomography;supervised learning","self-supervised super-resolution PET;dual GANs;high-resolution anatomical MR image;low-resolution PET image;dual generative adversarial networks;supervised learning;super-resolution PET images;convolutional neural networks;generative adversarial network;SSSR","","2","","11","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"A Generative Approach to Visualizing Satellite Data","S. Mitra; D. Rammer; S. Pallickara; S. L. Pallickara","Department of Computer Science, Colorado State University, Fort Collins, USA; Department of Computer Science, Colorado State University, Fort Collins, USA; Department of Computer Science, Colorado State University, Fort Collins, USA; Department of Computer Science, Colorado State University, Fort Collins, USA","2021 IEEE International Conference on Cluster Computing (CLUSTER)","13 Oct 2021","2021","","","815","816","We propose EVOKE, a model based on progressive Generative Adversarial Networks, that dynamically reconstructs high-resolution imagery during zoom-in operations using in-memory historical low-resolution images and is space-efficient to facilitate memory-residency at the clients.","2168-9253","978-1-7281-9666-4","10.1109/Cluster48925.2021.00079","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9556070","super-resolution;generative adversarial networks;in-memory storage;visual analytics","Satellites;Image resolution;Conferences;Computational modeling;Data visualization;Generative adversarial networks;Data transfer","data visualisation;database indexing;geophysical image processing;image reconstruction;image resolution;query processing;terrain mapping","Generative approach;visualizing satellite data;EVOKE;memory-residency;low-resolution images;zoom-in operations;high-resolution imagery;progressive Generative Adversarial Networks","","","","8","IEEE","13 Oct 2021","","","IEEE","IEEE Conferences"
"A State-of-the-Art Review on Image Synthesis With Generative Adversarial Networks","L. Wang; W. Chen; W. Yang; F. Bi; F. R. Yu","Mine Digitization Engineering Research Center of the Ministry of Education, China University of Mining and Technology, Xuzhou, China; Information Engineering College, Beijing Institute of Petrochemical Technology, Beijing, China; Mine Digitization Engineering Research Center of the Ministry of Education, China University of Mining and Technology, Xuzhou, China; Mine Digitization Engineering Research Center of the Ministry of Education, China University of Mining and Technology, Xuzhou, China; School of Information Technology, Carleton University, Ottawa, Canada","IEEE Access","14 Apr 2020","2020","8","","63514","63537","Generative Adversarial Networks (GANs) have achieved impressive results in various image synthesis tasks, and are becoming a hot topic in computer vision research because of the impressive performance they achieved in various applications. In this paper, we introduce the recent research on GANs in the field of image processing, including image synthesis, image generation, image semantic editing, image-to-image translation, image super-resolution, image inpainting, and cartoon generation. We analyze and summarize the methods used in these applications which have improved the generated results. Then, we discuss the challenges faced by GANs and introduce some methods to deal with these problems. We also preview some likely future research directions in the field of GANs, such as video generation, facial animation synthesis and 3D face reconstruction. The purpose of this review is to provide insights into the research on GANs and to present the various applications based on GANs in different scenarios.","2169-3536","","10.1109/ACCESS.2020.2982224","National Natural Science Foundation of China(grant numbers:51874300,51874299); National Natural Science Foundation of China and Shanxi Provincial People’s Government Jointly Funded Project of China for Coal Base and Low Carbon(grant numbers:U1510115); Open Research Fund of Key Laboratory of Wireless Sensor Network and Communication, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences(grant numbers:20190902,20190913); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9043519","Generative adversarial networks;image synthesis;image-to-image translation;image editing;cartoon generation","Image synthesis;Generative adversarial networks;Training;Face;Task analysis;Generators","computer vision;image resolution;image restoration;neural nets;stereo image processing","GANs;image synthesis tasks;computer vision research;image processing;image generation;image semantic editing;image-to-image translation;image super-resolution;image inpainting;cartoon generation;generative adversarial networks","","52","1","140","CCBY","20 Mar 2020","","","IEEE","IEEE Journals"
"Accurate and Efficient Generation of High-Resolution Facial Expression Images by Multi-Task Learning Using Generative Adversarial Networks","T. Hanano; M. Seo; Y. -W. Chen","Graduate School of Information and Engineering, Ritsumeikan University, Shiga, Japan; Osaka Institute of Technology, Osaka, Japan; Graduate School of Information and Engineering, Ritsumeikan University, Shiga, Japan","2022 IEEE 11th Global Conference on Consumer Electronics (GCCE)","18 Jan 2023","2022","","","765","768","Recently, the means to see human face images have increased owing to the spread of smartphones and social networking services. Especially, in the field of face images, the generation of face images using facial expression transformation has already been realized using deep learning-based approaches. However, in the existing deep learning-based models, only low-resolution images can be generated owing to limited computational resources, and the generated images are blur or aliasing. To solve this problem, we proposed to enhance the resolution of the generated facial image by using a super resolution network after the generative model, which can be considered as a serial model in our previous work. In this paper, we newly proposed a parallel model, which train the generative adversarial network and the super-resolution network through multi-task learning. Using the peak signal-to-noise ratio as an evaluation index, image quality was improved by 0.29 dB for the male test data and by 0.24 dB for the female test data compared with the our previous serial model.","2378-8143","978-1-6654-9232-4","10.1109/GCCE56475.2022.10014139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10014139","Generative Adversarial Nets;Pix2Pix;multi-task learning;parallel model;serial model","Learning systems;PSNR;Social networking (online);Computational modeling;Superresolution;Generative adversarial networks;Multitasking","emotion recognition;face recognition;image resolution;learning (artificial intelligence);social networking (online)","deep learning-based approaches;existing deep learning-based models;facial expression transformation;generated facial image;generative adversarial network;generative model;high-resolution facial expression images;human face images;image quality;low-resolution images;multitask learning;parallel model;social networking services;super resolution network;super-resolution network","","","","8","IEEE","18 Jan 2023","","","IEEE","IEEE Conferences"
"Simultaneous Super-Resolution and Segmentation Using a Generative Adversarial Network: Application to Neonatal Brain MRI","C. . -H. Pham; C. Tor-Díez; H. Meunier; N. Bednarek; R. Fablet; N. Passat; F. Rousseau","IMT Atlantique, LaTIM U1101 INSERM, UBL, Brest, France; IMT Atlantique, LaTIM U1101 INSERM, UBL, Brest, France; CHU de Reims, Service de médecine néonatale et réanimation pédiatrique, France; CHU de Reims, Service de médecine néonatale et réanimation pédiatrique, France; IMT Atlantique, Lab-STICC UMR CNRS 6285, Brest, France; CReSTIC, Université de Reims Champagne-Ardenne, Reims, France; IMT Atlantique, LaTIM U1101 INSERM, UBL, Brest, France","2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)","11 Jul 2019","2019","","","991","994","Brest, France The analysis of clinical neonatal brain MRI remains challenging due to low anisotropic resolution of the data. In most pipelines, images are first re-sampled using interpolation or single image super-resolution techniques and then segmented using (semi-)automated approaches. Image reconstruction and segmentation are then performed separately. In this paper, we propose an end-to-end generative adversarial network for simultaneous high-resolution reconstruction and segmentation of brain MRI data. This joint approach is first assessed on the simulated low-resolution images of the high-resolution neonatal dHCP dataset. Then, the learned model is used to enhance and segment real clinical low-resolution images. Results demonstrate the potential of our proposed method with respect to practical medical applications.","1945-8452","978-1-5386-3641-1","10.1109/ISBI.2019.8759255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759255","Super-resolution;segmentation;3D generative adversarial networks;neonatal brain MRI","Image segmentation;Image resolution;Magnetic resonance imaging;Image reconstruction;Pediatrics;Interpolation;Generative adversarial networks","biomedical MRI;brain;image reconstruction;image resolution;image segmentation;interpolation;medical image processing","medical applications;image reconstruction;interpolation;single image superresolution;simultaneous superresolution;image segmentation;high-resolution neonatal dHCP dataset;low-resolution images;brain MRI data;simultaneous high-resolution reconstruction;end-to-end generative adversarial network;low anisotropic resolution;clinical neonatal brain MRI","","1","","13","IEEE","11 Jul 2019","","","IEEE","IEEE Conferences"
"Adversarial Training for Speech Super-Resolution","S. E. Eskimez; K. Koishida; Z. Duan","Department of Electrical and Computer Engineering, University of Rochester, Rochester, NY, USA; Microsoft Corporation, Redmond, WA, USA; Department of Electrical and Computer Engineering, University of Rochester, Rochester, NY, USA","IEEE Journal of Selected Topics in Signal Processing","17 May 2019","2019","13","2","347","358","Speech super-resolution or speech bandwidth expansion aims to upsample a given speech signal by generating the missing high-frequency content. In this paper, we propose a deep neural network approach exploiting the adversarial training ideas that have been shown effective in image super-resolution. Specifically, our proposed network follows the generative adversarial networks setup, where the generator network uses a convolutional autoencoder architecture with one-dimensional convolution kernels to generate high-frequency log-power spectra from the low-frequency log-power spectra of the input speech. We propose to use both the reconstruction loss and the adversarial loss for training, and we employ a recent regularization method that penalizes the gradient norms of the discriminator to stabilize the training. We compare our proposed approach with two state-of-the-art neural network baselines and evaluate these methods with both objective speech quality measures and subjective perceptual and intelligibility tests. Results show that our proposed method outperforms both baselines in terms of both objective and subjective evaluations. To gain insights of the network architecture, we analyze key parameters of the proposed network including the number of layers, the number of convolution kernels, and the relative weight of the reconstruction and adversarial losses. Besides, we analyze the computational complexity of our method and the baselines and discuss ways for phase estimation. We further develop a noise-resilient version of the proposed approach by training the network with noisy speech inputs. Objective evaluation validates the noise-resilient property on unseen noise types.","1941-0484","","10.1109/JSTSP.2019.2909077","National Science Foundation(grant numbers:1617107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8681126","Speech super-resolution;artificial bandwidth expansion;generative adversarial networks;1D convolutional neural networks;speech processing","Training;Signal resolution;Image resolution;Generative adversarial networks;Generators;Bandwidth;Convolution","computational complexity;convolution;image reconstruction;image resolution;neural nets;noise;speech processing","convolutional autoencoder architecture;one-dimensional convolution kernels;high-frequency log-power spectra;reconstruction loss;adversarial loss;network architecture;noisy speech inputs;speech super-resolution;speech bandwidth expansion;deep neural network approach;adversarial training ideas;image super-resolution;generative adversarial networks setup;regularization method;neural network baselines;speech quality measures;low-frequency log-power spectra;computational complexity;speech signal","","12","","44","IEEE","3 Apr 2019","","","IEEE","IEEE Journals"
"Super-Resolution Generative Adversarial Network with Modified Architecture for Single Image Super-Resolution","N. A. Gowtham; S. Deepakq; D. Patra","Electrical Engineering Department, National Institute of Technology, Rourkela, India; Electrical Engineering Department, National Institute of Technology, Rourkela, India; Electrical Engineering Department, National Institute of Technology, Rourkela, India","2020 4th International Conference on Computer, Communication and Signal Processing (ICCCSP)","15 Jan 2021","2020","","","1","6","Recently, Single image Super-Resolution (SISR) has become an attractive research area in Image processing which generates a High-Resolution (HR) image by using Single Low-Resolution (LR) image. Deep learningbased SISR approaches have achieved better Super-Resolved (SR) results by using mean squared error (MSE) as an objective function that increases the quality of SR results over performance metrics like peak-signal-to-noise-ratio (PSNR) and structural similarity index (SSIM). Nevertheless, MSE based approaches lead to generate over smoothed images with less high-frequency texture information at larger upscaling factors. Recent experiments have proved that Generative Adversarial Networks (GAN) generates perceptually convincing SR images through efficient extraction of high-frequency information from single LR image. In this paper, we propose a GAN based approach for SISR with modified deep-residual network architecture. In our proposed technique, we introduce the bottle-neck convolutional (CN) layer in the network structure of the Generator. Adding bottle-neck layers improves the network performance through 1 x 1 convolutional layers which extract complex features from the input and also reduces the computational complexity compared to 3 x 3 convolution layers. We further improve the model performance by removing batch normalization layer from the entire generator to overcome the unpleasant artifacts and improves GPU usage while training.","","978-1-7281-6509-7","10.1109/ICCCSP49186.2020.9315285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9315285","GAN;SRGAN;SISR;Super-resolution;Adversarial training;Gang Plank;Nash Equilibrium;Resource Provisioning;Scalar chain;Trust","Generators;Training;Generative adversarial networks;Feature extraction;Superresolution;Gallium nitride;Convolution","convolutional neural nets;deep learning (artificial intelligence);feature extraction;image resolution;image texture;mean square error methods;neural net architecture","structural similarity index;smoothed images;texture information extraction;deep residual network architecture;convolutional layers;super resolution generative adversarial network;single image super resolution;image processing;deep learning;mean squared error;peak signal to noise ratio","","","","23","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"Super Resolution of Car Plate Images Using Generative Adversarial Networks","T. K. Lai; A. F. Abbas; A. M. Abdu; U. U. Sheikh; M. Mokji; K. Khalil","Faculty of Engineering, School of Electrical Engineering, Universiti Teknologi Malaysia, Skudai, Johor; Faculty of Engineering, School of Electrical Engineering, Universiti Teknologi Malaysia, Skudai, Johor; Faculty of Engineering, School of Electrical Engineering, Universiti Teknologi Malaysia, Skudai, Johor; Faculty of Engineering, School of Electrical Engineering, Universiti Teknologi Malaysia, Skudai, Johor; Faculty of Engineering, School of Electrical Engineering, Universiti Teknologi Malaysia, Skudai, Johor; Faculty of Engineering, School of Electrical Engineering, Universiti Teknologi Malaysia, Skudai, Johor","2019 IEEE 15th International Colloquium on Signal Processing & Its Applications (CSPA)","25 Apr 2019","2019","","","80","85","Car plate recognition is used in traffic monitoring and control systems such as intelligent parking lot management, finding stolen vehicles, and automated highway toll. In practice, Low-Resolution (LR) images or videos are widely used in surveillance systems. In low resolution surveillance systems, the car plate text is often illegible. Super-Resolution (SR) techniques can be used to improve the car plate quality by processing a series of LR images into a single High-Resolution (HR) image. Recovering the HR image from a single LR is still an ill-conditioned problem for SR. Previous methods always minimize the mean square loss in order to improve the peak signal to noise ratio (PSNR). However, minimizing the mean square loss leads to overly smoothed reconstructed image. In this paper, Generative Adversarial Networks (GANs) based SR is proposed to reconstruct the LR images into HR images. Besides that, perceptual loss is proposed to solve the smoothing issue. The quality of the GAN based SR generated images is compared to existing techniques such as bicubic, nearest and Super-Resolution Convolution Neural Network (SRCNN). The results show that the reconstructed images using GANs based SR achieve better results in term of perceptual quality compared to previous methods.","","978-1-5386-7563-2","10.1109/CSPA.2019.8696010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8696010","Super resolution;car plate;generative adversarial networks","Automobiles;Image resolution;Generators;Convolution;Image reconstruction;Signal resolution;Interpolation","automobiles;image enhancement;image recognition;image reconstruction;image resolution;neural nets;object recognition;traffic engineering computing;video surveillance","low resolution surveillance systems;car plate text;car plate images;car plate recognition;traffic monitoring;generative adversarial networks;image reconstruction;peak signal to noise ratio","","3","","29","IEEE","25 Apr 2019","","","IEEE","IEEE Conferences"
"Infrared imagery super-resolution by using a generative adversarial network","T. -A. Bui; P. -J. Lee; K. -M. Lee; W. Wang; S. -H. Shiu","Electrical Engineering Department, National Chi Nan Universtiy, Nantou, Taiwan; Electrical Engineering Department, National Chi Nan Universtiy, Nantou, Taiwan; Electrical Engineering Department, National Chi Nan Universtiy, Nantou, Taiwan; Research and Development Department, Liscotech System Co., Ltd., Taipei, Taiwan; Research and Development Department, Liscotech System Co., Ltd., Taipei, Taiwan","2021 IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW)","18 Nov 2021","2021","","","1","2","The thermal camera often has a limited spatial resolution compared to the RGB camera with typically provides megapixels of resolution. This study presents a super-resolution architecture for infrared (IR) imagery base on a generative adversarial network. The up-sampling in this proposed network’s design generates a new super-resolution image by four times. Moreover, in this paper, generative network and discriminative models for IR images are presented. The small-object features in super-resolution IR images are shown in the simulation section with high quality.","2575-8284","978-1-6654-3328-0","10.1109/ICCE-TW52618.2021.9603172","Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9603172","super-resolution;IR images;generative adversarial network;discriminative network","Conferences;Superresolution;Generative adversarial networks;Cameras;Spatial resolution","cameras;geophysical image processing;image reconstruction;image resolution;image sensors;infrared imaging","generative adversarial network;super-resolution image;generative network;super-resolution IR images;infrared imagery super-resolution;thermal camera;spatial resolution;RGB camera;super-resolution architecture;infrared imagery base","","","","8","IEEE","18 Nov 2021","","","IEEE","IEEE Conferences"
"Speech Super Resolution Generative Adversarial Network","S. E. Eskimez; K. Koishida","University of Rochester, Rochester, NY, USA; Microsoft Corporation, Redmond, WA, USA","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3717","3721","The goal of speech super-resolution (SSR) or speech bandwidth expansion is to generate the missing high-frequency components for a given low-resolution speech signal. It has the potential to improve the quality of telecommunications. We propose a new method for SSR that leverages the generative adversarial networks (GANs) and a regularization method for stabilizing the GAN training. The generator network is a convolutional autoencoder with 1D convolution kernels, operating along time-axis and generating the high-frequency log-power spectra from the low-frequency log-power spectra input. We employ two recent deep neural network (DNN) based approaches to compare them with our proposed method, including both objective speech quality metrics and subjective perceptual tests. We show that our proposed method outperforms the baseline methods in terms of both objective and subjective evaluations.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682215","generative adversarial networks;speech super-resolution;artificial speech bandwidth extension","Training;Narrowband;Generators;Signal resolution;Spectrogram;Generative adversarial networks;Convolution","convolution;learning (artificial intelligence);neural nets;signal reconstruction;speech processing","SSR;generative adversarial networks;regularization method;GAN training;generator network;1D convolution kernels;high-frequency log-power spectra;low-frequency log-power spectra input;objective speech quality metrics;speech super resolution generative adversarial network;speech bandwidth expansion;missing high-frequency components;low-resolution speech signal;deep neural network based approaches","","10","","31","IEEE","17 Apr 2019","","","IEEE","IEEE Conferences"
"Boosting Small Ship Detection in Optical Remote Sensing Images via Image Super-Resolution","L. Li; Z. Zhou; S. Cui","School of Automation, Beijing Institute of Technology, Beijing; School of Automation, Beijing Institute of Technology, Beijing; School of Automation, Beijing Institute of Technology, Beijing","2021 33rd Chinese Control and Decision Conference (CCDC)","30 Nov 2021","2021","","","1508","1512","Small ships in optical remote sensing images are hard to detect due to the lack of sufficient detail information. In this paper, we adopt the image super-resolution technology to solve this problem. Specifically, an effective super-resolution network is designed to generate clear super-resolution ship images from small blurry ones produced by the ship detector. Inspired by the idea of generative adversarial network (GAN), the super-resolution network is trained together with a discriminator network in an adversarial way, aiming at generating more realistic super-resolution images. Moreover, to eliminate false detections, the discriminator network is also used to distinguish ship and non-ship images via an additional classification branch. Experimental results demonstrate the effectiveness of the proposed method.","1948-9447","978-1-6654-4089-9","10.1109/CCDC52312.2021.9601674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9601674","Ship detection;Image super-resolution;Generative adversarial network","Training;Superresolution;Detectors;Optical detectors;Optical imaging;Generative adversarial networks;Boosting","image classification;image resolution;marine radar;object detection;radar imaging;remote sensing;ships","discriminator network;super-resolution images;false detections;nonship images;boosting small ship detection;optical remote sensing images;image super-resolution technology;super-resolution network;clear super-resolution ship images;ship detector;generative adversarial network","","","","16","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Simple and Efficient Unpaired Real-world Super-Resolution using Image Statistics","K. Yoon","SI Analytics, Daejeon, Republic of Korea","2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)","24 Nov 2021","2021","","","1983","1990","Learning super-resolution (SR) network without the paired low resolution (LR) and high resolution (HR) image is difficult because direct supervision through the corresponding HR counterpart is unavailable. Recently, many real-world SR researches take advantage of the unpaired image-to-image translation technique. That is, they used two or more generative adversarial networks (GANs), each of which translates images from one domain to another domain, e.g., translates images from the HR domain to the LR domain. However, it is not easy to stably learn such a translation with GANs using unpaired data. In this study, we present a simple and efficient method of training of real-world SR network. To stably train the network, we use statistics of an image patch, such as means and variances. Our real-world SR framework consists of two GANs, one for translating HR images to LR images (degradation task) and the other for translating LR to HR (SR task). We argue that the unpaired image translation using GANs can be learned efficiently with our proposed data sampling strategy, namely, variance matching. We test our method on the NTIRE 2020 real-world SR dataset. Our method outperforms the current state-of-the-art method in terms of the SSIM metric as well as produces comparable results on the LPIPS metric.","2473-9944","978-1-6654-0191-3","10.1109/ICCVW54120.2021.00225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9607538","","Measurement;Training;Degradation;Computer vision;Conferences;Superresolution;Generative adversarial networks","image resolution;learning (artificial intelligence);statistical analysis","image statistics;learning super-resolution network;paired low resolution;high resolution image;real-world SR researches;unpaired image-to-image translation technique;generative adversarial networks;GANs;HR domain;unpaired data;real-world SR network;image patch;real-world SR framework;LR images;NTIRE 2020 real-world SR dataset","","1","","21","IEEE","24 Nov 2021","","","IEEE","IEEE Conferences"
"Design of a High-Resolution Video Reconstruction and Transcoding System based on Super-Resolution GAN","T. -H. Hsu; P. -H. Wu; G. -J. Horng","Dept. of Computer Science and Information Engineering, Southern Taiwan University of Science and Technology, Tainan, Taiwan R.O.C.; Dept. of Computer Science and Information Engineering, Southern Taiwan University of Science and Technology, Tainan, Taiwan R.O.C.; Dept. of Computer Science and Information Engineering, Southern Taiwan University of Science and Technology, Tainan, Taiwan R.O.C.","2022 IET International Conference on Engineering Technologies and Applications (IET-ICETA)","8 Dec 2022","2022","","","1","2","With the popularization of high-definition video devices, more and more users and video streaming service providers desire to restore early classic videos and deliver classic video contents with improved resolution. However, existing video transcoding systems do not support super-resolution video reconstruction. A high-resolution video reconstruction and transcoding system design based on super-resolution image generative adversarial network (GAN) is proposed to perform super-resolution video reconstruction for low resolution videos and then transcode videos with different resolutions to meet the playback requirements of heterogeneous mobile devices in order to provide users with good video viewing quality. Users can have good video viewing quality with the proposed system even in the absence of the original high-resolution videos.","","978-1-6654-9138-9","10.1109/IET-ICETA56553.2022.9971690","Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9971690","Super Resolution Video Reconstruction;Generative Adversarial Network;Video Transcoding Server","Performance evaluation;Superresolution;Transcoding;Streaming media;Generative adversarial networks;Mobile handsets;Image restoration","image reconstruction;image resolution;transcoding;video coding;video signal processing;video streaming","classic video contents;early classic videos;existing video transcoding systems;good video viewing quality;high-definition video devices;high-resolution video reconstruction;high-resolution videos;low resolution videos;super-resolution GAN;super-resolution image generative adversarial network;super-resolution video reconstruction;transcode videos;transcoding system design;video streaming service providers","","","","10","IEEE","8 Dec 2022","","","IEEE","IEEE Conferences"
"Image Super-Resolution Reconstruction Using Generative Adversarial Networks Based on Wide-Channel Activation","X. Sun; Z. Zhao; S. Zhang; J. Liu; X. Yang; C. Zhou","School of Mechatronics Engineering, East China Jiaotong University, Nanchang, China; National Engineering Laboratory for Agri-Product Quality Traceability, Beijing, China; National Engineering Laboratory for Agri-Product Quality Traceability, Beijing, China; School of Engineering, University of Almería, Almería, Spain; National Engineering Laboratory for Agri-Product Quality Traceability, Beijing, China; National Engineering Laboratory for Agri-Product Quality Traceability, Beijing, China","IEEE Access","25 Feb 2020","2020","8","","33838","33854","In recent years, residual learning has shown excellent performance on convolutional neural network (CNN)-based single-image super-resolution (SISR) tasks. However, CNN-based SISR approaches have focused mainly on the design of deep architectures, and the rectified linear units (ReLUs) used in these networks hinder shallow-to-deep information transfer. As a result, these methods are unable to utilize some shallow information, and improving model performance is difficult. To solve the above issues, this paper proposes an image SR reconstruction method based on a generative adversarial network with a residual dense architecture. First, before ReLU activation, the number of feature channels is expanded by a factor of 6~9 using a 1 × 1 convolutional layer, which improves the utilization of shallow information. Next, the original discriminator is replaced with a relativistic average discriminator, thereby improving the authenticity of the discriminative network. Finally, preactivation features are used to improve the perceptual loss, thus providing stronger monitoring for brightness consistency and texture restoration. Experimental results show that the proposed algorithm improves the utilization of shallow information in a deep network. Structural similarity (SSIM) index evaluations show that the overall utilization of shallow information is increased by 105.52%. In addition, the average runtime is 0.42 sec/frame, nearly 3.6 times faster than those of traditional methods. Moreover, the recovered images have an average natural image quality evaluator value of 3.4 and high perceptual quality, showing that the proposed method is suitable for image reconstruction applications in fields such as agriculture and medicine.","2169-3536","","10.1109/ACCESS.2020.2974759","National Key Technology Research and Development Program of China(grant numbers:2019YFD0901004); National Natural Science Foundation of China(grant numbers:31960497); Beijing Academy of Agricultural and Forestry Sciences(grant numbers:QNJJ202014); Natural Science Foundation of Beijing Municipality(grant numbers:4184089); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9001139","Super-resolution;residual block;relativistic average discriminator;generative adversarial network;perceived quality","Image reconstruction;Gallium nitride;Generative adversarial networks;Image resolution;Brightness;Convolutional neural networks;Monitoring","convolutional neural nets;image reconstruction;image resolution;image texture;learning (artificial intelligence);neural net architecture","image super-resolution reconstruction;generative adversarial network;wide-channel activation;residual learning;convolutional neural network-based single-image super-resolution;CNN-based SISR approaches;deep architectures;rectified linear units;shallow-to-deep information transfer;image SR reconstruction method;residual dense architecture;ReLU activation;feature channels;brightness consistency;texture restoration;structural similarity index evaluations;SSIM","","4","","47","CCBY","18 Feb 2020","","","IEEE","IEEE Journals"
"Super-Resolution and Self-Attention with Generative Adversarial Network for Improving Malignancy Characterization of Hepatocellular Carcinoma","Y. Li; H. Huang; L. Zhang; G. Wang; H. Zhang; W. Zhou","School of Medical Information Engineering, Guangzhou University of Chinese Medicine, China; School of Medical Information Engineering, Guangzhou University of Chinese Medicine, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Department of Radiology, Guangdong General Hospital, Guangzhou, China; School of Medical Information Engineering, Guangzhou University of Chinese Medicine, China; School of Medical Information Engineering, Guangzhou University of Chinese Medicine, China","2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)","22 May 2020","2020","","","1556","1560","The slice thickness of MR imaging may remarkably degrade the clarity of 3D lesion images within through-plane slices (coronal or sagittal views) so as to influence the performance of lesion characterization. To alleviate the problem, we propose an end-to-end super-resolution and self-attention framework based on Generative adversarial networks (GAN) for improving the malignancy characterization of hepatocellular carcinoma (HCC). Specifically, a super-resolution subnetwork is designed to enhance the low-resolution patches of coronal or sagittal views based on the high resolution patches of the axial view, and then the enhanced patches are fed into the classification subnetwork for malignancy characterization. Furthermore, a self-attention mechanism is utilized to extract multi-level features for better super-resolution and lesion characterization. Experimental results of clinical HCCs demonstrate the superior performance of the proposed method compared with conventional CNN-based methods and show the potential in clinical practice.","1945-8452","978-1-5386-9330-8","10.1109/ISBI45749.2020.9098705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098705","Super-resolution;hepatocellular carcinoma;Convolutional Neural Network;malignancy;self-attention","Lesions;Feature extraction;Spatial resolution;Generators;Biomedical imaging;Generative adversarial networks","biomedical MRI;cancer;cellular biophysics;convolutional neural nets;feature extraction;image classification;image resolution;medical image processing","low-resolution patches;coronal views;sagittal views;high resolution patches;axial view;enhanced patches;classification subnetwork;self-attention mechanism;lesion characterization;malignancy characterization;hepatocellular carcinoma;slice thickness;MR imaging;3D lesion images;through-plane slices;end-to-end super-resolution;self-attention framework;super-resolution subnetwork;generative adversarial network;CNN-based methods;GAN;multilevel feature extraction;clinical HCC","","4","","12","IEEE","22 May 2020","","","IEEE","IEEE Conferences"
"Real-World Super-Resolution using Generative Adversarial Networks","H. Ren; A. Kheradmand; M. El-Khamy; S. Wang; D. Bai; J. Lee","SOC R&D, Samsung Semiconductor, Inc., San Diego, CA, USA; SOC R&D, Samsung Semiconductor, Inc., San Diego, CA, USA; SOC R&D, Samsung Semiconductor, Inc., San Diego, CA, USA; SOC R&D, Samsung Semiconductor, Inc., San Diego, CA, USA; SOC R&D, Samsung Semiconductor, Inc., San Diego, CA, USA; SOC R&D, Samsung Semiconductor, Inc., San Diego, CA, USA","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","1760","1768","Robust real-world super-resolution (SR) aims to generate perception-oriented high-resolution (HR) images from the corresponding low-resolution (LR) ones, without access to the paired LR-HR ground-truth. In this paper, we investigate how to advance the state of the art in real-world SR. Our method involves deploying an ensemble of generative adversarial networks (GANs) for robust real-world SR. The ensemble deploys different GANs trained with different adversarial objectives. Due to the lack of knowledge about the ground-truth blur and noise models, we design a generic training set with the LR images generated by various degradation models from a set of HR images. We achieve good perceptual quality by super resolving the LR images whose degradation was caused by unknown image processing artifacts. For real-world SR on images captured by mobile devices, the GANs are trained by weak supervision of a mobile SR training set having LR-HR image pairs, which we construct from the DPED dataset which provides registered mobile-DSLR images at the same scale. Our ensemble of GANs uses cues from the image luminance and adjusts to generate better HR images at low-illumination. Experiments on the NTIRE 2020 real-world super-resolution dataset show that our proposed SR approach achieves good perceptual quality.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150661","","Image resolution;Degradation;Gallium nitride;Training;Kernel;Generative adversarial networks","image resolution;learning (artificial intelligence);neural nets","generative adversarial networks;GAN;noise models;generic training set;unknown image processing artifacts;mobile SR training set;LR-HR image pairs;image luminance;perception-oriented high-resolution imaging;mobile-DSLR imaging;ground-truth blurring;DPED dataset;perception-oriented high-resolution image generation;NTIRE 2020 real-world superresolution dataset","","7","1","35","IEEE","28 Jul 2020","","","IEEE","IEEE Conferences"
"Generative Adversarial Network with Residual Dense Generator for Remote Sensing Image Super Resolution","R. Sustika; A. B. Suksmono; D. Danudirdjo; K. Wikantika","Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung (ITB), Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung (ITB), Bandung, Indonesia; Faculty of Earth Sciences and Technology, Institut Teknologi Bandung (ITB), Bandung, Indonesia","2020 International Conference on Radar, Antenna, Microwave, Electronics, and Telecommunications (ICRAMET)","25 Dec 2020","2020","","","34","39","Improving image resolution, especially spatial resolution, has been one of the most important concerns on remote sensing research communities. An efficient solution for improving spatial resolution is by using algorithm, known as super-resolution (SR). The super-resolution technique that received special attention recently is super-resolution based on deep learning. In this paper, we propose deep learning approach based on generative adversarial network (GAN) for remote sensing images super resolution. We used residual dense network (RDN) as generator network. Generally, deep learning with residual dense network (RDN) gives high performance on classical (objective) evaluation metrics meanwhile generative adversarial network (GAN) based approach shows a high perceptual quality. Experiment results show that combination of residual dense network generator with generative adversarial network training is found to be effective. Our proposed method outperforms the baseline method in terms of objective and perceptual quality evaluation metrics.","","978-1-7281-8922-2","10.1109/ICRAMET51080.2020.9298648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298648","convolutional neural network;generative adversarial network;remote sensing;image;residual dense network;super-resolution","Training;Spatial resolution;Remote sensing;Generators;Generative adversarial networks;PSNR;Measurement","image reconstruction;image resolution;learning (artificial intelligence);remote sensing","generative adversarial network training;residual dense generator;remote sensing image super resolution;image resolution;spatial resolution;remote sensing research communities;super-resolution technique;deep learning approach;remote sensing images super resolution;generator network;residual dense network generator","","2","","15","IEEE","25 Dec 2020","","","IEEE","IEEE Conferences"
"Dual Discriminator Generative Adversarial Network for Single Image Super-Resolution","P. Liu; Y. Hong; Y. Liu","University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Information Technology for Autonomous Underwater Vehicles, Chinese Academy of Science, Beijing, China; Key Laboratory of Information Technology for Autonomous Underwater Vehicles, Chinese Academy of Science, Beijing, China","2018 IEEE 9th International Conference on Software Engineering and Service Science (ICSESS)","10 Mar 2019","2018","","","1","8","Recently, several algorithms have been proposed to achieve the single image super-resolution by using deep convolutional neural networks. In this study, we present a dual discrimination generative adversarial network (D2GAN) for single image super-resolution (SISR). The proposed model has better stability to complete the reconstruction of super-resolution images for ×4 scale factor. The improved residual network and perceptual loss function are applied in the proposed algorithm which demonstrates a superior performance over state-of-the-art restoration quality. Meanwhile, the proposed reconstruction network has a faster training and convergence speed compared with other super-resolution methods. The proposed approach is evaluated on standard datasets and gets improved performance than previous works that based on deep convolutional neural networks.","2327-0594","978-1-5386-6565-7","10.1109/ICSESS.2018.8663715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663715","component;single image super-resolution;deep neural network;residual networks;peak signal-to-noise ratio;structural similarity index","Image resolution;Generative adversarial networks;Image reconstruction;Gallium nitride;Signal resolution;Convolution;Data models","convolutional neural nets;image reconstruction;image resolution;learning (artificial intelligence)","single image super-resolution;deep convolutional neural networks;dual discrimination generative adversarial network;super-resolution images;residual network;reconstruction network;super-resolution methods;standard datasets;training;convergence speed;perceptual loss function","","1","","37","IEEE","10 Mar 2019","","","IEEE","IEEE Conferences"
"Regularized Latent Space Exploration for Discriminative Face Super-Resolution","R. Shi; J. Zhang; Y. Li; S. Ge","School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","2534","2538","Learning face super-resolution models is challenged in many practical scenarios where high-resolution and low-resolution face pairs usually are difficult to collect for training examples. Recent self-supervised approach provides a feasible solution by using low-resolution faces to guide the generation of the corresponding high-resolution ones with a pretrained generator. In this paper, we propose a regularized latent space exploration approach to facilitate self-supervised face super-resolution. In the approach, a pretrained generative adversarial network (GAN) is fully used to control the exploration of high-resolution face generation in an iterative optimization manner for a low-resolution face. During the iteration, super-resolution faces are continually generated from a feasible latent space by the generator and evaluated by the discriminator, while the generator is online finetuned. The generation is evaluated by measuring the semantic loss as well as pixel loss between ground-truth low-resolution faces and the corresponding downsampled super-resolution faces. In this way, the generated faces can be appearance natural and semantic discriminative. Experiments validate the effectiveness of our approach in terms of quantitative metrics and visual quality.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746928","National Natural Science Foundation of China; Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746928","Face super-resolution;self-supervised learning;discriminative features","Training;Visualization;Superresolution;Semantics;Generative adversarial networks;Generators;Space exploration","face recognition;image resolution;iterative methods;neural nets;optimisation;unsupervised learning","regularized latent space exploration approach;self-supervised face super-resolution;pretrained generative adversarial network;high-resolution face generation;super-resolution faces;feasible latent space;ground-truth low-resolution faces;discriminative face super-resolution;low-resolution face pairs;self-supervised approach;pretrained generator","","","","27","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Image Super Resolution Reconstruction Algorithm Based on Strong Constraint","S. Shi; M. Li","College of Operational Support, Rocket Force University of Engineering, Xi’an, China; College of Operational Support, Rocket Force University of Engineering, Xi’an, China","2022 3rd International Conference on Computer Vision, Image and Deep Learning & International Conference on Computer Engineering and Applications (CVIDL & ICCEA)","18 Jul 2022","2022","","","1","5","To solve the problem of texture details loss in super-resolution reconstructed images, a novel image super-resolution algorithm (SCGAN) based on strong constraints with better fidelity was proposed. Firstly, in order to reconstruct finer texture details, an enhanced loss function was designed based on L1 function. Secondly, channel attention mechanism is introduced in super-resolution generative adversarial network architecture, and input feature weight parameters are given. Finally, the algorithm is validated on several benchmark data sets. The experimental results show that SCGAN not only has better visual effect, but also improves the objective evaluation index. Perceived similarity (LPIPS) improved at least 2.3% on average across the five test sets. Excluding RRDB algorithm with poor LPIPS, PSNR and SSIM improved at least 1. 2303dB on average and 0.0408 on average.","","978-1-6654-5911-2","10.1109/CVIDLICCEA56201.2022.9824123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9824123","super resolution;strong constraint;Generative Adversarial Network;channel attention","Superresolution;Reconstruction algorithms;Benchmark testing;Visual effects;Generative adversarial networks;Image restoration;Indexes","image reconstruction;image resolution;image texture","LPIPS;SCGAN;RRDB algorithm;image super resolution reconstruction algorithm;texture details loss;super-resolution reconstructed images;fine texture details;enhanced loss function;channel attention mechanism;super-resolution generative adversarial network architecture;L1 function;PSNR;SSIM","","","","26","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Multi-Frame Super-Resolution Algorithm Based on a WGAN","K. Ning; Z. Zhang; K. Han; S. Han; X. Zhang","School of Computer Science and Technology, North China University of Technology, Beijing, China; School of Computer Science and Technology, North China University of Technology, Beijing, China; School of Computer Science and Technology, North China University of Technology, Beijing, China; School of Computer Science and Technology, North China University of Technology, Beijing, China; School of Science, Institute of Photoelectronics Technology, Beijing Jiaotong University, Beijing, China","IEEE Access","18 Jun 2021","2021","9","","85839","85851","Image super-resolution reconstruction has been widely used in remote sensing, medicine and other fields. In recent years, due to the rise of deep learning research and the successful application of convolutional neural networks in the image field, the super-resolution reconstruction technology based on deep learning has also achieved great development. However, there are still some problems that need to be solved. For example, the current mainstream image super-resolution algorithms based on single or multiple frames pursue high performance indicators such as PSNR and SSIM, while the reconstructed image is relatively smooth and lacks many high-frequency details. It is not conducive to application in a real environment. To address such problem, this paper proposes a super-resolution reconstruction model of sequential images based on Generative Adversarial Networks (GAN). The proposed approach combines the registration module to fuse adjacent frames, effectively use the detailed information in multiple consecutive frames, and enhances the spatio-temporality of low-resolution images in sequential images. While the GAN was used to improve the effect of image high-frequency texture detail reconstruction, WGAN was introduced to optimize model training. The reconstruction results not only improved the PSNR and SSIM indexes but also reconstructed more high-frequency detail textures. Finally, in order to further improve the perception effect, an additional registration loss item RLT is introduced in the GAN network perception loss. Through extensive experiments, it shows that the model proposed in this paper effectively obtains the information between the sequence images. When the PSNR and SSIM indicators are improve, it can reconstruct better high-frequency texture details than the current advanced multi-frame algorithms.","2169-3536","","10.1109/ACCESS.2021.3088128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9452141","Super-resolution reconstruction;sequential images;convolutional neural network;Wasserstein generative adversarial network (WGAN)","Image reconstruction;Superresolution;Generative adversarial networks;Spatial resolution;Generators;Visual perception","edge detection;image denoising;image reconstruction;image resolution;image sampling;image sequences;image texture;learning (artificial intelligence);maximum likelihood estimation;neural nets;wavelet transforms","remote sensing;deep learning research;convolutional neural networks;image field;super-resolution reconstruction technology;current mainstream image super-resolution algorithms;single frames;high performance indicators;reconstructed image;high-frequency details;super-resolution reconstruction model;sequential images;Generative Adversarial Networks;multiple consecutive frames;low-resolution images;image high-frequency texture;WGAN;high-frequency detail textures;GAN network perception loss;sequence images;high-frequency texture details;current advanced multiframe algorithms;multiframe super-resolution algorithm","","3","","39","CCBY","11 Jun 2021","","","IEEE","IEEE Journals"
"Video Super Resolution with Generative Adversarial Network","K. Gopan; G. S. Kumar","Department of Electronics and Communication, Sree Chitra Thirunal College of Engineering, pappanamcode, India; Department of Electronics and Communication, Sree Chitra Thirunal College of Engineering, pappanamcode, India","2018 2nd International Conference on Trends in Electronics and Informatics (ICOEI)","2 Dec 2018","2018","","","1489","1493","This paper exhibits a novel implementation of video super resolution through Generative adversarial network. Generative adversarial networks (GANs) are a class of artificial intelligence algorithm implemented by a system of two neural networks provide a unique way to learn deep representations. The results of GAN shows slightly lower PSNR compared to traditional methods, since the frames produced by GAN is more appealing when viewed by human. GAN can learn from large datasets and automatically add high-frequency details and features to frames while traditional methods can't. The generator discriminator architecture in GAN pushes it to generate more realistic and appealing frames.","","978-1-5386-3570-4","10.1109/ICOEI.2018.8553719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8553719","Video super resolution;Generative adversarial network","Image resolution;Generative adversarial networks;Signal resolution;Conferences;Gallium nitride;Image reconstruction;Generators","image representation;image resolution;learning (artificial intelligence);neural nets;video signal processing","neural networks;GAN;generator discriminator architecture;video super resolution;Generative adversarial network;artificial intelligence algorithm;deep representation;PSNR","","2","","12","IEEE","2 Dec 2018","","","IEEE","IEEE Conferences"
"Guided Super-Resolution Restoration of Single Image Based on Image Quality Evaluation Network","S. Chen; S. Li; C. zhu","School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China","2019 IEEE THE 2nd INTERNATIONAL CONFERENCE ON MICRO/NANO SENSORS for AI, HEALTHCARE, AND ROBOTICS (NSENS)","21 Dec 2020","2019","","","72","77","SISR (Single image super-resolution) has always been a key problem in image processing field. In recent years, deep learning has been successfully used to SISR reconstruction. However, most of the previous deep learning methods use L2 norm based on pixel pairs as loss function, which results in a high peak signal-to-noise ratio (PSNR) value, but the perception quality has not been improved. When using Generative Adversarial Network (GAN), although it has good perception quality, PSNR is lower. So we’ll generate realistic results when both of them are used well. The image quality evaluation (IQA) network is to evaluate the image quality, so as to obtain good PSNR value and perception quality. In this paper, we use image quality assessment network to guide the SISR reconstruction network. Besides that, our proposed Super-resolution reconstruction of single image method is composed of several our given cross-attention units (CA) and is trained iteratively. Experimental results demonstrate that our method in qualitative and quantitative is better than others.","","978-1-7281-6652-0","10.1109/NSENS49395.2019.9293988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9293988","Single image super-resolution;cross-attention;image quality assessment;Generative Adversarial Network","Feature extraction;Convolution;Image quality;Image reconstruction;Training;Generative adversarial networks;Fuses","deep learning (artificial intelligence);image reconstruction;image resolution;image restoration","super-resolution restoration;image quality evaluation network;image processing field;deep learning;pixel pairs;loss function;signal-to-noise ratio;perception quality;PSNR value;image quality assessment network;SISR reconstruction network;super-resolution reconstruction;generative adversarial network;SISR;single image super-resolution","","","","25","IEEE","21 Dec 2020","","","IEEE","IEEE Conferences"
"An Adversarial Super-Resolution Remedy for Radar Design Trade-offs","K. Armanious; S. Abdulatif; F. Aziz; U. Schneider; B. Yang","Institute of Signal Processing and System Theory, University of Stuttgart, Germany; Institute of Signal Processing and System Theory, University of Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Institute of Signal Processing and System Theory, University of Stuttgart, Germany","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","Radar is of vital importance in many fields, such as autonomous driving, safety and surveillance applications. However, it suffers from stringent constraints on its design parametrization leading to multiple trade-offs. For example, the bandwidth in FMCW radars is inversely proportional with both the maximum unambiguous range and range resolution. In this work, we introduce a new method for circumventing radar design trade-offs. We propose the use of recent advances in computer vision, more specifically generative adversarial networks (GANs), to enhance low-resolution radar acquisitions into higher resolution counterparts while maintaining the advantages of the low-resolution parametrization. The capability of the proposed method was evaluated on the velocity resolution and range-azimuth trade-offs in micro-Doppler signatures and FMCW uniform linear array (ULA) radars, respectively.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8902510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902510","Radar;Super-resolution;Micro-Doppler;MIMO;Range-azimuth;Convolutional neural network;CNN;Generative adversarial networks;GAN;Remote sensing","Radar imaging;Legged locomotion;Generators;Generative adversarial networks;Sensors","computer vision;CW radar;direction-of-arrival estimation;Doppler radar;FM radar;radar imaging;radar resolution","safety;surveillance applications;design parametrization;multiple trade-offs;FMCW radars;maximum unambiguous range;range resolution;radar design trade-offs;generative adversarial networks;low-resolution radar acquisitions;low-resolution parametrization;velocity resolution;FMCW uniform linear array radars;adversarial super-resolution remedy;range-azimuth trade-offs;computer vision","","15","","28","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Image Super-Resolution via Generative Adversarial Network Using an Orthogonal Projection","H. Yamamoto; D. Kitahara; A. Hirabayashi","Graduate School of Information Science and Engineering, Ritsumeikan University, Shiga, Japan; Graduate School of Information Science and Engineering, Ritsumeikan University, Shiga, Japan; Graduate School of Information Science and Engineering, Ritsumeikan University, Shiga, Japan","2020 28th European Signal Processing Conference (EUSIPCO)","18 Dec 2020","2021","","","660","664","In this paper, we propose a simple but powerful idea to improve super-resolution (SR) methods based on convolutional neural networks (CNNs). We consider a linear manifold, which is the set of all SR images whose downsampling results are the same as the input image, and apply the orthogonal projection onto this linear manifold in the output layers of the CNNs. The proposed method can guarantee the consistency between the SR image and the input image and reduce the mean squared error. The proposed method is especially effective for SR methods based on generative adversarial networks (GANs), composed of one generator and one discriminator, since the generator can learn high-frequency components while maintaining low-frequency ones. Experiments show the effectiveness of the proposed technique for a GAN-based SR method. Finally we introduce an idea of extension to noisy images.","2076-1465","978-9-0827-9705-3","10.23919/Eusipco47968.2020.9287515","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287515","Single image super-resolution;generative adversarial network;orthogonal projection;constrained learning","Manifolds;Europe;Generative adversarial networks;Generators;Noise measurement;Convolutional neural networks;Signal resolution","convolutional neural nets;image resolution;image sampling;mean square error methods","image super-resolution;generative adversarial network;orthogonal projection;convolutional neural networks;CNNs;linear manifold;downsampling;output layers;SR image;mean squared error;noisy images;GAN-based SR;generator;discriminator;high-frequency components;low-frequency components","","","","23","","18 Dec 2020","","","IEEE","IEEE Conferences"
"Image Super-Resolution Method Based on Improved Generative Adversarial Network","N. Xiang; B. Tang; L. Wang","Liangjiang international college, Chongqing University of Technology, Chongqing, China; Liangjiang international college, Chongqing University of Technology, Chongqing, China; Liangjiang international college, Chongqing University of Technology, Chongqing, China","2022 IEEE 5th International Conference on Electronics Technology (ICET)","14 Jul 2022","2022","","","1207","1212","The image super-resolution algorithm based on generative adversarial network has the problem of imperfect extraction of detailed texture features, and the network is difficult to converge in the training process. Therefore, a new image super-resolution method: MR-SRGAN (Multi-branch receptive field dense block improved super-resolution generative adversarial network) is proposed. MR-SRGAN extracts image detail texture features through the new MBRS residual block and MRB module, then adjusts the loss function of the model to make the training easier to converge. Finally, in the super-resolution comparison experiment on Set5 and Set14 datasets, under the magnification of 2 and 4 times, the PSNR value of this algorithm is 0.36dB (Set $5 \times 2)$, 0.15dB (Set $14 \times 2)$, 0.63dB (Set $5 \times 4)$, 0.57dB (Set $14 \times 4)$ higher than SRGAN algorithm.","2768-6515","978-1-6654-8508-1","10.1109/ICET55676.2022.9824258","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9824258","Super-resolution;MR-SRGAN;MBRS residual block;MRB module","Training;Deep learning;Visualization;Conferences;Superresolution;Neural networks;Generative adversarial networks","feature extraction;image resolution;image texture;learning (artificial intelligence);neural nets","image super-resolution algorithm;texture features;MR-SRGAN;extracts image detail texture features;multibranch receptive field dense block improved super-resolution generative adversarial network;MBRS residual block;MRB module","","","","17","IEEE","14 Jul 2022","","","IEEE","IEEE Conferences"
"Enhancing Face Super-Resolution via Improving the Edge and Identity Preserving Network","M. B. Shahbakhsh; H. Hassanpour","Faculty of Computer Engineering & IT, Shahrood University of Technology, Shahrood, Iran; Faculty of Computer Engineering & IT, Shahrood University of Technology, Shahrood, Iran","2021 7th International Conference on Signal Processing and Intelligent Systems (ICSPIS)","11 Mar 2022","2021","","","1","4","Face super-resolution, known as face hallucination, is a domain-specific image super-resolution problem, which refers to generating high resolution face images from their low resolution. State-of-the-art face super-resolution methods used deep convolutional neural networks. However, due to significant pose changes and difficulty in recovering high-frequency details in facial areas, most of these methods do not deploy facial structures and identity information well, and it is tough for them to reconstruct super-resolved face images. According to previous researches, proper use of low-resolution image edges can be a solution for these problems. EIPNet (Edge and Identity Preserving Network) is one of the newest methods to achieve outstanding results in this area. In the EIPNet method, the authors used a lightweight edge extraction block in the proposed GAN structure. In this research, we intend to improve the performance of the EIPNet method by presenting a simple but efficient technique. Our proposed technique divides the face images into upper and lower parts. We train a separate network for each area. This technique reduces the number of face components to train from each area, and the networks can better be trained from their components. The results show that this technique can have an excellent effect on visual quality and quantitative measurements in face super-resolution.","","978-1-6654-0938-4","10.1109/ICSPIS54653.2021.9729372","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729372","Super-resolution;Face hallucination;Generative Adversarial Network;Facial components","Visualization;Image edge detection;Superresolution;Generative adversarial networks;Convolutional neural networks;Intelligent systems;Faces","edge detection;face recognition;image reconstruction;image resolution;neural nets","high resolution face images;state-of-the-art face super-resolution methods;deep convolutional neural networks;super-resolved face images;low-resolution image edges;Identity Preserving Network;EIPNet method;face components;face hallucination;domain-specific image super-resolution problem","","","","13","IEEE","11 Mar 2022","","","IEEE","IEEE Conferences"
"RankSRGAN: Generative Adversarial Networks With Ranker for Image Super-Resolution","W. Zhang; Y. Liu; C. Dong; Y. Qiao","ShenZhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences; ShenZhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; ShenZhen Key Lab of Computer Vision and Pattern Recognition, SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China","2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","3096","3105","Generative Adversarial Networks (GAN) have demonstrated the potential to recover realistic details for single image super-resolution (SISR). To further improve the visual quality of super-resolved results, PIRM2018-SR Challenge employed perceptual metrics to assess the perceptual quality, such as PI, NIQE, and Ma. However, existing methods cannot directly optimize these indifferentiable perceptual metrics, which are shown to be highly correlated with human ratings. To address the problem, we propose Super-Resolution Generative Adversarial Networks with Ranker (RankSRGAN) to optimize generator in the direction of perceptual metrics. Specifically, we first train a Ranker which can learn the behavior of perceptual metrics and then introduce a novel rank-content loss to optimize the perceptual quality. The most appealing part is that the proposed method can combine the strengths of different SR methods to generate better results. Extensive experiments show that RankSRGAN achieves visually pleasing results and reaches state-of-the-art performance in perceptual metrics. Project page: https://wenlongzhang0724.github.io/Projects/RankSRGAN.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9008788","","Measurement;Image resolution;Feature extraction;Gallium nitride;Generators;Visualization;Image quality","image resolution;neural nets;unsupervised learning","RankSRGAN;Ranker;single image super-resolution;visual quality;PIRM2018-SR Challenge;perceptual quality;Super-Resolution Generative Adversarial Networks;rank-content loss;SISR","","131","","42","IEEE","27 Feb 2020","","","IEEE","IEEE Conferences"
"Underwater Acoustic Image Enhancement by Using Fast Super-Resolution with Generative Adversarial Networks","A. Bucci; A. Topini; M. Franchi; L. Zacchini; N. Secciani; A. Ridolfi","Interuniversity Center of Integrated Systems for the Marine Environment (ISME), Italy; Interuniversity Center of Integrated Systems for the Marine Environment (ISME), Italy; Interuniversity Center of Integrated Systems for the Marine Environment (ISME), Italy; Interuniversity Center of Integrated Systems for the Marine Environment (ISME), Italy; Interuniversity Center of Integrated Systems for the Marine Environment (ISME), Italy; Interuniversity Center of Integrated Systems for the Marine Environment (ISME), Italy","Global Oceans 2020: Singapore – U.S. Gulf Coast","9 Apr 2021","2020","","","1","8","Acoustic sensors play a fundamental role in underwater applications. They are used to perform a wide variety of tasks: from the perception of the surrounding environment to the support of inertial sensors in navigation strategies. The quality of the acquired images deeply affects the obtained results and, consequently, image enhancement approaches need to be developed and tested. Super-Resolution (SR) techniques are employed to reconstruct one high-resolution image by composing a sequence of low-resolution ones. By applying these strategies, the information content of an image can be considerably increased, but the required computational time is incompatible for real-time employment. Due to this limitation, an SR Generative Adversarial Network (SRGAN) approach has been developed in the presented work, where the SR images are used during the training phase of the GAN framework. The proposed approach, which has been developed for images provided by a Forward-Looking Sonar (FLS), can guarantee a solid trade-off between the quality of the generated high-resolution image and the run-time execution.","0197-7385","978-1-7281-5446-6","10.1109/IEEECONF38699.2020.9389055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9389055","Sonar Imaging;Super Resolution;Generative Adversarial Network;Signal Processing;Underwater Imaging;Marine Robotics","Training;Superresolution;Sonar;Generative adversarial networks;Underwater acoustics;Task analysis;Image enhancement","acoustic imaging;image enhancement;image reconstruction;image resolution;marine navigation;sonar imaging","acoustic sensors;inertial sensors;navigation strategies;image enhancement;super-resolution techniques;high-resolution image;computational time;real-time employment;SR images;acoustic image enhancement;SR generative adversarial network;GAN framework;Forward-Looking Sonar;FLS;SRGAN","","1","","21","IEEE","9 Apr 2021","","","IEEE","IEEE Conferences"
"Toward Faster and Accurate Post-Disaster Damage Assessment: Development of End-to-End Building Damage Detection Framework with Super-Resolution Architecture","X. Fu; T. Kouyama; H. Yang; R. Nakamura; I. Yoshikawa","National Institute of Advance Industrial Science and Technology, Tokyo, Japan; National Institute of Advance Industrial Science and Technology, Tokyo, Japan; The University of Tokyo, Tokyo, Japan; National Institute of Advance Industrial Science and Technology, Tokyo, Japan; The University of Tokyo, Tokyo, Japan","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1588","1591","Building damage detection (BDD) with satellite images has been frequently adopted as an essential reference for post-disaster rescue, whereas its timeliness is significantly impacted by the long revisit time of high-resolution remote sensing satellites. Therefore, a reliable super-resolution method which is optimized for accurate and detail BDD is fundamental one for advancing the BDD analysis even when we can use only low-resolution images after a disaster. Based on Super-Resolution Generative Adversarial Network (SRGAN) and U-Net convolutional network, an efficient and novel BDD framework is proposed in this paper for obtaining upsampled BDD results from low-resolution post-disaster images. We trained the framework using two disasters from the xBD dataset and tested three different structures. The results show that our training structure based on an end-to-end framework successfully generated super-resolution BDD maps from low-resolution images, which performed significantly better than those from a two-stage training structure.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883317","Super-resolution;building damage;xBD dataset;end-to-end network;deep learning","Training;Satellites;Architecture;Superresolution;Buildings;Generative adversarial networks;Reliability","buildings (structures);convolutional neural nets;disasters;geophysical image processing;image resolution;remote sensing","Super-Resolution Generative Adversarial Network;U-Net convolutional network;low-resolution post-disaster images;super-resolution BDD maps;post-disaster damage assessment;satellite images;post-disaster rescue;high-resolution remote sensing satellites;end-end building damage detection framework;SRGAN","","","","11","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Unsupervised Image Super-Resolution Using Cycle-in-Cycle Generative Adversarial Networks","Y. Yuan; S. Liu; J. Zhang; Y. Zhang; C. Dong; L. Lin","Sensetime Research; Department of Automation, Tsinghua University, Beijing; Sensetime Research; Graduate School at Shenzhen, Tsinghua University, Shenzhen; Sensetime Research; Sensetime Research","2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","16 Dec 2018","2018","","","814","81409","We consider the single image super-resolution problem in a more general case that the low-/high-resolution pairs and the down-sampling process are unavailable. Different from traditional super-resolution formulation, the low-resolution input is further degraded by noises and blurring. This complicated setting makes supervised learning and accurate kernel estimation impossible. To solve this problem, we resort to unsupervised learning without paired data, inspired by the recent successful image-to-image translation applications. With generative adversarial networks (GAN) as the basic component, we propose a Cycle-in-Cycle network structure to tackle the problem within three steps. First, the noisy and blurry input is mapped to a noise-free low-resolution space. Then the intermediate image is up-sampled with a pre-trained deep model. Finally, we fine-tune the two modules in an end-to-end manner to get the high-resolution output. Experiments on NTIRE2018 datasets demonstrate that the proposed unsupervised method achieves comparable results as the state-of-the-art supervised models.","2160-7516","978-1-5386-6100-0","10.1109/CVPRW.2018.00113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8575264","","Image resolution;Kernel;Training;Gallium nitride;Generators;Degradation;Unsupervised learning","image denoising;image resolution;image restoration;neural nets;unsupervised learning","supervised learning;unsupervised learning;image-to-image translation applications;noisy input;blurry input;noise-free low-resolution space;unsupervised image super-resolution;single image super-resolution problem;down-sampling process;super-resolution formulation;low-resolution input;kernel estimation;cycle-in-cycle generative adversarial networks;NTIRE2018 dataset","","196","","35","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"Detection and Mapping of an Uncooperative Spinning Target under Low-light Illumination Condition","J. Mu; S. Cao; Y. Sheng; Y. Zhou; Z. Liu","Shanghai Aerospace Control Technology Institute, Shanghai Key Laboratory of Aerospace Intelligent Control Technology, Shanghai, China; Shanghai Aerospace Control Technology Institute, Shanghai Key Laboratory of Aerospace Intelligent Control, Shanghai, China; Shanghai Aerospace Control Technology Institute, Shanghai Key Laboratory of Aerospace Intelligent Control, Shanghai, China; Automation and Electronic Information, Xiangtan University, Xiangtan, China; Shanghai Aerospace Control Technology Institute, Shanghai Key Laboratory of Aerospace Intelligent Control, Shanghai, China","2021 China Automation Congress (CAC)","14 Mar 2022","2021","","","3885","3890","This paper investigates the simultaneous detection and mapping problem for inspecting an unknown and uncooperative target that is spinning in space. First, we apply a new unsupervised generative adversarial network (GAN) to enhance the low contrast and poor visibility images which are captured in low-light space illumination conditions. Second, due to the captured low-resolution (LR) images of the target contain small size of key-components, so that we propose a new small object detection network that combines a GAN-based super-resolution (SR) network and a FRCNN-based detection network to locate these objects. The SR network was used to reconstruct super-resolved images from the original LR images. Third, we utilize a SLAM-based algorithm to map and estimate the pose of the spinning target based on previous image enhancement. In summary, the integrated architecture has three components: a low-light enhancement GAN, a small object detection network, and a real-time SLAM system. The experimental results show that the integrated architecture achieves better visual quality and improves the awareness of an uncooperative spinning target.","2688-0938","978-1-6654-2647-3","10.1109/CAC53003.2021.9727717","Research and Development; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9727717","Low-light Image Enhancement;Super Resolution;Non-cooperative spinning target;Pose determination;Generative Adversarial Networks","Visualization;Simultaneous localization and mapping;Target tracking;Superresolution;Lighting;Object detection;Generative adversarial networks","gallium compounds;image enhancement;image reconstruction;image resolution;mobile robots;object detection;robot vision;SLAM (robots)","SLAM-based algorithm;map;estimate;previous image enhancement;low-light enhancement GAN;object detection network;uncooperative spinning target;low-light illumination condition;mapping problem;unknown target;uncooperative target;unsupervised generative adversarial network;poor visibility images;low-light space illumination conditions;low-resolution images;GAN-based super-resolution network;FRCNN-based detection network;SR network;original LR images","","","","18","IEEE","14 Mar 2022","","","IEEE","IEEE Conferences"
"Enhancement of Retinal Image From Line-Scanning Ophthalmoscope Using Generative Adversarial Networks","W. Li; Y. He; W. Kong; F. Gao; J. Wang; G. Shi","Suzhou Institute of Biomedical Engineering and Technology, Suzhou, Jiangsu, CN; Suzhou Institute of Biomedical Engineering and Technology, Suzhou, Jiangsu, CN; Suzhou Institute of Biomedical Engineering and Technology, Suzhou, Jiangsu, CN; Suzhou Institute of Biomedical Engineering and Technology, Suzhou, Jiangsu, CN; Suzhou Institute of Biomedical Engineering and Technology, Suzhou, Jiangsu, CN; Suzhou Institute of Biomedical Engineering and Technology, Suzhou, Jiangsu, CN","IEEE Access","5 Aug 2019","2019","7","","99830","99841","A line-scanning ophthalmoscope (LSO) is a retinal imaging technique that has the characteristics of high imaging resolution, wide field of view, and high imaging speed. However, the high-speed imaging with rather short exposure time inevitably reduces the signal intensity, and many factors, such as speckle noise and intraocular scatter, further degrade the signal-to-noise ratio (SNR) of retinal images. To effectively improve the image quality without increasing the LSO system’s complexity, the post-processing method of image super-resolution (SR) is adopted. In this paper, we propose a learning-based multi-frame retinal image SR method that directly learns an end-to-end mapping from low-resolution (LR) image sequences to high-resolution (HR) images. This network was validated on down-sampled and real LSO image sequences. We evaluated the method on a down-sampled dataset with the metrics of peak signal-to-noise ratio (PSNR), structural similarity (SSIM), and perceptual distance. Moreover, the power spectra and full width at half maximum (FWHM) were used as the no-reference image quality assessment (NR-IQA) algorithms to evaluate the reconstruction results of the real LSO image sequences. The experimental results indicate that the proposed method can significantly enhance the SNR of LSO images and efficiently improve the resolution of LSO retinal images, which has great practical significance for clinical diagnosis and analysis.","2169-3536","","10.1109/ACCESS.2019.2930329","National Basic Research Program of China (973 Program)(grant numbers:2017YFC0108201,2016YFC0102500,2017YFB0403700); National Natural Science Foundation of China(grant numbers:61605210,61675226); Frontier Science research project of the Chinese Academy of Sciences(grant numbers:QYZDB-SSW-JSC03); Jiangsu Province Science Fund for Distinguished Young Scholars(grant numbers:BK20160010); Chinese Academy of Sciences(grant numbers:XDB32000000); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8768363","Line-scanning ophthalmoscope;retinal images;multi-frame image super-resolution;learning-based","Retina;Imaging;Spatial resolution;Image sequences;Image reconstruction;Generative adversarial networks","biomedical optical imaging;image reconstruction;image resolution;image sequences;learning (artificial intelligence);medical image processing","low-resolution image sequences;high-resolution images;LSO image sequences;structural similarity;no-reference image quality assessment algorithms;LSO retinal images;line-scanning ophthalmoscope;generative adversarial networks;retinal imaging technique;high-speed imaging;signal intensity;speckle noise;signal-to-noise ratio;LSO system;image super-resolution;learning-based multiframe retinal image SR method;postprocessing method","","5","","42","CCBY","22 Jul 2019","","","IEEE","IEEE Journals"
"ESRGAN+ : Further Improving Enhanced Super-Resolution Generative Adversarial Network","N. C. Rakotonirina; A. Rasoanaivo","Laboratoire d’Informatique et Mathématiques, Université d’Antananarivo, Madagascar; Laboratoire d’Informatique et Mathématiques, Université d’Antananarivo, Madagascar","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","3637","3641","Enhanced Super-Resolution Generative Adversarial Network (ESRGAN) is a perceptual-driven approach for single image super-resolution that is able to produce photorealistic images. Despite the visual quality of these generated images, there is still room for improvement. In this fashion, the model is extended to further improve the perceptual quality of the images. We have designed a network architecture with a novel basic block to replace the one used by the original ESRGAN. Moreover, we introduce noise inputs to the generator network in order to exploit stochastic variation. The resulting images present more realistic textures.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054071","Super-resolution;Generative adversarial network","Visualization;Superresolution;Stochastic processes;Network architecture;Generative adversarial networks;Speech processing;Signal resolution","image resolution;image texture;neural nets;realistic images;stochastic processes;visual perception","Enhanced Super-Resolution Generative Adversarial Network;perceptual-driven approach;single image super-resolution;photorealistic images;generator network;ESRGAN+;perceptual quality;stochastic variation","","62","","28","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"Self-Normalizing Generative Adversarial Network for Super-Resolution Reconstruction of SAR Images","C. Zheng; X. Jiang; Y. Zhang; X. Liu; B. Yuan; Z. Li","School of Electronic Information and Electrical Engineering; School of Electronic Information and Electrical Engineering; Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering; School of Electronic Information and Electrical Engineering; Beijing Institute of Remote Sensing Information, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","1911","1914","High-resolution images with abundant detailed information are necessary elements for various applications of synthetic aperture radar (SAR). In this paper, a novel super-resolution image reconstruction method based on self-normalizing generative adversarial network (SNGAN) is proposed. Compared with other published GAN-based super-resolution algorithms, the proposed method reflects its superiority in two aspects. First, the scaled exponential linear units (SeLU) is introduced as the activation function of generator to give the GAN system self-normalization ability and make it more suitable for SAR images. Second, the batch normalization layers after convolution are canceled to reduce the computational requirement and model oscillation. Experiment results on the images of TerraSAR and MSTAR dataset demonstrate that the proposed method acquires satisfactory performance on the resolution enhancement and target recognition of SAR images.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900084","Generative adversarial network (GAN);super-resolution image reconstruction;target recognition","Image reconstruction;Radar polarimetry;Gallium nitride;Generative adversarial networks;Target recognition","image reconstruction;image resolution;neural nets;radar imaging;synthetic aperture radar","self-normalizing generative adversarial network;super-resolution reconstruction;SAR images;high-resolution images;synthetic aperture radar;batch normalization layers;resolution enhancement;super-resolution image reconstruction method;activation function;TerraSAR dataset;MSTAR dataset;target recognition","","9","","11","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Learning Spectral and Spatial Features Based on Generative Adversarial Network for Hyperspectral Image Super-Resolution","R. Jiang; X. Li; A. Gao; L. Li; H. Meng; S. Yue; L. Zhang","School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; Department of Electronic and Computer Engineering, Brunel University London, UK; School of Computer Science, University of Lincoln, Lincoln, UK; Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","3161","3164","Super-resolution (SR) of hyperspectral images (HSIs) aims to enhance the spatial/spectral resolution of hyperspectral imagery and the super-resolved results will benefit many remote sensing applications. A generative adversarial network for HSIs super-resolution (HSRGAN) is proposed in this paper. Specifically, HSRGAN constructs spectral and spatial blocks with residual network in generator to effectively learn spectral and spatial features from HSIs. Furthermore, a new loss function which combines the pixel-wise loss and adversarial loss together is designed to guide the generator to recover images approximating the original HSIs and with finer texture details. Quantitative and qualitative results demonstrate that the proposed HSRGAN is superior to the state of the art methods like SRCNN and SRGAN for HSIs spatial SR.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900228","Hyperspectral images;super-resolution;generative adversarial network;residual network","Spatial resolution;Generative adversarial networks;Generators;Hyperspectral imaging","geophysical image processing;hyperspectral imaging;image enhancement;image resolution;image texture;learning (artificial intelligence);remote sensing","spectral features;spatial features;generative adversarial network;hyperspectral image super-resolution;hyperspectral imagery;super-resolved results;remote sensing applications;HSIs super-resolution;HSRGAN;spatial blocks;residual network;loss function;pixel-wise loss;adversarial loss;original HSIs;HSIs spatial SR","","7","","7","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Face Super-Resolution Using Recurrent Generative Adversarial Network","J. Xiu; X. Qu; H. Yu","School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China","2022 IEEE 6th Information Technology and Mechatronics Engineering Conference (ITOEC)","23 Mar 2022","2022","6","","1169","1174","Theface super-resolution (SR) networks based on deep learning have more advanced performance than traditional SR algorithms. However, facial key components are difficult to reconstruct because the adjacent pixels have great change. Moreover, most face SR networks only focus on the performance and ignore the number of parameters. To solve the above problems, we propose the face super-resolution network using recurrent generative adversarial network (FSRRGAN). The generator is the face SR recurrent generator (FSRRG) with dense iterative up-down sampling blocks as the basic unit. It can reduce the number of parameters and effectively improve the reconstruction performance combined with the relativistic average patch discriminator (RAPD). We use the facial perceptual similarity distance (FPSD) loss to replace the traditional perceptual loss. The experimental results show that our network has excellent performance both qualitatively and quantitatively on 4x and 8x face reconstruction.","2693-289X","978-1-6654-3185-9","10.1109/ITOEC53115.2022.9734461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9734461","face super-resolution;generative adversarial network;deep learning;perceptual quality","Deep learning;Visualization;Mechatronics;Conferences;Superresolution;Generative adversarial networks;Generators","face recognition;image reconstruction;image resolution;iterative methods;learning (artificial intelligence)","recurrent generative adversarial network;super-resolution networks;advanced performance;traditional SR algorithms;facial key components;face SR networks;face super-resolution network;face SR recurrent generator;reconstruction performance;facial perceptual similarity distance loss;8x face reconstruction","","","","27","IEEE","23 Mar 2022","","","IEEE","IEEE Conferences"
"Advanced Generative Adversarial Network Based on Dense Connection For Single Image Super Resolution","S. Chen; S. Li; C. Zhu","College of Electrical Automation and Information Engineering, Tianjin University, Tianjin, China; College of Electrical Automation and Information Engineering, Tianjin University, Tianjin, China; College of Electrical Automation and Information Engineering, Tianjin University, Tianjin, China","2019 IEEE THE 2nd INTERNATIONAL CONFERENCE ON MICRO/NANO SENSORS for AI, HEALTHCARE, AND ROBOTICS (NSENS)","21 Dec 2020","2019","","","68","71","The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating more realistic texture in semantics and style during single image super-resolution. However, Since the loss function adopts L2 norm based on pixel points, the hallucinated details are often accompanied with unpleasant artifacts even false pixels. Our model adjusts generative loss to L1 norm, and perceptual loss is still based on L2 norm. L1 cost function can reduce the coefficients of some features to zero, thus indirectly realizing the selection of features according to the perceptual loss, and obtaining more real texture features. The combination of these two loss functions ensures that the reconstructed results of the model are very close to the target image in terms of spatial features, high-level abstract features and semantic features, overall sensory and image quality. The generating network of our model is based on dense residual structure, and the dense connection of residual-in-residual is used to implement fast and accurate learning of high frequency features of images. The adversarial network is based on the structure of discriminators in DCGAN and WGAN. Experimental results show that subjective quality we reconstructed is much higher than SRGAN.","","978-1-7281-6652-0","10.1109/NSENS49395.2019.9293953","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9293953","loss function;super-resolution;convolution neural network;generating adversarial network","Image reconstruction;Convolution;Generative adversarial networks;Adaptation models;Gallium nitride;Training;Numerical models","feature extraction;image denoising;image reconstruction;image resolution;image texture;neural nets","dense residual structure;dense connection;high frequency features;advanced generative adversarial network;single image super resolution;Super-Resolution Generative Adversarial Network;realistic texture;loss function;pixel points;generative loss;perceptual loss;L1 cost function;texture features;spatial features;high-level abstract features;semantic features;sensory image quality;generating network","","","","14","IEEE","21 Dec 2020","","","IEEE","IEEE Conferences"
"Super-Resolution Reconstruction Algorithm for Terahertz Images","Z. Hou; H. An; L. He; E. Li; D. Lai","School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","2022 3rd International Conference on Pattern Recognition and Machine Learning (PRML)","13 Sep 2022","2022","","","180","185","Terahertz imaging technology has great prospect in applications of nondestructive testing, biomedicine and security inspection. However, terahertz imaging has not received a satisfactory image quality so far due to problems such as complex noise, artifacts and low resolution. In this work, an image preprocessing algorithm by combining an improved wavelet thresholding function and a generative adversarial network image super-resolution algorithm was proposed. Specifically, the constant deviation between the original wavelet coefficients and the estimated wavelet coefficients could be reduced by improving the threshold function and setting appropriate adjustment parameters to dynamically select a fixed threshold. As such the approximation between of the reconstructed image and the original image could be improved. In addition, the generative network combined with the improved loss function was designed to obtain the detailed information of the images at multiple scales. Moreover, an image database containing 51,300 images was built by degrading and data expanding the original 3650 images collected from the DF2K dataset so as to evaluate the proposed super-resolution reconstruction algorithm of terahertz images. The obtained results show that there were more than 2 dB and at less 1 dB improvement compared with previous median filtering and the hard/soft threshold wavelet, respectively. Consequently, the preliminarily reconstructed terahertz images suggested that the improved threshold wavelet function together with the generative adversarial network may offer the possibility of provide a high quality image especially for nondestructive testing.","","978-1-6654-9950-7","10.1109/PRML56267.2022.9882225","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9882225","THZ imaging;super-resolution;wavelet threshold function;deep learning","Terahertz wave imaging;Thresholding (Imaging);Heuristic algorithms;Superresolution;Nondestructive testing;Reconstruction algorithms;Generative adversarial networks","image denoising;image reconstruction;image resolution;median filters;nondestructive testing;signal denoising;terahertz wave imaging;wavelet transforms","terahertz images;improved threshold wavelet function;high quality image;super-resolution reconstruction algorithm;terahertz imaging technology;biomedicine;security inspection;satisfactory image quality;image preprocessing algorithm;improved wavelet thresholding function;generative adversarial network image super-resolution algorithm;original wavelet coefficients;threshold function;setting appropriate adjustment parameters;reconstructed image;improved loss function;image database;original 3650 images;noise figure 2.0 dB;noise figure 1.0 dB","","","","19","IEEE","13 Sep 2022","","","IEEE","IEEE Conferences"
"A Study on Model Compression Methods for SRGAN","D. -h. Kim; J. -w. Lee; S. -h. Park","School of Computer Science and Engineering, Kyungpook National University, Daegu, Republic of Korea; School of Computer Science and Engineering, Kyungpook National University, Daegu, Republic of Korea; School of Computer Science and Engineering, Kyungpook National University, Daegu, Republic of Korea","2022 International Conference on Electronics, Information, and Communication (ICEIC)","11 Apr 2022","2022","","","1","3","The construction of SR algorithms by using deep learning model such as super-resolution generative adversarial networks (SRGAN) have become larger and complicated model architectures with requiring a vast amount of memory capacity. However, it is difficult to operate deep learning models which have millions of parameters at the mobile devices. Thus, in this paper, we present a study on lightweight neural network using network pruning method. Through our extensive experiments, pruned network can show similar performance to the original SRGAN model with substantially reduced model size.","2767-7699","978-1-6654-0934-6","10.1109/ICEIC54506.2022.9748707","National Research Foundation of Korea (NRF)(grant numbers:2020R1I1A3072227); Kyungpook National University(grant numbers:4199990214394); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9748707","Deep learning;Lightweight neural network;Network pruning;Super-resolution;Network compression;Fine-tuning;Knowledge-distillation","Deep learning;Performance evaluation;Knowledge engineering;Superresolution;Neural networks;Memory management;Generative adversarial networks","data compression;image resolution;learning (artificial intelligence);neural nets","model compression methods;SR algorithms;deep learning model;super-resolution generative adversarial networks;larger complicated model architectures;memory capacity;lightweight neural network;network pruning method;pruned network;original SRGAN model;substantially reduced model size","","","","8","IEEE","11 Apr 2022","","","IEEE","IEEE Conferences"
"Image Super-Resolution Quality Assessment: Structural Fidelity Versus Statistical Naturalness","W. Zhou; Z. Wang; Z. Chen","CAS Key Laboratory of Technology in Geo-spatial Information Processing and Application System, University of Science and Technology of China, Hefei, China; Dept. of Electrical & Computer Engineering, University of Waterloo, Waterloo, Canada; CAS Key Laboratory of Technology in Geo-spatial Information Processing and Application System, University of Science and Technology of China, Hefei, China","2021 13th International Conference on Quality of Multimedia Experience (QoMEX)","30 Jun 2021","2021","","","61","64","Single image super-resolution (SISR) algorithms reconstruct high-resolution (HR) images with their low-resolution (LR) counterparts. It is desirable to develop image quality assessment (IQA) methods that can not only evaluate and compare SISR algorithms, but also guide their future development. In this paper, we assess the quality of SISR generated images in a two-dimensional (2D) space of structural fidelity versus statistical naturalness. This allows us to observe the behaviors of different SISR algorithms as a tradeoff in the 2D space. Specifically, SISR methods are traditionally designed to achieve high structural fidelity but often sacrifice statistical naturalness, while recent generative adversarial network (GAN) based algorithms tend to create more natural-looking results but lose significantly on structural fidelity. Furthermore, such a 2D evaluation can be easily fused to a scalar quality prediction. Interestingly, we find that a simple linear combination of a straightforward local structural fidelity and a global statistical naturalness measures produce surprisingly accurate predictions of SISR image quality when tested using public subject-rated SISR image datasets. Code of the proposed SFSN model is publicly available at https://github.con/weizhou-geek/SFSN.","2472-7814","978-1-6654-3589-5","10.1109/QoMEX51781.2021.9465479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465479","image super-resolution;quality assessment;image decomposition;structural fidelity;statistical naturalness","Image quality;Degradation;Correlation;Superresolution;Two dimensional displays;Optimized production technology;Generative adversarial networks","data compression;image coding;image reconstruction;image resolution","single image super-resolution algorithms;high-resolution images;low-resolution counterparts;image quality assessment;two-dimensional space;different SISR algorithms;SISR methods;high structural fidelity;recent generative adversarial network based algorithms;scalar quality prediction;straightforward local structural fidelity;global statistical naturalness measures;SISR image quality;public subject-rated SISR image datasets;image super-resolution quality assessment","","9","","32","IEEE","30 Jun 2021","","","IEEE","IEEE Conferences"
"Recovery of Lossy Compressed Music Based on CNN Super-Resolution and GAN","Y. Liu","Beijing No. 101 Middle school, Beijing, China","2021 IEEE 3rd International Conference on Frontiers Technology of Information and Computer (ICFTIC)","24 Dec 2021","2021","","","623","629","The lossy compression of music audio files through MP3 cause loss of sound quality, which results in the decline of auditory experience and cannot meet the requirements of high-quality music playback in a wide variety of occasions. To solve this problem, after long-term exploration, we proposed an approach of time-domain and frequency-domain bandwidth expansion based on CNN and GAN to support high-quality MP3 lossy compressed music recovery by analyzing the characteristics and correlation of human voice and different kinds of musical instruments in high-frequency and low-frequency portions of music. For bandwidth extension in the frequency domain, a method similar to image inpainting is designed; for bandwidth extension in the time domain, a super-resolution method is designed. We compared the proposed method with RNN, BPCNN, and other methods. The experimental results prove that the method proposed in this paper has the lowest spectral loss and the best reconstruction quality. The experimental results of human ear discrimination further prove the effectiveness of the audio enhancement algorithm.","","978-1-6654-0605-5","10.1109/ICFTIC54370.2021.9647041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9647041","MP3 Lossy Compression;Bandwidth Extension CNN;GAN;Super Resolution","Instruments;Superresolution;Noise reduction;Music;Bandwidth;Generative adversarial networks;Convolutional neural networks","audio coding;audio signal processing;data compression;image resolution;image restoration;music;musical instruments","CNN super-resolution;lossy compression;music audio files;MP3 cause loss;sound quality;high-quality music playback;long-term exploration;time-domain;frequency-domain bandwidth expansion;high-quality MP3 lossy compressed music recovery;musical instruments;bandwidth extension;frequency domain;time domain;super-resolution method;reconstruction quality","","2","","20","IEEE","24 Dec 2021","","","IEEE","IEEE Conferences"
"Deep Mutual GAN for Life-Detection Radar Super Resolution","H. Xing; M. Bao; Y. Li; L. Shi; M. Xing","School of Electronic Engineering, Xidian University, Xi’an, China; School of Electronic Engineering, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; School of Electronic Engineering, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","16 Dec 2021","2022","19","","1","5","To improve the life-detection radar resolution under certain hardware conditions, in this letter, a deep mutual learning generative adversarial network model (Deep Mutual GAN) is proposed. In the proposed model, the generator can improve the angular resolution of the input low-resolution radar image by five times, which is enough to meet our requirements for the resolution of life detection. We innovatively use two generators in GAN with the same network structure and make the two generators learn from each other. In this way, the learning process of a generator is not only achieved by its confrontation with the discriminator but also guided by another generator. As a result, the knowledge of the generator is no longer only obtained through its own learning; each generator learns knowledge from another generator while learning knowledge by itself. The proposed model can effectively make the convergence of GAN more stable and improves the super resolution effect. We also introduce the details of the network structure of generator and discriminator, in which residual learning and a symmetrical network structure are applied. The experimental results show that the proposed method can achieve state-of-the-art imaging effect, which is meaningful for subsequent target detection and recognition.","1558-0571","","10.1109/LGRS.2021.3065696","National Key Research and Development Program of China(grant numbers:2018YFC0810202); Fundamental Research Funds for the Central Universities(grant numbers:JB190204); Science Foundation for Distinguished Young Scholars of Shaanxi Province(grant numbers:2020JC-25); Shaanxi Innovative Talents Promotion Plan-Science and Technology Innovation Team(grant numbers:2019TD-002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9389759","Deep mutual learning;generative adversarial network (GAN);life-detection radar imaging;super resolution (SR)","Generators;Radar imaging;Gallium nitride;Generative adversarial networks;Radar;Radar antennas;Receiving antennas","image resolution;learning (artificial intelligence);neural nets;object detection;radar imaging;radar resolution","life detection;learning process;super resolution effect;residual learning;symmetrical network structure;subsequent target detection;Deep Mutual GAN;life-detection radar super resolution;life-detection radar resolution;hardware conditions;deep mutual learning generative adversarial network model;angular resolution;input low-resolution radar image","","1","","17","IEEE","30 Mar 2021","","","IEEE","IEEE Journals"
"Face Image Super-Resolution Using Inception Residual Network and GAN Framework","S. D. Indradi; A. Arifianto; K. N. Ramadhani","School of Computing, Telkom University, Bandung, Indonesia; School of Computing, Telkom University, Bandung, Indonesia; School of Computing, Telkom University, Bandung, Indonesia","2019 7th International Conference on Information and Communication Technology (ICoICT)","16 Sep 2019","2019","","","1","6","Single Image Super-Resolution (SISR) is an image reconstruction technique that aims to generate a high-resolution image from a low-resolution image. One of the SISR implementations is to reconstruct face images in order to gain more facial information from a low-resolution face images. In this paper, we propose a method to reconstruct face images using a Generative Adversarial Network (GAN) framework that able to generate plausible high-resolution images. Inside the GAN framework, we use inception residual network to improve the generated image quality and stabilize the training. Experimental results demonstrated that our proposed method was able to generate visually pleasant face images with the highest PSNR score of 26.615 and SSIM score of 0.8461.","","978-1-5386-8052-0","10.1109/ICoICT.2019.8835253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8835253","Single Image Super-Resolution;image reconstruction;face image;Generative Adversarial Network.","Generators;Image reconstruction;Generative adversarial networks;Gallium nitride;Training;Face;Image resolution","face recognition;image reconstruction;image resolution;neural nets","inception residual network;GAN framework;image reconstruction technique;high-resolution image;low-resolution face images;generated image quality;face image super-resolution;generative adversarial network framework;single image super-resolution","","1","","28","IEEE","16 Sep 2019","","","IEEE","IEEE Conferences"
"Real-Scenes Face Super-Resolution using a Lightweight Generative Adversarial Network","C. Zhang; Y. He; X. Qi; Y. Yao; X. Mei","College of Electrical Engineering and Control Science, Nanjing Tech University, Nanjing, China; College of Electrical Engineering and Control Science, Nanjing Tech University, Nanjing, China; College of Electrical Engineering and Control Science, Nanjing Tech University, Nanjing, China; College of Electrical Engineering and Control Science, Nanjing Tech University, Nanjing, China; College of Electrical Engineering and Control Science, Nanjing Tech University, Nanjing, China","2021 3rd International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)","17 Mar 2022","2021","","","572","576","Although deep learning-based methods have achieved great success in the field of image super-resolution (SR), the SR algorithms still have some shortcomings, such as unsatisfactory results in reconstructing face images collected in real scenes, the model has a large amount of calculation and serious delays when running in a real-time scene. To solve the above problems, this paper proposes a SR algorithm for face images based on a lightweight Generative Adversarial Network (GAN). The algorithm in this paper constructs a real-scenes face datasets for training. Based on the ESRGAN, this study completes the lightweight reconstruction of the basic network inspired by MobileNetV3. Experimental results show that the algorithm is better than the existing mainstream SR algorithms in terms of image reconstruction time, model volume, and parameters amount. When the test image is a face image with an unknown degradation method collected in a real scene, the algorithm in this paper can also achieve the ideal reconstruction effect.","","978-1-6654-1790-7","10.1109/MLBDBI54094.2021.00114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9730992","Generative Adversarial Network;real scenes;super-resolution;lightweight;deep separable convolution","Training;Degradation;Computational modeling;Superresolution;Generative adversarial networks;Real-time systems;Data models","face recognition;image reconstruction;image resolution;learning (artificial intelligence)","basic network;existing mainstream SR algorithms;image reconstruction time;test image;face image;scenes face super-resolution;lightweight Generative Adversarial Network;deep learning-based methods;image super-resolution;SR algorithm;unsatisfactory results;serious delays;real-time scene;real-scenes;lightweight reconstruction","","","","14","IEEE","17 Mar 2022","","","IEEE","IEEE Conferences"
"Remote Sensing Image Super-Resolution Via Attentional Feature Aggregation Generative Adversarial Network","F. Cai; K. -Y. Wu; F. Wang","Key Laboratory for Information Science of Electromagnetic Waves (MoE), School of Information Science and Technology, Fudan University, Shanghai, China; Key Laboratory for Information Science of Electromagnetic Waves (MoE), School of Information Science and Technology, Fudan University, Shanghai, China; Key Laboratory for Information Science of Electromagnetic Waves (MoE), School of Information Science and Technology, Fudan University, Shanghai, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2598","2601","The extraction of high-frequency details is generally neglected in single image super-resolution (SISR) for remote sensing images. In this paper, we propose an attentional feature aggregation generative adversarial network (AFA-GAN) with the capability of strong feature extraction and attentional feature fusion to generate high-resolution remote sensing images. We adopt the residual feature aggregation framework for the feature extraction to make full use of the hierarchical features on the residual branches. To better fuse global and local features with inconsistent scales, an attentional feature fusion mechanism is utilized in residual feature aggregation modules. The comprehensive experiments with state-of-the-art SISR methods on the UC Merced dataset demonstrate the effectiveness and superiority of our AFA-GAN.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884863","National Natural Science Foundation of China(grant numbers:61901122); Natural Science Foundation of Shanghai(grant numbers:20ZR1406300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884863","Remote sensing images;single image super-resolution (SISR);attentional feature aggregation (AFA);generative adversarial network (GAN)","Visualization;Fuses;Superresolution;Feature extraction;Generative adversarial networks;Remote sensing;Image reconstruction","feature extraction;geophysical image processing;image fusion;image reconstruction;image resolution;remote sensing","high-resolution remote sensing images;residual feature aggregation framework;hierarchical features;global features;local features;attentional feature fusion mechanism;residual feature aggregation modules;AFA-GAN;remote sensing image super-resolution;high-frequency details;single image super-resolution;attentional feature aggregation generative adversarial network;strong feature extraction","","","","18","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Joint Denoising and Super-Resolution via Generative Adversarial Training","L. Chen; W. Dan; L. Cao; C. Wang; J. Li","Fujian Key Laboratory of Sensing and Computing for Smart City, Xiamen University, P. R. China; Fujian Key Laboratory of Sensing and Computing for Smart City, Xiamen University, P. R. China; Fujian Key Laboratory of Sensing and Computing for Smart City, Xiamen University, P. R. China; Fujian Key Laboratory of Sensing and Computing for Smart City, Xiamen University, P. R. China; Fujian Key Laboratory of Sensing and Computing for Smart City, Xiamen University, P. R. China","2018 24th International Conference on Pattern Recognition (ICPR)","29 Nov 2018","2018","","","2753","2758","Single image denoising and super-resolution are sitting in the core of various image processing and pattern recognition applications. Typically, these two tasks are handled separately, without regarding to joint reinforcement and learning. The former deals with equal-size pixel-to-pixel translation, while the latter deals with scaling up amount of input pixels. In this paper, we propose a Generative Adversarial Network(GAN) towards joint learning of single image denoising and super-resolution. In principle, our design allows both tasks to share several common building blocks, with the linking between both outputs to reinforce each other. Such a reinforcement is accomplished via designing a novel generative network through optimizing a novel loss function to achieve both denoising and super-resolution. Quantitatively comparing to a set of alternative approaches and baselines, the experiment demonstrated superior performance our method in denoising and super-resolution with high upscaling factors.","1051-4651","978-1-5386-3788-3","10.1109/ICPR.2018.8546286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546286","Denoising;Super-resolution;GAN","Image resolution;Noise reduction;Signal resolution;Generators;White noise;Task analysis;Generative adversarial networks","image denoising;image resolution;learning (artificial intelligence)","super-resolution;single image denoising;image processing;pattern recognition applications;joint reinforcement;equal-size pixel-to-pixel translation;joint learning;generative network;generative adversarial network;generative adversarial training;joint denoising and superresolution","","3","1","33","IEEE","29 Nov 2018","","","IEEE","IEEE Conferences"
"Image Super-resolution Reconstruction Based on an Improved Generative Adversarial Network","H. Liu; F. Wang; L. Liu","School of Automation and Information Engineering, Xi'an University of Techology, Xi’ an, China; School of Automation and Information Engineering, Xi'an University of Techology, Xi’ an, China; School of Automation and Information Engineering, Xi'an University of Techology, Xi’ an, China","2019 1st International Conference on Industrial Artificial Intelligence (IAI)","30 Sep 2019","2019","","","1","6","To solve the problem that images reconstructed by traditional super-resolution reconstruction (SR) techniques are smooth and lack good details, in this paper, we have presented an improved generative adversarial network for image super-resolution. The improved method was based on deep neural networks whose generative model contained a multi-layer convolution module and multi-layer deconvolution module, in which a layer hopping connection and a loss function was added to the perceptual loss. The discriminant model was made up of a multi-layer neural network whose loss function was based on the discriminant model loss function that was generated from the generative adversarial network. Finally, we selected PSNR and SSIM as the indicator in the experiments. In the experiments, the PSNR value of 2x, 3x and 4x magnification factor are improved on average by 1.125, 2.175 and 2.075 respectively and the SSIM value of 2x, 3x and 4x magnification factor are basically improved. Compared with the existing image super-resolution reconstruction methods, the effectiveness of the method that we proposed in image super-resolution reconstruction was proven.","","978-1-7281-3593-9","10.1109/ICIAI.2019.8850808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8850808","Image Super-resolution;Generative Adversarial Network;Convolutional Network;Residual Network","Image resolution;Generators;Generative adversarial networks;Convolution;Gallium nitride;Feature extraction;Convolutional neural networks","deconvolution;image reconstruction;image resolution;neural nets","layer hopping connection;multilayer neural network;discriminant model loss function;deep neural networks;image super-resolution reconstruction methods;generative adversarial network;multilayer deconvolution module","","2","","25","IEEE","30 Sep 2019","","","IEEE","IEEE Conferences"
"SSTRN: Semantic Style Transfer Reference Network for Face Super-Resolution","S. Farhangfar; A. Baradarani; M. A. Balafar; M. Asadpour","Faculty of Electrical and Computer Engineering, University of Tabriz, Tabriz, Iran; Faculty of Electrical and Computer Engineering, University of Tabriz, Tabriz, Iran; Faculty of Electrical and Computer Engineering, University of Tabriz, Tabriz, Iran; Faculty of Electrical and Computer Engineering, University of Tabriz, Tabriz, Iran","2022 29th International Conference on Systems, Signals and Image Processing (IWSSIP)","17 Aug 2022","2022","CFP2255E-ART","","1","4","Reference super-resolution (RefSR) has achieved promising results in the single image super-resolution (SISR) field by providing additional details from the reference images. Existing RefSR methods usually tend to extract similar or aligned features from reference images to further enhance the resolution of the final result. Therefore, the efficiency of RefSR models highly depends on the conformity between extracted features from the low-resolution (LR) and reference images. In this paper, we propose a new reference image generation scheme via semantic style transfer to unleash our model from relevant feature extraction computations. The generated reference images have the most content similarity and identical alignment with the LR input that compensates for the lost details of the LR images. Despite previous RefSR methods that rely on extracting and transferring texture information from the reference image to LR input, provided reference images are enriched with the style information of high-resolution (HR) images. Extensive experiments indicate the effectiveness of the proposed reference images.","2157-8702","978-1-6654-9578-3","10.1109/IWSSIP55020.2022.9854432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854432","Semantic style transfer;Reference-based super-resolution;Generative adversarial networks;Face images","Image synthesis;Computational modeling;Semantics;Superresolution;Feature extraction;Data mining;Signal resolution","face recognition;feature extraction;image enhancement;image resolution;image texture","image enhancement;texture information;LR images;semantic style transfer;RefSR model;SISR model;feature extraction;SSTRN;high-resolution images;reference image generation scheme;low-resolution images;single image super-resolution field;reference super-resolution;face super-resolution;semantic style transfer reference network","","","","16","IEEE","17 Aug 2022","","","IEEE","IEEE Conferences"
"Small Object Detection Networks Based on Classification-Oriented Super-Resolution GAN for UAV Aerial Imagery","Y. Chen; J. Li; Y. Niu; J. He","College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; Unit 75840, Guangzhou, China","2019 Chinese Control And Decision Conference (CCDC)","12 Sep 2019","2019","","","4610","4615","Small object detection is challenging for lack of discriminative information compared to medium, large objects. In this paper, we proposed small object detection networks based on classification-oriented super-resolution generative adversarial networks (CSRGAN) and validate them on public UAV aerial imagery benchmark. Through appending classification branch and introducing classification loss to typical SRGAN, generator of CSRGAN is trained to reconstruct realistic super-resolved (SR) images with classification-oriented discriminative features from low resolution images while discriminator is trained to predict true categories and distinguish generated SR images from original ones. Besides, VGG19 based feature-level content loss is applied to recover clearer and sharper contours in SR images, which is critical to object classification. Experiment results prove the classification-oriented enhancing effect of CSRGAN and the positive function of VGG19 based feature-level content loss.","1948-9447","978-1-7281-0106-4","10.1109/CCDC.2019.8832735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8832735","Object Detection;Object Classification;Super-resolution;Generative Adversarial Networks;UAV Aerial Imagery","Generators;Object detection;Feature extraction;Training;Spatial resolution;Generative adversarial networks","autonomous aerial vehicles;control engineering computing;feature extraction;image classification;image reconstruction;image resolution;mobile robots;neural nets;object detection;robot vision","CSRGAN;classification-oriented discriminative features;SR images;UAV aerial imagery;classification loss;small object detection networks;classification-oriented superresolution GAN;classification-oriented superresolution generative adversarial networks;object classification","","2","","21","IEEE","12 Sep 2019","","","IEEE","IEEE Conferences"
"Structure-Preserving Image Super-Resolution","C. Ma; Y. Rao; J. Lu; J. Zhou","Beijing National Research Center for Information Science and Technology (BNRist) and the Department of Automation, Tsinghua University, Beijing, China; Beijing National Research Center for Information Science and Technology (BNRist) and the Department of Automation, Tsinghua University, Beijing, China; Beijing National Research Center for Information Science and Technology (BNRist) and the Department of Automation, Tsinghua University, Beijing, China; Beijing National Research Center for Information Science and Technology (BNRist) and the Department of Automation, Tsinghua University, Beijing, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","4 Oct 2022","2022","44","11","7898","7911","Structures matter in single image super-resolution (SISR). Benefiting from generative adversarial networks (GANs), recent studies have promoted the development of SISR by recovering photo-realistic images. However, there are still undesired structural distortions in the recovered images. In this paper, we propose a structure-preserving super-resolution (SPSR) method to alleviate the above issue while maintaining the merits of GAN-based methods to generate perceptual-pleasant details. First, we propose SPSR with gradient guidance (SPSR-G) by exploiting gradient maps of images to guide the recovery in two aspects. On the one hand, we restore high-resolution gradient maps by a gradient branch to provide additional structure priors for the SR process. On the other hand, we propose a gradient loss to impose a second-order restriction on the super-resolved images, which helps generative networks concentrate more on geometric structures. Second, since the gradient maps are handcrafted and may only be able to capture limited aspects of structural information, we further extend SPSR-G by introducing a learnable neural structure extractor (NSE) to unearth richer local structures and provide stronger supervision for SR. We propose two self-supervised structure learning methods, contrastive prediction and solving jigsaw puzzles, to train the NSEs. Our methods are model-agnostic, which can be potentially used for off-the-shelf SR networks. Experimental results on five benchmark datasets show that the proposed methods outperform state-of-the-art perceptual-driven SR methods under LPIPS, PSNR, and SSIM metrics. Visual results demonstrate the superiority of our methods in restoring structures while generating natural SR images. Code is available at https://github.com/Maclory/SPSR.","1939-3539","","10.1109/TPAMI.2021.3114428","National Natural Science Foundation of China(grant numbers:62125603,U1813218,U1713214); Beijing Academy of Artificial Intelligence; Tsinghua University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546645","Super-resolution;image enhancement;self-supervised learning;generative adversarial network","Feature extraction;Image edge detection;Superresolution;Distortion;Task analysis;Generative adversarial networks;Image restoration","gradient methods;image reconstruction;image resolution;learning (artificial intelligence)","structure-preserving image super-resolution;structures matter;single image super-resolution;SISR;generative adversarial networks;photo-realistic images;undesired structural distortions;recovered images;structure-preserving super-resolution method;GAN-based methods;perceptual-pleasant details;gradient guidance;SPSR-G;high-resolution gradient maps;gradient branch;additional structure priors;gradient loss;generative networks;geometric structures;structural information;learnable neural structure extractor;unearth richer local structures;self-supervised structure learning methods;off-the-shelf SR networks;state-of-the-art perceptual-driven SR methods;natural SR images","","10","","69","IEEE","22 Sep 2021","","","IEEE","IEEE Journals"
"Text-Attentional Conditional Generative Adversarial Network for Super-Resolution of Text Images","Y. Wang; F. Su; Y. Qian","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China","2019 IEEE International Conference on Multimedia and Expo (ICME)","5 Aug 2019","2019","","","1024","1029","Text in natural scene images are often faced with low-resolution problem, which brings significant difficulties to many text-related tasks such as text detection and recognition. In this paper, we propose a novel text-attentional Conditional Generative Adversarial Network (cGAN) model for text image super-resolution (SR). The model enhances the original cGAN by introducing effective channel and spatial attention mechanisms based on the proposed Residual Dense Channel Attention Block and text/non-text segmentation information, which focus the model on the text regions instead of the background of the image to learn more effective representations of text and achieve better text super-resolution result. The proposed model achieves state-of-the-art performances on public text image super-resolution dataset.","1945-788X","978-1-5386-9552-4","10.1109/ICME.2019.00180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784962","Super-resolution, text image, cGAN, attention, segmentation","Feature extraction;Spatial resolution;Generators;Image segmentation;Generative adversarial networks;Task analysis","convolutional neural nets;image representation;image resolution;image segmentation;natural scenes;text detection","text detection;spatial attention mechanisms;Residual Dense Channel Attention Block;public text image super-resolution dataset;natural scene images;text-attentional conditional generative adversarial network model;cGAN model;nontext segmentation information","","5","","17","IEEE","5 Aug 2019","","","IEEE","IEEE Conferences"
"Multiresolution Mixture Generative Adversarial Network For Image Super-Resolution","Y. Wang; X. Lan; Y. Zhang; R. Miao; Z. Tian","School of Software, Xi’an Jiaotong University; School of Electronics and Information Engineering, Xi’an Jiaotong University; School of Software, Xi’an Jiaotong University; School of Information Sciences and Technology, Northeast Normal University; School of Software, Xi’an Jiaotong University","2020 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2020","2020","","","1","6","With regard to the problem of image super-resolution (SR), generative adversarial network (GAN) can make generated images have more details and better effect on perceptual quality than other methods. However, GAN-based methods may lose the contour of object in some texture-intensive areas. In order to recover contour better and further enhance perceptual quality, we propose a Multiresolution Mixture Generative Adversarial Network for Image Super-Resolution (MRMGAN), which employs a multiresolution mixture network (MRMNet) for image super-resolution. The MRMNet is able to have multiple resolution feature maps at the same time when training. Meanwhile, we propose a residual fluctuation loss, which aims to reduce the overall fluctuation of residual between SR image and high-resolution (HR) image. We evaluated the proposed method on benchmark datasets. Experimental results show that the proposed MRMGAN can get satisfactory performance.","1945-788X","978-1-7281-1331-9","10.1109/ICME46284.2020.9102972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102972","generative adversarial network;multi-resolution mixture network;residual fluctuation loss;super-resolution","Image resolution;Training;Signal resolution;Fluctuations;Generative adversarial networks;Gallium nitride;Machine learning","image resolution;image texture;neural nets","image super-resolution;perceptual quality enhancement;GAN-based methods;multiple resolution feature maps;SR image;multiresolution mixture generative adversarial network;texture-intensive areas;MRMGAN;MRMNet;residual fluctuation loss;high-resolution image","","","","27","IEEE","9 Jun 2020","","","IEEE","IEEE Conferences"
"Coupled Adversarial Learning for Single Image Super-Resolution","C. -C. Hsu; K. -Y. Huang","Department of Management Information Systems, National Pingtung University of Science and Technology, Pingtung, Taiwan; Department of Management Information Systems, National Pingtung University of Science and Technology, Pingtung, Taiwan","2020 IEEE 11th Sensor Array and Multichannel Signal Processing Workshop (SAM)","10 Jun 2020","2020","","","1","5","Generative adversarial nets (GAN) have been widely used in several image restoration tasks such as image denoise, enhancement, and super-resolution. The objective functions of an image super-resolution problem based on GANs usually are reconstruction error, semantic feature distance, and GAN loss. In general, semantic feature distance was used to measure the feature similarity between the super-resolved and ground-truth images, to ensure they have similar feature representations. However, the feature is usually extracted by the pre-trained model, in which the feature representation is not designed for distinguishing the extracted features from low-resolution and high-resolution images. In this study, a coupled adversarial net (CAN) based on Siamese Network Structure is proposed, to improve the effectiveness of the feature extraction. In the proposed CAN, we offer GAN loss and semantic feature distances simultaneously, reducing the training complexity as well as improving the performance. Extensive experiments conducted that the proposed CAN is effective and efficient, compared to state-of-the-art image super-resolution schemes.","2151-870X","978-1-7281-1946-5","10.1109/SAM48682.2020.9104288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9104288","Adversarial generative nets;super-resolution;coupled nets;semi-supervised learning","Training;Visualization;Cats;Superresolution;Semantics;Feature extraction;Generative adversarial networks","feature extraction;image representation;image resolution;image restoration;learning (artificial intelligence);neural nets","adversarial learning;single image super-resolution;generative adversarial nets;image restoration;image denoise;objective functions;semantic feature distance;GAN loss;general feature distance;feature similarity;ground-truth images;feature representation;high-resolution images;coupled adversarial net;feature extraction;image enhancement;reconstruction error;low-resolution images;CAN;Siamese network structure;training complexity","","","","18","IEEE","10 Jun 2020","","","IEEE","IEEE Conferences"
"D-ESRGAN: A Dual-Encoder GAN with Residual CNN and Vision Transformer for Iris Image Super-Resolution","C. Wang; T. Lu; G. Wu; Y. Wang; Z. Sun","School of Electrical and Information Engineering, Beijing University of Civil Engineering and Architecture, Beijing, P.R. China; CRIPAC, NLPR, CASIA, Beijing, P.R. China; Baidu Inc., Beijing, P.R. China; CRIPAC, NLPR, CASIA, Beijing, P.R. China; CRIPAC, NLPR, CASIA, Beijing, P.R. China","2022 IEEE International Joint Conference on Biometrics (IJCB)","17 Jan 2023","2022","","","1","8","Iris images captured in less-constrained environments, especially at long distances often suffer from the interference of low resolution, resulting in the loss of much valid iris texture information for iris recognition. In this paper, we propose a dual-encoder super-resolution generative adversarial network (D-ESRGAN) for compensating texture lost of the raw image meanwhile maintaining the newly generated textures more natural. Specifically, the proposed D-ESRGAN not only integrates the residual CNN encoder to extract local features, but also employs an emerging vision transformer encoder to capture global associative information. The local and global features from two encoders are further fused for the subsequent reconstruction of high-resolution features. During the training, we develop a three-stage strategy to alleviate the problem that generative adversarial networks are prone to collapse. Moreover, to boost the iris recognition performance, we introduce a triplet loss to push away the distance of super-resolved iris images with different IDs, and pull the distance of super-resolved iris images with the same ID much closer. Experimental results on the public CASIA-Iris-distance and CASIA-Iris-M1 datasets show that D-ESRGAN archives better performance than state-of-the-art baselines in terms of both super-resolution image quality metrics and iris recognition metric.","2474-9699","978-1-6654-6394-2","10.1109/IJCB54206.2022.10007938","National Natural Science Foundation of China(grant numbers:62106015,U1836217,62006225,62176025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10007938","","Measurement;Image quality;Superresolution;Generative adversarial networks;Feature extraction;Transformers;Generators","feature extraction;image recognition;image resolution;image texture;iris recognition","CASIA-Iris-M1 datasets;compensating texture;D-ESRGAN archives better performance;dual-encoder GAN;emerging vision transformer encoder;encoders;generative adversarial networks;global associative information;global features;high-resolution features;Iris image super-resolution;iris recognition performance;local features;newly generated textures;public CASIA-Iris-distance;raw image;residual CNN encoder;super-resolution generative adversarial network;super-resolution image quality metrics;super-resolved iris images;valid iris texture information","","","","31","IEEE","17 Jan 2023","","","IEEE","IEEE Conferences"
"Perceptual cGAN for MRI Super-resolution","S. A. Nasser; S. Shamsi; V. Bundele; B. Garg; A. Sethi","Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India; Whirlpool, Pune, India; Department of Energy Science and Engineering, Indian Institute of Technology Bombay, Mumbai, India; Department of Energy Science and Engineering, Indian Institute of Technology Bombay, Mumbai, India; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India","2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","8 Sep 2022","2022","","","3035","3038","Capturing high-resolution magnetic resonance (MR) images is a time consuming process, which makes it unsuitable for medical emergencies and pediatric patients. Low-resolution MR imaging, by contrast, is faster than its high-resolution counterpart, but it compromises on fine details necessary for a more precise diagnosis. Super-resolution (SR), when applied to low-resolution MR images, can help increase their utility by synthetically generating high-resolution images with little additional time. In this paper, we present an SR technique for MR images that is based on generative adversarial networks (GANs), which have proven to be quite useful in producing sharp-looking details in SR. We introduce a conditional GAN with perceptual loss, which is conditioned upon the input low-resolution image, which improves the performance for isotropic and anisotropic MRI super-resolution. Clinical Relevance- MR image super-resolution has the potential for improving image acquisition speed to save the time of the clinicians, while guaranteeing high-quality images.","2694-0604","978-1-7281-2782-8","10.1109/EMBC48229.2022.9871832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9871832","","Training;Three-dimensional displays;Magnetic resonance imaging;Superresolution;Semantics;Generative adversarial networks;Generators","biomedical MRI;image reconstruction;image representation;image resolution;medical image processing","high-quality images;perceptual cGAN;high-resolution magnetic resonance images;low-resolution MR imaging;high-resolution counterpart;low-resolution MR images;high-resolution images;input low-resolution image;isotropic MRI super-resolution;anisotropic MRI super-resolution;image super-resolution;image acquisition speed","Anisotropy;Child;Humans;Magnetic Resonance Imaging;Records","1","","19","IEEE","8 Sep 2022","","","IEEE","IEEE Conferences"
"Spatially Adaptive Losses for Video Super-resolution with GANs","X. Wang; A. Lucas; S. Lopez-Tapia; X. Wu; R. Molina; A. K. Katsaggelos","Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Dpto. de Ciencias de la Computación e Inteligencia Artificial, Universidad de Granada, Spain; Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Dpto. de Ciencias de la Computación e Inteligencia Artificial, Universidad de Granada, Spain; Dept. of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","16 Apr 2019","2019","","","1697","1701","Deep Learning techniques and more specifically Generative Adversarial Networks (GANs) have recently been used for solving the video super-resolution (VSR) problem. In some of the published works, feature-based perceptual losses have also been used, resulting in promising results. While there has been work in the literature incorporating temporal information into the loss function, studies which make use of the spatial activity to improve GAN models are still lacking. Towards this end, this paper aims to train a GAN guided by a spatially adaptive loss function. Experimental results demonstrate that the learned model achieves improved results with sharper images, fewer artifacts and less noise.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682742","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682742","Video Super-Resolution;Generative Adversarial Networks;Perceptual Loss;Spatial Adaptivity","Training;Gallium nitride;Spatial resolution;Adaptation models;Image edge detection;Generators","image resolution;learning (artificial intelligence);neural nets;video signal processing","video super-resolution problem;VSR;feature-based perceptual losses;GAN models;spatially adaptive loss function;temporal information;deep learning techniques","","1","","17","IEEE","16 Apr 2019","","","IEEE","IEEE Conferences"
"Photo-Realistic Image Super-Resolution via Variational Autoencoders","Z. -S. Liu; W. -C. Siu; Y. -L. Chan","Department of Electronic and Information Engineering (EIE), Center for Multimedia Signal Processing, The Hong Kong Polytechnic University, Hong Kong; Department of Electronic and Information Engineering (EIE), Center for Multimedia Signal Processing, The Hong Kong Polytechnic University, Hong Kong; Department of Electronic and Information Engineering (EIE), Center for Multimedia Signal Processing, The Hong Kong Polytechnic University, Hong Kong","IEEE Transactions on Circuits and Systems for Video Technology","2 Apr 2021","2021","31","4","1351","1365","There is a great leap in objective accuracy on image super-resolution, which recently brings a new challenge on image super-resolution with larger up-scaling (e.g. 4×) using pixel based distortion for measurement. This causes over-smooth effect which cannot grasp well the perceptual similarity. The advent of generative adversarial networks makes it possible super-resolve a low-resolution image to generate photo-realistic images sharing distribution with the high-resolution images. However, generative networks suffer from problems of mode-collapse and unrealistic sample generation. We propose to perform Image Super-Resolution via Variational AutoEncoders (SR-VAE) learning according to the conditional distribution of the high-resolution images induced by the low-resolution images. Given that the Conditional Variational Autoencoders tend to generate blur images, we add the conditional sampling mechanism to narrow down the latent subspace for reconstruction. To evaluate the model generalization, we use KL loss to measure the divergence between latent vectors and standard Gaussian distribution. Eventually, in order to balance the trade-off between super-resolution distortion and perception, not only that we use pixel based loss, we also use the modified deep feature loss between SR and HR images to estimate the reconstruction. In experiments, we evaluated a large number of datasets to make comparison with other state-of-the-art super-resolution approaches. Results on both objective and subjective measurements show that our proposed SR-VAE can achieve good photo-realistic perceptual quality closer to the natural image manifold while maintain low distortion.","1558-2205","","10.1109/TCSVT.2020.3003832","Centre for Signal Processing, Department of Electronic and Information Engineering, The Hong Kong Polytechnic University(grant numbers:1-BBA2,G-YBKG); Research Grants Council of the Hong Kong Special Administrative Region, China(grant numbers:PolyU 5243/13E); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121327","Image super-resolution;variational autoencoders;distortion;divergence","Gallium nitride;Generative adversarial networks;Distortion;Image reconstruction;Feature extraction;Distortion measurement;Generators","Gaussian distribution;image reconstruction;image resolution;image sampling;learning (artificial intelligence);neural nets;realistic images","super-resolution distortion;generative adversarial networks;low-resolution image;high-resolution images;conditional variational autoencoders;blur images;photorealistic image super-resolution;natural image manifold;pixel based distortion;over-smooth effect;unrealistic sample generation;mode-collapse;SR-VAE learning;conditional sampling mechanism;KL loss;standard Gaussian distribution;latent vectors;modified deep feature loss;HR images","","16","","55","IEEE","19 Jun 2020","","","IEEE","IEEE Journals"
"Image Super-Resolution using a Improved Generative Adversarial Network","H. Wang; W. Wu; Y. Su; Y. Duan; P. Wang","Department of Information Engineering, Wuhan University of Technology, Wuhan, Hubei Province, China; Department of Information Engineering, Wuhan University of Technology, Wuhan, Hubei Province, China; Department of Information Engineering, Wuhan University of Technology, Wuhan, Hubei Province, China; Department of Information Engineering, Wuhan University of Technology, Wuhan, Hubei Province, China; Department of Information Engineering, Wuhan University of Technology, Wuhan, Hubei Province, China","2019 IEEE 9th International Conference on Electronics Information and Emergency Communication (ICEIEC)","5 Aug 2019","2019","","","312","315","In recent years, there have been a variety of learning methods applied to single image super-resolution problems (SISR). Generative adversarial network (GAN) for image super-resolution which can infer photo-realistic natural images for 4× upscaling factors has been proposed. Images generated from SRGAN have sharper details, but some texture will be distorted and deformed. In this situation, the image looks unsatisfactory. In order to generate clearer, more eye-catching picture, we improved the SRGAN network. We proposed a encoder block in the generator to extract more crucial features. In this condition, we can generate more clear and natural image.","2377-844X","978-1-7281-1190-2","10.1109/ICEIEC.2019.8784610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784610","component;super-resolution;GAN;encoder","Image resolution;Training;Feature extraction;Generative adversarial networks;Generators;Convolutional neural networks;Gallium nitride","image resolution;learning (artificial intelligence);neural nets;realistic images","improved generative adversarial network;single image super-resolution problems;photo-realistic natural images;SRGAN network;clear image;natural image","","6","","12","IEEE","5 Aug 2019","","","IEEE","IEEE Conferences"
"License Plate Image Super Resolution Using Generative Adversarial Network(GAN)","B. K. Shah; A. Yadav; A. K. Dixit","Department of Computer Engineering, Delhi Technological University, Delhi, India; Department of Computer Engineering, Delhi Technological University, Delhi, India; Department of Computer Engineering, Delhi Technological University, Delhi, India","2022 International Conference on Applied Artificial Intelligence and Computing (ICAAIC)","16 Jun 2022","2022","","","1139","1143","Super resolution of images in the field of Computer Vision is a widely used for the conversion of images into high resolution without the loss of pixel data into the images. Due to fast movement of vehicles and low quality of camera the image cannot be verified easily so, the techniques of Generative Adversarial network have been applied for the Super resolution of license plate Images which works to recover the loss data of license plate images without loss of pixel data. Earlier, mean square error (MS E) and peak signal to noise ratio (PSNR) was used as content loss to minimize the error but at optimal minimization the images get over smoothen and pixel data were lost. This paper has proposed and applied VGG-19 as pretrained neural network along with MSE and PSNR to minimize the content loss which overall optimizes the perpetual loss, and over smoothness of the images gets controlled which saves pixel data. Later, the pre-trained neural network is integrated with Generative Adversarial Network [GAN] of discriminator and generator to produce high resolution images. Taking the PSNR as an evaluation metrices for the images, it increases from 26.184 to 28.696 and accuracy from 58% to 84%.","","978-1-6654-9710-7","10.1109/ICAAIC53929.2022.9792759","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9792759","Super Resolution;Generator;Discriminator;Peak signal to noise ratio;VGG-19","Computer vision;Image resolution;PSNR;Neural networks;Mean square error methods;Generative adversarial networks","computer vision;image resolution;mean square error methods;neural nets;road vehicles;traffic engineering computing","pixel data;loss data;PSNR;content loss;pretrained neural network;perpetual loss;generative adversarial network;license plate image super resolution;GAN;computer vision;vehicle movement;mean square error;peak signal to noise ratio;VGG-19;MSE;image smoothness","","","","33","IEEE","16 Jun 2022","","","IEEE","IEEE Conferences"
"Generative Adversarial Networks for Abnormal Event Detection in Videos Based on Self-Attention Mechanism","W. Zhang; G. Wang; M. Huang; H. Wang; S. Wen","Department of Information and Communication Engineering, Hainan University, Haikou, China; Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China; Department of Information and Communication Engineering, Hainan University, Haikou, China; Department of Computer and Cyberspace Security, Hainan University, Haikou, China; Department of Information and Communication Engineering, Hainan University, Haikou, China","IEEE Access","14 Sep 2021","2021","9","","124847","124860","Unsupervised anomaly detection defines an abnormal event as an event that does not conform to expected behavior. In the field of unsupervised anomaly detection, it is a pioneering work that leverages the difference between a future frame predicted by a generative adversarial network and its ground truth to detect an abnormal event. Based on the work, we improve the ability of video prediction framework to detect abnormal events by enhancing the difference between prediction results for normal and abnormal events. We incorporate super-resolution and self-attention mechanism to design a generative adversarial network. We propose an auto-encoder as a generator, which incorporates dense residual networks and self-attention. Moreover, we propose a new discriminator, which introduces self-attention on the basis of a relativistic discriminator. To predict a future frame with higher quality for normal events, we impose a constraint on the motion in video prediction by fusing optical flow and gradient difference between frames. We also introduce a perception constraint in video prediction to enrich the texture details of a frame. The AUC of our method on CUHK Avenue and Shanghai Tech datasets reaches 89.2% and 75.7% respectively, which is better than most existing methods. In addition, we propose a processing flow that can realize real-time anomaly detection in videos. The average running time of our video prediction framework is 37 frames per second. Among all real-time methods for abnormal event detection in videos, our method is competitive with the state-of-the-art methods.","2169-3536","","10.1109/ACCESS.2021.3110798","Natural Science Foundation of Hainan Province(grant numbers:2019CXTD400,617079); National Key Research and Development Program of China(grant numbers:SQ2020YFF0423852); Hainan Key Research and Development Program(grant numbers:620RC554,ZDYF2019115); National Natural Science Foundation of China(grant numbers:62175054,61865005,61762033); Open Project Program of Wuhan National Laboratory for Optoelectronics(grant numbers:2020WNLOKF001); National Key Technology Support Program(grant numbers:2015BAH55F04,2015BAH55F01); Major Science and Technology Project of Hainan Province(grant numbers:ZDKJ2016015); Scientific Research Staring Foundation of Hainan University(grant numbers:KYQD(ZR)1882); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530576","Abnormal event detection;generative adversarial networks (GANs);self-attention;video understanding","Streaming media;Event detection;Anomaly detection;Feature extraction;Generative adversarial networks;Generators;Training","feature extraction;image colour analysis;image resolution;image sequences;image texture;neural nets;real-time systems;unsupervised learning;video signal processing","generative adversarial network;abnormal event detection;unsupervised anomaly detection;dense residual networks;real time anomaly detection;self attention mechanism;super resolution mechanism;autoencoder;relativistic discriminator;video prediction;optical flow;gradient difference;frame texture details","","6","","55","CCBY","7 Sep 2021","","","IEEE","IEEE Journals"
"SAR Image Super-Resolution Reconstruction Based on Full-Resolution Discrimination","G. Xiao; L. Zhang","Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei, China; Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei, China","2022 IEEE International Conference on Image Processing (ICIP)","18 Oct 2022","2022","","","691","695","In image super-resolution reconstruction based on generative adversarial networks (GANs), the discrimination of high-resolution (HR) images enriches texture details. However, solely discriminating HR images limits the reconstruction quality, while discriminating other resolution features can improve the texture structures of the reconstructed HR images. Therefore, this paper proposes a SAR image super-resolution reconstruction algorithm based on full-resolution discrimination (FRD). In the suggested architecture, the full-resolution discriminator network is used to extract the high, medium, and low-resolution features, which are then fused into a full-resolution feature. Finally, the full-resolution feature difference between the authentic and fake images is input to the generator, which reduces the inaccuracy of single-resolution feature discrimination. Experimental results on synthetic aperture radar (SAR) images demonstrate that the proposed FRD algorithm performs better than the state-of-the-art super-resolution algorithms in reconstructing the texture structures of the HR SAR images.","2381-8549","978-1-6654-9620-9","10.1109/ICIP46576.2022.9897999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9897999","Synthetic aperture radar;super-resolution;generative adversarial network;full-resolution discrimination;feature fusion","Superresolution;Reconstruction algorithms;Apertures;Feature extraction;Generative adversarial networks;Radar polarimetry;Generators","","","","","","26","IEEE","18 Oct 2022","","","IEEE","IEEE Conferences"
"How Can We Make Gan Perform Better in Single Medical Image Super-Resolution? A Lesion Focused Multi-Scale Approach","J. Zhu; G. Yang; P. Lio","The Computer Laboratory, University of Cambridge, Cambridge, CB3 0FD, UK; Imperial College London, National Heart and Lung Institute, London, UK; The Computer Laboratory, University of Cambridge, Cambridge, CB3 0FD, UK","2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)","11 Jul 2019","2019","","","1669","1673","Single image super-resolution (SISR) is of great importance as a low-level computer vision task. The fast development of Generative Adversarial Network (GAN) based deep learning architectures realises an efficient and effective SISR to boost the spatial resolution of natural images captured by digital cameras. However, the SISR for medical images is still a very challenging problem. This is due to (1) compared to natural images, in general, medical images have lower signal to noise ratios, (2) GAN based models pre-trained on natural images may synthesise unrealistic patterns in medical images which could affect the clinical interpretation and diagnosis, and (3) the vanilla GAN architecture may suffer from unstable training and collapse mode that can also affect the SISR results. In this paper, we propose a novel lesion focused SR (LFSR) method, which incorporates GAN to achieve perceptually realistic SISR results for brain tumour MRI images. More importantly, we test and make comparison using recently developed GAN variations, e.g., Wasserstein GAN (WGAN) and WGAN with Gradient Penalty (WGAN-GP), and propose a novel multi-scale GAN (MS-GAN), to achieve a more stabilised and efficient training and improved perceptual quality of the super-resolved results. Based on both quantitative evaluations and our designed mean opinion score, the proposed LFSR coupled with MS-GAN has performed better in terms of both perceptual quality and efficiency.","1945-8452","978-1-5386-3641-1","10.1109/ISBI.2019.8759517","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759517","Generative Adversarial Network;Super-Resolution;Medical Image Analysis;Lesion Detection;Image Processing","Gallium nitride;Generative adversarial networks;Image resolution;Medical diagnostic imaging;Training;Lesions","biomedical MRI;brain;computer vision;edge detection;image resolution;learning (artificial intelligence);maximum likelihood estimation;medical image processing;tumours","Wasserstein generative adversarial network with gradient penalty;generative adversarial network based deep learning architectures;unstable training mode;lesion focused multi-scale approach;natural images;spatial resolution;low-level computer vision task;single medical image super-resolution;brain tumour MRI images;perceptually realistic SISR results;collapse mode;vanilla GAN architecture","","31","","28","IEEE","11 Jul 2019","","","IEEE","IEEE Conferences"
"Super-Resolution of Remote Sensing Images Based on Transferred Generative Adversarial Network","W. Ma; Z. Pan; J. Guo; B. Lei","Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing, China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","1148","1151","Single image super-resolution (SR) has been widely studied in recent years as a crucial technique for remote sensing applications. This paper proposes a SR method for remote sensing images based on a transferred generative adversarial network (TGAN). Different from the previous GAN-based SR approaches, the novelty of our method mainly reflects from two aspects. First, the batch normalization layers are removed to reduce the memory consumption and the computational burden, as well as raising the accuracy. Second, our model is trained in a transfer-learning fashion to cope with the insufficiency of training data, which is the crux of applying deep learning methods to remote sensing applications. The model is firstly trained on an external dataset DIV2K and further fine-tuned with the remote sensing dataset. Our experimental results demonstrate that the proposed method is superior to SRCNN and SRGAN in terms of both the objective evaluation and the subjective perspective.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517442","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517442","Remote sensing images;super-resolution;generative adversarial network;transfer learning","Image resolution;Remote sensing;Signal resolution;Training;Generative adversarial networks;Knowledge engineering;Task analysis","geophysical image processing;image resolution;learning (artificial intelligence);remote sensing","remote sensing images;transferred generative adversarial network;single image super-resolution;remote sensing applications;SR method;previous GAN-based SR approaches;transfer-learning fashion;deep learning methods;remote sensing dataset","","23","","12","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"MSG-CapsGAN: Multi-Scale Gradient Capsule GAN for Face Super Resolution","M. M. Majdabadi; S. -B. Ko","Department of Electrical and Computer Engineering, University of Saskatchewan, Saskatoon, Canada; Department of Electrical and Computer Engineering, University of Saskatchewan, Saskatoon, Canada","2020 International Conference on Electronics, Information, and Communication (ICEIC)","2 Apr 2020","2020","","","1","3","One of the most useful sub-fields of Super-Resolution (SR) is face SR. Given a Low-Resolution (LR) image of a face, the High-Resolution (HR) counterpart is demanded. However, performing SR task on extremely low resolution images is very challenging due to the image distortion in the HR results. Many deep learning-based SR approaches have intended to solve this issue by using attribute domain information. However, they require more complex data and even additional networks. To simplify this process and yet preserve the precision, a novel Multi-Scale Gradient GAN with Capsule Network as its discriminator is proposed in this paper. MSG-CapsGAN surpassed the state-of-the-art face SR networks in terms of PSNR. This network is a step towards a precise pose invariant SR system.","","978-1-7281-6289-8","10.1109/ICEIC49074.2020.9051244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9051244","Generative Adversarial Network (GAN);Capsule Network;Super Resolution","Electric potential;Superresolution;Generative adversarial networks;Distortion;Task analysis;Faces","face recognition;image reconstruction;image resolution;learning (artificial intelligence);neural nets;pose estimation","multiscale gradient capsule GAN;invariant SR system;state-of-the-art face SR networks;Capsule Network;novel MultiScale Gradient GAN;additional networks;attribute domain information;deep learning-based SR approaches;image distortion;extremely low resolution images;SR task;high-resolution counterpart;low-resolution image;face super resolution;MSG-CapsGAN","","6","","15","IEEE","2 Apr 2020","","","IEEE","IEEE Conferences"
"Super Resolution Image Reconstruction of Textile Based on SRGAN","J. Li; L. Wu; S. Wang; W. Wu; F. Song; G. Zheng","School of Eletromechanical Engineering, Guangdong University of Technology, Guangzhou, China; School of Eletromechanical Engineering, Guangdong University of Technology, Guangzhou, China; School of Eletromechanical Engineering, Guangdong University of Technology, Guangzhou, China; School of Eletromechanical Engineering, Guangdong University of Technology, Guangzhou, China; School of Eletromechanical Engineering, Guangdong University of Technology, Guangzhou, China; School of Eletromechanical Engineering, Guangdong University of Technology, Guangzhou, China","2019 IEEE International Conference on Smart Internet of Things (SmartIoT)","14 Nov 2019","2019","","","436","439","For the problem of image distortion in textile flaw detection, a super-resolution image reconstruction technique based on GAN (Generative adversarial network) can reconstruct the obtained low-pixel image into a high-pixel image. The generative adversarial network consists of a discriminative network and a generative network. Generative network is responsible for generate high-resolution images, discriminative network is responsible for identifying the authenticity of the image. the generative loss and discriminative loss continuously optimize the network and guide the generation of high-quality images. The experimental results show that, the PNSR of SRGAN is 0.83 higher than that of the Bilinear, and the SSIM is higher than 0.0819. SRGAN can get a clearer image and reconstruct a richer texture, more high-frequency details, and easier to identify defects, which is important in the flaw detection of fabrics.","","978-1-7281-3488-8","10.1109/SmartIoT.2019.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896586","Super resolution;Generative adversarial network;Textile","Generative adversarial networks;Image reconstruction;Convolution;Textiles;Gallium nitride","flaw detection;image reconstruction;image resolution;image texture;optimisation;textile industry","SRGAN;image distortion;textile flaw detection;generative adversarial network;pixel image;discriminative network;high-resolution images;discriminative loss;quality images;super resolution image reconstruction technique;PNSR","","3","","10","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Implementation of Super Resolution in Images Based on Generative Adversarial Network","K. S. Reddy; V. P. Vijayan; A. D. Gupta; P. Singh; R. G. VIdhya; D. Kapila","Department of Electronics and Communication Engineering, Teegala Krishna Reddy Engineering College, Hyderabad, India; Mangalam College of Engineering, Kottayam, Kerala, India; Postgraduate Department of Geography, Chandernagore Government College, Hugli, West Bengal, India; Department of Computer Science and Engineering, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India; Department of Electronics and Communication Engineering, HKBK College of Engineering, Bengaluru, Karnataka, India; Department of Computer Science and Engineering, Lovely Professional University, Phagwara, India","2022 8th International Conference on Smart Structures and Systems (ICSSS)","1 Jun 2022","2022","","","01","07","A 3D visualization of a microscopic object is provided by the integral imaging microscopy system. A generative-adversarial-network (GAN) relied on super resolution (SR) algorithm is suggested in this research to improve resolution. The generator in GAN network regresses the highresolution (HR) outcome out of the low-resolution (LR) input image, where the discriminator differentiates among the original as well as generated images. It could perhaps recover the edges and boost the resolution besides 2, 4, or indeed 8 times without compromising image quality for different sector in different field. The framework is validated using a variation of decreased microscopic specimen images as well as appropriately develops images with considerable directional view and compared with each other to get the best model among them in different sector. The quantifiable investigation reveals that the suggested framework outperforms the existing algorithms for microscopic images.","","978-1-6654-9761-9","10.1109/ICSSS54381.2022.9782170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9782170","generative adversarial network (GAN);super-resolution (SR);micro lens array (MLA)","Image quality;Visualization;Image resolution;Three-dimensional displays;Microscopy;Generative adversarial networks;Intelligent structures","image reconstruction;image resolution;medical image processing;optical images;optical microscopy;regression analysis","microscopic object;integral imaging microscopy system;generative-adversarial-network;super resolution algorithm;GAN network;low-resolution input image;image quality;different sector;decreased microscopic specimen images;microscopic images;generative adversarial network","","1","","15","IEEE","1 Jun 2022","","","IEEE","IEEE Conferences"
"ESinGAN: Enhanced Single-Image GAN Using Pixel Attention Mechanism for Image Super-Resolution","W. Sun; B. -D. Liu","College of Control Science and Engineering, China University of Petroleum (East China), Qingdao, China; College of Control Science and Engineering, China University of Petroleum (East China), Qingdao, China","2020 15th IEEE International Conference on Signal Processing (ICSP)","18 Jan 2021","2020","1","","181","186","Recently, the SinGAN model emerged, and it was famous for generating from a single image. The SinGAN model achieves superior performance to other advanced models for image super-resolution task (trained on a dataset or a single image). However, SinGAN does not consider the importance of feature pixels on the feature map. In this paper, we propose an Enhanced SinGAN model (ESinGAN), an unconditional generative model that can improve the defects of SinGAN using the Pixel Attention mechanism. To evaluate the proposed ESinGAN model's performance, we carry out the experiments on a benchmark dataset. Through the experiments, we have achieved better performance than SinGAN and proved the effectiveness of the proposed method. Not only is the image significantly improved visually, but the PSNR and SSIM values of the model are also considerably increased. Besides, ESinGAN runs as fast as SinGAN under the same experimental environment.","2164-5221","978-1-7281-4480-1","10.1109/ICSP48669.2020.9320934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320934","SinGAN;Image Super-resolution;Pixel Attention","Training;Superresolution;Image resolution;Generators;Generative adversarial networks;PSNR;Task analysis","image enhancement;image resolution;neural nets","pixel attention mechanism;image super-resolution task;feature pixels;feature map;unconditional generative model;ESinGAN;enhanced single-image GAN;PSNR;SSIM","","1","","20","IEEE","18 Jan 2021","","","IEEE","IEEE Conferences"
"A Power Data Reconstruction Method Based on Super-Resolution Generative Adversarial Network","C. Zhang; Z. Shao; F. Chen","Fujian Smart Electrical Engineering Technology Research Center, Fuzhou University, Fuzhou, China; Fujian Smart Electrical Engineering Technology Research Center, Fuzhou University, Fuzhou, China; Fujian Smart Electrical Engineering Technology Research Center, Fuzhou University, Fuzhou, China","2021 6th Asia Conference on Power and Electrical Engineering (ACPEE)","24 May 2021","2021","","","300","304","The smart grid is rapidly developing to become highly connected and automated. These advancements have been mainly attributed to the ubiquitous data communication in the grid. However, low sampling frequency will limit the utilization degree of data because low frequency measurement power data contains little information. The existing methods of reconstructing the low-frequency sampling data into the high-frequency sampling data have poor accuracy of data reconstruction since most of them failed to capture the characteristics of power data. This paper proposes a novel method based on super-resolution generative adversarial network (SRGAN) to address this issue. First, we convert power data into data-images. Furthermore, the data-images are used to train the SRGAN model. Finally, the trained generator can be used to reconstruct the low-frequency sampling data into the high-frequency sampling data. Numerical experiments have been carried out based on photovoltaic (PV) power generation time-series data from the State Grid Corporation of China with separately reconstruction of the irradiance and PV power datas. The results demonstrate the superior performance of the proposed method compared with a series of state-of-the-art methods.","","978-1-7281-9159-1","10.1109/ACPEE51499.2021.9437116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9437116","Super-resolution reconstruction;generative adversarial network;power data;data-driven","Photovoltaic systems;Adaptation models;Superresolution;Interference;Reconstruction algorithms;Generative adversarial networks;Smart grids","frequency measurement;image reconstruction;image resolution;neural nets;photovoltaic power systems;power engineering computing;power system measurement;smart power grids;time series","ubiquitous data communication;low frequency measurement power data;low-frequency sampling data;high-frequency sampling data;super-resolution generative adversarial network;photovoltaic power generation time-series data;power data reconstruction;smart grid;SRGAN model;State Grid Corporation of China","","1","","16","IEEE","24 May 2021","","","IEEE","IEEE Conferences"
"Super-Resolution of Satellite Images Based on Two-Dimensional RRDB and Edge-Enhanced Generative Adversarial Network","Y. -Z. Chen; T. -J. Liu; K. -H. Liu","Department of Electrical Engineering, Graduate Institute of Communication Engineering, National Chung Hsing University, Taichung, Taiwan; Department of Electrical Engineering, Graduate Institute of Communication Engineering, National Chung Hsing University, Taichung, Taiwan; Department of Computer Science and Information Engineering, National Taichung University of Science and Technology, Taichung, Taiwan","2022 IEEE International Conference on Consumer Electronics (ICCE)","15 Mar 2022","2022","","","1","4","With the increasing demand for high-resolution images, image super-resolution (SR) technology has become one of the focuses in related research fields. Generally speaking, high resolution is usually achieved by increasing the density and accuracy of the sensor. However, such an approach is quite expensive for equipment and design. In particular, increasing the density of satellite sensors must be undertaken great risks. Inspired by EEGAN and based on it, the Ultra-Dense Subnet (UDSN) and Edge Enhanced Network (EEN) were modified. Among them, the UDSN is used for feature extraction and obtains high-resolution results that look clear in the intermediate but are deteriorated by artifacts, and the Edge-Enhanced Subnet (EESN) is used to purify, extract and enhance the image contour and use mask processing to eliminate images contaminated by noise. Finally, the restored intermediate image and the enhanced edge are combined to produce a high-resolution image with high credibility and clear content. We use Kaggle open experimental dataset to test and compare the results among different methods. It proves the performance of the proposed model is better than other SR methods.","2158-4001","978-1-6654-4154-4","10.1109/ICCE53296.2022.9730339","Ministry of Science and Technology, Taiwan(grant numbers:MOST 107-2221-E-005-068-MY2,MOST 109-2221-E-005-059); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9730339","Super-resolution(SR);satellite images;generative adversarial network (GAN);residual in residual dense block (RRDB)","Visualization;Satellites;Image edge detection;Superresolution;Network architecture;Feature extraction;Generative adversarial networks","feature extraction;image enhancement;image resolution","image contour;use mask processing;intermediate image restoration;high-resolution image;satellite image super-resolution;satellite sensors;edge-enhanced generative adversarial network;obtains high-resolution results;two-dimensional RRDB;edge-enhanced subnet;EEN;EESN;SR methods","","","","20","IEEE","15 Mar 2022","","","IEEE","IEEE Conferences"
"Research on Infrared Image Super-Resolution Based on Enhanced Generative Adversarial Network","L. Sun; Y. Zhao","School of Information Technology Hebei University of Economics and Business, Shijiazhuang, China; School of Information Technology Hebei University of Economics and Business, Shijiazhuang, China","2022 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI)","17 Aug 2022","2022","","","334","338","Infrared image super-resolution reconstruction is an effective way to improve the quality of infrared images. Aiming at the problem that the reconstructed image of the enhanced generative adversarial network Esrgan is prone to artifacts, This paper proposes a multi-branch enhanced generative adversarial network model, which adds an attention mechanism module and a residual module to the backbone of the original enhanced generative adversarial network model generator. The attention mechanism module strengthens the learning of useful channel information and suppresses useless channel information through the learning of global channel information. The residual module is a stack of the original Esrgan model block, which is the normalization of the channel dimension and retains the high-frequency features of the image. Experiments show that, compared with the original Esrgan model, the image texture details generated by the improved model are clearer and the resolution is higher, and the PSNR and SSIM of the image are significantly improved.","","978-1-6654-6803-9","10.1109/ICCEAI55464.2022.00076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9853477","Super-resolution reconstruction;Esrgan;Attention mechanism;Channel;Residual module;Detail texture","Training;Image texture;Computational modeling;Superresolution;Generative adversarial networks;Feature extraction;Generators","image enhancement;image reconstruction;image resolution;image texture;infrared imaging;neural nets","original Esrgan model block;image texture details;enhanced generative adversarial network Esrgan;multibranch enhanced generative adversarial network model;attention mechanism module;infrared image super resolution reconstruction;global channel information;suppresses useless channel information;original enhanced generative adversarial network model generator","","","","6","IEEE","17 Aug 2022","","","IEEE","IEEE Conferences"
"Infrared Image Super-Resolution via Generative Adversarial Network with Gradient Penalty Loss","J. Q. Mei; X. Wen Ding; D. Zheng; T. Page","School of Electronic Engineering, Tianjin University of Technology and Education, Tianjin, China; School of Electronic Engineering, Tianjin University of Technology and Education, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; Dept. Computing & Electronic Engineering, Faculty of Engineering & Design, Institute of Technology, Sligo, Ireland","2022 IEEE International Instrumentation and Measurement Technology Conference (I2MTC)","30 Jun 2022","2022","","","1","6","Infrared thermal imaging technology has been gradually developed and widely applied in measurement and non-destructive testing. However, low-contrast blurred details and expensive acquisition equipment remain as barriers to its further practical applications and widespread adoption. In this paper, a novel framework comprising deep learning techniques is proposed to offer a relatively competitive and compatible solution of infrared image super-resolution. Firstly, radiance information from low-resolution imagery is detected and automatically translated to high-resolution through a Generative Adversarial Network (GAN) with Wasserstein distance. Secondly, a gradient penalty loss function is utilized for the discriminator to guide the generator to achieve reasonable and acceptable convergence. Through evaluation of three widely utilized infrared datasets, the proposed method demonstrates superior performance against the state-of-art method with more accurate Peak Signal-To-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM) respectively. The outcome of this study has implications for a real-application of deep learning based infrared non-destructive testing and measurement scenarios.","2642-2077","978-1-6654-8360-5","10.1109/I2MTC48687.2022.9806485","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9806485","Infrared Imaging;Super-Resolution;Deep Learning;Generative Adversarial Network;Gradient Penalty Loss","Training;Deep learning;PSNR;Atmospheric measurements;Superresolution;Generative adversarial networks;Particle measurements","convergence;convolutional neural nets;deep learning (artificial intelligence);gradient methods;image denoising;image resolution;infrared imaging;nondestructive testing;statistical distributions","low-contrast blurred details;expensive acquisition equipment;deep learning;infrared image super-resolution;generative adversarial network;gradient penalty loss function;nondestructive testing;infrared thermal imaging technology;Wasserstein distance;acceptable convergence;reasonable convergence;peak signal-to-noise ratio;PSNR;structural similarity index measure;SSIM","","","","32","IEEE","30 Jun 2022","","","IEEE","IEEE Conferences"
"A Unified Framework for Super-Resolution Based on Segmentation-Prior and Self-Attention","X. Hu; Y. Zhang; D. Yang","College of Information and Electronic Engineering Zhejiang University, Hangzhou, China; College of Information and Electronic Engineering Zhejiang University, Hangzhou, China; College of Information and Electronic Engineering Zhejiang University, Hangzhou, China","2022 IEEE 2nd International Conference on Data Science and Computer Application (ICDSCA)","29 Dec 2022","2022","","","80","84","Convolutional Neural Network (CNN) is intensively applied to super-resolution (SR) task because of its superior performance. However, the problem of SR task is still challenging due to the lack of prior knowledge and small receptive field of CNN. We propose a unified framework for single image SR based on segmentation-prior and self-attention, named Segmentation-Prior Self-Attention Generative Adversarial Network (SPSAGAN). This combination is led by a carefully designed weighted addition to balance the influence of feature and segmentation attentions. Thus, the SPSAGAN can emphasize textures in the same segmentation category and meanwhile focus on the long-distance feature relationship. Extensive experiments show that SPSAGAN can generate more realistic and visually pleasing textures compared to state-of-the-art SFTGAN [1] and ESRGAN [2] on OST and BSD100 datasets","","978-1-6654-7200-5","10.1109/ICDSCA56264.2022.9988090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9988090","Super-Resolution;GAN;Semantic Segmentation;Self-Attention","Image segmentation;Superresolution;Computer applications;Data science;Generative adversarial networks;Convolutional neural networks;Task analysis","convolutional neural nets;image resolution;image segmentation;image texture","BSD100 datasets;CNN;Convolutional Neural Network;ESRGAN;long-distance feature relationship;OST datasets;receptive field;segmentation attentions;segmentation category;segmentation-prior self-attention generative adversarial network;SFTGAN;single image SR;SPSAGAN;SR task;super-resolution task;visually pleasing textures;weighted addition","","","","22","IEEE","29 Dec 2022","","","IEEE","IEEE Conferences"
"FRAGAN-VSR: Frame-Recurrent Attention Generative Adversarial Network for Video Super-Resolution","Y. Zhang; G. Liu; Y. Zhao; D. Zha; W. Xin; L. Zhao; L. Wang","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China, Beijing, China","2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)","21 Dec 2021","2021","","","753","757","Video super resolution (SR) is an important task, which recovers high-resolution (HR) frames from consecutive low-resolution (LR) couterparts. The most advanced works achieved good performance to this day. However, most of them has largely focussed on making a breakthrough in accuracy and speed, which has neglect that how to recover the finer texture details. Therefore, in this paper, we first present an Video SR model combined generative adversarial network and recurrent neural network (GAN-RNN) structure. It is forced by the self-attention mechanism to pay great attention to the high-frequency information of the LR frames. The perceptual loss is introduced to retain the high-frequency detail which is different from other video SR network. A great deal of evaluations and comparisons with previous methods have confirmed the merits of the proposed framework which can significantly outperform the current state of the art.","2375-0197","978-1-6654-0898-1","10.1109/ICTAI52525.2021.00119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643258","Video Super-Resolution;Generative Adversarial Network;Recurrent Neural Network;Self-attention Mechanism","Training;Recurrent neural networks;Conferences;Superresolution;Fitting;Generative adversarial networks;Task analysis","image resolution;image texture;recurrent neural nets;video signal processing","FRAGAN-VSR;frame-recurrent attention generative adversarial network;video super-resolution;high-resolution frames;low-resolution couterparts;finer texture details;recurrent neural network structure;self-attention mechanism;high-frequency information;LR frames;high-frequency detail;video SR network;video SR model","","","","22","IEEE","21 Dec 2021","","","IEEE","IEEE Conferences"
"Image Super-Resolution Reconstruction of Pancreatic Carcinoma Based on Edge Repair Generative Adversarial Network","Y. Geng; W. Zhou","School of Mechatronic Engineering and Automation, Shanghai University, Shanghai; School of Mechatronic Engineering and Automation, Shanghai University, Shanghai","2022 41st Chinese Control Conference (CCC)","11 Oct 2022","2022","","","6421","6426","High-resolution medical imaging of pancreatic carcinoma is of great significance for the early diagnosis of the disease. Despite breakthroughs in accuracy and the capable of generating realistic textures, there are still some problems remain unsolved in current medical image super-resolution reconstruction methods: the edge details are often accompanied with unpleasant artifacts, how do we recover finer textures? To achieve this, we propose an Edge Repair Generative Adversarial Network (ERGAN). The model adds an edge repair network on the basis of the generator and the discriminator network, performs edge detection and repair on the input low-resolution images, then fuses the output edge feature map with the shallow feature map generated by the generator. Finally, the reconstructed images are sent to the discriminator through the up-sampling layer to evaluate the reconstruction effect. In this paper, the model is evaluated on the pancreatic carcinoma data set CPTAC-PDA published on the website of the Cancer Imaging Archive (TCIA). The experimental results show that the images reconstructed by the network model proposed in this paper not only improve the evaluation indicators, but also has a clearer cross-sectional outline and more obvious detailed features.","1934-1768","978-988-75815-3-6","10.23919/CCC55666.2022.9901818","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9901818","Pancreatic Carcinoma;Super-Resolution Reconstruction;Generative Adversarial Network;Edge Repair","Visualization;Image edge detection;Superresolution;Maintenance engineering;Reconstruction algorithms;Feature extraction;Generative adversarial networks","cancer;edge detection;feature extraction;image reconstruction;image resolution;image texture;medical image processing","Cancer Imaging Archive;current medical image super-resolution reconstruction methods;discriminator network;edge details;Edge Repair Generative Adversarial Network;edge repair network;high-resolution medical imaging;input low-resolution images;network model;output edge feature map;pancreatic carcinoma data;performs edge detection;reconstructed images","","","","17","","11 Oct 2022","","","IEEE","IEEE Conferences"
"Single Image Super-Resolution Algorithm Based on Enhanced Generative Adversarial Network","T. Du; Y. Zhang","School of Information Science and Engineering, Southeast University, Nanjing, China; School of Information Science and Engineering, Southeast University, Nanjing, China","2021 6th International Conference on Image, Vision and Computing (ICIVC)","14 Sep 2021","2021","","","357","361","With the advancement of technology, the processing of increasing image data becomes particularly important. Computer vision can process the hidden information behind these data. Image super-resolution aims to use a low-resolution image to generate a corresponding high-resolution image through the convolutional neural network, improving the quality of the image and the display effect. This paper proposes an Enhanced Generative Adversarial Network (EGAN), designing a new loss function, so that the generated image has more texture details than the previous method. On three benchmark datasets, Set5, Set14 and BSD100, the proposed method has a great improvement on the peak signal-to-noise ratio and structural similarity of the generated images.","","978-1-6654-4368-5","10.1109/ICIVC52351.2021.9527025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9527025","super-resolution;generative adversarial network;loss function","Computer vision;PSNR;Image color analysis;Superresolution;Benchmark testing;Generative adversarial networks;Convolutional neural networks","computer vision;convolutional neural nets;image resolution;image texture","convolutional neural network;enhanced generative adversarial network;single image super-resolution algorithm;image data;computer vision;hidden information;EGAN;structural similarity;image quality","","","","22","IEEE","14 Sep 2021","","","IEEE","IEEE Conferences"
"High Resolution Image Generation Using Learning Super-Resolution for Low Resolution Images","K. Nakayama; T. Goto","Dept. of Computer Science, Nagoya Institute of Technology, Nagoya, Japan; Dept. of Computer Science, Nagoya Institute of Technology, Nagoya, Japan","2022 4th International Conference on Computer Communication and the Internet (ICCCI)","9 Aug 2022","2022","","","83","86","Cameras have been installed in a variety of locations. This is to record evidence in case of trouble. However, many of these images have low resolution, which reduces the effectiveness of the evidence. In particular, license plate images can identify the parties involved, so it is important to read the characters. In this paper, we aim to improve the resolution of license plate images by using super-resolution with adversarial learning method.","","978-1-6654-6992-0","10.1109/ICCCI55554.2022.9850252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9850252","super-resolution;generative adversarial network","Image synthesis;Superresolution;License plate recognition;Generative adversarial networks;Cameras;Adversarial machine learning;Internet","cameras;image recognition;image resolution;learning (artificial intelligence)","adversarial learning method;high resolution image generation;super-resolution;low resolution images;license plate images","","","","5","IEEE","9 Aug 2022","","","IEEE","IEEE Conferences"
"Super-Resolution for Cross-Sensor Optical Remote Sensing Images","S. Ambudkar; R. Raj; K. Billa; R. Hukumchand","Pixxel.space, Bengaluru, Karnataka, India; Pixxel.space, Bengaluru, Karnataka, India; Pixxel.space, Bengaluru, Karnataka, India; Pixxel.space, Bengaluru, Karnataka, India","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1880","1883","Generative adversarial network (GAN) models are becoming popular in the field of remote sensing for generating high spatial resolution images from their low resolution versions. In this study, four models including two basic Super-resolution GAN models and two non-GAN Deep Learning models were trained and tested to achieve 2.5m, and 5m spatial resolution from their 10m spatial resolution satellite data. The comparison of results showed that the SRGAN model performed better than the other deep learning models. The performance metrics were also found to be consistent with available literature.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883182","Super-resolution;generative adversarial network;resolution enhancement","Deep learning;Satellites;Superresolution;Optical fiber networks;Generative adversarial networks;Optical imaging;Data models","geophysical image processing;image resolution;learning (artificial intelligence);remote sensing","low resolution versions;basic Super-resolution GAN models;nonGAN Deep Learning models;5m spatial resolution;10m spatial resolution satellite data;SRGAN model;cross-sensor optical remote sensing;generative adversarial network models;high spatial resolution images;size 2.5 m;size 10.0 m;size 5.0 m","","","","15","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Learning Structural Coherence Via Generative Adversarial Network for Single Image Super-resolution","Y. Li; J. Liu; Y. Chen","School of Computer Science, Sichuan University, Chengdu, China; School of Computer Science, Sichuan University, Chengdu, China; School of Computer Science, Sichuan University, Chengdu, China","2021 International Conference on Computer Engineering and Application (ICCEA)","28 Oct 2021","2021","","","184","188","Among the major remaining challenges for single image super-resolution (SISR) is the capacity to recover coherent images with global shapes and local details conforming to human vision system. Recent generative adversarial network (GAN) based SISR methods have yielded overall realistic SR images, however, there are always unpleasant textures accompanied with structural distortions in local regions. To target these issues, we introduce the gradient branch into the generator to preserve structural information by restoring high-resolution gradient maps in SR process. In addition, we utilize a U-net based discriminator to consider both the whole image and the detailed per-pixel authenticity, which could encourage the generator to maintain overall coherence of the reconstructed images. Moreover, we have studied objective functions and LPIPS perceptual loss is added to generate more realistic and natural details. Experimental results show that our proposed method outperforms state-of-the-art perceptual-driven SR methods in perception index (PI), and obtains more geometrically consistent and visually pleasing textures in natural image restoration.","","978-1-6654-2616-9","10.1109/ICCEA53728.2021.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9581104","sing image super-resolution;generative adversarial network;gradient map;U-net;perceptual loss","Shape;Machine vision;Superresolution;Coherence;Generative adversarial networks;Distortion;Linear programming","image resolution;image restoration;image texture;neural nets","realistic details;natural details;state-of-the-art perceptual-driven SR methods;natural image restoration;structural coherence;single image super-resolution;coherent images;local details;human vision system;recent generative adversarial network;SISR methods;realistic SR images;structural distortions;local regions;structural information;high-resolution gradient maps;U-net based discriminator;reconstructed images","","","","28","IEEE","28 Oct 2021","","","IEEE","IEEE Conferences"
"Single image super-resolution via deep learning","Z. Cao; X. Liu; Z. Wang","Shenzhen college of international education, Shenzhen, China; Tongii University, Shanghai, China; South China Agricultural University, Guangzhou, China","2022 3rd International Conference on Computer Vision, Image and Deep Learning & International Conference on Computer Engineering and Applications (CVIDL & ICCEA)","18 Jul 2022","2022","","","425","430","Single image Super-resolution (SISR) is a computer vision (CV) problem that aims to acquire a high-resolution (HR) image from a distorted low-resolution (LR) image, making it a valuable technology that could be utilized in various fields such as photography, medical imaging, satellite imaging, etc. As a result of the advancement of computing hardware and richer computational power, deep learning-based image super-resolution models have emerged at an unprecedented rate. This paper reviews SISR and its recent development. Three widely used deep architectures: convolutional neural network (CNN), generative adversarial network (GAN), and transformer are explained. Next, six different deep learning-based models that summarize research on SISR are analyzed. Finally, this review concludes with applications of SR, current challenges SISR models encountered, and potential future research directions.","","978-1-6654-5911-2","10.1109/CVIDLICCEA56201.2022.9824576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9824576","component;Computer Vision;Single image super-resolution;Deep learning;Convolutional neural networks (CNN);Generative adversarial networks (GAN);Attention mechanism;Transformer","Photography;Satellites;Computational modeling;Superresolution;Neural networks;Generative adversarial networks;Transformers","computer vision;convolutional neural nets;deep learning (artificial intelligence);image resolution","single image super-resolution;SISR;computer vision problem;high-resolution image;low-resolution image;medical imaging;satellite imaging;deep learning-based image super-resolution models;generative adversarial network;CV problem;HR image;LR image;computing hardware;convolutional neural network;GAN","","1","","14","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Recursive Conditional Generative Adversarial Networks for Video Transformation","S. Kim; D. Y. Suh","Department of Electrical Engineering, Kyung Hee University, Seoul, South Korea; Department of Electrical Engineering, Kyung Hee University, Seoul, South Korea","IEEE Access","2 Apr 2019","2019","7","","37807","37821","Conditional generative adversarial networks (cGANs) are used in various transformation applications, such as super-resolution, colorization, image denoising, and image inpainting. So far, cGANs have been applied to the transformation of still images, but their use could be extended to the transformation of video contents, which has a much larger market. This paper considers problems with the cGAN-based transformation of video contents. The major problem is flickering caused by the discontinuity between adjacent image frames. Several postprocessing algorithms have been proposed to reduce that effect after transformation. We propose a recursive cGAN in which the previous output frame is used as an input in addition to the current input frame to reduce the flickering effect without losing the objective quality of each image. Compared with previous postprocessing algorithms, our approach performed better in terms of various evaluation metrics for video contents.","2169-3536","","10.1109/ACCESS.2019.2906472","Korea Electric Power Corporation(grant numbers:R18XA02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673567","Image-to-image transformation;generative adversarial network;reducing flicker;video transformation","Generative adversarial networks;Image sequences;Gallium nitride;Histograms;Image resolution;Task analysis;Data models","image denoising;image resolution;image restoration;image sequences;neural nets;video signal processing","video transformation;super-resolution;image denoising;image inpainting;video contents;cGAN-based transformation;adjacent image frames;recursive cGAN;flickering effect;recursive conditional generative adversarial networks;postprocessing algorithms","","4","","40","OAPA","25 Mar 2019","","","IEEE","IEEE Journals"
"AI in Photography: Scrutinizing Implementation of Super-Resolution Techniques in Photo-Editors","N. Fatima","Department of Computer Science, Aligarh Muslim University, Aligarh, India","2020 35th International Conference on Image and Vision Computing New Zealand (IVCNZ)","17 Dec 2020","2020","","","1","6","Judging the quality of a photograph from the perspective of a photographer we can ascertain resolution, symmetry, content, location, etc. as some of the factors that influence the proficiency of a photograph. The exponential growth in the allurement for photography impels us to discover ways to perfect an input image in terms of the aforesaid parameters. Where content and location are the immutable ones, attributes like symmetry and resolution can be worked upon. In this paper, I prioritized resolution as our cynosure and there can be multiple ways to refine it. Image super-resolution is progressively becoming a prerequisite in the fraternity of computer graphics, computer vision, and image processing. It's the process of obtaining high-resolution images from their low-resolution counterparts. In my work, image super-resolution techniques like Interpolation, SRCNN (Super-Resolution Convolutional Neural Network), SRResNet (Super Resolution Residual Network), and GANs (Generative Adversarial Networks: Super-Resolution GAN-SRGAN and Conditional GAN-CGAN) were studied experimentally for post-enhancement of images in photography as employed by photo-editors, establishing the most coherent approach for attaining optimized super-resolution in terms of quality.","2151-2205","978-1-7281-8579-8","10.1109/IVCNZ51579.2020.9290737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9290737","interpolation;image processing;computer vision;super-resolution;gan","Photography;Training;Interpolation;Computer vision;Generative adversarial networks;Convolutional neural networks;Residual neural networks","computer vision;convolution;convolutional neural nets;image resolution;interpolation;photography","photo-editors;optimized super-resolution;photography;photographer;exponential growth;computer graphics;computer vision;image processing;high-resolution images;low-resolution counterparts;image super-resolution techniques;super-resolution convolutional neural network;super-resolution GAN-SRGAN;super resolution residual network","","2","","17","IEEE","17 Dec 2020","","","IEEE","IEEE Conferences"
"Terahertz Image Super-Resolution Reconstruction Using Unpaired Real-World Images","H. An; L. He; Z. Hou; D. Lai","School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","2022 3rd International Conference on Pattern Recognition and Machine Learning (PRML)","13 Sep 2022","2022","","","193","198","Terahertz imaging technology has been widely used in applications of security detection, defect detection and biomedicine. The in- sufficient resolution is still the main defect of this technology so far. The use of deep neural network for super-resolution reconstruction of image is a mainstream enhancement of resolution methods. Aiming at solving the shortcomings of existing methods to obtaining training sets and the design of networks, this paper proposes to use real- world terahertz images as low-resolution images and real-world optical images as ground truth to organize unpaired training sets, also a cycle adversarial super-resolution network is designed for the characteristics of unpaired training sets and different picture styles. In this paper we trained the network using training sets organized with the terahertz images which was collected through the Internet, and the images suitable for training in the Office-Home Datasets. The obtained results with real terahertz images shown that through the proposed network the resolution of terahertz images improved, which proves the feasibility of this network.","","978-1-6654-9950-7","10.1109/PRML56267.2022.9882221","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9882221","Terahertz imaging;super-resolution reconstruction;image degradation;deep neural networks;cycle generative adversarial networks","Training;Deep learning;Terahertz wave imaging;Biomedical optical imaging;Superresolution;Neural networks;Optical computing","image enhancement;image reconstruction;image resolution;learning (artificial intelligence);microwave photonics;neural nets;terahertz wave imaging","terahertz image super-resolution reconstruction;terahertz imaging;security detection;biomedicine;deep neural network;low-resolution images;real-world optical images;unpaired training sets;cycle adversarial super-resolution network;real-world terahertz images","","","","24","IEEE","13 Sep 2022","","","IEEE","IEEE Conferences"
"Image Super-Resolution With Self-Similarity Prior Guided Network and Sample-Discriminating Learning","Y. Hu; J. Li; Y. Huang; X. Gao","School of Medical Engineering and Technology, Xinjiang Medical University, Urumqi, China; Video and Image Processing System Laboratory, School of Electronic Engineering, Xidian University, Xi’an, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Transactions on Circuits and Systems for Video Technology","4 Apr 2022","2022","32","4","1966","1985","The nonlocal self-similarity in natural image provides an effective prior for single image super-resolution (SISR), which is beneficial to contextual information capture and performance improvement, as demonstrated by conventional SISR methods. However, it is little explored to utilize this property in deep neural networks. In this paper, we propose a self-similarity prior guided (SSPG) network to incorporate self-similarity-based nonlocal operation into deep neural network for SISR. Specifically, we design a cross-scale nearest-neighbor residual (CSNNR) block via introducing cross-scale  $k$ -nearest neighbors (KNN) matching into a residual block, which can be flexibly integrated into deep networks to capture long-range correlations among multi-scale and multi-level features. Meanwhile, by stacking a CSNNR block and a sequence of wide-activated residual blocks with a local skip-connection, a multi-level residual self-similarity (MRSS) module is developed to effectively employ local and nonlocal information for detail recovery. Thus, through cascading multiple MRSS modules, the proposed SSPG network performs both self-similarity-based nonlocal operation and convolution-based local operation on multi-level features to reconstruct informative features for accurate SISR. In addition, for pursuing visually pleasing results, we apply our SSPG network to the perception-oriented SISR field by following the framework of generative adversarial networks. In particular, we explore a sample-discriminating learning mechanism based on the statistical descriptions of training samples, and include it in optimization procedure to automatically tune the contributions of different samples according to their characteristics and then focus the network on creating realistic results. Extensive quantitative and qualitative evaluations on benchmark datasets illustrate the superiority of our proposed models over the state-of-the-art methods for both distortion-oriented and perception-oriented image super-resolution tasks.","1558-2205","","10.1109/TCSVT.2021.3093483","Natural Science Foundation of Xinjiang Uygur Autonomous Region(grant numbers:2020D01C157); National Natural Science Foundation of China(grant numbers:62036007,61772402,62050175,62061047); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9467283","Nonlocal self-similarity prior;sample-discriminating learning;k-nearest neighbors;single image super-resolution","Feature extraction;Superresolution;Image reconstruction;Training;Optimization;Generative adversarial networks;Spatial resolution","convolutional neural nets;deep learning (artificial intelligence);feature extraction;image denoising;image reconstruction;image representation;image resolution;image texture;nearest neighbour methods","self-similarity prior guided network;nonlocal self-similarity;natural image;image super-resolution;contextual information capture;performance improvement;SISR methods;deep neural network;self-similarity-based nonlocal operation;cross-scale nearest-neighbor residual;k-nearest neighbors;residual block;deep networks;multilevel features;CSNNR block;wide-activated residual blocks;local skip-connection;multilevel residual self-similarity module;local information;nonlocal information;multiple MRSS modules;SSPG network;convolution-based local operation;informative features;perception-oriented SISR field;generative adversarial networks;perception-oriented image super-resolution tasks;sample-discriminating learning","","6","","66","IEEE","29 Jun 2021","","","IEEE","IEEE Journals"
"Fine Perceptive GANs for Brain MR Image Super-Resolution in Wavelet Domain","S. You; B. Lei; S. Wang; C. K. Chui; A. C. Cheung; Y. Liu; M. Gan; G. Wu; Y. Shen","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China, and also with the University of Chinese Academy of Sciences, Beijing 100864, China.; School of Biomedical Engineering, Shenzhen University, Shenzhen 518060, China.; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China.; Department of Mathematics, Hong Kong Baptist University, Hong Kong, and also with the Department of Statistics, Stanford University, Stanford, CA 94305 USA.; Department of Mechanical and Aerospace Engineering, The Hong Kong University of Science and Technology, Hong Kong.; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing 100872, China.; College of Mathematics and Computer Science, Fuzhou University, Fuzhou 350108, China.; Data Recovery Key Laboratory of Sichuan Province, College of Mathematics and Information Science, Neijiang Normal University, Neijiang 641100, China.; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China.","IEEE Transactions on Neural Networks and Learning Systems","","2022","PP","99","1","13","Magnetic resonance (MR) imaging plays an important role in clinical and brain exploration. However, limited by factors such as imaging hardware, scanning time, and cost, it is challenging to acquire high-resolution MR images clinically. In this article, fine perceptive generative adversarial networks (FP-GANs) are proposed to produce super-resolution (SR) MR images from the low-resolution counterparts. By adopting the divide-and-conquer scheme, FP-GANs are designed to deal with the low-frequency (LF) and high-frequency (HF) components of MR images separately and parallelly. Specifically, FP-GANs first decompose an MR image into LF global approximation and HF anatomical texture subbands in the wavelet domain. Then, each subband generative adversarial network (GAN) simultaneously concentrates on super-resolving the corresponding subband image. In generator, multiple residual-in-residual dense blocks are introduced for better feature extraction. In addition, the texture-enhancing module is designed to trade off the weight between global topology and detailed textures. Finally, the reconstruction of the whole image is considered by integrating inverse discrete wavelet transformation in FP-GANs. Comprehensive experiments on the MultiRes_7T and ADNI datasets demonstrate that the proposed model achieves finer structure recovery and outperforms the competing methods quantitatively and qualitatively. Moreover, FP-GANs further show the value by applying the SR results in classification tasks.","2162-2388","","10.1109/TNNLS.2022.3153088","Strategic Priority Research Program of Chinese Academy of Sciences(grant numbers:XDB38040200); National Natural Science Foundations of China(grant numbers:62172403,61872351); International Science and Technology Cooperation Projects of Guangdong(grant numbers:2019A050510030); Distinguished Young Scholars Fund of Guangdong(grant numbers:2021B1515020019); Excellent Young Scholars of Shenzhen(grant numbers:RCYX20200714114641211); Shenzhen Key Basic Research Projects(grant numbers:JCYJ20200109115641762); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729556","Discrete wavelet transformation;generative adversarial network (GAN);magnetic resonance (MR) imaging;super-resolution (SR);textures enhance.","Wavelet domain;Magnetic resonance imaging;Generative adversarial networks;Task analysis;Image reconstruction;Hafnium;Discrete wavelet transforms","","","","","","","IEEE","7 Mar 2022","","","IEEE","IEEE Early Access Articles"
"Terahertz Image Super-Resolution Reconstruction of Passive Safety Inspection Based on Generative Adversarial Network","W. Yibin; Z. Rongyue; X. Hong; W. Hao; Y. Pan; Y. Zhou","College of Computer, Guangdong University of Technology, Guangzhou, China; College of Computer, Guangdong University of Technology, Guangzhou, China; College of Computer, Guangdong University of Technology, Guangzhou, China; College of Computer, Norwegian University of Science and Technology, Norway; College of Computer, Guangdong University of Technology, Guangzhou, China; College of Computer, Guangdong University of Technology, Guangzhou, China","2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)","21 Oct 2019","2019","","","22","27","When passive terahertz imaging technology is used in Safety inspection, it has low image resolution and is susceptible to environment. As a result, it is difficult to support the demand for high-resolution terahertz images in related projects. This paper proposes a passive terahertz image reconstruction method based on improved Generative Adversarial Networks, and compares it with other existing methods. Experimental results show that the improved SRGAN method has higher peak signal-to-noise ratio (PSNR) and structural similarity (SSIM).","","978-1-7281-2980-8","10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8875391","passive terahertz image, image super-resolution reconstruction, (GAN) Generative Adversarial Networks","Image reconstruction;Convolution;Imaging;PSNR;Training","automatic optical inspection;image reconstruction;image resolution;neural nets;terahertz wave imaging","terahertz image super-resolution reconstruction;passive safety inspection;generative adversarial network;passive terahertz imaging technology;low image resolution;high-resolution terahertz images;passive terahertz image reconstruction method;SRGAN method","","4","","21","IEEE","21 Oct 2019","","","IEEE","IEEE Conferences"
"Perceptual Quality Preserving Image Super-resolution via Channel Attention","W. -Y. Lee; P. -Y. Chuang; Y. -C. F. Wang","MOXA Lab, MOXA Inc., Taipei, Taiwan; MOXA Lab, MOXA Inc., Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","1737","1741","Generative Adversarial Network (GAN) has been widely applied on Single Image Super-Resolution (SISR) problems. However, there can be quite a variability in the results from the GAN-based methods. In some cases, the GAN-based methods might cause structure distortion, which can be easily distinguished by human beings, especially for artificial structures, because the methods only focus on the perceptual quality of the whole image. On the other hand, PSNR-oriented methods can prevent structure distortion but with overly smoothed context. To overcome these problems, we propose a deep neural net refiner for SISR methods, not only improving perceptual quality but also preserving context structures. In the experiments, our model qualitatively and quantitatively performs favorably against the state-of-the-art SISR methods.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683507","Super-Resolution;Channel Attention;Generative Adversarial Networks","","image resolution;neural nets","channel attention;GAN-based methods;structure distortion;artificial structures;PSNR-oriented methods;single image super-resolution problems;SISR methods;perceptual quality preserving image super-resolution;generative adversarial network","","4","","20","IEEE","17 Apr 2019","","","IEEE","IEEE Conferences"
"D-SRCAGAN : DEM Super-resolution Generative Adversarial Network","X. Deng; W. Hua; X. Liu; S. Chen; W. Zhang; J. Duan","School of Geography and Information Engineering, China University of Geosciences (Wuhan), Wuhan, China; School of Geography and Information Engineering, China University of Geosciences (Wuhan), Wuhan, China; School of Geography and Information Engineering, China University of Geosciences (Wuhan), Wuhan, China; School of Geography and Information Engineering, China University of Geosciences (Wuhan), Wuhan, China; School of Geography and Information Engineering, China University of Geosciences (Wuhan), Wuhan, China; School of Geography and Information Engineering, China University of Geosciences (Wuhan), Wuhan, China","IEEE Geoscience and Remote Sensing Letters","","2022","PP","99","1","1","High-resolution digital elevation models (DEMs) are widely used in many fields such as mapping, hydrology, meteorology and geology, where they can improve the accuracy and reliability of many geographic analysis applications as an input. However, due to the high cost and difficulty of acquiring high-resolution DEMs, as well as the problems of edge smoothing, data distortion and fractures in reconstructed ground surfaces with traditional super-resolution DEM reconstruction techniques. Inspired by the excellence of generative adversarial neural networks in super-resolution image analysis, this paper investigates an approach for DEM super-resolution reconstruction with deep residual generative adversarial network. An advanced DEM Super-resolution Generative Adversarial Network (D-SRCAGAN) is proposed in this paper, which can reconstruct a quadruple higher resolution DEM by using low-resolution DEM. Compared with the bicubic and SRGAN methods, the D-SRCAGAN method reconstruction results can retain more topographic features and obtain higher RMSE values.","1558-0571","","10.1109/LGRS.2022.3224296","National Key Research and Development Project(grant numbers:2019YFC0605102); National Natural Science Foundation of China(grant numbers:NSFC 41972307); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9961205","Digital elevation model (DEM);Super-resolution reconstruction;Improved super-resolution generative adversarial network (D-SRCAGAN);Attention mechanism","Image reconstruction;Superresolution;Training;Convolution;Image resolution;Generative adversarial networks;Generators","","","","","","","IEEE","23 Nov 2022","","","IEEE","IEEE Early Access Articles"
"ProfileSR-GAN: A GAN Based Super-Resolution Method for Generating High-Resolution Load Profiles","L. Song; Y. Li; N. Lu","Electrical and Computer Engineering Department, Future Renewable Energy Delivery and Management Systems Center, North Carolina State University, Raleigh, NC, USA; Electrical and Computer Engineering Department, Future Renewable Energy Delivery and Management Systems Center, North Carolina State University, Raleigh, NC, USA; Electrical and Computer Engineering Department, Future Renewable Energy Delivery and Management Systems Center, North Carolina State University, Raleigh, NC, USA","IEEE Transactions on Smart Grid","21 Jun 2022","2022","13","4","3278","3289","This paper presents a novel two-stage load profile super-resolution (LPSR) framework, ProfileSR-GAN, to upsample the low-resolution load profiles (LRLPs) to high-resolution load profiles (HRLPs). The LPSR problem is formulated as a Maximum-a-Posteriori problem. In the first-stage, a GAN-based model is adopted to restore high-frequency components from the LRLPs. To reflect the load-weather dependency, aside from the LRLPs, the weather data is added as an input to the GAN-based model. In the second-stage, a polishing network guided by outline loss and switching loss is novelly introduced to remove the unrealistic power fluctuations in the generated HRLPs and improve the point-to-point matching accuracy. To evaluate the realisticness of the generated HRLPs, a new set of load shape evaluation metrics is developed. Simulation results show that: i) ProfileSR-GAN outperforms the state-of-the-art methods in all shape-based metrics and can achieve comparable performance with those methods in point-to-point matching accuracy, and ii) after applying ProfileSR-GAN to convert LRLPs to HRLPs, the performance of a downstream task, non-intrusive load monitoring, can be significantly improved. This demonstrates that ProfileSR-GAN is an effective new mechanism for restoring high-frequency components in downsampled time-series data sets and improves the performance of downstream tasks that require HR load profiles as inputs.","1949-3061","","10.1109/TSG.2022.3158235","U.S. Department of Energy’s Office of Energy Efficiency and Renewable Energy (EERE) through the Solar Energy Technologies Office(grant numbers:DE-EE0008770); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9731506","Generative adversarial networks;load profile generation;machine learning;non-intrusive load monitoring;super-resolution;synthetic data","Generative adversarial networks;Superresolution;Load modeling;Generators;Meteorology;Fluctuations;Data models","image matching;image resolution;load forecasting;time series","ProfileSR-GAN;GAN based super-resolution method;generating high-resolution load profiles;two-stage load profile super-resolution framework;low-resolution load profiles;LRLPs;LPSR problem;Maximum-a-Posteriori problem;GAN-based model;high-frequency components;load-weather dependency;outline loss;switching loss;generated HRLPs;point-to-point matching accuracy;load shape evaluation metrics;shape-based metrics;nonintrusive load monitoring;HR load profiles","","1","","40","IEEE","9 Mar 2022","","","IEEE","IEEE Journals"
"HFD-SRGAN: Super-Resolution Generative Adversarial Network with High-frequency discriminator","J. -H. Huang; H. -K. Wang; Z. -W. Liao","Laboratory of image and pattern recognition, School of computer science and technology, Sichuan Normal University, China; Laboratory of image and pattern recognition, School of computer science and technology, Sichuan Normal University, China; Laboratory of image and pattern recognition, School of computer science and technology, Sichuan Normal University, China","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","14 Dec 2020","2020","","","3148","3153","The high-frequencies of images is very important both in keeping the edges and suppressing artifacts. To improve the performance of single image super-resolution (SISR) based on the SRGAN framework, we propose Super-Resolution Generative Adversarial Networks with high-frequency discriminator (HFD- SRGAN) by designing an additional discriminator for image's high-frequencies extracted by wavelets. Based on SRGAN, the image's high frequencies extracted by discrete wavelet transformations (DWT) were then introduced into GAN. Moreover, an additional discriminator for these high frequencies was built. Since the proposed model provides a direct and efficient way to locates and estimates the high frequencies of the reconstruction image, the visual effects of reconstructed the images can be improved with fewer computation costs. Experiments show that HFD-SRGAN has improved the visual effects of SRGAN when using the same generator network as SRGAN. The evaluation results show the performance of our method is equal to the state-of-the-art methods.","2577-1655","978-1-7281-8526-2","10.1109/SMC42975.2020.9282980","Giant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282980","","Image edge detection;Generative adversarial networks;Visual effects;Generators;Discrete wavelet transforms;High frequency;Image reconstruction","discrete wavelet transforms;image reconstruction;image resolution;neural nets","HFD-SRGAN;super-resolution generative adversarial network;high-frequency discriminator;single image super-resolution;discrete wavelet transformations;image reconstruction","","1","","48","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"Generative Adversarial Networks and Perceptual Losses for Video Super-Resolution","A. Lucas; S. López-Tapia; R. Molina; A. K. Katsaggelos","Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA; Computer Science and Artificial Intelligence Department, Universidad de Granada, Granada, Spain; Computer Science and Artificial Intelligence Department, Universidad de Granada, Granada, Spain; Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, USA","IEEE Transactions on Image Processing","15 May 2019","2019","28","7","3312","3327","Video super-resolution (VSR) has become one of the most critical problems in video processing. In the deep learning literature, recent works have shown the benefits of using adversarial-based and perceptual losses to improve the performance on various image restoration tasks; however, these have yet to be applied for video super-resolution. In this paper, we propose a generative adversarial network (GAN)-based formulation for VSR. We introduce a new generator network optimized for the VSR problem, named VSRResNet, along with new discriminator architecture to properly guide VSRResNet during the GAN training. We further enhance our VSR GAN formulation with two regularizers, a distance loss in feature-space and pixel-space, to obtain our final VSRResFeatGAN model. We show that pre-training our generator with the mean-squared-error loss only quantitatively surpasses the current state-of-the-art VSR models. Finally, we employ the PercepDist metric to compare the state-of-the-art VSR models. We show that this metric more accurately evaluates the perceptual quality of SR solutions obtained from neural networks, compared with the commonly used PSNR/SSIM metrics. Finally, we show that our proposed model, the VSRResFeatGAN model, outperforms the current state-of-the-art SR models, both quantitatively and qualitatively.","1941-0042","","10.1109/TIP.2019.2895768","Sony 2016 Research Award Program Research Project; National Science Foundation(grant numbers:DGE-1450006); Ministerio de Economía y Competitividad(grant numbers:DPI2016-77869-C2-2-R); Visiting Scholar Program at the University of Granada; Spanish FPU Program; Ministerio de Economía y Competitividad(grant numbers:DPI2016-77869-C2-2-R); Visiting Scholar Program at the University of Granada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629024","Artificial neural networks;video signal processing;image resolution;image generation","Neural networks;Training;Spatial resolution;Generators;Gallium nitride;Task analysis","image resolution;image restoration;learning (artificial intelligence);mean square error methods;neural nets;video signal processing","generative adversarial networks;perceptual losses;video super-resolution;video processing;generative adversarial network-based formulation;VSR GAN formulation;distance loss;mean-squared-error loss;deep learning literature;image restoration;VSRResNet;feature-space;pixel-space;VSRResFeatGAN model;neural networks;PSNR-SSIM metrics","","72","","30","IEEE","29 Jan 2019","","","IEEE","IEEE Journals"
"Analysis of Single Image Super Resolution Models","M. Köprülü; M. T. Eskil","Computer Engineering, Iştanbul Isik University, Istanbul, Türkiye; Computer Engineering, Iştanbul Isik University, Istanbul, Türkiye","2022 International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)","30 Dec 2022","2022","","","1","6","Image Super-Resolution (SR) is a set of image processing techniques which improve the resolution of images and videos. Deep learning approaches have made remarkable improvement in image super-resolution in recent years. This article aims and seeks to provide a comprehensive analysis on recent advances of models which has been used in image super-resolution. This study has been investigated over other essential topics of current model problems, such as publicly accessible benchmark data-sets and performance evaluation measures. Finally, The study concluded these analysis by highlighting several weaknesses of existing base models as their feeding strategy and approved that the training technique which is Blind Feeding, which led several model to achieve state-of-the art.","","978-1-6654-7095-7","10.1109/ICECCME55909.2022.9988599","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9988599","Single Image Super Resolution;Generative Adversarial Networks;Convolutional Neural Network;Image Processing","Training;Performance evaluation;Deep learning;Analytical models;Mechatronics;Computational modeling;Current measurement","deep learning (artificial intelligence);image resolution","blind feeding;deep learning approaches;image processing techniques;single image super resolution models","","","","13","IEEE","30 Dec 2022","","","IEEE","IEEE Conferences"
"Remote Sensing Image Super-Resolution via Saliency-Guided Feedback GANs","H. Wu; L. Zhang; J. Ma","School of Artificial Intelligence, BNU, Beijing, China; School of Artificial Intelligence, BNU, Beijing, China; School of Artificial Intelligence, BNU, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","2 Dec 2021","2022","60","","1","16","In remote sensing images (RSIs), the visual characteristics of different regions are versatile, which poses a considerable challenge to single image super-resolution (SISR). Most existing SISR methods for RSIs ignore the diverse reconstruction needs of different regions and thus face a serious contradiction between high perception quality and less spatial distortion. The mean square error (MSE) optimization-based methods produce results of unsatisfactory visual quality, while generative adversarial networks (GANs) can produce photo-realistic but severely distorted results caused by pseudotextures. In addition, increasingly deeper networks, although providing powerful feature representations, also face problems of overfitting and occupying too much storage space. In this article, we propose a new saliency-guided feedback GAN (SG-FBGAN) to address these problems. The proposed SG-FBGAN applies different reconstruction principles for areas with varying levels of saliency and uses feedback (FB) connections to improve the expressivity of the network while reducing parameters. First, we propose a saliency-guided FB generator with our carefully designed paired-feedback block (PFBB). The PFBB uses two branches, a salient and a nonsalient branch, to handle the FB information and generate powerful high-level representations for salient and nonsalient areas, respectively. Then, we measure the visual perception quality of salient areas, nonsalient areas, and the global image with a saliency-guided multidiscriminator, which can dramatically eliminate pseudotextures. Finally, we introduce a curriculum learning strategy to enable the proposed SG-FBGAN to handle complex degradation models. Comprehensive evaluations and ablation studies validate the effectiveness of our proposal.","1558-0644","","10.1109/TGRS.2020.3042515","Beijing Natural Science Foundation(grant numbers:L182029); National Natural Science Foundation of China(grant numbers:61571050,41771407); Beijing Normal University (BNU) Interdisciplinary Research Foundation for the First-Year Doctoral Candidates(grant numbers:BNUXKJC1926); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9301233","Deep learning (DL);generative adversarial network (GAN);remote sensing;saliency detection;super-resolution (SR)","Visualization;Image reconstruction;Generative adversarial networks;Distortion;Gallium nitride;Sensors;Optimization","geophysical image processing;image classification;image reconstruction;image resolution;image texture;learning (artificial intelligence);mean square error methods;remote sensing","SG-FBGAN;feedback connections;saliency-guided FB generator;paired-feedback block;PFBB;nonsalient branch;FB information;high-level representations;nonsalient areas;visual perception quality;global image;saliency-guided multidiscriminator;pseudotextures;remote sensing image super-resolution;RSI;visual characteristics;single image super-resolution;SISR methods;high perception quality;spatial distortion;mean square error optimization-based methods;generative adversarial networks;feature representations;storage space;saliency-guided feedback GAN","","10","","62","IEEE","21 Dec 2020","","","IEEE","IEEE Journals"
"Real-World Image Super-Resolution Via Kernel Augmentation And Stochastic Variation","H. Zhang; Y. Zhu; J. Sun; Y. Zhang","School of Computer Science, Northwestern Polytechnical University, Xi’an, P.R. China; School of Computer Science, Northwestern Polytechnical University, Xi’an, P.R. China; School of Astronautics, Northwestern Polytechnical University, Xi’an, P.R. China; School of Computer Science, Northwestern Polytechnical University, Xi’an, P.R. China","2022 IEEE International Conference on Image Processing (ICIP)","18 Oct 2022","2022","","","2506","2510","Deep learning (DL) based single image super-resolution (SISR) algorithms have now achieved highly satisfactory evaluation and visualization results on synthetic datasets. However, in some practical applications, especially when restoring some real-world low-resolution (LR) photos, the limitation and unicity of the most commonly used bicubic down-sampling kernel often lead to significant performance degradation of models trained under ideal conditions. Thus, we first propose a kernel augmentation (KA) strategy based on generative adversarial networks (GANs) to improve the generalization ability and robustness of current SISR models. Then, we intend to reconstruct the stochastic variation (SV) features that are widely present in natural images to obtain a more realistic feature representation. In the end, extensive experiments demonstrate the feasibility and effectiveness of our approach in dealing with real-world SISR problems.","2381-8549","978-1-6654-9620-9","10.1109/ICIP46576.2022.9897540","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9897540","Deep learning (DL);single image super-resolution (SISR);real-world, kernel augmentation (KA);stochastic variation (SV)","Deep learning;Degradation;Visualization;Superresolution;Stochastic processes;Generative adversarial networks;Robustness","","","","","","33","IEEE","18 Oct 2022","","","IEEE","IEEE Conferences"
"Image-based Super Resolution of Underwater Sonar Images using Generative Adversarial Network","M. Sung; J. Kim; S. -C. Yu","Department of Creative IT Engineeringline, Pohang University of Science and Technology(POSTECH), Pohang, Republic of Korea; Department of Creative IT Engineeringline, Pohang University of Science and Technology(POSTECH), Pohang, Republic of Korea; Department of Creative IT Engineeringline, Pohang University of Science and Technology(POSTECH), Pohang, Republic of Korea","TENCON 2018 - 2018 IEEE Region 10 Conference","24 Feb 2019","2018","","","0457","0461","Sonar sensors are widely used for underwater observations because they can be used in a turbid stream and have a long operating range. However, images taken with sonar sensors are difficult to identify because of low resolution. In this paper, we proposed a method based on a generative adversarial network to increase the resolution of the underwater sonar image. We built the network of 16 residual blocks and eight convolutional layers. We then trained it with sonar images cropped in several ways. As a result, we could improve the resolution of sonar images from various scenes and recorded a higher peak signal-to-noise ratio than interpolation. The proposed method could help to identify the underwater object without losing the working range of sonar.","2159-3450","978-1-5386-5457-6","10.1109/TENCON.2018.8650176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8650176","acoustic lens-based multi-beam sonar;sonar image enhancement;single image super resolution","Sonar;Image resolution;Training;Sensors;Generative adversarial networks;Gallium nitride;Image sensors","convolutional neural nets;geophysical image processing;image resolution;sonar detection;sonar imaging;underwater sound","generative adversarial network;underwater sonar image;underwater object;super resolution;sonar sensors;underwater observations;long operating range;peak signal-to-noise ratio","","6","","11","IEEE","24 Feb 2019","","","IEEE","IEEE Conferences"
"Image Super Resolution Using Deep Learning","N. P. L. Le; H. N. Do; V. T. D. Huynh; L. Mai","School of Electrical Engineering, International University, Vietnam; School of Electrical Engineering, International University, Vietnam; School of Electrical Engineering, International University, Vietnam; School of Electrical Engineering, International University, Vietnam","2022 IEEE Ninth International Conference on Communications and Electronics (ICCE)","16 Aug 2022","2022","","","369","374","Image upscaling has been applied in many applications in the image processing field. This paper shows a model which is able to perform image upscaling by 4 times using a series of convolutional filters and trained using the generative adversarial network (GAN) training scheme. The GAN training process involves a generator network, which will perform the image upscaling. The results of the generator network will be evaluated by a discriminator network for the realistic score which will be feedback to the generator network for training. The chosen GAN type is the GAN with a relativistic discriminator which calculates how realistic is the generated image compared to the real image. The network also utilizes different structures of dilated convolution filter, inception module and residue connection between the filters to enhance the feature extraction capability. The high-definition image dataset DIV2K is used for the training.","","978-1-6654-9745-9","10.1109/ICCE55644.2022.9852096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9852096","Deep learning;Image processing;Image Super Resolution.","Training;Deep learning;Interpolation;Image resolution;Computational modeling;Generative adversarial networks;Feature extraction","convolutional neural nets;deep learning (artificial intelligence);feature extraction;image resolution","image super resolution;image upscaling;image processing field;generative adversarial network training scheme;GAN training process;generator network;discriminator network;dilated convolution filter;high-definition image dataset;DIV2K dataset;relativistic discriminator;inception module","","","","22","IEEE","16 Aug 2022","","","IEEE","IEEE Conferences"
"Single Image Super Resolution using Residual Learning","W. -S. Jeon; S. -Y. Rhee","Dept. IT Convergence Engineering, Kyungnam University, Changwon, Kyungnam, Korea; Dept. Computer Engineering, Kyungnam University, Changwon, Kyungnam, Korea","2019 International Conference on Fuzzy Theory and Its Applications (iFUZZY)","16 Apr 2020","2019","","","1","4","The Resnet model is similar to the ensemble, and its performance and parameters can be considered according to the modular design. Currently, Resnet is widely used as a backbone network. In particular, the Resnet module that compensates the weight can consider the similarity of pixels. Therefore, in this paper, we propose a method to increase the similarity between pixels by performing the operation of the Resnet module which has an effect similar to the ensemble operation. It give us a better high resolution image.","2377-5831","978-1-7281-0840-7","10.1109/iFUZZY46984.2019.9066214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9066214","Single Image Super resolution;pixel wise conv;GAN;Residual Learning;CNN","Image resolution;Image restoration;Signal resolution;Gallium nitride;Conferences;Generative adversarial networks;Computer vision","convolutional neural nets;image resolution","modular design;Resnet model;residual learning;single image super resolution;high resolution image;ensemble operation;Resnet module","","","","9","IEEE","16 Apr 2020","","","IEEE","IEEE Conferences"
"Single image super resolution using deep convolutional generative neural networks","C. G. Turhan; H. S. Bılge","Gazi Universitesi, Ankara, Ankara, TR; Gazi Universitesi, Ankara, Ankara, TR","2018 26th Signal Processing and Communications Applications Conference (SIU)","9 Jul 2018","2018","","","1","4","Nowadays, deep convolutional networks have been focused on single image super-resolution problem due to their impressive performance on generating high-resolution images like as other computer vision tasks. It is clearly seen that among best known super-resolution models deep learning-based methods give the-state-of-the-art results. In this study, FSRGAN, based on a popular deep convolutional network (FSRCNN) due to its efficiency in spite of its simple architecture, is presented with generative adversarial training approach combining a discriminative network to the generator. The performance of the presented model is demonstrated by comparing to its baseline model, which is used as a generative network of our FSRGAN, the interpolation methods on well-known data sets based on PSNR metric.","","978-1-5386-1501-0","10.1109/SIU.2018.8404829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8404829","single image super resolution;convolutional neural networks;generative adversarial networks;discriminative networks","Image resolution;Computer vision;Conferences;Gallium nitride;Computational modeling;Training;Data models","computer vision;convolution;feedforward neural nets;image resolution;interpolation;learning (artificial intelligence)","single image super-resolution problem;computer vision tasks;learning-based methods;FSRGAN;generative adversarial training approach;discriminative network;deep convolutional generative neural networks;interpolation methods;PSNR metric","","1","","","IEEE","9 Jul 2018","","","IEEE","IEEE Conferences"
"Deep Objective Quality Assessment Driven Single Image Super-Resolution","B. Yan; B. Bare; C. Ma; K. Li; W. Tan","Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China; Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China; Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China; Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China; Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China","IEEE Transactions on Multimedia","24 Oct 2019","2019","21","11","2957","2971","Single-image super-resolution (SISR) is a classic problem in the image processing community, which aims at generating a high-resolution image from a low-resolution one. In recent years, deep learning based SISR methods emerged and achieved a performance leap than previous methods. However, because the evaluation metrics of SISR methods is peak signal-to-noise ratio (PSNR), previous methods usually choose L2-norm as the loss function. This leads to a significant improvement in the final PSNR value but little improvement in perceptual quality. In this paper, in order to achieve better results in both perceptual quality and PSNR values, we propose an objective quality assessment driven SISR method. First, we propose a novel full-reference image quality assessment approach for SISR and employ it as a loss function, namely super-resolution image quality assessment (SR-IQA) loss. Then, we combine SR-IQA loss with L2-norm to guide our proposed SISR method to achieve better results. Besides that, our proposed SISR method consists of several proposed highway units. Furthermore, in order to verify the generalization ability of our new kind of loss function, we integrate SR-IQA loss to generative adversarial networks based SR method and achieve better perceptual quality. Experimental results prove that our proposed SISR method achieves better performance than other methods both qualitatively and quantitatively in most of the cases.","1941-0077","","10.1109/TMM.2019.2914883","National Natural Science Foundation of China(grant numbers:61772137); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8705363","Single image super-resolution;full-reference quality assessment;generative adversarial networks;image enhancement","Feature extraction;Image resolution;Image quality;Quality assessment;Signal resolution;Deep learning;Measurement","image resolution;learning (artificial intelligence);neural nets","objective quality assessment driven single image super-resolution;image processing community;loss function;full-reference image quality assessment approach;SR-IQA loss;peak signal-to-noise ratio;PSNR;super-resolution image quality assessment loss;generative adversarial networks based SR method;deep learning based SISR methods","","25","","90","IEEE","3 May 2019","","","IEEE","IEEE Journals"
"Unsupervised Blur Kernel Estimation and Correction for Blind Super-Resolution","Y. Kim; J. Ha; Y. Cho; J. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Division of Future Vehicle, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Division of Future Vehicle, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Access","3 May 2022","2022","10","","45179","45189","Blind super-resolution (blind-SR) is an important task in the field of computer vision and has various applications in real-world. Blur kernel estimation is the main element of blind-SR along with the adaptive SR networks and a more accurately estimated kernel guarantees a better performance. Recently, generative adversarial networks (GANs), comparing recurrence patches across scales, have been the most successful unsupervised kernel estimation methods. However, they still involve several problems. ① Their sharpness discrimination ability has been noted as being too weak, causing them to focus more on pattern shapes than sharpness. ② In some cases, kernel correction processes were omitted; however, these are essential because the optimally generated kernel may be narrower than a point spread function (PSF) except when the PSF is ideal low-pass filter. ③ Previous studies also did not consider that GANs are affected by the thickness of edges as well as PSF. Thus, in this paper, 1) we propose a degradation and ranking comparison process designed to induce GAN models to became sensitive to image sharpness, and 2) propose a scale-free kernel correction technique using Gaussian kernel approximation including a thickness parameter. To improve the kernel accuracy further, we 3) propose a combination model of the proposed GAN and DIP(deep image prior) for more supervision, and designed a kernel correction network to propagate gradients through developed correction method. Several experiments demonstrate that our methods enhanced the  $l_{2}$  error and the shape of the kernel significantly. In addition, by combining with ordinary blind-SR algorithms, the best reconstruction accuracy was achieved among unsupervised blur kernel estimation methods.","2169-3536","","10.1109/ACCESS.2022.3170053","Korea Government (MSIT) through the Institute of Information and Communications Technology Planning and Evaluation (IITP) Grant (Artificial Intelligence Innovation Hub)(grant numbers:2021-0-02068); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9762718","Blind super-resolution;kernel estimation;kernel correction;generative adversarial networks;deep image prior","Kernel;Generative adversarial networks;Estimation;Electronics packaging;Superresolution;Image edge detection;Degradation","computer vision;edge detection;Gaussian processes;image resolution;image restoration;neural nets;optical transfer function;unsupervised learning","blind super-resolution;computer vision;generative adversarial network;point spread function;PSF;ranking comparison process;GAN model;image sharpness;scale-free kernel correction technique;Gaussian kernel approximation;kernel accuracy;kernel correction network;unsupervised blur kernel estimation;blind-SR algorithm;adaptive SR network;sharpness discrimination;pattern shapes;thickness parameter;gradient propagation;deep image prior","","","","29","CCBY","25 Apr 2022","","","IEEE","IEEE Journals"
"Image Compression at Very Low Bitrate Based on Deep Learned Super-Resolution","S. Hamis; T. Zaharia; O. Rousseau","ARTEMIS Department, Télécom SudParis, UMR CNRS 5157 SAMOVAR, Evry, France; ARTEMIS Department, Télécom SudParis, UMR CNRS 5157 SAMOVAR, Evry, France; Be-Bound, Paris, France","2019 IEEE 23rd International Symposium on Consumer Technologies (ISCT)","14 Nov 2019","2019","","","128","133","The problem of data storage and transmission on mobile devices is constantly growing up. Smartphones are nearly by default equipped with HD cameras that are taking high quality pictures, which can be instantly stored and easily uploaded on cloud platforms. Such a behavior favors the creation of a massive amount of data. In order to reduce the size of such data, it is mandatory to dispose of efficient compression techniques that can take into account the actual usage of such image data. For example, most of the pictures acquired by phone cameras are often displayed on a small screen and this, for a little amount of time. A solution to manage this kind of oversized data would be to store them in a lower resolution, additionally to a standard image compression. The downside of such an approach is that restoring an image to its original resolution is a challenging task, notably in the presence of complex compression artifacts, such as those introduced by sophisticated compression methods. In order to deal with such an issue, in this paper we propose a new model, specifically trained to perform super-resolution after compression with the BPG state-of-the-art codec. An advantage of the proposed approach comes from the fact that the underlying process can be interpreted as a postprocessing step, which can be easily added to any compression scheme without modifying the codec. Experimental results show that our model perceptually outperforms the state-of-the-art compression standards even for very low bitrates.","2159-1423","978-1-7281-3570-0","10.1109/ISCE.2019.8901038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901038","super-resolution;very low bitrate compression;generative adversarial networks;BPG format","","cameras;data compression;image coding;image resolution;image restoration;learning (artificial intelligence)","low bitrate;data storage problem;mobile devices;smartphones;HD cameras;high quality pictures;cloud platforms;efficient compression techniques;image data;phone cameras;BPG state-of-the-art codec;image compression;deep learned super-resolution;data transmission problem;image restoration","","3","1","28","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Improvement of Image Super Resolution by Deep Neural Networks","A. Prasolov; S. Stirenko; Y. Gordienko","National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, Kyiv, Ukraine; National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, Kyiv, Ukraine; National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, Kyiv, Ukraine","IEEE EUROCON 2021 - 19th International Conference on Smart Technologies","15 Sep 2021","2021","","","140","145","The modern methods and architectures for image super resolution which are based on deep neural networks (DNNs) are considered. Several ways of their improvements were proposed and demonstrated. It was shown that the perception models built on MobileNet and EfficientNet families of DNNs turned out to be faster in training and have a better perception loss rate than previously used VGG family. In the more general context the usage of the smaller DNNs with the higher performance and lower size allow researchers to use and deploy them on devices with the limited computational resources for Edge Computing layer.","","978-1-6654-3299-3","10.1109/EUROCON52738.2021.9535575","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9535575","Convolutional neural networks (CNNs);Deep learning;Generative adversarial networks (GANs);High-resolution (HR);Low resolution (LR);Super-resolution (SR)","Deep learning;Training;Performance evaluation;Image resolution;Conferences;Computer architecture;Convolutional neural networks","deep learning (artificial intelligence);image resolution","image super resolution;deep neural networks;perception models;EfficientNet families;perception loss rate;VGG family;DNN;MobileNet;computational resources;edge computing layer","","1","","20","IEEE","15 Sep 2021","","","IEEE","IEEE Conferences"
"Unsupervised Remote Sensing Image Super-Resolution Method Based on Adaptive Domain Distance Measurement Network","Y. Hou; J. Zhang","Aerospace Information Research Institute, University of Chinese Academy of Sciences, Beijing, China; Aerospace Information Research Institute, University of Chinese Academy of Sciences, Beijing, China","2020 3rd International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)","2 Jul 2020","2020","","","256","259","Compared with supervised learning, unsupervised learning is more practical; however, the associated training process is more difficult and complex. To solve the problems of unstable training and insufficient diversity of generative adversarial networks (GAN), which are widely used to realize unsupervised learning, we propose a novel unsupervised remote sensing image super-resolution method based on a reverse generating network module and the adaptive domain distance measurement network. The discriminant network of GAN is considered as a tool to measure a certain image attribute instead of the original GAN binary classification network. Furthermore, the adaptive domain distance measurement network is used to back feed the information of a high-resolution image to guide the optimization of the generating network. The results of experiments performed on various datasets demonstrate the effectiveness of the proposed method.","","978-1-7281-8143-1","10.1109/AEMCSE50948.2020.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9131243","GAN;remote senseng;super resolution;domain","","geophysical image processing;image resolution;pattern classification;remote sensing;unsupervised learning","unsupervised remote sensing image super-resolution method;adaptive domain distance measurement network;supervised learning;unsupervised learning;generative adversarial networks;reverse generating network module;discriminant network;original GAN binary classification network;high-resolution image","","3","","15","IEEE","2 Jul 2020","","","IEEE","IEEE Conferences"
"Automatic Generation of High-Resolution Facial Expression Images with End-to-End Models Using Pix2Pix and Super-Resolution Convolutional Neural Network","T. Hanano; M. Seo; Y. -W. Chen","Graduate School of Information and Engineering, Ritsumeikan University, Shiga, Japan; Osaka Institute of Technology, Osaka, Japan; Graduate School of Information and Engineering, Ritsumeikan University, Shiga, Japan","2021 IEEE 10th Global Conference on Consumer Electronics (GCCE)","1 Dec 2021","2021","","","798","801","Recently, the means to see human face images have increased owing to the spread of smartphones and social networking services. Therefore, research on facial image generation, such as facial expression transformation, has been actively conducted. Especially, in the field of face images, the generation of face images using facial expression transformation has already been realized using generative adversarial networks (i.e., pix2pix). However, in the conventional models, only low-resolution images can be generated owing to limited computational resources, and the generated images are blur or aliasing. To solve this problem, we improved the resolution of generated images by training the Pix2Pix and super-resolution convolutional neural network methods as one model end-to-end instead of training them separately. Using the peak signal-to-noise ratio as an evaluation index, image quality was improved by 0.391 dB compared with the conventional model.","2378-8143","978-1-6654-3676-2","10.1109/GCCE53005.2021.9622042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622042","Generative Adversarial Nets;Image-to-Image Translation with Conditional Adversarial Networks;Super-Resolution Convolutional Neural Network;end-to-end","Training;PSNR;Social networking (online);Computational modeling;Superresolution;Neural networks;Convolutional neural networks","convolutional neural nets;face recognition;image resolution","automatic generation;high-resolution facial expression images;end-to-end models;pix2pix;human face images;social networking services;facial image generation;facial expression transformation;generative adversarial networks;low-resolution images;super-resolution convolutional neural network methods;image quality","","2","","7","IEEE","1 Dec 2021","","","IEEE","IEEE Conferences"
"Structure-Texture Parallel Embedding for Remote Sensing Image Super-Resolution","T. Lu; K. Zhao; Y. Wu; Z. Wang; Y. Zhang","Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology, Wuhan, China; Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology, Wuhan, China; Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, NERCMS, China; Computer School, Hubei University of Arts and Science, Xiangyang, China","IEEE Geoscience and Remote Sensing Letters","27 Sep 2022","2022","19","","1","5","The structure and texture of images are crucial for remote sensing image super-resolution (SR). Generative adversarial networks (GANs) recover image details through adversarial training. However, the recovered images always have structural distortions, on the one hand, and GANs are difficult to train, on the other hand. In addition, some methods assist reconstruction by introducing prior information of the image, but this brings additional computational cost. To address this issue, we propose a novel structure-texture parallel embedding (SPE) method for SR of remote sensing images. Our method does not require additional image priors to reconstruct high-quality images. Specifically, we use the global structure information and local texture information of the image in the ascending space to guide the reconstruction result of the image. First, we design a structure preserving block (SPB) to extract global structural features in the ascending space of the image, so as to obtain global structure information for a priori representation. Then, we design a local texture attention module (LTAM) to restore richer texture details. We have conducted lots of experiments on Draper public dataset. Experimental results show that our proposed method not only achieves a better tradeoff between computational cost and performance, but also outperforms the existing several SR methods in terms of objective index evaluation and subjective visual effects.","1558-0571","","10.1109/LGRS.2022.3206348","National Natural Science Foundation of China(grant numbers:62072350,62171328,U1903214,62071339,61771353); Hubei Technology Innovation Project(grant numbers:2019AAA045); Central Government Guides Local Science and Technology Development Special Projects(grant numbers:2018ZYYD059); High value Intellectual Property Cultivation Project of Hubei Province; Enterprise Technology Innovation Project of Wuhan(grant numbers:202001602011971); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9888134","Remote sensing image super-resolution (SR);structure preserving;texture attention mechanism","Feature extraction;Remote sensing;Image reconstruction;Training;Superresolution;Convolution;Satellites","feature extraction;geophysical image processing;image reconstruction;image resolution;image texture;neural nets;remote sensing","Draper public dataset;structure-texture parallel embedding method;local texture attention module;structure preserving block;local texture information;global structure information;high-quality images;structural distortions;recovered images;image details;generative adversarial networks;remote sensing image super-resolution","","","","21","IEEE","12 Sep 2022","","","IEEE","IEEE Journals"
"End-to-End Recurrent Generative Adversarial Network for Traffic and Surveillance Applications","P. W. Patil; A. Dudhane; S. Murala","Department of Electrical Engineering, Computer Vision and Pattern Recognition Laboratory, Indian Institute of Technology Ropar, Rupnagar, Punjab, India; Department of Electrical Engineering, Computer Vision and Pattern Recognition Laboratory, Indian Institute of Technology Ropar, Rupnagar, Punjab, India; Department of Electrical Engineering, Computer Vision and Pattern Recognition Laboratory, Indian Institute of Technology Ropar, Rupnagar, Punjab, India","IEEE Transactions on Vehicular Technology","25 Jan 2021","2020","69","12","14550","14562","In video frame segmentation, many existing deep networks and contemporary approaches give a remarkable performance with the assumption that the only foreground is moving, and the background is stationary. However, in the presence of infrequent motion of foreground objects, sudden illumination changes in the background, bad weather, and dynamic background, the accurate foreground object(s) segmentation is a challenging task. Generative adversarial networks (GAN) based training shows fruitful results in various fields like image-to-image style transfer, image enhancement, semantic segmentation, image super-resolution, etc. The limited results of hand-crafted approaches for moving object segmentation (MOS) and the robustness of adversarial training for a given task inspired us to propose a novel approach for moving object segmentation (MOS). In this context, an end-to-end generative adversarial network (two generators) with recurrent technique is proposed for MOS and is named as RMS-GAN. The proposed RMS-GAN is able to incorporate foreground probability knowledge with residual and weight sharing based recurrent technique for accurate segmentation. The recurrent technique helps us to exhibit the temporal behavior between successive video frames, which is more prominent for any video processing applications. Also, to enhance the spatial coherence of the obtained foreground probability map using the generator-1 network, the cascaded architecture of two generators is proposed. The effectiveness of the proposed approach is evaluated both qualitatively and quantitatively on three benchmark video datasets for MOS. Experimental result analysis shows that the proposed network outperforms the existing state-of-the-art methods on three benchmark datasets for MOS.","1939-9359","","10.1109/TVT.2020.3043575","Science and Engineering Research Board(grant numbers:ECR/2018/001538); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288640","Generative adversarial networks;motion;recurrent;video frame segmentation","Generative adversarial networks;Task analysis;Generators;Estimation;Motion segmentation;Lighting;Meteorology","image enhancement;image resolution;image segmentation;object tracking;probability;recurrent neural nets;video signal processing","end-to-end recurrent generative adversarial network;video frame segmentation;deep networks;foreground objects;bad weather;generative adversarial networks based training;image-to-image style;image enhancement;semantic segmentation;image super-resolution;object segmentation;RMS-GAN;foreground probability knowledge;video processing applications;foreground probability map;benchmark video datasets","","13","","62","IEEE","9 Dec 2020","","","IEEE","IEEE Journals"
"Super-Resolution Reconstruction of Remote Sensing Images Based on GAN","L. Zhou; Y. Xia; Z. Liu","Jiangsu University of Science and Technology, Nanjing, China; Jiangsu University of Science and Technology, Nanjing, China; Jiangsu University of Science and Technology, Nanjing, China","2021 IEEE International Conference on Data Science and Computer Application (ICDSCA)","23 Dec 2021","2021","","","270","274","In recent years, the methods of super-resolution image reconstruction that based on deep learning have become a hot topic in research of computer vision. The methods of super-resolution image reconstruction that based on the Generative Adversarial Network (GAN) are not controlled in network generation, the models are easy to collapse, the generalization ability is undesirable, and the time complexity degree is too high. To fill these gaps, we propose a super-resolution image reconstruction method based on the GAN of encoding and decoding, which improves the quality of image reconstruction. First of all, our approach uses a design network with regularized structure to avoid model collapse. Then we build a generation network structure that based on encoding and decoding to suppress the uncontrollable defects of GAN network generated images. Finally, in the last layer of the generator, $\mathrm{N}^{\star}\mathrm{N}$ convolutional feature layer is included to replace the Softmax layer, which speeds up the training of the model. The experimental results show that the super-resolution remote sensing image reconstructed by the proposed method has higher reconstruction quality and better generalization ability in the DOTA training data sets. At the same time, the image reconstruction process can take much less time.","","978-1-6654-4054-7","10.1109/ICDSCA53499.2021.9649727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649727","GAN;Coding and Decoding;Remote Sensing Images;Super Resolution Reconstruction","Training;Deep learning;Image coding;Superresolution;Generative adversarial networks;Visual effects;Generators","computational complexity;computer vision;convolutional neural nets;geophysical image processing;image reconstruction;image resolution;remote sensing","generative adversarial network;generalization ability;superresolution image reconstruction method;design network;generation network structure;superresolution remote sensing image;deep learning;computer vision;time complexity degree;encoding;decoding;GAN network generated image;convolutional feature layer;softmax layer;DOTA training data sets","","","","11","IEEE","23 Dec 2021","","","IEEE","IEEE Conferences"
"Efficient Super Resolution for Large-Scale Images Using Attentional GAN","H. N. Pathak; X. Li; S. Minaee; B. Cowan","Data Science Department, Worcester Polytechnic Institute, Worcester, MA, USA; Expedia Group, Bellevue, WA, USA; Expedia Group, Bellevue, WA, USA; Expedia Group, Bellevue, WA, USA","2018 IEEE International Conference on Big Data (Big Data)","24 Jan 2019","2018","","","1777","1786","Single Image Super Resolution (SISR) is a well-researched problem with broad commercial relevance. However, most of the SISR literature focuses on small-size images under 500px, whereas business needs can mandate the generation of very high resolution images. At Expedia Group, we were tasked with generating images of at least 2000px for display on the website - four times greater than the sizes typically reported in the literature. This requirement poses a challenge that state-of-the-art models, validated on small images, have not been proven to handle. In this paper, we investigate solutions to the problem of generating high-quality images for large-scale1 super resolution in a commercial setting. We find that training a generative adversarial network (GAN) with attention from scratch using a large-scale lodging image data set generates images with high PSNR and SSIM scores. We describe a novel attentional SISR model for large-scale images, A-SRGAN, that uses a Flexible Self Attention layer to enable processing of large-scale images. We also describe a distributed algorithm which speeds up training by around a factor of five.","","978-1-5386-5035-6","10.1109/BigData.2018.8622477","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622477","super-resolution;deep learning;generative adversarial networks;attention;distributed training","Image resolution;Gallium nitride;Training;Visualization;Computational modeling;Generative adversarial networks;Business","image resolution;learning (artificial intelligence)","attentional GAN;SISR literature;high-quality images;generative adversarial network;large-scale lodging image data;single image super resolution;PSNR scores;SSIM scores;A-SRGAN;flexible self attention layer;distributed algorithm","","15","","33","IEEE","24 Jan 2019","","","IEEE","IEEE Conferences"
"Consecutive Context Perceive Generative Adversarial Networks for Serial Sections Inpainting","S. Zhang; L. Wang; J. Zhang; L. Gu; X. Jiang; X. Zhai; X. Sha; S. Chang","Division of Biomedical Engineering, China Medical University, Shenyang, China; Division of Biomedical Engineering, China Medical University, Shenyang, China; School of Basic Medicine Science, China Medical University, Shenyang, China; School of Basic Medicine Science, China Medical University, Shenyang, China; Division of Biomedical Engineering, China Medical University, Shenyang, China; School of Basic Medicine Science, China Medical University, Shenyang, China; Division of Biomedical Engineering, China Medical University, Shenyang, China; Division of Biomedical Engineering, China Medical University, Shenyang, China","IEEE Access","26 Oct 2020","2020","8","","190417","190430","Image inpainting is a hot topic in computer vision research and has been successfully applied to both traditional and digital mediums, such as oil paintings or old photos mending, image or video denoising and super-resolution. With the introduction of artificial intelligence (AI), a series of algorithms, represented by semantic inpainting, have been developed and better results were achieved. Medical image inpainting, as one of the most demanding applications, needs to meet both the visual effects and strict content correctness. 3D reconstruction of microstructures, based on serial sections, could provide more spatial information and help us understand the physiology or pathophysiology mechanism in histology study, in which extremely high-quality continuous images without any defects are required. In this article, we proposed a novel Consecutive Context Perceive Generative Adversarial Networks (CCPGAN) for serial sections inpainting. Our method can learn semantic information from its neighboring image, and restore the damaged parts of serial sectioning images to maximum extent. Validated with 2 sets of serial sectioning images of mouse kidney, qualitative and quantitative results suggested that our method could robustly restore breakage of any size and location while achieving near realtime performance.","2169-3536","","10.1109/ACCESS.2020.3031973","National Science Fund of Liaoning(grant numbers:2018-64); National Science Fund of China (NSFC)(grant numbers:31971115); Big Data Research for Health Science of China Medical University(grant numbers:6); Science Research Fund for Higher Education of Liaoning(grant numbers:LQNK201744); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229053","Serial sectioning images;generative adversarial network;consecutive context perceive GAN","Image restoration;Generative adversarial networks;Feature extraction;Biomedical imaging;Training;Convolution;Semantics","computer vision;image denoising;image resolution;image restoration;image segmentation;learning (artificial intelligence);medical image processing;neural nets;stereo image processing;video signal processing","computer vision;image superresolution;artificial intelligence;medical image inpainting;image quality;serial sectioning images;consecutive context perceive generative adversarial networks;3D microstructure reconstruction;image restoration;image denoising;video denoising","","2","","46","CCBYNCND","19 Oct 2020","","","IEEE","IEEE Journals"
"A Deep Residual Star Generative Adversarial Network for multi-domain Image Super-Resolution","R. M. Umer; A. Munir; C. Micheloni","Dept. of Computer Science University of Udine, Udine, Italy; Dept. of Computer Science University of Udine, Udine, Italy; Dept. of Computer Science University of Udine, Udine, Italy","2021 6th International Conference on Smart and Sustainable Technologies (SpliTech)","21 Oct 2021","2021","","","01","05","Recently, most of state-of-the-art single image super-resolution (SISR) methods have attained impressive performance by using deep convolutional neural networks (DCNNs). The existing SR methods have limited performance due to a fixed degradation settings, i.e. usually a bicubic downscaling of low-resolution (LR) image. However, in real-world settings, the LR degradation process is unknown which can be bicubic LR, bilinear LR, nearest-neighbor LR, or real LR. Therefore, most SR methods are ineffective and inefficient in handling more than one degradation settings within a single network. To handle the multiple degradation, i.e. refers to multi-domain image super-resolution, we propose a deep Super-Resolution Residual StarGAN (SR2*GAN), a novel and scalable approach that super-resolves the LR images for the multiple LR domains using only a single model. The proposed scheme is trained in a StarGAN like network topology with a single generator and discriminator networks. We demonstrate the effectiveness of our proposed approach in quantitative and qualitative experiments compared to other state-of-the-art methods.","","978-953-290-112-2","10.23919/SpliTech52315.2021.9566406","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9566406","Single Image Super-Resolution;Multi-domain SR;Deep Learning;GAN","Degradation;Network topology;Superresolution;Generative adversarial networks;Generators;Convolutional neural networks;Task analysis","","","","1","","26","","21 Oct 2021","","","IEEE","IEEE Conferences"
"Critical Review on Deep Learning and Smart Technologies for Image Super-Resolution","W. -C. Sui; X. Cheng; H. A. Chan",Caritas Institute of Higher Education; Nanjing University of Science and Technology; Caritas Institute of Higher Education,"TENCON 2022 - 2022 IEEE Region 10 Conference (TENCON)","20 Dec 2022","2022","","","1","8","Image super-resolution is an extremely useful way to improve the quality of an image. It is miracle that making use of the current signal processing and deep learning technologies, the image can look much appealing after the super-solution. This review paper is to highlight important techniques, especially to point out recent key contributions to make superior success of super-resolution of the recent years, especially on face super-resolution. We will start with a very brief and quick review on using conventional signal processing and classic learning approaches for super-resolution, and then concentrate on giving the advantages of deep learning, in particular, the recent powerful concepts on using latent vector and facial priors to achieve superior performance. Further topics of discussion include generative adversarial network (GAN), StyleGAN, latent space, facial priors and diffusion models. Our concentration is on the reasons for the success of these techniques. Attractive demonstrations on a few state-of-the-art models, including some of our work, are provided","2159-3450","978-1-6654-5095-9","10.1109/TENCON55691.2022.9977489","Nanjing University of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9977489","Image restoration;super-resolution;face-super-resolution;machine learning;deep learning","Deep learning;Superresolution;Signal processing;Generative adversarial networks;Image restoration;Faces;IEEE Regions","face recognition;image resolution;learning (artificial intelligence)","brief review;classic learning approaches;conventional signal processing;current signal processing;deep learning technologies;face super-resolution;image super-resolution;quick review;recent key contributions;recent powerful concepts;smart technologies;super-solution","","","","56","IEEE","20 Dec 2022","","","IEEE","IEEE Conferences"
"Deep Generative Adversarial Networks for Thin-Section Infant MR Image Reconstruction","J. Gu; Z. Li; Y. Wang; H. Yang; Z. Qiao; J. Yu","School of Information Science and Technology, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China; Key Laboratory of Medical Imaging Computing and Computer Assisted Intervention of Shanghai, Institute of Functional and Molecular Medical Imaging, Fudan University, Shanghai, China; The Children’s Hospital of Fudan University, Shanghai, China; The Children’s Hospital of Fudan University, Shanghai, China; Key Laboratory of Medical Imaging Computing and Computer Assisted Intervention of Shanghai, Institute of Functional and Molecular Medical Imaging, Fudan University, Shanghai, China","IEEE Access","4 Jun 2019","2019","7","","68290","68304","Due to their high spatial resolution, thin-section magnetic resonance (MR) images serve as ideal medical images for brain structure investigation and brain surgery navigation. However, compared with the clinically widely used thick-section MR images, thin-section MR images are less available due to the imaging cost. Thin-section MR images of infants are even scarcer but are quite valuable for the study of human brain development. Therefore, we propose a method for the reconstruction of thin-section MR images from thick-section images. A two-stage reconstruction framework based on generative adversarial networks (GANs) and a convolutional neural network (CNN) is proposed to reconstruct thin-section MR images from thick-section images in the axial and sagittal planes. A 3D-Y-Net-GAN is first proposed to fuse MR images from the axial and sagittal planes and to achieve the first-stage thin-section reconstruction. A 3D-DenseU-Net followed by a stack of enhanced residual blocks is then proposed to provide further detail recalibrations and structural corrections in the sagittal plane. In this method, a comprehensive loss function is also proposed to help the networks capture more structural details. The reconstruction performance of the proposed method is compared with bicubic interpolation, sparse representation, and 3D-SRU-Net. Cross-validation based on 35 cases and independent testing based on two datasets with totally 114 cases reveal that, compared with the other three methods, the proposed method provides an average 23.5% improvement in peak signal-to-noise ratio (PSNR), 90.5% improvement in structural similarity (SSIM), and 21.5% improvement in normalized mutual information (NMI). The quantitative evaluation and visual inspection demonstrate that our proposed method outperforms those methods by reconstructing more realistic results with better structural details.","2169-3536","","10.1109/ACCESS.2019.2918926","National Natural Science Foundation of China(grant numbers:61471125); National Basic Research Program of China(grant numbers:2015CB755500); Shanghai Shenkang Hospital Development Center Clinical Auxiliary Capacity (Imaging Medicine) Construction Project(grant numbers:SHDC22015031); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721701","Deep learning;infant magnetic resonance (MR) images;super-resolution reconstruction;thick-section;thin-section","Image reconstruction;Convolution;Feature extraction;Spatial resolution;Gallium nitride;Generators","biomedical MRI;brain;convolutional neural nets;image reconstruction;interpolation;learning (artificial intelligence);medical image processing;paediatrics","sagittal plane;deep generative adversarial networks;thin-section infant MR image reconstruction;thin-section magnetic resonance images;brain structure investigation;brain surgery navigation;thick-section MR images;thin-section MR images;medical images;generative adversarial networks;convolutional neural network;axial planes;3D-DenseU-Net;residual blocks;structural corrections;comprehensive loss function;bicubic interpolation;sparse representation;peak signal-to-noise ratio;structural similarity;normalized mutual information;visual inspection","","13","","30","OAPA","24 May 2019","","","IEEE","IEEE Journals"
"SiGAN: Siamese Generative Adversarial Network for Identity-Preserving Face Hallucination","C. -C. Hsu; C. -W. Lin; W. -T. Su; G. Cheung","Department of Management Information Systems, National Pingtung University of Science and Technology, Neipu, Taiwan; Institute of Communications Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering and Computer Science, York University, Toronto, ON, Canada","IEEE Transactions on Image Processing","4 Sep 2019","2019","28","12","6225","6236","Though generative adversarial networks (GANs) can hallucinate high-quality high-resolution (HR) faces from low-resolution (LR) faces, they cannot ensure identity preservation during face hallucination, making the HR faces difficult to recognize. To address this problem, we propose a Siamese GAN (SiGAN) to reconstruct HR faces that visually resemble their corresponding identities. On top of a Siamese network, the proposed SiGAN consists of a pair of two identical generators and one discriminator. We incorporate reconstruction error and identity label information in the loss function of SiGAN in a pairwise manner. By iteratively optimizing the loss functions of the generator pair and the discriminator of SiGAN, we not only achieve visually-pleasing face reconstruction but also ensure that the reconstructed information is useful for identity recognition. Experimental results demonstrate that SiGAN significantly outperforms existing face hallucination GANs in objective face verification performance while achieving promising visual-quality reconstruction. Moreover, for input LR faces with unseen identities that are not part of the training dataset, SiGAN can still achieve reasonable performance.","1941-0042","","10.1109/TIP.2019.2924554","Ministry of Science and Technology, Taiwan(grant numbers:MOST 108-2634-F-007-009,107-2218-E-020-002-MY3,107-2218-E-006-059); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8751141","Face hallucination;convolutional neural networks;generative adversarial networks;super-resolution;generative model","Face;Image reconstruction;Face recognition;Training;Generators;Image resolution;Generative adversarial networks","face recognition;image reconstruction;image representation;image resolution;iterative methods;learning (artificial intelligence)","SiGAN;Siamese generative adversarial network;identity-preserving face hallucination;generative adversarial networks;high-quality high-resolution;identity preservation;identical generators;reconstruction error;identity label information;loss function;generator pair;face reconstruction;identity recognition;objective face verification performance;visual-quality reconstruction;unseen identities;face hallucination GAN;Siamese GAN","","52","","31","IEEE","28 Jun 2019","","","IEEE","IEEE Journals"
"SAR Image Super-Resolution Based on Noise-Free Generative Adversarial Network","F. Gu; H. Zhang; C. Wang; F. Wu","Key Laboratory of Digital Earth Science, of Institute of Remote Sensing and Digital Earth, Chinese Academy of Science, Beijing, China; Key Laboratory of Digital Earth Science, of Institute of Remote Sensing and Digital Earth, Chinese Academy of Science, Beijing, China; Key Laboratory of Digital Earth Science, of Institute of Remote Sensing and Digital Earth, Chinese Academy of Science, Beijing, China; Key Laboratory of Digital Earth Science, of Institute of Remote Sensing and Digital Earth, Chinese Academy of Science, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2575","2578","Deep learning has been successfully applied to the ordinary image super-resolution (SR). However, since the synthetic aperture radar (SAR) images are often disturbed by multiplicative noise known as speckle and more blurry than ordinary images, there are few deep learning methods for the SAR image SR. In this paper, a deep generative adversarial network (DGAN) is proposed to reconstruct the pseudo high-resolution (HR) SAR images. First, a generator network is constructed to remove the noise of low-resolution SAR image and generate HR SAR image. Second, a discriminator network is used to differentiate between the pseudo super-resolution images and the realistic HR images. The adversarial objective function is introduced to make the pseudo HR SAR images closer to real SAR images. The experimental results show that our method can maintain the SAR image content with high-level noise suppression. The performance evaluation based on peak signal-to-noise-ratio and structural similarity index shows the superiority of the proposed method to the conventional CNN baselines.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8899202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8899202","Synthetic aperture radar;super-resolution;generative adversarial network","Radar polarimetry;Image reconstruction;Generators;Training;Generative adversarial networks","image denoising;image resolution;learning (artificial intelligence);neural nets;radar computing;radar imaging;radar resolution;synthetic aperture radar","deep generative adversarial network;realistic HR images;adversarial objective function;synthetic aperture radar images;SAR image superresolution;noise free generative adversarial network;deep learning;DGAN;pseudo high-resolution SAR images","","7","","12","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Single-image Super-resolution Based on Generative Adversarial Network with Dual Attention Mechanism","M. Xu; Y. Ding","Shanghai Film Academy, Shanghai University, China; Shanghai Film Academy, Shanghai University, China","2022 IEEE 5th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)","26 Jan 2023","2022","5","","239","250","Most of the single-image (SI) super-resolution (SR) methods based on convolutional neural network (CNN) focus on the broader or deeper model architecture design, ignoring the research on the correlation of features in the middle layer, which hinders the representative power of CNN. However, most of the classical SISR methods based on generative adversarial network (GAN) focus on improving generators and loss functions, which are difficult to balance visual quality and objective evaluation. In order to solve these problems, SRGAN-DAM-SISR is proposed in this paper, which is also a typical GAN structure. However, it is different from the classical SRGAN and ESRGAN. We have made many designs and innovations, including improving the traditional feature extraction module of the generator and the discriminator's discriminant target in the GAN, removing the batch normalization (BN) layer, using many loss functions for weighting and using some tricks to improve the performance of the network. Experimental results show the improvement and innovation to enhance the visual effect of the output image, the resulting image quality is also improved.","2693-2776","978-1-6654-7968-4","10.1109/IMCEC55388.2022.10020076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020076","attention mechanisms;generative adversarial networks;residual learning;super resolution;image enhancement","Image quality;Degradation;Technological innovation;Computational modeling;Superresolution;Generative adversarial networks;Visual effects","feature extraction;image enhancement;image resolution;learning (artificial intelligence);neural nets","batch normalization layer;discriminant target;discriminator;dual attention mechanism;feature extraction;GAN structure;generative adversarial network;generators;image enhancement;image quality;loss functions;model architecture design;output image;single-image super-resolution;SRGAN-DAM-SISR;visual effect;visual quality","","","","56","IEEE","26 Jan 2023","","","IEEE","IEEE Conferences"
"Decompression of Bluetooth-transmitted Audio using Super Resolution for Low-Latency Applications","A. J. Atienza; A. Calabano; M. L. Manalo; S. B. Salandanan; C. R. Lucas; F. De Leon; C. Ambatali; C. T. Tolentino","Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines","2021 International Conference on Information and Communication Technology Convergence (ICTC)","7 Dec 2021","2021","","","530","534","Bluetooth devices experience a common trade-off between quality and latency. This affects applications that require fast and accurate transmission of audio signals, especially in the medical and musical industry. In this paper, the use of super resolution techniques such as the Convolutional Neural Networks (CNN) and Generative Adversarial Networks (GAN) were utilized to improve the quality of Bluetooth-transmitted audio signals. We have shown that these two models were able to improve a number of speech and non speech audio signals based on our performance metrics: (1) Signal-to-Noise Ratio (SNR); (2) Log Spectral Distance (LSD); (3) Perceptual Evaluation of Audio Quality (PEAQ); and (4) Multi Stimulus test with Hidden Reference and Anchor (MUSHRA). Both models were able to improve the Bluetooth-transmitted audio signals, although the GAN model produced better results on both the objective and subjective evaluation tests compared to the CNN model. For the SNR, LSD, PEAQ, and MUSHRA, the GAN model averaged 20.4170 dB, 2.1408 dB, −2.7190, and 42.6500 respectively, while the CNN model averaged −1.7190 dB, 1.9410 dB, −2.7190, and 17.1600 respectively. For this project, the subjective test MUSHRA bear more weight in the results as the objective tests shows inconsistencies and cannot be heavily relied on.","2162-1233","978-1-6654-2383-0","10.1109/ICTC52510.2021.9620765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9620765","bluetooth;latency;deep learning;audio decompression;super resolution","Measurement;Industries;Music;Generative adversarial networks;Information and communication technology;Convolutional neural networks;Low latency communication","audio coding;audio signal processing;Bluetooth;convolutional neural nets;data compression;music;signal resolution","CNN model;low-latency applications;Bluetooth devices;medical industry;musical industry;super resolution techniques;convolutional neural networks;generative adversarial networks;Bluetooth-transmitted audio signals;nonspeech audio signals;signal-to-noise ratio;audio quality;GAN model;noise figure 2.1408 dB;noise figure -1.719 dB;noise figure 1.941 dB;noise figure 20.417 dB","","","","22","IEEE","7 Dec 2021","","","IEEE","IEEE Conferences"
"StarGAN Based Facial Expression Transfer for Anime Characters","M. Mobini; F. Ghaderi","Human Computer Interaction Lab., Tarbiat Modares University, Tehran, Iran; Human Computer Interaction Lab., Tarbiat Modares University, Tehran, Iran","2020 25th International Computer Conference, Computer Society of Iran (CSICC)","30 Mar 2020","2020","","","1","5","Human facial expression transfer has been well explored using Generative Adversarial Networks. Also, in case of anime style images, several successful attempts have been made to generate high-quality anime face images using GAN approach. However, the task of anime facial expression transfer is not well studied yet due to the lack of a clean labeled anime dataset. We address this issue from both data and model perspectives, by providing a clean labeled anime dataset and leveraging the use of the StarGAN image-to-image translation framework. Our collected dataset consists of about 5k high- quality anime face images including five major emotions collected from online image boards. We preprocessed our dataset by CARN super-resolution technique to improve quality of the images, and applied tuned StarGAN model to learn the mapping of an input anime image with arbitrary expression to the target expression. We evaluate our work by visually comparing the output translated results with the baseline model. Moreover, we provide a quantitative analysis of our proposed approach by computing the confusion matrix of expression transfer accuracy.","","978-1-7281-5937-9","10.1109/CSICC49403.2020.9050061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9050061","Facial Expression Transfer;Unpaired Image Translation;Generative Adversarial Network;Anime Generation","Statistical analysis;Computational modeling;Superresolution;Data preprocessing;Generative adversarial networks;Data models;Task analysis","computer animation;emotion recognition;face recognition;neural nets","expression transfer accuracy;anime characters;human facial expression transfer;generative adversarial networks;anime style images;high-quality anime face images;anime facial expression transfer;StarGAN image-to-image translation framework;high- quality anime face images;online image boards;StarGAN model;input anime image;arbitrary expression;target expression;labeled anime dataset;GAN approach;CARN super-resolution;confusion matrix","","3","","19","IEEE","30 Mar 2020","","","IEEE","IEEE Conferences"
"Modified Generative Adversarial Network for Super-Resolution of Terahertz Image","Z. Zhang; L. Zhang; X. Chen; Y. Xu","State Key Laboratory for Manufacturing Systems Engineering, Xi’an Jiaotong University, Xi’an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi’an Jiaotong University, Xi’an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi’an Jiaotong University, Xi’an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi’an Jiaotong University, Xi’an, China","2020 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)","24 Nov 2020","2020","","","602","605","Terahertz (THz) images have low spatial resolution, blurring contour features and high background noise owing to the limitation of terahertz (THz) wavelengths and the THz imaging systems. We have proposed a modified Generative Adversarial Network (GAN) for super-resolution (SR) purpose. To fit the THz images, we design a kind of image degradation model to generate low-resolution images with Gaussian blur and white Gaussian noise. We establish a dataset of damage images in the field of non-destructive testing (NDT) for training and testing. The experimental results on THz images demonstrate that the improved GAN model can improve the quality of THz images effectively. Our method can be beneficial to improve the accuracy of THz NDT with low resolution.","","978-1-7281-9277-2","10.1109/ICSMD50554.2020.9261734","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261734","THz image;super-resolution;degradation model;deep learning","Training;Image resolution;Imaging;Gallium nitride;Testing;Generators;Generative adversarial networks","AWGN;computerised instrumentation;image resolution;image restoration;neural nets;nondestructive testing;submillimetre wave imaging;terahertz wave imaging","GAN model;nondestructive testing;image blurring contour;low spatial resolution imaging;terahertz image superresolution;THz NDT;white Gaussian noise;image degradation model;THz imaging systems;background noise;modified generative adversarial network","","1","","15","IEEE","24 Nov 2020","","","IEEE","IEEE Conferences"
"Multi-Perspective Discriminators-Based Generative Adversarial Network for Image Super Resolution","O. -Y. Lee; Y. -H. Shin; J. -O. Kim","School of Electrical Engineering, Korea University, Seoul, South Korea; School of Electrical Engineering, Korea University, Seoul, South Korea; School of Electrical Engineering, Korea University, Seoul, South Korea","IEEE Access","30 Sep 2019","2019","7","","136496","136510","Recently, generative adversarial network-based image super resolution has been investigated, and it has been shown to lead to overwhelming improvements in subjective quality. However, it also leads to checkerboard artifacts and the unpleasing high-frequency (HF) components. In this paper, we propose a multi-discriminators-based image super resolution method that distinguishes those artifacts from various perspectives. First, the DCT perspective discriminator is proposed because the checkerboard artifacts are easily separated on the frequency domain. Second, the gradient perspective discriminator is proposed, because the unpleasing HF components can be discriminated on the gradient magnitude distribution. These proposed multi-perspective discriminators can easily identify artifacts, and they can help the generator reproduce artifact-less SR images. The experimental results show that the proposed SR-GAN with multi-perspective discriminators achieves objective and subjective quality improvements in terms of PSNR, SSIM, PI and MOS, as compared to the conventional SR-GAN by reducing the aforementioned artifacts.","2169-3536","","10.1109/ACCESS.2019.2942779","National Research Foundation of Korea(grant numbers:2019R1A2C1005834); Ministry of Science and ICT (MSIT), South Korea, through the Information Technology Research Center (ITRC) Support Program supervised by the Institute of Information and Communications Technology Planning and Evaluation (IITP)(grant numbers:IITP-2019-2018-0-01421); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845591","Image super-resolution;deep learning for super resolution;SR GAN;multi-discriminators","Generators;Discrete cosine transforms;Deep learning;Generative adversarial networks;Frequency-domain analysis;Spatial resolution","discrete cosine transforms;gradient methods;image reconstruction;image resolution","gradient perspective discriminator;unpleasing HF components;artifact-less SR images;subjective quality improvements;aforementioned artifacts;multiperspective discriminators-based generative adversarial network;generative adversarial network-based image super resolution;checkerboard artifacts;high-frequency components;multidiscriminators-based image super resolution method;DCT perspective discriminator","","13","","54","CCBY","20 Sep 2019","","","IEEE","IEEE Journals"
"SwiftSRGAN - Rethinking Super-Resolution for Efficient and Real-time Inference","K. S. Krishnan; K. S. Krishnan",NA; NA,"2021 International Conference on Intelligent Cybernetics Technology & Applications (ICICyTA)","4 Feb 2022","2021","","","46","51","In recent years, there have been several advancements in the task of image super-resolution using the state of the art Deep Learning-based architectures. Many super-resolution-based techniques previously published, require high-end and top-of-the-line Graphics Processing Unit (GPUs) to perform image super-resolution. With the increasing advancements in Deep Learning approaches, neural networks have become more and more compute hungry. We took a step back and, focused on creating a real-time efficient solution. We present an architecture that is faster and smaller in terms of its memory footprint. The proposed architecture uses Depth-wise Separable Convolutions to extract features and, it performs on-par with other super-resolution GANs (Generative Adversarial Networks) while maintaining real-time inference and a low memory footprint. A real-time super-resolution enables streaming high resolution media content even under poor bandwidth conditions. We need a real-time and efficient solution for tasks like cloud gaming and media streaming but also not at the cost of using a high-end top-of-the-line GPU. While maintaining an efficient trade-off between the accuracy and latency, we are able to produce a comparable performance model which is one-eighth (1/8) the size of super-resolution GANs and computes 74 times faster than super-resolution GANs. This significant reduction in inference time enables us to perform super-resolution in real-time.","","978-1-6654-1777-8","10.1109/ICICyTA53712.2021.9689188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689188","Image Super-Resolution;GANs;Depth-wise Separable Convolutions;Swift-SRGAN;Perceptual Loss Function;MobileNet Loss;Content Loss;Adversarial Loss;up-sampling;PSNR;SSIM","Superresolution;Neural networks;Graphics processing units;Computer architecture;Streaming media;Media;Feature extraction","convolution;feature extraction;graphics processing units;image resolution;learning (artificial intelligence);media streaming;neural nets","high-end top-of-the-line GPU;super-resolution GAN;inference time;real-time inference;image super-resolution;super-resolution-based techniques;real-time efficient solution;real-time super-resolution;high resolution media content;deep learning approaches","","","","23","IEEE","4 Feb 2022","","","IEEE","IEEE Conferences"
"Coupled Adversarial Training for Remote Sensing Image Super-Resolution","S. Lei; Z. Shi; Z. Zou","State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, USA","IEEE Transactions on Geoscience and Remote Sensing","22 Apr 2020","2020","58","5","3633","3643","Generative adversarial network (GAN) has made great progress in recent natural image super-resolution tasks. The key to its success is the integration of a discriminator which is trained to classify whether the input is a real high-resolution (HR) image or a generated one. Arguably, learning a strong discriminative prior is essential for generating high-quality images. However, in remote sensing images, we discover, through extensive statistical analysis, that there are more low-frequency components than natural images, which may lead to a “discrimination-ambiguity” problem, i.e., the discriminator will become “confused” to tell whether its input is real or not when dealing with those low-frequency regions, and therefore, the quality of generated HR images may be deeply affected. To address this problem, we propose a novel GAN-based super-resolution algorithm named coupled-discriminated GANs (CDGANs) for remote sensing images. Different from the previous GAN-based super-resolution models in which their discriminator takes in a single image at one time, in our model, the discriminator is specifically designed to take in a pair of images: a generated image and its HR ground truth, to make better discrimination of the inputs. We further introduce a dual pathway network architecture, a random gate, and a coupled adversarial loss to learn better correspondence between the discriminative results and the paired inputs. Experimental results on two public data sets demonstrate that our model can obtain more accurate super-resolution results in terms of both visual appearance and local details compared with other state of the arts. Our code will be made publicly available.","1558-0644","","10.1109/TGRS.2019.2959020","National Basic Research Program of China (973 Program)(grant numbers:2017YFC1405605); National Natural Science Foundation of China(grant numbers:61671037); Beijing Natural Science Foundation(grant numbers:4192034); National Defense Science and Technology Innovation Special Zone Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946581","Coupled adversarial training;deep convolutional neural networks;generative adversarial networks (GANs);remote sensing images;super-resolution","Remote sensing;Training;Generators;Gallium nitride;Task analysis","geophysical image processing;image representation;image resolution;learning (artificial intelligence);remote sensing;statistical analysis","CDGAN;coupled-discriminated GAN;GAN-based super-resolution;low-frequency components;high-quality images;strong discriminative;high-resolution image;natural image super-resolution tasks;generative adversarial network;remote sensing image super-resolution;coupled adversarial training;accurate super-resolution results;paired inputs;discriminative results;coupled adversarial loss;previous GAN-based super-resolution models;remote sensing images;generated HR images;low-frequency regions","","54","","58","IEEE","31 Dec 2019","","","IEEE","IEEE Journals"
"Text Image Super-Resolution by Image Matting and Text Label Supervision","K. Lin; Y. Liu; T. H. Li; S. Liu; G. Li","Peng Cheng Laboratory; School of Electronic and Computer Engineering, Peking University; Advanced Institute of Information Technology, Peking University; Tencent America; Peng Cheng Laboratory","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","9 Apr 2020","2019","","","1722","1727","These days, many methods have been proposed to deal with nature image super-resolution (SR) and get impressive performance. However, these methods don't do well in text images SR due to their ignorance of the difference between nature images and text images. In this paper, we propose a matting-based dual generative adversarial network (mdGAN) for text image SR. Firstly, the input image is decomposed into text, foreground and background layers using deep image matting. Then two parallel branches are constructed to recover text boundary information and color information respectively. Furthermore, in order to improve the restoration accuracy of characters in output image, we use the input image's corresponding ground truth text label as extra supervise information to refine the two-branch networks during training. Experiments on real text images demonstrate that our method outperforms several state-of-the-art methods quantitatively and qualitatively.","2160-7516","978-1-7281-2506-0","10.1109/CVPRW.2019.00222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9025615","","Image color analysis;Training;Image resolution;Gallium nitride;Image restoration;Generative adversarial networks;Optical character recognition software","image colour analysis;image resolution;image segmentation;text analysis","text image super-resolution;text label supervision;nature image super-resolution;nature images;matting-based dual generative adversarial network;text image SR;input image;background layers;deep image matting;text boundary information;color information;output image","","","","32","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"Single Image Super-Resolution Reconstruction of Enhanced Loss Function with Multi-GPU Training","J. Huang; K. Li; X. Wang","Department of Computer Science and Technology, Tsinghua University, China; Department of Computer Science and Technology, Tsinghua University, China; Department of Computer Technology and Application, Qinghai University, China","2019 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)","26 Mar 2020","2019","","","559","565","According to research on super-resolution (SR), SR image reconstruction using generated anti-networks can produce images that are more realistic than using convolutional neural networks. At present, SR technology based on convolutional neural networks ignores the impact of loss function on image reconstruction; the results lack detail and accuracy. In this paper, we use SR method and combine Generative Adversarial Networks to design a super-resolution (Lapras-GAN) model of the enhanced loss function. The proposed enhancement loss function is a Mix loss function that combines the multiscale SSIM and L1 loss functions to obtain realistic images. We performed qualitative and quantitative analysis of the performance of different loss functions and demonstrated the advantages of the Mix loss function. In addition, the neural network is accelerated by multiple GPUs of multiple nodes, which can be 3-4 times faster than a single node single GPU. Experimental results show that the proposed Lapras-GAN method can generate images consistent with images produced by human perception. Further comparisons show that our Lapras-GAN has excellent performance and test time in the PIRM2018 experimental test data set. Finally, we obtained a perception index of 1.83 and a test time of 0.031s in the PIRM2018 competition test set.","","978-1-7281-4328-6","10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9047446","Deep Learning, Generative Adversarial Networks, Loss Function, GPU, Single Image Super Resolution","Training;Gallium nitride;Graphics processing units;Mathematical model;Neural networks;Deep learning;Image reconstruction","graphics processing units;image reconstruction;image resolution;neural nets","Lapras-GAN;single image super-resolution reconstruction;enhanced loss function;SR image reconstruction;convolutional neural networks;SR technology;SR method;generative adversarial networks;enhancement loss function;Mix loss function;realistic images;different loss functions;neural network;single node single GPU;multi-GPU training;generated antinetworks;time 0.031 s","","1","","21","IEEE","26 Mar 2020","","","IEEE","IEEE Conferences"
"GLEAN: Generative Latent Bank for Image Super-Resolution and Beyond","K. C. K. Chan; X. Xu; X. Wang; J. Gu; C. C. Loy","S-Lab, Nanyang Technological University (NTU), Singapore; S-Lab, Nanyang Technological University (NTU), Singapore; Applied Research Center, Tencent PCG, Shenzhen, Guangdong, China; Shanghai AI Laboratory, Shanghai, China; S-Lab, Nanyang Technological University (NTU), Singapore","IEEE Transactions on Pattern Analysis and Machine Intelligence","3 Feb 2023","2023","45","3","3154","3168","We show that pre-trained Generative Adversarial Networks (GANs) such as StyleGAN and BigGAN can be used as a latent bank to improve the performance of image super-resolution. While most existing perceptual-oriented approaches attempt to generate realistic outputs through learning with adversarial loss, our method, Generative LatEnt bANk (GLEAN), goes beyond existing practices by directly leveraging rich and diverse priors encapsulated in a pre-trained GAN. But unlike prevalent GAN inversion methods that require expensive image-specific optimization at runtime, our approach only needs a single forward pass for restoration. GLEAN can be easily incorporated in a simple encoder-bank-decoder architecture with multi-resolution skip connections. Employing priors from different generative models allows GLEAN to be applied to diverse categories (e.g., human faces, cats, buildings, and cars). We further present a lightweight version of GLEAN, named LightGLEAN, which retains only the critical components in GLEAN. Notably, LightGLEAN consists of only 21% of parameters and 35% of FLOPs while achieving comparable image quality. We extend our method to different tasks including image colorization and blind image restoration, and extensive experiments show that our proposed models perform favorably in comparison to existing methods. Codes and models are available at https://github.com/open-mmlab/mmediting.","1939-3539","","10.1109/TPAMI.2022.3186715","RIE2020 Industry Alignment Fund Industry Collaboration Projects; cash and in-kind contribution from industry partner; NTU NAP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808408","Super-resolution;colorization;restoration;generative adversarial networks;generative prior","Image restoration;Generative adversarial networks;Task analysis;Superresolution;Generators;Faces;Optimization","","","","","","72","IEEE","28 Jun 2022","","","IEEE","IEEE Journals"
"Component Semantic Prior Guided Generative Adversarial Network for Face Super-Resolution","L. Liu; S. Wang; L. Wan","Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China","IEEE Access","24 Jun 2019","2019","7","","77027","77036","Face super-resolved (SR) images aid human perception. The state-of-the-art face SR methods leverage the spatial location of facial components as prior knowledge. However, it remains a great challenge to generate natural textures. In this paper, we propose a component semantic prior guided generative adversarial network (CSPGAN) to synthesize faces. Specifically, semantic probability maps of facial components are exploited to modulate features in the CSPGAN through affine transformation. To compensate for the overly smooth performance of the generative network, a gradient loss is proposed to recover the high-frequency details. Meanwhile, the discriminative network is designed to perform multiple tasks which predict semantic category and distinguish authenticity simultaneously. The extensive experimental results demonstrate the superiority of the CSPGAN in reconstructing photorealistic textures.","2169-3536","","10.1109/ACCESS.2019.2921859","National Natural Science Foundation of China(grant numbers:61572064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8734147","Facial component;face super-resolution;generative adversarial networks;multiple task;semantic prior","Semantics;Face;Image reconstruction;Spatial resolution;Training;Generative adversarial networks","affine transforms;face recognition;image reconstruction;image resolution;image texture;neural nets;probability","face super-resolution;spatial location;facial components;component semantic prior guided generative adversarial network;CSPGAN;semantic probability maps;generative network;discriminative network;semantic category;face SR methods;natural texture generation;affine transformation;gradient loss;high-frequency detail recovery;photorealistic texture reconstruction;face super-resolved images;human perception","","7","","61","OAPA","10 Jun 2019","","","IEEE","IEEE Journals"
"License Plate Image Analysis Empowered by Generative Adversarial Neural Networks (GANs)","I. H. El-Shal; O. M. Fahmy; M. A. Elattar","Informatics Sciences Center, School of Information Technology and Computer Science, Nile University, Giza, Egypt; Electrical Engineering Department, South Ural State University, Chelyabinsk, Russia; Informatics Sciences Center, School of Information Technology and Computer Science, Nile University, Giza, Egypt","IEEE Access","24 Mar 2022","2022","10","","30846","30857","Although the majority of existing License Plate (LP) recognition techniques have significant improvements in accuracy, they are still limited to ideal situations in which training data is correctly annotated with restricted scenarios. Moreover, images or videos are frequently used in monitoring systems that have Low Resolution (LR) quality. In this work, the problem of LP detection in digital images is addressed in the images of a naturalistic environment. Single-stage character segmentation and recognition are combined with adversarial Super-Resolution (SR) approaches to improve the quality of the LP by processing the LR images into High-Resolution (HR) images. This work proposes effective changes to the SRGAN network regarding the number of layers, an activation function, and the appropriate loss regularization using Total Variation (TV) loss. The main paper contribution can be summarized into presenting an end-to-end deep learning framework based on generative adversarial networks (GAN), which is able to generate realistic super-resolution images. Also, proposed adding a TV regularization to the loss function to help the model enhance the resolution of images. The proposed SRGAN can handle tiny  $72\times 72$  images of LPs. The paper explores how SRGAN performed over different datasets from many aspects, such as visual analysis, PSNR, SSIM, and Optical Character Recognition (OCR). The experiments demonstrate that the suggested SRGAN can generate high-resolution images that improve the accuracy of the license plate recognition stage compared to other systems.","2169-3536","","10.1109/ACCESS.2022.3157714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729829","Computer vision;deep learning;generative adversarial networks;image reconstruction;license plate recognition;single image super-resolution;total variation loss","Image edge detection;Computer vision;Generative adversarial networks;Feature extraction;Image color analysis;Superresolution;Optical character recognition software;License plate recognition","feature extraction;image classification;image resolution;image segmentation;neural nets;optical character recognition;traffic engineering computing","License Plate image analysis;generative adversarial neural networks;GAN;License Plate recognition techniques;training data;monitoring systems;Low Resolution quality;digital images;naturalistic environment;adversarial Super-Resolution;LR images;high-resolution images;SRGAN network;activation function;appropriate loss regularization;Total Variation loss;end-to-end deep learning framework;super-resolution images;TV regularization;loss function;visual analysis;Optical Character Recognition","","2","","58","CCBY","8 Mar 2022","","","IEEE","IEEE Journals"
"Multi Scale-Adaptive Super-Resolution Person Re-Identification Using GAN","M. Adil; S. Mamoon; A. Zakir; M. A. Manzoor; Z. Lian","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Information Science and Technology, East China University of Science and Technology, Shanghai, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Access","6 Oct 2020","2020","8","","177351","177362","In real-world surveillance systems, the person images captured by the camera network consists of various low-resolution (LR) images. It creates a resolution mismatching problem when compared against high-resolution images of a targeted person. It significantly affects the performance of person re-Identification. This problem is known as Low-Resolution Person re-identification (LR PREID). An efficient strategy would be to exploit image super-resolution (SR) with person re-identification as a mutual learning approach. In this paper, we propose a novel method MSA-SR-PREID to solve this problem. The model takes low-resolution images on different resolutions and resized them to pre-defined fixed resolution. The design of the super-resolution network consists of ESRGAN and the de-Noising module to generate super-resolution images. The SR images are later passed to the re-identification network to learn the unique descriptors to recognize a person identity. The performance of this model is evaluated on four competitive benchmarks, MLR-VIPeR, MLR-DukeMTMC-reID, VR-MSMT17, and VR-Market1501. The comparison with similar state-of-the-art demonstrates the superiority of our model.","2169-3536","","10.1109/ACCESS.2020.3023594","Fundamental Research Funds for the Central Universities(grant numbers:30919011401,30919011231); China Postdoctoral Science Foundation(grant numbers:2015M581800); National Key Research and Development Program of China(grant numbers:2016YFF0103604); Visiting Scholar Foundation of Key Laboratory of Biorheological Science and Technology, Ministry of Education, Chongqing University(grant numbers:CQKLBST-2018-011); Foundation of Shandong Provincial Key Laboratory of Digital Medicine and Computer Assisted Surgery(grant numbers:SDKL-DMCAS-2018-04); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195535","Person re-identification;low-resolution person re-identification;super-resolution;image de-noising","Image resolution;Feature extraction;Gallium nitride;Generative adversarial networks;Surveillance;Cameras;Noise reduction","image denoising;image resolution;learning (artificial intelligence);neural nets","super-resolution network;super-resolution images;SR images;re-identification network;person identity;person images;low-resolution images;resolution mismatching problem;high-resolution images;targeted person;low-resolution person reidentification;image super-resolution;fixed resolution;multiscale-adaptive super-resolution person reidentification;denoising module;MSA-SR-PREID;GAN","","10","","78","CCBYNCND","14 Sep 2020","","","IEEE","IEEE Journals"
"A Super-Resolution Generative Adversarial Network with Simplified Gradient Penalty and Relativistic Discriminator","H. Yu; H. Sa; D. Zou; J. Mao; W. Sheng","School of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; Junku (Shanghai) Informa tion Technology Co., Ltd., Shanghai, China; School of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; School of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; Department of Computer Science, Hangzhou Normal Uni., Hangzhou, China","2019 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2019","2019","","","1","8","Generative Adversarial Network (GAN) has been employed for single image super-resolution (SISR). However, unregularized GAN is difficult for training. This is due gradient descent based GAN optimization is not easy to convergence, thus limiting its performance for image super-resolution. In this paper, a relativistic super-resolution GAN with a simplified gradient penalty (RSRGAN-GP) is proposed for single image super-resolution. In the proposed method, a compact residual network optimized by removing Batch-Normalization layers is employed as the generator to estimate photo-realistic images of 4× upscaling. Further, we introduce a residual network, which also has no Batch-Normalization layers as the conditional discriminator and adopt a simplified gradient regularization to penalize it for stabilizing the super-resolution GAN training, thus guaranteeing high-quality image reconstruction. Additionally, the super-resolution GAN is enhanced with a relativistic discriminator, which produces sharp and rich-detail images at no extra computational cost. The results on benchmark datasets show that our proposed method can effectively improve the visual quality of super-resolved images and achieves competitive performance compared with related works.","2161-4407","978-1-7281-1985-4","10.1109/IJCNN.2019.8852251","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852251","Super-Resolution;Generative Adversarial Network;Residual Network;Relativistic Discriminator;Gradient Penalty","Generative adversarial networks;Gallium nitride;Training;Generators;Feature extraction","gradient methods;image reconstruction;image representation;image resolution;learning (artificial intelligence);optimisation;realistic images","simplified gradient penalty;relativistic discriminator;single image super-resolution;unregularized GAN;gradient descent;GAN optimization;compact residual network;photo-realistic images;simplified gradient regularization;high-quality image reconstruction;super-resolution generative adversarial network;super-resolution GAN","","2","","30","IEEE","30 Sep 2019","","","IEEE","IEEE Conferences"
"Research Progress on Generative Adversarial Network with its Applications","Z. Zhang","National Space Science Center, Chinese Academy of Sciences NO. 1 Nanertiao, Zhongguancun, Haidian District, Beijing, P.R. China","2020 IEEE 5th Information Technology and Mechatronics Engineering Conference (ITOEC)","16 Jul 2020","2020","","","396","399","As a new unsupervised learning algorithm framework, generative adversarial networks(GAN) have been favored by more and more researchers, and it has become a research hotspot now. GAN is inspired by the two-person zero-sum game theory in game theory. Its unique adversarial training idea can generate high-quality samples and has more powerful feature learning and feature expression capabilities than traditional machine learning algorithms. At present, GAN has achieved remarkable success in the field of computer vision, especially in the field of sample generation. Every year, a large number of GAN-related research papers are produced, reflecting the fiery degree of research on GAN model. Aiming at the hot model of GAN, first introduce the research status of GAN; then introduce the theory and framework of GAN, which analyzes in detail why the gradient disappears and the mode collapses during the training of GAN; then discussed some typical GAN improvement models, and summarized their theoretical improvements, advantages, limitations, application scenarios and implementation costs; Finally, the application results of GAN in data generation, image super-resolution, and image style conversion are shown, and the current challenges and future research directions of GAN are discussed.","","978-1-7281-4323-1","10.1109/ITOEC49072.2020.9141685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141685","machine learning;unsupervised learning;generative adversarial networks","Training;Representation learning;Analytical models;Mechatronics;Computational modeling;Superresolution;Generative adversarial networks","computer vision;game theory;image resolution;neural nets;unsupervised learning","research hotspot;two-person zero-sum game theory;unique adversarial training idea;feature expression capabilities;sample generation;GAN-related research papers;GAN model;research status;generative adversarial network;unsupervised learning algorithm framework;GAN improvement models;feature learning","","","","10","IEEE","16 Jul 2020","","","IEEE","IEEE Conferences"
"Enhanced generative adversarial network for 3D brain MRI super-resolution","J. Wang; Y. Chen; Y. Wu; J. Shi; J. Gee","Penn Image Computing and Science Laboratory, University of Pennsylvania, Philadelphia, PA, USA; Department of Bioengineering, University of California, Los Angeles, CA, USA; Penn Image Computing and Science Laboratory, University of Pennsylvania, Philadelphia, PA, USA; Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA, USA; Penn Image Computing and Science Laboratory, University of Pennsylvania, Philadelphia, PA, USA","2020 IEEE Winter Conference on Applications of Computer Vision (WACV)","14 May 2020","2020","","","3616","3625","Single image super-resolution (SISR) reconstruction for magnetic resonance imaging (MRI) has generated significant interest because of its potential to not only speed up imaging but to improve quantitative processing and analysis of available image data. Generative Adversarial Networks (GAN) have proven to perform well in image recovery tasks. In this work, we followed the GAN framework and developed a generator coupled with discriminator to tackle the task of 3D SISR on T1 brain MRI images. We developed a novel 3D memory-efficient residual-dense block generator (MRDG) that achieves state-of-the-art performance in terms of SSIM (Structural Similarity), PSNR (Peak Signal to Noise Ratio) and NRMSE (Normalized Root Mean Squared Error) metrics. We also designed a pyramid pooling discriminator (PPD) to recover details on different size scales simultaneously. Finally, we introduced model blending, a simple and computational efficient method to balance between image and texture quality in the final output, to the task of SISR on 3D images.","2642-9381","978-1-7281-6553-0","10.1109/WACV45572.2020.9093603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093603","","Three-dimensional displays;Gallium nitride;Training;Generative adversarial networks;Spatial resolution;Magnetic resonance imaging","biomedical MRI;brain;image reconstruction;image resolution;mean square error methods;medical image processing","pyramid pooling discriminator;texture quality;3D brain MRI super-resolution;single image super-resolution reconstruction;magnetic resonance imaging;generative adversarial networks;image recovery tasks;GAN framework;brain MRI images;3D memory-efficient residual-dense block generator","","19","","40","IEEE","14 May 2020","","","IEEE","IEEE Conferences"
"Details or Artifacts: A Locally Discriminative Learning Approach to Realistic Image Super-Resolution","J. Liang; H. Zeng; L. Zhang",The HongKong Polytechnic University; OPPO Research; The HongKong Polytechnic University,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","5647","5656","Single image super-resolution (SISR) with generative adversarial networks (GAN) has recently attracted increasing attention due to its potentials to generate rich details. However, the training of GAN is unstable, and it often introduces many perceptually unpleasant artifacts along with the generated details. In this paper, we demonstrate that it is possible to train a GAN-based SISR model which can stably generate perceptually realistic details while inhibiting visual artifacts. Based on the observation that the local statistics (e.g., residual variance) of artifact areas are often different from the areas of perceptually friendly details, we develop a framework to discriminate between GAN-generated artifacts and realistic details, and consequently generate an artifact map to regularize and stabilize the model training process. Our proposed locally discriminative learning (LDL) method is simple yet effective, which can be easily plugged in off-the-shelf SISR methods and boost their performance. Experiments demonstrate that LDL outperforms the state-of-the-art GAN based SISR methods, achieving not only higher reconstruction accuracy but also superior perceptual quality on both synthetic and real-world datasets. Codes and models are available at https://github.com/csjliang/LDL.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.00557","RGC RIF(grant numbers:R5001-18); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9878447","Low-level vision","Training;Visualization;Computer vision;Codes;Computational modeling;Superresolution;Generative adversarial networks","image reconstruction;image resolution;learning (artificial intelligence)","locally discriminative learning approach;realistic image super-resolution;single image super-resolution;generative adversarial networks;rich details;perceptually unpleasant artifacts;generated details;GAN-based SISR model;perceptually realistic details;visual artifacts;local statistics;residual variance;artifact areas;perceptually friendly details;GAN-generated artifacts;artifact map;model training process;locally discriminative learning method;off-the-shelf SISR methods;state-of-the-art GAN;superior perceptual quality","","1","","48","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Super-Resolution of Sea Surface Temperature Satellite Images","D. Lambhate; D. N. Subramani","Indian Institute of Science,Dept. of Computational and Data Sciences,Bangalore,India,560 012; Indian Institute of Science,Dept. of Computational and Data Sciences,Bangalore,India,560 012","Global Oceans 2020: Singapore – U.S. Gulf Coast","9 Apr 2021","2020","","","1","7","Availability of high-resolution maps of geophysical fields, devoid of data loss due to clouds, is an urgent requirement for operational forecasting. We develop a Bayesian algorithm for super-resolution (or downscaling) of lower resolution geophysical fields observed by satellites. The key novelty in the present algorithm is the development and use of a Generative Adversarial Network (GAN) to learn the prior probability distribution of the high-resolution geophysical fields from historical data and/or model forecasts. The trained GAN is used to sample from the high-resolution prior and a particle filter along with the low-resolution data (as observation) is used to obtain the posterior high-resolution geophysical field. The resultant algorithm has been named the Particle Filter Generative Adversarial Network super-resolution (PF-GAN-SR) algorithm. The new algorithm is applied to downscale sea surface temperature fields in the northwest Atlantic Ocean. Results show consistent performance across different downscaling ratios. Notably, the high-resolution fields obtained from the new algorithm has better similarity score with the true high-resolution field compared to those from bi-cubic interpolation (commonly used in the geophysical community) and the SR-GAN algorithm (used in the computer vision community).","0197-7385","978-1-7281-5446-6","10.1109/IEEECONF38699.2020.9389030","MHRD; IISc; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9389030","Downscaling;PF-GAN-SR;particle filter;Generative Adversarial Network","Sea surface;Satellites;Superresolution;Generative adversarial networks;Particle filters;Gallium nitride;Ocean temperature","geophysical image processing;image resolution;ocean temperature","low-resolution data;posterior high-resolution geophysical field;resultant algorithm;Particle Filter Generative Adversarial Network super-resolution algorithm;downscale sea surface temperature fields;high-resolution field;geophysical community;SR-GAN algorithm;sea surface temperature satellite images;high-resolution maps;data loss;Bayesian algorithm;lower resolution geophysical fields;high-resolution geophysical fields;historical data;model forecasts;northwest Atlantic Ocean","","1","","18","IEEE","9 Apr 2021","","","IEEE","IEEE Conferences"
"Nonlinear Multi-scale Super-resolution Using Deep Learning","K. Tran; A. Panahi; A. Adiga; W. Sakla; H. Krim","Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC; Computational Engineering Division, Lawrence Livermore National Laboratory, Livermore, CA; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3182","3186","We propose a deep learning architecture capable of performing up to 8× single image super-resolution. Our architecture incorporates an adversarial component from the super-resolution generative adversarial networks (SRGANs) and a multi-scale learning component from the multiple scale super-resolution network (MSSRNet), which only together can recover smaller structures inherent in satellite images. To further enhance our performance, we integrate progressive growing and training to our network. This, aided by feed forwarding connections in the network to move along and enrich information from previous inputs, produces super-resolved images at scaling factors of 2, 4, and 8. To ensure and enhance the stability of GANs, we employ Wasserstein GANs (WGANs) during training. Experimentally, we find that our architecture can recover small objects in satellite images during super-resolution whereas previous methods cannot.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682354","super-resolution;remote sensing data;GANs;dilated convolutions","Spatial resolution;Satellites;Training;Signal resolution;Convolution;Gallium nitride","geophysical image processing;image resolution;learning (artificial intelligence);neural nets","deep learning architecture;multiscale learning component;satellite images;single image superresolution;nonlinear multiscale superresolution;superresolution generative adversarial networks;multiple scale superresolution network;Wasserstein GANs","","2","","25","IEEE","17 Apr 2019","","","IEEE","IEEE Conferences"
"A Small Object Detection Solution by Using Super- Resolution Recovery","C. Xing; X. Liang; Z. Bao","College of Information Engineering & Art Design, Zhejiang University of Water Resources and Electric Power, Hangzhou, China; College of Information Engineering & Art Design, Zhejiang University of Water Resources and Electric Power, Hangzhou, China; College of Information Engineering & Art Design, Zhejiang University of Water Resources and Electric Power, Hangzhou, China","2019 IEEE 7th International Conference on Computer Science and Network Technology (ICCSNT)","20 Jan 2020","2019","","","313","316","Small object detection is the key challenge to aerial image object detection. Small objects in aerial images are usually too fuzzy to detect. This paper proposes a solution by using Generative Adversarial Network to recover small objects' low-resolution image to high-resolution to get better detection performance. Experiment result shows this solution achieves mAP 68.38% and missing rate 14.23%.","","978-1-7281-3299-0","10.1109/ICCSNT47585.2019.8962422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8962422","small object detection;super-resolution recovery;aerial image;UAV","Object detection;Generative adversarial networks;Generators;Filtering algorithms;Convolution","image resolution;neural nets;object detection","aerial image object detection;low-resolution image;detection performance;small object detection solution;generative adversarial network;superresolution recovery","","3","","17","IEEE","20 Jan 2020","","","IEEE","IEEE Conferences"
"Synthesis of 3D MRI Brain Images With Shape and Texture Generative Adversarial Deep Neural Networks","C. K. Chong; E. T. W. Ho","Department of Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia; Department of Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia","IEEE Access","3 May 2021","2021","9","","64747","64760","Generative Adversarial Networks (GAN) are emerging as an exciting training paradigm which promises a step improvement to the impressive feature learning capabilities of deep neural networks. Unlike supervised learning approaches, GAN learns generalizable features without requiring labeled images to achieve new capabilities like distinguishing previously unseen anomalies, creating novel instances of data and factorizing learned features into explainable dimensions in fully unsupervised fashion. The advanced feature learning property of GAN will enable the next generation of computational image understanding tasks. However, GAN models are difficult to train to converge towards good models, especially for high resolution and high dimensional datasets like image volumes. We develop a GAN approach to learn a generative model of T1-contrast 3D MRI image volumes of the healthy human brain by training on 1112 MRI images from the Human Connectome Project. Our method utilizes a first unconditional Super-Resolution GAN, dubbed the shape network, to learn the 3D shape variations in adult brains and a second conditional pix2pix GAN, dubbed the texture network, to upgrade image slices with realistic local contrast patterns. Novel 3D MRI images are synthesized by first applying the 3D voxel-wise deformation map which is generated from the shape network to deform the Montreal Neurological Institute (MNI) brain template and subsequently performing style transfer on axial-wise slices using the texture network. The Maximum Mean Discrepancy (MMD) and Multi-scale Structural Similarity Index Measure (MS-SSIM) scores of MRI image volumes synthesized using our GAN approach are competitive with state-of-art GAN methods. Our work establishes the feasibility of an alternative approach to high-dimensional GAN learning - splitting the type of information content learned among several GANs can be an effective form of regularization and complementary to latent code shaping or super-resolution approaches in state-of-the-art methods.","2169-3536","","10.1109/ACCESS.2021.3075608","Ministry of Higher Education, Malaysia, under the Higher Institution Center of Excellence (HI-CoE) program awarded to the Center for Intelligent Signal and Imaging Research (CISIR) at Universiti Teknologi Petronas; Yayasan Universiti Teknologi Petronas (YUTP)(grant numbers:015LC0-173); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9416434","Generative adversarial networks;MRI brain images;brain morphometry;deep neural networks;computational brain anatomy","Generative adversarial networks;Brain modeling;Magnetic resonance imaging;Training;Three-dimensional displays;Biological neural networks;Task analysis","biomedical MRI;brain;feature extraction;image resolution;image segmentation;image texture;learning (artificial intelligence);medical image processing;neural nets;neurophysiology","generative adversarial networks;exciting training paradigm;impressive feature;supervised learning approaches;generalizable features;factorizing learned features;advanced feature learning property;computational image understanding tasks;GAN models;high dimensional datasets;GAN approach;T1-contrast 3D;MRI image volumes;healthy human brain;MRI images;human connectome project;shape network;adult brains;texture network;image slices;novel 3D MRI images;Montreal Neurological Institute brain template;state-of-art GAN methods;latent code shaping;superresolution approaches;high-dimensional GAN learning-splitting;unconditional superresolution GAN;texture generative adversarial deep neural networks","","13","","74","CCBYNCND","26 Apr 2021","","","IEEE","IEEE Journals"
"Improving 3D Recovery based on Super-Resolution Generative Adversarial Network and Uniform Continuous Trajectory for Atomic Force Microscopy","K. -W. Huang; H. -C. Chen; S. -A. Lee; L. -C. Fu","Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan","2021 American Control Conference (ACC)","28 Jul 2021","2021","","","2601","2606","Atomic force microscope (AFM) is a powerful nano-scale measurement instrument, which is diffusely applied on different fields, such as biological science, nanomanipulation, semiconductor, Micro Electro Mechanical Systems (MEMS) detection, etc. The well-known advantage of AFM is its high-accuracy 3D topography reconstruction. Different from optical microscopy, which can only obtain 2D image by optical reflection, three kinds of operating principles of AFM respectively maintaining the contact force, amplitude or distance between the tip and sample surface during scanning to collect the sample's height information, and then help us to build a 3D sample topography. However, because of the physical contact with probe, there is a major problem in AFM - imaging speed. In this paper, we propose a new method which applies the Generative Adversarial Networks (GAN) to AFM image reconstruction, which can recover a high-resolution (HR) image from a low-resolution (LR) one with only a quarter of time. While using GAN, data uniformity is most crucial. To address this issue, we propose a new trajectory - Uniform continuous path (UC path) to break the limits on traditional raster scanning and a proposed feature similarity metric is used on comparing the reconstruction results in experiments.","2378-5861","978-1-6654-4197-1","10.23919/ACC50511.2021.9483059","Ministry of Science and Technology of Taiwan(grant numbers:109-2634-F-002-027-,109-2634-F-002-040-,109-2634-F-002-041); National Taiwan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9483059","","Atomic force microscopy;Three-dimensional displays;Optical microscopy;Force;Nonlinear distortion;Generative adversarial networks;Trajectory","atomic force microscopy;image reconstruction;image resolution;optical microscopy","powerful nanoscale measurement instrument;biological science;MicroElectro Mechanical Systems detection;high-accuracy 3D topography reconstruction;optical microscopy;optical reflection;contact force;sample surface;3D sample topography;physical contact;Generative Adversarial Networks;AFM image reconstruction;high-resolution image;data uniformity;continuous path;improving 3D recovery;super-resolution Generative Adversarial network;Uniform continuous trajectory;atomic force microscopy;atomic force microscope","","1","","23","","28 Jul 2021","","","IEEE","IEEE Conferences"
"Enhancing the Resolution of Satellite Imagery Using a Generative Model","M. Tayba; P. Rivas","Department of Computer Science, School of Engineering and Computer Science, Baylor University; Department of Computer Science, School of Engineering and Computer Science, Baylor University","2021 International Conference on Computational Science and Computational Intelligence (CSCI)","22 Jun 2022","2021","","","20","25","Recent breakthroughs in deep learning algorithms introduced the image super-resolution technique that maps the low-resolution image to generate a high-resolution image. These techniques increase various surveillance applications by providing finer spatial details than data from original sensors. Satellite images obtained from Moderate Resolution Imaging Spectroradiometer (MODIS) observation offer essential information about the earth’s landscape, ocean, and ecosystem, contributing to monitoring various applications in the scientific field. The spatial resolution of satellite images has a significant impact on image accuracy. This paper focuses on improving image resolution by training a convolutional neural network to produce super-resolution images from low-resolution images. We present an implementation of Super Resolution Generative Adversarial Network (SRGAN), a GAN-based approach that uses a perceptual loss function that includes an adversarial loss and a content loss. Using a discriminator network that is designed for discerning between super-resolved images and original photo-realistic images, the adversarial loss drives the solution of this architecture to natural images. Moreover, the content loss is driven by perceptual similarity rather than pixel space similarity. We used this architecture to satellite images collected from NASA MODIS devices and found satisfactory results. Our key finding is that our system’s result can now be used to improve a variety of low-resolution images.","","978-1-6654-5841-2","10.1109/CSCI54926.2021.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799082","image resolution;GAN;satellite image;deep neural network;super resolution","Training;Satellites;Surveillance;Superresolution;Generative adversarial networks;Spatial databases;Sensors","convolutional neural nets;deep learning (artificial intelligence);image enhancement;image resolution;radiometers","spatial resolution;satellite images;image accuracy;image resolution;super-resolution images;low-resolution image;super resolution generative adversarial network;adversarial loss;super-resolved images;original photo-realistic images;natural images;image super-resolution technique;high-resolution image;moderate resolution imaging spectroradiometer observation;generative model;deep learning algorithms;MODIS observation;convolutional neural network;GAN-based approach;perceptual loss function;discriminator network;perceptual similarity;NASA MODIS devices","","","","23","IEEE","22 Jun 2022","","","IEEE","IEEE Conferences"
"Part-Based Enhanced Super Resolution Network for Low-Resolution Person Re-Identification","Y. Ha; J. Tian; Q. Miao; Q. Yang; J. Guo; R. Jiang","Key Laboratory on High Trusted Information System in Hebei Province, School of Cyber Security and Computer, Hebei University, Baoding, China; Key Laboratory on High Trusted Information System in Hebei Province, School of Cyber Security and Computer, Hebei University, Baoding, China; School of Cyber Security and Computer, Hebei University, Baoding, China; School of Cyber Security and Computer, Hebei University, Baoding, China; School of Cyber Security and Computer, Hebei University, Baoding, China; School of Cyber Security and Computer, Hebei University, Baoding, China","IEEE Access","31 Mar 2020","2020","8","","57594","57605","Person re-identification (REID) is an important task in video surveillance and forensics applications. Many previous works often build models on the assumption that they have same resolution cross different camera views, while it is divorced from reality. To increase the adaptability of person REID models, this paper focuses on the low-resolution person REID task to relax the impractical assumption when traditional low-resolution person REID models are under pixel-to-pixel supervision in low and high resolution pedestrian image pairs. In addition, they are easily influenced by the global background, illumination or pose variations across camera views. Therefore, we propose a Part-based Enhanced Super Resolution (PESR) network by employing a part division strategy and an enhanced generative adversarial network to boost the unpaired pedestrian image super resolution process. Specifically, the part-based super resolution network transforms low resolution image in probe into high resolution without any pixel-to-pixel supervision and the part-based synthetic feature extractor module can learn discriminative pedestrian feature representation for the generated high resolution images, which employ a part feature connection loss as constraint to conduct matching for person re-identification. Furthermore, evaluations on four public person REID datasets demonstrate the advantages of our method over the state-of-the-art ones.","2169-3536","","10.1109/ACCESS.2020.2971612","Natural Science Foundation of Hebei Province(grant numbers:F2016201244); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8984370","Low-resolution person re-identification;enhanced super resolution;part based;realistic discriminator","Image resolution;Task analysis;Feature extraction;Cameras;Generative adversarial networks;Adaptation models;Lighting","feature extraction;image classification;image recognition;image representation;image resolution;learning (artificial intelligence);object detection;pedestrians;video surveillance","low-resolution person re-identification;video surveillance;forensics applications;low-resolution person REID task;impractical assumption;low-resolution person REID models;pixel-to-pixel supervision;part division strategy;enhanced generative adversarial network;unpaired pedestrian image super resolution process;part-based super resolution network;low resolution image;part-based synthetic feature extractor module;discriminative pedestrian feature representation;generated high resolution images;public person REID;part-based enhanced super resolution network","","4","","47","CCBY","5 Feb 2020","","","IEEE","IEEE Journals"
"SWCGAN: Generative Adversarial Network Combining Swin Transformer and CNN for Remote Sensing Image Super-Resolution","J. Tu; G. Mei; Z. Ma; F. Piccialli","School of Engineering and Technology, China University of Geosciences, Beijing, China; School of Engineering and Technology, China University of Geosciences, Beijing, China; School of Engineering and Technology, China University of Geosciences, Beijing, China; Department of Mathematics and Applications “R. Caccioppoli”, University of Naples Federico II, Napoli, Italy","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","27 Jul 2022","2022","15","","5662","5673","Easy and efficient acquisition of high-resolution remote sensing images is of importance in geographic information systems. Previously, deep neural networks composed of convolutional layers have achieved impressive progress in super-resolution reconstruction. However, the inherent problems of the convolutional layer, including the difficulty of modeling the long-range dependency, limit the performance of these networks on super-resolution reconstruction. To address the abovementioned problems, we propose a generative adversarial network (GAN) by combining the advantages of the swin transformer and convolutional layers, called SWCGAN. It is different from the previous super-resolution models, which are composed of pure convolutional blocks. The essential idea behind the proposed method is to generate high-resolution images by a generator network with a hybrid of convolutional and swin transformer layers and then to use a pure swin transformer discriminator network for adversarial training. In the proposed method, first, we employ a convolutional layer for shallow feature extraction that can be adapted to flexible input sizes; second, we further propose the residual dense swin transformer block to extract deep features for upsampling to generate high-resolution images; and third, we use a simplified swin transformer as the discriminator for adversarial training. To evaluate the performance of the proposed method, we compare the proposed method with other state-of-the-art methods by utilizing the UCMerced benchmark dataset, and we apply the proposed method to real-world remote sensing images. The results demonstrate that the reconstruction performance of the proposed method outperforms other state-of-the-art methods in most metrics.","2151-1535","","10.1109/JSTARS.2022.3190322","National Natural Science Foundation of China(grant numbers:11602235); Fundamental Research Funds for China Central Universities(grant numbers:2652021053); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9829280","Convolutional layers;generative adversarial network (GAN);remote sensing images;super-resolution reconstruction;swin transformer","Feature extraction;Superresolution;Transformers;Remote sensing;Image reconstruction;Generative adversarial networks;Task analysis","convolution;feature extraction;geographic information systems;geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);neural nets;remote sensing;unsupervised learning","real-world remote sensing images;simplified swin transformer;residual dense swin transformer block;adversarial training;pure swin transformer discriminator network;transformer layers;generator network;high-resolution images;pure convolutional blocks;previous super-resolution models;super-resolution reconstruction;convolutional layer;deep neural networks;high-resolution remote sensing images;efficient acquisition;easy acquisition;remote sensing image super-resolution;generative adversarial network combining swin transformer","","3","","44","CCBYNCND","13 Jul 2022","","","IEEE","IEEE Journals"
"Image Super-Resolution Reconstruction Based on Big Data and Cloud Computing","H. -A. Li; D. Wang; Z. Li; T. Ma","College of Computer Science and Technology, Xi’an University of Science and Technology, Xi’an, China; College of Computer Science and Technology, Xi’an University of Science and Technology, Xi’an, China; College of Computer Science and Technology, Xi’an University of Science and Technology, Xi’an, China; College of Computer Science and Technology, Xi’an University of Science and Technology, Xi’an, China","2022 IEEE 7th International Conference on Smart Cloud (SmartCloud)","14 Nov 2022","2022","","","177","183","Image super-resolution reconstruction can reconstruct low-resolution images into high-resolution images, which is an important application of big data combined with cloud computing. Using big data technology can mine the useful information of a large number of images, and cloud computing can reduce the model computation. However, existing super-resolution models are difficult to train and have problems such as artifacts, blurred detail texture and too smooth after image reconstruction. To solve the above problems, we propose the Multi-scale double Attention mechanism based on Residual Dense Generative Adversarial Network (MARDGAN), which uses multi-branch paths to extract image features of different scale sizes, to obtain multi-scale features information. We also design the double attention mechanism block (CSAB) and combine it with the Enhanced Residual Dense Block (ERDB) to form the deep residual dense attention module (DRDAM) to extract multi-level depth feature information. The perceptual capability of the model is improved by adding pixel loss, perceptual loss, and adversarial loss. The experimental results show that our proposed MARDGAN has shorter training time. And it can use the original image information more effectively than other methods on multiple benchmark datasets to recover super-resolution images with clearer details and better realism.","","978-1-6654-5179-6","10.1109/SmartCloud55982.2022.00035","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9944823","Big data;Cloud computing;Super-resolution reconstruction;Generative adversarial network;Feature extraction","Training;Cloud computing;Computational modeling;Superresolution;Big Data;Feature extraction;Generative adversarial networks","cloud computing;feature extraction;image reconstruction;image resolution","big data technology;cloud computing;deep residual dense attention module;double attention mechanism block;Enhanced Residual Dense Block;existing super-resolution models;high-resolution images;image features;image reconstruction;image super-resolution reconstruction;low-resolution images;model computation;multilevel depth feature information;Multiscale double Attention mechanism;multiscale features information;original image information;Residual Dense Generative Adversarial Network;super-resolution images","","","","47","IEEE","14 Nov 2022","","","IEEE","IEEE Conferences"
"Enhanced style transfer with colorization and super-resolution","L. JinKua; Y. ChenXiang; H. B. Abdalla","Department of computer science, Wenzhou-Kean University, Wenzhou, China; Department of computer science, Wenzhou-Kean University, Wenzhou, China; Department of computer science, Wenzhou-Kean University, Wenzhou, China","2022 7th International Conference on Communication, Image and Signal Processing (CCISP)","19 Dec 2022","2022","","","166","172","Style transfer is a novel and successful technology in the field of computer vision which allow people to create art pieces without training. This research has combined style transfer, colorization, and super-resolution algorithm to create a method to create art pieces from the black-white image as content and sketch art pieces as style with high resolution. This method could significantly lower the demand for art creation and allow people with little artistic skill to create desired artwork. Moreover, this research compares the impact of the different parameters in style transfer and the influence of the colorization in different processing stages resulting that colorizing the content image before style transfer would create a single style image that is more controllable but colorizing the generated image after style transfer would result in a more unpredictable multi-style image which depends on the training dataset of the image and the ratio of the weight in style transfer.","","978-1-6654-5959-4","10.1109/CCISP55629.2022.9974475","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974475","Style transfer;Image Colorization;Super Resolution;Generative Adversarial Networks;Convolutional Neural Network","Training;Computer vision;Art;Image color analysis;Superresolution;Neural networks;Signal processing algorithms","art;computer vision;image colour analysis;image resolution","art pieces;black-white image;computer vision;content image colorization;enhanced style transfer;single style image;superresolution algorithm;unpredictable multistyle image","","","","20","IEEE","19 Dec 2022","","","IEEE","IEEE Conferences"
"Joint Super-Resolution and Head Pose Estimation for Extreme Low-Resolution Faces","S. R. Malakshan; M. S. E. Saadabadi; M. Mostofa; S. Soleymani; N. M. Nasrabadi","Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA","IEEE Access","7 Feb 2023","2023","11","","11238","11253","State-of-the-art deep learning-based Head Pose Estimation (HPE) techniques have reached spectacular performance on High-Resolution (HR) face images. However, they still fail to achieve expected performance on low-resolution images at large scales. This work presents an end-to-end HPE framework assisted by a Face Super-Resolution (FSR) algorithm. The proposed FSR model is specifically guided to enhance the HPE performance rather than considering FSR as an independent task. To this end, we utilized a Multi-Stage Generative Adversarial Network (MSGAN) which benefit from a pose-aware adversarial loss and head pose estimation feedback to generate super-resolved images that are properly aligned for HPE. Also, we propose a degradation strategy rather than simple down-sampling approach to mimic the diverse properties of real-world Low-Resolution (LR) images. We evaluate the performance of our proposed method on both synthetic and real-world LR datasets and show the superiority of our approach in both visual and HPE metrics on the AFLW2000, BIWI, and WiderFace Datasets.","2169-3536","","10.1109/ACCESS.2023.3241606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10034761","Head pose estimation (HPE);face super-resolution (FSR);multi-stage generative adversarial networks (MSGAN);low-resolution (LR) face images","Face recognition;Task analysis;Generators;Pose estimation;Generative adversarial networks;Adaptation models","","","","","","95","CCBYNCND","1 Feb 2023","","","IEEE","IEEE Journals"
"Spectral–Spatial Generative Adversarial Network for Super-Resolution Land Cover Mapping With Multispectral Remotely Sensed Imagery","C. Shang; S. Jiang; F. Ling; X. Li; Y. Zhou; Y. Du","School of Geosciences, Yangtze University, Wuhan, China; School of Geosciences, Yangtze University, Wuhan, China; Key laboratory of Monitoring and Estimate for Environment and Disaster of Hubei province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key laboratory of Monitoring and Estimate for Environment and Disaster of Hubei province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key laboratory of Monitoring and Estimate for Environment and Disaster of Hubei province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key laboratory of Monitoring and Estimate for Environment and Disaster of Hubei province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","22 Dec 2022","2023","16","","522","537","Super-resolution mapping (SRM) can effectively predict the spatial distribution of land cover classes within mixed pixels at a higher spatial resolution than the original remotely sensed imagery. The uncertainty of land cover fraction errors within mixed pixels is one of the most important factors affecting SRM accuracy. Studies have shown that SRM methods using deep learning techniques have significantly improved land cover mapping accuracy but have not coped well with spectral–spatial errors. This study proposes an end-to-end SRM model using a spectral–spatial generative adversarial network (SGS) with the direct input of multispectral remotely sensed imagery, which deals with spectral–spatial error. The proposed SGS comprises the following three parts: first, cube-based convolution for spectral unmixing is adopted to generate land cover fraction images. Second, a residual-in-residual dense block fully and jointly considers spectral and spatial information and reduces spectral errors. Third, a relativistic average GAN is designed as a backbone to further improve the super-resolution performance and reduce spectral–spatial errors. SGS was tested in one synthetic and two realistic experiments with multi/hyperspectral remotely sensed imagery as the input, comparing the results with those of hard classification and several classic SRM methods. The results showed that SGS performed well at reducing land cover fraction errors, reconstructing spatial details, removing unpleasant and unrealistic land cover artifacts, and eliminating false recognition.","2151-1535","","10.1109/JSTARS.2022.3228741","Natural Science Foundation of Hubei Province(grant numbers:2022CFB689); National Natural Science Foundation of China(grant numbers:U22A20567); National Natural Science Foundation of China(grant numbers:62071457); Key Scientific Research Projects of Water Conservancy in Hubei Province, China(grant numbers:HBSLKY202103); Application Foundation Frontier Project of Wuhan(grant numbers:2020020601012283); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9982425","Deep learning (DL);generative adversarial network (GAN);land cover fractions;spectral–spatial errors;super-resolution mapping (SRM)","Generative adversarial networks;Superresolution;Spatial resolution;Layout;Remote sensing;Graphical models;Distribution functions","geophysical image processing;image classification;image reconstruction;image resolution;land cover;terrain mapping","classic SRM methods;end-to-end SRM model;higher spatial resolution;land cover classes;land cover fraction errors;land cover fraction images;land cover mapping accuracy;mixed pixels;multispectral remotely sensed imagery;original remotely sensed imagery;SGS;spatial distribution;spatial information;spectral errors;spectral information;spectral unmixing;spectral-spatial error;spectral-spatial generative adversarial network;SRM accuracy;super-resolution land cover mapping;super-resolution mapping;super-resolution performance;unpleasant land cover artifacts;unrealistic land cover artifacts","","","","61","CCBY","12 Dec 2022","","","IEEE","IEEE Journals"
"Rectified Wasserstein Generative Adversarial Networks for Perceptual Image Restoration","H. Ma; D. Liu; F. Wu","CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei, Anhui, China; CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei, Anhui, China; CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei, Anhui, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","3 Feb 2023","2023","45","3","3648","3663","Wasserstein generative adversarial network (WGAN) has attracted great attention due to its solid mathematical background, i.e., to minimize the Wasserstein distance between the generated distribution and the distribution of interest. In WGAN, the Wasserstein distance is quantitatively evaluated by the discriminator, also known as the critic. The vanilla WGAN trained the critic with the simple Lipschitz condition, which was later shown less effective for modeling complex distributions, like the distribution of natural images. We try to improve the WGAN training by introducing pairwise constraint on the critic, oriented to image restoration tasks. In principle, pairwise constraint is to suggest the critic assign a higher rating to the original (real) image than to the restored (generated) image, as long as such a pair of images are available. We show that such pairwise constraint may be implemented by rectifying the gradients in WGAN training, which leads to the proposed rectified Wasserstein generative adversarial network (ReWaGAN). In addition, we build interesting connections between ReWaGAN and the perception-distortion tradeoff. We verify ReWaGAN on two representative image restoration tasks: single image super-resolution (4× and 8×) and compression artifact reduction, where our ReWaGAN not only beats the vanilla WGAN consistently, but also outperforms the state-of-the-art perceptual quality-oriented methods significantly. Our code and models are publicly available at https://github.com/mahaichuan/ReWaGAN.","1939-3539","","10.1109/TPAMI.2022.3185316","Natural Science Foundation of China(grant numbers:62036005,62022075,62021001); Fundamental Research Funds for the Central Universities(grant numbers:WK3490000006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9803876","Compression artifact reduction;generative adversarial network (GAN);image restoration;image super-resolution;rectified Wasserstein GAN (ReWaGAN);Wasserstein GAN (WGAN)","Image restoration;Generative adversarial networks;Training;Generators;Task analysis;Measurement;Superresolution","","","","","","62","IEEE","22 Jun 2022","","","IEEE","IEEE Journals"
"Low Resolution Face Recognition System Based on ESRGAN","C. Song; Z. He; Y. Yu; Z. Zhang","Guangdong Ocean University(s), Zhanjiang, Guangdong, China; Guangdong Ocean University(s), Zhanjiang, Guangdong, China; Guangdong Ocean University(s), Zhanjiang, Guangdong, China; Guangdong Ocean University(s), Zhanjiang, Guangdong, China","2021 3rd International Conference on Applied Machine Learning (ICAML)","18 Feb 2022","2021","","","76","79","Low-resolution face recognition is one of the research hotspots of face recognition today. It can be widely used in face recognition in various scenarios, such as identity verification at stations and classroom check-in. The prior art has achieved better performance in ideal scenarios, but detecting low-resolution images will make it difficult to recognize low-resolution human faces, and the accuracy will eventually decrease. This is why improving the accuracy of low-resolution face recognition (LRFR) is still challenging. We have finished the reasearch aim to solve the problem about LRFR. The super-resolution GAN (SRGAN) and enhanced super-resolution GAN (ESRGAN) used in this search. Comparing these methods, we finally obtain a model that can solve the low-precision problem of LRFR. Our system uses super-resolution reconstruction as the preprocessing step of the LRFR problem, and then uses Facenet to recognize the image. These data sets are Wild Face Tag (LFW), YouTube Face Database (YTF), and Wider Face Dataset. The experimental results show that the accuracy of the ESRGAN based on Facenet of the proposed system in the unconstrained natural environment is as high as 98.78%. At the same time, increase the number and speed of face detection, effectively realize the function of multiple face recognition, has practical application value and system robustness.","","978-1-6654-2125-6","10.1109/ICAML54311.2021.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712098","Face detection;Face Recognition;YOLO;Super-resolution reconstruction;ESRGAN","Image recognition;Art;Databases;Face recognition;Superresolution;Machine learning;Generative adversarial networks","face recognition;image reconstruction;image resolution;video signal processing","low-resolution images;low-resolution human faces;low-resolution face recognition;LRFR;super-resolution GAN;ESRGAN;low-precision problem;super-resolution reconstruction;Wild Face Tag;YouTube Face Database;Wider Face Dataset;face detection;multiple face recognition;low resolution Face recognition system;face recognition today","","","","16","IEEE","18 Feb 2022","","","IEEE","IEEE Conferences"
"Variational Autoencoded Compositional Pattern Generative Adversarial Network for Handwritten Super Resolution Image Generation","C. G. Turhan; H. S. Bilge","Computer Engineering Department Faculty of Engineering, Gazi University, Ankara, Turkey; Electric-Electronic Engineering Department Faculty of Engineering, Gazi University, Ankara, Turkey","2018 3rd International Conference on Computer Science and Engineering (UBMK)","9 Dec 2018","2018","","","564","568","Since generative adversarial training has been decleared as one of the most exciting topics of the last 10 years by the pioneers, many researchers have focused on the Generative Adversarial Network (GAN) in their studies. On the otherhand, Variational Autoencoders (VAE) had gain autoencoders' popularity back. Due to some restrictions of GAN models and their lack of inference mechanism, hybrid models of GAN and VAE have emerged for image generation problem in nowadays. With the influence of these views and improvements, we have focused on addressing not only generating synthetic handwritten images but also their high-resolution version. For these tasks, Compositional Pattern Producing Networks (CPPN), VAE and GAN models are combined inspired by an existing model with some modification of its objective function. With this model, the idea behind the inspired study for generating high-resolution images are combined with the feature-wise reconstruction objective of a VAE/GAN hybrid model instead of pixel-like reconstruction approach of traditional VAE. For evaluating the model efficiency, our VAE/CPGAN model is compared with its basis models (GAN, VAE and VAE/GAN) and inspired model accoording to inception score. In this study, it is clearly seen that the proposed model is able to converge much faster than compared models for modeling the underlying distribution of handwritten image data.","","978-1-5386-7893-0","10.1109/UBMK.2018.8566539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8566539","variational autoencoders;generative models;adversarial training;image generation;synthetic handwritten images;high-resolution images","Gallium nitride;Image reconstruction;Training;Mathematical model;Generative adversarial networks;Data models;Adaptation models","encoding;handwriting recognition;image reconstruction;image resolution;learning (artificial intelligence);neural nets","handwritten super resolution image generation;generative adversarial training;feature-wise reconstruction objective;handwritten image data;variational autoencoded compositional pattern generative adversarial network;inference mechanism;CPGAN model;VAE-GAN hybrid model;CPPN;pixel-like reconstruction approach","","3","","13","IEEE","9 Dec 2018","","","IEEE","IEEE Conferences"
"On the Tradeoff between Computation-Time and Learning-Accuracy in GAN-based Super-Resolution Deep Learning","J. Shim; J. Kim; J. Kim","School of Electrical Engineering, Korea University, Seoul, Republic of Korea; School of Electrical Engineering, Korea University, Seoul, Republic of Korea; School of Electrical Engineering, Korea University, Seoul, Republic of Korea","2021 International Conference on Information Networking (ICOIN)","2 Feb 2021","2021","","","422","424","The trade-off between accuracy and computation should be considered when applying generative adversarial network (GAN)-based image generation to real-world applications. This paper presents a simple yet efficient method based on Progressive Growing of GANs (PGGAN) to exploit the trade-off for image generation. The scheme is evaluated using the LSUN dataset.","1976-7684","978-1-7281-9101-0","10.1109/ICOIN50884.2021.9333991","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9333991","","Deep learning;Image synthesis;Superresolution;Generative adversarial networks;Task analysis;Gallium nitride","image resolution;learning (artificial intelligence);neural nets","GAN-based super-resolution deep learning;GAN-based image generatioN;generative adversarial network-based image generation;computation time","","","","14","IEEE","2 Feb 2021","","","IEEE","IEEE Conferences"
"A Two-Layers Super-Resolution Based Generation Adversarial Spatiotemporal Fusion Model","S. Fang; Q. Guo; Y. Cao; J. Zhang","Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, Hefei University of Technology, Ministry of Education, Hefei, China; University of Science and Technology of China, Hefei, Anhui, China; Key Laboratory of Knowledge Engineering with Big Data, Hefei University of Technology, Ministry of Education, Hefei, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","891","894","Remote sensing image spatiotemporal fusion (STF) algorism plays an important role by supplementing the lack of original high-resolution remote sensing satellite images in the study scenarios of dense time-series data. In recent years, the deep-learning-based STF algorithm has become a research hotspot with comparatively higher accuracy and robustness. However, due to the lack of sufficient high-quality images for training and the huge resolution gap between low-resolution images and high-resolution images, it is difficult to recover detailed information, especially for areas of land-cover change. In this paper, we propose a two-layers super-resolution based generation adversarial spatiotemporal fusion model(TLSRSTF) using smaller inputs to reduce pressure on data requirements and a mutual affine convolution to reduce model parameters. Specifically, we only use a pair of high-resolution and low-resolution images and a high-resolution image at any time. A spatial degradation consistency is constructed to adaptively determine the ratio of two layers of the super-resolution STF model. The quantitative and qualitative experimental results on public spatiotemporal fusion datasets demonstrate our superiority over the state-of-the-art methods.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883547","National Natural Science Foundation of China(grant numbers:61872327,61175033); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883547","Spatiotemporal Fusion;Generative Adversarial Networks(GAN);Mutual Affine Convolution","Training;Adaptation models;Satellites;Convolution;Superresolution;Data models;Robustness","geophysical image processing;image fusion;image resolution;learning (artificial intelligence);remote sensing;spatiotemporal phenomena","sensing image spatiotemporal fusion algorism;high-resolution remote sensing satellite images;dense time-series data;STF algorithm;comparatively higher accuracy;robustness;high-quality images;huge resolution gap;low-resolution images;high-resolution image;super-resolution STF model;public spatiotemporal fusion datasets","","","","9","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"SRGAN with Total Variation Loss in Face Super-Resolution","H. Nguyen-Truong; K. N. A. Nguyen; S. Cao","Advanced Program in Computer Science, Faculty of Information Technology, Vietnam National University, Ho Chi Minh city, Vietnam; Advanced Program in Computer Science, Faculty of Information Technology, Vietnam National University, Ho Chi Minh city, Vietnam; Advanced Program in Computer Science, Faculty of Information Technology, Vietnam National University, Ho Chi Minh city, Vietnam","2020 7th NAFOSTED Conference on Information and Computer Science (NICS)","2 Feb 2021","2020","","","292","297","Facial image super-resolution is a crucial preprocessing for facial image analysis, face recognition, and image-based 3D face reconstruction. Convolutional neural networks were earlier used to produce high-resolution images that train quicker and shown excellent performance by learning mapping relation using pairs of low-resolution and high-resolution images. However, in some cases, they are incapable of recovering finer details and often generate blurry images. In this paper, we evaluate a method of applying Generative adversarial networks in generating realistic super-resolution images from low-resolution ones by using three typical losses for super-resolution: Content Loss, Adversarial Loss, Perceptual Loss, and proposed to use Total Variation Loss. We try different pre-trained famous Convolutional neural networks models (VGG19, FaceNet, and EfficientNet) in Perceptual Loss to have a general view with different backbones. Our network gains 32.67 of Peak signal-to-noise ratio (PSNR) and 0.89 of Structural similarity index (SSIM) in 100 random samples from the Flickr-Faces-HQ dataset.","","978-0-7381-0553-6","10.1109/NICS51282.2020.9335836","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9335836","","Training;Visualization;PSNR;Face recognition;Superresolution;Feature extraction;Convolutional neural networks","convolutional neural nets;face recognition;image reconstruction;image resolution;learning (artificial intelligence)","total variation loss;facial image super-resolution;facial image analysis;face recognition;image-based 3D face reconstruction;high-resolution images;blurry images;generative adversarial networks;low-resolution images;content loss;perceptual loss;convolutional neural networks models;Flickr-Faces-HQ dataset;adversarial loss;SRGAN;mapping relation;VGG19 model;FaceNet model;EfficientNet model;peak signal-to-noise ratio;structural similarity index;SSIM;PSNR","","1","","36","IEEE","2 Feb 2021","","","IEEE","IEEE Conferences"
"Super-Resolution Reconstruction Method of Remote Sensing Image Based on Multi-Feature Fusion","Z. -X. Huang; C. -W. Jing","Zhejiang Yijia Geographic Information Technology Company, Ltd., Hangzhou, China; Hangzhou Normal University, Hangzhou, China","IEEE Access","30 Jan 2020","2020","8","","18764","18771","The acquisition of remote sensing images is affected by imaging equipment and environmental conditions. Usually on lower performance devices, the resolution of the acquired images is also low. Among many methods, the super-resolution reconstruction method based on generative adversarial networks has obvious advantages over previous network models in reconstructing image texture details. However, it is found in experiments that not all of these reconstructed textures exist in the image itself. Aiming at the problem of whether the texture details of the reconstructed image are accurate and clear, we propose a super-resolution reconstruction method combining wavelet transform and generative adversarial network. Using wavelet multi-resolution analysis, training wavelet decomposition coefficients in the generative adversarial network can effectively improve the local detail information of the reconstructed image. Experimental results show that our method can effectively reconstruct more natural image textures and make the images more visually clear. In the remote sensing image test set, the four indicators of the algorithm, peak signal to noise ratio (PSNR), structural similarity (SSIM), Feature Similarity (FSIM) and Universal Image Quality (UIQ) are slightly better than the algorithms mentioned in the article.","2169-3536","","10.1109/ACCESS.2020.2967804","Key Special Projects through the Provincial Scientific Research Institutes Program of Zhejiang Province, China(grant numbers:2014F50022); Construction of Agricultural Science Park Program of Zhejiang Province, China(grant numbers:2019E70002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8963714","Remote sensing image;super-resolution;self-correlation;image texture","Image reconstruction;Wavelet transforms;Reconstruction algorithms;Remote sensing;Generative adversarial networks","image fusion;image reconstruction;image resolution;image texture;neural nets;remote sensing;wavelet transforms","wavelet multiresolution analysis;generative adversarial network;reconstructed image;natural image textures;remote sensing image test;super-resolution reconstruction method;remote sensing images;imaging equipment;image texture details;reconstructed textures;universal image quality;multi-feature fusion;environmental conditions;wavelet transform;training wavelet decomposition coefficients;peak signal to noise ratio;structural similarity;feature similarity","","11","","27","CCBY","20 Jan 2020","","","IEEE","IEEE Journals"
"Mars Image Super-Resolution Based on Generative Adversarial Network","C. Wang; Y. Zhang; Y. Zhang; R. Tian; M. Ding","Shanghai Institute of Satellite Engineering, Shanghai, China; School of Instrument Science and Engineering, Harbin Institute of Technology (HIT), Harbin, China; School of Instrument Science and Engineering, Harbin Institute of Technology (HIT), Harbin, China; School of Instrument Science and Engineering, Harbin Institute of Technology (HIT), Harbin, China; School of Instrument Science and Engineering, Harbin Institute of Technology (HIT), Harbin, China","IEEE Access","9 Aug 2021","2021","9","","108889","108898","High-resolution (HR) Mars images have great significance for studying the land-form features of Mars and analyzing the climate on Mars. Nowadays, the mainstream image super-resolution methods are based on deep learning or CNNs, which are better than traditional methods. However, these deep learning based methods obtain low-resolution(LR) images usually by using an ideal down-sampling method (e.g. bicubic interpolation). There are two limitations in the existing SR methods: 1) The paired LR-HR data by using such methods can achieve a satisfactory results when tested on an ideal datasets. But, these methods always fail in real Mars image super-resolution, since real Mars images rarely obey an ideal down-sampling rule. 2) The LR images obtained by ideal down-sampling methods have no noise while real Mars images usually have noise, which leads to the super-resolved images are not realistic in texture details. To solve the above-mentioned problems, in this article, we propose a novel two-step framework for Mars image super-resolution. Specifically, to address limitation 1), we focus on designing a new degradation framework by estimating blur-kernels. To address limitation 2), a Generative Adversarial Network (GAN) is trained to generate noise distribution. Extensive experiments on the Mars32k dataset demonstrate the effectiveness of the proposed method, and we achieve better qualitative and quantitative results compared to other SOTA methods.","2169-3536","","10.1109/ACCESS.2021.3101858","China Postdoctoral Science Foundation(grant numbers:259822); National Postdoctoral Program for Innovative Talents(grant numbers:BX20200108); National Science Foundation of China(grant numbers:61976070); Natural Science Foundation of Heilongjiang Province(grant numbers:LH2021F024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9503382","Generative adversarial network;kernel estimation;mars image super-resolution;noise model","Mars;Superresolution;Earth;Generative adversarial networks;Kernel;Feature extraction;Interpolation","image reconstruction;image resolution;image restoration;image texture;interpolation;learning (artificial intelligence);sampling methods","ideal down-sampling method;super-resolved images;Mars image super-resolution;generative adversarial network;Mars32k dataset;high-resolution Mars images;mainstream image super-resolution methods;deep learning based methods;existing SR methods;LR images","","5","","50","CCBY","2 Aug 2021","","","IEEE","IEEE Journals"
"Stochastic Super-Resolution for Downscaling Time-Evolving Atmospheric Fields With a Generative Adversarial Network","J. Leinonen; D. Nerini; A. Berne","Federal Office of Meteorology and Climatology MeteoSwiss, Locarno-Monti, Switzerland; Federal Office of Meteorology and Climatology MeteoSwiss, Locarno-Monti, Switzerland; Environmental Remote Sensing Laboratory, École Polytechnique fédérale de Lausanne, Lausanne, Switzerland","IEEE Transactions on Geoscience and Remote Sensing","27 Aug 2021","2021","59","9","7211","7223","Generative adversarial networks (GANs) have been recently adopted for super-resolution, an application closely related to what is referred to as “downscaling” in the atmospheric sciences: improving the spatial resolution of low-resolution images. The ability of conditional GANs to generate an ensemble of solutions for a given input lends itself naturally to stochastic downscaling, but the stochastic nature of GANs is not usually considered in super-resolution applications. Here, we introduce a recurrent, stochastic super-resolution GAN that can generate ensembles of time-evolving high-resolution atmospheric fields for an input consisting of a low-resolution sequence of images of the same field. We test the GAN using two data sets: one consisting of radar-measured precipitation from Switzerland; the other of cloud optical thickness derived from the Geostationary Earth Observing Satellite 16 (GOES-16). We find that the GAN can generate realistic, temporally consistent super-resolution sequences for both data sets. The statistical properties of the generated ensemble are analyzed using rank statistics, a method adapted from ensemble weather forecasting; these analyses indicate that the GAN produces close to the correct amount of variability in its outputs. As the GAN generator is fully convolutional, it can be applied after training to input images larger than the images used to train it. It is also able to generate time series much longer than the training sequences, as demonstrated by applying the generator to a three-month data set of the precipitation radar data. The source code to our GAN is available at https://github.com/jleinonen/downscaling-rnn-gan.","1558-0644","","10.1109/TGRS.2020.3032790","Swiss National Science Foundation(grant numbers:#200020_175700); Swiss National Supercomputing Centre (CSCS)(grant numbers:sm35); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9246532","Atmosphere;clouds;image processing;meteorological radar;neural networks;remote sensing","Gallium nitride;Generators;Meteorology;Generative adversarial networks;Training","atmospheric optics;atmospheric precipitation;atmospheric techniques;clouds;geophysics computing;image resolution;remote sensing;remote sensing by radar;stochastic processes;time series;weather forecasting","input images;GAN generator;generated ensemble;super-resolution sequences;data sets;low-resolution sequence;time-evolving high-resolution;stochastic super-resolution GAN;recurrent resolution GAN;super-resolution applications;stochastic nature;stochastic downscaling;conditional GANs;low-resolution images;spatial resolution;atmospheric sciences;generative adversarial network;downscaling time-evolving atmospheric fields","","20","","55","IEEE","2 Nov 2020","","","IEEE","IEEE Journals"
"Kernel Modeling Super-Resolution on Real Low-Resolution Images","R. Zhou; S. Süsstrunk","IC, EPFL; EPFL","2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","2433","2443","Deep convolutional neural networks (CNNs), trained on corresponding pairs of high- and low-resolution images, achieve state-of-the-art performance in single-image super-resolution and surpass previous signal-processing based approaches. However, their performance is limited when applied to real photographs. The reason lies in their training data: low-resolution (LR) images are obtained by bicubic interpolation of the corresponding high-resolution (HR) images. The applied convolution kernel significantly differs from real-world camera-blur. Consequently, while current CNNs well super-resolve bicubic-downsampled LR images, they often fail on camera-captured LR images. To improve generalization and robustness of deep super-resolution CNNs on real photographs, we present a kernel modeling super-resolution network (KMSR) that incorporates blur-kernel modeling in the training. Our proposed KMSR consists of two stages: we first build a pool of realistic blur-kernels with a generative adversarial network (GAN) and then we train a super-resolution network with HR and corresponding LR images constructed with the generated kernels. Our extensive experimental validations demonstrate the effectiveness of our single-image super-resolution approach on photographs with unknown blur-kernels.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010978","","Kernel;Gallium nitride;Image resolution;Training;Estimation;Signal resolution;Generative adversarial networks","cameras;convolutional neural nets;image resolution;image restoration;image sampling;interpolation","high-resolution images;convolution kernel;super-resolve bicubic-downsampled LR images;camera-captured LR images;super-resolution CNNs;photographs;kernel modeling super-resolution;blur-kernel modeling;realistic blur-kernels;super-resolution network;generated kernels;single-image super-resolution approach;real low-resolution images;deep convolutional neural networks;signal-processing based approaches;bicubic interpolation;real-world camera-blur","","62","","59","IEEE","27 Feb 2020","","","IEEE","IEEE Conferences"
"Quality Enhancement of Gaming Content using Generative Adversarial Networks","N. J. Avanaki; S. Zadtootaghaj; N. Barman; S. Schmidt; M. G. Martini; S. Möller","Quality and Usability Lab, TU Berlin, Germany; Quality and Usability Lab, TU Berlin, Germany; Wireless Multimedia & Networking Research Group, Kingston University, London, UK; Quality and Usability Lab, TU Berlin, Germany; Wireless Multimedia & Networking Research Group, Kingston University, London, UK; Quality and Usability Lab, Tech. Univ. Berlin, Berlin, Germany","2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX)","23 Jun 2020","2020","","","1","6","Recently, streaming of gameplay scenes has gained much attention, as evident with the rise of platforms such as Twitch.tv and Facebook Gaming. These streaming services have to deal with many challenges due to the low quality of source materials caused by client devices, network limitations such as bandwidth and packet loss, as well as low delay requirements. Spatial video artifact such as blockiness and blurriness as a result of as video compression or up-scaling algorithms can significantly impact the Quality of Experience of end-users of passive gaming video streaming applications. In this paper, we investigate solutions to enhance the video quality of compressed gaming content. Recently, several super-resolution enhancement techniques using Generative Adversarial Network (e.g., SRGAN) have been proposed, which are shown to work with high accuracy on non-gaming content. Towards this end, we improved the SRGAN by adding a modified loss function as well as changing the generator network such as layer levels and skip connections to improve the flow of information in the network, which is shown to improve the perceived quality significantly. In addition, we present a performance evaluation of improved SRGAN for the enhancement of frame quality caused by compression and rescaling artifacts for gaming content encoded in multiple resolution-bitrate pairs.","2472-7814","978-1-7281-5965-2","10.1109/QoMEX48832.2020.9123074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9123074","Quality Enhancement;Gaming Content;QoE;GAN;Quality Assessment","Performance evaluation;Social networking (online);Superresolution;Packet loss;Streaming media;Video compression;Generative adversarial networks","computer games;data compression;image resolution;neural nets;social networking (online);video coding;video streaming","quality enhancement;gameplay scenes;Twitch.tv;Facebook Gaming;streaming services;source materials;generative adversarial network;SRGAN;rescaling artifacts;frame quality;perceived quality;generator network;modified loss function;nongaming content;super-resolution enhancement techniques;compressed gaming content;video quality;passive gaming video streaming applications;quality of experience;up-scaling algorithms;video compression;blurriness;blockiness;spatial video artifact;low delay requirements;packet loss;network limitations;client devices","","1","","24","IEEE","23 Jun 2020","","","IEEE","IEEE Conferences"
"Image Super-Resolution using GAN - A study","D. Parekh; A. Maiti; V. Jain","Department of Computer Science, School of Engineering & Technology Sharda University, Greater Noida, India; Department of Computer Science, School of Engineering & Technology Sharda University, Greater Noida, India; Department of Computer Science, School of Engineering & Technology Sharda University, Greater Noida, India","2022 6th International Conference on Trends in Electronics and Informatics (ICOEI)","24 May 2022","2022","","","1539","1549","Reconstructing low-resolution images to high-resolution images by building a neural network is quite challenging but can be used in many applications like medical imaging, public surveillance, or old photo recovery. Compared to previous methods, deep learning has a breakthrough in high-resolution accuracy and speed. By applying a deep network with Generative Adversarial Networks, this model aims to enhance low-resolution images to produce high-resolution images. The major focus is to reconstruct the image with high resolution by developing the image with low-resolution in order to preserve the main details in the reconstructed images.","","978-1-6654-8328-5","10.1109/ICOEI53556.2022.9777129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9777129","High-resolution;Low-resolution;Super-Resolution;GAN;Generative Adversarial Network","Training;Computational modeling;Surveillance;Superresolution;Neural networks;Generative adversarial networks;Market research","deep learning (artificial intelligence);image enhancement;image resolution;image restoration","low-resolution image enhancement;deep learning;low-resolution image-high-resolution image reconstruction;GAN;generative adversarial networks;deep network;high-resolution accuracy;medical imaging;neural network;image superresolution","","","","29","IEEE","24 May 2022","","","IEEE","IEEE Conferences"
"Siamese Generative Adversarial Network for Change Detection Under Different Scales","M. Liu; Q. Shi; P. Liu; C. Wan","Guangdong Provincial Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Guangdong Provincial Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","2543","2546","Change detection methods based on low-resolution (LR) images with higher temporal resolution often lead to fuzzy results, while high-resolution images (HRIs) can provide more detailed information to solve this problem. However, it's hard to obtain two tiles of HRIs with high-quality for rapid change detection in actual production due to low temporal resolution and high cost. Therefore, it is necessary to explore a change detection method combing low- and high-resolution images to acquire urban change areas more accurately and quickly. In this paper, an end-to-end siamese generative adversarial network (SiamGAN) integrating a super resolution network and the siamese structure was proposed for change detection under different scales. The super-resolution network is used to reconstruct low-resolution images into high-resolution images, while the siamese structure is adopted as the classification network to detect changes. In the experiments, SiamGAN achieved an F1 of 76.06% and an IoU of 61.52% in the test set, which is respectively 5.68% and 6.92% higher than the CNN-based methods using LR images after bicubic interpolation. The results show that our proposed method can effectively overcome difference in scale between low- and high-resolution images and perform change detection more precisely and rapidly.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323499","Change detection;siamese network;super-resolution;high resolution images","Generators;Feature extraction;Training;Superresolution;Generative adversarial networks;Spatial resolution;Remote sensing","geophysical image processing;image reconstruction;image resolution;interpolation","change detection method;low-resolution images;higher temporal resolution;high-resolution images;rapid change detection;low temporal resolution;urban change areas;end-to-end siamese generative adversarial network;super resolution network;siamese structure;super-resolution network","","","","14","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"A Super-Resolution Generative Adversarial Network with Siamese CNN Based on Low Quality for Breast Cancer Identification","G. U. Nneji; J. Cai; D. Jianhua; H. N. Monday; C. J. Ejiyi; E. C. James; G. T. Mgbejime; A. Oluwasanmi","School of Information and Software Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Sichuan, China","2021 4th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)","4 Oct 2021","2021","","","218","223","Breast cancer is a chronic illness leading to the death of millions of people yearly. Despite the fact that successful identification of benign and malignant images is dependent on radiologists' long-term knowledge, specialists occasionally disagree with their decisions. An automatic system provides an alternative choice for the image diagnosis, thereby helping the expert to make more reliable decisions efficiently, less prone to errors and make diagnosis more scalable. Another issue based with the diagnosis of breast cancer identification is the poor quality of the image which poses a challenge in identification performance. An enhanced super-resolution generative adversarial network has been implemented in this paper to produce super-resolution images of breast cancer from a low-resolution counterpart with higher quality and finer details using an upscale factor of 4. Additionally, siamese convolutional neural network was utilized for the features extraction and classification of breast cancer. The proposed model provides an effective classification performance in terms of accuracy and ROC-AUC scores of 98.87% and 98.76% respectively as compared to other existing approaches.","","978-1-6654-1322-0","10.1109/PRAI53619.2021.9551033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551033","breast cancer;deep learning;super-resolution;siamese network;generative adversarial network","Measurement;Superresolution;Generative adversarial networks;Feature extraction;Breast cancer;Pattern recognition;Classification algorithms","cancer;edge detection;feature extraction;image classification;image representation;image resolution;image texture;learning (artificial intelligence);medical diagnostic computing;medical image processing;neural nets;patient diagnosis;pattern classification","siamese CNN;breast cancer identification;chronic illness;successful identification;benign images;malignant images;long-term knowledge;image diagnosis;reliable decisions;enhanced super-resolution generative adversarial network;super-resolution images;low-resolution counterpart;finer details;siamese convolutional neural network","","5","","15","IEEE","4 Oct 2021","","","IEEE","IEEE Conferences"
"Propagating Facial Prior Knowledge for Multitask Learning in Face Super-Resolution","C. Wang; J. Jiang; Z. Zhong; X. Liu","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Circuits and Systems for Video Technology","28 Oct 2022","2022","32","11","7317","7331","Existing face hallucination methods always achieve improved performance through regularizing the model with facial prior. Most of them always estimate facial prior information first and then leverage it to help the prediction of the target high-resolution face image. However, the accuracy of prior estimation is difficult to guarantee, especially for the low-resolution face image. Once the estimated prior is inaccurate or wrong, the following face super-resolution performance is unavoidably influenced. A natural question that arises: how to incorporate facial prior effectively and efficiently without prior estimation? To achieve this goal, we propose to learn facial prior knowledge at training stage, but test only with low-resolution face image, which can overcome the difficulty of estimating accurate prior. In addition, instead of estimating facial prior, we directly explore the potential of high-quality facial prior in the training phase and progressively propagate the facial prior knowledge from the teacher network (trained with the low-resolution face/high-quality facial prior and high-resolution face image pairs) to the student network (trained with the low-resolution face and high-resolution face image pairs). Quantitative and qualitative comparisons on benchmark face datasets demonstrate that our method outperforms the state-of-the-art face super-resolution methods. The source codes of the proposed method will be available at https://github.com/wcy-cs/KDFSRNet.","1558-2205","","10.1109/TCSVT.2022.3181828","National Natural Science Foundation of China(grant numbers:61971165,61922027); Fundamental Research Funds for the Central Universities(grant numbers:FRFCU5710050119); Natural Science Foundation of Heilongjiang Province(grant numbers:YQ2020F004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9792407","Face hallucination;face super-resolution;facial prior;knowledge distillation","Faces;Face recognition;Superresolution;Estimation;Training;Knowledge engineering;Generative adversarial networks","face recognition;image resolution;learning (artificial intelligence)","benchmark face datasets;face hallucination methods;face image pairs;face super-resolution performance;facial prior information;facial prior knowledge;low-resolution face image;prior estimation;state-of-the-art face super-resolution methods;student network;target high-resolution face image;teacher network","","2","","74","IEEE","9 Jun 2022","","","IEEE","IEEE Journals"
"7.4 GANPU: A 135TFLOPS/W Multi-DNN Training Processor for GANs with Speculative Dual-Sparsity Exploitation","S. Kang; D. Han; J. Lee; D. Im; S. Kim; S. Kim; H. -J. Yoo","KAIST, Daejeon, Korea; KAIST, Daejeon, Korea; KAIST, Daejeon, Korea; KAIST, Daejeon, Korea; KAIST, Daejeon, Korea; KAIST, Daejeon, Korea; KAIST, Daejeon, Korea","2020 IEEE International Solid- State Circuits Conference - (ISSCC)","13 Apr 2020","2020","","","140","142","Generative adversarial networks (GAN) have a wide range of applications, from image style transfer to synthetic voice generation [1]. GAN applications on mobile devices, such as face-to-Emoji conversion and super-resolution imaging, enable more engaging user interaction. As shown in Fig. 7.4.1, a GAN consists of 2 competing deep neural networks (DNN): a generator and a discriminator. The discriminator is trained, while the generator is fixed, to distinguish whether the generated image is real or fake. On the other hand, the generator is trained to generate fake images to fool the discriminator. The minimax rivalry between the 2 sub-DNNs enables the model to generate high-quality images, difficult even for humans to distinguish.","2376-8606","978-1-7281-3205-1","10.1109/ISSCC19947.2020.9062989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9062989","","Training;Gallium nitride;Generative adversarial networks;Generators;Computer architecture;Convolution;Multiplexing","backpropagation;image resolution;interactive systems;mobile computing;neural nets","high-quality images;GANPU;speculative dual-sparsity exploitation;generative adversarial networks;image style transfer;synthetic voice generation;GAN applications;mobile devices;face-to-Emoji conversion;superresolution imaging;user interaction;deep neural networks;DNN;fake images;multiDNN training processor","","40","","6","IEEE","13 Apr 2020","","","IEEE","IEEE Conferences"
"Stylegan-Induced Data-Driven Regularization for Inverse Problems","A. Conmy; S. Mukherjee; C. -B. Schönlieb","Department of Applied Mathematics and Theoretical Physics, University of Cambridge, UK; Department of Applied Mathematics and Theoretical Physics, University of Cambridge, UK; Department of Applied Mathematics and Theoretical Physics, University of Cambridge, UK","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","3788","3792","Recent advances in generative adversarial networks (GANs) have opened up the possibility of generating high-resolution photo-realistic images that were impossible to produce previously. The ability of GANs to sample from high-dimensional distributions has naturally motivated researchers to leverage their power for modeling the image prior in inverse problems. We extend this line of research by developing a Bayesian image reconstruction framework that utilizes the full potential of a pre-trained StyleGAN2 generator, which is the currently dominant GAN architecture, for constructing the prior distribution on the underlying image. Our proposed approach, which we refer to as learned Bayesian reconstruction with generative models (L-BRGM), entails joint optimization over the style-code and the input latent code, and enhances the expressive power of a pre-trained StyleGAN2 generator by allowing the style-codes to be different for different generator layers. Considering the inverse problems of image inpainting and super-resolution, we demonstrate that the proposed approach is competitive with, and sometimes superior to, state-of-the-art GAN-based image reconstruction methods.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747632","Inverse problems;generative prior","Inverse problems;Conferences;Superresolution;Signal processing;Generative adversarial networks;Generators;Bayes methods","Bayes methods;belief networks;image reconstruction;image restoration;inverse problems;learning (artificial intelligence);realistic images","stylegan-induced data-driven regularization;inverse problems;generative adversarial networks;GANs;high-resolution photo-realistic images;high-dimensional distributions;leverage their power;Bayesian image reconstruction framework;pre-trained StyleGAN2 generator;currently dominant GAN architecture;underlying image;learned Bayesian reconstruction;generative models;style-code;different generator layers;image inpainting;superior to state-of-the-art GAN-based image reconstruction methods","","1","","16","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Deep Learning for Inverse Problems in Imaging","",,"2019 Ninth International Conference on Image Processing Theory, Tools and Applications (IPTA)","19 Dec 2019","2019","","","i","i","Inverse problems have been widely studied in image processing, with applications in areas such as image denoising, blind/non-blind deblurring, super-resolution and compressive sensing. Lately deep learning techniques and architectures have made significant impact in the solution of various inverse problems, surpassing the performance of classical variational optimization algorithms. In this talk, we will review state-of-the-art deep architectures for inverse problems in imaging. We will compare the data-driven solutions of deep learning with standard iterative methods in terms of performance, speed and practicality. We will discuss adversarial learning, generative adversarial networks (GANs) and denoising auto-encoders (DAEs) that are used to learn the distribution of the data in the context of inverse problems. We will then provide a unified framework for the application of deep learning to the solution of various inverse problems, including motion deblurring, single image super-resolution, compressive sensing and sparse recovery. The tutorial will finish by summarizing the recent trends in literature to develop general, model-independent solution to inverse problems using novel deep architectures and learning strategies.","2154-512X","978-1-7281-3975-3","10.1109/IPTA.2019.8936102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936102","","","image denoising;image resolution;image restoration;inverse problems;iterative methods;learning (artificial intelligence);neural net architecture","inverse problems;deep learning techniques;state-of-the-art deep architectures;single image super-resolution;learning strategies;image processing;image denoising;blind-nonblind deblurring;super-resolution;compressive sensing;DAE;GAN;generative adversarial networks;adversarial learning","","","","","IEEE","19 Dec 2019","","","IEEE","IEEE Conferences"
"Multi-Image Super Resolution in Multi-Contrast MRI","M. Yurt; T. Çukur··","Ulusal Manyetik Rezonans Araştırma Merkezi, Bilkent Üniversitesi, Ankara, Türkiye; Sinirbilim Programı, Mühendislik ve Fen Bilimleri Enstitüsü, Bilkent Üniversitesi, Ankara, Türkiye","2020 28th Signal Processing and Communications Applications Conference (SIU)","7 Jan 2021","2020","","","1","4","Acquisition of high-resolution magnetic resonance images (MRI) under distinct contrasts can enhance diagnostic information required in clinical diagnosis. Yet, acquiring high-resolution images might be impractical due to increased noise, prolonged scan durations and hardware costs. In such situations, an alternative solution can be the synthesis of high-resolution images from low-resolution images. Common methods perform super resolution of a single image. However, in multi-contrast MRI, the images of a single contrast might not contain sufficient prior information required for a successful deblurring. To enhance the required prior information, complementary prior information available in other contrasts can be used. Here, a multi-contrast MRI super resolution method is proposed to simultaneously deblur the images of multiple distinct contrasts. The proposed method relies on generative adversarial networks that can produce as realistic images as possible by better recovering high-frequency details. Qualitative and quantitative evaluations on a multi-contrast MRI dataset demonstrated that the proposed method outperforms the alternative single image MRI super resolution method.","2165-0608","978-1-7281-7206-4","10.1109/SIU49456.2020.9302325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302325","super resolution;deblurring;multi-contrast MRI","Magnetic resonance imaging;Image resolution;Gallium nitride;Nanoelectromechanical systems;Magnetic resonance;Lenses;Kernel","biomedical MRI;image reconstruction;image representation;image resolution;image restoration;medical image processing","multiimage super resolution;high-resolution magnetic resonance images;diagnostic information;high-resolution images;prolonged scan durations;low-resolution images;single contrast;complementary prior information;multiple distinct contrasts;realistic images;multicontrast MRI dataset;alternative single image MRI super resolution method;multicontrast MRI superresolution method","","","","","IEEE","7 Jan 2021","","","IEEE","IEEE Conferences"
"CT Super-Resolution GAN Constrained by the Identical, Residual, and Cycle Learning Ensemble (GAN-CIRCLE)","C. You; G. Li; Y. Zhang; X. Zhang; H. Shan; M. Li; S. Ju; Z. Zhao; Z. Zhang; W. Cong; M. W. Vannier; P. K. Saha; E. A. Hoffman; G. Wang","Departments of Bioengineering and Electrical Engineering, Stanford University, Stanford, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, USA; College of Computer Science, Sichuan University, Chengdu, China; Department of Electrical and Computer Engineering, University of Iowa, Iowa City, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, USA; Department of Radiology, Jiangsu Key Laboratory of Molecular and Functional Imaging, Zhongda Hospital, Medical School, Southeast University, Nanjing, China; Department of Radiology, Jiangsu Key Laboratory of Molecular and Functional Imaging, Zhongda Hospital, Medical School, Southeast University, Nanjing, China; Department of Radiology, Wuxi No.2 People’s Hospital, Wuxi, China; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, USA; Department of Radiology, University of Chicago, Chicago, USA; Department of Electrical and Computer Engineering and Radiology, University of Iowa, Iowa City, USA; Department of Radiology and Biomedical Engineering, University of Iowa, Iowa City, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, USA","IEEE Transactions on Medical Imaging","31 Dec 2019","2020","39","1","188","203","In this paper, we present a semi-supervised deep learning approach to accurately recover high-resolution (HR) CT images from low-resolution (LR) counterparts. Specifically, with the generative adversarial network (GAN) as the building block, we enforce the cycle-consistency in terms of the Wasserstein distance to establish a nonlinear end-to-end mapping from noisy LR input images to denoised and deblurred HR outputs. We also include the joint constraints in the loss function to facilitate structural preservation. In this process, we incorporate deep convolutional neural network (CNN), residual learning, and network in network techniques for feature extraction and restoration. In contrast to the current trend of increasing network depth and complexity to boost the imaging performance, we apply a parallel 1 × 1 CNN to compress the output of the hidden layer and optimize the number of layers and the number of filters for each convolutional layer. The quantitative and qualitative evaluative results demonstrate that our proposed model is accurate, efficient and robust for super-resolution (SR) image restoration from noisy LR input images. In particular, we validate our composite SR networks on three large-scale CT datasets, and obtain promising results as compared to the other state-of-the-art methods.","1558-254X","","10.1109/TMI.2019.2922960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736838","Computed tomography (CT);super-resolution;noise reduction;deep learning;adversarial learning;residual learning","Computed tomography;Gallium nitride;Image resolution;Generative adversarial networks;Image reconstruction;Training","computerised tomography;convolutional neural nets;feature extraction;image denoising;image resolution;image restoration;medical image processing;supervised learning","high-resolution CT images;low-resolution counterparts;generative adversarial network;Wasserstein distance;nonlinear end-to-end mapping;noisy LR input images;denoised HR outputs;deblurred HR outputs;loss function;structural preservation;residual learning;feature extraction;CNN;convolutional layer;super-resolution image restoration;composite SR networks;large-scale CT datasets;CT super-resolution GAN;GAN-CIRCLE;semisupervised deep learning approach;cycle learning ensemble;deep convolutional neural network","Abdomen;Aged;Aged, 80 and over;Deep Learning;Female;Humans;Image Processing, Computer-Assisted;Male;Neural Networks, Computer;Tibia;Tomography, X-Ray Computed","188","","87","IEEE","14 Jun 2019","","","IEEE","IEEE Journals"
"Frequency Separation for Real-World Super-Resolution","M. Fritsche; S. Gu; R. Timofte","Computer Vision Lab, ETH Zürich, Switzerland; Computer Vision Lab, ETH Zürich, Switzerland; Computer Vision Lab, ETH Zürich, Switzerland","2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)","5 Mar 2020","2019","","","3599","3608","Most of the recent literature on image super-resolution (SR) assumes the availability of training data in the form of paired low resolution (LR) and high resolution (HR) images or the knowledge of the downgrading operator (usually bicubic downscaling). While the proposed methods perform well on standard benchmarks, they often fail to produce convincing results in real-world settings. This is because real-world images can be subject to corruptions such as sensor noise, which are severely altered by bicubic downscaling. Therefore, the models never see a real-world image during training, which limits their generalization capabilities. Moreover, it is cumbersome to collect paired LR and HR images in the same source domain. To address this problem, we propose DSGAN to introduce natural image characteristics in bicubically downscaled images. It can be trained in an unsupervised fashion on HR images, thereby generating LR images with the same characteristics as the original images. We then use the generated data to train a SR model, which greatly improves its performance on real-world images. Furthermore, we propose to separate the low and high image frequencies and treat them differently during training. Since the low frequencies are preserved by downsampling operations, we only require adversarial training to modify the high frequencies. This idea is applied to our DSGAN model as well as the SR model. We demonstrate the effectiveness of our method in several experiments through quantitative and qualitative analysis. Our solution is the winner of the AIM Challenge on Real World SR at ICCV 2019.","2473-9944","978-1-7281-5023-9","10.1109/ICCVW.2019.00445","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022593","super resolution;unsupervised learnig;real world;gan;deep learning","Image resolution;Training;Gallium nitride;Neural networks;Standards;Generative adversarial networks","image resolution;image sampling","real-world super-resolution;image super-resolution;low resolution image;high resolution images;bicubic downscaling;real-world image;natural image characteristics;bicubically downscaled images;HR images;LR images;low image frequencies;high image frequencies;real world SR;frequency separation;downsampling operations","","70","","41","IEEE","5 Mar 2020","","","IEEE","IEEE Conferences"
"An Unsupervised Remote Sensing Single-Image Super-Resolution Method Based on Generative Adversarial Network","N. Zhang; Y. Wang; X. Zhang; D. Xu; X. Wang","School of Optoelectronics, University of Chinese Academy of Sciences, Beijing, China; Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, China; School of Optoelectronics, University of Chinese Academy of Sciences, Beijing, China; School of Optoelectronics, University of Chinese Academy of Sciences, Beijing, China; Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, China","IEEE Access","14 Feb 2020","2020","8","","29027","29039","Image super-resolution (SR) technique can improve the spatial resolution of images without upgrading the imaging system. As a result, SR promotes the development of high resolution (HR) remote sensing image applications. Many remote sensing image SR algorithms based on deep learning have been proposed recently, which can effectively improve the spatial resolution under the constraints of HR images. However, images acquired by remote sensing imaging devices typically have lower resolution. Hence, an insufficient number of HR remote sensing images are available for training deep neural networks. In view of this problem, we propose an unsupervised SR method that does not require HR remote sensing images. The proposed method introduces a generative adversarial network (GAN) that obtains SR images through the generator; then, the SR images are downsampled to train the discriminator with low resolution (LR) images. Our method outperformed several methods in terms of the quality of the obtained SR images as measured by 6 evaluation metrics, which proves the satisfactory performance of the proposed unsupervised method for improving the spatial resolution of remote sensing images.","2169-3536","","10.1109/ACCESS.2020.2972300","National Natural Science Foundation of China(grant numbers:11703027); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8986554","Image super-resolution;unsupervised learning;remote sensing;generative adversarial network","Remote sensing;Image reconstruction;Generative adversarial networks;Training;Gallium nitride","convolutional neural nets;geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","HR remote sensing images;generative adversarial network;SR images;spatial resolution;unsupervised remote sensing single-image super-resolution method;super-resolution technique;imaging system;high resolution remote sensing image applications;remote sensing image SR algorithms;HR images;remote sensing imaging devices;unsupervised SR method","","10","","90","CCBY","7 Feb 2020","","","IEEE","IEEE Journals"
"Agricultural Pest Super-Resolution and Identification With Attention Enhanced Residual and Dense Fusion Generative and Adversarial Network","Q. Dai; X. Cheng; Y. Qiao; Y. Zhang","School of Information and Computer, Anhui Agricultural University, Hefei, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Information and Computer, Anhui Agricultural University, Hefei, China; School of Information and Computer, Anhui Agricultural University, Hefei, China","IEEE Access","13 May 2020","2020","8","","81943","81959","The growth of the most significant field crops such as rice, wheat, maize, and soybean are influenced because of various pests. And crop production is decreased due to various categories of insects. Deep learning technologies significantly increased the efficiency of identifying and controlling agricultural pests attack. However, agricultural pests images obtained are often obscure and unclear because of the sparse density of cameras deployed in the real farmland. This always makes pests difficult to recognize and monitor. Additionally, the existing classification and segmentation methods are not satisfying for the identification of low-resolution images because they are pre-trained on the clear and high-resolution datasets. Therefore, it is crucial to restore and upscale the obtained low-resolution pest images in order to improve classification accuracy and the recall rate of the instance segmentation. In this paper, we propose a generative adversarial network (GAN) with quadra-attention and residual and dense fusion mechanisms to transform low-resolution pest images. Compared with previous state-of-the-art PSNR-oriented super-resolution methods, our proposed method is more powerful in image reconstruction and achieves the state of the art performance. The experiment results show that after reconstructing with our proposed gan, the recall rate increased by 182.89% and classification accuracy also improved a lot. Besides, our proposed method could decrease the density of the camera layout in the agricultural Internet of Things (IOT) monitor systems and the cost of infrastructure, which is practical for real-world applications.","2169-3536","","10.1109/ACCESS.2020.2991552","National Key Research and Development Project of China(grant numbers:2017YFD0301303); 2019 National Undergraduate Training Programs for Innovation and Entrepreneurship(grant numbers:201910364073); Anhui Provincial Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9082695","Agricultural pests;super-resolution;classification;object instance segmentation;deep learning;quadra-attention;residual and dense fusion","Agriculture;Insects;Image segmentation;Deep learning;Generative adversarial networks;Diseases","agriculture;crops;feature extraction;image classification;image reconstruction;image resolution;image segmentation;Internet of Things;learning (artificial intelligence);neural nets;pest control","agricultural pest image restoration;pest image resolution;PSNR-oriented super-resolution methods;attention enhanced residual network;dense fusion generative network;field crops;agricultural pest super-resolution;agricultural Internet of Things;image reconstruction;generative adversarial network;classification;segmentation;agricultural pests attack;deep learning","","9","","41","CCBY","30 Apr 2020","","","IEEE","IEEE Journals"
"Joint Face Super-Resolution and Deblurring Using Generative Adversarial Network","J. U. Yun; B. Jo; I. K. Park","Department of Information and Communication Engineering, Inha University, Incheon, South Korea; Department of Information and Communication Engineering, Inha University, Incheon, South Korea; Department of Information and Communication Engineering, Inha University, Incheon, South Korea","IEEE Access","10 Sep 2020","2020","8","","159661","159671","Facial image super-resolution (SR) is an important aspect of facial analysis, and it can contribute significantly to tasks such as face alignment, face recognition, and image-based 3D reconstruction. Recent convolutional neural network (CNN) based models have exhibited significant advancements by learning mapping relations using pairs of low-resolution (LR) and high-resolution (HR) facial images. However, because these methods are conventionally aimed at increasing the PSNR and SSIM metrics, the reconstructed HR images might be blurry and have an overall unsatisfactory perceptual quality even when state-of-the-art quantitative results are achieved. In this study, we address this limitation by proposing an adversarial framework intended to reconstruct perceptually high-quality HR facial images while simultaneously removing blur. To this end, a simple five-layer CNN is employed to extract feature maps from LR facial images, and this feature information is provided to two-branch encoder-decoder networks that generate HR facial images with and without blur. In addition, local and global discriminators are combined to focus on the reconstruction of HR facial structures. Both qualitative and quantitative results demonstrate the effectiveness of the proposed method for generating photorealistic HR facial images from a variety of LR inputs. Moreover, it was also verified, through a use case scenario that the proposed method can contribute more to the field of face recognition than existing approaches.","2169-3536","","10.1109/ACCESS.2020.3020729","National Research Foundation of Korea (NRF) funded by the Korea Government (MSIT)(grant numbers:NRF-2019R1A2C1006706); Samsung Research Funding Center of Samsung Electronics(grant numbers:SRFCIT1901-06); Institute for Information and Communications Technology Planning and Evaluation (IITP) funded by the Korea Government (MSIT) (Artificial Intelligence Convergence Research Center, Inha University)(grant numbers:2020-0-01389); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9181507","Facial image super-resolution;deblurring;generative adversarial network;face recognition","Face;Image reconstruction;Image resolution;Generative adversarial networks;Generators;Decoding;Feature extraction","convolutional neural nets;face recognition;feature extraction;image coding;image resolution;image restoration;learning (artificial intelligence);visual perception","HR facial images;two-branch encoder-decoder networks;LR facial images;feature maps;perceptual quality;reconstructed HR images;convolutional neural network based models;image-based 3D reconstruction;face alignment;facial analysis;facial image super-resolution;generative adversarial network;joint face super-resolution;face recognition;HR facial structures","","7","","48","CCBY","31 Aug 2020","","","IEEE","IEEE Journals"
"Multiattention Generative Adversarial Network for Remote Sensing Image Super-Resolution","S. Jia; Z. Wang; Q. Li; X. Jia; M. Xu","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Key Laboratory for Geo-Environmental Monitoring of Coastal Zone of the Ministry of Natural Resources, Shenzhen University, Shenzhen, China; School of Engineering and Information Technology, University of New South Wales, Canberra, ACT, Australia; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Geoscience and Remote Sensing","14 Jun 2022","2022","60","","1","15","Image super-resolution (SR) methods can generate remote sensing images with high spatial resolution without increasing the cost of acquisition equipment, thereby providing a feasible way to improve the quality of remote sensing images. Clearly, image SR is a severe ill-posed problem. With the development of deep learning, the powerful fitting ability of deep neural networks has solved this problem to some extent. Since the texture information of various remote sensing images are totally different from each other, in this article, we proposed a network based on generative adversarial network (GAN) to achieve high-resolution remote sensing images, named multiattention GAN (MA-GAN). The main body of the generator in MA-GAN contains three blocks: pyramid convolutional residual dense (PCRD) block, attention-based upsampling (AUP) block, and attention-based fusion (AF) block. Specifically, the developed attention pyramid convolutional (AttPConv) operator in the PCRD block combines multiscale convolution and channel attention (CA) to automatically learn and adjust the scale of residuals for better representation. The established AUP block uses pixel attention (PA) to perform arbitrary scales of upsampling. The AF block uses branch attention (BA) to integrate upsampled low-resolution images with high-level features. Besides, the loss function takes both adversarial loss and feature loss into consideration to guide the learning procedure of the generator. We have compared our MA-GAN approach with several state-of-the-art methods on a number of remote sensing scenes, and the experimental results consistently demonstrate the effectiveness of the proposed MA-GAN. For study replication, the source code will be released at: https://github.com/ZhihaoWang1997/MA-GAN.","1558-0644","","10.1109/TGRS.2022.3180068","National Natural Science Foundation of China(grant numbers:41971300,61901278); Key Project of Department of Education of Guangdong Province(grant numbers:2020ZDZX3045); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2022A1515011290); Natural Science Foundation of Guangdong Province(grant numbers:2021A1515011413); Shenzhen Scientific Research and Development Funding Program(grant numbers:20200803152531004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9787539","Generative adversarial network (GAN);remote sensing image;super-resolution (SR)","Remote sensing;Generators;Convolution;Generative adversarial networks;Task analysis;Spatial resolution;Interpolation","convolution;geophysical image processing;image resolution;image texture;learning (artificial intelligence);neural nets;remote sensing","multiattention generative adversarial network;remote sensing image super-resolution;super-resolution methods;high spatial resolution;image SR;deep neural networks;high-resolution remote sensing images;named multiattention GAN;MA-GAN;attention-based fusion;developed attention pyramid convolutional operator;multiscale convolution;channel attention;established AUP block;low-resolution images;remote sensing scenes","","4","","60","IEEE","3 Jun 2022","","","IEEE","IEEE Journals"
"Adaptive Diagonal Total-Variation Generative Adversarial Network for Super-Resolution Imaging","Z. San-You; C. De-Qiang; J. Dai-Hong; K. Qi-Qi; M. Lu","Department of Science and Technology, Suzhou Wujiang District Public Security Bureau, Suzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; Key Laboratory of Intelligent Industrial Control Technology of Jiangsu Province, Information and Electrical Engineering College, Xuzhou University of Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China","IEEE Access","31 Mar 2020","2020","8","","57517","57526","To address problems that the loss function does not correlate well with perceptual vision in super-resolution methods based on the convolutional neural network(CNN), a novel model called the ADTV-SRGAN is designed based on the adaptive diagonal total-variation generative adversarial network. Combined with global perception and the local structure adaptive method, spatial loss based on the diagonal variation model is proposed to make the loss function can be adjusted according to the spatial features. Pixel loss and characteristic loss are in combination with the spatial loss for the fusing optimization of the total loss function such that high-frequency details of the images are maintained to improve their quality. The results of experiment show that the proposed method can obtain competitive results in objective evaluations. In subjective assessment, images reconstructed by it are clear, delicate, and natural, and it preserved edge- and texture-related details.","2169-3536","","10.1109/ACCESS.2020.2981726","National Natural Science Foundation of China(grant numbers:51774281); National Key R&D Program of China(grant numbers:2018YFC0808302); Major Project of Natural Science Research of the Jiangsu Higher Education Institutions of China(grant numbers:18KJA520012); Xuzhou Science and Technology Plan Project(grant numbers:KC19197); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9040511","Generative adversarial network;super-resolution imaging;image reconstruction;total variation;loss function","Adaptation models;Image reconstruction;Gallium nitride;Image edge detection;Feature extraction;Generative adversarial networks","convolutional neural nets;feature extraction;image motion analysis;image reconstruction;image resolution;image texture","super-resolution methods;adaptive diagonal total-variation generative adversarial network;local structure adaptive method;spatial loss;diagonal variation model;characteristic loss;total loss function;super-resolution imaging;convolutional neural network;CNN;ADTV-SRGAN","","2","","40","CCBY","18 Mar 2020","","","IEEE","IEEE Journals"
"Face Image Super Resolution using a Generative Adversarial Network","K. Varma; G. S. Reddy; N. Subramanyam","Department of CSE, PES University; Department of CSE, PES University; Department of CSE, PES University","2021 Smart Technologies, Communication and Robotics (STCR)","10 Nov 2021","2021","","","1","8","Traditional image super resolution centered around purely mathematical models are capable of creating gradient based textures, but fail to render the specific lineaments that would be expected in a realistically upscaled image. This is especially problematic in scenarios involving images of subjects whose recognition is reliant on the presence of specific characteristics, for example, faces. In this paper, we describe a deep learning model that is capable of generating an 8x upscaled photo from a low resolution image of a face. The underlying model is based on the SRGAN architecture that deviates from the conventional GAN approach of the adversarial back and forth between generator and discriminator by incorporating an added content loss whose value is dependent on the detection of the natural features in the generated image by a pre-trained VGG model. The model is trained on the Celeb Faces Attributes dataset with over 1,00,000 data points and can produce upscaled images that are realistic with a coherent presence of the natural attributes of a face.","","978-1-6654-1806-5","10.1109/STCR51658.2021.9588816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9588816","Image Super Resolution;SRGAN;Facial Enhancement","Deep learning;Image resolution;Image recognition;Face recognition;Generative adversarial networks;Feature extraction;Mathematical models","face recognition;feature extraction;geophysical signal processing;gradient methods;image enhancement;image processing;image resolution;image texture;learning (artificial intelligence)","face image super resolution;generative adversarial network;traditional image super resolution;purely mathematical models;gradient based textures;specific lineaments;realistically upscaled image;subjects whose recognition;deep learning model;8x upscaled photo;low resolution image;conventional GAN approach;generator;added content loss whose value;pre-trained VGG model;Celeb Faces Attributes dataset;upscaled images","","","","31","IEEE","10 Nov 2021","","","IEEE","IEEE Conferences"
"Learning Spatial Attention for Face Super-Resolution","C. Chen; D. Gong; H. Wang; Z. Li; K. -Y. K. Wong","Department of Computer Science, The University of Hong Kong, Hong Kong; Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China; Department of Computer Science, The University of Hong Kong, Hong Kong","IEEE Transactions on Image Processing","21 Dec 2020","2021","30","","1219","1231","General image super-resolution techniques have difficulties in recovering detailed face structures when applying to low resolution face images. Recent deep learning based methods tailored for face images have achieved improved performance by jointly trained with additional task such as face parsing and landmark prediction. However, multi-task learning requires extra manually labeled data. Besides, most of the existing works can only generate relatively low resolution face images (e.g., 128 × 128), and their applications are therefore limited. In this paper, we introduce a novel SPatial Attention Residual Network (SPARNet) built on our newly proposed Face Attention Units (FAUs) for face super-resolution. Specifically, we introduce a spatial attention mechanism to the vanilla residual blocks. This enables the convolutional layers to adaptively bootstrap features related to the key face structures and pay less attention to those less feature-rich regions. This makes the training more effective and efficient as the key face structures only account for a very small portion of the face image. Visualization of the attention maps shows that our spatial attention network can capture the key face structures well even for very low resolution faces (e.g., 16×16). Quantitative comparisons on various kinds of metrics (including PSNR, SSIM, identity similarity, and landmark detection) demonstrate the superiority of our method over current state-of-the-arts. We further extend SPARNet with multi-scale discriminators, named as SPARNetHD, to produce high resolution results (i.e., 512×512). We show that SPARNetHD trained with synthetic data can not only produce high quality and high resolution outputs for synthetically degraded face images, but also show good generalization ability to real world low quality face images. Codes are available at https://github.com/chaofengc/Face-SPARNet.","1941-0042","","10.1109/TIP.2020.3043093","Tencent AI Lab; Research Grant Council of the Hong Kong (SAR), China(grant numbers:HKU 17203119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9293182","Face super-resolution;spatial attention;generative adversarial networks","Faces;Face recognition;Task analysis;Spatial resolution;Training;Residual neural networks;Gallium nitride","convolutional neural nets;face recognition;feature extraction;image resolution;learning (artificial intelligence);object detection","face super-resolution;general image super-resolution techniques;face structures;deep learning;face image;face parsing;landmark prediction;multitask learning;relatively low resolution face images;spatial attention mechanism;key face structures;attention maps;low resolution faces;high resolution results;synthetically degraded face images;low quality face images;face attention units;spatial attention residual network;learning spatial attention;vanilla residual blocks;convolutional layers;bootstrap features;landmark detection;multiscale discriminators;SPARNetHD;https://github.com/chaofengc/Face-SPARNet","","52","","66","IEEE","14 Dec 2020","","","IEEE","IEEE Journals"
"Enhancing Perceptual Loss with Adversarial Feature Matching for Super-Resolution","A. R. Tej; S. Sukanta Halder; A. P. Shandeelya; V. Pankajakshan","Indian Institute of Technology, Roorkee, India; Carnegie Mellon University, USA; International Institute of Information Technology, Bhubaneswar, India; Indian Institute of Technology, Roorkee, India","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","Single image super-resolution (SISR) is an ill-posed problem with an indeterminate number of valid solutions. Solving this problem with neural networks would require access to extensive experience, either presented as a large training set over natural images or a condensed representation from another pre-trained network. Perceptual loss functions, which belong to the latter category, have achieved breakthrough success in SISR and several other computer vision tasks. While perceptual loss plays a central role in the generation of photo-realistic images, it also produces undesired pattern artifacts in the super-resolved outputs. In this paper, we show that the root cause of these pattern artifacts can be traced back to a mismatch between the pre-training objective of perceptual loss and the super-resolution objective. To address this issue, we propose to augment the existing perceptual loss formulation with a novel content loss function that uses the latent features of a discriminator network to filter the unwanted artifacts across several levels of adversarial similarity. Further, our modification has a stabilizing effect on non-convex optimization in adversarial training. The proposed approach offers notable gains in perceptual quality based on an extensive human evaluation study and a competent reconstruction fidelity when tested on objective evaluation metrics.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207102","Single Image Super-Resolution;Perceptual Loss Functions;Generative Adversarial Networks","Training;Image reconstruction;Image resolution;Generators;Signal resolution;Computer architecture;Task analysis","computer vision;concave programming;image reconstruction;image resolution","perceptual loss functions;photo-realistic images;undesired pattern artifacts;super-resolved outputs;pre-training objective;super-resolution objective;content loss function;discriminator network;adversarial training;perceptual quality;perceptual loss formulation;pre-trained network;natural images;training set;neural networks;SISR;single image super-resolution;adversarial feature matching","","5","","31","IEEE","28 Sep 2020","","","IEEE","IEEE Conferences"
"Enhancing Traffic Scene Predictions with Generative Adversarial Networks","P. König; S. Aigner; M. Körner","TUM Department of Civil, Geo and Environmental Engineering, Technical University of Munich, Germany; TUM Department of Civil, Geo and Environmental Engineering, Technical University of Munich, Germany; TUM Department of Civil, Geo and Environmental Engineering, Technical University of Munich, Germany","2019 IEEE Intelligent Transportation Systems Conference (ITSC)","28 Nov 2019","2019","","","1768","1775","We present a new two-stage pipeline for predicting frames of traffic scenes where relevant objects can still reliably be detected. Using a recent video prediction network, we first generate a sequence of future frames based on past frames. A second network then enhances these frames in order to make them appear more realistic. This ensures the quality of the predicted frames to be sufficient to enable accurate detection of objects, which is especially important for autonomously driving cars. To verify this two-stage approach, we conducted experiments on the Cityscapes dataset. For enhancing, we trained two image-to-image translation methods based on generative adversarial networks, one for blind motion deblurring and one for image super-resolution. All resulting predictions were quantitatively evaluated using both traditional metrics and a state-of-the-art object detection network showing that the enhanced frames appear qualitatively improved. While the traditional image comparison metrics, i.e., MSE, PSNR, and SSIM, failed to confirm this visual impression, the object detection evaluation resembles it well. The best performing prediction-enhancement pipeline is able to increase the average precision values for detecting cars by about 9% for each prediction step, compared to the non-enhanced predictions.","","978-1-5386-7024-8","10.1109/ITSC.2019.8917046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917046","","Training;Gallium nitride;Generators;Image resolution;Object detection;Pipelines;Automobiles","image enhancement;image motion analysis;image resolution;image restoration;image sequences;neural nets;object detection;road traffic;traffic engineering computing;video signal processing","generative adversarial networks;two-stage pipeline;traffic scenes;video prediction network;image-to-image translation methods;image super-resolution;object detection network;object detection evaluation;nonenhanced predictions;prediction-enhancement pipeline;image comparison metrics;traffic scene predictions;frame sequence;Cityscapes dataset;blind motion deblurring;frame enhancement","","1","","42","IEEE","28 Nov 2019","","","IEEE","IEEE Conferences"
"Image and Video Super Resolution using Recurrent Generative Adversarial Network","O. Thawakar; P. W. Patil; A. Dudhane; S. Murala; U. Kulkarni","Shri Guru Gobind Singhji Institute of Engineering and Technology Nanded; Indian Institute of Technology Ropar, INDIA; Indian Institute of Technology Ropar, INDIA; Indian Institute of Technology Ropar, INDIA; Shri Guru Gobind Singhji Institute of Engineering and Technology Nanded","2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)","25 Nov 2019","2019","","","1","8","Recently, the convolutional neural network with residual learning models achieves high accuracy for single image super-resolution with different scale factors. With adversarial learning model, effective learning of transformation function for the low-resolution input image to a high-resolution target image can be achieved. In this paper, we propose a method for image and video super-resolution using the recurrent generative adversarial network named SR2GAN. In the proposed model (SR2GAN) we use recursive learning for video super-resolution to overcome the difficulty of learning transformation function for synthesizing realistic high-resolution images. This recursive approach helps to reduce the parameters with increasing depth of the model. An extensive evaluation is performed to examine the effectiveness of the proposed model, which shows that SR2GAN performs better in terms of peak signal to noise ratio (PSNR) and structural self-similarity index (SSIM) as compared to the state-of-the-art methods for super-resolution. For source code and supplementary material visit: https://github.com/OmkarThawakar/SR2GAN/.","2643-6213","978-1-7281-0990-9","10.1109/AVSS.2019.8909900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8909900","","Generators;Training;Decoding;Generative adversarial networks;Image restoration","image resolution;learning (artificial intelligence);recurrent neural nets","high-resolution images;video super resolution;recurrent generative adversarial network;convolutional neural network;residual learning models;single image super-resolution;scale factors;adversarial learning model;transformation function;low-resolution input image;high-resolution target image;video super-resolution;recursive learning;SR2GAN framework;peak signal to noise ratio;PSNR;structural self-similarity index;SSIM","","7","","39","IEEE","25 Nov 2019","","","IEEE","IEEE Conferences"
"Game Image Quality Enhancement Algorithm based on Generative Adversarial Network and Knowledge Distillation","L. Li; J. Xiahou","College of Informatics, Xiamen University, Xiamen, China; Quanzhou Normal University, Quanzhou, China","2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)","3 Aug 2022","2022","10","","2570","2575","Nowadays, with the development of computer graphics and the improvement of related hardware, the picture quality of games is getting higher and higher. Today's mainstream games support resolutions up to 4k or above. At the same time, for a large number of excellent games in the past, the picture quality is far behind today due to technical and hardware limitations at the time. Blurred picture quality is becoming more and more unbearable for users. For this reason, the game company will spend a lot of resources to reset the game to meet the needs of these users. The combination of super-resolution technology based on deep learning and generative adversarial networks can effectively improve image resolution. In this paper, we combines ESRGAN(Enhanced Super-Resolution Generative Adversarial Networks)to design a real-time game image quality enhancement algorithm, and distilled the model, reduce parameters for increase the game frames.","2693-2865","978-1-6654-2207-9","10.1109/ITAIC54216.2022.9836707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9836707","image super resolution;Generative Adversarial Network;Knowledge Distillation","Knowledge engineering;Image quality;Superresolution;Games;Production;Jitter;Rendering (computer graphics)","computer games;image enhancement;image resolution","computer graphics;technical hardware limitations;blurred picture quality;game company;super-resolution technology;image resolution;enhanced super-resolution generative adversarial networks;real-time game image quality enhancement algorithm;game frames;knowledge distillation;ESRGAN","","","","9","IEEE","3 Aug 2022","","","IEEE","IEEE Conferences"
"Generative Adversarial Network-based Image Super-Resolution with a Novel Quality Loss","X. Zhu; L. Zhang; L. Zhang; X. Liu; Y. Shen; S. Zhao","School of Software Engineering, Tongji University, Shanghai, China; School of Software Engineering, Tongji University, Shanghai, China; School of Software Engineering, Tongji University, Shanghai, China; School of Software Engineering, Tongji University, Shanghai, China; School of Software Engineering, Tongji University, Shanghai, China; School of Software Engineering, Tongji University, Shanghai, China","2019 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)","10 Feb 2020","2019","","","1","2","Single Image Super-Resolution (SISR) has been a very attractive research topic in recent years. Breakthroughs in SISR have been achieved due to deep learning and Generative Adversarial Networks (GANs). However, the generated image still suffers from undesired artifacts. In this paper, we propose a new method named GMGAN for SISR tasks. In this method, to generate images more in line with Human Vision System (HVS), we design a quality loss by integrating an IQA metric named Gradient Magnitude Similarity Deviation (GMSD). To our knowledge, it is the first time to truly integrate an IQA metric into SISR. Moreover, to overcome the instability of the original GAN, we use a variation of GANs named WGAN-GP. Experiments show that GMGAN with quality loss and WGAN-GP can generate visually appealing results and set a new state-of-art.","2642-3529","978-1-7281-3038-5","10.1109/ISPACS48206.2019.8986250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8986250","Single Image Super-Resolution;Image Quality Assessment;Generative Adversarial Network","","gradient methods;image resolution;learning (artificial intelligence);neural nets","generative adversarial network-based image super-resolution;novel quality loss;Single Image Super-Resolution;deep learning;SISR tasks;GA;human vision system;IQA metric;gradient magnitude similarity deviation;human vision system","","3","","5","IEEE","10 Feb 2020","","","IEEE","IEEE Conferences"
"An Improved SRGAN Based Ambiguity Suppression Algorithm for SAR Ship Target Contrast Enhancement","J. Ai; G. Fan; Y. Mao; J. Jin; M. Xing; H. Yan","Key Laboratory of Radar Imaging and Microwave Photonics, Nanjing University of Aeronautics and Astronautics, Ministry of Education, Nanjing, China; Intelligent Interconnected Systems Laboratory of Anhui, Hefei University of Technology, Hefei, China; Intelligent Interconnected Systems Laboratory of Anhui, Hefei University of Technology, Hefei, China; Intelligent Interconnected Systems Laboratory of Anhui, Hefei University of Technology, Hefei, China; Academy of Advanced Interdisciplinary Research, Xidian University, Xi’an, China; Key Laboratory of Radar Imaging and Microwave Photonics, Nanjing University of Aeronautics and Astronautics, Ministry of Education, Nanjing, China","IEEE Geoscience and Remote Sensing Letters","29 Dec 2021","2022","19","","1","5","Due to the specific characteristics of synthetic aperture radar (SAR), there will be ambiguity interference in SAR images, resulting in low contrast of the ship target to the clutter. This letter proposes an improved super-resolution generative adversarial network (ISRGAN) based ambiguity suppression algorithm for SAR ship target contrast enhancement. The proposed ISRGAN is the first attempt of using GAN for SAR ambiguity suppression. As a post-processing procedure, it does not need prior information of SAR systems, so it can be applied to various observation scenes and different acquisition modes. The generator of ISRGAN embeds the residual dense network (RDN) to optimally fuse the global and local features of the image, and it effectively improves the completeness of the feature information used for SAR ship target contrast enhancement. The superiority of ISRGAN on ambiguity suppression is validated on the Chinese Gaofen-3 imagery.","1558-0571","","10.1109/LGRS.2021.3111553","National Natural Science Foundation of China(grant numbers:62071164,61701157); China Postdoctoral Science Foundation(grant numbers:2020T130165); open fund of Key Laboratory of Radar Imaging and Microwave Photonics, Nanjing University of Aeronautics and Astronautics, Ministry of Education(grant numbers:NJ20210008); Fundamental Research Funds for the Central Universities of China(grant numbers:JZ2020HGTB0012,PA2021AKSK0113); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9539247","Azimuth ambiguity suppression;improved super-resolution generative adversarial network (ISRGAN);synthetic aperture radar (SAR);target contrast enhancement","Feature extraction;Synthetic aperture radar;Convolution;Marine vehicles;Radar polarimetry;Generators;Generative adversarial networks","image enhancement;image resolution;object detection;radar imaging;ships;synthetic aperture radar","SAR ship target contrast enhancement;ISRGAN;improved SRGAN based ambiguity suppression algorithm;SAR images;super-resolution generative adversarial network based ambiguity suppression algorithm;SAR ambiguity suppression;SAR systems","","3","","15","IEEE","16 Sep 2021","","","IEEE","IEEE Journals"
"Binocular Infrared Depth Estimation Based On Generative Adversarial Network","J. Wang; K. Geng; G. Yin; X. Cheng; Y. Sun; P. Ding","School of Mechanical Engeering, Southeast University, Nanjing, China; School of Mechanical Engeering, Southeast University, Nanjing, China; School of Mechanical Engeering, Southeast University, Nanjing, China; School of Mechanical Engeering, Southeast University, Nanjing, China; School of Mechanical Engeering, Southeast University, Nanjing, China; School of Mechanical Engeering, Southeast University, Nanjing, China","2022 6th CAA International Conference on Vehicular Control and Intelligence (CVCI)","8 Dec 2022","2022","","","1","6","Dedicated to the fulfillment of the all-weather scene perception of intelligent vehicle, our work focus on depth estimation based on binocular infrared image. First of all, considering the rareness of binocular infrared datasets, we apply a top-down attention and gradient alignment based on generative adversarial network (GAN) to convert binocular visible datasets into pseudo-infrared datasets, which was used to fine-tune the depth estimation network. In this way, the basal function of binocular infrared depth estimation could be achieved. Then, the enhancement and super-resolution (SR) preprocessing method based on high-order degradation modeling process was introduced to enhance the image edge information and enrich the image details. The experiment results showed that the image details are richer after SR, which improves the accuracy and breadth of binocular depth perception by 5%.","","978-1-6654-5374-5","10.1109/CVCI56766.2022.9964565","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9964565","Infrared image;binocular depth estimation;generative adversarial network;super-resolution","Degradation;Intelligent vehicles;Image edge detection;Superresolution;Estimation;Generative adversarial networks","edge detection;image fusion;infrared imaging;neural nets;spatial variables measurement;stereo image processing;visual perception","all-weather scene perception;binocular depth perception;binocular infrared datasets;binocular infrared depth estimation;binocular infrared image;binocular visible datasets;depth estimation network;enhancement method;GAN;generative adversarial network;gradient alignment;high-order degradation modeling process;image details;image edge information enhancement;intelligent vehicle;pseudoinfrared datasets;super-resolution preprocessing method;top-down attention","","","","11","IEEE","8 Dec 2022","","","IEEE","IEEE Conferences"
"A Dual Regression Scheme to Improve GAN in Low-Dose CT Scan Restoration","X. Zhang","Mechanical Engineering, College of Engineering, Boston University","2022 International Conference on Big Data, Information and Computer Network (BDICN)","20 Apr 2022","2022","","","732","737","The application of Super Resolution (SR) technology on recovering low-dose medical image is gaining its importance nowadays. Because it can provide as many contextual details as high-dose CT for physi-cians without harming the patient or spending more on devices. Usage of Deep Learning (DL) on SR tasks has been developed many years, and Generative Adversarial Network (GAN) plays a leading role among them. In this paper, we find that using a special closed-loop scheme, dual network, can strongly improve the performance of GAN model, with about 1.2 point of improvement in PSNR. And the best way to implement this dual network is also evaluated.","","978-1-6654-8476-3","10.1109/BDICN55575.2022.00142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9758446","Super-resolution;Dual regression;GAN;CT-scans","Performance evaluation;Deep learning;Image resolution;Computed tomography;Generative adversarial networks;Generators;Data models","computerised tomography;deep learning (artificial intelligence);diagnostic radiography;image reconstruction;medical image processing;regression analysis","deep learning;GAN model;dual network;special closed-loop scheme;generative adversarial network;SR tasks;high-dose CT;low-dose medical image;super resolution technology;low-dose CT scan restoration;dual regression scheme","","","","25","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Investigating the Effects of Image Correction Through Affine Transformations on Licence Plate Recognition","A. Boby; D. Brown; J. Connan; M. Marais","Computer Science, Rhodes University, Grahamstown, South Africa; Computer Science, Rhodes University, Grahamstown, South Africa; Computer Science, Rhodes University, Grahamstown, South Africa; Computer Science, Rhodes University, Grahamstown, South Africa","2022 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)","22 Aug 2022","2022","","","1","6","Licence plate recognition has many real-world applications, which fall under security and surveillance. Deep learning for licence plate recognition has been adopted to improve existing image-based processing techniques in recent years. Object detectors are a popular choice for approaching this task. All object detectors are some form of a convolutional neural network. The You Only Look Once framework and Region-Based Convolutional Neural Networks are popular models within this field. A novel architecture called the Warped Planar Object Detector is a recent development by Zou et al. that takes inspiration from YOLO and Spatial Network Transformers. This paper aims to compare the performance of the Warped Planar Object Detector and YOLO on licence plate recognition by training both models with the same data and then directing their output to an Enhanced Super-Resolution Generative Adversarial Network to upscale the output image, then lastly using an Optical Character Recognition engine to classify characters detected from the images.","","978-1-6654-8422-0","10.1109/icABCD54961.2022.9856380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9856380","object detection;optical character recognition;generative adversarial network;spatial network transformer;super-resolution","Surveillance;Image recognition;Superresolution;Detectors;Transformers;Generative adversarial networks;Convolutional neural networks;License plate recognition","deep learning (artificial intelligence);image resolution;object detection;optical character recognition;traffic engineering computing","optical character recognition engine;enhanced super resolution generative adversarial network;YOLO;planar object detector;spatial network transformers;image based processing techniques;deep learning;surveillance;security;affine transformations;image correction;warped planar object detector;licence plate recognition;convolutional neural networks","","","","20","IEEE","22 Aug 2022","","","IEEE","IEEE Conferences"
"A Novel Framework for Denoised High Resolution Generative Adversarial Network – DHRGAN","R. Kumar; S. Kumar Maji","Dept. of Computer Science & Engineering, Indian Institute of Technology Patna, Patna, India; Dept. of Computer Science & Engineering, Indian Institute of Technology Patna, Patna, India","2020 7th International Conference on Signal Processing and Integrated Networks (SPIN)","20 Apr 2020","2020","","","1033","1038","The advent of deeper convolutional neural networks and related methodologies have made significant achievements in the area of single image super-resolution (SISR). However, none of these techniques are equipped to handle noisy images, i.e., denoising the image as well as enhancing its spatial resolution. In this paper, we propose a denoised high resolution generative adversarial network (DHRGAN), capable of handling noise removal from given sample images while trying to super-resolve it to the desired magnification. As per our knowledge, this is the first GAN framework equipped to remove noise while simultaneously trying to magnify images. To accomplish this, we propose a two-layered generator network in addition to the discriminator network. In the upper layer of the generator network (also called UDCNN), we make use of the mean square error function for training samples while in the lower layer of generator network (called LSRResNet) we make use of a perceptual loss function (comprising of content loss function and adversarial loss function) for the same. We train the discriminator network, which is responsible for separating super-resolved images and ground truth images, using the adversarial loss function, thereby making the generator more robust. The content loss function that we employ in the generator actuates perceptual similarity rather than pixel similarity, which further strengthens its robustness. The resulting DHRGAN network can recover more realistic textures from heavily downsampled noisy images. We have used speckle noise, a common noise observed in natural scenes captured by airborne acquisition devices, to check the performance of DHRGAN. Experiments performed on standard image database, both visually and quantitatively, justify the superior performance of DHRGAN over existing similar networks.","2688-769X","978-1-7281-5475-6","10.1109/SPIN48934.2020.9071211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9071211","Super-Resolution;Denoising;Speckle noise;DHRGAN;Perceptual similarity","Image resolution;Generators;Generative adversarial networks;Gallium nitride;Convolution;Signal resolution;Noise measurement","image denoising;image resolution;image sampling;image texture;natural scenes;neural nets;visual databases","deeper convolutional neural networks;related methodologies;single image super-resolution;spatial resolution;noise removal;sample images;generator network;discriminator network;mean square error function;perceptual loss function;content loss function;adversarial loss function;ground truth images;resulting DHRGAN network;heavily downsampled noisy images;standard image database;similar networks;denoised high resolution generative adversarial network","","","","17","IEEE","20 Apr 2020","","","IEEE","IEEE Conferences"
"Review on Generative Adversarial Network in Computer Vision: Methods and Metrics","S. Bao","Southwest Jiaotong University, Chengdu, China","2021 2nd International Conference on Big Data & Artificial Intelligence & Software Engineering (ICBASE)","3 Feb 2022","2021","","","535","542","Generate adversarial networks (GAN) is a popular method, which can be widely used in numerous research areas, such as computer vision, natural language processing, and time series synthesis. However, few references are proposed to give a comprehensive review on GAN based methods. This paper aims to provide a detailed review of GAN based algorithms on computer vision tasks, such as image style transfer, image/video generation, image matting, and image super-resolution. Furthermore, we conclude the evaluation metrics for those tasks to show the effectiveness of GAN based on method. Our review can help beginners recognize the GAN based methods and give a brief introduction on how to apply them to their tasks.","","978-1-6654-2709-8","10.1109/ICBASE53849.2021.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9696113","GAN;Image style transfer;Image matting;Image generation;Video generation;Image super-resolution","Measurement;Computer vision;Superresolution;Time series analysis;Generative adversarial networks;Natural language processing;Task analysis","computer vision;image resolution;natural language processing;time series;video signal processing","generative adversarial network;generate adversarial networks;numerous research areas;natural language processing;time series synthesis;GAN based methods;GAN based algorithms;computer vision tasks;image style;image matting;image super-resolution;evaluation metrics","","","","29","IEEE","3 Feb 2022","","","IEEE","IEEE Conferences"
"YOLOv5-based ALPR Improvement using Selective SR-GAN","N. Pourhadi; B. Shafizadeh; F. Eshghi; M. Kelarestaghi","Electrical and Computer Engineering Department, Kharazmi University, Tehran, Iran; Electrical and Computer Engineering Department, Kharazmi University, Tehran, Iran; Electrical and Computer Engineering Department, Kharazmi University, Tehran, Iran; Electrical and Computer Engineering Department, Kharazmi University, Tehran, Iran","2022 2nd International Conference on Computing and Machine Intelligence (ICMI)","5 Sep 2022","2022","","","1","6","Automatic License-Plate Recognition (ALPR) has widespread use in Intelligent Transportation Systems (ITS), security and surveillance systems, and crime investigation. However, the lack of a fixed setup and involvement of cameras with different qualities give rise to the generation of low-resolution (LR) images. Therefore, more recently introduced deep-learning resolution-upgrade algorithms are essential in modern ALPR systems. In this paper, we propose an additional selective Generative-Adversarial-Network (GAN) Super Resolution (SR) step between the two state-of-the-art You-Only-Look-Once (YOLO)v5-based License-Plate Detection (LPD) and Character Recognition (CR) steps. SR-GAN is proposed due to its perceptual information maintenance. Furthermore, selectiveness is suggested to avoid unnecessary high time-complexity impact. The experimental results show a significant accuracy increase of 18% and an average runtime of 86ms, suitable for many real-time applications.","","978-1-6654-7483-2","10.1109/ICMI55296.2022.9873675","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9873675","Deep Learning;Intelligent Transportation System;License-Plate Detection;Generative Adversarial Network;Super Resolution","Image resolution;Runtime;Surveillance;Transportation;Maintenance engineering;Cameras;Generative adversarial networks","cameras;deep learning (artificial intelligence);feature extraction;image resolution;intelligent transportation systems;object detection;object recognition;optical character recognition","YOLOv5-based ALPR Improvement;crime investigation;low-resolution images;deep-learning resolution-upgrade algorithms;ALPR systems;character recognition;automatic license-plate recognition;selective SR-GAN;intelligent transportation systems;security-surveillance systems;cameras;selective generative-adversarial-network super resolution step;you-only-look-once v5-based license-plate detection;time-complexity impact","","","","21","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Dual Discriminator Generative Adversarial Network for Single Image Super-Resolution","P. Yuan; Y. Zhang","Yunnan Normal University, Kunming, China; Yunnan Normal University, Kunming, China","2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","23 Jan 2020","2019","","","1","7","Single image super-resolution(SISR) is to reconstruct a high resolution(HR) image from a single low resolution(LR) image. In this paper, with generative adversarial networks(GAN) model as the basic component, we build a dual discriminator super-resolution reconstruction network(DDSRRN) to improve the quality of image super-resolution reconstruction. By adding another discriminator based on GAN, we combine the Kullback-Leibler(KL) with reverse KL divergence to make a unified objective function to train the two discriminators, and by using the complementary statistical characteristics of these two divergences, the prediction density is effectively dispersed in multi-mode, which can avoid collapse of the network model during the reconstruction process and improve the stability of model training. We build the content loss function using the Charbonnier loss and use the intermediate features information of the two discriminators to build the perceptual loss function and style loss function. The experimental results show that the proposed method has sharp edges and rich details in subjective vision, and obtains better subjective visual evaluation and objective quantitative evaluation.","","978-1-7281-4852-6","10.1109/CISP-BMEI48845.2019.8965727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8965727","Generative Adversarial Networks;Convolutional Neural Network;Image Super-resolution Reconstruction;Deep Learning;KL Divergence","","image reconstruction;image resolution;learning (artificial intelligence);neural nets","content loss function;perceptual loss function;style loss function;dual discriminator generative adversarial network;image super-resolution reconstruction;reverse KL divergence;objective function;network model;Kullback-Leibler divergence;subjective visual evaluation;objective quantitative evaluation","","","","28","IEEE","23 Jan 2020","","","IEEE","IEEE Conferences"
"Image Super-Resolution Reconstruction Based on a Generative Adversarial Network","Y. Wu; L. Lan; H. Long; G. Kong; X. Duan; C. Xu","School of Computer Science and Technology, Guizhou University, Guiyang, China; School of Computer Science and Technology, Guizhou University, Guiyang, China; School of Computer Science and Technology, Guizhou University, Guiyang, China; School of Computer Science and Technology, Guizhou University, Guiyang, China; School of Computer Science and Technology, Guizhou University, Guiyang, China; School of Computer Science and Technology, Guizhou University, Guiyang, China","IEEE Access","7 Dec 2020","2020","8","","215133","215144","In the field of computer vision, super-resolution reconstruction techniques based on deep learning have undergone considerable advancement; however, certain limitations remain, such as insufficient feature extraction and blurred image generation. To address these problems, we propose an image super-resolution reconstruction model based on a generative adversarial network. First, we employ a dual network structure in the generator network to solve the problem of insufficient feature extraction. The dual network structure is divided into an upsample subnetwork and a refinement subnetwork, which upsample and optimize a low-resolution image, respectively. In a scene with large upscaling factors, this structure can reduce the negative effect of noise and enhance the utilization of high-frequency details, thereby generating high-quality reconstruction results. Second, to generate sharper super-resolution images, we use the perceptual loss, which exhibits a fast convergence and excellent visual effect, to guide the generator network training. We apply the ResNeXt-50-$32\times 4\text{d}$ network, which has few parameters and a large depth, to calculate the loss to obtain a reconstructed super-resolution image that is highly realistic. Finally, we introduce the Wasserstein distance into the discriminator network to enhance the discrimination ability and stability of the model. Specifically, this distance is employed to eliminate the activation function in the last layer of the network and avoid the use of the logarithm in calculating the loss function. Extensive experiments on the DIV2K, Set5, Set14, and BSD100 datasets demonstrate the effectiveness of the proposed model.","2169-3536","","10.1109/ACCESS.2020.3040424","National Natural Science Foundation of China(grant numbers:[2018]61741124); Science Planning Project of Guizhou Province, Guizhou Science and Technology Cooperation Platform Talent [2018](grant numbers:5781); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9269971","Deep learning;dual network structure;generative adversarial network;perceptual loss;super-resolution","Image segmentation;Semantics;Feature extraction;Generative adversarial networks;Generators;Stability analysis;Image reconstruction","feature extraction;image reconstruction;image resolution;image sampling;learning (artificial intelligence);neural nets","generative adversarial network;feature extraction;blurred image generation;image super-resolution reconstruction model;Wasserstein distance;discriminator network;generator network training;high-quality reconstruction results;low-resolution image;upsample subnetwork;dual network structure","","6","","32","CCBY","25 Nov 2020","","","IEEE","IEEE Journals"
"Least Squares Relativistic Generative Adversarial Network for Perceptual Super-Resolution Imaging","S. Zhang; D. Cheng; D. Jiang; Q. Kou","Department of Science and Technology, Suzhou Wujiang District Public Security Bureau Population Management Brigade, Suzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; Information and Electrical Engineering College, Xuzhou University of Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China","IEEE Access","19 Oct 2020","2020","8","","185198","185208","Currently, deep-learning-based methods have been the most popular super-resolution techniques owing to the improvement of super-resolution performance. However, they are still lack perceptual fine details and thus result in unsatisfying visual quality. This article proposes a novel method for high-quality perceptual super-resolution imaging, named SRLRGAN-SN. It aims to recovery visually plausible images with perceptual texture details by using the least squares relativistic generative adversarial network (GAN). The method applies the spectral normalization on the network with the target of enhancing the performance of GAN for super-resolution task. The least squares relativistic discriminator is designed to drive reconstruction images approximating high-quality perceptual manifold. Besides, a novel perceptual loss assembly is proposed to preserve structural texture details as much as possible. Results of experiment show that our method can not only recovery more visually realistic details, but also outperforms other popular methods regarding to quantitative metrics and perceptual evaluations.","2169-3536","","10.1109/ACCESS.2020.3030044","National Natural Science Foundation of China(grant numbers:51774281); National Key Research and Development Program of China(grant numbers:2018YFC0808302); Major Project of Natural Science Research of the Jiangsu Higher Education Institutions of China(grant numbers:18KJA520012); Xuzhou Science and Technology Plan Project(grant numbers:KC19197); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9220103","Generative adversarial network;super-resolution imaging;relativistic discriminator;perceptual quality;spectral normalization","Generative adversarial networks;Gallium nitride;Training;Imaging;Generators;Task analysis","image reconstruction;image resolution;image texture;learning (artificial intelligence);least squares approximations;neural nets","least squares relativistic discriminator;spectral normalization;SRLRGAN-SN;image reconstruction;perceptual texture details;visually plausible images;high-quality perceptual super-resolution imaging;visual quality;deep learning;least squares relativistic generative adversarial network;perceptual evaluations;visually realistic details;structural texture details;perceptual loss assembly;high-quality perceptual manifold","","4","","45","CCBY","12 Oct 2020","","","IEEE","IEEE Journals"
"Multi-Stage Generation of Tile Images Based on Generative Adversarial Network","J. Lu; M. Shi; Y. Lu; C. -C. Chang; L. Li; R. Bai","College of Computer Science, Hangzhou Dianzi University, Hangzhou, China; College of Computer Science, Hangzhou Dianzi University, Hangzhou, China; College of Computer Science, Hangzhou Dianzi University, Hangzhou, China; Department of Computer Science, University of Warwick, Coventry, U.K; College of Computer Science, Hangzhou Dianzi University, Hangzhou, China; Key Laboratory of Brain Machine Collaborative Intelligence of Zhejiang Province, Hangzhou, China","IEEE Access","12 Dec 2022","2022","10","","127502","127513","Deep learning techniques have been recently widely used in the field of texture image generation. There are still two major problems when applying them to tile image design work. On the one hand, there is still lack of enough diverse ceramic tile images for the training process. On the other hand, the output image is difficult to control and adjust, and cannot meet the designer’s requirements of interactivity. Therefore, we propose a multi-stage generation algorithm of tile images based on generative adversarial network(GAN). First, the multi-scale attention GAN is applied to generate controllable texture image. Then, the SWAG texture synthesis GAN is also applied to obtain controllable and diverse image style. And finally, through the style iteration mechanism and the multiple step magnification method based on image super-resolution reconstruction network, the final tile images can be automatically generated with larger-size and higher-precision. The relevant experiments demonstrate that our method can not only generate high-quality tile images in a relatively short period of time, but also consider human interaction to a certain extent, and maintain a certain degree of control over the main texture and style of the final generated tile images. It has good and wide application value.","2169-3536","","10.1109/ACCESS.2022.3218636","National Natural Science Foundation of China(grant numbers:62172132); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9933808","Tile images;generative adversarial networks;style transfer;image super-resolution magnification","Generative adversarial networks;Generators;Superresolution;Image reconstruction;Training;Feature extraction","deep learning (artificial intelligence);image reconstruction;image resolution;image texture;tiles","controllable image style;controllable texture image;deep learning techniques;diverse ceramic tile images;diverse image style;final generated tile images;final tile images;high-quality tile images;image super-resolution reconstruction network;multiscale attention GAN;multistage generation algorithm;SWAG texture synthesis;texture image generation;tile image design work","","","","33","CCBY","1 Nov 2022","","","IEEE","IEEE Journals"
"Performance Enhancement of BOTDA Based on the Image Super-Resolution Reconstruction","Y. Hu; Q. Shang","China Mobile Research and Development Center, Hangzhou, China; Department of Electronic and Communication Engineering, North China Electric Power University, Baoding, China","IEEE Sensors Journal","11 Feb 2022","2022","22","4","3397","3404","The acquisition time of Brillouin optical time domain analysis (BOTDA) sensor is relatively long since it requires multiple scans of probe tones to map the Brillouin gain spectra (BGS). To enhance the performance of BOTDA with fewer probe tones and lower time-domain sampling rate, we propose a method based on generative adversarial network (GAN) to reconstruct the super-resolution BGS from its low-resolution counterpart for <inline-formula> <tex-math notation=""LaTeX"">$4\times $ </tex-math></inline-formula> upscaling factors. We preliminarily prepare a dataset composed of ideal BGSs with different linewidths, spatial resolutions, and Brillouin frequency shifts (BFS) for network training and create a 2048-level colormap for the conversion between BGS and its RGB image. By cropping the measured BGS into consecutive frames and making cross-correlation to transform each frame to a new one with nearly ideal Lorentzian shape as input for the independent reconstruction, the <inline-formula> <tex-math notation=""LaTeX"">$4\times $ </tex-math></inline-formula> enlarged super-resolved BGS conforming to the real BGS distribution could be established. The validity of our method was shown through a conventional BOTDA experiment. The results show that 75% measurements were reduced and the resolution in spatial and frequency domain were raised by 4 times, and the measurement accuracy also got greatly improved.","1558-1748","","10.1109/JSEN.2021.3139321","National Natural Science Foundation of China(grant numbers:61775057); Natural Science Foundation of Hebei Province of China(grant numbers:2019502179); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9665753","Brillouin optical time-domain analyzer;Brillouin gain spectrum;generative adversarial networks;image super-resolution;deep learning","Generators;Training;Image reconstruction;Sensors;Scattering;Frequency measurement;Time-domain analysis","Brillouin spectra;distributed sensors;fibre optic sensors;frequency-domain analysis;image reconstruction;image resolution;optical images;optical neural nets;spectral line breadth;time-domain analysis","Brillouin optical time domain analysis sensor;Brillouin gain spectra;probe tones;time-domain sampling rate;generative adversarial network;super-resolution BGS;spatial resolutions;Brillouin frequency shifts;2048-level colormap;RGB image;cross-correlation;Lorentzian shape;BGS distribution;image super-resolution reconstruction;BOTDA sensor;linewidths","","","","22","IEEE","30 Dec 2021","","","IEEE","IEEE Journals"
"Feature Super-Resolution: Make Machine See More Clearly","W. Tan; B. Yan; B. Bare","School of Computer Science, Fudan University; Fudan University, Shanghai, Shanghai, CN; School of Computer Science, Fudan University","2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","16 Dec 2018","2018","","","3994","4002","Identifying small size images or small objects is a notoriously challenging problem, as discriminative representations are difficult to learn from the limited information contained in them with poor-quality appearance and unclear object structure. Existing research works usually increase the resolution of low-resolution image in the pixel space in order to provide better visual quality for human viewing. However, the improved performance of such methods is usually limited or even trivial in the case of very small image size (we will show it in this paper explicitly). In this paper, different from image super-resolution (ISR), we propose a novel super-resolution technique called feature super-resolution (FSR), which aims at enhancing the discriminatory power of small size image in order to provide high recognition precision for machine. To achieve this goal, we propose a new Feature Super-Resolution Generative Adversarial Network (FSR-GAN) model that transforms the raw poor features of small size images to highly discriminative ones by performing super-resolution in the feature space. Our FSR-GAN consists of two subnetworks: a feature generator network G and a feature discriminator network D. By training the G and the D networks in an alternative manner, we encourage the G network to discover the latent distribution correlations between small size and large size images and then use G to improve the representations of small images. Extensive experiment results on Oxford5K, Paris, Holidays, and Flick100k datasets demonstrate that the proposed FSR approach can effectively enhance the discriminatory ability of features. Even when the resolution of query images is reduced greatly, e.g., 1/64 original size, the query feature enhanced by our FSR approach achieves surprisingly high retrieval performance at different image resolutions and increases the retrieval precision by 25% compared to the raw query feature.","2575-7075","978-1-5386-6420-9","10.1109/CVPR.2018.00420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8578518","","Image resolution;Feature extraction;Gallium nitride;Generative adversarial networks;Data models;Image recognition;Euclidean distance","image representation;image resolution;image retrieval;neural nets","query images;FSR approach;raw query feature;low-resolution image;image super-resolution;Feature Super-Resolution Generative Adversarial Network model;FSR-GAN;feature discriminator network;feature generator network","","22","","23","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"Image Creation Based on Transformer and Generative Adversarial Networks","H. Liu; Q. Liu","School of Computer and Control Engineering, Yantai University, Yantai, China; School of Computer and Control Engineering, Yantai University, Yantai, China","IEEE Access","17 Oct 2022","2022","10","","108296","108306","To address the problem of low authenticity of generated images in existing generative models, the transformer super-resolution generative adversarial network(TransSRGAN) model based on the generative adversarial network is proposed. The generator of the model uses the transformer encoder sub-module as the basic module. The features of the input vector are extracted. low-definition images are generated through the transformer encoder submodule, and the low-definition image is up-sampled by the convolutional neural network to complete the image generation. The discriminator of this model uses the convolutional neural network as the basic module. To discriminate the real samples from the generated fake samples, the discriminator extracts the image features by the convolutional neural network. The experimental results show that the TransSRGAN model brings the distribution of the generated samples closer to the training samples, effectively raises the quality of the generated samples, improves the authenticity of the generated samples, and enriches the diversity of the generated samples. During the training process, there was no mode collapse or instability.","2169-3536","","10.1109/ACCESS.2022.3213079","National Natural Science Foundation of China(grant numbers:62172351); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9913966","Image generation;generative adversarial network;transformer;self-attention","Generative adversarial networks;Transformers;Feature extraction;Training data;Convolutional neural networks;Image generation;Image synthesis;Superresolution;Encoding","convolutional neural nets;image resolution;image sampling","TransSRGAN model;image generation;convolutional neural network;transformer encoder submodule;low-definition image;basic module;transformer encoder sub-module;generative models;image creation","","","","28","CCBY","10 Oct 2022","","","IEEE","IEEE Journals"
"Edge Guided Learning for Image Super-resolution with Realistic Textures","Z. Li; Z. Zhong; Z. Chen; G. Yao; X. Chen; W. Huang","Department of Computer Science, Jinan University, Guangzhou, China; Department of Computer Science, Jinan University, Guangzhou, China; Department of Computer Science, Jinan University, Guangzhou, China; Department of Computer Science, Jinan University, Guangzhou, China; Department of Computer Science, Jinan University, Guangzhou, China; Guangfa Bank, Guangzhou, China","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","8","Super-resolution (SR) methods are used to reconstruct details in images to obtain an improved resolution. Recently, SR methods based on generative adversarial networks (GANs) have become seminal due to their effectiveness in generating textures. However, a common problem is the presence of unpleasant artifacts. In this paper, an edge-guided SR neural network (Edge-SRN) is proposed by introducing a plug-in edge detection module and incorporating a new edge loss, which increases the reconstruction accuracy and reduces artifacts. We also use the Edge-SRN as a teacher network to a knowledge distillation framework for training a lightweight student SR model. The student model learned from Edge-SRN outperforms its counterparts learned from GAN-based teachers or from the ground-truth HR images in both reconstruction accuracy and perceptual quality, which indicates the ability of reconstructing realistic textures can be transferred well from Edge-SRN to a small model. Extensive experiments on diverse criteria show the promising performance of our method compared with several state-of-the-art SR methods in the qualitative and quantitative evaluations. Our code is available at https://github.com/lizhangray/Edge-SRN","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9891974","National Natural Science Foundation of China(grant numbers:62071201,U2031104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9891974","Super-resolution;Texture quality;Knowledge distillation","Training;Knowledge engineering;Laplace equations;Codes;Image edge detection;Superresolution;Neural networks","edge detection;image reconstruction;image resolution;image texture;learning (artificial intelligence);neural nets","image super-resolution;realistic textures;super-resolution methods;generative adversarial networks;generating textures;edge-guided SR neural network;edge loss;reconstruction accuracy;teacher network;lightweight student SR model;GAN-based teachers;state-of-the-art SR methods","","","","44","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"Face Beauty: Improving Quality of Face with Semantic Segmentation Prior and Style Encoder","Y. Deng; Y. Zhou; J. Lan; Y. Huang; Q. Gao; T. Tong","Fujian Key Lab of Medical Instrumentation & Pharmaceutical Technology, Fuzhou University, Fujian, China; Fujian Key Lab of Medical Instrumentation & Pharmaceutical Technology, Fuzhou University, Fujian, China; Fujian Key Lab of Medical Instrumentation & Pharmaceutical Technology, Fuzhou University, Fujian, China; Fujian Key Lab of Medical Instrumentation & Pharmaceutical Technology, Fuzhou University, Fujian, China; Imperial Vision Technology, Fuzhou, Fujian, China; Imperial Vision Technology, Fuzhou, Fujian, China","2020 Cross Strait Radio Science & Wireless Technology Conference (CSRSWTC)","11 Mar 2021","2020","","","1","3","Despite image super-resolution has great progress in recent years, state-of-the-art face super-resolution still has much potential to promote visual quality. Most of these methods utilize a deep convolutional neural network to explore a mapping between low resolution and high resolution, but it cannot well explore facial structures and local knowledge. In this work, we propose a face hallucination method that explicitly incorporates semantic segmentation prior and style encoder to improve the quality of low resolution face images. To enhance the feature mapping and color mapping of the face, we focus on transferring the prior information extracted from the segmentation mask to the super-resolution process. Furthermore, we add the color attention residual block as a color fidelity unit to preserve the color information of the mapped area. In this way, we can input the latent code generated by the style encoder as parameters into the network to improve the image quality. Experimental results demonstrate that our proposed model achieves superior performance over state-of-the-art approaches including the enhanced super-resolution generative adversarial networks (ESRGAN) and Residual Channel Attention Networks (RCAN).","","978-1-7281-8181-3","10.1109/CSRSWTC50769.2020.9372584","National Natural Science Foundation of China(grant numbers:61901120,61802065); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9372584","face hallucination;semantic segmentation;style encoder","Wireless communication;Image segmentation;Image color analysis;Superresolution;Semantics;Feature extraction;Faces","face recognition;image colour analysis;image resolution;image segmentation;neural nets","face beauty;semantic segmentation;style encoder;image super-resolution;state-of-the-art face super-resolution;visual quality;deep convolutional neural network;facial structures;local knowledge;face hallucination method;low resolution face images;feature mapping;color mapping;segmentation mask;super-resolution process;color attention residual block;color fidelity unit;color information;mapped area;image quality;enhanced super-resolution generative adversarial networks;Residual Channel Attention Networks","","","","11","IEEE","11 Mar 2021","","","IEEE","IEEE Conferences"
"FCSR-GAN: Joint Face Completion and Super-Resolution via Multi-Task Learning","J. Cai; H. Han; S. Shan; X. Chen","University of Chinese Academy of Sciences, Beijing, China; Peng Cheng Laboratory, Shenzhen, China; CAS Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Biometrics, Behavior, and Identity Science","30 Mar 2020","2020","2","2","109","121","Combined variations containing low-resolution and occlusion often present in face images in the wild, e.g., under the scenario of video surveillance. While most of the existing face image recovery approaches can handle only one type of variation per model, in this work, we propose a deep generative adversarial network (FCSR-GAN) for performing joint face completion and face super-resolution via multi-task learning. The generator of FCSR-GAN aims to recover a high-resolution face image without occlusion given an input low-resolution face image with occlusion. The discriminator of FCSR-GAN uses a set of carefully designed losses (an adversarial loss, a perceptual loss, a pixel loss, a smooth loss, a style loss, and a face prior loss) to assure the high quality of the recovered high-resolution face images without occlusion. The whole network of FCSR-GAN can be trained end-to-end using our two-stage training strategy. Experimental results on the public-domain CelebA and Helen databases show that the proposed approach outperforms the state-of-the-art methods in jointly performing face super-resolution (up to 8×) and face completion, and shows good generalization ability in cross-database testing. Our FCSR-GAN is also useful for improving face identification performance when there are low-resolution and occlusion in face images. The code of FCSR-GAN is available at: https://github.com/swordcheng/FCSR-GAN.","2637-6407","","10.1109/TBIOM.2019.2951063","National Natural Science Foundation of China(grant numbers:61732004,61672496); Chinese Academy of Sciences(grant numbers:GJHZ1843); Chinese Academy of Sciences(grant numbers:2018135); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890717","Joint face completion and super-resolution;multi-task learning;generative adversarial network;two-stage training","Face;Biometrics (access control);Training;Gallium nitride;Generative adversarial networks","face recognition;image resolution;learning (artificial intelligence);neural nets","joint face completion;multitask learning;high-resolution face image;occlusion;low-resolution face image;face prior loss;high-resolution face images;face super-resolution;face identification performance;face image recovery approaches;FCSR-GAN;deep generative adversarial network;adversarial loss;perceptual loss;pixel loss;smooth loss;style loss","","23","","58","USGov","4 Nov 2019","","","IEEE","IEEE Journals"
"EndoL2H: Deep Super-Resolution for Capsule Endoscopy","Y. Almalioglu; K. Bengisu Ozyoruk; A. Gokce; K. Incetan; G. Irem Gokceler; M. Ali Simsek; K. Ararat; R. J. Chen; N. J. Durr; F. Mahmood; M. Turan","Department of Computer Science, University of Oxford, Oxford, U.K.; Institute of Biomedical Engineering, Boğaziçi University, Istanbul, Turkey; Electrical and Electronics Engineering, Boğaziçi University, Istanbul, Turkey; Institute of Biomedical Engineering, Boğaziçi University, Istanbul, Turkey; Institute of Biomedical Engineering, Boğaziçi University, Istanbul, Turkey; Electrical and Electronics Engineering, Boğaziçi University, Istanbul, Turkey; Department of Computational Engineering, Friedrich Alexander Universität Erlangen-Nürnberg, Erlangen, Germany; Department of Biomedical Informatics, Harvard Medical School, Boston, MA, USA; Department of Biomedical Engineering, Johns Hopkins University (JHU), Baltimore, MD, USA; Department of Pathology, Harvard Medical School, Boston, MA, USA; Institute of Biomedical Engineering, Boğaziçi University, Istanbul, Turkey","IEEE Transactions on Medical Imaging","30 Nov 2020","2020","39","12","4297","4309","Although wireless capsule endoscopy is the preferred modality for diagnosis and assessment of small bowel diseases, the poor camera resolution is a substantial limitation for both subjective and automated diagnostics. Enhanced-resolution endoscopy has shown to improve adenoma detection rate for conventional endoscopy and is likely to do the same for capsule endoscopy. In this work, we propose and quantitatively validate a novel framework to learn a mapping from low-to-high-resolution endoscopic images. We combine conditional adversarial networks with a spatial attention block to improve the resolution by up to factors of $8\times $ , $10\times $ , $12\times $ , respectively. Quantitative and qualitative studies demonstrate the superiority of EndoL2H over state-of-the-art deep super-resolution methods Deep Back-Projection Networks (DBPN), Deep Residual Channel Attention Networks (RCAN) and Super Resolution Generative Adversarial Network (SRGAN). Mean Opinion Score (MOS) tests were performed by 30 gastroenterologists qualitatively assess and confirm the clinical relevance of the approach. EndoL2H is generally applicable to any endoscopic capsule system and has the potential to improve diagnosis and better harness computational approaches for polyp detection and characterization. Our code and trained models are available at https://github.com/CapsuleEndoscope/EndoL2H.","1558-254X","","10.1109/TMI.2020.3016744","Scientific and Technological Research Council of Turkey (TUBITAK) (The International Fellowship for Outstanding Researchers)(grant numbers:2232); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9167261","Capsule endoscopy;super-resolution;conditional generative adversarial network;spatial attention network","Spatial resolution;Endoscopes;Generators;Degradation;Cameras;Generative adversarial networks","biomedical optical imaging;diseases;endoscopes;image resolution;medical image processing;neural nets","wireless capsule endoscopy;bowel diseases;camera resolution;enhanced-resolution endoscopy;adenoma detection rate;back-projection networks;deep residual channel attention networks;super resolution generative adversarial network;mean opinion score tests;endoscopic capsule system;low-high-resolution endoscopic images;EndoL2H;polyp detection","Capsule Endoscopy","19","","61","IEEE","14 Aug 2020","","","IEEE","IEEE Journals"
"Joint Demosaicing and Super-Resolution (JDSR): Network Design and Perceptual Optimization","X. Xu; Y. Ye; X. Li","Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Department of Computer and Data Sciences, Case Western Reserve University, Cleveland, OH, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA","IEEE Transactions on Computational Imaging","1 Feb 2021","2020","6","","968","980","Image demosaicing and super-resolution are two important tasks in color imaging pipeline. So far they have been mostly independently studied in the open literature of deep learning; little is known about the potential benefit of formulating a joint demosaicing and super-resolution (JDSR) problem. In this article, we propose an end-to-end optimization solution to the JDSR problem and demonstrate its practical significance in computational imaging. Our technical contributions are mainly two-fold. On network design, we have developed a Residual-Dense Squeeze-and-Excitation Networks (RDSEN) supported by a pre-demosaicing network (PDNet) as the pre-processing step. We address the issue of spatio-spectral attention for color-filter-array (CFA) data and discuss how to achieve better information flow by concatenating Residue-Dense Squeeze-and-Excitation Blocks (RDSEBs) for JDSR. Experimental results have shown that significant PSNR/SSIM gain can be achieved by RDSEN over previous network architectures including state-of-the-art RCAN. On perceptual optimization, we propose to leverage the latest ideas including relativistic discriminator and pre-excitation perceptual loss function to further improve the visual quality of textured regions in reconstructed images. Our extensive experiment results have shown that Texture-enhanced Relativistic average Generative Adversarial Network (TRaGAN) can produce both subjectively more pleasant images and objectively lower perceptual distortion scores than standard GAN for JDSR. Finally, we have verified the benefit of JDSR to high-quality image reconstruction from real-world Bayer pattern data collected by NASA Mars Curiosity.","2333-9403","","10.1109/TCI.2020.2999819","NSF(grant numbers:IIS-2027127,IIS-1951504,CNS-1940859,CNS-1946327,CNS-1814825,OAC-1940855); DoJ/NIJ(grant numbers:NIJ 2018-75-CX-0032); West Virginia Higher Education Policy Commission(grant numbers:HEPC.dsr.18.5); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9109718","Color imaging;joint image demosaicing and super-resolution (JDSR);residual-dense squeeze-and-excitation network (RDSEN);perceptual optimization","Generative adversarial networks;Optimization;Image reconstruction;Imaging;Task analysis;Color","image colour analysis;image filtering;image reconstruction;image resolution;image segmentation;image texture;neural nets;optimisation","joint demosaicing and super-resolution problem;PDNet;residual-dense squeeze-and-excitation network;TRaGAN;PSNR-SSIM gain;NASA Mars Curiosity;texture-enhanced relativistic average generative adversarial network;perceptual distortion scores;image reconstruction;pre-excitation perceptual loss function;RCAN;color-filter-array data;spatio-spectral attention;pre-demosaicing network;RDSEN;computational imaging;JDSR problem;end-to-end optimization solution;deep learning;color imaging pipeline;image demosaicing;perceptual optimization","","12","","60","IEEE","5 Jun 2020","","","IEEE","IEEE Journals"
"Fine-grained Adversarial Image Inpainting with Super Resolution","Y. Li; B. Jiang; Y. Lu; L. Shen",Beijing Institute of Remote Sensing Information; Beijing Institute of Remote Sensing Information; Beijing Institute of Remote Sensing Information; Beijing Institute of Remote Sensing Information,"2019 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2019","2019","","","1","8","Image inpainting refers to synthesizing plausible contents for images with missing regions. However, current methods often create blurry textures, distorted structures and loss of details, especially when the image has complex scenes or large missing regions. We propose a fine-grained adversarial image inpainting model with super resolution. It performs a coarse-to-fine inpainting procedure in two stages. The proposed generator first synthesizes initial predictions of the missing regions with a novel encoder-decoder structure. Then it refines the predicted missing regions by generating high-frequency details via super resolution. We evaluate the proposed from both pixel level and semantic level. Experiments demonstrate that the proposed can generate higher quality inpainting results than the baseline models in both metrics.","2161-4407","978-1-7281-1985-4","10.1109/IJCNN.2019.8852241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852241","Image Inpainting;Image Completion;Super Resolution","Image resolution;Generators;Feature extraction;Generative adversarial networks;Image restoration;Decoding;Neural networks","image coding;image reconstruction;image resolution;image restoration;image texture","super resolution;plausible contents;blurry textures;distorted structures;complex scenes;fine-grained adversarial image inpainting model;coarse-to-fine inpainting procedure;predicted missing regions;high-frequency details;encoder-decoder structure;higher quality inpainting","","3","","29","IEEE","30 Sep 2019","","","IEEE","IEEE Conferences"
"TDPN: Texture and Detail-Preserving Network for Single Image Super-Resolution","Q. Cai; J. Li; H. Li; Y. -H. Yang; F. Wu; D. Zhang","School of Information Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China; Department of Computing Science, University of Alberta, Edmonton, Canada; School of Information Science and Technology, University of Science and Technology of China, Hefei, China; CUHK(SZ)- Linklogis Joint Laboratory of Computer Vision and Artificial Intelligence, Shenzhen, China","IEEE Transactions on Image Processing","15 Mar 2022","2022","31","","2375","2389","Single image super-resolution (SISR) using deep convolutional neural networks (CNNs) achieves the state-of-the-art performance. Most existing SISR models mainly focus on pursuing high peak signal-to-noise ratio (PSNR) and neglect textures and details. As a result, the recovered images are often perceptually unpleasant. To address this issue, in this paper, we propose a texture and detail-preserving network (TDPN), which focuses not only on local region feature recovery but also on preserving textures and details. Specifically, the high-resolution image is recovered from its corresponding low-resolution input in two branches. First, a multi-reception field based branch is designed to let the network fully learn local region features by adaptively selecting local region features in different reception fields. Then, a texture and detail-learning branch supervised by the textures and details decomposed from the ground-truth high resolution image is proposed to provide additional textures and details for the super-resolution process to improve the perceptual quality. Finally, we introduce a gradient loss into the SISR field and define a novel hybrid loss to strengthen boundary information recovery and to avoid overly smooth boundary in the final recovered high-resolution image caused by using only the MAE loss. More importantly, the proposed method is model-agnostic, which can be applied to most off-the-shelf SISR networks. The experimental results on public datasets demonstrate the superiority of our TDPN on most state-of-the-art SISR methods in PSNR, SSIM and perceptual quality. We will share our code on https://github.com/tocaiqing/TDPN.","1941-0042","","10.1109/TIP.2022.3154614","National Science Foundation of China(grant numbers:62102338,61906162,62172347); National Natural Science Foundation of Shandong Province(grant numbers:ZR2020QF031); China Postdoctoral Science Foundation(grant numbers:2021M693078); Shenzhen Science and Technology Program(grant numbers:RCBS20200714114910193); Shenzhen Research Institute of Big Data; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Natural Sciences and Engineering Research Council of Canada; University of Alberta; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9727093","Single image super-resolution (SISR);convolutional neural network (CNN);texture and detail-preserving network (TDPN);multi-branch network;multi-reception field module","Visualization;Convolutional neural networks;Superresolution;Generative adversarial networks;Feature extraction;Convolution;Learning systems","deep learning (artificial intelligence);image reconstruction;image resolution;image texture","single image super-resolution;deep convolutional neural networks;high peak signal-to-noise ratio;detail-preserving network;TDPN;local region feature recovery;low-resolution input;reception fields;detail-learning branch;ground-truth high resolution image;perceptual quality;off-the-shelf SISR networks;texture and detail-preserving network;MAE loss;CNNs","","3","","72","IEEE","3 Mar 2022","","","IEEE","IEEE Journals"
"Unsupervised Denoising for Super-Resolution (UDSR) of Real-World Images","K. Prajapati; V. Chudasama; H. Patel; A. Sarvaiya; K. Upla; K. Raja; R. Ramachandra; C. Busch","Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Department of Computer Science, Norwegian University of Science and Technology (NTNU), Gjøvik, Norway; Department of Information Security and Communication Technology, Norwegian University of Science and Technology (NTNU), Gjøvik, Norway; Department of Information Security and Communication Technology, Norwegian University of Science and Technology (NTNU), Gjøvik, Norway","IEEE Access","29 Nov 2022","2022","10","","122329","122346","Single Image Super-Resolution (SISR) using Convolutional Neural Networks (CNNs) for many applications in supervised manner has resulted in significant improvement in state-of-the-art performance. Such supervised models achieve remarkable accuracy; albeit their poor generalization ability for real-world Low-Resolution (LR) images. Supervised training in many SR works involves synthetically generated LR images from its corresponding High-Resolution (HR) images. As the distribution of such LR observation is relatively different from that of real LR image, the supervised training in SISR task results in a degradation when applied on real-world data. SISR has been scaled to real-world data recently by posing the unsupervised problem into a supervised one through learning the distribution of noisy LR observation first, following which supervised training is performed to obtain the SR image. It therefore involves two steps where the accuracy of SR image relies on how closely the LR’s distribution is learnt in the first step. In this work, we overcome such limitation by introducing unsupervised denoising network to transform real noisy LR image to clean image and then pre-trained SR network is utilised to increase the spatial resolution of cleaned LR image to generate SR image. Thus, instead of evaluating the denoised image in LR space to train the denoising network, we inspect the denoised image in SR space which allows to overcome the SR network’s generalization problem. The proposed Unsupervised Denoising framework for Super-Resolution (UDSR) is validated on real-world datasets (NTIRE-2020 Real-World SR Challenge validation and testing dataset (Track-1)) by comparing it with many recent unsupervised SISR methods. The performance of denoising and SR networks is superior in terms of various perceptual indices such as Perceptual Index (PI) and Ma Score in addition to numerous non-references metrics.","2169-3536","","10.1109/ACCESS.2022.3223101","Science and Engineering Research Board (SERB), a statutory body of the Department of Science and Technology (DST), Government of India(grant numbers:ECR/2017/003268); Norwegian Biometric Laboratory (NBL), NTNU, Gjøvik, Norway; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9954406","Convolutional neural network;generative adversarial network;image enhancement;image restoration;single-image super-resolution;unsupervised learning","Noise reduction;Training;Superresolution;Task analysis;Convolutional neural networks;Noise measurement;Generative adversarial networks;Unsupervised learning","image denoising;image resolution;unsupervised learning","CNN;convolutional neural networks;high-resolution imaging;low-resolution imaging;LR distribution;LR image denoising;LR space;noisy LR observation;NTIRE-2020 Real-World SR Challenge validation;single image super-resolution;SISR task;spatial resolution;SR image;SR network denoising;SR space;supervised models;supervised training;UDSR;unsupervised denoising framework;unsupervised denoising network;unsupervised SISR methods","","","","110","CCBY","17 Nov 2022","","","IEEE","IEEE Journals"
"Small Object Detection Leveraging on Simultaneous Super-resolution","H. Ji; Z. Gao; X. Liu; Y. Zhang; T. Mei","School of Remote Sensing and Information Engineering Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering Wuhan University, Wuhan, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; School of Remote Sensing and Information Engineering Wuhan University, Wuhan, China; Electronic and Information School, Wuhan University, Wuhan, China","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","803","810","Despite the impressive advancement achieved in object detection, the detection performance of small object is still far from satisfactory due to the lack of sufficient detailed appearance to distinguish it from similar objects. Inspired by the positive effects of super-resolution for object detection, we propose a framework that can be incorporated with detector networks to improve the performance of small object detection, in which the low-resolution image is super-resolved via generative adversarial network (GAN) in an unsupervised manner. In our method, the super-resolution network and the detection network are trained jointly. In particular, the detection loss is back-propagated into the super-resolution network during training to facilitate detection. Compared with available simultaneous super-resolution and detection methods which heavily rely on low-/high-resolution image pairs, our work breaks through such restriction via applying the CycleGAN strategy, achieving increased generality and applicability, while remaining an elegant structure. Extensive experiments on datasets from both computer vision and remote sensing communities demonstrate that our method obtains competitive performance on a wide range of complex scenarios.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9413058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413058","","Training;Image segmentation;Computer vision;Superresolution;Object detection;Detectors;Generative adversarial networks","computer vision;image resolution;object detection;remote sensing","low-resolution image;generative adversarial network;super-resolution network;detection network;simultaneous super-resolution;small object detection;detector networks;CycleGAN;computer vision;remote sensing","","1","","36","IEEE","5 May 2021","","","IEEE","IEEE Conferences"
"Image super-resolution method based on generative adversarial network","Y. Lijun; Z. Xiaoming; L. Fan; S. Gang; C. Zhou; Y. Jing; Z. Min; C. Yongchang; W. Lingling; C. Zelong; P. Lan; B. Fengqing; Y. Zifang; X. Hongqiu; L. Pengjian; L. Zhisheng; T. Qiang","Changzhutan Tobacco Logistics Co., Ltd. of Hunan Province, ChangSha, China; Hunan Tobacco Company, Chagnsha, China; Hunan Tobacco Company, Chagnsha, China; Hunan Tobacco Workers Training Center, Xiangtan; Hunan Tobacco Company, Chagnsha, China; Hunan Tobacco Company, Chagnsha, China; Hunan Tobacco Company, Chagnsha, China; Hunan Tobacco Company, Chagnsha, China; Hunan Tobacco Workers Training Center, Xiangtan; Changzhutan Tobacco Logistics Co., Ltd. of Hunan Province, ChangSha, China; Changzhutan Tobacco Logistics Co., Ltd. of Hunan Province, ChangSha, China; Changzhutan Tobacco Logistics Co., Ltd. of Hunan Province, ChangSha, China; Changzhutan Tobacco Logistics Co., Ltd. of Hunan Province, ChangSha, China; Changzhutan Tobacco Logistics Co., Ltd. of Hunan Province, ChangSha, China; College of Information Science and Engineering, Hunan Normal University, ChangSha, China; College of Information Science and Engineering, Hunan Normal University, ChangSha, China; College of Engineering and Design, Hunan Normal University, ChangSha, China","2021 4th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)","19 Aug 2021","2021","","","909","915","Although deep convolutional neural networks have made breakthroughs in the accuracy and speed of single-image super-resolution, there are still many unsolved problems: firstly, How to refine the texture problem when performing super-resolution processing at a larger magnification ratio. Secondly, the existing convolutional neural network image super-resolution algorithms are prone to overfitting and insufficient convergence of the loss function. Aiming at two problems, an image super-resolution method based on generative adversarial network is proposed. The feature map is spatially transformed on the network to solve the problem of refined texture, combined with CycleGAN and SRGAN, the network structure is improved and the loss function is optimized, and the SRCICGAN algorithm is proposed to restore the four times down-sampled image to solve the loss function problem. The experiment is compared with the latest six methods on three data sets. The PSNR and SSIM indicators are 1.92% and 5.49% higher in the Flickr2K data set, respectively, and better visual effects can be obtained in terms of detailed texture.","","978-1-6654-1596-5","10.1109/AEMCSE51986.2021.00185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9513030","SRCICGAN;ESFT method;ASSP semantic segmentation probability map;generating adversarial networks","Structural rings;Superresolution;Semantics;Software algorithms;Generative adversarial networks;Visual effects;Convolutional neural networks","convolutional neural nets;image resolution;image texture","generative adversarial network;deep convolutional neural networks;single-image super-resolution;texture problem;network structure;loss function problem;convolutional neural network image super-resolution algorithms;PSNR;SSIM;CycleGAN;SRGAN;SRCICGAN;down-sampled image;Flickr2K","","","","18","IEEE","19 Aug 2021","","","IEEE","IEEE Conferences"
"Image Resolution Enhancer using Deep Learning","H. Mittal; V. Rai; S. Sonawane; S. Mhatre","BE, Computer Engineering Vidyavardhini's College of Engineering and Technology-Vasai, Palghar, India; Mumbai University; Computer Engineering Vidyavardhini's College of Engineering and Technology-Vasai, Palghar, India; Mumbai University","2022 International Conference on Applied Artificial Intelligence and Computing (ICAAIC)","16 Jun 2022","2022","","","578","586","Image Super-Resolution is a technique that is used to obtain high-resolution, realistic images from low-resolution input images. Deep learning algorithms such as SRCNN, ESRGAN, RDN, etc. have shown significant results in this field. But these algorithms at times vary in results. To solve this problem, this research study has proposed an image super-resolution by using Patch Extraction on Deep Learning Algorithm, in which the LR image is first divided into patches and then the algorithms like RDN and ESRGAN are applied. Comparing each patch from each algorithm based on PSNR values, the patch with the highest PSNR value will be selected. After picking up all the patches for that image, it will be reconstructed and hence the super-resolution image will be obtained as the output.","","978-1-6654-9710-7","10.1109/ICAAIC53929.2022.9792975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9792975","Computer Vision;Deep Learning;Convolutional Neural Networks;Image Super-Resolution;Residual Dense Networks;Generative Adversarial Networks;Patch Extraction","Deep learning;Superresolution;Estimation;Computer architecture;Observers;Artificial intelligence;Image reconstruction","deep learning (artificial intelligence);image enhancement;image reconstruction;image resolution;image sampling;realistic images","image super-resolution;realistic images;low-resolution input images;deep learning algorithms;ESRGAN;RDN;LR image;image resolution enhancer","","1","","13","IEEE","16 Jun 2022","","","IEEE","IEEE Conferences"
"Physics-Informed Hyperspectral Remote Sensing Image Synthesis With Deep Conditional Generative Adversarial Networks","L. Liu; W. Li; Z. Shi; Z. Zou","State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing, China; Department of Guidance, Navigation and Control, School of Astronautics, Beihang University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","18 May 2022","2022","60","","1","15","High-resolution hyperspectral remote sensing images are of great significance to agricultural, urban, and military applications. However, collecting and labeling hyperspectral images are time-consuming, expensive, and usually heavily rely on domain knowledge. In this article, we propose a new method for generating high-resolution hyperspectral images and subpixel ground-truth annotations from RGB images. Given a single high-resolution RGB image as its conditional input, unlike previous methods that directly predict spectral reflectance and ignores the physics behind it, we consider both imaging mechanism and spectral mixing, introduce a deep generative network that first recovers the spectral abundance for each pixel, and then generate the final spectral data cube with the standard USGS spectral library. In this way, our method not only synthesizes high-quality spectral data existing in the real world but also generates subpixel-level spectral abundance with well-defined spectral reflectance characteristics. We also introduce a spatial discriminative network and a spectral discriminative network to improve the fidelity of the synthetic output from both spatial and spectral perspectives. The whole framework can be trained end-to-end in an adversarial training paradigm. We refer to our method as “Physics-informed Deep Adversarial Spectral Synthesis (PDASS).” On the IEEE grss_dfc_2018 dataset, our method achieves an MPSNR of 47.56 on spectral reconstruction accuracy and outperforms other state-of-the-art methods. As latent variables, the generated spectral abundance and the atmospheric absorption coefficients of sunlight also suggest the effectiveness of our method.","1558-0644","","10.1109/TGRS.2022.3173532","National Natural Science Foundation of China(grant numbers:62125102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9770778","Generation adversarial networks (GANs);hyperspectral image;imaging model;remote sensing;spectral super-resolution (SSR)","Hyperspectral imaging;Superresolution;Atmospheric modeling;Image reconstruction;Absorption;Spatial resolution;Libraries","geophysical image processing;geophysical signal processing;hyperspectral imaging;image classification;image colour analysis;image reconstruction;image resolution;remote sensing;spectral analysis","Physics-informed hyperspectral remote sensing image synthesis;deep conditional generative adversarial networks;high-resolution hyperspectral remote sensing images;agricultural applications;urban, applications;military applications;high-resolution hyperspectral images;subpixel ground-truth annotations;RGB images;single high-resolution RGB image;conditional input;imaging mechanism;spectral mixing;deep generative network;final spectral data cube;standard USGS spectral library;high-quality spectral data;subpixel-level spectral abundance;well-defined spectral reflectance characteristics;spatial discriminative network;spectral discriminative network;spatial perspectives;spectral perspectives;adversarial training paradigm;Physics-informed Deep Adversarial Spectral Synthesis;spectral reconstruction accuracy;generated spectral abundance","","1","","79","IEEE","9 May 2022","","","IEEE","IEEE Journals"
"Breast Cancer Histopathology Image Super-Resolution Using Wide-Attention GAN With Improved Wasserstein Gradient Penalty and Perceptual Loss","F. Shahidi","Department of Informatics (FTIR), Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia","IEEE Access","26 Feb 2021","2021","9","","32795","32809","In the realm of image processing, enhancing the quality of the images is known as a superresolution problem (SR). Among SR methods, a super-resolution generative adversarial network, or SRGAN, has been introduced to generate SR images from low-resolution images. As it is of the utmost importance to keep the size and the shape of the images, while enlarging the medical images, we propose a novel super-resolution model with a generative adversarial network to generate SR images with finer details and higher quality to encourage less blurring. By widening residual blocks and using a self-attention layer, our model becomes robust and generalizable as it is able to extract the most important part of the images before up-sampling. We named our proposed model as wide-attention SRGAN (WA-SRGAN). Moreover, we have applied improved Wasserstein with a Gradient penalty to stabilize the model while training. To train our model, we have applied images from Camylon 16 database and enlarged them by 2×, 4×, 8×, and 16× upscale factors with the ground truth of the size of 256 × 256 × 3. Furthermore, two normalization methods, including batch normalization, and weight normalization have been applied and we observed that weight normalization is an enabling factor to improve metric performance in terms of SSIM. Moreover, several evaluation metrics, such as PSNR, MSE, SSIM, MS-SSIM, and QILV have been applied for having a comprehensive objective comparison with other methods, including SRGAN, A-SRGAN, and bicubial. Also, we performed the job of classification by using a deep learning model called ResNeXt-101 (32 × 8d) for super-resolution, high-resolution, and low-resolution images and compared the outcomes in terms of accuracy score. Finally, the results on breast cancer histopathology images show the superiority of our model by using weight normalization and a batch size of one in terms of restoration of the color and the texture details.","2169-3536","","10.1109/ACCESS.2021.3057497","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9348911","SRGAN;Wasserstein gradient penalty;weight and batch normalization;perceptual loss;breast cancer histopathology medical images;classification","Generative adversarial networks;Histopathology;Superresolution;Biomedical imaging;Measurement;Training;Generators","biological organs;cancer;deep learning (artificial intelligence);gradient methods;image classification;image colour analysis;image denoising;image enhancement;image resolution;image restoration;image texture;medical image processing","breast cancer histopathology image super-resolution;image processing;super-resolution generative adversarial network;SR images;low-resolution images;medical images;self-attention layer;wide-attention SRGAN;weight normalization;deep learning;perceptual loss;WA-SRGAN;batch normalization;ResNeXt-101;image classification;color restoration;texture restoration;Wasserstein gradient penalty","","10","","58","CCBY","5 Feb 2021","","","IEEE","IEEE Journals"
"SSR-VFD: Spatial Super-Resolution for Vector Field Data Analysis and Visualization","L. Guo; S. Ye; J. Han; H. Zheng; H. Gao; D. Z. Chen; J. -X. Wang; C. Wang",Nankai University; Zhejiang University; University of Notre Dame; University of Notre Dame; University of Notre Dame; University of Notre Dame; University of Notre Dame; University of Notre Dame,"2020 IEEE Pacific Visualization Symposium (PacificVis)","7 May 2020","2020","","","71","80","We present SSR-VFD, a novel deep learning framework that produces coherent spatial super-resolution (SSR) of three-dimensional vector field data (VFD). SSR-VFD is the first work that advocates a machine learning approach to generate high-resolution vector fields from low-resolution ones. The core of SSR-VFD lies in the use of three separate neural nets that take the three components of a low-resolution vector field as input and jointly output a synthesized high-resolution vector field. To capture spatial coherence, we take into account magnitude and angle losses in network optimization. Our method can work in the in situ scenario where VFD are down-sampled at simulation time for storage saving and these reduced VFD are upsampled back to their original resolution during postprocessing. To demonstrate the effectiveness of SSR-VFD, we show quantitative and qualitative results with several vector field data sets of different characteristics and compare our method against volume upscaling using bicubic interpolation, and two solutions based on CNN and GAN, respectively.","2165-8773","978-1-7281-5697-2","10.1109/PacificVis48177.2020.8737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086293","Spatial super-resolution;vector field data;convolutional neural network;deep learning","Deep learning;Interpolation;Superresolution;Neural networks;Data visualization;Spatial coherence;Generative adversarial networks","convolutional neural nets;data visualisation;image resolution;interpolation;learning (artificial intelligence);vectors","SSR-VFD;spatial super-resolution;high-resolution vector fields;low-resolution vector field;vector field data sets;visualization;deep learning;machine learning;neural nets;spatial coherence;network optimization;bicubic interpolation;CNN;GAN;three-dimensional vector field data analysis","","26","","25","IEEE","7 May 2020","","","IEEE","IEEE Conferences"
"Unsupervised Super-Resolution of OCT Images Using Generative Adversarial Network for Improved Age-Related Macular Degeneration Diagnosis","V. Das; S. Dandapat; P. K. Bora","Department of Electronics and Electrical Engineering, Indian Institute of Technology Guwahati, Guwahati, India; Department of Electronics and Electrical Engineering, Indian Institute of Technology Guwahati, Guwahati, India; Department of Electronics and Electrical Engineering, Indian Institute of Technology Guwahati, Guwahati, India","IEEE Sensors Journal","2 Jul 2020","2020","20","15","8746","8756","Age-related macular degeneration (AMD) is the leading cause of progressive vision loss in the elderly. Optical coherence tomography (OCT) is a promising diagnostic tool for early detection and management of AMD. However, the speckle noise and low resolution (LR) of the OCT images affect its diagnostic viabilities. Therefore, denoising and super-resolution (SR) techniques present a potential solution to improve the quality of the OCT images. Recent methods rely on example-based approaches that require paired LR and high resolution (HR) images for training. However, the large scale acquisition of paired LR-HR images presents pertinent challenges in clinical settings. Therefore, this work proposes an unsupervised framework using the generative adversarial network (GAN) to perform fast and reliable SR without the requirement of aligned LR-HR pairs. We use adversarial learning with cycle consistency and identity mapping priors to preserve the spatial correlation, color and texture details in the generated clean HR images. Experimental results on clinical-grade OCT images show that the proposed method outperforms the existing methods both in terms of SR performance and computational time. Improved classification accuracy of 96.54% is obtained when the generated images are used for automated AMD diagnosis. The enhanced generalizability and faithful reconstruction attributes make the proposed method suitable for assisting ophthalmologists in better diagnosis and treatment planning.","1558-1748","","10.1109/JSEN.2020.2985131","Department of Biotechnology, Government of India, through the North East Centre for Biological Sciences and Healthcare Engineering (NECBH)(grant numbers:BT/COE/34/SP28408/2018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9055188","Age-related macular degeneration (AMD);generative adversarial network (GAN);optical coherence tomography (OCT);super-resolution","Generative adversarial networks;Training;Retina;Image reconstruction;Gallium nitride","biomedical optical imaging;diseases;feature extraction;geriatrics;image classification;image denoising;image reconstruction;image resolution;image texture;medical image processing;optical tomography;speckle;vision defects","unsupervised framework;macular degeneration diagnosis;aligned LR-HR pairs;high-resolution images;generative adversarial network;OCT images;unsupervised super-resolution","","19","","43","IEEE","2 Apr 2020","","","IEEE","IEEE Journals"
"SSR-TVD: Spatial Super-Resolution for Time-Varying Data Analysis and Visualization","J. Han; C. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA","IEEE Transactions on Visualization and Computer Graphics","2 May 2022","2022","28","6","2445","2456","We present SSR-TVD, a novel deep learning framework that produces coherent spatial super-resolution (SSR) of time-varying data (TVD) using adversarial learning. In scientific visualization, SSR-TVD is the first work that applies the generative adversarial network (GAN) to generate high-resolution volumes for three-dimensional time-varying data sets. The design of SSR-TVD includes a generator and two discriminators (spatial and temporal discriminators). The generator takes a low-resolution volume as input and outputs a synthesized high-resolution volume. To capture spatial and temporal coherence in the volume sequence, the two discriminators take the synthesized high-resolution volume(s) as input and produce a score indicating the realness of the volume(s). Our method can work in the in situ visualization setting by downscaling volumetric data from selected time steps as the simulation runs and upscaling downsampled volumes to their original resolution during postprocessing. To demonstrate the effectiveness of SSR-TVD, we show quantitative and qualitative results with several time-varying data sets of different characteristics and compare our method against volume upscaling using bicubic interpolation and a solution solely based on CNN.","1941-0506","","10.1109/TVCG.2020.3032123","National Science Foundation(grant numbers:IIS-1455886,CNS-1629914,DUE-1833129,IIS-1955395); Nvidia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229162","Time-varying data visualization;deep learning;super-resolution;generative adversarial network","Data visualization;Coherence;Deep learning;Generative adversarial networks;Training;Gallium nitride","data analysis;data visualisation;image resolution;interpolation;learning (artificial intelligence)","SSR-TVD;spatial super-resolution;time-varying data analysis;generative adversarial network;high-resolution volumes;three-dimensional time-varying data sets;temporal discriminators;low-resolution volume;synthesized high-resolution volume;spatial coherence;temporal coherence;simulation;upscaling downsampled volumes;original resolution","","14","","48","IEEE","19 Oct 2020","","","IEEE","IEEE Journals"
"Supervised Pixel-Wise GAN for Face Super-Resolution","M. Zhang; Q. Ling","Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China","IEEE Transactions on Multimedia","25 Jun 2021","2021","23","","1938","1950","For many face-related multimedia applications, low-resolution face images may greatly degrade the face recognition performance and necessitate face super-resolution (SR). Among the current SR methods, MSE-oriented SR methods often produce over-smoothed outputs and could miss some texture details while GAN-oriented SR methods may generate artifacts which are harmful to face recognition. To resolve the above issues, this paper presents a supervised pixel-wise Generative Adversarial Network (SPGAN) that can resolve a very low-resolution face image of $16\times 16$ or smaller pixel-size to its larger version of multiple scaling factors ($2\times$, $4\times$, $8\times$ and even $16\times$) in a unified framework. Being different from traditional unsupervised discriminators which generate a single number to represent the likelihood whether the input image is real or fake, the proposed supervised pixel-wise discriminator mainly focus on whether each pixel of the generated SR face image is as photo-realistic as its corresponding pixel in the ground-truth HR (high-resolution) face image. To further improve the face recognition performance of SPGAN, we take advantage of the face identity prior by sending two inputs to the discriminator, including an input face image (either a real HR face image or its corresponding SR face image) and its face features which are extracted from a pre-trained face recognition model. Due to the introduced face identity prior, the identity-based discriminator can pay more attention to texture details which are closely related to face recognition. Extensive experiments demonstrate that the proposed SPGAN can achieve more photo-realistic SR images and higher face recognition accuracy than some state-of-the-art methods.","1941-0077","","10.1109/TMM.2020.3006414","New Energy and Intelligent Networked Automobile Industry of Anhui Province; National Key Research and Development Program of China(grant numbers:2016YFC0201003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9132630","Face image super-resolution;supervised;generative adversarial nets (GAN);face recognition;pixel-wise GAN","Face recognition;Gallium nitride;Generative adversarial networks;Feature extraction;Task analysis","face recognition;feature extraction;image classification;image resolution;image texture;learning (artificial intelligence)","texture details;photo-realistic SR images;higher face recognition accuracy;supervised pixel-wise GAN;face-related multimedia applications;low-resolution face image;face recognition performance;necessitate face super-resolution;current SR methods;MSE-oriented SR methods;GAN-oriented SR methods;smaller pixel-size;input image;supervised pixel-wise discriminator;generated SR face image;corresponding pixel;ground-truth HR face image;input face image;corresponding SR face image;face features;pre-trained face recognition model;supervised pixel-wise generative adversarial network","","13","","46","IEEE","2 Jul 2020","","","IEEE","IEEE Journals"
"TSR-TVD: Temporal Super-Resolution for Time-Varying Data Analysis and Visualization","J. Han; C. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame","IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","205","215","We present TSR-TVD, a novel deep learning framework that generates temporal super-resolution (TSR) of time-varying data (TVD) using adversarial learning. TSR-TVD is the first work that applies the recurrent generative network (RGN), a combination of the recurrent neural network (RNN) and generative adversarial network (GAN), to generate temporal high-resolution volume sequences from low-resolution ones. The design of TSR-TVD includes a generator and a discriminator. The generator takes a pair of volumes as input and outputs the synthesized intermediate volume sequence through forward and backward predictions. The discriminator takes the synthesized intermediate volumes as input and produces a score indicating the realness of the volumes. Our method handles multivariate data as well where the trained network from one variable is applied to generate TSR for another variable. To demonstrate the effectiveness of TSR-TVD, we show quantitative and qualitative results with several time-varying multivariate data sets and compare our method against standard linear interpolation and solutions solely based on RNN or CNN.","1941-0506","","10.1109/TVCG.2019.2934255","U.S. National Science Foundation(grant numbers:IIS-1455886,CNS-1629914,DUE-1833129); NVIDIA GPU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802285","Time-varying data visualization;super-resolution;deep learning;recurrent generative network","Gallium nitride;Data visualization;Deep learning;Spatial resolution;Training;Generators;Generative adversarial networks","data analysis;data visualisation;learning (artificial intelligence);recurrent neural nets","TSR-TVD;temporal super-resolution;time-varying data analysis;recurrent generative network;generative adversarial network;time-varying multivariate data sets;time-varying data visualization;recurrent neural network;RGN;RNN;GAN;deep learning","","12","","62","IEEE","15 Aug 2019","","","IEEE","IEEE Journals"
"Adversarial Multi-Path Residual Network for Image Super-Resolution","Q. Wang; Q. Gao; L. Wu; G. Sun; L. Jiao","Key Laboratory of Ministry of Education of Intellisense and Image Understanding, School of Telecommunication Engineering, Xidian University, Xi’an, China; Xidian-Ningbo Information Technology Institute, Ningbo, China; Huawei Consumer Business Group, Xi’an, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; Key Laboratory of Ministry of Education of Intellisense and Image Understanding, School of Artificial Intelligence, Xidian University, Xi’an, China","IEEE Transactions on Image Processing","26 Jul 2021","2021","30","","6648","6658","Recently, deep convolutional neural networks have demonstrated remarkable progresses on single image super-resolution (SR) problem. However, most of them use more deeper and wider networks to improve SR performance, which is not practical in real-world applications due to large complexity, high computation cost, and low efficiency. In addition, they cannot provide high perception quality and guarantee objective quality simultaneously. To address these limitations, we in this paper propose a novel Adversarial Multi-path Residual Network (AMPRN), which can largely suppress the number of network parameters and achieve a higher SR performance compared with the state-of-the-art methods. More specifically, we propose a multi-path residual block (MPRB) for multi-path residual network (MPRN) with fewer network parameters, which can extract abundant local features by fully using features from different paths generated by channel slices. These hierarchical features from all the MPRBs are then jointly aggregated by global gradual feature fusion. Following MPRN, we construct an adversarial gradient network with a gradient loss to make the gradient distribution of the generated SR images and ground truth image closer. In this way, the generated SR images of our model can provide high perception quality and objective quality. Finally, several experimental results demonstrate that our AMPRN achieves better performance in comparison with fewer parameters than the state-of-the-art methods.","1941-0042","","10.1109/TIP.2021.3096089","Initiative Postdoctoral Supporting Program(grant numbers:BX20190262); China Postdoctoral Science Foundation(grant numbers:2019M663642); National Natural Science Foundation of Shaanxi Province(grant numbers:2020JZ-19,2020JQ-327); Natural Science Foundation of Ningbo(grant numbers:2018A610049); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9490520","Single image super-resolution (SISR);residual learning;deep convolutional neural network","Feature extraction;Residual neural networks;Superresolution;Generative adversarial networks;Image reconstruction;Generators;Training","convolutional neural nets;feature extraction;image fusion;image resolution","generated SR images;ground truth image;high perception quality;deep convolutional neural networks;single image super-resolution problem;deeper networks;wider networks;high computation cost;multipath residual block;local features;hierarchical features;global gradual feature fusion;adversarial gradient network;adversarial multipath residual network","","10","","40","IEEE","19 Jul 2021","","","IEEE","IEEE Journals"
"Single-Image Super-Resolution for Remote Sensing Images Using a Deep Generative Adversarial Network With Local and Global Attention Mechanisms","Y. Li; S. Mavromatis; F. Zhang; Z. Du; J. Sequeira; Z. Wang; X. Zhao; R. Liu","Zhejiang Provincial Laboratory of Geographic Information System (GIS), School of Earth Sciences, Zhejiang University, Hangzhou, China; Laboratory of Computer Science and Systems (LIS), The French National Centre for Scientific Research (CNRS), Aix-Marseille University, Marseille, France; Zhejiang Provincial Laboratory of Geographic Information System (GIS), School of Earth Sciences, Zhejiang University, Hangzhou, China; Zhejiang Provincial Laboratory of Geographic Information System (GIS), School of Earth Sciences, Zhejiang University, Hangzhou, China; Laboratory of Computer Science and Systems (LIS), The French National Centre for Scientific Research (CNRS), Aix-Marseille University, Marseille, France; City Intelligence, Cloud & AI, Huawei Technologies Company Ltd., Shenzhen, China; City Intelligence, Cloud & AI, Huawei Technologies Company Ltd., Shenzhen, China; Zhejiang Provincial Laboratory of Geographic Information System (GIS), School of Earth Sciences, Zhejiang University, Hangzhou, China","IEEE Transactions on Geoscience and Remote Sensing","13 Jan 2022","2022","60","","1","24","Super-resolution (SR) technology is an important way to improve spatial resolution under the condition of sensor hardware limitations. With the development of deep learning (DL), some DL-based SR models have achieved state-of-the-art performance, especially the convolutional neural network (CNN). However, considering that remote sensing images usually contain a variety of ground scenes and objects with different scales, orientations, and spectral characteristics, previous works usually treat important and unnecessary features equally or only apply different weights in the local receptive field, which ignores long-range dependencies; it is still a challenging task to exploit features on different levels and reconstruct images with realistic details. To address these problems, an attention-based generative adversarial network (SRAGAN) is proposed in this article, which applies both local and global attention mechanisms. Specifically, we apply local attention in the SR model to focus on structural components of the earth’s surface that require more attention, and global attention is used to capture long-range interdependencies in the channel and spatial dimensions to further refine details. To optimize the adversarial learning process, we also use local and global attentions in the discriminator model to enhance the discriminative ability and apply the gradient penalty in the form of hinge loss and loss function that combines <inline-formula> <tex-math notation=""LaTeX"">$L1$ </tex-math></inline-formula> pixel loss, <inline-formula> <tex-math notation=""LaTeX"">$L1$ </tex-math></inline-formula> perceptual loss, and relativistic adversarial loss to promote rich details. The experiments show that SRAGAN can achieve performance improvements and reconstruct better details compared with current state-of-the-art SR methods. A series of ablation investigations and model analyses validate the efficiency and effectiveness of our method.","1558-0644","","10.1109/TGRS.2021.3093043","National Key Research and Development Project(grant numbers:2018YFB0505000); Fundamental Research Funds for the Central Universities(grant numbers:2019QNA3013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9479919","Convolutional neural networks (CNNs);generative adversarial network (GAN);local and global attention module;remote sensing;single-image super super-resolution (SISR)","Remote sensing;Feature extraction;Image reconstruction;Spatial resolution;Signal processing algorithms;Biological system modeling;Generative adversarial networks","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image reconstruction;image resolution;remote sensing","single-image super-resolution;remote sensing images;deep generative adversarial network;global attention mechanisms;spatial resolution;deep learning;SR model;convolutional neural network;ground scenes;spectral characteristics;local receptive field;attention-based generative adversarial network;spatial dimensions;adversarial learning process;discriminator model;L1 pixel loss;L1 perceptual loss;relativistic adversarial loss;SRAGAN;gradient penalty;hinge loss;loss function","","4","","78","IEEE","12 Jul 2021","","","IEEE","IEEE Journals"
"Unsupervised Remoting Sensing Super-Resolution via Migration Image Prior","J. Wang; Z. Shao; T. Lu; X. Huang; R. Zhang; Y. Wang",Wuhan University; Wuhan University; Wuhan Institute of Technology; University of Arkansas; Wuhan University; Wuhan Institute of Technology,"2021 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2021","2021","","","1","6","Recently, satellites with high temporal resolution have fostered wide attention in various practical applications. Due to limitations of bandwidth and hardware cost, however, the spatial resolution of such satellites is considerably low, largely limiting their potentials in scenarios that require spatially explicit information. To improve image resolution, numerous approaches based on training low-high resolution pairs have been proposed to address the super-resolution (SR) task. De-spite their success, however, low/high spatial resolution pairs are usually difficult to obtain in satellites with a high temporal resolution, making such approaches in SR impractical to use. In this paper, we proposed a new unsupervised learning framework, called ""MIP"", which achieves SR tasks without low/high resolution image pairs. First, random noise maps are fed into a designed generative adversarial network (GAN) for reconstruction. Then, the proposed method converts the reference image to latent space as the migration image prior. Finally, we update the input noise via an implicit method, and further transfer the texture and structured information from the reference image. Extensive experimental results on the Draper dataset show that MIP achieves significant improvements over state-of-the-art methods both quantitatively and qualitatively. The proposed MIP is open-sourced at https://github.com/jiaming-wang/MIP.","1945-788X","978-1-6654-3864-3","10.1109/ICME51207.2021.9428093","National Natural Science Foundation of China; Wuhan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9428093","Super-resolution;unsupervised learning;latent space;deep neural networks","Training;Satellites;Limiting;Superresolution;Neural networks;Generative adversarial networks;Sensors","geophysical image processing;image reconstruction;image resolution;image sampling;neural nets;remote sensing;unsupervised learning","unsupervised remoting sensing super-resolution;satellites;image resolution;unsupervised learning;reference image;migration image prior;low-high resolution pair training;Draper dataset;MIP;generative adversarial network;GAN","","1","","27","IEEE","9 Jun 2021","","","IEEE","IEEE Conferences"
"Multi-Domain Image Super-Resolution Generative Adversarial Network for Low-Resolution Person Re-Identification","S. Chen; H. Wu; Y. Chen","Institute of Robotics and Intelligent Systems, Wuhan University of Science and Technology, Wuhan, China; Institute of Robotics and Intelligent Systems, Wuhan University of Science and Technology, Wuhan, China; Institute of Robotics and Intelligent Systems, Wuhan University of Science and Technology, Wuhan, China","2021 40th Chinese Control Conference (CCC)","6 Oct 2021","2021","","","8353","8359","Person re-identification (ReID) is an important task in video surveillance application. To address the issue that various low-resolutions and scale mismatching always exist in the real world, a multi-domain image-to-image translation network, termed Multi-Domain image Super-Resolution Generative Adversarial Network (MSRGAN), is proposed to learn the mapping relationship between the various low-resolution domains and the high-resolution domain. MSRGAN can ensure that the transferred image has a similar resolution as in the target domain. It is also able to keep the identity information of images from low-resolution domain during the translation. In addition, a novel ReID model, termed CSA-ReID in which channel attention and spatial attention module are introduced, is designed to learn resolution-invariant deep representations. The proposed method achieves 90.7% rank-1 accuracy and 96.4% rank-5 accuracy on multiple low-resolutions Market-1501 dataset. The experimental results prove that the proposed method achieves promising generalization ability and accuracy compared with the state-of-the-art methods.","1934-1768","978-9-8815-6380-4","10.23919/CCC52363.2021.9549785","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9549785","person re-identification;cross-resolution;super-resolution;attention","Adaptation models;Superresolution;Generative adversarial networks;Video surveillance;Robustness;Spatial resolution;Task analysis","image representation;image resolution;learning (artificial intelligence);neural nets;video surveillance","multidomain image-to-image translation network;resolution-invariant deep representations;person re-identification;multidomain image super-resolution generative adversarial network;video surveillance;MSRGAN","","","","17","","6 Oct 2021","","","IEEE","IEEE Conferences"
"From Artifact Removal to Super-Resolution","J. Wang; Z. Shao; X. Huang; T. Lu; R. Zhang; Y. Li","State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Department of Geosciences, University of Arkansas, Fayetteville, AR, USA; School of Computer Science and Engineering, Wuhan Institute of Technology, Wuhan, China; Institute of Photogrammetry and Remote Sensing, Chinese Academy of Surveying and Mapping, Beijing, China; State Key Laboratory for Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","23 Aug 2022","2022","60","","1","15","Deep-learning-based super-resolution (SR) methods have been extensively studied and have achieved significant performance with deep convolutional neural networks. However, the results still suffer from the ringing effect, especially in satellite image SR tasks, due to the loss of image details in the satellite degradation process. In this article, we build a novel satellite SR framework by decomposing a high-resolution image into three components, i.e., low-resolution (LR), artifact, and high-frequency information. Specifically, we propose an artifact removal network with a self-adaption difference convolution (SDC) to fully exploit the structure prior in the LR image and predict the artifact map. Considering that the artifact map and the high-frequency map share a similar pattern, we introduce the supervised structure correction (SSC) block that establishes a bridge between the high-frequency generation process and the artifact removal process. Experimental results on satellite images demonstrate that the proposed method owns an improved tradeoff between the performance and the computational cost compared to existing state-of-the-art satellite and natural SR methods. The source code is available at https://github.com/jiaming-wang/ARSRN.","1558-0644","","10.1109/TGRS.2022.3196709","National Natural Science Foundation of China(grant numbers:42090012); Guangxi Science and Technology Program(grant numbers:GuiKe 2021AB30019); 03 Special Research and 5G Project of Jiangxi Province in China(grant numbers:20212ABC03A09); Zhuhai Industry University Research Cooperation Project of China(grant numbers:ZH22017001210098PWC); Sichuan Science and Technology Program(grant numbers:2022YFN0031); Zhizhuo Research Fund on Spatial-Temporal Artificial Intelligence(grant numbers:ZZJJ202202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9851467","Artifact removal;difference convolution;remote sensing;super-resolution (SR)","Satellites;Image edge detection;Task analysis;Convolution;Superresolution;Image reconstruction;Generative adversarial networks","convolutional neural nets;deep learning (artificial intelligence);geophysical image processing;image resolution","deep convolutional neural networks;ringing effect;satellite image SR tasks;image details;satellite degradation process;high-resolution image;high-frequency information;artifact removal network;self-adaption difference convolution;LR image;artifact map;supervised structure correction block;high-frequency generation process;deep-learning-based super-resolution methods;low-resolution","","","","59","IEEE","5 Aug 2022","","","IEEE","IEEE Journals"
"Improved Resolution of Dehazed Images with Dark Channel Prior and Super Resolution GAN","S. Shubham; S. Deb; R. Chaudhuri","CSE Department, National Institute of Technology, Agartala, India; CSE Department, National Institute of Technology, Agartala, India; CSE Department, National Institute of Technology, Agartala, India","2022 IEEE International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)","13 Jun 2022","2022","","","1","6","Extracting information from an image becomes difficult when the scene is disrupted due to bad atmospheric conditions. Suspended particles like fog, rain and dust creates haze in the scene. In many real time situations vision algorithms work on clean and sharp images. This makes the task of vision algorithms difficult to operate and get correct results. Moreover, after dehazing an image still a lot of information gets missing because recovery is not perfect. To fill the information gaps resolution of the image needs to be improved. Haze removal and image resolution improvement is a difficult task and this problem is poorly posed. Over the years many methods have come to address the problem of haze and also improvement of resolution of image. However, they have been addressed independently and in many real time environments resolution of dehazed image is low due to which many vision algorithms fail. In this paper, we propose a method combining Dark Channel Prior and Super Resolution GAN removing haze and improving resolution of image simultaneously followed by working principle with proper discussion of algorithm accompanied with visual representation of experimental results.","","978-1-6654-8316-2","10.1109/ICDCECE53908.2022.9793249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793249","Haze;Blur;Dark Channel Prior;Super Resolution;GAN","Visualization;Image resolution;Satellites;Rain;Robot vision systems;Generative adversarial networks;Real-time systems","computer vision;fog;image colour analysis;image denoising;image enhancement;image resolution;image restoration;optical images;video signal processing","dehazed image;Dark Channel;Super Resolution GAN;bad atmospheric conditions;suspended particles;rain;dust;time situations vision algorithms work;clean images;sharp images;information gaps resolution;haze removal;time environments resolution;improving resolution","","","","33","IEEE","13 Jun 2022","","","IEEE","IEEE Conferences"
"A Latent Encoder Coupled Generative Adversarial Network (LE-GAN) for Efficient Hyperspectral Image Super-Resolution","Y. Shi; L. Han; L. Han; S. Chang; T. Hu; D. Dancey","Department of Computing and Mathematics, Faculty of Science and Engineering, Manchester Metropolitan University, Manchester, U.K; Department of Computing and Mathematics, Faculty of Science and Engineering, Manchester Metropolitan University, Manchester, U.K; Department of Computer Science, Brunel University London, Uxbridge, U.K; State Key Laboratory of Remote Sensing Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; College of Plant Protection, Hebei Agriculture University, Baoding, China; Department of Computing and Mathematics, Faculty of Science and Engineering, Manchester Metropolitan University, Manchester, U.K","IEEE Transactions on Geoscience and Remote Sensing","10 Aug 2022","2022","60","","1","19","Realistic hyperspectral image (HSI) super-resolution (SR) techniques aim to generate a high-resolution (HR) HSI with higher spectral and spatial fidelity from its low-resolution (LR) counterpart. The generative adversarial network (GAN) has proven to be an effective deep learning framework for image SR. However, the optimization process of existing GAN-based models frequently suffers from the problem of mode collapse, leading to the limited capacity of spectral–spatial invariant reconstruction. This may cause the spectral–spatial distortion to the generated HSI, especially with a large upscaling factor. To alleviate the problem of mode collapse, this work has proposed a novel GAN model coupled with a latent encoder (LE-GAN), which can map the generated spectral–spatial features from the image space to the latent space and produce a coupling component to regularize the generated samples. Essentially, we treat an HSI as a high-dimensional manifold embedded in a latent space. Thus, the optimization of GAN models is converted to the problem of learning the distributions of HR HSI samples in the latent space, making the distributions of the generated SR HSIs closer to those of their original HR counterparts. We have conducted experimental evaluations on the model performance of SR and its capability in alleviating mode collapse. The proposed approach has been tested and validated based on two real HSI datasets with different sensors (i.e., AVIRIS and UHD-185) for various upscaling factors (i.e.,  $\times 2$ ,  $\times 4$ , and  $\times 8$ ) and added noise levels (i.e.,  $\infty $ , 40, and 80 dB) and compared with the state-of-the-art SR models (i.e., hyperspectral coupled network (HyCoNet), low tensor-train rank (LTTR), band attention GAN (BAGAN), SR-GAN, and WGAN). Experimental results show that the proposed model outperforms the competitors on the SR quality, robustness, and alleviation of mode collapse. The proposed approach is able to capture spectral and spatial details and generate more faithful samples than its competitors. It has also been found that the proposed model is more robust to noise and less sensitive to the upscaling factor and has been proven to be effective in improving the convergence of the generator and the spectral–spatial fidelity of the SR HSIs.","1558-0644","","10.1109/TGRS.2022.3193441","Biotechnology and Biological Sciences Research Council (BBSRC)(grant numbers:BB/R019983/1,BB/S020969/1); Newton Fund Institutional Links through the Newton-Ungku Omar Fund Partnership [the grant is funded by the U.K. Department of Business, Energy, and Industrial Strategy (BEIS)](grant numbers:ID 332438911); Open Research Fund of Key Laboratory of Digital Earth Science, Chinese Academy of Sciences(grant numbers:2019LDE003); Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/W007762/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9837938","Deep learning (DL);generative adversarial network (GAN);hyperspectral image (HSI) super-resolution (SR)","Superresolution;Generative adversarial networks;Generators;Spatial resolution;Optimization;Data models;Distortion","deep learning (artificial intelligence);geophysical image processing;hyperspectral imaging;image coding;image denoising;image reconstruction;image resolution;tensors","realistic hyperspectral image super resolution techniques;spectral spatial invariant reconstruction;spectral spatial distortion;generated spectral spatial features;spectral spatial fidelity;SR HSI;spatial details;spectral details;SR quality;SR-GAN;hyperspectral coupled network;state-of-the-art SR models;HSI datasets;generated SR;HR HSI samples;high dimensional manifold;coupling component;latent space;image space;LE-GAN;GAN model;generated HSI;GAN-based models;optimization process;image SR;deep learning framework;higher spectral fidelity;high resolution HSI;generative adversarial network;latent encoder","","","","69","IEEE","25 Jul 2022","","","IEEE","IEEE Journals"
"A GAN-based Super Resolution Model for Efficient Image Enhancement in Underwater Sonar Images","T. T. C; A. M. Nambiar; A. Mittal","Department of Computer Science and Engineering, Indian Institute of Technology, Madras, Chennai, India; Department of Computer Science and Engineering, Indian Institute of Technology, Madras, Chennai, India; Department of Computer Science and Engineering, Indian Institute of Technology, Madras, Chennai, India","OCEANS 2022 - Chennai","19 May 2022","2022","","","1","8","Acoustic imaging systems dominate in underwater imaging due to their unique ability to illuminate objects on the seabed, even in dark or turbid water conditions. These systems mounted on an autonomous underwater vehicle (AUV) are being used for a variety of civilian and military applications. Mine detection and classification is a predominant application. The raw images captured using these systems are usually noisy and poor in their resolution. Consequently, methods to enhance sonar images are necessary to aid further processing and classification of these acquired scenes. Inspired by the developments in the field of deep learning in different areas of computer vision, this study explores efficient deep neural networks for acoustic image super resolution. The study is performed on a custom-made sonar image dataset to handle the deficiency of public datasets in the domain. We employ a Generative Adversarial Network (GAN) deep learning model i.e. pre-trained ESRGAN and make use of transfer learning to achieve our goal with limited data samples. We use the model published by the original authors, Xintao Wang et al and experiment with our proposed method in three ways. a) Direct use of pre-trained model b) Fine-tuning the model with VGG-19 feature extractors at the discriminator and c) Finetuning the model with ResNet-34 feature extractors at the discriminator. The super resolved images are validated through image quality assessment metrics like PSNR, SSIM, and Perceptual index.","","978-1-6654-1821-8","10.1109/OCEANSChennai45887.2022.9775508","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9775508","Acoustic image enhancement;single image super resolution;ESRGAN","Deep learning;Image resolution;Oceans;Transfer learning;Sonar measurements;Feature extraction;Generative adversarial networks","acoustic imaging;autonomous underwater vehicles;computer vision;deep learning (artificial intelligence);feature extraction;image capture;image classification;image enhancement;image resolution;sonar imaging","image enhancement;underwater sonar images;acoustic imaging systems;underwater imaging;autonomous underwater vehicle;mine classification;deep neural networks;acoustic image super resolution;generative adversarial network;ESRGAN;transfer learning;image quality assessment metrics;mine detection;deep learning","","","","37","IEEE","19 May 2022","","","IEEE","IEEE Conferences"
"Siamese-SR: A Siamese Super-Resolution Model for Boosting Resolution of Digital Rock Images for Improved Petrophysical Property Estimation","V. R. Ahuja; U. Gupta; S. R. Rapole; N. Saxena; R. Hofmann; R. J. Day-Stirrat; J. Prakash; P. K. Yalavarthy","Shell India Markets Private Ltd., Shell Technology Centre Bangalore, Mahadeva Kodigehalli, Bengaluru, Karnataka, India; Department of Computational and Data Sciences, Indian Institute of Science, Bengaluru, Karnataka, India; Department of Computational and Data Sciences, Indian Institute of Science, Bengaluru, Karnataka, India; Shell International Exploration and Production Inc., Shell Technology Center Houston, Houston, TX, USA; Shell International Exploration and Production Inc., Shell Technology Center Houston, Houston, TX, USA; Shell International Exploration and Production Inc., Shell Technology Center Houston, Houston, TX, USA; Department of Instrumentation and Applied Physics, Indian Institute of Science, Bengaluru, Karnataka, India; Department of Computational and Data Sciences, Indian Institute of Science, Bengaluru, Karnataka, India","IEEE Transactions on Image Processing","18 May 2022","2022","31","","3479","3493","Digital Rock Physics leverages advances in digital image acquisition and analysis techniques to create 3D digital images of rock samples, which are used for computational modeling and simulations to predict petrophysical properties of interest. However, the accuracy of the predictions is crucially dependent on the quality of the digital images, which is currently limited by the resolution of the micro-CT scanning technology. We have proposed a novel Deep Learning based Super-Resolution model called Siamese-SR to digitally boost the resolution of Digital Rock images whilst retaining the texture and providing optimal de-noising. The Siamese-SR model consists of a generator which is adversarially trained with a relativistic and a siamese discriminator utilizing Materials In Context (MINC) loss estimator. This model has been demonstrated to improve the resolution of sandstone rock images acquired using micro-CT scanning by a factor of 2. Another key highlight of our work is that for the evaluation of the super-resolution performance, we propose to move away from image-based metrics such as Structural Similarity (SSIM) and Peak Signal to Noise Ratio (PSNR) because they do not correlate well with expert geological and petrophysical evaluations. Instead, we propose to subject the super-resolved images to the next step in the Digital Rock workflow to calculate a crucial petrophysical property of interest, viz. porosity and use it as a metric for evaluation of our proposed Siamese-SR model against several other existing super-resolution methods like SRGAN, ESRGAN, EDSR and SPSR. Furthermore, we also use Local Attribution Maps to show how our proposed Siamese-SR model focuses optimally on edge-semantics, which is what leads to improvement in the image-based porosity prediction, the permeability prediction from Multiple Relaxation Time Lattice Boltzmann Method (MRTLBM) flow simulations as well as the prediction of other petrophysical properties of interest derived from Mercury Injection Capillary Pressure (MICP) simulations.","1941-0042","","10.1109/TIP.2022.3172211","Shell; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771091","Image super-resolution;deep learning;generative adversarial networks;siamese networks;digital rock physics;petrophysics;geology;micro computed tomography;local attribution maps","Superresolution;Rocks;Predictive models;Measurement;Physics;Signal resolution;Generators","computerised tomography;flow simulation;geology;geophysical techniques;hydrocarbon reservoirs;image resolution;lattice Boltzmann methods;learning (artificial intelligence);permeability;petrology;porosity;rocks","petrophysical evaluations;Digital Rock workflow;Siamese-SR model;image-based porosity prediction;Siamese Super-Resolution model;boosting Resolution;Digital Rock images;petrophysical property estimation;Digital Rock Physics leverages advances;digital image acquisition;rock samples;computational modeling;microCT scanning technology;siamese discriminator;sandstone rock images;image-based metrics;expert geological evaluations","","1","","45","IEEE","9 May 2022","","","IEEE","IEEE Journals"
"Unsupervised Single Image Super-Resolution Network (USISResNet) for Real-World Data Using Generative Adversarial Network","K. Prajapati; V. Chudasama; H. Patel; K. Upla; R. Ramachandra; K. Raja; C. Busch","Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Norwegian University of Science and Technology (NTNU), Gjøvik, Norway; Norwegian University of Science and Technology (NTNU), Gjøvik, Norway; Norwegian University of Science and Technology (NTNU), Gjøvik, Norway","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","1904","1913","Current state-of-the-art Single Image Super-Resolution (SISR) techniques rely largely on supervised learning where Low-Resolution (LR) images are synthetically generated with known degradation (e.g., bicubic downsampling). The deep learning models trained with such synthetic dataset generalize poorly on the real-world or natural data where the degradation characteristics cannot be fully modelled. As an implication, the super-resolved images obtained for real LR images do not produce optimal Super-Resolution (SR) images. We propose a new SR approach to mitigate such an issue using unsupervised learning in Generative Adversarial Network (GAN) framework - USISResNet. In an attempt to provide high quality SR image for perceptual inspection, we also introduce a new loss function based on the Mean Opinion Score (MOS). The effectiveness of the proposed architecture is validated with extensive experiments on NTIRE-2020 Real-world SR Challenge validation (Track-1) set along with testing datasets (Track-1 and Track-2). We demonstrate the generalizable nature of proposed network by evaluating real-world images as against other state-of-the-art methods which employ synthetically downsampled LR images. The proposed network has further been evaluated on NTIRE 2020 Real-world SR Challenge dataset where the approach has achieved reliable accuracy.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9151093","","Gallium nitride;Image resolution;Generative adversarial networks;Generators;Task analysis;Degradation;Machine learning","data analysis;image resolution;unsupervised learning","supervised learning;Low-Resolution images;deep learning models;synthetic dataset;natural data;degradation characteristics;optimal Super-Resolution images;SR approach;unsupervised learning;Generative Adversarial Network framework;high quality SR image;NTIRE-2020 Real-world SR Challenge validation;real-world images;downsampled LR images;NTIRE 2020 Real-world SR Challenge dataset;unsupervised Single Image Super-Resolution Network;Real-world data;USISResNet;loss function;Mean Opinion Score;perceptual inspection","","11","","55","IEEE","28 Jul 2020","","","IEEE","IEEE Conferences"
"Super-resolution Guided Pore Detection for Fingerprint Recognition","S. N. Ferdous; A. Dabouei; J. Dawson; N. M. Nasrabadi","Lane Department of Computer Science and Electrical Engineering, West Virginia University, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, USA","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","8085","8092","Performance of fingerprint recognition algorithms substantially rely on fine features extracted from fingerprints. Apart from minutiae and ridge patterns, pore features have proven to be usable for fingerprint recognition. Although features from minutiae and ridge patterns are quite attainable from low-resolution images, using pore features is practical only if the fingerprint image is of high resolution which necessitates a model that enhances the image quality of the conventional 500 ppi legacy fingerprints preserving the fine details. To find a solution for recovering pore information from low-resolution fingerprints, we adopt a joint learning-based approach that combines both super-resolution and pore detection networks. Our modified single image Super-Resolution Generative Adversarial Network (SRGAN) framework helps to reliably reconstruct high-resolution fingerprint samples from low-resolution ones assisting the pore detection network to identify pores with a high accuracy. The network jointly learns a distinctive feature representation from a real low-resolution fingerprint sample and successfully synthesizes a high-resolution sample from it. To add discriminative information and uniqueness for all the subjects, we have integrated features extracted from a deep fingerprint verifier with the SRGAN quality discriminator. We also add ridge reconstruction loss, utilizing ridge patterns to make the best use of extracted features. Our proposed method solves the recognition problem by improving the quality of fingerprint images. High recognition accuracy of the synthesized samples that is close to the accuracy achieved using the original high-resolution images validate the effectiveness of our proposed model.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9413043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413043","","Image quality;Image recognition;Image matching;Superresolution;Fingerprint recognition;Feature extraction;Generative adversarial networks","feature extraction;fingerprint identification;image matching;image reconstruction;image resolution;learning (artificial intelligence);neural nets;object detection","pore information;joint learning-based approach;pore detection network;high-resolution fingerprint samples;distinctive feature representation;low-resolution fingerprint sample;deep fingerprint verifier;SRGAN quality discriminator;ridge reconstruction loss;ridge patterns;fingerprint image;high-resolution images;fingerprint recognition algorithms;fine features;minutiae;pore features;low-resolution images;image quality;single image super-resolution generative adversarial network;legacy fingerprints;super-resolution guided pore detection","","","","49","IEEE","5 May 2021","","","IEEE","IEEE Conferences"
"Real-World Person Re-Identification via Super-Resolution and Semi-Supervised Methods","L. Xia; J. Zhu; Z. Yu","School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China","IEEE Access","4 Mar 2021","2021","9","","35834","35845","Person re-identification has made great progress over the years. However, due to the problem of super-resolution and few labeled samples, it is difficult to apply in practice. In this paper, we propose a semi-supervised super-resolution person re-identification method based on soft multi-labels. Firstly, a Mixed-Space Super-Resolution model (MSSR) is constructed based on Generative Adversarial Networks (GAN), which aims to convert low-resolution person images into high-resolution images. Secondly, a Part-based Graph Convolutional Network (PGCN) is proposed to extract discriminative feature by exploring the relationship of local features within person. Finally, to solve the problem of label limitation, we use the PGCN trained with a small amount of labeled samples to predict the soft multi-labels of unlabeled samples, and further train PGCN with unlabeled samples based on a novel multi-label similarity loss. Experiments have been conducted on the Market1501, CUHK03, and MSMT17 datasets to evaluate this method, which show that it outperforms other semi-supervised methods.","2169-3536","","10.1109/ACCESS.2021.3063000","Hunan Science and Technology Project(grant numbers:2017GK2271); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9366508","Person re-identification;GAN;super-resolution;multi-labels;semi-supervised","Superresolution;Feature extraction;Training;Gallium nitride;Data models;Dictionaries;Predictive models","convolutional neural nets;feature extraction;graph theory;image classification;image resolution","generative adversarial networks;PGCN;label limitation;soft multilabels;semisupervised methods;person re-identification;part-based graph convolutional network;multilabel similarity loss;mixed-space super-resolution model;feature extraction","","6","","41","CCBY","1 Mar 2021","","","IEEE","IEEE Journals"
"Protecting Intellectual Property of Generative Adversarial Networks from Ambiguity Attacks","D. S. Ong; C. Seng Chan; K. W. Ng; L. Fan; Q. Yang",University of Malaya; University of Malaya; WeBank AI Lab; WeBank AI Lab; Hong Kong University of Science and Technology,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","3629","3638","Ever since Machine Learning as a Service emerges as a viable business that utilizes deep learning models to generate lucrative revenue, Intellectual Property Right (IPR) has become a major concern because these deep learning models can easily be replicated, shared, and re-distributed by any unauthorized third parties. To the best of our knowledge, one of the prominent deep learning models - Generative Adversarial Networks (GANs) which has been widely used to create photorealistic image are totally unprotected despite the existence of pioneering IPR protection methodology for Convolutional Neural Networks (CNNs). This paper therefore presents a complete protection framework in both black-box and white-box settings to enforce IPR protection on GANs. Empirically, we show that the proposed method does not compromise the original GANs performance (i.e. image generation, image super-resolution, style transfer), and at the same time, it is able to withstand both removal and ambiguity attacks against embedded watermarks. Codes are available at https://github.com/dingsheng-ong/ipr-gan.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.00363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9577609","","Deep learning;Knowledge engineering;Computer vision;Image synthesis;Superresolution;Intellectual property;Watermarking","authorisation;convolutional neural nets;image resolution;image watermarking;industrial property;learning (artificial intelligence);security of data","lucrative revenue;Intellectual Property Right;prominent deep learning models;generative adversarial networks;IPR protection methodology;Convolutional Neural Networks;complete protection framework;GAN performance;image generation;ambiguity attacks;intellectual property protection;Machine Learning;convolutional neural networks","","3","","33","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Improved Generative Adversarial Network-Based Super Resolution Reconstruction for Low-Frequency Measurement of Smart Grid","F. Li; D. Lin; T. Yu","Guangdong Key Laboratory of Clean Energy Technology, South China University of Technology, Guangzhou, China; Guangdong Key Laboratory of Clean Energy Technology, South China University of Technology, Guangzhou, China; Guangdong Key Laboratory of Clean Energy Technology, South China University of Technology, Guangzhou, China","IEEE Access","20 May 2020","2020","8","","85257","85270","There is a universal trend toward a data-driven smart grid, which aims to realize two-way communication of energy flow and data flow between various agents across power generation side, transmission&distribution side, electricity retailors and end users. However, the low frequency electrical measurement data accumulated over a long period of time is insignificant for intelligent agents. This paper presents a machine learning method for reconstructing the low frequency electrical measurement data in smart grid. Firstly, the electrical measurement data is converted into electrical images, and then the low frequency electrical measurement data is reconstructed into high frequency electrical measurement data by generative adversarial network to improve the training stability, Wasserstein distance is introduced into the reconstruction mechanism. In addition, by designing the deep residual network based generator, the deep convolutional network based discriminator as well as the perception loss function, the reconstruction accuracy and the high-frequency detail reduction ability are improved. The proposed method is tested on three publicly available datasets and compared with the traditional data reconstruction method, justifying that this method not only can restore high-frequency details with less error, but also can be generalized to different datasets at one location and to datasets at different locations with satisfactory accuracy.","2169-3536","","10.1109/ACCESS.2020.2992836","National Natural Science Foundation of China(grant numbers:51777078); Key Projects of Basic Research and Applied Basic Research in Universities of Guangdong Province(grant numbers:2018KZDXM001); Funding of Key Projects of Basic Scientific Research Operating Expenses of Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9087855","Data-driven;super-resolution reconstruction;generative adversarial network;electrical measurement data","Electric variables measurement;Image reconstruction;Generative adversarial networks;Frequency measurement;Smart grids;Gallium nitride","convolutional neural nets;data handling;frequency measurement;image reconstruction;image resolution;learning (artificial intelligence);multi-agent systems;power engineering computing;power system stability;recurrent neural nets;smart power grids;statistical distributions","low frequency electrical measurement data;high frequency electrical measurement data;deep residual network based generator;data reconstruction;low-frequency measurement;data-driven smart grid;energy flow;data flow;super resolution reconstruction;intelligent agents;generative adversarial network;power generation side;Wasserstein distance;transmission & distribution side;electricity retailors;end users;deep convolutional network based discriminator;machine learning;electrical images","","5","","36","CCBY","6 May 2020","","","IEEE","IEEE Journals"
"Reinforced Swin-Convs Transformer for Simultaneous Underwater Sensing Scene Image Enhancement and Super-resolution","T. Ren; H. Xu; G. Jiang; M. Yu; X. Zhang; B. Wang; T. Luo","School of Mathematics and Statistics, Ningbo University, Ningbo, China; School of Mathematics and Statistics, Ningbo University, Ningbo, China; Faculty of Information Science and Engineering, Ningbo University, Ningbo, China; Faculty of Information Science and Engineering, Ningbo University, Ningbo, China; School of Mathematics and Statistics, Ningbo University, Ningbo, China; School of Mathematics and Statistics, Ningbo University, Ningbo, China; Faculty of Information Science and Engineering, Ningbo University, Ningbo, China","IEEE Transactions on Geoscience and Remote Sensing","23 Sep 2022","2022","60","","1","16","Underwater image enhancement (UIE) technology aims to tackle the challenge of restoring the degraded underwater images due to light absorption and scattering. Meanwhile, the ever-increasing requirement for higher resolution images from a lower resolution in the underwater domain cannot be overlooked. To address these problems, a novel U-Net-based reinforced Swin-Convs Transformer for simultaneous enhancement and superresolution (URSCT-SESR) method is proposed. Specifically, with the deficiency of U-Net based on pure convolutions, the Swin Transformer is embedded into U-Net for improving the ability to capture the global dependence. Then, given the inadequacy of the Swin Transformer capturing the local attention, the reintroduction of convolutions may capture more local attention. Thus, an ingenious manner is presented for the fusion of convolutions and the core attention mechanism to build a reinforced Swin-Convs Transformer block (RSCTB) for capturing more local attention, which is reinforced in the channel and the spatial attention of the Swin Transformer. Finally, experimental results on available datasets demonstrate that the proposed URSCT-SESR achieves the state-of-the-art performance compared with other methods in terms of both subjective and objective evaluations. The code is publicly available at https://github.com/TingdiRen/URSCT-SESR.","1558-0644","","10.1109/TGRS.2022.3205061","Natural Science Foundation of China(grant numbers:62171243,61871247,62071266,61931022,61671412,62271276); Zhejiang Natural Science Foundation of China(grant numbers:LY19F020009,LY21F010003,LY19F010002,LQ20F010002,LY21F010014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9881581","Super-resolution (SR);Swin-Convs Transformer;U-Net;underwater image enhancement (UIE)","Transformers;Atmospheric modeling;Generative adversarial networks;Image resolution;Image enhancement;Convolutional neural networks;Superresolution","image enhancement;image resolution","simultaneous underwater sensing scene image enhancement;super-resolution;image enhancement technology;degraded underwater images;light absorption;higher resolution images;underwater domain;simultaneous enhancement;URSCT-SESR;Swin Transformer;local attention;core attention mechanism;reinforced Swin-Convs Transformer block;restoring;scattering;novel U-Net-based reinforced Swin-Convs Transformer;superresolution;(URSCT-SESR) method;convolutions;Swin Transformer capturing;embedded;reintroduction;ingenious manner;fusion;mechanism;spatial attention;datasets demonstrate;state-of-the-art;subjective;objective evaluations;U-Net;capture;lower resolution;U","","2","","69","IEEE","8 Sep 2022","","","IEEE","IEEE Journals"
"Direct Unsupervised Super-Resolution Using Generative Adversarial Network (DUS-GAN) for Real-World Data","K. Prajapati; V. Chudasama; H. Patel; K. Upla; K. Raja; R. Ramachandra; C. Busch","Electronics Engineering Department, Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Electronics Engineering Department, Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Electronics Engineering Department, Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Electronics Engineering Department, Sardar Vallabhbhai National Institute of Technology (SVNIT), Surat, India; Department of Computer Science, Norwegian University of Science and Technology (NTNU), Gjøvik, Norway; Department of Information Security and Communication Technology, Norwegian University of Science and Technology (NTNU), Gjøvik, Norway; Department of Information Security and Communication Technology, Norwegian University of Science and Technology (NTNU), Gjøvik, Norway","IEEE Transactions on Image Processing","30 Sep 2021","2021","30","","8251","8264","The deep learning models for the Single Image Super-Resolution (SISR) task have found success in recent years. However, one of the prime limitations of existing deep learning-based SISR approaches is that they need supervised training. Specifically, the Low-Resolution (LR) images are obtained through known degradation (for instance, bicubic downsampling) from the High-Resolution (HR) images to provide supervised data as an LR-HR pair. Such training results in a domain shift of learnt models when real-world data is provided with multiple degradation factors not present in the training set. To address this challenge, we propose an unsupervised approach for the SISR task using Generative Adversarial Network (GAN), which we refer to hereafter as DUS-GAN. The novel design of the proposed method accomplishes the SR task without degradation estimation of real-world LR data. In addition, a new human perception-based quality assessment loss, i.e., Mean Opinion Score (MOS), has also been introduced to boost the perceptual quality of SR results. The pertinence of the proposed method is validated with numerous experiments on different reference-based (i.e., NTIRE Real-world SR Challenge validation dataset) and no-reference based (i.e., NTIRE Real-world SR Challenge Track-1 and Track-2) testing datasets. The experimental analysis demonstrates committed improvement from the proposed method over the other state-of-the-art unsupervised SR approaches, both in terms of subjective and quantitative evaluations on different reference metrics (i.e., LPIPS, PI-RMSE graph) and no-reference quality measures such as NIQE, BRISQUE and PIQE. We also provide the implementation of the proposed approach (https://github.com/kalpeshjp89/DUSGAN) to support reproducible research.","1941-0042","","10.1109/TIP.2021.3113783","Science and Engineering Research Board (SERB), a statutory body of the Department of Science and Technology (DST), Government of India(grant numbers:ECR/2017/003268); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9547774","Unsupervised learning;image quality;image enhancement;image reconstruction;spatial resolution;artificial neural networks;interpolation","Training;Degradation;Generative adversarial networks;Superresolution;Task analysis;Unsupervised learning;Quality assessment","data compression;deep learning (artificial intelligence);image resolution;unsupervised learning","direct unsupervised Super-Resolution;Generative Adversarial Network;DUS-GAN;real-world data;deep learning models;Single Image Super-Resolution task;deep learning-based SISR approaches;supervised training;Low-Resolution images;bicubic downsampling;High-Resolution images;supervised data;LR-HR pair;domain shift;multiple degradation factors;training set;unsupervised approach;SISR task;degradation estimation;real-world LR data;human perception-based quality assessment loss;perceptual quality;NTIRE Real-world SR Challenge validation dataset;NTIRE Real-world SR Challenge Track-1;state-of-the-art unsupervised SR approaches;reference metrics;no-reference quality measures;Mean Opinion Score","","6","","68","IEEE","24 Sep 2021","","","IEEE","IEEE Journals"
"SRDN: A Unified Super-Resolution and Motion Deblurring Network for Space Image Restoration","X. Yang; X. Wang; N. Wang; X. Gao","State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Transactions on Geoscience and Remote Sensing","21 Feb 2022","2022","60","","1","11","Space target super-resolution (SR) is a domain-specific single image SR problem aiming to help distinguish the satellite and spacecrafts from numerous space debris. Compared to the other object SR problem, images for space target are always in low quality with varies of degradation condition, as a result of long distance and motion blur, which significantly reduces the manual classification reliability, especially for these small targets, e.g., satellite payloads. To address this challenge, we present an end-to-end SR and deblurring network (SRDN). Concretely, focusing on the low-resolution (LR) space target images with blind motion blur, we integrate the SR and deblur function together, improving the image quality by a unified generative adversarial network (GAN)-based framework. We implement a deblur module by using contrastive learning to extract degradation feature and add symmetrical downsampling and upsampling modules to the SR network in order to restore texture information, while shortcut connections are redesigned to maintain the global similarity. Extensive experiments on the public satellite dataset, BUAA-SID-share1.5, demonstrate that our network outperforms the state-of-the-art SR and deblur methods.","1558-0644","","10.1109/TGRS.2021.3131264","National Natural Science Foundation of China(grant numbers:61976166,62036007,62176195,61922066,61876142); Key Research and Development Program of Shaanxi(grant numbers:2021GY-030); Innovation Capacity Support Plan of Shaanxi Province(grant numbers:2020KJXX-027); Fundamental Research Funds for the Central Universities(grant numbers:JB210115); Open Research Projects of Zhejiang Laboratory(grant numbers:2021KG0AB01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9627923","Artificial intelligence;artificial neural networks;high-resolution (HR) imaging;image denoising","Feature extraction;Target recognition;Degradation;Image resolution;Superresolution;Generative adversarial networks;Image restoration","astronomical image processing;feature extraction;image motion analysis;image representation;image resolution;image restoration;image texture;learning (artificial intelligence);neural nets","blind motion blur;deblur function;image quality;unified generative adversarial network-based framework;deblur module;SR network;public satellite dataset;SRDN;unified super-resolution;motion deblurring network;space image restoration;space target super-resolution;domain-specific single image SR problem;space debris;object SR problem;manual classification reliability;low-resolution space target images;SR and deblurring network;symmetrical downsampling module;symmetrical upsampling module;BUAA-SID-share1.5 dataset","","3","","57","IEEE","29 Nov 2021","","","IEEE","IEEE Journals"
"Improved Generative Adversarial Network for Generating High-Resolution Images from Low-Resolution Images","A. Jain; A. Sarkar; A. P. Agrawal","Department of Computer Science and Engineering, Sharda University, Uttar Pradesh, India; Department of Computer Science and Engineering, Sharda University, Uttar Pradesh, India; Department of Computer Science and Engineering, Sharda University, Uttar Pradesh, India","2023 13th International Conference on Cloud Computing, Data Science & Engineering (Confluence)","22 Feb 2023","2023","","","360","364","The procedure of generating a high-resolution (HR) image from a low-resolution (LR) image is known as super-resolution (SR). In this paper, we try to perform SR using Deep Learning techniques. For better performance in medicinal imaging, forensics, pattern recognition, satellite imaging, surveillance, etc., zooming of a particular area of attention in the image is required, making high resolution necessary. We present ISRGAN (Improved Super Resolution Generative Adversarial Network), an improved version of SRGAN (Super Resolution Generative Adversarial Network) for image SR. For training the network, images from the DIV2K dataset have been used. The dataset consists of 800 different images which have been resized to 32x32 and 128x128 pixels to form LR and HR images respectively. A Generative Adversarial Network is based on the idea of Adversarial training, and comprises of 2 parts, a discriminator network, and a generator network. The generator produces a HR image from the LR image, whereas the discriminator network classifies the generated image as fake or real. The presented model produces decent results and our final super-resolved results show that the presented ISRGAN model produces images with enhanced features.","","978-1-6654-6263-1","10.1109/Confluence56041.2023.10048886","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10048886","Super Resolution;Deep Learning;DIV2K;Generative Adversarial Network;Adversarial training","Training;Deep learning;Satellites;Surveillance;Forensics;Superresolution;Generative adversarial networks","","","","","","20","IEEE","22 Feb 2023","","","IEEE","IEEE Conferences"
"Quality Enhancement for Drone Based Video using FPGA","Y. Vedavyas; S. S. Harsha; M. S. Subhash; S. Vasavi","Department of Computer Science & Engineering, VR Siddhartha Engineering College, India; Department of Computer Science & Engineering, VR Siddhartha Engineering College, India; Department of Computer Science & Engineering, VR Siddhartha Engineering College, India; Department of Computer Science & Engineering, VR Siddhartha Engineering College, India","2022 International Conference on Electronics and Renewable Systems (ICEARS)","13 Apr 2022","2022","","","29","34","Nowadays Drones are being widely used for surveillance and various other activities. The video stream produced by the drone can be disturbing or can contain noise data which might reduce the quality of the video stream. The video stream can be enhanced so that there is no disturbance in the video stream. The video enhancement can be done in real-time with the help of field programmable gate array (FPGA) which reduces the processing time with low energy consumption. Our project mainly focuses on enhancing the quality of the video stream using enhanced super-resolution generative adversarial networks (ESRGAN), contrast-limited Adaptive histogram equalization (CLAHE), Gamma Correction and Saturation Adjustment by integrating the image source in the drone with the FPGA.","","978-1-6654-8425-1","10.1109/ICEARS53579.2022.9751731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751731","Image Processing;Drone Video;Field Programmable Gate Arrays;Quality Enhancement;Enhanced Super-Resolution Generative Adversarial Networks;Contrast-Limited Adaptive Histogram Equalization;Gamma Correction;Saturation Adjustment","Histograms;Renewable energy sources;Adaptive systems;Surveillance;Superresolution;Streaming media;Logic gates","field programmable gate arrays;image enhancement;image resolution;video signal processing;video streaming","video stream;FPGA;quality enhancement;drone based video;Drones;video enhancement","","","","16","IEEE","13 Apr 2022","","","IEEE","IEEE Conferences"
"Super-Resolution for Overhead Imagery Using DenseNets and Adversarial Learning","M. Bosch; C. M. Gifford; P. A. Rodriguez","The Johns Hopkins University, Applied Physics Laboratory; The Johns Hopkins University, Applied Physics Laboratory; The Johns Hopkins University, Applied Physics Laboratory","2018 IEEE Winter Conference on Applications of Computer Vision (WACV)","7 May 2018","2018","","","1414","1422","Recent advances in Generative Adversarial Learning allow for new modalities of image super-resolution by learning low to high resolution mappings. In this paper we present our work using Generative Adversarial Networks (GANs) with applications to overhead and satellite imagery. We have experimented with several state-of-the-art architectures. We propose a GAN-based architecture using densely connected convolutional neural networks (DenseNets) to be able to super-resolve overhead imagery with a factor of up to 8x. We have also investigated resolution limits of these networks. We report results on several publicly available datasets, including SpaceNet data and IARPA Multi-View Stereo Challenge, and compare performance with other state-of-the-art architectures.","","978-1-5386-4886-5","10.1109/WACV.2018.00159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354263","","Image resolution;Generators;Gallium nitride;Training;Computer architecture;Task analysis;Convolution","convolution;feedforward neural nets;image resolution;learning (artificial intelligence);stereo image processing","image super-resolution;high resolution mappings;Generative Adversarial Networks;GAN;satellite imagery;state-of-the-art architectures;densely connected convolutional neural networks;DenseNets;super-resolve overhead imagery;resolution limits;Generative Adversarial Learning;modalities","","12","","24","IEEE","7 May 2018","","","IEEE","IEEE Conferences"
"GLEAN: Generative Latent Bank for Large-Factor Image Super-Resolution","K. C. K. Chan; X. Wang; X. Xu; J. Gu; C. C. Loy","S-Lab, Nanyang Technological University; Applied Research Center, Tencent PCG; S-Lab, Nanyang Technological University; Shanghai AI Laboratory; S-Lab, Nanyang Technological University","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","14240","14249","We show that pre-trained Generative Adversarial Networks (GANs), e.g., StyleGAN, can be used as a latent bank to improve the restoration quality of large-factor image super-resolution (SR). While most existing SR approaches attempt to generate realistic textures through learning with adversarial loss, our method, Generative LatEnt bANk (GLEAN), goes beyond existing practices by directly leveraging rich and diverse priors encapsulated in a pre-trained GAN. But unlike prevalent GAN inversion methods that require expensive image-specific optimization at runtime, our approach only needs a single forward pass to generate the upscaled image. GLEAN can be easily incorporated in a simple encoder-bank-decoder architecture with multi-resolution skip connections. Switching the bank allows the method to deal with images from diverse categories, e.g., cat, building, human face, and car. Images upscaled by GLEAN show clear improvements in terms of fidelity and texture faithfulness in comparison to existing methods as shown in Fig. 1.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.01402","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9578478","","Runtime;Superresolution;Imaging;Computer architecture;Switches;Generative adversarial networks;Image restoration","image coding;image resolution;image restoration;image texture;learning (artificial intelligence)","multiresolution skip connections;encoder-bank-decoder architecture;upscaled image;image-specific optimization;prevalent GAN inversion methods;pretrained GAN;diverse priors;directly leveraging rich priors;existing practices;GLEAN;generative latent bank;adversarial loss;SR approaches;large-factor image super-resolution","","51","","46","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Tactile Pattern Super Resolution with Taxel-based Sensors","B. Wu; Q. Liu; Q. Zhang","Department of Computer Science and Technology, Dalian University of Technology, Dalian, China; Department of Computer Science and Technology, Dalian University of Technology, Dalian, China; Department of Computer Science and Technology, Dalian University of Technology, Dalian, China","2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","26 Dec 2022","2022","","","3644","3650","In contrast to sophisticated means of visual su-per resolution (SR), not much work has been done in the tactile SR field. Existing tactile SR algorithms for taxel-based sensors mainly focus on enhancing the localization accuracy, and generally associate with a specific type of hardware, sometimes not applicable to generic taxel-based tactile sensors. Inspired by image SR, we investigate the tactile pattern SR in this paper, and present how to transform successful image SR schemes, e.g. Convolutional Neural Network (CNN) and Generative Adversarial Network (GAN) to serve the tactile SR. We propose two tactile SR models, i.e. TactileSRCNN and TactileSRGAN, and establish a new tactile pattern SR dataset for model learning. The ground truth of high resolution (HR) tactile patterns in the dataset is obtained via multi-sampling (i.e. overlapping reception) and registration of low resolution (LR) sensor. One key contribution of this research lies in achieving ×100 (from 3×4×4 to 40×40) times tactile pattern SR with a one-time tapping of 3-axis taxel-based sensor. Different from existing tactile SR algorithms which improves the localization accuracy of a single contact point, the proposed scheme can provide multi-point contact detection to robotic applications.","2153-0866","978-1-6654-7927-1","10.1109/IROS47612.2022.9981062","National Science Foundation of China(grant numbers:62071083,U1908214); Fundamental Research Funds for the Central Universities(grant numbers:DUT21GJ208); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9981062","","Location awareness;Visualization;Image resolution;Tactile sensors;Transforms;Generative adversarial networks;Sensor systems","convolutional neural nets;haptic interfaces;image resolution;learning (artificial intelligence);tactile sensors","3-axis taxel-based sensor;generic taxel-based tactile sensors;high resolution tactile patterns;image SR schemes;localization accuracy;low resolution sensor;tactile pattern SR dataset;tactile pattern super resolution;tactile SR algorithms;tactile SR field;tactile SR models;taxel-based sensors;visual super resolution","","1","","26","IEEE","26 Dec 2022","","","IEEE","IEEE Conferences"
"Image to Image Translation Networks using Perceptual Adversarial Loss Function","S. Altakrouri; S. B. Usman; N. B. Ahmad; T. Justinia; N. M. Noor","Jeddah College of Advertising, University of Business and Technology, Jeddah, Saudi Arabia; Razak Faculty of Technology and Informatics, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia; Razak Faculty of Technology and Informatics, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia; Technology & Health Informatics Department, King Saud bin Abdulaziz University for Health Sciences, Jeddah, Saudi Arabia; Razak Faculty of Technology and Informatics, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia","2021 IEEE International Conference on Signal and Image Processing Applications (ICSIPA)","20 Oct 2021","2021","","","89","94","Image to image translation based on deep learning models is a subject of immense importance in the disciplines of Artificial Intelligence (AI) and Computer Vision (CV). A variety of traditional tasks such as image colorization, image denoising and image inpainting, are categorized as typical paired image translation tasks. In computer vision, super-resolution regeneration is particularly important field. We proposed an improved algorithm to mitigate the issues that arises during the reconstruction using super resolution based on generative adversarial network. It is difficult to train in reconstruction of results. The generated images and the corresponding ground-truth images should share the same fundamental structure in order to output the required resultant images. The shared basic structure between the input and the corresponding output image is not as optimal as assumed for paired image translation tasks, which can greatly impact the generating model performance. The traditional GAN based model used in image-to-image translation tasks used a pre-trained classification network. The pre-trained networks perform well on the classification tasks compared to image translation tasks because they were trained on features that contribute to better classification. We proposed the perceptual loss based efficient net Generative Adversarial Network (PL-E-GAN) for super resolution tasks. Unlike other state of the art image translation models, the PL-E-GAN offers a generic architecture for image super-resolution tasks. PL-E-GAN is constituted of two convolutional neural networks (CNNs) that are the Generative network and Discriminator network Gn and Dn, respectively. PL-E-GAN employed both the generative adversarial loss and perceptual adversarial loss as objective function to the network. The integration of these loss function undergoes an adversarial training and both the networks Gn and Dn trains alternatively. The feasibility and benefits of the PL-E-GAN over several image translation models are shown in studies and tested on many image-to-image translation tasks","2642-6471","978-1-6654-3592-5","10.1109/ICSIPA52582.2021.9576815","Universiti Teknologi Malaysia; Ministry of Higher Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9576815","Generative adversarial network;super-resolution;image-to-image translation;convolutional neural network;EfficientNet;perceptual loss","Training;Computer vision;Superresolution;Generative adversarial networks;Linear programming;Convolutional neural networks;Task analysis","computer vision;deep learning (artificial intelligence);gallium compounds;image classification;image denoising;image resolution;image restoration","pretrained networks;PL-E-GAN;super resolution tasks;image super-resolution tasks;generative adversarial loss;image-to-image translation tasks;image translation networks;computer vision;image colorization;image denoising;typical paired image translation tasks;ground-truth images;resultant images;corresponding output image;traditional GAN based model;pretrained classification network;perceptual adversarial loss function;efficient net generative adversarial network","","1","","33","IEEE","20 Oct 2021","","","IEEE","IEEE Conferences"
"PCB Defect Detection based on Generative Adversarial Network","S. You","State Key Laboratory on Integrated Optoelectronics, Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China","2022 2nd International Conference on Consumer Electronics and Computer Engineering (ICCECE)","21 Feb 2022","2022","","","557","560","This paper proposes a PCB defect detection scheme based on the generative confrontation network, which can be applied to the automatic detection system of PCB vision inspection (vision inspection). We use the edge-enhanced super-resolution GAN (EESRGAN) applied in the field of remote sensing to enhance the PCB images and complete the super-resolution detection of the reconstructed picture. And use the PCB pictures of different preprocessing models in an end-to-end manner to compare the recognition of PCB defects after training. Experiments on the PCB data set show that the PCB pictures after sliding cutting are input into the result of EESRGAN training, which can relatively accurately identify the 6 types of defects contained in the data set. Our results show the effectiveness of our data processing methods.","","978-1-6654-0886-8","10.1109/ICCECE54139.2022.9712737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712737","PCB defect detection;EESRGAN;Generative Adversarial Network","Training;Fault diagnosis;Machine vision;Image edge detection;Superresolution;Inspection;Generative adversarial networks","automatic optical inspection;computer vision;electronic engineering computing;fault diagnosis;image enhancement;image reconstruction;image resolution;inspection;neural nets;printed circuits","generative adversarial network;PCB defect detection;generative confrontation network;automatic detection system;PCB vision inspection;edge-enhanced super-resolution GAN;remote sensing;PCB images;super-resolution detection;reconstructed picture;PCB pictures;preprocessing models;PCB data;EESRGAN training","","2","","12","IEEE","21 Feb 2022","","","IEEE","IEEE Conferences"
"Dual Generative Adversarial Network For Ultrasound Localization Microscopy","Y. Zhao; S. Liu; A. Luo; B. Peng","School of Computer Science, Southwest Petroleum University, Sichuan, China, Chengdu, China; School of Computer Science, Southwest Petroleum University, Sichuan, China, Chengdu, China; Sichuan Provincial Key Laboratory of Ultrasound Cardiac Electrophysiology and Biomechanics, Sichuan, China, Chengdu, China; School of Computer Science, Southwest Petroleum University, Sichuan, China, Chengdu, China","2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","18 Nov 2022","2022","","","3125","3130","Ultrasound localization microscopy (ULM) is a new imaging technique that uses microbubbles (MBs) to improve the spatial resolution of ultrasound (US) imaging. For ULM, it is critical to accurately localize MB position. Recently, deep learning-based methods are adopted to acquire MB localization, which shows promising performance and efficient computation. However, detection of high-concentration MBs is still a challenging task. To further improve the localization accuracy, a dual generative adversarial network (DualGAN)-based ULM imaging method (DualGAN-ULM) is proposed in this paper to overcome the problems of long data processing time and low parameter robustness in current ULM imaging methods. This method is trained using simulated data generated by point spread function (PSF) convolution and uses dual generation adversarial strategy to enable the generator to perform accurate localization under high-concentration MB conditions. Meanwhile, the localization and reconstruction capabilities of five ULM methods, namely Centroid, CS-ULM, mUNET-ULM, mSPCN-ULM and DualGAN-ULM, are evaluated in this paper. The experimental results reveal that DL-based ULM methods (DualGAN-ULM, mSPCN-ULM, and mUNET-ULM) outperform compressed sensing-based localization methods (CS-ULM) and Centroid in terms of localization accuracy and localization dependability. DualGAN-ULM performs better than mSPCN-ULM and mUNET-ULM, making it a more realistic ULM method.","2577-1655","978-1-6654-5258-8","10.1109/SMC53654.2022.9945563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9945563","Ultrasound Localization Microscopy;Ultrasound Super-Resolution Imaging;Microbubble Localization;Generative Adversarial Networks;Point Spread Function","Location awareness;Learning systems;Ultrasonic imaging;Microscopy;Superresolution;Generative adversarial networks;Robustness","biomedical ultrasonics;compressed sensing;image reconstruction;image resolution;learning (artificial intelligence);medical image processing;optical transfer function","CS-ULM;current ULM imaging methods;deep learning-based methods;DL-based ULM methods;dual generation adversarial strategy;dual generative adversarial network-based ULM imaging method;DualGAN-ULM;high-concentration MB conditions;high-concentration MBs;imaging technique;localization accuracy;localization dependability;MB localization;mSPCN-ULM;mUNET-ULM;realistic ULM method;reconstruction capabilities;sensing-based localization methods;ultrasound localization microscopy","","","","18","IEEE","18 Nov 2022","","","IEEE","IEEE Conferences"
"Crop Leaf Disease Image Super-Resolution and Identification With Dual Attention and Topology Fusion Generative Adversarial Network","Q. Dai; X. Cheng; Y. Qiao; Y. Zhang","School of Information and Computer, Anhui Agricultural University, Hefei, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Information and Computer, Anhui Agricultural University, Hefei, China; School of Information and Computer, Anhui Agricultural University, Hefei, China","IEEE Access","26 Mar 2020","2020","8","","55724","55735","For agricultural disease image identification, obtained images are typically unclear, which can lead to poor identification results in real production environments. The quality of an image has a significant impact on the identification accuracy of pre-trained image classifiers. To address this problem, we propose a generative adversarial network with dual-attention and topology-fusion mechanisms called DATFGAN. This network can effectively transform unclear images into clear and high-resolution images. Additionally, the weight sharing scheme in our proposed network can significantly reduce the number of parameters. Experimental results demonstrate that DATFGAN yields more visually pleasing results than state-of-the-art methods. Additionally, treated images are evaluated based on identification tasks. The results demonstrate that the proposed method significantly outperforms other methods and is sufficiently robust for practical use.","2169-3536","","10.1109/ACCESS.2020.2982055","National Key Research and Development Project of China(grant numbers:2017YFD0301303); 2019 National Undergraduate Training Programs for Innovation and Entrepreneurship(grant numbers:201910364073); Open Foundation of Key Laboratory of Agricultural E-commerce(grant numbers:AEC2018012); Open Foundation of Anhui Key Laboratory of Intelligent Agricultural Technology And Equipment(grant numbers:APKLSATE $2019\times 012$); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9042295","Crop leaf disease;attention;generative adversarial networks;super-resolution;identification","Diseases;Agriculture;Feature extraction;Topology;Network topology;Generators","agriculture;crops;feature extraction;image classification;image resolution;learning (artificial intelligence);neural nets;plant diseases","poor identification results;production environments;identification accuracy;pre-trained image classifiers;dual-attention;topology-fusion mechanisms;unclear images;high-resolution images;weight sharing scheme;treated images;identification tasks;crop leaf disease image super-resolution;dual attention;topology fusion generative adversarial network;agricultural disease image identification;DATFGAN;visually pleasing results","","22","","37","CCBY","19 Mar 2020","","","IEEE","IEEE Journals"
"DeepDT: Generative Adversarial Network for High-Resolution Climate Prediction","J. Cheng; J. Liu; Q. Kuang; Z. Xu; C. Shen; W. Liu; K. Zhou","School of Computer, Wuhan University, Wuhan, China; School of Computer, Wuhan University, Wuhan, China; Public Weather Services Center, China Meteorological Administration (CMA), Beijing, China; School of Big Data and Software Engineering, Chongqing University, Chongqing, China; School of Computer, Wuhan University, Wuhan, China; School of Computer, Wuhan University, Wuhan, China; School of Computer, Wuhan University, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","15 Dec 2021","2022","19","","1","5","Climate prediction is susceptible to a variety of meteorological factors, and downscaling technology is used for high-resolution climate prediction. This technology can generate small-scale regional climate prediction from large-scale climate output information. Inspired by the concept of image super resolution, we propose to apply the convolutional neural network (CNN) to downscaling technology. However, some unpleasant artifacts always appear in the final climate images generated by existing CNN-based models. To further eliminate these unpleasant artifacts, we present a new training strategy for the generative adversarial network, termed DeepDT. The key idea of our DeepDT is to train a generator and a discriminator separately. More specifically, we apply the residual-in-residual dense block as the basic frame structure to fully extract the features of the input. Additionally, we innovatively use a CNN model to fuse multiple climate elements to generate trainable climate images, and build a high-quality climate data set. Finally, we evaluate the DeepDT using the proposed climate data sets, and the experiments indicate that DeepDT performs best compared to most CNN-based models in climate prediction.","1558-0571","","10.1109/LGRS.2020.3041760","National Key Research and Development Program of China(grant numbers:2018YFC1507801); National Science Foundation of China (NSFC)(grant numbers:61972290); Fundamental Research Funds for the Central Universities(grant numbers:2042019kf0226); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9383802","Climate prediction;generative adversarial network;image super resolution","Meteorology;Generators;Predictive models;Feature extraction;Data models;Training;Generative adversarial networks","","","","3","","15","IEEE","23 Mar 2021","","","IEEE","IEEE Journals"
"See Clearly in the Distance: Representation Learning GAN for Low Resolution Object Recognition","Y. Xi; J. Zheng; W. Jia; X. He; H. Li; Z. Ren; K. -M. Lam","School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, Australia; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, Australia; Institute for Media Innovation, Nanyang Technological University, Singapore; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, Australia; Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong","IEEE Access","24 Mar 2020","2020","8","","53203","53214","Identifying tiny objects with extremely low resolution is generally considered a very challenging task even for human vision, due to limited information presented inside the object areas. There have been very limited attempts in recent years to deal with low-resolution recognition. The existing solutions rely on either generating super-resolution images or learning multi-scale features. However, their performance improvement becomes very limited, especially when the resolution becomes very low. In this paper, we propose a Representation Learning Generative Adversarial Network (RL-GAN) to generate super image representation that is optimized for recognition. Our solution deals with the classical vision task of object recognition in the distance. We evaluate our idea on the challenging task of low-resolution object recognition. Comparison of experimental results conducted on public and our newly created WIDER-SHIP datasets demonstrate the effectiveness of our RL-GAN, which improves the classification results significantly, with 10-15% gain on average, compared with benchmark solutions.","2169-3536","","10.1109/ACCESS.2020.2978980","National Natural Science Foundation of China(grant numbers:61972321); Research and Development Plan of Shaanxi Province(grant numbers:2017ZDXM-GY-094,2015KTZDGY04-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9026982","Convolutional neural networks;generative adversarial networks;low resolution object recognition;representation learning","Image resolution;Object recognition;Signal resolution;Feature extraction;Image recognition;Generative adversarial networks;Task analysis","computer vision;feature extraction;image classification;image representation;image resolution;learning (artificial intelligence);object recognition","low resolution object recognition;Representation Learning GAN;low-resolution object recognition;classical vision task;super image representation;RL-GAN;generating super-resolution images;low-resolution recognition;object areas;extremely low resolution;identifying tiny objects","","7","","53","CCBY","6 Mar 2020","","","IEEE","IEEE Journals"
"Generative Difference Image for Blind Image Quality Assessment","Y. Han; Y. Wang; Y. Ma","Xinjiang Laboratory of Minority Speech and Language Information Processing, Chinese Academy of Sciences, Urumqi, China; Xinjiang Laboratory of Minority Speech and Language Information Processing, Chinese Academy of Sciences, Urumqi, China; Xinjiang Laboratory of Minority Speech and Language Information Processing, Chinese Academy of Sciences, Urumqi, China","2021 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI)","4 Oct 2021","2021","","","108","115","Image quality usually refers to the degree of error of the distorted image relative to the reference image in the human visual perception system. Image quality assessment is to score the image quality objectively. No-reference image quality assessment is limited to distorted image information, which is more challenging in the field of computer vision. In this paper, we proposed an approach based on difference image generation to address this problem. First, by removing the up-sampling layer and batch normalization layer in the Super-Resolution Generative Adversarial Network (SRGAN) to build a difference image generation model, and applying the content loss function to optimize the model. Then, the regression network is constructed based on the convolutional neural network (CNN). The regression network contains 4 convolutional layers and 2 fully connected layers and learns the correlation between the generated difference image and the image quality score to predict the distorted image quality. Finally, comparative experiments were evaluated on three public datasets. Compared with the previous state-of-the-art methods, our method obtains similar results on the LIVE dataset and achieves significant improvement on the TID2013 and CSIQ datasets. The results demonstrate that our proposed approach achieves state-of-the-art image quality prediction.","","978-1-6654-3960-2","10.1109/ICCEAI52939.2021.00021","West Light Foundation of The Chinese Academy of Sciences(grant numbers:2019-XBQNXZ-B-009); Natural Science Foundation of Xinjiang, China(grant numbers:2020D01B55); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544120","image quality assessment;generative adversarial networks;difference image generation","Image quality;Correlation;Image synthesis;Superresolution;Generative adversarial networks;Distortion;Generators","computer vision;convolutional neural nets;image resolution;image sampling;learning (artificial intelligence);regression analysis;visual perception","blind image quality assessment;human visual perception system;no-reference image quality assessment;distorted image information;batch normalization layer;super-resolution generative adversarial network;difference image generation model;regression network;generated difference image;image quality score;distorted image quality;image quality prediction;generative difference image;content loss function;TID2013 dataset;CSIQ dataset;convolutional neural network;up-sampling layer","","","","39","IEEE","4 Oct 2021","","","IEEE","IEEE Conferences"
"Facial Expression Neutralization With StoicNet","W. Carver; I. Nwogu","1 Lomb Memorial Dive, Rochester Institute of Technology, Rochester, NY; 1 Lomb Memorial Dive, Rochester Institute of Technology, Rochester, NY","2021 IEEE Winter Conference on Applications of Computer Vision Workshops (WACVW)","21 Apr 2021","2021","","","201","208","Expression neutralization is the process of synthetically altering an image of a face so as to remove any facial expression from it without changing the face's identity. Facial expression neutralization could have a variety of applications, particularly in the realms of facial recognition, in action unit analysis, or even improving the quality of identification pictures for various types of documents. Our proposed model, StoicNet, combines the robust encoding capacity of variational autoencoders, the generative power of generative adversarial networks, and the enhancing capabilities of super resolution networks with a learned encoding transformation to achieve compelling expression neutralization, while preserving the identity of the input face. Objective experiments demonstrate that StoicNet successfully generates realistic, identity-preserved faces with neutral expressions, regardless of the emotion or expression intensity of the input face.","2690-621X","978-1-6654-1967-3","10.1109/WACVW52041.2021.00026","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9407808","","Computer vision;Face recognition;Conferences;Generative adversarial networks;Encoding","emotion recognition;face recognition;image coding;image enhancement;image resolution;learning (artificial intelligence);neural nets","facial expression neutralization;StoicNet;facial recognition;generative adversarial networks;identity-preserved faces;neutral expressions;face identity;action unit analysis;variational autoencoders;super resolution network;learned encoding transformation","","","","27","IEEE","21 Apr 2021","","","IEEE","IEEE Conferences"
"A Progressive Fusion Generative Adversarial Network for Realistic and Consistent Video Super-Resolution","P. Yi; Z. Wang; K. Jiang; J. Jiang; T. Lu; J. Ma","National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, China; Peng Cheng Laboratory, Shenzhen, China; School of Computer Science and Engineering, Wuhan Institute of Technology, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","1 Apr 2022","2022","44","5","2264","2280","How to effectively fuse temporal information from consecutive frames remains to be a non-trivial problem in video super-resolution (SR), since most existing fusion strategies (direct fusion, slow fusion, or 3D convolution) either fail to make full use of temporal information or cost too much calculation. To this end, we propose a novel progressive fusion network for video SR, in which frames are processed in a way of progressive separation and fusion for the thorough utilization of spatio-temporal information. We particularly incorporate multi-scale structure and hybrid convolutions into the network to capture a wide range of dependencies. We further propose a non-local operation to extract long-range spatio-temporal correlations directly, taking place of traditional motion estimation and motion compensation (ME&MC). This design relieves the complicated ME&MC algorithms, but enjoys better performance than various ME&MC schemes. Finally, we improve generative adversarial training for video SR to avoid temporal artifacts such as flickering and ghosting. In particular, we propose a frame variation loss with a single-sequence training method to generate more realistic and temporally consistent videos. Extensive experiments on public datasets show the superiority of our method over state-of-the-art methods in terms of performance and complexity. Our code is available at https://github.com/psychopa4/MSHPFNL.","1939-3539","","10.1109/TPAMI.2020.3042298","National Key Research and Development Program of China(grant numbers:2016YFE0202300); National Natural Science Foundation of China(grant numbers:61671332,U1903214,U1736206,62071339,62072350,62072347,61971165,61773295); Hubei Province Technological Innovation Major(grant numbers:2019AAA049,2019AAA045); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9279273","Convolutional neural network;video super-resolution;spatio-temporal correlation;progressive fusion;generative adversarial network","Training;Convolution;Three-dimensional displays;Image reconstruction;Gallium nitride;Neural networks;Generative adversarial networks","","","","21","","71","IEEE","3 Dec 2020","","","IEEE","IEEE Journals"
"A Compact Memristor-based GAN Architecture with a Case Study on Single Image Super-Resolution","Z. Dong; Y. Fang; L. Huang; J. Li; D. Qi","College of Electrical Engineering, Zhejiang University, Hangzhou; College of Electrical Engineering, Zhejiang University, Hangzhou; State Grid Beijing Electric Power Corporation Fengtai Power Supply Bureau, Beijing, China; State Grid Beijing Electric Power Corporation Fengtai Power Supply Bureau, Beijing, China; College of Electrical Engineering, Zhejiang University, Hangzhou","2019 Chinese Control And Decision Conference (CCDC)","12 Sep 2019","2019","","","3069","3074","The generative adversarial network (GAN) is a kind of unsupervised learning approach with the capacity of dealing with the challenge of limited labeled data in the supervised learning world. However, the limited data bandwidth, as well as the performance gap between processing units and memory of the conventional computing platform becomes a major obstacle in the GAN based applications. In this paper, a memristor-based convolution neural network (CNN) unit synthesized with the spintronic memristor crossbar circuit and a general sigmoid activation function circuit is designed for the implementation of convolutional calculation. Notably, multiple memristor-based CNN units can be utilized for the construction of the generator and discriminator respectively. Based on this, a compact GAN architecture composed of the generator block and discriminator block is presented. For verification, the presented memristor-based GAN is applied to the single image super-resolution (SR). The experimental results demonstrate the validity and effectiveness of the entire scheme.","1948-9447","978-1-7281-0106-4","10.1109/CCDC.2019.8832460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8832460","Generative adversarial network;Spintronic memristor;Convolutional computation;Single image super-resolution","Memristors;Gallium nitride;Spintronics;Generative adversarial networks;Generators;Current density;Computer architecture","convolutional neural nets;image resolution;memristors;unsupervised learning","generator block;discriminator block;generative adversarial network;unsupervised learning approach;memristor-based convolution neural network unit;spintronic memristor crossbar circuit;single image superresolution;memristor-based GAN architecture;sigmoid activation function circuit;memristor-based CNN units","","1","","23","IEEE","12 Sep 2019","","","IEEE","IEEE Conferences"
"Multimodal-Boost: Multimodal Medical Image Super-Resolution Using Multi-Attention Network With Wavelet Transform","F. A. Dharejo; M. Zawish; F. Deeba; Y. Zhou; K. Dev; S. A. Khowaja; N. M. F. Qureshi","Computer Net-work Information Center, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Walton Institute for Information and Communication Systems Science, Waterford Institute of Technology, Ireland; Computer Net-work Information Center, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Computer Net-work Information Center, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Department of institute of intelligent systems, University of Johannesburg, South Africa; Faculty of Engineering and Technology, University of Sindh, Jamshoro, Pakistan; Department of Computer Education, Sungkyunkwan University, Seoul, Korea","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2022","PP","99","1","14","Multimodal medical images are widely used by clinicians and physicians to analyze and retrieve complementary information from high-resolution images in a non-invasive manner. Loss of corresponding image resolution adversely affects the overall performance of medical image interpretation. Deep learning-based single image super resolution (SISR) algorithms have revolutionized the overall diagnosis framework by continually improving the architectural components and training strategies associated with convolutional neural networks (CNN) on low-resolution images. However, existing work lacks in two ways: i) the SR output produced exhibits poor texture details, and often produce blurred edges, ii) most of the models have been developed for a single modality, hence, require modification to adapt to a new one. This work addresses (i) by proposing generative adversarial network (GAN) with deep multi-attention modules to learn high-frequency information from low-frequency data. Existing approaches based on the GAN have yielded good SR results; however, the texture details of their SR output have been experimentally confirmed to be deficient for medical images particularly. The integration of wavelet transform (WT) and GANs in our proposed SR model addresses the aforementioned limitation concerning textons. While the WT divides the LR image into multiple frequency bands, the transferred GAN uses multi-attention and upsample blocks to predict high-frequency components. Additionally, we present a learning method for training domain-specific classifiers as perceptual loss functions. Using a combination of multi-attention GAN loss and a perceptual loss function results in an efficient and reliable performance. Applying the same model for medical images from diverse modalities is challenging, our work addresses (ii) by training and performing on several modalities via transfer learning. Using two medical datasets, we validate our proposed SR network against existing state-of-the-art approaches and achieve promising results in terms of structural similarity index (SSIM) and peak signal-to-noise ratio (PSNR).","1557-9964","","10.1109/TCBB.2022.3191387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9832515","Attention modules;generative adversarial network;multimodality data;super-resolution;transfer learning;wavelet transform","Generative adversarial networks;Task analysis;Image reconstruction;Medical diagnostic imaging;Image edge detection;Training;Feature extraction","","","","","","","IEEE","18 Jul 2022","","","IEEE","IEEE Early Access Articles"
"Bridging Component Learning with Degradation Modelling for Blind Image Super-Resolution","Y. Wu; F. Li; H. Bai; W. Lin; R. Cong; Y. Zhao","Institute of Information Science, Beijing Jiaotong University, Beijing, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; School of Computer Science and Engineering, Nanyang Technological University, 50 Nanyang Avenue, Singapore; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China","IEEE Transactions on Multimedia","","2022","PP","99","1","16","Convolutional Neural Network (CNN)-based image super-resolution (SR) has exhibited impressive success on known degraded low-resolution (LR) images. However, this type of approach is hard to hold its performance in practical scenarios when the degradation process (i.e. blur and downsampling) is unknown. Despite existing blind SR methods proposed to solve this problem using blur kernel estimation, the perceptual quality and reconstruction accuracy are still unsatisfactory. In this paper, we analyze the degradation of a high-resolution (HR) image from image intrinsic components according to a degradation-based formulation model. We propose a components decomposition and co-optimization network (CDCN) for blind SR. Firstly, CDCN decomposes the input LR image into structure and detail components in feature space. Then, the mutual collaboration block (MCB) is presented to exploit the relationship between both two components. In this way, the detail component can provide informative features to enrich the structural context and the structure component can carry structural context for better detail revealing via a mutual complementary manner. After that, we present a degradation-driven learning strategy to jointly supervise the HR image detail and structure restoration process. Finally, a multi-scale fusion module followed by an upsampling layer is designed to fuse the structure and detail features and perform SR reconstruction. Empowered by such degradation-based components decomposition, collaboration, and mutual optimization, we can bridge the correlation between component learning and degradation modelling for blind SR, thereby producing SR results with more accurate textures. Extensive experiments on both synthetic SR datasets and real-world images show that the proposed method achieves the state-of-the-art performance compared to existing methods.","1941-0077","","10.1109/TMM.2022.3216115","National Key R & D Program of China(grant numbers:2022YFE0200300); Fundamental Research Funds for the Central Universities(grant numbers:2019JBZ102); National Natural Science Foundation of China(grant numbers:61972023,62002014,62120106009); Beijing Natural Science Foundation(grant numbers:4222013,L223022); Beijing Nova Program under Grant(grant numbers:Z201100006820016); CAAI-Huawei MindSpore Open Fund and the China Scholarship Council(grant numbers:202007090046); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9925720","blind image super-resolution;convolutional neural network;component learning;degradation modelling;degradation-driven learning strategy","Degradation;Kernel;Image reconstruction;Estimation;Superresolution;Generative adversarial networks;Collaboration","","","","","","","CCBY","20 Oct 2022","","","IEEE","IEEE Early Access Articles"
"Super-Resolution Reconstruction of Remote Sensing Images Using Generative Adversarial Network With Shallow Information Enhancement","Y. Fu; X. Zhang; M. Wang","College of Information and Computer Engineering, Northeast Forestry University, Harbin, China; College of Economics and Business Administration, Heilongjiang Institute of Technology, Harbin, China; College of Information and Computer Engineering, Northeast Forestry University, Harbin, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","11 Oct 2022","2022","15","","8529","8540","The super-resolution (SR) reconstruction method based on deep learning can significantly improve the spatial SR of remote sensing images. However, the current methods make insufficient use of the remote context information and channel information in shallow feature extraction, resulting in the limited effect of SR reconstruction. This article proposed a new SR reconstruction model, SIEGAN, which uses generative adversarial network with shallow information enhancement to improve the effect of SR reconstruction of remote sensing images. Similar to other generative adversarial models, SIEGAN is composed of generator and discriminator. But SIEGAN enhances the generator's ability to extract shallow information by using three different scale convolution operations. Specifically, a depthwise convolution is used to extract the local context information of each band of the image. A depthwise dilation convolution is used to capture the remote context information in the image. Finally, a 1×1 convolution is used to extract the correlation features between different channels in remote sensing images. In addition, SIEGAN uses U-Net network as its discriminator to provide detailed feedback per pixel to the generator to improve the model's ability to identify image details. And the spectral–spatial total variation loss function is introduced to ensure the spectral–spatial reliability of the reconstructed images. The experimental results on Gaofen-1 data proved that compared with the state-of-the-art models, SIEGAN has achieved better SR reconstruction performance. Furthermore, the reconstructed images by SIEGAN demonstrate better performance in land cover classification.","2151-1535","","10.1109/JSTARS.2022.3209819","National Natural Science Foundation of China(grant numbers:71473034); Natural Science Foundation of Heilongjiang Province(grant numbers:LH2019G001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9903573","Generative adversarial network (GAN);multiscale shallow information;remote sensing images;super-resolution (SR) reconstruction","Feature extraction;Image reconstruction;Superresolution;Spatial resolution;Remote sensing;Generative adversarial networks","","","","","","37","CCBY","26 Sep 2022","","","IEEE","IEEE Journals"
"High-Resolution Pelvic MRI Reconstruction Using a Generative Adversarial Network With Attention and Cyclic Loss","G. Li; J. Lv; X. Tong; C. Wang; G. Yang","School of Computer and Control Engineering, Yantai University, Yantai, China; School of Computer and Control Engineering, Yantai University, Yantai, China; School of Computer and Control Engineering, Yantai University, Yantai, China; Human Phenome Institute, Fudan University, Shanghai, China; National Heart and Lung Institute, Imperial College London, London, U.K","IEEE Access","2 Aug 2021","2021","9","","105951","105964","Magnetic resonance imaging (MRI) is an important medical imaging modality, but its acquisition speed is quite slow due to the physiological limitations. Recently, super-resolution methods have shown excellent performance in accelerating MRI. In some circumstances, it is difficult to obtain high-resolution images even with prolonged scan time. Therefore, we proposed a novel super-resolution method that uses a generative adversarial network with cyclic loss and attention mechanism to generate high-resolution MR images from low-resolution MR images by upsampling factors of 2× and 4×. We implemented our model on pelvic images from healthy subjects as training and validation data, while those data from patients were used for testing. The MR dataset was obtained using different imaging sequences, including T2, T2W SPAIR, and mDIXON-W. Four methods, i.e., BICUBIC, SRCNN, SRGAN, and EDSR were used for comparison. Structural similarity, peak signal to noise ratio, root mean square error, and variance inflation factor were used as calculation indicators to evaluate the performances of the proposed method. Various experimental results showed that our method can better restore the details of the high-resolution MR image as compared to the other methods. In addition, the reconstructed high-resolution MR image can provide better lesion textures in the tumor patients, which is promising to be used in clinical diagnosis.","2169-3536","","10.1109/ACCESS.2021.3099695","National Natural Science Foundation of China(grant numbers:61902338); National Natural Science Foundation of China(grant numbers:62001120); Shanghai Sailing Program(grant numbers:20YF1402400); British Heart Foundation(grant numbers:TG/18/5/34111,PG/16/78/32402); Hangzhou Economic and Technological Development Area Strategical Grant (Imperial Institute of Advanced Technology); European Research Council Innovative Medicines Initiative on Development of Therapeutics and Diagnostics Combatting Coronavirus Infections Award “DRAGON: rapiD and secuRe AI imaging based diaGnosis, stratification, fOllow-up, and preparedness for coronavirus paNdemics”(grant numbers:H2020-JTI-IMI2 101005122); AI for Health Imaging Award “CHAIMELEON: Accelerating the Lab to Market Transition of AI Tools for Cancer Management”(grant numbers:H2020-SC1-FA-DTS-2019-1 952172); U.K. Research and Innovation(grant numbers:MR/V023799/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9493874","Super-resolution reconstruction;pelvic;generative adversarial network;cyclic loss;attention","Generative adversarial networks;Magnetic resonance imaging;Image reconstruction;Superresolution;Generators;Decoding;Training","biomedical MRI;image enhancement;image reconstruction;image resolution;image sampling;image sequences;medical image processing;tumours","high-resolution pelvic MRI reconstruction;generative adversarial network;magnetic resonance imaging;important medical imaging modality;super-resolution methods;high-resolution images;novel super-resolution method;cyclic loss;attention mechanism;high-resolution MR image;low-resolution MR images;pelvic images;different imaging sequences","","9","","49","CCBYNCND","26 Jul 2021","","","IEEE","IEEE Journals"
"Adaptive Image Scaling for Corresponding Points Matching between Images with Differing Spatial Resolutions","H. Toriya; A. Dewan; I. Kitahara","Dept. of Intelligent Interaction Tech., University of Tsukuba, Tsukuba, Ibaraki, Japan; School of Earth and Planetary Sciences, Curtin University, Perth, WA, Australia; Center for Computational Sciences, University of Tsukuba, Tsukuba, Ibaraki, Japan","2020 IEEE International Conference on Big Data (Big Data)","19 Mar 2021","2020","","","3088","3095","In this study, an image scaling method to improve the accuracy of the image registration between images using different imaging devices is proposed. It is known that conventional keypoint detection, description, and matching methods do not work well between images with different spatial resolutions, such as those captured by drones and satellites. Thus, we propose a method to improve the geometric accuracy of image registration through an adaptive combination of super-resolution and low- resolution images and downscaling to high-resolution images based on the assumption that artificial structures are perceived as relatively simple shapes in top-view images. If the superresolution factor is too high, artifacts are generated, and the accuracy of the corresponding matching points will be decreased. Thus, estimating the highest super-resolution factor while avoiding the artifacts is necessary. Using the super-resolution factor, super-resolution processing of satellite images and downscaling to drone images are simultaneously performed. This is followed by corresponding points matching to achieve high estimation accuracy in the image registration process. Through quantitative evaluation experiments performed using pairs of images with 12 times difference in spatial resolutions, we demonstrated that high-accuracy image registration is possible by applying super-resolution processing at a factor of 4 to 6.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9377754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377754","image registration;drones;satellite images;super-resolution;generative adversarial networks","Image registration;Satellites;Shape;Superresolution;Big Data;Spatial resolution;Drones","feature extraction;image matching;image reconstruction;image registration;image resolution;medical image processing","drone images;high estimation accuracy;image registration process;12 times difference;high-accuracy image registration;super-resolution processing;adaptive image scaling;points matching;differing spatial resolutions;image scaling method;different imaging devices;conventional keypoint detection;matching methods;geometric accuracy;adaptive combination;low- resolution images;high-resolution images;top-view images;superresolution factor;corresponding matching points;super-resolution factor;satellite images","","1","","23","IEEE","19 Mar 2021","","","IEEE","IEEE Conferences"
"Exemplar Guided Face Image Super-Resolution Without Facial Landmarks","B. Dogan; S. Gu; R. Timofte","Computer Vision Lab, D-ITET, ETH Zurich; Computer Vision Lab, D-ITET, ETH Zurich; Computer Vision Lab, D-ITET, ETH Zurich","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","9 Apr 2020","2019","","","1814","1823","Nowadays, due to the ubiquitous visual media there are vast amounts of already available high-resolution (HR) face images. Therefore, for super-resolving a given very low-resolution (LR) face image of a person it is very likely to find another HR face image of the same person which can be used to guide the process. In this paper, we propose a convolutional neural network (CNN)-based solution, namely GWAInet, which applies super-resolution (SR) by a factor 8x on face images guided by another unconstrained HR face image of the same person with possible differences in age, expression, pose or size. GWAInet is trained in an adversarial generative manner to produce the desired high quality perceptual image results. The utilization of the HR guiding image is realized via the use of a warper subnetwork that aligns its contents to the input image and the use of a feature fusion chain for the extracted features from the warped guiding image and the input image. In training, the identity loss further helps in preserving the identity related features by minimizing the distance between the embedding vectors of SR and HR ground truth images. Contrary to the current state-of-the-art in face super-resolution, our method does not require facial landmark points for its training, which helps its robustness and allows it to produce fine details also for the surrounding face region in a uniform manner. Our method GWAInet produces photo-realistic images in upscaling factor 8x and outperforms state-of-the-art in quantitative terms and perceptual quality.","2160-7516","978-1-7281-2506-0","10.1109/CVPRW.2019.00232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9025508","","Face;Image resolution;Gallium nitride;Feature extraction;Training;Image reconstruction;Generative adversarial networks","convolutional neural nets;face recognition;feature extraction;image representation;image resolution;learning (artificial intelligence);realistic images","face region;photo-realistic images;exemplar guided face image super-resolution;ubiquitous visual media;high-resolution face images;low-resolution face image;convolutional neural network-based solution;GWAInet;unconstrained HR face image;HR guiding image;input image;feature fusion chain;warped guiding image;truth images;high quality perceptual image;LR face image;CNN-based solution;warper subnetwork;feature extraction;identity loss;embedding vectors;HR ground truth images;SR ground truth images;photorealistic images","","24","","52","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"High-Frequency Refinement for Sharper Video Super-Resolution","V. Singh; A. Sharma; S. Devanathan; A. Mittal","Computer Vision Lab, Indian Institute of Technology-Madras; Computer Vision Lab, Indian Institute of Technology-Madras; Computer Vision Lab, Indian Institute of Technology-Madras; Computer Vision Lab, Indian Institute of Technology-Madras","2020 IEEE Winter Conference on Applications of Computer Vision (WACV)","14 May 2020","2020","","","3288","3297","A video super-resolution technique is expected to generate a `sharp' upsampled video. The sharpness in the generated video comes from the precise prediction of the high-frequency details (e.g. object edges). Thus high-frequency prediction becomes a vital sub-problem of the super-resolution task. To generate a sharp-upsampled video, this paper proposes an upsampling network architecture `HFR-Net' that works on the principle of `explicit refinement and fusion of high-frequency details'. To implement this principle and to train HFR-Net, a novel technique named 2-phase progressive-retrogressive training is being proposed. Additionally, a method called dual motion warping is also being introduced to preprocess the videos that have varying motion intensities (slow and fast). Results on multiple video datasets demonstrate the improved performance of our approach over the current state-of-the-art.","2642-9381","978-1-7281-6553-0","10.1109/WACV45572.2020.9093572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093572","","Spatial resolution;Training;Signal resolution;Feature extraction;Task analysis;Computer vision;Generative adversarial networks","image motion analysis;image resolution;learning (artificial intelligence);neural net architecture;video signal processing","high-frequency refinement;video super resolution;upsampling network architecture;2-phase progressive-retrogressive training;video sharpness;HFR-Net training;dual motion warping;video preprocessing;video motion intensities","","1","","29","IEEE","14 May 2020","","","IEEE","IEEE Conferences"
"Unsupervised Real-World Super-Resolution: A Domain Adaptation Perspective","W. Wang; H. Zhang; Z. Yuan; C. Wang",ByteDance AI Lab; UC San Diego; ByteDance AI Lab; ByteDance AI Lab,"2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","4298","4307","Most existing convolution neural network (CNN) based super-resolution (SR) methods generate their paired training dataset by artificially synthesizing low-resolution (LR) images from the high-resolution (HR) ones. However, this dataset preparation strategy harms the application of these CNNs in real-world scenarios due to the inherent domain gap between the training and testing data. A popular attempts towards the challenge is unpaired generative adversarial networks, which generate ""real"" LR counterparts from real HR images using image-to-image translation and then perform super-resolution from ""real"" LR→SR. Despite great progress, it is still difficult to synthesize perfect ""real"" LR images for super-resolution. In this paper, we firstly consider the real-world SR problem from the traditional domain adaptation perspective. We propose a novel unpaired SR training framework based on feature distribution alignment, with which we can obtain degradation-indistinguishable feature maps and then map them to HR images. In order to generate better SR images for target LR domain, we introduce several regularization losses to force the aligned feature to locate around the target domain. Our experiments indicate that our SR network obtains the state-of-the-art performance over both blind and unpaired SR methods on diverse datasets.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.00428","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711325","Low-level and physics-based vision","Training;Convolution;Superresolution;Neural networks;Force;Generative adversarial networks;Decoding","","","","7","","48","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Towards Underwater Object Recognition Based on Supervised Learning","Z. Chen; T. Zhao; N. Cheng; X. Sun; X. Fu","Information Science and Technology College, Dalian Maritime University, Dalian, China; Information Science and Technology College, Dalian Maritime University, Dalian, China; Information Science and Technology College, Dalian Maritime University, Dalian, China; Information Science and Technology College, Dalian Maritime University, Dalian, China; Information Science and Technology College, Dalian Maritime University, Dalian, China","2018 OCEANS - MTS/IEEE Kobe Techno-Oceans (OTO)","6 Dec 2018","2018","","","1","4","Underwater robots play a significant role in exploring the underwater world. In recent years, underwater robots still can't recognize the underwater objects accurately. In order to find a solution to the problem of underwater robot recognition, we put forward a framework. There are three parts in our framework. First, a color correction algorithm is used to compensate color casts and produce natural color corrected images. Second, we employ Super-Resolution Generative Adversarial Network to enhance the underwater images. There are two parts in Super-Resolution Generative Adversarial Network. One is the modified generate network $G$, and the other is the discriminator network $D$. We modify the generate network $G$ on basis of ResNet. Third, we employ object recognition algorithm to process the enhanced images for detecting and recognizing the underwater object. The experimental results show that the proposed framework can achieve good results in underwater object recognition.","","978-1-5386-1654-3","10.1109/OCEANSKOBE.2018.8559050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8559050","Underwater image;Color correction;image enhancement;Generative Adversarial Network;Object recognition","Image color analysis;Image recognition;Object recognition;Generative adversarial networks;Image enhancement;Histograms","image colour analysis;learning (artificial intelligence);object recognition;robot vision","supervised learning;underwater robot recognition;natural color corrected images;underwater images;underwater object recognition;discriminator network;super-resolution generative adversarial network;ResNet basis","","1","","16","IEEE","6 Dec 2018","","","IEEE","IEEE Conferences"
"Superresolution Land Cover Mapping Using a Generative Adversarial Network","C. Shang; X. Li; G. M. Foody; Y. Du; F. Ling","University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; School of Geography, University of Nottingham, Nottingham, U.K.; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","24 Dec 2021","2022","19","","1","5","Superresolution mapping (SRM) is a commonly used method to cope with the problem of mixed pixels when predicting the spatial distribution within low-resolution pixels. Central to the popular SRM method is the spatial pattern model, which is utilized to represent the land cover spatial distribution within mixed pixels. The use of an inappropriate spatial pattern model limits such SRM analyses. Alternative approaches, such as deep-learning-based algorithms, which learn the spatial pattern from training data through a convolutional neural network, have been shown to have considerable potential. Deep learning methods, however, are limited by issues such as the way the fraction images are utilized. Here, a novel SRM model based on a generative adversarial network (GAN), GAN-SRM, is proposed that uses an end-to-end network to address the main limitations of existing SRM methods. The potential of the proposed GAN-SRM model was assessed using four land cover subsets and compared to hard classification and several popular SRM methods. The experimental results show that of the set of methods explored, the GAN-SRM model was able to generate the most accurate high-resolution land cover maps.","1558-0571","","10.1109/LGRS.2020.3020395","Innovation Group Project of Hubei Natural Science Foundation(grant numbers:2019CFA019); Hubei Province Natural Science Fund for Distinguished Young Scholars(grant numbers:2018CFA062); Natural Science Foundation of China(grant numbers:61671425); Youth Innovation Promotion Association CAS(grant numbers:2017384); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195742","Deep learning;generative adversarial network (GAN);super-resolution mapping (SRM)","Generative adversarial networks;Training data;Layout;Spatial resolution;Training;Gallium nitride","","","","4","","26","IEEE","14 Sep 2020","","","IEEE","IEEE Journals"
"High Quality Training Set Collection using Generative Adversarial Network","S. S. Jang; K. H. Hwang; Y. G. Ha","Computer Science & Engineering, Konkuk University, Seoul, South Korea; Computer Science & Engineering, Konkuk University, Seoul, South Korea; Computer Science & Engineering, Konkuk University, Seoul, South Korea","2020 IEEE International Conference on Big Data and Smart Computing (BigComp)","20 Apr 2020","2020","","","455","458","Image classification and object detection using deep learning have evolved with continuous research. In particular, the development of big data and the improvement of computer hardware performance have contributed extremely to the development of deep learning. Deep learning technologies like Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) can train models through training data. In other words, the optimal value of the weight parameter is automatically obtained from the training data. In this way, training data is the most important in deep learning. The quality and amount of training data affects the learning performance of deep learning models. In order to obtain high quality training data, it is difficult for the user to collect it directly. And using a web crawler to collect images for search keywords is also in problem. The images collected by the crawler include many low-resolution images and irrelevant images. These image data are bad for training deep learning model. Therefore, this paper purposes to collect high quality learning data by automatically applying SRGAN to low resolution images after image collection through image crawler and converting high quality images.","2375-9356","978-1-7281-6034-4","10.1109/BigComp48618.2020.00-27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070346","Low resolution, Super-resolution, Training Data Set, ESRGAN, Crawler","Image resolution;Machine learning;Training data;Training;Crawlers;Data models;Generative adversarial networks","convolutional neural nets;image classification;image resolution;image retrieval;Internet;learning (artificial intelligence);object detection;recurrent neural nets","big data;deep learning technologies;Convolutional Neural Network;Recurrent Neural Network;learning performance;deep learning model;high quality training data;low-resolution images;image data;high quality learning data;low resolution images;image collection;image crawler;high quality images;high quality training set collection;generative adversarial network;object detection;SRGAN;Web crawler;image classification","","","","11","IEEE","20 Apr 2020","","","IEEE","IEEE Conferences"
"Deep Group-Wise Angular Translation of Cardiac Diffusion MRI in q-space via Manifold Regularized GAN","Y. He; L. Wang; F. Yang; P. Clarysse; Y. Zhu","Univ Lyon, INSA-Lyon, Université Claude Bernard Lyon 1, UJM-Saint Etienne, CNRS, In-serm, CREATIS UMR 5220, U1206, LYON, France; Key Laboratory of Intelligent Medical Image Analysis and Precise Diagnosis of Guizhou Province, School of Computer Science and Technology, Guizhou University, Guiyang, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; Univ Lyon, INSA-Lyon, Université Claude Bernard Lyon 1, UJM-Saint Etienne, CNRS, In-serm, CREATIS UMR 5220, U1206, LYON, France; Univ Lyon, INSA-Lyon, Université Claude Bernard Lyon 1, UJM-Saint Etienne, CNRS, In-serm, CREATIS UMR 5220, U1206, LYON, France","2020 15th IEEE International Conference on Signal Processing (ICSP)","18 Jan 2021","2020","1","","511","515","Diffusion magnetic resonance imaging (dMRI) has become an indispensable tool for non-invasive characterization of fiber structures of tissues. Clinical applicability of dMRI is often shackled by trade-off between image quality and long acquisition time. We propose a novel group-wise image translation method to improve the angular resolution of cardiac dMRI data. It consists in using a generative adversarial network (GAN) model to estimate a sequence of images from given DW images acquired in a limited number of diffusion gradient directions. We embed a supervised manifold regularized term in the GAN loss function to exploit the correlation between multiple DW images acquired in different gradient directions. Experimental results on cardiac dMRI data demonstrated that our method can significantly improve the quality of diffusion tensor imaging (DTI) reconstruction.","2164-5221","978-1-7281-4480-1","10.1109/ICSP48669.2020.9320925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320925","diffusion MRI;super-resolution;cardiac DTI;image synthesis;deep learning;spatial-angular information","Gallium nitride;Generators;Generative adversarial networks;Correlation;Manifolds;Diffusion tensor imaging;Three-dimensional displays","biodiffusion;biological tissues;biomedical MRI;cardiology;image reconstruction;image resolution;image sequences;medical image processing;neural nets;supervised learning","angular resolution;diffusion gradient directions;supervised manifold regularized term;GAN loss function;multiple DW images;diffusion tensor imaging reconstruction;deep group-wise angular translation;cardiac diffusion MRI;manifold regularized GAN;diffusion magnetic resonance imaging;noninvasive characterization;image quality;group-wise image translation;cardiac dMRI;generative adversarial network;q-space;image sequence;diffusion-weighted images;fiber structures","","","","25","IEEE","18 Jan 2021","","","IEEE","IEEE Conferences"
"Unsupervised Unpaired Super-Resolution Using an Active Sampling Strategy Based on Edge Detection","K. Long; B. Jiang; Y. Yang","State Key Laboratory for Novel Software Technology Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology Nanjing University, Nanjing, China","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","01","08","Most existing super-resolution (SR) methods rely on pairs of low resolution (LR) and high resolution (HR) images and predetermined degradation operations (e.g., bicubic), usually trained by supervised learning. However, they often fail in real-world scenarios because of the occurrence of noise and blur. The key reason is that the degradation process is unknown, and no HR-LR pairs can be obtained directly. To address the above issues, this paper explores the optimization of an unsupervised unpaired SR method inspired by generative models such as Generative Adversarial Networks (GAN) and Cycle-Consistent Adversarial Networks (CycleGAN). We propose an active sampling strategy based on edge detection, and introduce a denoising network to construct a novel unsupervised unpaired SR framework. The active sampling strategy can perform image-level feature alignment by sampling image patches actively, thus optimizing the learning direction of the generator. At the same time, the denoising network can reduce the learning difficulty of the generator by preprocessing real-world LR images. Extensive experiments indicate that our method obtains better performance over other existing solutions to the unsupervised unpaired SR challenge,","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892530","Natural Science Foundation of China(grant numbers:62176119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892530","super-resolution;unsupervised learning;adver-sarial learning;active sampling;denoising","Degradation;Measurement;Image edge detection;Noise reduction;Superresolution;Supervised learning;Neural networks","edge detection;image classification;image denoising;image resolution;image sampling;learning (artificial intelligence)","unsupervised unpaired super-resolution;active sampling strategy;edge detection;existing super-resolution methods;high resolution images;predetermined degradation operations;supervised learning;degradation process;HR-LR pairs;unsupervised unpaired SR method;generative models;denoising network;novel unsupervised unpaired SR framework;image-level feature alignment;image patches;learning direction;real-world LR images;unsupervised unpaired SR challenge","","","","42","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"MSFSR: A Multi-Stage Face Super-Resolution with Accurate Facial Representation via Enhanced Facial Boundaries","Y. Zhang; Y. Wu; L. Chen","Fujian Provincial Engineering Technology Research Center of Photoelectric Sensing Application, Key Laboratory of OptoElectronic Science and Technology for Medicine of Ministry of Education, Fujian Provincial Key Laboratory of Photonics Technology, Fujian Normal University; Fujian Provincial Engineering Technology Research Center of Photoelectric Sensing Application, Key Laboratory of OptoElectronic Science and Technology for Medicine of Ministry of Education, Fujian Provincial Key Laboratory of Photonics Technology, Fujian Normal University; Fujian Provincial Engineering Technology Research Center of Photoelectric Sensing Application, Key Laboratory of OptoElectronic Science and Technology for Medicine of Ministry of Education, Fujian Provincial Key Laboratory of Photonics Technology, Fujian Normal University","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","2120","2129","The majority of Face Super-Resolution (FSR) approaches apply specific facial priors as guidance in super-resolving the given low-resolution (LR) into high-resolution (HR) images. To improve the FSR performance, various kinds of facial representations were explored in the past decades. Nevertheless, there remains a challenge in estimating high-quality facial representations for LR images. To address this problem, we propose novel facial representation - enhanced facial boundaries. By semantically connecting the facial landmark points, enhanced facial boundaries retain rich semantic information and are robust to different spatial resolution scales. Based on the enhanced facial boundaries, we design a novel Multi-Stage FSR (MS-FSR) approach, which applies the multi-stage strategy to recover high-quality face images progressively. The enhanced facial boundaries and the coarse-to-fine supervision facilitate the facial boundaries estimation process in producing high quality facial representation. The one-time projection of the FSR task is decomposed into multiple simpler sub-processes. In these ways, the MSFSR estimates a more robust facial representation and achieves better performance. Experimental results indicate the superiority of our approach to the state-of-the-art approaches in both qualitative and quantitative measurements.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150789","","Face;Spatial resolution;Task analysis;Image reconstruction;Semantics;Generative adversarial networks","face recognition;image representation;image resolution","multistage face super-resolution;accurate facial representation;enhanced facial boundaries;specific facial priors;high-resolution images;high-quality facial representations;facial landmark points;novel MultiStage FSR approach;high-quality face images;facial boundaries estimation process;high quality facial representation;robust facial representation","","7","","36","IEEE","28 Jul 2020","","","IEEE","IEEE Conferences"
"Facial Image Super Resolution on 3 Architectures of Generative Adversarial Network","M. A. N. Kemas; A. S. H. P.; Y. Widhiyasana; N. Syakrani","Student of DIV Informatics Engineering, Politeknik Negeri Bandung, Bandung, Indonesia; Student of DIV Informatics Engineering, Politeknik Negeri Bandung, Bandung, Indonesia; Informatics Engineering, Politeknik Negeri Bandung, Bandung, Indonesia; Informatics Engineering, Politeknik Negeri Bandung, Bandung, Indonesia","2020 International Conference on ICT for Smart Society (ICISS)","4 Jan 2021","2020","","","1","8","Facial images are widely used for biometric recognition such as facial recognition, analysis or reconstruction. Consequently, it is necessary to increase the resolution of facial images from low resolution to high resolution or super resolution. Generative Adversarial Network (GAN) is a machine-learning-based method that can be used to increase image resolution. GAN is composed of two CNN, namely Generator and Discriminator. This research focuses on examining the effect of Generator configuration, specifically the number of feature extractor blocks named basic blocks and filters on Generator, which are built based on three different architectures, which are Inception, Resnet, and Inception-Resnet. Our finding shows that Resnet with 128 number of filter and 32 number of basic blocks gives the best result.","2640-0545","978-1-6654-0422-8","10.1109/ICISS50791.2020.9307573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9307573","Quality of facial image enhancement;Generative Adversarial Network;Inception;Resnet;Inception-Resnet;Number of Basic Blocks;Number of Filters","Image resolution;Generators;Convolution;Training;Generative adversarial networks;Gallium nitride;Face recognition","biometrics (access control);face recognition;feature extraction;image reconstruction;image resolution;learning (artificial intelligence);neural nets","facial image super resolution;biometric recognition;GAN;machine-learning-based method;generative adversarial network;feature extractor blocks;Inception-Resnet","","","","18","IEEE","4 Jan 2021","","","IEEE","IEEE Conferences"
"A Generative Adversarial Network for AI-Aided Chair Design","Z. Liu; F. Gao; Y. Wang","National Engineering Lab for Video Technology, Peking University, Beijing, China; The Future Lab, Tsinghua University, Beijing, China; National Engineering Lab for Video Technology, Peking University, Beijing, China","2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)","25 Apr 2019","2019","","","486","490","We present a method for improving human design of chairs. The goal of the method is generating enormous chair candidates in order to facilitate human designer by creating sketches and 3d models accordingly based on the generated chair design. It consists of an image synthesis module, which learns the underlying distribution of training dataset, a super-resolution module, which improve quality of generated image and human involvements. Finally, we manually pick one of the generated candidates to create a real life chair for illustration.","","978-1-7281-1198-8","10.1109/MIPR.2019.00098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695313","deep learning;GAN;AI-aided Design","Image resolution;Image generation;Prototypes;Training;Generative adversarial networks;Shape;Generators","furniture;image resolution;learning (artificial intelligence);solid modelling;stereo image processing","generated chair design;image synthesis module;super-resolution module;generated image;generated candidates;life chair;generative adversarial network;AI-aided chair design;human designer;chair candidates","","3","","26","IEEE","25 Apr 2019","","","IEEE","IEEE Conferences"
"Enhancing resolution in coherent microscopy using deep learning","T. Liu; K. de Haan; Y. Rivenson; Z. Wei; X. Zeng; Y. Zhang; A. Ozcan","California NanoSystems Institute (CNSI), University of California, Los Angeles, CA, USA; California NanoSystems Institute (CNSI), University of California, Los Angeles, CA, USA; California NanoSystems Institute (CNSI), University of California, Los Angeles, CA, USA; Electrical and Computer Engineering Department, University of California, Los Angeles, CA, USA; Electrical and Computer Engineering Department, University of California, Los Angeles, CA, USA; California NanoSystems Institute (CNSI), University of California, Los Angeles, CA, USA; Department of Surgery, University of California, Los Angeles, CA, USA","2019 Conference on Lasers and Electro-Optics (CLEO)","1 Jul 2019","2019","","","1","2","A generative adversarial network (GAN) based super-resolution framework is presented. This deep learning-based framework is capable of enhancing the resolution of coherent imaging systems in both pixel size-limited and diffraction-limited microscopy systems.","2160-8989","978-1-943580-57-6","10.1364/CLEO_AT.2019.AM2I.6","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8749690","","Spatial resolution;Microscopy;Lung;Deep learning;Generative adversarial networks","biological techniques;biology computing;image resolution;learning (artificial intelligence);optical microscopy","coherent imaging systems;diffraction-limited microscopy systems;coherent microscopy;generative adversarial network;super-resolution framework;deep learning-based framework","","","","6","","1 Jul 2019","","","IEEE","IEEE Conferences"
"Maximum a Posteriori on a Submanifold: a General Image Restoration Method with GAN","F. Luo; X. Wu","Dept. of Elec & Comp Engineering, McMaster University, Hamilton, Canada; Dept. of Elec & Comp Engineering, McMaster University, Hamilton, Canada","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","7","We propose a general method for various image restoration problems, such as denoising, deblurring, super-resolution and inpainting. The problem is formulated as a constrained optimization problem. Its objective is to maximize a posteriori probability of latent variables, and its constraint is that the image generated by these latent variables must be the same as the degraded image. We use a Generative Adversarial Network (GAN) as our density estimation model. Convincing results are obtained on MNIST dataset.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207162","image restoration;deep learning;optimization","Image restoration;Gallium nitride;Estimation;Degradation;Generators;Generative adversarial networks;Optimization","image resolution;image restoration;neural nets;optimisation;probability","posteriori probability;latent variables;degraded image;GAN;submanifold;general image restoration method;image restoration problems;super-resolution;inpainting;constrained optimization problem;generative adversarial network;MNIST dataset","","","","25","IEEE","28 Sep 2020","","","IEEE","IEEE Conferences"
"Image Classification and Generation Based on GAN Model","H. Meng; F. Guo","School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; Faculty of Science, University of Calgary, Calgary, Canada","2021 3rd International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)","17 Mar 2022","2021","","","180","183","The topic of image processing is becoming more and more popular in the field of artificial intelligence, and it can be applied to fields of biology, medicine, video games, art, and etc. In order to have a deeper understanding of how to optimize the image processing, this paper mainly proposed the Generative Adversarial Network (GAN), which is an emerging deep learning model with the ability to continuously improve modeling under the game, and there are already many applications related to image processing, such as video prediction, 3-dimensional object generation, image super-resolution and etc. In this paper, we mainly implement image generation and image classification based on GAN model. In order to indicate the performance of GAN model in image generation in detail, GAN models with linear layers and with convolution layers are trained and compared based on MNIST datasets. Furthermore, we train GAN model with linear layers, and GAN model with convolution layers, Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), and Residual Network (ResNet) models in image classification based on the Mixed National Institute of Standards and Technology database (MNIST), and receive the training loss and testing accuracy of these models for different epochs in image classification. The experimental results demonstrated that GAN model with convolution layers performs best in both image generation and image classification.","","978-1-6654-1790-7","10.1109/MLBDBI54094.2021.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9731058","Image generation;GAN model;Image classification;Experimental analysis","Training;Convolution;Image synthesis;Games;Predictive models;Generative adversarial networks;Data models","feature extraction;image classification;image resolution;learning (artificial intelligence);multilayer perceptrons;neural nets","image classification;GAN model;image processing;emerging deep learning model;image super-resolution;image generation;convolution layers;Residual Network models","","","","13","IEEE","17 Mar 2022","","","IEEE","IEEE Conferences"
"Pix2Pix GAN Image Synthesis To Detect Electric Vehicle License Plate","A. Kalpana.; A. John","Central Research Laboratory Bharat Electronics Limited, Bengaluru, India; Central Research Laboratory Bharat Electronics Limited, Bengaluru, India","2022 IEEE 4th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA)","22 Dec 2022","2022","","","439","443","The area of image processing is more intensive in development and research activities for decades. The role of image processing is huge in modeling, analytics, communication, computation, information security, information forensics and smart city application. Images are ubiquitous in day to day life and images or videos play dominant role in monitoring applications. But when it comes to development of specific application, collection of data is a very challenging task. Nowadays deep learning plays a significant role for generation of data. Robust technologies like Generative Adversarial Network (GAN) and Cycle GAN play a crucial role for generating realistic images with super resolution. GAN and its associated methods used for image synthesis improve the accuracy of deep learning models. In this paper, we analyze challenges of license plate recognition in realistic situation and experiments demonstrate that GAN can generate realistic images to improve the accuracy of license plate recognition.","","978-1-6654-6246-4","10.1109/ICCCMLA56841.2022.9989063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9989063","Generative Adversarial Network;Image synthesis;Generator;License Plate Recognition;Deep Learning","Deep learning;Image synthesis;Smart cities;Information security;Generative adversarial networks;Electric vehicles;Task analysis","deep learning (artificial intelligence);electric vehicles;gallium compounds;image recognition;image resolution;realistic images;traffic engineering computing","Cycle GAN;deep learning models;electric vehicle license plate;generative adversarial network;image processing;information forensics;information security;license plate recognition;monitoring applications;pix2pix GAN image synthesis;realistic images;smart city application;super resolution","","","","21","IEEE","22 Dec 2022","","","IEEE","IEEE Conferences"
"License Plate Detection and Recognition System for All Types of Bangladeshi Vehicles Using Multi-step Deep Learning Model","H. H. Shomee; A. Sams","Department of Computer Science and Engineering, Brac University, Dhaka, Bangladesh; Department of Electrical and Electronic Engineering, Bangladesh University of Engineering and Technology, Bangladesh","2021 Digital Image Computing: Techniques and Applications (DICTA)","23 Dec 2021","2021","","","01","07","A robust license plate (LP) detection and recognition system can extract the license plate information from a still image or video of a moving or stationary vehicle. Bangla license plate recognition is a complicated subject of study due to no publicly available dataset and its specific characteristics with over 100 unique classes, including words, letters, and digits. This paper proposes a robust multi-step deep learning system based on You Only Look Once (YOLO) architecture that can extract license plate information from a real-world image. The resulting system localizes license plates using YOLOv4 object detector model, automatically crops the license plates using bounding box coordinates, enhances the extracted license plate image quality using Enhanced Super Resolution Generative Adversarial Networks (ESRGAN), and then recognizes the classes using YOLOv4 without segmenting the characters. Synthetic images have been used to make proposed method capable of recognizing the classes in unfavorable and complicated conditions. A complete two-part dataset named ‘Bangla LPDB-A’ is created in this study. This dataset includes Bangladeshi vehicle images with manually annotated license plates and cropped license plates with manually annotated words, letters, and digits. The proposed system is tested on this dataset that has achieved mean average precision (mAP) of 98.35% and 98.09% for final detection and recognition model, which has an average prediction time of 23 ms and 35 ms.","","978-1-6654-1709-9","10.1109/DICTA52665.2021.9647284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9647284","Bangla license plate;Deep learning;Generative adversarial networks;Image processing;Object detection;YOLO","Deep learning;Image quality;Image segmentation;Image recognition;Image resolution;Computational modeling;License plate recognition","deep learning (artificial intelligence);feature extraction;image annotation;image recognition;image resolution;image segmentation;object detection;object recognition;traffic engineering computing;video signal processing","bounding box coordinates;YOLO architecture;You Only Look Once architecture;mAP;mean average precision;ESRGAN;two-part dataset;Bangla LPDB-A;publicly available dataset;Bangla license plate recognition;stationary vehicle;moving vehicle;robust license plate detection;recognition system;recognition model;cropped license plates;manually annotated license plates;Bangladeshi vehicle images;synthetic images;Enhanced Super Resolution Generative Adversarial Networks;extracted license plate image quality;YOLOv4 object detector model;real-world image;license plate information;robust multistep deep learning system;time 35.0 ms;time 23 ms","","2","","19","IEEE","23 Dec 2021","","","IEEE","IEEE Conferences"
"SRInpaintor: When Super-Resolution Meets Transformer for Image Inpainting","F. Li; A. Li; J. Qin; H. Bai; W. Lin; R. Cong; Y. Zhao","Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; School of Computer Science and Engineering, Nanyang Technological University 50 Nanyang Avenue, Singapore; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China","IEEE Transactions on Computational Imaging","2 Sep 2022","2022","8","","743","758","Recent image inpainting methods have achieved remarkable improvements by using generative adversarial networks (GAN). Most of them have been designed to produce plausible results from high-level semantic features using only high-resolution (HR) supervision. However, because abundant details are lost in large holes, it is difficult to simultaneously synthesize details while preserving structural coherence in HR space. Besides, the correlations between the inside and outside of the missing region play a critical role in transferring relevant known information to generate semantic-coherent textures, especially in patch matching-based methods. In this work, we present SRInpaintor which inherits the merits of super-resolution (SR) and transformer for high-fidelity image inpainting. The SRInpaintor starts from global structure reasoning with low-resolution (LR) input and progressively refines the local textures in HR space, constituting a multi-stage framework with SR supervision. The bottom stage recovers coarse SR results that provide structural information as an appearance prior, and is combined with the higher-resolution corrupted image at the next stage to render available textures for the missing region. Such a design can analyse the image from LR to HR with the increase of stages, enabling coarse-to-fine information propagation and detail refinement. In addition, we propose a hierarchical transformer (HieFormer) to model the long-term correlations between distant contexts and holes. By embedding it into a compact latent space in a cross-scale manner, we can ensure reliable relevant texture transformation and robust appearance consistency. Experimental results demonstrate the superiority of our method compared with recent state-of-the-art methods. Code will be available on https://github.com/lifengshiwo/SRInpaintor.","2333-9403","","10.1109/TCI.2022.3190142","National Key R&D Program of China(grant numbers:2022YFE0200300); National Natural Science Foundation of China(grant numbers:61972023,62120106009,62002014); Fundamental Research Funds for the Central Universities(grant numbers:2019JBZ102); Beijing Nova Program(grant numbers:Z201100006820016); China Scholarship Council(grant numbers:202007090046); Beijing Natural Science Foundation(grant numbers:4222013); Singapore Ministry of Education Tier-2 Fund(grant numbers:MOE2016-T2-2-057(S)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9827481","Generative image inpainting;progressive super-resolution;transformer","Transformers;Image reconstruction;Task analysis;Superresolution;Image edge detection;Correlation;Semantics","feature extraction;image matching;image resolution;image restoration;neural nets","image inpainting methods;generative adversarial networks;GAN;high-level semantic features;high-resolution supervision;HR space;semantic-coherent textures;patch matching-based methods;high-fidelity image inpainting;global structure reasoning;low-resolution input;local textures;multistage framework;SR supervision;structural information;coarse-to-fine information propagation;hierarchical transformer;long-term correlations;compact latent space","","","","76","IEEE","12 Jul 2022","","","IEEE","IEEE Journals"
"A Fully Progressive Approach to Single-Image Super-Resolution","Y. Wang; F. Perazzi; B. McWilliams; A. Sorkine-Hornung; O. Sorkine-Hornung; C. Schroers",ETH Zurich; Disney Research; NA; Oculus; ETH Zurich; Disney Research,"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","16 Dec 2018","2018","","","977","97709","Recent deep learning approaches to single image superresolution have achieved impressive results in terms of traditional error measures and perceptual quality. However, in each case it remains challenging to achieve high quality results for large upsampling factors. To this end, we propose a method (ProSR) that is progressive both in architecture and training: the network upsamples an image in intermediate steps, while the learning process is organized from easy to hard, as is done in curriculum learning. To obtain more photorealistic results, we design a generative adversarial network (GAN), named ProGanSR, that follows the same progressive multi-scale design principle. This not only allows to scale well to high upsampling factors (e.g., 8×) but constitutes a principled multi-scale approach that increases the reconstruction quality for all upsampling factors simultaneously. In particular ProSR ranks 2nd in terms of SSIM and 4th in terms of PSNR in the NTIRE2018 SISR challenge [35]. Compared to the top-ranking team, our model is marginally lower, but runs 5 times faster.","2160-7516","978-1-5386-6100-0","10.1109/CVPRW.2018.00131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8575284","","Training;Gallium nitride;Image resolution;Image reconstruction;Generative adversarial networks;Computer architecture;Generators","image reconstruction;image resolution;image sampling;learning (artificial intelligence)","single-image super-resolution;perceptual quality;learning process;generative adversarial network;progressive multiscale design principle;principled multiscale approach;reconstruction quality;NTIRE2018 SISR challenge;deep learning;upsampling factors;ProSR method;ProGanSR","","132","","41","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"Optimizing Image Compression With Deep Super-Resolution Techniques","S. Hamis; T. Zaharia; O. Rousseau",Télécom SudParis; Télécom SudParis; Be-Bound,"IEEE Consumer Electronics Magazine","4 Aug 2020","2020","9","5","91","101","Efficient image/video storage and transmission on mobile devices is becoming today an important challenge, since smartphones have become the most popular image acquisition devices, progressively replacing traditional cameras. However, most of the time, the acquired pictures are displayed on small screens and for a limited time. In order to manage this kind of oversized (with respect to the usage) data, it is mandatory to employ dedicated compression techniques. The solution considered in this article consists of storing solely low resolution versions of the images that can be efficiently compressed with standardized solutions. The challenge is then to restore high quality, full resolution images, while dealing with the complex artifacts that are inherently introduced by modern codecs. In this article, we introduce a two-stage approach, which consists of applying a deep superresolution technique upon images compressed with state-of-the-art codecs. The experimental results obtained demonstrate that the proposed method outperforms, in terms of perceptual quality, existing compression standards, in particular at very low bitrates.","2162-2256","","10.1109/MCE.2020.2986994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9090900","","Image coding;Transform coding;Image reconstruction;Generative adversarial networks;Standards;Bit rate;Image resolution","cameras;codecs;data compression;image coding;image resolution","compression standards;deep superresolution technique;resolution images;acquired pictures;image acquisition devices;smartphones;mobile devices;super-resolution techniques;image compression","","","","18","IEEE","11 May 2020","","","IEEE","IEEE Magazines"
"An Efficient Object Detection and Classification from Restored Thermal Images based on Mask RCNN","E. Thenmozhi; A. Karunakaran; J. R. Arunkumar; V. Chinnammal; C. Kalaivanan; G. Anitha","Department of Information Technology, Panimalar Engineering College, Chennai; Department of Electronics and Communication Engineering, S.A Engineering College, Chennai; Department of Computer Science and Engineering, Modern Institute of Technology and Research Centre, Alwar, Rajasthan; Department of Electronics and Communication Engineering, Rajalakshmi Instittue of Technology, Chennai; Department of Electrical and Electronics Engineering, Sona College of Technology, Salem; Department of Electronics and Communication Engineering, Saveetha School of Engineering, SIMATS, Chennai","2022 Sixth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)","22 Dec 2022","2022","","","639","645","In recent years, thermal cameras are extensively employed in several industries, including biometrics, intelligent surveillance, and health monitoring. The thermal cameras’ exorbitant price, meanwhile, makes them difficult to obtain. Furthermore, blurring brought on by camera movement, object movement, and focus settings is a problem with thermal photos. There haven’t been many research on thermal image-centered picture restoration that focus on such issues. Additionally, it is critical to accelerate the processing capability of image treatment technologies in order to work in tandem with techniques like object tracking and activity detection that make use of temporal data from thermal recordings. Furthermore, no research has been done on the use of thermal pictures for super-resolution rebuilding and deblurring. Due to the inability to discern reflected on the soil surface or wall caused by the heat emitted by the item, previous research on object recognition using thermal imaging include inaccuracies. This paper suggests a deep learning-based technique for thermal image reconstruction that combines deblurring and super-resolution reconstruction in one step. Recent advances in deep learning have shown that approaches based on generative adversarial networks (GANs) perform well in image-to-image translation challenges because they can maintain texture features in pictures and produce finer, more convincing textures than traditional feed forward encoders. This research study suggests a deblur-SRRGAN for thermal image restoration in light of the benefits of GAN. Additionally, a MR-CNN is also recommended to perform object recognition in the thermal image reconstruction.","2768-0673","978-1-6654-6941-8","10.1109/I-SMAC55078.2022.9987422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9987422","Thermal images;deep learning;Image deblurring;subject and thermal reflection detection","Surface reconstruction;Surveillance;Superresolution;Soil;Generative adversarial networks;Cameras;Thermal analysis","convolutional neural nets;deep learning (artificial intelligence);image classification;image resolution;image restoration;image texture;infrared imaging;object detection;object recognition","activity detection;camera movement;deep learning-based technique;focus settings;image treatment technologies;image-to-image translation challenges;object recognition;object tracking;restored thermal images;super-resolution rebuilding;super-resolution reconstruction;thermal cameras;thermal image reconstruction;thermal image restoration;thermal image-centered picture restoration;thermal imaging;thermal photos;thermal pictures;thermal recordings","","","","15","IEEE","22 Dec 2022","","","IEEE","IEEE Conferences"
"Generative Data Augmentation applied to Face Recognition","M. Jabberi; A. Wali; A. M. Alimi","REsearch Groups in Intelligent Machines (REGIM Lab), University of Sfax National Engineering School of Sfax (ENIS), Sfax, Tunisia; REsearch Groups in Intelligent Machines (REGIM Lab), University of Sfax National Engineering School of Sfax (ENIS), Sfax, Tunisia; Department of Electrical and Electronic Engineering Science, Faculty of Engineering and the Built Environment, University of Johannesburg, South Africa","2023 International Conference on Information Networking (ICOIN)","22 Feb 2023","2023","","","242","247","In this paper, we present a data augmentation method whose goal is to generate face images and maximize faces variation in the training set. The main objective is to break free from the traditional data augmentation techniques used in deep neural networks such as geometric and photometric transformations. Our method consists in generating face images using Deep Convolutional Generative Adversarial Networks (DC-GAN) feed with light pose variations of the face in 2D plane. Its a selective feature space augmentation. Then, we apply face resolution enhancement based on Enhanced Super Resolution GAN (ESRGAN), since the generated faces are inferior and noisy. As a final step, we perform face verification using Deep Convolutional Neural Networks (CNNs) to confirm the robustness of the used pipeline. The found results achieves comparable performance in comparison with the state-of-the-art methods.","1976-7684","978-1-6654-6268-6","10.1109/ICOIN56518.2023.10049052","Ministry of Higher Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10049052","Face Recognition;Data augmentation;GANs;Deep CNNs;Pose variation;High Resolution;DCGAN;ESRGAN","Training;Face recognition;Pipelines;Superresolution;Neural networks;Generative adversarial networks;Robustness","","","","","","31","IEEE","22 Feb 2023","","","IEEE","IEEE Conferences"
"Realistic Dreams: Cascaded Enhancement of GAN-generated Images with an Example in Face Morphing Attacks","N. Damer; F. Boutros; A. M. Saladié; F. Kirchbuchner; A. Kuijper","Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany; Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany; Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany; Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany; Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany","2019 IEEE 10th International Conference on Biometrics Theory, Applications and Systems (BTAS)","3 Sep 2020","2019","","","1","10","The quality of images produced by generative adversarial networks (GAN) is commonly a trade-off between the model size, its training data needs, and the generation resolution. This trad-off is clear when applying GANs to issues like generating face morphing attacks, where the latent vector used by the generator is manipulated. In this paper, we propose an image enhancement solution designed to increase the quality and resolution of GAN-generated images. The solution is designed to require limited training data and be extendable to higher resolutions. We successfully apply our solution on GAN-based face morphing attacks. Beside the face recognition vulnerability and attack detectability analysis, we prove that the images enhanced by our solution are of higher visual and quantitative quality in comparison to unprocessed attacks and attack images enhanced by state-of-the-art super-resolution approaches.","2474-9699","978-1-7281-1522-1","10.1109/BTAS46853.2019.9185994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185994","","Image resolution;Face;Gallium nitride;Generative adversarial networks;Training;Image enhancement;Generators","face recognition;gallium compounds;III-V semiconductors;image enhancement;image resolution","GAN-based face morphing attacks;face recognition vulnerability;attack detectability analysis;image enhancement solution;applying GANs;generation resolution;training data needs;generative adversarial networks;GAN-generated images;attack images;unprocessed attacks;quantitative quality;higher visual quality","","13","","39","IEEE","3 Sep 2020","","","IEEE","IEEE Conferences"
"Accelerated WGAN update strategy with loss change rate balancing","X. Ouyang; Y. Chen; G. Agam",Illinois Institute of Technology; Illinois Institute of Technology; Illinois Institute of Technology,"2021 IEEE Winter Conference on Applications of Computer Vision (WACV)","14 Jun 2021","2021","","","2545","2554","Optimizing the discriminator in Generative Adversarial Networks (GANs) to completion in the inner training loop is computationally prohibitive, and on finite datasets would result in overfitting. To address this, a common update strategy is to alternate between k optimization steps for the discriminator D and one optimization step for the generator G. This strategy is repeated in various GAN algorithms where k is selected empirically. In this paper, we show that this update strategy is not optimal in terms of accuracy and convergence speed, and propose a new update strategy for networks with Wasserstein GAN (WGAN) group related loss functions (e.g. WGAN, WGAN-GP, Deblur GAN, and Super resolution GAN). The proposed update strategy is based on a loss change ratio comparison of G and D. We demonstrate that the proposed strategy improves both convergence speed and accuracy.","2642-9381","978-1-6654-0477-8","10.1109/WACV48630.2021.00259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9423302","","Training;Computer vision;Adaptive systems;Conferences;Generative adversarial networks;Nash equilibrium;Generators","data handling;learning (artificial intelligence);neural nets;optimisation","accelerated WGAN update strategy;loss change rate balancing;generative adversarial networks;optimization step;GAN algorithms;Wasserstein GAN group related loss functions;WGAN training;data distribution","","1","","28","IEEE","14 Jun 2021","","","IEEE","IEEE Conferences"
"A Unified Neural Architecture for Instrumental Audio Tasks","S. Spratley; D. Beck; T. Cohn","School of Computing and Information Systems, The University of Melbourne, Victoria, Australia; School of Computing and Information Systems, The University of Melbourne, Victoria, Australia; School of Computing and Information Systems, The University of Melbourne, Victoria, Australia","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","461","465","Within Music Information Retrieval (MIR), prominent tasks - including pitch-tracking, source-separation, super-resolution, and synthesis - typically call for specialised methods, despite their similarities. Conditional Generative Adversarial Networks (cGANs) have been shown to be highly versatile in learning general image-to-image translations, but have not yet been adapted across MIR. In this work, we present an end-to-end supervisable architecture to perform all aforementioned audio tasks, consisting of a WaveNet synthesiser conditioned on the output of a jointly-trained cGAN spectrogram translator. In doing so, we demonstrate the potential of such flexible techniques to unify MIR tasks, promote efficient transfer learning, and converge research to the improvement of powerful, general methods. Finally, to the best of our knowledge, we present the first application of GANs to guided instrument synthesis.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682765","music information retrieval;generative adversarial network;audio modelling;synthesis","Task analysis;Spectrogram;Instruments;Computer architecture;Image resolution;Generative adversarial networks;Harmonic analysis","audio signal processing;information retrieval;learning (artificial intelligence);music;neural nets;spectral analysis","MIR tasks;guided instrument synthesis;unified neural architecture;instrumental audio tasks;source-separation;cGANs;image-to-image translations;end-to-end supervisable architecture;WaveNet synthesiser;spectrogram translator;flexible techniques;transfer learning;music information retrieval;pitch-tracking;conditional generative adversarial networks","","","","26","IEEE","17 Apr 2019","","","IEEE","IEEE Conferences"
"Multi-Step Reinforcement Learning for Single Image Super-Resolution","K. Vassilo; C. Heatwole; T. Taha; A. Mehmood","University of Dayton, Dayton, OH; University of Dayton, Dayton, OH; University of Dayton, Dayton, OH; Air Force Research Laboratory, Wright-Patterson AFB, OH","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","2160","2168","Deep Learning (DL) has become prevalent in today's image processing research due to its power and versatility. It has dominated the Single Image Super-Resolution (SISR) field with its ability to obtain High-Resolution (HR) images from their Low-Resolution (LR) counterparts, particularly using Generative Adversarial Networks (GANs). Interest in SISR comes from its potential to increase the performance of supplementary image processing tasks such as object detection, localization, and classification. This research applies a multi-agent Reinforcement Learning (RL) algorithm to SISR, creating an advanced ensemble approach for combining powerful GANs. In our implementation each agent chooses a particular action from a fixed action set comprised of results from existing GAN SISR algorithms to update its pixel values. The pixel-wise or patch-wise arrangement of agents and rewards encourages the algorithm to learn a strategy to increase the resolution of an image by choosing the best pixel values from each option.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150927","","Gallium nitride;Image resolution;Image color analysis;Task analysis;Image restoration;Standards;Image reconstruction","image resolution;learning (artificial intelligence);multi-agent systems;object detection","multistep reinforcement learning;image processing research;generative adversarial networks;supplementary image processing tasks;multiagent reinforcement learning algorithm;GAN SISR algorithms;pixel-wise patch-wise arrangement;single image super-resolution field","","2","","25","IEEE","28 Jul 2020","","","IEEE","IEEE Conferences"
"Iris Recognition for Biometrics Based on CNN with Super-resolution GAN","K. Kashihara","College of Information Science and Engineering (CISE), Ritsumeikan University, Kusatsu, Shiga, Japan","2020 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS)","23 Jun 2020","2020","","","1","6","Biometric technologies can realize high-security systems. Although camera performance and photographic environment cause a low signal-to-noise ratio, super-resolution (SR) techniques, such as generative adversarial networks (SRGANs) and deep convolutional neural networks (DCNNs), can improve image quality. This study aimed to investigate the effect of the SRGANs on individual identification by DCNNs, assuming external image noise and a prefiltering process in actual cases of iris recognition. After downgraded iris images were improved by the SRGANs, a DCNN classifier predicted the individuals from the restored images. The accuracies of the DCNN classifier were higher in the SR images using the Bicubic method or squared mean errors than the SRGANs focusing on perceptual loss. This result suggests that it may be easier for the DCNN classifier to create image features based on the pixel-based differences (i.e., high peak signal-to-noise ratio), rather than on the perceptual image differences. In the future, a robust security system based on SR methods may be capable of assessing a health condition using the images obtained for individual certification.","2473-4691","978-1-7281-4384-2","10.1109/EAIS48028.2020.9122757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9122757","biometrics;iris recognition;neural networks;image analysis;deep learning","","biometrics (access control);cameras;convolutional neural nets;feature extraction;image classification;image filtering;image resolution;iris recognition","iris recognition;biometric technologies;high-security systems;camera performance;photographic environment;low signal-to-noise ratio;super-resolution techniques;generative adversarial networks;SRGANs;deep convolutional neural networks;image quality;external image noise;prefiltering process;downgraded iris images;DCNN classifier;SR images;image features;pixel-based differences;perceptual image differences;robust security system;SR methods;image restoration;bicubic method;squared mean errors;perceptual loss","","2","","16","IEEE","23 Jun 2020","","","IEEE","IEEE Conferences"
"Enhancing Low Quality in Radiograph Datasets Using Wavelet Transform Convolutional Neural Network and Generative Adversarial Network for COVID-19 Identification","G. U. Nneji; J. Cai; D. Jianhua; H. N. Monday; I. A. Chikwendu; A. Oluwasanmi; E. C. James; G. T. Mgbejime","School of Information and Software Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Sichuan, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Sichuan, China","2021 4th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)","4 Oct 2021","2021","","","146","151","The coronavirus disease of 2019 (COVID-19) pandemic has caused a global public health epidemic since there is no 100% vaccine to cure or prevent the further spread of the virus. With the ever-increasing number of new infections, creating automated methods for COVID-19 identification of Chest X-ray images is critical to aiding clinical diagnosis and reducing the time-consumption for image interpretation. This paper proposes a novel joint framework for accurate COVID-19 identification by integrating an enhanced super-resolution generative adversarial network with a noise reduction filter bank of wavelet transform convolutional neural network on both Chest X-ray and Chest Tomography images for COVID-19 identification. The super-resolution utilized in this study is to enhance the image quality while the wavelet transform Convolutional Neural Network architecture is used to accurately identify COVID-19. Our proposed architecture is very robust to noise and vanishing gradient problem. We used public domain datasets of Chest x-ray images and Chest Tomography to train and check the performance of our COVID-19 identification task. This experiment shows that our system is consistently efficient by accuracy of 0.988, sensitivity of 0.994, and specificity of 0.987, AUC of 0.99, F1-score of 0.982 and 0.989 for precision using the Chest X-ray dataset while for Chest Tomography dataset, an accuracy of 0.978, sensitivity of 0.981, and specificity of 0.979, AUC of 0.985, F1-score of 0.961 and precision of 0.980. These performances have also outweighed other established state-of-the-art learning methods.","","978-1-6654-1322-0","10.1109/PRAI53619.2021.9551043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551043","chest tomography;chest x-ray;COVID-19;deep learning;identification;super-resolution;wavelet transform","COVID-19;Wavelet transforms;Training;Sensitivity;Superresolution;Tomography;Generative adversarial networks","convolutional neural nets;diagnostic radiography;diseases;epidemics;image denoising;image enhancement;image filtering;image resolution;learning (artificial intelligence);medical image processing;wavelet transforms","chest X-ray dataset;global public health epidemic;chest X-ray images;COVID-19 identification;image quality enhancement;radiograph datasets;super-resolution generative adversarial network enhancement;chest tomography images;wavelet transform convolutional neural network;coronavirus disease;low quality enhancement;image interpretation;clinical diagnosis;noise reduction filter bank","","8","","17","IEEE","4 Oct 2021","","","IEEE","IEEE Conferences"
"Agriculture Land Appraisal with Use of Remote Sensing and Infrastructure Data","N. Kussul; A. Shelestov; H. Yailymova; L. Shumilo; S. Drozd","Space Research Institute NASU-SSAU, Kyiv, Ukraine; Space Research Institute NASU-SSAU, Kyiv, Ukraine; Space Research Institute NASU-SSAU, Kyiv, Ukraine; Department of Geographical Sciences, University of Maryland, College Park, MD, USA; National Technical University of Ukraine “Igor Sikorsky Kiev Polytechnic Institute”, Kyiv, Ukraine","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","2785","2788","1st July 2021 the law on the creation of land market start effect in Ukraine. As a result, land appraisal became cornerstone task in Ukrainian agriculture sector. The official methodology on land appraisal includes use of soil fertility characteristics combined with coefficients related to the distance to the infrastructure objects or settlements and placing of field in specific functional areas, like recreational, or areas with high level of radiation pollution. In this study we collected open source infostructure geospatial information and characteristics of fields obtained from remote sensing data - crop types and Normalized Difference Vegetation Index to build land price predictive model trained on the official land market information. This work designed to investigate potential of geo-informational technologies and remote sensing in the land appraisal use. We separated all available ground truth land price data into three groups by fields size - very small, small, medium and big. We found different relationships between field characteristics and prices. For very small fields the most important features are area, altitude, slope, bonitet and distances to elevators, villages and roads. For small fields the most important are bonitet, altitude, area and distances to cities and roads. For medium and big field's area, slope, distance to cities, roads and historical NDVI.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884045","deep learning;Generative Adversarial Networks;GAN;super-resolution;Sentinel-2","Pollution;Roads;Urban areas;Vegetation mapping;Soil;Predictive models;Agriculture","agriculture;crops;geographic information systems;land use planning;pricing;remote sensing;soil;vegetation;vegetation mapping","cornerstone task;Ukrainian agriculture sector;official methodology;soil fertility characteristics;infrastructure objects;settlements;specific functional areas;open source infostructure geospatial information;remote sensing data - crop types;Normalized Difference Vegetation Index;land price predictive model;official land market information;geo-informational technologies;land appraisal use;available ground truth land price data;fields size;field characteristics;bonitet;big field;agriculture land appraisal;infrastructure data;st July;land market start effect","","","","15","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"SR-ITM-GAN: Learning 4K UHD HDR With a Generative Adversarial Network","H. Zeng; X. Zhang; Z. Yu; Y. Wang","Department of Electronic Engineering, College of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Electronic Engineering, College of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Electronic Engineering, College of Information Science and Engineering, Ocean University of China, Qingdao, China; School of Life Science and Technology, Xidian University, Xi’an, China","IEEE Access","13 Oct 2020","2020","8","","182815","182827","Currently, high dynamic range (HDR) videos with high resolution (HR) have become popular due to the display and the rendered technological advancements. However, making ultra-high definition (UHD) with HDR videos is expensive. The legacy low-resolution (LR) standard dynamic range (SDR) format is still largely used in practice. It is necessary to search for a solution to transform LR SDR videos into UHD HDR format. In this paper, we consider joint super resolution and learning inverse tone mapping an issue of high-frequency reconstruction and local contrast enhancement, and we propose an architecture based on a generative adversarial network to apply joint SR-ITM learning. Specifically, we include the residual ResNeXt block (RRXB) as a basic module to better capture high-frequency textures and adopt YUV interpolation to achieve local contrast enhancement. By adopting a generative adversarial network as a pivotal training mechanism, our designs show advantages in both integration and performance. Our code is now available on GitHub: SR-ITM-GAN.","2169-3536","","10.1109/ACCESS.2020.3028584","National Natural Science Foundation of China(grant numbers:61701463); Key Technology Research and Development Program of Shandong (Public welfare)(grant numbers:2019GHY112041); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2019JQ-138); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212411","Super resolution;inverse tone mapping;generative adversarial network;high dynamic range","Generative adversarial networks;Videos;Task analysis;UHDTV;Image reconstruction;Image resolution;Computer architecture","data compression;image colour analysis;image enhancement;image reconstruction;image resolution;interpolation;learning (artificial intelligence);rendering (computer graphics);video signal processing","high-frequency reconstruction;local contrast enhancement;generative adversarial network;joint SR-ITM learning;capture high-frequency textures;SR-ITM-GAN;high dynamic range videos;rendered technological advancements;ultra-high definition;HDR videos;legacy low-resolution standard dynamic range format;LR SDR videos;UHD HDR format;joint super resolution;learning inverse tone mapping","","5","","68","CCBYNCND","5 Oct 2020","","","IEEE","IEEE Journals"
"Rethinking CNN-Based Pansharpening: Guided Colorization of Panchromatic Images via GANs","F. Ozcelik; U. Alganci; E. Sertel; G. Unal","Artificial Intelligence and Data Science Research and Application Center, Istanbul Technical University (ITU), Istanbul, Turkey; Research Center for Satellite Communications and Remote Sensing (CSCRS), Istanbul Technical University (ITU), Istanbul, Turkey; Research Center for Satellite Communications and Remote Sensing (CSCRS), Istanbul Technical University (ITU), Istanbul, Turkey; Artificial Intelligence and Data Science Research and Application Center, Istanbul Technical University (ITU), Istanbul, Turkey","IEEE Transactions on Geoscience and Remote Sensing","24 Mar 2021","2021","59","4","3486","3501","Convolutional neural network (CNN)-based approaches have shown promising results in the pansharpening of the satellite images in recent years. However, they still exhibit limitations in producing high-quality pansharpening outputs. To that end, we propose a new self-supervised learning framework, where we treat pansharpening as a colorization problem, which brings an entirely novel perspective and solution to the problem compared with the existing methods that base their solution solely on producing a super-resolution version of the multispectral image. Whereas the CNN-based methods provide a reduced-resolution panchromatic image as the input to their model along with the reduced-resolution multispectral images and, hence, learn to increase their resolution together, we instead provide the grayscale transformed multispectral image as the input and train our model to learn the colorization of the grayscale input. We further address the fixed downscale ratio assumption during training, which does not generalize well to the full-resolution scenario. We introduce a noise injection into the training by randomly varying the downsampling ratios. Those two critical changes, along with the addition of adversarial training in the proposed PanColorization generative adversarial network (PanColorGAN) framework, help overcome the spatial-detail loss and blur problems that are observed in CNN-based pansharpening. The proposed approach outperforms the previous CNN-based and traditional methods, as demonstrated in our experiments.","1558-0644","","10.1109/TGRS.2020.3010441","Research Fund of the Istanbul Technical University Project(grant numbers:MGA-2017-40811); Turkcell-ITU Researcher Funding Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9153037","AI;colorization;convolutional neural networks (CNNs);deep learning;generative adversarial networks (GANs);image fusion;PanColorization generative adversarial network (PanColorGAN);pansharpening;self-supervised learning;super-resolution (SR)","Task analysis;Spatial resolution;Training;Standards;Sensors;Multiresolution analysis","convolutional neural nets;geophysical image processing;image colour analysis;image resolution;supervised learning","adversarial training;grayscale transformed multispectral image;blur problems;PanColorGAN;panchromatic image resolution;PanColorization generative adversarial network;CNN based pansharpening;panchromatic image colorization;self supervised learning;satellite images;convolutional neural network;multispectral image resolution","","37","","44","IEEE","31 Jul 2020","","","IEEE","IEEE Journals"
"Structure-Aware Deep Networks and Pixel-Level Generative Adversarial Training for Single Image Super-Resolution","W. Shi; F. Tao; Y. Wen","Guangdong Province Engineering Laboratory for Digital Creative Technology, Guangdong-Hong Kong Joint Laboratory for Big Data Imaging and Communication, Shenzhen Key Laboratory of Digital Creative Technology, College of Electronics and Information Engineering, Shenzhen University, Shenzhen, No. 3688, Nanhai Avenue, Nanshan District, Shenzhen, China; Guangdong Province Engineering Laboratory for Digital Creative Technology, Guangdong-Hong Kong Joint Laboratory for Big Data Imaging and Communication, Shenzhen Key Laboratory of Digital Creative Technology, College of Electronics and Information Engineering, Shenzhen University, Shenzhen, No. 3688, Nanhai Avenue, Nanshan District, Shenzhen, China; Guangdong Province Engineering Laboratory for Digital Creative Technology, Guangdong-Hong Kong Joint Laboratory for Big Data Imaging and Communication, Shenzhen Key Laboratory of Digital Creative Technology, College of Electronics and Information Engineering, Shenzhen University, Shenzhen, No. 3688, Nanhai Avenue, Nanshan District, Shenzhen, China","IEEE Transactions on Instrumentation and Measurement","","2023","PP","99","1","1","The resolution of current display devices is getting higher and higher, and 4K/8K display devices have become popular, which requires image super-resolution technologies to enlarge and restore the input low-resolution images into high-resolution ones. In addition, image super-resolution technologies can facilitate various vision-based measurement applications. Recently, super-resolution methods based on generative adversarial networks (GAN) have become the mainstream. However, some recent studies shown that GAN-based image super-resolution methods will cause structural distortion. Existing methods alleviate the problem of structural distortion by enhancing structure generation. But this type of methods cannot essentially solve the problem of structural distortion caused by adversarial training. In contrast, this paper proposes the pixel-level generative adversarial training to solve the structural distortion problem, which finely constrains the structure of images during the adversarial training process. In addition, to better generate the structure and details of images and make full use of similar texture details within images, we build a structure-aware image super-resolution network, which not only enhances the structure generation through gradient guidance but also effectively integrates non-local self-similarity modules in a multi-level manner. Experimental results show that the proposed method achieves better quantitative and qualitative results than the state-of-the-art methods. The ablation experiments show that the proposed structure-aware deep network and pixel-level adversarial training can improve the performance of image super-resolution.","1557-9662","","10.1109/TIM.2023.3246523","National Science Foundation of China(grant numbers:62101346); Guangdong Basic and Applied Basic Research Foundation(grant numbers:2021A1515011702); Shenzhen Higher Education Institutions(grant numbers:20200812104316001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10049122","Single image super-resolution;generative adversarial network;nonlocal self-similarity;structure preserving;gradient guidance","Superresolution;Training;Image resolution;Distortion;Image reconstruction;Visualization;Convolution","","","","","","","IEEE","20 Feb 2023","","","IEEE","IEEE Early Access Articles"
"Multi-Laplacian GAN with Edge Enhancement for Face Super Resolution","S. Ko; B. -R. Dai","Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan, R. O. C.; Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan, R. O. C.","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","3505","3512","Face image super-resolution has become a research hotspot in the field of image processing. Nowadays, more and more researches add additional information, such as landmark, identity, to reconstruct high resolution images from low resolution ones, and have a good performance in quantitative terms and perceptual quality. However, these additional information is hard to obtain in many cases. In this work, we focus on reconstructing face images by extracting useful information from face images directly rather than using additional information. By observing edge information in each scale of face images, we propose a method to reconstruct high resolution face images with enhanced edge information. In additional, with the proposed training procedure, our method reconstructs photo-realistic images in upscaling factor 8× and outperforms state-of-the-art methods both in quantitative terms and perceptual quality.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9412950","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9412950","","Training;Face recognition;Image edge detection;Superresolution;Data mining;Image reconstruction","face recognition;feature extraction;image enhancement;image reconstruction;image resolution;neural nets;realistic images","quantitative terms;perceptual quality;multiLaplacian GAN;edge enhancement;face image super-resolution;research hotspot;image processing;high resolution face images;enhanced edge information;photo-realistic image reconstruction;useful information extraction;face image reconstruction;generative adversarial networks","","3","","40","IEEE","5 May 2021","","","IEEE","IEEE Conferences"
"Individual Tree Crown Detection using GAN and RetinaNet on Tropical Forest","Z. Roslan; Z. A. Long; R. Ismail","Malaysian Institute of Information Technology, University Kuala Lumpur, Kuala Lumpur, Malaysia; Malaysian Institute of Information Technology, University Kuala Lumpur, Kuala Lumpur, Malaysia; Malaysian Institute of Information Technology, University Kuala Lumpur, Kuala Lumpur, Malaysia","2021 15th International Conference on Ubiquitous Information Management and Communication (IMCOM)","17 Mar 2021","2021","","","1","7","The detection performance of tree crowns in forest environment has not been satisfactory compared to common objects, especially using aerial RGB imagery. Previous methods regarding Individual Tree Crown Detection (ITCD) utilizes different data sources to improve the detection rate due to the noisy image. Image enhancement methods such as super-resolution provide a solution to the noisy image by reconstructing the image using the low-resolution image. Generative Adversarial Network (GAN)-based model has shown success in super-resolution techniques. However, the GAN-based model created artefacts that may hinder the accuracy of the detection. In this paper, a noise-cancelling GAN-based model is proposed by averaging the weights of a compressed image and non-compressed image. The proposed method forces the network to discriminate the noise to generate a more photorealistic image. This method is inspired by super-resolution GAN (SRGAN) architecture with Residual Dense Network as the generator network. A two-stage object detection RetinaNet model is then used to detect the individual tree crowns in a sequential fashion. Extensive experiments have been conducted on a self-assembled tree crown dataset which showed the proposed model is more superior than a non-enhanced model with 0.6017 and 0.5908 respectively. Based on the results of the proposed method, the super-resolution technique can be used in conjunction with object detection algorithm to improve the detection in ITCD to improve the detection rate.","","978-1-6654-2318-2","10.1109/IMCOM51814.2021.9377360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377360","tree crown detection;super-resolution;noise-cancelling;RetinaNet;aerial imagery","Superresolution;Vegetation;Forestry;Object detection;Generative adversarial networks;Noise measurement;Task analysis","data compression;forestry;geophysical image processing;image coding;image colour analysis;image denoising;image enhancement;image reconstruction;image resolution;neural nets;object detection","photorealistic imaging;two-stage object detection RetinaNet model;tree crown dataset;superresolution technique;object detection algorithm;individual tree crown detection;image enhancement methods;low-resolution imaging;generative adversarial network-based model;noise-cancelling GAN-based model;image compression;tropical forest environment;superresolution GAN architecture;noncompressed imaging;ITCD;SRGAN architecture","","4","","37","IEEE","17 Mar 2021","","","IEEE","IEEE Conferences"
"Enhancing NDVI Calculation of Low-Resolution Imagery using ESRGANs","M. M. Khaliq; R. Mumtaz","School of Electrical Engineering and Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan; School of Electrical Engineering and Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan","2022 24th International Multitopic Conference (INMIC)","13 Dec 2022","2022","","","1","6","Normalized Difference Vegetation Index (NDVI) has been one of the key scales for monitoring multiple plant parameters, but satellite imagery is never up to date, which makes it difficult to get readings for the recent situation of field crops. Doing so with Unmanned Aerial System, drone, in this case, is an intricate task, but with its advantages which include timely and effective measurements with the least errors to be fixed in post-processing of data. Before this, NDVI has been calculated using an Unmanned Aerial System, but the problem of the low resolution of the imagery always lingers. With the recent advancement of generated adversarial networks, the up-scaling of images has been made possible, which, if done with the right model, rules out the need for upgrading the camera hardware that is never cost-effective. We have come up with the solution of calculating the vegetation index of field crops by implementing Enhanced Super-Resolution Generated Adversarial Networks with drone imagery to calculate the vegetation index of crop fields. A simple near-infrared spectrum camera is usually not capable of producing a higher resolution image, by implementing the aforementioned generated adversarial network, we have been able to calculate vegetation index for a comparably much higher resolution image without upgrading with sophisticated hardware. We were able to perform the calculations for more pixels (12952) against the same area yielded an output value of 0.829 as compared to 0.828 in the case of low-resolution imagery (546416 pixels). The averaged values for red and near-infrared pixels showed changes from 32.337 to 30.264 for red, and from 189.168 to 182.1656 for near-infrared pixels. The results produced with this technique are different from those generated using original images which account for a new gateway in the calculation of the NDVI.","2049-3630","979-8-3503-9710-9","10.1109/INMIC56986.2022.9972928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9972928","Machine Learning;super-resolution;Generative Adversarial Networks;Multispectral imagery;NDVI","Satellites;Superresolution;Vegetation mapping;Crops;Cameras;Hardware;Indexes","autonomous aerial vehicles;crops;geophysical image processing;image resolution;infrared imaging;mobile robots;neural nets;remote sensing","camera hardware;crop fields;data post-processing;drone imagery;enhanced super-resolution generated adversarial networks;ESRGANs;field crops;image resolution;low-resolution imagery;NDVI calculation;near-infrared pixels;near-infrared spectrum camera;normalized difference vegetation index;plant parameter monitoring;satellite imagery;unmanned aerial system","","","","22","IEEE","13 Dec 2022","","","IEEE","IEEE Conferences"
"A Generative Adversarial Network with Attention Module for Unpaired Image-to-Image Translation","R. An; F. Yan; T. Deng","School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China","2021 China Automation Congress (CAC)","14 Mar 2022","2021","","","2526","2531","The Image-to-Image Translation (I2IT) is a challenging image processing task that can be applied to many aspects, such as super-resolution and style transfer. Although several image translation algorithms based on Generative Adversarial Network (GAN) have been proposed, achieving better translation effects still remains a problem worthy of attention. This work proposes a model that fuses an attention module and ResNet-based generator to enhance the performance of I2IT. Using an attention module after the first downsampling, our model can focus more on important low-level semantic features. After the downsampling, the residual blocks provide contextual supplementary information of the photos. The qualitative and quantitative experimental results on unpaired datasets show that our model is better than the SOTA methods, which further confirms the robustness and effectiveness of the proposed model.","2688-0938","978-1-6654-2647-3","10.1109/CAC53003.2021.9727816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9727816","image-to-image translation;generative adversarial network;attention mechanism","Automation;Fuses;Image processing;Superresolution;Semantics;Generative adversarial networks;Generators","image enhancement;language translation;multimedia systems;neural nets","photo contextual supplementary information;I2IT performance enhancement;GAN;challenging image processing task;unpaired image-to-image translation;ResNet-based generator;translation effects;generative adversarial network;image translation algorithms","","1","","20","IEEE","14 Mar 2022","","","IEEE","IEEE Conferences"
"Detail Fusion GAN: High-Quality Translation for Unpaired Images with GAN-based Data Augmentation","L. Li; Y. Li; C. Wu; H. Dong; P. Jiang; F. Wang","School of Software Engineering, Xi'an Jiaotong University, Xi'an, China; School of Software Engineering, Xi'an Jiaotong University, Xi'an, China; School of Software Engineering, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; School of Software Engineering, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","1731","1736","Image-to-image translation, a task to learn the mapping relation between two different domains, is a rapid-growing research field in deep learning. Although existing Generative Adversarial Network (GAN)-based methods have achieved decent results in this field, there are still some limitations in generating high-quality images for practical applications (e.g., data augmentation and image inpainting). In this work, we aim to propose a GAN-based network for data augmentation which can generate translated images with more details and less artifacts. The proposed Detail Fusion Generative Adversarial Network (DFGAN) consists of a detail branch, a transfer branch, a filter module, and a reconstruction module. The detail branch is trained by a super-resolution loss and its intermediate features can be used to introduce more details to the transfer branch by the filter module. Extensive evaluations demonstrate that our model generates more satisfactory images against the state-of-the-art approaches for data augmentation.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9412542","National Natural Science Foundation of China(grant numbers:61803298); Natural Science Foundation of Jiangsu Province(grant numbers:BK20180236); Fundamental Research Funds for the Central Universities(grant numbers:xjj2018240); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9412542","","Deep learning;Image segmentation;Computer vision;Superresolution;Generative adversarial networks;Information filters;Data models","data handling;feature extraction;image reconstruction;image resolution;image restoration;image texture;language translation;learning (artificial intelligence);object recognition","Detail Fusion GAN;high-quality translation;unpaired images;GAN-based data augmentation;image-to-image translation;mapping relation;deep learning;Generative Adversarial Network-based methods;decent results;high-quality images;image inpainting;GAN-based network;Detail Fusion Generative Adversarial Network;detail branch;transfer branch;filter module;satisfactory images","","","","18","IEEE","5 May 2021","","","IEEE","IEEE Conferences"
"Towards Trustworthy Perception Information Sharing on Connected and Autonomous Vehicles","J. Guo; Q. Yang; S. Fu; R. Boyles; S. Turner; K. Clarke","Computer Science and Engineering, University of North Texas, Denton, TX, USA; Computer Science and Engineering, University of North Texas, Denton, TX, USA; Computer Science and Engineering, University of North Texas, Denton, TX, USA; Computer Science, California State University - Sacramento, Roseville, CA, USA; Computer Science, Grambling State University, Grambling, LA, USA; Computer Science, Texas Christian University, Fort Worth, TX, USA","2020 International Conference on Connected and Autonomous Driving (MetroCAD)","13 Jul 2020","2020","","","85","90","Sharing perception data among autonomous vehicles is extremely useful to extending the line of sight and field of view of autonomous vehicles, which otherwise suffer from blind spots and occlusions. However, the security of using data from a random other car in making driving decisions is an issue. Without the ability of assessing the trustworthiness of received information, it will be too risky to use them for any purposes. On the other hand, when information is exchanged between vehicles, it provides a golden opportunity to quantitatively study a vehicle's trust. In this paper, we propose a trustworthy information sharing framework for connected and autonomous vehicles in which vehicles measure each other's trust using the Dirichlet-Categorical (DC) model. To increase a vehicle's capability of assessing received data's trust, we leverage the Enhanced Super-Resolution Generative Adversarial Networks (ESRGAN) model to increase the resolution of blurry images. As a result, a vehicle is able to evaluate the trustworthiness of received data that contain distant objects. Based on the KITTI dataset, we evaluate the proposed solution and discover that vehicle's trust assessment capability can be increased by 11 - 37%, using the ESRGAN model.","","978-1-7281-6059-7","10.1109/MetroCAD48866.2020.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138639","Connect vehicles;trustworthy information sharing;object detection;autonomous vehicles;image super-resolution","","decision making;image resolution;mobile robots;neural nets;road vehicles;security of data;trusted computing","autonomous vehicles;trustworthy perception information sharing;connected vehicles;sharing perception data;blind spot occlusions;vehicle measure;Dirichlet-categorical model;vehicle capability;enhanced super-resolution generative adversarial networks model;blurry images;ESRGAN model;KITTI dataset;vehicle trust assessment capability","","1","","0","IEEE","13 Jul 2020","","","IEEE","IEEE Conferences"
"Deep Learning Mobile App Based Microscopic Leaf Imaging Disease Classification with Azure Cloud Computing Service","J. J. Danker Khoo; K. Hann Lim; N. N. Mohd Nistah; T. Anung Basuki","Department of Electrical and Computer Engineering, Curtin University Malaysia, Miri, Malaysia; Department of Electrical and Computer Engineering, Curtin University Malaysia, Miri, Malaysia; Department of Electrical and Computer Engineering, Curtin University Malaysia, Miri, Malaysia; Department of Electrical and Computer Engineering, Curtin University Malaysia, Miri, Malaysia","2021 International Conference on Green Energy, Computing and Sustainable Technology (GECOST)","20 Sep 2021","2021","","","1","6","The growth of rubber trees always suffer from blight disease that can be detected on the leaves. Several studies show that an early detection of blight disease may contribute to a positive turnout recovery rate. In this paper, a mobile app-based microscopic leaf imaging disease classification is proposed to detect infected leaves that provides a probability of disease types, geo-tagging location, and smart reporting with recovery stage to assist productivity workflow. Super Resolution Generative Adversarial Network is applied to upscale a low resolution microscopic leaf imaging while introducing finer texture detail. After super resolution reconstruction, a convolution neural network classifier is performed to classify disease groups with an improved accuracy. The diagnostic solution is designed on the Azure cloud computing service to manage the plant disease database, perform reinforcement learning, host web application, secure authentication and display valuable insight of recovery.","","978-1-6654-3865-0","10.1109/GECOST52368.2021.9538689","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9538689","Deep Learning;Cloud Computing;Microsoft Azure;Rubber Plantation;Agriculture;Super Resolution","Deep learning;Cloud computing;Visualization;Image resolution;Microscopy;Computer architecture;Generative adversarial networks","cloud computing;convolutional neural nets;deep learning (artificial intelligence);image classification;image reconstruction;image resolution;image texture;mobile computing;object detection;plant diseases;probability;rubber","superresolution reconstruction;convolution neural network classifier;Azure cloud computing service;plant disease database;rubber trees;blight disease;positive turnout recovery rate;recovery stage;deep learning mobile app-based microscopic leaf imaging disease classification;infected leaves detection;disease type probability;geo-tagging location;smart reporting;productivity workflow;superresolution generative adversarial network;low resolution microscopic leaf imaging;disease group classification;reinforcement learning;Web application;authentication security","","","","27","IEEE","20 Sep 2021","","","IEEE","IEEE Conferences"
"Spatiotemporal Reflectance Fusion Using a Generative Adversarial Network","C. Shang; X. Li; Z. Yin; X. Li; L. Wang; Y. Zhang; Y. Du; F. Ling","College of Resources and Environment, University of Chinese Academy of Sciences, Beijing, China; College of Resources and Environment, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China; Key Laboratory of Monitoring and Estimate for Environment and Disaster of Hubei Province, Innovation Academy for Precision Measurement Science and Technology, Chinese Academy of Sciences, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","13 Dec 2021","2022","60","","1","15","The spatiotemporal reflectance fusion method is used to blend high-temporal and low-spatial resolution images with their low-temporal and high-spatial resolution counterparts that were previously acquired by various satellite sensors. Recently, a wide variety of learning-based solutions have been developed, but challenges remain. These solutions usually require two sets of data acquired before and after the prediction time, making them unsuitable for near-real-time predicting. The solutions are always trained band by band and thus do not consider the spectral correlation. High-resolution temporal changes are difficult to reconstruct accurately with the network structure used, which lowers the accuracy of the fusion result. To address these problems, this study proposes a novel spatiotemporal adaptive reflectance fusion model using a generative adversarial network (GASTFN). In GASTFN, an end-to-end network, including a generative and discriminative network, is simultaneously trained for all spectral bands. The proposed model can be applied to the one-pair case, consider the spectral correlation of each band, and improve the process of producing super-resolution imagery by adopting the discriminative network for image reflectance values rather than temporal changes in reflectance. The proposed model has been verified with two actual satellite data sets acquired in heterogeneous landscapes and areas with abrupt changes, with a comparison of the state-of-art methods. The results show that GASTFN can generate the most accurate fusion images with more detailed textures, more realistic spatial shapes, and higher accuracy, demonstrating that the GASTFN is effective for predicting near-real-time changes in image reflectance and preserves the most valuable spatial information.","1558-0644","","10.1109/TGRS.2021.3065418","Hubei Provincial Natural Science Foundation for Innovation Groups(grant numbers:2019CFA019); Strategic Priority Research Program of Chinese Academy of Sciences(grant numbers:XDA2003030201); Natural Science Foundation of China(grant numbers:62071457); Application Foundation Frontier Project of Wuhan(grant numbers:2020020601012283); Hubei Province Natural Science Fund for Distinguished Young Scholars(grant numbers:2018CFA062); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9383451","Generative adversarial network (GAN);spatiotemporal fusion;super-resolution;temporal changes","Spatiotemporal phenomena;Remote sensing;Generative adversarial networks;Superresolution;Spatial resolution;Gallium nitride;Layout","","","","5","","51","IEEE","23 Mar 2021","","","IEEE","IEEE Journals"
"Dual-Enhanced Registration for Field of View Ultrasound Sonography","Z. Fan; Z. Wang; J. Xin; Z. Wang; L. Liu; X. Zhang; J. Liu","College of Medicine and Biological Information Engineering, Northeastern University, Shenyang, China; College of Medicine and Biological Information Engineering, Northeastern University, Shenyang, China; Key Laboratory of Big Data Management and Analytics (Liaoning Province), Northeastern University, Shenyang, China; Acoustics Science and Technology Laboratory, Harbin Engineering University, Harbin, China; College of Medicine and Biological Information Engineering, Northeastern University, Shenyang, China; Institute of Intelligent Healthcare Technology, Neusoft Corporation, Ltd., Shenyang, China; Institute of Intelligent Healthcare Technology, Neusoft Corporation, Ltd., Shenyang, China","IEEE Access","21 Jul 2020","2020","8","","128602","128612","Extended Field of View Ultrasound Sonography (EFOV-US) uses the existing ultrasound images for image stitching, so as to display the shape and scope of organ occupation and the relationship with surrounding tissues comprehensively. However, there are still some problems in Extended Field of View Ultrasound Sonography, such as matching error and unstable quality of image stitching. In view of these problems, we propose Dual-enhanced EFOV-US method that overcomes the limitation and produces higher quality results. Firstly, the gray enhancement method is used to improve the image contrast and reduce the noise interference. Then the super-resolution method based on the generative adversarial network is used to improve the resolution of the ultrasonic image further and increase the number of feature point matching between stitching images. The high quality ultrasound wide-range image is gotten by stitching and fusing the double enhanced image. The experimental results show that the proposed method is effective and practical.","2169-3536","","10.1109/ACCESS.2020.3008525","National Natural Science Foundation of China(grant numbers:61472069,61402089); China Postdoctoral Science Foundation(grant numbers:2019T120216,2018M641705); Fundamental Research Funds for the Central Universities(grant numbers:N2019007,N180101028,N180408019,N2024005-2); CETC Joint Fund, the fund of Acoustics Science and Technology Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138393","Extended field of view ultrasound sonography;gray enhancement;generative adversarial network;super-resolution;image registration","Ultrasonic imaging;Generative adversarial networks;Feature extraction;Training;Gallium nitride","biomedical ultrasonics;image enhancement;image matching;image registration;image resolution;medical image processing;ultrasonic imaging","image stitching;dual-enhanced EFOV-US method;gray enhancement method;image contrast;ultrasonic image;stitching images;high quality ultrasound wide-range image;double enhanced image;extended field-of-view ultrasound sonography;dual-enhanced registration;noise interference;generative adversarial network","","","","54","CCBY","10 Jul 2020","","","IEEE","IEEE Journals"
"A Survey on the New Generation of Deep Learning in Image Processing","L. Jiao; J. Zhao","Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education, School of Artificial Intelligence, Xidian University, Xi’an, China","IEEE Access","9 Dec 2019","2019","7","","172231","172263","During the past decade, deep learning is one of the essential breakthroughs made in artificial intelligence. In particular, it has achieved great success in image processing. Correspondingly, various applications related to image processing are also promoting the rapid development of deep learning in all aspects of network structure, layer designing, and training tricks. However, the deeper structure makes the back-propagation algorithm more difficult. At the same time, the scale of training images without labels is also rapidly increasing, and class imbalance severely affects the performance of deep learning, these urgently require more novelty deep models and new parallel computing system to more effectively interpret the content of the image and form a suitable analysis mechanism. In this context, this survey provides four deep learning model series, which includes CNN series, GAN series, ELM-RVFL series, and other series, for comprehensive understanding towards the analytical techniques of image processing field, clarify the most important advancements and shed some light on future studies. By further studying the relationship between deep learning and image processing tasks, which can not only help us understand the reasons for the success of deep learning but also inspires new deep models and training methods. More importantly, this survey aims to improve or arouse other researchers to catch a glimpse of the state-of-the-art deep learning methods in the field of image processing and facilitate the applications of these deep learning technologies in their research tasks. Besides, we discuss the open issues and the promising directions of future research in image processing using the new generation of deep learning.","2169-3536","","10.1109/ACCESS.2019.2956508","National Key R&D Program of China(grant numbers:2018YFC0825305,2018YFC0825303); State Key Program of National Natural Science of China(grant numbers:61836009); National Natural Science Foundation of China(grant numbers:61501353,61573267,61473215); Shaanxi University of Science and Technology(grant numbers:2019BJ-11); Program for Cheung Kong Scholars and Innovative Research Team in University(grant numbers:IRT_15R53); The Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project)(grant numbers:B07048); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917633","Image processing;deep learning;convolutional neural network;generative adversarial network;extreme learning machine;deep forest;capsule networks;ADMM-Net;image classification;style transfer;object detection;super-resolution","Machine learning;Task analysis;Generative adversarial networks;Convolutional neural networks;Image resolution;Mathematical model","image processing;learning (artificial intelligence);neural net architecture","novelty deep models;deep learning model series;image processing field;training methods;state-of-the-art deep learning methods;deep learning technologies;ELM-RVFL series;CNN series;GAN series;back-propagation algorithm","","72","","182","CCBY","28 Nov 2019","","","IEEE","IEEE Journals"
"Face Hallucination With Finishing Touches","Y. Zhang; I. W. Tsang; J. Li; P. Liu; X. Lu; X. Yu","Key Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Nanjing, China; Australian Artificial Intelligence Institute, University of Technology Sydney, Ultimo, NSW, Australia; Australian Artificial Intelligence Institute, University of Technology Sydney, Ultimo, NSW, Australia; Institute of High Performance Computing, Research Agency for Science, Technology and Research (A*STAR), Singapore; Key Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Nanjing, China; Australian Artificial Intelligence Institute, University of Technology Sydney, Ultimo, NSW, Australia","IEEE Transactions on Image Processing","14 Jan 2021","2021","30","","1728","1743","Obtaining a high-quality frontal face image from a low-resolution (LR) non-frontal face image is primarily important for many facial analysis applications. However, mainstreams either focus on super-resolving near-frontal LR faces or frontalizing non-frontal high-resolution (HR) faces. It is desirable to perform both tasks seamlessly for daily-life unconstrained face images. In this paper, we present a novel Vivid Face Hallucination Generative Adversarial Network (VividGAN) for simultaneously super-resolving and frontalizing tiny non-frontal face images. VividGAN consists of coarse-level and fine-level Face Hallucination Networks (FHnet) and two discriminators, i.e., Coarse-D and Fine-D. The coarse-level FHnet generates a frontal coarse HR face and then the fine-level FHnet makes use of the facial component appearance prior, i.e., fine-grained facial components, to attain a frontal HR face image with authentic details. In the fine-level FHnet, we also design a facial component-aware module that adopts the facial geometry guidance as clues to accurately align and merge the frontal coarse HR face and prior information. Meanwhile, two-level discriminators are designed to capture both the global outline of a face image as well as detailed facial characteristics. The Coarse-D enforces the coarsely hallucinated faces to be upright and complete while the Fine-D focuses on the fine hallucinated ones for sharper details. Extensive experiments demonstrate that our VividGAN achieves photo-realistic frontal HR faces, reaching superior performance in downstream tasks, i.e., face recognition and expression classification, compared with other state-of-the-art methods.","1941-0042","","10.1109/TIP.2020.3046918","National Natural Science Foundation of China(grant numbers:61871123); Key Research and Development Program in Jiangsu Province(grant numbers:BE2016739); Australian Research Council (ARC)(grant numbers:DP180100106,DP200101328); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9318504","Face hallucination;super-resolution;face frontalization;generative adversarial network","Face recognition;Faces;Image resolution;Superresolution;Task analysis;Generative adversarial networks;Deep learning","emotion recognition;face recognition;image classification;image resolution;neural nets;unsupervised learning","high-quality frontal face image;finishing touches;nonfrontal high-resolution faces;Coarse-D discriminator;Fine-D discriminator;vivid face hallucination generative adversarial network;expression classification;face recognition;facial component-aware module;fine-grained facial components;fine-level FHnet;frontal coarse HR face;coarse-level FHnet;VividGAN;near-frontal LR faces;facial analysis;low-resolution nonfrontal face image","Automated Facial Recognition;Face;Female;Humans;Image Processing, Computer-Assisted;Machine Learning;Male","13","","76","IEEE","8 Jan 2021","","","IEEE","IEEE Journals"
"Recursive Copy and Paste GAN: Face Hallucination From Shaded Thumbnails","Y. Zhang; I. W. Tsang; Y. Luo; C. Hu; X. Lu; X. Yu","Key Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Nanjing, China; Australian Institute of Artificial Intelligence, University of Technology Sydney, Ultimo, NSW, Australia; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Automation and the College of Artificial Intelligent, Nanjing University of Posts and Telecommunications, Nanjing, China; Key Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Nanjing, China; Australian Institute of Artificial Intelligence, University of Technology Sydney, Ultimo, NSW, Australia","IEEE Transactions on Pattern Analysis and Machine Intelligence","1 Jul 2022","2022","44","8","4321","4338","Existing face hallucination methods based on convolutional neural networks (CNNs) have achieved impressive performance on low-resolution (LR) faces in a normal illumination condition. However, their performance degrades dramatically when LR faces are captured in non-uniform illumination conditions. This paper proposes a Recursive Copy and Paste Generative Adversarial Network (Re-CPGAN) to recover authentic high-resolution (HR) face images while compensating for non-uniform illumination. To this end, we develop two key components in our Re-CPGAN: internal and recursive external Copy and Paste networks (CPnets). Our internal CPnet exploits facial self-similarity information residing in the input image to enhance facial details; while our recursive external CPnet leverages an external guided face for illumination compensation. Specifically, our recursive external CPnet stacks multiple external Copy and Paste (EX-CP) units in a compact model to learn normal illumination and enhance facial details recursively. By doing so, our method offsets illumination and upsamples facial details progressively in a coarse-to-fine fashion, thus alleviating the ambiguity of correspondences between LR inputs and external guided inputs. Furthermore, a new illumination compensation loss is developed to capture illumination from the external guided face image effectively. Extensive experiments demonstrate that our method achieves authentic HR face images in a uniform illumination condition with a $16\times$16× magnification factor and outperforms state-of-the-art methods qualitatively and quantitatively.","1939-3539","","10.1109/TPAMI.2021.3061312","National Natural Science Foundation of China(grant numbers:61871123,61976017,61802203); Key Research and Development Program in Jiangsu Province(grant numbers:BE2016739); Australian Research Council(grant numbers:DP180100106,DP200101328); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361225","Face hallucination;super-resolution;illumination normalization;generative adversarial network","Lighting;Faces;Face recognition;Training;Superresolution;Rain;Generative adversarial networks","face recognition;image reconstruction;image resolution;learning (artificial intelligence);neural nets","shaded thumbnails;face hallucination methods;convolutional neural networks;normal illumination condition;performance degrades;LR faces;nonuniform illumination conditions;Re-CPGAN;high-resolution face images;CPnets;internal CPnet;facial self-similarity information residing;input image;recursive external CPnet;method offsets illumination;upsamples facial details;LR inputs;external guided inputs;illumination compensation loss;external guided face image;uniform illumination condition","Algorithms;Face;Hallucinations;Humans;Neural Networks, Computer","9","","75","IEEE","23 Feb 2021","","","IEEE","IEEE Journals"
"Deep Learning Face Hallucination via Attributes Transfer and Enhancement","M. Li; Y. Sun; Z. Zhang; H. Xie; J. Yu","Department of Automation, University of Science and Technology of China; Department of Automation, University of Science and Technology of China; Department of Automation, University of Science and Technology of China; Department of Automation, University of Science and Technology of China; Department of Automation, University of Science and Technology of China","2019 IEEE International Conference on Multimedia and Expo (ICME)","5 Aug 2019","2019","","","604","609","Face hallucination technique aims to generate high-resolution (HR) face images from low-resolution (LR) inputs. Even though existing face hallucination methods have achieved great performance on the global region evaluation, most of them cannot reasonably restore local attributes, especially when ultra-resolving tiny LR face image (16 × 16 pixels) to its larger version (8× upscaling factor). In this paper, we propose a novel attribute-guided face transfer and enhancement network for face hallucination. Specifically, we first construct a face transfer network, which upsamples LR face images to HR feature maps, and then fuses facial attributes and the upsampled features to generate HR face images with rational attributes. Finally, a face enhancement network is developed based on generative adversarial network (GAN) to improve visual quality by exploiting a composite loss that combines image color, texture and content. Extensive experiments demonstrate that our method achieves superior face hallucination results and outperforms the state-of-the-art.","1945-788X","978-1-5386-9552-4","10.1109/ICME.2019.00110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8785029","Face hallucination, facial attributes, face attribute transfer, face enhancement, face super-resolution","Face;Image resolution;Image color analysis;Facial features;Feature extraction;Visualization;Generative adversarial networks","convolutional neural nets;face recognition;image colour analysis;image enhancement;image resolution;learning (artificial intelligence)","face transfer network;LR face images;facial attributes;face enhancement network;generative adversarial network;image color;face hallucination technique;high-resolution face images;global region evaluation;attribute-guided face transfer;GAN;HR feature maps;HR face images;deep learning face hallucination","","8","","27","IEEE","5 Aug 2019","","","IEEE","IEEE Conferences"
"AS-RIG: Adaptive Selection of Reconstructed Input by Generator or Interpolation for Person Re-Identification in Cross-Modality Visible and Thermal Images","J. K. Kang; M. B. Lee; H. S. Yoon; K. R. Park","Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea; Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea; Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea; Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea","IEEE Access","22 Jan 2021","2021","9","","12055","12066","Multimodal camera-based person re-identification (ReID) is important in the field of intelligent surveillance. Thermal cameras can solve the problem in that visible-light cameras cannot acquire the valid feature information of a person under poor illumination conditions. However, thermal cameras usually have lower frame resolution than visible-light cameras. To overcome this problem, we propose an adaptive selection of reconstructed input by generator or interpolation (AS-RIG) method, which can adaptively select the generative adversarial network (GAN), or an interpolation method (bi-linear or bi-cubic). AS-RIG automatically selects a resolution-model using the mean-squared error (MSE), feature distance (FD), and structural similarity (SSIM). To verify the performance of our proposed method, two open databases are used: the DBPerson-Recog-DB1 and Sun Yat-set University multiple modality Re-ID (SYSU-MM01). Infrared frames from both databases are resized to be smaller than the original ones for experimentation. Experimental results show that our generator outperforms traditional interpolation methods. In addition, the person ReID experimental results demonstrate that AS-RIG outperforms non-adaptive selection methods and state-of-the-art methods.","2169-3536","","10.1109/ACCESS.2021.3051637","Ministry of Science and ICT (MSIT), Korea, under the Information Technology Research Center (ITRC) Support Program supervised by the Institute for Information and Communications Technology Promotion (IITP)(grant numbers:IITP-2020-2020-0-01789); National Research Foundation of Korea (NRF) funded by the MSIT through the Basic Science Research Program(grant numbers:NRF-2020R1A2C1006179,NRF-2019R1A2C1083813); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324824","Person Re-ID;convolutional neural network (CNN);super-resolution (SR);GAN","Cameras;Feature extraction;Lighting;Generators;Interpolation;Generative adversarial networks;Data models","cameras;feature extraction;image matching;image reconstruction;image resolution;infrared imaging;interpolation;mean square error methods","adaptive selection;thermal images;intelligent surveillance;thermal cameras;visible-light cameras;feature information;poor illumination conditions;frame resolution;interpolation method;AS-RIG;generative adversarial network;resolution-model;feature distance;Sun Yat-set University multiple modality Re-ID;traditional interpolation methods;person ReID experimental results;nonadaptive selection methods;cross-modality visible images;mean-squared error;multimodal camera-based person re-identification","","3","","54","CCBY","14 Jan 2021","","","IEEE","IEEE Journals"
"Robust Face Hallucination Algorithm Using Motion Blur Embedded Nearest Proximate Patch Representation","D. Rai; S. S. Rajput","Department of Computer Science and Engineering, National Institute of Technology Patna, Patna, Bihar, India; Department of Computer Science and Engineering, National Institute of Technology Patna, Patna, Bihar, India","IEEE Transactions on Instrumentation and Measurement","18 Jan 2023","2023","72","","1","10","Face hallucination (FH) techniques have received a lot of attention in recent years for generating high-resolution (HR) face images from captured low-resolution (LR), noisy, and blurry images. However, existing FH techniques are incapable of dealing with motion blur, which is commonly introduced in captured images due to camera defocussing and other factors. Therefore, to make the FH process more resistant to motion blur, in this article, we present a novel learning-based FH algorithm called Motion Blur Embedded Nearest Proximate Patch Representation (MBENPPR). The MBENPPR algorithm begins by estimating the motion blur kernel from a motion-blurred LR test face. The estimated kernel is then embedded in training images to make them compatible with test images. It assists in reducing the effect of motion blur in the reconstruction process. Furthermore, the nearest proximate patches are selected from the training space to represent the test image patches as a weighted linear combination of selected patches. It facilitates the proposed algorithm in preserving sharp edges and texture information in the resulting faces. The results of simulations on standard datasets and locally captured real-life faces show that the MBENPPR algorithm outperforms the compared existing algorithms.","1557-9662","","10.1109/TIM.2022.3223141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9954422","Face hallucination (FH);motion-blur;position-patch;proximate patch;super-resolution (SR)","Faces;Training;Face recognition;Kernel;Image reconstruction;Image resolution;Generative adversarial networks","edge detection;face recognition;image capture;image motion analysis;image representation;image resolution;image restoration;image texture;nearest neighbour methods","captured images;face hallucination techniques;high-resolution face images;image patches;learning-based face hallucination algorithm;MBENPPR algorithm;motion blur embedded nearest proximate patch representation;motion-blurred low-resolution test face;nearest proximate patches","","3","","57","IEEE","17 Nov 2022","","","IEEE","IEEE Journals"
"Pro-UIGAN: Progressive Face Hallucination From Occluded Thumbnails","Y. Zhang; X. Yu; X. Lu; P. Liu","Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information, Ministry of Education, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Australian Institute of Artificial Intelligence, University of Technology Sydney, Ultimo, NSW, Australia; Key Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Nanjing, China; Center for Frontier AI Research (CFAR), Research Agency for Science, Technology and Research (A*STAR), Singapore","IEEE Transactions on Image Processing","26 Apr 2022","2022","31","","3236","3250","In this paper, we study the task of hallucinating an authentic high-resolution (HR) face from an occluded thumbnail. We propose a multi-stage Progressive Upsampling and Inpainting Generative Adversarial Network, dubbed Pro-UIGAN, which exploits facial geometry priors to replenish and upsample ( $8\times $ ) the occluded and tiny faces ( $16\times 16$  pixels). Pro-UIGAN iteratively (1) estimates facial geometry priors for low-resolution (LR) faces and (2) acquires non-occluded HR face images under the guidance of the estimated priors. Our multi-stage hallucination network upsamples and inpaints occluded LR faces via a coarse-to-fine fashion, significantly reducing undesirable artifacts and blurriness. Specifically, we design a novel cross-modal attention module for facial priors estimation, in which an input face and its landmark features are formulated as queries and keys, respectively. Such a design encourages joint feature learning across the input facial and landmark features, and deep feature correspondences will be discovered by attention. Thus, facial appearance features and facial geometry priors are learned in a mutually beneficial manner. Extensive experiments show that our Pro-UIGAN attains visually pleasing completed HR faces, thus facilitating downstream tasks, i.e., face alignment, face parsing, face recognition as well as expression classification.","1941-0042","","10.1109/TIP.2022.3167280","National Natural Science Foundation of China(grant numbers:61871123); Key Research and Development Program in Jiangsu Province(grant numbers:BE2016739); Agency for Science, Technology and Research (A*STAR) under its AME Programmatic Funding Scheme(grant numbers:A18A1b0045); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760261","Face inpainting;super-resolution;face hallucination;generative adversarial network","Face recognition;Faces;Geometry;Task analysis;Generative adversarial networks;Superresolution;Semantics","","","Algorithms;Face;Hallucinations;Head;Humans;Image Processing, Computer-Assisted","2","","68","IEEE","19 Apr 2022","","","IEEE","IEEE Journals"
"Spatio-Temporal Generative Adversarial Network based Power Distribution Network State Estimation with Multiple Time-scale Measurements","Y. Liu; Y. Wang; Q. Yang","Polytechnic Institute and College of Electrical Engineering, Zhejiang University, Hangzhou, China; College of Electrical Engineering, Zhejiang University, Hangzhou, China; College of Electrical Engineering, Zhejiang University, Hangzhou, China","IEEE Transactions on Industrial Informatics","","2023","PP","99","1","8","The increasing penetration of distributed renewable generation has introduced significant uncertainties and randomness to the power distribution network operation. Accurate and timely awareness of the network operation is of paramount importance to ensure system safety and reliability and is considered non-trivial and costly as substantial network reinforcement with advanced measurement devices is generally required. Also, the existing state estimation methods, e.g., weighted least square (WLS), may not converge in the presence of incomplete and inaccurate measurements. This paper proposes a spatio-temporal estimation generative adversarial network (ST-EGAN) consisting of feature extraction, information completion, data reconstruction and fake data discrimination to generate high-resolution pseudo-measurements to promote the accuracy and robustness of state estimation. The task of high-resolution power distribution network state estimation is carried out based on the mixed dataset of multiple time-scale measurements obtained from Supervisory Control and Data Acquisition (SCADA) and Phasor Measurement Units (PMU). The proposed solution is extensively assessed using the IEEE 33-bus test network compared with the existing solutions for a range of scenarios with different resolutions and noise intensities. The numerical results demonstrated that the proposed ST-EGAN can reduce the mean RMSE by 4.78% compared to interpolation algorithms, and reduce the RMSE by 0.14% and 0.21% compared with deep convolutional generative adversarial networks (DCGAN) and super-resolution convolutional networks (SRCNN) in the presence of noises with different intensities. The proposed method can be generalized to cases with different topological structures and measurement assembly conditions.","1941-0050","","10.1109/TII.2023.3234624","Nature Science Foundation of China(grant numbers:52177119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10008049","State estimation;high-resolution perception;interpolation;data generation","Distribution networks;State estimation;Phasor measurement units;Power measurement;Power systems;Generative adversarial networks;Task analysis","","","","","","","IEEE","6 Jan 2023","","","IEEE","IEEE Early Access Articles"
"Inter-Task Association Critic for Cross-Resolution Person Re-Identification","Z. Cheng; Q. Dong; S. Gong; X. Zhu","Queen Mary University of London; Queen Mary University of London; Queen Mary University of London; Vision Semantics Limited, London, UK","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","2602","2612","Person images captured by unconstrained surveillance cameras often have low resolutions (LR). This causes the resolution mismatch problem when matched against the high-resolution (HR) gallery images, negatively affecting the performance of person re-identification (re-id). An effective approach is to leverage image super-resolution (SR) along with person re-id in a joint learning manner. However, this scheme is limited due to dramatically more difficult gradients backpropagation during training. In this paper, we introduce a novel model training regularisation method, called Inter-Task Association Critic (INTACT), to address this fundamental problem. Specifically, INTACT discovers the underlying association knowledge between image SR and person re-id, and leverages it as an extra learning constraint for enhancing the compatibility of SR model with person re-id in HR image space. This is realised by parameterising the association constraint which enables it to be automatically learned from the training data. Extensive experiments validate the superiority of INTACT over the state-of-the-art approaches on the cross-resolution re-id task using five standard person re-id datasets.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157357","","Image resolution;Training;Task analysis;Gallium nitride;Generative adversarial networks;Cameras;Generators","image representation;image resolution;learning (artificial intelligence);neural nets;video surveillance","high-resolution gallery images;image super-resolution;joint learning manner;INTACT;image SR;HR image space;association constraint;cross-resolution re-id task;person re-id datasets;cross-resolution person re-identification;person images;unconstrained surveillance cameras;low resolutions;resolution mismatch problem;inter-task association critic;gradient backpropagation;model training regularisation method","","14","","54","IEEE","5 Aug 2020","","","IEEE","IEEE Conferences"
"Fusion of Hyperspectral and Panchromatic Images Using Generative Adversarial Network and Image Segmentation","W. Dong; Y. Yang; J. Qu; W. Xie; Y. Li","State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","29 Dec 2021","2022","60","","1","13","Hyperspectral (HS) image fusion aims at integrating a panchromatic (PAN) image and an HS image, featuring the fused image with the spatial quality of the former and the spectral diversity of the latter. The classic fusion algorithm generally includes three consecutive procedures that are upsampling, detail extraction, and detail injection. In this article, we propose an HS and PAN image fusion method based on generative adversarial network and local estimation of injection gain. Instead of upsampling the HS image by classical interpolation techniques, a generative adversarial super-resolution network (GASN) is designed to obtain the interpolated HS image in the fusion framework. GASN establishes a spectral-information-based discriminator to conduct adversarial learning with the generator, so as to preserve the spectral information of the low-resolution HS image. An image segmentation-based injection gain estimation (ISGE) algorithm is subsequently proposed for HS and PAN images fusion. The injection gain is estimated over image segments obtained by a binary partition tree approach to improve the fusion performance. The proposed GASN and ISGE are implemented into two credible global estimation pansharpening methods, and experimental results prove the performance improvement of the proposed method. The proposed method is also compared with existing state-of-the-art methods, and experiments on several public databases demonstrate that the proposed method is competitive or superior to the state-of-the-art fusion methods.","1558-0644","","10.1109/TGRS.2021.3078711","National Defense Pre-Research Foundation; Higher Education Discipline Innovation Project(grant numbers:B08038); National Natural Science Foundation of China(grant numbers:61801359,61571345,91538101,61501346,61502367,61701360); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2021JQ-194,2021JQ-197); Fundamental Research Funds for the Central Universities(grant numbers:XJS210108,XJS210104); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2020A1515110856); Yangtze River Scholar Bonus Schemes of China(grant numbers:CJT160102); Ten Thousand Talent Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9437429","Details injection;hyperspectral (HS) fusion;image segment;injection gains","Estimation;Spatial resolution;Pansharpening;Image segmentation;Generators;Generative adversarial networks;Feature extraction","geophysical image processing;image fusion;image representation;image resolution;image sampling;image segmentation;interpolation;learning (artificial intelligence);neural nets;spectral analysis","spectral-information-based discriminator;adversarial learning;low-resolution HS image;image segmentation-based injection gain estimation algorithm;GASN;panchromatic image;hyperspectral image fusion;interpolation techniques;generative adversarial super-resolution network;interpolated HS image;HS image upsampling;PAN images fusion;global estimation pansharpening methods","","6","","43","IEEE","20 May 2021","","","IEEE","IEEE Journals"
"MRI Restoration Using Edge-Guided Adversarial Learning","Y. Chai; B. Xu; K. Zhang; N. Lepore; J. C. Wood","Department of Radiology, CIBORG Laboratory, Children’s Hospital Los Angeles, Los Angeles, USA; Department of Biomedical Engineering, University of Southern California, Los Angeles, USA; Department of Electrical and Computer Engineering, University of California Davis, Davis, USA; Department of Radiology, CIBORG Laboratory, Children’s Hospital Los Angeles, Los Angeles, USA; Division of Cardiology, Children’s Hospital Los Angeles, Los Angeles, USA","IEEE Access","14 May 2020","2020","8","","83858","83870","Magnetic resonance imaging (MRI) images acquired as multislice two-dimensional (2D) images present challenges when reformatted in orthogonal planes due to sparser sampling in the through-plane direction. Restoring the “missing” through-plane slices, or regions of an MRI image damaged by acquisition artifacts can be modeled as an image imputation task. In this work, we consider the damaged image data or missing through-plane slices as image masks and proposed an edge-guided generative adversarial network to restore brain MRI images. Inspired by the procedure of image inpainting, our proposed method decouples image repair into two stages: edge connection and contrast completion, both of which used general adversarial networks (GAN). We trained and tested on a dataset from the Human Connectome Project to test the application of our method for thick slice imputation, while we tested the artifact correction on clinical data and simulated datasets. Our Edge-Guided GAN had superior PSNR, SSIM, conspicuity and signal texture compared to traditional imputation tools, the Context Encoder and the Densely Connected Super Resolution Network with GAN (DCSRN-GAN). The proposed network may improve utilization of clinical 2D scans for 3D atlas generation and big-data comparative studies of brain morphometry.","2169-3536","","10.1109/ACCESS.2020.2992204","National Heart Lung and the Blood Institute(grant numbers:1U01HL117718-01,1RO1HL136484-A1); National Center for Research Resources(grant numbers:UL1 TR001855-02); University of Southern California’s Center for High-Performance Computing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086007","Artifact correction;edge;generative adversarial network;image restoration;imputation;magnetic resonance imaging","Image edge detection;Image restoration;Magnetic resonance imaging;Two dimensional displays;Generators;Generative adversarial networks;Gallium nitride","biomedical MRI;brain;image resolution;image restoration;image segmentation;image texture;medical image processing;neurophysiology","edge-guided GAN;densely connected super resolution network;edge-guided adversarial learning;image inpainting;brain MRI images;edge-guided generative adversarial network;damaged image data;image imputation task;orthogonal planes;magnetic resonance imaging images;MRI restoration;clinical data;slice imputation","","6","","65","CCBY","4 May 2020","","","IEEE","IEEE Journals"
"Reconfigurable and Low-Complexity Accelerator for Convolutional and Generative Networks Over Finite Fields","W. Xu; Z. Zhang; X. You; C. Zhang","Purple Mountain Laboratories, Nanjing, China; Purple Mountain Laboratories, Nanjing, China; Purple Mountain Laboratories, Nanjing, China; Purple Mountain Laboratories, Nanjing, China","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20 Nov 2020","2020","39","12","4894","4907","Convolutional neural networks (CNNs) have gained great success in various fields, such as computer vision and natural language processing. Besides, with the breakthrough in unsupervised learning, generative adversarial network (GAN) is recently utilized to generate virtual data from limited data sets. The generative model of GAN has impressive applications, such as style transfer and image super-resolution. However, the promising performance of CNN and GAN comes at the cost of prohibitive computation complexity. The convolution (CONV) in CNN and the transposed CONV (TCONV) in GAN are the two operations that dominant the overall complexity. The prior works exploit the fast algorithms, Winograd and fast Fourier transform (FFT), to reduce the complexity of spatial CONV. However, Winograd only supports fixed filter size while FFT has high transform overhead. Moreover, very few works apply fast algorithms to accelerate GAN models. In this article, a reconfigurable and low-complexity accelerator on ASIC for both CNN and GAN is proposed to address these problems. First, by exploiting Fermat number transform (FNT), we propose two FNT-based fast algorithms to reduce the complexity of CONV and TCONV computations, respectively. Then the architectures of the FNT-based accelerator are presented to implement the proposed fast algorithms. The methodology to determine the design parameters and optimize the dataflow is also described for obtaining maximum performance and optimal efficiency. Moreover, we implement the proposed accelerator on 65 nm 1P9M technology and evaluate it on various CNN and GAN models. The post-layout results show that our design achieves a throughput of 288.0 GOP/s on VGG-16 with 25.11 GOP/s/mm2 area efficiency, which is superior to the state-of-the-art CNN accelerators. Furthermore, at least $1.7\times $ speedup over the existing accelerators is obtained on GAN. The resulting energy efficiency is $275.3\times $ and $12.5\times $ of CPU and GPU.","1937-4151","","10.1109/TCAD.2020.2973355","NSFC(grant numbers:61871115,61501116); Jiangsu Provincial NSF for Excellent Young Scholars(grant numbers:BK20180059); Six Talent Peak Program of Jiangsu Province(grant numbers:2018-DZXX-001); Distinguished Perfection Professorship of Southeast University; Fundamental Research Funds for the Central Universities; SRTP of Southeast University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994049","Convolutional neural network (CNN);fast convolution (CONV);Fermat number transform (FNT);generative network;reconfigurable architectures","Gallium nitride;Convolution;Generative adversarial networks;Complexity theory;Transforms;Inference algorithms;Two dimensional displays","computational complexity;convolutional neural nets;fast Fourier transforms;image resolution;unsupervised learning","unsupervised learning;FFT;fast Fourier transform;Winograd;CNN accelerators;FNT-based accelerator;TCONV computations;reconfigurable complexity accelerator;GAN models;spatial CONV;prohibitive computation complexity;image super-resolution;style transfer;generative adversarial network;natural language processing;computer vision;convolutional neural networks;low-complexity accelerator","","6","","34","IEEE","11 Feb 2020","","","IEEE","IEEE Journals"
"Face Recognition With Masks Based on Spatial Fine-Grained Frequency Domain Broadening","H. -Q. Chen; K. Xie; M. -R. Li; C. Wen; J. -B. He","Western Institute, Yangtze University, Karamay, China; Western Institute, Yangtze University, Karamay, China; Western Institute, Yangtze University, Karamay, China; School of Computer Science, Yangtze University, Jingzhou, China; School of Computer Science and Engineering, Central South University, Changsha, China","IEEE Access","25 Jul 2022","2022","10","","75536","75548","Along with social distancing, wearing masks is an effective method of preventing the transmission of COVID-19 in the ongoing pandemic. However, masks occlude a large number of facial features, preventing facial recognition. The recognition rate of existing methods may be significantly reduced by the presence of masks. In this paper, we propose a method to effectively solve the problem of the lack of facial feature information needed to perform facial recognition on people wearing masks. The proposed approach uses image super-resolution technology to perform image preprocessing along with a deep bilinear module to improve EfficientNet. It also combines feature enhancement with frequency domain broadening, fuses the spatial features and frequency domain features of the unoccluded areas of the face, and classifies the fused features. The features of the unoccluded area are increased to improve the accuracy of recognition of masked faces. The results of a cross-validation show that the proposed approach achieved an accuracy of 98% on the RMFRD dataset, as well as a higher recognition rate and faster speed than previous methods. In addition, we also performed an experimental evaluation in an actual facial recognition system and achieved an accuracy of 99%, which demonstrates the effectiveness and practicability of the proposed method.","2169-3536","","10.1109/ACCESS.2022.3191113","Natural Science Foundation of Xinjiang Uygur Autonomous Region(grant numbers:2020D01A131); Fund of Hubei Ministry of Education(grant numbers:B2019039); Graduate Teaching and Research Fund of Yangtze University(grant numbers:YJY201909); Teaching and Research Fund of Yangtze University(grant numbers:JY2019011); Undergraduate Training Programs for Innovation and Entrepreneurship of Yangtze University(grant numbers:Yz2021040); National College Student Innovation and Entrepreneurship Training Program(grant numbers:202110489003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9830694","Face recognition with mask;convolutional neural network;frequency domain widening;bilinear module;RMFRD dataset","Face recognition;Feature extraction;Facial features;Frequency-domain analysis;Generative adversarial networks;Image recognition;Training","face recognition;feature extraction;image resolution;object detection","face recognition;masks;fine-grained frequency domain broadening;facial features;facial feature information;image super-resolution technology;feature enhancement;spatial features;frequency domain features;unoccluded area;fused features;masked faces;actual facial recognition system","","2","","45","CCBY","15 Jul 2022","","","IEEE","IEEE Journals"
"Multi-scale Feature Relation Modeling for Facial Expression Restoration","Z. Liu; Y. Wu; C. Zhang","College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; School of Marine Science and Technology, Tianjin University, Tianjin, China","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","7","Facial expression analysis in the wild is easily vulnerable to the quality of facial images, such as low resolution or occlusion. Existing facial image restoration studies have mostly failed to take full advantage of facial expression prior information, which leads to loss of information related to facial expression in the restoration results. In this paper, we propose a multi-scale feature relation modeling GAN (MFRM-GAN) for facial expression restoration by exploring the multi-scale property and relationship of facial action units. Based on the GAN model, the MFRM-GAN integrates the graph convolution network (GCN) for feature relation modeling and feature pyramid network (FPN) for multi-scale feature extraction. Extensive qualitative and quantitative experiments on BP4D and DISFA datasets demonstrate that our proposed MFRM-GAN (i) can conduct facial expression in-painting and facial image super-resolution jointly, (ii) can recover better facial expression details comparing with state-of-the-art method in both visual effect and AU detection task.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533592","National Natural Science Foundation of China(grant numbers:41806116,61503277); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533592","","Gold;Convolution;Superresolution;Neural networks;Feature extraction;Generative adversarial networks;Visual effects","face recognition;feature extraction;image resolution;image restoration","facial expression restoration;facial expression analysis;facial images;facial image restoration studies;restoration results;multiscale feature relation modeling GAN;MFRM-GAN;facial action units;GAN model;feature pyramid network;multiscale feature extraction;facial image super-resolution;facial expression details","","","","30","IEEE","20 Sep 2021","","","IEEE","IEEE Conferences"
"DEAR-GAN: Degradation-Aware Face Restoration with GAN Prior","Y. Hu; Y. Wang; J. Zhang","School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen, China; School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China","IEEE Transactions on Circuits and Systems for Video Technology","","2023","PP","99","1","1","With the development of generative adversarial networks (GANs), recent face restoration (FR) methods often utilize pre-trained GAN models (i.e., StyleGAN2) as prior to generate rich details. However, these methods usually struggle to balance realness and fidelity when facing various degradation levels. In this paper, we propose a novel DEgradation-Aware Restoration network with GAN prior, dubbed DEAR-GAN, for FR tasks by explicitly learning the degradation representations (DR) to adapt to various degradation. Specifically, an unsupervised degradation representation learning (UDRL) strategy is first developed to extract DR of the input degraded images. Then, a degradation-aware feature interpolation (DAFI) module is proposed to dynamically fuse the two types of informative features (i.e., features from degraded images and features from GAN prior network) with flexible adaption to various degradation based on DR. Extensive experiments show that our proposed DEAR-GAN outperforms the state-of-the-art methods for face restoration under multiple degradation and face super-resolution, and demonstrate the effectiveness of feature interpolation, which can be extended to face inpainting to achieve excellent results.","1558-2205","","10.1109/TCSVT.2023.3244786","National Natural Science Foundation of China(grant numbers:61902009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10044117","Face restoration;generative adversarial network (GAN);GAN prior;representation learning;feature interpolation","Faces;Degradation;Generative adversarial networks;Image restoration;Feature extraction;Task analysis;Interpolation","","","","","","","IEEE","14 Feb 2023","","","IEEE","IEEE Early Access Articles"
"Reliable Perceptual Loss Computation for GAN-Based Super-Resolution With Edge Texture Metric","J. Kim; C. Lee","School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea","IEEE Access","3 Sep 2021","2021","9","","120127","120137","Super-resolution (SR) is an ill-posed problem. Generating high-resolution (HR) images from low-resolution (LR) images remains a major challenge. Recently, SR methods based on deep convolutional neural networks (DCN) have been developed with impressive performance improvement. DCN-based SR techniques can be largely divided into peak signal-to-noise ratio (PSNR)-oriented SR networks and generative adversarial networks (GAN)-based SR networks. In most current GAN-based SR networks, the perceptual loss is computed from the feature maps of a single layer or several fixed layers using a differentiable feature extractor such as VGG. This limited layer utilization may produce overly textured artifacts. In this paper, a new edge texture metric (ETM) is proposed to quantify the characteristics of images and then it is utilized only in the training phase to select an appropriate layer when calculating the perceptual loss. We present experimental results showing that the GAN-based SR network trained with the proposed method achieves qualitative and quantitative perceptual quality improvements compared to many of the existing methods.","2169-3536","","10.1109/ACCESS.2021.3108394","Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Education, Science and Technology(grant numbers:NRF-2020R1A2C1012221); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9524635","Artificial neural networks;computer vision;image enhancement;image resolution","Training;Semantics;Feature extraction;Measurement;Image reconstruction;Superresolution;Image edge detection","convolutional neural nets;feature extraction;image resolution;image texture","GAN-based super-resolution;edge texture metric;high-resolution images;low-resolution images;SR methods;deep convolutional neural networks;DCN-based SR techniques;GAN-based SR network;reliable perceptual loss computation","","","","62","CCBYNCND","27 Aug 2021","","","IEEE","IEEE Journals"
"Bandwidth Extension is All You Need","J. Su; Y. Wang; A. Finkelstein; Z. Jin","Princeton University, USA; Princeton University, USA; Princeton University, USA; Adobe Research, USA","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","696","700","Speech generation and enhancement have seen recent breakthroughs in quality thanks to deep learning. These methods typically operate at a limited sampling rate of 16-22kHz due to computational complexity and available datasets. This limitation imposes a gap between the output of such methods and that of high-fidelity (≥44kHz) real-world audio applications. This paper proposes a new bandwidth extension (BWE) method that expands 8-16kHz speech signals to 48kHz. The method is based on a feed-forward WaveNet architecture trained with a GAN-based deep feature loss. A mean-opinion-score (MOS) experiment shows significant improvement in quality over state-of-the-art BWE methods. An AB test reveals that our 16-to-48kHz BWE is able to achieve fidelity that is typically indistinguishable from real high-fidelity recordings. We use our method to enhance the output of recent speech generation and denoising methods, and experiments demonstrate significant improvement in sound quality over these baselines. We propose this as a general approach to narrow the gap between generated speech and recorded speech, without the need to adapt such methods to higher sampling rates.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9413575","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413575","bandwidth extension;audio super resolution;generative adversarial networks;deep features;speech enhancement","Training;Deep learning;Conferences;Noise reduction;Signal processing algorithms;Bandwidth;Speech enhancement","acoustic noise;audio signal processing;computational complexity;deep learning (artificial intelligence);feature extraction;signal denoising;signal sampling;speech enhancement","denoising methods;sound quality;sampling rates;deep learning;sampling rate;computational complexity;high-fidelity real-world audio applications;bandwidth extension method;speech signals;feed-forward WaveNet architecture;GAN-based deep feature loss;mean-opinion-score experiment;high-fidelity recordings;speech generation;BWE methods;speech enhancement;frequency 48.0 kHz;frequency 16.0 kHz to 22.0 kHz;frequency 8.0 kHz to 16.0 kHz;frequency 44.0 kHz","","7","","40","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"Glance: A Generative Approach to Interactive Visualization of Voluminous Satellite Imagery","S. Mitra; D. Rammer; S. Pallickara; S. L. Pallickara","Department of Computer Science, Colorado State University, Fort Collins, USA; Department of Computer Science, Colorado State University, Fort Collins, USA; Department of Computer Science, Colorado State University, Fort Collins, USA; Department of Computer Science, Colorado State University, Fort Collins, USA","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","359","367","Challenges in interactive visualizations over satellite data collections stem primarily from their inherent data volumes. Enabling interactive visualizations of such data results in both processing and I/O (network and disk) on the server side. These are further exacerbated by multiple, concurrent requests issued by different clients. Hotspots may also arise when multiple users are interested in a particular geographical extent. We propose a novel methodology to support interactive visualizations over voluminous satellite imagery. Our system, codenamed Glance, generates models that once installed on the client side, substantially alleviate resource requirements on the server side. Our system dynamically generates imagery during zoom-in operations. Glance also supports image refinements using partial high-resolution information when available. Glance is based broadly on a deep Generative Adversarial Network, and our model is space-efficient to facilitate memory-residency at the clients. We supplement Glance with a module to estimate rendering errors when using the model to generate imagery as opposed to a resource-intensive query-and-retrieve operation to the server. Benchmarks to profile our methodology show substantive improvements in interactivity with up to 23x reduction in time lags without utilizing GPU and 297x-6627x reduction while harnessing GPU. Further, the perceptual quality of the images from our generative model is robust with PSNR values ranging from 32.2-40.5, depending on the scenario and upscale factor.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671537","National Science Foundation; National Institute of Food and Agriculture; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671537","super-resolution;generative adversarial networks;edge enhancement;in-memory storage;visual analytics","Training;Satellites;Superresolution;Data visualization;Graphics processing units;Big Data;Data models","data visualisation;graphics processing units;image resolution;interactive systems;query processing;rendering (computer graphics)","generative approach;interactive visualization;voluminous satellite imagery;satellite data collections;inherent data volumes;multiple requests;concurrent requests;Glance;deep Generative Adversarial Network;generative model","","","","33","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Deep Learning-Based, Misalignment Resilient, Real-Time Fourier Ptychographic Microscopy Reconstruction of Biological Tissue Slides","V. Bianco; M. D. Priscoli; D. Pirone; G. Zanfardino; P. Memmolo; F. Bardozzo; L. Miccio; G. Ciaparrone; P. Ferraro; R. Tagliaferri","CNR - Institute of Applied Sciences and Intelligent Systems “E. Caianiello”, Pozzuoli, Italy; Neurone Lab, Department of Management and Innovation Systems (DISA-MIS), University of Salerno, Fisciano, Italy; Università di Napoli “Federico II”, Napoli, Italy; Neurone Lab, Department of Management and Innovation Systems (DISA-MIS), University of Salerno, Fisciano, Italy; CNR - Institute of Applied Sciences and Intelligent Systems “E. Caianiello”, Pozzuoli, Italy; Neurone Lab, Department of Management and Innovation Systems (DISA-MIS), University of Salerno, Fisciano, Italy; CNR - Institute of Applied Sciences and Intelligent Systems “E. Caianiello”, Pozzuoli, Italy; Neurone Lab, Department of Management and Innovation Systems (DISA-MIS), University of Salerno, Fisciano, Italy; CNR - Institute of Applied Sciences and Intelligent Systems “E. Caianiello”, Pozzuoli, Italy; Neurone Lab, Department of Management and Innovation Systems (DISA-MIS), University of Salerno, Fisciano, Italy","IEEE Journal of Selected Topics in Quantum Electronics","17 Mar 2022","2022","28","4: Mach. Learn. in Photon. Commun. and Meas. Syst.","1","10","Fourier ptychographic microscopy probes label-free samples from multiple angles and achieves super resolution phase-contrast imaging according to a synthetic aperture principle. Thus, it is particularly suitable for high-resolution imaging of tissue slides over a wide field of view. Recently, in order to make the optical setup robust against misalignments-induced artefacts, numerical multi-look has been added to the conventional phase retrieval process, thus allowing the elimination of related phase errors but at the cost of a long computational time. Here we train a generative adversarial network to emulate the process of complex amplitude estimation. Once trained, the network can accurately reconstruct in real-time Fourier ptychographic images acquired using a severely misaligned setup. We benchmarked the network by reconstructing images of animal neural tissue slides. Above all, we show that important morphometric information, relevant for diagnosis on neural tissues, are retrieved using the network output. These are in very good agreement with the parameters calculated from the ground-truth, thus speeding up significantly the quantitative phase-contrast analysis of tissue samples.","1558-4542","","10.1109/JSTQE.2022.3154236","ELIXIR IT Research Infrastructure Project; PON Ricerca and Innovazione; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9720941","Fourier ptychographic microscopy;deep learning;generative adversarial networks;phase imaging","Image reconstruction;Light emitting diodes;Imaging;Microscopy;Lighting;Optical imaging;Generators","amplitude estimation;biological tissues;biomedical optical imaging;image reconstruction;image resolution;learning (artificial intelligence);medical image processing;optical microscopy","misalignments-induced artefacts;numerical multilook;conventional phase retrieval process;related phase errors;long computational time;generative adversarial network;complex amplitude estimation;ptychographic images;severely misaligned setup;animal neural tissue slides;neural tissues;network output;quantitative phase-contrast analysis;tissue samples;misalignment resilient;real-time Fourier ptychographic microscopy reconstruction;biological tissue slides;Fourier ptychographic microscopy probes label-free samples;multiple angles;super resolution phase-contrast imaging;synthetic aperture principle;high-resolution imaging;optical setup robust","","7","","54","IEEE","24 Feb 2022","","","IEEE","IEEE Journals"
"Evaluation of GAN Architectures For Visualisation of HPV Viruses From Microscopic Images","X. W. Gao; X. Wen; D. Li; W. Liu; J. Xiong; B. Xu; J. Liu; H. Zhang; X. Liu","Department of Computer Science, Middlesex University, London, UK; Department of Nature Science, Middlesex University, London, UK; Department of Nature Science, Middlesex University, London, UK; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China","2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)","25 Jan 2022","2021","","","829","833","Human papillomavirus (HPV) remains a leading cause of virus-induced cancers and has a typical size of 52 to 55nm in diameter. Hence conventional light microscopy that usually sustains a resolution at $\sim$ 100nm per pixel falls short of detecting it. This study explores four state of the art generative adversarial networks (GANs) for visualising HPV. The evaluation is achieved by counting the HPV clusters that are corrected identified as well as drug treated cultured cells, i.e. no HPVs. The average sensitivity and specificity are 78.81%, 76.37%, 76.62% and 84.71% for CycleGAN, Pix2pix, ESRGAN and Pix2pixHD respectively. For ESRGAN, the training takes place by matching pairs between low and high resolution (x4) images. For the other three networks, the translation is performed from original raw images to their coloured maps that have undertaken Gaussian filtering in order to discern HPV clusters visually. Pix2pixHD appears to perform the best.","","978-1-6654-4337-1","10.1109/ICMLA52953.2021.00137","Royal Society; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680101","Generative adversarial network (GAN);super resolution;Human papilloma virus like particles (HPVLPs);Pix2pixHD;CycleGAN","Training;Drugs;Visualization;Image resolution;Filtering;Microscopy;Machine learning","bioinformatics;cancer;cellular biophysics;convolutional neural nets;data visualisation;drugs;Gaussian processes;image filtering;image matching;image resolution;microorganisms;optical microscopy","Pix2pixHD;GAN architectures;HPV viruses;human papillomavirus;virus-induced cancers;conventional light microscopy;generative adversarial networks;GANs;HPV clusters;cultured cells;Pix2pix;ESRGAN;HPV visualisation;CycleGAN;image matching;Gaussian filtering;size 52.0 nm to 55.0 nm;size 100.0 nm","","2","","14","IEEE","25 Jan 2022","","","IEEE","IEEE Conferences"
"Image Processing Using Multi-Code GAN Prior","J. Gu; Y. Shen; B. Zhou",The Chinese University of Hong Kong; The Chinese University of Hong Kong; The Chinese University of Hong Kong,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","3009","3018","Despite the success of Generative Adversarial Networks (GANs) in image synthesis, applying trained GAN models to real image processing remains challenging. Previous methods typically invert a target image back to the latent space either by back-propagation or by learning an additional encoder. However, the reconstructions from both of the methods are far from ideal. In this work, we propose a novel approach, called mGANprior, to incorporate the well-trained GANs as effective prior to a variety of image processing tasks. In particular, we employ multiple latent codes to generate multiple feature maps at some intermediate layer of the generator, then compose them with adaptive channel importance to recover the input image. Such an over-parameterization of the latent space significantly improves the image reconstruction quality, outperforming existing competitors. The resulting high-fidelity image reconstruction enables the trained GAN models as prior to many real-world applications, such as image colorization, super-resolution, image inpainting, and semantic manipulation. We further analyze the properties of the layer-wise representation learned by GAN models and shed light on what knowledge each layer is capable of representing.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157000","","Gallium nitride;Image reconstruction;Task analysis;Generators;Semantics;Image resolution","image colour analysis;image reconstruction;image resolution;learning (artificial intelligence);neural nets","multicode GAN prior;generative adversarial networks;image synthesis;latent space;image processing tasks;multiple latent codes;multiple feature maps;image reconstruction quality;high-fidelity image reconstruction;image colorization;image inpainting;back-propagation;mGANprior;intermediate layer;super-resolution;semantic manipulation;layer-wise representation","","96","","53","IEEE","5 Aug 2020","","","IEEE","IEEE Conferences"
"Multi-Attributed and Structured Text-to-Face Synthesis","R. Wadhawan; T. Drall; S. Singh; S. Chakraverty","Department of Computer Science and Engineering, Netaji Subhas Institute of Technology, New Delhi, India; Department of Computer Science and Engineering, Netaji Subhas Institute of Technology, New Delhi, India; Department of Computer Science and Engineering, Netaji Subhas Institute of Technology, New Delhi, India; Department of Computer Science and Engineering, Netaji Subhas University of Technology, New Delhi, India","2020 IEEE International Conference on Technology, Engineering, Management for Societal impact using Marketing, Entrepreneurship and Talent (TEMSMET)","6 Oct 2021","2020","","","1","7","Generative Adversarial Networks (GANs) have revolutionized image synthesis through many applications like face generation, photograph editing, and image super-resolution. Image synthesis using GANs has predominantly been uni-modal, with few approaches that can synthesize images from text or other data modes. Text-to-image synthesis, especially text-to-face synthesis, has promising use cases of robust face-generation from eye witness accounts and augmentation of the reading experience with visual cues. However, only a couple of datasets provide consolidated face data and textual descriptions for text-to-face synthesis. Moreover, these textual annotations are less extensive and descriptive, which reduces the diversity of faces generated from it. This paper empirically proves that increasing the number of facial attributes in each textual description helps GANs generate more diverse and real-looking faces. To prove this, we propose a new methodology that focuses on using structured textual descriptions. We also consolidate a Multi-Attributed and Structured Text-to-face (MAST) dataset consisting of high-quality images with structured textual annotations and make it available to researchers to experiment and build upon. Lastly, we report benchmark Fréchet’s Inception Distance (FID), Facial Semantic Similarity (FSS), and Facial Semantic Distance (FSD) scores for the MAST dataset.","","978-1-6654-0482-2","10.1109/TEMSMET51618.2020.9557583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557583","Machine Learning;Text-to-face synthesis;Generative Adversarial Network;Face Generation;MAST dataset;Crowdsourcing;Frechet’s Inception Distance","Frequency selective surfaces;Visualization;Image synthesis;Annotations;Semantics;Superresolution;Machine learning","face recognition;feature extraction;image resolution;text analysis","face generation;image super-resolution;GANs;Text-to-image synthesis;text-to-face synthesis;robust face-generation;consolidated face data;textual description;structured textual descriptions;Text-to-face dataset;high-quality images;structured textual annotations;Generative Adversarial Networks","","","","20","IEEE","6 Oct 2021","","","IEEE","IEEE Conferences"
"Tensor-Generative Adversarial Network with Two-Dimensional Sparse Coding: Application to Real-Time Indoor Localization","C. Zhu; L. Xu; X. -Y. Liu; F. Qian","The Center for Information Geoscience, University of Electronic Science and Technology of China; Dept. of Electrical Engineering, Columbia University; Dept. of Computer Science and Engineering, Shanghai Jiao Tong University; The Center for Information Geoscience, University of Electronic Science and Technology of China","2018 IEEE International Conference on Communications (ICC)","30 Jul 2018","2018","","","1","6","Localization technology is important for the development of indoor location-based services (LBS). Global Positioning System (GPS) becomes invalid in indoor environments due to the non-line-of-sight issue, so it is urgent to develop a real-time high-accuracy localization approach for smartphones. However, accurate localization is challenging due to issues such as real-time response requirements, limited fingerprint samples and mobile device storage. To address these problems, we propose a novel deep learning architecture: Tensor-Generative Adversarial Network (TGAN). We first introduce a transform-based 3D tensor to model fingerprint samples. Instead of those passive methods that construct a fingerprint database as a prior, our model applies artificial neural network with deep learning to train network classifiers and then gives out estimations. Then we propose a novel tensorbased super-resolution scheme using the generative adversarial network (GAN) that adopts sparse coding as the generator network and a residual learning network as the discriminator. Further, we analyze the performance of TGAN and implement a trace-based localization experiment, which achieves better performance. Compared to existing methods for smartphones indoor positioning, that are energy- consuming and high demands on devices, TGAN can give out an improved solution in localization accuracy, response time and implementation complexity.","1938-1883","978-1-5386-3180-5","10.1109/ICC.2018.8423008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423008","","Tensile stress;Dictionaries;Radio frequency;Generative adversarial networks;Encoding;Training;Matrix decomposition","fingerprint identification;Global Positioning System;image matching;image resolution;indoor communication;indoor radio;learning (artificial intelligence);mobile computing;mobile radio;neural nets;smart phones","Tensor-generative adversarial network;localization technology;Global Positioning System;mobile device storage;deep learning architecture;TGAN;fingerprint database;artificial neural network;network classifiers;residual learning network;sparse coding;location-based services;smartphones","","6","","16","IEEE","30 Jul 2018","","","IEEE","IEEE Conferences"
"CT-Scan Denoising Using a Charbonnier Loss Generative Adversarial Network","B. Gajera; S. R. Kapil; D. Ziaei; J. Mangalagiri; E. Siegel; D. Chapman","Department of Computer Science, University of Maryland, Baltimore County, Baltimore, MD, USA; Department of Computer Science, University of Maryland, Baltimore County, Baltimore, MD, USA; Department of Computer Science, University of Maryland, Baltimore County, Baltimore, MD, USA; Department of Computer Science, University of Maryland, Baltimore County, Baltimore, MD, USA; Department of Diagnostic Radiology and Nuclear Medicine, University of Maryland School of Medicine, Baltimore, MD, USA; Department of Computer Science, University of Maryland, Baltimore County, Baltimore, MD, USA","IEEE Access","14 Jun 2021","2021","9","","84093","84109","We propose a Generative Adversarial Network (GAN) optimized for noise reduction in CT-scans. The objective of CT scan denoising is to obtain higher quality imagery using a lower radiation exposure to the patient. Recent work in computer vision has shown that the use of Charbonnier distance as a term in the perceptual loss of a GAN can improve the performance of image reconstruction and video super-resolution. However, the use of a Charbonnier structural loss term has not yet been applied or evaluated for the purpose of CT scan denoising. Our proposed GAN makes use of a Wasserstein adversarial loss, a pretrained VGG19 perceptual loss, as well as a Charbonnier distance structural loss. We evaluate our approach using both applied Poisson noise distribution in order to simulate low-dose CT imagery, as well as using an anthropomorphic thoracic phantom at different exposure levels. Our evaluation criteria are Peek Signal to Noise (PSNR) as well as Structured Similarity (SSIM) of the denoised images, and we compare the results of our method versus recent state of the art deep denoising GANs. In addition, we report global noise through uniform soft tissue mediums. Our findings show that the incorporation of the Charbonnier Loss with the VGG-19 network improves the performance of the denoising as measured with the PSNR and SSIM, and that the method greatly reduces soft tissue noise to levels comparable to the NDCT scan.","2169-3536","","10.1109/ACCESS.2021.3087424","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9448108","CT-scan denoising;machine learning;computed tomography;medical diagnostic imaging;generative adversarial network","Noise reduction;Computed tomography;Image reconstruction;Indexes;Generative adversarial networks;X-ray imaging;PSNR","biological tissues;computerised tomography;image denoising;image reconstruction;image resolution;medical image processing;phantoms;Poisson distribution","CT-scan denoising;GAN;image reconstruction;video superresolution;Charbonnier structural loss term;Wasserstein adversarial loss;pretrained VGG19 perceptual loss;Charbonnier distance structural loss;applied Poisson noise distribution;low-dose CT imagery;denoised images;denoising GANs;VGG-19 network;NDCT scan;Charbonnier loss generative adversarial network;peek signal-to-noise","","4","","44","CCBY","7 Jun 2021","","","IEEE","IEEE Journals"
"MBD-GAN: Model-based image deblurring with a generative adversarial network","L. Song; E. Y. Lam","Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong SAR, China; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong SAR, China","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","7306","7313","This paper presents a methodology to tackle inverse imaging problems by leveraging the synergistic power of imaging model and deep learning. The premise is that while learning-based techniques have quickly become the methods of choice in various applications, they often ignore the prior knowledge embedded in imaging models. Incorporating the latter has the potential to improve the image estimation. Specifically, we first provide a mathematical basis of using generative adversarial network (GAN) in inverse imaging through considering an optimization framework. Then, we develop the specific architecture that connects the generator and discriminator networks with the imaging model. While this technique can be applied to a variety of problems, from image reconstruction to super-resolution, we take image deblurring as the example here, where we show in detail the implementation and experimental results of what we call the model-based deblurring GAN (MBD-GAN).","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9411979","University of Hong Kong(grant numbers:104005438,104005864); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9411979","","Superresolution;Imaging;Generative adversarial networks;Generators;Robustness;Image restoration;Mathematical model","deep learning (artificial intelligence);image reconstruction;image resolution;neural nets","MBD-GAN;generative adversarial network;inverse imaging problems;imaging model;deep learning;learning-based techniques;image estimation;discriminator networks;image reconstruction;model-based deblurring GAN;model-based image deblurring","","1","","43","IEEE","5 May 2021","","","IEEE","IEEE Conferences"
"Learning-Assisted Inversion for Solving Nonlinear Inverse Scattering Problem","K. Xu; Z. Qian; Y. Zhong; J. Su; H. Gao; W. Li","School of Mechatronic Engineering, China University of Mining and Technology, Xuzhou, China; Ministry of Education, Engineering Research Center of Smart Microsensors and Microsystems, Hangzhou Dianzi University, Hangzhou, China; Department of Physics and Technology, UiT The Arctic University of Norway, Tromso, Norway; Ministry of Education, College of Electronics and Information, Key Laboratory of RF Circuit and System, Hangzhou Dianzi University, Hangzhou, China; Ministry of Education, College of Electronics and Information, Key Laboratory of RF Circuit and System, Hangzhou Dianzi University, Hangzhou, China; Ministry of Education, College of Electronics and Information, Key Laboratory of RF Circuit and System, Hangzhou Dianzi University, Hangzhou, China","IEEE Transactions on Microwave Theory and Techniques","","2022","PP","99","1","12","Solving inverse scattering problems (ISPs) is challenging because of its intrinsic ill-posedness and the nonlinearity. When dealing with highly nonlinear ISPs, i.e., those scatterers with high contrast and/or electrically large size, the traditional iterative nonlinear inversion methods converge slowly and take lots of computation time, even maybe trapped into local wrong solution. To alleviate the above challenges, a learning-assisted (LA) inversion approach termed as the LA inversion method (LAIM) with advanced generative adversarial network (GAN) in virtue of a new recently established contraction integral equation for inversion (CIE-I) is proposed to achieve a good balance between the computational efficiency and the accuracy of solving highly nonlinear ISPs. The preliminary profiles composed of only small amount of low-frequency components can be got efficiently by the Fourier bases expansion of CIE-I inversion (FBE-CIE-I). The physically exacted information can be taken as the input of the neural network to recover super-resolution image with more high-frequency components. A weighted loss function composed of the adversarial loss, mean absolute percentage error (MAPE), and structural similarity (SSIM) is used under the pix2pix GAN framework. In addition, the self-attention module is used at the end of the generator network to capture the physical distance information between two pixels and enhance the inversion accuracy of the feature scatterers. To further improve the inversion efficiency, the data-driven method (DDM) is used to achieve real-time imaging by cascading U-net and pix2pix GAN, where U-net is used to replace FBE-CIE-I in the LAIM. Compared with other LA inversion, both the synthetic and experimental examples have validated the merits of the proposed LAIM and DDM.","1557-9670","","10.1109/TMTT.2022.3228945","China Postdoctoral Science Foundation(grant numbers:2019M661984); National Natural Science Foundation of China(grant numbers:61971174,62293493); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9996181","Highly nonlinear;inverse scattering;pix2pix generative adversarial network (GAN);real-time imaging;self-attention;structural similarity (SSIM)","Generative adversarial networks;Imaging;Scattering;Real-time systems;Mathematical models;Iterative methods;Image reconstruction","","","","","","","IEEE","21 Dec 2022","","","IEEE","IEEE Early Access Articles"
"Concatenate Word Embedding for Text to Image through Generative Adversarial Network","R. Khalida; S. Madenda; S. Harmanto; I. M. Wiryana","Department of Informatics Engineering, Gunadarma University, Depok, Indonesia; Department of Informatics Engineering, Gunadarma University, Depok, Indonesia; Department of Informatics Engineering, Gunadarma University, Depok, Indonesia; Department of Informatics Engineering, Gunadarma University, Depok, Indonesia","2022 International Conference on Informatics, Multimedia, Cyber and Information System (ICIMCIS)","20 Jan 2023","2022","","","259","264","Since the explosion of deep learning, automatic image generation from natural language is highly desirable through artificial intelligence (AI) as it makes it easier for users to create visually rich images through the ease of language. One of the methods used to generate images from text is GAN, in this study using word embedding is to process natural language and develop GAN by concatenate word embedding. In this work, we carry out our early-stage research which is to explore the simple technique of concatenate word embedding as the input of the GAN neural network. We show that this model is a novelty for the GAN model with the concept of multimodal input that is able to generate text to image and is expected to improve performance on a stronger GAN. Based on the explanation of our research method, this model can be implemented and can be developed for various GAN tasks such as style transfer, image to image, face inpainting or image repair semantically, and super resolution.","","978-1-6654-7327-9","10.1109/ICIMCIS56303.2022.10017727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10017727","text;image;word embedding;GAN","Training;Vocabulary;Image resolution;Computational modeling;Natural languages;Maintenance engineering;Generative adversarial networks","deep learning (artificial intelligence);feature extraction;image resolution;natural language processing;text analysis","AI;artificial intelligence;automatic image generation;concatenate word embedding;deep learning;GAN neural network;GAN tasks;generative adversarial network;natural language","","","","22","IEEE","20 Jan 2023","","","IEEE","IEEE Conferences"
"SRARNet: A Unified Framework for Joint Superresolution and Aircraft Recognition","W. Tang; C. Deng; Y. Han; Y. Huang; B. Zhao","Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Information and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, School of Information and Electronics, Beijing Institute of Technology, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","6 Jan 2021","2021","14","","327","336","Aircraft recognition in high-resolution remote sensing images has rapidly progressed with the advance of convolutional neural networks (CNNs). However, the previous CNN-based methods may not work well for recognizing aircraft in low-resolution remote sensing images because the blurred aircraft in these images offer insufficient details to distinguish them from similar types of targets. An intuitive solution is to introduce superresolution preprocessing. However, conventional superresolution methods mainly focus on reconstructing natural images with detailed texture rather than constructing a high-resolution object with strong discriminative information for the recognition task. To address these problems, we propose a unified framework for joint superresolution and aircraft recognition (Joint-SRARNet) that tries to improve the recognition performance by generating discriminative, high-resolution aircraft from low-resolution remote sensing images. Technically, this network integrates superresolution and recognition tasks into the generative adversarial network (GAN) framework through a joint loss function. The generator is constructed as a joint superresolution and refining subnetwork that can upsample small blurred images into high-resolution ones and restore high-frequency information. In the discriminator, we introduce a new classification loss function that forces the discriminator to distinguish between real and fake images while recognizing the type of aircraft. In addition, the classification loss function is back-propagated to the generator to obtain high-resolution images with discriminative information for easier recognition. Extensive experiments on the challenging multitype aircraft of remote sensing images (MTARSI) dataset demonstrate the effectiveness of the proposed method in restoring a clear super-resolved image from a small blurred image and significant improvement in the recognition performance. To our knowledge, this is the first work on joint superresolution and aircraft recognition tasks.","2151-1535","","10.1109/JSTARS.2020.3037225","National Natural Science Foundation of China(grant numbers:91838303,91738302); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9254000","Aircraft recognition;multitask GAN;superresolution","Aircraft;Image recognition;Task analysis;Remote sensing;Generative adversarial networks;Aircraft manufacture;Generators","backpropagation;convolutional neural nets;image classification;image resolution;image restoration;image sampling;object recognition;remote sensing","convolutional neural networks;SRARNet;GAN framework;CNN-based methods;generative adversarial network framework;high-resolution aircraft;natural images;conventional superresolution methods;blurred aircraft;low-resolution remote sensing images;high-resolution remote sensing images;aircraft recognition;blurred image","","4","","42","CCBY","10 Nov 2020","","","IEEE","IEEE Journals"
"CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training","J. Bao; D. Chen; F. Wen; H. Li; G. Hua",University of Science and Technology of China; NA; Microsoft Research; University of Science and Technology of China; Microsoft Research,"2017 IEEE International Conference on Computer Vision (ICCV)","25 Dec 2017","2017","","","2764","2773","We present variational generative adversarial networks, a general learning framework that combines a variational auto-encoder with a generative adversarial network, for synthesizing images in fine-grained categories, such as faces of a specific person or objects in a category. Our approach models an image as a composition of label and latent attributes in a probabilistic model. By varying the fine-grained category label fed into the resulting generative model, we can generate images in a specific category with randomly drawn values on a latent attribute vector. Our approach has two novel aspects. First, we adopt a cross entropy loss for the discriminative and classifier network, but a mean discrepancy objective for the generative network. This kind of asymmetric loss function makes the GAN training more stable. Second, we adopt an encoder network to learn the relationship between the latent space and the real image space, and use pairwise feature matching to keep the structure of generated images. We experiment with natural images of faces, flowers, and birds, and demonstrate that the proposed models are capable of generating realistic and diverse samples with fine-grained category labels. We further show that our models can be applied to other tasks, such as image inpainting, super-resolution, and data augmentation for training better face recognition models.","2380-7504","978-1-5386-1032-9","10.1109/ICCV.2017.299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8237561","","Gallium nitride;Training;Hidden Markov models;Data models;Generators;Image generation","entropy;face recognition;feature extraction;image classification;image coding;image matching;learning (artificial intelligence)","CVAE-GAN;fine-grained image generation;asymmetric training;variational generative adversarial networks;general learning framework;variational auto-encoder;fine-grained categories;probabilistic model;fine-grained category label;latent attribute vector;cross entropy loss;classifier network;mean discrepancy objective;generative network;asymmetric loss function;GAN training;encoder network;natural images;image inpainting;face recognition models","","247","","48","IEEE","25 Dec 2017","","","IEEE","IEEE Conferences"
"Thermal Image Reconstruction Using Deep Learning","G. Batchuluun; Y. W. Lee; D. T. Nguyen; T. D. Pham; K. R. Park","Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea; Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea; Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea; Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea; Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea","IEEE Access","20 Jul 2020","2020","8","","126839","126858","A high-resolution thermal camera is very expensive and is thus difficult to be used. Furthermore, thermal images become blurred in various cases of object motion, camera shaking, and camera defocusing. To solve these problems, a previous super-resolution restoration (SRR) technique converting a thermal image acquired by a low-resolution camera into a high-resolution one, and a thermal image deblurring method have been researched. However, existing studies were performed based on 1-channel (grayscale) images. In addition, a large-sized and whole image has been used in the existing thermal image deblurring methods, which causes lower deblurring performance. In this study, we propose novel SRR and deblurring methods. The proposed deblurring method is conducted based on small region images. The proposed methods are also conducted using 3-channel (color) thermal images and generative adversarial networks. In addition, the performances of this method are compared in various color spaces (RGB, Gray, HLS, HSV, Lab, Luv, XYZ, YCrCb), image sizes, and thermal databases. Through experiments using self-collected databases and open databases, it was confirmed that the proposed methods show better performance than the state-of-the-art methods.","2169-3536","","10.1109/ACCESS.2020.3007896","National Research Foundation of Korea (NRF) funded by the Ministry of Science and ICT (MSIT) through the Basic Science Research Program(grant numbers:NRF-2019R1F1A1041123); MSIT, South Korea, through the Information Technology Research Center (ITRC) Support Program, supervised by the Institute of Information & Communications Technology Planning & Evaluation (IITP)(grant numbers:IITP-2020-2020-0-01789); NRF funded by the MSIT through the Basic Science Research Program(grant numbers:NRF-2020R1A2C1006179); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136691","Thermal image;super-resolution reconstruction;deep learning;generative adversarial network;image deblurring","Cameras;Image restoration;Image reconstruction;Image color analysis;Gallium nitride;Deep learning","cameras;image colour analysis;image reconstruction;image resolution;image restoration;infrared imaging;learning (artificial intelligence)","large-sized image;whole image;SRR;3-channel thermal images;image sizes;thermal databases;thermal image reconstruction;high-resolution thermal camera;camera shaking;camera defocusing;low-resolution camera;thermal image deblurring method;1-channel images;super-resolution restoration technique;small region images","","9","","93","CCBY","8 Jul 2020","","","IEEE","IEEE Journals"
"DUG-RECON: A Framework for Direct Image Reconstruction Using Convolutional Generative Networks","V. S. S. Kandarpa; A. Bousse; D. Benoit; D. Visvikis","LaTIM, INSERM, UMR 1101, Université de Bretagne Occidentale, Brest, France; LaTIM, INSERM, UMR 1101, Université de Bretagne Occidentale, Brest, France; LaTIM, INSERM, UMR 1101, Université de Bretagne Occidentale, Brest, France; LaTIM, INSERM, UMR 1101, Université de Bretagne Occidentale, Brest, France","IEEE Transactions on Radiation and Plasma Medical Sciences","30 Dec 2020","2021","5","1","44","53","This article explores convolutional generative networks as an alternative to iterative reconstruction algorithms in medical image reconstruction. The task of medical image reconstruction involves mapping of projection domain data collected from the detector to the image domain. This mapping is done typically through iterative reconstruction algorithms which are time consuming and computationally expensive. Trained deep learning networks provide faster outputs as proven in various tasks across computer vision. In this work, we propose a direct reconstruction framework exclusively with deep learning architectures. The proposed framework consists of three segments, namely, denoising, reconstruction, and super resolution (SR). The denoising and the SR segments act as processing steps. The reconstruction segment consists of a novel double U-Net generator (DUG) which learns the sinogram-to-image transformation. This entire network was trained on positron emission tomography (PET) and computed tomography (CT) images. The reconstruction framework approximates 2-D mapping from the projection domain to the image domain. The architecture proposed in this proof-of-concept work is a novel approach to direct image reconstruction; further improvement is required to implement it in a clinical setting.","2469-7303","","10.1109/TRPMS.2020.3033172","French Ministry of Education and Research through a Ph.D. Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9235522","Deep learning;generative adversarial networks (GANs);medical image reconstruction","Image reconstruction;Deep learning;Computer architecture;Image segmentation;Biomedical imaging;Noise reduction;Positron emission tomography","computerised tomography;convolutional neural nets;image denoising;image reconstruction;image resolution;image segmentation;iterative methods;learning (artificial intelligence);medical image processing;positron emission tomography","DUG-RECON;direct image reconstruction;convolutional generative networks;iterative reconstruction algorithms;medical image reconstruction;projection domain data;image domain;trained deep learning networks;direct reconstruction framework;deep learning architectures;denoising reconstruction;U-Net generator;sinogram-to-image transformation;computed tomography images;positron emission tomography;PET;CT images","","12","","32","IEEE","22 Oct 2020","","","IEEE","IEEE Journals"
"D2SC-GAN: Dual Deep-Shallow Channeled Generative Adversarial Network, for Resolving Low-Resolution Faces for Recognition in Classroom Scenarios","A. Bhattacharjee; S. Das","Department of Computer Science and Engineering, Visualization and Perception Laboratory, IIT Madras, Chennai, India; Department of Computer Science and Engineering, Visualization and Perception Laboratory, IIT Madras, Chennai, India","IEEE Transactions on Biometrics, Behavior, and Identity Science","22 Jun 2020","2020","2","3","223","234","Face Recognition using convolutional neural networks have achieved considerable success in constrained environments in the recent past. However, the performance of these methods deteriorates in case of mismatch of training and test distributions, under classroom/surveillance scenarios. These test (probe) samples suffer from degradations such as noise, poor illumination, pose variations, occlusion, low-resolution (LR), blur as well as aliasing, when compared to the crisp, rich training (gallery) set, comprising mostly of high-resolution (HR) mugshot images captured in laboratory settings. To cope with this scenario, we propose a novel dual deep-shallow channeled generative adversarial network (D2SC-GAN) which performs supervised domain adaptation (DA) by mapping LR degraded probe samples to their corresponding HR gallery-like counterparts to perform closed-set face recognition. D2SC-GAN uses a multi-component loss function comprising of multi-resolution patchwise MSE and normalized chi-squared distance loss functions, along with a Kullback-Leibler divergence based loss function. Moreover, we propose a novel classroom face dataset called the Indian Classroom Face Dataset (ICFD), which, to the best of our knowledge, is a first of its kind and will be helpful to explore the challenges of face recognition when used for automatically recording the attendance in classroom conditions. The proposed network achieves superior results on five real-world face datasets when compared with recent state-of-the-art deep as well as shallow supervised domain adaptation (DA), super-resolution (SR), and degraded face recognition (DFR) methods, which show the effectiveness of our proposed method.","2637-6407","","10.1109/TBIOM.2020.2983524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9050650","Face recognition;face generation;generative adversarial networks;convolutional neural networks;classroom FR","Generators;Face recognition;Probes;Task analysis;Training;Image reconstruction","face recognition;image resolution","D2SC-GAN;dual deep-shallow channeled generative adversarial network;convolutional neural networks;probe samples;multicomponent loss function;multiresolution patchwise MSE;Kullback-Leibler divergence based loss function;real-world face datasets;high-resolution mugshot imaging;HR mugshot imaging;supervised domain adaptation;DA;HR gallery-like counterparts;ICFD;Indian classroom face dataset;DFR method;degraded face recognition methods;normalized chisquared distance loss functions","","5","","56","IEEE","30 Mar 2020","","","IEEE","IEEE Journals"
"GHOST—A New Face Swap Approach for Image and Video Domains","A. Groshev; A. Maltseva; D. Chesakov; A. Kuznetsov; D. Dimitrov","Artificial Intelligence Research Institute (AIRI), Moscow, Russia; Artificial Intelligence Research Institute (AIRI), Moscow, Russia; Artificial Intelligence Research Institute (AIRI), Moscow, Russia; Artificial Intelligence Research Institute (AIRI), Moscow, Russia; Artificial Intelligence Research Institute (AIRI), Moscow, Russia","IEEE Access","16 Aug 2022","2022","10","","83452","83462","Deep fake stands for a face swapping algorithm where the source and target can be an image or a video. Researchers have investigated sophisticated generative adversarial networks (GAN), autoencoders, and other approaches to establish precise and robust algorithms for face swapping. However the achieved results are far from perfect in terms of human and visual evaluation. In this study, we propose a new one-shot pipeline for image-to-image and image-to-video face swap solutions - GHOST (Generative High-fidelity One Shot Transfer). We take the FaceShifter (image-to-image) architecture as a baseline approach and propose several major architecture improvements which include a new eye-based loss function, face mask smooth algorithm, a new face swap pipeline for image-to-video face transfer, a new stabilization technique to decrease face jittering on adjacent frames and a super-resolution stage. In the experimental stage, we show that our solution outperforms SoTA face swap architectures in terms of ID retrieval (+1.5% improvement), shape (the second best value) and eye gaze preserving (+1% improvement) metrics. We also established an ablation study for our solution to estimate the contribution of pipeline stages to the overall accuracy, which showed that the eye loss leads to 2% improvement in the ID retrieval and 45% improvement in the eye gaze preserving.","2169-3536","","10.1109/ACCESS.2022.3196668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9851423","Deep fake;face swap;GHOST;AEI-Net;eye loss;face mask smooth;stabilization;super resolution","Faces;Face recognition;Pipelines;Deepfakes;Training;Measurement;Image reconstruction","eye;face recognition;image enhancement;image processing;image resolution;motion estimation;shape recognition;smoothing methods;video signal processing","image-to-image;baseline approach;architecture improvements;eye-based loss function;smooth algorithm;face swap pipeline;image-to-video face transfer;face jittering;face swap architectures;GHOST-a new face swap approach;video domains;face swapping algorithm;autoencoders;precise algorithms;robust algorithms;one-shot pipeline;image-to-video face swap solutions;Generative High-fidelity;Shot Transfer","","","","30","CCBY","5 Aug 2022","","","IEEE","IEEE Journals"
"Perceptual-DualGAN: Perceptual Losses for Image to Image Translation with Generative Adversarial Nets","X. Qu; X. Wang; Z. Wang; L. Wang; L. Zhang","School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","8","Thinking about cross-domain image-to-image translation problems, where an input image belonging to domain U is transformed into an output image belonging to another domain V. A series of typical tasks, such as style transformation, colorization, super-resolution, can be seen as cross-domain image-to-image translation tasks. Recent methods such as Conditional Generative Adversarial Networks (cGANs) make big progress in this field, but they require paired image data, which is hard to obtain. The DualGAN (Unsupervised Dual Learning for Image-to-Image Translation) architecture was proposed to solve the issue of lack of paired data. But the pixel-level reconstruction losses of DualGAN are simple. In this paper, we replace the pixel-level reconstruction losses with the perceptual reconstruction losses, and propose a more advanced framework for cross-domain image-to-image translation named perceptual-DualGAN. The perceptual reconstruction losses consist of feature reconstruction losses and style reconstruction losses, both of them are computed from pretrained loss networks. Experiments on multiple image translation tasks show that our framework almost performs superior to other methods. And the results of experiments illustrate that our framework can generate more realistic and more natural photos.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489108","cross-domain image-to-image translation;perceptual losses;GAN;generative model","Image reconstruction;Generators;Task analysis;Gallium nitride;Training;Loss measurement;Convolutional neural networks","feature extraction;image reconstruction;image representation;learning (artificial intelligence);neural nets","image data;pixel-level reconstruction losses;perceptual reconstruction losses;perceptual-DualGAN;feature reconstruction losses;style reconstruction losses;generative adversarial nets;cross-domain image-to-image translation problems;input image;output image;unsupervised dual learning for image-to-image translation","","5","","32","IEEE","14 Oct 2018","","","IEEE","IEEE Conferences"
