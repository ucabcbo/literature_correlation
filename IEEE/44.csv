"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Two-Stage Cross-Modality Transfer Learning Method for Military-Civilian SAR Ship Recognition","Y. Song; J. Li; P. Gao; L. Li; T. Tian; J. Tian","School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","18 Apr 2022","2022","19","","1","5","Military-civilian attribute recognition of ships in synthetic aperture radar (SAR) imagery plays an important role in marine surveillance. However, high-quality labeled data are hard to obtain for SAR ships, which hinder the development of deep learning models. Considering that models directly transferred from labeled optical images cannot achieve satisfactory performance for SAR applications due to the great discrepancy of different modalities, we propose a two-stage transfer learning method by combining the data-level and feature-level knowledge transfer. First, CycleGAN is adopted in the first stage to transfer the labeled optical image domain to the intermediate SAR-like image domain with the attribute labels. Then, a novel network called Domain Transfer using Adversarial learning and Metric learning (DTAM) is proposed to realize the task of military-civilian ship recognition by the domain adaption of the intermediate domain and the target SAR domain with joint adversarial learning and metric learning. To validate the proposed method, we establish a high-resolution SAR ship recognition dataset (HRSSRD), containing SAR and optical images of military and civilian ships. The experimental results show that the proposed two-stage architecture exhibits promising performance on the problem of SAR military-civilian ship recognition.","1558-0571","","10.1109/LGRS.2022.3162707","National Natural Science Foundation of China(grant numbers:42071339); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9743385","Domain adaption;military-civilian ship recognition;optical remote sensing images;synthetic aperture radar (SAR) imagery;transfer learning","Optical imaging;Synthetic aperture radar;Marine vehicles;Optical sensors;Image recognition;Task analysis;Radar polarimetry","image classification;learning (artificial intelligence);object detection;radar imaging;ships;synthetic aperture radar","military-civilian SAR ship recognition;synthetic aperture radar imagery;marine surveillance;high-quality labeled data;SAR ships;deep learning models;labeled optical images;SAR applications;two-stage transfer learning method;data-level;feature-level knowledge transfer;labeled optical image domain;intermediate SAR-like image domain;attribute labels;Domain Transfer;metric learning;domain adaption;intermediate domain;target SAR domain;joint adversarial learning;high-resolution SAR ship recognition dataset;military ships;civilian ships;two-stage architecture;SAR military-civilian ship recognition;stage cross-modality Transfer learning method","","3","","18","IEEE","28 Mar 2022","","","IEEE","IEEE Journals"
"Use of Sentinel-l and Sentinel-2 for Monitoring Illegal Fishing Off Ghana","A. Kurekin; B. Loveday; O. Clements; G. Quartly; P. Miller; G. Wiafe; K. A. Agyekum","Plymouth Marine Laboratory, Plymouth, UK; Plymouth Marine Laboratory, Plymouth, UK; Plymouth Marine Laboratory, Plymouth, UK; Plymouth Marine Laboratory, Plymouth, UK; Plymouth Marine Laboratory, Plymouth, UK; Coastal & Marine Resources Management Centre, College of Basic and Applied Sciences, Legon, Ghana; Coastal & Marine Resources Management Centre, College of Basic and Applied Sciences, Legon, Ghana","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","6875","6878","An efficient and inexpensive service has been developed for the monitoring of fishing vessels in West Africa using Earth Observation (EO) data. The service makes use of fast-delivery data from the Synthetic Aperture Radar (SAR) instrument on Sentinel-l and the Multi Spectral Imager (MSI) on Sentinel-2, detecting objects that differ markedly from their immediate background using a constant false alarm rate (CFAR) test. The selected objects are then discounted from further analysis if they fall within the bespoke land mask or can be shown from time series analysis to be static (signals associated with jetties, oil platforms and “ghost objects” arising from very bright land targets). Detections are matched to, and verified by, AIS data, which provides location and dimensions of ships that are legally in the region. Both matched and un-matched data are then displayed on a web portal for use by the Gulf of Guinea (GoG) state authorities.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8519539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519539","Synthetic Aperture Radar;vessel detection;illegal fishing;automatic identification system","Artificial intelligence;Synthetic aperture radar;Monitoring;Cloud computing;Marine vehicles;Aquaculture;Optical sensors","object detection;radar detection;radar imaging;ships;synthetic aperture radar;time series","illegal fishing;Gulf of Guinea state authorities;Synthetic Aperture Radar;constant false alarm rate test;MultiSpectral Imager;Synthetic Aperture Radar instrument;fast-delivery data;Earth Observation data;West Africa;fishing vessels;inexpensive service;Sentinel-2;Sentinel-1;un-matched data;AIS data;ghost objects;time series analysis;bespoke land mask","","3","","9","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Flood Mapping with SAR and Multi-Spectral Remote Sensing Images Based on Weighted Evidential Fusion","X. Chen; Y. Cui; C. Wen; M. Zheng; Y. Gao; J. Li","School of Earth and Space Sciences, Peking University, Beijing, China; School of Earth and Space Sciences, Peking University, Beijing, China; Information Center of Ministry of Civil Affairs of the People's Republic of China, Beijing, China; Information Center of Ministry of Civil Affairs of the People's Republic of China, Beijing, China; Information Center of Ministry of Civil Affairs of the People's Republic of China, Beijing, China; Faculty of Geographical Science, Beijing Normal University, Beijing, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","2519","2522","Synthetic Aperture Radar (SAR) and Multi-spectral (MS) remote sensing images are commonly used for flood mapping. SAR images can provide valid backscattering measurements of inundated areas through cloud cover, while MS data is able to monitor the spectral changes of ground surface, but usually affected by clouds. The complementary characteristics of the two data indicate the potential of their combining application for flood monitoring in emergency. This paper proposes a novel weighted evidential fusion method to take full advantages of the SAR and MS data for change detection during the flood. First, pre-processing and classification are performed with the SAR and MS data, independently. Second, a modified PCR6 rule for evidential fusion is proposed, which introduces the confusion matrixes to calculate the weight of evidences so that the conflicting degree in the fusion process can be reduced. Then, the flood inundating, standing and receding patterns are identified, which can be used to describe the flooding process in details. Practically, the proposed method is applied to flood mapping of the Typhoon Rumbia in 2018, in Shouguang City, China. The experiments show that the proposed fusion scheme efficiently use both of the SAR and MS data, and improve the flood mapping accuracy.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324158","SAR;multi-spectral;change detection;evidential fusion;flood monitoring;remote sensing","Floods;Synthetic aperture radar;Remote sensing;Land surface;Earth;Radar polarimetry;Monitoring","floods;geophysical image processing;hydrological techniques;image classification;image fusion;radar imaging;remote sensing by radar;synthetic aperture radar","modified PCR6 rule;confusion matrixes;AD 2018;Typhoon Rumbia;China;Shouguang City;flooding process;flood inundating;fusion process;evidential fusion method;flood monitoring;spectral changes;cloud cover;backscattering measurements;SAR images;multispectral remote sensing images;flood mapping accuracy;MS data;fusion scheme","","","","6","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Unsupervised Categorization of Forest-Cover Using Multi-Spectral and Hybrid Polarimetric Sar Images","S. M. Aswatha; R. Mahapatra; J. Mukhopadhyay; P. K. Biswas; S. Aikat; A. Misra","Indian Institute of Technology, Kharagpur, India; Indian Institute of Technology, Kharagpur, India; Indian Institute of Technology, Kharagpur, India; Indian Institute of Technology, Kharagpur, India; Indian Institute of Technology, Kharagpur, India; Space Applications Centre, Ahmedabad, India","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2603","2606","In this paper, we propose to distinguish forest-cover in an unsupervised fashion by a combination of passive multi-spectral imagery and active hybrid polarized SAR data. At first, multi-spectral imagery (MSI) is used to separate general vegetation region (e.g., forest, mature grassland, and pre-harvest agricultural fields) from the imaged scene using spectral slopes based rules and support vector machine technique. Then, hybrid polarimetric SAR image of the same region (acquired with a common time stamp) is clustered into three scatter classes, namely, surface, volume, and dihedral, using Stokes parameters based m - δ decomposition. Forest cover is extracted by bi-labeled pixels of the study site that correspond to vegetation (in MSI) and volume scatter (in SAR), which forms a community level classification of forest region. Further, using Wishart derived mean-shift clustering technique, we segregate possible categories of forest clusters within the mapped forest region to obtain a sub-community level classification. Discernible spectral and scattering characteristics of remotely sensed images are explored in our work for identifying forest regions and their possible categories. The proposed method is automated by freeing the manual supervision in selecting seed pixels for training any machine learning technique.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898870","Forest classification;hybrid polarimetric SAR image;multi-spectral image;unsupervised classification;Wishart mean-shift","Forestry;Radar polarimetry;Vegetation mapping;Remote sensing;Covariance matrices;Synthetic aperture radar;Manuals","agriculture;forestry;geophysical image processing;image classification;learning (artificial intelligence);radar imaging;radar polarimetry;remote sensing by radar;synthetic aperture radar;vegetation mapping","machine learning technique;community level classification;volume scatter;bi-labeled pixels;mature grassland;pre-harvest agricultural fields;separate general vegetation region;active hybrid polarized SAR data;passive multispectral imagery;unsupervised fashion;forest-cover;unsupervised categorization;remotely sensed images;scattering characteristics;discernible spectral characteristics;mapped forest region;forest clusters;Wishart derived mean-shift clustering technique;MSI;Stokes parameters;hybrid polarimetric SAR image;support vector machine technique;spectral slopes;imaged scene","","1","","11","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"SAR Target Recognition with Deep Learning","R. J. Soldin","Lockheed Martin Space, King of Prussia, Pennsylvania","2018 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)","9 May 2019","2018","","","1","8","The automated detection and classification of objects in imagery is an important topic for many applications in remote sensing. These can include the counting of cars and ships and the tracking of military vehicles for the defense and intelligence industry. Synthetic aperture radar (SAR) provides day/night and all-weather imaging capabilities. SAR is a powerful data source for Deep Learning (DL) algorithms to provide automatic target recognition (ATR) capabilities. DL classification was shown to be extremely effective on multi-spectral satellite imagery during the IARPA Functional Map of the World (fMoW). In our work we look to extend these techniques to SAR. We start by applying ResNet-18 to the Moving and Stationary Target Acquisition and Recognition (MSTAR) dataset. The MSTAR program, sponsored by DARPA and AFRL, consists of SAR collections of military style targets using an aerial X-band radar with one-foot resolution. We achieved an overall classification accuracy of 99% on 10 different classes of targets, confirming previously published results. We then extend this classifier to investigate an emerging target and the effects of limited training data on system performance.","2332-5615","978-1-5386-9306-3","10.1109/AIPR.2018.8707419","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8707419","ATR;target recognition;artificial intelligence;AI;deep learning;CNN;neural networks;machine learning;image understanding;recognition;classification;synthetic aperture radar","Training;Synthetic aperture radar;Classification algorithms;Data models;Target recognition;Imaging;Image resolution","learning (artificial intelligence);military computing;military radar;military vehicles;object detection;radar imaging;radar target recognition;synthetic aperture radar","SAR target recognition;deep learning;remote sensing;military vehicles;intelligence industry;synthetic aperture radar;DL classification;multispectral satellite imagery;MSTAR program;SAR collections;aerial X-band radar;all-weather imaging;automatic target recognition;recognition dataset;automated classification;IARPA functional map;ResNet-18","","4","","15","IEEE","9 May 2019","","","IEEE","IEEE Conferences"
"SEFEPNet: Scale Expansion and Feature Enhancement Pyramid Network for SAR Aircraft Detection With Small Sample Dataset","P. Zhang; H. Xu; T. Tian; P. Gao; L. Li; T. Zhao; N. Zhang; J. Tian","School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China; School of Artificial Intelligence Automation, Huazhong University of Science Technology, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","10 May 2022","2022","15","","3365","3375","Aircraft detection in synthetic aperture radar (SAR) images is still a challenging research task because of the insufficient public data, the difficulty of multiscale target detection, and the complexity of background interference. In this article, we construct a public SAR aircraft detection dataset (SADD) with complex background and interference objects to facilitate the research in SAR aircraft detection. Then, we propose the scale expansion and feature enhancement pyramid network as the SADD baseline. It uses a four-scale fusion method to combine the shallow position information with the deep semantic information, effectively adapting to the multiscale target detection in SAR images, significantly improving the detection effect of small targets. The feature enhancement pyramid structure is connected behind the backbone network to weaken the background texture and highlight the target to achieve feature enhancement, improving the ability to extract target features in complex backgrounds. Finally, to further improve the detection performance of the small-scale SAR aircraft dataset, we propose a domain adaptive transfer learning method. Experiments on SADD show that this method can significantly improve the recall rate and F1 score. At the same time, we find that the transfer effect of using homologous but different types of targets as the source domain is better than those of heterologous but same types of targets in SAR aircraft detection, which is instructive for future research.","2151-1535","","10.1109/JSTARS.2022.3169339","National Natural Science Foundation of China(grant numbers:42071339); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761751","Feature enhancement pyramid (FEP);synthetic aperture radar (SAR) aircraft detection;transfer learning","Aircraft;Feature extraction;Synthetic aperture radar;Transfer learning;Atmospheric modeling;Object detection;Data models","aircraft;feature extraction;image enhancement;learning (artificial intelligence);neural nets;object detection;radar detection;radar imaging;synthetic aperture radar","target features;scale expansion;feature enhancement pyramid network;multiscale target detection;public SAR aircraft detection dataset;interference objects;four-scale fusion method;SAR images;feature enhancement pyramid structure;SEFEPNet;SAR aircraft detection;small sample dataset;aircraft detection;SADD;complex background objects;deep semantic information;backbone network;background texture;recall rate improvement;F1 score improvement;adaptive transfer learning method","","3","","44","CCBY","21 Apr 2022","","","IEEE","IEEE Journals"
"Retrieval and multi-temporal characterization of oil spills from multi-sensor earth observation imagery","R. Pelich; T. V. La; M. Chini; P. Matgen","Environmental Research and Innovation department, Luxembourg Institute of Science and Technology, Belvaux, Luxembourg; Environmental Research and Innovation department, Luxembourg Institute of Science and Technology, Belvaux, Luxembourg; Environmental Research and Innovation department, Luxembourg Institute of Science and Technology, Belvaux, Luxembourg; Environmental Research and Innovation department, Luxembourg Institute of Science and Technology, Belvaux, Luxembourg","2022 IEEE International Workshop on Metrology for the Sea; Learning to Measure Sea Health Parameters (MetroSea)","24 Nov 2022","2022","","","388","392","In this study we propose an image classification method that allows to delineate oil spills from multi-sensor earth observation (EO) data, i.e. Synthetic Aperture Radar (SAR) and multi-spectral imagery. By making use of the SAR intensity and an index derived from multi-spectral data, we perform a multiscale-based bimodal distribution classification, represented in our case by the oil spill and sea clutter, respectively. The proposed method is applied to a sequence of images acquired with a daily frequency allowing to characterise the temporal and spatial of evolution of the oil spill. In addition, we address the surface wind and currents corresponding to each satellite image in order to investigate their impact on the oil spill evolution. The experimental results are focused on two different oil spill events: one in the waters around Mauritius after a Japanese bulk carrier, MV Wakashio, ran aground on a coral reef, and one in the Persian golf which is the largest offshore oil development area.","","978-1-6654-9942-2","10.1109/MetroSea55331.2022.9950927","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9950927","multi-spectral;multi-temporal;oil spill;Synthetic Aperture Radar (SAR)","Earth;Sea surface;Satellites;Radar measurements;Oils;Spaceborne radar;Soft sensors","geophysical image processing;geophysical techniques;image classification;marine pollution;oceanographic techniques;oil pollution;radar imaging;remote sensing;remote sensing by radar;synthetic aperture radar","different oil spill events;image classification method;largest offshore oil development area;multiscale-based bimodal distribution classification;multisensor earth observation data;multisensor earth observation imagery;multispectral data;multispectral imagery;multitemporal characterization;oil spill evolution;Synthetic Aperture Radar","","","","9","IEEE","24 Nov 2022","","","IEEE","IEEE Conferences"
"Comparative analysis of different fusion rules for SAR and multi-spectral image fusion based on NSCT and IHS transform","X. J. Chong; C. Xuejiao","College of Earth Science and Engineering, Hohai University, Nanjing, China; College of Earth Science and Engineering, Hohai University, Nanjing, China","2015 International Conference on Computer and Computational Sciences (ICCCS)","21 Dec 2015","2015","","","271","274","In order to improve the fusion quality of SAR and multi-spectral image, this paper proposes an image fusion method based on nonsubsampled contourlet transform (NSCT) and IHS transform. Since the fusion rule plays a very important role during the fusion process, four fusion rules are analyzed and compared. Three fusion rules are commonly used in previous works and a new fusion rule is proposed in this paper. To evaluate the performance of different fusion rules, fusion experiments are carried on COSMO-SkyMed SAR and Landsat OLI image. The experimental results indicate that the proposed rule is more effective than the other three regular fusion rules.","","978-1-4799-1819-5","10.1109/ICCACS.2015.7361364","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7361364","Iimage fusion;NSCT;IHS transform;fusion rule","Transforms;Synthetic aperture radar;Image fusion;Remote sensing;Satellites;Filter banks;Image resolution","image fusion;radar imaging;synthetic aperture radar;transforms","multispectral image fusion;nonsubsampled contourlet transform;NSCT;intensity hue saturation;IHS transform;fusion rule;COSMO-SkyMed SAR;Landsat OLI image","","1","","11","IEEE","21 Dec 2015","","","IEEE","IEEE Conferences"
"Self-Supervised Learning for Invariant Representations From Multi-Spectral and SAR Images","P. Jain; B. Schoen-Phelan; R. Ross","School of Computer Science, Technological University Dublin, Dublin, Ireland; School of Computer Science, Technological University Dublin, Dublin, Ireland; School of Computer Science, Technological University Dublin, Dublin, Ireland","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","21 Sep 2022","2022","15","","7797","7808","Self-supervised learning (SSL) has become the new state of the art in several domain classification and segmentation tasks. One popular category of SSL are distillation networks, such as Bootstrap Your Own Latent (BYOL). This work proposes RS-BYOL, which builds on BYOL in the remote sensing (RS) domain where data are nontrivially different from natural RGB images. Since multispectral (MS) and synthetic aperture radar (SAR) sensors provide varied spectral and spatial resolution information, we utilize them as an implicit augmentation to learn invariant feature embeddings. In order to learn RS-based invariant features with SSL, we trained RS-BYOL in two ways, i.e., single channel feature learning and three channel feature learning. This work explores the usefulness of single channel feature learning from random 10 MS bands of 10–20 m resolution and VV-VH of SAR bands compared to the common notion of using three or more bands. In our linear probing evaluation, these single channel features reached a 0.92 F1 score on the EuroSAT classification task and 59.6 mIoU on the IEEE Data Fusion Contest segmentation task for certain single bands. We also compare our results with ImageNet weights and show that the RS-based SSL model outperforms the supervised ImageNet-based model. We further explore the usefulness of multimodal data compared to single modality data, and it is shown that utilizing MS and SAR data allows better invariant representations to be learnt than utilizing only MS data.","2151-1535","","10.1109/JSTARS.2022.3204888","Science Foundation Ireland(grant numbers:13/RC/2106_P2); ADAPT SFI Research Centre at Technological University Dublin ADAPT; SFI Research Centre for AI-Driven Digital Content Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9880533","Optical-synthetic aperture radar (SAR) fusion;satellite images;self-supervised learning (SSL);unsupervised learning","Synthetic aperture radar;Task analysis;Optical sensors;Optical imaging;Representation learning;Remote sensing;Satellites","feature extraction;geophysical image processing;image classification;image fusion;image resolution;image segmentation;radar imaging;remote sensing by radar;supervised learning;synthetic aperture radar","segmentation tasks;RS-BYOL;remote sensing domain;natural RGB images;synthetic aperture radar;spectral resolution information;spatial resolution information;invariant feature embeddings;RS-based invariant features;single channel feature learning;random 10 MS bands;SAR bands;single channel features;single bands;RS-based SSL model;supervised ImageNet-based model;single modality data;invariant representations;MS data;multispectral;SAR images;self-supervised learning;domain classification;IEEE data fusion contest segmentation task;size 10.0 m to 20.0 m","","3","","70","CCBY","7 Sep 2022","","","IEEE","IEEE Journals"
"SETHI / RAMSES-NG: New performances of the flexible multi-spectral airborne remote sensing research platform","R. Baqué; O. Ruault du Plessis; N. Castet; P. Fromage; J. Martinot-Lagarde; J. -F. Nouvel; H. Oriot; S. Angelliaume; F. Brigui; H. Cantalloube; M. Chanteclerc; P. Dubois-Fernandez; X. Dupuis; P. Martineau","Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE","2017 European Radar Conference (EURAD)","8 Jan 2018","2017","","","191","194","SETHI is an airborne SAR/GMTI system developed by the French Aerospace Lab. ONERA, and integrating various sensors. In 2016 ONERA invested in upgrade and improvement of all SETHI components. The microwave ones cover from VHF-UHF to X Band, full polarimetric and very high resolution, along track and cross track interferometry and very high precision multi-baseline capacity for interferometry and tomography applications. The optronic sensors offer very high spatial resolution visible images and fine spectral scene analysis in VNIR and SWIR bands. This paper presents the upgrade and new performances of this flexible platform and the qualification campaign results with various sensor configurations.","","978-2-87487-049-1","10.23919/EURAD.2017.8249179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249179","Remote sensing;SAR;Very High Resolution;Moving target detection and tracking;Optronic","Image resolution;Radar antennas;Synthetic aperture radar;Optical sensors;Trajectory","airborne radar;artificial satellites;image sensors;radar interferometry;remote sensing by radar;synthetic aperture radar","airborne SAR-GMTI system;high-spatial resolution visible images;SETHI-RAMSES-NG;sensor configurations;fine spectral scene analysis;optronic sensors;tomography applications;high precision multibaseline capacity;cross track interferometry;very high resolution;polarimetric resolution;VHF-UHF;SETHI components;flexible multispectral airborne remote sensing research platform","","5","","4","","8 Jan 2018","","","IEEE","IEEE Conferences"
"SETHI and RAMSES-NG flexible multi-spectral airborne remote sensing research platforms","R. Baqué; O. R. du Plessis; P. Dreuillet; Y. -M. Frédéric","Electromagnetism and Radar Department, ONERA, France; Electromagnetism and Radar Department, ONERA, France; Electromagnetism and Radar Department, ONERA, France; Optronic Department, ONERA, France","2016 CIE International Conference on Radar (RADAR)","5 Oct 2017","2016","","","1","5","SEHI and RAMSES-NG are airborne SAR systems developed by the French Aerospace Lab. ONERA, and integrating various sensors. The microwave ones cover from VHF-UHF to X Band, full polarimetric and very high resolution, along track and cross track interferometry and very high precision multi-baseline capacity for interferometry and tomography applications. The optronic sensors offer very high spatial resolution visible images and fine spectral scene analysis in VNIR and SWIR bands. This paper presents the flexible capacity of these platforms and last campaign results with various sensor configurations.","","978-1-5090-4828-1","10.1109/RADAR.2016.8059303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8059303","Remote sensing;SAR;Very High Resolution;Moving target detection and tracking;Optronic","Synthetic aperture radar;Trajectory;Image resolution;Optical sensors;Optical receivers","airborne radar;geophysical equipment;geophysical techniques;image sensors;radar antennas;radar imaging;radar interferometry;radar polarimetry;remote sensing;synthetic aperture radar","French Aerospace Lab;polarimetric resolution;very high resolution;cross track interferometry;high precision multibaseline capacity;fine spectral scene analysis;flexible capacity;SWIR band;optronic sensor;high spatial resolution visible image;tomography application;VHF-UHF microwave;flexible multispectral airborne remote sensing research platform;airborne SAR system","","5","","5","IEEE","5 Oct 2017","","","IEEE","IEEE Conferences"
"Internal Learning for Sequence-to-Sequence Cloud Removal via Synthetic Aperture Radar Prior Information","P. Ebel; M. Schmitt; X. X. Zhu","Data Science in Earth Observation(SiPEO), Technical University of Munich (TUM), Munich, Germany; Department of Geoinformatics, Munich University of Applied Sciences, Munich, Germany; Remote Sensing Technology Institute (IMF), German Aerospace Center (DLR), Wessling, Germany","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2691","2694","Many observations acquired via optical satellites are polluted by cloud coverage, impeding a continuous and on-demand monitoring of the Earth. Recent advances in the field of cloud removal consider multi-temporal data to reconstruct pixels covered by clouds at a time point of interest. Yet, the limitation of preceding work is that information gets integrated over time, removing any temporal resolution from the de-clouded end products. In this work we consider a sequence-to-sequence approach, translating cloudy time series to a series of cloud-free multi-spectral images without the need of any external cloud-free data set. Our network is guided by synthetic aperture radar (SAR) information providing a strong prior for the reconstruction of cloud-covered information. We analyze the proposed method by visual inspection of predictions and in terms of error metrics to highlight its benefits. Finally, an ablation study is conducted in which the our network is compared against a baseline model and the effectiveness of the proposed SAR prior is demonstrated.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554268","synthetic aperture radar;optical imagery;cloud removal;time series;data fusion;deep learning","Laser radar;Satellites;Clouds;Time series analysis;Predictive models;Optical imaging;Adaptive optics","","","","2","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A Conditional Generative Adversarial Network to Fuse Sar And Multispectral Optical Data For Cloud Removal From Sentinel-2 Images","C. Grohnfeldt; M. Schmitt; X. Zhu","Signal Processing in Earth Observation, Technical University of Munich (TUM), Munich, Germany; Signal Processing in Earth Observation, Technical University of Munich (TUM), Munich, Germany; Signal Processing in Earth Observation, Technical University of Munich (TUM), Munich, Germany","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","1726","1729","In this paper, we present the first conditional generative adversarial network (cGAN) architecture that is specifically designed to fuse synthetic aperture radar (SAR) and optical multi-spectral (MS) image data to generate cloud- and haze-free MS optical data from a cloud-corrupted MS input and an auxiliary SAR image. Experiments on Sentinel-2 MS and Sentinel-l SAR data confirm that our extended SAR-Opt-cGAN model utilizes the auxiliary SAR information to better reconstruct MS images than an equivalent model which uses the same architecture but only single-sensor MS data as input.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8519215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519215","SAR;optical remote sensing;data fusion;deep learning;generative adversarial network (GAN);cloud-removal","Synthetic aperture radar;Optical sensors;Optical imaging;Clouds;Remote sensing;Adaptive optics;Generative adversarial networks","geophysical image processing;image fusion;radar imaging;synthetic aperture radar","cloud-free MS optical data;Sentinel-l SAR data;single-sensor MS data;reconstruct MS images;auxiliary SAR information;extended SAR-Opt-cGAN model;auxiliary SAR image;cloud-corrupted MS input;haze-free MS optical data;multispectral image data;synthetic aperture radar;conditional generative adversarial network architecture;Sentinel-2;cloud removal;multispectral optical data","","51","3","12","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Effective Classification of Local Climate Zones Based on Multi-Source Remote Sensing Data","H. Jing; Y. Feng; W. Zhang; Y. Zhang; S. Wang; K. Fu; K. Chen","Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Department of Electrical and Computer Engineering, Northeastern University; Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Institute of Electronics, Chinese Academy of Sciences, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2666","2669","The local climate zone (LCZ) classification divides the urban areas into 17 categories, which are composed of 10 manmade structures and 7 natural landscapes. Though originally designed for temperature study, LCZ classification can be used for studies on economy and population. In this paper, we achieve a LCZ classification with convolutional neural networks based on the multi-source remote sensing data, including the polarimetric synthetic aperture radar (PolSAR) data and the corresponding multi-spectral imagery (MSI). Through experiments we attempt to reveal the contributions of the SAR data and the MSI to the classification performance. Furthermore, we emphasize the crucial importance of the preprocessing on the training data to derive a balanced dataset. We are ranked second in the Tianchi competition rankings when we submit our results.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898475","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898475","Multi-modality;local climate zone (LCZ) classification;convolutional neural networks;SAR;multispectral imagery","Meteorology;Training;Urban areas;Synthetic aperture radar;Remote sensing;Convolutional neural networks;Feature extraction","atmospheric techniques;climatology;image classification;radar imaging;radar polarimetry;remote sensing by radar;synthetic aperture radar","classification performance;SAR data;MSI;multispectral imagery;polarimetric synthetic aperture radar data;multisource remote sensing data;convolutional neural networks;economy;LCZ classification;temperature study;natural landscapes;manmade structures;urban areas;local climate zone classification;training data","","6","","10","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Classification of Hyperspectral Image for Property Analysis","A. Verma; K. Gupta","Department of Computer Science and Engineering, Amity University Uttar Pradesh, Noida, India; Department of Computer Science and Engineering, Amity University Uttar Pradesh, Noida, India","2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS)","10 Mar 2019","2018","","","1","4","For the detection of the sea ice SAR algorithm has been utilized in order to avoid any damage to ship. This will identify whether there is any obstruction in the way of ice or not so that ship does not strike with ice. The desired results are obtained when SAR algorithm is connected on RADARl imagery data. They also studied the algorithm for the segmentation of ice known as pixel based segmentation which helps to differentiate ice based on its properties. Large number of methods has been utilized for multi temporal segmentation from the MODIS data which is known as TempoSeg strategy for multiyear sea ice. Synthetic Aperture Radar utilized the RADARSATl imagery data in order to detect the ice of sea at different regions of the seas. With the help of Rl imagery data better outcomes are provided by the automated algorithm. In present work, the automated SAR algorithm is required to execute in order to detect sea ice.","","978-1-5386-2842-3","10.1109/ICCONS.2018.8663049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663049","Hyperspectral;multi-spectral;SAR;Image property","Hyperspectral imaging;Ice;Feature extraction;Image segmentation;Synthetic aperture radar","geophysical image processing;image segmentation;oceanographic techniques;radar imaging;remote sensing by radar;sea ice;synthetic aperture radar","automated SAR algorithm;hyperspectral image;property analysis;sea ice SAR algorithm;pixel based segmentation;multitemporal segmentation;MODIS data;multiyear sea ice;RADARSATl imagery data;Rl imagery data","","","","12","IEEE","10 Mar 2019","","","IEEE","IEEE Conferences"
"The DALO-ARCTIC campaign: Multi-spectral SAR Imaging of Ice Features in Greenland","A. Reigber; E. Krogager; M. Keller; M. Jaeger; I. Hajnsek; R. Horn",NA; NA; NA; NA; NA; NA,"Proceedings of EUSAR 2016: 11th European Conference on Synthetic Aperture Radar","5 Sep 2016","2016","","","1","3","In May 2015, the Danish Defence Acquisition and Logistics Organization (DALO) together with the German Aerospace Center (DLR) conducted the joint DALO-ARCTIC airborne SAR campaign with the F-SAR sensor over several testsites in Greenland. Principal goal of this campaign was to demonstrate the capabilities of SAR for security applications in arctic environments, as well as to investigate various advanced methods for extracting ice and snow parameters from SAR data. During this campaign, the ability of F-SAR to simultaneously record fully-polarimetric SAR data in several frequency bands was used for the first time on a large scale. Due to the significantly varying penetration depth of the different bands into ice and snow, it is of particular interest to understand and analyse what can be seen in each band and what are the dominating scattering processes. This paper will discuss this based on examples of polarimetric multi-band imaging of ice and snow layers from data acquired during the DALO-ARCTIC campaign. In this way, the huge potential of multi-spectral SAR imaging for the analysis of ice bodies will be demonstrated.","","978-3-8007-4228-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559298","","","","","","","","","","5 Sep 2016","","","VDE","VDE Conferences"
"Synergetic potentials of C-band SAR and multi-spectral imagery for tropical classifications in Northern Mato Grosso (BR)","R. Hagensieker; B. Waske","Institute of Geographical Scienes, Freie Universität Berlin; Institute of Geographical Scienes, Freie Universität Berlin","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","5486","5489","Using monthly as well as annual statistics, we investigate the potentials of synergetic utilization of multispectral and C-band SAR data for the classification of a study site in the central Brazilian state of Mato Grosso. We aim at the classification of five tropical land cover classes (primary forests, secondary vegetation, pasture, agricultural, water), and highlight the potentials of standalone S1 classification, as well as the synergetic potentials using two sensors. The overall size of the study site is about 300.000 km2, encompassing multiple tiles of S1 and LS-8. Results show S1 classification alone to yield accuracies of up to 88% (not accounting for secondary vegetation), and synergetic approaches to pass area adjusted overall accuracies of 95 %. While we were not able to sufficiently separate primary from secondary forests, forests overall as well as water yielded UA's and PA's just below 100 %.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8128246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128246","SAR;Multi-Spectral;Classification;Multi-temporal","Sensors;Remote sensing;Vegetation mapping;Artificial satellites;Earth;Training;Image resolution","forestry;geophysical image processing;image classification;land cover;remote sensing by radar;synthetic aperture radar;vegetation","northern Mato Grosso;central Brazilian state;multispectral data;forests;vegetation;multispectral imagery;tropical land cover classification;C-band SAR data","","","","7","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"A Near-field Imaging Algorithm for Synthetic Aperture Interferometric Radiometers","P. Fu; F. Hu; D. Zhu; H. Xia; C. Deng; Y. Yan","National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China","2022 IEEE MTT-S International Wireless Symposium (IWS)","20 Dec 2022","2022","1","","1","3","Near-field imaging of synthetic aperture interfero-metric radiometers (SAIR) is discussed. If the scene plane is parallel to the array plane, the near-field visibility function can be represented as the convolution results of brightness temperature (BT) distribution and a kernel function. Therefore, the near-field imaging process of SAIR is a deconvolution operation. This paper presents a frequency-domain-based (FDB) algorithm for near-field SAIR. First, weighting the visibility function by the redundancy factor. Second, the algorithm exploits the deconvolution operation with frequency domain to reconstruct the 4-D image domain data. Finally, the BT image is reconstructed via a dimension-reducing operation. The imaging experiment shows that the presented method can reconstruct the passive millimeter-wave (PMMW) image.","","978-1-6654-8197-7","10.1109/IWS55252.2022.9977981","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9977981","Near-field imaging;synthetic aperture interfero-metric radiometer;convolution;frequency domain","Radiometers;Wireless communication;Image quality;Deconvolution;Redundancy;Millimeter wave technology;Imaging","deconvolution;image processing;image reconstruction;millimetre wave imaging;object detection;radar imaging;radiometers;radiometry;synthetic aperture radar","4-D image domain data;array plane;brightness temperature distribution;BT image;convolution results;deconvolution operation;dimension-reducing operation;frequency domain;frequency-domain-based algorithm;imaging experiment shows;kernel function;near-field imaging algorithm;near-field imaging process;near-field SAIR;near-field visibility function;passive millimeter-wave image;scene plane;synthetic aperture interfero-metric radiometers;synthetic aperture interferometric radiometers","","","","9","IEEE","20 Dec 2022","","","IEEE","IEEE Conferences"
"A new vegetation index for cooperative inversion of winter wheat covered surface soil moisture based on sentinel-1/2 remote sensing data","B. Zhang; J. Zhao; N. Li; Z. Guo","College of Computer and Information Engineering, Henan University, Kaifeng, China; College of Computer and Information Engineering, Henan University, Kaifeng, China; College of Computer and Information Engineering, Henan University, Kaifeng, China; College of Computer and Information Engineering, Henan University, Kaifeng, China","IET International Radar Conference (IET IRC 2020)","22 Sep 2021","2020","2020","","445","449","Aiming at the problem of the interfere of winter wheat on radar backscattering coefficient in surface soil moisture inversion, a new vegetation index called Fusion Vegetation Index (FVI) is defined in this study. Based on the Multi-Spectral Imager (MSI) data of Sentinel-2, and the Synthetic Aperture Radar (SAR) data of Sentinel-1, using FVI to retrieve water content of winter wheat, combined with Water Cloud model, the interference of winter wheat in soil moisture inversion was reduced. The results show that good soil moisture retrieval results can be obtained by combining with FVI.","","","10.1049/icp.2021.0636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9545596","","","backscatter;geophysical image processing;moisture;remote sensing by radar;soil;synthetic aperture radar;vegetation;vegetation mapping","winter wheat covered surface soil moisture;radar backscattering coefficient;surface soil moisture inversion;Fusion Vegetation Index;FVI;MultiSpectral Imager data;Sentinel-2;Synthetic Aperture Radar data;soil moisture retrieval results;Sentinel-1;Water Cloud model","","","","","","22 Sep 2021","","","IET","IET Conferences"
"A Wavenumber Domain Imaging Algorithm for Synthetic Aperture Interferometric Radiometry in Near-Field","P. Fu; F. Hu; H. Hu; T. Zheng","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","6511","6514","This paper presents a passive-millimeter imaging algorithnm for synthetic aperture interferometric radiometry (SAIR) in near-field. The SAIR measures the visibility function of the scene by antenna arrays. In the far field, according to the Van Cittert-Zernike theorem, there is a Fourier transform between visibility function and scene brightness temperature. However, in the near field, because of the cross-coupling of azimuth direction and distance direction, Van Cittert-Zernike theorem is not valid. In this paper, the visibility function is transformed into wave number domain using spherical wave decomposition. After compensating the phase term related to the distance, the SAIR near-field imaging is realized.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323395","spherical wave decomposition;passive-millimeter imaging;synthetic aperture interferometric radiometry;near-field imaging","Imaging;Fourier transforms;Apertures;Microwave radiometry;Brightness temperature;Antennas;Antenna measurements","antenna arrays;Fourier transforms;millimetre wave imaging;radar imaging;radiometers;radiometry;synthetic aperture radar","synthetic aperture interferometric radiometry;passive-millimeter imaging algorithnm;SAIR;visibility function;Van Cittert-Zernike theorem;scene brightness temperature;wave number domain;near-field imaging;wavenumber domain imaging algorithm","","1","","5","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Open Multi-Processing Acceleration for Unsupervised Land Cover Categorization Using Probabilistic Latent Semantic Analysis","S. Bernabé; C. García; R. Fernández-Beltrán; M. E. Paoletti; J. M. Haut; J. Plaza; A. Plaza","Department of Computer Architecture and Automation, Complutense University, Madrid, Spain; Department of Computer Architecture and Automation, Complutense University, Madrid, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón, Spain; Hyperspectral Computing Laboratory, University of Extremadura, Cáceres, Spain; Hyperspectral Computing Laboratory, University of Extremadura, Cáceres, Spain; Hyperspectral Computing Laboratory, University of Extremadura, Cáceres, Spain; Hyperspectral Computing Laboratory, University of Extremadura, Cáceres, Spain","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","9835","9838","The probabilistic Latent Semantic Analysis (pLSA) model has recently shown a great potential to uncover highly descriptive semantic features from limited amounts of remote sensing data. Nonetheless, the high computational cost of this algorithm often constraints its operational application for land cover categorization tasks. In this scenario, this paper presents an Open Multi-Processing (OpenMP) implementation of the pLSA algorithm for unsupervised Synthetic Aperture Radar (SAR) and Multi-Spectral Imaging (MSI) image categorization. The experimental results suggest that multi-core systems are an important architecture for the efficient processing of both SAR and MSI datasets. Specifically, the proposed approach is able to cover a real scenario exhibiting good results in both accuracy and performance terms.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898507","Open Multi-Processing (OpenMP);multi-core processors;probabilistic Latent Semantic Analysis (pLSA);land cover categorization","Remote sensing;Semantics;Probabilistic logic;Synthetic aperture radar;Agriculture;Buildings;Forestry","geophysical image processing;image classification;radar imaging;remote sensing by radar;synthetic aperture radar","semantic features;probabilistic latent semantic analysis;remote sensing data;land cover categorization tasks;pLSA algorithm;multicore systems;unsupervised land cover categorization;open multiprocessing acceleration;pLSA model;descriptive semantic features;multispectral imaging;MSI;image categorization","","","","16","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"A Imaging Algorithm Based on Angular Spectrum Theory for Synthetic Aperture Interferometric Radiometer","P. Fu; F. Hu; D. Zhu; Y. Xu","National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","7610","7613","For near-field synthetic aperture interferometric radiometer (SAIR), the Fourier transform relationship between the visi-bility function and the near-field brightness temperature (BT) distribution is not valid. It is a challenging task for near-field SAIR imaging to realize very-close range accurate imaging with large field of view (FOV). In this paper, we present a new SAIR near-field imaging algorithm based on angular spec-trum theory to realize the passive millimeter-wave (PMMW) imaging, called synthetic-angular-spectrum imaging (SASI) algorithm. This SASI algorithm mainly addresses data sam-ples of a 4-D visibility function acquired from planar arrays. First, we invert the 4-D visibility samples into the angular spectrum domain via the Fourier transformation. Second, a dedicated phase factor compensation is adopted and the dimension-reducing accumulation is employed to generate the synthetic angular spectrum (SAS) of near-field BT distri-bution. Finally, we reconstruct the BT image by making use of the generated SAS data. Experiment results show that the presented SASI algorithm can reconstruct the BT image.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883866","National Natural Science Foundation of China(grant numbers:61901244,61871438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883866","Synthetic aperture interferometric ra-diometer (SAIR);near field;synthetic angular spectrum","Fourier transforms;Imaging;Planar arrays;Apertures;Radiometry;Brightness temperature;Arrays","Fourier transforms;image reconstruction;millimetre wave imaging;radar imaging;radiometers;radiometry;synthetic aperture radar","near-field brightness temperature distribution;near-field SAIR;range accurate imaging;near-field imaging algorithm;angular spec-trum theory;passive millimeter-wave imaging;called synthetic-angular-spectrum imaging algorithm;4-D visibility function;4-D visibility samples;angular spectrum domain;Fourier transformation;synthetic angular spectrum;BT image;presented SASI algorithm;angular spectrum theory;near-field synthetic aperture interferometric radiometer;Fourier transform relationship;visi-bility function","","","","7","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Mapping Snow Cover Extent Using Optical and SAR Data","A. Wendleder; A. J. Dietz; K. Schork","Land surface Applications (LAX), German Remote Sensing Data Center (DFD), Wessling; Land surface Applications (LAX), German Remote Sensing Data Center (DFD), Wessling; Land surface Applications (LAX), German Remote Sensing Data Center (DFD), Wessling","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","5104","5107","Snow cover plays an important role both globally and regionally as it is fundamental for local water availability, river run-off, and groundwater recharge. Hence, the exact knowledge of extent and dynamic of the snow coverage is essential. This study combines synergetic optical and SAR data with the main object to map the snow cover extent. As the Sentinel-Mission provides a wide swath width and a high revisit time (2-3 days at mid-latitudes with same acquisition geometry), the Sentinel-1 Interferometric Wide Swath Mode (IW) SAR data and Sentinel-2 multi-spectral data are used. Additionally, the TanDEM-X DEM is applied for the exact determination of the snow line as well as for snow classification. The mapping of the snow cover extent is applied on the three test sites Devon Island in Canada, Nordenskiöld, Svalbard, and French Alps, France which are characterized by different topography and land cover. The classification achieved an overall accuracy of 85% for Devon Island, 60% for Nordenskiöld and 88% for the French Alps.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518374","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518374","Snow Cover Extent;optical data;SAR;NDSI;Sentinel-1;Sentinel-2","Snow;Synthetic aperture radar;Backscatter;Ice;Optical sensors;Integrated optics;Optical interferometry","groundwater;hydrological techniques;radar imaging;radar interferometry;remote sensing;snow;synthetic aperture radar;terrain mapping","land cover;local water availability;snow cover extent;TanDEM-X DEM;Canada;Nordenskiöld;Svalbard;French Alps;Devon Island;river run-off;groundwater recharge;snow classification;snow line;Sentinel-2 multispectral data;Sentinel-1 Interferometric Wide Swath Mode SAR data;wide swath width;Sentinel-Mission;snow coverage","","1","","6","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"A Near-Field Imaging Algorithm Based on Angular Spectrum Theory for Synthetic Aperture Interferometric Radiometer","P. Fu; D. Zhu; F. Hu; Y. Xu; H. Xia","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing and the School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing and the School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing and the School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing and the School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing and the School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Microwave Theory and Techniques","1 Jul 2022","2022","70","7","3606","3616","For the near-field synthetic aperture interferometric radiometer (SAIR), the Fourier transform relationship between the visibility function and the near-field brightness temperature (BT) distribution is not valid. It is a challenging task for near-field SAIR imaging to realize very close-range accurate imaging with a large field of view (FOV). This article presents a new SAIR near-field imaging algorithm based on the angular spectrum theory to realize the passive millimeter-wave (PMMW) imaging, called synthetic-angular-spectrum imaging (SASI) algorithm. This SASI algorithm mainly addresses data samples of a 4-D visibility function acquired from planar arrays. First, we invert 4-D visibility samples into the angular spectrum domain via the Fourier transformation. The obtained angular spectrum data cannot be directly used to estimate the near-field BT distribution. Second, a dedicated phase factor compensation is adopted for handling this problem. The dimension-reducing accumulation is employed to generate the synthetic angular spectrum (SAS) of near-field BT distribution. Finally, we reconstruct the BT image by using the generated SAS data. Simulation and experiment results show that the presented SASI algorithm has the superiority on image reconstruction quality, especially for the off-axis regions, compared with the existing near-field SAIR imaging methods.","1557-9670","","10.1109/TMTT.2022.3175156","National Natural Science Foundation of China(grant numbers:61901244,61871438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9782134","Near field;synthetic angular spectrum (SAS);synthetic aperture interferometric radiometer (SAIR)","Imaging;Synthetic aperture sonar;Fourier transforms;Calibration;Apertures;Microwave radiometry;Directive antennas","Fourier transforms;geophysical image processing;image reconstruction;millimetre wave imaging;radar imaging;radiometers;radiometry;remote sensing by radar;synthetic aperture radar","image reconstruction quality;near-field SAIR;near-field imaging algorithm;angular spectrum theory;near-field synthetic aperture interferometric radiometer;Fourier transform relationship;visibility function;near-field brightness temperature distribution;close-range accurate imaging;passive millimeter-wave imaging;called synthetic-angular-spectrum imaging algorithm;4-D visibility samples;angular spectrum domain;Fourier transformation;angular spectrum data;synthetic angular spectrum;BT image;presented SASI algorithm","","","","23","IEEE","25 May 2022","","","IEEE","IEEE Journals"
"SETHI/RAMSES-NG new performances of the flexible multi-spectral airborne remote sensing research platform","R. Baqué; O. Ruault du Plessis; N. Castet; P. Fromage; J. Martinot-Lagarde; J. -F. Nouvel; H. Oriot; S. Angelliaume; F. Brigui; H. Cantalloube; M. Chanteclerc; P. Dubois-Fernandez; X. Dupuis; P. Martineau","Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR; Office National d'Etudes et de Recherches Aerospatiales, Chatillon, ÃŽle-de-France, FR","International Conference on Radar Systems (Radar 2017)","28 May 2018","2017","","","1","4","SETHI is an airborne SAR/GMTI system developed by the French Aerospace Lab. ONERA, and integrating various sensors. In 2016 ONERA invested in upgrade and improvement of all SETHI components. The microwave ones cover from VHF-UHF to X Band, full polarimetric and very high resolution, along track and cross track interferometry and very high precision multi-baseline capacity for interferometry and tomography applications. The optronic sensors offer very high spatial resolution visible images and fine spectral scene analysis in VNIR and SWIR bands. This paper presents the upgrade and new performances of this flexible platform and the qualification campaign results with various sensor configurations.","","978-1-78561-672-3","10.1049/cp.2017.0407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367492","Remote sensing;SAR;Very High Resolution;Moving target detection and tracking;Optronic","","airborne radar;geophysical equipment;geophysical techniques;image sensors;radar antennas;remote sensing;synthetic aperture radar","SETHI / RAMSES;flexible multispectral airborne remote sensing research platform;airborne SAR/GMTI system;French Aerospace Lab;2016 ONERA;SETHI components;microwave ones;VHF-UHF;polarimetric resolution;very high resolution;cross track interferometry;high precision multibaseline capacity;tomography applications;optronic sensors;high spatial resolution visible images;fine spectral scene analysis;flexible platform;sensor configurations","","1","","","","28 May 2018","","","IET","IET Conferences"
"A Novel Imaging Method Using Fractional Fourier Transform for Near-Field Synthetic Aperture Radiometer Systems","H. Hu; D. Zhu; F. Hu","School of Electronic Information and Communications and the National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications and the National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications and the National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","22 Apr 2022","2022","19","","1","5","In the domain of synthetic aperture radiometry, a Fourier transform (FT) relationship can be established between the brightness temperature of the target in the far-field region and the visibility function output by the system. However, when the target is in the near-field range of the imaging system, the existing far-field imaging methods cannot be used directly for the inversion of the near-field visibility function, because the target radiation signal cannot simply be regarded as a plane wave signal. In this letter, we propose a novel imaging method for synthetic aperture radiometer systems on the basis of the characteristics of the near-field target radiation signal. We introduce the near-field error term to reformulate the relationship between visibility function and brightness temperature in near field. Based on the reestablished signal model, we present an image reconstruction algorithm via fractional Fourier transformation, named near-field fractional FT (NF-FRFT), to estimate the near-field brightness temperature. Compared with the conventional near-field imaging method, the proposed NF-FRFT method can achieve better image reconstruction quality without extra hardware consumption. Furthermore, another advantage of this approach is that no additional array layout design is required. The validity of this method is demonstrated by a series of simulations and experiments.","1558-0571","","10.1109/LGRS.2022.3166219","National Natural Science Foundation of China(grant numbers:61901244); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9754577","Fractional Fourier transformation;inversion method;synthetic aperture","Imaging;Brightness temperature;Antenna arrays;Mathematical models;Apertures;Fourier transforms;Radiometry","Fourier transforms;image reconstruction;microwave imaging;millimetre wave imaging;radar imaging;radiometers;radiometry;synthetic aperture radar","fractional Fourier transformation;named near-field fractional FT;near-field brightness temperature;conventional near-field imaging method;NF-FRFT method;image reconstruction quality;novel imaging method;fractional Fourier transform;near-field synthetic aperture radiometer systems;synthetic aperture radiometry;far-field region;visibility function output;near-field range;imaging system;existing far-field imaging methods;near-field visibility function;plane wave signal;near-field target radiation signal;near-field error term;reestablished signal model;image reconstruction algorithm","","","","13","IEEE","11 Apr 2022","","","IEEE","IEEE Journals"
"ISAR imaging of non-cooperative targets via dual band photonics-based radar system","F. Laghezza; F. Scotti; D. Onori; A. Bogoni","CNIT, National University Consortium for Telecommunications, Pisa, Italy; CNIT, National University Consortium for Telecommunications, Pisa, Italy; TeCIP Institute Scuola Superiore Sant’ Anna, Pisa, Italy; TeCIP Institute Scuola Superiore Sant’ Anna, Pisa, Italy","2016 17th International Radar Symposium (IRS)","23 Jun 2016","2016","","","1","4","We present results of ISAR imaging derived from a field trial detecting different non-cooperative targets with a photonics-based dual band radar operating in S and X band. Images of the targets have been extracted from collected data demonstrating the capability of the system to operate as an imaging radar. The innovative features of the photonic system as the frequency flexibility and the coherent distribution to decentralized peripherals open the way to multi-spectral/static imaging.","2155-5753","978-1-5090-2518-3","10.1109/IRS.2016.7497319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7497319","Radar System;Dual-Band;Microwave photonics;Inverse Synthetic Aperture Radar","Radar imaging;Photonics;Imaging;Laser radar;Doppler effect;Dual band","microwave photonics;radar imaging;synthetic aperture radar","noncooperative target ISAR imaging;dual band photonics-based radar system;S band;X band;frequency flexibility;coherent distribution;multispectral imaging;static imaging","","13","","16","IEEE","23 Jun 2016","","","IEEE","IEEE Conferences"
"Mapping urban impervious surfaces by fusing optical and SAR data at decision level","Y. Bai; G. Sun; Y. Ge; Y. Zhang; Y. Li","Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; National Astronomical Observatories, Chinese Academy of Sciences, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","6336","6339","The extraction of urban impervious surface information plays a key role in the studies of urbanization and its related environmental issues. Optical and SAR remote sensing provides complementary information to improve the accuracy of impervious mapping. However, the fusing of information acquired by different sensors is challenging. Optical and SAR features have distinct characteristics, and require different classification strategy and classification types. In this study, a strategy of fusing multi-spectral optical and polarimetric SAR data at decision-level is proposed. Features are extracted from optical and SAR data, then staked auto-encoder is applied to achieve the land use and land cover classification separately. D-S evidence theory is used to fuse the classification result and the imperious surface map is derived. The experiment was conducted in a highly complex urban area of Hong Kong and the results proves the soundness of the method.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8898039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8898039","impervious surface;decision-level fusion;land use and land cover;multi-spectrum;synthetic aperture radar","","geophysical image processing;geophysical signal processing;image classification;image fusion;radar polarimetry;remote sensing;remote sensing by radar;synthetic aperture radar;terrain mapping","related environmental issues;complementary information;impervious mapping;different classification strategy;classification types;polarimetric SAR data;decision-level;optical SAR data;land use;land cover classification;classification result;imperious surface map;highly complex urban area;urban impervious surfaces;decision level;urban impervious surface information","","","","8","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Single Satellite Optical Imagery Dehazing using SAR Image Prior Based on conditional Generative Adversarial Networks","B. Huang; Z. Li; C. Yang; F. Sun; Y. Song","Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Tsinghua University; Shanghai University Of Engineering Science; Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Tsinghua University; Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Tsinghua University; Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Tsinghua University","2020 IEEE Winter Conference on Applications of Computer Vision (WACV)","14 May 2020","2020","","","1795","1802","Satellite image dehazing aims at precisely retrieving the real situations of the obscured parts from the hazy remote sensing (RS) images, which is a challenging task since the hazy regions contain both ground features and haze components. Many approaches of removing haze focus on processing multi-spectral or RGB images, whereas few of them utilize multi-sensor data. The multi-sensor data fusion is significant to provide auxiliary information since RGB images are sensitive to atmospheric conditions. In this paper, a dataset called SateHaze1k is established and composed of 1200 pairs clear Synthetic Aperture Radar (SAR), hazy RGB, and corresponding ground truth images, which are divided into three degrees of the haze, i.e. thin, moderate, and thick fog. Moreover, we propose a novel fusion dehazing method to directly restore the haze-free RS images by using an end-to-end conditional generative adversarial network(cGAN). The proposed network combines the information of both RGB and SAR images to eliminate the image blurring. Besides, the dilated residual blocks of the generator can also sufficiently improve the dehazing effects. Our experiments demonstrate that the proposed method, which fuses the information of different sensors applied to the cloudy conditions, can achieve more precise results than other baseline models.","2642-9381","978-1-7281-6553-0","10.1109/WACV45572.2020.9093471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093471","","Synthetic aperture radar;Satellites;Remote sensing;Gallium nitride;Task analysis;Optical imaging;Optical sensors","image colour analysis;image enhancement;image restoration;neural nets;radar imaging;remote sensing by radar;sensor fusion;spaceborne radar;synthetic aperture radar","synthetic aperture radar;hazy RGB;fusion dehazing method;haze-free RS images;image blurring;dehazing effects;cloudy conditions;single satellite optical imagery dehazing;SAR image;conditional generative adversarial networks;hazy remote sensing images;ground features;RGB images;multisensor data fusion;ground truth images;cGAN;SateHaze1k;multispectral images","","14","","39","IEEE","14 May 2020","","","IEEE","IEEE Conferences"
"Multi-Modal Self-Supervised Representation Learning for Earth Observation","P. Jain; B. Schoen-Phelan; R. Ross","School of Computer Science, Technological University Dublin, Dublin, Ireland; School of Computer Science, Technological University Dublin, Dublin, Ireland; School of Computer Science, Technological University Dublin, Dublin, Ireland","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3241","3244","Self-Supervised learning (SSL) has reduced the performance gap between supervised and unsupervised learning, due to its ability to learn invariant representations. This is a boon to the domains like Earth Observation (EO), where labelled data availability is scarce but unlabelled data is freely available. While Transfer Learning from generic RGB pre-trained models is still common-place in EO, we argue that, it is essential to have good EO domain specific pre-trained model in order to use with downstream tasks with limited labelled data. Hence, we explored the applicability of SSL with multi-modal satellite imagery for downstream tasks. For this we utilised the state-of-art SSL architectures i.e. BYOL and SimSiam to train on EO data. Also to obtain better invariant representations, we considered multi-spectral (MS) images and synthetic aperture radar (SAR) images as separate augmented views of an image to maximise their similarity. Our work shows that by learning single channel representations through non-contrastive learning, our approach can outperform ImageNet pre-trained models significantly on a scene classification task. We further explored the usefulness of a momentum encoder by comparing the two architectures i.e. BYOL and SimSiam but did not identify a significant improvement in performance between the models.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553741","Science Foundation Ireland(grant numbers:13/RC/2106); European Regional Development Fund(grant numbers:13/RC/2106); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553741","self-supervised learning;unsupervised learning;satellite images","Earth;Training;Satellites;Image analysis;Transfer learning;Data models;Radar polarimetry","image classification;image sensors;learning (artificial intelligence);pattern classification;synthetic aperture radar;unsupervised learning","multimodal self-Supervised representation Learning;Earth Observation;self-Supervised learning;performance gap;unsupervised learning;invariant representations;labelled data availability;Transfer Learning;generic RGB pre-trained models;common-place;good EO domain specific pre-trained model;downstream tasks;multimodal satellite imagery;state-of-art SSL architectures i.e;EO data;multispectral images;synthetic aperture radar images;single channel representations;noncontrastive learning;ImageNet pre-trained models;scene classification task","","2","","15","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Blue Noise Sampling and Nystrom Extension for Graph Based Change Detection","D. A. Jimenez-Sierra; H. D. Benítez-Restrepo; G. R. Arce; J. F. Florez-Ospina","Departamento de Electrónica y Ciencias de la Computación, Pontificia Universidad Javeriana Cali; Departamento de Electrónica y Ciencias de la Computación, Pontificia Universidad Javeriana Cali; Multimodal Imaging and Spectroscopy Laboratory, University of Delaware; Multimodal Imaging and Spectroscopy Laboratory, University of Delaware","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2895","2898","In this paper, we address the problem of sampling on graphs for change detection in large multi-spectral (MS) and synthetic aperture radar (SAR) images by proposing a graph-based data-driven framework. The main steps of the proposed approach are: (i) the segmentation of regions that enclose the change; (ii) the use of smoothness prior for learning a graph of the regions; (iii) the integration of blue-noise sampling (BN) in the change detection scheme. We validate our approach in 14 real cases of remote sensing according to quantitative analyses. The results confirm that using a structured sampling such as BN outperforms recent state-of-the-art methods in change detection for multimodal data.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9555107","The World Bank; Colombian Ministry of Science, Technology and Innovation; Colombian Ministry of Industry and Tourism, and ICETEX(grant numbers:FP44842-217-2018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555107","Blue-noise;change detection;data fusion;graph;remote sensing images;sampling;smoothness","Measurement;Statistical analysis;Signal processing algorithms;Tools;Signal processing;Sampling methods;Radar polarimetry","graph theory;image sampling;image segmentation;radar detection;radar imaging;remote sensing by radar;synthetic aperture radar","multimodal data;quantitative analyses;remote sensing;MS images;multispectral images;SAR images;synthetic aperture radar images;graph-based data-driven framework;graph based change detection;Nystrom extension;blue noise sampling;structured sampling","","1","","17","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Exploring the Fusion of Sentinel-1 SAR and Sentinel-2 MSI Data for Built-Up Area Mapping Using Deep Learning","S. Hafner; Y. Ban; A. Nascetti","Division of Geoinformatics, KTH Royal Institute of Technology; Division of Geoinformatics, KTH Royal Institute of Technology; Division of Geoinformatics, KTH Royal Institute of Technology","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","4720","4723","This research explores the potential of combining Sentinel-1 C-band Synthetic Aperture Radar (SAR) and Sentinel-2 MultiSpectral Instrument (MSI) data for Built-Up Area (BUA) mapping using deep learning. A lightweight U-Net model is trained using openly available building footprint reference data in North America and tested in four cities across three additional continents. The best test performance in terms of F1 score was achieved by the joint use of SAR and multispectral data (0.676), followed by multi-spectral (0.611) and SAR data (0.601). The developed fusion approach is particularly promising to distinguish BUA in low-density residential neighborhoods. Furthermore, our fusion approach compares favorably to the state-of-the-art in BUA mapping in the selected cities. However, associated with the diverse characteristics of human settlements around the world, considerable differences in accuracy among the test cities were observed. This indicates the need for more sophisticated fusion techniques to improve CNN model generalization and for adding more diverse training data.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553448","Swedish National Space Agency; ESA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553448","Sentinel-1;Sentinel-2;Built-up area mapping;data fusion;deep learning","Deep learning;Instruments;Urban areas;Training data;Optical imaging;Data models;Internet","convolutional neural nets;geophysical image processing;image fusion;learning (artificial intelligence);radar imaging;remote sensing by radar;synthetic aperture radar","Sentinel-1 SAR;Sentinel-2 MSI data;Built-Up Area mapping;deep learning;SAR data;BUA mapping;fusion techniques;diverse training data;building footprint reference data;Sentinel-1 C-band synthetic aperture radar;lightweight U-Net model;Sentinel-2 multispectral instrument data;F1 score","","1","","8","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Analysis of the Multispectral and SAR Image","S. Zhang; Y. Zhang; Y. Chou; Z. Wang; Y. Shi; Z. Sun","Simulation Technology and Service CO., Ltd AVIC International, Shanghai, China; Institute of Electronic, Engineering Technology Harbin Institute of Technology, Haerbin, China; Simulation Technology and Service CO., Ltd AVIC International, Shanghai, China; Department of electrical and computer engineering, Northeastern University, Boston, USA; Simulation Technology and Service CO., Ltd AVIC International, Shanghai, China; Simulation Technology and Service CO., Ltd AVIC International, Shanghai, China","2021 IEEE 6th International Conference on Computer and Communication Systems (ICCCS)","21 Jun 2021","2021","","","312","315","The SAR image and the multispectral image are both used for dynamic monitoring, mineral resources investigation, urban and rural monitoring and evaluation, traffic network exploration, forest resources investigation, desertification monitoring, and so on. The multi-spectral and SAR image fusion to improve the classify quality is discussed in this paper, compared the common fusion algorithms of the SAR image and multi spectral images, that is standard color transform (Brovey) method, phase recovery (Gram-Schmidt) method and color space transform (HSV) method, principal component transformation super resolution (PCA) method and Bias method (Pansharp), by which the fused image is more relative with the multi-spectral and SAR.","","978-1-6654-1256-8","10.1109/ICCCS52626.2021.9449213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9449213","SAR;multi spectral;image fusion","Image resolution;Image color analysis;Transforms;Distortion;Visual effects;Radar polarimetry;Classification algorithms","image colour analysis;image fusion;image resolution;principal component analysis;radar imaging;synthetic aperture radar;transforms","dynamic monitoring;traffic network exploration;forest resources investigation;desertification monitoring;SAR image fusion;multispectral images;standard color transform method;mineral resources investigation;rural monitoring;urban monitoring;phase recovery method;color space transform method;principal component transformation super resolution method;Bias method","","","","3","IEEE","21 Jun 2021","","","IEEE","IEEE Conferences"
"An improved clean algorithm for RFI mitigation in aperture synthesis radiometers","X. Peng; F. Hu; F. He; D. Zhu; Y. Cheng; H. Hu; T. Zheng","School of Electronic Information and Communications, HuaZhong University of Science and Technology, Wuhan, China; The National Key Laboratory of Science and Technology on Multi-spectral Information Processing, Wuhan, China; The National Key Laboratory of Science and Technology on Multi-spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, HuaZhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, HuaZhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, HuaZhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, HuaZhong University of Science and Technology, Wuhan, China","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","3448","3451","The SMOS mission is developed for monitoring the surface soil moisture and ocean salinity by a two dimensional L-band synthetic aperture interferometric radiometer. However, artificial sources emitting in the protected L-band are contaminating the retrievals of the soil moisture and ocean salinity from the measurements. To mitigate the RFIs' impacts, the classical CLEAN algorithm was introduced and works well for most isolated point RFI sources. However, in presence of interactions between different RFI sources, the performance of the classical CLEAN algorithm will deteriorate. Thus, in this work, we present an improved CLEAN algorithm to compensate for the RFIs' impacts more accurately in presence of interactions from adjacent RFI sources. It adds back one previously detected RFI to the cleaned map and then reestimates the parameter of this RFI source. Numerical studies using synthetic SMOS data have been carried out to demonstrate that the proposed algorithm outperforms the classical CLEAN algorithm in presence of interactions between RFI sources.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127740","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127740","RFI mitigation;aperture synthesis radiometers (ASR);improved CLEAN algorithm","Earth;Apertures;Extraterrestrial measurements;Pollution measurement;Interference;SMOS mission;Parameter estimation","geophysical signal processing;hydrological techniques;oceanographic equipment;radiofrequency interference;radiometers;radiometry;remote sensing by radar;salinity (geophysical);soil;synthetic aperture radar","classical CLEAN algorithm;improved clean algorithm;surface soil moisture;dimensional L-band synthetic aperture interferometric radiometer;protected L-band;aperture synthesis radiometer;artificial ocean salinity source;RFI source mitigation detection;synthetic SMOS mission data","","1","","8","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Spatio-temporal characterization in satellite image time series","A. Radoi; M. Datcu","University Politehnica of Bucharest (UPB), Bucharest, Romania; German Aerospace Center (DLR), Wessling, Germany","2015 8th International Workshop on the Analysis of Multitemporal Remote Sensing Images (Multi-Temp)","10 Sep 2015","2015","","","1","4","Last years have witnessed an increased interest in the analysis of evolution of spatio-temporal structures in large data volumes. The current satellite remote sensing missions allow the recording of long Satellite Image Time Series (SITS) with passive and active sensors. However, the spatio-temporal characteristics of SITS imply different approaches. This paper aims at presenting an overview of these issues, and also some recent results based on Gibbs Markov Random Fields models that are used to describe the spatio-temporal patterns. In addition, in order to obtain an automatic analysis of these patterns, the problem of determining the optimal number of spatio-temporal clusters is also discussed. The experiments are carried on Landsat 7 multi-temporal and multi-spectral images and on Envisat ASAR images, both at 30 meters spatial resolution.","","978-1-4673-7119-3","10.1109/Multi-Temp.2015.7245805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7245805","","Satellites;Remote sensing;Earth;Rate-distortion;Laser radar;Markov random fields;Optical sensors","image processing;Markov processes;remote sensing by radar;sensors;synthetic aperture radar;time series","synthetic aperture radar;advanced SAR;Envisat ASAR image;Landsat 7 multispectral image;Landsat 7 multitemporal image;spatiotemporal pattern;Gibbs Markov random fields model;active sensor;passive sensor;satellite remote sensing mission;large data volume;spatiotemporal structure evolution analysis;satellite image time series;SITS spatiotemporal characterization","","2","","9","IEEE","10 Sep 2015","","","IEEE","IEEE Conferences"
"Fusion of RADARSAT-2 imagery with LANDSAT-8 multispectral data for improving land cover classification performance using SVM","C. Sukawattanavijit; J. Chen","School of Electronics and Information Engineering, Beihang University Beijing, CHINA; School of Electronics and Information Engineering, Beihang University Beijing, CHINA","2015 IEEE 5th Asia-Pacific Conference on Synthetic Aperture Radar (APSAR)","29 Oct 2015","2015","","","567","572","Study of the land cover classification using multi-source data are very important for eco-environment monitoring, land use planning and climatic change detection. In this study, the utility of multi-source RADARSAT-2 and LANDSAT-8 multi-spectral images for improving land cover classification performance using Support Vector Machine (SVM) classifier. HH polarized C band RADARSAT-2 images were fused with the three band (6, 5, and 4) LANDSAT-8 multispectral image for land cover classification. Wavelet-based fusion (WT) techniques are implemented in the data fusion process. The Radial Basic Function (RBF) kernel function were used for SVM classifier in order to classify land cover types in the study area. The results of the SVM classification were compared with those using standard method Maximum Likelihood (ML) classifier, and it demonstrates a higher accuracy. Finally, it was indicated by the study that the fusion of SAR and optical images can significantly improve the classification accuracy with respect to use single dataset, and the SVM classifier could clearly outperform the standard method the ML classifier.","","978-1-4673-7297-8","10.1109/APSAR.2015.7306273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7306273","image fusion;RADARSAT-2;LANDSAT-8;land cover classification;Support Vector Machine (SVM)","Support vector machines;Remote sensing;Satellites;Earth;Accuracy;Kernel;Training","climatology;environmental monitoring (geophysics);geophysical image processing;image classification;image fusion;land cover;land use planning;radar imaging;radial basis function networks;remote sensing by radar;satellite communication;support vector machines;wavelet transforms","HH polarized C band RADARSAT-2 imagery fusion;LANDSAT-8 multispectral data;land cover classification performance improvement;SVM classifier;support vector machine classifier;multisource data;eco-environment monitoring;land use planning;climatic change detection;wavelet-based fusion techniques;WT techniques;data fusion process;radial basic function kernel function;RBF kernel function","","5","","27","IEEE","29 Oct 2015","","","IEEE","IEEE Conferences"
"A Multi-Sensor Approach to Separate Palm Oil Plantations from Forest Cover Using NDFI and a Modified Pauli Decomposition Technique","M. Erith; Z. Alfonso; L. Erik","Forestry Department, The Food and Agriculture Organization of the United Nations, Rome, Italy; Forestry Department, The Food and Agriculture Organization of the United Nations, Rome, Italy; Forestry Department, The Food and Agriculture Organization of the United Nations, Rome, Italy","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","4481","4484","In this work, a multi-sensor approach to separate oil palm plantations from forest cover using NDFI and a modified Pauli Decomposition technique is presented. The main contribution of this research is the potential to reduce misclassification of both classes, in the context of automated-base supervised classification algorithms, to decrease uncertainties derived through the detection and mapping process of forest cover. The hereby proposed method includes the generation of a primary forest map cover defining thresholds from a high resolution multi -spectral satellite image, and then the palm oil plantation will be filtered out from this classification using scattering mechanisms by a Pauli Decomposition approach. Preliminary results shown the capabilities of this approach in order to generate complementary information to separate the oil palm plantations from the forest cover classification.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324567","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324567","NDFI;Pauli Decomposition;Forest Cover Change;SAR Polarimetry;REDD+","Forestry;Oils;Remote sensing;Scattering;Uncertainty;Synthetic aperture radar;Satellites","forestry;geophysical image processing;image classification;terrain mapping;vegetation mapping","palm oil plantation;Pauli Decomposition approach;multisensor approach;separate palm oil plantations;forest cover;NDFI;modified Pauli Decomposition technique;separate oil palm plantations;automated-base supervised classification algorithms;mapping process;high resolution multi-spectral satellite image;primary forest map cover","","3","","9","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Channel Compressive Aperture Synthesis","T. Zheng; F. Hu; H. Hu; P. Fu","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","21 May 2020","2020","17","6","1027","1031","Aperture synthesis (AS) passive imaging technique has been proven effective in remote sensing for high resolution. Generally, a synthetic aperture radiometer needs the same number of channels as the antennas. As a consequence, the system complexity, volume, and cost increase rapidly as the size of the array expands. In this letter, the channel compressive AS (CCAS) method is proposed to reduce the receiver channels and correlators. Every channel connects to several different antennas by a selected connection network, and the visibilities are rebuilt from the cross correlation between output signals of the channels. Also, the principles of choosing connection network are discussed to guarantee the performance of the reconstructed brightness temperature (BT) images. Simulation results have shown the validation of the proposed method. It is of great application potential for very large-scale array in the future.","1558-0571","","10.1109/LGRS.2019.2937984","National Natural Science Foundation of China(grant numbers:61871438); China International Joint Research Center of Green Communications and Networking(grant numbers:2015B01008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848489","Channel compressive;connection network;synthetic aperture radiometer","Correlation;Apertures;Microwave radiometry;Antenna arrays;Image reconstruction;Redundancy","geophysical equipment;image reconstruction;radar interferometry;radiometers;radiometry;remote sensing;synthetic aperture radar","receiver channels;antennas;cross correlation;reconstructed brightness temperature images;channel compressive aperture synthesis;passive imaging technique;remote sensing;synthetic aperture radiometer","","4","","11","IEEE","25 Sep 2019","","","IEEE","IEEE Journals"
"High-Resolution RFI Localization Using Covariance Matrix Augmentation in Synthetic Aperture Interferometric Radiometry","J. Li; F. Hu; F. He; L. Wu","Huawei Technologies Co., Ltd., Shenzhen, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","26 Jan 2018","2018","56","2","1186","1198","Radio frequency interference (RFI) is a significant limiting factor in the retrieval of geophysical parameters measured by microwave radiometers. RFI localization is crucial to mitigate or remove the RFI impacts. In this paper, a novel RFI localization approach using covariance matrix augmentation in synthetic aperture interferometric radiometry (SAIR) is proposed. It utilizes the property of the sparse array configuration, which is commonly used in SAIR, where the sparse array can be viewed as a virtual filled array with much larger number of antenna elements. The approach can be applied in SAIR with a sparse array configuration, such as the European Space Agency Soil Moisture and Ocean Salinity (SMOS) mission. Results on real SMOS data show that, compared with the previous approach, the presented approach has an improved performance of RFI localization with comparable accuracy of localization, such as improved spatial resolution, lower sidelobes, and larger identifiable number of RFIs.","1558-0644","","10.1109/TGRS.2017.2761261","National Natural Science Foundation of China(grant numbers:61172100); Fundamental Research Funds for the Central Universities(grant numbers:HUST 2015QN093); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8085390","Beamforming;direction-of-arrival (DOA) estimation;microwave radiometry;radio frequency interference (RFI);Soil Moisture and Ocean Salinity (SMOS);sparse array antennas;synthetic aperture radiometry","Antenna arrays;Covariance matrices;Arrays;Array signal processing;Apertures;Microwave radiometry;Instruments","geophysical signal processing;radar interferometry;radiofrequency interference;radiometers;radiometry;remote sensing by radar;synthetic aperture radar","SMOS mission;European Space Agency Soil Moisture and Ocean Salinity mission;virtual filled array;sparse array configuration;SAIR;microwave radiometers;radio frequency interference;synthetic aperture interferometric radiometry;covariance matrix augmentation;high-resolution RFI localization","","18","","42","IEEE","26 Oct 2017","","","IEEE","IEEE Journals"
"Development Of Algorithms For The Estimation Of Hydrological Parameters Combining Cosmo-Skymed And Sentinel Time Series With In Situ Measurements","D. Tapete; F. Cigna; S. Paloscia; E. Santi; S. Pettinato; G. Fontanelli; E. Chiarito; C. Notarnicola; G. Cuozzo; A. Jacob; L. De Gregorio; M. Rossi","Italian Space Agency (ASI), Via del Politecnico s.n.c., Rome, Italy; Italian Space Agency (ASI), Via del Politecnico s.n.c., Rome, Italy; Institute of Applied Physics - National Research Council of Italy (IFAC–CNR), Sesto Fiorentino, Italy; Institute of Applied Physics - National Research Council of Italy (IFAC–CNR), Sesto Fiorentino, Italy; Institute of Applied Physics - National Research Council of Italy (IFAC–CNR), Sesto Fiorentino, Italy; Institute of Applied Physics - National Research Council of Italy (IFAC–CNR), Sesto Fiorentino, Italy; Institute of Applied Physics - National Research Council of Italy (IFAC–CNR), Sesto Fiorentino, Italy; Institute for Applied Remote Sensing, Bolzano, Italy; Institute for Applied Remote Sensing, Bolzano, Italy; Institute for Applied Remote Sensing, Bolzano, Italy; Institute for Applied Remote Sensing, Bolzano, Italy; Institute for Applied Remote Sensing, Bolzano, Italy","2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium (M2GARSS)","2 Jun 2020","2020","","","53","56","The collaborative research project “ALGORITHMS” (20192021) between the Italian Space Agency (ASI) and the Institute of Applied Physics of the National Research Council of Italy (IFAC–CNR) aims to develop innovative algorithms to estimate the main hydrological parameters (e.g. soil moisture content, vegetation properties, snow water equivalent). The proposed algorithms combine Synthetic Aperture Radar (SAR), multispectral and hyperspectral satellite data with in-situ measurements. First results are presented based on retrieval analyses and surveys over the test sites in northern and central Italy, using exceptionally long, consistent and multi-polarized C- and X-band SAR time series from the Copernicus Sentinel-1 and ASI’s COSMO-SkyMed missions, as well as Copernicus Sentinel2 high resolution multi-spectral imagery.","","978-1-7281-2190-1","10.1109/M2GARSS47143.2020.9105313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105313","Soil moisture content;snow water equivalent;sensitivity analysis;Artificial Neural Networks;COSMO-SkyMed;Sentinels","Water;Satellites;Soil measurements;Snow;Time series analysis;Soil moisture;Vegetation mapping","radar imaging;radar interferometry;remote sensing by radar;snow;synthetic aperture radar;vegetation;vegetation mapping","C-band SAR time series;Copernicus Sentinel-2 high resolution multispectral imagery;ASI COSMO-SkyMed mission;ALGORITHMS;National Research Council of Italy;Italian Space Agency;collaborative research project;Sentinel time series;Copernicus Sentinel-1 mission;X-band SAR time series;central Italy;northern Italy;hyperspectral satellite data;snow water equivalent;vegetation properties;moisture content;hydrological parameters;IFAC-CNR;Institute of Applied Physics","","11","","3","IEEE","2 Jun 2020","","","IEEE","IEEE Conferences"
"Collaborative Mapping Rice Planting Areas Using Multisource Remote Sensing Data","P. Zhai; S. Li; Z. He; Y. Deng; Y. Hu","School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; The Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou, China; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5969","5972","Recent satellite missions have provided a variety of high spatial resolution, multi-spectral, and high-frequency revisit remote sensing datasets. The collaborative use of optical and synthetic aperture radar (SAR) imagery in remote sensing applications attracts considerable attention. The purpose of this paper is to investigate the contribution of both data to the rice planting area mapping. In particular, the red-edge band was introduced to construct a red-edge vegetation index based on Sentinel-2 data. C-band quad-pol Radarsat-2 data was also used. We finally used the random forest algorithm, collaborating with optical and radar data to map rice planting area. We found that the red-edge band and red-edge vegetation index can improve the classification accuracy compared to the classifier using NIR (near-infrared) band and NDVI (Normalized Difference Vegetation Index). The result shows that the jointly use of optical and radar data is feasible to map rice planting area. The overall accuracy, recall and F-measure are 0.9441, 0.9598 and 0.9680, respectively.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553245","National Natural Science Foundation of China(grant numbers:2020YFG0033,41871247); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553245","red edge;SAR;rice mapping;random forest;Sentinel-2;Radarsat-2","Radar remote sensing;Laser radar;Spaceborne radar;Vegetation mapping;Optical imaging;Adaptive optics;Optical sensors","crops;geophysical image processing;image classification;radar imaging;radar polarimetry;remote sensing;remote sensing by radar;synthetic aperture radar;vegetation;vegetation mapping","Sentinel-2 data;c-band quad-pol Radarsat-2 data;optical radar data;map rice planting area;red-edge band;red-edge vegetation index;NIR band;Normalized Difference Vegetation Index;red edge;rice mapping;collaborative mapping rice planting areas;multisource remote sensing data;recent satellite missions;high spatial resolution;high-frequency revisit remote sensing datasets;remote sensing applications;rice planting area mapping","","1","","12","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Oil Spill Impacts on Mangrove Forest from Satellite Remote Sensing","S. S. Farhana Ahmad; N. Hazrina Idris","Department of Geoinformation, Faculty of Built Environment and Surveying, Universiti Teknologi Malaysia, Johor Darul Takzim, Malaysia; Tropical Resource Mapping Research Group, Department of Geoinformation, Faculty of Built Environment and Surveying, Universiti Teknologi Malaysia, Johor Darul Takzim, Malaysia","2021 7th International Conference on Space Science and Communication (IconSpace)","9 May 2022","2021","","","60","64","The mangrove forest has been continuously threatened by oil spills occurring on the sea surfaces. The oil spills pose and cause severe and long-term effect havoc on mangrove forests that sustain them. Previous research has found that satellite remote sensing technologies are one of the most effective techniques to detect oil spills and assess the health of mangrove forests in contaminated areas. This study utilized the Synthetic-Aperture Radar (SAR) images from dualpolarized Sentinel-1 and Multi-Spectral Instrument (MSI) from Sentinel-2 to study the impact of oil spills on Mangrove Forest in Pantai Cermin, Negeri Sembilan. The Random Forest classification was used to detect the oil spill areas, while vegetation indices were used to assess the impact of oil pollution on mangrove forests in the early stages. Analysis from Sentinel1 imagery shows that the oil spill could be accurately detected using the Random Forest classifer with accuracy of 76%. Spectral indices: the normalized difference vegetation index (NDVI) was explored and evaluated to study the health of mangrove forest after the oil spills event. It is found that the oil spills have caused physical suffocation as well as toxicological effects to the mangrove forests.","2165-431X","978-1-6654-2523-0","10.1109/IconSpace53224.2021.9768774","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768774","oil spill;remote sensing;sentinel 1;sentinel 2","Sea surface;Radar remote sensing;Satellites;Oils;Surface contamination;Spaceborne radar;Vegetation mapping","geophysical image processing;image classification;marine pollution;oil pollution;radar imaging;remote sensing;remote sensing by radar;synthetic aperture radar;toxicology;vegetation;vegetation mapping","Random Forest classifer;mangrove forest;oil spill impacts;Random Forest classification;oil spill areas","","","","4","IEEE","9 May 2022","","","IEEE","IEEE Conferences"
"SpaceFibre: A multi-Gigabit/s interconnect for spacecraft onboard data handling","S. Parkes; C. McClements; D. McLaren; A. F. Florit; A. G. Villafranca","Space Technology Centre, University of Dundee, Dundee, UK; Space Technology Centre, University of Dundee, Dundee, UK; Space Technology Centre, University of Dundee, Dundee, UK; STAR-Dundee Ltd., Dundee, UK; STAR-Dundee Ltd., Dundee, UK","2015 IEEE Aerospace Conference","8 Jun 2015","2015","","","1","13","SpaceFibre is a spacecraft onboard data link and network technology being developed by University of Dundee for the European Space Agency (ESA), which runs over both copper and fibre optic cables. Initially targeted at very high data rate payloads such as Synthetic Aperture Radar (SAR) and multi-spectral imaging instruments, SpaceFibre is capable of fulfilling a wider set of spacecraft onboard communications applications because of its inbuilt QoS and FDIR capabilities and its backwards compatibility with the ubiquitous SpaceWire technology. SpaceFibre operates at 2.5 Gbits/s providing 12 times the throughput of a SpaceWire link with current flight qualified technology and allowing data from multiple SpaceWire devices to be concentrated over a single SpaceFibre link. This substantially reduces cable harness mass and simplifies redundancy strategies. The innovative QoS mechanism in SpaceFibre provides concurrent bandwidth reservation, priority and scheduled QoS. This simplifies spacecraft system engineering through integrated quality of service (QoS), which reduces system engineering costs and streamlines integration and test. Novel integrated FDIR support provides galvanic isolation, transparent recovery from transient errors, error containment in virtual channels and frames, and “Babbling Idiot” protection. SpaceFibre enhances onboard network robustness through its inherent FDIR and graceful degradation techniques incorporated in the network hardware. This simplifies system FDIR software, reducing development and system validation time and cost. SpaceFibre includes low latency event signalling and time distribution with broadcast messages. This enables a single network to be used for several functions including: transporting very high data rate payload data, carrying SpaceWire traffic, deterministic delivery of command/control information, time distribution and event signalling. SpaceFibre is backwards compatible with existing SpaceWire equipment at the packet level allowing simple interconnection of SpaceWire devices into a SpaceFibre network and enabling that equipment to take advantage of the QoS and FDIR capabilities of SpaceFibre.","1095-323X","978-1-4799-5380-6","10.1109/AERO.2015.7119317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119317","SpaceWire;SpaceFibre;Network;Spacecraft Onboard Data-Handling;Quality of Service;FDIR;Next Generation Interconnect","Bandwidth;Quality of service;Standards;Instruments;Radiation detectors;Space vehicles;Payloads","aerospace instrumentation;data handling;quality of service;spaceborne radar;synthetic aperture radar","SpaceFibre;spacecraft onboard data handling;University of Dundee;European Space Agency;ESA;copper cables;fibre optic cables;synthetic aperture radar;multispectral imaging instruments;SpaceWire technology;innovative QoS mechanism;quality of service;FDIR software","","21","","6","IEEE","8 Jun 2015","","","IEEE","IEEE Conferences"
"Monitoring LULC dynamics in the Sao Paulo region through landsat and C-band SAR time series","L. Iannini; R. Molijn; A. Mousivand; R. Hanssen","Geoscience and Remote Sensing Department, Delft University of Technology; Geoscience and Remote Sensing Department, Delft University of Technology; Geoscience and Remote Sensing Department, Delft University of Technology; Geoscience and Remote Sensing Department, Delft University of Technology","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","90","93","The paper debates a novel approach for sugarcane identification and characterization based on multi-spectral and multi-temporal profile matching. A parametric model aimed at identifying sugarcane among pasture/grasses/shrubs, annual crops and forest is proposed. Differently from other supervised and unsupervised classification techniques, the discussed profile-based parametric model accounts for variability in growth date, that becomes valuable information to be extracted, rather than simply a nuisance parameter, and delivers an effective extrapolation of the cane vigor. The approach is then applied to Landsat 5 TM and ERS/ENVISAT SAR time-series over the Orindiuva area attaining preliminary promising although perfectible results.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7325705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325705","Crop identification;sugarcane mapping;multi-sensor analysis;curve fitting","Remote sensing;Agriculture;Satellites;Synthetic aperture radar;Earth;Vegetation mapping;Sensors","remote sensing by radar;time series;vegetation mapping","sugarcane identification;multispectral profile matching;multitemporal profile matching;C-band SAR time series;LandSAT;ERS/ENVISAT SAR time-series;Orindiuva area;monitoring LULC dynamics","","1","","6","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Assessment of a Random Forest Classifier in Urban Local Climate Zone Classification Using Sentinel-2 and PALSAR-2","C. Chen; H. Bagan; X. Xie; L. Tan; Y. Yamagata","School of Environmental and Geographical Sciences, Shanghai Normal University, Shanghai, China; Center for Global Environmental Research, National Institute for Environmental Studies, Ibaraki, Japan; School of Environmental and Geographical Sciences, Shanghai Normal University, Shanghai, China; School of Environmental and Geographical Sciences, Shanghai Normal University, Shanghai, China; Center for Global Environmental Research, National Institute for Environmental Studies, Ibaraki, Japan","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","6797","6800","This study evaluated different input features for the local climate zone (LCZ) classification using a random forest (RF) classifier. The input features included spectral reflectance and textural features from Sentinel-2 multi-spectral imagery and polarimetric features from dual-polarized ($\text{HH}+\text{HV}$) PALSAR-2 data. The analysis of the feature importance for the RF classifier was measured by Gini and permutation importance. The analysis of the feature contributions to each LCZ class was performed by a feature contribution method based on decision paths in the RF. The results showed that the multi-spectral bands from Sentinel-2 imagery played a dominant role in LCZ classification, especially Band 12 (short-wave infrared-2). The contributions of the PALSAR-2 HV polarization band were higher in land cover LCZ types than in built LCZ types. The combined analysis of feature importance and contribution would provide a reference for the performance of RF classifiers in terms of LCZ mapping.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553260","National Natural Science Foundation of China(grant numbers:41771372); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553260","Local climate zone;Random forest;Feature importance;Feature contribution;Nanchang","Radio frequency;Reflectivity;Geoscience and remote sensing;Forestry;Random forests;Meteorology","geophysical image processing;image classification;image texture;land cover;radar polarimetry;remote sensing;remote sensing by radar;synthetic aperture radar","LCZ mapping;built LCZ types;land cover LCZ types;PALSAR-2 HV polarization band;LCZ classification;Sentinel-2 imagery;multispectral bands;feature contribution method;LCZ class;feature contributions;permutation importance;RF classifier;feature importance;PALSAR-2 data;dual-polarized;polarimetric features;Sentinel-2 multispectral imagery;textural features;spectral reflectance;different input features;urban local climate zone classification;random forest classifier","","","","11","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Mediterranean shrublands biomass estimation using Sentinel-1 and Sentinel-2","J. Chang; M. Shoshany","Department of Civil and Environment Engineering, Technion-Israel Institute of Technology, Haifa, Israel; Department of Civil and Environment Engineering, Technion-Israel Institute of Technology, Haifa, Israel","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","5300","5303","Potential for synergetic use of Sentinel- 1 and Sentinel-2 for mapping biomass of Mediterranean shrublands is investigated. As preliminary research, backscatter and its ratio from Sentinel-1 (C-band dual polarization SAR), and NDVI from Sentinel-2 (13 bands multi-spectral data) are assessed by using the NDVIR biomass model. Then the fusion biomass model is proposed based on shrub volume formations. The fusion model is verified by filed survey data which measured shrub height and diameter applied into the allometric model. The proposed fusion model shows around 14 % improvement of accuracy compared to the single sensor model (r-square: from 0.72 to 0.86, RMSE: from 0.158 to 0.109).","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7730380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7730380","Biomass;C-band SAR;Mediterranean;Fusion;Semi-arid;Sentinel;Shrublands","Biomass;Biological system modeling;Remote sensing;Data models;Estimation;Vegetation mapping;Mathematical model","remote sensing by radar;synthetic aperture radar;vegetation mapping","Mediterranean shrubland biomass estimation;Sentinel-1;Sentinel-2;biomass mapping;C-band dual polarization SAR;multispectral data;NDVIR biomass model;fusion biomass model;shrub volume formation;proposed fusion model;allometric model;single sensor model","","24","","11","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Combined Use of Optical and SAR Images for Mapping Coastal Erosion Risk","M. Bresciani; N. Ghirardi; G. Fornaro; V. Zamparelli; F. De Santi; G. De Carolis; D. Tapete; M. Palandri; C. Giardino","CNR - Institute for Electromagnetic Sensing of the Environment, Italy; CNR - Institute for Electromagnetic Sensing of the Environment, Italy; CNR - Institute for Electromagnetic Sensing of the Environment, Italy; CNR - Institute for Electromagnetic Sensing of the Environment, Italy; CNR - Institute for Electromagnetic Sensing of the Environment, Italy; CNR - Institute for Electromagnetic Sensing of the Environment, Italy; ASI - Italian Space Agency (ASI); e-GEOS S.p.A.; CNR - Institute for Electromagnetic Sensing of the Environment, Italy","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","7549","7552","This study demonstrates the use of a novel satellite remote sensing approach to map coastal erosion vulnerability in the Italian site of Piscinas (Sardinia). We focused on the land/water transitional ecosystem, to identify potential coastal erosion phenomena. For this analysis, a synergistic approach between multi-spectral satellite data (Sentinel-2) and SAR imagery (COSMO-SkyMed and Sentinel-1B) was exploited. Two vulnerability maps were created: one longterm (2016–2018) and one short-term (wind event). The results confirm how the coastal vulnerability of this site seems to be linked to episodic events, consequently, the dune system of Piscinas might be considered safe from coastal erosion processes.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554000","Italian Space Agency (ASI); ASI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554000","Remote sensing;Coastal zones;Vulnerability maps;Optical images;Radar images","Satellites;Ecosystems;Sea measurements;Optical imaging;Radar polarimetry;Optical fiber communication;Optical sensors","erosion;geophysical image processing;radar imaging;remote sensing;remote sensing by radar;synthetic aperture radar","map coastal erosion vulnerability;Italian site;Piscinas;potential coastal erosion phenomena;synergistic approach;multispectral satellite data;Sentinel-2;SAR imagery;COSMO-SkyMed;Sentinel-1B;vulnerability maps;short-term;coastal vulnerability;coastal erosion processes;SAR images;mapping coastal erosion risk;satellite remote","","2","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"The Potential of Sentinel Satellites for Large Area Aboveground Forest Biomass Mapping","A. Haywood; C. Stone; S. Jones","School of Mathematical and Geospatial Sciences, RMIT University, Melbourne, Australia; New South Wales Department of Industry - Lands, Sydney, Australia; School of Mathematical and Geospatial Sciences, RMIT University, Melbourne, Australia","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","9030","9033","Estimation of aboveground forest biomass is critical for regional carbon policies and sustainable forest management. Both passive optical remote sensing and active microwave remote sensing can play an important role in the monitoring of forest biomass. In this study, the recently launched Sentinel-2 Multi Spectral Instrument satellite and Sentinel-1 SAR satellite systems were evaluated and integrated to investigate the relative strengths of each sensor for mapping aboveground forest biomass at a regional scale. The Australian state of Victoria, with its wide range of forest vegetation was chosen as the study area to demonstrate the scalability and transferability of the approach. In this study aboveground forest biomass (AGB) was defined as the tons of carbon per hectare for the aboveground components (stem, branches, leaves) of all live large trees greater than 10 cm in diameter at breast height (DBHOB). Sentinel-2 and Sentinel-1 data were fused within a machine learning framework using a boosted regression tree model and high-quality ground survey data. Multicriteria evaluations showed the use of the two independent and fundamentally different Sentinel satellite systems were able to provide robust estimates (R2 of 0.62, RMSE of 32.2 t.C.ha-1) of aboveground forest biomass, with each sensor compensating for the weakness (cloud perturbations and spectral saturation for Sentinel 2, and sensitivity to ground moisture for Sentinel 1) of each other. As archives for Sentinel-2 and Sentinel-1 continue to grow, mapping aboveground forest biomass and dynamics at moderate resolution over large regions should become increasingly feasible.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517597","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517597","biomass estimation;Sentinel-1;Sentinel-2;machine learning;boosted regression tree model;data fusion;Victoria;Australia","Forestry;Biomass;Vegetation;Meteorology;Satellites;Surfaces;Carbon","forestry;geophysical techniques;regression analysis;remote sensing by radar;synthetic aperture radar;vegetation;vegetation mapping","Sentinel satellite systems;Sentinel-2 MultiSpectral Instrument satellite;diameter at breast height;ground moisture;Australian state;Victoria;high-quality ground survey data;boosted regression tree model;Sentinel-1 data;aboveground components;forest vegetation;Sentinel-1 SAR satellite systems;active microwave remote sensing;passive optical remote sensing;sustainable forest management;area aboveground forest biomass mapping","","1","","11","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Large Scale Forest Parameter Estimation Through a Deep Learning-Based Fusion of Sentinel-2 and Tandem-X Data","D. Carcereri; P. Rizzoli; D. Ienco; J. -L. Bueso-Bello; C. González; S. Puliti; L. Brurzone","Universitá degli studi di Trento (UNITN), Italy; German Aerospace Center (DLR), Microwaves and Radar Institute; National Research Institute for Agriculture, Food and the Environment (INRAE), France; German Aerospace Center (DLR), Microwaves and Radar Institute; German Aerospace Center (DLR), Microwaves and Radar Institute; Norwegian Institute of Bioeconomy Research (NIBIO), Norway; Universitá degli studi di Trento (UNITN), Italy","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","5773","5776","The estimation of forest parameters, such as canopy height model (CHM) and above ground biomass (AGB), is of ut-most importance for forest monitoring, carbon-cycle modelling, disturbance analysis, resource inventorying and natural disaster prevention. In this work, we profit from the most recent advancements in deep learning research to propose a convolutional neural network (CNN) architecture for frequent forest parameter estimation at large scale. Our technique consists of a fully convolutional, multi-modal framework, which works on a single set of complementary multi-spectral and interferometric SAR data, acquired by ESA's Sentinel-2 and DLR's TanDEM-X missions, respectively. The regression performance of our framework has been tested over four tropical forest test sites in Gabon, Africa. The estimation of CHM shows promising early results when compared to state-of-the-art methods and has the advantage of requiring only a single input image pair instead of a longer time-series, as commonly done for state-of-the-art model-based techniques.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884872","forest monitoring;forest height;deep learning;sensor fusion;Sentinel-2;TanDEM-X","Deep learning;Analytical models;Parameter estimation;Biological system modeling;Estimation;Geoscience and remote sensing;Forestry","forestry;learning (artificial intelligence);neural nets;radar interferometry;remote sensing by radar;synthetic aperture radar;vegetation;vegetation mapping","scale forest parameter estimation;deep learning-based fusion;tandem-X data;forest parameters;canopy height model;CHM;ground biomass;ut-most importance;forest monitoring;carbon-cycle modelling;disturbance analysis;resource inventorying;natural disaster prevention;deep learning research;convolutional neural network architecture;frequent forest parameter estimation;multimodal framework;complementary multispectral;ESA's Sentinel-2;DLR's TanDEM-X missions;tropical forest test sites;state-of-the-art model-based techniques","","","","18","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Improving SAR and Optical Image Fusion for Lulc Classification with Domain Knowledge","K. R. Prabhakar; V. H. Nukala; J. Gubbi; A. Pal; B. P","TCS Research, INDIA; TCS Research, INDIA; TCS Research, INDIA; TCS Research, INDIA; TCS Research, INDIA","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","711","714","Fusing SAR and multi-spectral images to generate a precise land cover map in a weakly supervised setting is a challenging yet essential problem. The inaccurate, noisy, and inexact ground truth labels pose difficulty training any machine learning models. In this paper, we make a fundamental and pivotal contribution towards improving the ground truth label quality using domain knowledge. We present a simple yet effective mechanism to refine the low-resolution noisy ground truth labels. The proposed approach is trained and tested on a publicly available DFC2020 dataset. Through experiments, we show the effectiveness of our method by training a deep learning model on the refined labels that outperform even the models trained with clean ground truth.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884283","CNN;SAR;multispectral;image fusion","Training;Deep learning;Training data;Geoscience and remote sensing;Optical imaging;Noise measurement;Reliability","geophysical image processing;image classification;image fusion;land cover;learning (artificial intelligence);optical images;radar imaging;synthetic aperture radar;terrain mapping","SAR;multispectral images;precise land cover map;weakly supervised setting;challenging yet essential problem;inaccurate ground truth labels;noisy, ground truth labels;inexact ground truth labels;machine learning models;fundamental contribution;pivotal contribution;domain knowledge;simple yet effective mechanism;low-resolution noisy ground truth labels;publicly available DFC2020 dataset;deep learning model;refined labels;clean ground truth;optical image fusion;lulc classification","","","","8","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"SAR-to-Optical Image Translation Using Supervised Cycle-Consistent Adversarial Networks","L. Wang; X. Xu; Y. Yu; R. Yang; R. Gui; Z. Xu; F. Pu","Collaborative Sensing Laboratory, School of Electronic Information, Wuhan University, Wuhan, China; Collaborative Sensing Laboratory, School of Electronic Information, Wuhan University, Wuhan, China; Collaborative Sensing Laboratory, School of Electronic Information, Wuhan University, Wuhan, China; Collaborative Sensing Laboratory, School of Electronic Information, Wuhan University, Wuhan, China; Collaborative Sensing Laboratory, School of Electronic Information, Wuhan University, Wuhan, China; Electrical Engineering Department, Stanford University, Stanford, CA, USA; Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China","IEEE Access","19 Sep 2019","2019","7","","129136","129149","Optical remote sensing (RS) data suffer from the limitation of bad weather and cloud contamination, whereas synthetic aperture radar (SAR) can work under all weather conditions and overcome this disadvantage of optical RS data. However, due to the imaging mechanism of SAR and the speckle noise, untrained people are difficult to recognize the land cover types visually from SAR images. Inspired by the excellent image-to-image translation performance of Generative Adversarial Networks (GANs), a supervised Cycle-Consistent Adversarial Network (S-CycleGAN) was proposed to generate large optical images from the SAR images. When the optical RS data are unavailable or partly unavailable, the generated optical images can be alternative data that aid in land cover visual recognition for untrained people. The main steps of SAR-to-optical image translation were as follows. First, the large SAR image was split to small patches. Then S-CycleGAN was used to translate the SAR patches to optical image patches. Finally, the optical image patches were stitched to generate the large optical image. A paired SAR-optical image dataset which covered 32 Chinese cities was published to evaluate the proposed method. The dataset was generated from Sentinel-1 (SEN-1) SAR images and Sentinel-2 (SEN-2) multi-spectral images. S-CycleGAN was applied to two experiments, which were SAR-to-optical image translation and cloud removal, and the results showed that S-CycleGAN could keep both the land cover and structure information well, and its performance was superior to some famous image-to-image translation models.","2169-3536","","10.1109/ACCESS.2019.2939649","National Basic Research Program of China (973 Program)(grant numbers:2016YFB0502600); Thirteen-Five Civil Aerospace Planning Project — Integration of Communication, Navigation and Remote Sensing Comprehensive Application Technology; Chinese Technology Research and Development of the Major Project of High-Resolution Earth Observation System(grant numbers:03-Y20A10-9001-15/16); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8825802","SAR-to-optical image translation;visualization;GAN;Sentinel;cloud removal","Radar polarimetry;Optical imaging;Clouds;Optical sensors;Adaptive optics;Optical polarization;Gallium nitride","geophysical image processing;optical images;radar imaging;remote sensing by radar;synthetic aperture radar;terrain mapping","SAR-to-optical image translation;supervised Cycle-Consistent Adversarial Networks;optical remote sensing data;optical RS data;imaging mechanism;generated optical images;SAR patches;optical image patches;paired SAR-optical image dataset;Sentinel-1 SAR images;multispectral images;image-to-image translation models;S-CycleGAN;Chinese cities;land cover;Generative Adversarial Networks;weather conditions;cloud contamination;bad weather","","59","","58","CCBY","5 Sep 2019","","","IEEE","IEEE Journals"
"Change detection analysis of tornado disaster using conditional copulas and Data Fusion for cost-effective disaster management","B. Gokaraju; A. C. Turlapaty; D. A. Doss; R. L. King; N. H. Younan",The University of West Alabama; VR Siddhartha Engineering College; The University of West Alabama; Mississippi State University; Mississippi State University,"2015 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)","31 Mar 2016","2015","","","1","8","The up-to-date results are presented from an ongoing study of the Data Fusion of multi-temporal and multi-sensor satellite datasets for near real time damage and debris assessment after a tornado disaster event. The space-borne sensor datasets comprising of: (i) C-band SAR dataset from RADARSAT-2; (ii) Multi-Spectral (MS) optical dataset including NIR from RapidEye; (iii) MS and panchromatic dataset of Advanced Linear Imaging (ALI), are studied for multi-sensor data fusion. A combined approach of multi-polarized radiometric and textural feature extraction, and statistical learning based feature classification is devised for fine tuning of the complex and generalized change detection model. We also investigated the use of multi-variate conditional copula as a classifier technique, by formulating the change and no-change as a binary-class classification problem in this study. The classification results from the above technique are used for assessment of damage and debris cover after the tornado disaster event. The performance of the above approach yields a very significant Kappa accuracy up to 75%. A 10-fold cross validation strategy is used for quantitative analysis of the performance of the classification model. This study will be further extended for modelling the effect of incidence angle discrepancies or climatic condition variances, which will address the heterogeneity factor in terms of local statistics of the dataset.","2332-5615","978-1-4673-9558-8","10.1109/AIPR.2015.7444537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7444537","change detection;machine learning;conditional Copula;disaster management;data fusion","Tornadoes;Data integration;Spatial resolution;Synthetic aperture radar;Feature extraction;Remote sensing;Disaster management","emergency management;feature extraction;image classification;learning (artificial intelligence);radar imaging;remote sensing;sensor fusion;statistical distributions;storms","change detection analysis;tornado disaster management;conditional copula;multisensor data fusion;C-band SAR dataset;RADARSAT-2;NIR;RapidEye;advanced linear imaging;ALI;feature extraction;statistical learning;feature classification","","10","","19","IEEE","31 Mar 2016","","","IEEE","IEEE Conferences"
"Table of contents","",,"2016 Sensor Signal Processing for Defence (SSPD)","18 Oct 2016","2016","","","i","iii","The following topics are dealt with: adaptive receiver search strategy; environmental dependent modeling; Gaussian particle filtering; ground vehicle tracking ; robust detection; micro-UAS drones; L-band 3-D holographic radar; direction finding antenna arrays; cognitive radar waveform design; full-polarization micro-Doppler; microwave anechoic chamber; fractional Fourier transform based co-radar waveform; underwater LiDAR target signatures; sparse multi-spectral depth codes; circular SAR data; digital elevation model aided SAR-based GMTI processing; multi-family GLRT; polarimetric SAR images; novel motion compensation approach; SAS; spectral library clustering; Bayesian information criterion; modified spectral line camera; bistatic micro-doppler characteristics; high dynamic range spectral estimation; small UAV traffic; robust unmixing algorithms; hyperspectral imagery; radar filters; target Doppler frequency; interference covariance matrix uncertainties; 3D RF-seeker antenna arrays; adaptive M-estimation; robust cubature Kalman filtering; fractional Fourier based sparse channel estimation; multicarrier underwater acoustic communication system; multiple spherical arrays design; acoustic source localization; space geodesy facility laser ranging sensor; Joint array and spatial sparsity based optimisation; DoA estimation; enhanced-range intrusion detection; pyroelectric infrared sensors; knowledge-aided adaptive detection and multipath exploitation radar.","","978-1-5090-0326-6","10.1109/SSPD.2016.7590580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590580","","","anechoic chambers (electromagnetic);antenna arrays;autonomous aerial vehicles;channel estimation;cognitive radio;covariance matrices;digital elevation models;direction-of-arrival estimation;Fourier transforms;Gaussian processes;holography;hyperspectral imaging;infrared detectors;interference;Kalman filters;motion compensation;object tracking;optical radar;optimisation;particle filtering (numerical methods);radar imaging;radar polarimetry;receivers;security of data;synthetic aperture radar","high dynamic range spectral estimation;small UAV traffic;robust unmixing algorithms;hyperspectral imagery;radar filters;target Doppler frequency;interference covariance matrix uncertainties;3D RF-seeker antenna arrays;adaptive M-estimation;robust cubature Kalman filtering;fractional Fourier based sparse channel estimation;multicarrier underwater acoustic communication system;multiple spherical arrays design;acoustic source localization;space geodesy facility laser ranging sensor;joint array and spatial sparsity based optimisation;DoA estimation;enhanced-range intrusion detection;pyroelectric infrared sensors;knowledge-aided adaptive detection;multipath exploitation radar;bistatic micro-doppler characteristics;modified spectral line camera;Bayesian information criterion;spectral library clustering;SAS;novel motion compensation approach;polarimetric SAR images;multi-family GLRT;digital elevation model aided SAR-based GMTI processing;circular SAR data;sparse multispectral depth codes;underwater LiDAR target signatures;fractional Fourier transform based co-radar waveform;microwave anechoic chamber;full-polarization micro-Doppler;cognitive radar waveform design;direction finding antenna arrays;L-band 3D holographic radar;micro-UAS drones;robust detection;ground vehicle tracking;Gaussian particle filtering;environmental dependent modeling;adaptive receiver search strategy","","","","","IEEE","18 Oct 2016","","","IEEE","IEEE Conferences"
